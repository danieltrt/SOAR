file_path,api_count,code
eval_network.py,0,"b'#! /usr/bin/env python3\n\n\'\'\'\nClassify sounds using database - evaluation code.\nGenerates a score based on contents of Preproc/Test/\n\nAuthor: Scott H. Hawley\n\nThis is kind of a mixture of Keun Woo Choi\'s code https://github.com/keunwoochoi/music-auto_tagging-keras\n   and the MNIST classifier at https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n\nTrained using Fraunhofer IDMT\'s database of monophonic guitar effects,\n   clips were 2 seconds long, sampled at 44100 Hz\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'Agg\')\n\nfrom keras.models import  load_model\nimport matplotlib.pyplot as plt\nimport librosa\nimport os\nfrom panotti.models import *\nfrom panotti.datautils import *\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom timeit import default_timer as timer\n\n\ndef create(n, constructor=list):   # creates an list of empty lists\n    for _ in range(n):\n        yield constructor()\n\ndef count_mistakes(y_scores,Y_test,paths_test,class_names):\n    n_classes = len(class_names)\n    mistake_count = np.zeros(n_classes)\n    mistake_log = list(create(n_classes))\n    max_string_len = 0\n    for i in range(Y_test.shape[0]):\n        pred = decode_class(y_scores[i],class_names)\n        truth = decode_class(Y_test[i],class_names)\n        if (pred != truth):\n            mistake_count[truth] += 1\n            max_string_len = max( len(paths_test[i]), max_string_len )\n            mistake_log[truth].append( paths_test[i].ljust(max_string_len)+"": should be ""+class_names[truth]+\n                "" but came out as ""+class_names[pred])\n\n    mistakes_sum = int(np.sum(mistake_count))\n    print(""    Found"",mistakes_sum,""total mistakes out of"",Y_test.shape[0],""attempts"")\n    print(""      Mistakes by class: "")\n\n    for i in range(n_classes):\n        print(""          class \\\'"",class_names[i],""\\\': "",int(mistake_count[i]), sep="""")\n        for j in range(len(mistake_log[i])):\n            print(""                  "",mistake_log[i][j])\n    return\n\n\ndef eval_network(weights_file=""weights.hdf5"", classpath=""Preproc/Test/"", batch_size=40):\n    np.random.seed(1)\n\n    # get the data\n    X_test, Y_test, paths_test, class_names = build_dataset(path=classpath, batch_size=batch_size)\n    print(""class names = "",class_names)\n    n_classes = len(class_names)\n\n    # Load the model\n    model, serial_model = setup_model(X_test, class_names, weights_file=weights_file, missing_weights_fatal=True)\n    model.summary()\n\n    num_pred = X_test.shape[0]\n\n    print(""Running predict..."")\n    y_scores = model.predict(X_test[0:num_pred,:,:,:],batch_size=batch_size)\n\n\n    print(""Counting mistakes "")\n    count_mistakes(y_scores,Y_test,paths_test,class_names)\n\n    print(""Measuring ROC..."")\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    auc_score = roc_auc_score(Y_test, y_scores)\n    print(""Global AUC = "",auc_score)\n\n    print(""\\nDrawing ROC curves..."")\n    fig = plt.figure()\n    lw = 2                      # line width\n    for i in range(n_classes):\n        plt.plot(fpr[i], tpr[i], lw=lw, label=class_names[i]+"": AUC=""+\'{0:.4f}\'.format(roc_auc[i]))\n    plt.plot([0, 1], [0, 1], color=\'navy\', lw=lw, linestyle=\'--\')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel(\'False Positive Rate\')\n    plt.ylabel(\'True Positive Rate\')\n    plt.title(\'Receiver operating characteristic\')\n    plt.legend(loc=""lower right"")\n    plt.draw()\n    #plt.show(block=False)\n    roc_filename = ""roc_curves.png""\n    print(""Saving curves to file"",roc_filename)\n    plt.savefig(roc_filename)\n    plt.close(fig)\n    print("""")\n\n    # evaluate the model\n    print(""Running model.evaluate..."")\n    scores = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)\n    print(\'Test loss:\', scores[0])\n    print(\'Test accuracy:\', scores[1])\n    print(""All model scores:"")\n    print(model.metrics_names)\n    print(scores)\n\n    print(""\\nFinished."")\n    #plt.show()\n    return\n\n\nif __name__ == \'__main__\':\n    import argparse\n    parser = argparse.ArgumentParser(description=""evaluates network on testing dataset"")\n    parser.add_argument(\'-w\', \'--weights\', #nargs=1, type=argparse.FileType(\'r\'),\n        help=\'weights file in hdf5 format\', default=""weights.hdf5"")\n    parser.add_argument(\'-c\', \'--classpath\', #type=argparse.string,\n        help=\'test dataset directory with list of classes\', default=""Preproc/Test/"")\n    parser.add_argument(\'--batch_size\', default=40, type=int, help=""Number of clips to send to GPU at once"")\n\n    args = parser.parse_args()\n    eval_network(weights_file=args.weights, classpath=args.classpath, batch_size=args.batch_size)\n'"
predict_class.py,0,"b'#! /usr/bin/env python3\n\'\'\'\nGiven one audio clip, output what the network thinks\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nimport librosa\nimport os\nfrom os.path import isfile\nfrom panotti.models import *\nfrom panotti.datautils import *\n\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'  # less TF messages, thanks\n\ndef get_canonical_shape(signal):\n    if len(signal.shape) == 1:\n        return (1, signal.shape[0])\n    else:\n        return signal.shape\n\n\ndef predict_one(signal, sr, model, expected_melgram_shape):# class_names, model)#, weights_file=""weights.hdf5""):\n    X = make_layered_melgram(signal,sr)\n    print(""signal.shape, melgram_shape, sr = "",signal.shape, X.shape, sr)\n\n    if (X.shape[1:] != expected_melgram_shape):   # resize if necessary, pad with zeros\n        Xnew = np.zeros([1]+list(expected_melgram_shape))\n        min1 = min(  Xnew.shape[1], X.shape[1]  )\n        min2 = min(  Xnew.shape[2], X.shape[2]  )\n        min3 = min(  Xnew.shape[3], X.shape[3]  )\n        Xnew[0,:min1,:min2,:min3] = X[0,:min1,:min2,:min3]  # truncate\n        X = Xnew\n    return model.predict(X,batch_size=1,verbose=False)[0]\n\n\ndef main(args):\n    np.random.seed(1)\n    weights_file=args.weights\n    dur = args.dur\n    resample = args.resample\n    mono = args.mono\n\n    # Load the model\n    model, class_names = load_model_ext(weights_file)\n    if model is None:\n        print(""No weights file found.  Aborting"")\n        exit(1)\n\n    #model.summary()\n\n    #TODO: Keras load_models is spewing warnings about not having been compiled. we can ignore those,\n    #   how to turn them off?  Answer: can invoke with python -W ignore ...\n\n    #class_names = get_class_names(args.classpath) # now encoding names in model weights file\n    nb_classes = len(class_names)\n    print(nb_classes,"" classes to choose from: "",class_names)\n    expected_melgram_shape = model.layers[0].input_shape[1:]\n    print(""Expected_melgram_shape = "",expected_melgram_shape)\n    file_count = 0\n    json_file = open(""data.json"", ""w"")\n    json_file.write(\'{\\n""items"":[\')\n\n    idnum = 0\n    numfiles = len(args.file)\n    print(""Reading"",numfiles,""files"")\n    for infile in args.file:\n        if os.path.isfile(infile):\n            file_count += 1\n            print(""File"",infile,"":"",end="""")\n\n            signal, sr = load_audio(infile, mono=mono, sr=resample)\n\n            y_proba = predict_one(signal, sr, model, expected_melgram_shape) # class_names, model, weights_file=args.weights)\n\n            for i in range(nb_classes):\n                print( class_names[i],"": "",y_proba[i],"", "",end="""",sep="""")\n            answer = class_names[ np.argmax(y_proba)]\n            print(""--> ANSWER:"", class_names[ np.argmax(y_proba)])\n            outstr = \'\\n  {\\n   ""id"": ""\'+str(idnum)+\'"",\\n      ""name"":""\'+infile+\'"",\\n      ""tags"":[\\n   ""\'+answer+\'""]\\n  }\'\n            if (idnum < numfiles-1):\n                outstr += \',\'\n            json_file.write(outstr)\n            json_file.flush()     # keep json file up to date\n        else:\n            pass #print("" *** File"",infile,""does not exist.  Skipping."")\n        idnum += 1\n\n    json_file.write(""]\\n}\\n"")\n    json_file.close()\n\n    return\n\n\nif __name__ == \'__main__\':\n    import argparse\n    parser = argparse.ArgumentParser(description=""predicts which class file(s) belong(s) to"")\n    parser.add_argument(\'-w\', \'--weights\', #nargs=1, type=argparse.FileType(\'r\'),\n        help=\'weights file in hdf5 format\', default=""weights.hdf5"")\n    #parser.add_argument(\'-c\', \'--classpath\', #type=argparse.string, help=\'directory with list of classes\', default=""Preproc/Test/"")\n    parser.add_argument(""-m"", ""--mono"", help=""convert input audio to mono"",action=""store_true"")\n    parser.add_argument(""-r"", ""--resample"", type=int, default=44100, help=""convert input audio to mono"")\n    parser.add_argument(\'-d\', ""--dur"",  type=float, default=None,   help=\'Max duration (in seconds) of each clip\')\n\n    parser.add_argument(\'file\', help=""file(s) to classify"", nargs=\'+\')\n    args = parser.parse_args()\n\n    main(args)\n'"
preprocess_data.py,0,"b'#! /usr/bin/env python3\n\n\'\'\'\nPreprocess audio\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nfrom panotti.datautils import *\nimport librosa\nfrom audioread import NoBackendError\nimport os\nfrom PIL import Image\nfrom functools import partial\nfrom imageio import imwrite\nimport multiprocessing as mp\nfrom utils.resolve_osx_aliases import resolve_osx_alias\n\n# this is either just the regular shape, or it returns a leading 1 for mono\ndef get_canonical_shape(signal):\n    if len(signal.shape) == 1:\n        return (1, signal.shape[0])\n    else:\n        return signal.shape\n\n\ndef find_max_shape(path, mono=False, sr=None, dur=None, clean=False):\n    if (mono) and (sr is not None) and (dur is not None):   # special case for speedy testing\n        return [1, int(sr*dur)]\n    shapes = []\n    for dirname, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            if not (filename.startswith(\'.\') or (\'.csv\' in filename)):    # ignore hidden files & CSVs\n                filepath = os.path.join(dirname, filename)\n                try:\n                    signal, sr = librosa.load(filepath, mono=mono, sr=sr)\n                except NoBackendError as e:\n                    print(""Could not open audio file {}"".format(filepath))\n                    raise e\n                if (clean):                           # Just take the first file and exit\n                    return get_canonical_shape(signal)\n                shapes.append(get_canonical_shape(signal))\n\n    return (max(s[0] for s in shapes), max(s[1] for s in shapes))\n\n\ndef convert_one_file(printevery, class_index, class_files, nb_classes, classname, n_load, dirname, resample, mono,\n        already_split, nosplit, n_train, outpath, subdir, max_shape, clean, out_format, mels, phase, file_index):\n    infilename = class_files[file_index]\n    audio_path = dirname + \'/\' + infilename\n\n    if (0 == file_index % printevery) or (file_index+1 == len(class_files)):\n        print(""\\r Processing class "",class_index+1,""/"",nb_classes,"": \\\'"",classname,\n            ""\\\', File "",file_index+1,""/"", n_load,"": "",audio_path,""                             "",\n            sep="""",end=""\\r"")\n    sr = None\n    if (resample is not None):\n        sr = resample\n\n    signal, sr = load_audio(audio_path, mono=mono, sr=sr)\n\n    # Reshape / pad so all output files have same shape\n    shape = get_canonical_shape(signal)     # either the signal shape or a leading one\n    if (shape != signal.shape):             # this only evals to true for mono\n        signal = np.reshape(signal, shape)\n        #print(""...reshaped mono so new shape = "",signal.shape, end="""")\n    #print("",  max_shape = "",max_shape,end="""")\n    padded_signal = np.zeros(max_shape)     # (previously found max_shape) allocate a long signal of zeros\n    use_shape = list(max_shape[:])\n    use_shape[0] = min( shape[0], max_shape[0] )\n    use_shape[1] = min( shape[1], max_shape[1] )\n    #print("",  use_shape = "",use_shape)\n    padded_signal[:use_shape[0], :use_shape[1]] = signal[:use_shape[0], :use_shape[1]]\n\n    layers = make_layered_melgram(padded_signal, sr, mels=mels, phase=phase)\n\n    if not already_split and (not nosplit):\n        if (file_index >= n_train):\n            outsub = ""Test/""\n        else:\n            outsub = ""Train/""\n    elif nosplit:\n        outsub = """"\n    else:\n        outsub = subdir\n\n    outfile = outpath + outsub + classname + \'/\' + infilename+\'.\'+out_format\n    save_melgram(outfile, layers, out_format=out_format)\n    return\n\n\n\ndef preprocess_dataset(inpath=""Samples/"", outpath=""Preproc/"", train_percentage=0.8, resample=None, already_split=False,\n    nosplit=False, sequential=False, mono=False, dur=None, clean=False, out_format=\'npy\', mels=96, phase=False):\n\n    if (resample is not None):\n        print("" Will be resampling at"",resample,""Hz"",flush=True)\n\n    if (True == already_split):\n        print("" Data is already split into Train & Test"",flush=True)\n        class_names = get_class_names(path=inpath+""Train/"")   # get the names of the subdirectories\n        sampleset_subdirs = [""Train/"",""Test/""]\n    elif nosplit:\n        print("" All files output to same directory"",flush=True)\n        class_names = get_class_names(path=inpath)   # get the names of the subdirectories\n        sampleset_subdirs = [""./""]\n    else:\n        print("" Will be imposing 80-20 (Train-Test) split"",flush=True)\n        class_names = get_class_names(path=inpath)   # get the names of the subdirectories\n        sampleset_subdirs = [""./""]\n\n    if (True == sequential):\n        print("" Sequential ordering"",flush=True)\n    else:\n        print("" Shuffling ordering"",flush=True)\n\n    print("" Finding max shape..."",flush=True)\n    max_shape = find_max_shape(inpath, mono=mono, sr=resample, dur=dur, clean=clean)\n    print(\'\'\' Padding all files with silence to fit shape:\n              Channels : {}\n              Samples  : {}\n          \'\'\'.format(max_shape[0], max_shape[1]))\n\n    nb_classes = len(class_names)\n    print("""",len(class_names),""classes.  class_names = "",class_names,flush=True)\n\n    if nosplit:\n        train_outpath = outpath\n        test_outpath = outpath\n    else:\n        train_outpath = outpath+""Train/""\n        test_outpath = outpath+""Test/""\n    if not os.path.exists(outpath):\n        os.mkdir( outpath );   # make a new directory for preproc\'d files\n        if not nosplit:\n            os.mkdir( train_outpath );\n            os.mkdir( test_outpath );\n    else:\n        train_outpath = outpath\n        test_outpath = outpath\n\n    parallel = True     # set to false for debugging. when parallel jobs crash, usually no error messages are given, the system just hangs\n    if (parallel):\n        cpu_count = os.cpu_count()\n        print("""",cpu_count,""CPUs detected: Parallel execution across"",cpu_count,""CPUs"",flush=True)\n    else:\n        cpu_count = 1\n        print(""Serial execution"",flush=True)\n\n\n    for subdir in sampleset_subdirs: #non-class subdirs of Samples (in case already split into Test/ Train; see above)\n\n\n        for class_index, classname in enumerate(class_names):   # go through the classes\n            print("""")           # at the start of each new class, newline\n\n            # make new Preproc/ subdirectories for class\n            if not os.path.exists(train_outpath+classname):\n                print(""Making directory "",train_outpath+classname)\n                os.mkdir( train_outpath+classname );\n                if not nosplit:\n                    os.mkdir( test_outpath+classname );\n            dirname = inpath+subdir+classname\n            class_files = list(listdir_nohidden(dirname))   # all filenames for this class, skip hidden files\n            class_files.sort()\n            if (not sequential): # shuffle directory listing (e.g. to avoid alphabetic order)\n                np.random.shuffle(class_files)   # shuffle directory listing (e.g. to avoid alphabetic order)\n\n            n_files = len(class_files)\n            n_load = n_files            # sometimes we may multiple by a small # for debugging\n            n_train = int( n_load * train_percentage)\n\n            printevery = 20             # how often to output status messages when processing lots of files\n\n            file_indices = tuple( range(len(class_files)) )\n\n            if (not parallel):\n                for file_index in file_indices:    # loop over all files\n                    convert_one_file(printevery, class_index, class_files, nb_classes, classname, n_load, dirname,\n                        resample, mono, already_split, nosplit, n_train, outpath, subdir, max_shape, clean, out_format, mels, phase, file_index)\n            else:\n                pool = mp.Pool(cpu_count)\n                pool.map(partial(convert_one_file, printevery, class_index, class_files, nb_classes, classname, n_load, dirname,\n                    resample, mono, already_split, nosplit, n_train, outpath, subdir, max_shape, clean, out_format, mels, phase), file_indices)\n                pool.close() # shut down the pool\n\n\n    print("""")    # at the very end, newline\n    return\n\nif __name__ == \'__main__\':\n    import platform\n    import argparse\n    parser = argparse.ArgumentParser(description=""preprocess_data: convert sames to python-friendly data format for faster loading"")\n    parser.add_argument(""-a"", ""--already"", help=""data is already split into Test & Train (default is to add 80-20 split"",action=""store_true"")\n    parser.add_argument(""-s"", ""--sequential"", help=""don\'t randomly shuffle data for train/test split"",action=""store_true"")\n    parser.add_argument(""-m"", ""--mono"", help=""convert input audio to mono"",action=""store_true"")\n    parser.add_argument(""-n"", ""--nosplit"", help=""do not create any Train/Test split in output (everything to same directory)"",action=""store_true"")\n\n    parser.add_argument(""-r"", ""--resample"", type=int, default=44100, help=""convert input audio to mono"")\n    parser.add_argument(\'-d\', ""--dur"",  type=float, default=3,   help=\'Max duration (in seconds) of each clip. Default = 3s\')\n    parser.add_argument(\'-c\', ""--clean"", help=""Assume \'clean data\'; Do not check to find max shape (faster)"", action=\'store_true\')\n    parser.add_argument(\'-f\',\'--format\', help=""format of output file (npz, jpeg, png, etc). Default = npz"", type=str, default=\'npz\')\n    parser.add_argument(\'-i\',\'--inpath\', help=""input directory for audio samples (default=\'Samples\')"", type=str, default=\'Samples\')\n    parser.add_argument(\'-o\',\'--outpath\', help=""output directory for spectrograms (default=\'Preproc\')"", type=str, default=\'Preproc\')\n    parser.add_argument(""--mels"", help=""number of mel coefficients to use in spectrograms"", type=int, default=96)\n    parser.add_argument(""--phase"", help=""Include phase information as extra channels"", action=\'store_true\')\n\n    args = parser.parse_args()\n    if ((\'Darwin\' == platform.system()) and (not args.mono)):\n        # bug/feature in OS X that causes np.dot() to sometimes hang if multiprocessing is running\n        mp.set_start_method(\'forkserver\', force=True)   # hopefully this here makes it never hang\n        print("" WARNING: Using stereo files w/ multiprocessing on OSX may cause the program to hang."")\n        print("" This is because of a mismatch between the way Python multiprocessing works and some Apple libraries"")\n        print("" If it hangs, try running with mono only (-m) or the --clean option, or turn off parallelism"")\n        print(""  See https://github.com/numpy/numpy/issues/5752 for more on this."")\n        print("""")\n\n    preprocess_dataset(inpath=args.inpath+\'/\', outpath=args.outpath+\'/\', resample=args.resample, already_split=args.already, sequential=args.sequential, mono=args.mono,\n        nosplit=args.nosplit, dur=args.dur, clean=args.clean, out_format=args.format, mels=args.mels, phase=args.phase)\n'"
setup.py,0,"b'from setuptools import setup\nfrom setuptools import find_packages\n\ntry:\n    from pypandoc import convert\n    read_md = lambda f: convert(f, \'rst\')\nexcept ImportError:\n    print(""warning: pypandoc module not found, could not convert Markdown to RST"")\n    read_md = lambda f: open(f, \'r\').read()\n\n\nsetup(name=\'Panotti\',\n      version=\'1.0.0\',\n      description=\'Multi-Channel Audio Classifier\',\n      long_description=read_md(\'README.md\'),\n      author=\'Scott Hawley\',\n      author_email=\'scott.hawley@belmont.edu\',\n      url=\'https://github.com/drscotthawley/panotti\',\n      download_url=\'https://github.com/drscotthawley/panotti/tarball/1.0.0\',\n      license=\'MIT\',\n      install_requires=[\'keras\', \'librosa\', \'h5py\'],\n      extras_require={\n          \'headgames\': [\'pygame\'],\n      },\n      packages=find_packages()\n) \n'"
train_network.py,0,"b'#! /usr/bin/env python3\n\'\'\'\nClassify sounds using database\nAuthor: Scott H. Hawley\n\nThis is kind of a mixture of Keun Woo Choi\'s code https://github.com/keunwoochoi/music-auto_tagging-keras\n   and the MNIST classifier at https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n\nTrained using Fraunhofer IDMT\'s database of monophonic guitar effects,\n   clips were 2 seconds long, sampled at 44100 Hz\n\'\'\'\nfrom __future__ import print_function\nimport sys\nprint(sys.path)\nprint(sys.version)\nimport numpy as np\nfrom panotti.models import *\nfrom panotti.datautils import *\n#from keras.callbacks import ModelCheckpoint #,EarlyStopping\nimport os\nfrom os.path import isfile\nfrom timeit import default_timer as timer\nfrom panotti.multi_gpu import MultiGPUModelCheckpoint\nfrom panotti.mixup_generator import MixupGenerator\nimport math\n\ndef train_network(weights_file=""weights.hdf5"", classpath=""Preproc/Train/"",\n    epochs=50, batch_size=20, val_split=0.2, tile=False, max_per_class=0,\n    k_fold=1):\n\n    np.random.seed(1)  # fix a number to get reproducibility; comment out for random behavior\n\n    # Get the data\n    X_train, Y_train, paths_train, class_names = build_dataset(path=classpath,\n        batch_size=batch_size, tile=tile, max_per_class=max_per_class)\n\n    save_best_only = (val_split > 1e-6)\n    assert k_fold  <= 1/val_split   # make sure we don\'t repeat folds\n\n    for k in range(k_fold):\n\n        # Instantiate the model\n        model, serial_model = setup_model(X_train, class_names,\n            weights_file=weights_file, quiet=(k!=0))\n\n        # Split between Training and Validation Set, val_split = percentage to use for val\n        split_index = int(X_train.shape[0]*(1-val_split))   # Train first, Val second\n        X_val, Y_val = X_train[split_index:], Y_train[split_index:]\n        X_train, Y_train = X_train[:split_index], Y_train[:split_index]\n\n        # if we\'re doing k-folding cross-val, don\'t overwrite the weights file until the last time\n        callbacks = None if (k < k_fold-1) else [MultiGPUModelCheckpoint(filepath=weights_file, verbose=1, save_best_only=save_best_only,\n              serial_model=serial_model, period=1, class_names=class_names)]\n\n        steps_per_epoch = X_train.shape[0] // batch_size\n        if False and ((len(class_names) > 2) or (steps_per_epoch > 1)):\n            training_generator = MixupGenerator(X_train, Y_train, batch_size=batch_size, alpha=0.25)()\n            model.fit_generator(generator=training_generator, steps_per_epoch=steps_per_epoch,\n                  epochs=epochs, shuffle=True,\n                  verbose=1, callbacks=callbacks, validation_data=(X_val, Y_val))\n        else:\n            model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, shuffle=True,\n                  verbose=1, callbacks=callbacks, #validation_split=val_split)\n                  validation_data=(X_val, Y_val))\n\n        if k < k_fold-1: # reconstitute and re-split the data for the next loop\n            print(""\\n\\n------ Starting another round of cross-validation, for k ="",k+2,""/"",k_fold,""------"")\n            X_train = np.concatenate((X_val, X_train))  # stick the val at the front this time\n            Y_train = np.concatenate((Y_val, Y_train))\n\n\n    # overwrite text file class_names.txt  - does not put a newline after last class name\n    with open(\'class_names.txt\', \'w\') as outfile:\n        outfile.write(""\\n"".join(class_names))\n\n    # Score the model against Test dataset\n    X_test, Y_test, paths_test, class_names_test  = build_dataset(path=classpath+""../Test/"", tile=tile)\n    assert( class_names == class_names_test )\n    score = model.evaluate(X_test, Y_test, verbose=0)\n    print(\'Test loss:\', score[0])\n    print(\'Test accuracy:\', score[1])\n\n\nif __name__ == \'__main__\':\n    import argparse\n    parser = argparse.ArgumentParser(description=""trains network using training dataset"")\n    parser.add_argument(\'-w\', \'--weights\', #nargs=1, type=argparse.FileType(\'r\'),\n        help=\'weights file (in .hdf5)\', default=""weights.hdf5"")\n    parser.add_argument(\'-c\', \'--classpath\', #type=argparse.string,\n        help=\'Train dataset directory with list of classes\', default=""Preproc/Train/"")\n    parser.add_argument(\'--epochs\', default=20, type=int, help=""Number of iterations to train for"")\n    parser.add_argument(\'--batch_size\', default=40, type=int, help=""Number of clips to send to GPU at once"")\n    parser.add_argument(\'--val\', default=0.2, type=float, help=""Fraction of train to split off for validation"")\n    parser.add_argument(""--tile"", help=""tile mono spectrograms 3 times for use with imagenet models"",action=""store_true"")\n    parser.add_argument(\'-m\', \'--maxper\', type=int, default=0, help=""Max examples per class"")\n    parser.add_argument(\'-k\', \'--kfold\', type=int, default=1, help=""Enable k-fold cross-validation (max = 1/val)"")\n\n    args = parser.parse_args()\n    train_network(weights_file=args.weights, classpath=args.classpath, epochs=args.epochs,\n        batch_size=args.batch_size, val_split=args.val, tile=args.tile, max_per_class=args.maxper,\n        k_fold=args.kfold)\n'"
examples/headgames.py,0,"b'#! /usr/bin/env python\n\'\'\'\nHeadGames -  GUI for demo-ing binaural source localization\nAuthor: Scott Hawley\n\n""But if you want to win, you gotta learn how to play""--Foreigner, ""Head Games""\n\nStill under construction\nRequirements:\n    pygame\n    librosa\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nimport pygame\nimport pygame.gfxdraw\nimport math\nimport librosa\nimport os\nimport sys\nsys.path.insert(0, \'..\')\nfrom keras.models import load_model\nfrom panotti.datautils import *\n#from predict_class import predict_one\nimport glob\nimport random\nimport re\nimport colorsys\nimport argparse\n\n\nBLACK = (0, 0, 0)\nDARKGREY = (55,55,55)\nWHITE = (255, 255, 255)\nGREEN = (0, 255, 0)\nBLUE = (0, 0, 255)\nRED = (255, 0, 0)\nCYAN = (0, 255, 255)\nMAGENTA = (255, 0, 255)\n\n\ndef predict_one(signal, sr, class_names, model, weights_file=""weights.hdf5""):\n    X = make_layered_melgram(signal,sr)\n    return model.predict_proba(X,batch_size=1,verbose=0)[0]\n\n\ndef get_wav_file_list(path=""binaural/Samples/"",shuffle=True):\n    path = path.rstrip(\'/\')   # remove any trailing slash\n    file_list = glob.glob(path+""*/*.wav"")\n    if shuffle:\n        random.shuffle(file_list)\n    return file_list\n\ndef parse_class_string(filename):\n    str = re.search(\'class.*\\/\',filename).group(0)[0:-1]\n    str2 = re.search(\'-a.*\\.\',str).group(0)[2:-1]\n    return float(str2)\n\ndef draw_head(screen,origin,screensize):\n    color=DARKGREY\n    cx, cy, scale  = origin[0],origin[1], int(screensize[1]/4)\n    headsize = (int(scale*2/3),scale)\n    rx, ry = int(headsize[0]/2), int(headsize[1]/2)\n\n    #ears\n    color=BLACK\n    earw, earh = scale/10, scale/4\n    earrx, earry = int(scale/20), int(scale/8)\n    pygame.gfxdraw.filled_ellipse(screen, cx-rx, cy, earrx, earry, color)\n    pygame.gfxdraw.aaellipse(screen, cx-rx, cy, earrx, earry, color)\n    pygame.gfxdraw.filled_ellipse(screen, cx+rx, cy, earrx, earry, color)\n    pygame.gfxdraw.aaellipse(screen, cx+rx, cy, earrx, earry, color)\n\n\n    # head proper\n    color = DARKGREY\n\n    headbox = (cx-headsize[0]/2, int(cy-scale/2), headsize[0], headsize[1])\n    pygame.gfxdraw.filled_ellipse(screen, cx, cy, rx, ry, color)\n    pygame.gfxdraw.aaellipse(screen, cx, cy, rx, ry, color)\n    #head = pygame.draw.ellipse(screen, color, headbox)\n    #nose\n    noserad = int(scale/15)\n    nose = pygame.draw.circle(screen, color, (cx,int(headbox[1]+noserad/4)), noserad  )\n    return\n\n\ndef draw_bounds(screen,origin,screensize,angles):\n    n_az = len(angles)\n    radius = int(screensize[1]*.5)-10\n    width = int(2)\n    color = BLUE\n    x, y, r = origin[0], origin[1], radius\n    boundary = pygame.gfxdraw.aacircle(screen, x, y, r, color)\n    #boundary = pygame.draw.circle(screen, color, origin, radius, width)\n\n    # draw a bunch of lines\n    radian_sweep = 2*math.pi / n_az\n    radian_start = -0.5*radian_sweep\n    for i in range(n_az):               # draw a bunch of bounds\n        rad = radian_start + i*radian_sweep\n        startpos = origin\n        endpos = (int(origin[0]-radius*math.sin(rad)), int(origin[1]+radius*math.cos(rad)))\n        pygame.draw.line(screen, color, startpos, endpos)\n    return\n\ndef draw_pie(screen,origin,screensize,angles,guess_az,r_fac=1.0,color=GREEN):\n    n_az = len(angles)\n\n    if guess_az is None:\n        return\n    cx, cy, r  = origin[0],origin[1], screensize[1]*.5-10\n    b = r/5\n    r = b + r_fac*(r-b)\n\n    guess_az_rad = guess_az*math.pi/180\n    # Start list of polygon points\n    deg_sweep = 360.0 / n_az\n    radian_sweep = 2*math.pi / n_az\n    radian_start = guess_az_rad - 0.5*radian_sweep\n    deg_inc = math.pi/180\n    p = [(cx, cy)]\n    for n in range(0,int(deg_sweep)+1):  # Get points on arc in 1-degree increments\n        rad = radian_start + n*deg_inc\n        x = cx + int(r*math.sin(rad))\n        y = cy - int(r*math.cos(rad))\n        p.append((x, y))\n    p.append((cx, cy))\n    # Draw pie segment\n    if len(p) > 2:\n        pygame.draw.polygon(screen, color, p)\n    return\n\n\n\ndef assign_sat(color, sout):\n    rgb_to_hsv = np.vectorize(colorsys.rgb_to_hsv)\n    hsv_to_rgb = np.vectorize(colorsys.hsv_to_rgb)\n\n    r,g,b = color[0]/255.0, color[1]/255.0, color[2]/255.0\n    #print(""r,g,b ="",r,g,b)\n    h, s, v = rgb_to_hsv(r,g,b)\n    #print(""h,s,v="",h,s,v,"" sout="",sout)\n    s = sout\n    r, g, b = hsv_to_rgb(h, s, v)\n    r, g, b = int(255*r), int(255*g), int(255*b)\n    return (r,g,b)\n\n\ndef draw_probs_text(screen,origin,screensize,angles,probs):\n    radius = int(screensize[1]*.38)\n    fontsize = int(radius/7)\n    myfont = pygame.font.SysFont(\'arial\', fontsize)\n    for i in range(len(angles)):               # draw a bunch of bounds\n        rad = angles[i] * math.pi/180\n        if (probs[i]==np.max(probs)):\n            color=MAGENTA\n        else:\n            color=BLUE\n        text = myfont.render(\'{0:.3f}\'.format(probs[i]).lstrip(\'0\'), True, color)\n        tw, th = text.get_width(), text.get_height()\n        x = int( origin[0] + radius * math.sin(rad) - tw/2)\n        y = int( origin[1] - radius * math.cos(rad) - th/2)\n        screen.blit(text,(x,y))\n    return\n\ndef draw_probs_pies(screen,origin,screensize,angles,probs,true_az):\n    radius = int(screensize[1]*.38)\n    guess_az = angles[ np.argmax(probs)]\n\n    for i in range(len(angles)):               # draw a bunch of bounds\n        rad = angles[i] * math.pi/180\n        piecolor = assign_sat(GREEN,probs[i])\n        draw_pie(screen,origin,screensize,angles,angles[i],color=piecolor )\n\n    draw_pie(screen,origin,screensize,angles,true_az,r_fac=1.04,color=RED )\n    draw_pie(screen,origin,screensize,angles,guess_az,color=assign_sat(GREEN,np.max(probs)))\n    return\n\n\n\n################ MAIN CODE #############\ndef do_pygame(n_az=12, weights_file=""binaural/weights.hdf5"", wavpath=""binaural/Samples/""):\n    # Define some colors\n\n    # make a list of valid angles\n    angles = []\n    deg_sweep = 360/n_az\n    for n in range(n_az):\n        angles.append(-180+ n*deg_sweep)\n    print(""angles = "",angles)\n    file_list=get_wav_file_list(path=wavpath)\n    print(""len of file_list in path "",wavpath,"" = "",len(file_list))\n    class_names=angles  # get_class_names(path=""binaural/Samples/"", sort=True)\n\n    # Load the model\n    print(""Loading model..."")\n    model = load_model(weights_file)\n    if model is None:\n        print(""No weights file found.  Aborting"")\n        exit(1)\n    model.summary()\n\n\n    pygame.init()\n    pygame.font.init()\n\n    # Set the width and height of the screen [width, height]\n    screensize = (500, 500)\n    screen = pygame.display.set_mode(screensize,pygame.RESIZABLE)\n\n    pygame.display.set_caption(""Head Games"")\n\n    # Loop until the user clicks the close button.\n    print(""Every time you click the image, it will load a new file"")\n    done = False\n\n    # Used to manage how fast the screen updates\n    clock = pygame.time.Clock()\n    guess_az = 0.0\n    true_az = 0.0\n    deg_inc = 360/n_az\n    probs = None\n    # -------- Main Program Loop -----------\n    while not done:\n        # --- Main event loop\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                done = True\n            if event.type == pygame.VIDEORESIZE:\n                screensize = (event.w, event.h)\n                screen = pygame.display.set_mode(screensize,pygame.RESIZABLE)\n\n        # --- Game logic should go here\n            if event.type == pygame.MOUSEBUTTONUP:\n                guess_az = guess_az + deg_inc\n\n                # load new file\n                filenum = random.randint(0,len(file_list)-1)\n                print(""filenum = "",filenum)\n                infile = file_list[filenum]\n                print(""infile = "",infile)\n                signal, sr = librosa.load(infile, mono=False, sr=44100)   # librosa naturally makes mono from stereo btw\n                probs  = predict_one(signal, sr, class_names, model, weights_file=weights_file)\n                print(""     probs = "",probs)\n                guess_az = angles[ np.argmax(probs)]\n                # get true az from filename\n                true_az = parse_class_string(infile)\n                print(""     guess_az, true_az = "",guess_az,"", "",true_az,sep="""")\n\n\n        # --- Screen-clearing code goes here\n\n        # Here, we clear the screen to white. Don\'t put other drawing commands\n        # above this, or they will be erased with this command.\n\n        # If you want a background image, replace this clear with blit\'ing the\n        # background image.\n        screen.fill(WHITE)\n\n        # --- Drawing code should go here\n        origin = (int(screensize[0]/2),int(screensize[1]/2))\n        #draw (text) probabilities for different angles\n        if probs is not None:\n            draw_probs_pies(screen,origin,screensize,angles,probs,true_az)\n            draw_probs_text(screen,origin,screensize,angles,probs)\n\n        draw_bounds(screen,origin,screensize,angles)\n        draw_head(screen,origin,screensize)\n\n        # --- Go ahead and update the screen with what we\'ve drawn.\n        pygame.display.flip()\n\n        # --- Limit to 60 frames per second\n        clock.tick(3)\n\n    # Close the window and quit.\n    pygame.quit()\n\n\nif __name__ == ""__main__"":\n    print(""headgames.py - Still under construction\\n"")\n    if (not os.path.isdir(""binaural"")) or (not os.path.isdir(""binaural/Samples"")):\n        print(""\\nYou need to run ./binaural_setup.sh first."")\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=""evaluates network on testing dataset"")\n    parser.add_argument(\'-w\', \'--weights\', #nargs=1, type=argparse.FileType(\'r\'),\n        help=\'weights file in hdf5 format\', default=""binaural/weights.hdf5"")\n    parser.add_argument(\'-n\', \'--naz\', #type=argparse.string,\n        help=\'Number of azimuthal bins\', default=12)\n    parser.add_argument(\'-d\', \'--dir\', #type=argparse.string,\n            help=\'Directory containing test .wav files\', default=\'binaural/Samples\')\n\n    args = parser.parse_args()\n    weights_file=args.weights\n    n_az = int(args.naz)\n    print(""n_az = "",n_az)\n    wavpath = args.dir\n    if (not os.path.isfile(weights_file)):\n        print(""Error, can\'t find weights file ""+weights_file)\n        sys.exit(1)\n    #TODO: First check for existence of files we need: binaural/, binaural/Samples, binaural/weights.hdf5\n    do_pygame(n_az=n_az, weights_file=weights_file, wavpath=wavpath)\n'"
examples/physionet2016_setup.py,0,"b'#! /usr/bin/env python\n\n\'\'\'\n Set up the heart sounds database for the physionet 2016 challenge\n See https://www.physionet.org/challenge/2016/\n\nNOTE: The PhysioNet 2016 Challenge dataset has a ""validation"" section, but their \n    \'validation\' data is INCLUDED in their training set. \n    So what we need do is regard the val set as val data, but DELETE instances of \n    val data that appear in the training set\n\nRequirements:  \n    The dataset, which the program will try to download from the following URLs:\n        https://www.physionet.org/physiobank/database/challenge/2016/training.zip\n        https://www.physionet.org/physiobank/database/challenge/2016/validation.zip\n\'\'\'\n\nfrom __future__ import print_function\nimport os\nfrom os.path import isfile\nimport glob\nimport pandas as pd\nimport shutil\nimport sys\nfrom subprocess import call\nimport glob\nimport subprocess\n\nsys.path.insert(0, \'../utils\')\nfrom split_audio import *\n\nmainpath = ""physionet2016""\nsamplepath = ""Samples/""\ntrainpath = ""Samples/Train/""\ntestpath = ""Samples/Test/""\n\nclass_names = (\'normal\',\'abnormal\')\nset_names = (\'training-a\', \'training-b\', \'training-c\', \'training-d\', \'training-e\', \'training-f\',\'validation\') # no point getting their val set\n\n\n# TODO: this never checks in case one of the operations fails\ndef download_if_missing(dirname=""training-f"", filename=""training.zip"", \n    url=""https://www.physionet.org/physiobank/database/challenge/2016/training.zip"",tar=False):\n\n    if not os.path.isdir(dirname):\n            print(""Directory \\\'""+dirname+""/\\\' not present.  Checking for compressed archive"",filename)\n\n            if not os.path.isfile(filename):\n                import urllib\n                print(""   Compressed archive \\\'""+filename+""\\\' not present.  Downloading it..."")\n\n                if sys.version_info[0] >= 3:    # Python 3 and up\n                    from urllib.request import urlretrieve\n                else:                           # Python 2\n                    from urllib import urlretrieve\n                urlretrieve(url, filename)\n\n\n            print(""   Uncompressing archive..."",end="""")\n            if (tar):\n                call([""tar"",""-zxf"",filename])\n            else:\n                call([""unzip"",filename])\n            print("" done."")\n    return\n\n\n# create the directories we need\ndef make_dirs():\n    if not os.path.exists(mainpath):\n        print(""Creating directory ""+mainpath+""..."")\n        os.mkdir( mainpath )\n        print(""Changing directory to ""+mainpath+""..."")\n        os.chdir(mainpath)\n    if not os.path.exists(samplepath):\n        os.mkdir( samplepath )\n        os.mkdir( trainpath )\n        os.mkdir( testpath )\n        for classname in class_names:\n            os.mkdir( trainpath+classname );   \n            os.mkdir( testpath+classname );\n    return  \n\n\n# read in a text file as a list of lines\ndef slurp_file(filepath):\n    line_list = open(filepath).readlines()\n    return line_list\n\n\n# any files with same names in both Test/ and Train/ get deleted\ndef delete_test_dupes(class_names):\n    for classname in class_names:\n        print(""Deleting duplicates in ""+testpath+classname+""/ & ""+trainpath+classname+""..."")\n        trainlist = [os.path.basename(x) for x in glob.glob(trainpath+classname+""/*"")]\n        testlist = [os.path.basename(x) for x in glob.glob(testpath+classname+""/*"")]\n        both = set(trainlist).intersection(testlist)\n        #print("" both = "",both)\n        for filename in both:\n            path = trainpath+classname+""/""+filename\n            os.remove(path)\n    return\n\n\ndef chopup_clips(class_names):\n    dur = 5;\n    print(""Chopping audio files into"",dur,""second clips..."")\n    file_list = glob.glob(""Samples/*/*/*.wav"")\n    split_audio(file_list, clip_dur=dur, remove_orig=True)\n    return\n\n\ndef main():\n    make_dirs()\n    download_if_missing()\n    download_if_missing(dirname=""validation"", filename=""validation.zip"", \n           url=""https://www.physionet.org/physiobank/database/challenge/2016/validation.zip"")\n\n    for set_idx, setname in enumerate(set_names):\n     \n        if (setname != \'validation\'):\n            destpath = trainpath\n        else:\n            destpath = testpath\n\n        ref_filename = setname+\'/\'+\'REFERENCE.csv\'\n        df = pd.read_csv(ref_filename, names=(""file"",""code""))\n        df[""code""] = df[""code""].replace([-1,1],[\'normal\',\'abnormal\'])   \n        df[""file""] = df[""file""].replace([r""$""],["".wav""],regex=True)\n\n        for index, row in df.iterrows():\n            this_file = row[""file""]\n            this_class = row[""code""]\n            src = setname+\'/\'+this_file\n            dst = destpath + this_class + \'/cl-\'+this_class+""-""+this_file\n            print(""src, dst =  "",src,dst)\n            shutil.copyfile(src,dst)\n\n    delete_test_dupes(class_names)\n    chopup_clips(class_names)\n\n    print(""\\nFINISHED."")\n    print(""Now run the following command:\\n cd physionet2016; ../../preprocess_data.py --already"") \n    return\n\n\nif __name__ == \'__main__\':\n    main()\n'"
panotti/__init__.py,0,"b'__all__ = [""models"", ""multi_gpu"", ""mixup_generator""]\n'"
panotti/datautils.py,0,"b'\n\'\'\'\ndatautils.py:  Just some routines that we use for moving data around\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nimport librosa\nimport os\nfrom os.path import isfile, splitext\nfrom imageio import imread, imwrite\nimport glob\nfrom skimage import img_as_ubyte\nfrom random import shuffle\n\n\ndef listdir_nohidden(path,subdirs_only=False, skip_csv=True):\n    \'\'\'\n    ignore hidden files. call should be inside list().  subdirs_only means it ignores regular files\n    \'\'\'\n    for f in os.listdir(path):\n        if not f.startswith(\'.\'):     # this skips the hidden\n            if ((False==subdirs_only) or (os.path.isdir(path+""/""+f))):\n                if (\'.csv\' == os.path.splitext(f)[1]) and (skip_csv):\n                    pass\n                else:\n                    yield f\n\n\n# class names are subdirectory names in Preproc/ directory\ndef get_class_names(path=""Preproc/Train/"", sort=True):\n    if (sort):\n        class_names = sorted(list(listdir_nohidden(path, subdirs_only=True)))     # sorted alphabetically for consistency with ""ls"" command\n    else:\n        class_names = listdir_nohidden(path)             # not in same order as ""ls"", because Python\n    return class_names\n\n\ndef get_total_files(class_names, path=""Preproc/Train/""):\n    sum_total = 0\n    for subdir in class_names:\n        files = os.listdir(path+subdir)\n        n_files = len(files)\n        sum_total += n_files\n    return sum_total\n\ndef scale_to_uint8(float_img):\n    #out_img = 255*(float_img - np.min(float_img))/np.ptp(float_img).astype(np.uint8)\n    out_img = img_as_ubyte( (float_img-np.min(float_img))/np.ptp(float_img) )\n    return out_img\n\ndef save_melgram(outfile, melgram, out_format=\'npz\'):\n    channels = melgram.shape[3]\n    melgram = melgram.astype(np.float16)\n    if ((\'jpeg\' == out_format) or (\'png\' == out_format)) and (channels <=4):\n        melgram = np.squeeze(melgram)  # squeeze gets rid of dimensions of batch_size 1\n        #melgram = np.moveaxis(melgram, 1, 3).squeeze()      # we use the \'channels_first\' in tensorflow, but images have channels_first. squeeze removes unit-size axes\n        melgram = np.flip(melgram, 0)    # flip spectrogram image right-side-up before saving, for viewing\n        if (2 == channels): # special case: 1=greyscale, 3=RGB, 4=RGBA, ..no 2.  so...?\n            # pad a channel of zeros (for blue) and you\'ll just be stuck with it forever. so channels will =3\n            # TODO: this is SLOWWW\n            b = np.zeros((melgram.shape[0], melgram.shape[1], 3))  # 3-channel array of zeros\n            b[:,:,:-1] = melgram                          # fill the zeros on the 1st 2 channels\n            imwrite(outfile, scale_to_uint8(b), format=out_format)\n        else:\n            imwrite(outfile, scale_to_uint8(melgram), format=out_format)\n    elif (\'npy\' == out_format):\n        np.save(outfile,melgram=melgram)\n    else:\n        np.savez_compressed(outfile,melgram=melgram)    # default is compressed npz file\n    return\n\n\ndef load_audio(audio_path, mono=None, sr=None, convertOSXaliases=True):  # wrapper for librosa.load\n    try:\n        signal, sr = librosa.load(audio_path, mono=mono, sr=sr)\n    except NoBackendError as e:\n        if (\'Darwin\' == platform.system()):   # handle OS X alias files gracefully\n            source = resolve_osx_alias(audio_path, convert=convertOSXaliases, already_checked_os=True) # convert to symlinks for next time\n            try:\n                signal, sr = librosa.load(source, mono=mono, sr=sr)\n            except NoBackendError as e:\n                print(""\\n*** ERROR: Could not open audio file {}"".format(audio_path),""\\n"",flush=True)\n                raise e\n        else:\n            print(""\\n*** ERROR: Could not open audio file {}"".format(audio_path),""\\n"",flush=True)\n            raise e\n    return signal, sr\n\n\ndef load_melgram(file_path):\n    #auto-detect load method based on filename extension\n    name, extension = os.path.splitext(file_path)\n    if (\'.npy\' == extension):\n        melgram = np.load(file_path)\n    elif (\'.npz\' == extension):          # compressed npz file (preferred)\n        with np.load(file_path) as data:\n            melgram = data[\'melgram\']\n    elif (\'.png\' == extension) or (\'.jpeg\' == extension):\n        arr = imread(file_path)\n        melgram = np.reshape(arr, (1,arr.shape[0],arr.shape[1],1))  # convert 2-d image\n        melgram = np.flip(melgram, 0)     # we save images \'rightside up\' but librosa internally presents them \'upside down\'\n    else:\n        print(""load_melgram: Error: unrecognized file extension \'"",extension,""\' for file "",file_path,sep="""")\n    #print(""melgram.shape = "",melgram.shape)\n    return melgram\n\n\ndef get_sample_dimensions(class_names, path=\'Preproc/Train/\'):\n    classname = class_names[0]\n    audio_path = path + classname + \'/\'\n    infilename = os.listdir(audio_path)[0]\n    melgram = load_melgram(audio_path+infilename)\n    print(""   get_sample_dimensions: ""+infilename+"": melgram.shape = "",melgram.shape)\n    return melgram.shape\n\n\ndef encode_class(class_name, class_names, label_smoothing=0.005):\n# makes a ""one-hot"" vector for each class name called\n#  label_smoothing is a parameter to make the training more robust to mislabeled data\n    try:\n        idx = class_names.index(class_name)\n        num_classes = len(class_names)\n        vec = np.zeros(num_classes)\n        vec[idx] = 1\n\n        if label_smoothing > 0:\n            vec = vec * (1 - label_smoothing) + label_smoothing / num_classes\n        return vec\n    except ValueError:\n        return None\n\n\ndef decode_class(vec, class_names):  # generates a number from the one-hot vector\n    return int(np.argmax(vec))\n\n\ndef shuffle_XY_paths(X,Y,paths):   # generates a randomized order, keeping X&Y(&paths) together\n    assert (X.shape[0] == Y.shape[0] )\n    #print(""shuffle_XY_paths: Y.shape[0], len(paths) = "",Y.shape[0], len(paths))\n    idx = np.array(range(Y.shape[0]))\n    np.random.shuffle(idx)\n    newX = np.copy(X)\n    newY = np.copy(Y)\n    newpaths = paths[:]\n    for i in range(len(idx)):\n        newX[i] = X[idx[i],:,:]\n        newY[i] = Y[idx[i],:]\n        newpaths[i] = paths[idx[i]]\n    return newX, newY, newpaths\n\ndef make_melgram(mono_sig, sr, n_mels=128):   # @keunwoochoi upgraded form 96 to 128 mel bins in kapre\n    #melgram = librosa.logamplitude(librosa.feature.melspectrogram(mono_sig,  # latest librosa deprecated logamplitude in favor of amplitude_to_db\n    #    sr=sr, n_mels=96),ref_power=1.0)[np.newaxis,np.newaxis,:,:]\n\n    melgram = librosa.amplitude_to_db(librosa.feature.melspectrogram(mono_sig,\n        sr=sr, n_mels=n_mels))[np.newaxis,:,:,np.newaxis]     # last newaxis is b/c tensorflow wants \'channels_last\' order\n\n    \'\'\'\n    # librosa docs also include a perceptual CQT example:\n    CQT = librosa.cqt(mono_sig, sr=sr, fmin=librosa.note_to_hz(\'A1\'))\n    freqs = librosa.cqt_frequencies(CQT.shape[0], fmin=librosa.note_to_hz(\'A1\'))\n    perceptual_CQT = librosa.perceptual_weighting(CQT**2, freqs, ref=np.max)\n    melgram = perceptual_CQT[np.newaxis,np.newaxis,:,:]\n    \'\'\'\n    return melgram\n\ndef make_phase_gram(mono_sig, sr, n_bins=128):\n    stft = librosa.stft(mono_sig)#, n_fft = (2*n_bins)-1)\n    magnitude, phase = librosa.magphase(stft)   # we don\'t need magnitude\n\n    # resample the phase array to match n_bins\n    phase = np.resize(phase, (n_bins, phase.shape[1]))[np.newaxis,:,:,np.newaxis]\n    return phase\n\n\n\n# turn multichannel audio as multiple melgram layers\ndef make_layered_melgram(signal, sr, mels=128, phase=False):\n    if (signal.ndim == 1):      # given the way the preprocessing code is  now, this may not get called\n        signal = np.reshape( signal, (1,signal.shape[0]))\n\n    # get mel-spectrogram for each channel, and layer them into multi-dim array\n    for channel in range(signal.shape[0]):\n        melgram = make_melgram(signal[channel],sr, n_mels=mels)\n\n        if (0 == channel):\n            layers = melgram\n        else:\n            layers = np.append(layers,melgram,axis=3)  # we keep axis=0 free for keras batches, axis=3 means \'channels_last\'\n\n        if (phase):\n            phasegram = make_phase_gram(signal[channel],sr, n_bins=mels)\n            layers = np.append(layers,phasegram,axis=3)\n    return layers\n\n\ndef nearest_multiple( a, b ):   # returns number smaller than a, which is the nearest multiple of b\n    return  int(a/b) * b\n\n\n# can be used for test dataset as well\ndef build_dataset(path=""Preproc/Train/"", load_frac=1.0, batch_size=None, tile=False, max_per_class=0):\n\n    class_names = get_class_names(path=path)\n    print(""class_names = "",class_names)\n    nb_classes = len(class_names)\n\n    total_files = get_total_files(class_names, path=path)\n    total_load = int(total_files * load_frac)\n\n    if max_per_class > 0:\n        total_load = min( total_load, max_per_class * nb_classes)\n\n    if (batch_size is not None):                # keras gets particular: dataset size must be mult. of batch_size\n        total_load = nearest_multiple( total_load, batch_size)\n\n    print(""       total files = "",total_files,"", going to load total_load = "",total_load)\n\n    print(""total files = "",total_files,"", going to load total_load = "",total_load)\n\n    # pre-allocate memory for speed (old method used np.concatenate, slow)\n    mel_dims = get_sample_dimensions(class_names,path=path)  # get dims of sample data file\n    if (tile):\n        ldims = list(mel_dims)\n        ldims[3] = 3\n        mel_dims = tuple(ldims)\n    print("" melgram dimensions: "",mel_dims)\n    X = np.zeros((total_load, mel_dims[1], mel_dims[2], mel_dims[3]))\n    Y = np.zeros((total_load, nb_classes))\n    paths = []\n\n    load_count = 0\n    for idx, classname in enumerate(class_names):\n        print("""")\n        this_Y = np.array(encode_class(classname,class_names) )\n        this_Y = this_Y[np.newaxis,:]\n        class_files = os.listdir(path+classname)\n        shuffle(class_files)  # just to remove any special ordering\n        n_files = len(class_files)\n        n_load =  int(n_files * load_frac)   # n_load is how many files of THIS CLASS are expected to be loaded\n        if max_per_class > 0:\n            n_load = min( n_load, max_per_class)\n        printevery = 100\n\n        file_list = class_files[0:n_load]\n\n        for idx2, infilename in enumerate(file_list):   # Load files in a particular class\n            audio_path = path + classname + \'/\' + infilename\n            if (0 == idx2 % printevery) or (idx2+1 == len(class_files)):\n                print(""\\r Loading class "",idx+1,""/"",nb_classes,"": \\\'"",classname,\n                    ""\\\', File "",idx2+1,""/"", n_load,"": "",audio_path,""                  "",\n                    sep="""",end="""")\n\n            #auto-detect load method based on filename extension\n            melgram = load_melgram(audio_path)\n            if (tile) and (melgram.shape != mel_dims):\n                melgram = np.tile(melgram, 3)\n            elif (melgram.shape != mel_dims):\n                print(""\\n\\n    WARNING: Expecting spectrogram with dimensions mel_dims = "",mel_dims,"", but got one with melgram.shape = "",melgram.shape)\n                print(""     The offending file is = "",audio_path)\n\n            # usually it\'s the 2nd dimension of melgram.shape that is affected by audio file length\n            use_len = min(X.shape[2],melgram.shape[2])\n            X[load_count,:,0:use_len] = melgram[:,:,0:use_len]\n            #X[load_count,:,:] = melgram\n            Y[load_count,:] = this_Y\n            paths.append(audio_path)\n            load_count += 1\n            if (load_count >= total_load):   # Abort loading files after last even multiple of batch size\n                break\n\n        if (load_count >= total_load):   # Second break needed to get out of loop over classes\n            break\n\n\n    print("""")\n    if ( load_count != total_load ):  # check to make sure we loaded everything we thought we would\n        raise Exception(""Loaded ""+str(load_count)+"" files but was expecting ""+str(total_load) )\n\n    X, Y, paths = shuffle_XY_paths(X,Y,paths)  # mix up classes, & files within classes\n\n    return X, Y, paths, class_names\n'"
panotti/mixup_generator.py,0,"b'\'\'\'\n# Author: Yusuke Uchida\n# from https://github.com/yu4u/mixup-generator/blob/master/mixup_generator.py\n#  MIT License\nMIT License\n\nCopyright (c) 2017 Yusuke Uchida\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\'\'\'\n\nimport numpy as np\n\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s / r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser\n\n\n\nclass MixupGenerator():\n    def __init__(self, X_train, y_train, batch_size=32, alpha=0.2, shuffle=True, datagen=None):\n        self.X_train = X_train\n        self.y_train = y_train\n        self.batch_size = batch_size\n        self.alpha = alpha\n        self.shuffle = shuffle\n        self.sample_num = len(X_train)\n        self.datagen = datagen\n        self.eraser = get_random_eraser()\n\n    def __call__(self):\n        while True:\n            indexes = self.__get_exploration_order()\n            itr_num = int(len(indexes) // (self.batch_size * 2))\n\n            for i in range(itr_num):\n                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n                X, y = self.__data_generation(batch_ids)\n\n                yield X, y\n\n    def __get_exploration_order(self):\n        indexes = np.arange(self.sample_num)\n\n        if self.shuffle:\n            np.random.shuffle(indexes)\n\n        return indexes\n\n    def __data_generation(self, batch_ids):\n        _, h, w, c = self.X_train.shape\n        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n        X_l = l.reshape(self.batch_size, 1, 1, 1)\n        y_l = l.reshape(self.batch_size, 1)\n\n        X1 = self.X_train[batch_ids[:self.batch_size]]\n        X2 = self.X_train[batch_ids[self.batch_size:]]\n        X = X1 * X_l + X2 * (1 - X_l)\n\n        if self.datagen:\n            for i in range(self.batch_size):\n                X[i] = self.datagen.random_transform(X[i])\n                X[i] = self.datagen.standardize(X[i])\n\n        if isinstance(self.y_train, list):\n            y = []\n\n            for y_train_ in self.y_train:\n                y1 = y_train_[batch_ids[:self.batch_size]]\n                y2 = y_train_[batch_ids[self.batch_size:]]\n                y.append(y1 * y_l + y2 * (1 - y_l))\n        else:\n            y1 = self.y_train[batch_ids[:self.batch_size]]\n            y2 = self.y_train[batch_ids[self.batch_size:]]\n            y = y1 * y_l + y2 * (1 - y_l)\n\n        return X, y\n'"
panotti/models.py,0,"b'from __future__ import print_function\n\n\'\'\'\npanotti_models.py\nAuthor: Scott Hawley\n\nWhere we\'ll put various NN models.\n\nMyCNN:  This is kind of a mixture of Keun Woo Choi\'s code https://github.com/keunwoochoi/music-auto_tagging-keras\n   and the MNIST classifier at https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n\'\'\'\nfrom keras import backend as K\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential, Model, load_model, save_model\nfrom keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten, Conv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import ELU\nfrom keras.optimizers import SGD, Adam\n\nfrom os.path import isfile\nfrom panotti.multi_gpu import *\nfrom tensorflow.python.client import device_lib\nfrom panotti.multi_gpu import make_parallel, get_available_gpus\nimport h5py\n\n\n\n# This is a VGG-style network that I made by \'dumbing down\' @keunwoochoi\'s compact_cnn code\n# I have not attempted much optimization, however it *is* fairly understandable\ndef Panotti_CNN(X_shape, nb_classes, nb_layers=4):\n    # Inputs:\n    #    X_shape = [ # spectrograms per batch, # audio channels, # spectrogram freq bins, # spectrogram time bins ]\n    #    nb_classes = number of output n_classes\n    #    nb_layers = number of conv-pooling sets in the CNN\n    from keras import backend as K\n    K.set_image_data_format(\'channels_last\')                   # SHH changed on 3/1/2018 b/c tensorflow prefers channels_last\n\n    nb_filters = 32  # number of convolutional filters = ""feature maps""\n    kernel_size = (3, 3)  # convolution kernel size\n    pool_size = (2, 2)  # size of pooling area for max pooling\n    cl_dropout = 0.5    # conv. layer dropout\n    dl_dropout = 0.6    # dense layer dropout\n\n    print("" MyCNN_Keras2: X_shape = "",X_shape,"", channels = "",X_shape[3])\n    input_shape = (X_shape[1], X_shape[2], X_shape[3])\n    model = Sequential()\n    model.add(Conv2D(nb_filters, kernel_size, padding=\'same\', input_shape=input_shape, name=""Input""))\n    model.add(MaxPooling2D(pool_size=pool_size))\n    model.add(Activation(\'relu\'))        # Leave this relu & BN here.  ELU is not good here (my experience)\n    model.add(BatchNormalization(axis=-1))  # axis=1 for \'channels_first\'; but tensorflow preferse channels_last (axis=-1)\n\n    for layer in range(nb_layers-1):   # add more layers than just the first\n        model.add(Conv2D(nb_filters, kernel_size, padding=\'same\'))\n        model.add(MaxPooling2D(pool_size=pool_size))\n        model.add(Activation(\'elu\'))\n        model.add(Dropout(cl_dropout))\n        #model.add(BatchNormalization(axis=-1))  # ELU authors reccommend no BatchNorm. I confirm.\n\n    model.add(Flatten())\n    model.add(Dense(128))            # 128 is \'arbitrary\' for now\n    #model.add(Activation(\'relu\'))   # relu (no BN) works ok here, however ELU works a bit better...\n    model.add(Activation(\'elu\'))\n    model.add(Dropout(dl_dropout))\n    model.add(Dense(nb_classes))\n    model.add(Activation(""softmax"",name=""Output""))\n    return model\n\n\n# Used for when you want to use weights from a previously-trained model,\n# with a different set/number of output classes\ndef attach_new_weights(model, new_nb_classes, n_pop = 2, n_p_dense = None, last_dropout = 0.6):\n\n    # ""penultimate"" dense layer was originally 64 or 128. can change it here\n    if (n_p_dense is not None):\n        n_pop = 5\n\n    # pop off the last n_pop layers. We definitely want the last 2: Activation() and Dense(nb_classes)\n    for i in range(n_pop):\n        model.pop()\n\n    if (n_p_dense is not None):\n        model.add(Dense(n_p_dense))\n        model.add(Activation(\'elu\'))\n        model.add(Dropout(last_dropout))\n\n    # attach final output layers\n    model.add(Dense(new_nb_classes))  # new_nb_classes = new number of output classes\n    model.add(Activation(""softmax""))\n    return model\n\n\n# Next two routines are for attaching class names inside the saved model .hdf5 weights file\n# From https://stackoverflow.com/questions/44310448/attaching-class-labels-to-a-keras-model\ndef load_model_ext(filepath, custom_objects=None):\n    model = load_model(filepath, custom_objects=custom_objects)    # load the model normally\n\n    #--- Now load it again and look for additional useful metadata\n    f = h5py.File(filepath, mode=\'r\')\n\n    # initialize class_names with numbers (strings) in case hdf5 file doesn\'t have any\n    output_length = model.layers[-1].output_shape[1]\n    class_names = [str(x) for x in range(output_length)]\n    if \'class_names\' in f.attrs:\n        class_names = f.attrs.get(\'class_names\').tolist()\n        class_names = [x.decode() for x in class_names]\n    f.close()\n    return model, class_names\n\ndef save_model_ext(model, filepath, overwrite=True, class_names=None):\n    save_model(model, filepath, overwrite)\n    if class_names is not None:\n        f = h5py.File(filepath, mode=\'a\')\n        f.attrs[\'class_names\'] = np.array(class_names, dtype=\'S\')  # have to encode it somehow\n        f.close()\n\n\n# Freezing speeds up training by only declaring all but the last leave_last\n# layers as non-trainable; but  likely results in lower accuracy\n#  NOTE: In practice this achieves so little that I don\'t even use this:\n#         Most of the model parameters are in the last few layers anyway\ndef freeze_layers(model, train_last=3):\n    num_layers = len(model.layers)\n    freeze_layers = min( num_layers - train_last, num_layers )  # any train_last too big, freezes whole model\n    if (train_last < 0):                # special flag to disable freezing\n        freeze_layers = 0\n    print(""Freezing "",freeze_layers,""/"",num_layers,"" layers of model"")\n    for i in range(freeze_layers):\n        model.layers[i].trainable = False\n    return model\n\n\n# This is the main routine for setting up a model\ndef setup_model(X, class_names, nb_layers=4, try_checkpoint=True,\n    weights_file=\'weights.hdf5\', quiet=False, missing_weights_fatal=False, multi_tag=False):\n    \'\'\' In the following, the reason we hang on to & return serial_model,\n         is because Keras can\'t save parallel models, but according to fchollet\n         the serial & parallel versions will always share the same weights\n         (Strange but true!)\n    \'\'\'\n\n    # Here\'s where one might \'swap out\' different neural network \'model\' choices\n    serial_model = Panotti_CNN(X.shape, nb_classes=len(class_names), nb_layers=nb_layers)\n\n    # don\'t bother with freezing layers, at least with the hope of trianing on a laptop. doesn\'t speed up by more than a factor of 2.\n    # serial_model = freeze_layers(serial_model, train_last = 3)\n\n    # Initialize weights using checkpoint if it exists.\n    if (try_checkpoint):\n        print(""Looking for previous weights..."")\n        if ( isfile(weights_file) ):\n            print (\'Weights file detected. Loading from \',weights_file)\n            loaded_model = load_model(weights_file)   # strip any previous parallel part, to be added back in later\n            serial_model.set_weights( loaded_model.get_weights() )   # assign weights based on checkpoint\n        else:\n            if (missing_weights_fatal):\n                print(""Need weights file to continue.  Aborting"")\n                assert(not missing_weights_fatal)\n            else:\n                print(\'No weights file detected, so starting from scratch.\')\n\n\n    opt = \'adadelta\' # Adam(lr = 0.00001)  # So far, adadelta seems to work the best of things I\'ve tried\n    #opt = \'adam\'\n    metrics = [\'accuracy\']\n\n    if (multi_tag):     # multi_tag means more than one class can be \'chosen\' at a time; default is \'only one\'\n        loss = \'binary_crossentropy\'\n    else:\n        loss = \'categorical_crossentropy\'\n\n    serial_model.compile(loss=loss, optimizer=opt, metrics=metrics)\n\n    # Multi-GPU ""parallel"" capability\n    gpu_count = get_available_gpus()\n    if (gpu_count >= 2):\n        print("" Parallel run on"",gpu_count,""GPUs"")\n        model = make_parallel(serial_model, gpu_count=gpu_count)\n        model.compile(loss=loss, optimizer=opt, metrics=metrics)\n    else:\n        model = serial_model\n\n    if (not quiet):\n        print(""Summary of serial model (duplicated across"",gpu_count,""GPUs):"")\n        serial_model.summary()  # print out the model layers\n\n    return model, serial_model   # fchollet says to hang on to the serial model for checkpointing\n'"
panotti/multi_gpu.py,0,"b'from keras.layers import concatenate\nfrom keras.layers.core import Lambda\nfrom keras.models import Model\nfrom keras.utils import multi_gpu_model\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\nimport numpy as np\nfrom panotti import models\n\ndef make_serial(model, parallel=True):   # Undoes make_parallel, but keyword included in case it\'s called on a serial model\n    if (parallel):\n        return model.layers[-2]\n    else:\n        return model                    # if model\'s already serial, return original model\n\n\ndef get_available_gpus():  # from https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n    local_device_protos = device_lib.list_local_devices()\n    gpu_list =  [x.name for x in local_device_protos if x.device_type == \'GPU\']\n    count = len(gpu_list)\n    print("" Available GPUs = "",gpu_list,"", count = "",count)\n    return count\n\n\ndef make_parallel(serial_model, gpu_count=-1):\n    return multi_gpu_model(serial_model, gpus=gpu_count)\n\n\n\nclass MultiGPUModelCheckpoint(Callback):\n    """"""Save the *serial version* of the model after every epoch.\n    `filepath` can contain named formatting options,\n    which will be filled the value of `epoch` and\n    keys in `logs` (passed in `on_epoch_end`).\n    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\n    then the model checkpoints will be saved with the epoch number and\n    the validation loss in the filename.\n    # Arguments\n        filepath: string, path to save the model file.\n        monitor: quantity to monitor.\n        verbose: verbosity mode, 0 or 1.\n        save_best_only: if `save_best_only=True`,\n            the latest best model according to\n            the quantity monitored will not be overwritten.\n        mode: one of {auto, min, max}.\n            If `save_best_only=True`, the decision\n            to overwrite the current save file is made\n            based on either the maximization or the\n            minimization of the monitored quantity. For `val_acc`,\n            this should be `max`, for `val_loss` this should\n            be `min`, etc. In `auto` mode, the direction is\n            automatically inferred from the name of the monitored quantity.\n        save_weights_only: if True, then only the model\'s weights will be\n            saved (`model.save_weights(filepath)`), else the full model\n            is saved (`model.save(filepath)`).\n        period: Interval (number of epochs) between checkpoints.\n        ## Not implmented pb: Boolan: Also save weights to Protobuf file for compatibility with Tensorflow\n    """"""\n\n    def __init__(self, filepath, monitor=\'val_loss\', verbose=0,\n                 save_best_only=False, save_weights_only=False,\n                 mode=\'auto\', period=1, serial_model=None, class_names=None):# , pb=False):\n        super(MultiGPUModelCheckpoint, self).__init__()\n        self.monitor = monitor\n        self.verbose = verbose\n        self.filepath = filepath\n        self.save_best_only = save_best_only\n        self.save_weights_only = save_weights_only\n        self.period = period\n        self.epochs_since_last_save = 0\n        self.class_names = class_names\n\n        if (serial_model is None):\n            self.serial_model = model\n        else:\n            self.serial_model = serial_model\n\n        if mode not in [\'auto\', \'min\', \'max\']:\n            warnings.warn(\'ModelCheckpoint mode %s is unknown, \'\n                          \'fallback to auto mode.\' % (mode),\n                          RuntimeWarning)\n            mode = \'auto\'\n\n        if mode == \'min\':\n            self.monitor_op = np.less\n            self.best = np.Inf\n        elif mode == \'max\':\n            self.monitor_op = np.greater\n            self.best = -np.Inf\n        else:\n            if \'acc\' in self.monitor or self.monitor.startswith(\'fmeasure\'):\n                self.monitor_op = np.greater\n                self.best = -np.Inf\n            else:\n                self.monitor_op = np.less\n                self.best = np.Inf\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epochs_since_last_save += 1\n        if self.epochs_since_last_save >= self.period:\n            self.epochs_since_last_save = 0\n            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n            if self.save_best_only:\n                current = logs.get(self.monitor)\n                if current is None:\n                    warnings.warn(\'Can save best model only with %s available, \'\n                                  \'skipping.\' % (self.monitor), RuntimeWarning)\n                else:\n                    if self.monitor_op(current, self.best):\n                        if self.verbose > 0:\n                            print(\'\\nEpoch %05d: %s improved from %0.5f to %0.5f,\'\n                                  \' saving model to %s\'\n                                  % (epoch + 1, self.monitor, self.best,\n                                     current, filepath))\n                        self.best = current\n                        if self.save_weights_only:\n                            self.serial_model.save_weights(filepath, overwrite=True)\n                        else:\n                            #self.serial_model.save(filepath, overwrite=True)\n                            models.save_model_ext(self.serial_model, filepath, overwrite=True, class_names=self.class_names)\n\n                    else:\n                        if self.verbose > 0:\n                            print(\'\\nEpoch %05d: %s did not improve\' %\n                                  (epoch + 1, self.monitor))\n            else:\n                if self.verbose > 0:\n                    print(\'\\nEpoch %05d: saving model to %s\' % (epoch + 1, filepath))\n                if self.save_weights_only:\n                    self.serial_model.save_weights(filepath, overwrite=True)\n                else:\n                    #self.serial_model.save(filepath, overwrite=True)\n                    models.save_model_ext(self.serial_model, filepath, overwrite=True, class_names=self.class_names)\n'"
sorting-hat/scp_upload.py,0,"b'#!/usr/bin/env python3\nfrom paramiko import SSHClient, WarningPolicy, SSHConfig, ProxyCommand\nfrom scp import SCPClient    # from https://github.com/jbardin/scp.py\nimport sys\nimport os\n\nfrom multiprocessing import Process, Queue\nimport threading\n\n\n# Define default simple progress callback that prints the current percentage completed for the file\ndef simple_callback(filename, size, sent):\n    sys.stdout.write(""%s\\\'s progress: %.2f%%   \\r"" % (filename, float(sent)/float(size)*100) )\n\n\ndef scp_thread(scp, src_blob, dst_blob):  # putting and closing together in one\n    scp.put(src_blob, dst_blob)\n    scp.close()\n\n\ndef scp_upload(src_blob=\'Preproc.tar.gz\', dst_blob=""~"", options={\'hostname\': \'lecun\', \'username\': \'shawley\'}, progress=simple_callback):\n    # from https://gist.github.com/acdha/6064215\n\n    #--- Make the Paramiko SSH thing use my .ssh/config file (b/c I like ProxyCommand!)\n    client = SSHClient()\n    client.load_system_host_keys()\n    client._policy = WarningPolicy()\n    client.set_missing_host_key_policy(WarningPolicy())  # hmm. WarningPolicy? Most people use AutoAddPolicy. \n\n    ssh_config = SSHConfig()\n    user_config_file = os.path.expanduser(""~/.ssh/config"")\n    if os.path.exists(user_config_file):\n        with open(user_config_file) as f:\n            ssh_config.parse(f)\n\n    cfg = {\'hostname\': options[\'hostname\'], \'username\': options[""username""]}\n\n    user_config = ssh_config.lookup(cfg[\'hostname\'])\n    for k in (\'hostname\', \'username\', \'port\'):\n        if k in user_config:\n            cfg[k] = user_config[k]\n\n    if \'proxycommand\' in user_config:\n        cfg[\'sock\'] = ProxyCommand(user_config[\'proxycommand\'])\n\n    client.connect(**cfg)\n\n    socket_timeout = None # number of seconds for timeout. None = never timeout. TODO: None means program may hang. But timeouts are annoying!\n\n    # SCPCLient takes a paramiko transport and progress callback as its arguments.\n    scp = SCPClient(client.get_transport(), progress=progress, socket_timeout=socket_timeout)\n\n    # NOW we can finally upload! (in a separate process)\n    #scp.put(src_blob, dst_blob)   # now in scp_thread\n\n    # we want this to be non-blocking so we stick it in a thread\n    thread = threading.Thread(target=scp_thread, args=(scp,src_blob, dst_blob) )\n    thread.start()\n\n    #scp.close()  # now in scp_thread\n\n\nif __name__ == \'__main__\':\n    scp_upload()\n'"
sorting-hat/settingsjson.py,0,"b'\nimport json\n# preprocess_data -s -m --dur=4.0 -r=44100\n# train_network.py --epochs=10 --val=0\nsettings_json = json.dumps([\n    {\'type\': \'title\',\n     \'title\': \'Sorting Hat Settings\'},\n    {\'type\': \'string\',\n     \'title\': \'Server\',\n     \'desc\': \'Hostname or IP address of GPU compute server\',\n     \'section\': \'network\',\n     \'key\': \'server\'},\n    {\'type\': \'string\',\n     \'title\': \'Username\',\n     \'desc\': \'Username on GPU server\',\n     \'section\': \'network\',\n     \'key\': \'username\'},\n    {\'type\': \'path\',\n     \'title\': \'SSH keys\',\n     \'desc\': \'Path to ssh keys\',\n     \'section\': \'network\',\n     \'key\': \'sshKeyPath\'},\n    {\'type\': \'bool\',\n     \'title\': \'Clean\',\n     \'desc\': \'Dataset is known to be completely uniform. (Overrides duration & mono)\',\n     \'section\': \'preproc\',\n     \'key\': \'clean\'},\n    {\'type\': \'bool\',\n     \'title\': \'Mono\',\n     \'desc\': \'Force audio to mono\',\n     \'section\': \'preproc\',\n     \'key\': \'mono\'},\n    {\'type\': \'bool\',\n     \'title\': \'Sequential split\',\n     \'desc\': \'For Test/Train split: preserve sequential order of audio clips (False = Shuffle)\',\n     \'section\': \'preproc\',\n     \'key\': \'sequential\'},\n    {\'type\': \'numeric\',\n     \'title\': \'Duration\',\n     \'desc\': \'Length in seconds of audio clips (truncated/padded if too long/short)\',\n     \'section\': \'preproc\',\n     \'key\': \'duration\'},\n    {\'type\': \'numeric\',\n     \'title\': \'Sample rate\',\n     \'desc\': \'Sample rate to re-sample all audio clips to\',\n     \'section\': \'preproc\',\n     \'key\': \'sampleRate\'},\n    {\'type\': \'options\',\n     \'title\': \'Spectrogram file format \',\n     \'desc\': ""File format for spectrogram images. (npz = default)"",\n     \'section\': \'preproc\',\n     \'key\': \'specFileFormat\',\n     \'options\': [\'npz\', \'png\', \'jpeg\',\'npy\']},\n    {\'type\': \'bool\',\n     \'title\': ""Split long files (doesn\'t work yet)"",\n     \'desc\': \'Audio files longer than <duration> get multiple parts sent (False=Truncate)\',\n     \'section\': \'preproc\',\n     \'key\': \'split_audio\'},\n    {\'type\': \'options\',\n     \'title\': \'Starting weights\',\n     \'desc\': ""Initial neural network weights for training (Default = whatever\'s on the hard drive)"",\n     \'section\': \'train\',\n     \'key\': \'weightsOption\',\n     \'options\': [\'Default\', \'Random\', ""Upload (doesn\'t work yet)""]},\n    {\'type\': \'numeric\',\n     \'title\': \'Epochs\',\n     \'desc\': \'Number of machine learning iterations to run.\',\n     \'section\': \'train\',\n     \'key\': \'epochs\'},\n    {\'type\': \'numeric\',\n     \'title\': \'Validation split\',\n     \'desc\': \'Fraction of training data to ""split off"" for validation\',\n     \'section\': \'train\',\n     \'key\': \'val_split\'},\n     {\'type\': \'numeric\',           # this isn\'t technically training, but we want it to be post-upload\n      \'title\': ""Augment factor (doesn\'t work yet)"",\n      \'desc\': \'Squeeze & stretch spectrograms to increase dataset by this factor (1=Off)\',\n      \'section\': \'train\',\n      \'key\': \'aug_fac\'},\n     ])\n'"
sorting-hat/sorting-hat.py,0,"b'#! /usr/bin/env python3\n\n# Author: Braiden King\n# Team 15\n# HackMT 2018\n\nimport os\nimport subprocess\nfrom flask import Flask, request, render_template, send_file, send_from_directory\nimport shutil\nimport time\nfrom jinja2 import Markup\nimport os\n\napp = Flask(__name__)\n\n\nAPP_ROOT = os.path.dirname(os.path.abspath(__file__))\n\n\napp.jinja_env.globals[\'include_file\'] = lambda filename : Markup(app.jinja_loader.get_source(app.jinja_env, filename)[0])\n\n\n\n@app.route(""/"")\ndef index():\n    if os.path.exists(\'.lock\'):\n        return render_template(\'busy.html\')   # tell user to come back if it\'s in use\n    return render_template(\'index.html\')\n\n\n@app.route(""/busy"")\ndef busy():\n    return render_template(\'busy.html\')\n\n\n# User uploads data for training\n@app.route(""/upload_train"", methods=[""POST""])\ndef upload_train():\n    if os.path.exists(\'.lock\'):\n        return render_template(\'busy.html\')   # tell user to come back if it\'s in use\n\n    target = os.path.join(APP_ROOT, \'./\')\n    print(target)\n\n    if not os.path.isdir(target):\n        os.mkdir(target)\n\n    for file in request.files.getlist(""file""):\n\n        filename = str(file.filename)\n        filename.replace(\' \',\'\\\\ \')\n        destination = ""/"".join([target, filename])\n        print(""filename = "",filename,"", destination = "",destination)\n        file.save(destination)\n\n    cmd = \'touch .lock; rm -rf Preproc Samples; unzip \'+destination+\' | tee log.txt \'\n    print(\'cmd = [\',cmd,\']\')\n    p = subprocess.Popen(cmd, stdout = subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, shell=True)\n    out,err = p.communicate()       # all the output and error will get sent to the browser\n    print(""out = "",str(out))\n    print(""err = "",str(err))\n    return render_template(\'preproc.html\')\n\n\n@app.route(""/upload_preproc"",methods=[\'GET\',\'POST\'])\ndef upload_preproc():\n    cmd = \'touch .lock; rm -f Samples.zip;  ../preprocess_data.py -s -m --dur=4.0 -r=44100 | tee -a log.txt\'\n    print(\'cmd = [\',cmd,\']\')\n    p = subprocess.Popen(cmd, stdout = subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, shell=True)\n    out,err = p.communicate()       # all the output and error will get sent to the browser\n    print(""out = "",str(out))\n    print(""err = "",str(err))\n    return render_template(\'train.html\')\n\n@app.route(""/train"",methods=[\'GET\',\'POST\'])\ndef train():\n    cmd = \'touch .lock; ../train_network.py --epochs=10 --val=0 | tee -a log.txt;  rm -f .lock\'\n    print(\'cmd = [\',cmd,\']\')\n    p = subprocess.Popen(cmd, stdout = subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, shell=True)\n    out,err = p.communicate()       # all the output and error will get sent to the browser\n    print(""out = "",str(out))\n    print(""err = "",str(err))\n    return render_template(\'done_train.html\')\n\n\n@app.route(""/download_train"", methods=[""GET"", ""POST""])\ndef download_train():\n      try:\n          #return send_file(""weights.hdf5"", attachment_filename= ""weights.hdf5"")\n          return send_from_directory(""."", ""weights.hdf5"", as_attachment=True)\n      except Exception as e:\n          return str(e)\n\n\n@app.route(""/upload_sort"", methods=[""POST""])\ndef upload_sort():\n\n    target = os.path.join(APP_ROOT, \'Samples_sort/\')\n\n    if not os.path.isdir(target):\n        os.mkdir(target)\n\n    for file in request.files.getlist(""file""):\n\n        filename = file.filename\n        filename = str(file.filename)\n        if (\'\' != filename):\n            filename.replace(\' \',\'\\\\ \')\n            destination = ""/"".join([target, filename])\n            print("" in sort: filename = "",filename,"", destination = "",destination)\n            file.save(destination)\n\n    cmd = \'touch .lock; rm -f data.json; cd Samples_sort; ../../predict_class.py -d=4.0 -r=44100 -m -w ../weights.hdf5 -c ../Samples * | tee -a ../log.txt; cp data.json ..; cd ..; rm -rf .lock Samples_sort\'\n    print(\'cmd = [\',cmd,\']\')\n    p = subprocess.Popen(cmd, stdout = subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, shell=True)\n    out,err = p.communicate()       # all the output and error will get sent to the browser\n    print(""out = "",str(out))\n    print(""err = "",str(err))\n\n    return render_template(\'done_sort.html\')\n\n\n@app.route(""/download_sort"", methods=[""GET"",""PUT""])\ndef download_sort():\n   #cmd= ""echo hello;  pwd;  zip -r downloads.zip data.json""# file.exe""\n   #print(\'cmd = [\',cmd,\']\')\n   #p = subprocess.Popen(cmd, stdout = subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, shell=True)\n   #out,err = p.communicate()       # all the output and error will get sent to the browser\n   #print(""out = "",str(out))\n   #print(""err = "",str(err))\n   try:\n       return send_from_directory(""."", ""data.json"", as_attachment=True)\n   except Exception as e:\n       return str(e)\n\n\n\n\nif __name__ == ""__main__"":\n    app.run(debug=True, threaded=True, port=8000, host=\'0.0.0.0\')\n'"
utils/__init__.py,0,b'\n'
utils/augment_audio.py,0,"b'#! /usr/bin/env python\n\'\'\'\nAuthor: Scott H. Hawley\n\nBased on paper,\nA SOFTWARE FRAMEWORK FOR MUSICAL DATA AUGMENTATION\nBrian McFee, Eric J. Humphrey, and Juan P. Bello\nhttps://bmcfee.github.io/papers/ismir2015_augmentation.pdf\n\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nimport librosa\nfrom random import getrandbits\nimport sys, getopt, os\nfrom multiprocessing import Pool\nfrom functools import partial\n\n\ndef random_onoff():                # randomly turns on or off\n    return bool(getrandbits(1))\n\n\n# returns a list of augmented audio data, stereo or mono\ndef augment_audio(y, sr, n_augment = 0, allow_speedandpitch = True, allow_pitch = True,\n    allow_speed = True, allow_dyn = True, allow_noise = True, allow_timeshift = True, tab="""",quiet=False):\n\n    mods = [y]                  # always returns the original as element zero\n    length = y.shape[0]\n\n    for i in range(n_augment):\n        if not quiet:\n            print(tab+""augment_audio: "",i+1,""of"",n_augment)\n        y_mod = y.copy()\n        count_changes = 0\n\n        # change speed and pitch together\n        if (allow_speedandpitch) and random_onoff():\n            length_change = np.random.uniform(low=0.9,high=1.1)\n            speed_fac = 1.0  / length_change\n            if not quiet:\n                print(tab+""    resample length_change = "",length_change)\n            tmp = np.interp(np.arange(0,len(y),speed_fac),np.arange(0,len(y)),y)\n            #tmp = resample(y,int(length*lengt_fac))    # signal.resample is too slow\n            minlen = min( y.shape[0], tmp.shape[0])     # keep same length as original;\n            y_mod *= 0                                    # pad with zeros\n            y_mod[0:minlen] = tmp[0:minlen]\n            count_changes += 1\n\n        # change pitch (w/o speed)\n        if (allow_pitch) and random_onoff():\n            bins_per_octave = 24        # pitch increments are quarter-steps\n            pitch_pm = 4                                # +/- this many quarter steps\n            pitch_change =  pitch_pm * 2*(np.random.uniform()-0.5)\n            if not quiet:\n                print(tab+""    pitch_change = "",pitch_change)\n            y_mod = librosa.effects.pitch_shift(y, sr, n_steps=pitch_change, bins_per_octave=bins_per_octave)\n            count_changes += 1\n\n        # change speed (w/o pitch),\n        if (allow_speed) and random_onoff():\n            speed_change = np.random.uniform(low=0.9,high=1.1)\n            if not quiet:\n                print(tab+""    speed_change = "",speed_change)\n            tmp = librosa.effects.time_stretch(y_mod, speed_change)\n            minlen = min( y.shape[0], tmp.shape[0])        # keep same length as original;\n            y_mod *= 0                                    # pad with zeros\n            y_mod[0:minlen] = tmp[0:minlen]\n            count_changes += 1\n\n        # change dynamic range\n        if (allow_dyn) and random_onoff():\n            dyn_change = np.random.uniform(low=0.5,high=1.1)  # change amplitude\n            if not quiet:\n                print(tab+""    dyn_change = "",dyn_change)\n            y_mod = y_mod * dyn_change\n            count_changes += 1\n\n        # add noise\n        if (allow_noise) and random_onoff():\n            noise_amp = 0.005*np.random.uniform()*np.amax(y)\n            if random_onoff():\n                if not quiet:\n                    print(tab+""    gaussian noise_amp = "",noise_amp)\n                y_mod +=  noise_amp * np.random.normal(size=length)\n            else:\n                if not quiet:\n                    print(tab+""    uniform noise_amp = "",noise_amp)\n                y_mod +=  noise_amp * np.random.normal(size=length)\n            count_changes += 1\n\n        # shift in time forwards or backwards\n        if (allow_timeshift) and random_onoff():\n            timeshift_fac = 0.2 *2*(np.random.uniform()-0.5)  # up to 20% of length\n            if not quiet:\n                print(tab+""    timeshift_fac = "",timeshift_fac)\n            start = int(length * timeshift_fac)\n            if (start > 0):\n                y_mod = np.pad(y_mod,(start,0),mode=\'constant\')[0:y_mod.shape[0]]\n            else:\n                y_mod = np.pad(y_mod,(0,-start),mode=\'constant\')[0:y_mod.shape[0]]\n            count_changes += 1\n\n        # last-ditch effort to make sure we made a change (recursive/sloppy, but...works)\n        if (0 == count_changes):\n            if not quiet:\n                print(""No changes made to signal, trying again"")\n            mods.append(  augment_audio(y, sr, n_augment = 1, tab=""      "", quiet=quiet)[1] )\n        else:\n            mods.append(y_mod)\n\n    return mods\n\n\ndef augment_one_file(file_list, n_augment, quiet, file_index):\n\n    infile = file_list[file_index]\n    if os.path.isfile(infile):\n        print(""    Operating on file "",infile,"", making "",n_augment,"" augmentations..."",sep="""")\n        y, sr = librosa.load(infile, sr=None)\n        mods = augment_audio(y, sr, n_augment=n_augment, quiet=quiet)\n        for i in range(len(mods)-1):\n            filename_no_ext = os.path.splitext(infile)[0]\n            ext = os.path.splitext(infile)[1]\n            outfile = filename_no_ext+""_aug""+str(i+1)+ext\n            if not quiet:\n                print(""      mod = "",i+1,"": saving file"",outfile,""..."")\n            librosa.output.write_wav(outfile,mods[i+1],sr)\n    else:\n        print("" *** File"",infile,""does not exist.  Skipping."")\n    return\n\ndef main(args):\n    np.random.seed(1)\n    quiet = args.quiet\n\n    if args.test:  # just testing the augment_audio.py on sample data\n        y, sr = librosa.load(librosa.util.example_audio_file(),sr=None)\n        librosa.output.write_wav(""orig.wav"",y,sr)\n        mods = augment_audio(y, sr, n_augment=args.N, quiet=quiet)\n        for i in range(len(mods)-1):\n            outfile = ""modded""+str(i+1)+"".wav""\n            librosa.output.write_wav(outfile,mods[i+1],sr)\n        sys.exit()\n\n    # read in every file on the list, augment it lots of times, output all those\n    file_indices = tuple( range(len(args.file)) )\n    cpu_count = os.cpu_count()\n    pool = Pool(cpu_count)\n    pool.map(partial(augment_one_file, args.file, args.N, args.quiet), file_indices)\n\n    \'\'\'\n    for infile in args.file:\n        if os.path.isfile(infile):\n            print(""    Operating on file "",infile,"", making "",args.N,"" augmentations..."",sep="""")\n            y, sr = librosa.load(infile, sr=None)\n            mods = augment_audio(y, sr, n_augment=args.N, quiet=quiet)\n            for i in range(len(mods)-1):\n                filename_no_ext = os.path.splitext(infile)[0]\n                ext = os.path.splitext(infile)[1]\n                outfile = filename_no_ext+""_aug""+str(i+1)+ext\n                if not quiet:\n                    print(""      mod = "",i+1,"": saving file"",outfile,""..."")\n                librosa.output.write_wav(outfile,mods[i+1],sr)\n        else:\n            print("" *** File"",infile,""does not exist.  Skipping."")\n    \'\'\'\n    return\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Perform data augmentation\')\n    parser.add_argument(""-q"", ""--quiet"", help=""quiet mode; reduce output"",\n                    action=""store_true"")\n    parser.add_argument(""-t"", ""--test"", help=""test on sample data (takes precedence over other args)"", action=""store_true"")\n    parser.add_argument(""N"", help=""number of augmentations to generate"",type=int)\n    parser.add_argument(\'file\', help=""sound files to augment"", nargs=\'*\')\n    args = parser.parse_args()\n    main(args)\n'"
utils/binauralify.py,0,"b'#!/usr/bin/env python\n\'\'\'\nbinauralify.py\nSend a mono file to a bunch of stereo files of binaural audio, for various source locations/angles\n\nAuthor: Scott Hawley, modified from Adam Bard\'s code at http://web.uvic.ca/~adambard/ASP/project/\n\nIn the code\'s current state, it only varies in a horizontal plane (""azimuth""),\nbut you can easily modify it to go up/down (""elevation"") as well.\n\nFor my ML runs, I\'m trying n_az = 12, i.e. every 30 degrees.\n\nRequirements:\n    HRTF data: It will automatically try to download the HRTF measurements from\n        http://sound.media.mit.edu/resources/KEMAR/compact.tar.Z\n        and install them in the current directory\n        If this fails, you can just install them yourself\n\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nfrom scipy import *\nimport librosa\nimport os, sys\nfrom multiprocessing import Pool\nfrom functools import partial\n\n\n# TODO: this never checks in case one of the operations fails\ndef download_if_missing(dirname=""compact"", filename=""compact.tar.Z"",\n    url=""http://sound.media.mit.edu/resources/KEMAR/compact.tar.Z"",tar=True):\n\n    if not os.path.isdir(dirname):\n        print(""Directory \\\'""+dirname+""/\\\' not present.  Checking for compressed archive"",filename)\n\n        if not os.path.isfile(filename):\n            import urllib\n            print(""   Compressed archive \\\'""+filename+""\\\' not present.  Downloading it..."")\n\n            if sys.version_info[0] >= 3:    # Python 3 and up\n                from urllib.request import urlretrieve\n            else:                           # Python 2\n                from urllib import urlretrieve\n            urlretrieve(url, filename)\n\n        from subprocess import call\n        print(""   Uncompressing archive..."",end="""")\n        if (tar):\n            call([""tar"",""-zxf"",filename])\n        else:\n            call([""unzip"",filename])\n        print("" done."")\n    return\n\n\n\ndef readHRTF_file(name):   # from https://github.com/uncopenweb/3DSound\n    \'\'\'Read the hrtf data from compact MATLAB format files\'\'\'\n    r = np.fromfile( open(name, \'rb\'), np.dtype(\'>i2\'), 256)\n    r.shape = (128,2)\n    # half the rate to 22050 and scale to 0 -> 1\n    r = r.astype(float)\n    # should use a better filter here, this is a box lowering the sample rate from 44100 to 22050\n    r = (r[0::2,:] + r[1::2,:]) / 65536\n    return r\n\n\n\ndef setangles(elev, azimuth):\n    elev = int(elev)\n    azimuth = int(azimuth)\n\n    #bring to multiple of ten\n    if elev != 0:\n        while elev%10 > 0:\n            elev = elev + 1\n\n    if elev > 90:\n        elev = 90\n    if elev < -40:\n        elev = -40\n\n    #Set increment of azimuth based on elevation\n    if abs(elev) < 30:\n        incr = 5\n    elif abs(elev) == 30:\n        incr = 6\n    elif abs(elev) == 40:\n        incr = 6.43\n        opts = [0, 6, 13, 19, 26, 32, 29, 45, 51, 58, 64, 71, 77, 84, 90, 96, 103, 109, 116, 122, 129, 135, 141, 148, 154, 161, 167, 174, 180]\n    elif elev == 50:\n        incr = 8\n    elif elev == 60:\n        incr = 10\n    elif elev == 70:\n        incr = 15\n    elif elev == 80:\n        incr = 30\n    elif elev == 90:\n        incr = 0\n        azimuth = 0\n    flip = False\n\n    #bring into [-pi,pi]\n    while azimuth > 180:\n        azimuth = azimuth - 180\n    while azimuth < -180:\n        azimuth = azimuth + 180\n\n    #check if we need to flip left and right.\n    if azimuth < 0:\n        azimuth = abs(azimuth)\n        flip = True\n\n    if abs(elev) == 40:\n        incr = 6.43\n        num = incr\n        while azimuth > num:\n            num = num + incr\n\n        azimuth = str(int(round(num)))\n        #special case for non-integer increment\n\n    elif azimuth != 0:\n        while azimuth % incr > 0:\n            azimuth = azimuth + 1\n\n    if int(azimuth) < 100:\n        azimuth = ""0"" + str(int(azimuth))\n\n    if int(azimuth) < 10:\n        azimuth = ""00""+ str(int(azimuth))\n\n    return elev, azimuth, flip\n\n\n\ndef read(elev, azimuth, N=128):\n    """""" Accepts elev and azimuth in degrees, and returns closest impulse response and\n    transfer function to that combination from compact KEMAR HRTF measurements""""""\n\n    elev, azimuth, flip = setangles(elev, azimuth)\n    filename = ""compact/elev""+str(elev)+""/H""+str(elev)+""e""+str(azimuth)+""a.dat""\n    h_t = readHRTF_file(filename)\n\n    h_t_l = transpose(transpose(h_t)[0])\n    h_t_r = transpose(transpose(h_t)[1])\n    if flip:\n        return h_t_r, h_t_l\n    return h_t_l, h_t_r\n\n\n# this is the code that takes a mono signal and projects it to one \'location\'\ndef project(sig, elev, azimuth):\n    h_t_l, h_t_r = read(elev, azimuth)\n\n    Hw_l = fft(h_t_l, len(sig))\n    Hw_r = fft(h_t_r, len(sig))\n\n    f_audio = fft(sig)\n    f_audio_l = Hw_l*f_audio\n    f_audio_r = Hw_r*f_audio\n    t_audio_l = ifft(f_audio_l, len(sig)).real\n    t_audio_r = ifft(f_audio_r, len(sig)).real\n    return t_audio_l, t_audio_r\n\n\n# Bard\'s code for spining one audio clip around.  I\'m not using it but, still leaving in\ndef path(t_sig, infile, sr, start, end, duration=0, window_size=1024, fs=44100):\n    """""" Moves a sound from start to end positions over duration (Seconds)""""""\n    M = (fs/2.) / window_size\n    w = r_[:fs/2.:M]\n    N = len(w)\n\n    window = hamming(N)   # this is for overlapping multiple \'locations\' into one long clip\n    #window = r_[:window_size])\n\n    i = 1\n    elev = start[0]\n    elev_end = end[0]\n\n    if duration == 0:\n        duration = len(t_sig)/fs\n\n    azimuth = start[1]\n    azimuth_end = end[1]\n    N_steps = int(len(t_sig) * 2 / window_size)\n    elev_delta = float((elev_end - elev) / float(N_steps)) #deg/half-window\n    azimuth_delta = float((azimuth_end - azimuth) / float(N_steps))\n\n    output_l = zeros( len(t_sig) )\n    output_r = zeros( len(t_sig) )\n\n    outpath = ""./""\n    while i*(window_size) < len(t_sig):\n        ind_min = int( (i-1)*window_size)\n        ind_max = int( (i)*window_size )\n        t_sig_w = t_sig[ind_min:ind_max] * window\n        t_output_l, t_output_r = project(t_sig_w, elev, azimuth)\n\n        output_l[ind_min:ind_max] += t_output_l\n        output_r[ind_min:ind_max] += t_output_r\n\n        elev = elev + elev_delta\n        azimuth = azimuth + azimuth_delta\n\n        i = i + 0.5\n\n    return output_l, output_r\n\n\n\n# takes a single file\'s worth of mono and generates multiple files at different locations\ndef project_multi(mono_sig, infile, sr, start, end, steps, quiet=False):\n    elev_bgn = start[0]\n    az_bgn = start[1]\n    elev_end = end[0]\n    az_end = end[1]\n    steps_elev = steps[0]\n    steps_az = steps[1]\n    elev_delta = float((elev_end - elev_bgn) / float(steps_elev)) #deg/half-window\n    az_delta = float((az_end - az_bgn) / float(steps_az))\n\n    total = steps_elev * steps_az\n\n    outpath = ""./""\n    count = 0\n    for i in range(steps_elev):\n        elev = elev_bgn + i * elev_delta\n        for j in range(steps_az):\n            count += 1\n            az = az_bgn + j * az_delta\n\n            stereo_l, stereo_r = project(mono_sig, elev, az)\n            stereo_sig = np.vstack( (stereo_l, stereo_r))\n\n            # save to file\n            classname = ""class""+str(count).zfill(2)+""-""+""a""+str(az)#+""e""+str(elev)+ # can add elevation if you want\n            if not os.path.exists(outpath+classname):\n                os.mkdir( outpath+classname)\n            filename_no_ext = os.path.splitext(infile)[0]\n            ext = os.path.splitext(infile)[1]\n            outfile = classname+\'/\'+filename_no_ext+\'_\'+classname+ext\n            if not quiet:\n                print(""\\r    elev, az = "",elev,az,"", outfile = "",outfile,""             "")\n            librosa.output.write_wav(outfile,stereo_sig,sr)\n    if not quiet:\n        print("""")\n    return\n\ndef binauralify_one_file(file_list, n_az, quiet,file_index):\n\n    infile = file_list[file_index]\n    if os.path.isfile(infile):\n        print(""   Binauralifying file"",infile,""..."")\n        mono, sr = librosa.load(infile, sr=None)   # librosa naturally makes mono from stereo btw\n        project_multi(mono, infile, sr, (0,-180), (0, 180), (1,n_az), quiet=quiet)\n    else:\n        print(""   *** File"",infile,""does not exist.  Skipping."")\n    return\n\ndef main(args):\n\n    download_if_missing()                # make sure we\'ve got the hrtf data we need\n    cpu_count = os.cpu_count()\n    print("""",cpu_count,""CPUs detected: Parallel execution across"",cpu_count,""CPUs"")\n    file_indices = tuple( range(len(args.file)) )\n\n    pool = Pool(cpu_count)\n    pool.map(partial(binauralify_one_file, args.file, args.n_az, args.quiet), file_indices)\n    \'\'\'\n    for infile in args.file:\n        if os.path.isfile(infile):\n            print(""   Binauralifying file"",infile,""..."")\n            mono, sr = librosa.load(infile, sr=None)   # librosa naturally makes mono from stereo btw\n            project_multi(mono, infile, sr, (0,-180), (0, 180), (1,args.n_az), quiet=args.quiet)\n        else:\n            print(""   *** File"",infile,""does not exist.  Skipping."")\n    \'\'\'\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=""binauralify: generate binaural samples from mono audio"")\n#   parser.add_argument(""n_elev"", help=""number of discrete poitions of elevation"",type=int)\n    parser.add_argument(""-q"", ""--quiet"", help=""quiet mode; reduce output"",\n                    action=""store_true"")\n    parser.add_argument(""n_az"", help=""number of discrete poitions of azimuth"",type=int)\n    parser.add_argument(\'file\', help=""mono wav file(s) to binauralify"", nargs=\'+\')\n    args = parser.parse_args()\n    main(args)\n'"
utils/concat_audio.py,0,"b'#! /usr/bin/env python\n\'\'\'\nconcat_audio.py\nAuthor: Scott Hawley\n\nJoins a bunch of audio files into one big file.\nFilename of output is whatever the last filename is + ""_Long"" \n\nWorks on mono, stereo,...arbitrary numbers of channels\n\n\'\'\'\nfrom __future__ import print_function\n\nimport numpy as np\nimport librosa\nimport os\n\n\ndef main(args):\n\tcount = 0\n\tfor infile in args.file:\n\t\tcount += 1\n\t\tif os.path.isfile(infile):\n\t\t\tprint(""Input file: "",infile,""... "",end="""",sep="""")\n\t\t\tsignal, sr = librosa.load(infile, sr=None, mono=False)   # don\'t assume sr or mono\n\t\t\tif (1 == signal.ndim):\n\t\t\t\tprint(""this is a mono file.  signal.shape = "",signal.shape)\n\t\t\telse:\n\t\t\t\tprint(""this is a multi-channel file: signal.shape = "",signal.shape)\n\t\t\taxis = signal.ndim - 1\n\n\t\t\tif (1 == count):\n\t\t\t\tlong_clip = signal\n\t\t\telse:\n\t\t\t\tlong_clip = np.concatenate((long_clip,signal),axis=axis)\n\n\t\telse:\n\t\t\tprint("" *** File"",infile,""does not exist.  Skipping."")\n\n\tfilename_no_ext = os.path.splitext(infile)[0]\n\text = \'.wav\'  # os.path.splitext(infile)[1]\n\toutfile = filename_no_ext+""_Long""+ext\n\tprint(""Saving file"",outfile)\n\tlibrosa.output.write_wav(outfile,long_clip,sr)\n\treturn\n\n\n\nif __name__ == ""__main__"":\n\timport argparse\n\tparser = argparse.ArgumentParser(description=""concat_audio: concatenates multiple files into one"")\n\tparser.add_argument(\'file\', help=""file(s) to concat"", nargs=\'+\')   \n\targs = parser.parse_args()\n\tmain(args)\n\n'"
utils/h5topb.py,0,"b'#! /usr/bin/env python3\n# credit: John D\'Souza, https://medium.com/@johnsondsouza23/export-keras-model-to-protobuf-for-tensorflow-serving-101ad6c65142\n\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom tensorflow.python.saved_model import builder as saved_model_builder\nfrom tensorflow.python.saved_model.signature_def_utils import predict_signature_def\nfrom tensorflow.python.saved_model import tag_constants\n\n# Function to export Keras model to Protocol Buffer format\n# Inputs:\n#       path_to_h5: Path to Keras h5 model\n#       export_path: Path to store Protocol Buffer model\n\n\n# In order to use Tensorflow on a CPU, you need channels_last, regardless of your ~/.keras/keras.json settings\nK.set_image_data_format(\'channels_last\')\n\ndef export_h5_to_pb(path_to_h5, export_path):\n\n    # Set the learning phase to Test since the model is already trained.\n    K.set_learning_phase(0)\n\n    # Load the Keras model\n    keras_model = load_model(path_to_h5)\n\n    # Build the Protocol Buffer SavedModel at \'export_path\'\n    builder = saved_model_builder.SavedModelBuilder(export_path)\n\n    # Create prediction signature to be used by TensorFlow Serving Predict API\n    signature = predict_signature_def(inputs={""images"": keras_model.input},\n                                      outputs={""scores"": keras_model.output})\n\n    with K.get_session() as sess:\n        # Save the meta graph and the variables\n        builder.add_meta_graph_and_variables(sess=sess, tags=[tag_constants.SERVING],\n                                         signature_def_map={""predict"": signature})\n\n    builder.save()\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Convert Keras HDF5 model to Tensoflow\')\n    parser.add_argument(\'path_to_h5\', help=""hdf5 file(s) to convert"")\n    parser.add_argument(\'export_path\', help=""pb file(s) to generate"")\n    args = parser.parse_args()\n    export_h5_to_pb(args.path_to_h5, args.export_path)\n'"
utils/img2npy.py,0,"b'#!/usr/bin/env python3\n\n# Converts Image files format files to numpy, reading whatever image format is given\n# does not remove old extension, i.e. new file is ____.jpeg.npy (no reason other than laziness)\n# Runs in parallel\n\n# TODO: if <file> is actually a directory, then it should greate a new <directory>.npy\n#  AND *recursively* create a new version of original directory with all npy files replaced\n\n\nfrom PIL import Image\nimport os\nfrom multiprocessing import Pool\nimport numpy as np\nfrom functools import partial\n\n\ndef convert_one_file(file_list,  mono, file_index):\n\n    infile = file_list[file_index]\n    out_format = \'npy\'\n    if os.path.isfile(infile):\n        outfile = infile+"".""+out_format\n        print(""    Operating on file"",infile,"", converting to "",outfile)\n        img = Image.open(infile)\n        arr = np.asarray(img)\n        arr = np.reshape(arr, (1,1,arr.shape[0],arr.shape[1]))\n        print(\'arr.shape = \',arr.shape)\n        np.save(outfile,arr)\n    return\n\n\ndef main(args):\n\n    file_indices = tuple( range(len(args.file)) )\n\n    cpu_count = os.cpu_count()\n    pool = Pool(cpu_count)\n    pool.map(partial(convert_one_file, args.file, args.mono), file_indices)\n    return\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Convert image file to numpy array format\')\n    parser.add_argument(""-m"", ""--mono"", help=""Save greyscale encoding for mono files (otherwise # color channels)"",action=""store_true"")\n    parser.add_argument(\'file\', help="".npy file(s) to convert"", nargs=\'+\')\n    args = parser.parse_args()\n    main(args)\n'"
utils/np2img.py,0,"b'#!/usr/bin/env python3\n\n# Converts NumPy format files to image files, using whatever image format is specified\n# default = jpeg\n# does not remove old extension, i.e. new file is ____.npy.jpeg (no reason other than laziness)\n# Runs in parallel\n\n# TODO: if <file> is actually a directory, then it should greate a new <directory>.jpeg\n#  AND *recursively* create a new version of original directory with all npy files replaced\n#  by image files.\n#   Intended usage:  ./np2img Preproc/      (\n#                    would generate Preproc.jpeg/Train/*.npy.jpeg, etc)\n# ...\'course, alternatively we could just let ../preprocess_data.py save as jpegs\n#  and enable ../panotti/datautils.py, etc to read them.\n\nimport os\n#from multiprocessing.pool import ThreadPool as Pool\nfrom multiprocessing.pool import Pool\nimport numpy as np\nfrom functools import partial\nfrom scipy.misc import imsave\n\ndef convert_one_file(file_list, out_format, mono, file_index):\n    infile = file_list[file_index]\n    if os.path.isfile(infile):\n        basename, extension = os.path.splitext(infile)\n        if (\'.npz\' == extension) or (\'.npy\' == extension):\n            outfile = basename+"".""+out_format\n            print(""    Operating on file"",infile,"", converting to "",outfile)\n            if (\'.npz\' == extension):\n                with np.load(infile) as data:\n                    arr = data[\'melgram\']\n            else:\n                    arr = np.load(infile)\n            channels = arr.shape[-1]\n            if (channels <= 4):\n                #arr = np.reshape(arr, (arr.shape[2],arr.shape[3]))\n                arr = np.moveaxis(arr, 1, 3).squeeze()      # we use the \'channels_first\' in tensorflow, but images have channels_first. squeeze removes unit-size axes\n                arr = np.flip(arr, 0)    # flip spectrogram image right-side-up before saving, for easier viewing\n                if (2 == channels): # special case: 1=greyscale, 3=RGB, 4=RGBA, ..no 2.  so...?\n                    # pad a channel of zeros (for blue) and you\'ll just be stuck with it forever. so channels will =3\n                    b = np.zeros((arr.shape[0], layers.shape[1], 3))  # 3-channel array of zeros\n                    b[:,:,:-1] = arr                          # fill the zeros on the 1st 2 channels\n                    imsave(outfile, b, format=out_format)\n                else:\n                    imsave(outfile, arr, format=out_format)\n            else:\n                print(""   Skipping file"",infile,"": Channels > 4. Not representable in jpeg or png format."")\n        else:\n            print(""    Skipping file"",infile,"": not numpy format"")\n    else:\n        print(""    Skipping file"",infile,"": file not found"")\n\n    return\n\n\ndef main(args):\n    # farm out the list of files across multiple cpus\n    file_indices = tuple( range(len(args.file)) )\n    cpu_count = os.cpu_count()\n    pool = Pool(cpu_count)\n    pool.map(partial(convert_one_file, args.file, args.format, args.mono), file_indices)\n    return\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Convert numpy array file to image format\')\n    parser.add_argument(\'--format\', help=""format of output image (jpeg, png, etc). Default = png"", type=str, default=\'png\')\n    parser.add_argument(""-m"", ""--mono"", help=""Use greyscale encoding for mono files (otherwise use RGB)"",action=""store_true"")\n    parser.add_argument(\'file\', help="".npy file(s) to convert"", nargs=\'+\')\n    args = parser.parse_args()\n    main(args)\n'"
utils/pullTags.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Sat Jan 27 14:09:00 2018\n\n@authors: Braden Carei (initial), Scott Hawley (revisions/parallelism)\n\nExtracts metadata from Apple Loops .caf files\n""""""\n\nimport os\nimport subprocess\nimport errno\nimport shutil\nfrom sys import version_info\nimport glob\nfrom multiprocessing import Pool\nfrom functools import partial\nif version_info >= (3, 4):\n    from plistlib import loads as readPlistFromString\nelse:\n    from plistlib import readPlistFromString\nimport re\n\n\nkeys_to_use = [\'kMDItemMusicalInstrumentName\',\n               \'kMDItemMusicalInstrumentCategory\',\n               \'kMDItemMusicalGenre\',\n               \'kMDItemAppleLoopDescriptors\',\n               \'kMDItemTimeSignature\']\n\n\ndef make_dir(directory):  # makes a directory if it doesn\'t exist\n    try:\n        os.stat(directory)\n    except:\n        os.mkdir(directory)\n\ndef make_link(source, link_name):  # makes a symbolic link (unix) or shortcut (Windows):\n    # TODO: how to do on windows?\n    try:\n        os.stat(link_name)\n    except:\n        os.symlink(source, link_name)\n\n\ndef pullTags_one_file(file_list, new_main_folder, file_index):\n    # We actually pull the tags and create the directories & symbolic links as we go,\n    #   and let the OS/filesystem handle \'collisions\' if more than one process is trying to create the same thing\n    infile = file_list[file_index]\n    #print(\'infile = \',infile)\n    output = subprocess.check_output([\'mdls\',\'-plist\',\'-\', infile])  # mdls is an Apple command-line utility\n    plist = readPlistFromString(output)\n    #print(plist)\n    print_every = 100\n    if (0 == file_index % print_every):\n        print(""pullTags:  File "",file_index,""/"",len(file_list),"": "",infile,sep="""")\n    for key in keys_to_use:\n        #print("" Checking key = "",key)\n        try:\n            tags = plist[key]\n            if tags:                       # guard against blank tags\n                if isinstance(tags, str):\n                    tags = [tags]      # just make it a length-1 list\n                #print(""               key = "",key,"",   tags (list):"")\n                for tag in tags:\n                    tag = re.sub(\'[^a-zA-Z\\d\\ ]|( ){2,}\',\'_\',tag )  # whitelist only certain characters. e.g. ""4/4""->""4_4""\n                    #tag = tag.replace(""/"", ""-"").replace("";"", ""-"").replace(""\\\\"", ""-"").replace("" "", ""_"").replace\n                    #print(""                                                      ["",tag,\']\',sep="""")\n                    if tag:              # guard against blank tags\n                        new_folder = new_main_folder+\'/\'+tag\n                        make_dir(new_folder)\n                        link_name = new_folder+\'/\'+os.path.basename(infile)\n                        make_link(infile, link_name)\n        except:\n            #print(""Key error: File"",infile,""doesn\'t contain key"",key)\n            pass\n    return\n\n\ndef hawleys_way(args):\n    search_dirs = args.dir\n    new_main_folder=\'Samples/\'\n    make_dir(new_main_folder)\n\n    print(""Searching for .caf files in starting directories "",search_dirs)\n    # Rescursively search for .caf files starting in various starting directories\n    file_list = []\n    for search_dir in search_dirs:\n        for filename in glob.iglob(search_dir+\'/**/*.caf\', recursive=True):\n            file_list.append(filename)\n\n    # farm out the pulling of tags to many files simultaneously across all processors\n    file_indices = tuple( range(len(file_list)) )\n    cpu_count = os.cpu_count()\n    if (False):                              # simple single-processor execution for testing\n        for file_index in file_indices:\n            pullTags_one_file(file_list,new_main_folder,file_index)\n    else:\n        pool = Pool(cpu_count)\n        print(""Mapping to"",cpu_count,""processes"")\n        pool.map(partial(pullTags_one_file, file_list, new_main_folder), file_indices)\n    return\n\n\n\ndef bradens_way():\n    # Current working directory\n    CWD = os.getcwd()\n\n    UNKNOWN_FOLDER = ""New Folder""\n\n    # Folders\n    folders = {\n        UNKNOWN_FOLDER: []\n    }\n\n    # get a list of all the names of new folders\n    for relative_path in os.listdir(CWD):\n        full_path = os.path.join(CWD, relative_path)\n\n        # If running from a script, skip self.\n        #if os.path.samefile(full_path, __file__):\n        #  continue\n\n        try:\n            output = subprocess.check_output([\'mdls\',\'-plist\',\'-\', full_path])\n\n            plist = readPlistFromString(output)\n\n            if ((\'kMDItemMusicalInstrumentName\' in plist) or (\'kMDItemMusicalInstrumentCategory\' in plist)\n                or (\'kMDItemMusicalGenre\' in plist) or (\'kMDItemAppleLoopDescriptors\' in plist)):\n\n                tag1 = plist[\'kMDItemMusicalInstrumentName\']\n                tag2 = plist[\'kMDItemMusicalInstrumentCategory\']\n                tag3 = plist[\'kMDItemMusicalGenre\']\n                tag4 = plist[\'kMDItemAppleLoopDescriptors\']\n\n                if tag1 not in folders:\n                        folders[tag1] = []\n\n                if tag2 not in folders:\n                        folders[tag2] = []\n\n                if tag3 not in folders:\n                        folders[tag3] = []\n\n                if tag4 not in folders:\n                        folders[tag4] = []\n\n                new_path = os.path.join(CWD, tag1, relative_path)\n                folders[tag1].append([full_path, new_path])\n\n                new_path = os.path.join(CWD, tag2, relative_path)\n                folders[tag2].append([full_path, new_path])\n\n                new_path = os.path.join(CWD, tag3, relative_path)\n                folders[tag3].append([full_path, new_path])\n\n                new_path = os.path.join(CWD, tag4, relative_path)\n                folders[tag4].append([full_path, new_path])\n\n            else:\n                # Move file to the catch-all folder\n                new_path = os.path.join(CWD, UNKNOWN_FOLDER, relative_path)\n                folders[UNKNOWN_FOLDER].append([full_path, new_path])\n\n        except:\n            print(""Could not process: %s"" % full_path)\n\n    #Create folders and move files\n    for (folder, tuples) in folders.items():\n        folder_path = os.path.join(CWD, folder)\n                #print(folder_path)\n                # Create folder if it does not exist\n        try:\n            os.makedirs(folder_path)\n            print(""Created folder: %s"" % folder_path)\n        except OSError as exception:\n            if exception.errno != errno.EEXIST:\n                raise\n\n        # Move files\n        for t in tuples:\n            try:\n                shutil.copy(t[0],t[1])\n                shutil.copy(t[0],t[2])\n                shutil.copy(t[0],t[3])\n                shutil.copy(t[0],t[4])\n            except:\n                print(""Could not move file: %s"" % t[0])\n    return\n\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Pull metadata tags from Apple Loops .caf files\')\n    parser.add_argument(\'dir\', help=""directory/ies to search in"", nargs=\'*\', default=[\'/Library/Audio\'])\n    args = parser.parse_args()\n    hawleys_way(args)\n'"
utils/resolve_osx_aliases.py,0,"b'#!/usr/bin/env python3\n#\n# Resolve Mac OS X \'aliases\' by finding where they point to\n# Author: Scott H. Hawley\n#\n# Description:\n# Mac OSX aliases are not symbolic links. Trying to read one will probably crash your code.\n# Here a few routines to help. Run these to change the filename before trying to read a file.\n# Intended to be called from within other python code\n#\n# Python port modified from https://hints.macworld.com/article.php?story=20021024064107356\n#\n# Requirements: osascript (AppleScript), platform, subprocess, shlex\n#\n# TODO: - could make it work in parallel when mutliple filenames are given\n#\n# NOTE: By default, this only returns the names of the original source files,\n#       but if you set convert=True, it will also convert aliases to symbolic links.\n#\nimport subprocess, platform, os, shlex\n\n\n# returns true if a file is an OSX alias, false otherwise\ndef isAlias(path, already_checked_os=False):\n    if (not already_checked_os) and (\'Darwin\' != platform.system()):  # already_checked just saves a few microseconds ;-)\n        return False\n    checkpath = os.path.abspath(path)       # osascript needs absolute paths\n    # Next several lines are AppleScript\n    line_1=\'tell application ""Finder""\'\n    line_2=\'set theItem to (POSIX file ""\'+checkpath+\'"") as alias\'\n    line_3=\'if the kind of theItem is ""alias"" then\'\n    line_4=\'   return true\'\n    line_5=\'else\'\n    line_6=\'   return false\'\n    line_7=\'end if\'\n    line_8=\'end tell\'\n    cmd = ""osascript -e \'""+line_1+""\' -e \'""+line_2+""\' -e \'""+line_3+""\' -e \'""+line_4+""\' -e \'""+line_5+""\' -e \'""+line_6+""\' -e \'""+line_7+""\' -e \'""+line_8+""\'""\n    args = shlex.split(cmd)              # shlex splits cmd up appropriately so we can call subprocess.Popen with shell=False (better security)\n    p = subprocess.Popen(args, shell=False, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    retval = p.wait()\n    if (0 == retval):\n        line = p.stdout.readlines()[0]\n        line2 = line.decode(\'UTF-8\').replace(\'\\n\',\'\')\n        if (\'true\' == line2):\n            return True\n        else:\n            return False\n    else:\n        print(\'resolve_osx_alias: Error: subprocess returned non-zero exit code \'+str(retval))\n    return None\n\n\n\ndef resolve_osx_alias(path, already_checked_os=False, convert=False):        # single file/path name\n    if (not already_checked_os) and (\'Darwin\' != platform.system()):  # already_checked just saves a few microseconds ;-)\n        return path\n    checkpath = os.path.abspath(path)       # osascript needs absolute paths\n    # Next several lines are AppleScript\n    line_1=\'tell application ""Finder""\'\n    line_2=\'set theItem to (POSIX file ""\'+checkpath+\'"") as alias\'\n    line_3=\'if the kind of theItem is ""alias"" then\'\n    line_4=\'   get the posix path of (original item of theItem as text)\'\n    line_5=\'else\'\n    line_6=\'return ""\'+checkpath+\'""\'\n    line_7 =\'end if\'\n    line_8 =\'end tell\'\n    cmd = ""osascript -e \'""+line_1+""\' -e \'""+line_2+""\' -e \'""+line_3+""\' -e \'""+line_4+""\' -e \'""+line_5+""\' -e \'""+line_6+""\' -e \'""+line_7+""\' -e \'""+line_8+""\'""\n    args = shlex.split(cmd)              # shlex splits cmd up appropriately so we can call subprocess.Popen with shell=False (better security)\n    p = subprocess.Popen(args, shell=False, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    retval = p.wait()\n    if (0 == retval):\n        line = p.stdout.readlines()[0]\n        source = line.decode(\'UTF-8\').replace(\'\\n\',\'\')\n        if (convert):\n            os.remove(checkpath)\n            os.symlink(source, checkpath)\n    else:\n        print(\'resolve_osx_aliases: Error: subprocess returned non-zero exit code \'+str(retval))\n        source = \'\'\n    return source\n\n\ndef resolve_osx_aliases(filelist, convert=False):  # multiple files\n    #print(""filelist = "",filelist)\n    if (\'Darwin\' != platform.system()):\n        return filelist\n    outlist = []\n    for infile in filelist:\n        source = resolve_osx_alias(infile, already_checked_os=True, convert=convert)\n        if (\'\' != source):\n            outlist.append(source)\n    #print(""outlist = "",outlist)\n    return outlist\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Resolve OSX aliases\')\n    parser.add_argument(\'file\', help=""alias files to resolve"", nargs=\'+\')\n    args = parser.parse_args()\n    outlist = resolve_osx_aliases(args.file)\n    print(""outlist = "",outlist)\n'"
utils/shortCut.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Sun Jan 28 07:41:46 2018\n\n@author: TheRealest\n\nWindows utility for creating new file shortcuts based on data.json file \n""""""\n\nimport json\nimport platform\nimport os\n\nsys = platform.system()\nprint(sys)\n\nif sys == ""Windows"":\n    import winshell\n    from win32com.client import Dispatch\n    \njson_file = input(str(""Enter JSON file path (make sure it is in the same dir): \\n""))\nprint(json_file)\npath_txt = input(""Enter the main path FOOL (make sure it is in the same dir):  \\n"")\nprint(path_txt)\n\nmain_directory = input(""put new folder path here"")\nprint(main_directory)\nwith open(json_file) as json_data:\n\n   file_paths = []\n   for folder, subs, files in os.walk(path_txt):\n       for filename in files:\n           file_paths.append(os.path.abspath(os.path.join(folder, filename)))\n\n   # load JSON file\n   d = json.load(json_data)\n   items = d[""items""]\n   num_items = len(items)\n\n   # hrs, mins, secs = tim.split(\':\')\n   \n   for x in range(num_items):\n       # get old path name for every file to put in symbolic links\n       old_path_name = file_paths[x]\n       print(old_path_name)\n\n       # make new filename for each element: name + id\n       item = items[x]\n       if sys == ""Windows"":\n           old_path_name, tail = old_path_name.split(\'.\')\n           new_path_name = old_path_name + ""_"" + item[""id""] + ""."" + tail\n       else:\n           old_path_name1, tail = old_path_name.split(\'.\')\n           new_path_name = old_path_name1 + ""_"" + item[""id""] + ""."" + tail\n           \n\n       # askes for input and makes new folders(if needed)\n\n       tags = item[""tags""]\n       tag = tags[0]\n       if sys == ""Windows"":\n           new_directory = main_directory + ""\\\\"" + tag\n       else:\n           new_directory = main_directory + ""/"" + tag\n       \n       subfolders = os.listdir(main_directory)\n       if (tag not in subfolders):\n           os.mkdir(new_directory)\n           \n            # create a symbolic link\n       pre_dest = item[""name""] + ""_"" + item[""id""] + tail\n       src = old_path_name\n       if sys == ""Windows"":\n           dst = ""Desktop\\\\"" + pre_dest\n       else:\n           pre_dest = item[""name""] + ""_"" + item[""id""] + ""."" + tail\n           dst = new_directory + ""/"" + pre_dest\n\n       tail_len = len(item[""name""])\n       old_path_name_temp = old_path_name[:-tail_len]\n       \n       os.symlink(src, dst)\n\n       # Creates ShortCuts\n       if sys == ""Windows"":\n           desktop = winshell.desktop()\n           path = os.path.join(new_directory, item[""name""] + ""_"" + item[""id""] + "".lnk"")\n           target = old_path_name + ""."" + tail\n           wDir = new_path_name\n       \n      \n           icon = r""C:\\WINDOWS\\system32\\notepad.exe""\n\n           shell = Dispatch(\'WScript.Shell\')\n           shortcut = shell.CreateShortCut(path)\n           shortcut.Targetpath = target\n           shortcut.WorkingDirectory = wDir\n           shortcut.IconLocation = icon\n           shortcut.save()\n'"
utils/split_audio.py,0,"b'#! /usr/bin/env python\n\'\'\'\nsplit_audio.py\nAuthor: Scott Hawley\n\nSplits an audio file into clips of length ""clip_dur"" where is clip_dur the duration in seconds\nGenerated files get a ""_sN"" appended to their filename (before the extension) where N just \ncounts the clip number\n\nWorks on mono, stereo,...arbitrary numbers of channels\n\nIf the sound file duration is not an integer multiple of clip_dur, then it will\ngenerate the ""last piece"" padded with zeros on the end (so all clips have the same duration)\n\'\'\'\nfrom __future__ import print_function\n\nimport numpy as np\nimport librosa\nimport os\n\ndef fix_last_element(clip_list, intended_length, axis):\n    #intended_length = clip_list[0].shape[axis]\n    last_length = clip_list[-1].shape[axis]\n    num_zeros = intended_length - last_length\n    if (num_zeros > 0):\n        ndims = clip_list[-1].ndim\n        pad_list = []\n        for i in range(ndims):\n            if (axis == i):\n                pad_list.append((0,num_zeros))\n            else:\n                pad_list.append((0,0))\n        clip_list[-1] = np.pad( clip_list[-1], pad_list, mode=\'constant\')\n\n    clips = np.asarray( clip_list )\n    return clips\n\n\n\ndef split_audio(file_list, clip_dur=2, remove_orig=True):\n    for infile in file_list:\n        if os.path.isfile(infile):\n            print(""     Splitting file: "",infile,"" into "",clip_dur,""-second clips... "",end="""",sep="""")\n            signal, sr = librosa.load(infile, sr=None, mono=False)   # don\'t assume sr or mono\n            if (1 == signal.ndim):\n                print(""       this is a mono file.  signal.shape = "",signal.shape)\n            else:\n                print(""       this is a multi-channel file: signal.shape = "",signal.shape)\n            axis = signal.ndim - 1\n            signal_length = signal.shape[axis]\n            stride = clip_dur * sr                             # length of clip in samples\n            print(""stride= "",stride,"", signal_length = "", signal_length )                 \n            indices = np.arange(stride, signal_length,stride)   # where to split\n            clip_list = np.split( signal, indices, axis=axis)       # do the splitting\n            intended_length = stride\n            clips = fix_last_element(clip_list, intended_length, axis) # what to do with last clip\n\n            sections = int( np.ceil( signal.shape[axis] / stride) ) # just to check \n            if( sections != clips.shape[0]):                        # just in case\n                print(""              **** Warning: sections = ""+str(sections)+"", but clips.shape[0] = ""+str(clips.shape[0]) )\n            ndigits = len(str(sections))   # find out # digits needed to print section #s\n            for i in range(sections):\n                clip = clips[i]\n                filename_no_ext = os.path.splitext(infile)[0]\n                ext = os.path.splitext(infile)[1]\n                outfile = filename_no_ext+""_s""+\'{num:{fill}{width}}\'.format(num=i+1, fill=\'0\', width=ndigits)+ext\n                print(""        Saving file"",outfile)\n                librosa.output.write_wav(outfile,clip,sr)\n\n            if remove_orig:\n                os.remove(infile)\n        else:\n            print(""     *** File"",infile,""does not exist.  Skipping."")\n    return\n\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=""Splits file(s) into multiple clips"")\n    parser.add_argument(""-r"", ""--remove"", help=""remove original (long) file(s) after splitting"",\n                    action=""store_true"")\n    parser.add_argument(""clip_dur"", help=""duraction of each clip in seconds"",type=int)\n    parser.add_argument(\'file\', help=""file(s) to split"", nargs=\'+\')   \n    args = parser.parse_args()\n    split_audio(args.file, clip_dur=args.clip_dur, remove_orig=args.remove)\n'"
