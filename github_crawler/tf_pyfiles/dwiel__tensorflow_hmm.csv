file_path,api_count,code
setup.py,0,"b""from setuptools import setup\n\n\nsetup(\n    name='tensorflow_hmm',\n    version='0.2.5',\n    description='Tensorflow and numpy implementations of the HMM viterbi and '\n                'forward/backward algorithms',\n    url='http://github.com/dwiel/tensorflow_hmm',\n    author='Zach Dwiel',\n    author_email='zdwiel@gmail.com',\n    license='Apache',\n    packages=['tensorflow_hmm'],\n    install_requires=[\n        'numpy',\n        'pytest',\n        'tensorflow',\n    ],\n)\n"""
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# tensorflow_hmm documentation build configuration file, created by\n# sphinx-quickstart on Wed Apr 20 16:16:34 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath(\'.\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.viewcode\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n# source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'tensorflow_hmm\'\ncopyright = u\'2016, Zach Dwiel\'\nauthor = u\'Zach Dwiel\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u\'0.1.1\'\n# The full version, including alpha/beta/rc tags.\nrelease = u\'0.1.1\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'_build\']\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   \'da\', \'de\', \'en\', \'es\', \'fi\', \'fr\', \'hu\', \'it\', \'ja\'\n#   \'nl\', \'no\', \'pt\', \'ro\', \'ru\', \'sv\', \'tr\'\n# html_search_language = \'en\'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only \'ja\' uses this config value\n# html_search_options = {\'type\': \'default\'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = \'scorer.js\'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'tensorflow_hmmdoc\'\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'tensorflow_hmm.tex\', u\'tensorflow\\\\_hmm Documentation\',\n     u\'Zach Dwiel\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'tensorflow_hmm\', u\'tensorflow_hmm Documentation\',\n     [author], 1)\n]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'tensorflow_hmm\', u\'tensorflow_hmm Documentation\',\n     author, \'tensorflow_hmm\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n# texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n# texinfo_no_detailmenu = False\n'"
examples/viterbi_wikipedia_example.py,2,"b'""""""\nAn example using both tensorflow and numpy implementations of viterbi\nreplicating example on wikipedia\n""""""\nfrom __future__ import print_function\n\n__author__ = \'Marvin Bertin <marvin.bertin@gmail.com>\'\n\nimport tensorflow as tf\nimport numpy as np\n\n\nfrom tensorflow_hmm import HMMNumpy, HMMTensorflow\n\n\ndef dptable(V, pathScores, states):\n    print("" "".join((""%10d"" % i) for i in range(V.shape[0])))\n    for i, y in enumerate(pathScores.T):\n        print(""%.7s: "" % states[i])\n        print("" "".join(""%.7s"" % (""%f"" % yy) for yy in y))\n\n\ndef main():\n    p0 = np.array([0.6, 0.4])\n\n    emi = np.array([[0.5, 0.1],\n                    [0.4, 0.3],\n                    [0.1, 0.6]])\n\n    trans = np.array([[0.7, 0.3],\n                      [0.4, 0.6]])\n    states = {0: \'Healthy\', 1: \'Fever\'}\n    obs = {0: \'normal\', 1: \'cold\', 2: \'dizzy\'}\n\n    obs_seq = np.array([0, 1, 2])\n\n    print()\n    print(""TensorFlow Example: "")\n\n    tf_model = HMMTensorflow(trans, p0)\n\n    y = emi[obs_seq]\n    tf_s_graph, tf_scores_graph = tf_model.viterbi_decode(y)\n    tf_s = tf.Session().run(tf_s_graph)\n    print(""Most likely States: "", [obs[s] for s in tf_s])\n\n    tf_scores = tf.Session().run(tf_scores_graph)\n    pathScores = np.array(np.exp(tf_scores))\n    dptable(pathScores, pathScores, states)\n\n    print()\n    print(""numpy Example: "")\n    np_model = HMMNumpy(trans, p0)\n\n    y = emi[obs_seq]\n    np_states, np_scores = np_model.viterbi_decode(y)\n    print(""Most likely States: "", [obs[s] for s in np_states])\n    pathScores = np.array(np.exp(np_scores))\n    dptable(pathScores, pathScores, states)\n\nif __name__ == ""__main__"":\n    main()\n'"
tensorflow_hmm/__init__.py,0,"b'from .hmm import HMMNumpy, HMMTensorflow\n'"
tensorflow_hmm/hmm.py,43,"b'import tensorflow as tf\nimport numpy as np\n\n\nclass HMM(object):\n    """"""\n    A class for Hidden Markov Models.\n\n    The model attributes are:\n    - K :: the number of states\n    - P :: the K by K transition matrix (from state i to state j,\n        (i, j) in [1..K])\n    - p0 :: the initial distribution (defaults to starting in state 0)\n    """"""\n\n    def __init__(self, P, p0=None, length=None):\n        self.K = P.shape[0]\n        self.length = length\n\n        if len(P.shape) !=  2:\n            raise ValueError(\'P shape should have length 2. found {}\'.format(len(P.shape)))\n        if P.shape[0] !=  P.shape[1]:\n            raise ValueError(\'P.shape should be square, found {}\'.format(P.shape))\n\n        # make sure probability matrix is normalized\n        P = P / np.sum(P,1)\n\n        self.P = P.astype(dtype=np.float32)\n        self.logP = np.log(self.P)\n\n        if p0 is None:\n            self.p0 = np.ones(self.K)\n            self.p0 /= sum(self.p0)\n        elif len(p0) != self.K:\n            raise ValueError(\n                \'dimensions of p0 {} must match P[0] {}\'.format(\n                    p0.shape, P.shape[0]))\n        else:\n            self.p0 = p0\n        self.logp0 = np.log(self.p0)\n\n\nclass HMMNumpy(HMM):\n\n    def forward_backward(self, y):\n        # set up\n        if y.ndim == 2:\n            y = y[np.newaxis, ...]\n\n        nB, nT = y.shape[:2]\n\n        posterior = np.zeros((nB, nT, self.K))\n        forward = np.zeros((nB, nT + 1, self.K))\n        backward = np.zeros((nB, nT + 1, self.K))\n\n        # forward pass\n        forward[:, 0, :] = 1.0 / self.K\n        for t in range(nT):\n            tmp = np.multiply(\n                np.matmul(forward[:, t, :], self.P),\n                y[:, t]\n            )\n            # normalize\n            forward[:, t + 1, :] = tmp / np.sum(tmp, axis=1)[:, np.newaxis]\n\n        # backward pass\n        backward[:, -1, :] = 1.0 / self.K\n        for t in range(nT, 0, -1):\n            # TODO[marcel]: double check whether y[:,t-1] should be y[:,t]\n            tmp = np.matmul(self.P, (y[:, t - 1] * backward[:, t, :]).T).T\n            # normalize\n            backward[:, t - 1, :] = tmp / np.sum(tmp, axis=1)[:, np.newaxis]\n\n        # remove initial/final probabilities and squeeze for non-batched tests\n        forward = np.squeeze(forward[:, 1:, :])\n        backward = np.squeeze(backward[:, :-1, :])\n\n        # TODO[marcel]: posterior missing initial probabilities\n        # combine and normalize\n        posterior = np.array(forward) * np.array(backward)\n        # [:,None] expands sum to be correct size\n        posterior = posterior / np.sum(posterior, axis=-1)[..., np.newaxis]\n\n        # squeeze for non-batched tests\n        return posterior, forward, backward\n\n    def _viterbi_partial_forward(self, scores):\n        tmpMat = np.zeros((self.K, self.K))\n        for i in range(self.K):\n            for j in range(self.K):\n                tmpMat[i, j] = scores[i] + self.logP[i, j]\n        return tmpMat\n\n    def _viterbi_partial_forward_batched(self, scores):\n        """"""\n        Expects inputs in [B, K] layout\n        """"""\n        # support non-batched version\n        if scores.ndim == 1:\n            scores = scores[np.newaxis, ...]\n\n        nB, K  = scores.shape\n        assert K == self.K, ""Incompatible scores""\n\n        tmpMat = np.zeros((nB, self.K, self.K))\n        for i in range(self.K):\n            for j in range(self.K):\n                tmpMat[:, i, j] = scores[:, i] + self.logP[i, j]\n        return tmpMat\n\n    def viterbi_decode(self, y):\n        nT = y.shape[0]\n\n        pathStates = np.zeros((nT, self.K), dtype=np.int)\n        pathScores = np.zeros((nT, self.K))\n\n        # initialize\n        pathScores[0] = self.logp0 + np.log(y[0])\n\n        for t, yy in enumerate(y[1:]):\n            # propagate forward\n            tmpMat = self._viterbi_partial_forward(pathScores[t])\n            # the inferred state\n            pathStates[t + 1] = np.argmax(tmpMat, 0)\n            pathScores[t + 1] = np.max(tmpMat, 0) + np.log(yy)\n\n        # now backtrack viterbi to find states\n        s = np.zeros(nT, dtype=np.int)\n        s[-1] = np.argmax(pathScores[-1])\n        for t in range(nT - 1, 0, -1):\n            s[t - 1] = pathStates[t, s[t]]\n\n        return s, pathScores\n\n    def viterbi_decode_batched(self, y):\n        """"""\n        Expects inputs in [B, N, K] layout\n        """"""\n        # take care of non-batched version\n        if y.ndim == 2:\n            y = y[np.newaxis, ...]\n\n        nB, nT = y.shape[:2]\n\n        pathStates = np.zeros((nB, nT, self.K), dtype=np.int)\n        pathScores = np.zeros((nB, nT, self.K))\n\n        # initialize\n        pathScores[:, 0] = self.logp0 + np.log(y[:, 0])\n\n        for t in range(0, nT-1):\n            yy = y[:, t+1]\n            # propagate forward\n            tmpMat = self._viterbi_partial_forward_batched(pathScores[:, t])\n            # the inferred state\n            pathStates[:, t + 1] = np.argmax(tmpMat, axis=1)\n            pathScores[:, t + 1] = np.squeeze(np.max(tmpMat, axis=1)) + np.log(yy)\n\n        # now backtrack viterbi to find states\n        s = np.zeros((nB, nT), dtype=np.int)\n        s[:, -1] = np.argmax(pathScores[:, -1], axis=1)\n        for t in range(nT - 1, 0, -1):\n            # s[:, t - 1] = pathStates[:, t][range(nB), s[:, t]]\n            s[:, t - 1] = np.choose(s[:, t], pathStates[:, t].T)\n\n        return s, pathScores\n\n\ndef tf_map(fn, arrays):\n    """"""\n    Apply fn to each of the values in each of the arrays.  Implemented in\n    native python would look like:\n\n        return map(fn, *arrays)\n\n    more explicitly:\n\n        output[i] = fn(arrays[0][i], arrays[1][i], ... arrays[-1][i])\n\n    This function assumes that all arrays have same leading dim.\n    """"""\n    indices = tf.range(tf.shape(arrays[0])[0])\n    out = tf.map_fn(lambda ii: fn(*[array[ii] for array in arrays]), indices, dtype=tf.int64)\n    return out\n\nclass HMMTensorflow(HMM):\n\n    def forward_backward(self, y):\n        """"""\n        runs forward backward algorithm on state probabilities y\n\n        Arguments\n        ---------\n        y : np.array : shape (T, K) where T is number of timesteps and\n            K is the number of states\n\n        Returns\n        -------\n        (posterior, forward, backward)\n        posterior : list of length T of tensorflow graph nodes representing\n            the posterior probability of each state at each time step\n        forward : list of length T of tensorflow graph nodes representing\n            the forward probability of each state at each time step\n        backward : list of length T of tensorflow graph nodes representing\n            the backward probability of each state at each time step\n        """"""\n        y = tf.cast(y, tf.float32)\n\n        if len(y.shape) == 2:\n            y = tf.expand_dims(y, axis=0)\n\n        # set up\n        N = tf.shape(y)[0]\n\n        # y (batch, recurrent, features) -> (recurrent, batch, features)\n        y = tf.transpose(y, (1, 0, 2))\n\n        # forward pass\n        def forward_function(last_forward, yi):\n            tmp = tf.multiply(tf.matmul(last_forward, self.P), yi)\n            return tmp / tf.reduce_sum(tmp, axis=1, keep_dims=True)\n\n        forward = tf.scan(\n            forward_function,\n            y,\n            initializer=tf.ones((N, self.K)) * (1.0 / self.K),\n        )\n\n        # backward pass\n        def backward_function(last_backward, yi):\n            # combine transition matrix with observations\n            combined = tf.multiply(\n                tf.expand_dims(self.P, 0), tf.expand_dims(yi, 1)\n            )\n            tmp = tf.reduce_sum(\n                tf.multiply(combined, tf.expand_dims(last_backward, 1)), axis=2\n            )\n            return tmp / tf.reduce_sum(tmp, axis=1, keep_dims=True)\n\n        backward = tf.scan(\n            backward_function,\n            tf.reverse(y, [0]),\n            initializer=tf.ones((N, self.K)) * (1.0 / self.K),\n        )\n        backward = tf.reverse(backward, [0])\n\n\t\t# combine forward and backward into posterior probabilities\n        # (recurrent, batch, features)\n        posterior = forward * backward\n        posterior = posterior / tf.reduce_sum(posterior, axis=2, keep_dims=True)\n\n        # (recurrent, batch, features) -> (batch, recurrent, features)\n        posterior = tf.transpose(posterior, (1, 0, 2))\n        forward = tf.transpose(forward, (1, 0, 2))\n        backward = tf.transpose(backward, (1, 0, 2))\n\n        return posterior, forward, backward\n\n    def _viterbi_partial_forward(self, scores):\n        # first convert scores into shape [K, 1]\n        # then concatenate K of them into shape [K, K]\n        expanded_scores = tf.concat(\n            [tf.expand_dims(scores, 1)] * self.K, 1\n        )\n        return expanded_scores + self.logP\n\n    def _viterbi_partial_forward_batched(self, scores):\n        """"""\n        Expects inputs in [B, Kl layout\n        """"""\n        # first convert scores into shape [B, K, 1]\n        # then concatenate K of them into shape [B, K, K]\n        expanded_scores = tf.concat(\n            [tf.expand_dims(scores, axis=2)] * self.K, axis=2\n        )\n        return expanded_scores + self.logP\n\n    def viterbi_decode(self, y):\n        """"""\n        Runs viterbi decode on state probabilies y.\n\n        Arguments\n        ---------\n        y : np.array : shape (T, K) where T is number of timesteps and\n            K is the number of states\n\n        Returns\n        -------\n        (s, pathScores)\n        s : list of length T of tensorflow ints : represents the most likely\n            state at each time step.\n        pathScores : list of length T of tensorflow tensor of length K\n            each value at (t, k) is the log likliehood score in state k at\n            time t.  sum(pathScores[t, :]) will not necessary == 1\n        """"""\n        y = np.asarray(y)\n        if len(y.shape) != 2:\n            raise ValueError((\n                \'y should be 2d of shape (nT, {}).  Found {}\'\n            ).format(self.K, y.shape))\n\n        if y.shape[1] != self.K:\n            raise ValueError((\n                \'y has an invalid shape.  first dimension is time and second \'\n                \'is K.  Expected K for this model is {}, found {}.\'\n            ).format(self.K, y.shape[1]))\n\n        nT = y.shape[0]\n\n        # pathStates and pathScores wil be of type tf.Tensor.  They\n        # are lists since tensorflow doesn\'t allow indexing, and the\n        # list and order are only really necessary to build the unrolled\n        # graph.  We never do any computation across all of time at once\n        pathStates = []\n        pathScores = []\n\n        # initialize\n        pathStates.append(None)\n        pathScores.append(self.logp0 + np.log(y[0]))\n\n        for t, yy in enumerate(y[1:]):\n            # propagate forward\n            tmpMat = self._viterbi_partial_forward(pathScores[t])\n\n            # the inferred state\n            pathStates.append(tf.argmax(tmpMat, 0))\n            pathScores.append(tf.reduce_max(tmpMat, 0) + np.log(yy))\n\n        # now backtrack viterbi to find states\n        s = [0] * nT\n        s[-1] = tf.argmax(pathScores[-1], 0)\n        for t in range(nT - 1, 0, -1):\n            s[t - 1] = tf.gather(pathStates[t], s[t])\n\n        return s, tf.stack(pathScores, axis=0)\n\n    def viterbi_decode_batched(self, y, onehot=False):\n        """"""\n        Runs viterbi decode on state probabilies y in batch mode\n\n        Arguments\n        ---------\n        y : np.array : shape (B, T, K) where T is number of timesteps and\n            K is the number of states\n        onehot : boolean : if true, returns a onehot representation of the\n            most likely states, instead of integer indexes of the most likely\n            states.\n\n        Returns\n        -------\n        (s, pathScores)\n        s : list of length T of tensorflow ints : represents the most likely\n            state at each time step.\n        pathScores : list of length T of tensorflow tensor of length K\n            each value at (t, k) is the log likliehood score in state k at\n            time t.  sum(pathScores[t, :]) will not necessary == 1\n        """"""\n        if len(y.shape) == 2:\n            # y = y[np.newaxis, ...]\n            y = tf.expand_dims(y, axis=0)\n\n        if  len(y.shape) != 3:\n            raise ValueError((\n                \'y should be 3d of shape (nB, nT, {}).  Found {}\'\n            ).format(self.K, y.shape))\n\n        nB, nT, nC = y.shape\n\n        if nC != self.K:\n            raise ValueError((\n                \'y has an invalid shape.  first dimension is time and second \'\n                \'is K.  Expected K for this model is {}, found {}.\'\n            ).format(self.K, nC))\n\n        # pathStates and pathScores will be of type tf.Tensor.  They\n        # are lists since tensorflow doesn\'t allow indexing, and the\n        # list and order are only really necessary to build the unrolled\n        # graph.  We never do any computation across all of time at once. The\n        # indexing into these list has the dimension of time.\n        pathStates = []\n        pathScores = []\n\n        # initialize\n        pathStates.append(None)\n        pathScores.append(self.logp0 + tf.log(y[:, 0]))\n\n        for t in range(0, nT-1):\n            yy = tf.squeeze(y[:, t+1])\n            # propagate forward\n            tmpMat = self._viterbi_partial_forward_batched(pathScores[t])\n\n            # the inferred state\n            pathStates.append(tf.argmax(tmpMat, axis=1))\n            pathScores.append(tf.reduce_max(tmpMat, axis=1) + tf.log(yy))\n\n        # now backtrack viterbi to find states\n        s = [None] * nT\n        s[-1] = tf.argmax(pathScores[-1], axis=1)\n        for t in range(nT - 1, 0, -1):\n            s[t - 1] = tf_map(lambda p, i: p[i], [pathStates[t], s[t]])\n\n        s = tf.stack(s, axis=1)\n        pathScores = tf.stack(pathScores, axis=1)\n\n        if onehot:\n            s = tf.one_hot(s, depth=nC)\n\n        return s, pathScores\n'"
tensorflow_hmm/hmm_layer.py,2,"b""from keras.layers import Lambda, Activation\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_hmm import HMMTensorflow\n\n\nclass HMMLayer(Layer):\n    def __init__(self, states, length=None, viterbi_inference=True, **kwargs):\n        # todo: perhaps states should just be inferred by the input shape\n        # todo: create a few utility functions for generating transition matrices\n        self.viterbi_inference = viterbi_inference\n        self.states = states\n        self.P = np.ones((states, states), dtype=np.float32) * (0.01 / (states - 1))\n        for i in range(states):\n            self.P[i, i] = 0.99\n\n        self.hmm = HMMTensorflow(self.P)\n\n        super(HMMLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        if len(input_shape) != 3:\n            raise ValueError('input_shape must be 3, found {}'.format(len(input_shape)))\n\n        super(HMMLayer, self).build(input_shape)  # Be sure to call this somewhere!\n\n    def call(self, x):\n        # todo: only optionally apply sigmoid\n        # todo: apply viterbi during inference\n        x = Activation(K.sigmoid)(x)\n\n        # using K.in_train_phase results in both if and else conditions being\n        # computed, which in this case is very expensive. instead, tf.cond\n        # is used. Even so, if and else conditions must be wrapped in a lambda\n        # to ensure that they are not computed unless that path is chosen.\n        if self.viterbi_inference:\n            # include this in the graph so that keras knows that the learning phase\n            # variable needs to be passed into tensorflows session run.\n            x = K.in_train_phase(x, x)\n\n            return Lambda(lambda x: tf.cond(\n                K.learning_phase(),\n                lambda: self.hmm.forward_backward(x)[0],\n                lambda: self.hmm.viterbi_decode_batched(x, onehot=True)[0],\n            ))(x)\n        else:\n            return Lambda(lambda x: self.hmm.forward_backward(x)[0])(x)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n"""
test/test_hmm.py,11,"b'from __future__ import print_function\n\nimport pytest\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_hmm import HMMNumpy, HMMTensorflow\n\n\n@pytest.fixture\ndef latch_P():\n    P = np.array([[0.5, 0.5], [0.0, 1.0]])\n    # P = np.array([[0.5, 0.5], [0.5, 0.5]])\n    # P = np.array([[0.5, 0.5], [0.0000000001, 0.9999999999]])\n    # P = np.array([[0.5, 0.5], [1e-50, 1 - 1e-50]])\n\n    for i in range(2):\n        for j in range(2):\n            print(\'from\', i, \'to\', j, P[i, j])\n    return P\n\n\n@pytest.fixture\ndef hmm_latch(latch_P):\n    return HMMNumpy(latch_P)\n\n\n@pytest.fixture\ndef fair_P():\n    return np.array([[0.5, 0.5], [0.5, 0.5]])\n\n\n@pytest.fixture\ndef hmm_fair(fair_P):\n    return HMMNumpy(fair_P)\n\n\n@pytest.fixture\ndef hmm_tf_fair(fair_P):\n    return HMMTensorflow(fair_P)\n\n\n@pytest.fixture\ndef hmm_tf_latch(latch_P):\n    return HMMTensorflow(latch_P)\n\n\ndef lik(y):\n    """"""\n\n    given 1d vector of likliehoods length N, return matrix with\n    shape (N, 2) where (N, 0) is 1 - y and (N, 1) is y.\n\n    given a 2d array of likelihood sequences of size [N, B] where B is the batch\n    size, return [B, N, 2] where out[B, N, 0] + out[B, N, 1] = 1\n\n    This makes it easy to convert a time series of probabilities\n    into 2 states, off/on, for a simple HMM.\n    """"""\n\n    liklihood = np.array([y, y], float).T\n    liklihood[..., 0] = 1 - liklihood[..., 0]\n    return liklihood\n\ndef test_tf_hmm_invalid_P_shape():\n    with pytest.raises(ValueError):\n        HMMTensorflow(np.ones((1, 2)))\n\ndef test_tf_hmm_invalid_P_dimensions():\n    with pytest.raises(ValueError):\n        HMMTensorflow(np.ones((1,)))\n\ndef test_hmm_tf_fair_forward_backward(hmm_tf_fair, hmm_fair):\n    y = lik(np.array([0, 0, 1, 1]))\n\n    np_posterior, _, _ = hmm_fair.forward_backward(y)\n    print(\'tf\')\n    g_posterior, _, _ = hmm_tf_fair.forward_backward(y)\n    tf_posterior = np.concatenate(tf.Session().run(g_posterior))\n\n    print(\'np_posterior\', np_posterior)\n    print(\'tf_posterior\', tf_posterior)\n    assert np.isclose(np_posterior, tf_posterior).all()\n\n\ndef test_hmm_tf_fair_forward_backward_multiple_batch(hmm_tf_fair, hmm_fair):\n    y = lik(np.array([0, 0, 1, 1]))\n    y = np.stack([y] * 3)\n\n    np_posterior, _, _ = hmm_fair.forward_backward(y)\n    print(\'tf\')\n    g_posterior, _, _ = hmm_tf_fair.forward_backward(y)\n    tf_posterior = tf.Session().run(g_posterior)\n\n    print(\'np_posterior\', np_posterior)\n    print(\'tf_posterior\', tf_posterior)\n    assert np.isclose(np_posterior, tf_posterior).all()\n\n\ndef test_hmm_tf_latch_forward_backward_multiple_batch(hmm_tf_latch, hmm_latch):\n    y = lik(np.array([0, 0, 1, 1]))\n    y = np.stack([y] * 3)\n\n    np_posterior, np_forward, np_backward = hmm_latch.forward_backward(y)\n    print(\'tf\')\n    g_posterior, g_forward, g_backward = hmm_tf_latch.forward_backward(y)\n    tf_posterior = tf.Session().run(g_posterior)\n    tf_forward = tf.Session().run(g_forward)\n    tf_backward = tf.Session().run(g_backward)\n\n    assert np.isclose(np_forward, tf_forward).all()\n    print(\'np_backward\', np_backward)\n    print(\'tf_backward\', tf_backward)\n    assert np.isclose(np_backward, tf_backward).all()\n    print(\'np_posterior\', np_posterior)\n    print(\'tf_posterior\', tf_posterior)\n    assert np.isclose(np_posterior, tf_posterior).all()\n\ndef test_lik():\n    yin = np.array([0, 0.25, 0.5, 0.75, 1])\n    y = lik(yin)\n\n    assert np.all(y == np.array([\n        [1.00, 0.00],\n        [0.75, 0.25],\n        [0.50, 0.50],\n        [0.25, 0.75],\n        [0.00, 1.00],\n    ]))\n\n\ndef test_hmm_fair_forward_backward(hmm_fair):\n    y = lik(np.array([0, 0, 1, 1]))\n\n    posterior, f, b = hmm_fair.forward_backward(y)\n\n    # if P is filled with 0.5, the only thing that matters is the emission\n    # liklihood.  assert that the posterior is = the liklihood of y\n    for i, yi in enumerate(y):\n        liklihood = yi / np.sum(yi)\n        assert np.isclose(posterior[i, :], liklihood).all()\n\n    # assert that posterior for any given t sums to 1\n    assert np.isclose(np.sum(posterior, 1), 1).all()\n\n\ndef test_hmm_latch_two_step_no_noise(hmm_latch):\n    for i in range(2):\n        for j in range(2):\n            y = [i, i, j, j]\n            # y = [i, j]\n\n            if i == 1 and j == 0:\n                continue\n\n            print(\'*\'*80)\n            print(y)\n            states, scores = hmm_latch.viterbi_decode(lik(y))\n\n            assert all(states == y)\n\n\ndef test_hmm_tf_partial_forward(hmm_tf_latch, hmm_latch):\n    scoress = [\n        np.log(np.array([0, 1])),\n        np.log(np.array([1, 0])),\n        np.log(np.array([0.25, 0.75])),\n        np.log(np.array([0.5, 0.5])),\n    ]\n\n    for scores in scoress:\n        tf_ret = tf.Session().run(\n            hmm_tf_latch._viterbi_partial_forward(scores)\n        )\n        np_ret = hmm_latch._viterbi_partial_forward(scores)\n\n        assert (tf_ret == np_ret).all()\n\n\ndef test_hmm_tf_partial_forward_batched(hmm_tf_latch, hmm_latch):\n    scoress = [\n        np.log(np.array([0, 1])),\n        np.log(np.array([1, 0])),\n        np.log(np.array([0.25, 0.75])),\n        np.log(np.array([0.5, 0.5])),\n    ]\n\n    scores_batch = np.asarray(scoress)\n\n    np_res = hmm_latch._viterbi_partial_forward_batched(scores_batch)\n    tf_res = tf.Session().run(\n        hmm_tf_latch._viterbi_partial_forward_batched(scores_batch)\n    )\n\n    assert (tf_res == np_res).all()\n\n\ndef test_hmm_partial_forward_batched(hmm_latch):\n    scoress = [\n        np.log(np.array([0, 1])),\n        np.log(np.array([1, 0])),\n        np.log(np.array([0.25, 0.75])),\n        np.log(np.array([0.5, 0.5])),\n    ]\n\n    scores_batch = np.array(scoress)\n\n    res = [hmm_latch._viterbi_partial_forward(scores) for scores in scoress]\n    res_batched = hmm_latch._viterbi_partial_forward_batched(scores_batch)\n\n    assert np.all(np.asarray(res) == res_batched)\n\n\ndef test_hmm_tf_viterbi_decode(hmm_tf_latch, hmm_latch):\n    ys = [\n        lik(np.array([0, 0])),\n        lik(np.array([1, 1])),\n        lik(np.array([0, 1])),\n        lik(np.array([0, 0.25, 0.5, 0.75, 1])),\n    ]\n\n    for y in ys:\n        tf_s_graph, tf_scores_graph = hmm_tf_latch.viterbi_decode(y)\n        tf_s, tf_scores = tf.Session().run([tf_s_graph, tf_scores_graph])\n\n        np_s, np_scores = hmm_latch.viterbi_decode(y)\n\n        assert (tf_s == np_s).all()\n        assert (tf_scores == np_scores).all()\n\n\ndef test_hmm_viterbi_decode_batched(hmm_latch):\n    ys_T2 = [\n        lik(np.array([0, 0])),\n        lik(np.array([0, 1])),\n        lik(np.array([1, 1])),\n    ]\n    ys_T5 = [\n        lik([0, 0.25, 0.5, 0.75, 1]),\n        lik([0, 0.65, 0.5, 0.95, .1]),\n    ]\n\n    ys_T2_batch = np.asarray(ys_T2)\n    ys_T5_batch = np.asarray(ys_T5)\n\n    res = [hmm_latch.viterbi_decode(y) for y in ys_T2]\n    res_s, res_scores = zip(*res)\n    res_s_batch, res_scores_batch = hmm_latch.viterbi_decode_batched(ys_T2_batch)\n    assert np.all(np.asarray(res_s) == res_s_batch)\n    assert np.all(np.asarray(res_scores) == res_scores_batch)\n\n    res = [hmm_latch.viterbi_decode(y) for y in ys_T5]\n    res_s, res_scores = zip(*res)\n    res_s_batch, res_scores_batch = hmm_latch.viterbi_decode_batched(ys_T5_batch)\n    assert np.all(np.asarray(res_s) == res_s_batch)\n    assert np.all(np.asarray(res_scores) == res_scores_batch)\n\n\ndef test_hmm_tf_viterbi_decode_batched(hmm_tf_latch, hmm_latch):\n    ys_T2_batch = np.asarray([\n        lik(np.array([0, 0])),\n        lik(np.array([0, 1])),\n        lik(np.array([1, 1])),\n    ], dtype=np.float32)\n\n    ys_T5_batch = np.asarray([\n        lik([0, 0.25, 0.5, 0.75, 1]),\n        lik([0, 0.65, 0.5, 0.95, .1]),\n        lik([0, 0.25, 0.5, 0.75, 1]),\n    ], dtype=np.float32)\n\n    for y in (ys_T5_batch, ys_T2_batch):\n        np_res_s, np_res_scores = hmm_latch.viterbi_decode_batched(y)\n\n        y_variable = tf.placeholder(tf.float32, shape=(None, y.shape[1], y.shape[2]))\n        tf_s_graph, tf_scores_graph = hmm_tf_latch.viterbi_decode_batched(y_variable)\n        init_op = tf.global_variables_initializer()\n        with tf.Session() as session:\n            session.run(init_op)\n\n            tf_s = session.run(tf_s_graph, {y_variable: y})\n            tf_scores = session.run(tf_scores_graph, {y_variable: y})\n\n        np.testing.assert_allclose(tf_s, np_res_s)\n        np.testing.assert_allclose(tf_scores, np_res_scores)\n\n\ndef test_hmm_tf_viterbi_decode_wrong_shape(hmm_tf_latch, hmm_latch):\n    with pytest.raises(ValueError):\n        hmm_tf_latch.viterbi_decode([0, 1, 1, 0])\n'"
