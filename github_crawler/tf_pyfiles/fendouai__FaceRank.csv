file_path,api_count,code
find_faces_in_picture.py,0,"b'from PIL import Image\nimport face_recognition\nimport os\nprint(""h"")\ndef find_and_save_face(web_file,face_file):\n    # Load the jpg file into a numpy array\n    image = face_recognition.load_image_file(web_file)\n    print(image.dtype)\n    # Find all the faces in the image\n    face_locations = face_recognition.face_locations(image)\n\n    print(""I found {} face(s) in this photograph."".format(len(face_locations)))\n\n    for face_location in face_locations:\n\n        # Print the location of each face in this image\n        top, right, bottom, left = face_location\n        print(""A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}"".format(top, left, bottom, right))\n\n        # You can access the actual face itself like this:\n        face_image = image[top:bottom, left:right]\n        pil_image = Image.fromarray(face_image)\n        pil_image.save(face_file)\nprint(""h"")\nlist = os.listdir(""web_image/"")\nprint(list)\n\nfor image in list:\n    id_tag = image.find(""."")\n    name=image[0:id_tag]\n    print(name)\n\n    web_file = ""./web_image/"" +image\n    face_file=""./face_image/""+name+"".jpg""\n\n    im=Image.open(""./web_image/""+image)\n    try:\n        find_and_save_face(web_file, face_file)\n    except:\n        print(""fail"")\n'"
resize_image.py,0,"b'from PIL import Image\nimport os\n\nlist = os.listdir(""./face_image"")\nprint(list)\n\nfor image in list:\n    id_tag = image.find(""."")\n    name=image[0:id_tag]\n    print(name)\n\n    im=Image.open(""./face_image/""+image)\n    out = im.resize((128, 128))\n    #out.show()\n    out.save(""./resize_image/""+name+"".jpg"")\n\n'"
run_model.py,29,"b'\'\'\'\nA Convolutional Network implementation example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom PIL import Image\nimport numpy\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 3000\nbatch_size = 10\ndisplay_step = 2\n\n# Network Parameters\nn_input = 128*128 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [None, 128, 128, 3])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n\n# Create some wrappers for simplicity\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\'SAME\')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\n\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding=\'SAME\')\n\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # Reshape input picture\n    x = tf.reshape(x, shape=[-1, 128, 128, 3])\n\n    # Convolution Layer\n    conv1 = conv2d(x, weights[\'wc1\'], biases[\'bc1\'])\n    print(conv1.shape)\n    # Max Pooling (down-sampling)\n    conv1 = maxpool2d(conv1, k=2)\n    print(conv1.shape)\n    # Convolution Layer\n    conv2 = conv2d(conv1, weights[\'wc2\'], biases[\'bc2\'])\n    print(conv2.shape)\n    # Max Pooling (down-sampling)\n    conv2 = maxpool2d(conv2, k=2)\n    print(conv2.shape)\n    # Fully connected layer\n    # Reshape conv2 output to fit fully connected layer input\n    fc1 = tf.reshape(conv2, [-1, weights[\'wd1\'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weights[\'wd1\']), biases[\'bd1\'])\n    fc1 = tf.nn.relu(fc1)\n    # Apply Dropout\n    fc1 = tf.nn.dropout(fc1, dropout)\n\n    # Output, class prediction\n    out = tf.add(tf.matmul(fc1, weights[\'out\']), biases[\'out\'])\n    return out\n\n# Store layers weight & bias\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    \'wc1\': tf.Variable(tf.random_normal([5, 5, 3, 24])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    \'wc2\': tf.Variable(tf.random_normal([5, 5, 24, 96])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    \'wd1\': tf.Variable(tf.random_normal([32*32*96, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    \'out\': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    \'bc1\': tf.Variable(tf.random_normal([24])),\n    \'bc2\': tf.Variable(tf.random_normal([96])),\n    \'bd1\': tf.Variable(tf.random_normal([1024])),\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n# Construct model\npred = conv_net(x, weights, biases, keep_prob)\npred_result=tf.argmax(pred, 1)\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\nsaver=tf.train.Saver()\n\n# Launch the graph\nwith tf.Session() as sess:\n    saver.restore(sess, ""./model/model.ckpt"")\n    step = 1\n    # Keep training until reach max iterations\n    list = os.listdir(""./test_resize/"")\n    print(list)\n    print(len(list))\n\n    for batch_id in range(0, 2):\n        batch = list[batch_id * 10:batch_id * 10 + 10]\n        batch_xs = []\n        batch_ys = []\n        for image in batch:\n            id_tag = image.find(""-"")\n            score = image[0:id_tag]\n            # print(score)\n            img = Image.open(""./test_resize/"" + image)\n            img_ndarray = numpy.asarray(img, dtype=\'float32\')\n            img_ndarray = numpy.reshape(img_ndarray, [128, 128, 3])\n            # print(img_ndarray.shape)\n            batch_x = img_ndarray\n            batch_xs.append(batch_x)\n\n        # print(batch_ys)\n        batch_xs = numpy.asarray(batch_xs)\n        print(batch_xs.shape)\n\n        # Run optimization op (backprop)\n        pred_result_test=sess.run(pred_result, feed_dict={x: batch_xs,keep_prob: 1.})\n        print(pred_result_test)\n    print(""Test Finished!"")\n    saver.save(sess,""./model/model.ckpt"")'"
stack_data.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport numpy\nfrom PIL import Image\nimport os\n\nlist = os.listdir(""./resize_image/"")\nprint(list)\nprint(len(list))\nfor batch_id in range(1, 10):\n\tbatch = list[batch_id * 10:batch_id * 10 + 10]\n\tbatch_xs=[]\n\tbatch_ys=[]\n\tfor image in batch:\n\t\tid_tag = image.find(""-"")\n\t\tscore = image[0:id_tag]\n\t\t# print(score)\n\t\timg = Image.open(""./resize_image/"" + image)\n\t\timg_ndarray = numpy.asarray(img, dtype=\'float32\')\n\t\timg_ndarray = numpy.reshape(img_ndarray, [128, 128, 3])\n\t\t# print(img_ndarray.shape)\n\t\tbatch_x = img_ndarray\n\t\tbatch_xs.append(batch_x)\n\t\t#print(batch_xs)\n\t\tbatch_y = numpy.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\t\t# print(type(score))\n\t\tbatch_y[int(score) - 1] = 1\n\t\t# print(batch_y)\n\t\tbatch_y = numpy.reshape(batch_y, [10,])\n\t\tbatch_ys.append(batch_y)\n\t\t#print(batch_ys)\n\tbatch_xs=numpy.asarray(batch_xs)\n\tprint(batch_xs.shape)\n\tbatch_ys = numpy.asarray(batch_ys)\n\tprint(batch_ys.shape)'"
t_find_faces_in_picture.py,0,"b'from PIL import Image\nimport face_recognition\nimport os\n\ndef find_and_save_face(web_file,face_file):\n    # Load the jpg file into a numpy array\n    image = face_recognition.load_image_file(web_file)\n    print(image.dtype)\n    # Find all the faces in the image\n    face_locations = face_recognition.face_locations(image)\n\n    print(""I found {} face(s) in this photograph."".format(len(face_locations)))\n\n    for face_location in face_locations:\n\n        # Print the location of each face in this image\n        top, right, bottom, left = face_location\n        print(""A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}"".format(top, left, bottom, right))\n\n        # You can access the actual face itself like this:\n        face_image = image[top:bottom, left:right]\n        pil_image = Image.fromarray(face_image)\n        pil_image.save(face_file)\n\n\nlist = os.listdir(""./test_web/"")\nprint(list)\n\nfor image in list:\n    id_tag = image.find(""."")\n    name=image[0:id_tag]\n    print(name)\n\n    web_file = ""./test_web/"" +image\n    face_file=""./test_face/""+name+"".jpg""\n    try:\n        find_and_save_face(web_file, face_file)\n    except:\n        print(""fail"")\n\n'"
t_resize_image.py,0,"b'from PIL import Image\nimport os\n\nlist = os.listdir(""./test_face"")\nprint(list)\n\nfor image in list:\n    name_len=len(image)\n    name=image[0:name_len-3]\n    print(name)\n    im=Image.open(""./test_face/""+image)\n    out = im.resize((128, 128))\n    #out.show()\n    out.save(""./test_resize/""+name+""jpg"")\n\n'"
train_model.py,28,"b'\'\'\'\nA Convolutional Network implementation example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom PIL import Image\nimport numpy\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 3000\nbatch_size = 10\ndisplay_step = 3\n\n# Network Parameters\nn_input = 128*128 # MNIST data input (img shape: 128*128 )\nn_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [None, 128, 128, 3])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n\n# Create some wrappers for simplicity\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\'SAME\')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\n\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding=\'SAME\')\n\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # Reshape input picture\n    x = tf.reshape(x, shape=[-1, 128, 128, 3])\n\n    # Convolution Layer\n    conv1 = conv2d(x, weights[\'wc1\'], biases[\'bc1\'])\n    print(conv1.shape)\n    # Max Pooling (down-sampling)\n    conv1 = maxpool2d(conv1, k=2)\n    print(conv1.shape)\n    # Convolution Layer\n    conv2 = conv2d(conv1, weights[\'wc2\'], biases[\'bc2\'])\n    print(conv2.shape)\n    # Max Pooling (down-sampling)\n    conv2 = maxpool2d(conv2, k=2)\n    print(conv2.shape)\n    # Fully connected layer\n    # Reshape conv2 output to fit fully connected layer input\n    fc1 = tf.reshape(conv2, [-1, weights[\'wd1\'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weights[\'wd1\']), biases[\'bd1\'])\n    fc1 = tf.nn.relu(fc1)\n    # Apply Dropout\n    fc1 = tf.nn.dropout(fc1, dropout)\n\n    # Output, class prediction\n    out = tf.add(tf.matmul(fc1, weights[\'out\']), biases[\'out\'])\n    return out\n\n# Store layers weight & bias\nweights = {\n    # 5x5 conv, 3 input, 24 outputs\n    \'wc1\': tf.Variable(tf.random_normal([5, 5, 3, 24])),\n    # 5x5 conv, 24 inputs, 96 outputs\n    \'wc2\': tf.Variable(tf.random_normal([5, 5, 24, 96])),\n    # fully connected, 32*32*96 inputs, 1024 outputs\n    \'wd1\': tf.Variable(tf.random_normal([32*32*96, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    \'out\': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    \'bc1\': tf.Variable(tf.random_normal([24])),\n    \'bc2\': tf.Variable(tf.random_normal([96])),\n    \'bd1\': tf.Variable(tf.random_normal([1024])),\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n# Construct model\npred = conv_net(x, weights, biases, keep_prob)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\nsaver=tf.train.Saver()\n\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n    # Keep training until reach max iterations\n    list = os.listdir(""./resize_image/"")\n    print(list)\n    print(len(list))\n    count=0\n    while count<10:\n        count = count+1\n        print(""count:"",count)\n        for batch_id in range(0, 12):\n            batch = list[batch_id * 10:batch_id * 10 + 10]\n            batch_xs = []\n            batch_ys = []\n            for image in batch:\n                id_tag = image.find(""-"")\n                score = image[0:id_tag]\n                # print(score)\n                img = Image.open(""./resize_image/"" + image)\n                img_ndarray = numpy.asarray(img, dtype=\'float32\')\n                img_ndarray = numpy.reshape(img_ndarray, [128, 128, 3])\n                # print(img_ndarray.shape)\n                batch_x = img_ndarray\n                batch_xs.append(batch_x)\n                # print(batch_xs)\n                batch_y = numpy.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n                # print(type(score))\n                batch_y[int(score) - 1] = 1\n                # print(batch_y)\n                batch_y = numpy.reshape(batch_y, [10, ])\n                batch_ys.append(batch_y)\n            # print(batch_ys)\n            batch_xs = numpy.asarray(batch_xs)\n            print(batch_xs.shape)\n            batch_ys = numpy.asarray(batch_ys)\n            print(batch_ys.shape)\n\n            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys,\n                                           keep_prob: dropout})\n            if step % display_step == 0:\n                # Calculate batch loss and accuracy\n                loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_xs,\n                                                                  y: batch_ys,\n                                                                  keep_prob: 1.})\n                print(""Iter "" + str(step*batch_size) + "", Minibatch Loss= "" + \\\n                      ""{:.6f}"".format(loss) + "", Training Accuracy= "" + \\\n                      ""{:.5f}"".format(acc))\n            step += 1\n    print(""Optimization Finished!"")\n    saver.save(sess,""./model/model.ckpt"")\n\n'"
FaceRank_with_keras/faceRank_with_keras.py,0,"b'# -*- coding: utf-8 -*-\r\n""""""\r\n@Time    : 2017/8/1 13:37\r\n@Author  : hadxu\r\n""""""\r\n\r\nfrom keras.models import Sequential\r\nfrom keras.layers.core import Dense, Dropout, Flatten, Activation\r\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\r\nfrom keras.preprocessing.image import load_img, img_to_array\r\nfrom keras.utils import np_utils\r\nimport os\r\nimport numpy as np\r\n\r\n\r\ndef load_dataset(filedir):\r\n    """"""\r\n    \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\r\n    :param filedir:\r\n    :return:\r\n    """"""\r\n    image_data_list = []\r\n    label = []\r\n    train_image_list = os.listdir(filedir + \'/train\')\r\n    for img in train_image_list:\r\n        url = os.path.join(filedir + \'/train/\' + img)\r\n        image = load_img(url, target_size=(128, 128))\r\n        image_data_list.append(img_to_array(image))\r\n        label.append(img.split(\'-\')[0])\r\n    img_data = np.array(image_data_list)\r\n    img_data = img_data.astype(\'float32\')\r\n    img_data /= 255\r\n    return img_data, label\r\n\r\n\r\ndef make_network():\r\n    model = Sequential()\r\n    model.add(Conv2D(32, (3, 3), padding=\'same\', input_shape=(128, 128, 3)))\r\n    model.add(Activation(\'relu\'))\r\n    model.add(Conv2D(32, (3, 3)))\r\n    model.add(Activation(\'relu\'))\r\n    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n    model.add(Dropout(0.5))\r\n\r\n    model.add(Flatten())\r\n    model.add(Dense(128))\r\n    model.add(Activation(\'relu\'))\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(11))\r\n    model.add(Activation(\'softmax\'))\r\n\r\n    return model\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    train_x, train_y = load_dataset(\'data\')\r\n    train_y = np_utils.to_categorical(train_y)\r\n    model = make_network()\r\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adadelta\', metrics=[\'accuracy\'])\r\n    hist = model.fit(train_x, train_y, batch_size=32, epochs=200, verbose=1)\r\n'"
