file_path,api_count,code
src/EvalNet.py,17,"b'import tensorflow.contrib.layers as layers\nfrom collections import namedtuple\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.contrib import slim\nimport poly_utils as polyutils\n\nInputs = namedtuple(""Inputs"",\n                    [""cnn_feats"", ""pred_polys"", ""predicted_mask"", ""ious"", ""hidd1"", ""hidd2"", ""cells_1"", ""cells_2"",\n                     ""pred_mask_imgs""])\n\n\nclass EvalNet(object):\n    def __init__(self, batch_size, max_poly_len=71):\n        self.seq_len = max_poly_len\n        self.batch_size = batch_size\n        self._ph = self._define_phs()\n        self.cost = None\n        self.predicted_ious = None\n        # -\n        self.name = ""EvalNet""\n        self.is_training = False\n        self._zero_batch = np.zeros([self.batch_size, 1])\n        self._first_pass = True\n\n    def _define_phs(self):\n\n        cnn_feats = tf.placeholder(tf.float32, shape=[self.batch_size, 28, 28, 128], name=""cnn_feats"")\n        pred_mask_imgs = tf.placeholder(tf.float32, shape=[self.batch_size, 28, 28, 2], name=""pred_mask_imgs"")\n\n        # --\n        pred_polys = tf.placeholder(tf.float32, shape=[self.batch_size, self.seq_len, 2],\n                                    name=""pred_polys"")\n        predicted_mask = tf.placeholder(tf.float32, shape=[self.batch_size, self.seq_len],\n                                        name=""predicted_mask"")\n        # ---\n        h1 = tf.placeholder(tf.float32, shape=[self.batch_size, self.seq_len, 28, 28, 64], name=""hidden1"")\n        cells_1 = tf.placeholder(tf.float32, shape=[self.batch_size, 1, 28, 28, 64],\n                                 name=""cell_state_hidden1"")\n        h2 = tf.placeholder(tf.float32, shape=[self.batch_size, self.seq_len, 28, 28, 16], name=""hidden2"")\n        cells_2 = tf.placeholder(tf.float32, shape=[self.batch_size, 1, 28, 28, 16],\n                                 name=""cell_state_hidden2"")\n\n        ious = tf.placeholder(tf.float32, shape=[self.batch_size, 1], name=""ious"")\n        return Inputs(cnn_feats, pred_polys, predicted_mask, ious, h1, h2, cells_1, cells_2, pred_mask_imgs)\n\n    def training(self):\n        raise NotImplementedError()\n\n    def draw_mask(self, img_h, img_w, pred_poly, pred_mask):\n        batch_size = pred_poly.shape[0]\n\n        pred_poly_lens = np.sum(pred_mask, axis=1)\n\n        assert pred_poly_lens.shape[0] == batch_size == self.batch_size, \'%s,%s,%s\' % (\n            str(pred_poly_lens.shape[0]), str(batch_size), str(self.batch_size))\n\n        masks_imgs = []\n        for i in range(batch_size):\n            # Cleaning the polys\n            p_poly = pred_poly[i][:pred_poly_lens[i], :]\n\n            # Printing the mask\n            # if self.draw_perimeter is False:\n            try:\n                mask1 = np.zeros((img_h, img_w))\n                mask1 = polyutils.draw_poly(mask1, p_poly.astype(np.int))\n                mask1 = np.reshape(mask1, [img_h, img_w, 1])\n                # else:\n                mask = polyutils.polygon_perimeter(p_poly.astype(np.int), img_side=28)\n                mask = np.reshape(mask, [img_h, img_w, 1])\n            except:\n                import ipdb;\n                ipdb.set_trace()\n\n            mask = np.concatenate((mask, mask1), axis=2)\n\n            masks_imgs.append(mask)\n        masks_imgs = np.array(masks_imgs, dtype=np.float32)\n        return np.reshape(masks_imgs, [self.batch_size, img_h, img_w, 2])\n\n    def _feed_dict(self, train_batch, is_training=True):\n\n        pred_polys = train_batch[\'raw_polys\'] * np.expand_dims(train_batch[\'masks\'], axis=2)  # (seq,batch,2)\n        pred_polys = np.transpose(pred_polys, [1, 0, 2])  # (batch,seq,2)\n\n        pred_mask = np.transpose(train_batch[\'masks\'], [1, 0])  # (batch_size,seq_len)\n        cnn_feats = train_batch[\'cnn_feats\']  # (batch_size, 28, 28, 128)\n\n        cells_1 = np.stack([np.split(train_batch[\'hiddens_list\'][-1][0], 2, axis=3)[0]], axis=1)\n\n        cells_2 = np.stack([np.split(train_batch[\'hiddens_list\'][-1][1], 2, axis=3)[0]], axis=1)\n\n        pred_mask_imgs = self.draw_mask(28, 28, pred_polys, pred_mask)\n\n        if is_training:\n            raise NotImplementedError()\n\n        r = {\n            self._ph.cells_1: cells_1,\n            self._ph.cells_2: cells_2,\n            self._ph.pred_mask_imgs: pred_mask_imgs,\n            self._ph.cnn_feats: cnn_feats,\n            self._ph.predicted_mask: pred_mask,\n            self._ph.pred_polys: pred_polys,\n            self._ph.ious: self._zero_batch\n        }\n\n        return r\n\n    def do_train(self, sess, train_batch, cost_op, backpass_op, train_writer, log, batch_idx):\n        """"""\n        Perform a training iteration.l\n        """"""\n        raise NotImplementedError()\n\n    def build_graph(self):\n        self._build_model()\n        return self.predicted_ious\n\n    def _myForwardPass(self):\n        cnn_feats = self._ph.cnn_feats\n        pred_polys = self._ph.pred_polys\n        pred_mask_imgs = self._ph.pred_mask_imgs\n        last_cell_state_1 = self._ph.cells_1[:, -1, :, :, :]\n        last_cell_state_2 = self._ph.cells_2[:, -1, :, :, :]\n        weight_decay = 0.00001\n\n        predicted_history = tf.zeros(shape=(self.batch_size, 28, 28, 1))\n\n        # Drawing the canvas\n        for i in range(self.seq_len):\n            pred_polys_t = pred_polys[:, i]  # batch x\n            indices = tf.concat(\n                [tf.reshape(tf.range(0, self.batch_size), (self.batch_size, 1)), tf.cast(pred_polys_t, tf.int32)],\n                axis=1)\n            updates = tf.ones(shape=self.batch_size)\n            pred_polys_t = tf.scatter_nd(indices, updates, shape=(self.batch_size, 28, 28))\n            predicted_history = predicted_history + tf.expand_dims(pred_polys_t, axis=-1)\n\n        xt = tf.concat([cnn_feats, predicted_history, pred_mask_imgs, last_cell_state_1, last_cell_state_2],\n                       axis=3)\n\n        with slim.arg_scope([slim.conv2d], kernel_size=[3, 3], stride=1,\n                            weights_regularizer=slim.l2_regularizer(weight_decay),\n                            activation_fn=tf.nn.relu,\n                            normalizer_fn=slim.batch_norm,\n                            normalizer_params={""is_training"": self.is_training, ""decay"": 0.99, ""center"": True,\n                                               ""scale"": True},\n                            weights_initializer=layers.variance_scaling_initializer(\n                                factor=2.0, mode=\'FAN_IN\',\n                                uniform=False)\n                            ):\n            self._conv1 = slim.conv2d(xt, scope=""conv1"", num_outputs=16)\n            self._conv2 = slim.conv2d(self._conv1, scope=""conv2"", num_outputs=1)\n\n        output = layers.fully_connected(slim.flatten(self._conv2), 1, weights_regularizer=layers.l2_regularizer(1e-5),\n                                        scope=""FC"")\n        return output\n\n    def _build_model(self):\n        prediction = self._myForwardPass()\n\n        self.predicted_ious = prediction\n        return self.predicted_ious\n\n    def do_test(self, sess, instance, *_):\n        output = sess.run(\n            self.predicted_ious,\n            feed_dict=self._feed_dict(instance, is_training=False)\n        )\n\n        return output\n'"
src/GGNNPolyModel.py,2,"b'import tensorflow as tf\nimport utils\nimport numpy as np\n\n\nclass GGNNPolygonModel(object):\n    """"""Class to load GGNNPolygonModel and run inference.""""""\n\n    # Tensors names to gather from the graph\n\n    # Input\n    IMG = \'imgs:0\'\n    FEATURE_INDEX = ""feature_index:0""\n    ADJ = \'adjcent:0\'\n    POLY = \'polys:0\'\n    MASK = \'masks:0\'\n\n    # Outputs\n    OUTPUT_POLYS_TENSOR_NAME = \'ggnn_out_poly:0\'\n    OUTPUT_MASKS_TENSOR_NAME = \'ggnn_out_masks:0\'\n\n    def __init__(self, meta_graph_path, graph=None):\n        """"""Creates and loads PolygonModel. """"""\n        if graph is None:\n            self.graph = tf.Graph()\n        else:\n            self.graph = graph\n\n        self.saver = None\n        self.eval_pred_fn = None\n        self._restore_graph(meta_graph_path)\n        self.max_poly_len = 142\n\n    def _restore_graph(self, meta_graph_path):\n        with self.graph.as_default():\n            self.saver = tf.train.import_meta_graph(meta_graph_path, clear_devices=True)\n\n    def _prediction(self):\n        return {\n            \'polys\': self.graph.get_tensor_by_name(self.OUTPUT_POLYS_TENSOR_NAME),\n            \'masks\': self.graph.get_tensor_by_name(self.OUTPUT_MASKS_TENSOR_NAME)\n        }\n\n    def register_eval_fn(self, eval_pred_fn):\n        self.eval_pred_fn = eval_pred_fn\n\n    def do_test(self, sess, input_images, feature_index, polys, masks):\n        """"""\n        Return polygon\n        """"""\n\n        assert input_images.shape[1:] == (224, 224, 3), \'image must be rgb 224x224 but is (%s)\' % str(\n            input_images.shape)\n\n        adjcent_matrix = self.create_adjacency_matrix(polys, masks)\n\n        pred_dict = sess.run(\n            self._prediction(),\n            feed_dict={\n                self.IMG: input_images,\n                self.FEATURE_INDEX: feature_index,\n                self.ADJ: adjcent_matrix,\n                self.POLY: polys,\n                self.MASK: masks\n            }\n        )\n        #\n        polygons = pred_dict[\'polys\']\n        masks = pred_dict[\'masks\']\n        #\n        polygons = self._postprocess_polygons(polygons, masks)\n        pred_dict[\'polys\'] = polygons\n\n        return {\'polys_ggnn\': polygons}\n\n    def create_adjacency_matrix(self, batch_poly, batch_mask):\n        """"""\n        Create adjacency matrix for ggnn\n\n        Args:\n            polygons: T x N x 2 vertices in range [0, grid_side]\n            masks: T x N x 1 masks\n\n        Returns:\n            adjacency_matrix: [Batch_size, self.max_poly_len, self.max_poly_len * 3 * 2]\n        """"""\n        batch_size = len(batch_poly)\n        n_nodes = self.max_poly_len\n        n_edge_types = 3\n        a = np.zeros([batch_size, n_nodes, n_nodes * n_edge_types * 2])\n        for batch in range(len(batch_poly)):\n            mask = batch_mask[batch]\n            index, = np.where(mask == 0)\n            if len(index) > 0:\n                index = index[0]\n                if index > 2:\n                    for i in range(index):\n                        if i % 2 == 0:\n                            if i < index - 2:\n\n                                a[batch][i][(0) * n_nodes + i + 2] = 1\n                                a[batch][i + 2][(0 + n_edge_types) * n_nodes + i] = 1\n\n                                a[batch][i + 2][(0) * n_nodes + i] = 1\n                                a[batch][i][(0 + n_edge_types) * n_nodes + i + 2] = 1\n\n                                a[batch][i][(1) * n_nodes + i + 1] = 1\n                                a[batch][i + 1][(1 + n_edge_types) * n_nodes + i] = 1\n\n                                a[batch][i + 1][(2) * n_nodes + i] = 1\n                                a[batch][i][(2 + n_edge_types) * n_nodes + i + 1] = 1\n\n                            else:\n                                a[batch][i][(0) * n_nodes + 0] = 1\n                                a[batch][0][(0 + n_edge_types) * n_nodes + i] = 1\n\n                                a[batch][0][(0) * n_nodes + i] = 1\n                                a[batch][i][(0 + n_edge_types) * n_nodes + 0] = 1\n\n                                a[batch][i][(1) * n_nodes + i + 1] = 1\n                                a[batch][i + 1][(1 + n_edge_types) * n_nodes + i] = 1\n\n                                a[batch][i + 1][(2) * n_nodes + i] = 1\n                                a[batch][i][(2 + n_edge_types) * n_nodes + i + 1] = 1\n\n                        else:\n                            if i < index - 1:\n                                a[batch][i][(2) * n_nodes + i + 1] = 1\n                                a[batch][i + 1][(2 + n_edge_types) * n_nodes + i] = 1\n\n                                a[batch][i + 1][(1) * n_nodes + i] = 1\n                                a[batch][i][(1 + n_edge_types) * n_nodes + i + 1] = 1\n\n\n                            else:\n                                a[batch][i][(2) * n_nodes + 0] = 1\n                                a[batch][0][(2 + n_edge_types) * n_nodes + i] = 1\n\n                                a[batch][0][(1) * n_nodes + i] = 1\n                                a[batch][i][(1 + n_edge_types) * n_nodes + 0] = 1\n\n        return a\n\n    def _postprocess_polygons(self, polygons, masks, ):\n        """"""\n        Post process polygons.\n\n        Args:\n            polygons: T x N x 2 vertices in range [0, grid_side]\n            masks: T x N x 1 masks\n\n        Returns:\n            processed_polygons: list of N polygons\n        """"""\n\n        result = utils._mask_polys(polygons, masks)\n        result1 = [utils._poly0g_to_poly01(p, 112) for p in result]\n        return result1\n'"
src/PolygonModel.py,5,"b'import tensorflow as tf\nimport numpy as np\nimport utils\nfrom distutils.version import LooseVersion\n\nclass PolygonModel(object):\n    """"""Class to load PolygonModel and run inference.""""""\n\n    # Tensors names to gather from the graph\n\n    # Input\n    INPUT_IMGS_TENSOR_NAME = \'InputImgs:0\'\n    INPUT_FIRST_TOP_K = ""TopKFirstPoint:0""\n\n    # Outputs\n    OUTPUT_POLYS_TENSOR_NAME = \'OutputPolys:0\'\n    OUTPUT_MASKS_TENSOR_NAME = \'OutputMasks:0\'\n    OUTPUT_CNN_FEATS_TENSOR_NAME = \'OutputCNNFeats:0\'\n    # --\n    OUTPUT_STATE1_TENSOR_NAME = \'OutputState1:0\'\n    OUTPUT_STATE2_TENSOR_NAME = \'OutputState2:0\'\n\n    def __init__(self, meta_graph_path, graph=None):\n        """"""Creates and loads PolygonModel. """"""\n\n        #check whether a supported version of tensorflow is installed\n        if (\n                (LooseVersion(tf.__version__) < LooseVersion(\'1.3.0\')) \n             or (LooseVersion(tf.__version__) > LooseVersion(\'1.3.1\'))\n           ):\n            err_string = \'you are using tensorflow version \' + tf.__version__ + \' but only versions 1.3.0 to 1.3.1 are supported\'\n            raise NotImplementedError(err_string)\n\n        if graph is None:\n            self.graph = tf.Graph()\n        else:\n            self.graph = graph\n\n        self.saver = None\n        self.eval_pred_fn = None\n        self._restore_graph(meta_graph_path)\n\n    def _restore_graph(self, meta_graph_path):\n        with self.graph.as_default():\n            self.saver = tf.train.import_meta_graph(meta_graph_path, clear_devices=True)\n\n    def _prediction(self):\n        return {\n            \'polys\': self.graph.get_tensor_by_name(self.OUTPUT_POLYS_TENSOR_NAME),\n            \'masks\': self.graph.get_tensor_by_name(self.OUTPUT_MASKS_TENSOR_NAME),\n            \'state1\': self.graph.get_tensor_by_name(self.OUTPUT_STATE1_TENSOR_NAME),\n            \'state2\': self.graph.get_tensor_by_name(self.OUTPUT_STATE2_TENSOR_NAME),\n            \'cnn_feats\': self.graph.get_tensor_by_name(self.OUTPUT_CNN_FEATS_TENSOR_NAME)\n        }\n\n    def register_eval_fn(self, eval_pred_fn):\n        self.eval_pred_fn = eval_pred_fn\n\n    def do_test(self, sess, input_images, first_top_k=0):\n        """"""\n        Return polygon\n        """"""\n        assert input_images.shape[1:] == (224, 224, 3), \'image must be rgb 224x224 (%s)\' % str(input_images.shape)\n        pred_dict = sess.run(\n            self._prediction(),\n            feed_dict={self.INPUT_IMGS_TENSOR_NAME: input_images, self.INPUT_FIRST_TOP_K: first_top_k}\n        )\n        #\n        polygons = pred_dict[\'polys\']\n        pred_dict[\'raw_polys\'] = polygons\n        masks = pred_dict[\'masks\']\n        #\n        polygons = self._postprocess_polygons(polygons, masks)\n        pred_dict[\'polys\'] = polygons\n        pred_dict[\'hiddens_list\'] = [[pred_dict[\'state1\'], pred_dict[\'state2\']]]\n\n        if self.eval_pred_fn is not None:\n            scores = self.eval_pred_fn(pred_dict)\n        else:\n            scores = None\n\n        return {\'polys\': polygons, \'scores\': scores}\n\n    def _postprocess_polygons(self, polygons, masks, ):\n        """"""\n        Post process polygons.\n\n        Args:\n            polygons: T x N x 2 vertices in range [0, grid_side]\n            masks: T x N x 1 masks\n\n        Returns:\n            processed_polygons: list of N polygons\n        """"""\n        result = np.swapaxes(polygons, 0, 1)\n        masks = np.swapaxes(masks, 0, 1)\n        result = utils._mask_polys(result, masks)\n        result = [utils._poly0g_to_poly01(p) for p in result]\n\n        return result\n'"
src/__init__.py,0,b''
src/inference.py,16,"b'import matplotlib\nmatplotlib.use(\'Agg\')\n\nimport tensorflow as tf\nimport glob\nimport os\nimport numpy as np\nfrom PolygonModel import PolygonModel\nfrom EvalNet import EvalNet\nfrom GGNNPolyModel import GGNNPolygonModel\nimport utils\nimport skimage.io as io\nimport tqdm\nimport json\n\n#\ntf.logging.set_verbosity(tf.logging.INFO)\n# --\nflags = tf.flags\nFLAGS = flags.FLAGS\n# ---\nflags.DEFINE_string(\'PolyRNN_metagraph\', \'\', \'PolygonRNN++ MetaGraph \')\nflags.DEFINE_string(\'PolyRNN_checkpoint\', \'\', \'PolygonRNN++ checkpoint \')\nflags.DEFINE_string(\'EvalNet_checkpoint\', \'\', \'Evaluator checkpoint \')\nflags.DEFINE_string(\'GGNN_metagraph\', \'\', \'GGNN poly MetaGraph \')\nflags.DEFINE_string(\'GGNN_checkpoint\', \'\', \'GGNN poly checkpoint \')\nflags.DEFINE_string(\'InputFolder\', \'../imgs/\', \'Folder with input image crops\')\nflags.DEFINE_string(\'OutputFolder\', \'../output/\', \'OutputFolder\')\nflags.DEFINE_boolean(\'Use_ggnn\', False, \'Use GGNN to postprocess output\')\n\n#\n\n_BATCH_SIZE = 1\n_FIRST_TOP_K = 5\n\ndef save_to_json(crop_name, predictions_dict):\n    output_dict = {\'img_source\': crop_name, \'polys\': predictions_dict[\'polys\'][0].tolist()}\n    if \'polys_ggnn\' in predictions_dict:\n        output_dict[\'polys_ggnn\'] = predictions_dict[\'polys_ggnn\'][0].tolist()\n\n    fname = os.path.basename(crop_name).split(\'.\')[0] + \'.json\'\n\n    fname = os.path.join(FLAGS.OutputFolder, fname)\n\n    json.dump(output_dict, open(fname, \'w\'), indent=4)\n\n\ndef inference(_):\n    # Creating the graphs\n    evalGraph = tf.Graph()\n    polyGraph = tf.Graph()\n\n    # Evaluator Network\n    tf.logging.info(""Building EvalNet..."")\n    with evalGraph.as_default():\n        with tf.variable_scope(""discriminator_network""):\n            evaluator = EvalNet(_BATCH_SIZE)\n            evaluator.build_graph()\n        saver = tf.train.Saver()\n\n        # Start session\n        evalSess = tf.Session(config=tf.ConfigProto(\n            allow_soft_placement=True\n        ), graph=evalGraph)\n        saver.restore(evalSess, FLAGS.EvalNet_checkpoint)\n\n    # PolygonRNN++\n    tf.logging.info(""Building PolygonRNN++ ..."")\n    model = PolygonModel(FLAGS.PolyRNN_metagraph, polyGraph)\n\n    model.register_eval_fn(lambda input_: evaluator.do_test(evalSess, input_))\n\n    polySess = tf.Session(config=tf.ConfigProto(\n        allow_soft_placement=True\n    ), graph=polyGraph)\n\n    model.saver.restore(polySess, FLAGS.PolyRNN_checkpoint)\n\n    if FLAGS.Use_ggnn:\n        ggnnGraph = tf.Graph()\n        tf.logging.info(""Building GGNN ..."")\n        ggnnModel = GGNNPolygonModel(FLAGS.GGNN_metagraph, ggnnGraph)\n        ggnnSess = tf.Session(config=tf.ConfigProto(\n            allow_soft_placement=True\n        ), graph=ggnnGraph)\n\n        ggnnModel.saver.restore(ggnnSess, FLAGS.GGNN_checkpoint)\n\n    tf.logging.info(""Testing..."")\n    if not os.path.isdir(FLAGS.OutputFolder):\n        tf.gfile.MakeDirs(FLAGS.OutputFolder)\n    crops_path = glob.glob(os.path.join(FLAGS.InputFolder, \'*.png\'))\n\n    for crop_path in tqdm.tqdm(crops_path):\n        image_np = io.imread(crop_path)\n        image_np = np.expand_dims(image_np, axis=0)\n        preds = [model.do_test(polySess, image_np, top_k) for top_k in range(_FIRST_TOP_K)]\n\n        # sort predictions based on the eval score and pick the best\n        preds = sorted(preds, key=lambda x: x[\'scores\'][0], reverse=True)[0]\n\n        if FLAGS.Use_ggnn:\n            polys = np.copy(preds[\'polys\'][0])\n            feature_indexs, poly, mask = utils.preprocess_ggnn_input(polys)\n            preds_gnn = ggnnModel.do_test(ggnnSess, image_np, feature_indexs, poly, mask)\n            output = {\'polys\': preds[\'polys\'], \'polys_ggnn\': preds_gnn[\'polys_ggnn\']}\n        else:\n            output = {\'polys\': preds[\'polys\']}\n\n        # dumping to json files\n        save_to_json(crop_path, output)\n\n\nif __name__ == \'__main__\':\n    tf.app.run(inference)\n'"
src/poly_utils.py,0,"b'# import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np\nimport cv2\nimport skimage.draw as draw\n\n\ndef vis_polys(ax, img, poly, title=\'\'):\n    h, w = img.shape[:2]\n    ax.imshow(img, aspect=\'equal\')\n    patch_poly = patches.Polygon(poly, alpha=0.6, color=\'blue\')\n    ax.add_patch(patch_poly)\n    poly = np.append(poly, [poly[0, :]], axis=0)\n    #\n    ax.plot(poly[:, 0] * w, poly[:, 1] * h, \'-o\', linewidth=2, color=\'orange\')\n    # first point different color\n    ax.plot(poly[0, 0] * w, poly[0, 1] * h, \'-o\', linewidth=3, color=\'blue\')\n    ax.set_title(title)\n    ax.axis(\'off\')\n\n\ndef draw_poly(mask, poly):\n    """"""\n    Draw a polygon in the img.\n\n    Args:\n    img: np array of type np.uint8\n    poly: np array of shape N x 2\n    """"""\n    cv2.fillPoly(mask, [poly], 255)\n\n    return mask\n\n\ndef polygon_perimeter(polygon, img_side=28):\n    """"""\n    Generate the perimeter of a polygon including the vertices.\n    """"""\n    # Create empty image\n    img_shape = [img_side, img_side]\n    img = np.zeros(img_shape, dtype=np.float32)\n\n    prev_idx, cur_idx = -1, 0\n    poly_len = len(polygon)\n    while cur_idx < poly_len:\n        # Get vertices\n        prev_vertex = polygon[prev_idx]\n        cur_vertex = polygon[cur_idx]\n\n        # Get line pixels\n        prev_rr, prev_cc = draw.line(\n            prev_vertex[1], prev_vertex[0],\n            cur_vertex[1], cur_vertex[0]\n        )\n        # Draw lines\n        img[prev_rr, prev_cc] = 1.\n\n        # Increment prev_idx and cur_idx\n        prev_idx += 1\n        cur_idx += 1\n\n    return img\n'"
src/utils.py,0,"b'import numpy as np\n\n_MAX_POLY_LEN = 142\n\n\ndef _poly0g_to_poly01(polygon, grid_side=28):\n    """"""\n    [0, grid_side] coordinates to [0, 1].\n\n    Note: we add 0.5 to the vertices so that the lie in the middle of the cell.\n    """"""\n    result = (polygon.astype(np.float32) + 0.5) / grid_side\n\n    return result\n\n\ndef _mask_polys(polys, masks):\n    """"""\n    Return masked polys.\n    """"""\n    new_polys = []\n    for poly, mask in zip(polys, masks):\n        cur_poly = poly[mask.astype(np.bool)]\n        new_polys.append(cur_poly)\n\n    return new_polys\n\n\ndef _poly01_to_index(polygon, grid_side=112):\n    """"""\n    Return poly index in a flat array.\n    """"""\n    result = []\n    for item in polygon:\n        result.append(item[0] + item[1] * grid_side)\n\n    return result\n\n\ndef preprocess_ggnn_input(pred_01_poly):\n    """"""\n    Prepare data for GGNN\n    """"""\n\n    enhanced_poly = []\n    for i in range(len(pred_01_poly)):\n        if i < len(pred_01_poly) - 1:\n            enhanced_poly.append(pred_01_poly[i])\n\n            enhanced_poly.append(\n                np.array(\n                    [(pred_01_poly[i][0] + pred_01_poly[i + 1][0]) / 2,\n                     (pred_01_poly[i][1] + pred_01_poly[i + 1][1]) / 2])\n            )\n        else:\n            enhanced_poly.append(pred_01_poly[i])\n            enhanced_poly.append(\n                np.array(\n                    [(pred_01_poly[i][0] + pred_01_poly[0][0]) / 2,\n                     (pred_01_poly[i][1] + pred_01_poly[0][1]) / 2])\n            )\n\n    poly_for_feature_index = np.floor(np.array(enhanced_poly) * 112).astype(np.int32)\n    feature_indexs = _poly01_to_index(poly_for_feature_index, 112)\n    feature_indexs = np.array(feature_indexs)\n    fwd_poly = np.floor(np.array(enhanced_poly) * 112).astype(np.int32)\n    poly_len = len(fwd_poly)\n\n    array_feature_indexs = np.ones(_MAX_POLY_LEN, np.float32) * 0.\n    arr_fwd_poly = np.ones((_MAX_POLY_LEN, 2), np.float32) * -1.\n    arr_mask = np.zeros(_MAX_POLY_LEN, np.int32)\n    arr_fwd_poly[:poly_len] = fwd_poly\n    arr_mask[:poly_len] = 1\n    array_feature_indexs[:poly_len] = feature_indexs\n\n    return np.array([array_feature_indexs]), np.array([arr_fwd_poly]), np.array([arr_mask])\n'"
src/vis_predictions.py,0,"b'import matplotlib\nmatplotlib.use(\'Agg\')\n\nimport argparse\nimport glob\nimport os\nimport json\nimport matplotlib.pyplot as plt\nfrom poly_utils import vis_polys\nimport skimage.io as io\nimport numpy as np\nimport tqdm\n\ndef main(pred_dir, show_ggnn):\n    preds_path = glob.glob(os.path.join(pred_dir, \'*.json\'))\n\n    fig, axes = plt.subplots(1, 2 if show_ggnn else 1, num=0,figsize=(12,6))\n    axes = np.array(axes).flatten()\n    for pred_path in tqdm.tqdm(preds_path):\n        pred = json.load(open(pred_path, \'r\'))\n        file_name = pred_path.split(\'/\')[-1].split(\'.\')[0]\n\n        im_crop, polys = io.imread(pred[\'img_source\']), np.array(pred[\'polys\'])\n        vis_polys(axes[0], im_crop, polys, title=\'PolygonRNN++ : %s \' % file_name)\n        if show_ggnn:\n            vis_polys(axes[1], im_crop, np.array(pred[\'polys_ggnn\']), title=\' PolygonRNN++ + GGNN : %s\' % file_name)\n\n        fig_name = os.path.join(pred_dir, file_name) + \'.png\'\n        fig.savefig(fig_name)\n        \n        [ax.cla() for ax in axes]\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-pred_dir\', default=\'output/\', help=\'dir with the predicted json files\')\n    parser.add_argument(\'--show_ggnn\', action=""store_true"", default=False, help=\'visualize ggnn\')\n    # --\n    args = parser.parse_args()\n    main(args.pred_dir, args.show_ggnn)\n'"
