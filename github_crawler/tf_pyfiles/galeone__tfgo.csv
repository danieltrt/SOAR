file_path,api_count,code
test_models/create.py,7,"b'# Copyright (C) 2017 Paolo Galeone <nessuno@nerdz.eu>\n#\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, you can obtain one at http://mozilla.org/MPL/2.0/.\n# Exhibit B is not attached; this software is compatible with the\n# licenses expressed under Section 1.12 of the MPL v2.\n""""""Use DyTB to define and train a model. Then redefines it, changing the input\nwhile restoring the learned weights of the best model. Then export it in a protobuf.""""""\n\nimport sys\n\nimport tensorflow as tf\nfrom dytb.inputs.predefined.MNIST import MNIST\nfrom dytb.models.predefined.LeNetDropout import LeNetDropout\nfrom dytb.train import train\n\n\ndef main():\n    """"""main executes the operations described in the module docstring""""""\n    lenet = LeNetDropout()\n    mnist = MNIST()\n\n    info = train(model=lenet, dataset=mnist, hyperparameters={""epochs"": 1})\n\n    checkpoint_path = info[""paths""][""best""]\n\n    with tf.Session() as sess:\n        # Define a new model, import the weights from best model trained\n        # Change the input structure to use a placeholder\n        images = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name=""input_"")\n        # define in the default graph the model that uses placeholder as input\n        _ = lenet.get(images, mnist.num_classes)\n\n        # The best checkpoint path contains just one checkpoint, thus the last is the best\n        saver = tf.train.Saver()\n        saver.restore(sess, tf.train.latest_checkpoint(checkpoint_path))\n\n        # Create a builder to export the model\n        builder = tf.saved_model.builder.SavedModelBuilder(""export"")\n        # Tag the model in order to be capable of restoring it specifying the tag set\n        builder.add_meta_graph_and_variables(sess, [""tag""])\n        builder.save()\n\n        # save the checkpoint files. Those are needed to freeze the graph.\n        tf.gfile.MakeDirs(""models"")\n        saver.save(sess, ""models/model"")\n\n        # Write the serialized form of the graph\n        tf.train.write_graph(sess.graph, ""models"", ""model.pb"")\n\n    return 0\n\n\nif __name__ == ""__main__"":\n    sys.exit(main())\n'"
test_models/estimator.py,13,"b'import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n\nclass EStrain:\n    def __init__(self):\n        self.iris = load_iris()\n\n    def get_train_test(self):\n        data = self.iris.data\n        target = self.iris.target\n        x_train, x_test, y_train, y_test = train_test_split(\n            data, target, test_size=0.3, random_state=0\n        )\n        return x_train, x_test, y_train, y_test\n\n    def get_feature_columns_by_numpy(self):\n        columns = [tf.feature_column.numeric_column(""your_input"", shape=(4,))]\n        return columns\n\n    def get_feature_columns_by_pandas(self):\n        columns = [\n            tf.feature_column.numeric_column(name, shape=(1,)) for name in list(""abcd"")\n        ]\n        return columns\n\n    def input_fn_by_numpy(self, x, y):\n        return tf.estimator.inputs.numpy_input_fn(\n            x={""your_input"": x},\n            y=y,\n            batch_size=512,\n            num_epochs=1,\n            shuffle=False,\n            queue_capacity=1000,\n            num_threads=1,\n        )\n\n    def input_fn_by_pandas(self, x, y):\n        return tf.estimator.inputs.pandas_input_fn(\n            x,\n            y,\n            batch_size=32,\n            num_epochs=1,\n            shuffle=False,\n            queue_capacity=1000,\n            num_threads=1,\n        )\n\n    def to_pandas(self, arr, columns):\n        return pd.DataFrame(arr, columns=columns)\n\n    def get_est(self, path, feature_columns):\n        est = tf.estimator.DNNClassifier(\n            feature_columns=feature_columns,\n            hidden_units=[10, 20, 10],\n            n_classes=3,\n            model_dir=path,\n        )\n        return est\n\n    def train_by_numpy(self):\n        x_train, x_test, y_train, y_test = self.get_train_test()\n        feature_columns = self.get_feature_columns_by_numpy()\n        est = self.get_est(""./output/1"", feature_columns)\n        train_input = self.input_fn_by_numpy(x_train, y_train)\n        test_input = self.input_fn_by_numpy(x_test, y_test)\n        est.train(input_fn=train_input)\n        accuracy_score = est.evaluate(input_fn=test_input)[""accuracy""]\n        print(""accuracy:%s\\n"" % accuracy_score)\n        """""" a test example""""""\n        samples = np.array([[6.4, 3.2, 4.5, 1.5], [6.4, 3.2, 4.5, 1.5]])\n        samples_input = self.input_fn_by_numpy(samples, None)\n        predictions = list(est.predict(samples_input))\n        print(predictions)\n        predicted_classes = int(predictions[0][""classes""])\n        print(""predict result is %s\\n"" % predicted_classes)\n\n    def train_by_pandas(self):\n        x_train, x_test, y_train, y_test = self.get_train_test()\n        feature_columns = self.get_feature_columns_by_pandas()\n        est = self.get_est(""./output/2"", feature_columns)\n        x_train_pd = self.to_pandas(x_train, columns=list(""abcd""))\n        x_test_pd = self.to_pandas(x_test, columns=list(""abcd""))\n        y_train_pd = pd.Series(y_train)\n        y_test_pd = pd.Series(y_test)\n        train_input = self.input_fn_by_pandas(x_train_pd, y_train_pd)\n        test_input = self.input_fn_by_pandas(x_test_pd, y_test_pd)\n        est.train(input_fn=train_input)\n        accuracy_score = est.evaluate(input_fn=test_input)[""accuracy""]\n        print(""accuracy:%s\\n"" % accuracy_score)\n        """""" a test example""""""\n        samples = pd.DataFrame([[6.4, 3.2, 4.5, 1.5]], columns=list(""abcd""))\n        samples_input = self.input_fn_by_pandas(samples, None)\n        predictions = list(est.predict(samples_input))\n        print(predictions)\n        predicted_classes = int(predictions[0][""classes""])\n        print(""predict result is %s\\n"" % predicted_classes)\n\n\nclass ConvertToPB:\n    def __init__(self):\n        self.model_dir_np = ""./output/1""\n        self.model_dir_pd = ""./output/2""\n\n    def serving_input_receiver_fn(self, feature_spec):\n        serizlized_ft_example = tf.placeholder(\n            dtype=tf.float64, shape=[None, 4], name=""input_tensor""\n        )\n        receiver_tensors = {""input"": serizlized_ft_example}\n        features = tf.parse_example(serizlized_ft_example, feature_spec)\n        return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n\n    def convert_np(self):\n        es = EStrain()\n        feature_columns = es.get_feature_columns_by_numpy()\n        est = es.get_est(self.model_dir_np, feature_columns)\n        feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n        export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n            feature_spec\n        )\n        est.export_saved_model(""./output/1pb"", export_input_fn, as_text=True)\n\n    def convert_pd(self):\n        es = EStrain()\n        feature_columns = es.get_feature_columns_by_pandas()\n        est = es.get_est(self.model_dir_pd, feature_columns)\n        feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n        export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n            feature_spec\n        )\n        est.export_saved_model(""./output/2pb"", export_input_fn, as_text=True)\n\n\nif __name__ == ""__main__"":\n\n    et = EStrain()\n    et.train_by_pandas()\n    et.train_by_numpy()\n\n    ct = ConvertToPB()\n    ct.convert_np()\n    ct.convert_pd()\n'"
