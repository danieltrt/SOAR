file_path,api_count,code
setup.py,0,"b""#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the 'License');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an 'AS IS' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport os\nimport setuptools\nfrom distutils import log\nimport sys\n\n# Related third party imports\n\n# Local application/library specific imports\nimport versioneer as versioneer\n\n#\nlog.set_verbosity(log.DEBUG)\nlog.info('Entered setup.py')\nlog.info('$PATH=%s' % os.environ['PATH'])\n\n\n# Check the Python version:\nsupported_versions = [(3, 4), (3, 5), (3, 6)]\nif sys.version_info in supported_versions:\n    raise RuntimeError(\n        'See https://github.com/genicam/harvesters#requirements'\n    )\n\n\nwith open('README.rst', 'r',encoding='utf-8_sig') as fh:\n    __doc__ = fh.read()\n\ndescription = '\xf0\x9f\x8c\x88 Friendly Image Acquisition Library for Computer Vision People'\n\n# Determine the base directory:\nbase_dir = os.path.dirname(__file__)\nsrc_dir = os.path.join(base_dir, 'src')\n\n# Make our package importable when executing setup.py;\n# the package is located in src_dir:\nsys.path.insert(0, src_dir)\n\nsetuptools.setup(\n    # The author of the package:\n    author='The GenICam Committee',\n    author_email='genicam@list.stemmer-imaging.com',\n    # Tells the index and pip some additional metadata about our package:\n    classifiers=(\n        'Development Status :: 3 - Alpha',\n        'Intended Audience :: Science/Research',\n        'Intended Audience :: Education',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: Apache Software License',\n        'Operating System :: MacOS :: MacOS X',\n        'Operating System :: Microsoft :: Windows',\n        'Operating System :: POSIX',\n        'Programming Language :: Python :: 3.4',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n    ),\n    # A short, on-sentence summary of the package:\n    description=description,\n    # Location where the package may be downloaded:\n    download_url='https://pypi.org/project/harvesters/',\n    # A list of required Python modules:\n    install_requires=[\n        'genicam==1.0.0',\n        'numpy'\n    ],\n    #\n    license='Apache Software License V2.0',\n    # A detailed description of the package:\n    long_description=__doc__,\n    # The index to tell what type of markup is used for the long description:\n    long_description_content_type='text/x-rst',\n    # The name of the package:\n    name='harvesters',\n    # A list of all Python import packages that should be included in the\n    # distribution package:\n    packages=setuptools.find_packages(where='src'),\n    # Keys: Package names; an empty name stands for the root package.\n    # Values: Directory names relative to the setup.py.\n    package_dir={\n        '': 'src'\n    },\n    # Keys: Package names.\n    # Values: A list of globs.\n    # All the files that match package_data will be added to the MANIFEST\n    # file if no template is provided:\n    package_data={\n        'harvesters': [\n            os.path.join(\n                'logging', '*.ini'\n            ),\n            os.path.join(\n                'test', 'xml', '*.xml'\n            ),\n            os.path.join(\n                'test', 'xml', '*.zip'\n            ),\n        ]\n    },\n    # A list of supported platforms:\n    platforms='any',\n    #\n    provides=['harvesters'],\n    # The URL for the website of the project:\n    url='https://github.com/genicam/harvesters',\n    # The package version:\n    version=versioneer.get_version(),\n)\n"""
versioneer.py,0,"b'\n# Version: 0.18\n\n""""""The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/warner/python-versioneer\n* Brian Warner\n* License: Public Domain\n* Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, and pypy\n* [![Latest Version]\n(https://pypip.in/version/versioneer/badge.svg?style=flat)\n](https://pypi.python.org/pypi/versioneer/)\n* [![Build Status]\n(https://travis-ci.org/warner/python-versioneer.png?branch=master)\n](https://travis-ci.org/warner/python-versioneer)\n\nThis is a tool for managing a recorded version number in distutils-based\npython projects. The goal is to remove the tedious and error-prone ""update\nthe embedded version string"" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\n* `pip install versioneer` to somewhere to your $PATH\n* add a `[versioneer]` section to your setup.cfg (see below)\n* run `versioneer install` in your source tree, commit the results\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github\'s\n  ""tarball from tag"" feature\n* a release tarball, produced by ""setup.py sdist"", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. ""git describe"" (for checkouts), which knows\n  about recent ""tags"" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. ""myproject-1.2"" instead of just ""1.2""), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n""0.7-1-g574ab98-dirty"" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of ""574ab98"", and is ""dirty"" (it has\nuncommitted changes.\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a \'setup.py sdist\' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the ""outside"" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `[\'version\']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project\'s version\n  string. The default ""pep440"" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the ""Styles"" section\n  below for alternative styles.\n\n* `[\'full-revisionid\']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. ""1076c978a8d3cfc70f408fe5974aa6c092c949ac"".\n\n* `[\'date\']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `[\'dirty\']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `[\'error\']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of ""unknown"".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an ""about"" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()[\'version\']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, ""pep440"", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional ""local\nversion"" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example ""0.11+2.g1076c97.dirty"" indicates that the\ntree is like the ""1076c97"" commit but has uncommitted changes ("".dirty""), and\nthat this commit is two revisions (""+2"") beyond the ""0.11"" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. ""0.11"".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of ""0+unknown"". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/warner/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  ""master"" and ""slave"" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other langauges) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/warner/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/warner/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n""Entry-point scripts"" (`setup(entry_points={""console_scripts"": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/warner/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n### Unicode version strings\n\nWhile Versioneer works (and is continually tested) with both Python 2 and\nPython 3, it is not entirely consistent with bytes-vs-unicode distinctions.\nNewer releases probably generate unicode version strings on py2. It\'s not\nclear that this is wrong, but it may be surprising for applications when then\nwrite these strings to a network connection or include them in bytes-oriented\nAPIs like cryptographic checksums.\n\n[Bug #71](https://github.com/warner/python-versioneer/issues/71) investigates\nthis question.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg`, if necessary, to include any new configuration settings\n  indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the Creative Commons ""Public Domain\nDedication"" license (CC0-1.0), as described in\nhttps://creativecommons.org/publicdomain/zero/1.0/ .\n\n""""""\n\nfrom __future__ import print_function\ntry:\n    import configparser\nexcept ImportError:\n    import ConfigParser as configparser\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_root():\n    """"""Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    """"""\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, ""setup.py"")\n    versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow \'python path/to/setup.py COMMAND\'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, ""setup.py"")\n        versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (""Versioneer was unable to run the project root directory. ""\n               ""Versioneer requires setup.py to be executed from ""\n               ""its immediate directory (like \'python setup.py COMMAND\'), ""\n               ""or in a way that lets it use sys.argv[0] to find the root ""\n               ""(like \'python path/to/setup.py COMMAND\')."")\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # ""versioneer"" may be imported multiple times, and python\'s shared\n        # module-import table will cache the first one. So we can\'t use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        me = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(me)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir:\n            print(""Warning: build in %s is using versioneer.py from %s""\n                  % (os.path.dirname(me), versioneer_py))\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root):\n    """"""Read the project setup.cfg file to determine Versioneer config.""""""\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, ""setup.cfg"")\n    parser = configparser.SafeConfigParser()\n    with open(setup_cfg, ""r"") as f:\n        parser.readfp(f)\n    VCS = parser.get(""versioneer"", ""VCS"")  # mandatory\n\n    def get(parser, name):\n        if parser.has_option(""versioneer"", name):\n            return parser.get(""versioneer"", name)\n        return None\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = get(parser, ""style"") or """"\n    cfg.versionfile_source = get(parser, ""versionfile_source"")\n    cfg.versionfile_build = get(parser, ""versionfile_build"")\n    cfg.tag_prefix = get(parser, ""tag_prefix"")\n    if cfg.tag_prefix in (""\'\'"", \'""""\'):\n        cfg.tag_prefix = """"\n    cfg.parentdir_prefix = get(parser, ""parentdir_prefix"")\n    cfg.verbose = get(parser, ""verbose"")\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\nLONG_VERSION_PY[\'git\'] = \'\'\'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""%(DOLLAR)sFormat:%%d%(DOLLAR)s""\n    git_full = ""%(DOLLAR)sFormat:%%H%(DOLLAR)s""\n    git_date = ""%(DOLLAR)sFormat:%%ci%(DOLLAR)s""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""%(STYLE)s""\n    cfg.tag_prefix = ""%(TAG_PREFIX)s""\n    cfg.parentdir_prefix = ""%(PARENTDIR_PREFIX)s""\n    cfg.versionfile_source = ""%(VERSIONFILE_SOURCE)s""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %%s"" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %%s"" %% (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %%s (error)"" %% dispcmd)\n            print(""stdout was %%s"" %% stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %%s but none started with prefix %%s"" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %%s"" %% "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %%s"" %% r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %%s not under git control"" %% root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%%s*"" %% tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%%d.g%%s"" %% (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%%d.g%%s"" %% (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%%d"" %% pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%%d"" %% pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%%s"" %% pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%%s"" %% pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%%s\'"" %% style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n\'\'\'\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%s*"" % tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef do_vcs_install(manifest_in, versionfile_source, ipy):\n    """"""Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        me = __file__\n        if me.endswith("".pyc"") or me.endswith("".pyo""):\n            me = os.path.splitext(me)[0] + "".py""\n        versioneer_file = os.path.relpath(me)\n    except NameError:\n        versioneer_file = ""versioneer.py""\n    files.append(versioneer_file)\n    present = False\n    try:\n        f = open("".gitattributes"", ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(versionfile_source):\n                if ""export-subst"" in line.strip().split()[1:]:\n                    present = True\n        f.close()\n    except EnvironmentError:\n        pass\n    if not present:\n        f = open("".gitattributes"", ""a+"")\n        f.write(""%s export-subst\\n"" % versionfile_source)\n        f.close()\n        files.append("".gitattributes"")\n    run_command(GITS, [""add"", ""--""] + files)\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\nSHORT_VERSION_PY = """"""\n# This file was generated by \'versioneer.py\' (0.18) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\n\nversion_json = \'\'\'\n%s\n\'\'\'  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n""""""\n\n\ndef versions_from_file(filename):\n    """"""Try to determine the version from _version.py if present.""""""\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(""unable to read _version.py"")\n    mo = re.search(r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"",\n                   contents, re.M | re.S)\n    if not mo:\n        mo = re.search(r""version_json = \'\'\'\\r\\n(.*)\'\'\'  # END VERSION_JSON"",\n                       contents, re.M | re.S)\n    if not mo:\n        raise NotThisMethod(""no version_json in _version.py"")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename, versions):\n    """"""Write the given version number to the given _version.py file.""""""\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=("","", "": ""))\n    with open(filename, ""w"") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(""set %s to \'%s\'"" % (filename, versions[""version""]))\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\nclass VersioneerBadRootError(Exception):\n    """"""The project root directory is unknown or missing key files.""""""\n\n\ndef get_versions(verbose=False):\n    """"""Get the project version from whatever source is available.\n\n    Returns dict with two keys: \'version\' and \'full\'.\n    """"""\n    if ""versioneer"" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[""versioneer""]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, ""please set [versioneer]VCS= in setup.cfg""\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, ""unrecognized VCS \'%s\'"" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert cfg.versionfile_source is not None, \\\n        ""please set versioneer.versionfile_source""\n    assert cfg.tag_prefix is not None, ""please set versioneer.tag_prefix""\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. \'git\n    # describe\'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by \'setup.py sdist\',\n    # and for users of a tarball/zipball created by \'git archive\' or github\'s\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(""get_keywords"")\n    from_keywords_f = handlers.get(""keywords"")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(""got version from expanded keyword %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(""got version from file %s %s"" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(""pieces_from_vcs"")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(""got version from VCS %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(""got version from parentdir %s"" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(""unable to compute version"")\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None, ""error"": ""unable to compute version"",\n            ""date"": None}\n\n\ndef get_version():\n    """"""Get the short version string for this project.""""""\n    return get_versions()[""version""]\n\n\ndef get_cmdclass():\n    """"""Get the custom setuptools/distutils subclasses used by Versioneer.""""""\n    if ""versioneer"" in sys.modules:\n        del sys.modules[""versioneer""]\n        # this fixes the ""python setup.py develop"" case (also \'install\' and\n        # \'easy_install .\'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A\'s setup.py imports A\'s Versioneer, leaving it in\n        # sys.modules by the time B\'s setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it\'s pre-build state, so the\n        # parent is protected against the child\'s ""import versioneer"". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent\'s versioneer too.\n        # Also see https://github.com/warner/python-versioneer/issues/52\n\n    cmds = {}\n\n    # we add ""version"" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = ""report generated version string""\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(""Version: %s"" % vers[""version""])\n            print("" full-revisionid: %s"" % vers.get(""full-revisionid""))\n            print("" dirty: %s"" % vers.get(""dirty""))\n            print("" date: %s"" % vers.get(""date""))\n            if vers[""error""]:\n                print("" error: %s"" % vers[""error""])\n    cmds[""version""] = cmd_version\n\n    # we override ""build_py"" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn\'t copied too, \'git describe\' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # we override different ""build_py"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.build_py import build_py as _build_py\n    else:\n        from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n    cmds[""build_py""] = cmd_build_py\n\n    if ""cx_Freeze"" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n        # nczeczulin reports that py2exe won\'t like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   ""version"": versioneer.get_version().split(""+"", 1)[0], # FILEVERSION\n        #   ""product_version"": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""build_exe""] = cmd_build_exe\n        del cmds[""build_py""]\n\n    if \'py2exe\' in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # py3\n        except ImportError:\n            from py2exe.build_exe import py2exe as _py2exe  # py2\n\n        class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""py2exe""] = cmd_py2exe\n\n    # we override different ""sdist"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[""version""]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(""UPDATING %s"" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)\n    cmds[""sdist""] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = """"""\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or \'python versioneer.py setup\'.\n""""""\n\nSAMPLE_CONFIG = """"""\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run \'versioneer.py setup\' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n""""""\n\nINIT_PY_SNIPPET = """"""\nfrom ._version import get_versions\n__version__ = get_versions()[\'version\']\ndel get_versions\n""""""\n\n\ndef do_setup():\n    """"""Main VCS-independent setup function for installing Versioneer.""""""\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(""Adding sample versioneer config to setup.cfg"",\n                  file=sys.stderr)\n            with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print("" creating %s"" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, ""w"") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {""DOLLAR"": ""$"",\n                        ""STYLE"": cfg.style,\n                        ""TAG_PREFIX"": cfg.tag_prefix,\n                        ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                        ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       ""__init__.py"")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, ""r"") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = """"\n        if INIT_PY_SNIPPET not in old:\n            print("" appending to %s"" % ipy)\n            with open(ipy, ""a"") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print("" %s unmodified"" % ipy)\n    else:\n        print("" %s doesn\'t exist, ok"" % ipy)\n        ipy = None\n\n    # Make sure both the top-level ""versioneer.py"" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they\'ll be copied into source distributions. Pip won\'t be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, ""MANIFEST.in"")\n    simple_includes = set()\n    try:\n        with open(manifest_in, ""r"") as f:\n            for line in f:\n                if line.startswith(""include ""):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn\'t cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant \'include\'\n    # lines is safe, though.\n    if ""versioneer.py"" not in simple_includes:\n        print("" appending \'versioneer.py\' to MANIFEST.in"")\n        with open(manifest_in, ""a"") as f:\n            f.write(""include versioneer.py\\n"")\n    else:\n        print("" \'versioneer.py\' already in MANIFEST.in"")\n    if cfg.versionfile_source not in simple_includes:\n        print("" appending versionfile_source (\'%s\') to MANIFEST.in"" %\n              cfg.versionfile_source)\n        with open(manifest_in, ""a"") as f:\n            f.write(""include %s\\n"" % cfg.versionfile_source)\n    else:\n        print("" versionfile_source already in MANIFEST.in"")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0\n\n\ndef scan_setup_py():\n    """"""Validate the contents of setup.py against Versioneer\'s expectations.""""""\n    found = set()\n    setters = False\n    errors = 0\n    with open(""setup.py"", ""r"") as f:\n        for line in f.readlines():\n            if ""import versioneer"" in line:\n                found.add(""import"")\n            if ""versioneer.get_cmdclass()"" in line:\n                found.add(""cmdclass"")\n            if ""versioneer.get_version()"" in line:\n                found.add(""get_version"")\n            if ""versioneer.VCS"" in line:\n                setters = True\n            if ""versioneer.versionfile_source"" in line:\n                setters = True\n    if len(found) != 3:\n        print("""")\n        print(""Your setup.py appears to be missing some important items"")\n        print(""(but I might be wrong). Please make sure it has something"")\n        print(""roughly like the following:"")\n        print("""")\n        print("" import versioneer"")\n        print("" setup( version=versioneer.get_version(),"")\n        print(""        cmdclass=versioneer.get_cmdclass(),  ...)"")\n        print("""")\n        errors += 1\n    if setters:\n        print(""You should remove lines like \'versioneer.VCS = \' and"")\n        print(""\'versioneer.versionfile_source = \' . This configuration"")\n        print(""now lives in setup.cfg, and should be removed from setup.py"")\n        print("""")\n        errors += 1\n    return errors\n\n\nif __name__ == ""__main__"":\n    cmd = sys.argv[1]\n    if cmd == ""setup"":\n        errors = do_setup()\n        errors += scan_setup_py()\n        if errors:\n            sys.exit(1)\n'"
docs/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# GenTL-Python Binding documentation build configuration file, created by\n# sphinx-quickstart on Thu Jun 22 06:21:22 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'../src\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.ifconfig\',\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx.ext.todo\'\n]\n\n# TO-DO\ntodo_include_todos = True\n\n# Napoleon settings\nnapoleon_google_docstring = True\nnapoleon_numpy_docstring = True\nnapoleon_include_init_with_doc = False\nnapoleon_include_private_with_doc = False\nnapoleon_include_special_with_doc = True\nnapoleon_use_admonition_for_examples = False\nnapoleon_use_admonition_for_notes = False\nnapoleon_use_admonition_for_references = False\nnapoleon_use_ivar = False\nnapoleon_use_param = True\nnapoleon_use_rtype = True\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#\n# source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = \'Harvester\'\ncopyright = \'2018 EMVA\'\nauthor = \'EMVA\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \'0.0.0\'\n# The full version, including alpha/beta/rc tags.\nrelease = \'0\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#\n# today = \'\'\n#\n# Else, today_fmt is used as the format for a strftime call.\n#\n# today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = []\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n#\n# default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'bizstyle\'\n\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.\n# ""<project> v<release> documentation"" by default.\n#\n# html_title = \'GenTL-Python Binding v0.0.1\'\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#\n# html_logo = None\n#html_logo = \'../../_images/genicam_logo.png\'\n\n# The name of an image file (relative to this directory) to use as a favicon of\n# the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\n# html_static_path = [\'_static\']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n#\n# html_extra_path = []\n\n# If not None, a \'Last updated on:\' timestamp is inserted at every page\n# bottom, using the given strftime format.\n# The empty string is equivalent to \'%b %d, %Y\'.\n#\n# html_last_updated_fmt = None\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n#\n# html_domain_indices = True\n\n# If false, no index is generated.\n#\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#\n# html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#\n# html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#\n# html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   \'da\', \'de\', \'en\', \'es\', \'fi\', \'fr\', \'h\', \'it\', \'ja\'\n#   \'nl\', \'no\', \'pt\', \'ro\', \'r\', \'sv\', \'tr\', \'zh\'\n#\n# html_search_language = \'en\'\n\n# A dictionary with options for the search language support, empty by default.\n# \'ja\' uses this config value.\n# \'zh\' user can custom change `jieba` dictionary path.\n#\n# html_search_options = {\'type\': \'default\'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n#\n# html_search_scorer = \'scorer.js\'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'HarvesterDoc\'\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n     # The paper size (\'letterpaper\' or \'a4paper\').\n     #\n     # \'papersize\': \'letterpaper\',\n\n     # The font size (\'10pt\', \'11pt\' or \'12pt\').\n     #\n     # \'pointsize\': \'10pt\',\n\n     # Additional stuff for the LaTeX preamble.\n     #\n     # \'preamble\': \'\',\n\n     # Latex figure (float) alignment\n     #\n     # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'Harvester.tex\', \'Harvester Documentation\',\n     \'EMVA\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#\n# latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n#\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#\n# latex_appendices = []\n\n# It false, will not define \\strong, \\code, \titleref, \\crossref ... but only\n# \\sphinxstrong, ..., \\sphinxtitleref, ... To help avoid clash with user added\n# packages.\n#\n# latex_keep_old_macro_names = True\n\n# If false, no module index is generated.\n#\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'harvesters\', \'Harvester Documentation\',\n     [author], 1)\n]\n\n# If true, show URL addresses after external links.\n#\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'Harvester\', \'Harvester Documentation\',\n     author, \'Harvester\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n#\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n#\n# texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#\n# texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n#\n# texinfo_no_detailmenu = False\n\nepub_author = \'EMVA\'\nepub_publisher = \'EMVA\'\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    \'https://docs.python.org/\' + \\\n    str(sys.version_info[0]) + \'.\' + \\\n    str(sys.version_info[1]): None\n}\n\n# List up the module to be mocked.\nautodoc_mock_imports = [\'genicam\', \'numpy\']\n\ndef skip(app, what, name, obj, skip, options):\n    if name == ""__init__"":\n        return False\n    return skip\n\ndef setup(app):\n    app.connect(""autodoc-skip-member"", skip)\n'"
src/harvesters/__init__.py,0,"b""\nfrom ._version import get_versions\n__version__ = get_versions()['version']\nif not __version__:\n    __version__ = '1.2.4'\ndel get_versions\n"""
src/harvesters/_version.py,0,"b'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""$Format:%d$""\n    git_full = ""$Format:%H$""\n    git_date = ""$Format:%ci$""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""pep440-pre""\n    cfg.tag_prefix = """"\n    cfg.parentdir_prefix = ""harvesters""\n    cfg.versionfile_source = ""_version.py""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%s*"" % tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n'"
src/harvesters/core.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nfrom collections.abc import Iterable\nfrom datetime import datetime\nfrom enum import IntEnum\nimport io\nfrom logging import Logger\nimport ntpath\nimport os\nimport pathlib\nfrom queue import Queue\nfrom queue import Full, Empty\nimport signal\nimport sys\nfrom threading import Lock, Thread, Event\nfrom threading import current_thread, main_thread\nimport time\nfrom typing import Union, List, Optional\nfrom urllib.parse import urlparse\nfrom warnings import warn\nimport weakref\nimport tempfile\n\n# Related third party imports\nimport numpy\n\nfrom genicam.genapi import NodeMap\nfrom genicam.genapi import LogicalErrorException, RuntimeException\nfrom genicam.genapi import ChunkAdapterGeneric, ChunkAdapterU3V, \\\n    ChunkAdapterGEV\n\nfrom genicam.gentl import TimeoutException, \\\n    NotImplementedException, ParsingChunkDataException, NoDataException, \\\n    ErrorException, InvalidBufferException, InvalidParameterException\nfrom genicam.gentl import GenericException\nfrom genicam.gentl import GenTLProducer, BufferToken, EventManagerNewBuffer\nfrom genicam.gentl import DEVICE_ACCESS_FLAGS_LIST, EVENT_TYPE_LIST, \\\n    ACQ_START_FLAGS_LIST, ACQ_STOP_FLAGS_LIST, ACQ_QUEUE_TYPE_LIST, \\\n    PAYLOADTYPE_INFO_IDS\nfrom genicam.gentl import EventToken, Port, PIXELFORMAT_NAMESPACE_IDS\nfrom genicam.gentl import Buffer as Buffer_\n\n# Local application/library specific imports\nfrom harvesters._private.core.port import ConcretePort\nfrom harvesters._private.core.statistics import Statistics\nfrom harvesters.util.logging import get_logger\nfrom harvesters.util.pfnc import dict_by_names, dict_by_ints\nfrom harvesters.util.pfnc import Dictionary\nfrom harvesters.util.pfnc import component_2d_formats\n\n\n_is_logging_buffer_manipulation = True if \'HARVESTERS_LOG_BUFFER_MANIPULATION\' in os.environ else False\n_sleep_duration_default = 0.000001  # s\n\n\ndef _deprecated(deprecated: object, alternative: object) -> None:\n    #\n    items = []\n    for obj in (deprecated, alternative):\n        items.append(obj.__name__ + \'()\' if callable(obj) else obj)\n\n    keys = {\'deprecated\': 0, \'alternative\': 1}\n    warn(\n        \'{0} will be deprecated shortly. Use {1} instead.\'.format(\n            items[keys[\'deprecated\']], items[keys[\'alternative\']]\n        ),\n        DeprecationWarning, stacklevel=3\n    )\n\n\nclass Module:\n    def __init__(\n            self, module=None,\n            node_map: Optional[NodeMap] = None, parent=None):\n        self._module = module\n        self._node_map = node_map\n        self._parent = parent\n\n    @property\n    def node_map(self):\n        """"""\n        The GenICam feature node map that belongs to the owner object.\n\n        :getter: Returns itself.\n        :type: genicam.genapi.NodeMap\n        """"""\n        return self._node_map\n\n    @property\n    def parent(self):\n        """"""\n        The parent GenTL entity.\n\n        :getter: Returns itself.\n        :type: Module\n        """"""\n        return self._parent\n\n    @property\n    def port(self) -> Port:\n        """"""\n        The GenTL Port entity that belongs to the GenTL entity.\n\n        :getter: Returns itself.\n        :type: Port\n        """"""\n\n        return self._module.port\n\n    def register_event(self, event_type=None) -> EventToken:\n        """"""\n        Registers an even that is defined by the GenTL standard.\n\n        :param event_type: Set an event type to register.\n        :return: Returns an event token that is used to retrieve the event.\n        :type: EventToken\n        """"""\n        return self._module.register_event(event_type)\n\n\nclass DataStream(Module):\n    def __init__(\n            self,\n            module: Optional[Module] = None,\n            node_map: Optional[NodeMap] = None,\n            parent: Optional[Module] = None):\n        super().__init__(module=module, node_map=node_map, parent=parent)\n\n    def open(self, data_stream_id: str = None) -> None:\n        """"""\n        Opens the GenTL data stream entity.\n\n        :param data_stream_id: Set a data stream ID to open.\n        :return: None\n        """"""\n        self._module.open(data_stream_id)\n\n    @property\n    def id_(self):\n        """"""\n        The ID of the GenTL entity.\n\n        :getter: Returns itself.\n        :type: str\n        """"""\n        return self._module.id_\n\n    @property\n    def buffer_announce_min(self):\n        """"""\n        The minimum number that is required to run image acquisition process.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        return self._module.buffer_announce_min\n\n    def defines_payload_size(self) -> bool:\n        """"""\n        Returns the truth value of a proposition: The target GenTL Producer\n        defines payload size.\n\n        :return: The truth value.\n        """"""\n        return self._module.defines_payload_size()\n\n    @property\n    def payload_size(self) -> int:\n        """"""\n        The size of the payload. The unit is [Bytes].\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        return self._module.payload_size\n\n    def queue_buffer(self, announced_buffer: Buffer_ = None) -> None:\n        """"""\n        Queues the announced buffer to the input buffer pool of the image\n        acquisition engine.\n\n        :param announced_buffer:\n        :return: None\n        """"""\n        self._module.queue_buffer(announced_buffer)\n\n    def start_acquisition(self, flags=None, num_images=None) -> None:\n        """"""\n        Starts image acquisition.\n\n        :param flags:\n        :param num_images:\n        :return: None.\n        """"""\n        self._module.start_acquisition(flags, num_images)\n\n    def is_open(self) -> bool:\n        """"""\n        Returns the truth value of a proposition: The DataStream entity has\n        been opened.\n\n        :return: :const:`True` if it\'s been opened. Otherwise :const:`False`.\n        :rtype: bool\n        """"""\n        return self._module.is_open()\n\n    def stop_acquisition(self, flags=None):\n        """"""\n        Stops image acquisition.\n\n        :param flags:\n        :return: None\n        """"""\n        self._module.stop_acquisition(flags)\n\n    def revoke_buffer(self, buffer=None):\n        """"""\n        Revokes the specified buffer from the queue.\n\n        :param buffer: Set an announced :class:`Buffer` object to revoke.\n        :return: The revoked buffer object.\n        :rtype: :class:`Buffer`\n        """"""\n        return self._module.revoke_buffer(buffer)\n\n    def flush_buffer_queue(self, operation=None) -> None:\n        """"""\n        Flushes the queue.\n\n        :param operation: Set an operation to execute.\n        :return: None\n        """"""\n        self._module.flush_buffer_queue(operation)\n\n    def close(self) -> None:\n        """"""\n        Closes the given DataStream entity.\n        :return:  None\n        """"""\n        self._module.close()\n\n    def announce_buffer(self, buffer_token=None) -> Buffer_:\n        """"""\n        Announces the give buffer.\n\n        :param buffer_token: Set a buffer to announce.\n        :return: An announced buffer.\n        :type: :class:`Buffer_`\n        """"""\n        return self._module.announce_buffer(buffer_token)\n\n\nclass RemoteDevice(Module):\n    def __init__(\n            self, module=None, node_map: NodeMap = None, parent=None):\n        super().__init__(module=module, node_map=node_map, parent=parent)\n\n    @property\n    def port(self):\n        return self._parent.remote_port\n\n\nclass Device(Module):\n    def __init__(self, module=None, node_map: NodeMap = None, parent=None):\n        super().__init__(module=module, node_map=node_map, parent=parent)\n\n    @property\n    def data_stream_ids(self):\n        return self._module.data_stream_ids\n\n    def create_data_stream(self):\n        return self._module.create_data_stream()\n\n    @property\n    def id_(self):\n        return self._module.id_\n\n    @property\n    def tl_type(self):\n        return self._module.tl_type\n\n    def is_open(self):\n        return self._module.is_open()\n\n    def close(self):\n        self._module.close()\n\n    @property\n    def port(self):\n        return self._module.local_port\n\n\nclass Interface(Module):\n    def __init__(\n            self, module=None, node_map: Optional[NodeMap] = None,\n            parent=None):\n        super().__init__(module=module, node_map=node_map, parent=parent)\n\n\nclass System(Module):\n    def __init__(\n            self,\n            module=None, node_map: Optional[NodeMap] = None, parent=None):\n        assert parent is None\n        super().__init__(module=module, node_map=node_map, parent=parent)\n\n\nclass DeviceInfo:\n    def __init__(self, device_info=None):\n        self._device_info = device_info\n\n    def create_device(self):\n        return self._device_info.create_device()\n\n    def __repr__(self):\n        properties = [\n            \'id_\',\n            \'vendor\',\n            \'model\',\n            \'tl_type\',\n            \'user_defined_name\',\n            \'serial_number\',\n            \'version\',\n        ]\n        results = []\n        for _property in properties:\n            if _property is \'\':\n                result = None\n            else:\n                try:\n                    result = eval(\'self._device_info.\' + _property)\n                except:\n                    result = None\n            results.append(result)\n\n        info = \'(\'\n        delimiter = \', \'\n        for i, r in enumerate(results):\n            if r:\n                r = \'\\\'{0}\\\'\'.format(r)\n            else:\n                r = \'None\'\n            info += \'{0}={1}\'.format(properties[i], r)\n            info += delimiter\n        info = info[:-len(delimiter)]\n        info += \')\'\n        return info\n\n    @property\n    def id_(self):\n        return self._device_info.id_\n\n    @property\n    def vendor(self):\n        return self._device_info.vendor\n\n    @property\n    def model(self):\n        return self._device_info.model\n\n    @property\n    def tl_type(self):\n        return self._device_info.tl_type\n\n    @property\n    def user_defined_name(self):\n        return self._device_info.user_defined_name\n\n    @property\n    def serial_number(self):\n        return self._device_info.serial_number\n\n    @property\n    def version(self):\n        return self._device_info.version\n\n\nclass _SignalHandler:\n    _event = None\n    _threads = None\n\n    def __init__(\n            self, *,\n            event=None, threads=None, logger: Optional[Logger] = None):\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__()\n\n        #\n        assert event\n        assert threads\n\n        #\n        self._event = event\n        self._threads = threads\n\n    def __call__(self, signum, frame):\n        """"""\n        A registered Python signal modules will call this method.\n        """"""\n\n        self._logger.debug(\n            \'Going to terminate threads having triggered \'\n            \'by the event {0}.\'.format(\n                self._event\n            )\n        )\n\n        # Set the Event:\n        self._event.set()\n\n        # Terminate the threads:\n        for thread in self._threads:\n            thread.stop()\n            thread.join()\n\n        self._logger.debug(\n            \'Has terminated threads having triggered by \'\n            \'the event {0}.\'.format(\n                self._event\n            )\n        )\n\n\nclass ThreadBase:\n    """"""\n    Is a base class that is used to implement a thread that users want to\n    use. For example, in general, PyQt application should implement a\n    thread using QThread instead of Python\'s built-in Thread class.\n    """"""\n    def __init__(self, *, logger: Optional[Logger] = None, mutex=None):\n        #\n        super().__init__()\n        #\n        self._logger = logger or get_logger(name=__name__)\n        #\n        self._mutex = mutex\n        self._is_running = False\n        self._id = None\n\n    def start(self) -> None:\n        self._internal_start()\n        self._logger.debug(\n            \'Started thread {:0X}.\'.format(self.id_)\n        )\n\n    def _internal_start(self) -> None:\n        """"""\n        Releases the acquired mutex.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: None.\n        """"""\n        raise NotImplementedError\n\n    def stop(self) -> None:\n        self._internal_stop()\n        self._logger.debug(\n            \'Stopped thread {:0X}.\'.format(self.id_)\n        )\n\n    def join(self):\n        """"""\n        Waits until the given task is completed.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: None.\n        """"""\n        raise NotImplementedError\n\n    def _internal_stop(self):\n        """"""\n        Releases the acquired mutex.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: None.\n        """"""\n        raise NotImplementedError\n\n    def acquire(self):\n        """"""\n        Acquires a mutex.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: An acquired :class:`MutexLocker` object.\n        :rtype: MutexLocker\n        """"""\n        raise NotImplementedError\n\n    def release(self) -> None:\n        """"""\n        Releases the acquired mutex.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: None.\n        """"""\n        raise NotImplementedError\n\n    def is_running(self) -> bool:\n        """"""\n        Returns the truth value of a proposition: The thread is running.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: :const:`True` if the thread is running. Otherwise it returns :const:`False`.\n        :type: bool\n        """"""\n        raise NotImplementedError\n\n    @property\n    def id_(self) -> int:\n        return self._id\n\n\nclass MutexLocker:\n    def __init__(self, thread: ThreadBase=None):\n        """"""\n        :param thread:\n        """"""\n        #\n        assert thread\n        #\n        super().__init__()\n        #\n        self._thread = thread\n        self._locked_mutex = None\n\n    def __enter__(self):\n        #\n        if self._thread is None:\n            return None\n\n        #\n        self._locked_mutex = self._thread.acquire()\n        return self._locked_mutex\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        #\n        if self._thread is None:\n            return\n\n        #\n        self._thread.release()\n\n\nclass _ImageAcquisitionThread(ThreadBase):\n    def __init__(\n            self, *,\n            image_acquire=None, logger: Optional[Logger] = None):\n        """"""\n\n        :param image_acquire:\n        :param logger:\n        """"""\n        #\n        assert image_acquire\n        #\n        super().__init__(\n            mutex=Lock(), logger=logger\n        )\n\n        #\n        self._ia = image_acquire\n        self._worker = self._ia.worker_image_acquisition\n        self._sleep_duration = self._ia.sleep_duration\n        self._thread = None\n\n    def _internal_start(self):\n        """"""\n\n        :return: None.\n        """"""\n        self._thread = _NativeThread(\n            thread_owner=self, worker=self._worker,\n            sleep_duration=self._sleep_duration\n        )\n        self._id = self._thread.id_\n\n        # Start running its worker method.\n        self._is_running = True\n        self._thread.start()\n\n    def join(self):\n        # Wait until the run methods is terminated.\n        self._thread.join()\n\n    def _internal_stop(self):\n        #\n        if self._thread is None:\n            return\n\n        # Prepare to terminate the worker method.\n        self._thread.stop()\n        self._is_running = False\n\n    def acquire(self):\n        #\n        if self._thread:\n            return self._thread.acquire()\n        else:\n            return None\n\n    def release(self):\n        #\n        if self._thread:\n            self._thread.release()\n        else:\n            return\n\n    @property\n    def worker(self):\n        #\n        if self._thread:\n            return self._thread.worker\n        else:\n            return None\n\n    @worker.setter\n    def worker(self, obj):\n        #\n        if self._thread:\n            self._thread.worker = obj\n        else:\n            return\n\n    @property\n    def mutex(self):\n        return self._mutex\n\n    @property\n    def id_(self):\n        return self._thread.id_\n\n    def is_running(self):\n        return self._is_running\n\n\nclass _NativeThread(Thread):\n    def __init__(self, thread_owner=None, worker=None,\n                 sleep_duration=_sleep_duration_default):\n        """"""\n\n        :param thread_owner:\n        :param worker:\n        :param sleep_duration:\n        """"""\n\n        #\n        assert thread_owner\n\n        #\n        super().__init__(daemon=self._is_interactive())\n\n        #\n        self._worker = worker\n        self._thread_owner = thread_owner\n        self._sleep_duration = sleep_duration\n\n    @staticmethod\n    def _is_interactive():\n        #\n        if bool(getattr(sys, \'ps1\', sys.flags.interactive)):\n            return True\n\n        #\n        try:\n            from traitlets.config.application import Application as App\n            return App.initialized() and App.instance().interact\n        except (ImportError, AttributeError):\n            return False\n\n    def stop(self):\n        with self._thread_owner.mutex:\n            self._thread_owner._is_running = False\n\n    def run(self):\n        """"""\n        Runs its worker method.\n\n        This method will be terminated once its parent\'s is_running\n        property turns False.\n        """"""\n        while self._thread_owner.is_running():\n            if self._worker:\n                self._worker()\n                time.sleep(self._sleep_duration)\n\n    def acquire(self):\n        return self._thread_owner.mutex.acquire()\n\n    def release(self):\n        self._thread_owner.mutex.release()\n\n    @property\n    def id_(self):\n        return self.ident\n\n    @property\n    def worker(self):\n        return self._worker\n\n    @worker.setter\n    def worker(self, obj):\n        self._worker = obj\n\n    @property\n    def mutex(self):\n        return self._thread_owner.mutex\n\n\nclass ComponentBase:\n    """"""\n    Is a base class of various data component types.\n    """"""\n    def __init__(self, *, buffer=None):\n        """"""\n        :param buffer:\n        """"""\n        #\n        assert buffer\n\n        #\n        super().__init__()\n\n        #\n        self._buffer = buffer\n        self._data = None\n\n    @property\n    def data_format(self) -> str:\n        """"""\n        The type of the data component.\n\n        :getter: Returns itself.\n        :type: str\n        """"""\n        return self._buffer.data_format\n\n    @property\n    def data_format_namespace(self) -> PIXELFORMAT_NAMESPACE_IDS:\n        """"""\n        The data type namespace of the data component.\n\n        :getter: Returns itself.\n        :type: :class:`genicam.gentl.PIXELFORMAT_NAMESPACE_IDS`\n        """"""\n        return self._buffer.data_format\n\n    @property\n    def source_id(self) -> int:\n        """"""\n        The source ID of the data component.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        return self._buffer.source_id\n\n    @property\n    def data(self) -> Optional[numpy.ndarray]:\n        """"""\n        The raw image data.\n\n        :getter: Returns itself.\n        :type: :class:`numpy.ndarray`\n        """"""\n        return self._data\n\n\nclass ComponentUnknown(ComponentBase):\n    """"""\n    Represents a data component that is classified as\n    :const:`PART_DATATYPE_UNKNOWN` by the GenTL Standard.\n    """"""\n    def __init__(self):\n        #\n        super().__init__()\n\n\nclass Component2DImage(ComponentBase):\n    """"""\n    Represents a data component that is classified as\n    :const:`PART_DATATYPE_2D_IMAGE` by the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer=None, part=None, node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n        :param buffer:\n        :param part:\n        :param node_map:\n        """"""\n        #\n        assert buffer\n        assert node_map\n\n        #\n        super().__init__(buffer=buffer)\n\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        self._part = part\n        self._node_map = node_map\n        proxy = Dictionary.get_proxy(symbolic=self.data_format)\n        self._nr_components = proxy.nr_components\n        self._data = self._to_np_array(proxy)\n\n    def _to_np_array(self, pf_proxy):\n        #\n        if self.has_part():\n            nr_bytes = self._part.data_size\n        else:\n            try:\n                w = self._buffer.width\n            except NotImplementedException:\n                w = self._node_map.Width.value\n            try:\n                h = self._buffer.height\n            except NotImplementedException:\n                h = self._node_map.Height.value\n            nr_bytes = h * w\n            nr_bytes *= pf_proxy.depth_in_byte\n            try:\n                padding_y = self._buffer.padding_y\n            except NotImplementedException:\n                padding_y = 0\n            nr_bytes += padding_y\n\n        array = numpy.frombuffer(\n            self._buffer.raw_buffer, count=int(nr_bytes),\n            dtype=\'uint8\',\n            offset=self.data_offset\n        )\n        return pf_proxy.expand(array)\n\n    def represent_pixel_location(self) -> Optional[numpy.ndarray]:\n        """"""\n        Returns a NumPy array that represents the 2D pixel location,\n        which is defined by PFNC, of the original image data.\n\n        You may use the returned NumPy array for a calculation to map the\n        original image to another format.\n\n        :return: A NumPy array that represents the 2D pixel location.\n        :rtype: numpy.ndarray\n        """"""\n        if self.data is None:\n            return None\n\n        #\n        return self._data.reshape(\n            self.height + self.y_padding,\n            int(self.width * self._nr_components + self.x_padding)\n        )\n\n    @property\n    def num_components_per_pixel(self) -> float:\n        """"""\n        The number of data components per pixel.\n\n        :getter: Returns itself.\n        :type: float\n        """"""\n        return self._nr_components\n\n    def __repr__(self):\n        return \'{0} x {1}, {2}, {3} elements,\\n{4}\'.format(\n            self.width,\n            self.height,\n            self.data_format,\n            self.data.size,\n            self.data\n        )\n\n    @property\n    def width(self) -> int:\n        """"""\n        The width of the data component in the buffer in number of pixels.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.width\n            else:\n                value = self._buffer.width\n        except GenericException:\n            try:\n                value = self._node_map.Width.value\n            except AttributeError:\n                value = 0\n        return value\n\n    @property\n    def height(self) -> int:\n        """"""\n        The height of the data component in the buffer in number of pixels.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.height\n            else:\n                value = self._buffer.height\n                if value == 0:\n                    value = self._buffer.delivered_image_height\n        except GenericException:\n            try:\n                value = self._node_map.Height.value\n            except AttributeError:\n                value = 0\n        return value\n\n    @property\n    def data_format_value(self) -> int:\n        """"""\n        The data type of the data component as integer value.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.data_format\n            else:\n                value = self._buffer.pixel_format\n        except GenericException:\n            value = self._node_map.PixelFormat.get_int_value()\n        assert type(value) is int\n        return value\n\n    @property\n    def data_format(self) -> str:\n        """"""\n        The data type of the data component as string.\n\n        :getter: Returns itself.\n        :type: str\n        """"""\n        return dict_by_ints[self.data_format_value]\n\n    @property\n    def delivered_image_height(self) -> int:\n        """"""\n        The image height of the data component.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.delivered_image_height\n            else:\n                value = self._buffer.delivered_image_height\n        except GenericException:\n            value = 0\n        return value\n\n    @property\n    def x_offset(self) -> int:\n        """"""\n        The X offset of the data in the buffer in number of pixels from the\n        image origin to handle areas of interest.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.x_offset\n            else:\n                value = self._buffer.offset_x\n        except GenericException:\n            value = self._node_map.OffsetX.value\n        return value\n\n    @property\n    def y_offset(self) -> int:\n        """"""\n        The Y offset of the data in the buffer in number of pixels from the\n        image origin to handle areas of interest.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.y_offset\n            else:\n                value = self._buffer.offset_y\n        except GenericException:\n            value = self._node_map.OffsetY.value\n        return value\n\n    @property\n    def x_padding(self) -> int:\n        """"""\n        The X padding of the data component in the buffer in number of pixels.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.x_padding\n            else:\n                value = self._buffer.padding_x\n        except GenericException:\n            value = 0\n        return value\n\n    @property\n    def y_padding(self) -> int:\n        """"""\n        The Y padding of the data component in the buffer in number of pixels.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            if self._part:\n                value = self._part.y_padding\n            else:\n                value = self._buffer.padding_y\n        except GenericException:\n            value = 0\n        return value\n\n    def has_part(self):\n        return self._part is not None\n\n    @property\n    def data_offset(self):\n        if self.has_part():\n            return self._part.data_offset\n        else:\n            return 0\n\n\nclass Buffer:\n    """"""\n    Is provided by an :class:`ImageAcquire` object when you call its\n    :meth:`~harvesters.core.ImageAcquirer.fetch_buffer` method. It provides\n    you a way to access acquired data and its relevant information.\n\n    Note that it will never be necessary to create this object by yourself\n    in general.\n    """"""\n    def __init__(\n            self, *,\n            buffer=None, node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__()\n\n        #\n        self._buffer = buffer\n        self._node_map = node_map\n\n        self._payload = self._build_payload(\n            buffer=buffer,\n            node_map=node_map,\n            logger=self._logger\n        )\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.queue()\n\n    def __repr__(self):\n        return \'{0}\'.format(self.payload.__repr__())\n\n    @property\n    def timestamp_ns(self) -> int:\n        """"""\n        The timestamp. The unit is [ns].\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        return self._buffer.timestamp_ns\n\n    @property\n    def timestamp(self) -> int:\n        """"""\n        The timestamp. The unit is GenTL Producer dependent.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        try:\n            timestamp = self._buffer.timestamp_ns\n        except GenericException:\n            try:\n                timestamp = self._buffer.timestamp\n            except GenericException:\n                timestamp = 0\n\n        return timestamp\n\n    @property\n    def timestamp_frequency(self) -> int:\n        """"""\n        The timestamp tick frequency which is used to represent a timestamp.\n        The unit is [Hz].\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        #\n        frequency = 1000000000  # Hz\n\n        try:\n            _ = self._buffer.timestamp_ns\n        except GenericException:\n            try:\n                frequency = self._buffer.parent.parent.timestamp_frequency\n            except GenericException:\n                try:\n                    frequency = self._node_map.GevTimestampTickFrequency.value\n                except GenericException:\n                    pass\n\n        return frequency\n\n    @property\n    def payload_type(self):\n        """"""\n        The payload type that the :class:`Buffer` object contains.\n\n        :getter: Returns itself.\n        :type: TODO\n        """"""\n\n        return self._buffer.payload_type\n\n    @property\n    def payload(self):\n        """"""\n        A containing object which derives from :class:`PayloadBase` class.\n\n        :getter: Returns itself.\n        :type: :class:`PayloadBase`\n        """"""\n        return self._payload\n\n    def queue(self):\n        """"""\n        Queues the buffer to prepare for the upcoming image acquisition. Once\n        the buffer is queued, the :class:`Buffer` object will be obsolete.\n        You\'ll have nothing to do with it.\n\n        Note that you have to return _the ownership of the fetched buffers to\n        the :class:`ImageAcquirer` object before stopping image acquisition\n        calling this method because the :class:`ImageAcquirer` object tries\n        to clear the self-allocated buffers when it stops image acquisition.\n        """"""\n        #\n        if _is_logging_buffer_manipulation:\n            self._logger.debug(\n                \'Queued Buffer module #{0}\'\n                \' containing frame #{1}\'\n                \' to DataStream module {2}\'\n                \' of Device module {3}\'\n                \'.\'.format(\n                    self._buffer.context,\n                    self._buffer.frame_id,\n                    self._buffer.parent.id_,\n                    self._buffer.parent.parent.id_\n                )\n            )\n\n        self._buffer.parent.queue_buffer(self._buffer)\n\n    @staticmethod\n    def _build_payload(\n            *,\n            buffer=None, node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        #\n        assert buffer\n        assert node_map\n\n        #\n        p_type = buffer.payload_type\n        if p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_UNKNOWN:\n            payload = PayloadUnknown(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_IMAGE or \\\n                buffer.payload_type == \\\n                PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_CHUNK_DATA:\n            payload = PayloadImage(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_RAW_DATA:\n            payload = PayloadRawData(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_FILE:\n            payload = PayloadFile(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_JPEG:\n            payload = PayloadJPEG(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_JPEG2000:\n            payload = PayloadJPEG2000(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_H264:\n            payload = PayloadH264(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_CHUNK_ONLY:\n            payload = PayloadChunkOnly(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        elif p_type == PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_MULTI_PART:\n            payload = PayloadMultiPart(\n                buffer=buffer, node_map=node_map, logger=logger\n            )\n        else:\n            payload = None\n\n        return payload\n\n\nclass PayloadBase:\n    """"""\n    Is a base class of various payload types. The types are defined by the\n    GenTL Standard. In general, you should not have to design a class that\n    derives from this base class.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            logger: Optional[Logger] = None):\n        """"""\n        :param buffer:\n        :param logger:\n        """"""\n        #\n        assert buffer\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__()\n\n        self._buffer = buffer\n        self._components = []\n\n    @property\n    def payload_type(self):\n        """"""\n        The type of the payload.\n\n        :getter: Returns itself.\n        :type: :class:`genicam.gentl.PAYLOADTYPE_INFO_IDS`\n        """"""\n        return self._buffer.payload_type\n\n    def _build_component(\n            self,\n            buffer=None, part=None, node_map: Optional[NodeMap] = None):\n        #\n        try:\n            if part:\n                data_format = part.data_format\n            else:\n                data_format = buffer.pixel_format\n        except GenericException:\n            # As a workaround, we are going to retrive a data format\n            # value from the remote device node map; note that there\n            # could be a case where the value is not synchronized with\n            # the delivered buffer; in addition, note that it:\n            if node_map:\n                name = node_map.PixelFormat.value\n                if name in dict_by_names:\n                    data_format = dict_by_names[name]\n                else:\n                    raise\n            else:\n                raise\n\n        symbolic = dict_by_ints[data_format]\n        if symbolic in component_2d_formats:\n            return Component2DImage(\n                buffer=buffer, part=part, node_map=node_map,\n                logger=self._logger\n            )\n\n        return None\n\n    @property\n    def components(self):\n        """"""\n        A :class:`list` containing objects that derive from\n        :const:`ComponentBase` class.\n\n        :getter: Returns itself.\n        :type: ComponentBase\n        """"""\n        return self._components\n\n\nclass PayloadUnknown(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_UNKNOWN`\n    by the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadImage(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_IMAGE` by\n    the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n        # Build data components.\n        self._components.append(\n            self._build_component(\n                buffer=buffer, node_map=node_map\n            )\n        )\n\n    def __repr__(self):\n        return \'{0}\'.format(self.components[0].__repr__())\n\n\nclass PayloadRawData(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_RAW_DATA`\n    by the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadFile(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_FILE` by\n    the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadJPEG(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_JPEG` by\n    the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadJPEG2000(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_JPEG2000`\n    by the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadH264(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_H264` by\n    the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadChunkOnly(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_CHUNK_ONLY`\n    by the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer: Optional[Buffer] = None,\n            node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n\n\nclass PayloadMultiPart(PayloadBase):\n    """"""\n    Represents a payload that is classified as\n    :const:`genicam.gentl.PAYLOADTYPE_INFO_IDS.PAYLOAD_TYPE_MULTI_PART`\n    by the GenTL Standard.\n    """"""\n    def __init__(\n            self, *,\n            buffer=None, node_map: Optional[NodeMap] = None,\n            logger: Optional[Logger] = None):\n        """"""\n\n        :param buffer:\n        :param node_map:\n        :param logger:\n        """"""\n\n        #\n        assert buffer\n        assert node_map\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__(buffer=buffer, logger=self._logger)\n        #\n\n        # Build data components.\n        # We know the buffer consists of a set of ""part"" that is\n        # defined by the GenTL standard.\n        for i, part in enumerate(self._buffer.parts):\n            self._components.append(\n                self._build_component(\n                    buffer=buffer, part=part, node_map=node_map\n                )\n            )\n\n    def __repr__(self):\n        ret = \'\'\n        for i, c in enumerate(self.components):\n            ret += \'Component #{0}: {1}\\n\'.format(i, c.__repr__())\n        ret = ret[:-1]\n        return ret\n\n\nclass Callback:\n    """"""\n    Is used as a base class to implement user defined callback behavior.\n    """"""\n    def emit(self, context: Optional[object] = None) -> None:\n        """"""\n        Is called when a specific condition is met.\n\n        This method is abstract and should be reimplemented in any sub-class.\n\n        :return: None.\n        """"""\n        raise NotImplementedError\n\n\nclass ImageAcquirer:\n    """"""\n    Manages everything you need to acquire images from the connecting device.\n    """"""\n\n    #\n    _event = Event()\n    _specialized_tl_type = [\'U3V\', \'GEV\']\n\n    class Events(IntEnum):\n        TURNED_OBSOLETE = 0,\n        NEW_BUFFER_AVAILABLE = 1,\n        RETURN_ALL_BORROWED_BUFFERS = 2,\n        READY_TO_STOP_ACQUISITION = 3,\n\n    def _create_acquisition_thread(self) -> _ImageAcquisitionThread:\n        return _ImageAcquisitionThread(\n            image_acquire=self, logger=self._logger\n        )\n\n    def __init__(\n            self, *, device=None,\n            profiler=None, logger: Optional[Logger] = None,\n            sleep_duration: float = _sleep_duration_default,\n            file_path: Optional[str] = None\n    ):\n        """"""\n\n        :param device:\n        :param profiler:\n        :param logger:\n        :param sleep_duration:\n        :param file_path: Set a path to camera description file which you want to load on the target node map instead of the one which the device declares.\n        """"""\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        assert device\n\n        #\n        super().__init__()\n\n        #\n        interface = device.parent\n        system = interface.parent\n\n        env_var = \'HARVESTERS_XML_FILE_DIR\'\n        if env_var in os.environ:\n            self._xml_dir = os.getenv(env_var)\n        else:\n            self._xml_dir = None\n\n        #\n        exceptions = (GenericException, LogicalErrorException)\n\n        self._system = None\n        self._interface = None\n        self._device = None\n        self._remote_device = None\n\n        sources = [system, interface, device, device]\n        ports = [\n            system.port, interface.port, device.local_port, device.remote_port\n        ]\n        destinations = [\n            \'_system\', \'_interface\', \'_device\', \'_remote_device\'\n        ]\n        ctors = [System, Interface, Device, RemoteDevice]\n        parents = [None, self._system, self._interface, self._device]\n        file_paths = [None, None, None, file_path]\n\n        for (ctor, destination, file_path_, parent, port, source) in \\\n                zip(ctors, destinations, file_paths, parents, ports, sources):\n            #\n            try:\n                node_map = _get_port_connected_node_map(\n                    port=port, logger=self._logger,\n                    xml_dir_to_store=self._xml_dir, file_path=file_path_\n                )\n            except exceptions as e:\n                # Accept a case where the target GenTL entity does not\n                # provide any device description XML file:\n                self._logger.error(e, exc_info=True)\n                node_map = None\n            #\n            setattr(\n                self, destination, ctor(\n                    module=source, node_map=node_map, parent=parent\n                )\n            )\n\n        if self._remote_device:\n            # Providing an device description file is mandatory for\n            # a GenICam compliant cameras (= remote devices):\n            assert self._remote_device.node_map\n\n        #\n        self._data_streams = []\n        self._event_new_buffer_managers = []\n\n        self._create_ds_at_connection = True\n        if self._create_ds_at_connection:\n            self._setup_data_streams()\n\n        #\n        self._profiler = profiler\n\n        #\n        self._num_filled_buffers_to_hold = 1\n        self._queue = Queue(maxsize=self._num_filled_buffers_to_hold)\n\n        #\n        self._sleep_duration = sleep_duration\n        self._thread_image_acquisition = self._create_acquisition_thread()\n\n        # Prepare handling the SIGINT event:\n        self._threads = []\n        self._threads.append(self._thread_image_acquisition)\n\n        # Create a signal handler if it\'s being run in the main thread:\n        self._sigint_handler = None\n        if current_thread() is main_thread():\n            self._sigint_handler = _SignalHandler(\n                event=self._event, threads=self._threads, logger=self._logger\n            )\n            signal.signal(signal.SIGINT, self._sigint_handler)\n            self._logger.info(\'Created a signal handler for SIGINT.\')\n\n        #\n        self._num_images_to_acquire = -1\n\n        #\n        self._timeout_for_image_acquisition = 1  # ms\n\n        #\n        self._statistics = Statistics()\n\n        #\n        self._announced_buffers = []\n\n        #\n        self._has_acquired_1st_image = False\n        self._is_acquiring = False\n        self._buffer_handling_mode = \'OldestFirstOverwrite\'\n\n        # Determine the default value:\n        num_buffers_default = 16\n        try:\n            self._min_num_buffers = self._data_streams[0].buffer_announce_min\n        except InvalidParameterException as e:\n            # In general, a GenTL Producer should not raise the\n            # InvalidParameterException to the inquiry for\n            # STREAM_INFO_BUF_ANNOUNCE_MIN because it is totally legal\n            # but we have observed a fact that there is at least one on\n            # the market. As a workaround we involve this try-except block:\n            self._logger.debug(e, exc_info=True)\n            self._min_num_buffers = num_buffers_default\n            self._num_buffers = num_buffers_default\n        else:\n            self._num_buffers = max(\n                num_buffers_default, self._min_num_buffers\n            )\n\n        #\n        self._logger.info(\n            \'Instantiated an ImageAcquirer object for {0}.\'.format(\n                self._device.id_\n            )\n        )\n\n        #\n        self._chunk_adapter = self._get_chunk_adapter(\n            device=self.device, node_map=self.remote_device.node_map\n        )\n\n        #\n        self._finalizer = weakref.finalize(self, self.destroy)\n\n        #\n        self._supported_events = [\n            self.Events.TURNED_OBSOLETE,\n            self.Events.RETURN_ALL_BORROWED_BUFFERS,\n            self.Events.READY_TO_STOP_ACQUISITION,\n            self.Events.NEW_BUFFER_AVAILABLE\n        ]\n        self._callback_dict = dict()\n        for event in self._supported_events:\n            self._callback_dict[event] = None\n\n    def _emit_callbacks(self, event: Events) -> None:\n        callbacks = self._callback_dict[event]\n        if isinstance(callbacks, Iterable):\n            for callback in callbacks:\n                self._emit_callback(callback)\n        else:\n            callback = callbacks\n            self._emit_callback(callback)\n\n    def _emit_callback(\n            self,\n            callback: Optional[Union[Callback, List[Callback]]]) -> None:\n        if callback:\n            if isinstance(callback, Callback):\n                callback.emit(context=self)\n            else:\n                raise TypeError\n\n    def _check_validity(self, event: Events):\n        if event not in self._supported_events:\n            raise ValueError\n\n    def add_callback(self, event: Events, callback: Callback):\n        self._check_validity(event)\n        assert callback\n        self._callback_dict[event] = callback\n\n    def remove_callback(self, event: Events):\n        self._check_validity(event)\n        self._callback_dict[event] = None\n\n    def remove_callbacks(self):\n        for event in self._supported_events:\n            self._callback_dict[event] = None\n\n    @property\n    def supported_events(self):\n        return self._supported_events\n\n    @staticmethod\n    def _get_chunk_adapter(\n            *, device=None, node_map: Optional[NodeMap] = None):\n        if device.tl_type == \'U3V\':\n            return ChunkAdapterU3V(node_map)\n        elif device.tl_type == \'GEV\':\n            return ChunkAdapterGEV(node_map)\n        else:\n            return ChunkAdapterGeneric(node_map)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self._finalizer()\n\n    def destroy(self) -> None:\n        """"""\n        Destroys itself; releases all preserved external resources such as\n        buffers or the connected remote device.\n\n        :return: None\n        """"""\n        id_ = None\n        if self.device:\n            #\n            self.stop_acquisition()\n            #\n            self._release_data_streams()\n            #\n            id_ = self._device.id_\n            #\n            if self.remote_device.node_map:\n                self.remote_device.node_map.disconnect()\n            #\n            if self._device.is_open():\n                self._device.close()\n\n        self._device = None\n\n        #\n        if id_:\n            self._logger.info(\n                \'Destroyed the ImageAcquirer object which {0} \'\n                \'had belonged to.\'.format(id_)\n            )\n        else:\n            self._logger.info(\n                \'Destroyed an ImageAcquirer.\'\n            )\n\n        if self._profiler:\n            self._profiler.print_diff()\n\n        #\n        self._emit_callbacks(self.Events.TURNED_OBSOLETE)\n\n    @property\n    def buffer_handling_mode(self) -> str:\n        """"""\n        The buffer handling mode that\'s been applied.\n\n        :getter: Returns itself.\n        :setter: Overwrites itself with the given value.\n        :type: str\n        """"""\n        return self._buffer_handling_mode\n\n    @buffer_handling_mode.setter\n    def buffer_handling_mode(self, value):\n        self._buffer_handling_mode = value\n\n    @property\n    def num_buffers(self) -> int:\n        """"""\n        The number of buffers that is prepared for the image acquisition\n        process. The buffers will be announced to the target GenTL Producer.\n\n        :getter: Returns itself.\n        :setter: Overwrites itself with the given value.\n        :type: int\n        """"""\n        return self._num_buffers\n\n    @num_buffers.setter\n    def num_buffers(self, value: int = 1):\n        #\n        if value >= self._min_num_buffers:\n            self._num_buffers = value\n        else:\n            raise ValueError(\n                \'The number of buffers must be \'\n                \'greater than or equal to {0}\'.format(\n                    self._min_num_buffers\n                )\n            )\n\n    @property\n    def sleep_duration(self) -> float:\n        """"""\n        The duration that lets the image acquisition thread sleeps at\n        every execution. The unit is [ms].\n\n        :getter: Returns itself.\n        :type: float\n        """"""\n        return self._sleep_duration\n\n    @property\n    def min_num_buffers(self) -> int:\n        """"""\n        The minimum number of the buffers for image acquisition. You have to\n        set a value to :meth:`num_buffers` so that is greater than or equal\n        to this.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        return self._min_num_buffers\n\n    @property\n    def num_filled_buffers_to_hold(self) -> int:\n        """"""\n        The number of buffers that is used for a case where the image\n        acquisition process runs in the background. You will fetch buffers\n        from the buffers when you call the :meth:`fetch_buffer` method in a\n        case you started the image acquisition passing :const:`True` to\n        :data:`run_in_background` of the :meth:`start_acquisition` method.\n\n        :getter: Returns itself.\n        :setter: Overwrites itself with the given value.\n        :type: int\n        """"""\n        return self._num_filled_buffers_to_hold\n\n    @num_filled_buffers_to_hold.setter\n    def num_filled_buffers_to_hold(self, value: int = 1):\n        if value > 0:\n            # Update the value:\n            self._num_filled_buffers_to_hold = value\n\n            # Move the stored buffers to the temporary list object:\n            buffers = []\n            while not self._queue.empty():\n                buffers.append(\n                    self._queue.get_nowait()\n                )\n\n            # Newly create a Queue object:\n            self._queue = Queue(maxsize=self._num_filled_buffers_to_hold)\n\n            # Move the buffers back to the newly created Queue object:\n            while len(buffers) > 0:\n                try:\n                    self._queue.put(buffers.pop(0))\n                except Full as e:\n                    # Can\'t put it because the queue is full.\n                    # Discard the buffer:\n                    self._logger.debug(e, exc_info=True)\n                    buffer = buffers.pop(0)\n                    buffer.parent.queue_buffer(buffer)\n\n        else:\n            raise ValueError(\n                \'The number of filled buffers to hold must be > 0.\'\n            )\n\n    @property\n    def num_holding_filled_buffers(self) -> int:\n        """"""\n        The number of available buffers, i.e., the buffers that contain\n        images.\n\n        :getter: Returns itself.\n        :type: int\n        """"""\n        return self._queue.qsize()\n\n    @property\n    def data_streams(self) -> List[DataStream]:\n        """"""\n        A list of GenTL :class:`DataStream` objects that the\n        :class:`ImageAcquire` object is working with.\n\n        :getter: Returns itself.\n        :type: The associative :class:`DataStream` object.\n        """"""\n        return self._data_streams\n\n    @property\n    def remote_device(self) -> RemoteDevice:\n        """"""\n        The remote GenTL :class:`Device` object, typically a camera, that the\n        :class:`ImageAcquire` object is working with.\n\n        :getter: Returns itself.\n        :type: RemoteDevice\n        """"""\n        return self._remote_device\n\n    @property\n    def device(self) -> Device:\n        """"""\n        The local GenTL :class:`Device` proxy object that the\n        :class:`ImageAcquire` object is working with.\n\n        :getter: Returns itself.\n        :type: Device\n        """"""\n        return self._device\n\n    @property\n    def interface(self) -> Interface:\n        """"""\n        The GenTL :class:`Interface` object that the\n        :class:`ImageAcquire` object is working with.\n\n        :getter: Returns itself.\n        :type: Interface\n        """"""\n        return self._interface\n\n    @property\n    def system(self) -> System:\n        """"""\n        The GenTL :class:`System` object that the\n        :class:`ImageAcquire` object is working with.\n\n        :getter: Returns itself.\n        :type: System\n        """"""\n        return self._system\n\n    def is_acquiring_images(self):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.is_acquiring_images, self.is_acquiring)\n        return self.is_acquiring()\n\n    def is_acquiring(self) -> bool:\n        """"""\n        Returns the truth value of a proposition: It\'s acquiring images.\n\n        :return: :const:`True` if it\'s acquiring images. Otherwise :const:`False`.\n        :rtype: bool\n        """"""\n        return self._is_acquiring\n\n    @property\n    def timeout_for_image_acquisition(self) -> int:\n        """"""\n        The unit is [ms].\n\n        :getter:\n        :setter:\n        :type: int\n        """"""\n        return self._timeout_for_image_acquisition\n\n    @timeout_for_image_acquisition.setter\n    def timeout_for_image_acquisition(self, ms):\n        self._timeout_for_image_acquisition = ms\n\n    @property\n    def thread_image_acquisition(self) -> ThreadBase:\n        """"""\n        The thread object that runs image acquisition.\n\n        :getter: Returns itself.\n        :setter: Overwrites itself with the given value.\n        :type: :class:`ThreadBase`\n        """"""\n        return self._thread_image_acquisition\n\n    @thread_image_acquisition.setter\n    def thread_image_acquisition(self, obj):\n        self._thread_image_acquisition = obj\n        self._thread_image_acquisition.worker = self.worker_image_acquisition\n\n    @property\n    def statistics(self) -> Statistics:\n        """"""\n        The statistics about image acquisition.\n\n        :getter: Returns itself.\n        :type: :class:`Statistics`\n        """"""\n        return self._statistics\n\n    def _setup_data_streams(self):\n        for i, stream_id in enumerate(self._device.data_stream_ids):\n            #\n            _data_stream = self._device.create_data_stream()\n\n            try:\n                _data_stream.open(stream_id)\n            except GenericException as e:\n                self._logger.debug(e, exc_info=True)\n            else:\n                self._logger.info(\n                    \'Opened DataStream module {0} of {1}.\'.format(\n                        _data_stream.id_, _data_stream.parent.id_\n                    )\n                )\n\n            #\n            exceptions = (GenericException, LogicalErrorException)\n            try:\n                node_map = _get_port_connected_node_map(\n                    port=_data_stream.port, logger=self._logger\n                )\n            except exceptions as e:\n                # Accept a case where the target GenTL entity does not\n                # provide any device description XML file:\n                self._logger.error(e, exc_info=True)\n                node_map = None\n\n            self._data_streams.append(\n                DataStream(\n                    module=_data_stream, node_map=node_map,\n                    parent=self._device\n                )\n            )\n            # Create an Event Manager object for image acquisition.\n            event_token = self._data_streams[i].register_event(\n                EVENT_TYPE_LIST.EVENT_NEW_BUFFER\n            )\n            self._event_new_buffer_managers.append(\n                EventManagerNewBuffer(event_token)\n            )\n\n    def start_image_acquisition(self, run_in_background=False):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.start_image_acquisition, self.start_acquisition)\n        self.start_acquisition(run_in_background=run_in_background)\n\n    def start_acquisition(self, run_in_background: bool = False) -> None:\n        """"""\n        Starts image acquisition.\n\n        :param run_in_background: Set `True` if you want to let the ImageAcquire keep acquiring images in the background and the images you get calling `fetch_buffer` will be from the ImageAcquirer. Otherwise, the images will directly come from the target GenTL Producer.\n\n        :return: None.\n        """"""\n        if not self._create_ds_at_connection:\n            self._setup_data_streams()\n\n        #\n        num_required_buffers = self._num_buffers\n        for data_stream in self._data_streams:\n            try:\n                num_buffers = data_stream.buffer_announce_min\n                if num_buffers < num_required_buffers:\n                    num_buffers = num_required_buffers\n            except GenericException as e:\n                num_buffers = num_required_buffers\n                self._logger.debug(e, exc_info=True)\n\n            if data_stream.defines_payload_size():\n                buffer_size = data_stream.payload_size\n            else:\n                buffer_size = self.remote_device.node_map.PayloadSize.value\n\n            raw_buffers = self._create_raw_buffers(\n                num_buffers, buffer_size\n            )\n\n            buffer_tokens = self._create_buffer_tokens(\n                raw_buffers\n            )\n\n            self._announced_buffers = self._announce_buffers(\n                data_stream=data_stream, _buffer_tokens=buffer_tokens\n            )\n\n            self._queue_announced_buffers(\n                data_stream=data_stream, buffers=self._announced_buffers\n            )\n\n        # Reset the number of images to acquire.\n        try:\n            acq_mode = self.remote_device.node_map.AcquisitionMode.value\n            if acq_mode == \'Continuous\':\n                num_images_to_acquire = -1\n            elif acq_mode == \'SingleFrame\':\n                num_images_to_acquire = 1\n            elif acq_mode == \'MultiFrame\':\n                num_images_to_acquire = \\\n                    self.remote_device.node_map.AcquisitionFrameCount.value\n            else:\n                num_images_to_acquire = -1\n        except GenericException as e:\n            # The node doesn\'t exist.\n            num_images_to_acquire = -1\n            self._logger.debug(e, exc_info=True)\n\n        self._num_images_to_acquire = num_images_to_acquire\n\n        try:\n            # We\'re ready to start image acquisition. Lock the device\'s\n            # transport layer related features:\n            self.remote_device.node_map.TLParamsLocked.value = 1\n        except GenericException:\n            # SFNC < 2.0\n            pass\n\n        # Start image acquisition.\n        self._is_acquiring = True\n\n        for data_stream in self._data_streams:\n            data_stream.start_acquisition(\n                ACQ_START_FLAGS_LIST.ACQ_START_FLAGS_DEFAULT,\n                self._num_images_to_acquire\n            )\n\n        #\n        if run_in_background:\n            if self.thread_image_acquisition:\n                self.thread_image_acquisition.start()\n\n        #\n        self.remote_device.node_map.AcquisitionStart.execute()\n\n        self._logger.info(\n            \'{0} started image acquisition.\'.format(self._device.id_)\n        )\n\n        if self._profiler:\n            self._profiler.print_diff()\n\n    def worker_image_acquisition(self) -> None:\n        """"""\n        The worker method of the image acquisition task.\n\n        :return: None\n        """"""\n        #\n        queue = self._queue\n\n        #\n        for event_manager in self._event_new_buffer_managers:\n            try:\n                if self.is_acquiring():\n                    event_manager.update_event_data(\n                        self._timeout_for_image_acquisition\n                    )\n                else:\n                    return\n            except TimeoutException:\n                continue\n            else:\n                # Check if the delivered buffer is complete:\n                if event_manager.buffer.is_complete():\n                    #\n                    if _is_logging_buffer_manipulation:\n                        self._logger.debug(\n                            \'Acquired Buffer module #{0}\'\n                            \' containing frame #{1}\'\n                            \' from DataStream module {2}\'\n                            \' of Device module {3}\'\n                            \'.\'.format(\n                                event_manager.buffer.context,\n                                event_manager.buffer.frame_id,\n                                event_manager.parent.id_,\n                                event_manager.parent.parent.id_\n                            )\n                        )\n                    #\n                    if self.buffer_handling_mode == \'OldestFirstOverwrite\':\n                        # We want to keep the latest ones:\n                        with MutexLocker(self.thread_image_acquisition):\n                            if not self._is_acquiring:\n                                return\n\n                            if queue.full():\n                                # Pick up the oldest one:\n                                _buffer = queue.get()\n\n                                if _is_logging_buffer_manipulation:\n                                    self._logger.debug(\n                                        \'Queued Buffer module #{0}\'\n                                        \' containing frame #{1}\'\n                                        \' to DataStream module {2}\'\n                                        \' of Device module {3}\'\n                                        \'.\'.format(\n                                            _buffer.context,\n                                            _buffer.frame_id,\n                                            _buffer.parent.id_,\n                                            _buffer.parent.parent.id_\n                                        )\n                                    )\n                                # Then discard/queue it:\n                                _buffer.parent.queue_buffer(_buffer)\n\n                            # Get the latest buffer:\n                            _buffer = event_manager.buffer\n\n                            # Then append it to the list which the user\n                            # fetches later:\n                            queue.put(_buffer)\n\n                            # Then update the statistics using the buffer:\n                            self._update_statistics(_buffer)\n                    else:\n                        # Get the latest buffer:\n                        _buffer = event_manager.buffer\n\n                        # Then update the statistics using the buffer:\n                        self._update_statistics(_buffer)\n\n                        # We want to keep the oldest ones:\n                        with MutexLocker(self.thread_image_acquisition):\n                            #\n                            if not self._is_acquiring:\n                                return\n\n                            #\n                            if queue.full():\n                                # We have not space to keep the latest one.\n                                # Discard/queue the latest buffer:\n                                _buffer.parent.queue_buffer(_buffer)\n                            else:\n                                # Just append it to the list:\n                                if queue:\n                                    queue.put(_buffer)\n\n                    # Call the registered callback:\n                    self._emit_callbacks(self.Events.NEW_BUFFER_AVAILABLE)\n\n                    #\n                    self._update_num_images_to_acquire()\n\n                else:\n                    # Discard/queue the latest buffer when incomplete\n                    self._logger.debug(\n                        \'Acquired buffer is complete: {0}\'.format(\n                            event_manager.buffer.is_complete()\n                        )\n                    )\n\n                    # Queue the incomplete buffer; we have nothing to do\n                    # with it:\n                    data_stream = event_manager.buffer.parent\n                    data_stream.queue_buffer(event_manager.buffer)\n\n                    #\n                    with MutexLocker(self.thread_image_acquisition):\n                        if not self._is_acquiring:\n                            return\n\n    def _update_chunk_data(self, buffer: Optional[Buffer] = None):\n        try:\n            if buffer.num_chunks == 0:\n                """"""\n                self._logger.debug(\n                    \'The buffer does not contain any chunk data.\'\n                )\n                """"""\n                return\n        except (ParsingChunkDataException, ErrorException) as e:\n            #self._logger.error(e, exc_info=True)\n            pass\n        except (\n                NotImplementedException, NoDataException,\n                InvalidBufferException\n            ) as e:\n            #self._logger.debug(e, exc_info=True)\n            pass\n        else:\n            """"""\n            self._logger.debug(\n                \'The buffer contains chunk data.\'\n            )\n            """"""\n\n            #\n            is_generic = False\n            if buffer.tl_type not in self._specialized_tl_type:\n                is_generic = True\n\n            try:\n                if is_generic:\n                    self._chunk_adapter.attach_buffer(\n                        buffer.raw_buffer, buffer.chunk_data_info_list\n                    )\n                else:\n                    self._chunk_adapter.attach_buffer(buffer.raw_buffer)\n            except GenericException as e:\n                # Failed to parse the chunk data. Something must be wrong.\n                self._logger.error(e, exc_info=True)\n            else:\n                """"""\n                self._logger.debug(\n                    \'Updated the node map of {0}.\'.format(\n                        buffer.parent.parent.id_\n                    )\n                )\n                """"""\n                pass\n\n    def fetch_buffer(\n            self, *,\n            timeout: float = 0, is_raw: bool = False,\n            cycle_s: float = None) -> Optional[Buffer]:\n        """"""\n        Fetches an available :class:`Buffer` object that has been filled up\n        with a single image and returns it.\n\n        :param timeout: Set the period that defines the expiration for an available buffer delivery; if no buffer is fetched within the period then TimeoutException will be raised. The unit is [s].\n        :param is_raw: Set :const:`True` if you need a raw GenTL Buffer module; note that you\'ll have to manipulate the object by yourself.\n        :param cycle_s: Set the cycle that defines how frequently check if a buffer is available. The unit is [s].\n\n        :return: A :class:`Buffer` object.\n        :rtype: Buffer\n        """"""\n        #\n        if not self.is_acquiring():\n            # Does not make any sense. Raise TimeoutException:\n            raise TimeoutException\n\n        #\n        _buffer = None\n\n        watch_timeout = True if timeout > 0 else False\n        base = time.time()\n\n        if self.thread_image_acquisition and \\\n                self.thread_image_acquisition.is_running():\n            # Case #1:\n            if cycle_s:\n                # Use the specified cycle:\n                _cycle_s = cycle_s\n            else:\n                # Use the library default value:\n                _cycle_s = 0.0001\n\n            while _buffer is None:\n                # Expired the suggested period; give it up:\n                """"""\n                if watch_timeout and (time.time() - base) > timeout:\n                    raise TimeoutException\n                """"""\n\n                with MutexLocker(self.thread_image_acquisition):\n                    try:\n                        _buffer = self._queue.get(\n                            block=True, timeout=_cycle_s\n                        )\n                    except Empty:\n                        continue\n        else:\n            # Case #2:\n            #\n            event_manager = self._event_new_buffer_managers[0]\n            while _buffer is None:\n                # Expired the suggested period; give it up:\n                if watch_timeout and (time.time() - base) > timeout:\n                    raise TimeoutException\n                #\n                try:\n                    event_manager.update_event_data(\n                        self._timeout_for_image_acquisition\n                    )\n                except TimeoutException:\n                    continue\n                else:\n                    # Check if the delivered buffer is complete:\n                    if event_manager.buffer.is_complete():\n                        #\n                        if _is_logging_buffer_manipulation:\n                            self._logger.debug(\n                                \'Acquired Buffer module #{0}\'\n                                \' containing frame #{1}\'\n                                \' from DataStream module {2}\'\n                                \' of Device module {3}\'\n                                \'.\'.format(\n                                    event_manager.buffer.context,\n                                    event_manager.buffer.frame_id,\n                                    event_manager.parent.id_,\n                                    event_manager.parent.parent.id_\n                                )\n                            )\n\n                    # Get the latest buffer:\n                    _buffer = event_manager.buffer\n\n        if _buffer:\n            #\n            self._update_chunk_data(buffer=_buffer)\n\n            # Then update the statistics using the buffer:\n            self._update_statistics(_buffer)\n\n            #\n            if not is_raw:\n                _buffer = Buffer(\n                    buffer=_buffer,\n                    node_map=self.remote_device.node_map,\n                    logger=self._logger\n                )\n\n        #\n        self._update_num_images_to_acquire()\n\n        return _buffer\n\n    def _update_num_images_to_acquire(self) -> None:\n        #\n        if self._num_images_to_acquire >= 1:\n            self._num_images_to_acquire -= 1\n\n        #\n        if self._num_images_to_acquire == 0:\n            #\n            self._emit_callbacks(self.Events.READY_TO_STOP_ACQUISITION)\n\n    def _update_statistics(self, buffer) -> None:\n        #\n        assert buffer\n\n        #\n        self._statistics.increment_num_images()\n        self._statistics.update_timestamp(buffer)\n\n    @staticmethod\n    def _create_raw_buffers(\n            num_buffers: int = 0, size: int = 0) -> List[bytes]:\n        #\n        assert num_buffers >= 0\n        assert size >= 0\n\n        # Instantiate a list object.\n        raw_buffers = []\n\n        # Append bytes objects to the list.\n        # The number is specified by num_buffer and the buffer size is\n        # specified by size.\n        for _ in range(num_buffers):\n            raw_buffers.append(bytes(size))\n\n        # Then return the list.\n        return raw_buffers\n\n    @staticmethod\n    def _create_buffer_tokens(raw_buffers: List[bytes] = None):\n        #\n        assert raw_buffers\n\n        # Instantiate a list object.\n        _buffer_tokens = []\n\n        # Append Buffer Token object to the list.\n        for i, buffer in enumerate(raw_buffers):\n            _buffer_tokens.append(\n                BufferToken(buffer, i)\n            )\n\n        # Then returns the list.\n        return _buffer_tokens\n\n    def _announce_buffers(\n            self,\n            data_stream: DataStream = None,\n            _buffer_tokens: List[BufferToken] = None) -> List[Buffer]:\n        #\n        assert data_stream\n\n        #\n        announced_buffers = []\n\n        # Iterate announcing buffers in the Buffer Tokens.\n        for token in _buffer_tokens:\n            # Get an announced buffer.\n            announced_buffer = data_stream.announce_buffer(token)\n\n            # And append it to the list.\n            announced_buffers.append(announced_buffer)\n\n            #\n            self._logger.debug(\n                \'Announced Buffer #{0} to DataStraem {1}.\'.format(\n                    announced_buffer.context,\n                    data_stream.id_\n                )\n            )\n\n        # Then return the list of announced Buffer objects.\n        return announced_buffers\n\n    def _queue_announced_buffers(\n            self,\n            data_stream: Optional[DataStream] = None,\n            buffers: Optional[List[Buffer]] = None) -> None:\n        #\n        assert data_stream\n\n        #\n        for buffer in buffers:\n            data_stream.queue_buffer(buffer)\n            self._logger.debug(\n                \'Queued Buffer module #{0}\'\n                \' to DataStream module {1}\'\n                \' of Device module {2}\'\n                \'.\'.format(\n                    buffer.context,\n                    data_stream.id_,\n                    data_stream.parent.id_\n                )\n            )\n\n    def stop_image_acquisition(self):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.stop_image_acquisition, self.stop_acquisition)\n        self.stop_acquisition()\n\n    def stop_acquisition(self) -> None:\n        """"""\n        Stops image acquisition.\n\n        :return: None.\n        """"""\n        if self.is_acquiring():\n            #\n            self._is_acquiring = False\n\n            #\n            if self.thread_image_acquisition.is_running():\n                self.thread_image_acquisition.stop()\n                self.thread_image_acquisition.join()\n\n            with MutexLocker(self.thread_image_acquisition):\n                #\n                self.remote_device.node_map.AcquisitionStop.execute()\n\n                try:\n                    # Unlock TLParamsLocked in order to allow full device\n                    # configuration:\n                    self.remote_device.node_map.TLParamsLocked.value = 0\n                except GenericException:\n                    # SFNC < 2.0\n                    pass\n\n                for data_stream in self._data_streams:\n                    # Stop image acquisition.\n                    try:\n                        data_stream.stop_acquisition(\n                            ACQ_STOP_FLAGS_LIST.ACQ_STOP_FLAGS_KILL\n                        )\n                    except GenericException as e:\n                        self._logger.error(e, exc_info=True)\n\n                    # Flash the queue for image acquisition process.\n                    self._flush_buffers(data_stream)\n\n                for event_manager in self._event_new_buffer_managers:\n                    event_manager.flush_event_queue()\n\n                if self._create_ds_at_connection:\n                    self._release_buffers()\n                else:\n                    self._release_data_streams()\n\n            #\n            self._has_acquired_1st_image = False\n\n            #\n            self._chunk_adapter.detach_buffer()\n\n            #\n            self._logger.info(\n                \'{0} stopped image acquisition.\'.format(self._device.id_)\n            )\n\n        if self._profiler:\n            self._profiler.print_diff()\n\n    def _flush_buffers(self, data_stream: DataStream) -> None:\n        # Notify the client that he has to return/queue buffers back:\n        self._emit_callbacks(\n            self.Events.RETURN_ALL_BORROWED_BUFFERS\n        )\n        data_stream.flush_buffer_queue(\n            ACQ_QUEUE_TYPE_LIST.ACQ_QUEUE_ALL_DISCARD\n        )\n\n    def _release_data_streams(self) -> None:\n        #\n        self._release_buffers()\n\n        #\n        for data_stream in self._data_streams:\n            if data_stream and data_stream.is_open():\n                name_ds = data_stream.id_\n                name_dev = data_stream.parent.id_\n                data_stream.close()\n                self._logger.info(\n                    \'Closed DataStream module {0} of {1}.\'.format(\n                        name_ds, name_dev\n                    )\n                )\n\n        #\n        self._data_streams.clear()\n        self._event_new_buffer_managers.clear()\n\n    def _release_buffers(self) -> None:\n        #\n        for data_stream in self._data_streams:\n            if data_stream.is_open():\n                #\n                for buffer in self._announced_buffers:\n                    self._logger.debug(\n                        \'Revoked Buffer module #{0}.\'.format(\n                            buffer.context,\n                            data_stream.id_,\n                            data_stream.parent.id_\n                        )\n                    )\n                    _ = data_stream.revoke_buffer(buffer)\n\n        self._announced_buffers.clear()\n\n        # Flush the queue; we don\'t need the buffers anymore:\n        while not self._queue.empty():\n            _ = self._queue.get_nowait()\n\n\ndef _retrieve_file_path(\n        *,\n        port: Optional[Port] = None,\n        url: Optional[str] = None,\n        file_path_to_load: Optional[str] = None,\n        logger: Optional[Logger] = None,\n        xml_dir_to_store: Optional[str] = None):\n    #\n    _logger = logger or get_logger(name=__name__)\n\n    #\n    if file_path_to_load:\n        # A file that is specified by the client will be used:\n        if not os.path.exists(file_path_to_load):\n            raise LogicalErrorException(\n                \'{0} does not exist.\'.format(file_path_to_load)\n            )\n    else:\n        if url is None:\n            # Inquire its URL information.\n            if len(port.url_info_list) > 0:\n                url = port.url_info_list[0].url\n            else:\n                raise LogicalErrorException(\n                    \'The target port does not hold any URL.\'\n                )\n\n        _logger.info(\'URL: {0}\'.format(url))\n\n        # And parse the URL.\n        location, others = url.split(\':\', 1)\n        location = location.lower()\n\n        if location == \'local\':\n            file_name, address, size = others.split(\';\')\n            address = int(address, 16)\n            # Remove optional /// after local: See section 4.1.2 in GenTL\n            # v1.4 Standard\n            file_name = file_name.lstrip(\'/\')\n\n            # It may specify the schema version.\n            delimiter = \'?\'\n            if delimiter in size:\n                size, _ = size.split(delimiter)\n            size = int(size, 16)  # From Hex to Dec\n\n            # Now we get the file content.\n            size, binary_data = port.read(address, size)\n\n            # Store the XML file on the host side; it may be a Zipped XML\n            # file or a plain XML file:\n            file_path_to_load = _save_file(\n                xml_dir_to_store=xml_dir_to_store, file_name=file_name,\n                binary_data=binary_data\n            )\n\n        elif location == \'file\':\n            file_path_to_load = urlparse(url).path\n\n        elif location == \'http\' or location == \'https\':\n            raise NotImplementedError(\n                \'Failed to parse URL {0}: Harvester has not supported \'\n                \'downloading a device description file from vendor \'\n                \'web site. If you must rely on the current condition,\'\n                \'just try to make a request to the Harvester \'\n                \'maintainer.\'.format(url)\n            )\n        else:\n            raise LogicalErrorException(\n                \'Failed to parse URL {0}: Unknown format.\'.format(url)\n            )\n\n    return file_path_to_load\n\n\ndef _save_file(\n        *,\n        xml_dir_to_store: Optional[str] = None,\n        file_name: Optional[str] = None,\n        binary_data=None):\n    #\n    assert binary_data\n    assert file_name\n\n    #\n    bytes_io = io.BytesIO(binary_data)\n\n    if xml_dir_to_store is not None:\n        # Create the directory if it didn\'t exist:\n        if not os.path.exists(xml_dir_to_store):\n            os.makedirs(xml_dir_to_store)\n    else:\n        xml_dir_to_store = tempfile.mkdtemp(\n            prefix=datetime.now().strftime(\'%Y%m%d%H%M%S_\'),\n        )\n\n    #\n    _file_name = ntpath.basename(file_name)\n    file_path = os.path.join(xml_dir_to_store, _file_name)\n\n    #\n    mode = \'w+\'\n    data_to_write = bytes_content = bytes_io.getvalue()\n    if pathlib.Path(file_path).suffix.lower() == \'.zip\':\n        mode += \'b\'\n    else:\n        data_to_write = bytes_content.decode()\n        pos = data_to_write.find(\'\\x00\')\n        if pos != -1:\n            # Found a \\x00:\n            data_to_write = data_to_write[:pos]\n    #\n    with open(file_path, mode) as f:\n        f.write(data_to_write)\n\n    return file_path\n\n\ndef _get_port_connected_node_map(\n        *,\n        port: Optional[Port] = None,\n        logger: Optional[Logger] = None,\n        file_path: Optional[str] = None,\n        xml_dir_to_store: Optional[str] = None):\n    #\n    assert port\n\n    #\n    _logger = logger or get_logger(name=__name__)\n\n    # Instantiate a GenICam node map object.\n    node_map = NodeMap()\n\n    #\n    file_path = _retrieve_file_path(\n        port=port, file_path_to_load=file_path, logger=logger, xml_dir_to_store=xml_dir_to_store\n    )\n\n    #\n    if file_path is not None:\n        # Every valid (zipped) XML file MUST be parsed as expected and the\n        # method returns the file path where the file is located:\n        # Then load the XML file content on the node map object.\n        has_valid_file = True\n\n        # In this case, the file has been identified as a Zip file but\n        # has been diagnosed as BadZipFile due to a technical reason.\n        # Let the NodeMap object load the file from the path:\n        try:\n            node_map.load_xml_from_zip_file(file_path)\n        except RuntimeException:\n            try:\n                node_map.load_xml_from_file(file_path)\n            except RuntimeException as e:\n                _logger.error(e, exc_info=True)\n                has_valid_file = False\n\n        if has_valid_file:\n            # Instantiate a concrete port object of the remote device\'s\n            # port.\n            concrete_port = ConcretePort(port)\n\n            # And finally connect the concrete port on the node map\n            # object.\n            node_map.connect(concrete_port, port.name)\n\n    # Then return the node map:\n    return node_map\n\n\nclass _CallbackDestroyImageAcquirer(Callback):\n    def __init__(self, harvester):\n        self._harvester = harvester\n\n    def emit(self, context: Optional[ImageAcquirer] = None) -> None:\n        context.destroy()\n        if context in self._harvester.image_acquirers:\n            self._harvester.image_acquirers.remove(context)\n\n\nclass Harvester:\n    """"""\n    Is the class that works for you as Harvester Core. Everything begins with\n    this class.\n    """"""\n    #\n    def __init__(\n            self, *,\n            profile=False, logger: Optional[Logger] = None):\n        """"""\n\n        :param profile:\n        :param logger:\n        """"""\n\n        #\n        self._logger = logger or get_logger(name=__name__)\n\n        #\n        super().__init__()\n\n        #\n        self._cti_files = []\n        self._producers = []\n        self._systems = []\n        self._interfaces = []\n        self._device_info_list = []\n        self._ias = []\n\n        #\n        self._has_revised_device_list = False\n        self._timeout_for_update = 1000  # ms\n\n        #\n        if profile:\n            from harvesters._private.core.helper.profiler import Profiler\n            self._profiler = Profiler()\n        else:\n            self._profiler = None\n\n        if self._profiler:\n            self._profiler.print_diff()\n\n        #\n        self._finalizer = weakref.finalize(self, self._reset)\n\n    @property\n    def image_acquirers(self):\n        """"""\n        The ImageAcquire objects.\n\n        :getter: Returns its value.\n        :type: ImageAcquire\n        """"""\n        return self._ias\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self._finalizer()\n\n    def reset(self) -> None:\n        """"""\n        Resets the Harvester object to the initial state.\n        """"""\n        self._finalizer()\n\n    @property\n    def cti_files(self):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(\'cti_files\', \'files\')\n        return self.files\n\n    @property\n    def files(self) -> List[str]:\n        """"""\n        A list of associative CTI files.\n\n        :getter: Returns itself.\n        :type: list[str]\n        """"""\n        return self._cti_files\n\n    @property\n    def device_info_list(self) -> List[DeviceInfo]:\n        """"""\n        A list of available device information.\n\n        :getter: Returns itself.\n        :type: list[DeviceInfo]\n        """"""\n        return self._device_info_list\n\n    @property\n    def timeout_for_update(self) -> int:\n        """"""\n        The duration that is used as the time limit for the device\n        enumeration process. The unit is [ms].\n\n        :getter: Returns itself.\n        :setter: Overwrites itself with the given value.\n        :type: int\n        """"""\n        return self._timeout_for_update\n\n    @timeout_for_update.setter\n    def timeout_for_update(self, ms: Optional[int] = 0) -> None:\n        self._timeout_for_update = ms\n\n    @property\n    def has_revised_device_info_list(self) -> bool:\n        return self._has_revised_device_list\n\n    @has_revised_device_info_list.setter\n    def has_revised_device_info_list(self, value):\n        self._has_revised_device_list = value\n\n    def create_image_acquirer(\n            self, list_index: Optional[int] = None, *,\n            id_: Optional[str] = None,\n            vendor: Optional[str] = None,\n            model: Optional[str] = None,\n            tl_type: Optional[str] = None,\n            user_defined_name: Optional[str] = None,\n            serial_number: Optional[str] = None,\n            version: Optional[str] = None,\n            sleep_duration: Optional[float] = _sleep_duration_default,\n            file_path: Optional[str] = None,\n            privilege: str = \'exclusive\'\n        ):\n        """"""\n        Creates an image acquirer for the specified remote device and return\n        the created :class:`ImageAcquirer` object.\n\n        :param list_index: Set an item index of the list of :class:`DeviceInfo` objects.\n        :param id_: Set an index of the device information list.\n        :param vendor: Set a vendor name of the target device.\n        :param model: Set a model name of the target device.\n        :param tl_type: Set a transport layer type of the target device.\n        :param user_defined_name: Set a user defined name string of the target device.\n        :param serial_number: Set a serial number string of the target device.\n        :param version: Set a version number string of the target device.\n        :param sleep_duration: Set a sleep duration in second that is inserted after the image acquisition worker is executed.\n        :param file_path: Set a path to camera description file which you want to load on the target node map instead of the one which the device declares.\n        :param privilege: Set an access privilege. `exclusive`, `contorl`, and `read_only` are supported. The default is `exclusive`.\n\n        :return: An :class:`ImageAcquirer` object that associates with the specified device.\n\n        Note that you have to close it when you are ready to release the\n        device that you have been controlled. As long as you hold it, the\n        controlled device will be not available from other clients.\n\n        """"""\n        #\n        if self.device_info_list is None:\n            # TODO: Throw an exception to tell clients that there\'s no\n            # device to connect.\n            return None\n\n        # Instantiate a GenTL Device module.\n        if list_index is not None:\n            device = self.device_info_list[list_index].create_device()\n        else:\n            keys = [\n                \'id_\', \'vendor\', \'model\', \'tl_type\',\n                \'user_defined_name\', \'serial_number\', \'version\',\n            ]\n\n            # Create a copy of the list. Do not use the original list:\n            candidates = self.device_info_list.copy()\n\n            for key in keys:\n                key_value = eval(key)\n                if key_value:\n                    items_to_be_removed = []\n                    # Find out the times to be removed from the candidates.\n                    for item in candidates:\n                        try:\n                            if key_value != eval(\'item.\' + key):\n                                items_to_be_removed.append(item)\n                        except GenericException as e:\n                            # The candidate doesn\'t support the information.\n                            self._logger.warn(e, exc_info=True)\n                            pass\n                    # Remove irrelevant items from the candidates.\n                    for item in items_to_be_removed:\n                        candidates.remove(item)\n\n            num_candidates = len(candidates)\n            if num_candidates > 1:\n                raise ValueError(\n                    \'You have two or more candidates. \'\n                    \'You have to pass one or more keys so that \'\n                    \'a single candidate is specified.\'\n                )\n            elif num_candidates == 0:\n                raise ValueError(\n                    \'You have no candidate. \'\n                    \'You have to pass one or more keys so that \'\n                    \'a single candidate is specified.\'\n                )\n            else:\n                device = candidates[0].create_device()\n\n        # Then open it.\n        try:\n            #\n            if privilege == \'exclusive\':\n                _privilege = DEVICE_ACCESS_FLAGS_LIST.DEVICE_ACCESS_EXCLUSIVE\n            elif privilege == \'control\':\n                _privilege = DEVICE_ACCESS_FLAGS_LIST.DEVICE_ACCESS_CONTROL\n            elif privilege == \'read_only\':\n                _privilege = DEVICE_ACCESS_FLAGS_LIST.DEVICE_ACCESS_READONLY\n            else:\n                raise NotImplementedError(\n                    \'{0} is not supported.\'.format(privilege)\n                )\n\n            #\n            device.open(_privilege)\n\n        except GenericException as e:\n            self._logger.debug(e, exc_info=True)\n            # Just re-throw the exception. The decision should be made by\n            # the client but not Harvester:\n            raise\n        else:\n            self._logger.info(\n                \'Opened Device module, {0}.\'.format(device.id_)\n            )\n\n            # Create an :class:`ImageAcquirer` object and return it.\n            ia = ImageAcquirer(\n                device=device, profiler=self._profiler,\n                logger=self._logger, sleep_duration=sleep_duration,\n                file_path=file_path\n            )\n            self._ias.append(ia)\n\n            if self._profiler:\n                self._profiler.print_diff()\n\n        return ia\n\n    def add_cti_file(self, file_path: str):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.add_cti_file, self.add_file)\n        self.add_file(file_path)\n\n    def add_file(self, file_path: str) -> None:\n        """"""\n        Adds a CTI file as one of GenTL Producers to work with.\n\n        :param file_path: Set a file path to the target CTI file.\n\n        :return: None.\n        """"""\n        if not os.path.exists(file_path):\n            self._logger.warning(\n                \'Attempted to add {0} which does not exist.\'.format(file_path)\n            )\n\n        if file_path not in self._cti_files:\n            self._cti_files.append(file_path)\n            self._logger.info(\n                \'Added {0} to the CTI file list.\'.format(file_path)\n            )\n\n    def remove_cti_file(self, file_path: str):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.remove_cti_file, self.remove_file)\n        self.remove_file(file_path)\n\n    def remove_file(self, file_path: str) -> None:\n        """"""\n        Removes the specified CTI file from the list.\n\n        :param file_path: Set a file path to the target CTI file.\n\n        :return: None.\n        """"""\n        if file_path in self._cti_files:\n            self._cti_files.remove(file_path)\n            self._logger.info(\n                \'Removed {0} from the CTI file list.\'.format(file_path)\n            )\n\n    def remove_cti_files(self) -> None:\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.remove_cti_files, self.remove_files)\n        self.remove_files()\n\n    def remove_files(self) -> None:\n        """"""\n        Removes all CTI files in the list.\n\n        :return: None.\n        """"""\n\n        self._cti_files.clear()\n\n        #\n        self._logger.info(\'Removed the all CTI file from the list.\')\n\n    def _open_gentl_producers(self) -> None:\n        #\n        for file_path in self._cti_files:\n            producer = GenTLProducer.create_producer()\n            try:\n                producer.open(file_path)\n            except GenericException as e:\n                self._logger.debug(e, exc_info=True)\n            else:\n                self._producers.append(producer)\n                self._logger.info(\n                    \'Initialized GenTL Producer, {0}.\'.format(\n                        producer.path_name\n                    )\n                )\n\n    def _open_systems(self) -> None:\n        for producer in self._producers:\n            system = producer.create_system()\n            try:\n                system.open()\n            except GenericException as e:\n                self._logger.debug(e, exc_info=True)\n            else:\n                self._systems.append(system)\n                self._logger.info(\'Opened System module, {0}.\'.format(\n                        system.id_\n                    )\n                )\n\n    def _reset(self) -> None:\n        """"""\n        Initializes the :class:`Harvester` object. Once you reset the\n        :class:`Harvester` object, all allocated resources, including buffers\n        and remote device, will be released.\n\n        :return: None.\n        """"""\n        #\n        for ia in self._ias:\n            ia.destroy()\n\n        self._ias.clear()\n\n        #\n        self._logger.info(\'Started resetting the Harvester object.\')\n        self.remove_files()\n        self._release_gentl_producers()\n\n        if self._profiler:\n            self._profiler.print_diff()\n\n        #\n        self._logger.info(\'Completed resetting the Harvester object.\')\n\n    def _release_gentl_producers(self) -> None:\n        #\n        self._release_systems()\n\n        #\n        for producer in self._producers:\n            if producer and producer.is_open():\n                name = producer.path_name\n                producer.close()\n                self._logger.info(\'Closed {0}.\'.format(name))\n\n        #\n        self._producers.clear()\n\n    def _release_systems(self) -> None:\n        #\n        self._release_interfaces()\n\n        #\n        for system in self._systems:\n            if system is not None and system.is_open():\n                name = system.id_\n                system.close()\n                self._logger.info(\'Closed System module, {0}.\'.format(name))\n\n        #\n        self._systems.clear()\n\n    def _release_interfaces(self) -> None:\n        #\n        self._release_device_info_list()\n\n        #\n        if self._interfaces is not None:\n            for iface in self._interfaces:\n                if iface.is_open():\n                    name = iface.id_\n                    iface.close()\n                    self._logger.info(\n                        \'Closed Interface module, {0}.\'.format(name)\n                    )\n\n        #\n        self._interfaces.clear()\n\n    def _release_device_info_list(self) -> None:\n        #\n        if self.device_info_list is not None:\n            self._device_info_list.clear()\n\n        #\n        self._logger.info(\'Discarded the device information list.\')\n\n    def update_device_info_list(self):\n        """"""\n        Will be deprecated shortly.\n        """"""\n        _deprecated(self.update_device_info_list, self.update)\n        self.update()\n\n    def update(self) -> None:\n        """"""\n        Updates the list that holds available devices. You\'ll have to call\n        this method every time you added CTI files or plugged/unplugged\n        devices.\n\n        :return: None.\n        """"""\n        #\n        self._release_gentl_producers()\n\n        try:\n            self._open_gentl_producers()\n            self._open_systems()\n            #\n            for system in self._systems:\n                #\n                system.update_interface_info_list(self.timeout_for_update)\n\n                #\n                for i_info in system.interface_info_list:\n                    iface = i_info.create_interface()\n                    try:\n                        iface.open()\n                    except GenericException as e:\n                        self._logger.debug(e, exc_info=True)\n                    else:\n                        self._logger.info(\n                            \'Opened Interface module, {0}.\'.format(iface.id_)\n                        )\n                        iface.update_device_info_list(self.timeout_for_update)\n                        self._interfaces.append(iface)\n                        for d_info in iface.device_info_list:\n                            self.device_info_list.append(\n                                DeviceInfo(device_info=d_info)\n                            )\n\n        except GenericException as e:\n            self._logger.error(e, exc_info=True)\n            self._has_revised_device_list = False\n        else:\n            self._has_revised_device_list = True\n\n        #\n        self._logger.info(\'Updated the device information list.\')\n\n\nif __name__ == \'__main__\':\n    pass\n'"
src/harvesters/_private/__init__.py,0,b''
src/harvesters/test/__init__.py,0,b''
src/harvesters/test/base_harvester.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nfrom logging import DEBUG\nimport os\nimport sys\nimport unittest\n\n# Related third party imports\n\n# Local application/library specific imports\nfrom harvesters.core import Harvester\nfrom harvesters.util.logging import get_logger\nfrom harvesters.test.helper import get_package_dir\n\n\ndef get_cti_file_path():\n    name = \'HARVESTERS_TEST_TARGET\'\n    if name in os.environ:\n        # Run tests with specified GenTL Producer:\n        cti_file_path = os.getenv(name)\n    else:\n        try:\n            import genicam\n        except ImportError:\n            # Failed to import genicam module; suggest the expected\n            # solution to the client:\n            raise ImportError(\n                \'You must specify a target GenTL Producer either using \'\n                \'HARVESTERS_TEST_TARGET or installing genicam module.\'\n            )\n        else:\n            # Run tests with the default test target, TLSimu:\n            dir_name = get_package_dir(\'genicam\')\n            cti_file_path = os.path.join(dir_name, \'TLSimu.cti\')\n    \n    return cti_file_path\n    \n    \nclass TestHarvesterCoreBase(unittest.TestCase):\n    _cti_file_path = get_cti_file_path()\n    sys.path.append(_cti_file_path)\n\n    def __init__(self, *args, **kwargs):\n        #\n        super().__init__(*args, **kwargs)\n\n        #\n        self._harvester = None\n        self._ia = None\n        self._thread = None\n        self._logger = get_logger(name=\'harvesters\', level=DEBUG)\n        self._buffers = []\n\n    def setUp(self):\n        #\n        super().setUp()\n\n        #\n        self._harvester = Harvester(logger=self._logger)\n        self._harvester.add_file(self._cti_file_path)\n        self._harvester.update()\n\n    def tearDown(self):\n        #\n        if self.ia:\n            self.ia.destroy()\n\n        #\n        self._harvester.reset()\n\n        #\n        self._ia = None\n\n        #\n        super().tearDown()\n\n    @property\n    def harvester(self):\n        return self._harvester\n\n    @property\n    def ia(self):\n        return self._ia\n\n    @ia.setter\n    def ia(self, value):\n        self._ia = value\n\n    @property\n    def general_purpose_thread(self):\n        return self._thread\n\n    @general_purpose_thread.setter\n    def general_purpose_thread(self, value):\n        self._thread = value\n\n    def is_running_with_default_target(self):\n        return True if \'TLSimu.cti\' in self._cti_file_path else False\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
src/harvesters/test/helper.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport importlib\nimport os\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\ndef get_package_dir(name):\n    module = importlib.import_module(name)\n    return os.path.dirname(module.__file__)\n'"
src/harvesters/test/test_acq_frame_rate.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport datetime\nfrom threading import Thread\nimport time\nimport unittest\n\n# Related third party imports\n\n# Local application/library specific imports\nfrom harvesters.test.base_harvester import TestHarvesterCoreBase\n\n\nclass ThreadWithTimeLimit(Thread):\n    def __init__(self, *, worker=None, timeout=0, sleep=0.25):\n        """"""\n\n        :param worker:\n        :param timeout: Set timeout value in second.\n        """"""\n        #\n        super().__init__()\n\n        #\n        self._worker = worker\n        self._is_running = False\n        self._timeout_s = timeout\n        self._time_base = 0\n        self._sleep = sleep\n\n    def run(self):\n        self._is_running = True\n        self._time_base = time.time()\n        while self._is_running:\n            #\n            if self._worker:\n                self._worker(id_=self.ident)\n                time.sleep(self._sleep)\n            #\n            diff_s = time.time() - self._time_base\n            if diff_s > self._timeout_s:\n                self._is_running = False\n\n\nclass TestTutorials(TestHarvesterCoreBase):\n\n    def _test_performance_on_image_acquisition(self, sleep_duration=0.0):\n        #\n        self._logger.info(\n            \'Sleep duration: {0} s\'.format(sleep_duration)\n        )\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(\n            0, sleep_duration=sleep_duration\n        )\n\n        # Then start image acquisition.\n        self.ia.start_acquisition(run_in_background=True)\n\n        # Run the image acquisition thread:\n        thread = ThreadWithTimeLimit(\n            worker=self._worker_update_statistics, timeout=5\n        )\n        thread.start()\n        thread.join()\n\n        # Stop image acquisition:\n        self.ia.stop_acquisition()\n\n        # Destroy the image acquirer:\n        self.ia.destroy()\n\n    def _worker_update_statistics(self, id_: int):\n        #\n        if self.ia:\n            message_config = \'W: {0} x H: {1}, {2}, \'.format(\n                self.ia.remote_device.node_map.Width.value,\n                self.ia.remote_device.node_map.Height.value,\n                self.ia.remote_device.node_map.PixelFormat.value\n            )\n\n            message_statistics = \'{0:.1f} fps, elapsed {1}, {2} images\'.format(\n                self.ia.statistics.fps,\n                str(datetime.timedelta(\n                    seconds=int(self.ia.statistics.elapsed_time_s)\n                )),\n                self.ia.statistics.num_images\n            )\n\n            #\n            self._logger.info(\n                \'{0:08x}: {1}\'.format(\n                    id_, message_config + message_statistics\n                )\n            )\n\n    def test_performance_on_image_acquisition_with_sleep_duration(self):\n        # Connect to the first camera in the list.\n        sleep_duration = 0.001\n        for i in range(4):\n            self._test_performance_on_image_acquisition(\n                sleep_duration=sleep_duration\n            )\n            sleep_duration *= 0.1\n\n    def test_performance_on_image_acquisition_with_zero_sleep_duration(self):\n        self._test_performance_on_image_acquisition(\n            sleep_duration=0.0\n        )\n\n    def test_multiple_access(self):\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        #\n        self.ia.start_acquisition(run_in_background=True)\n\n        #\n        nr = 100\n\n        # Run the image acquisition thread:\n        threads = []\n        for i in range(nr):\n            threads.append(\n                ThreadWithTimeLimit(\n                    worker=self._worker_update_statistics,\n                    timeout=10, sleep=0\n                )\n            )\n\n        for thread in threads:\n            thread.start()\n\n        for thread in threads:\n            thread.join()\n\n        #\n        self.ia.stop_acquisition()\n\n        # Destroy the image acquirer:\n        self.ia.destroy()\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
src/harvesters/test/test_harvester_core.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport os\nfrom queue import Queue, Empty\nfrom shutil import rmtree\nimport sys\nfrom tempfile import gettempdir\nfrom typing import Optional\nimport threading\nimport time\nimport unittest\nfrom urllib.parse import quote\n\n# Related third party imports\nfrom genicam.gentl import TimeoutException\nimport numpy as np\n\n# Local application/library specific imports\nfrom harvesters.test.base_harvester import TestHarvesterCoreBase\nfrom harvesters.test.base_harvester import get_cti_file_path\nfrom harvesters.core import _retrieve_file_path\nfrom harvesters.core import Callback\nfrom harvesters.core import Harvester\nfrom harvesters.core import ImageAcquirer\nfrom harvesters.test.helper import get_package_dir\nfrom harvesters.util.pfnc import Dictionary\n\n\nclass TestHarvesterCore(TestHarvesterCoreBase):\n    sleep_duration = .5  # Time to keep sleeping [s]\n\n    def test_basic_usage_1(self):\n        """"""\n        We walk through a basic usage and manually close the image\n        acquirer.\n\n        :return: None.\n        """"""\n\n        # Prepare an image acquirer for device #0.\n        ia = self.harvester.create_image_acquirer(0)\n\n        # Acquire images.\n        self._basic_usage(ia)\n\n        # Discard the image acquirer.\n        ia.destroy()\n\n    def test_basic_usage_2(self):\n        """"""\n        We walk through a basic usage and omit manually closing the image\n        acquirer using the with statement.\n\n        :return: None.\n        """"""\n\n        # Prepare an image acquirer for device #0.\n        with self.harvester.create_image_acquirer(0) as ia:\n\n            # Acquire images.\n            self._basic_usage(ia)\n\n    def _basic_usage(self, ia: ImageAcquirer):\n        # Start image acquisition.\n        ia.start_acquisition()\n\n        # Fetch a buffer that is filled with image data.\n        with ia.fetch_buffer() as buffer:\n            # Reshape it.\n            self._logger.info(\'{0}\'.format(buffer))\n\n        # Stop image acquisition.\n        ia.stop_acquisition()\n\n    def test_multiple_image_acquirers(self):\n        num_devices = len(self.harvester.device_info_list)\n        self._test_image_acquirers(num_ias=num_devices)\n\n    def _test_image_acquirers(self, num_ias=1):\n        #\n        self._logger.info(\'Number of devices: {0}\'.format(num_ias))\n\n        #\n        ias = []  # Image Acquirers\n\n        #\n        for list_index in range(num_ias):\n            ias.append(\n                self.harvester.create_image_acquirer(\n                    list_index=list_index\n                )\n                # Or you could simply do the same thing as follows:\n                # self.harvester.create_image_acquirer(list_index)\n            )\n\n        #\n        for i in range(3):\n            #\n            self._logger.info(\'---> Round {0}: Set up\'.format(i))\n            for index, ia in enumerate(ias):\n                ia.start_acquisition()\n                self._logger.info(\n                    \'Device #{0} has started image acquisition.\'.format(index)\n                )\n\n            k = 0\n\n            # Run it as fast as possible.\n            frames = 10\n\n            while k < frames:\n                for ia in ias:\n                    if k % 2 == 0:\n                        # Option 1: This way is secure and preferred.\n                        try:\n                            # We know we\'ve started image acquisition but this\n                            # try-except block is demonstrating a case where\n                            # a client called fetch_buffer method even though\n                            # he\'d forgotten to start image acquisition.\n                            with ia.fetch_buffer() as buffer:\n                                self._logger.info(\'{0}\'.format(buffer))\n                        except AttributeError:\n                            # Harvester Core has not started image acquisition\n                            # so calling fetch_buffer() raises AttributeError\n                            # because None object is used for the with\n                            # statement.\n                            pass\n                    else:\n                        # Option 2: You can manually do the same job but not\n                        # recommended because you might forget to queue the\n                        # buffer.\n                        buffer = ia.fetch_buffer()\n                        self._logger.info(\'{0}\'.format(buffer))\n\n                #\n                k += 1\n\n            #\n            self._logger.info(\'<--- Round {0}: Tear down\'.format(i))\n            for index, ia in enumerate(ias):\n                ia.stop_acquisition()\n                self._logger.info(\n                    \'Device #{0} has stopped image acquisition.\'.format(index)\n                )\n\n        for ia in ias:\n            ia.destroy()\n\n    def test_controlling_a_specific_camera(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # The basic usage.\n        ia = self.harvester.create_image_acquirer(0)\n        ia.destroy()\n\n        # The basic usage but it explicitly uses the parameter name.\n        ia = self.harvester.create_image_acquirer(\n            list_index=0\n        )\n        ia.destroy()\n\n        # The key can\'t specify a unique device so it raises an exception.\n        with self.assertRaises(ValueError):\n            self.harvester.create_image_acquirer(\n                vendor=\'EMVA_D\'\n            )\n\n        # The key specifies a unique device.\n        self._logger.info(self.harvester.device_info_list)\n        ia = self.harvester.create_image_acquirer(\n            serial_number=\'SN_InterfaceA_0\'\n        )\n        ia.destroy()\n\n    def test_timeout_on_fetching_buffer(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Create an image acquirer:\n        ia = self.harvester.create_image_acquirer(0)\n\n        # We do not start image acquisition:\n        #ia.start_acquisition()\n\n        timeout = 3  # sec\n\n        with self.assertRaises(TimeoutException):\n            # Try to fetch a buffer but the IA will immediately raise\n            # TimeoutException because it\'s not started image acquisition:\n            _ = ia.fetch_buffer(timeout=timeout)\n\n        # Then we setup the device for software trigger mode:\n        ia.remote_device.node_map.TriggerMode.value = \'On\'\n        ia.remote_device.node_map.TriggerSource.value = \'Software\'\n\n        # We\'re ready to start image acquisition:\n        ia.start_acquisition()\n\n        with self.assertRaises(TimeoutException):\n            # Try to fetch a buffer but the IA will raise TimeoutException\n            # because we\'ve not triggered the device so far:\n            _ = ia.fetch_buffer(timeout=timeout)\n\n        # We finally acquire an image triggering the device:\n        buffer = None\n        self.assertIsNone(buffer)\n\n        ia.remote_device.node_map.TriggerSoftware.execute()\n        buffer = ia.fetch_buffer(timeout=timeout)\n        self.assertIsNotNone(buffer)\n        self._logger.info(\'{0}\'.format(buffer))\n        buffer.queue()\n\n        # Now we stop image acquisition:\n        ia.stop_acquisition()\n        ia.destroy()\n\n    def test_stop_start_and_stop(self):\n        # Create an image acquirer:\n        ia = self.harvester.create_image_acquirer(0)\n\n        # It\'s not necessary but we stop image acquisition first;\n        #\n        ia.stop_acquisition()\n\n        # Then start it:\n        ia.start_acquisition()\n\n        # Fetch a buffer to make sure it\'s working:\n        with ia.fetch_buffer() as buffer:\n            self._logger.info(\'{0}\'.format(buffer))\n\n        # Then stop image acquisition:\n        ia.stop_acquisition()\n\n        # And destroy the ImageAcquirer:\n        ia.destroy()\n\n    def test_num_holding_filled_buffers(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list:\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        # Setup the camera before starting image acquisition:\n        self.setup_camera()\n\n        #\n        tests = [\n            self._test_issue_120_1\n        ]\n        for test in tests:\n            for num_images in [1, 2, 4, 8]:\n                #\n                self.ia.num_filled_buffers_to_hold = num_images\n\n                # Start image acquisition:\n                self.ia.start_acquisition(run_in_background=True)\n\n                # Run a test:\n                test(num_images)\n\n                # Stop image acquisition:\n                self.ia.stop_acquisition()\n\n    def _test_issue_120_1(self, num_images):\n        # Make sure num_holding_filled_buffers is incremented every trigger:\n        for i in range(num_images):\n            #\n            self.assertEqual(\n                self.ia.num_holding_filled_buffers, i\n            )\n\n            # Trigger it:\n            self.generate_software_trigger(sleep_s=self.sleep_duration)\n\n            # It must be incremented:\n            self.assertEqual(\n                self.ia.num_holding_filled_buffers, i + 1\n            )\n\n        # Trigger it again, we know it\'s redundant compared to the\n        # maximum capacity:\n        self.generate_software_trigger(sleep_s=self.sleep_duration)\n\n        # Make sure num_holding_filled_buffers does not exceed\n        # num_filled_buffers_to_hold:\n        self.assertEqual(\n            self.ia.num_filled_buffers_to_hold,\n            self.ia.num_holding_filled_buffers\n        )\n\n        # Make sure num_holding_filled_buffers is decreased every time\n        # a filled buffer is fetched:\n        for i in range(num_images):\n            #\n            self.assertEqual(\n                self.ia.num_holding_filled_buffers,\n                num_images - i\n            )\n            #\n            with self.ia.fetch_buffer():\n                #\n                self.assertEqual(\n                    self.ia.num_holding_filled_buffers,\n                    num_images - (i + 1)\n                )\n\n    def setup_camera(self):\n        self.ia.remote_device.node_map.AcquisitionMode.value = \'Continuous\'\n        self.ia.remote_device.node_map.TriggerMode.value = \'On\'\n        self.ia.remote_device.node_map.TriggerSource.value = \'Software\'\n\n    def generate_software_trigger(self, sleep_s=0.):\n        # Trigger the camera because you have already setup your\n        # equipment for the upcoming image acquisition.\n        self.ia.remote_device.node_map.TriggerSoftware.execute()\n        #\n        if sleep_s > 0:\n            time.sleep(sleep_s)\n\n    def test_issue_59(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        #\n        min = self.ia._data_streams[0].buffer_announce_min\n        with self.assertRaises(ValueError):\n            self.ia.num_buffers = min - 1\n\n        #\n        with self.assertRaises(ValueError):\n            self.ia.num_filled_buffers_to_hold = 0\n\n        #\n        self.ia.num_filled_buffers_to_hold = min\n\n    def test_issue_60(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        # Check the number of buffers:\n        self.assertEqual(16, self.ia.num_buffers)\n\n    @unittest.skip(\'It has been obsolete; see issue #141.\')\n    def test_issue_61(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        # Register a call back method:\n        self.ia.on_new_buffer_arrival = self._callback_on_new_buffer_arrival\n\n        # We turn software trigger on:\n        self.setup_camera()\n\n        # We have not fetched any buffer:\n        self.assertEqual(0, len(self._buffers))\n\n        # Start image acquisition:\n        self.ia.start_acquisition(run_in_background=True)\n\n        # Trigger the target device:\n        num_images = self.ia.num_buffers\n        self.assertTrue(num_images > 0)\n\n        # Trigger the target device:\n        for _ in range(num_images):\n            self.generate_software_trigger(sleep_s=self.sleep_duration)\n\n        # If the callback method was called, then we should have the same\n        # number of buffers with num_images:\n        self.assertEqual(num_images, len(self._buffers))\n\n        # Release the buffers before stopping image acquisition:\n        for buffer in self._buffers:\n            buffer.queue()\n\n        self._buffers.clear()\n\n        # Then stop image acquisition:\n        self.ia.stop_acquisition()\n\n    def _callback_on_new_buffer_arrival(self):\n        # Fetch a buffer and keep it:\n        self._buffers.append(self.ia.fetch_buffer())\n\n    def test_issue_66(self):\n        if not self.is_running_with_default_target():\n            return\n\n        file_names = [\'altered_plain.xml\', \'altered_zip.zip\']\n        expected_values = [\'plain\', \'zip\']\n        for i, file_name in enumerate(file_names):\n            self._test_issue_66(\n                \'issue_66_\' + file_name, expected_values[i]\n            )\n\n    def _test_issue_66(self, file_name, expected_value):\n        #\n        xml_dir = self._get_xml_dir()\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(\n            0, file_path=os.path.join(xml_dir, file_name)\n        )\n\n        # Compare DeviceModelNames:\n        self.assertEqual(\n            \'Altered TLSimu (\' + expected_value + \')\',\n            self.ia.remote_device.node_map.DeviceModelName.value\n        )\n\n        #\n        self.ia.destroy()\n\n    def test_issue_67(self):\n        if not self.is_running_with_default_target():\n            return\n\n        file_names = [\'altered_plain.xml\', \'altered_zip.zip\']\n        for i, file_name in enumerate(file_names):\n            self._test_issue_67(\n                \'issue_67_\' + file_name\n            )\n\n    def _test_issue_67(self, expected_file_name):\n        #\n        xml_dir = self._get_xml_dir()\n\n        #\n        url = \'file://\'\n        file_path = xml_dir + \'/\' + expected_file_name\n\n        # \'\\\' -> \'/\'\n        file_path.replace(\'\\\\\', \'/\')\n\n        # \':\' -> \'|\'\n        file_path.replace(\':\', \'|\')\n\n        # \' \' -> \'%20\'\n        file_path = quote(file_path)\n\n        #\n        url += file_path\n\n        # Parse the URL:\n        retrieved_file_path = _retrieve_file_path(url=url)\n\n        # Compare file names:\n        self.assertEqual(\n            os.path.basename(retrieved_file_path),\n            expected_file_name\n        )\n\n    def test_issue_121(self):\n        #\n        expected_file_path = \'/Foo.xml\'\n\n        #\n        url = \'file://\' + expected_file_path\n        retrieved_file_path = _retrieve_file_path(url=url)\n\n        # Compare file names:\n        self.assertEqual(\n            retrieved_file_path,\n            expected_file_path\n        )\n\n    @staticmethod\n    def _get_xml_dir():\n        return os.path.join(get_package_dir(\'harvesters\'), \'test\', \'xml\')\n\n    def test_issue_70(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list:\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        # Then check the minimum buffer number that a client can ask\n        # the ImageAcquire object to prepare:\n        self.assertEqual(5, self.ia.min_num_buffers)\n\n    def test_issue_78(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # The device_info_list must not turn empty even if a given key\n        # does not match to any candidate:\n        self._logger.info(self.harvester.device_info_list)\n        device_info_list = self.harvester.device_info_list.copy()\n        try:\n            self.harvester.create_image_acquirer(\n                serial_number=\'abcdefghijklmnopqrstuwxyz!#$%&=~|<>\'\n            )\n        except ValueError:\n            self.assertEqual(\n                device_info_list, self.harvester.device_info_list\n            )\n\n    def test_issue_130_1(self):\n        #\n        self.ia = self.harvester.create_image_acquirer(0)\n        #\n        self.ia.start_acquisition(run_in_background=False)\n        #\n        with self.ia.fetch_buffer() as buffer:\n            self.assertIsNotNone(buffer)\n        #\n        self.ia.stop_acquisition()\n\n    def test_issue_141(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        # We turn software trigger on:\n        self.setup_camera()\n\n        # Create a callback:\n        self.on_new_buffer_available = _OnNewBufferAvailable(\n            ia=self.ia, buffers=self._buffers\n        )\n        self.on_return_buffer_now = _OnReturnBufferNow(\n            holder=self.on_new_buffer_available\n        )\n\n        # Trigger the target device:\n        self.num_images = self.ia.num_buffers\n        self.assertTrue(self.num_images > 0)\n\n        #\n        tests = [\n            self._test_141_with_callback, self._test_141_without_callback\n        ]\n        for test in tests:\n            # We have not yet fetched any buffer:\n            self.assertEqual(0, len(self.on_new_buffer_available.buffers))\n\n            # Run a sub-test:\n            test()\n\n            # Then stop image acquisition:\n            self.ia.stop_acquisition()\n\n    def _test_141_with_callback(self):\n        # Add it to the image acquire so that it can get notified when the\n        # event happened:\n        self.ia.add_callback(\n            ImageAcquirer.Events.NEW_BUFFER_AVAILABLE,\n            self.on_new_buffer_available\n        )\n        self.ia.add_callback(\n            ImageAcquirer.Events.RETURN_ALL_BORROWED_BUFFERS,\n            self.on_return_buffer_now\n        )\n\n        #\n        self._test_141_body()\n\n        # If the callback method was called, then we should have the same\n        # number of buffers with num_images:\n        self.assertEqual(\n            self.ia.num_buffers, len(self.on_new_buffer_available.buffers)\n        )\n\n    def _test_141_without_callback(self):\n        # Remove all callbacks to not any callback work:\n        self.ia.remove_callbacks()\n        \n        #\n        self._test_141_body()\n        \n        # The list must be empty because the emit method has not been called:\n        self.assertEqual(\n            0, len(self.on_new_buffer_available.buffers)\n        )\n\n    def _test_141_body(self):\n        # Start image acquisition:\n        self.ia.start_acquisition(run_in_background=True)\n\n        # Trigger the target device:\n        for _ in range(self.num_images):\n            self.generate_software_trigger(sleep_s=self.sleep_duration)\n\n    def test_issue_146(self):\n        #\n        tests = [\n            self._test_issue_146_group_packed_10,\n            self._test_issue_146_group_packed_12,\n            self._test_issue_146_packed_10,\n            self._test_issue_146_packed_12,\n        ]\n        #\n        for test in tests:\n            test()\n\n    def _test_issue_146_group_packed_10(self):\n        _1st = 0xff\n        _3rd = 0xff\n        ba = bytes([_1st, 0x33, _3rd])\n        packed = np.frombuffer(ba, dtype=np.uint8)\n        pf = Dictionary.get_proxy(\'BayerRG10Packed\')\n        unpacked = pf.expand(packed)\n        self.assertEqual(_1st * 4 + 3, unpacked[0])\n        self.assertEqual(_3rd * 4 + 3, unpacked[1])\n\n    def _test_issue_146_group_packed_12(self):\n        _1st = 0xff\n        _3rd = 0xff\n        ba = bytes([_1st, 0xff, _3rd])\n        packed = np.frombuffer(ba, dtype=np.uint8)\n        pf = Dictionary.get_proxy(\'BayerRG12Packed\')\n        unpacked = pf.expand(packed)\n        self.assertEqual(_1st * 16 + 0xf, unpacked[0])\n        self.assertEqual(_3rd * 16 + 0xf, unpacked[1])\n\n    def _test_issue_146_packed_10(self):\n        element = 0xff\n        ba = bytes([element, element, element, element])\n        packed = np.frombuffer(ba, dtype=np.uint8)\n        pf = Dictionary.get_proxy(\'Mono10p\')\n        unpacked = pf.expand(packed)\n        self.assertEqual(0x3ff, unpacked[0])\n        self.assertEqual(0x3ff, unpacked[1])\n        self.assertEqual(0x7ff, unpacked[2])\n\n    def _test_issue_146_packed_12(self):\n        _1st = 0xff\n        _3rd = 0xff\n        ba = bytes([_1st, 0xff, _3rd])\n        packed = np.frombuffer(ba, dtype=np.uint8)\n        pf = Dictionary.get_proxy(\'Mono12p\')\n        unpacked = pf.expand(packed)\n        self.assertEqual(0xf * 256 + _1st, unpacked[0])\n        self.assertEqual(_3rd * 16 + 0xf, unpacked[1])\n\n\nclass _TestIssue81(threading.Thread):\n    def __init__(self, message_queue=None, cti_file_path=None):\n        super().__init__()\n        self._message_queue = message_queue\n        self._cti_file_path = cti_file_path\n\n    def run(self):\n        h = Harvester()\n        h.add_file(self._cti_file_path)\n        h.update()\n        try:\n            ia = h.create_image_acquirer(0)\n        except:\n            # Transfer the exception anyway:\n            self._message_queue.put(sys.exc_info())\n        else:\n            ia.start_acquisition()\n            ia.stop_acquisition()\n            ia.destroy()\n            h.reset()\n\n\nclass TestIssue81(unittest.TestCase):\n    _cti_file_path = get_cti_file_path()\n    sys.path.append(_cti_file_path)\n\n    def test_issue_81(self):\n        message_queue = Queue()\n        t = _TestIssue81(\n            message_queue=message_queue, cti_file_path=self._cti_file_path\n        )\n        t.start()\n        t.join()\n        try:\n            result = message_queue.get(block=False)\n        except Empty:\n            # Nothing happened; everything is fine.\n            pass\n        else:\n            exception, message, backtrace = result\n            # Transfer the exception:\n            raise exception(message)\n\n\nclass TestIssue85(unittest.TestCase):\n    _cti_file_path = get_cti_file_path()\n    sys.path.append(_cti_file_path)\n\n    def setUp(self) -> None:\n        #\n        self.env_var = \'HARVESTERS_XML_FILE_DIR\'\n        self.original = None if os.environ else os.environ[self.env_var]\n\n    def tearDown(self) -> None:\n        if self.original:\n            os.environ[self.env_var] = self.original\n\n    def test_issue_85(self):\n        #\n        temp_dir = os.path.join(\n            gettempdir(), \'harvester\', self.test_issue_85.__name__\n        )\n\n        #\n        if os.path.isdir(temp_dir):\n            rmtree(temp_dir)\n        os.makedirs(temp_dir)\n\n        #\n        os.environ[self.env_var] = temp_dir\n\n        #\n        self.assertFalse(os.listdir(temp_dir))\n\n        #\n        with Harvester() as h:\n            h.add_file(self._cti_file_path)\n            h.update()\n            with h.create_image_acquirer(0):\n                # Check if XML files have been stored in the expected\n                # directory:\n                self.assertTrue(os.listdir(temp_dir))\n\n\nclass _OnNewBufferAvailable(Callback):\n    def __init__(self, ia: ImageAcquirer, buffers: list):\n        super().__init__()\n        self._ia = ia\n        self._buffers = buffers\n\n    def emit(self, context: Optional[object] = None) -> None:\n        buffer = self._ia.fetch_buffer()\n        self._buffers.append(buffer)\n\n    @property\n    def buffers(self):\n        return self._buffers\n\n\nclass _OnReturnBufferNow(Callback):\n    def __init__(self, holder: _OnNewBufferAvailable):\n        super().__init__()\n        self._holder = holder\n        \n    def emit(self, context: Optional[object] = None) -> None:\n        # Return/Queue the buffers before stopping image acquisition:\n        while len(self._holder.buffers) > 0:\n            buffer = self._holder.buffers.pop(-1)\n            buffer.queue()\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
src/harvesters/test/test_tutorials.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport unittest\n\n# Related third party imports\nfrom harvesters.core import Harvester\n\n# Local application/library specific imports\nfrom harvesters.test.base_harvester import TestHarvesterCoreBase\nfrom harvesters.test.base_harvester import get_cti_file_path\n\n\nclass TestTutorials(TestHarvesterCoreBase):\n\n    def test_severis_usage(self):\n        if not self.is_running_with_default_target():\n            return\n\n        # Connect to the first camera in the list.\n        self.ia = self.harvester.create_image_acquirer(0)\n\n        #\n        num_images_to_acquire = 0\n\n        # Setup the camera before starting image acquisition.\n        self.setup_camera()\n\n        # Then start image acquisition.\n        self.ia.start_acquisition()\n\n        # Setup your equipment then trigger the camera.\n        self.setup_equipment_and_trigger_camera()\n\n        while num_images_to_acquire < 100:\n            #\n            with self.ia.fetch_buffer() as buffer:\n                #\n                self._logger.info(\'{0}\'.format(buffer))\n\n                # TODO: Work with the image you got.\n                # self.do_something(buffer)\n\n                # Set up your equipment for the next image acquisition.\n                self.setup_equipment_and_trigger_camera()\n\n            num_images_to_acquire += 1\n\n    def setup_camera(self):\n        self.ia.remote_device.node_map.AcquisitionMode.value = \'Continuous\'\n        self.ia.remote_device.node_map.TriggerMode.value = \'On\'\n        self.ia.remote_device.node_map.TriggerSource.value = \'Software\'\n\n    def setup_equipment_and_trigger_camera(self):\n        # Setup your equipment.\n        # TODO: Code here.\n\n        # Trigger the camera because you have already setup your\n        # equipment for the upcoming image acquisition.\n        self.ia.remote_device.node_map.TriggerSoftware.execute()\n\n\nclass TestTutorials2(unittest.TestCase):\n    def setUp(self) -> None:\n        # The following block is just for administrative purpose;\n        # you should not include it in your code:\n        self.cti_file_path = get_cti_file_path()\n        if \'TLSimu.cti\' not in self.cti_file_path:\n            self.skipTest(\'The target is not TLSimu.\')\n\n        # Create a Harvester object:\n        self.harvester = Harvester()\n\n    def tearDown(self) -> None:\n        #\n        self.harvester.reset()\n\n    def test_traversable_tutorial(self):\n        # Add a CTI file path:\n        self.harvester.add_file(self.cti_file_path)\n        self.harvester.update()\n\n        # Connect to the first camera in the list:\n        ia = self.harvester.create_image_acquirer(0)\n\n        #\n        num_images_to_acquire = 0\n\n        # Then start image acquisition:\n        ia.start_acquisition()\n\n        while num_images_to_acquire < 100:\n            #\n            with ia.fetch_buffer() as buffer:\n                # self.do_something(buffer)\n                pass\n\n            num_images_to_acquire += 1\n\n        # We don\'t need the ImageAcquirer object. Destroy it:\n        ia.destroy()\n\n    def test_ticket_127(self):\n        #\n        self.harvester.add_cti_file(self.cti_file_path)\n        self.harvester.remove_cti_file(self.cti_file_path)\n\n        #\n        self.harvester.add_cti_file(self.cti_file_path)\n        self.harvester.remove_cti_files()\n\n        #\n        self.harvester.add_cti_file(self.cti_file_path)\n        self.assertIsNotNone(self.harvester.cti_files)\n\n        #\n        self.harvester.update_device_info_list()\n\n        # Connect to the first camera in the list:\n        ia = self.harvester.create_image_acquirer(0)\n\n        #\n        ia.start_image_acquisition()\n        self.assertTrue(ia.is_acquiring_images())\n        ia.stop_image_acquisition()\n        self.assertFalse(ia.is_acquiring_images())\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
src/harvesters/util/__init__.py,0,b''
src/harvesters/util/_pfnc.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\n# We create the following symbolics from the official PFNC table so the\n# numeric values are all capitalized but this is an exception: We usually\n# go with lower case in other Python files.\nsymbolics = {\n    # As of 17-Feb-2017\n    0x01080001: \'Mono8\',\n    0x01080002: \'Mono8s\',\n    0x01100003: \'Mono10\',\n    0x010C0004: \'Mono10Packed\',\n    0x01100005: \'Mono12\',\n    0x010C0006: \'Mono12Packed\',\n    0x01100007: \'Mono16\',\n    0x01080008: \'BayerGR8\',\n    0x01080009: \'BayerRG8\',\n    0x0108000A: \'BayerGB8\',\n    0x0108000B: \'BayerBG8\',\n    0x0110000C: \'BayerGR10\',\n    0x0110000D: \'BayerRG10\',\n    0x0110000E: \'BayerGB10\',\n    0x0110000F: \'BayerBG10\',\n    0x01100010: \'BayerGR12\',\n    0x01100011: \'BayerRG12\',\n    0x01100012: \'BayerGB12\',\n    0x01100013: \'BayerBG12\',\n    0x02180014: \'RGB8\',\n    0x02180015: \'BGR8\',\n    0x02200016: \'RGBa8\',\n    0x02200017: \'BGRa8\',\n    0x02300018: \'RGB10\',\n    0x02300019: \'BGR10\',\n    0x0230001A: \'RGB12\',\n    0x0230001B: \'BGR12\',\n    0x0220001C: \'RGB10V1Packed\',\n    0x0220001D: \'RGB10p32\',\n    0x020C001E: \'YUV411_8_UYYVYY\',\n    0x0210001F: \'YUV422_8_UYVY\',\n    0x02180020: \'YUV8_UYV\',\n    0x02180021: \'RGB8_Planar\',\n    0x02300022: \'RGB10_Planar\',\n    0x02300023: \'RGB12_Planar\',\n    0x02300024: \'RGB16_Planar\',\n    0x01100025: \'Mono14\',\n    0x010C0026: \'BayerGR10Packed\',\n    0x010C0027: \'BayerRG10Packed\',\n    0x010C0028: \'BayerGB10Packed\',\n    0x010C0029: \'BayerBG10Packed\',\n    0x010C002A: \'BayerGR12Packed\',\n    0x010C002B: \'BayerRG12Packed\',\n    0x010C002C: \'BayerGB12Packed\',\n    0x010C002D: \'BayerBG12Packed\',\n    0x0110002E: \'BayerGR16\',\n    0x0110002F: \'BayerRG16\',\n    0x01100030: \'BayerGB16\',\n    0x01100031: \'BayerBG16\',\n    0x02100032: \'YUV422_8\',\n    0x02300033: \'RGB16\',\n    0x02240034: \'RGB12V1Packed\',\n    0x02100035: \'RGB565p\',\n    0x02100036: \'BGR565p\',\n    0x01010037: \'Mono1p\',\n    0x01020038: \'Mono2p\',\n    0x01040039: \'Mono4p\',\n    0x0218003A: \'YCbCr8_CbYCr\',\n    0x0210003B: \'YCbCr422_8\',\n    0x020C003C: \'YCbCr411_8_CbYYCrYY\',\n    0x0218003D: \'YCbCr601_8_CbYCr\',\n    0x0210003E: \'YCbCr601_422_8\',\n    0x020C003F: \'YCbCr601_411_8_CbYYCrYY\',\n    0x02180040: \'YCbCr709_8_CbYCr\',\n    0x02100041: \'YCbCr709_422_8\',\n    0x020C0042: \'YCbCr709_411_8_CbYYCrYY\',\n    0x02100043: \'YCbCr422_8_CbYCrY\',\n    0x02100044: \'YCbCr601_422_8_CbYCrY\',\n    0x02100045: \'YCbCr709_422_8_CbYCrY\',\n    0x010A0046: \'Mono10p\',\n    0x010C0047: \'Mono12p\',\n    0x021E0048: \'BGR10p\',\n    0x02240049: \'BGR12p\',\n    0x0230004A: \'BGR14\',\n    0x0230004B: \'BGR16\',\n    0x0240004C: \'BGRa10\',\n    0x0228004D: \'BGRa10p\',\n    0x0240004E: \'BGRa12\',\n    0x0230004F: \'BGRa12p\',\n    0x02400050: \'BGRa14\',\n    0x02400051: \'BGRa16\',\n    0x010A0052: \'BayerBG10p\',\n    0x010C0053: \'BayerBG12p\',\n    0x010A0054: \'BayerGB10p\',\n    0x010C0055: \'BayerGB12p\',\n    0x010A0056: \'BayerGR10p\',\n    0x010C0057: \'BayerGR12p\',\n    0x010A0058: \'BayerRG10p\',\n    0x010C0059: \'BayerRG12p\',\n    0x020C005A: \'YCbCr411_8\',\n    0x0218005B: \'YCbCr8\',\n    0x021E005C: \'RGB10p\',\n    0x0224005D: \'RGB12p\',\n    0x0230005E: \'RGB14\',\n    0x0240005F: \'RGBa10\',\n    0x02280060: \'RGBa10p\',\n    0x02400061: \'RGBa12\',\n    0x02300062: \'RGBa12p\',\n    0x02400063: \'RGBa14\',\n    0x02400064: \'RGBa16\',\n    0x02200065: \'YCbCr422_10\',\n    0x02200066: \'YCbCr422_12\',\n    0x01080067: \'SCF1WBWG8\',\n    0x01100068: \'SCF1WBWG10\',\n    0x010A0069: \'SCF1WBWG10p\',\n    0x0110006A: \'SCF1WBWG12\',\n    0x010C006B: \'SCF1WBWG12p\',\n    0x0110006C: \'SCF1WBWG14\',\n    0x0110006D: \'SCF1WBWG16\',\n    0x0108006E: \'SCF1WGWB8\',\n    0x0110006F: \'SCF1WGWB10\',\n    0x010A0070: \'SCF1WGWB10p\',\n    0x01100071: \'SCF1WGWB12\',\n    0x010C0072: \'SCF1WGWB12p\',\n    0x01100073: \'SCF1WGWB14\',\n    0x01100074: \'SCF1WGWB16\',\n    0x01080075: \'SCF1WGWR8\',\n    0x01100076: \'SCF1WGWR10\',\n    0x010A0077: \'SCF1WGWR10p\',\n    0x01100078: \'SCF1WGWR12\',\n    0x010C0079: \'SCF1WGWR12p\',\n    0x0110007A: \'SCF1WGWR14\',\n    0x0110007B: \'SCF1WGWR16\',\n    0x0108007C: \'SCF1WRWG8\',\n    0x0110007D: \'SCF1WRWG10\',\n    0x010A007E: \'SCF1WRWG10p\',\n    0x0110007F: \'SCF1WRWG12\',\n    0x010C0080: \'SCF1WRWG12p\',\n    0x01100081: \'SCF1WRWG14\',\n    0x01100082: \'SCF1WRWG16\',\n    0x02300083: \'YCbCr10_CbYCr\',\n    0x021E0084: \'YCbCr10p_CbYCr\',\n    0x02300085: \'YCbCr12_CbYCr\',\n    0x02240086: \'YCbCr12p_CbYCr\',\n    0x02140087: \'YCbCr422_10p\',\n    0x02180088: \'YCbCr422_12p\',\n    0x02300089: \'YCbCr601_10_CbYCr\',\n    0x021E008A: \'YCbCr601_10p_CbYCr\',\n    0x0230008B: \'YCbCr601_12_CbYCr\',\n    0x0224008C: \'YCbCr601_12p_CbYCr\',\n    0x0220008D: \'YCbCr601_422_10\',\n    0x0214008E: \'YCbCr601_422_10p\',\n    0x0220008F: \'YCbCr601_422_12\',\n    0x02180090: \'YCbCr601_422_12p\',\n    0x02300091: \'YCbCr709_10_CbYCr\',\n    0x021E0092: \'YCbCr709_10p_CbYCr\',\n    0x02300093: \'YCbCr709_12_CbYCr\',\n    0x02240094: \'YCbCr709_12p_CbYCr\',\n    0x02200095: \'YCbCr709_422_10\',\n    0x02140096: \'YCbCr709_422_10p\',\n    0x02200097: \'YCbCr709_422_12\',\n    0x02180098: \'YCbCr709_422_12p\',\n    0x02200099: \'YCbCr422_10_CbYCrY\',\n    0x0214009A: \'YCbCr422_10p_CbYCrY\',\n    0x0220009B: \'YCbCr422_12_CbYCrY\',\n    0x0218009C: \'YCbCr422_12p_CbYCrY\',\n    0x0220009D: \'YCbCr601_422_10_CbYCrY\',\n    0x0214009E: \'YCbCr601_422_10p_CbYCrY\',\n    0x0220009F: \'YCbCr601_422_12_CbYCrY\',\n    0x021800A0: \'YCbCr601_422_12p_CbYCrY\',\n    0x022000A1: \'YCbCr709_422_10_CbYCrY\',\n    0x021400A2: \'YCbCr709_422_10p_CbYCrY\',\n    0x022000A3: \'YCbCr709_422_12_CbYCrY\',\n    0x021800A4: \'YCbCr709_422_12p_CbYCrY\',\n    0x021000A5: \'BiColorRGBG8\',\n    0x021000A6: \'BiColorBGRG8\',\n    0x022000A7: \'BiColorRGBG10\',\n    0x021400A8: \'BiColorRGBG10p\',\n    0x022000A9: \'BiColorBGRG10\',\n    0x021400AA: \'BiColorBGRG10p\',\n    0x022000AB: \'BiColorRGBG12\',\n    0x021800AC: \'BiColorRGBG12p\',\n    0x022000AD: \'BiColorBGRG12\',\n    0x021800AE: \'BiColorBGRG12p\',\n    0x010800AF: \'Coord3D_A8\',\n    0x010800B0: \'Coord3D_B8\',\n    0x010800B1: \'Coord3D_C8\',\n    0x021800B2: \'Coord3D_ABC8\',\n    0x021800B3: \'Coord3D_ABC8_Planar\',\n    0x021000B4: \'Coord3D_AC8\',\n    0x021000B5: \'Coord3D_AC8_Planar\',\n    0x011000B6: \'Coord3D_A16\',\n    0x011000B7: \'Coord3D_B16\',\n    0x011000B8: \'Coord3D_C16\',\n    0x023000B9: \'Coord3D_ABC16\',\n    0x023000BA: \'Coord3D_ABC16_Planar\',\n    0x022000BB: \'Coord3D_AC16\',\n    0x022000BC: \'Coord3D_AC16_Planar\',\n    0x012000BD: \'Coord3D_A32f\',\n    0x012000BE: \'Coord3D_B32f\',\n    0x012000BF: \'Coord3D_C32f\',\n    0x026000C0: \'Coord3D_ABC32f\',\n    0x026000C1: \'Coord3D_ABC32f_Planar\',\n    0x024000C2: \'Coord3D_AC32f\',\n    0x024000C3: \'Coord3D_AC32f_Planar\',\n    0x010800C4: \'Confidence1\',\n    0x010100C5: \'Confidence1p\',\n    0x010800C6: \'Confidence8\',\n    0x011000C7: \'Confidence16\',\n    0x012000C8: \'Confidence32f\',\n    0x010800C9: \'R8\',\n    0x010A00CA: \'R10\',\n    0x010C00CB: \'R12\',\n    0x011000CC: \'R16\',\n    0x010800CD: \'G8\',\n    0x010A00CE: \'G10\',\n    0x010C00CF: \'G12\',\n    0x011000D0: \'G16\',\n    0x010800D1: \'B8\',\n    0x010A00D2: \'B10\',\n    0x010C00D3: \'B12\',\n    0x011000D4: \'B16\',\n    0x010A00D5: \'Coord3D_A10p\',\n    0x010A00D6: \'Coord3D_B10p\',\n    0x010A00D7: \'Coord3D_C10p\',\n    0x010C00D8: \'Coord3D_A12p\',\n    0x010C00D9: \'Coord3D_B12p\',\n    0x010C00DA: \'Coord3D_C12p\',\n    0x021E00DB: \'Coord3D_ABC10p\',\n    0x021E00DC: \'Coord3D_ABC10p_Planar\',\n    0x022400DE: \'Coord3D_ABC12p\',\n    0x022400DF: \'Coord3D_ABC12p_Planar\',\n    0x021400F0: \'Coord3D_AC10p\',\n    0x021400F1: \'Coord3D_AC10p_Planar\',\n    0x021800F2: \'Coord3D_AC12p\',\n    0x021800F3: \'Coord3D_AC12p_Planar\',\n    0x021800F4: \'YCbCr2020_8_CbYCr\',\n    0x023000F5: \'YCbCr2020_10_CbYCr\',\n    0x021E00F6: \'YCbCr2020_10p_CbYCr\',\n    0x023000F7: \'YCbCr2020_12_CbYCr\',\n    0x022400F8: \'YCbCr2020_12p_CbYCr\',\n    0x020C00F9: \'YCbCr2020_411_8_CbYYCrYY\',\n    0x021000FA: \'YCbCr2020_422_8\',\n    0x021000FB: \'YCbCr2020_422_8_CbYCrY\',\n    0x022000FC: \'YCbCr2020_422_10\',\n    0x022000FD: \'YCbCr2020_422_10_CbYCrY\',\n    0x021400FE: \'YCbCr2020_422_10p\',\n    0x021400FF: \'YCbCr2020_422_10p_CbYCrY\',\n    0x02200100: \'YCbCr2020_422_12\',\n    0x02200101: \'YCbCr2020_422_12_CbYCrY\',\n    0x02180102: \'YCbCr2020_422_12p\',\n    0x02180103: \'YCbCr2020_422_12p_CbYCrY\',\n}\n\n'"
src/harvesters/util/logging.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nfrom logging import getLogger\nfrom logging import StreamHandler, Formatter\nfrom logging import ERROR\nfrom logging.config import fileConfig\nimport os\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\n_name = \'HARVESTERS_LOGGING_CONFIG\'\n_config_file = None\nif _name in os.environ:\n    _config_file = os.getenv(_name)\n    if os.path.exists(_config_file):\n        pass\n    else:\n        _config_file = None\n\n\ndef get_logger(*, logger_given=None, name=None, level=ERROR):\n    #\n    if logger_given:\n        # Use their logger:\n        logger = logger_given\n    else:\n        # Use our logger:\n        if _config_file:\n            # Set up the logger following to the configuration file:\n            with open(_config_file) as file:\n                fileConfig(fname=file)\n            #\n            logger = getLogger(name=\'harvesters\')\n\n        else:\n            if not name:\n                name = __name__\n\n            # Set up the logger following to the default configuration:\n            logger = getLogger(name)\n            logger.setLevel(level)\n\n            # The default logger uses only a stream handler:\n            logging_handler = StreamHandler()\n\n            # Check if handlers are already present:\n            if logger.hasHandlers():\n                # Then clear the handlers before adding new handlers:\n                logger.handlers.clear()\n\n            # Set up the formatter:\n            formatter = Formatter(\n                \'%(asctime)s :: %(name)s :: %(levelname)s :: %(message)s\'\n            )\n            logging_handler.setFormatter(formatter)\n            logging_handler.setLevel(level)\n\n            #\n            logger.addHandler(logging_handler)\n\n        #\n        logger.propagate = False\n\n    return logger\n\n\n'"
src/harvesters/util/pfnc.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nfrom enum import IntEnum\nfrom typing import Optional\n\n# Related third party imports\nimport numpy\n\n# Local application/library specific imports\nfrom harvesters.util._pfnc import symbolics as _symbolics\n\n#\nsymbolics = _symbolics\ndict_by_ints = symbolics\ndict_by_names = {n: i for i, n in symbolics.items()}\n\n# 32-bit value layout\n# |31            24|23            16|15            08|07            00|\n# | C| Comp. Layout| Effective Size |            Pixel ID             |\n\n# Custom flag\npfnc_custom = 0x80000000\n\n# Component layout\npfnc_single_component = 0x01000000\npfnc_multiple_component = 0x02000000\npfnc_component_mask = 0x02000000\n\n# Effective size\npfnc_pixel_size_mask = 0x00ff0000\npfnc_pixel_size_shift = 16\n\n\ndef get_effective_pixel_size(pixel_format_value):\n    """"""\n    Returns the effective pixel size (number of bits a pixel occupies in memory).\n    This includes padding in many cases and the actually used bits are less.\n    """"""\n    return (pixel_format_value & pfnc_pixel_size_mask) >> \\\n           pfnc_pixel_size_shift\n\n\ndef is_custom(pixel_format_value):\n    return (pixel_format_value & pfnc_custom) == pfnc_custom\n\n\ndef is_single_component(pixel_format_value):\n    return (pixel_format_value & pfnc_component_mask) == pfnc_single_component\n\n\ndef is_multiple_component(pixel_format_value):\n    return (pixel_format_value & pfnc_component_mask) == pfnc_multiple_component\n\n\ndef get_bits_per_pixel(data_format):\n    """"""\n    Returns the number of (used) bits per pixel.\n    So without padding.\n    Returns None if format is not known.\n    """"""\n    if data_format in component_8bit_formats:\n        return 8\n    elif data_format in component_10bit_formats:\n        return 10\n    elif data_format in component_12bit_formats:\n        return 12\n    elif data_format in component_14bit_formats:\n        return 14\n    elif data_format in component_16bit_formats:\n        return 16\n    # format not known\n    return None\n\n\nmono_location_formats = [\n    #\n    \'Mono8\',\n    \'Mono8s\',\n    \'Mono10\',\n    \'Mono12\',\n    \'Mono14\',\n    \'Mono16\',\n    #\n    \'R8\',\n    \'R10\',\n    \'R12\',\n    \'R16\',\n    \'G8\',\n    \'G10\',\n    \'G12\',\n    \'G16\',\n    \'B8\',\n    \'B10\',\n    \'B12\',\n    \'B16\',\n    #\n    \'Coord3D_A8\',\n    \'Coord3D_B8\',\n    \'Coord3D_C8\',\n    \'Coord3D_A16\',\n    \'Coord3D_B16\',\n    \'Coord3D_C16\',\n    \'Coord3D_A32f\',\n    \'Coord3D_B32f\',\n    \'Coord3D_C32f\',\n    #\n    \'Confidence1\',\n    \'Confidence8\',\n    \'Confidence16\',\n    \'Confidence32f\',\n]\n\nmono_packed_location_formats = [\n    \'Mono1p\',\n    \'Mono2p\',\n    \'Mono4p\',\n    \'Mono10Packed\',\n    \'Mono10p\',\n    \'Mono12Packed\',\n    \'Mono12p\',\n    \'Coord3D_A10p\',\n    \'Coord3D_B10p\',\n    \'Coord3D_C10p\',\n    \'Coord3D_A12p\',\n    \'Coord3D_B12p\',\n    \'Coord3D_C12p\',\n]\n\nlmn_444_location_formats = [\n    #\n    \'RGB8\',\n    \'RGB10\',\n    \'RGB12\',\n    \'RGB14\',\n    \'RGB16\',\n    #\n    \'BGR8\',\n    \'BGR10\',\n    \'BGR12\',\n    \'BGR14\',\n    \'BGR16\',\n    #\n    \'Coord3D_ABC8\',\n    \'Coord3D_ABC8_Planar\',\n    \'Coord3D_ABC16\',\n    \'Coord3D_ABC16_Planar\',\n    \'Coord3D_ABC32f\',\n    \'Coord3D_ABC32f_Planar\',\n]\n\nlmn_444_packed_location_formats = [\n    #\n    \'RGB8Packed\',\n    #\n    \'Coord3D_ABC10p\',\n    \'Coord3D_ABC10p_Planar\',\n    \'Coord3D_ABC12p\',\n    \'Coord3D_ABC12p_Planar\',\n]\n\nlmn_422_location_formats = [\n    \'YUV422_8_UYVY\',\n    \'YUV422_8\',\n    \'YCbCr422_8\',\n    \'YCbCr601_422_8\',\n    \'YCbCr709_422_8\',\n    \'YCbCr422_8_CbYCrY\',\n    \'YCbCr601_422_8_CbYCrY\',\n    \'YCbCr709_422_8_CbYCrY\',\n    \'YCbCr422_10\',\n    \'YCbCr422_12\',\n    \'YCbCr601_422_10\',\n    \'YCbCr601_422_12\',\n    \'YCbCr709_422_10\',\n    \'YCbCr709_422_12\',\n    \'YCbCr422_10_CbYCrY\',\n    \'YCbCr422_12_CbYCrY\',\n    \'YCbCr601_422_10_CbYCrY\',\n    \'YCbCr601_422_12_CbYCrY\',\n    \'YCbCr709_422_10_CbYCrY\',\n    \'YCbCr709_422_12_CbYCrY\',\n    \'YCbCr2020_422_8\',\n    \'YCbCr2020_422_8_CbYCrY\',\n    \'YCbCr2020_422_10\',\n    \'YCbCr2020_422_10_CbYCrY\',\n    \'YCbCr2020_422_12\',\n    \'YCbCr2020_422_12_CbYCrY\',\n]\n\nlmn_422_packed_location_formats = [\n    \'YCbCr422_10p\',\n    \'YCbCr422_12p\',\n    \'YCbCr601_422_10p\',\n    \'YCbCr601_422_12p\',\n    \'YCbCr709_422_10p\',\n    \'YCbCr709_422_12p\',\n    \'YCbCr422_10p_CbYCrY\',\n    \'YCbCr422_12p_CbYCrY\',\n    \'YCbCr601_422_10p_CbYCrY\',\n    \'YCbCr601_422_12p_CbYCrY\',\n    \'YCbCr709_422_10p_CbYCrY\',\n    \'YCbCr709_422_12p_CbYCrY\',\n    \'YCbCr2020_422_10p\',\n    \'YCbCr2020_422_10p_CbYCrY\',\n    \'YCbCr2020_422_12p\',\n    \'YCbCr2020_422_12p_CbYCrY\',\n]\n\nlmn_411_location_formats = [\n    \'YUV411_8_UYYVYY\',\n    \'YCbCr411_8_CbYYCrYY\',\n    \'YCbCr601_411_8_CbYYCrYY\',\n    \'YCbCr709_411_8_CbYYCrYY\',\n    \'YCbCr411_8\',\n    \'YCbCr2020_411_8_CbYYCrYY\',\n]\n\nlmno_4444_location_formats = [\n    \'RGBa8\',\n    \'RGBa10\',\n    \'RGBa12\',\n    \'RGBa14\',\n    \'RGBa16\',\n    \'BGRa8\',\n    \'BGRa10\',\n    \'BGRa12\',\n    \'BGRa14\',\n    \'BGRa16\',\n]\n\nlmno_4444_packed_location_formats = [\n    \'RGBa10p\',\n    \'RGBa12p\',\n    \'BGRa10p\',\n    \'BGRa12p\',\n]\n\nlm_44_location_formats = [\n    \'Coord3D_AC8\',\n    \'Coord3D_AC8_Planar\',\n    \'Coord3D_AC16\',\n    \'Coord3D_AC16_Planar\',\n    \'Coord3D_AC32f\',\n    \'Coord3D_AC32f_Planar\',\n]\n\nlm_44_packed_location_formats = [\n    \'Coord3D_AC10p\',\n    \'Coord3D_AC10p_Planar\',\n    \'Coord3D_AC12p\',\n    \'Coord3D_AC12p_Planar\',\n]\n\nbayer_location_formats = [\n    \'BayerGR8\',\n    \'BayerRG8\',\n    \'BayerGB8\',\n    \'BayerBG8\',\n    \'BayerGR10\',\n    \'BayerRG10\',\n    \'BayerGB10\',\n    \'BayerBG10\',\n    \'BayerGR12\',\n    \'BayerRG12\',\n    \'BayerGB12\',\n    \'BayerBG12\',\n    \'BayerGR16\',\n    \'BayerRG16\',\n    \'BayerGB16\',\n    \'BayerBG16\',\n]\n\nbayer_packed_location_formats = [\n    \'BayerGR10Packed\',\n    \'BayerRG10Packed\',\n    \'BayerGB10Packed\',\n    \'BayerBG10Packed\',\n    \'BayerGR12Packed\',\n    \'BayerRG12Packed\',\n    \'BayerGB12Packed\',\n    \'BayerBG12Packed\',\n    \'BayerBG10p\',\n    \'BayerBG12p\',\n    \'BayerGB10p\',\n    \'BayerGB12p\',\n    \'BayerGR10p\',\n    \'BayerGR12p\',\n    \'BayerRG10p\',\n    \'BayerRG12p\',\n]\n\nuint8_formats = [\n    #\n    \'Mono8\',\n    #\n    \'RGB8\',\n    \'RGB8Packed\',\n    \'RGBa8\',\n    #\n    \'BGR8\',\n    \'BGRa8\',\n    #\n    \'BayerGR8\',\n    \'BayerGB8\',\n    \'BayerRG8\',\n    \'BayerBG8\',\n    #\n    \'Coord3D_A8\',\n    \'Coord3D_B8\',\n    \'Coord3D_C8\',\n    \'Coord3D_ABC8\',\n    \'Coord3D_ABC8_Planar\',\n    \'Coord3D_AC8\',\n    \'Coord3D_AC8_Planar\',\n    #\n    \'Confidence1\',\n    \'Confidence8\',\n]\n\nuint16_formats = [\n    #\n    \'Mono10\',\n    \'Mono12\',\n    \'Mono14\',\n    \'Mono16\',\n    #\n    \'RGB10\',\n    \'RGB12\',\n    \'RGB14\',\n    \'RGB16\',\n    #\n    \'BGR10\',\n    \'BGR12\',\n    \'BGR14\',\n    \'BGR16\',\n    #\n    \'RGBa10\',\n    \'RGBa12\',\n    \'RGBa14\',\n    \'RGBa16\',\n    #\n    \'BGRa10\',\n    \'BGRa12\',\n    \'BGRa14\',\n    \'BGRa16\',\n    #\n    \'BayerGR10\',\n    \'BayerGB10\',\n    \'BayerRG10\',\n    \'BayerBG10\',\n    #\n    \'BayerGR12\',\n    \'BayerGB12\',\n    \'BayerRG12\',\n    \'BayerBG12\',\n    #\n    \'BayerGR16\',\n    \'BayerRG16\',\n    \'BayerGB16\',\n    \'BayerBG16\',\n    #\n    \'Coord3D_A16\',\n    \'Coord3D_B16\',\n    \'Coord3D_C16\',\n    #\n    \'Coord3D_ABC16\',\n    \'Coord3D_ABC16_Planar\',\n    #\n    \'Coord3D_AC16\',\n    \'Coord3D_AC16_Planar\',\n    #\n    \'Coord3D_A10p\',\n    \'Coord3D_B10p\',\n    \'Coord3D_C10p\',\n    #\n    \'Coord3D_A12p\',\n    \'Coord3D_B12p\',\n    \'Coord3D_C12p\',\n    #\n    \'Coord3D_ABC10p\',\n    \'Coord3D_ABC10p_Planar\',\n    #\n    \'Coord3D_ABC12p\',\n    \'Coord3D_ABC12p_Planar\',\n    #\n    \'Coord3D_AC10p\',\n    \'Coord3D_AC10p_Planar\',\n    #\n    \'Coord3D_AC12p\',\n    \'Coord3D_AC12p_Planar\',\n    #\n    \'Confidence16\',\n]\n\nuint32_formats = [\n    \'Mono32\',\n]\n\nfloat32_formats = [\n    #\n    \'Coord3D_A32f\',\n    \'Coord3D_B32f\',\n    \'Coord3D_C32f\',\n    #\n    \'Coord3D_ABC32f\',\n    \'Coord3D_ABC32f_Planar\',\n    #\n    \'Coord3D_AC32f\',\n    \'Coord3D_AC32f_Planar\',\n    #\n    \'Confidence32f\',\n]\n\ncomponent_8bit_formats = [\n    #\n    \'Mono8\',\n    #\n    \'RGB8\',\n    \'RGBa8\',\n    #\n    \'BGR8\',\n    \'BGRa8\',\n    #\n    \'BayerGR8\',\n    \'BayerGB8\',\n    \'BayerRG8\',\n    \'BayerBG8\',\n    #\n    \'Confidence8\',\n]\n\ncomponent_10bit_formats = [\n    #\n    \'Mono10\',\n    #\n    \'RGB10\',\n    \'RGBa10\',\n    #\n    \'BGR10\',\n    \'BGRa10\',\n    #\n    \'BayerGR10\',\n    \'BayerGB10\',\n    \'BayerRG10\',\n    \'BayerBG10\',\n]\n\ncomponent_12bit_formats = [\n    #\n    \'Mono12\',\n    #\n    \'RGB12\',\n    \'RGBa12\',\n    #\n    \'BGR12\',\n    \'BGRa12\',\n    #\n    \'BayerGR12\',\n    \'BayerGB12\',\n    \'BayerRG12\',\n    \'BayerBG12\',\n]\n\ncomponent_14bit_formats = [\n    #\n    \'Mono14\',\n    #\n    \'RGB14\',\n    \'RGBa14\',\n    #\n    \'BGR14\',\n    \'BGRa14\',\n]\n\ncomponent_16bit_formats = [\n    #\n    \'Mono16\',\n    #\n    \'RGB16\',\n    \'RGBa16\',\n    #\n    \'BayerGR16\',\n    \'BayerRG16\',\n    \'BayerGB16\',\n    \'BayerBG16\',\n    #\n    \'Coord3D_A16\',\n    \'Coord3D_B16\',\n    \'Coord3D_C16\',\n    #\n    \'Coord3D_ABC16\',\n    \'Coord3D_ABC16_Planar\',\n    #\n    \'Coord3D_AC16\',\n    \'Coord3D_AC16_Planar\',\n    #\n    \'Confidence16\',\n]\n\ncomponent_32bit_formats = [\n    \'Confidence32f\',\n]\n\ncomponent_2d_formats = [\n    #\n    \'Mono8\',\n    \'Mono10\',\n    \'Mono12\',\n    \'Mono14\',\n    \'Mono16\',\n    #\n    \'Mono10Packed\',\n    \'Mono12Packed\',\n    #\n    \'RGB8\',\n    \'RGB10\',\n    \'RGB12\',\n    \'RGB14\',\n    \'RGB16\',\n    #\n    \'BGR8\',\n    \'BGR10\',\n    \'BGR12\',\n    \'BGR14\',\n    \'BGR16\',\n    #\n    \'RGBa8\',\n    \'RGBa10\',\n    \'RGBa12\',\n    \'RGBa14\',\n    \'RGBa16\',\n    #\n    \'BGRa8\',\n    \'BGRa10\',\n    \'BGRa12\',\n    \'BGRa14\',\n    \'BGRa16\',\n    #\n    \'BayerGR8\',\n    \'BayerGB8\',\n    \'BayerRG8\',\n    \'BayerBG8\',\n    #\n    \'BayerGR10\',\n    \'BayerGB10\',\n    \'BayerRG10\',\n    \'BayerBG10\',\n    #\n    \'BayerGR12\',\n    \'BayerGB12\',\n    \'BayerRG12\',\n    \'BayerBG12\',\n    #\n    \'BayerGR16\',\n    \'BayerRG16\',\n    \'BayerGB16\',\n    \'BayerBG16\',\n    #\n    \'Coord3D_A8\',\n    \'Coord3D_B8\',\n    \'Coord3D_C8\',\n    \'Coord3D_ABC8\',\n    \'Coord3D_ABC8_Planar\',\n    \'Coord3D_AC8\',\n    \'Coord3D_AC8_Planar\',\n    \'Coord3D_A16\',\n    \'Coord3D_B16\',\n    \'Coord3D_C16\',\n    \'Coord3D_ABC16\',\n    \'Coord3D_ABC16_Planar\',\n    \'Coord3D_AC16\',\n    \'Coord3D_AC16_Planar\',\n    \'Coord3D_A32f\',\n    \'Coord3D_B32f\',\n    \'Coord3D_C32f\',\n    \'Coord3D_ABC32f\',\n    \'Coord3D_ABC32f_Planar\',\n    \'Coord3D_AC32f\',\n    \'Coord3D_AC32f_Planar\',\n    \'Coord3D_A10p\',\n    \'Coord3D_B10p\',\n    \'Coord3D_C10p\',\n    \'Coord3D_A12p\',\n    \'Coord3D_B12p\',\n    \'Coord3D_C12p\',\n    \'Coord3D_ABC10p\',\n    \'Coord3D_ABC10p_Planar\',\n    \'Coord3D_ABC12p\',\n    \'Coord3D_ABC12p_Planar\',\n    \'Coord3D_AC10p\',\n    \'Coord3D_AC10p_Planar\',\n    \'Coord3D_AC12p\',\n    \'Coord3D_AC12p_Planar\',\n    #\n    \'Confidence1\',\n    \'Confidence1p\',\n    \'Confidence8\',\n    \'Confidence16\',\n    \'Confidence32f\',\n]\n\nrgb_formats = [\n    #\n    \'RGB8\',\n    \'RGB10\',\n    \'RGB12\',\n    \'RGB14\',\n    \'RGB16\',\n]\n\nrgba_formats = [\n    #\n    \'RGBa8\',\n    \'RGBa10\',\n    \'RGBa12\',\n    \'RGBa14\',\n    \'RGBa16\',\n]\n\nbgr_formats = [\n    #\n    \'BGR8\',\n    \'BGR10\',\n    \'BGR12\',\n    \'BGR14\',\n    \'BGR16\',\n]\n\nbgra_formats = [\n    #\n    \'BGRa8\',\n    \'BGRa10\',\n    \'BGRa12\',\n    \'BGRa14\',\n    \'BGRa16\',\n]\n\n\nclass _DataSize(IntEnum):\n    INT8 = 1\n    UINT8 = 2\n    UINT16 = 3\n    UINT32 = 4\n    FLOAT32 = 5\n\n\nclass _Location(IntEnum):\n    MONO = 1\n    LMN444 = 2\n    LMN422 = 3\n    LMN411 = 4\n    LMNO4444 = 5\n    LM44 = 6\n    BAYER = 7\n\n\nclass _Alignment:\n    def __init__(self, unpacked: IntEnum, packed: Optional[IntEnum] = None):\n        #\n        super().__init__()\n        #\n        self._unpacked = unpacked\n        self._packed = packed if packed else unpacked\n        #\n        for target in (self._packed, self._unpacked):\n            size = self._get_size(target)\n            assert size > 0\n            assert (size % 4) == 0\n        assert self._get_size(self._unpacked) >= self._get_size(self._packed)\n\n    def __repr__(self):\n        repr = \'\'\n        repr += \'Unpacked: {}, \'.format(self.unpacked)\n        repr += \'Unpacked size: {}, \'.format(self.unpacked_size)\n        repr += \'Packed: {}, \'.format(self.packed)\n        repr += \'Is packed: {}\'.format(self.is_packed())\n        return repr\n\n    @property\n    def unpacked(self):\n        return self._unpacked\n\n    @property\n    def unpacked_size(self):\n        return self._get_size(self.unpacked) / 8\n\n    @property\n    def packed(self):\n        return self._packed\n\n    def is_packed(self):\n        return self._unpacked != self._packed\n\n    @staticmethod\n    def _get_size(index: IntEnum):\n        if (index == _DataSize.INT8) or (index == _DataSize.UINT8):\n            return 8\n        elif index == _DataSize.UINT16:\n            return 16\n        elif (index == _DataSize.UINT32) or (index == _DataSize.FLOAT32):\n            return 32\n        else:\n            raise ValueError\n\n\nclass _PixelFormat:\n    def __init__(\n            self, alignment: _Alignment = None, symbolic: str = None,\n            nr_components=None, unit_depth_in_bit: int = None,\n            location: _Location = None):\n        #\n        super().__init__()\n        #\n        self._alignment = alignment\n        self._symbolic = symbolic\n        self._nr_components = nr_components\n        self._unit_depth_in_bit = unit_depth_in_bit\n        self._location = location\n        #\n        self._check_validity()\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        raise NotImplementedError\n\n    @property\n    def alignment(self):\n        return self._alignment\n\n    @property\n    def symbolic(self) -> str:\n        return self._symbolic\n\n    @property\n    def nr_components(self):\n        return self._nr_components\n\n    @property\n    def depth_in_bit(self):\n        return self._nr_components * self._unit_depth_in_bit\n\n    @property\n    def depth_in_byte(self):\n        return self.depth_in_bit / 8\n\n    @property\n    def location(self):\n        return self._location\n\n    def _check_validity(self):\n        assert self._alignment\n        assert self._symbolic\n        assert self._nr_components\n        assert self._unit_depth_in_bit\n        assert self._location\n\n    def __repr__(self):\n        repr = \'\'\n        repr += \'Symbolic: {}, \'.format(self.symbolic)\n        repr += \'Nr. components: {}, \'.format(self.nr_components)\n        repr += \'Depth[b]: {}, \'.format(self.depth_in_bit)\n        repr += \'Depth[B]: {}, \'.format(self.depth_in_byte)\n        repr += \'Data boundary: {}\'.format(self.alignment)\n        return repr\n\n\n# ----\n\n\nclass _Unpacked(_PixelFormat):\n    def __init__(\n            self, alignment: _Alignment = None, symbolic: str = None,\n            nr_components=None, unit_depth_in_bit: int = None,\n            location: _Location = None):\n        #\n        super().__init__(\n            alignment=alignment,\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n\n# ----\n\n\nclass _Unpacked_Uint8(_Unpacked):\n    def __init__(\n            self, symbolic: str = None, nr_components=None,\n            unit_depth_in_bit: int = None, location: _Location = None):\n        #\n        super().__init__(\n            alignment=_Alignment(unpacked=_DataSize.UINT8),\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array\n\n\nclass _Unpacked_Int8(_Unpacked):\n    def __init__(\n            self, symbolic: str = None, nr_components=None,\n            unit_depth_in_bit: int = None, location: _Location = None):\n        #\n        super().__init__(\n            alignment=_Alignment(unpacked=_DataSize.INT8),\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.int8)\n\n\nclass _Unpacked_Uint16(_Unpacked):\n    def __init__(\n            self, symbolic: str = None, nr_components=None,\n            unit_depth_in_bit: int = None, location: _Location = None):\n        #\n        super().__init__(\n            alignment=_Alignment(unpacked=_DataSize.UINT16),\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.uint16)\n\n\nclass _Unpacked_Float32(_Unpacked):\n    def __init__(\n            self, symbolic: str = None, nr_components=None,\n            unit_depth_in_bit: int = None, location: _Location = None):\n        #\n        super().__init__(\n            alignment=_Alignment(unpacked=_DataSize.FLOAT32),\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.float32)\n\n\n# ----\n\n\nclass _Mono_Unpacked_Uint8(_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.MONO\n        )\n\n\nclass _Mono_Unpacked_Int8(_Unpacked_Int8):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location = _Location.MONO\n        )\n\n\nclass _Mono_Unpacked_Uint16(_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.MONO\n        )\n\n\nclass _Mono_Unpacked_Float32(_Unpacked_Float32):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            unit_depth_in_bit=32,\n            location=_Location.MONO\n        )\n\n\n# ----\n\n\nclass Mono8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Mono8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass Mono8s(_Mono_Unpacked_Int8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Mono8s\',\n            unit_depth_in_bit=8\n        )\n\n\nclass Mono10(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Mono10\',\n            unit_depth_in_bit=10\n        )\n\n\nclass Mono12(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Mono12\',\n            unit_depth_in_bit=12\n        )\n\n\nclass Mono14(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Mono14\',\n            unit_depth_in_bit=14\n        )\n\n\nclass Mono16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Mono16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass R8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'R8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass R10(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'R10\',\n            unit_depth_in_bit=10\n        )\n\n\nclass R12(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'R12\',\n            unit_depth_in_bit=12\n        )\n\n\nclass R16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'R16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass G8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'G8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass G10(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'G10\',\n            unit_depth_in_bit=10\n        )\n\n\nclass G12(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'G12\',\n            unit_depth_in_bit=12\n        )\n\n\nclass G16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'G16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass B8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'B8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass B10(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'B10\',\n            unit_depth_in_bit=10\n        )\n\n\nclass B12(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'B12\',\n            unit_depth_in_bit=12\n        )\n\n\nclass B16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'B16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass Coord3D_A8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Coord3D_A8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass Coord3D_B8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Coord3D_B8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass Coord3D_C8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Coord3D_C8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass Coord3D_A16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Coord3D_A16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass Coord3D_B16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Coord3D_B16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass Coord3D_C16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Coord3D_C16\',\n            unit_depth_in_bit=16\n        )\n\n\n# ----\n\n\nclass Coord3D_A32f(_Mono_Unpacked_Float32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_A32f\')\n\n\nclass Coord3D_B32f(_Mono_Unpacked_Float32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_B32f\')\n\n\nclass Coord3D_C32f(_Mono_Unpacked_Float32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_C32f\')\n\n\n# ----\n\n\nclass Confidence1(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Confidence1\',\n            unit_depth_in_bit=1\n        )\n\n\nclass Confidence8(_Mono_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Confidence8\',\n            unit_depth_in_bit=8\n        )\n\n\nclass Confidence16(_Mono_Unpacked_Uint16):\n    def __init__(self):\n        #\n        super().__init__(\n            symbolic=\'Confidence16\',\n            unit_depth_in_bit=16\n        )\n\n\nclass Confidence32f(_Mono_Unpacked_Float32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Confidence32f\')\n\n\n# ----\n\n\nclass _Packed(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, nr_components=None,\n            unit_depth_in_bit: int = None, location: _Location = None):\n        #\n        super().__init__(\n            alignment=_Alignment(\n                unpacked=_DataSize.UINT16, packed=_DataSize.UINT8\n            ),\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n\n# ----\n\n\nclass _GroupPacked(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, nr_components: float = None,\n            unit_depth_in_bit: int = None, location: _Location = None):\n        #\n        super().__init__(\n            alignment=_Alignment(\n                unpacked=_DataSize.UINT16, packed=_DataSize.UINT8\n            ),\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=location\n        )\n\n\n# ----\n\n\nclass _GroupPacked_10(_GroupPacked):\n    def __init__(\n            self, symbolic: str = None, nr_components: float = None,\n            location: _Location = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=10,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        nr_packed = 3\n        nr_unpacked = 2\n        #\n        p1st, p2nd, p3rd = numpy.reshape(\n            array, (array.shape[0] // nr_packed, nr_packed)\n        ).astype(numpy.uint16).T\n        #\n        mask = 0x3\n        up1st = numpy.bitwise_or(\n            p1st << 2, numpy.bitwise_and(mask, p2nd)\n        )\n        up2nd = numpy.bitwise_or(\n            p3rd << 2, numpy.bitwise_and(mask, p2nd >> 4)\n        )\n        #\n        return numpy.reshape(\n            numpy.concatenate(\n                (up1st[:, None], up2nd[:, None]), axis=1\n            ),\n            nr_unpacked * up1st.shape[0]\n        )\n\n\nclass _GroupPacked_12(_GroupPacked):\n    def __init__(\n            self, symbolic: str = None, nr_components: float = None,\n            location: _Location = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=nr_components,\n            unit_depth_in_bit=12,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        nr_packed = 3\n        nr_unpacked = 2\n        #\n        p1st, p2nd, p3rd = numpy.reshape(\n            array, (array.shape[0] // nr_packed, nr_packed)\n        ).astype(numpy.uint16).T\n        #\n        mask = 0xf\n        up1st = numpy.bitwise_or(\n            p1st << 4, numpy.bitwise_and(mask, p2nd)\n        )\n        up2nd = numpy.bitwise_or(\n            p3rd << 4, numpy.bitwise_and(mask, p2nd >> 4)\n        )\n        #\n        return numpy.reshape(\n            numpy.concatenate(\n                (up1st[:, None], up2nd[:, None]), axis=1\n            ),\n            nr_unpacked * up1st.shape[0]\n        )\n\n\n# ----\n\n\nclass _10p(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, nr_components: float = None,\n            location: _Location = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(\n                unpacked=_DataSize.UINT16, packed=_DataSize.UINT8\n            ),\n            nr_components=nr_components,\n            unit_depth_in_bit=10,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        nr_packed = 4\n        nr_unpacked = 3\n        #\n        p1st, p2nd, p3rd, p4th = numpy.reshape(\n            array, (array.shape[0] // nr_packed, nr_packed)\n        ).astype(numpy.uint16).T\n        #\n        up1st = numpy.bitwise_or(\n            p1st, numpy.bitwise_and(0x300, p2nd << 8)\n        )\n        up2nd = numpy.bitwise_or(\n            numpy.bitwise_and(0x3f, p2nd >> 2),\n            numpy.bitwise_and(0x3e0, p3rd << 6)\n        )\n        up3rd = numpy.bitwise_or(\n            numpy.bitwise_and(0x7, p3rd >> 5),\n            numpy.bitwise_and(0x7f8, p4th << 3)\n        )\n        #\n        return numpy.reshape(\n            numpy.concatenate(\n                (up1st[:, None], up2nd[:, None], up3rd[:, None]), axis=1\n            ),\n            nr_unpacked * up1st.shape[0]\n        )\n\n\nclass _12p(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, nr_components: float = None,\n            location: _Location = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(\n                unpacked=_DataSize.UINT16, packed=_DataSize.UINT8\n            ),\n            nr_components=nr_components,\n            unit_depth_in_bit=12,\n            location=location\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        nr_packed = 3\n        nr_unpacked = 2\n        #\n        p1st, p2nd, p3rd = numpy.reshape(\n            array, (array.shape[0] // nr_packed, nr_packed)\n        ).astype(numpy.uint16).T\n        #\n        up1st = numpy.bitwise_or(\n            p1st, numpy.bitwise_and(0xf00, p2nd << 8)\n        )\n        up2nd = numpy.bitwise_or(\n            numpy.bitwise_and(0xf, p2nd >> 4),\n            numpy.bitwise_and(0xff0, p3rd << 4)\n        )\n        #\n        return numpy.reshape(\n            numpy.concatenate(\n                (up1st[:, None], up2nd[:, None]), axis=1\n            ),\n            nr_unpacked * up1st.shape[0]\n        )\n\n\n# ----\n\n\nclass _Mono_10p(_10p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            location=_Location.MONO\n        )\n\n\nclass _Mono_12p(_12p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            location = _Location.MONO\n        )\n\n\n# ----\n\n\nclass _Mono_GroupPacked_10(_GroupPacked_10):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            location=_Location.MONO\n        )\n\n\nclass _Mono_GroupPacked_12(_GroupPacked_12):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1.,\n            location=_Location.MONO\n        )\n\n\n# ----\n\n\nclass Mono10p(_Mono_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Mono10p\')\n\n\nclass Mono10Packed(_Mono_GroupPacked_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Mono10Packed\')\n\n\nclass Mono12Packed(_Mono_GroupPacked_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Mono12Packed\')\n\n\nclass Mono12p(_Mono_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Mono12p\')\n\n\nclass Coord3D_A10p(_Mono_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_A10p\')\n\n\nclass Coord3D_B10p(_Mono_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_B10p\')\n\n\nclass Coord3D_C10p(_Mono_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_C10p\')\n\n\nclass Coord3D_A12p(_Mono_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_A12p\')\n\n\nclass Coord3D_B12p(_Mono_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_B12p\')\n\n\nclass Coord3D_C12p(_Mono_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_C12p\')\n\n\n# \'Mono1p\',\n# \'Mono2p\',\n# \'Mono4p\',\n\n\n# ----\n\n\nclass _LMN444_Unpacked_Uint8(_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LMN444\n        )\n\n\nclass _LMN444_Unpacked_Uint16(_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LMN444\n        )\n\n\nclass _LMN444_Unpacked_Float32(_Unpacked_Float32):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LMN444\n        )\n\n\n# ----\n\n\nclass _LMN444_Unpacked_Uint8_8(_LMN444_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=8\n        )\n\n\nclass _LMN444_Unpacked_Uint16_10(_LMN444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=10\n        )\n\n\nclass _LMN444_Unpacked_Uint16_12(_LMN444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=12\n        )\n\n\nclass _LMN444_Unpacked_Uint16_14(_LMN444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=14\n        )\n\n\nclass _LMN444_Unpacked_Uint16_16(_LMN444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=16\n        )\n\n\nclass _LMN444_Unpacked_Float32_32(_LMN444_Unpacked_Float32):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=32\n        )\n\n\n# ----\n\n\nclass RGB8(_LMN444_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGB8\')\n\n\nclass RGB10(_LMN444_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGB10\')\n\n\nclass RGB12(_LMN444_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGB12\')\n\n\nclass RGB14(_LMN444_Unpacked_Uint16_14):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGB14\')\n\n\nclass RGB16(_LMN444_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGB16\')\n\n\n# ----\n\n\nclass BGR8(_LMN444_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGR8\')\n\n\nclass BGR10(_LMN444_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGR10\')\n\n\nclass BGR12(_LMN444_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGR12\')\n\n\nclass BGR14(_LMN444_Unpacked_Uint16_14):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGR14\')\n\n\nclass BGR16(_LMN444_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGR16\')\n\n\n# ----\n\n\nclass Coord3D_ABC8(_LMN444_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC8\')\n\n\nclass Coord3D_ABC8_Planar(_LMN444_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC8_Planar\')\n\n\n# ----\n\n\nclass Coord3D_ABC16(_LMN444_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC16\')\n\n\nclass Coord3D_ABC16_Planar(_LMN444_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC16_Planar\')\n\n\n# ----\n\n\nclass Coord3D_ABC32f(_LMN444_Unpacked_Float32_32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC32f\')\n\n\nclass Coord3D_ABC32f_Planar(_LMN444_Unpacked_Float32_32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC32f_Planar\')\n\n\n# \'RGB8Packed\',  # TODO\n\n\n# ----\n\n\nclass _LMN444_10p(_10p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3.,\n            location=_Location.LMN444\n        )\n\n\nclass _LMN444_12p(_12p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3.,\n            location=_Location.LMN444\n        )\n\n\n# ----\n\n\nclass Coord3D_ABC10p(_LMN444_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC10p\')\n\n\nclass Coord3D_ABC10p_Planar(_LMN444_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC10p_Planar\')\n\n\nclass Coord3D_ABC12p(_LMN444_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC12p\')\n\n\nclass Coord3D_ABC12p_Planar(_LMN444_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_ABC12p_Planar\')\n\n\n# ----\n\n\nclass _LMN422(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, alignment: _Alignment = None,\n            unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=alignment,\n            nr_components=2.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LMN422\n        )\n\n\nclass _LMN411(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, alignment: _Alignment = None,\n            unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=alignment,\n            nr_components=1.5,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LMN411\n        )\n\n\nclass _LMNO4444(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, alignment: _Alignment = None,\n            unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=alignment,\n            nr_components=4.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LMNO4444\n        )\n\n\n# ----\n\n\nclass _LMN422_Unpacked_Uint8(_LMN422):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT8),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array\n\n\nclass _LMN422_Unpacked_Uint16(_LMN422):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT16),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.uint16)\n\n\nclass _LMN411_Unpacked_Uint8(_LMN411):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT8),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array\n\n\nclass _LMNO4444_Unpacked_Uint8(_LMNO4444):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT8),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array\n\n\n# ----\n\n\nclass _LMN422_GroupPacked_10(_GroupPacked_10):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3,\n            location=_Location.LMN422\n        )\n\n\nclass _LMN422_GroupPacked_12(_GroupPacked_12):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3,\n            location=_Location.LMN422\n        )\n\n\nclass _LMN422_10p(_10p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=3,\n            location=_Location.LMN422\n        )\n\n\nclass _LMN422_12p(_12p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=2,\n            location=_Location.LMN422\n        )\n\n\n# ----\n\n\nclass _LMN422_Unpacked_Uint8_8(_LMN422_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=8\n        )\n\n\nclass _LMN422_Unpacked_Uint16_10(_LMN422_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=10\n        )\n\n\nclass _LMN422_Unpacked_Uint16_12(_LMN422_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=12\n        )\n\n\nclass _LMN411_Unpacked_Uint8_8(_LMN411_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=8\n        )\n\n\nclass _LMNO4444_Unpacked_Uint8_8(_LMNO4444_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=8\n        )\n\n\n# ----\n\n\nclass YUV422_8_UYVY(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YUV422_8_UYVY\')\n\n\nclass YUV422_8(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YUV422_8\')\n\n\nclass YCbCr422_8(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_8\')\n\n\nclass YCbCr601_422_8(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_8\')\n\n\nclass YCbCr709_422_8(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_8\')\n\n\nclass YCbCr422_8_CbYCrY(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_8_CbYCrY\')\n\n\nclass YCbCr601_422_8_CbYCrY(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_8_CbYCrY\')\n\n\nclass YCbCr709_422_8_CbYCrY(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_8_CbYCrY\')\n\n\nclass YCbCr2020_422_8(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_8\')\n\n\nclass YCbCr2020_422_8_CbYCrY(_LMN422_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_8_CbYCrY\')\n\n\nclass YCbCr422_10(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_10\')\n\n\nclass YCbCr601_422_10(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_10\')\n\n\nclass YCbCr709_422_10(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_10\')\n\n\nclass YCbCr422_10_CbYCrY(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_10_CbYCrY\')\n\n\nclass YCbCr601_422_10_CbYCrY(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_10_CbYCrY\')\n\n\nclass YCbCr709_422_10_CbYCrY(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_10_CbYCrY\')\n\n\nclass YCbCr2020_422_10(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_10\')\n\n\nclass YCbCr2020_422_10_CbYCrY(_LMN422_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_10_CbYCrY\')\n\n\nclass YCbCr422_12(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_12\')\n\n\nclass YCbCr601_422_12(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_12\')\n\n\nclass YCbCr709_422_12(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_12\')\n\n\nclass YCbCr422_12_CbYCrY(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_12_CbYCrY\')\n\n\nclass YCbCr601_422_12_CbYCrY(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_12_CbYCrY\')\n\n\nclass YCbCr709_422_12_CbYCrY(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_12_CbYCrY\')\n\n\nclass YCbCr2020_422_12(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_12\')\n\n\nclass YCbCr2020_422_12_CbYCrY(_LMN422_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_12_CbYCrY\')\n\n\n# ----\n\n\nclass YCbCr422_10p(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_10p\')\n\n\nclass YCbCr601_422_10p(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_10p\')\n\n\nclass YCbCr601_422_12p(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_12p\')\n\n\nclass YCbCr709_422_10p(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_10p\')\n\n\nclass YCbCr422_10p_CbYCrY(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_10p_CbYCrY\')\n\n\nclass YCbCr601_422_10p_CbYCrY(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_10p_CbYCrY\')\n\n\nclass YCbCr709_422_10p_CbYCrY(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_10p_CbYCrY\')\n\n\nclass YCbCr2020_422_10p(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_10p\')\n\n\nclass YCbCr2020_422_10p_CbYCrY(_LMN422_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_10p_CbYCrY\')\n\n\nclass YCbCr422_12p(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_12p\')\n\n\nclass YCbCr709_422_12p(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_12p\')\n\n\nclass YCbCr422_12p_CbYCrY(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr422_12p_CbYCrY\')\n\n\nclass YCbCr601_422_12p_CbYCrY(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_422_12p_CbYCrY\')\n\n\nclass YCbCr709_422_12p_CbYCrY(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_422_12p_CbYCrY\')\n\n\nclass YCbCr2020_422_12p(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_12p\')\n\n\nclass YCbCr2020_422_12p_CbYCrY(_LMN422_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_422_12p_CbYCrY\')\n\n\nclass YUV411_8_UYYVYY(_LMN411_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YUV411_8_UYYVYY\')\n\n\nclass YCbCr411_8_CbYYCrYY(_LMN411_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr411_8_CbYYCrYY\')\n\n\nclass YCbCr601_411_8_CbYYCrYY(_LMN411_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr601_411_8_CbYYCrYY\')\n\n\nclass YCbCr709_411_8_CbYYCrYY(_LMN411_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr709_411_8_CbYYCrYY\')\n\n\nclass YCbCr411_8(_LMN411_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr411_8\')\n\n\nclass YCbCr2020_411_8_CbYYCrYY(_LMN411_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'YCbCr2020_411_8_CbYYCrYY\')\n\n\nclass RGBa8(_LMNO4444_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa8\')\n\n\nclass BGRa8(_LMNO4444_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa8\')\n\n\n# ----\n\n\nclass _LMNO4444_Unpacked_Uint16(_LMNO4444):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT16),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.uint16)\n\n\nclass _LMNO4444_10p(_10p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=4.,\n            location=_Location.LMNO4444\n        )\n\n\nclass _LMNO4444_12p(_12p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=4.,\n            location=_Location.LMNO4444\n        )\n\n\n# ----\n\n\nclass _LMNO4444_Unpacked_Uint16_10(_LMNO4444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=10\n        )\n\n\nclass _LMNO4444_Unpacked_Uint16_12(_LMNO4444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=12\n        )\n\n\nclass _LMNO4444_Unpacked_Uint16_14(_LMNO4444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=14\n        )\n\n\nclass _LMNO4444_Unpacked_Uint16_16(_LMNO4444_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=16\n        )\n\n\n# ----\n\n\nclass RGBa10(_LMNO4444_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa10\')\n\n\nclass BGRa10(_LMNO4444_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa10\')\n\n\nclass RGBa12(_LMNO4444_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa12\')\n\n\nclass BGRa12(_LMNO4444_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa12\')\n\n\nclass RGBa14(_LMNO4444_Unpacked_Uint16_14):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa14\')\n\n\nclass BGRa14(_LMNO4444_Unpacked_Uint16_14):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa14\')\n\n\nclass RGBa16(_LMNO4444_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa16\')\n\n\nclass BGRa16(_LMNO4444_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa16\')\n\n\nclass RGBa10p(_LMNO4444_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa10p\')\n\n\nclass BGRa10p(_LMNO4444_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa10p\')\n\n\nclass RGBa12p(_LMNO4444_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'RGBa12p\')\n\n\nclass BGRa12p(_LMNO4444_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BGRa12p\')\n\n\n# ----\n\n\nclass _LM44(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, alignment: _Alignment = None,\n            unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=alignment,\n            nr_components=2.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.LM44\n        )\n\n\nclass _LM44_Unpacked_Float32(_LM44):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.FLOAT32),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.float32)\n\n\nclass _LM44_GroupPacked_10(_GroupPacked_10):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=2\n        )\n\n\nclass _LM44_GroupPacked_12(_GroupPacked_12):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=2\n        )\n\n\nclass _LM44_10p(_10p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=2,\n            location=_Location.LM44\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        raise NotImplementedError\n\n\nclass _LM44_12p(_12p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=2,\n            location=_Location.LM44\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        raise NotImplementedError\n\n\nclass _LM44_Unpacked_Uint8(_LM44):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT8),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array\n\n\nclass _LM44_Unpacked_Uint16(_LM44):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT16),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.uint16)\n\n\n# ----\n\n\nclass _LM44_Unpacked_Uint8_8(_LM44_Unpacked_Uint8):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=8\n        )\n\n\nclass _LM44_Unpacked_Uint16_16(_LM44_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=16\n        )\n\n\n# ----\n\n\nclass _LM44_Unpacked_Float32_32(_LM44_Unpacked_Float32):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=32\n        )\n\n\nclass Coord3D_AC32f(_LM44_Unpacked_Float32_32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC32f\')\n\n\nclass Coord3D_AC32f_Planar(_LM44_Unpacked_Float32_32):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC32f_Planar\')\n\n\nclass Coord3D_AC8(_LM44_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC8\')\n\n\nclass Coord3D_AC8_Planar(_LM44_Unpacked_Uint8_8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC8_Planar\')\n\n\nclass Coord3D_AC10p(_LM44_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC10p\')\n\n\nclass Coord3D_AC10p_Planar(_LM44_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC10p_Planar\')\n\n\nclass Coord3D_AC12p(_LM44_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC12p\')\n\n\nclass Coord3D_AC12p_Planar(_LM44_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC12p_Planar\')\n\n\nclass Coord3D_AC16(_LM44_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC16\')\n\n\nclass Coord3D_AC16_Planar(_LM44_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'Coord3D_AC16_Planar\')\n\n\n# ----\n\n\nclass _Bayer(_PixelFormat):\n    def __init__(\n            self, symbolic: str = None, alignment: _Alignment = None,\n            unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=alignment,\n            nr_components=1.,\n            unit_depth_in_bit=unit_depth_in_bit,\n            location=_Location.BAYER\n        )\n\n\n# ----\n\n\nclass _Bayer_Unpacked_Uint8(_Bayer):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT8),\n            unit_depth_in_bit=8\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array\n\n\nclass _Bayer_Unpacked_Uint16(_Bayer):\n    def __init__(self, symbolic: str = None, unit_depth_in_bit: int = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            alignment=_Alignment(unpacked=_DataSize.UINT16),\n            unit_depth_in_bit=unit_depth_in_bit\n        )\n\n    def expand(self, array: numpy.ndarray) -> numpy.ndarray:\n        return array.view(numpy.uint16)\n\n\n# ----\n\n\nclass _Bayer_Unpacked_Uint16_10(_Bayer_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=10\n        )\n\n\nclass _Bayer_Unpacked_Uint16_12(_Bayer_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=12\n        )\n\n\nclass _Bayer_Unpacked_Uint16_16(_Bayer_Unpacked_Uint16):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            unit_depth_in_bit=16\n        )\n\n\n# ----\n\n\nclass BayerGR8(_Bayer_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR8\')\n\n\nclass BayerRG8(_Bayer_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG8\')\n\n\nclass BayerGB8(_Bayer_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB8\')\n\n\nclass BayerBG8(_Bayer_Unpacked_Uint8):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG8\')\n\n\nclass BayerGR10(_Bayer_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR10\')\n\n\nclass BayerRG10(_Bayer_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG10\')\n\n\nclass BayerGB10(_Bayer_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB10\')\n\n\nclass BayerBG10(_Bayer_Unpacked_Uint16_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG10\')\n\n\nclass BayerGR12(_Bayer_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR12\')\n\n\nclass BayerRG12(_Bayer_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG12\')\n\n\nclass BayerGB12(_Bayer_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB12\')\n\n\nclass BayerBG12(_Bayer_Unpacked_Uint16_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG12\')\n\n\nclass BayerGR16(_Bayer_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR16\')\n\n\nclass BayerRG16(_Bayer_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG16\')\n\n\nclass BayerGB16(_Bayer_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB16\')\n\n\nclass BayerBG16(_Bayer_Unpacked_Uint16_16):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG16\')\n\n\n# ----\n\n\nclass _Bayer_GroupPacked_10(_GroupPacked_10):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1,\n            location=_Location.BAYER\n        )\n\n\nclass _Bayer_GroupPacked_12(_GroupPacked_12):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1,\n            location=_Location.BAYER\n        )\n\n\nclass _Bayer_10p(_10p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1,\n            location=_Location.BAYER\n        )\n\n\nclass _Bayer_12p(_12p):\n    def __init__(self, symbolic: str = None):\n        #\n        super().__init__(\n            symbolic=symbolic,\n            nr_components=1,\n            location=_Location.BAYER\n        )\n\n\n# ----\n\n\nclass BayerGR10Packed(_Bayer_GroupPacked_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR10Packed\')\n\n\nclass BayerRG10Packed(_Bayer_GroupPacked_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG10Packed\')\n\n\nclass BayerGB10Packed(_Bayer_GroupPacked_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB10Packed\')\n\n\nclass BayerBG10Packed(_Bayer_GroupPacked_10):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG10Packed\')\n\n\nclass BayerBG10p(_Bayer_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG10p\')\n\n\nclass BayerGB10p(_Bayer_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB10p\')\n\n\nclass BayerGR10p(_Bayer_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR10p\')\n\n\nclass BayerRG10p(_Bayer_10p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG10p\')\n\n\nclass BayerGR12Packed(_Bayer_GroupPacked_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR12Packed\')\n\n\nclass BayerRG12Packed(_Bayer_GroupPacked_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG12Packed\')\n\n\nclass BayerGB12Packed(_Bayer_GroupPacked_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB12Packed\')\n\n\nclass BayerBG12Packed(_Bayer_GroupPacked_12):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG12Packed\')\n\n\nclass BayerBG12p(_Bayer_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerBG12p\')\n\n\nclass BayerGB12p(_Bayer_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGB12p\')\n\n\nclass BayerGR12p(_Bayer_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerGR12p\')\n\n\nclass BayerRG12p(_Bayer_12p):\n    def __init__(self):\n        #\n        super().__init__(symbolic=\'BayerRG12p\')\n\n\nclass Dictionary:\n    _pixel_formats = [\n        Mono8(),\n        Mono8s(),\n        Mono10(),\n        Mono12(),\n        Mono14(),\n        Mono16(),\n        R8(),\n        R10(),\n        R12(),\n        R16(),\n        G8(),\n        G10(),\n        G12(),\n        G16(),\n        B8(),\n        B10(),\n        B12(),\n        B16(),\n        Coord3D_A8(),\n        Coord3D_B8(),\n        Coord3D_C8(),\n        Coord3D_A16(),\n        Coord3D_B16(),\n        Coord3D_C16(),\n        Coord3D_A32f(),\n        Coord3D_B32f(),\n        Coord3D_C32f(),\n        Confidence1(),\n        Confidence8(),\n        Confidence16(),\n        Confidence32f(),\n        # Mono1p(),\n        # Mono2p(),\n        # Mono4p(),\n        Mono10Packed(),\n        Mono10p(),\n        Mono12Packed(),\n        Mono12p(),\n        Coord3D_A10p(),\n        Coord3D_B10p(),\n        Coord3D_C10p(),\n        Coord3D_A12p(),\n        Coord3D_B12p(),\n        Coord3D_C12p(),\n        RGB8(),\n        RGB10(),\n        RGB12(),\n        RGB14(),\n        RGB16(),\n        BGR8(),\n        BGR10(),\n        BGR12(),\n        BGR14(),\n        BGR16(),\n        Coord3D_ABC8(),\n        Coord3D_ABC8_Planar(),\n        Coord3D_ABC16(),\n        Coord3D_ABC16_Planar(),\n        Coord3D_ABC32f(),\n        Coord3D_ABC32f_Planar(),\n        # RGB8Packed(),\n        Coord3D_ABC10p(),\n        Coord3D_ABC10p_Planar(),\n        Coord3D_ABC12p(),\n        Coord3D_ABC12p_Planar(),\n        YUV422_8_UYVY(),\n        YUV422_8(),\n        YCbCr422_8(),\n        YCbCr601_422_8(),\n        YCbCr709_422_8(),\n        YCbCr422_8_CbYCrY(),\n        YCbCr601_422_8_CbYCrY(),\n        YCbCr709_422_8_CbYCrY(),\n        YCbCr422_10(),\n        YCbCr422_12(),\n        YCbCr601_422_10(),\n        YCbCr601_422_12(),\n        YCbCr709_422_10(),\n        YCbCr709_422_12(),\n        YCbCr422_10_CbYCrY(),\n        YCbCr422_12_CbYCrY(),\n        YCbCr601_422_10_CbYCrY(),\n        YCbCr601_422_12_CbYCrY(),\n        YCbCr709_422_10_CbYCrY(),\n        YCbCr709_422_12_CbYCrY(),\n        YCbCr2020_422_8(),\n        YCbCr2020_422_8_CbYCrY(),\n        YCbCr2020_422_10(),\n        YCbCr2020_422_10_CbYCrY(),\n        YCbCr2020_422_12(),\n        YCbCr2020_422_12_CbYCrY(),\n        YCbCr422_10p(),\n        YCbCr422_12p(),\n        YCbCr601_422_10p(),\n        YCbCr601_422_12p(),\n        YCbCr709_422_10p(),\n        YCbCr709_422_12p(),\n        YCbCr422_10p_CbYCrY(),\n        YCbCr422_12p_CbYCrY(),\n        YCbCr601_422_10p_CbYCrY(),\n        YCbCr601_422_12p_CbYCrY(),\n        YCbCr709_422_10p_CbYCrY(),\n        YCbCr709_422_12p_CbYCrY(),\n        YCbCr2020_422_10p(),\n        YCbCr2020_422_10p_CbYCrY(),\n        YCbCr2020_422_12p(),\n        YCbCr2020_422_12p_CbYCrY(),\n        YUV411_8_UYYVYY(),\n        YCbCr411_8_CbYYCrYY(),\n        YCbCr601_411_8_CbYYCrYY(),\n        YCbCr709_411_8_CbYYCrYY(),\n        YCbCr411_8(),\n        YCbCr2020_411_8_CbYYCrYY(),\n        RGBa8(),\n        RGBa10(),\n        RGBa12(),\n        RGBa14(),\n        RGBa16(),\n        BGRa8(),\n        BGRa10(),\n        BGRa12(),\n        BGRa14(),\n        BGRa16(),\n        RGBa10p(),\n        RGBa12p(),\n        BGRa10p(),\n        BGRa12p(),\n        Coord3D_AC8(),\n        Coord3D_AC8_Planar(),\n        Coord3D_AC16(),\n        Coord3D_AC16_Planar(),\n        Coord3D_AC32f(),\n        Coord3D_AC32f_Planar(),\n        Coord3D_AC10p(),\n        Coord3D_AC10p_Planar(),\n        Coord3D_AC12p(),\n        Coord3D_AC12p_Planar(),\n        BayerGR8(),\n        BayerRG8(),\n        BayerGB8(),\n        BayerBG8(),\n        BayerGR10(),\n        BayerRG10(),\n        BayerGB10(),\n        BayerBG10(),\n        BayerGR12(),\n        BayerRG12(),\n        BayerGB12(),\n        BayerBG12(),\n        BayerGR16(),\n        BayerRG16(),\n        BayerGB16(),\n        BayerBG16(),\n        BayerGR10Packed(),\n        BayerRG10Packed(),\n        BayerGB10Packed(),\n        BayerBG10Packed(),\n        BayerGR12Packed(),\n        BayerRG12Packed(),\n        BayerGB12Packed(),\n        BayerBG12Packed(),\n        BayerBG10p(),\n        BayerBG12p(),\n        BayerGB10p(),\n        BayerGB12p(),\n        BayerGR10p(),\n        BayerGR12p(),\n        BayerRG10p(),\n        BayerRG12p(),\n    ]\n\n    def __init__(self):\n        #\n        super().__init__()\n        #\n        for p in self._pixel_formats:\n            print(p)\n        pass\n\n    @classmethod\n    def get_proxy(cls, symbolic: str):\n        #\n        _pf = None\n        for pf in cls._pixel_formats:\n            if symbolic == pf.symbolic:\n                _pf = pf\n                break\n        #\n        return _pf\n\n\n'"
src/harvesters/_private/core/__init__.py,0,b''
src/harvesters/_private/core/command.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\nclass Command:\n    def __init__(self):\n        super().__init__()\n\n    def execute(self):\n        raise NotImplementedError\n'"
src/harvesters/_private/core/observer.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\nclass Observer:\n    def __init__(self):\n        #\n        super().__init__()\n\n    def update(self):\n        # Update itself.\n        raise NotImplementedError\n\n'"
src/harvesters/_private/core/port.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\n\n# Related third party imports\nfrom genicam.genapi import AbstractPort\nfrom genicam.genapi import EAccessMode\nfrom genicam.gentl import Port\n\n# Local application/library specific imports\n\n\nclass ConcretePort(AbstractPort):\n    """"""\n    An object-oriented version of PortImpl class.\n\n    """"""\n    def __init__(self, port_object=None):\n        #\n        super().__init__()\n\n        #\n        if isinstance(port_object, Port):\n            self._port = port_object\n        else:\n            raise TypeError(\'Supplied object is not a Port object.\')\n\n    @property\n    def port(self):\n        return self._port\n\n    def is_open(self):\n        return False if self.port is None else True\n\n    def write(self, address, value):\n        self.port.write(address, value)\n\n    def read(self, address, length):\n        buffer = self.port.read(address, length)\n        return buffer[1]\n\n    def open(self, port_object):\n        self._port = port_object\n\n    def close(self):\n        self._port = None\n\n    def get_access_mode(self):\n        return EAccessMode.RW if self.is_open() else EAccessMode.NA\n'"
src/harvesters/_private/core/statistics.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport time\n\n# Related third party imports\nfrom genicam.gentl import GenericException\n\n# Local application/library specific imports\n\n\nclass Statistics:\n    def __init__(self):\n        #\n        super().__init__()\n\n        #\n        self._time_base = time.time()\n        self._time_elapsed = 0\n        self._timestamp_base = 0\n        self._has_acquired_1st_timestamp = False\n        self._fps = 0.\n        self._num_images = 0\n        self._fps_max = 0.\n\n    def update_timestamp(self, buffer):\n        freq = self._get_timestamp_freq(buffer)\n        if freq is not None:\n            if not self._has_acquired_1st_timestamp:\n                self._timestamp_base = self._get_timestamp(buffer)\n                self._has_acquired_1st_timestamp = True\n            else:\n                # Calculate the instant frame rate from the gap between\n                # the one before the latest and the latest:\n                now = self._get_timestamp(buffer)\n                diff = now - self._timestamp_base\n                self._timestamp_base = now\n                if diff > 0:\n                    fps = freq / diff\n                    if fps > self._fps_max:\n                        self._fps_max = fps\n                    self._fps = fps\n        else:\n            if self._time_elapsed > 0:\n                self._fps = self._num_images / self._time_elapsed\n\n    @staticmethod\n    def _get_timestamp(buffer):\n        try:\n            timestamp = buffer.timestamp_ns\n        except GenericException:\n            try:\n                timestamp = buffer.timestamp\n            except GenericException:\n                timestamp = 0\n\n        return timestamp\n\n    @staticmethod\n    def _get_timestamp_freq(buffer):\n        #\n        try:\n            _ = buffer.timestamp_ns\n        except GenericException:\n            try:\n                frequency = buffer.parent.parent.timestamp_frequency\n            except GenericException:\n                return None\n        else:\n            frequency = 1000000000  # Hz\n\n        return frequency\n\n    def reset(self):\n        self._time_base = time.time()\n        self._timestamp_base = 0\n        self._has_acquired_1st_timestamp = False\n        self._fps = 0.\n        self._num_images = 0\n        self._fps_max = 0.\n\n    def increment_num_images(self, num=1):\n        self._time_elapsed = time.time() - self._time_base\n        self._num_images += num\n\n    @property\n    def fps(self):\n        return self._fps\n\n    @property\n    def fps_max(self):\n        return self._fps_max\n\n    @property\n    def num_images(self):\n        return self._num_images\n\n    @property\n    def elapsed_time_s(self):\n        return self._time_elapsed\n\n'"
src/harvesters/_private/core/subject.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\nclass Subject:\n    def __init__(self):\n        #\n        super().__init__()\n\n        #\n        self._observers = []\n\n    def add_observer(self, observer):\n        if observer not in self._observers:\n            self._observers.append(observer)\n\n    def remove_observer(self, observer):\n        if observer in self._observers:\n            self._observers.remove(observer)\n\n    def update_observers(self):\n        # Update its observers.\n        for o in self._observers:\n            o.update()\n'"
src/harvesters/_private/core/helper/__init__.py,0,b''
src/harvesters/_private/core/helper/profiler.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\n\n# Related third party imports\nfrom pympler import tracker, summary, muppy\n\n# Local application/library specific imports\n\n\nclass Profiler:\n    def __init__(self):\n        #\n        super().__init__()\n\n        #\n        self._tracker = tracker.SummaryTracker()\n\n    def print_diff(self):\n        self._tracker.print_diff()\n\n    @staticmethod\n    def summarize():\n        summary.print_(\n            summary.summarize(muppy.get_objects())\n        )\n'"
src/harvesters/_private/core/helper/system.py,0,"b'#!/usr/bin/env python3\n# ----------------------------------------------------------------------------\n#\n# Copyright 2018 EMVA\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# ----------------------------------------------------------------------------\n\n\n# Standard library imports\nimport platform\nimport re\n\n# Related third party imports\n\n# Local application/library specific imports\n\n\ndef is_running_on_macos():\n    """"""\n    Returns a truth value for a proposition: ""the program is running on a\n    macOS machine"".\n\n    :rtype: bool\n    """"""\n    pattern = re.compile(\'darwin\', re.IGNORECASE)\n    return False if not pattern.search(platform.platform()) else True\n\n\ndef is_running_on_windows():\n    """"""\n    Returns a truth value for a proposition: ""the program is running on a\n    Windows machine"".\n\n    :rtype: bool\n    """"""\n    pattern = re.compile(\'windows\', re.IGNORECASE)\n    return False if not pattern.search(platform.platform()) else True\n'"
