file_path,api_count,code
03 - TensorFlow Basic/01 - Basic.py,6,"b""# \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x9d\x98 \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9d\xb8 \xea\xb5\xac\xec\x84\xb1\xec\x9d\x84 \xec\x9d\xb5\xed\x9e\x99\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\n# tf.constant: \xeb\xa7\x90 \xea\xb7\xb8\xeb\x8c\x80\xeb\xa1\x9c \xec\x83\x81\xec\x88\x98\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nhello = tf.constant('Hello, TensorFlow!')\nprint(hello)\n\na = tf.constant(10)\nb = tf.constant(32)\nc = tf.add(a, b)  # a + b \xeb\xa1\x9c\xeb\x8f\x84 \xec\x93\xb8 \xec\x88\x98 \xec\x9e\x88\xec\x9d\x8c\nprint(c)\n\n# \xec\x9c\x84\xec\x97\x90\xec\x84\x9c \xeb\xb3\x80\xec\x88\x98\xec\x99\x80 \xec\x88\x98\xec\x8b\x9d\xeb\x93\xa4\xec\x9d\x84 \xec\xa0\x95\xec\x9d\x98\xed\x96\x88\xec\xa7\x80\xeb\xa7\x8c, \xec\x8b\xa4\xed\x96\x89\xec\x9d\xb4 \xec\xa0\x95\xec\x9d\x98\xed\x95\x9c \xec\x8b\x9c\xec\xa0\x90\xec\x97\x90\xec\x84\x9c \xec\x8b\xa4\xed\x96\x89\xeb\x90\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\x80 \xec\x95\x84\xeb\x8b\x99\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc Session \xea\xb0\x9d\xec\xa0\x9c\xec\x99\x80 run \xeb\xa9\x94\xec\x86\x8c\xeb\x93\x9c\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xeb\x95\x8c \xea\xb3\x84\xec\x82\xb0\xec\x9d\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x94\xb0\xeb\x9d\xbc\xec\x84\x9c \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xea\xb3\xbc, \xec\x8b\xa4\xed\x96\x89\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\x84 \xeb\xb6\x84\xeb\xa6\xac\xed\x95\x98\xec\x97\xac \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\xa8\xec\x9d\x84 \xea\xb9\x94\xeb\x81\x94\xed\x95\x98\xea\xb2\x8c \xec\x9e\x91\xec\x84\xb1\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x8b\xa4\xed\x96\x89\xed\x95\xa0 \xec\x84\xb8\xec\x85\x98\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nsess = tf.Session()\n# sess.run: \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c \xed\x85\x90\xec\x84\x9c \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84(\xeb\xb3\x80\xec\x88\x98\xeb\x82\x98 \xec\x88\x98\xec\x8b\x9d \xeb\x93\xb1\xeb\x93\xb1)\xeb\xa5\xbc \xec\x8b\xa4\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nprint(sess.run(hello))\nprint(sess.run([a, b, c]))\n\n# \xec\x84\xb8\xec\x85\x98\xec\x9d\x84 \xeb\x8b\xab\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nsess.close()\n"""
03 - TensorFlow Basic/02 - Variable.py,11,"b'# \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xec\x8a\xa4\xed\x99\x80\xeb\x8d\x94\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x9d\x98 \xea\xb0\x9c\xeb\x85\x90\xec\x9d\x84 \xec\x9d\xb5\xed\x98\x80\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4\nimport tensorflow as tf\n\n# tf.placeholder: \xea\xb3\x84\xec\x82\xb0\xec\x9d\x84 \xec\x8b\xa4\xed\x96\x89\xed\x95\xa0 \xeb\x95\x8c \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xeb\xb0\x9b\xeb\x8a\x94 \xeb\xb3\x80\xec\x88\x98\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# None \xec\x9d\x80 \xed\x81\xac\xea\xb8\xb0\xea\xb0\x80 \xec\xa0\x95\xed\x95\xb4\xec\xa7\x80\xec\xa7\x80 \xec\x95\x8a\xec\x95\x98\xec\x9d\x8c\xec\x9d\x84 \xec\x9d\x98\xeb\xaf\xb8\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nX = tf.placeholder(tf.float32, [None, 3])\nprint(X)\n\n# X \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xec\x8a\xa4\xed\x99\x80\xeb\x8d\x94\xec\x97\x90 \xeb\x84\xa3\xec\x9d\x84 \xea\xb0\x92 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xec\x8a\xa4\xed\x99\x80\xeb\x8d\x94\xec\x97\x90\xec\x84\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c \xea\xb2\x83 \xec\xb2\x98\xeb\x9f\xbc, \xeb\x91\x90\xeb\xb2\x88\xec\xa7\xb8 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x98 \xec\x9a\x94\xec\x86\x8c\xec\x9d\x98 \xea\xb0\xaf\xec\x88\x98\xeb\x8a\x94 3\xea\xb0\x9c \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nx_data = [[1, 2, 3], [4, 5, 6]]\n\n# tf.Variable: \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\xa9\xb4\xec\x84\x9c \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xed\x95\xa0 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9d\xb4 \xea\xb0\x92\xec\x9d\xb4 \xeb\xb0\x94\xeb\xa1\x9c \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xec\xa2\x8c\xec\x9a\xb0\xed\x95\x98\xeb\x8a\x94 \xea\xb0\x92\xeb\x93\xa4\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# tf.random_normal: \xea\xb0\x81 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x98 \xec\xb4\x88\xea\xb8\xb0\xea\xb0\x92\xec\x9d\x84 \xec\xa0\x95\xea\xb7\x9c\xeb\xb6\x84\xed\x8f\xac \xeb\x9e\x9c\xeb\x8d\xa4 \xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nW = tf.Variable(tf.random_normal([3, 2]))\nb = tf.Variable(tf.random_normal([2, 1]))\n\n# \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\xa0 \xec\x88\x98\xec\x8b\x9d\xec\x9d\x84 \xec\x9e\x91\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# tf.matmul \xec\xb2\x98\xeb\x9f\xbc mat* \xeb\xa1\x9c \xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xeb\x8a\x94 \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x96\x89\xeb\xa0\xac \xea\xb3\x84\xec\x82\xb0\xec\x9d\x84 \xec\x88\x98\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nexpr = tf.matmul(X, W) + b\n\nsess = tf.Session()\n# \xec\x9c\x84\xec\x97\x90\xec\x84\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c Variable \xeb\x93\xa4\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94 \xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4\n# \xec\xb2\x98\xec\x9d\x8c\xec\x97\x90 tf.global_variables_initializer \xeb\xa5\xbc \xed\x95\x9c \xeb\xb2\x88 \xec\x8b\xa4\xed\x96\x89\xed\x95\xb4\xec\x95\xbc \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nsess.run(tf.global_variables_initializer())\n\nprint(""=== x_data ==="")\nprint(x_data)\nprint(""=== W ==="")\nprint(sess.run(W))\nprint(""=== b ==="")\nprint(sess.run(b))\nprint(""=== expr ==="")\n# expr \xec\x88\x98\xec\x8b\x9d\xec\x97\x90\xeb\x8a\x94 X \xeb\x9d\xbc\xeb\x8a\x94 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\xb4 \xed\x95\x84\xec\x9a\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x94\xb0\xeb\x9d\xbc\xec\x84\x9c expr \xec\x8b\xa4\xed\x96\x89\xec\x8b\x9c\xec\x97\x90\xeb\x8a\x94 \xec\x9d\xb4 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xec\x8b\xa4\xec\xa0\x9c \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xeb\x84\xa3\xec\x96\xb4\xec\xa4\x98\xec\x95\xbc\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nprint(sess.run(expr, feed_dict={X: x_data}))\n\nsess.close()\n'"
03 - TensorFlow Basic/03 - Linear Regression.py,9,"b'# X \xec\x99\x80 Y \xec\x9d\x98 \xec\x83\x81\xea\xb4\x80\xea\xb4\x80\xea\xb3\x84\xeb\xa5\xbc \xeb\xb6\x84\xec\x84\x9d\xed\x95\x98\xeb\x8a\x94 \xea\xb8\xb0\xec\xb4\x88\xec\xa0\x81\xec\x9d\xb8 \xec\x84\xa0\xed\x98\x95 \xed\x9a\x8c\xea\xb7\x80 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xea\xb3\xa0 \xec\x8b\xa4\xed\x96\x89\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\nx_data = [1, 2, 3]\ny_data = [1, 2, 3]\n\nW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\nb = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n\n# name: \xeb\x82\x98\xec\xa4\x91\xec\x97\x90 \xed\x85\x90\xec\x84\x9c\xeb\xb3\xb4\xeb\x93\x9c\xeb\x93\xb1\xec\x9c\xbc\xeb\xa1\x9c \xea\xb0\x92\xec\x9d\x98 \xeb\xb3\x80\xed\x99\x94\xeb\xa5\xbc \xec\xb6\x94\xec\xa0\x81\xed\x95\x98\xea\xb1\xb0\xeb\x82\x98 \xec\x82\xb4\xed\x8e\xb4\xeb\xb3\xb4\xea\xb8\xb0 \xec\x89\xbd\xea\xb2\x8c \xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\x84 \xeb\xb6\x99\xec\x97\xac\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\nX = tf.placeholder(tf.float32, name=""X"")\nY = tf.placeholder(tf.float32, name=""Y"")\nprint(X)\nprint(Y)\n\n# X \xec\x99\x80 Y \xec\x9d\x98 \xec\x83\x81\xea\xb4\x80 \xea\xb4\x80\xea\xb3\x84\xeb\xa5\xbc \xeb\xb6\x84\xec\x84\x9d\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xea\xb0\x80\xec\x84\xa4 \xec\x88\x98\xec\x8b\x9d\xec\x9d\x84 \xec\x9e\x91\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# y = W * x + b\n# W \xec\x99\x80 X \xea\xb0\x80 \xed\x96\x89\xeb\xa0\xac\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x88\xeb\xaf\x80\xeb\xa1\x9c tf.matmul \xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x88\xeb\x9d\xbc \xea\xb8\xb0\xeb\xb3\xb8 \xea\xb3\xb1\xec\x85\x88 \xea\xb8\xb0\xed\x98\xb8\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x96\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nhypothesis = W * X + b\n\n# \xec\x86\x90\xec\x8b\xa4 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x91\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# mean(h - Y)^2 : \xec\x98\x88\xec\xb8\xa1\xea\xb0\x92\xea\xb3\xbc \xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92\xec\x9d\x98 \xea\xb1\xb0\xeb\xa6\xac\xeb\xa5\xbc \xeb\xb9\x84\xec\x9a\xa9(\xec\x86\x90\xec\x8b\xa4) \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ncost = tf.reduce_mean(tf.square(hypothesis - Y))\n# \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x97\x90 \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xed\x8f\xac\xed\x95\xa8\xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xeb\x8a\x94 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb2\xbd\xec\x82\xac \xed\x95\x98\xea\xb0\x95\xeb\xb2\x95 \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xeb\xa5\xbc \xec\x88\x98\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n# \xeb\xb9\x84\xec\x9a\xa9\xec\x9d\x84 \xec\xb5\x9c\xec\x86\x8c\xed\x99\x94 \xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4 \xec\xb5\x9c\xec\xa2\x85 \xeb\xaa\xa9\xed\x91\x9c\ntrain_op = optimizer.minimize(cost)\n\n# \xec\x84\xb8\xec\x85\x98\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xea\xb3\xa0 \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    # \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xeb\xa5\xbc 100\xeb\xb2\x88 \xec\x88\x98\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    for step in range(100):\n        # sess.run \xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 train_op \xec\x99\x80 cost \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        # \xec\x9d\xb4 \xeb\x95\x8c, \xea\xb0\x80\xec\x84\xa4 \xec\x88\x98\xec\x8b\x9d\xec\x97\x90 \xeb\x84\xa3\xec\x96\xb4\xec\x95\xbc \xed\x95\xa0 \xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92\xec\x9d\x84 feed_dict \xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x84\xeb\x8b\xac\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n\n        print(step, cost_val, sess.run(W), sess.run(b))\n\n    # \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xea\xb0\x80 \xec\x99\x84\xeb\xa3\x8c\xeb\x90\x9c \xeb\xaa\xa8\xeb\x8d\xb8\xec\x97\x90 \xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8 \xea\xb0\x92\xec\x9d\x84 \xeb\x84\xa3\xea\xb3\xa0 \xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x80 \xec\x9e\x98 \xeb\x82\x98\xec\x98\xa4\xeb\x8a\x94\xec\xa7\x80 \xed\x99\x95\xec\x9d\xb8\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n    print(""\\n=== Test ==="")\n    print(""X: 5, Y:"", sess.run(hypothesis, feed_dict={X: 5}))\n    print(""X: 2.5, Y:"", sess.run(hypothesis, feed_dict={X: 2.5}))\n'"
04 - Neural Network Basic/01 - Classification.py,17,"b""# \xed\x84\xb8\xea\xb3\xbc \xeb\x82\xa0\xea\xb0\x9c\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94\xec\xa7\x80 \xec\x97\x86\xeb\x8a\x94\xec\xa7\x80\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc, \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98\xec\x9d\xb8\xec\xa7\x80 \xec\xa1\xb0\xeb\xa5\x98\xec\x9d\xb8\xec\xa7\x80 \xeb\xb6\x84\xeb\xa5\x98\xed\x95\x98\xeb\x8a\x94 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport numpy as np\n\n# [\xed\x84\xb8, \xeb\x82\xa0\xea\xb0\x9c]\nx_data = np.array(\n    [[0, 0], [1, 0], [1, 1], [0, 0], [0, 0], [0, 1]])\n\n# [\xea\xb8\xb0\xed\x83\x80, \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, \xec\xa1\xb0\xeb\xa5\x98]\n# \xeb\x8b\xa4\xec\x9d\x8c\xea\xb3\xbc \xea\xb0\x99\xec\x9d\x80 \xed\x98\x95\xec\x8b\x9d\xec\x9d\x84 one-hot \xed\x98\x95\xec\x8b\x9d\xec\x9d\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\x9d\xbc\xea\xb3\xa0 \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ny_data = np.array([\n    [1, 0, 0],  # \xea\xb8\xb0\xed\x83\x80\n    [0, 1, 0],  # \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98\n    [0, 0, 1],  # \xec\xa1\xb0\xeb\xa5\x98\n    [1, 0, 0],\n    [1, 0, 0],\n    [0, 0, 1]\n])\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32)\nY = tf.placeholder(tf.float32)\n\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x80 2\xec\xb0\xa8\xec\x9b\x90\xec\x9c\xbc\xeb\xa1\x9c [\xec\x9e\x85\xeb\xa0\xa5\xec\xb8\xb5(\xed\x8a\xb9\xec\x84\xb1), \xec\xb6\x9c\xeb\xa0\xa5\xec\xb8\xb5(\xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94)] -> [2, 3] \xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nW = tf.Variable(tf.random_uniform([2, 3], -1., 1.))\n\n# \xed\x8e\xb8\xed\x96\xa5\xec\x9d\x84 \xea\xb0\x81\xea\xb0\x81 \xea\xb0\x81 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xec\x95\x84\xec\x9b\x83\xed\x92\x8b \xea\xb0\xaf\xec\x88\x98\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x8e\xb8\xed\x96\xa5\xec\x9d\x80 \xec\x95\x84\xec\x9b\x83\xed\x92\x8b\xec\x9d\x98 \xea\xb0\xaf\xec\x88\x98, \xec\xa6\x89 \xec\xb5\x9c\xec\xa2\x85 \xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x92\xec\x9d\x98 \xeb\xb6\x84\xeb\xa5\x98 \xea\xb0\xaf\xec\x88\x98\xec\x9d\xb8 3\xec\x9c\xbc\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nb = tf.Variable(tf.zeros([3]))\n\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x97\x90 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98 W\xea\xb3\xbc \xed\x8e\xb8\xed\x96\xa5 b\xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\nL = tf.add(tf.matmul(X, W), b)\n# \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xec\x99\x80 \xed\x8e\xb8\xed\x96\xa5\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb3\x84\xec\x82\xb0\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc \xea\xb0\x92\xec\x97\x90\n# \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x97\x90\xec\x84\x9c \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x9c\xea\xb3\xb5\xed\x95\x98\xeb\x8a\x94 \xed\x99\x9c\xec\x84\xb1\xed\x99\x94 \xed\x95\xa8\xec\x88\x98\xec\x9d\xb8 ReLU \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\xa0\x81\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nL = tf.nn.relu(L)\n\n# \xeb\xa7\x88\xec\xa7\x80\xeb\xa7\x89\xec\x9c\xbc\xeb\xa1\x9c softmax \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x89\xbd\xea\xb2\x8c \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4\n# softmax \xed\x95\xa8\xec\x88\x98\xeb\x8a\x94 \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x92\xec\x9d\x84 \xec\xa0\x84\xec\xb2\xb4\xed\x95\xa9\xec\x9d\xb4 1\xec\x9d\xb8 \xed\x99\x95\xeb\xa5\xa0\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\xa3\xbc\xeb\x8a\x94 \xed\x95\xa8\xec\x88\x98\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x88) [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\nmodel = tf.nn.softmax(L)\n\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xb9\x84\xec\x9a\xa9 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x91\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xea\xb0\x81 \xea\xb0\x9c\xeb\xb3\x84 \xea\xb2\xb0\xea\xb3\xbc\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xed\x95\xa9\xec\x9d\x84 \xea\xb5\xac\xed\x95\x9c \xeb\x92\xa4 \xed\x8f\x89\xea\xb7\xa0\xec\x9d\x84 \xeb\x82\xb4\xeb\x8a\x94 \xeb\xb0\xa9\xec\x8b\x9d\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\xa0\x84\xec\xb2\xb4 \xed\x95\xa9\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x8c, \xea\xb0\x9c\xeb\xb3\x84 \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xea\xb5\xac\xed\x95\x9c \xeb\x92\xa4 \xed\x8f\x89\xea\xb7\xa0\xec\x9d\x84 \xeb\x82\xb4\xeb\x8a\x94 \xeb\xb0\xa9\xec\x8b\x9d\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 axis \xec\x98\xb5\xec\x85\x98\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# axis \xec\x98\xb5\xec\x85\x98\xec\x9d\xb4 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4 -1.09 \xec\xb2\x98\xeb\x9f\xbc \xec\xb4\x9d\xed\x95\xa9\xec\x9d\xb8 \xec\x8a\xa4\xec\xb9\xbc\xeb\x9d\xbc\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\xb6\x9c\xeb\xa0\xa5\xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n#        Y         model         Y * tf.log(model)   reduce_sum(axis=1)\n# \xec\x98\x88) [[1 0 0]  [[0.1 0.7 0.2]  -> [[-1.0  0    0]  -> [-1.0, -0.09]\n#     [0 1 0]]  [0.2 0.8 0.0]]     [ 0   -0.09 0]]\n# \xec\xa6\x89, \xec\x9d\xb4\xea\xb2\x83\xec\x9d\x80 \xec\x98\x88\xec\xb8\xa1\xea\xb0\x92\xea\xb3\xbc \xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92 \xec\x82\xac\xec\x9d\xb4\xec\x9d\x98 \xed\x99\x95\xeb\xa5\xa0 \xeb\xb6\x84\xed\x8f\xac\xec\x9d\x98 \xec\xb0\xa8\xec\x9d\xb4\xeb\xa5\xbc \xeb\xb9\x84\xec\x9a\xa9\xec\x9c\xbc\xeb\xa1\x9c \xea\xb3\x84\xec\x82\xb0\xed\x95\x9c \xea\xb2\x83\xec\x9d\xb4\xeb\xa9\xb0,\n# \xec\x9d\xb4\xea\xb2\x83\xec\x9d\x84 Cross-Entropy \xeb\x9d\xbc\xea\xb3\xa0 \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ncost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\ntrain_op = optimizer.minimize(cost)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nfor step in range(100):\n    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n\n    if (step + 1) % 10 == 0:\n        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n# 0: \xea\xb8\xb0\xed\x83\x80 1: \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, 2: \xec\xa1\xb0\xeb\xa5\x98\n######\n# tf.argmax: \xec\x98\x88\xec\xb8\xa1\xea\xb0\x92\xea\xb3\xbc \xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92\xec\x9d\x98 \xed\x96\x89\xeb\xa0\xac\xec\x97\x90\xec\x84\x9c tf.argmax \xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb0\x80\xec\x9e\xa5 \xed\x81\xb0 \xea\xb0\x92\xec\x9d\x84 \xea\xb0\x80\xec\xa0\xb8\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x88) [[0 1 0] [1 0 0]] -> [1 0]\n#    [[0.2 0.7 0.1] [0.9 0.1 0.]] -> [1 0]\nprediction = tf.argmax(model, 1)\ntarget = tf.argmax(Y, 1)\nprint('\xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:', sess.run(prediction, feed_dict={X: x_data}))\nprint('\xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92:', sess.run(target, feed_dict={Y: y_data}))\n\nis_correct = tf.equal(prediction, target)\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint('\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n"""
04 - Neural Network Basic/02 - Deep NN.py,18,"b""# \xed\x84\xb8\xea\xb3\xbc \xeb\x82\xa0\xea\xb0\x9c\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94\xec\xa7\x80 \xec\x97\x86\xeb\x8a\x94\xec\xa7\x80\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc, \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98\xec\x9d\xb8\xec\xa7\x80 \xec\xa1\xb0\xeb\xa5\x98\xec\x9d\xb8\xec\xa7\x80 \xeb\xb6\x84\xeb\xa5\x98\xed\x95\x98\xeb\x8a\x94 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x98 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xec\x97\xac\xeb\x9f\xac\xea\xb0\x9c\xeb\xa1\x9c \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xec\x97\xac \xeb\xa7\x90\xeb\xa1\x9c\xeb\xa7\x8c \xeb\x93\xa3\xeb\x8d\x98 \xeb\x94\xa5\xeb\x9f\xac\xeb\x8b\x9d\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\xb4 \xeb\xb4\x85\xec\x8b\x9c\xeb\x8b\xa4!\nimport tensorflow as tf\nimport numpy as np\n\n# [\xed\x84\xb8, \xeb\x82\xa0\xea\xb0\x9c]\nx_data = np.array(\n    [[0, 0], [1, 0], [1, 1], [0, 0], [0, 0], [0, 1]])\n\n# [\xea\xb8\xb0\xed\x83\x80, \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, \xec\xa1\xb0\xeb\xa5\x98]\ny_data = np.array([\n    [1, 0, 0],  # \xea\xb8\xb0\xed\x83\x80\n    [0, 1, 0],  # \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98\n    [0, 0, 1],  # \xec\xa1\xb0\xeb\xa5\x98\n    [1, 0, 0],\n    [1, 0, 0],\n    [0, 0, 1]\n])\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32)\nY = tf.placeholder(tf.float32)\n\n# \xec\xb2\xab\xeb\xb2\x88\xec\xa7\xb8 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xec\x9d\x98 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x80 [\xed\x8a\xb9\xec\x84\xb1, \xed\x9e\x88\xeb\x93\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xeb\x89\xb4\xeb\x9f\xb0\xea\xb0\xaf\xec\x88\x98] -> [2, 10] \xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nW1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n# \xeb\x91\x90\xeb\xb2\x88\xec\xa7\xb8 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xec\x9d\x98 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x84 [\xec\xb2\xab\xeb\xb2\x88\xec\xa7\xb8 \xed\x9e\x88\xeb\x93\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xeb\x89\xb4\xeb\x9f\xb0 \xea\xb0\xaf\xec\x88\x98, \xeb\xb6\x84\xeb\xa5\x98 \xea\xb0\xaf\xec\x88\x98] -> [10, 3] \xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nW2 = tf.Variable(tf.random_uniform([10, 3], -1., 1.))\n\n# \xed\x8e\xb8\xed\x96\xa5\xec\x9d\x84 \xea\xb0\x81\xea\xb0\x81 \xea\xb0\x81 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xec\x95\x84\xec\x9b\x83\xed\x92\x8b \xea\xb0\xaf\xec\x88\x98\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# b1 \xec\x9d\x80 \xed\x9e\x88\xeb\x93\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xeb\x89\xb4\xeb\x9f\xb0 \xea\xb0\xaf\xec\x88\x98\xeb\xa1\x9c, b2 \xeb\x8a\x94 \xec\xb5\x9c\xec\xa2\x85 \xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x92 \xec\xa6\x89, \xeb\xb6\x84\xeb\xa5\x98 \xea\xb0\xaf\xec\x88\x98\xec\x9d\xb8 3\xec\x9c\xbc\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nb1 = tf.Variable(tf.zeros([10]))\nb2 = tf.Variable(tf.zeros([3]))\n\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x98 \xed\x9e\x88\xeb\x93\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x97\x90 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98 W1\xea\xb3\xbc \xed\x8e\xb8\xed\x96\xa5 b1\xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\nL1 = tf.add(tf.matmul(X, W1), b1)\nL1 = tf.nn.relu(L1)\n\n# \xec\xb5\x9c\xec\xa2\x85\xec\xa0\x81\xec\x9d\xb8 \xec\x95\x84\xec\x9b\x83\xed\x92\x8b\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x9e\x88\xeb\x93\xa0\xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x97\x90 \xeb\x91\x90\xeb\xb2\x88\xec\xa7\xb8 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98 W2\xec\x99\x80 \xed\x8e\xb8\xed\x96\xa5 b2\xeb\xa5\xbc \xec\xa0\x81\xec\x9a\xa9\xed\x95\x98\xec\x97\xac 3\xea\xb0\x9c\xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\x83\x85\xeb\x8b\x88\xeb\x8b\xa4.\nmodel = tf.add(tf.matmul(L1, W2), b2)\n\n# \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x97\x90\xec\x84\x9c \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x9c\xea\xb3\xb5\xeb\x90\x98\xeb\x8a\x94 \xed\x81\xac\xeb\xa1\x9c\xec\x8a\xa4 \xec\x97\x94\xed\x8a\xb8\xeb\xa1\x9c\xed\x94\xbc \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4\n# \xeb\xb3\xb5\xec\x9e\xa1\xed\x95\x9c \xec\x88\x98\xec\x8b\x9d\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xea\xb3\xa0\xeb\x8f\x84 \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xeb\xa5\xbc \xec\x9c\x84\xed\x95\x9c \xeb\xb9\x84\xec\x9a\xa9 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c \xec\xa0\x81\xec\x9a\xa9\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\ncost = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n\noptimizer = tf.train.AdamOptimizer(learning_rate=0.01)\ntrain_op = optimizer.minimize(cost)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nfor step in range(100):\n    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n\n    if (step + 1) % 10 == 0:\n        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n# 0: \xea\xb8\xb0\xed\x83\x80 1: \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, 2: \xec\xa1\xb0\xeb\xa5\x98\n######\nprediction = tf.argmax(model, 1)\ntarget = tf.argmax(Y, 1)\nprint('\xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:', sess.run(prediction, feed_dict={X: x_data}))\nprint('\xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92:', sess.run(target, feed_dict={Y: y_data}))\n\nis_correct = tf.equal(prediction, target)\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint('\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n"""
04 - Neural Network Basic/03 - Word2Vec.py,13,"b'# Word2Vec \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c \xea\xb5\xac\xed\x98\x84\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# matplot \xec\x97\x90\xec\x84\x9c \xed\x95\x9c\xea\xb8\x80\xec\x9d\x84 \xed\x91\x9c\xec\x8b\x9c\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x84\xa4\xec\xa0\x95\nfont_name = matplotlib.font_manager.FontProperties(\n                fname=""/Library/Fonts/NanumGothic.otf""  # \xed\x95\x9c\xea\xb8\x80 \xed\x8f\xb0\xed\x8a\xb8 \xec\x9c\x84\xec\xb9\x98\xeb\xa5\xbc \xeb\x84\xa3\xec\x96\xb4\xec\xa3\xbc\xec\x84\xb8\xec\x9a\x94\n            ).get_name()\nmatplotlib.rc(\'font\', family=font_name)\n\n# \xeb\x8b\xa8\xec\x96\xb4 \xeb\xb2\xa1\xed\x84\xb0\xeb\xa5\xbc \xeb\xb6\x84\xec\x84\x9d\xed\x95\xb4\xeb\xb3\xbc \xec\x9e\x84\xec\x9d\x98\xec\x9d\x98 \xeb\xac\xb8\xec\x9e\xa5\xeb\x93\xa4\nsentences = [""\xeb\x82\x98 \xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xeb\x82\x98 \xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xeb\x82\x98 \xeb\x8f\x99\xeb\xac\xbc \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xeb\x8f\x99\xeb\xac\xbc"",\n             ""\xec\x97\xac\xec\x9e\x90\xec\xb9\x9c\xea\xb5\xac \xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xec\x83\x9d\xec\x84\xa0 \xec\x9a\xb0\xec\x9c\xa0 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xec\x83\x9d\xec\x84\xa0 \xec\x8b\xab\xeb\x8b\xa4 \xec\x9a\xb0\xec\x9c\xa0 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xeb\x88\x88 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xeb\x82\x98 \xec\x97\xac\xec\x9e\x90\xec\xb9\x9c\xea\xb5\xac \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xec\x97\xac\xec\x9e\x90\xec\xb9\x9c\xea\xb5\xac \xeb\x82\x98 \xec\x8b\xab\xeb\x8b\xa4"",\n             ""\xec\x97\xac\xec\x9e\x90\xec\xb9\x9c\xea\xb5\xac \xeb\x82\x98 \xec\x98\x81\xed\x99\x94 \xec\xb1\x85 \xec\x9d\x8c\xec\x95\x85 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xeb\x82\x98 \xea\xb2\x8c\xec\x9e\x84 \xeb\xa7\x8c\xed\x99\x94 \xec\x95\xa0\xeb\x8b\x88 \xec\xa2\x8b\xeb\x8b\xa4"",\n             ""\xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xec\x8b\xab\xeb\x8b\xa4"",\n             ""\xea\xb0\x95\xec\x95\x84\xec\xa7\x80 \xea\xb3\xa0\xec\x96\x91\xec\x9d\xb4 \xec\xa2\x8b\xeb\x8b\xa4""]\n\n# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xec\xa0\x84\xeb\xb6\x80 \xed\x95\xa9\xec\xb9\x9c \xed\x9b\x84 \xea\xb3\xb5\xeb\xb0\xb1\xec\x9c\xbc\xeb\xa1\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\x93\xa4\xec\x9d\x84 \xeb\x82\x98\xeb\x88\x84\xea\xb3\xa0 \xea\xb3\xa0\xec\x9c\xa0\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\x93\xa4\xeb\xa1\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\nword_sequence = "" "".join(sentences).split()\nword_list = "" "".join(sentences).split()\nword_list = list(set(word_list))\n# \xeb\xac\xb8\xec\x9e\x90\xec\x97\xb4\xeb\xa1\x9c \xeb\xb6\x84\xec\x84\x9d\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83 \xeb\xb3\xb4\xeb\x8b\xa4, \xec\x88\xab\xec\x9e\x90\xeb\xa1\x9c \xeb\xb6\x84\xec\x84\x9d\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4 \xed\x9b\xa8\xec\x94\xac \xec\x9a\xa9\xec\x9d\xb4\xed\x95\x98\xeb\xaf\x80\xeb\xa1\x9c\n# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90\xec\x84\x9c \xeb\xac\xb8\xec\x9e\x90\xeb\x93\xa4\xec\x9d\x98 \xec\x9d\xb8\xeb\x8d\xb1\xec\x8a\xa4\xeb\xa5\xbc \xeb\xbd\x91\xec\x95\x84\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4,\n# \xec\x9d\xb4\xeb\xa5\xbc \xed\x91\x9c\xed\x98\x84\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x97\xb0\xea\xb4\x80 \xeb\xb0\xb0\xec\x97\xb4\xea\xb3\xbc, \xeb\x8b\xa8\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90\xec\x84\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb0\xb8\xec\xa1\xb0 \xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xeb\x8a\x94 \xec\x9d\xb8\xeb\x8d\xb1\xec\x8a\xa4 \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xad\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nword_dict = {w: i for i, w in enumerate(word_list)}\n\n# \xec\x9c\x88\xeb\x8f\x84\xec\x9a\xb0 \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\xa5\xbc 1 \xeb\xa1\x9c \xed\x95\x98\xeb\x8a\x94 skip-gram \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x88) \xeb\x82\x98 \xea\xb2\x8c\xec\x9e\x84 \xeb\xa7\x8c\xed\x99\x94 \xec\x95\xa0\xeb\x8b\x88 \xec\xa2\x8b\xeb\x8b\xa4\n#   -> ([\xeb\x82\x98, \xeb\xa7\x8c\xed\x99\x94], \xea\xb2\x8c\xec\x9e\x84), ([\xea\xb2\x8c\xec\x9e\x84, \xec\x95\xa0\xeb\x8b\x88], \xeb\xa7\x8c\xed\x99\x94), ([\xeb\xa7\x8c\xed\x99\x94, \xec\xa2\x8b\xeb\x8b\xa4], \xec\x95\xa0\xeb\x8b\x88)\n#   -> (\xea\xb2\x8c\xec\x9e\x84, \xeb\x82\x98), (\xea\xb2\x8c\xec\x9e\x84, \xeb\xa7\x8c\xed\x99\x94), (\xeb\xa7\x8c\xed\x99\x94, \xea\xb2\x8c\xec\x9e\x84), (\xeb\xa7\x8c\xed\x99\x94, \xec\x95\xa0\xeb\x8b\x88), (\xec\x95\xa0\xeb\x8b\x88, \xeb\xa7\x8c\xed\x99\x94), (\xec\x95\xa0\xeb\x8b\x88, \xec\xa2\x8b\xeb\x8b\xa4)\nskip_grams = []\n\nfor i in range(1, len(word_sequence) - 1):\n    # (context, target) : ([target index - 1, target index + 1], target)\n    # \xec\x8a\xa4\xed\x82\xb5\xea\xb7\xb8\xeb\x9e\xa8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa0 \xed\x9b\x84, \xec\xa0\x80\xec\x9e\xa5\xec\x9d\x80 \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xea\xb3\xa0\xec\x9c\xa0 \xeb\xb2\x88\xed\x98\xb8(index)\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\n    target = word_dict[word_sequence[i]]\n    context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]]\n\n    # (target, context[0]), (target, context[1])..\n    for w in context:\n        skip_grams.append([target, w])\n\n\n# skip-gram \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x97\x90\xec\x84\x9c \xeb\xac\xb4\xec\x9e\x91\xec\x9c\x84\xeb\xa1\x9c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xeb\xbd\x91\xec\x95\x84 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x98 \xeb\xb0\xb0\xec\xb9\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xed\x95\xa8\xec\x88\x98\ndef random_batch(data, size):\n    random_inputs = []\n    random_labels = []\n    random_index = np.random.choice(range(len(data)), size, replace=False)\n\n    for i in random_index:\n        random_inputs.append(data[i][0])  # target\n        random_labels.append([data[i][1]])  # context word\n\n    return random_inputs, random_labels\n\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\n# \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xeb\xb0\x98\xeb\xb3\xb5\xed\x95\xa0 \xed\x9a\x9f\xec\x88\x98\ntraining_epoch = 300\n# \xed\x95\x99\xec\x8a\xb5\xeb\xa5\xa0\nlearning_rate = 0.1\n# \xed\x95\x9c \xeb\xb2\x88\xec\x97\x90 \xed\x95\x99\xec\x8a\xb5\xed\x95\xa0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x9d\x98 \xed\x81\xac\xea\xb8\xb0\nbatch_size = 20\n# \xeb\x8b\xa8\xec\x96\xb4 \xeb\xb2\xa1\xed\x84\xb0\xeb\xa5\xbc \xea\xb5\xac\xec\x84\xb1\xed\x95\xa0 \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x98 \xed\x81\xac\xea\xb8\xb0\n# \xec\x9d\xb4 \xec\x98\x88\xec\xa0\x9c\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 x, y \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa1\x9c \xed\x91\x9c\xed\x98\x84\xed\x95\x98\xea\xb8\xb0 \xec\x89\xbd\xea\xb2\x8c 2 \xea\xb0\x9c\xec\x9d\x98 \xea\xb0\x92\xeb\xa7\x8c \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nembedding_size = 2\n# word2vec \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xed\x82\xa4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c nce_loss \xed\x95\xa8\xec\x88\x98\xec\x97\x90\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x83\x98\xed\x94\x8c\xeb\xa7\x81 \xed\x81\xac\xea\xb8\xb0\n# batch_size \xeb\xb3\xb4\xeb\x8b\xa4 \xec\x9e\x91\xec\x95\x84\xec\x95\xbc \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nnum_sampled = 15\n# \xec\xb4\x9d \xeb\x8b\xa8\xec\x96\xb4 \xea\xb0\xaf\xec\x88\x98\nvoc_size = len(word_list)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\ninputs = tf.placeholder(tf.int32, shape=[batch_size])\n# tf.nn.nce_loss \xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\xa0\xa4\xeb\xa9\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xec\x9d\xb4\xeb\xa0\x87\xea\xb2\x8c [batch_size, 1] \xea\xb5\xac\xec\x84\xb1\xed\x95\xb4\xec\x95\xbc\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nlabels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n\n# word2vec \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x98 \xea\xb2\xb0\xea\xb3\xbc \xea\xb0\x92\xec\x9d\xb8 \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9 \xeb\xb2\xa1\xed\x84\xb0\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xeb\xb3\x80\xec\x88\x98\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\xb4\x9d \xeb\x8b\xa8\xec\x96\xb4 \xea\xb0\xaf\xec\x88\x98\xec\x99\x80 \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9 \xea\xb0\xaf\xec\x88\x98\xeb\xa5\xbc \xed\x81\xac\xea\xb8\xb0\xeb\xa1\x9c \xed\x95\x98\xeb\x8a\x94 \xeb\x91\x90 \xea\xb0\x9c\xec\x9d\x98 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x84 \xea\xb0\x96\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nembeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n# \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9 \xeb\xb2\xa1\xed\x84\xb0\xec\x9d\x98 \xec\xb0\xa8\xec\x9b\x90\xec\x97\x90\xec\x84\x9c \xed\x95\x99\xec\x8a\xb5\xed\x95\xa0 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xed\x96\x89\xeb\x93\xa4\xec\x9d\x84 \xeb\xbd\x91\xec\x95\x84\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x88) embeddings     inputs    selected\n#    [[1, 2, 3]  -> [2, 3] -> [[2, 3, 4]\n#     [2, 3, 4]                [3, 4, 5]]\n#     [3, 4, 5]\n#     [4, 5, 6]]\nselected_embed = tf.nn.embedding_lookup(embeddings, inputs)\n\n# nce_loss \xed\x95\xa8\xec\x88\x98\xec\x97\x90\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\xa0\x95\xec\x9d\x98\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nnce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\nnce_biases = tf.Variable(tf.zeros([voc_size]))\n\n# nce_loss \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xea\xb5\xac\xed\x98\x84\xed\x95\x98\xeb\xa0\xa4\xeb\xa9\xb4 \xeb\xa7\xa4\xec\x9a\xb0 \xeb\xb3\xb5\xec\x9e\xa1\xed\x95\x98\xec\xa7\x80\xeb\xa7\x8c,\n# \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xea\xb0\x80 \xec\xa0\x9c\xea\xb3\xb5\xed\x95\x98\xeb\xaf\x80\xeb\xa1\x9c \xea\xb7\xb8\xeb\x83\xa5 tf.nn.nce_loss \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0\xeb\xa7\x8c \xed\x95\x98\xeb\xa9\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nloss = tf.reduce_mean(\n            tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size))\n\ntrain_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nwith tf.Session() as sess:\n    init = tf.global_variables_initializer()\n    sess.run(init)\n\n    for step in range(1, training_epoch + 1):\n        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n\n        _, loss_val = sess.run([train_op, loss],\n                               feed_dict={inputs: batch_inputs,\n                                          labels: batch_labels})\n\n        if step % 10 == 0:\n            print(""loss at step "", step, "": "", loss_val)\n\n    # matplot \xec\x9c\xbc\xeb\xa1\x9c \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xec\x97\xac \xec\x8b\x9c\xea\xb0\x81\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xed\x99\x95\xec\x9d\xb8\xed\x95\xb4\xeb\xb3\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4\n    # \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9 \xeb\xb2\xa1\xed\x84\xb0\xec\x9d\x98 \xea\xb2\xb0\xea\xb3\xbc \xea\xb0\x92\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xec\x97\xac \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    # with \xea\xb5\xac\xeb\xac\xb8 \xec\x95\x88\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 sess.run \xeb\x8c\x80\xec\x8b\xa0 \xea\xb0\x84\xeb\x8b\xa8\xed\x9e\x88 eval() \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n    trained_embeddings = embeddings.eval()\n\n\n#########\n# \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9\xeb\x90\x9c Word2Vec \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n# \xea\xb2\xb0\xea\xb3\xbc\xeb\x8a\x94 \xed\x95\xb4\xeb\x8b\xb9 \xeb\x8b\xa8\xec\x96\xb4\xeb\x93\xa4\xec\x9d\xb4 \xec\x96\xbc\xeb\xa7\x88\xeb\x82\x98 \xeb\x8b\xa4\xeb\xa5\xb8 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xec\x9d\xb8\xec\xa0\x91\xed\x95\xb4 \xec\x9e\x88\xeb\x8a\x94\xec\xa7\x80\xeb\xa5\xbc \xeb\xb3\xb4\xec\x97\xac\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\n######\nfor i, label in enumerate(word_list):\n    x, y = trained_embeddings[i]\n    plt.scatter(x, y)\n    plt.annotate(label, xy=(x, y), xytext=(5, 2),\n                 textcoords=\'offset points\', ha=\'right\', va=\'bottom\')\n\nplt.show()\n'"
"05 - TensorBoard, Saver/01 - Saver.py",21,"b""# \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb3\xa0 \xec\x9e\xac\xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8a\x94 \xeb\xb0\xa9\xeb\xb2\x95\xec\x9d\x84 \xec\x9d\xb5\xed\x98\x80\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n\nimport tensorflow as tf\nimport numpy as np\n\n\ndata = np.loadtxt('./data.csv', delimiter=',',\n                  unpack=True, dtype='float32')\n\n# \xed\x84\xb8, \xeb\x82\xa0\xea\xb0\x9c, \xea\xb8\xb0\xed\x83\x80, \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, \xec\xa1\xb0\xeb\xa5\x98\n# x_data = 0, 1\n# y_data = 2, 3, 4\nx_data = np.transpose(data[0:2])\ny_data = np.transpose(data[2:])\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\n# \xed\x95\x99\xec\x8a\xb5\xec\x97\x90 \xec\xa7\x81\xec\xa0\x91\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xea\xb3\xa0 \xed\x95\x99\xec\x8a\xb5 \xed\x9a\x9f\xec\x88\x98\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc \xeb\x8b\xa8\xec\x88\x9c\xed\x9e\x88 \xec\xa6\x9d\xea\xb0\x80\xec\x8b\x9c\xed\x82\xac \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\nglobal_step = tf.Variable(0, trainable=False, name='global_step')\n\nX = tf.placeholder(tf.float32)\nY = tf.placeholder(tf.float32)\n\nW1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\nL1 = tf.nn.relu(tf.matmul(X, W1))\n\nW2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.))\nL2 = tf.nn.relu(tf.matmul(L1, W2))\n\nW3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.))\nmodel = tf.matmul(L2, W3)\n\ncost = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n\noptimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n# global_step\xeb\xa1\x9c \xeb\x84\x98\xea\xb2\xa8\xec\xa4\x80 \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc, \xed\x95\x99\xec\x8a\xb5\xec\x9a\xa9 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xed\x95\xa0 \xeb\x95\x8c \xeb\xa7\x88\xeb\x8b\xa4 \xed\x95\x99\xec\x8a\xb5 \xed\x9a\x9f\xec\x88\x98\xeb\xa5\xbc \xed\x95\x98\xeb\x82\x98\xec\x94\xa9 \xec\xa6\x9d\xea\xb0\x80\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\ntrain_op = optimizer.minimize(cost, global_step=global_step)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\n# \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb3\xa0 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\x8a\x94 API\xeb\xa5\xbc \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# global_variables \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \xec\x95\x9e\xec\x84\x9c \xec\xa0\x95\xec\x9d\x98\xed\x95\x98\xec\x98\x80\xeb\x8d\x98 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb1\xb0\xeb\x82\x98 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xac \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nsaver = tf.train.Saver(tf.global_variables())\n\nckpt = tf.train.get_checkpoint_state('./model')\nif ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n    saver.restore(sess, ckpt.model_checkpoint_path)\nelse:\n    sess.run(tf.global_variables_initializer())\n\n# \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\xa7\x84\xed\x96\x89\nfor step in range(2):\n    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n\n    print('Step: %d, ' % sess.run(global_step),\n          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n\n# \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x9c \xeb\x92\xa4, \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nsaver.save(sess, './model/dnn.ckpt', global_step=global_step)\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n# 0: \xea\xb8\xb0\xed\x83\x80 1: \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, 2: \xec\xa1\xb0\xeb\xa5\x98\n######\nprediction = tf.argmax(model, 1)\ntarget = tf.argmax(Y, 1)\nprint('\xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:', sess.run(prediction, feed_dict={X: x_data}))\nprint('\xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92:', sess.run(target, feed_dict={Y: y_data}))\n\nis_correct = tf.equal(prediction, target)\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint('\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n"""
"05 - TensorBoard, Saver/02 - TensorBoard.py",30,"b""# \xed\x85\x90\xec\x84\x9c\xeb\xb3\xb4\xeb\x93\x9c\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xea\xb0\x81\xec\xa2\x85 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\x84\xa4\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 \xeb\xb0\xa9\xeb\xb2\x95\xec\x9d\x84 \xec\x9d\xb5\xed\x98\x80\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n\nimport tensorflow as tf\nimport numpy as np\n\n\ndata = np.loadtxt('./data.csv', delimiter=',',\n                  unpack=True, dtype='float32')\n\nx_data = np.transpose(data[0:2])\ny_data = np.transpose(data[2:])\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nglobal_step = tf.Variable(0, trainable=False, name='global_step')\n\nX = tf.placeholder(tf.float32)\nY = tf.placeholder(tf.float32)\n\n# with tf.name_scope \xec\x9c\xbc\xeb\xa1\x9c \xeb\xac\xb6\xec\x9d\x80 \xeb\xb8\x94\xeb\x9f\xad\xec\x9d\x80 \xed\x85\x90\xec\x84\x9c\xeb\xb3\xb4\xeb\x93\x9c\xec\x97\x90\xec\x84\x9c \xed\x95\x9c \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x95\x88\xec\x97\x90 \xed\x91\x9c\xed\x98\x84\xed\x95\xb4\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4\nwith tf.name_scope('layer1'):\n    W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.), name='W1')\n    L1 = tf.nn.relu(tf.matmul(X, W1))\n\nwith tf.name_scope('layer2'):\n    W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.), name='W2')\n    L2 = tf.nn.relu(tf.matmul(L1, W2))\n\nwith tf.name_scope('output'):\n    W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.), name='W3')\n    model = tf.matmul(L2, W3)\n\nwith tf.name_scope('optimizer'):\n    cost = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n    train_op = optimizer.minimize(cost, global_step=global_step)\n\n    # tf.summary.scalar \xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x88\x98\xec\xa7\x91\xed\x95\x98\xea\xb3\xa0 \xec\x8b\xb6\xec\x9d\x80 \xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xec\xa7\x80\xec\xa0\x95\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n    tf.summary.scalar('cost', cost)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsaver = tf.train.Saver(tf.global_variables())\n\nckpt = tf.train.get_checkpoint_state('./model')\nif ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n    saver.restore(sess, ckpt.model_checkpoint_path)\nelse:\n    sess.run(tf.global_variables_initializer())\n\n# \xed\x85\x90\xec\x84\x9c\xeb\xb3\xb4\xeb\x93\x9c\xec\x97\x90\xec\x84\x9c \xed\x91\x9c\xec\x8b\x9c\xed\x95\xb4\xec\xa3\xbc\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xed\x85\x90\xec\x84\x9c\xeb\x93\xa4\xec\x9d\x84 \xec\x88\x98\xec\xa7\x91\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nmerged = tf.summary.merge_all()\n# \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xec\x99\x80 \xed\x85\x90\xec\x84\x9c\xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xeb\x94\x94\xeb\xa0\x89\xed\x86\xa0\xeb\xa6\xac\xeb\xa5\xbc \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nwriter = tf.summary.FileWriter('./logs', sess.graph)\n# \xec\x9d\xb4\xeb\xa0\x87\xea\xb2\x8c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c \xeb\xa1\x9c\xea\xb7\xb8\xeb\x8a\x94, \xed\x95\x99\xec\x8a\xb5 \xed\x9b\x84 \xeb\x8b\xa4\xec\x9d\x8c\xec\x9d\x98 \xeb\xaa\x85\xeb\xa0\xb9\xec\x96\xb4\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x9b\xb9\xec\x84\x9c\xeb\xb2\x84\xeb\xa5\xbc \xec\x8b\xa4\xed\x96\x89\xec\x8b\x9c\xed\x82\xa8 \xeb\x92\xa4\n# tensorboard --logdir=./logs\n# \xeb\x8b\xa4\xec\x9d\x8c \xec\xa3\xbc\xec\x86\x8c\xec\x99\x80 \xec\x9b\xb9\xeb\xb8\x8c\xeb\x9d\xbc\xec\x9a\xb0\xec\xa0\x80\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xed\x85\x90\xec\x84\x9c\xeb\xb3\xb4\xeb\x93\x9c\xec\x97\x90\xec\x84\x9c \xed\x99\x95\xec\x9d\xb8\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# http://localhost:6006\n\n# \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\xa7\x84\xed\x96\x89\nfor step in range(100):\n    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n\n    print('Step: %d, ' % sess.run(global_step),\n          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n\n    # \xec\xa0\x81\xec\xa0\x88\xed\x95\x9c \xec\x8b\x9c\xec\xa0\x90\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xec\x88\x98\xec\xa7\x91\xed\x95\x98\xea\xb3\xa0 \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n    writer.add_summary(summary, global_step=sess.run(global_step))\n\nsaver.save(sess, './model/dnn.ckpt', global_step=global_step)\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n# 0: \xea\xb8\xb0\xed\x83\x80 1: \xed\x8f\xac\xec\x9c\xa0\xeb\xa5\x98, 2: \xec\xa1\xb0\xeb\xa5\x98\n######\nprediction = tf.argmax(model, 1)\ntarget = tf.argmax(Y, 1)\nprint('\xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:', sess.run(prediction, feed_dict={X: x_data}))\nprint('\xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92:', sess.run(target, feed_dict={Y: y_data}))\n\nis_correct = tf.equal(prediction, target)\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint('\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n"""
"05 - TensorBoard, Saver/03 - TensorBoard2.py",33,"b'import tensorflow as tf\nimport numpy as np\n\ndata = np.loadtxt(\'./data.csv\', delimiter=\',\',\n                  unpack=True, dtype=\'float32\')\n\nx_data = np.transpose(data[0:2])\ny_data = np.transpose(data[2:])\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nglobal_step = tf.Variable(0, trainable=False, name=\'global_step\')\n\nX = tf.placeholder(tf.float32)\nY = tf.placeholder(tf.float32)\n\nwith tf.name_scope(\'layer1\'):\n    W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.), name=\'W1\')\n    L1 = tf.nn.relu(tf.matmul(X, W1))\n\n    tf.summary.histogram(""X"", X)\n    tf.summary.histogram(""Weights"", W1)\n\nwith tf.name_scope(\'layer2\'):\n    W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.), name=\'W2\')\n    L2 = tf.nn.relu(tf.matmul(L1, W2))\n\n    tf.summary.histogram(""Weights"", W2)\n\nwith tf.name_scope(\'output\'):\n    W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.), name=\'W3\')\n    model = tf.matmul(L2, W3)\n\n    tf.summary.histogram(""Weights"", W3)\n    tf.summary.histogram(""Model"", model)\n\nwith tf.name_scope(\'optimizer\'):\n    cost = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n    train_op = optimizer.minimize(cost, global_step=global_step)\n\n    tf.summary.scalar(\'cost\', cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsaver = tf.train.Saver(tf.global_variables())\n\nckpt = tf.train.get_checkpoint_state(\'./model\')\nif ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n    saver.restore(sess, ckpt.model_checkpoint_path)\nelse:\n    sess.run(tf.global_variables_initializer())\n\nmerged = tf.summary.merge_all()\nwriter = tf.summary.FileWriter(\'./logs\', sess.graph)\n\nfor step in range(100):\n    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n\n    print(\'Step: %d, \' % sess.run(global_step),\n          \'Cost: %.3f\' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n\n    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n    writer.add_summary(summary, global_step=sess.run(global_step))\n\nsaver.save(sess, \'./model/dnn.ckpt\', global_step=global_step)\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\nprediction = tf.argmax(model, 1)\ntarget = tf.argmax(Y, 1)\nprint(\'\xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:\', sess.run(prediction, feed_dict={X: x_data}))\nprint(\'\xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92:\', sess.run(target, feed_dict={Y: y_data}))\n\nis_correct = tf.equal(prediction, target)\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint(\'\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84: %.2f\' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n'"
06 - MNIST/01 - MNIST.py,15,"b'# \xeb\xa8\xb8\xec\x8b\xa0\xeb\x9f\xac\xeb\x8b\x9d \xed\x95\x99\xec\x8a\xb5\xec\x9d\x98 Hello World \xec\x99\x80 \xea\xb0\x99\xec\x9d\x80 MNIST(\xec\x86\x90\xea\xb8\x80\xec\x94\xa8 \xec\x88\xab\xec\x9e\x90 \xec\x9d\xb8\xec\x8b\x9d) \xeb\xac\xb8\xec\xa0\x9c\xeb\xa5\xbc \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9c\xbc\xeb\xa1\x9c \xed\x92\x80\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n# \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x97\x90 \xea\xb8\xb0\xeb\xb3\xb8 \xeb\x82\xb4\xec\x9e\xa5\xeb\x90\x9c mnist \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xeb\xa1\x9c\xeb\x93\x9c\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c \xed\x8f\xb4\xeb\x8d\x94\xec\x97\x90 MNIST \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x97\x86\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0 \xec\x9e\x90\xeb\x8f\x99\xec\x9c\xbc\xeb\xa1\x9c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xeb\x8b\xa4\xec\x9a\xb4\xeb\xa1\x9c\xeb\x93\x9c\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# one_hot \xec\x98\xb5\xec\x85\x98\xec\x9d\x80 \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xeb\x8f\x99\xeb\xac\xbc \xeb\xb6\x84\xeb\xa5\x98 \xec\x98\x88\xec\xa0\x9c\xec\x97\x90\xec\x84\x9c \xeb\xb3\xb4\xec\x95\x98\xeb\x8d\x98 one_hot \xeb\xb0\xa9\xec\x8b\x9d\xec\x9d\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\n# \xec\x9e\x85\xeb\xa0\xa5 \xea\xb0\x92\xec\x9d\x98 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x80 [\xeb\xb0\xb0\xec\xb9\x98\xed\x81\xac\xea\xb8\xb0, \xed\x8a\xb9\xec\x84\xb1\xea\xb0\x92] \xec\x9c\xbc\xeb\xa1\x9c \xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x86\x90\xea\xb8\x80\xec\x94\xa8 \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\x8a\x94 28x28 \xed\x94\xbd\xec\x85\x80\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa3\xa8\xec\x96\xb4\xec\xa0\xb8 \xec\x9e\x88\xea\xb3\xa0, \xec\x9d\xb4\xeb\xa5\xbc 784\xea\xb0\x9c\xec\x9d\x98 \xed\x8a\xb9\xec\x84\xb1\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nX = tf.placeholder(tf.float32, [None, 784])\n# \xea\xb2\xb0\xea\xb3\xbc\xeb\x8a\x94 0~9 \xec\x9d\x98 10 \xea\xb0\x80\xec\xa7\x80 \xeb\xb6\x84\xeb\xa5\x98\xeb\xa5\xbc \xea\xb0\x80\xec\xa7\x91\xeb\x8b\x88\xeb\x8b\xa4.\nY = tf.placeholder(tf.float32, [None, 10])\n\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x98 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\x8a\x94 \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xea\xb5\xac\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# 784(\xec\x9e\x85\xeb\xa0\xa5 \xed\x8a\xb9\xec\x84\xb1\xea\xb0\x92)\n#   -> 256 (\xed\x9e\x88\xeb\x93\xa0\xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4 \xeb\x89\xb4\xeb\x9f\xb0 \xea\xb0\xaf\xec\x88\x98) -> 256 (\xed\x9e\x88\xeb\x93\xa0\xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4 \xeb\x89\xb4\xeb\x9f\xb0 \xea\xb0\xaf\xec\x88\x98)\n#   -> 10 (\xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x92 0~9 \xeb\xb6\x84\xeb\xa5\x98)\nW1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n# \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x97\x90 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xeb\xa5\xbc \xea\xb3\xb1\xed\x95\x98\xea\xb3\xa0 ReLU \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\nL1 = tf.nn.relu(tf.matmul(X, W1))\n\nW2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n# L1 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x97\x90 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xeb\xa5\xbc \xea\xb3\xb1\xed\x95\x98\xea\xb3\xa0 ReLU \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\nL2 = tf.nn.relu(tf.matmul(L1, W2))\n\nW3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n# \xec\xb5\x9c\xec\xa2\x85 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x80 W3 \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xea\xb3\xb1\xed\x95\xb4 10\xea\xb0\x9c\xec\x9d\x98 \xeb\xb6\x84\xeb\xa5\x98\xeb\xa5\xbc \xea\xb0\x80\xec\xa7\x80\xea\xb2\x8c \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nmodel = tf.matmul(L2, W3)\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\noptimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nbatch_size = 100\ntotal_batch = int(mnist.train.num_examples / batch_size)\n\nfor epoch in range(15):\n    total_cost = 0\n\n    for i in range(total_batch):\n        # \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x9d\x98 mnist \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x98 next_batch \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4\n        # \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c \xed\x81\xac\xea\xb8\xb0\xeb\xa7\x8c\xed\x81\xbc \xed\x95\x99\xec\x8a\xb5\xed\x95\xa0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n\n        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n        total_cost += cost_val\n\n    print(\'Epoch:\', \'%04d\' % (epoch + 1),\n          \'Avg. cost =\', \'{:.3f}\'.format(total_cost / total_batch))\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\n# model \xeb\xa1\x9c \xec\x98\x88\xec\xb8\xa1\xed\x95\x9c \xea\xb0\x92\xea\xb3\xbc \xec\x8b\xa4\xec\xa0\x9c \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\xb8 Y\xec\x9d\x98 \xea\xb0\x92\xec\x9d\x84 \xeb\xb9\x84\xea\xb5\x90\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# tf.argmax \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x98\x88\xec\xb8\xa1\xed\x95\x9c \xea\xb0\x92\xec\x97\x90\xec\x84\x9c \xea\xb0\x80\xec\x9e\xa5 \xed\x81\xb0 \xea\xb0\x92\xec\x9d\x84 \xec\x98\x88\xec\xb8\xa1\xed\x95\x9c \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\xb4\xeb\x9d\xbc\xea\xb3\xa0 \xed\x8f\x89\xea\xb0\x80\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x88) [0.1 0 0 0.7 0 0.2 0 0 0 0] -> 3\nis_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint(\'\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:\', sess.run(accuracy,\n                        feed_dict={X: mnist.test.images,\n                                   Y: mnist.test.labels}))\n'"
06 - MNIST/02 - Dropout.py,17,"b'# \xea\xb3\xbc\xec\xa0\x81\xed\x95\xa9 \xeb\xb0\xa9\xec\xa7\x80 \xea\xb8\xb0\xeb\xb2\x95 \xec\xa4\x91 \xed\x95\x98\xeb\x82\x98\xec\x9d\xb8 Dropout \xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32, [None, 784])\nY = tf.placeholder(tf.float32, [None, 10])\nkeep_prob = tf.placeholder(tf.float32)\n\nW1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\nL1 = tf.nn.relu(tf.matmul(X, W1))\n# \xed\x85\x90\xec\x84\x9c\xed\x94\x8c\xeb\xa1\x9c\xec\x9a\xb0\xec\x97\x90 \xeb\x82\xb4\xec\x9e\xa5\xeb\x90\x9c \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac dropout \xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x95\xa8\xec\x88\x98\xec\x97\x90 \xec\xa0\x81\xec\x9a\xa9\xed\x95\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x99\x80 \xed\x99\x95\xeb\xa5\xa0\xeb\xa7\x8c \xeb\x84\xa3\xec\x96\xb4\xec\xa3\xbc\xeb\xa9\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4. \xea\xb2\x81\xeb\x82\x98 \xeb\xa7\xa4\xec\xa7\x81!!\nL1 = tf.nn.dropout(L1, keep_prob)\n\nW2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\nL2 = tf.nn.relu(tf.matmul(L1, W2))\nL2 = tf.nn.dropout(L2, keep_prob)\n\nW3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\nmodel = tf.matmul(L2, W3)\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\noptimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nbatch_size = 100\ntotal_batch = int(mnist.train.num_examples / batch_size)\n\nfor epoch in range(30):\n    total_cost = 0\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n\n        _, cost_val = sess.run([optimizer, cost],\n                               feed_dict={X: batch_xs,\n                                          Y: batch_ys,\n                                          keep_prob: 0.8})\n        total_cost += cost_val\n\n    print(\'Epoch:\', \'%04d\' % (epoch + 1),\n          \'Avg. cost =\', \'{:.3f}\'.format(total_cost / total_batch))\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\nis_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint(\'\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:\', sess.run(accuracy,\n                        feed_dict={X: mnist.test.images,\n                                   Y: mnist.test.labels,\n                                   keep_prob: 1}))\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8 (matplot)\n######\nlabels = sess.run(model,\n                  feed_dict={X: mnist.test.images,\n                             Y: mnist.test.labels,\n                             keep_prob: 1})\n\nfig = plt.figure()\nfor i in range(10):\n    subplot = fig.add_subplot(2, 5, i + 1)\n    subplot.set_xticks([])\n    subplot.set_yticks([])\n    subplot.set_title(\'%d\' % np.argmax(labels[i]))\n    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n                   cmap=plt.cm.gray_r)\n\nplt.show()\n'"
07 - CNN/01 - CNN.py,29,"b'# \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80 \xec\xb2\x98\xeb\xa6\xac \xeb\xb6\x84\xec\x95\xbc\xec\x97\x90\xec\x84\x9c \xea\xb0\x80\xec\x9e\xa5 \xec\x9c\xa0\xeb\xaa\x85\xed\x95\x9c \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\xb8 CNN \xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xeb\x8d\x94 \xeb\x86\x92\xec\x9d\x80 \xec\x9d\xb8\xec\x8b\x9d\xeb\xa5\xa0\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\n# \xea\xb8\xb0\xec\xa1\xb4 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 \xec\x9e\x85\xeb\xa0\xa5 \xea\xb0\x92\xec\x9d\x84 28x28 \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xec\xb0\xa8\xec\x9b\x90\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xec\x98\x80\xec\x9c\xbc\xeb\x82\x98,\n# CNN \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 2\xec\xb0\xa8\xec\x9b\x90 \xed\x8f\x89\xeb\xa9\xb4\xea\xb3\xbc \xed\x8a\xb9\xec\x84\xb1\xec\xb9\x98\xec\x9d\x98 \xed\x98\x95\xed\x83\x9c\xeb\xa5\xbc \xea\xb0\x96\xeb\x8a\x94 \xea\xb5\xac\xec\xa1\xb0\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\nX = tf.placeholder(tf.float32, [None, 28, 28, 1])\nY = tf.placeholder(tf.float32, [None, 10])\nkeep_prob = tf.placeholder(tf.float32)\n\n# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xb3\x80\xec\x88\x98\xec\x99\x80 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\x8a\x94 \xeb\x8b\xa4\xec\x9d\x8c\xea\xb3\xbc \xea\xb0\x99\xec\x9d\x80 \xed\x98\x95\xed\x83\x9c\xeb\xa1\x9c \xea\xb5\xac\xec\x84\xb1\xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# W1 [3 3 1 32] -> [3 3]: \xec\xbb\xa4\xeb\x84\x90 \xed\x81\xac\xea\xb8\xb0, 1: \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92 X \xec\x9d\x98 \xed\x8a\xb9\xec\x84\xb1\xec\x88\x98, 32: \xed\x95\x84\xed\x84\xb0 \xea\xb0\xaf\xec\x88\x98\n# L1 Conv shape=(?, 28, 28, 32)\n#    Pool     ->(?, 14, 14, 32)\nW1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n# tf.nn.conv2d \xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xed\x95\x9c\xec\xb9\xb8\xec\x94\xa9 \xec\x9b\x80\xec\xa7\x81\xec\x9d\xb4\xeb\x8a\x94 \xec\xbb\xa8\xeb\xb3\xbc\xeb\xa3\xa8\xec\x85\x98 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xec\x89\xbd\xea\xb2\x8c \xeb\xa7\x8c\xeb\x93\xa4 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# padding=\'SAME\' \xec\x9d\x80 \xec\xbb\xa4\xeb\x84\x90 \xec\x8a\xac\xeb\x9d\xbc\xec\x9d\xb4\xeb\x94\xa9\xec\x8b\x9c \xec\xb5\x9c\xec\x99\xb8\xea\xb3\xbd\xec\x97\x90\xec\x84\x9c \xed\x95\x9c\xec\xb9\xb8 \xeb\xb0\x96\xec\x9c\xbc\xeb\xa1\x9c \xeb\x8d\x94 \xec\x9b\x80\xec\xa7\x81\xec\x9d\xb4\xeb\x8a\x94 \xec\x98\xb5\xec\x85\x98\nL1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding=\'SAME\')\nL1 = tf.nn.relu(L1)\n# Pooling \xec\x97\xad\xec\x8b\x9c tf.nn.max_pool \xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xec\x89\xbd\xea\xb2\x8c \xea\xb5\xac\xec\x84\xb1\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nL1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n# L1 = tf.nn.dropout(L1, keep_prob)\n\n# L2 Conv shape=(?, 14, 14, 64)\n#    Pool     ->(?, 7, 7, 64)\n# W2 \xec\x9d\x98 [3, 3, 32, 64] \xec\x97\x90\xec\x84\x9c 32 \xeb\x8a\x94 L1 \xec\x97\x90\xec\x84\x9c \xec\xb6\x9c\xeb\xa0\xa5\xeb\x90\x9c W1 \xec\x9d\x98 \xeb\xa7\x88\xec\xa7\x80\xeb\xa7\x89 \xec\xb0\xa8\xec\x9b\x90, \xed\x95\x84\xed\x84\xb0\xec\x9d\x98 \xed\x81\xac\xea\xb8\xb0 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nW2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\nL2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding=\'SAME\')\nL2 = tf.nn.relu(L2)\nL2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n# L2 = tf.nn.dropout(L2, keep_prob)\n\n# FC \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4: \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92 7x7x64 -> \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92 256\n# Full connect\xeb\xa5\xbc \xec\x9c\x84\xed\x95\xb4 \xec\xa7\x81\xec\xa0\x84\xec\x9d\x98 Pool \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xec\x9d\xb8 (?, 7, 7, 64) \xeb\xa5\xbc \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x98\xec\x97\xac \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x84 \xec\xa4\x84\xec\x97\xac\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\n#    Reshape  ->(?, 256)\nW3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\nL3 = tf.reshape(L2, [-1, 7 * 7 * 64])\nL3 = tf.matmul(L3, W3)\nL3 = tf.nn.relu(L3)\nL3 = tf.nn.dropout(L3, keep_prob)\n\n# \xec\xb5\x9c\xec\xa2\x85 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92 L3 \xec\x97\x90\xec\x84\x9c\xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5 256\xea\xb0\x9c\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb0\x9b\xec\x95\x84\xec\x84\x9c 0~9 \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\xb8 10\xea\xb0\x9c\xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\nW4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\nmodel = tf.matmul(L3, W4)\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\noptimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n# \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc RMSPropOptimizer \xeb\xa1\x9c \xeb\xb0\x94\xea\xbf\x94\xec\x84\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x99\x95\xec\x9d\xb8\xed\x95\xb4\xeb\xb4\x85\xec\x8b\x9c\xeb\x8b\xa4.\n# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nbatch_size = 100\ntotal_batch = int(mnist.train.num_examples / batch_size)\n\nfor epoch in range(15):\n    total_cost = 0\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        # \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc CNN \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x9c\x84\xed\x95\x9c \xec\x9e\x90\xeb\xa3\x8c\xed\x98\x95\xed\x83\x9c\xec\x9d\xb8 [28 28 1] \xec\x9d\x98 \xed\x98\x95\xed\x83\x9c\xeb\xa1\x9c \xec\x9e\xac\xea\xb5\xac\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n\n        _, cost_val = sess.run([optimizer, cost],\n                               feed_dict={X: batch_xs,\n                                          Y: batch_ys,\n                                          keep_prob: 0.7})\n        total_cost += cost_val\n\n    print(\'Epoch:\', \'%04d\' % (epoch + 1),\n          \'Avg. cost =\', \'{:.3f}\'.format(total_cost / total_batch))\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\nis_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint(\'\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:\', sess.run(accuracy,\n                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n                                   Y: mnist.test.labels,\n                                   keep_prob: 1}))\n'"
07 - CNN/02 - tf.layers.py,19,"b'# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xea\xb5\xac\xec\x84\xb1\xec\x9d\x84 \xec\x86\x90\xec\x89\xbd\xea\xb2\x8c \xed\x95\xb4 \xec\xa3\xbc\xeb\x8a\x94 \xec\x9c\xa0\xed\x8b\xb8\xeb\xa6\xac\xed\x8b\xb0 \xeb\xaa\xa8\xec\x9d\x8c\xec\x9d\xb8 tensorflow.layers \xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# 01 - CNN.py \xeb\xa5\xbc \xec\x9e\xac\xea\xb5\xac\xec\x84\xb1\xed\x95\x9c \xea\xb2\x83\xec\x9d\xb4\xeb\x8b\x88, \xec\x86\x8c\xec\x8a\xa4\xeb\xa5\xbc \xed\x95\x9c \xeb\xb2\x88 \xeb\xb9\x84\xea\xb5\x90\xed\x95\xb4\xeb\xb3\xb4\xec\x84\xb8\xec\x9a\x94.\n# \xec\x9d\xb4\xec\xb2\x98\xeb\x9f\xbc TensorFlow \xec\x97\x90\xeb\x8a\x94 \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xeb\x8a\x94 \xeb\x8b\xa4\xec\x96\x91\xed\x95\x9c \xed\x95\xa8\xec\x88\x98\xec\x99\x80 \xec\x9c\xa0\xed\x8b\xb8\xeb\xa6\xac\xed\x8b\xb0\xeb\x93\xa4\xec\x9d\xb4 \xeb\xa7\xa4\xec\x9a\xb0 \xeb\xa7\x8e\xec\x9d\xb4 \xeb\xa7\x88\xeb\xa0\xa8\xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x8b\xa4\xeb\xa7\x8c, \xec\xb2\x98\xec\x9d\x8c\xec\x97\x90\xeb\x8a\x94 \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9d\xb8 \xea\xb0\x9c\xeb\x85\x90\xec\x97\x90 \xec\x9d\xb5\xec\x88\x99\xed\x9e\x88\xec\xa7\x80\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4 \xec\xa2\x8b\xec\x9c\xbc\xeb\xaf\x80\xeb\xa1\x9c \xec\x9d\xb4\xed\x9b\x84\xec\x97\x90\xeb\x8f\x84 \xea\xb0\x80\xea\xb8\x89\xec\xa0\x81 \xea\xb8\xb0\xeb\xb3\xb8 \xed\x95\xa8\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32, [None, 28, 28, 1])\nY = tf.placeholder(tf.float32, [None, 10])\nis_training = tf.placeholder(tf.bool)\n\n# \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c inputs, outputs size, kernel_size \xeb\xa7\x8c \xeb\x84\xa3\xec\x96\xb4\xec\xa3\xbc\xeb\xa9\xb4\n# \xed\x99\x9c\xec\x84\xb1\xed\x99\x94 \xed\x95\xa8\xec\x88\x98 \xec\xa0\x81\xec\x9a\xa9\xec\x9d\x80 \xeb\xac\xbc\xeb\xa1\xa0, \xec\xbb\xa8\xeb\xb3\xbc\xeb\xa3\xa8\xec\x85\x98 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\x82\x98\xeb\xa8\xb8\xec\xa7\x80 \xec\x88\x98\xec\xb9\x98\xeb\x93\xa4\xec\x9d\x80 \xec\x95\x8c\xec\x95\x84\xec\x84\x9c \xea\xb3\x84\xec\x82\xb0\xed\x95\xb4\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x8a\xb9\xed\x9e\x88 Weights \xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\x8a\x94\xeb\x8d\xb0 xavier_initializer \xeb\xa5\xbc \xec\x93\xb0\xea\xb3\xa0 \xec\x9e\x88\xeb\x8a\x94 \xeb\x93\xb1,\n# \xed\x81\xac\xea\xb2\x8c \xec\x8b\xa0\xea\xb2\xbd\xec\x93\xb0\xec\xa7\x80 \xec\x95\x8a\xec\x95\x84\xeb\x8f\x84 \xec\x9d\xbc\xeb\xb0\x98\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xed\x9a\xa8\xec\x9c\xa8\xec\xa0\x81\xec\x9d\xb8 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\nL1 = tf.layers.conv2d(X, 32, [3, 3], activation=tf.nn.relu)\nL1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])\nL1 = tf.layers.dropout(L1, 0.7, is_training)\n\nL2 = tf.layers.conv2d(L1, 64, [3, 3], activation=tf.nn.relu)\nL2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])\nL2 = tf.layers.dropout(L2, 0.7, is_training)\n\nL3 = tf.contrib.layers.flatten(L2)\nL3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)\nL3 = tf.layers.dropout(L3, 0.5, is_training)\n\nmodel = tf.layers.dense(L3, 10, activation=None)\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\noptimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nbatch_size = 100\ntotal_batch = int(mnist.train.num_examples/batch_size)\n\nfor epoch in range(15):\n    total_cost = 0\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n        _, cost_val = sess.run([optimizer, cost],\n                               feed_dict={X: batch_xs,\n                                          Y: batch_ys,\n                                          is_training: True})\n        total_cost += cost_val\n\n    print(\'Epoch:\', \'%04d\' % (epoch + 1),\n          \'Avg. cost =\', \'{:.4f}\'.format(total_cost / total_batch))\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\nis_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\nprint(\'\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:\', sess.run(accuracy,\n                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n                                   Y: mnist.test.labels,\n                                   is_training: False}))\n'"
08 - Autoencoder/01 - Autoencoder.py,13,"b'# \xeb\x8c\x80\xed\x91\x9c\xec\xa0\x81\xec\x9d\xb8 \xeb\xb9\x84\xec\xa7\x80\xeb\x8f\x84(Unsupervised) \xed\x95\x99\xec\x8a\xb5 \xeb\xb0\xa9\xeb\xb2\x95\xec\x9d\xb8 Autoencoder \xeb\xa5\xbc \xea\xb5\xac\xed\x98\x84\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\nlearning_rate = 0.01\ntraining_epoch = 20\nbatch_size = 100\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4 \xea\xb5\xac\xec\x84\xb1 \xec\x98\xb5\xec\x85\x98\nn_hidden = 256  # \xed\x9e\x88\xeb\x93\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xeb\x89\xb4\xeb\x9f\xb0 \xea\xb0\xaf\xec\x88\x98\nn_input = 28*28   # \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92 \xed\x81\xac\xea\xb8\xb0 - \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80 \xed\x94\xbd\xec\x85\x80\xec\x88\x98\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\n# Y \xea\xb0\x80 \xec\x97\x86\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 Y\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nX = tf.placeholder(tf.float32, [None, n_input])\n\n# \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x99\x80 \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xec\x99\x80 \xed\x8e\xb8\xed\x96\xa5 \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x8b\xa4\xec\x9d\x8c\xea\xb3\xbc \xea\xb0\x99\xec\x9d\xb4 \xec\x9d\xb4\xec\x96\xb4\xec\xa7\x80\xeb\x8a\x94 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xea\xb0\x92\xeb\x93\xa4 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# input -> encode -> decode -> output\nW_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\nb_encode = tf.Variable(tf.random_normal([n_hidden]))\n# sigmoid \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xea\xb5\xac\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# sigmoid(X * W + b)\n# \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4 \xea\xb5\xac\xec\x84\xb1\nencoder = tf.nn.sigmoid(\n                tf.add(tf.matmul(X, W_encode), b_encode))\n\n# encode \xec\x9d\x98 \xec\x95\x84\xec\x9b\x83\xed\x92\x8b \xed\x81\xac\xea\xb8\xb0\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xeb\xb3\xb4\xeb\x8b\xa4 \xec\x9e\x91\xec\x9d\x80 \xed\x81\xac\xea\xb8\xb0\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4 \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xec\x95\x95\xec\xb6\x95\xed\x95\x98\xec\x97\xac \xed\x8a\xb9\xec\x84\xb1\xec\x9d\x84 \xeb\xbd\x91\xec\x95\x84\xeb\x82\xb4\xea\xb3\xa0,\n# decode \xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5\xec\x9d\x84 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc \xeb\x8f\x99\xec\x9d\xbc\xed\x95\x9c \xed\x81\xac\xea\xb8\xb0\xeb\xa5\xbc \xea\xb0\x96\xeb\x8f\x84\xeb\xa1\x9d\xed\x95\x98\xec\x97\xac \xec\x9e\x85\xeb\xa0\xa5\xea\xb3\xbc \xeb\x98\x91\xea\xb0\x99\xec\x9d\x80 \xec\x95\x84\xec\x9b\x83\xed\x92\x8b\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4 \xeb\x82\xb4\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x9e\x88\xeb\x93\xa0 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xec\x9d\x98 \xea\xb5\xac\xec\x84\xb1\xea\xb3\xbc \xed\x8a\xb9\xec\x84\xb1\xec\xb9\x98\xec\x9d\x84 \xeb\xbd\x91\xec\x95\x84\xeb\x82\xb4\xeb\x8a\x94 \xec\x95\x8c\xea\xb3\xa0\xeb\xa6\xac\xec\xa6\x98\xec\x9d\x84 \xeb\xb3\x80\xea\xb2\xbd\xed\x95\x98\xec\x97\xac \xeb\x8b\xa4\xec\x96\x91\xed\x95\x9c \xec\x98\xa4\xed\x86\xa0\xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xa4 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nW_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\nb_decode = tf.Variable(tf.random_normal([n_input]))\n# \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4 \xea\xb5\xac\xec\x84\xb1\n# \xec\x9d\xb4 \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94\xea\xb0\x80 \xec\xb5\x9c\xec\xa2\x85 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ndecoder = tf.nn.sigmoid(\n                tf.add(tf.matmul(encoder, W_decode), b_decode))\n\n# \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94\xeb\x8a\x94 \xec\x9d\xb8\xed\x92\x8b\xea\xb3\xbc \xec\xb5\x9c\xeb\x8c\x80\xed\x95\x9c \xea\xb0\x99\xec\x9d\x80 \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x82\xb4\xec\x95\xbc \xed\x95\x98\xeb\xaf\x80\xeb\xa1\x9c, \xeb\x94\x94\xec\xbd\x94\xeb\x94\xa9\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x8f\x89\xea\xb0\x80\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4\n# \xec\x9e\x85\xeb\xa0\xa5 \xea\xb0\x92\xec\x9d\xb8 X \xea\xb0\x92\xec\x9d\x84 \xed\x8f\x89\xea\xb0\x80\xeb\xa5\xbc \xec\x9c\x84\xed\x95\x9c \xec\x8b\xa4\xec\xb8\xa1 \xea\xb2\xb0\xea\xb3\xbc \xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c\xed\x95\x98\xec\x97\xac decoder \xec\x99\x80\xec\x9d\x98 \xec\xb0\xa8\xec\x9d\xb4\xeb\xa5\xbc \xec\x86\x90\xec\x8b\xa4\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ncost = tf.reduce_mean(tf.pow(X - decoder, 2))\noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\ntotal_batch = int(mnist.train.num_examples/batch_size)\n\nfor epoch in range(training_epoch):\n    total_cost = 0\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        _, cost_val = sess.run([optimizer, cost],\n                               feed_dict={X: batch_xs})\n        total_cost += cost_val\n\n    print(\'Epoch:\', \'%04d\' % (epoch + 1),\n          \'Avg. cost =\', \'{:.4f}\'.format(total_cost / total_batch))\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n# \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92(\xec\x9c\x84\xec\xaa\xbd)\xea\xb3\xbc \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\xb4 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c \xea\xb0\x92(\xec\x95\x84\xeb\x9e\x98\xec\xaa\xbd)\xec\x9d\x84 \xec\x8b\x9c\xea\xb0\x81\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb9\x84\xea\xb5\x90\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n######\nsample_size = 10\n\nsamples = sess.run(decoder,\n                   feed_dict={X: mnist.test.images[:sample_size]})\n\nfig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n\nfor i in range(sample_size):\n    ax[0][i].set_axis_off()\n    ax[1][i].set_axis_off()\n    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n\nplt.show()\n'"
09 - GAN/01 - GAN.py,26,"b'# 2016\xeb\x85\x84\xec\x97\x90 \xea\xb0\x80\xec\x9e\xa5 \xea\xb4\x80\xec\x8b\xac\xec\x9d\x84 \xeb\xa7\x8e\xec\x9d\xb4 \xeb\xb0\x9b\xec\x95\x98\xeb\x8d\x98 \xeb\xb9\x84\xea\xb0\x90\xeb\x8f\x85(Unsupervised) \xed\x95\x99\xec\x8a\xb5 \xeb\xb0\xa9\xeb\xb2\x95\xec\x9d\xb8\n# Generative Adversarial Network(GAN)\xec\x9d\x84 \xea\xb5\xac\xed\x98\x84\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# https://arxiv.org/abs/1406.2661\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\ntotal_epoch = 100\nbatch_size = 100\nlearning_rate = 0.0002\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4 \xea\xb5\xac\xec\x84\xb1 \xec\x98\xb5\xec\x85\x98\nn_hidden = 256\nn_input = 28 * 28\nn_noise = 128  # \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0\xec\x9d\x98 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88\xec\x9d\x98 \xed\x81\xac\xea\xb8\xb0\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\n# GAN \xeb\x8f\x84 Unsupervised \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4\xeb\xaf\x80\xeb\xa1\x9c Autoencoder \xec\xb2\x98\xeb\x9f\xbc Y \xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nX = tf.placeholder(tf.float32, [None, n_input])\n# \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88 Z\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nZ = tf.placeholder(tf.float32, [None, n_noise])\n\n# \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8a\x94 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nG_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\nG_b1 = tf.Variable(tf.zeros([n_hidden]))\nG_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\nG_b2 = tf.Variable(tf.zeros([n_input]))\n\n# \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8a\x94 \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nD_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\nD_b1 = tf.Variable(tf.zeros([n_hidden]))\n# \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0\xec\x9d\x98 \xec\xb5\x9c\xec\xa2\x85 \xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x92\xec\x9d\x80 \xec\x96\xbc\xeb\xa7\x88\xeb\x82\x98 \xec\xa7\x84\xec\xa7\x9c\xec\x99\x80 \xea\xb0\x80\xea\xb9\x9d\xeb\x83\x90\xeb\xa5\xbc \xed\x8c\x90\xeb\x8b\xa8\xed\x95\x98\xeb\x8a\x94 \xed\x95\x9c \xea\xb0\x9c\xec\x9d\x98 \xec\x8a\xa4\xec\xb9\xbc\xeb\x9d\xbc\xea\xb0\x92\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nD_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\nD_b2 = tf.Variable(tf.zeros([1]))\n\n\n# \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0(G) \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ndef generator(noise_z):\n    hidden = tf.nn.relu(\n                    tf.matmul(noise_z, G_W1) + G_b1)\n    output = tf.nn.sigmoid(\n                    tf.matmul(hidden, G_W2) + G_b2)\n\n    return output\n\n\n# \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0(D) \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ndef discriminator(inputs):\n    hidden = tf.nn.relu(\n                    tf.matmul(inputs, D_W1) + D_b1)\n    output = tf.nn.sigmoid(\n                    tf.matmul(hidden, D_W2) + D_b2)\n\n    return output\n\n\n# \xeb\x9e\x9c\xeb\x8d\xa4\xed\x95\x9c \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88(Z)\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\ndef get_noise(batch_size, n_noise):\n    return np.random.normal(size=(batch_size, n_noise))\n\n\n# \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xeb\x9e\x9c\xeb\x8d\xa4\xed\x95\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nG = generator(Z)\n# \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xea\xb0\x80 \xec\xa7\x84\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xec\x9d\xb8\xec\xa7\x80 \xed\x8c\x90\xeb\xb3\x84\xed\x95\x9c \xea\xb0\x92\xec\x9d\x84 \xea\xb5\xac\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nD_gene = discriminator(G)\n# \xec\xa7\x84\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xed\x8c\x90\xeb\xb3\x84\xed\x95\x9c \xea\xb0\x92\xec\x9d\x84 \xea\xb5\xac\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nD_real = discriminator(X)\n\n# \xeb\x85\xbc\xeb\xac\xb8\xec\x97\x90 \xeb\x94\xb0\xeb\xa5\xb4\xeb\xa9\xb4, GAN \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x98 \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xeb\x8a\x94 loss_G \xec\x99\x80 loss_D \xeb\xa5\xbc \xec\xb5\x9c\xeb\x8c\x80\xed\x99\x94 \xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x8b\xa4\xeb\xa7\x8c loss_D\xec\x99\x80 loss_G\xeb\x8a\x94 \xec\x84\x9c\xeb\xa1\x9c \xec\x97\xb0\xea\xb4\x80\xea\xb4\x80\xea\xb3\x84\xea\xb0\x80 \xec\x9e\x88\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90 \xeb\x91\x90 \xea\xb0\x9c\xec\x9d\x98 \xec\x86\x90\xec\x8b\xa4\xea\xb0\x92\xec\x9d\xb4 \xed\x95\xad\xec\x83\x81 \xea\xb0\x99\xec\x9d\xb4 \xec\xa6\x9d\xea\xb0\x80\xed\x95\x98\xeb\x8a\x94 \xea\xb2\xbd\xed\x96\xa5\xec\x9d\x84 \xeb\xb3\xb4\xec\x9d\xb4\xec\xa7\x80\xeb\x8a\x94 \xec\x95\x8a\xec\x9d\x84 \xea\xb2\x83 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# loss_D\xea\xb0\x80 \xec\xa6\x9d\xea\xb0\x80\xed\x95\x98\xeb\xa0\xa4\xeb\xa9\xb4 loss_G\xeb\x8a\x94 \xed\x95\x98\xeb\x9d\xbd\xed\x95\xb4\xec\x95\xbc\xed\x95\x98\xea\xb3\xa0, loss_G\xea\xb0\x80 \xec\xa6\x9d\xea\xb0\x80\xed\x95\x98\xeb\xa0\xa4\xeb\xa9\xb4 loss_D\xeb\x8a\x94 \xed\x95\x98\xeb\x9d\xbd\xed\x95\xb4\xec\x95\xbc\xed\x95\x98\xeb\x8a\x94 \xea\xb2\xbd\xec\x9f\x81\xea\xb4\x80\xea\xb3\x84\xec\x97\x90 \xec\x9e\x88\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x85\xbc\xeb\xac\xb8\xec\x9d\x98 \xec\x88\x98\xec\x8b\x9d\xec\x97\x90 \xeb\x94\xb0\xeb\xa5\xb8 \xeb\x8b\xa4\xec\x9d\x8c \xeb\xa1\x9c\xec\xa7\x81\xec\x9d\x84 \xeb\xb3\xb4\xeb\xa9\xb4 loss_D \xeb\xa5\xbc \xec\xb5\x9c\xeb\x8c\x80\xed\x99\x94\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4\xec\x84\x9c\xeb\x8a\x94 D_gene \xea\xb0\x92\xec\x9d\x84 \xec\xb5\x9c\xec\x86\x8c\xed\x99\x94\xed\x95\x98\xea\xb2\x8c \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0\xec\x97\x90 \xec\xa7\x84\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xeb\x84\xa3\xec\x97\x88\xec\x9d\x84 \xeb\x95\x8c\xec\x97\x90\xeb\x8f\x84 \xec\xb5\x9c\xeb\x8c\x80\xea\xb0\x92\xec\x9d\x84 : tf.log(D_real)\n# \xea\xb0\x80\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xeb\x84\xa3\xec\x97\x88\xec\x9d\x84 \xeb\x95\x8c\xec\x97\x90\xeb\x8f\x84 \xec\xb5\x9c\xeb\x8c\x80\xea\xb0\x92\xec\x9d\x84 : tf.log(1 - D_gene)\n# \xea\xb0\x96\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xed\x82\xa4\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x9d\xb4\xea\xb2\x83\xec\x9d\x80 \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0\xeb\x8a\x94 \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0\xea\xb0\x80 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\x82\xb8 \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xea\xb0\x80 \xea\xb0\x80\xec\xa7\x9c\xeb\x9d\xbc\xea\xb3\xa0 \xed\x8c\x90\xeb\x8b\xa8\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nloss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n# \xeb\xb0\x98\xeb\xa9\xb4 loss_G \xeb\xa5\xbc \xec\xb5\x9c\xeb\x8c\x80\xed\x99\x94\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4\xec\x84\x9c\xeb\x8a\x94 D_gene \xea\xb0\x92\xec\x9d\x84 \xec\xb5\x9c\xeb\x8c\x80\xed\x99\x94\xed\x95\x98\xea\xb2\x8c \xeb\x90\x98\xeb\x8a\x94\xeb\x8d\xb0,\n# \xec\x9d\xb4\xea\xb2\x83\xec\x9d\x80 \xea\xb0\x80\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xeb\x84\xa3\xec\x97\x88\xec\x9d\x84 \xeb\x95\x8c, \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0\xea\xb0\x80 \xec\xb5\x9c\xeb\x8c\x80\xed\x95\x9c \xec\x8b\xa4\xec\xa0\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\x9d\xbc\xea\xb3\xa0 \xed\x8c\x90\xeb\x8b\xa8\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# \xeb\x85\xbc\xeb\xac\xb8\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 loss_D \xec\x99\x80 \xea\xb0\x99\xec\x9d\x80 \xec\x88\x98\xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xec\xb5\x9c\xec\x86\x8c\xed\x99\x94 \xed\x95\x98\xeb\x8a\x94 \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0\xeb\xa5\xbc \xec\xb0\xbe\xec\xa7\x80\xeb\xa7\x8c,\n# \xea\xb2\xb0\xea\xb5\xad D_gene \xea\xb0\x92\xec\x9d\x84 \xec\xb5\x9c\xeb\x8c\x80\xed\x99\x94\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4\xeb\xaf\x80\xeb\xa1\x9c \xeb\x8b\xa4\xec\x9d\x8c\xea\xb3\xbc \xea\xb0\x99\xec\x9d\xb4 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nloss_G = tf.reduce_mean(tf.log(D_gene))\n\n# loss_D \xeb\xa5\xbc \xea\xb5\xac\xed\x95\xa0 \xeb\x95\x8c\xeb\x8a\x94 \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xeb\x90\x98\xeb\x8a\x94 \xeb\xb3\x80\xec\x88\x98\xeb\xa7\x8c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb3\xa0,\n# loss_G \xeb\xa5\xbc \xea\xb5\xac\xed\x95\xa0 \xeb\x95\x8c\xeb\x8a\x94 \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xeb\x90\x98\xeb\x8a\x94 \xeb\xb3\x80\xec\x88\x98\xeb\xa7\x8c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xeb\xa5\xbc \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nD_var_list = [D_W1, D_b1, D_W2, D_b2]\nG_var_list = [G_W1, G_b1, G_W2, G_b2]\n\n# GAN \xeb\x85\xbc\xeb\xac\xb8\xec\x9d\x98 \xec\x88\x98\xec\x8b\x9d\xec\x97\x90 \xeb\x94\xb0\xeb\xa5\xb4\xeb\xa9\xb4 loss \xeb\xa5\xbc \xea\xb7\xb9\xeb\x8c\x80\xed\x99\x94 \xed\x95\xb4\xec\x95\xbc\xed\x95\x98\xec\xa7\x80\xeb\xa7\x8c, minimize \xed\x95\x98\xeb\x8a\x94 \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90\n# \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xed\x95\x98\xeb\xa0\xa4\xeb\x8a\x94 loss_D \xec\x99\x80 loss_G \xec\x97\x90 \xec\x9d\x8c\xec\x88\x98 \xeb\xb6\x80\xed\x98\xb8\xeb\xa5\xbc \xeb\xb6\x99\xec\x97\xac\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\ntrain_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n                                                         var_list=D_var_list)\ntrain_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n                                                         var_list=G_var_list)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\ntotal_batch = int(mnist.train.num_examples/batch_size)\nloss_val_D, loss_val_G = 0, 0\n\nfor epoch in range(total_epoch):\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        noise = get_noise(batch_size, n_noise)\n\n        # \xed\x8c\x90\xeb\xb3\x84\xea\xb8\xb0\xec\x99\x80 \xec\x83\x9d\xec\x84\xb1\xea\xb8\xb0 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xea\xb0\x81\xea\xb0\x81 \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        _, loss_val_D = sess.run([train_D, loss_D],\n                                 feed_dict={X: batch_xs, Z: noise})\n        _, loss_val_G = sess.run([train_G, loss_G],\n                                 feed_dict={Z: noise})\n\n    print(\'Epoch:\', \'%04d\' % epoch,\n          \'D loss: {:.4}\'.format(loss_val_D),\n          \'G loss: {:.4}\'.format(loss_val_G))\n\n    #########\n    # \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4 \xeb\x90\x98\xec\x96\xb4\xea\xb0\x80\xeb\x8a\x94 \xeb\xaa\xa8\xec\x8a\xb5\xec\x9d\x84 \xeb\xb3\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\xa3\xbc\xea\xb8\xb0\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xec\x97\xac \xec\xa0\x80\xec\x9e\xa5\n    ######\n    if epoch == 0 or (epoch + 1) % 10 == 0:\n        sample_size = 10\n        noise = get_noise(sample_size, n_noise)\n        samples = sess.run(G, feed_dict={Z: noise})\n\n        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n\n        for i in range(sample_size):\n            ax[i].set_axis_off()\n            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n\n        plt.savefig(\'samples/{}.png\'.format(str(epoch).zfill(3)), bbox_inches=\'tight\')\n        plt.close(fig)\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n'"
09 - GAN/02 - GAN2.py,29,"b'# GAN \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xeb\x8b\xa8\xec\x88\x9c\xed\x9e\x88 \xeb\x9e\x9c\xeb\x8d\xa4\xed\x95\x9c \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xec\x95\x84\xeb\x8b\x8c,\n# \xec\x9b\x90\xed\x95\x98\xeb\x8a\x94 \xec\x86\x90\xea\xb8\x80\xec\x94\xa8 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x9d\xb4\xeb\x9f\xb0 \xeb\xb0\xa9\xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xed\x9d\x91\xeb\xb0\xb1 \xec\x82\xac\xec\xa7\x84\xec\x9d\x84 \xec\xbb\xac\xeb\x9f\xac\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa0\xeb\x8b\xa4\xeb\x93\xa0\xea\xb0\x80, \xeb\x98\x90\xeb\x8a\x94 \xec\x84\xa0\xed\x99\x94\xeb\xa5\xbc \xec\xb1\x84\xec\x83\x89\xed\x95\x9c\xeb\x8b\xa4\xeb\x93\xa0\xea\xb0\x80 \xed\x95\x98\xeb\x8a\x94 \xec\x9d\x91\xec\x9a\xa9\xec\x9d\xb4 \xea\xb0\x80\xeb\x8a\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\ntotal_epoch = 100\nbatch_size = 100\nn_hidden = 256\nn_input = 28 * 28\nn_noise = 128\nn_class = 10\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32, [None, n_input])\n# \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88\xec\x99\x80 \xec\x8b\xa4\xec\xa0\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xec\x97\x90, \xea\xb7\xb8\xec\x97\x90 \xed\x95\xb4\xeb\x8b\xb9\xed\x95\x98\xeb\x8a\x94 \xec\x88\xab\xec\x9e\x90\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xeb\x84\xa3\xec\x96\xb4\xec\xa3\xbc\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nY = tf.placeholder(tf.float32, [None, n_class])\nZ = tf.placeholder(tf.float32, [None, n_noise])\n\n\ndef generator(noise, labels):\n    with tf.variable_scope(\'generator\'):\n        # noise \xea\xb0\x92\xec\x97\x90 labels \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xec\xb6\x94\xea\xb0\x80\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        inputs = tf.concat([noise, labels], 1)\n\n        # TensorFlow \xec\x97\x90\xec\x84\x9c \xec\xa0\x9c\xea\xb3\xb5\xed\x95\x98\xeb\x8a\x94 \xec\x9c\xa0\xed\x8b\xb8\xeb\xa6\xac\xed\x8b\xb0 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xeb\xa7\xa4\xec\x9a\xb0 \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c \xea\xb5\xac\xec\x84\xb1\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        hidden = tf.layers.dense(inputs, n_hidden,\n                                 activation=tf.nn.relu)\n        output = tf.layers.dense(hidden, n_input,\n                                 activation=tf.nn.sigmoid)\n\n    return output\n\n\ndef discriminator(inputs, labels, reuse=None):\n    with tf.variable_scope(\'discriminator\') as scope:\n        # \xeb\x85\xb8\xec\x9d\xb4\xec\xa6\x88\xec\x97\x90\xec\x84\x9c \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xec\x99\x80 \xec\x8b\xa4\xec\xa0\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\xb3\x84\xed\x95\x98\xeb\x8a\x94 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x98 \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xeb\x8f\x99\xec\x9d\xbc\xed\x95\x98\xea\xb2\x8c \xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4,\n        # \xec\x9d\xb4\xec\xa0\x84\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xeb\x90\x98\xec\x97\x88\xeb\x8d\x98 \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x9e\xac\xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        if reuse:\n            scope.reuse_variables()\n\n        inputs = tf.concat([inputs, labels], 1)\n\n        hidden = tf.layers.dense(inputs, n_hidden,\n                                 activation=tf.nn.relu)\n        output = tf.layers.dense(hidden, 1,\n                                 activation=None)\n\n    return output\n\n\ndef get_noise(batch_size, n_noise):\n    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n\n# \xec\x83\x9d\xec\x84\xb1 \xeb\xaa\xa8\xeb\x8d\xb8\xea\xb3\xbc \xed\x8c\x90\xeb\xb3\x84 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x97\x90 Y \xec\xa6\x89, labels \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xec\xb6\x94\xea\xb0\x80\xed\x95\x98\xec\x97\xac\n# labels \xec\xa0\x95\xeb\xb3\xb4\xec\x97\x90 \xed\x95\xb4\xeb\x8b\xb9\xed\x95\x98\xeb\x8a\x94 \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xeb\x8f\x84\xeb\xa1\x9d \xec\x9c\xa0\xeb\x8f\x84\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nG = generator(Z, Y)\nD_real = discriminator(X, Y)\nD_gene = discriminator(G, Y, True)\n\n# \xec\x86\x90\xec\x8b\xa4\xed\x95\xa8\xec\x88\x98\xeb\x8a\x94 \xeb\x8b\xa4\xec\x9d\x8c\xec\x9d\x84 \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x98\xec\x97\xac GAN \xeb\x85\xbc\xeb\xac\xb8\xec\x97\x90 \xeb\x82\x98\xec\x98\xa8 \xeb\xb0\xa9\xec\x8b\x9d\xea\xb3\xbc\xeb\x8a\x94 \xec\x95\xbd\xea\xb0\x84 \xeb\x8b\xa4\xeb\xa5\xb4\xea\xb2\x8c \xec\x9e\x91\xec\x84\xb1\xed\x95\x98\xec\x98\x80\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# http://bamos.github.io/2016/08/09/deep-completion/\n# \xec\xa7\x84\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\xb3\x84\xed\x95\x98\xeb\x8a\x94 D_real \xea\xb0\x92\xec\x9d\x80 1\xec\x97\x90 \xea\xb0\x80\xea\xb9\x9d\xeb\x8f\x84\xeb\xa1\x9d,\n# \xea\xb0\x80\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\xb3\x84\xed\x95\x98\xeb\x8a\x94 D_gene \xea\xb0\x92\xec\x9d\x80 0\xec\x97\x90 \xea\xb0\x80\xea\xb9\x9d\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xeb\x8a\x94 \xec\x86\x90\xec\x8b\xa4 \xed\x95\xa8\xec\x88\x98\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nloss_D_real = tf.reduce_mean(\n                    tf.nn.sigmoid_cross_entropy_with_logits(\n                        logits=D_real, labels=tf.ones_like(D_real)))\nloss_D_gene = tf.reduce_mean(\n                    tf.nn.sigmoid_cross_entropy_with_logits(\n                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n# loss_D_real \xea\xb3\xbc loss_D_gene \xec\x9d\x84 \xeb\x8d\x94\xed\x95\x9c \xeb\x92\xa4 \xec\x9d\xb4 \xea\xb0\x92\xec\x9d\x84 \xec\xb5\x9c\xec\x86\x8c\xed\x99\x94 \xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xec\xb5\x9c\xec\xa0\x81\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nloss_D = loss_D_real + loss_D_gene\n# \xea\xb0\x80\xec\xa7\x9c \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\xa7\x84\xec\xa7\x9c\xec\x97\x90 \xea\xb0\x80\xea\xb9\x9d\xea\xb2\x8c \xeb\xa7\x8c\xeb\x93\xa4\xeb\x8f\x84\xeb\xa1\x9d \xec\x83\x9d\xec\x84\xb1\xeb\xa7\x9d\xec\x9d\x84 \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xed\x82\xa4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4, D_gene \xec\x9d\x84 \xec\xb5\x9c\xeb\x8c\x80\xed\x95\x9c 1\xec\x97\x90 \xea\xb0\x80\xea\xb9\x9d\xeb\x8f\x84\xeb\xa1\x9d \xeb\xa7\x8c\xeb\x93\x9c\xeb\x8a\x94 \xec\x86\x90\xec\x8b\xa4\xed\x95\xa8\xec\x88\x98\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nloss_G = tf.reduce_mean(\n                    tf.nn.sigmoid_cross_entropy_with_logits(\n                        logits=D_gene, labels=tf.ones_like(D_gene)))\n\n# TensorFlow \xec\x97\x90\xec\x84\x9c \xec\xa0\x9c\xea\xb3\xb5\xed\x95\x98\xeb\x8a\x94 \xec\x9c\xa0\xed\x8b\xb8\xeb\xa6\xac\xed\x8b\xb0 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4\n# discriminator \xec\x99\x80 generator scope \xec\x97\x90\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xeb\x90\x9c \xeb\xb3\x80\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\x89\xbd\xea\xb2\x8c \xea\xb0\x80\xec\xa0\xb8\xec\x98\xac \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nvars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n                           scope=\'discriminator\')\nvars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n                           scope=\'generator\')\n\ntrain_D = tf.train.AdamOptimizer().minimize(loss_D,\n                                            var_list=vars_D)\ntrain_G = tf.train.AdamOptimizer().minimize(loss_G,\n                                            var_list=vars_G)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\ntotal_batch = int(mnist.train.num_examples/batch_size)\nloss_val_D, loss_val_G = 0, 0\n\nfor epoch in range(total_epoch):\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        noise = get_noise(batch_size, n_noise)\n\n        _, loss_val_D = sess.run([train_D, loss_D],\n                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n        _, loss_val_G = sess.run([train_G, loss_G],\n                                 feed_dict={Y: batch_ys, Z: noise})\n\n    print(\'Epoch:\', \'%04d\' % epoch,\n          \'D loss: {:.4}\'.format(loss_val_D),\n          \'G loss: {:.4}\'.format(loss_val_G))\n\n    #########\n    # \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4 \xeb\x90\x98\xec\x96\xb4\xea\xb0\x80\xeb\x8a\x94 \xeb\xaa\xa8\xec\x8a\xb5\xec\x9d\x84 \xeb\xb3\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\xa3\xbc\xea\xb8\xb0\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94\xec\x97\x90 \xeb\x94\xb0\xeb\xa5\xb8 \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xec\x97\xac \xec\xa0\x80\xec\x9e\xa5\n    ######\n    if epoch == 0 or (epoch + 1) % 10 == 0:\n        sample_size = 10\n        noise = get_noise(sample_size, n_noise)\n        samples = sess.run(G,\n                           feed_dict={Y: mnist.test.labels[:sample_size],\n                                      Z: noise})\n\n        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n\n        for i in range(sample_size):\n            ax[0][i].set_axis_off()\n            ax[1][i].set_axis_off()\n\n            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n\n        plt.savefig(\'samples2/{}.png\'.format(str(epoch).zfill(3)), bbox_inches=\'tight\')\n        plt.close(fig)\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n'"
10 - RNN/01 - MNIST.py,17,"b'# \xeb\xa8\xb8\xec\x8b\xa0\xeb\x9f\xac\xeb\x8b\x9d \xed\x95\x99\xec\x8a\xb5\xec\x9d\x98 Hello World \xec\x99\x80 \xea\xb0\x99\xec\x9d\x80 MNIST(\xec\x86\x90\xea\xb8\x80\xec\x94\xa8 \xec\x88\xab\xec\x9e\x90 \xec\x9d\xb8\xec\x8b\x9d) \xeb\xac\xb8\xec\xa0\x9c\xeb\xa5\xbc \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9c\xbc\xeb\xa1\x9c \xed\x92\x80\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\nlearning_rate = 0.001\ntotal_epoch = 30\nbatch_size = 128\n\n# RNN \xec\x9d\x80 \xec\x88\x9c\xec\x84\x9c\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xec\x9e\x90\xeb\xa3\x8c\xeb\xa5\xbc \xeb\x8b\xa4\xeb\xa3\xa8\xeb\xaf\x80\xeb\xa1\x9c,\n# \xed\x95\x9c \xeb\xb2\x88\xec\x97\x90 \xec\x9e\x85\xeb\xa0\xa5\xeb\xb0\x9b\xeb\x8a\x94 \xea\xb0\xaf\xec\x88\x98\xec\x99\x80, \xec\xb4\x9d \xeb\xaa\x87 \xeb\x8b\xa8\xea\xb3\x84\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa3\xa8\xec\x96\xb4\xec\xa0\xb8\xec\x9e\x88\xeb\x8a\x94 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xeb\xb0\x9b\xec\x9d\x84\xec\xa7\x80\xeb\xa5\xbc \xec\x84\xa4\xec\xa0\x95\xed\x95\xb4\xec\x95\xbc\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x9d\xb4\xeb\xa5\xbc \xec\x9c\x84\xed\x95\xb4 \xea\xb0\x80\xeb\xa1\x9c \xed\x94\xbd\xec\x85\x80\xec\x88\x98\xeb\xa5\xbc n_input \xec\x9c\xbc\xeb\xa1\x9c, \xec\x84\xb8\xeb\xa1\x9c \xed\x94\xbd\xec\x85\x80\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5 \xeb\x8b\xa8\xea\xb3\x84\xec\x9d\xb8 n_step \xec\x9c\xbc\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x98\xec\x98\x80\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nn_input = 28\nn_step = 28\nn_hidden = 128\nn_class = 10\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32, [None, n_step, n_input])\nY = tf.placeholder(tf.float32, [None, n_class])\n\nW = tf.Variable(tf.random_normal([n_hidden, n_class]))\nb = tf.Variable(tf.random_normal([n_class]))\n\n# RNN \xec\x97\x90 \xed\x95\x99\xec\x8a\xb5\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xec\x85\x80\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\n# \xeb\x8b\xa4\xec\x9d\x8c \xed\x95\xa8\xec\x88\x98\xeb\x93\xa4\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\xa9\xb4 \xeb\x8b\xa4\xeb\xa5\xb8 \xea\xb5\xac\xec\xa1\xb0\xec\x9d\x98 \xec\x85\x80\xeb\xa1\x9c \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c \xeb\xb3\x80\xea\xb2\xbd\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4\n# BasicRNNCell,BasicLSTMCell,GRUCell\ncell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n\n# RNN \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\n# \xec\x9b\x90\xeb\x9e\x98\xeb\x8a\x94 \xeb\x8b\xa4\xec\x9d\x8c\xea\xb3\xbc \xea\xb0\x99\xec\x9d\x80 \xea\xb3\xbc\xec\xa0\x95\xec\x9d\x84 \xea\xb1\xb0\xec\xb3\x90\xec\x95\xbc \xed\x95\x98\xec\xa7\x80\xeb\xa7\x8c\n# states = tf.zeros(batch_size)\n# for i in range(n_step):\n#     outputs, states = cell(X[[:, i]], states)\n# ...\n# \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc tf.nn.dynamic_rnn \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\xa9\xb4\n# CNN \xec\x9d\x98 tf.nn.conv2d \xed\x95\xa8\xec\x88\x98\xec\xb2\x98\xeb\x9f\xbc \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c RNN \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\n# \xea\xb2\x81\xeb\x82\x98 \xeb\xa7\xa4\xec\xa7\x81!!\noutputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n\n# \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc Y\xec\x9d\x98 \xeb\x8b\xa4\xec\x9d\x8c \xed\x98\x95\xec\x8b\x9d\xea\xb3\xbc \xeb\xb0\x94\xea\xbf\x94\xec\x95\xbc \xed\x95\x98\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90\n# Y : [batch_size, n_class]\n# outputs \xec\x9d\x98 \xed\x98\x95\xed\x83\x9c\xeb\xa5\xbc \xec\x9d\xb4\xec\x97\x90 \xeb\xa7\x9e\xec\xb6\xb0 \xeb\xb3\x80\xea\xb2\xbd\xed\x95\xb4\xec\x95\xbc\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# outputs : [batch_size, n_step, n_hidden]\n#        -> [n_step, batch_size, n_hidden]\n#        -> [batch_size, n_hidden]\noutputs = tf.transpose(outputs, [1, 0, 2])\noutputs = outputs[-1]\nmodel = tf.matmul(outputs, W) + b\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\ntotal_batch = int(mnist.train.num_examples/batch_size)\n\nfor epoch in range(total_epoch):\n    total_cost = 0\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        # X \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc RNN \xec\x9e\x85\xeb\xa0\xa5 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x97\x90 \xeb\xa7\x9e\xea\xb2\x8c [batch_size, n_step, n_input] \xed\x98\x95\xed\x83\x9c\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n\n        _, cost_val = sess.run([optimizer, cost],\n                               feed_dict={X: batch_xs, Y: batch_ys})\n        total_cost += cost_val\n\n    print(\'Epoch:\', \'%04d\' % (epoch + 1),\n          \'Avg. cost =\', \'{:.3f}\'.format(total_cost / total_batch))\n\nprint(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\nis_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n\ntest_batch_size = len(mnist.test.images)\ntest_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\ntest_ys = mnist.test.labels\n\nprint(\'\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:\', sess.run(accuracy,\n                       feed_dict={X: test_xs, Y: test_ys}))\n'"
10 - RNN/02 - Autocomplete.py,20,"b""# \xec\x9e\x90\xec\x97\xb0\xec\x96\xb4 \xec\xb2\x98\xeb\xa6\xac\xeb\x82\x98 \xec\x9d\x8c\xec\x84\xb1 \xec\xb2\x98\xeb\xa6\xac \xeb\xb6\x84\xec\x95\xbc\xec\x97\x90 \xeb\xa7\x8e\xec\x9d\xb4 \xec\x82\xac\xec\x9a\xa9\xeb\x90\x98\xeb\x8a\x94 RNN \xec\x9d\x98 \xea\xb8\xb0\xeb\xb3\xb8\xec\xa0\x81\xec\x9d\xb8 \xec\x82\xac\xec\x9a\xa9\xeb\xb2\x95\xec\x9d\x84 \xec\x9d\xb5\xed\x9e\x99\xeb\x8b\x88\xeb\x8b\xa4.\n# 4\xea\xb0\x9c\xec\x9d\x98 \xea\xb8\x80\xec\x9e\x90\xeb\xa5\xbc \xea\xb0\x80\xec\xa7\x84 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c\xec\xbc\x9c, 3\xea\xb8\x80\xec\x9e\x90\xeb\xa7\x8c \xec\xa3\xbc\xec\x96\xb4\xec\xa7\x80\xeb\xa9\xb4 \xeb\x82\x98\xeb\xa8\xb8\xec\xa7\x80 \xed\x95\x9c \xea\xb8\x80\xec\x9e\x90\xeb\xa5\xbc \xec\xb6\x94\xec\xb2\x9c\xed\x95\x98\xec\x97\xac \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\x99\x84\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\xa8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport numpy as np\n\n\nchar_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n            'o', 'p', 'q', 'r', 's', 't', 'u',\n            'v', 'w', 'x', 'y', 'z']\n\n# one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9 \xec\x82\xac\xec\x9a\xa9 \xeb\xb0\x8f \xeb\x94\x94\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x84 \xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\x97\xb0\xea\xb4\x80 \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\n# {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\nnum_dic = {n: i for i, n in enumerate(char_arr)}\ndic_len = len(num_dic)\n\n# \xeb\x8b\xa4\xec\x9d\x8c \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x80 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xea\xb2\x83 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# wor -> X, d -> Y\n# woo -> X, d -> Y\nseq_data = ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n\n\ndef make_batch(seq_data):\n    input_batch = []\n    target_batch = []\n\n    for seq in seq_data:\n        # \xec\x97\xac\xea\xb8\xb0\xec\x84\x9c \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 input_batch \xec\x99\x80 target_batch \xeb\x8a\x94\n        # \xec\x95\x8c\xed\x8c\x8c\xeb\xb2\xb3 \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x98 \xec\x9d\xb8\xeb\x8d\xb1\xec\x8a\xa4 \xeb\xb2\x88\xed\x98\xb8 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n        # [22, 14, 17] [22, 14, 14] [3, 4, 4] [3, 8, 21] ...\n        input = [num_dic[n] for n in seq[:-1]]\n        # 3, 3, 15, 4, 3 ...\n        target = num_dic[seq[-1]]\n        # one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x84 \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        # if input is [0, 1, 2]:\n        # [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n        #  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n        #  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n        input_batch.append(np.eye(dic_len)[input])\n        # \xec\xa7\x80\xea\xb8\x88\xea\xb9\x8c\xec\xa7\x80 \xec\x86\x90\xec\x8b\xa4\xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8d\x98 softmax_cross_entropy_with_logits \xed\x95\xa8\xec\x88\x98\xeb\x8a\x94\n        # label \xea\xb0\x92\xec\x9d\x84 one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9c\xbc\xeb\xa1\x9c \xeb\x84\x98\xea\xb2\xa8\xec\xa4\x98\xec\x95\xbc \xed\x95\x98\xec\xa7\x80\xeb\xa7\x8c,\n        # \xec\x9d\xb4 \xec\x98\x88\xec\xa0\x9c\xec\x97\x90\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xec\x86\x90\xec\x8b\xa4 \xed\x95\xa8\xec\x88\x98\xec\x9d\xb8 sparse_softmax_cross_entropy_with_logits \xeb\x8a\x94\n        # one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xec\x9c\xbc\xeb\xaf\x80\xeb\xa1\x9c index \xeb\xa5\xbc \xea\xb7\xb8\xeb\x83\xa5 \xeb\x84\x98\xea\xb2\xa8\xec\xa3\xbc\xeb\xa9\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        target_batch.append(target)\n\n    return input_batch, target_batch\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\nlearning_rate = 0.01\nn_hidden = 128\ntotal_epoch = 30\n# \xed\x83\x80\xec\x9e\x85 \xec\x8a\xa4\xed\x85\x9d: [1 2 3] => 3\n# RNN \xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4\xec\x9d\x98 \xea\xb0\xaf\xec\x88\x98\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\nn_step = 3\n# \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92 \xed\x81\xac\xea\xb8\xb0. \xec\x95\x8c\xed\x8c\x8c\xeb\xb2\xb3\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\xb4\xeb\xaf\x80\xeb\xa1\x9c 26\xea\xb0\x9c\xea\xb0\x80 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x88) c => [0 0 1 0 0 0 0 0 0 0 0 ... 0]\n# \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xeb\x8f\x84 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc \xeb\xa7\x88\xec\xb0\xac\xea\xb0\x80\xec\xa7\x80\xeb\xa1\x9c 26\xea\xb0\x9c\xec\x9d\x98 \xec\x95\x8c\xed\x8c\x8c\xeb\xb2\xb3\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb6\x84\xeb\xa5\x98\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nn_input = n_class = dic_len\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\nX = tf.placeholder(tf.float32, [None, n_step, n_input])\n# \xeb\xb9\x84\xec\x9a\xa9\xed\x95\xa8\xec\x88\x98\xec\x97\x90 sparse_softmax_cross_entropy_with_logits \xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\xaf\x80\xeb\xa1\x9c\n# \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc\xec\x9d\x98 \xea\xb3\x84\xec\x82\xb0\xec\x9d\x84 \xec\x9c\x84\xed\x95\x9c \xec\x9b\x90\xeb\xb3\xb8\xea\xb0\x92\xec\x9d\x98 \xed\x98\x95\xed\x83\x9c\xeb\x8a\x94 one-hot vector\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\x9d\xbc \xec\x9d\xb8\xeb\x8d\xb1\xec\x8a\xa4 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xea\xb7\xb8\xeb\x8c\x80\xeb\xa1\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90\n# \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xea\xb0\x92\xeb\xa7\x8c \xec\x9e\x88\xeb\x8a\x94 1\xec\xb0\xa8\xec\x9b\x90 \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x84 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb0\x9b\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n# [3] [3] [15] [4] ...\n# \xea\xb8\xb0\xec\xa1\xb4\xec\xb2\x98\xeb\x9f\xbc one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\xeb\xa9\xb4 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x98 \xed\x98\x95\xed\x83\x9c\xeb\x8a\x94 [None, n_class] \xec\x97\xac\xec\x95\xbc\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nY = tf.placeholder(tf.int32, [None])\n\nW = tf.Variable(tf.random_normal([n_hidden, n_class]))\nb = tf.Variable(tf.random_normal([n_class]))\n\n# RNN \xec\x85\x80\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ncell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n# \xea\xb3\xbc\xec\xa0\x81\xed\x95\xa9 \xeb\xb0\xa9\xec\xa7\x80\xeb\xa5\xbc \xec\x9c\x84\xed\x95\x9c Dropout \xea\xb8\xb0\xeb\xb2\x95\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ncell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n# \xec\x97\xac\xeb\x9f\xac\xea\xb0\x9c\xec\x9d\x98 \xec\x85\x80\xec\x9d\x84 \xec\xa1\xb0\xed\x95\xa9\xed\x95\xb4\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\x85\x80\xec\x9d\x84 \xec\xb6\x94\xea\xb0\x80\xeb\xa1\x9c \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\ncell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n\n# \xec\x97\xac\xeb\x9f\xac\xea\xb0\x9c\xec\x9d\x98 \xec\x85\x80\xec\x9d\x84 \xec\xa1\xb0\xed\x95\xa9\xed\x95\x9c RNN \xec\x85\x80\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nmulti_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n\n# tf.nn.dynamic_rnn \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x88\x9c\xed\x99\x98 \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\n# time_major=True\noutputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n\n# \xec\xb5\x9c\xec\xa2\x85 \xea\xb2\xb0\xea\xb3\xbc\xeb\x8a\x94 one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9 \xed\x98\x95\xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4\noutputs = tf.transpose(outputs, [1, 0, 2])\noutputs = outputs[-1]\nmodel = tf.matmul(outputs, W) + b\n\ncost = tf.reduce_mean(\n            tf.nn.sparse_softmax_cross_entropy_with_logits(\n                logits=model, labels=Y))\n\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\ninput_batch, target_batch = make_batch(seq_data)\n\nfor epoch in range(total_epoch):\n    _, loss = sess.run([optimizer, cost],\n                       feed_dict={X: input_batch, Y: target_batch})\n\n    print('Epoch:', '%04d' % (epoch + 1),\n          'cost =', '{:.6f}'.format(loss))\n\nprint('\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!')\n\n#########\n# \xea\xb2\xb0\xea\xb3\xbc \xed\x99\x95\xec\x9d\xb8\n######\n# \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94\xea\xb0\x92\xec\x9d\xb4 \xec\xa0\x95\xec\x88\x98\xec\x9d\xb4\xeb\xaf\x80\xeb\xa1\x9c \xec\x98\x88\xec\xb8\xa1\xea\xb0\x92\xeb\x8f\x84 \xec\xa0\x95\xec\x88\x98\xeb\xa1\x9c \xeb\xb3\x80\xea\xb2\xbd\xed\x95\xb4\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\nprediction = tf.cast(tf.argmax(model, 1), tf.int32)\n# one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x88\xeb\xaf\x80\xeb\xa1\x9c \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xea\xb7\xb8\xeb\x8c\x80\xeb\xa1\x9c \xeb\xb9\x84\xea\xb5\x90\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nprediction_check = tf.equal(prediction, Y)\naccuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n\ninput_batch, target_batch = make_batch(seq_data)\n\npredict, accuracy_val = sess.run([prediction, accuracy],\n                                 feed_dict={X: input_batch, Y: target_batch})\n\npredict_words = []\nfor idx, val in enumerate(seq_data):\n    last_char = char_arr[predict[idx]]\n    predict_words.append(val[:3] + last_char)\n\nprint('\\n=== \xec\x98\x88\xec\xb8\xa1 \xea\xb2\xb0\xea\xb3\xbc ===')\nprint('\xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92:', [w[:3] + ' ' for w in seq_data])\nprint('\xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:', predict_words)\nprint('\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:', accuracy_val)\n"""
10 - RNN/03 - Seq2Seq.py,20,"b""# \xec\xb1\x97\xeb\xb4\x87, \xeb\xb2\x88\xec\x97\xad, \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80 \xec\xba\xa1\xec\x85\x94\xeb\x8b\x9d\xeb\x93\xb1\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xeb\x90\x98\xeb\x8a\x94 \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4 \xed\x95\x99\xec\x8a\xb5/\xec\x83\x9d\xec\x84\xb1 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\xb8 Seq2Seq \xec\x9d\x84 \xea\xb5\xac\xed\x98\x84\xed\x95\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\n# \xec\x98\x81\xec\x96\xb4 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xed\x95\x9c\xea\xb5\xad\xec\x96\xb4 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa1\x9c \xeb\xb2\x88\xec\x97\xad\xed\x95\x98\xeb\x8a\x94 \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\xa8\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\xb4\x85\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport numpy as np\n\n# S: \xeb\x94\x94\xec\xbd\x94\xeb\x94\xa9 \xec\x9e\x85\xeb\xa0\xa5\xec\x9d\x98 \xec\x8b\x9c\xec\x9e\x91\xec\x9d\x84 \xeb\x82\x98\xed\x83\x80\xeb\x82\xb4\xeb\x8a\x94 \xec\x8b\xac\xeb\xb3\xbc\n# E: \xeb\x94\x94\xec\xbd\x94\xeb\x94\xa9 \xec\xb6\x9c\xeb\xa0\xa5\xec\x9d\x84 \xeb\x81\x9d\xec\x9d\x84 \xeb\x82\x98\xed\x83\x80\xeb\x82\xb4\xeb\x8a\x94 \xec\x8b\xac\xeb\xb3\xbc\n# P: \xed\x98\x84\xec\x9e\xac \xeb\xb0\xb0\xec\xb9\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x9d\x98 time step \xed\x81\xac\xea\xb8\xb0\xeb\xb3\xb4\xeb\x8b\xa4 \xec\x9e\x91\xec\x9d\x80 \xea\xb2\xbd\xec\x9a\xb0 \xeb\xb9\x88 \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4\xeb\xa5\xbc \xec\xb1\x84\xec\x9a\xb0\xeb\x8a\x94 \xec\x8b\xac\xeb\xb3\xbc\n#    \xec\x98\x88) \xed\x98\x84\xec\x9e\xac \xeb\xb0\xb0\xec\xb9\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x9d\x98 \xec\xb5\x9c\xeb\x8c\x80 \xed\x81\xac\xea\xb8\xb0\xea\xb0\x80 4 \xec\x9d\xb8 \xea\xb2\xbd\xec\x9a\xb0\n#       word -> ['w', 'o', 'r', 'd']\n#       to   -> ['t', 'o', 'P', 'P']\nchar_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz\xeb\x8b\xa8\xec\x96\xb4\xeb\x82\x98\xeb\xac\xb4\xeb\x86\x80\xec\x9d\xb4\xec\x86\x8c\xeb\x85\x80\xed\x82\xa4\xec\x8a\xa4\xec\x82\xac\xeb\x9e\x91']\nnum_dic = {n: i for i, n in enumerate(char_arr)}\ndic_len = len(num_dic)\n\n# \xec\x98\x81\xec\x96\xb4\xeb\xa5\xbc \xed\x95\x9c\xea\xb8\x80\xeb\xa1\x9c \xeb\xb2\x88\xec\x97\xad\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xed\x95\x99\xec\x8a\xb5 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\nseq_data = [['word', '\xeb\x8b\xa8\xec\x96\xb4'], ['wood', '\xeb\x82\x98\xeb\xac\xb4'],\n            ['game', '\xeb\x86\x80\xec\x9d\xb4'], ['girl', '\xec\x86\x8c\xeb\x85\x80'],\n            ['kiss', '\xed\x82\xa4\xec\x8a\xa4'], ['love', '\xec\x82\xac\xeb\x9e\x91']]\n\n\ndef make_batch(seq_data):\n    input_batch = []\n    output_batch = []\n    target_batch = []\n\n    for seq in seq_data:\n        # \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x98 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92. \xec\x9e\x85\xeb\xa0\xa5\xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xea\xb8\x80\xec\x9e\x90\xeb\x93\xa4\xec\x9d\x84 \xed\x95\x9c\xea\xb8\x80\xec\x9e\x90\xec\x94\xa9 \xeb\x96\xbc\xec\x96\xb4 \xeb\xb0\xb0\xec\x97\xb4\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa0\xeb\x8b\xa4.\n        input = [num_dic[n] for n in seq[0]]\n        # \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x98 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92. \xec\x8b\x9c\xec\x9e\x91\xec\x9d\x84 \xeb\x82\x98\xed\x83\x80\xeb\x82\xb4\xeb\x8a\x94 S \xec\x8b\xac\xeb\xb3\xbc\xec\x9d\x84 \xeb\xa7\xa8 \xec\x95\x9e\xec\x97\x90 \xeb\xb6\x99\xec\x97\xac\xec\xa4\x80\xeb\x8b\xa4.\n        output = [num_dic[n] for n in ('S' + seq[1])]\n        # \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xeb\xb9\x84\xea\xb5\x90\xed\x95\xa0 \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x98 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92. \xeb\x81\x9d\xeb\x82\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\x84 \xec\x95\x8c\xeb\xa0\xa4\xec\xa3\xbc\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xeb\xa7\x88\xec\xa7\x80\xeb\xa7\x89\xec\x97\x90 E \xeb\xa5\xbc \xeb\xb6\x99\xec\x9d\xb8\xeb\x8b\xa4.\n        target = [num_dic[n] for n in (seq[1] + 'E')]\n\n        input_batch.append(np.eye(dic_len)[input])\n        output_batch.append(np.eye(dic_len)[output])\n        # \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xeb\xa7\x8c one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x98 (sparse_softmax_cross_entropy_with_logits \xec\x82\xac\xec\x9a\xa9)\n        target_batch.append(target)\n\n    return input_batch, output_batch, target_batch\n\n\n#########\n# \xec\x98\xb5\xec\x85\x98 \xec\x84\xa4\xec\xa0\x95\n######\nlearning_rate = 0.01\nn_hidden = 128\ntotal_epoch = 100\n# \xec\x9e\x85\xeb\xa0\xa5\xea\xb3\xbc \xec\xb6\x9c\xeb\xa0\xa5\xec\x9d\x98 \xed\x98\x95\xed\x83\x9c\xea\xb0\x80 one-hot \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9c\xbc\xeb\xa1\x9c \xea\xb0\x99\xec\x9c\xbc\xeb\xaf\x80\xeb\xa1\x9c \xed\x81\xac\xea\xb8\xb0\xeb\x8f\x84 \xea\xb0\x99\xeb\x8b\xa4.\nn_class = n_input = dic_len\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xea\xb5\xac\xec\x84\xb1\n######\n# Seq2Seq \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x80 \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94\xec\x9d\x98 \xec\x9e\x85\xeb\xa0\xa5\xea\xb3\xbc \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94\xec\x9d\x98 \xec\x9e\x85\xeb\xa0\xa5\xec\x9d\x98 \xed\x98\x95\xec\x8b\x9d\xec\x9d\xb4 \xea\xb0\x99\xeb\x8b\xa4.\n# [batch size, time steps, input size]\nenc_input = tf.placeholder(tf.float32, [None, None, n_input])\ndec_input = tf.placeholder(tf.float32, [None, None, n_input])\n# [batch size, time steps]\ntargets = tf.placeholder(tf.int64, [None, None])\n\n\n# \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4.\nwith tf.variable_scope('encode'):\n    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n\n    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input,\n                                            dtype=tf.float32)\n\n# \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x84 \xea\xb5\xac\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4.\nwith tf.variable_scope('decode'):\n    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n\n    # Seq2Seq \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x80 \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x98 \xec\xb5\x9c\xec\xa2\x85 \xec\x83\x81\xed\x83\x9c\xea\xb0\x92\xec\x9d\x84\n    # \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80\xec\x9d\x98 \xec\xb4\x88\xea\xb8\xb0 \xec\x83\x81\xed\x83\x9c\xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xeb\x84\xa3\xec\x96\xb4\xec\xa3\xbc\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4 \xed\x95\xb5\xec\x8b\xac.\n    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input,\n                                            initial_state=enc_states,\n                                            dtype=tf.float32)\n\n\nmodel = tf.layers.dense(outputs, n_class, activation=None)\n\n\ncost = tf.reduce_mean(\n            tf.nn.sparse_softmax_cross_entropy_with_logits(\n                logits=model, labels=targets))\n\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\n\n#########\n# \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d \xeb\xaa\xa8\xeb\x8d\xb8 \xed\x95\x99\xec\x8a\xb5\n######\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\ninput_batch, output_batch, target_batch = make_batch(seq_data)\n\nfor epoch in range(total_epoch):\n    _, loss = sess.run([optimizer, cost],\n                       feed_dict={enc_input: input_batch,\n                                  dec_input: output_batch,\n                                  targets: target_batch})\n\n    print('Epoch:', '%04d' % (epoch + 1),\n          'cost =', '{:.6f}'.format(loss))\n\nprint('\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!')\n\n\n#########\n# \xeb\xb2\x88\xec\x97\xad \xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8\n######\n# \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xeb\xb0\x9b\xec\x95\x84 \xeb\xb2\x88\xec\x97\xad \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\x98\x88\xec\xb8\xa1\xed\x95\x98\xea\xb3\xa0 \xeb\x94\x94\xec\xbd\x94\xeb\x94\xa9\xed\x95\x98\xeb\x8a\x94 \xed\x95\xa8\xec\x88\x98\ndef translate(word):\n    # \xec\x9d\xb4 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x80 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xea\xb3\xbc \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa1\x9c [\xec\x98\x81\xec\x96\xb4\xeb\x8b\xa8\xec\x96\xb4, \xed\x95\x9c\xea\xb8\x80\xeb\x8b\xa8\xec\x96\xb4] \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\xa7\x80\xeb\xa7\x8c,\n    # \xec\x98\x88\xec\xb8\xa1\xec\x8b\x9c\xec\x97\x90\xeb\x8a\x94 \xed\x95\x9c\xea\xb8\x80\xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\x95\x8c\xec\xa7\x80 \xeb\xaa\xbb\xed\x95\x98\xeb\xaf\x80\xeb\xa1\x9c, \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94\xec\x9d\x98 \xec\x9e\x85\xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xec\x9d\x98\xeb\xaf\xb8 \xec\x97\x86\xeb\x8a\x94 \xea\xb0\x92\xec\x9d\xb8 P \xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xec\xb1\x84\xec\x9a\xb4\xeb\x8b\xa4.\n    # ['word', 'PPPP']\n    seq_data = [word, 'P' * len(word)]\n\n    input_batch, output_batch, target_batch = make_batch([seq_data])\n\n    # \xea\xb2\xb0\xea\xb3\xbc\xea\xb0\x80 [batch size, time step, input] \xec\x9c\xbc\xeb\xa1\x9c \xeb\x82\x98\xec\x98\xa4\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90,\n    # 2\xeb\xb2\x88\xec\xa7\xb8 \xec\xb0\xa8\xec\x9b\x90\xec\x9d\xb8 input \xec\xb0\xa8\xec\x9b\x90\xec\x9d\x84 argmax \xeb\xa1\x9c \xec\xb7\xa8\xed\x95\xb4 \xea\xb0\x80\xec\x9e\xa5 \xed\x99\x95\xeb\xa5\xa0\xec\x9d\xb4 \xeb\x86\x92\xec\x9d\x80 \xea\xb8\x80\xec\x9e\x90\xeb\xa5\xbc \xec\x98\x88\xec\xb8\xa1 \xea\xb0\x92\xec\x9c\xbc\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa0\xeb\x8b\xa4.\n    prediction = tf.argmax(model, 2)\n\n    result = sess.run(prediction,\n                      feed_dict={enc_input: input_batch,\n                                 dec_input: output_batch,\n                                 targets: target_batch})\n\n    # \xea\xb2\xb0\xea\xb3\xbc \xea\xb0\x92\xec\x9d\xb8 \xec\x88\xab\xec\x9e\x90\xec\x9d\x98 \xec\x9d\xb8\xeb\x8d\xb1\xec\x8a\xa4\xec\x97\x90 \xed\x95\xb4\xeb\x8b\xb9\xed\x95\x98\xeb\x8a\x94 \xea\xb8\x80\xec\x9e\x90\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x99\x80 \xea\xb8\x80\xec\x9e\x90 \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa0\xeb\x8b\xa4.\n    decoded = [char_arr[i] for i in result[0]]\n\n    # \xec\xb6\x9c\xeb\xa0\xa5\xec\x9d\x98 \xeb\x81\x9d\xec\x9d\x84 \xec\x9d\x98\xeb\xaf\xb8\xed\x95\x98\xeb\x8a\x94 'E' \xec\x9d\xb4\xed\x9b\x84\xec\x9d\x98 \xea\xb8\x80\xec\x9e\x90\xeb\x93\xa4\xec\x9d\x84 \xec\xa0\x9c\xea\xb1\xb0\xed\x95\x98\xea\xb3\xa0 \xeb\xac\xb8\xec\x9e\x90\xec\x97\xb4\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa0\xeb\x8b\xa4.\n    end = decoded.index('E')\n    translated = ''.join(decoded[:end])\n\n    return translated\n\n\nprint('\\n=== \xeb\xb2\x88\xec\x97\xad \xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8 ===')\n\nprint('word ->', translate('word'))\nprint('wodr ->', translate('wodr'))\nprint('love ->', translate('love'))\nprint('loev ->', translate('loev'))\nprint('abcd ->', translate('abcd'))\n"""
11 - Inception/predict.py,11,"b'import tensorflow as tf\n# import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport sys\n\n\ntf.app.flags.DEFINE_string(""output_graph"",\n                           ""./workspace/flowers_graph.pb"",\n                           ""\xed\x95\x99\xec\x8a\xb5\xeb\x90\x9c \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\xb4 \xec\xa0\x80\xec\x9e\xa5\xeb\x90\x9c \xec\x9c\x84\xec\xb9\x98"")\ntf.app.flags.DEFINE_string(""output_labels"",\n                           ""./workspace/flowers_labels.txt"",\n                           ""\xed\x95\x99\xec\x8a\xb5\xed\x95\xa0 \xeb\xa0\x88\xec\x9d\xb4\xeb\xb8\x94 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0 \xed\x8c\x8c\xec\x9d\xbc"")\ntf.app.flags.DEFINE_boolean(""show_image"",\n                            True,\n                            ""\xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80 \xec\xb6\x94\xeb\xa1\xa0 \xed\x9b\x84 \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xeb\xb3\xb4\xec\x97\xac\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4."")\n\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n    labels = [line.rstrip() for line in tf.gfile.GFile(FLAGS.output_labels)]\n\n    with tf.gfile.FastGFile(FLAGS.output_graph, \'rb\') as fp:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(fp.read())\n        tf.import_graph_def(graph_def, name=\'\')\n\n    with tf.Session() as sess:\n        logits = sess.graph.get_tensor_by_name(\'final_result:0\')\n        image = tf.gfile.FastGFile(sys.argv[1], \'rb\').read()\n        prediction = sess.run(logits, {\'DecodeJpeg/contents:0\': image})\n\n    # print(\'=== \xec\x98\x88\xec\xb8\xa1 \xea\xb2\xb0\xea\xb3\xbc ===\')\n    # top_result = int(np.argmax(prediction[0]))\n    # name = labels[top_result]\n    # score = prediction[0][top_result]\n    # print(\'%s (%.2f%%)\' % (name, score * 100))\n\n    print(\'=== \xec\x98\x88\xec\xb8\xa1 \xea\xb2\xb0\xea\xb3\xbc ===\')\n    for i in range(len(labels)):\n        name = labels[i]\n        score = prediction[0][i]\n        print(\'%s (%.2f%%)\' % (name, score * 100))\n\n    if FLAGS.show_image:\n        img = mpimg.imread(sys.argv[1])\n        plt.imshow(img)\n        plt.show()\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
11 - Inception/retrain.py,72,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Simple transfer learning with an Inception v3 architecture model which\ndisplays summaries in TensorBoard.\n\nThis example shows how to take a Inception v3 architecture model trained on\nImageNet images, and train a new top layer that can recognize other classes of\nimages.\n\nThe top layer receives as input a 2048-dimensional vector for each image. We\ntrain a softmax layer on top of this representation. Assuming the softmax layer\ncontains N labels, this corresponds to learning N + 2048*N model parameters\ncorresponding to the learned biases and weights.\n\nHere\'s an example, which assumes you have a folder containing class-named\nsubfolders, each full of images for each label. The example folder flower_photos\nshould have a structure like this:\n\n~/flower_photos/daisy/photo1.jpg\n~/flower_photos/daisy/photo2.jpg\n...\n~/flower_photos/rose/anotherphoto77.jpg\n...\n~/flower_photos/sunflower/somepicture.jpg\n\nThe subfolder names are important, since they define what label is applied to\neach image, but the filenames themselves don\'t matter. Once your images are\nprepared, you can run the training with a command like this:\n\nbazel build third_party/tensorflow/examples/image_retraining:retrain && \\\nbazel-bin/third_party/tensorflow/examples/image_retraining/retrain \\\n--image_dir ~/flower_photos\n\nYou can replace the image_dir argument with any folder containing subfolders of\nimages. The label for each image is taken from the name of the subfolder it\'s\nin.\n\nThis produces a new model file that can be loaded and run by any TensorFlow\nprogram, for example the label_image sample code.\n\n\nTo use with TensorBoard:\n\nBy default, this script will log summaries to /tmp/retrain_logs directory\n\nVisualize the summaries with this command:\n\ntensorboard --logdir /tmp/retrain_logs\n\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport hashlib\nimport os.path\nimport random\nimport re\nimport struct\nimport sys\nimport tarfile\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\n\nfrom tensorflow.python.framework import graph_util\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.util import compat\n\nFLAGS = None\n\n# These are all parameters that are tied to the particular model architecture\n# we\'re using for Inception v3. These include things like tensor names and their\n# sizes. If you want to adapt this script to work with another model, you will\n# need to update these to reflect the values in the network you\'re using.\n# pylint: disable=line-too-long\nDATA_URL = \'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\'\n# pylint: enable=line-too-long\nBOTTLENECK_TENSOR_NAME = \'pool_3/_reshape:0\'\nBOTTLENECK_TENSOR_SIZE = 2048\nMODEL_INPUT_WIDTH = 299\nMODEL_INPUT_HEIGHT = 299\nMODEL_INPUT_DEPTH = 3\nJPEG_DATA_TENSOR_NAME = \'DecodeJpeg/contents:0\'\nRESIZED_INPUT_TENSOR_NAME = \'ResizeBilinear:0\'\nMAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n\n\ndef create_image_lists(image_dir, testing_percentage, validation_percentage):\n    """"""Builds a list of training images from the file system.\n\n    Analyzes the sub folders in the image directory, splits them into stable\n    training, testing, and validation sets, and returns a data structure\n    describing the lists of images for each label and their paths.\n\n    Args:\n      image_dir: String path to a folder containing subfolders of images.\n      testing_percentage: Integer percentage of the images to reserve for tests.\n      validation_percentage: Integer percentage of images reserved for validation.\n\n    Returns:\n      A dictionary containing an entry for each label subfolder, with images split\n      into training, testing, and validation sets within each label.\n    """"""\n    if not gfile.Exists(image_dir):\n        print(""Image directory \'"" + image_dir + ""\' not found."")\n        return None\n    result = {}\n    sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n    # The root directory comes first, so skip it.\n    is_root_dir = True\n    for sub_dir in sub_dirs:\n        if is_root_dir:\n            is_root_dir = False\n            continue\n        extensions = [\'jpg\', \'jpeg\', \'JPG\', \'JPEG\']\n        file_list = []\n        dir_name = os.path.basename(sub_dir)\n        if dir_name == image_dir:\n            continue\n        print(""Looking for images in \'"" + dir_name + ""\'"")\n        for extension in extensions:\n            file_glob = os.path.join(image_dir, dir_name, \'*.\' + extension)\n            file_list.extend(gfile.Glob(file_glob))\n        if not file_list:\n            print(\'No files found\')\n            continue\n        if len(file_list) < 20:\n            print(\'WARNING: Folder has less than 20 images, which may cause issues.\')\n        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n            print(\'WARNING: Folder {} has more than {} images. Some images will \'\n                  \'never be selected.\'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n        label_name = re.sub(r\'[^a-z0-9]+\', \' \', dir_name.lower())\n        training_images = []\n        testing_images = []\n        validation_images = []\n        for file_name in file_list:\n            base_name = os.path.basename(file_name)\n            # We want to ignore anything after \'_nohash_\' in the file name when\n            # deciding which set to put an image in, the data set creator has a way of\n            # grouping photos that are close variations of each other. For example\n            # this is used in the plant disease data set to group multiple pictures of\n            # the same leaf.\n            hash_name = re.sub(r\'_nohash_.*$\', \'\', file_name)\n            # This looks a bit magical, but we need to decide whether this file should\n            # go into the training, testing, or validation sets, and we want to keep\n            # existing files in the same set even if more files are subsequently\n            # added.\n            # To do that, we need a stable way of deciding based on just the file name\n            # itself, so we do a hash of that and then use that to generate a\n            # probability value that we use to assign it.\n            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n            percentage_hash = ((int(hash_name_hashed, 16) %\n                                (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n                               (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n            if percentage_hash < validation_percentage:\n                validation_images.append(base_name)\n            elif percentage_hash < (testing_percentage + validation_percentage):\n                testing_images.append(base_name)\n            else:\n                training_images.append(base_name)\n        result[label_name] = {\n            \'dir\': dir_name,\n            \'training\': training_images,\n            \'testing\': testing_images,\n            \'validation\': validation_images,\n        }\n    return result\n\n\ndef get_image_path(image_lists, label_name, index, image_dir, category):\n    """"""""Returns a path to an image for a label at the given index.\n\n    Args:\n      image_lists: Dictionary of training images for each label.\n      label_name: Label string we want to get an image for.\n      index: Int offset of the image we want. This will be moduloed by the\n      available number of images for the label, so it can be arbitrarily large.\n      image_dir: Root folder string of the subfolders containing the training\n      images.\n      category: Name string of set to pull images from - training, testing, or\n      validation.\n\n    Returns:\n      File system path string to an image that meets the requested parameters.\n\n    """"""\n    if label_name not in image_lists:\n        tf.logging.fatal(\'Label does not exist %s.\', label_name)\n    label_lists = image_lists[label_name]\n    if category not in label_lists:\n        tf.logging.fatal(\'Category does not exist %s.\', category)\n    category_list = label_lists[category]\n    if not category_list:\n        tf.logging.fatal(\'Label %s has no images in the category %s.\',\n                         label_name, category)\n    mod_index = index % len(category_list)\n    base_name = category_list[mod_index]\n    sub_dir = label_lists[\'dir\']\n    full_path = os.path.join(image_dir, sub_dir, base_name)\n    return full_path\n\n\ndef get_bottleneck_path(image_lists, label_name, index, bottleneck_dir,\n                        category):\n    """"""""Returns a path to a bottleneck file for a label at the given index.\n\n    Args:\n      image_lists: Dictionary of training images for each label.\n      label_name: Label string we want to get an image for.\n      index: Integer offset of the image we want. This will be moduloed by the\n      available number of images for the label, so it can be arbitrarily large.\n      bottleneck_dir: Folder string holding cached files of bottleneck values.\n      category: Name string of set to pull images from - training, testing, or\n      validation.\n\n    Returns:\n      File system path string to an image that meets the requested parameters.\n    """"""\n    return get_image_path(image_lists, label_name, index, bottleneck_dir,\n                          category) + \'.txt\'\n\n\ndef create_inception_graph():\n    """"""""Creates a graph from saved GraphDef file and returns a Graph object.\n\n    Returns:\n      Graph holding the trained Inception network, and various tensors we\'ll be\n      manipulating.\n    """"""\n    with tf.Session() as sess:\n        model_filename = os.path.join(\n            FLAGS.model_dir, \'classify_image_graph_def.pb\')\n        with gfile.FastGFile(model_filename, \'rb\') as f:\n            graph_def = tf.GraphDef()\n            graph_def.ParseFromString(f.read())\n            bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n                tf.import_graph_def(graph_def, name=\'\', return_elements=[\n                    BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n                    RESIZED_INPUT_TENSOR_NAME]))\n    return sess.graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor\n\n\ndef run_bottleneck_on_image(sess, image_data, image_data_tensor,\n                            bottleneck_tensor):\n    """"""Runs inference on an image to extract the \'bottleneck\' summary layer.\n\n    Args:\n      sess: Current active TensorFlow Session.\n      image_data: String of raw JPEG data.\n      image_data_tensor: Input data layer in the graph.\n      bottleneck_tensor: Layer before the final softmax.\n\n    Returns:\n      Numpy array of bottleneck values.\n    """"""\n    bottleneck_values = sess.run(\n        bottleneck_tensor,\n        {image_data_tensor: image_data})\n    bottleneck_values = np.squeeze(bottleneck_values)\n    return bottleneck_values\n\n\ndef maybe_download_and_extract():\n    """"""Download and extract model tar file.\n\n    If the pretrained model we\'re using doesn\'t already exist, this function\n    downloads it from the TensorFlow.org website and unpacks it into a directory.\n    """"""\n    dest_directory = FLAGS.model_dir\n    if not os.path.exists(dest_directory):\n        os.makedirs(dest_directory)\n    filename = DATA_URL.split(\'/\')[-1]\n    filepath = os.path.join(dest_directory, filename)\n    if not os.path.exists(filepath):\n\n        def _progress(count, block_size, total_size):\n            sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' %\n                             (filename,\n                              float(count * block_size) / float(total_size) * 100.0))\n            sys.stdout.flush()\n\n        filepath, _ = urllib.request.urlretrieve(DATA_URL,\n                                                 filepath,\n                                                 _progress)\n        print()\n        statinfo = os.stat(filepath)\n        print(\'Successfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    tarfile.open(filepath, \'r:gz\').extractall(dest_directory)\n\n\ndef ensure_dir_exists(dir_name):\n    """"""Makes sure the folder exists on disk.\n\n    Args:\n      dir_name: Path string to the folder we want to create.\n    """"""\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n\ndef write_list_of_floats_to_file(list_of_floats , file_path):\n    """"""Writes a given list of floats to a binary file.\n\n    Args:\n      list_of_floats: List of floats we want to write to a file.\n      file_path: Path to a file where list of floats will be stored.\n\n    """"""\n\n    s = struct.pack(\'d\' * BOTTLENECK_TENSOR_SIZE, *list_of_floats)\n    with open(file_path, \'wb\') as f:\n        f.write(s)\n\n\ndef read_list_of_floats_from_file(file_path):\n    """"""Reads list of floats from a given file.\n\n    Args:\n      file_path: Path to a file where list of floats was stored.\n    Returns:\n      Array of bottleneck values (list of floats).\n\n    """"""\n\n    with open(file_path, \'rb\') as f:\n        s = struct.unpack(\'d\' * BOTTLENECK_TENSOR_SIZE, f.read())\n        return list(s)\n\n\nbottleneck_path_2_bottleneck_values = {}\n\n\ndef get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\n                             category, bottleneck_dir, jpeg_data_tensor,\n                             bottleneck_tensor):\n    """"""Retrieves or calculates bottleneck values for an image.\n\n    If a cached version of the bottleneck data exists on-disk, return that,\n    otherwise calculate the data and save it to disk for future use.\n\n    Args:\n      sess: The current active TensorFlow Session.\n      image_lists: Dictionary of training images for each label.\n      label_name: Label string we want to get an image for.\n      index: Integer offset of the image we want. This will be modulo-ed by the\n      available number of images for the label, so it can be arbitrarily large.\n      image_dir: Root folder string  of the subfolders containing the training\n      images.\n      category: Name string of which  set to pull images from - training, testing,\n      or validation.\n      bottleneck_dir: Folder string holding cached files of bottleneck values.\n      jpeg_data_tensor: The tensor to feed loaded jpeg data into.\n      bottleneck_tensor: The output tensor for the bottleneck values.\n\n    Returns:\n      Numpy array of values produced by the bottleneck layer for the image.\n    """"""\n    label_lists = image_lists[label_name]\n    sub_dir = label_lists[\'dir\']\n    sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n    ensure_dir_exists(sub_dir_path)\n    bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n                                          bottleneck_dir, category)\n    if not os.path.exists(bottleneck_path):\n        print(\'Creating bottleneck at \' + bottleneck_path)\n        image_path = get_image_path(image_lists, label_name, index, image_dir,\n                                    category)\n        if not gfile.Exists(image_path):\n            tf.logging.fatal(\'File does not exist %s\', image_path)\n        image_data = gfile.FastGFile(image_path, \'rb\').read()\n        bottleneck_values = run_bottleneck_on_image(sess, image_data,\n                                                    jpeg_data_tensor,\n                                                    bottleneck_tensor)\n        bottleneck_string = \',\'.join(str(x) for x in bottleneck_values)\n        with open(bottleneck_path, \'w\') as bottleneck_file:\n            bottleneck_file.write(bottleneck_string)\n\n    with open(bottleneck_path, \'r\') as bottleneck_file:\n        bottleneck_string = bottleneck_file.read()\n    bottleneck_values = [float(x) for x in bottleneck_string.split(\',\')]\n    return bottleneck_values\n\n\ndef cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n                      jpeg_data_tensor, bottleneck_tensor):\n    """"""Ensures all the training, testing, and validation bottlenecks are cached.\n\n    Because we\'re likely to read the same image multiple times (if there are no\n    distortions applied during training) it can speed things up a lot if we\n    calculate the bottleneck layer values once for each image during\n    preprocessing, and then just read those cached values repeatedly during\n    training. Here we go through all the images we\'ve found, calculate those\n    values, and save them off.\n\n    Args:\n      sess: The current active TensorFlow Session.\n      image_lists: Dictionary of training images for each label.\n      image_dir: Root folder string of the subfolders containing the training\n      images.\n      bottleneck_dir: Folder string holding cached files of bottleneck values.\n      jpeg_data_tensor: Input tensor for jpeg data from file.\n      bottleneck_tensor: The penultimate output layer of the graph.\n\n    Returns:\n      Nothing.\n    """"""\n    how_many_bottlenecks = 0\n    ensure_dir_exists(bottleneck_dir)\n    for label_name, label_lists in image_lists.items():\n        for category in [\'training\', \'testing\', \'validation\']:\n            category_list = label_lists[category]\n            for index, unused_base_name in enumerate(category_list):\n                get_or_create_bottleneck(sess, image_lists, label_name, index,\n                                         image_dir, category, bottleneck_dir,\n                                         jpeg_data_tensor, bottleneck_tensor)\n                how_many_bottlenecks += 1\n                if how_many_bottlenecks % 100 == 0:\n                    print(str(how_many_bottlenecks) + \' bottleneck files created.\')\n\n\ndef get_random_cached_bottlenecks(sess, image_lists, how_many, category,\n                                  bottleneck_dir, image_dir, jpeg_data_tensor,\n                                  bottleneck_tensor):\n    """"""Retrieves bottleneck values for cached images.\n\n    If no distortions are being applied, this function can retrieve the cached\n    bottleneck values directly from disk for images. It picks a random set of\n    images from the specified category.\n\n    Args:\n      sess: Current TensorFlow Session.\n      image_lists: Dictionary of training images for each label.\n      how_many: If positive, a random sample of this size will be chosen.\n      If negative, all bottlenecks will be retrieved.\n      category: Name string of which set to pull from - training, testing, or\n      validation.\n      bottleneck_dir: Folder string holding cached files of bottleneck values.\n      image_dir: Root folder string of the subfolders containing the training\n      images.\n      jpeg_data_tensor: The layer to feed jpeg image data into.\n      bottleneck_tensor: The bottleneck output layer of the CNN graph.\n\n    Returns:\n      List of bottleneck arrays, their corresponding ground truths, and the\n      relevant filenames.\n    """"""\n    class_count = len(image_lists.keys())\n    bottlenecks = []\n    ground_truths = []\n    filenames = []\n    if how_many >= 0:\n        # Retrieve a random sample of bottlenecks.\n        for unused_i in range(how_many):\n            label_index = random.randrange(class_count)\n            label_name = list(image_lists.keys())[label_index]\n            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n            image_name = get_image_path(image_lists, label_name, image_index,\n                                        image_dir, category)\n            bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n                                                  image_index, image_dir, category,\n                                                  bottleneck_dir, jpeg_data_tensor,\n                                                  bottleneck_tensor)\n            ground_truth = np.zeros(class_count, dtype=np.float32)\n            ground_truth[label_index] = 1.0\n            bottlenecks.append(bottleneck)\n            ground_truths.append(ground_truth)\n            filenames.append(image_name)\n    else:\n        # Retrieve all bottlenecks.\n        for label_index, label_name in enumerate(image_lists.keys()):\n            for image_index, image_name in enumerate(\n                    image_lists[label_name][category]):\n                image_name = get_image_path(image_lists, label_name, image_index,\n                                            image_dir, category)\n                bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n                                                      image_index, image_dir, category,\n                                                      bottleneck_dir, jpeg_data_tensor,\n                                                      bottleneck_tensor)\n                ground_truth = np.zeros(class_count, dtype=np.float32)\n                ground_truth[label_index] = 1.0\n                bottlenecks.append(bottleneck)\n                ground_truths.append(ground_truth)\n                filenames.append(image_name)\n    return bottlenecks, ground_truths, filenames\n\n\ndef get_random_distorted_bottlenecks(\n        sess, image_lists, how_many, category, image_dir, input_jpeg_tensor,\n        distorted_image, resized_input_tensor, bottleneck_tensor):\n    """"""Retrieves bottleneck values for training images, after distortions.\n\n    If we\'re training with distortions like crops, scales, or flips, we have to\n    recalculate the full model for every image, and so we can\'t use cached\n    bottleneck values. Instead we find random images for the requested category,\n    run them through the distortion graph, and then the full graph to get the\n    bottleneck results for each.\n\n    Args:\n      sess: Current TensorFlow Session.\n      image_lists: Dictionary of training images for each label.\n      how_many: The integer number of bottleneck values to return.\n      category: Name string of which set of images to fetch - training, testing,\n      or validation.\n      image_dir: Root folder string of the subfolders containing the training\n      images.\n      input_jpeg_tensor: The input layer we feed the image data to.\n      distorted_image: The output node of the distortion graph.\n      resized_input_tensor: The input node of the recognition graph.\n      bottleneck_tensor: The bottleneck output layer of the CNN graph.\n\n    Returns:\n      List of bottleneck arrays and their corresponding ground truths.\n    """"""\n    class_count = len(image_lists.keys())\n    bottlenecks = []\n    ground_truths = []\n    for unused_i in range(how_many):\n        label_index = random.randrange(class_count)\n        label_name = list(image_lists.keys())[label_index]\n        image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n        image_path = get_image_path(image_lists, label_name, image_index, image_dir,\n                                    category)\n        if not gfile.Exists(image_path):\n            tf.logging.fatal(\'File does not exist %s\', image_path)\n        jpeg_data = gfile.FastGFile(image_path, \'rb\').read()\n        # Note that we materialize the distorted_image_data as a numpy array before\n        # sending running inference on the image. This involves 2 memory copies and\n        # might be optimized in other implementations.\n        distorted_image_data = sess.run(distorted_image,\n                                        {input_jpeg_tensor: jpeg_data})\n        bottleneck = run_bottleneck_on_image(sess, distorted_image_data,\n                                             resized_input_tensor,\n                                             bottleneck_tensor)\n        ground_truth = np.zeros(class_count, dtype=np.float32)\n        ground_truth[label_index] = 1.0\n        bottlenecks.append(bottleneck)\n        ground_truths.append(ground_truth)\n    return bottlenecks, ground_truths\n\n\ndef should_distort_images(flip_left_right, random_crop, random_scale,\n                          random_brightness):\n    """"""Whether any distortions are enabled, from the input flags.\n\n    Args:\n      flip_left_right: Boolean whether to randomly mirror images horizontally.\n      random_crop: Integer percentage setting the total margin used around the\n      crop box.\n      random_scale: Integer percentage of how much to vary the scale by.\n      random_brightness: Integer range to randomly multiply the pixel values by.\n\n    Returns:\n      Boolean value indicating whether any distortions should be applied.\n    """"""\n    return (flip_left_right or (random_crop != 0) or (random_scale != 0) or\n            (random_brightness != 0))\n\n\ndef add_input_distortions(flip_left_right, random_crop, random_scale,\n                          random_brightness):\n    """"""Creates the operations to apply the specified distortions.\n\n    During training it can help to improve the results if we run the images\n    through simple distortions like crops, scales, and flips. These reflect the\n    kind of variations we expect in the real world, and so can help train the\n    model to cope with natural data more effectively. Here we take the supplied\n    parameters and construct a network of operations to apply them to an image.\n\n    Cropping\n    ~~~~~~~~\n\n    Cropping is done by placing a bounding box at a random position in the full\n    image. The cropping parameter controls the size of that box relative to the\n    input image. If it\'s zero, then the box is the same size as the input and no\n    cropping is performed. If the value is 50%, then the crop box will be half the\n    width and height of the input. In a diagram it looks like this:\n\n    <       width         >\n    +---------------------+\n    |                     |\n    |   width - crop%     |\n    |    <      >         |\n    |    +------+         |\n    |    |      |         |\n    |    |      |         |\n    |    |      |         |\n    |    +------+         |\n    |                     |\n    |                     |\n    +---------------------+\n\n    Scaling\n    ~~~~~~~\n\n    Scaling is a lot like cropping, except that the bounding box is always\n    centered and its size varies randomly within the given range. For example if\n    the scale percentage is zero, then the bounding box is the same size as the\n    input and no scaling is applied. If it\'s 50%, then the bounding box will be in\n    a random range between half the width and height and full size.\n\n    Args:\n      flip_left_right: Boolean whether to randomly mirror images horizontally.\n      random_crop: Integer percentage setting the total margin used around the\n      crop box.\n      random_scale: Integer percentage of how much to vary the scale by.\n      random_brightness: Integer range to randomly multiply the pixel values by.\n      graph.\n\n    Returns:\n      The jpeg input layer and the distorted result tensor.\n    """"""\n\n    jpeg_data = tf.placeholder(tf.string, name=\'DistortJPGInput\')\n    decoded_image = tf.image.decode_jpeg(jpeg_data, channels=MODEL_INPUT_DEPTH)\n    decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n    decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n    margin_scale = 1.0 + (random_crop / 100.0)\n    resize_scale = 1.0 + (random_scale / 100.0)\n    margin_scale_value = tf.constant(margin_scale)\n    resize_scale_value = tf.random_uniform(tensor_shape.scalar(),\n                                           minval=1.0,\n                                           maxval=resize_scale)\n    scale_value = tf.multiply(margin_scale_value, resize_scale_value)\n    precrop_width = tf.multiply(scale_value, MODEL_INPUT_WIDTH)\n    precrop_height = tf.multiply(scale_value, MODEL_INPUT_HEIGHT)\n    precrop_shape = tf.stack([precrop_height, precrop_width])\n    precrop_shape_as_int = tf.cast(precrop_shape, dtype=tf.int32)\n    precropped_image = tf.image.resize_bilinear(decoded_image_4d,\n                                                precrop_shape_as_int)\n    precropped_image_3d = tf.squeeze(precropped_image, squeeze_dims=[0])\n    cropped_image = tf.random_crop(precropped_image_3d,\n                                   [MODEL_INPUT_HEIGHT, MODEL_INPUT_WIDTH,\n                                    MODEL_INPUT_DEPTH])\n    if flip_left_right:\n        flipped_image = tf.image.random_flip_left_right(cropped_image)\n    else:\n        flipped_image = cropped_image\n    brightness_min = 1.0 - (random_brightness / 100.0)\n    brightness_max = 1.0 + (random_brightness / 100.0)\n    brightness_value = tf.random_uniform(tensor_shape.scalar(),\n                                         minval=brightness_min,\n                                         maxval=brightness_max)\n    brightened_image = tf.multiply(flipped_image, brightness_value)\n    distort_result = tf.expand_dims(brightened_image, 0, name=\'DistortResult\')\n    return jpeg_data, distort_result\n\n\ndef variable_summaries(var):\n    """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""\n    with tf.name_scope(\'summaries\'):\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar(\'mean\', mean)\n        with tf.name_scope(\'stddev\'):\n            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n        tf.summary.scalar(\'stddev\', stddev)\n        tf.summary.scalar(\'max\', tf.reduce_max(var))\n        tf.summary.scalar(\'min\', tf.reduce_min(var))\n        tf.summary.histogram(\'histogram\', var)\n\n\ndef add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor):\n    """"""Adds a new softmax and fully-connected layer for training.\n\n    We need to retrain the top layer to identify our new classes, so this function\n    adds the right operations to the graph, along with some variables to hold the\n    weights, and then sets up all the gradients for the backward pass.\n\n    The set up for the softmax and fully-connected layers is based on:\n    https://tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\n\n    Args:\n      class_count: Integer of how many categories of things we\'re trying to\n      recognize.\n      final_tensor_name: Name string for the new final node that produces results.\n      bottleneck_tensor: The output of the main CNN graph.\n\n    Returns:\n      The tensors for the training and cross entropy results, and tensors for the\n      bottleneck input and ground truth input.\n    """"""\n    with tf.name_scope(\'input\'):\n        bottleneck_input = tf.placeholder_with_default(\n            bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],\n            name=\'BottleneckInputPlaceholder\')\n\n        ground_truth_input = tf.placeholder(tf.float32,\n                                            [None, class_count],\n                                            name=\'GroundTruthInput\')\n\n    # Organizing the following ops as `final_training_ops` so they\'re easier\n    # to see in TensorBoard\n    layer_name = \'final_training_ops\'\n    with tf.name_scope(layer_name):\n        with tf.name_scope(\'weights\'):\n            layer_weights = tf.Variable(tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, class_count], stddev=0.001), name=\'final_weights\')\n            variable_summaries(layer_weights)\n        with tf.name_scope(\'biases\'):\n            layer_biases = tf.Variable(tf.zeros([class_count]), name=\'final_biases\')\n            variable_summaries(layer_biases)\n        with tf.name_scope(\'Wx_plus_b\'):\n            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n            tf.summary.histogram(\'pre_activations\', logits)\n\n    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n    tf.summary.histogram(\'activations\', final_tensor)\n\n    with tf.name_scope(\'cross_entropy\'):\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n            labels=ground_truth_input, logits=logits)\n        with tf.name_scope(\'total\'):\n            cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    tf.summary.scalar(\'cross_entropy\', cross_entropy_mean)\n\n    with tf.name_scope(\'train\'):\n        train_step = tf.train.GradientDescentOptimizer(FLAGS.learning_rate).minimize(\n            cross_entropy_mean)\n\n    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n            final_tensor)\n\n\ndef add_evaluation_step(result_tensor, ground_truth_tensor):\n    """"""Inserts the operations we need to evaluate the accuracy of our results.\n\n    Args:\n      result_tensor: The new final node that produces results.\n      ground_truth_tensor: The node we feed ground truth data\n      into.\n\n    Returns:\n      Tuple of (evaluation step, prediction).\n    """"""\n    with tf.name_scope(\'accuracy\'):\n        with tf.name_scope(\'correct_prediction\'):\n            prediction = tf.argmax(result_tensor, 1)\n            correct_prediction = tf.equal(\n                prediction, tf.argmax(ground_truth_tensor, 1))\n        with tf.name_scope(\'accuracy\'):\n            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    tf.summary.scalar(\'accuracy\', evaluation_step)\n    return evaluation_step, prediction\n\n\ndef main(_):\n    # Setup the directory we\'ll write summaries to for TensorBoard\n    if tf.gfile.Exists(FLAGS.summaries_dir):\n        tf.gfile.DeleteRecursively(FLAGS.summaries_dir)\n    tf.gfile.MakeDirs(FLAGS.summaries_dir)\n\n    # Set up the pre-trained graph.\n    maybe_download_and_extract()\n    graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (\n        create_inception_graph())\n\n    # Look at the folder structure, and create lists of all the images.\n    image_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,\n                                     FLAGS.validation_percentage)\n    class_count = len(image_lists.keys())\n    if class_count == 0:\n        print(\'No valid folders of images found at \' + FLAGS.image_dir)\n        return -1\n    if class_count == 1:\n        print(\'Only one valid folder of images found at \' + FLAGS.image_dir +\n              \' - multiple classes are needed for classification.\')\n        return -1\n\n    # See if the command-line flags mean we\'re applying any distortions.\n    do_distort_images = should_distort_images(\n        FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n        FLAGS.random_brightness)\n    sess = tf.Session()\n\n    if do_distort_images:\n        # We will be applying distortions, so setup the operations we\'ll need.\n        distorted_jpeg_data_tensor, distorted_image_tensor = add_input_distortions(\n            FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n            FLAGS.random_brightness)\n    else:\n        # We\'ll make sure we\'ve calculated the \'bottleneck\' image summaries and\n        # cached them on disk.\n        cache_bottlenecks(sess, image_lists, FLAGS.image_dir, FLAGS.bottleneck_dir,\n                          jpeg_data_tensor, bottleneck_tensor)\n\n    # Add the new layer that we\'ll be training.\n    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n     final_tensor) = add_final_training_ops(len(image_lists.keys()),\n                                            FLAGS.final_tensor_name,\n                                            bottleneck_tensor)\n\n    # Create the operations we need to evaluate the accuracy of our new layer.\n    evaluation_step, prediction = add_evaluation_step(\n        final_tensor, ground_truth_input)\n\n    # Merge all the summaries and write them out to /tmp/retrain_logs (by default)\n    merged = tf.summary.merge_all()\n    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + \'/train\',\n                                         sess.graph)\n    validation_writer = tf.summary.FileWriter(FLAGS.summaries_dir + \'/validation\')\n\n    # Set up all our weights to their initial default values.\n    init = tf.global_variables_initializer()\n    sess.run(init)\n\n    # Run the training for as many cycles as requested on the command line.\n    for i in range(FLAGS.how_many_training_steps):\n        # Get a batch of input bottleneck values, either calculated fresh every time\n        # with distortions applied, or from the cache stored on disk.\n        if do_distort_images:\n            train_bottlenecks, train_ground_truth = get_random_distorted_bottlenecks(\n                sess, image_lists, FLAGS.train_batch_size, \'training\',\n                FLAGS.image_dir, distorted_jpeg_data_tensor,\n                distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n        else:\n            train_bottlenecks, train_ground_truth, _ = get_random_cached_bottlenecks(\n                sess, image_lists, FLAGS.train_batch_size, \'training\',\n                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n                bottleneck_tensor)\n        # Feed the bottlenecks and ground truth into the graph, and run a training\n        # step. Capture training summaries for TensorBoard with the `merged` op.\n        train_summary, _ = sess.run([merged, train_step],\n                                    feed_dict={bottleneck_input: train_bottlenecks,\n                                               ground_truth_input: train_ground_truth})\n        train_writer.add_summary(train_summary, i)\n\n        # Every so often, print out how well the graph is training.\n        is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n        if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n            train_accuracy, cross_entropy_value = sess.run(\n                [evaluation_step, cross_entropy],\n                feed_dict={bottleneck_input: train_bottlenecks,\n                           ground_truth_input: train_ground_truth})\n            print(\'%s: Step %d: Train accuracy = %.1f%%\' % (datetime.now(), i,\n                                                            train_accuracy * 100))\n            print(\'%s: Step %d: Cross entropy = %f\' % (datetime.now(), i,\n                                                       cross_entropy_value))\n            validation_bottlenecks, validation_ground_truth, _ = (\n                get_random_cached_bottlenecks(\n                    sess, image_lists, FLAGS.validation_batch_size, \'validation\',\n                    FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n                    bottleneck_tensor))\n            # Run a validation step and capture training summaries for TensorBoard\n            # with the `merged` op.\n            validation_summary, validation_accuracy = sess.run(\n                [merged, evaluation_step],\n                feed_dict={bottleneck_input: validation_bottlenecks,\n                           ground_truth_input: validation_ground_truth})\n            validation_writer.add_summary(validation_summary, i)\n            print(\'%s: Step %d: Validation accuracy = %.1f%% (N=%d)\' %\n                  (datetime.now(), i, validation_accuracy * 100,\n                   len(validation_bottlenecks)))\n\n    # We\'ve completed all our training, so run a final test evaluation on\n    # some new images we haven\'t used before.\n    test_bottlenecks, test_ground_truth, test_filenames = (\n        get_random_cached_bottlenecks(sess, image_lists, FLAGS.test_batch_size,\n                                      \'testing\', FLAGS.bottleneck_dir,\n                                      FLAGS.image_dir, jpeg_data_tensor,\n                                      bottleneck_tensor))\n    test_accuracy, predictions = sess.run(\n        [evaluation_step, prediction],\n        feed_dict={bottleneck_input: test_bottlenecks,\n                   ground_truth_input: test_ground_truth})\n    print(\'Final test accuracy = %.1f%% (N=%d)\' % (\n        test_accuracy * 100, len(test_bottlenecks)))\n\n    if FLAGS.print_misclassified_test_images:\n        print(\'=== MISCLASSIFIED TEST IMAGES ===\')\n        for i, test_filename in enumerate(test_filenames):\n            if predictions[i] != test_ground_truth[i].argmax():\n                print(\'%70s  %s\' % (test_filename, image_lists.keys()[predictions[i]]))\n\n    # Write out the trained graph and labels with the weights stored as constants.\n    output_graph_def = graph_util.convert_variables_to_constants(\n        sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\n    with gfile.FastGFile(FLAGS.output_graph, \'wb\') as f:\n        f.write(output_graph_def.SerializeToString())\n    with gfile.FastGFile(FLAGS.output_labels, \'w\') as f:\n        f.write(\'\\n\'.join(image_lists.keys()) + \'\\n\')\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--image_dir\',\n        type=str,\n        default=\'\',\n        help=\'Path to folders of labeled images.\'\n    )\n    parser.add_argument(\n        \'--output_graph\',\n        type=str,\n        default=\'/tmp/output_graph.pb\',\n        help=\'Where to save the trained graph.\'\n    )\n    parser.add_argument(\n        \'--output_labels\',\n        type=str,\n        default=\'/tmp/output_labels.txt\',\n        help=\'Where to save the trained graph\\\'s labels.\'\n    )\n    parser.add_argument(\n        \'--summaries_dir\',\n        type=str,\n        default=\'/tmp/retrain_logs\',\n        help=\'Where to save summary logs for TensorBoard.\'\n    )\n    parser.add_argument(\n        \'--how_many_training_steps\',\n        type=int,\n        default=4000,\n        help=\'How many training steps to run before ending.\'\n    )\n    parser.add_argument(\n        \'--learning_rate\',\n        type=float,\n        default=0.01,\n        help=\'How large a learning rate to use when training.\'\n    )\n    parser.add_argument(\n        \'--testing_percentage\',\n        type=int,\n        default=10,\n        help=\'What percentage of images to use as a test set.\'\n    )\n    parser.add_argument(\n        \'--validation_percentage\',\n        type=int,\n        default=10,\n        help=\'What percentage of images to use as a validation set.\'\n    )\n    parser.add_argument(\n        \'--eval_step_interval\',\n        type=int,\n        default=10,\n        help=\'How often to evaluate the training results.\'\n    )\n    parser.add_argument(\n        \'--train_batch_size\',\n        type=int,\n        default=100,\n        help=\'How many images to train on at a time.\'\n    )\n    parser.add_argument(\n        \'--test_batch_size\',\n        type=int,\n        default=-1,\n        help=""""""\\\n      How many images to test on. This test set is only used once, to evaluate\n      the final accuracy of the model after training completes.\n      A value of -1 causes the entire test set to be used, which leads to more\n      stable results across runs.\\\n      """"""\n    )\n    parser.add_argument(\n        \'--validation_batch_size\',\n        type=int,\n        default=100,\n        help=""""""\\\n      How many images to use in an evaluation batch. This validation set is\n      used much more often than the test set, and is an early indicator of how\n      accurate the model is during training.\n      A value of -1 causes the entire validation set to be used, which leads to\n      more stable results across training iterations, but may be slower on large\n      training sets.\\\n      """"""\n    )\n    parser.add_argument(\n        \'--print_misclassified_test_images\',\n        default=False,\n        help=""""""\\\n      Whether to print out a list of all misclassified test images.\\\n      """""",\n        action=\'store_true\'\n    )\n    parser.add_argument(\n        \'--model_dir\',\n        type=str,\n        default=\'/tmp/imagenet\',\n        help=""""""\\\n      Path to classify_image_graph_def.pb,\n      imagenet_synset_to_human_label_map.txt, and\n      imagenet_2012_challenge_label_map_proto.pbtxt.\\\n      """"""\n    )\n    parser.add_argument(\n        \'--bottleneck_dir\',\n        type=str,\n        default=\'/tmp/bottleneck\',\n        help=\'Path to cache bottleneck layer values as files.\'\n    )\n    parser.add_argument(\n        \'--final_tensor_name\',\n        type=str,\n        default=\'final_result\',\n        help=""""""\\\n      The name of the output classification layer in the retrained graph.\\\n      """"""\n    )\n    parser.add_argument(\n        \'--flip_left_right\',\n        default=False,\n        help=""""""\\\n      Whether to randomly flip half of the training images horizontally.\\\n      """""",\n        action=\'store_true\'\n    )\n    parser.add_argument(\n        \'--random_crop\',\n        type=int,\n        default=0,\n        help=""""""\\\n      A percentage determining how much of a margin to randomly crop off the\n      training images.\\\n      """"""\n    )\n    parser.add_argument(\n        \'--random_scale\',\n        type=int,\n        default=0,\n        help=""""""\\\n      A percentage determining how much to randomly scale up the size of the\n      training images by.\\\n      """"""\n    )\n    parser.add_argument(\n        \'--random_brightness\',\n        type=int,\n        default=0,\n        help=""""""\\\n      A percentage determining how much to randomly multiply the training image\n      input pixels up or down by.\\\n      """"""\n    )\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)'"
12 - DQN/agent.py,13,"b'# \xea\xb2\x8c\xec\x9e\x84 \xea\xb5\xac\xed\x98\x84\xea\xb3\xbc DQN \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\x8b\xa4\xed\x96\x89\xed\x95\x98\xea\xb3\xa0 \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xec\xa7\x84\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\nimport numpy as np\nimport random\nimport time\n\nfrom game import Game\nfrom model import DQN\n\n\ntf.app.flags.DEFINE_boolean(""train"", False, ""\xed\x95\x99\xec\x8a\xb5\xeb\xaa\xa8\xeb\x93\x9c. \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90 \xeb\xb3\xb4\xec\x97\xac\xec\xa3\xbc\xec\xa7\x80 \xec\x95\x8a\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4."")\nFLAGS = tf.app.flags.FLAGS\n\n# \xec\xb5\x9c\xeb\x8c\x80 \xed\x95\x99\xec\x8a\xb5 \xed\x9a\x9f\xec\x88\x98\nMAX_EPISODE = 10000\n# 1000\xeb\xb2\x88\xec\x9d\x98 \xed\x95\x99\xec\x8a\xb5\xeb\xa7\x88\xeb\x8b\xa4 \xed\x95\x9c \xeb\xb2\x88\xec\x94\xa9 \xed\x83\x80\xea\xb2\x9f \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9d\x84 \xec\x97\x85\xeb\x8d\xb0\xec\x9d\xb4\xed\x8a\xb8\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nTARGET_UPDATE_INTERVAL = 1000\n# 4 \xed\x94\x84\xeb\xa0\x88\xec\x9e\x84\xeb\xa7\x88\xeb\x8b\xa4 \xed\x95\x9c \xeb\xb2\x88\xec\x94\xa9 \xed\x95\x99\xec\x8a\xb5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nTRAIN_INTERVAL = 4\n# \xed\x95\x99\xec\x8a\xb5 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xec\x96\xb4\xeb\x8a\x90\xec\xa0\x95\xeb\x8f\x84 \xec\x8c\x93\xec\x9d\x80 \xed\x9b\x84, \xec\x9d\xbc\xec\xa0\x95 \xec\x8b\x9c\xea\xb0\x84 \xec\x9d\xb4\xed\x9b\x84\xec\x97\x90 \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xec\x8b\x9c\xec\x9e\x91\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nOBSERVE = 100\n\n# action: 0: \xec\xa2\x8c, 1: \xec\x9c\xa0\xec\xa7\x80, 2: \xec\x9a\xb0\nNUM_ACTION = 3\nSCREEN_WIDTH = 6\nSCREEN_HEIGHT = 10\n\n\ndef train():\n    print(\'\xeb\x87\x8c\xec\x84\xb8\xed\x8f\xac \xea\xb9\xa8\xec\x9a\xb0\xeb\x8a\x94 \xec\xa4\x91..\')\n    sess = tf.Session()\n\n    game = Game(SCREEN_WIDTH, SCREEN_HEIGHT, show_game=False)\n    brain = DQN(sess, SCREEN_WIDTH, SCREEN_HEIGHT, NUM_ACTION)\n\n    rewards = tf.placeholder(tf.float32, [None])\n    tf.summary.scalar(\'avg.reward/ep.\', tf.reduce_mean(rewards))\n\n    saver = tf.train.Saver()\n    sess.run(tf.global_variables_initializer())\n\n    writer = tf.summary.FileWriter(\'logs\', sess.graph)\n    summary_merged = tf.summary.merge_all()\n\n    # \xed\x83\x80\xea\xb2\x9f \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9d\x84 \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    brain.update_target_network()\n\n    # \xeb\x8b\xa4\xec\x9d\x8c\xec\x97\x90 \xec\xb7\xa8\xed\x95\xa0 \xec\x95\xa1\xec\x85\x98\xec\x9d\x84 DQN \xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb2\xb0\xec\xa0\x95\xed\x95\xa0 \xec\x8b\x9c\xea\xb8\xb0\xeb\xa5\xbc \xea\xb2\xb0\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    epsilon = 1.0\n    # \xed\x94\x84\xeb\xa0\x88\xec\x9e\x84 \xed\x9a\x9f\xec\x88\x98\n    time_step = 0\n    total_reward_list = []\n\n    # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\x8b\x9c\xec\x9e\x91\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    for episode in range(MAX_EPISODE):\n        terminal = False\n        total_reward = 0\n\n        # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\x98\xea\xb3\xa0 \xed\x98\x84\xec\x9e\xac \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        # \xec\x83\x81\xed\x83\x9c\xeb\x8a\x94 screen_width x screen_height \xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 \xed\x99\x94\xeb\xa9\xb4 \xea\xb5\xac\xec\x84\xb1\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n        state = game.reset()\n        brain.init_state(state)\n\n        while not terminal:\n            # \xec\x9e\x85\xec\x8b\xa4\xeb\xa1\xa0\xec\x9d\xb4 \xeb\x9e\x9c\xeb\x8d\xa4\xea\xb0\x92\xeb\xb3\xb4\xeb\x8b\xa4 \xec\x9e\x91\xec\x9d\x80 \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 \xeb\x9e\x9c\xeb\x8d\xa4\xed\x95\x9c \xec\x95\xa1\xec\x85\x98\xec\x9d\x84 \xec\x84\xa0\xed\x83\x9d\xed\x95\x98\xea\xb3\xa0\n            # \xea\xb7\xb8 \xec\x9d\xb4\xec\x83\x81\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 DQN\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x95\xa1\xec\x85\x98\xec\x9d\x84 \xec\x84\xa0\xed\x83\x9d\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n            # \xec\xb4\x88\xeb\xb0\x98\xec\x97\x94 \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4 \xec\xa0\x81\xea\xb2\x8c \xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n            # \xec\xb4\x88\xeb\xb0\x98\xec\x97\x90\xeb\x8a\x94 \xea\xb1\xb0\xec\x9d\x98 \xeb\x8c\x80\xeb\xb6\x80\xeb\xb6\x84 \xeb\x9e\x9c\xeb\x8d\xa4\xea\xb0\x92\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8b\xa4\xea\xb0\x80 \xec\xa0\x90\xec\xa0\x90 \xec\xa4\x84\xec\x96\xb4\xeb\x93\xa4\xec\x96\xb4\n            # \xeb\x82\x98\xec\xa4\x91\xec\x97\x90\xeb\x8a\x94 \xea\xb1\xb0\xec\x9d\x98 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xea\xb2\x8c\xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n            if np.random.rand() < epsilon:\n                action = random.randrange(NUM_ACTION)\n            else:\n                action = brain.get_action()\n\n            # \xec\x9d\xbc\xec\xa0\x95 \xec\x8b\x9c\xea\xb0\x84\xec\x9d\xb4 \xec\xa7\x80\xeb\x82\x9c \xeb\x92\xa4 \xeb\xb6\x80\xed\x84\xb0 \xec\x9e\x85\xec\x8b\xa4\xeb\xa1\xa0 \xea\xb0\x92\xec\x9d\x84 \xec\xa4\x84\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n            # \xec\xb4\x88\xeb\xb0\x98\xec\x97\x90\xeb\x8a\x94 \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4 \xec\xa0\x84\xed\x98\x80 \xec\x95\x88\xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n            if episode > OBSERVE:\n                epsilon -= 1 / 1000\n\n            # \xea\xb2\xb0\xec\xa0\x95\xed\x95\x9c \xec\x95\xa1\xec\x85\x98\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\xa7\x84\xed\x96\x89\xed\x95\x98\xea\xb3\xa0, \xeb\xb3\xb4\xec\x83\x81\xea\xb3\xbc \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x98 \xec\xa2\x85\xeb\xa3\x8c \xec\x97\xac\xeb\xb6\x80\xeb\xa5\xbc \xeb\xb0\x9b\xec\x95\x84\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n            state, reward, terminal = game.step(action)\n            total_reward += reward\n\n            # \xed\x98\x84\xec\x9e\xac \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc Brain\xec\x97\x90 \xea\xb8\xb0\xec\x96\xb5\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n            # \xea\xb8\xb0\xec\x96\xb5\xed\x95\x9c \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xed\x95\x99\xec\x8a\xb5\xed\x95\x98\xea\xb3\xa0, \xeb\x8b\xa4\xec\x9d\x8c \xec\x83\x81\xed\x83\x9c\xec\x97\x90\xec\x84\x9c \xec\xb7\xa8\xed\x95\xa0 \xed\x96\x89\xeb\x8f\x99\xec\x9d\x84 \xea\xb2\xb0\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n            brain.remember(state, action, reward, terminal)\n\n            if time_step > OBSERVE and time_step % TRAIN_INTERVAL == 0:\n                # DQN \xec\x9c\xbc\xeb\xa1\x9c \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xec\xa7\x84\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n                brain.train()\n\n            if time_step % TARGET_UPDATE_INTERVAL == 0:\n                # \xed\x83\x80\xea\xb2\x9f \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9d\x84 \xec\x97\x85\xeb\x8d\xb0\xec\x9d\xb4\xed\x8a\xb8 \xed\x95\xb4 \xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\n                brain.update_target_network()\n\n            time_step += 1\n\n        print(\'\xea\xb2\x8c\xec\x9e\x84\xed\x9a\x9f\xec\x88\x98: %d \xec\xa0\x90\xec\x88\x98: %d\' % (episode + 1, total_reward))\n\n        total_reward_list.append(total_reward)\n\n        if episode % 10 == 0:\n            summary = sess.run(summary_merged, feed_dict={rewards: total_reward_list})\n            writer.add_summary(summary, time_step)\n            total_reward_list = []\n\n        if episode % 100 == 0:\n            saver.save(sess, \'model/dqn.ckpt\', global_step=time_step)\n\n\ndef replay():\n    print(\'\xeb\x87\x8c\xec\x84\xb8\xed\x8f\xac \xea\xb9\xa8\xec\x9a\xb0\xeb\x8a\x94 \xec\xa4\x91..\')\n    sess = tf.Session()\n\n    game = Game(SCREEN_WIDTH, SCREEN_HEIGHT, show_game=True)\n    brain = DQN(sess, SCREEN_WIDTH, SCREEN_HEIGHT, NUM_ACTION)\n\n    saver = tf.train.Saver()\n    ckpt = tf.train.get_checkpoint_state(\'model\')\n    saver.restore(sess, ckpt.model_checkpoint_path)\n\n    # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\x8b\x9c\xec\x9e\x91\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    for episode in range(MAX_EPISODE):\n        terminal = False\n        total_reward = 0\n\n        state = game.reset()\n        brain.init_state(state)\n\n        while not terminal:\n            action = brain.get_action()\n\n            # \xea\xb2\xb0\xec\xa0\x95\xed\x95\x9c \xec\x95\xa1\xec\x85\x98\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\xa7\x84\xed\x96\x89\xed\x95\x98\xea\xb3\xa0, \xeb\xb3\xb4\xec\x83\x81\xea\xb3\xbc \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x98 \xec\xa2\x85\xeb\xa3\x8c \xec\x97\xac\xeb\xb6\x80\xeb\xa5\xbc \xeb\xb0\x9b\xec\x95\x84\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n            state, reward, terminal = game.step(action)\n            total_reward += reward\n\n            brain.remember(state, action, reward, terminal)\n\n            # \xea\xb2\x8c\xec\x9e\x84 \xec\xa7\x84\xed\x96\x89\xec\x9d\x84 \xec\x9d\xb8\xea\xb0\x84\xec\x9d\xb4 \xec\x9d\xb8\xec\xa7\x80\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xeb\x8a\x94 \xec\x86\x8d\xeb\x8f\x84\xeb\xa1\x9c^^; \xeb\xb3\xb4\xec\x97\xac\xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4.\n            time.sleep(0.3)\n\n        print(\'\xea\xb2\x8c\xec\x9e\x84\xed\x9a\x9f\xec\x88\x98: %d \xec\xa0\x90\xec\x88\x98: %d\' % (episode + 1, total_reward))\n\n\ndef main(_):\n    if FLAGS.train:\n        train()\n    else:\n        replay()\n\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
12 - DQN/game.py,0,"b'# \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc \xed\x9a\x8c\xed\x94\xbc \xea\xb2\x8c\xec\x9e\x84 \xec\xa6\x89, \xec\x9e\x90\xec\x9c\xa8\xec\xa3\xbc\xed\x96\x89\xec\xb0\xa8:-D \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xea\xb5\xac\xed\x98\x84\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\nimport numpy as np\nimport random\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\nclass Game:\n    def __init__(self, screen_width, screen_height, show_game=True):\n        self.screen_width = screen_width\n        self.screen_height = screen_height\n        # \xeb\x8f\x84\xeb\xa1\x9c\xec\x9d\x98 \xed\x81\xac\xea\xb8\xb0\xeb\x8a\x94 \xec\x8a\xa4\xed\x81\xac\xeb\xa6\xb0\xec\x9d\x98 \xeb\xb0\x98\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xed\x95\x98\xeb\xa9\xb0, \xeb\x8f\x84\xeb\xa1\x9c\xec\x9d\x98 \xec\xa2\x8c\xec\xb8\xa1 \xec\x9a\xb0\xec\xb8\xa1\xec\x9d\x98 \xec\x97\xac\xeb\xb0\xb1\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\xb4\xeb\x91\xa1\xeb\x8b\x88\xeb\x8b\xa4.\n        self.road_width = int(screen_width / 2)\n        self.road_left = int(self.road_width / 2 + 1)\n        self.road_right = int(self.road_left + self.road_width - 1)\n\n        # \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xec\x99\x80 \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\x98 \xec\xb4\x88\xea\xb8\xb0 \xec\x9c\x84\xec\xb9\x98\xec\x99\x80, \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\x86\x8d\xeb\x8f\x84\xeb\xa5\xbc \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        self.car = {""col"": 0, ""row"": 2}\n        self.block = [\n            {""col"": 0, ""row"": 0, ""speed"": 1},\n            {""col"": 0, ""row"": 0, ""speed"": 2},\n        ]\n\n        self.total_reward = 0.\n        self.current_reward = 0.\n        self.total_game = 0\n        self.show_game = show_game\n\n        if show_game:\n            self.fig, self.axis = self._prepare_display()\n\n    def _prepare_display(self):\n        """"""\xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90 \xeb\xb3\xb4\xec\x97\xac\xec\xa3\xbc\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 matplotlib \xec\x9c\xbc\xeb\xa1\x9c \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\xa0 \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x84 \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.""""""\n        fig, axis = plt.subplots(figsize=(4, 6))\n        fig.set_size_inches(4, 6)\n        # \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x84 \xeb\x8b\xab\xec\x9c\xbc\xeb\xa9\xb4 \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\xa8\xec\x9d\x84 \xec\xa2\x85\xeb\xa3\x8c\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        fig.canvas.mpl_connect(\'close_event\', exit)\n        plt.axis((0, self.screen_width, 0, self.screen_height))\n        plt.tick_params(top=\'off\', right=\'off\',\n                        left=\'off\', labelleft=\'off\',\n                        bottom=\'off\', labelbottom=\'off\')\n\n        plt.draw()\n        # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x84 \xec\xa7\x84\xed\x96\x89\xed\x95\x98\xeb\xa9\xb0 \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x84 \xec\x97\x85\xeb\x8d\xb0\xec\x9d\xb4\xed\x8a\xb8 \xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xeb\x8f\x84\xeb\xa1\x9d interactive \xeb\xaa\xa8\xeb\x93\x9c\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        plt.ion()\n        plt.show()\n\n        return fig, axis\n\n    def _get_state(self):\n        """"""\xea\xb2\x8c\xec\x9e\x84\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n\n        \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\x8a\x94 screen_width x screen_height \xed\x81\xac\xea\xb8\xb0\xeb\xa1\x9c \xea\xb0\x81 \xec\x9c\x84\xec\xb9\x98\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xec\x83\x81\xed\x83\x9c\xea\xb0\x92\xec\x9d\x84 \xea\xb0\x80\xec\xa7\x80\xea\xb3\xa0 \xec\x9e\x88\xec\x9c\xbc\xeb\xa9\xb0,\n        \xeb\xb9\x88 \xea\xb3\xb5\xea\xb0\x84\xec\x9d\xb8 \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 0, \xec\x82\xac\xeb\xac\xbc\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 1\xec\x9d\xb4 \xeb\x93\xa4\xec\x96\xb4\xec\x9e\x88\xeb\x8a\x94 1\xec\xb0\xa8\xec\x9b\x90 \xeb\xb0\xb0\xec\x97\xb4\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n        \xea\xb3\x84\xec\x82\xb0\xec\x9d\x98 \xed\x8e\xb8\xec\x9d\x98\xec\x84\xb1\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 2\xec\xb0\xa8\xec\x9b\x90 -> 1\xec\xb0\xa8\xec\x9b\x90\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x98\xec\x97\xac \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        """"""\n        state = np.zeros((self.screen_width, self.screen_height))\n\n        state[self.car[""col""], self.car[""row""]] = 1\n\n        if self.block[0][""row""] < self.screen_height:\n            state[self.block[0][""col""], self.block[0][""row""]] = 1\n\n        if self.block[1][""row""] < self.screen_height:\n            state[self.block[1][""col""], self.block[1][""row""]] = 1\n\n        return state\n\n    def _draw_screen(self):\n        title = "" Avg. Reward: %d Reward: %d Total Game: %d"" % (\n                        self.total_reward / self.total_game,\n                        self.current_reward,\n                        self.total_game)\n\n        # self.axis.clear()\n        self.axis.set_title(title, fontsize=12)\n\n        road = patches.Rectangle((self.road_left - 1, 0),\n                                 self.road_width + 1, self.screen_height,\n                                 linewidth=0, facecolor=""#333333"")\n        # \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8, \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xeb\x93\xa4\xec\x9d\x84 1x1 \xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 \xec\xa0\x95\xec\x82\xac\xea\xb0\x81\xed\x98\x95\xec\x9c\xbc\xeb\xa1\x9c \xea\xb7\xb8\xeb\xa6\xac\xeb\x8f\x84\xeb\xa1\x9d\xed\x95\x98\xeb\xa9\xb0, \xec\xa2\x8c\xed\x91\x9c\xeb\xa5\xbc \xea\xb8\xb0\xec\xa4\x80\xec\x9c\xbc\xeb\xa1\x9c \xec\xa4\x91\xec\x95\x99\xec\x97\x90 \xec\x9c\x84\xec\xb9\x98\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        # \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xec\x9d\x98 \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xea\xb3\xbc \xec\xb6\xa9\xeb\x8f\x8c\xec\x8b\x9c \xed\x99\x95\xec\x9d\xb8\xec\x9d\xb4 \xea\xb0\x80\xeb\x8a\xa5\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d 0.5\xeb\xa7\x8c\xed\x81\xbc \xec\x95\x84\xeb\x9e\x98\xec\xaa\xbd\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\x8f\x99\xed\x95\x98\xec\x97\xac \xea\xb7\xb8\xeb\xa6\xbd\xeb\x8b\x88\xeb\x8b\xa4.\n        car = patches.Rectangle((self.car[""col""] - 0.5, self.car[""row""] - 0.5),\n                                1, 1,\n                                linewidth=0, facecolor=""#00FF00"")\n        block1 = patches.Rectangle((self.block[0][""col""] - 0.5, self.block[0][""row""]),\n                                   1, 1,\n                                   linewidth=0, facecolor=""#0000FF"")\n        block2 = patches.Rectangle((self.block[1][""col""] - 0.5, self.block[1][""row""]),\n                                   1, 1,\n                                   linewidth=0, facecolor=""#FF0000"")\n\n        self.axis.add_patch(road)\n        self.axis.add_patch(car)\n        self.axis.add_patch(block1)\n        self.axis.add_patch(block2)\n\n        self.fig.canvas.draw()\n        # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x98 \xeb\x8b\xa4\xec\x9d\x8c \xeb\x8b\xa8\xea\xb3\x84 \xec\xa7\x84\xed\x96\x89\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 matplot \xec\x9d\x98 \xec\x9d\xb4\xeb\xb2\xa4\xed\x8a\xb8 \xeb\xa3\xa8\xed\x94\x84\xeb\xa5\xbc \xec\x9e\xa0\xec\x8b\x9c \xeb\xa9\x88\xec\xb6\xa5\xeb\x8b\x88\xeb\x8b\xa4.\n        plt.pause(0.0001)\n\n    def reset(self):\n        """"""\xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8, \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\x98 \xec\x9c\x84\xec\xb9\x98\xec\x99\x80 \xeb\xb3\xb4\xec\x83\x81\xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.""""""\n        self.current_reward = 0\n        self.total_game += 1\n\n        self.car[""col""] = int(self.screen_width / 2)\n\n        self.block[0][""col""] = random.randrange(self.road_left, self.road_right + 1)\n        self.block[0][""row""] = 0\n        self.block[1][""col""] = random.randrange(self.road_left, self.road_right + 1)\n        self.block[1][""row""] = 0\n\n        self._update_block()\n\n        return self._get_state()\n\n    def _update_car(self, move):\n        """"""\xec\x95\xa1\xec\x85\x98\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xeb\xa5\xbc \xec\x9d\xb4\xeb\x8f\x99\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n\n        \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8 \xec\x9c\x84\xec\xb9\x98 \xec\xa0\x9c\xed\x95\x9c\xec\x9d\x84 \xeb\x8f\x84\xeb\xa1\x9c\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\x9d\xbc \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x98 \xec\xa2\x8c\xec\x9a\xb0\xec\xb8\xa1 \xeb\x81\x9d\xec\x9c\xbc\xeb\xa1\x9c \xed\x95\x98\xea\xb3\xa0,\n        \xeb\x8f\x84\xeb\xa1\x9c\xeb\xa5\xbc \xeb\x84\x98\xec\x96\xb4\xea\xb0\x80\xeb\xa9\xb4 \xed\x8c\xa8\xeb\x84\x90\xed\x8b\xb0\xeb\xa5\xbc \xec\xa3\xbc\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x99\xec\x8a\xb5\xed\x95\xb4\xec\x84\x9c \xeb\x8f\x84\xeb\xa1\x9c\xeb\xa5\xbc \xeb\x84\x98\xec\xa7\x80 \xec\x95\x8a\xea\xb2\x8c \xeb\xa7\x8c\xeb\x93\xa4\xeb\xa9\xb4 \xeb\x8d\x94\xec\x9a\xb1 \xec\xa2\x8b\xec\x9d\x84 \xea\xb2\x83 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        """"""\n\n        # \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xec\x9d\x98 \xec\x9c\x84\xec\xb9\x98\xea\xb0\x80 \xeb\x8f\x84\xeb\xa1\x9c\xec\x9d\x98 \xec\xa2\x8c\xec\xb8\xa1\xec\x9d\x84 \xeb\x84\x98\xec\xa7\x80 \xec\x95\x8a\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4: max(0, move) > 0\n        self.car[""col""] = max(self.road_left, self.car[""col""] + move)\n        # \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xec\x9d\x98 \xec\x9c\x84\xec\xb9\x98\xea\xb0\x80 \xeb\x8f\x84\xeb\xa1\x9c\xec\x9d\x98 \xec\x9a\xb0\xec\xb8\xa1\xec\x9d\x84 \xeb\x84\x98\xec\xa7\x80 \xec\x95\x8a\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.: min(max, screen_width) < screen_width\n        self.car[""col""] = min(self.car[""col""], self.road_right)\n\n    def _update_block(self):\n        """"""\xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\x84 \xec\x9d\xb4\xeb\x8f\x99\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n\n        \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\xb4 \xed\x99\x94\xeb\xa9\xb4 \xeb\x82\xb4\xec\x97\x90 \xec\x9e\x88\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0\xeb\x8a\x94 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\x86\x8d\xeb\x8f\x84\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc \xec\x9c\x84\xec\xb9\x98 \xeb\xb3\x80\xea\xb2\xbd\xec\x9d\x84,\n        \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x84 \xeb\xb2\x97\xec\x96\xb4\xeb\x82\x9c \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 \xeb\x8b\xa4\xec\x8b\x9c \xeb\xb0\xa9\xed\x95\xb4\xeb\xa5\xbc \xec\x8b\x9c\xec\x9e\x91\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xec\x9e\xac\xec\x84\xa4\xec\xa0\x95\xec\x9d\x84 \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        """"""\n        reward = 0\n\n        if self.block[0][""row""] > 0:\n            self.block[0][""row""] -= self.block[0][""speed""]\n        else:\n            self.block[0][""col""] = random.randrange(self.road_left, self.road_right + 1)\n            self.block[0][""row""] = self.screen_height\n            reward += 1\n\n        if self.block[1][""row""] > 0:\n            self.block[1][""row""] -= self.block[1][""speed""]\n        else:\n            self.block[1][""col""] = random.randrange(self.road_left, self.road_right + 1)\n            self.block[1][""row""] = self.screen_height\n            reward += 1\n\n        return reward\n\n    def _is_gameover(self):\n        # \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xea\xb3\xbc \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xea\xb0\x80 \xec\xb6\xa9\xeb\x8f\x8c\xed\x96\x88\xeb\x8a\x94\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x8c\xec\x95\x85\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        # \xec\x82\xac\xea\xb0\x81\xed\x98\x95 \xeb\xb0\x95\xec\x8a\xa4\xec\x9d\x98 \xec\xb6\xa9\xeb\x8f\x8c\xec\x9d\x84 \xec\xb2\xb4\xed\x81\xac\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x88\xeb\x9d\xbc \xec\xa2\x8c\xed\x91\x9c\xeb\xa5\xbc \xec\xb2\xb4\xed\x81\xac\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\xb4\xec\x96\xb4\xec\x84\x9c \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90\xeb\x8a\x94 \xec\x95\xbd\xea\xb0\x84 \xeb\x8b\xa4\xeb\xa5\xb4\xea\xb2\x8c \xeb\xb3\xb4\xec\x9d\xbc \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        if ((self.car[""col""] == self.block[0][""col""] and\n             self.car[""row""] == self.block[0][""row""]) or\n            (self.car[""col""] == self.block[1][""col""] and\n             self.car[""row""] == self.block[1][""row""])):\n\n            self.total_reward += self.current_reward\n\n            return True\n        else:\n            return False\n\n    def step(self, action):\n        # action: 0: \xec\xa2\x8c, 1: \xec\x9c\xa0\xec\xa7\x80, 2: \xec\x9a\xb0\n        # action - 1 \xec\x9d\x84 \xed\x95\x98\xec\x97\xac, \xec\xa2\x8c\xed\x91\x9c\xeb\xa5\xbc \xec\x95\xa1\xec\x85\x98\xec\x9d\xb4 0 \xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0 -1 \xeb\xa7\x8c\xed\x81\xbc, 2 \xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0 1 \xeb\xa7\x8c\xed\x81\xbc \xec\x98\xae\xea\xb9\x81\xeb\x8b\x88\xeb\x8b\xa4.\n        self._update_car(action - 1)\n        # \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\x84 \xec\x9d\xb4\xeb\x8f\x99\xec\x8b\x9c\xed\x82\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\xb4 \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xec\x97\x90 \xec\xb6\xa9\xeb\x8f\x8c\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xea\xb3\xa0 \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x84 \xeb\xaa\xa8\xeb\x91\x90 \xec\xa7\x80\xeb\x82\x98\xea\xb0\x80\xeb\xa9\xb4 \xeb\xb3\xb4\xec\x83\x81\xec\x9d\x84 \xec\x96\xbb\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        escape_reward = self._update_block()\n        # \xec\x9b\x80\xec\xa7\x81\xec\x9e\x84\xec\x9d\xb4 \xec\xa0\x81\xec\x9d\x84 \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8f\x84 \xeb\xb3\xb4\xec\x83\x81\xec\x9d\x84 \xec\xa4\x98\xec\x84\x9c \xec\x95\x88\xec\xa0\x95\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\x8f\x99\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83 \xec\xb2\x98\xeb\x9f\xbc \xeb\xb3\xb4\xec\x9d\xb4\xea\xb2\x8c \xeb\xa7\x8c\xeb\x93\xad\xeb\x8b\x88\xeb\x8b\xa4.\n        stable_reward = 1. / self.screen_height if action == 1 else 0\n        # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\xb4 \xec\xa2\x85\xeb\xa3\x8c\xeb\x90\x90\xeb\x8a\x94\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\x8b\xa8\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9e\x90\xeb\x8f\x99\xec\xb0\xa8\xec\x99\x80 \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\xb4 \xec\xb6\xa9\xeb\x8f\x8c\xed\x96\x88\xeb\x8a\x94\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x8c\xec\x95\x85\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        gameover = self._is_gameover()\n\n        if gameover:\n            # \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x97\x90 \xec\xb6\xa9\xeb\x8f\x8c\xed\x95\x9c \xea\xb2\xbd\xec\x9a\xb0 -2\xec\xa0\x90\xec\x9d\x84 \xeb\xb3\xb4\xec\x83\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\xa4\x8d\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\xb4 \xeb\x91\x90 \xea\xb0\x9c\xec\x9d\xb4\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n            # \xec\x9e\xa5\xec\x95\xa0\xeb\xac\xbc\xec\x9d\x84 \xed\x9a\x8c\xed\x94\xbc\xed\x96\x88\xec\x9d\x84 \xeb\x95\x8c \xeb\xb3\xb4\xec\x83\x81\xec\x9d\x84 \xec\xa3\xbc\xec\xa7\x80 \xec\x95\x8a\xea\xb3\xa0, \xec\xb6\xa9\xeb\x8f\x8c\xed\x95\x9c \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\xa7\x8c -1\xec\xa0\x90\xec\x9d\x84 \xec\xa3\xbc\xec\x96\xb4\xeb\x8f\x84 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n            reward = -2\n        else:\n            reward = escape_reward + stable_reward\n            self.current_reward += reward\n\n        if self.show_game:\n            self._draw_screen()\n\n        return self._get_state(), reward, gameover\n'"
12 - DQN/model.py,16,"b""# \xec\x95\x8c\xed\x8c\x8c\xea\xb3\xa0\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xa0 \xea\xb5\xac\xea\xb8\x80\xec\x9d\x98 \xeb\x94\xa5\xeb\xa7\x88\xec\x9d\xb8\xeb\x93\x9c\xec\x9d\x98 \xeb\x85\xbc\xeb\xac\xb8\xec\x9d\x84 \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x9c DQN \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n# http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html\nimport tensorflow as tf\nimport numpy as np\nimport random\nfrom collections import deque\n\n\nclass DQN:\n    # \xed\x95\x99\xec\x8a\xb5\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\x96\xbc\xeb\xa7\x88\xeb\x82\x98 \xeb\xa7\x8e\xec\x9d\xb4 \xec\xa0\x80\xec\x9e\xa5\xed\x95\xb4\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0\xec\xa7\x80\xeb\xa5\xbc \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    # (\xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xea\xb2\xb0\xea\xb3\xbc = \xea\xb2\x8c\xec\x9e\x84\xed\x8c\x90\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c + \xec\xb7\xa8\xed\x95\x9c \xec\x95\xa1\xec\x85\x98 + \xeb\xa6\xac\xec\x9b\x8c\xeb\x93\x9c + \xec\xa2\x85\xeb\xa3\x8c\xec\x97\xac\xeb\xb6\x80)\n    REPLAY_MEMORY = 10000\n    # \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c \xec\x82\xac\xec\x9a\xa9/\xea\xb3\x84\xec\x82\xb0\xed\x95\xa0 \xec\x83\x81\xed\x83\x9c\xea\xb0\x92(\xec\xa0\x95\xed\x99\x95\xed\x9e\x88\xeb\x8a\x94 replay memory)\xec\x9d\x98 \xea\xb0\xaf\xec\x88\x98\xeb\xa5\xbc \xec\xa0\x95\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    BATCH_SIZE = 32\n    # \xea\xb3\xbc\xea\xb1\xb0\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xea\xb0\x80\xec\xa4\x91\xec\xb9\x98\xeb\xa5\xbc \xec\xa4\x84\xec\x9d\xb4\xeb\x8a\x94 \xec\x97\xad\xed\x95\xa0\xec\x9d\x84 \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n    GAMMA = 0.99\n    # \xed\x95\x9c \xeb\xb2\x88\xec\x97\x90 \xeb\xb3\xbc \xec\xb4\x9d \xed\x94\x84\xeb\xa0\x88\xec\x9e\x84 \xec\x88\x98 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n    # \xec\x95\x9e\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xea\xb9\x8c\xec\xa7\x80 \xea\xb3\xa0\xeb\xa0\xa4\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xa8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n    STATE_LEN = 4\n\n    def __init__(self, session, width, height, n_action):\n        self.session = session\n        self.n_action = n_action\n        self.width = width\n        self.height = height\n        # \xea\xb2\x8c\xec\x9e\x84 \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xeb\xa9\x94\xeb\xaa\xa8\xeb\xa6\xac\n        self.memory = deque()\n        # \xed\x98\x84\xec\x9e\xac \xea\xb2\x8c\xec\x9e\x84\xed\x8c\x90\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\n        self.state = None\n\n        # \xea\xb2\x8c\xec\x9e\x84\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xeb\xb0\x9b\xec\x9d\x84 \xeb\xb3\x80\xec\x88\x98\n        # [\xea\xb2\x8c\xec\x9e\x84\xed\x8c\x90\xec\x9d\x98 \xea\xb0\x80\xeb\xa1\x9c \xed\x81\xac\xea\xb8\xb0, \xea\xb2\x8c\xec\x9e\x84\xed\x8c\x90\xec\x9d\x98 \xec\x84\xb8\xeb\xa1\x9c \xed\x81\xac\xea\xb8\xb0, \xea\xb2\x8c\xec\x9e\x84 \xec\x83\x81\xed\x83\x9c\xec\x9d\x98 \xea\xb0\xaf\xec\x88\x98(\xed\x98\x84\xec\x9e\xac+\xea\xb3\xbc\xea\xb1\xb0+\xea\xb3\xbc\xea\xb1\xb0..)]\n        self.input_X = tf.placeholder(tf.float32, [None, width, height, self.STATE_LEN])\n        # \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xeb\x82\xb8 \xec\x95\xa1\xec\x85\x98\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. 0, 1, 2 ..\n        self.input_A = tf.placeholder(tf.int64, [None])\n        # \xec\x86\x90\xec\x8b\xa4\xea\xb0\x92\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\x8a\x94\xeb\x8d\xb0 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. train \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x98\xec\x84\xb8\xec\x9a\x94.\n        self.input_Y = tf.placeholder(tf.float32, [None])\n\n        self.Q = self._build_network('main')\n        self.cost, self.train_op = self._build_op()\n\n        # \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xeb\x8d\x94 \xec\x9e\x98 \xeb\x90\x98\xea\xb2\x8c \xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4,\n        # \xec\x86\x90\xec\x8b\xa4\xea\xb0\x92 \xea\xb3\x84\xec\x82\xb0\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8a\x94 \xed\x83\x80\xea\xb2\x9f(\xec\x8b\xa4\xec\xb8\xa1\xea\xb0\x92)\xec\x9d\x98 Q value\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\x8a\x94 \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9d\x84 \xeb\x94\xb0\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\n        self.target_Q = self._build_network('target')\n\n    def _build_network(self, name):\n        with tf.variable_scope(name):\n            model = tf.layers.conv2d(self.input_X, 32, [4, 4], padding='same', activation=tf.nn.relu)\n            model = tf.layers.conv2d(model, 64, [2, 2], padding='same', activation=tf.nn.relu)\n            model = tf.contrib.layers.flatten(model)\n            model = tf.layers.dense(model, 512, activation=tf.nn.relu)\n\n            Q = tf.layers.dense(model, self.n_action, activation=None)\n\n        return Q\n\n    def _build_op(self):\n        # DQN \xec\x9d\x98 \xec\x86\x90\xec\x8b\xa4 \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xeb\xb6\x80\xeb\xb6\x84\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. \xeb\x8b\xa4\xec\x9d\x8c \xec\x88\x98\xec\x8b\x9d\xec\x9d\x84 \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x98\xec\x84\xb8\xec\x9a\x94.\n        # Perform a gradient descent step on (y_j-Q(\xc3\xb0_j,a_j;\xce\xb8))^2\n        one_hot = tf.one_hot(self.input_A, self.n_action, 1.0, 0.0)\n        Q_value = tf.reduce_sum(tf.multiply(self.Q, one_hot), axis=1)\n        cost = tf.reduce_mean(tf.square(self.input_Y - Q_value))\n        train_op = tf.train.AdamOptimizer(1e-6).minimize(cost)\n\n        return cost, train_op\n\n    # refer: https://github.com/hunkim/ReinforcementZeroToAll/\n    def update_target_network(self):\n        copy_op = []\n\n        main_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='main')\n        target_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target')\n\n        # \xed\x95\x99\xec\x8a\xb5 \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9d\x98 \xeb\xb3\x80\xec\x88\x98\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xed\x83\x80\xea\xb2\x9f \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb3\xb5\xec\x82\xac\xed\x95\xb4\xec\x84\x9c \xed\x83\x80\xea\xb2\x9f \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xec\xb5\x9c\xec\x8b\xa0\xec\x9c\xbc\xeb\xa1\x9c \xec\x97\x85\xeb\x8d\xb0\xec\x9d\xb4\xed\x8a\xb8\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        for main_var, target_var in zip(main_vars, target_vars):\n            copy_op.append(target_var.assign(main_var.value()))\n\n        self.session.run(copy_op)\n\n    def get_action(self):\n        Q_value = self.session.run(self.Q,\n                                   feed_dict={self.input_X: [self.state]})\n\n        action = np.argmax(Q_value[0])\n\n        return action\n\n    def init_state(self, state):\n        # \xed\x98\x84\xec\x9e\xac \xea\xb2\x8c\xec\x9e\x84\xed\x8c\x90\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xec\xb4\x88\xea\xb8\xb0\xed\x99\x94\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4. \xec\x95\x9e\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xea\xb9\x8c\xec\xa7\x80 \xea\xb3\xa0\xeb\xa0\xa4\xed\x95\x9c \xec\x8a\xa4\xed\x83\x9d\xec\x9c\xbc\xeb\xa1\x9c \xeb\x90\x98\xec\x96\xb4 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        state = [state for _ in range(self.STATE_LEN)]\n        # axis=2 \xeb\x8a\x94 input_X \xec\x9d\x98 \xea\xb0\x92\xec\x9d\xb4 \xeb\x8b\xa4\xec\x9d\x8c\xec\xb2\x98\xeb\x9f\xbc \xeb\xa7\x88\xec\xa7\x80\xeb\xa7\x89 \xec\xb0\xa8\xec\x9b\x90\xec\x9c\xbc\xeb\xa1\x9c \xec\x8c\x93\xec\x95\x84\xec\x98\xac\xeb\xa6\xb0 \xed\x98\x95\xed\x83\x9c\xeb\xa1\x9c \xeb\xa7\x8c\xeb\x93\xa4\xec\x97\x88\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.\n        # \xec\x9d\xb4\xeb\xa0\x87\xea\xb2\x8c \xed\x95\xb4\xec\x95\xbc \xec\xbb\xa8\xeb\xb3\xbc\xeb\xa3\xa8\xec\x85\x98 \xeb\xa0\x88\xec\x9d\xb4\xec\x96\xb4\xeb\xa5\xbc \xec\x86\x90\xec\x89\xbd\xea\xb2\x8c \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xa0 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        # self.input_X = tf.placeholder(tf.float32, [None, width, height, self.STATE_LEN])\n        self.state = np.stack(state, axis=2)\n\n    def remember(self, state, action, reward, terminal):\n        # \xed\x95\x99\xec\x8a\xb5\xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa1\x9c \xed\x98\x84\xec\x9e\xac\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa7\x8c\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x8c, \xea\xb3\xbc\xea\xb1\xb0\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xea\xb9\x8c\xec\xa7\x80 \xea\xb3\xa0\xeb\xa0\xa4\xed\x95\x98\xec\x97\xac \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xec\x98\x80\xea\xb3\xa0,\n        # \xec\x9d\xb4 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 \xea\xb3\xbc\xea\xb1\xb0 3\xeb\xb2\x88 + \xed\x98\x84\xec\x9e\xac = \xec\xb4\x9d 4\xeb\xb2\x88\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xec\x98\x80\xec\x9c\xbc\xeb\xa9\xb0,\n        # \xec\x83\x88\xeb\xa1\x9c\xec\x9a\xb4 \xec\x83\x81\xed\x83\x9c\xea\xb0\x80 \xeb\x93\xa4\xec\x96\xb4\xec\x99\x94\xec\x9d\x84 \xeb\x95\x8c, \xea\xb0\x80\xec\x9e\xa5 \xec\x98\xa4\xeb\x9e\x98\xeb\x90\x9c \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xec\xa0\x9c\xea\xb1\xb0\xed\x95\x98\xea\xb3\xa0 \xec\x83\x88\xeb\xa1\x9c\xec\x9a\xb4 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xeb\x84\xa3\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        next_state = np.reshape(state, (self.width, self.height, 1))\n        next_state = np.append(self.state[:, :, 1:], next_state, axis=2)\n\n        # \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xea\xb2\xb0\xea\xb3\xbc, \xec\xa6\x89, \xec\x95\xa1\xec\x85\x98\xec\x9c\xbc\xeb\xa1\x9c \xec\x96\xbb\xec\x96\xb4\xec\xa7\x84 \xec\x83\x81\xed\x83\x9c\xec\x99\x80 \xeb\xb3\xb4\xec\x83\x81\xeb\x93\xb1\xec\x9d\x84 \xeb\xa9\x94\xeb\xaa\xa8\xeb\xa6\xac\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        self.memory.append((self.state, next_state, action, reward, terminal))\n\n        # \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xea\xb2\xb0\xea\xb3\xbc\xec\x9d\x98 \xea\xb0\xaf\xec\x88\x98\xeb\xa5\xbc \xec\xa0\x9c\xed\x95\x9c\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\n        if len(self.memory) > self.REPLAY_MEMORY:\n            self.memory.popleft()\n\n        self.state = next_state\n\n    def _sample_memory(self):\n        sample_memory = random.sample(self.memory, self.BATCH_SIZE)\n\n        state = [memory[0] for memory in sample_memory]\n        next_state = [memory[1] for memory in sample_memory]\n        action = [memory[2] for memory in sample_memory]\n        reward = [memory[3] for memory in sample_memory]\n        terminal = [memory[4] for memory in sample_memory]\n\n        return state, next_state, action, reward, terminal\n\n    def train(self):\n        # \xea\xb2\x8c\xec\x9e\x84 \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb4\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c \xeb\xa9\x94\xeb\xaa\xa8\xeb\xa6\xac\xec\x97\x90\xec\x84\x9c \xeb\xb0\xb0\xec\xb9\x98 \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\xa7\x8c\xed\x81\xbc\xec\x9d\x84 \xec\x83\x98\xed\x94\x8c\xeb\xa7\x81\xed\x95\x98\xec\x97\xac \xea\xb0\x80\xec\xa0\xb8\xec\x98\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        state, next_state, action, reward, terminal = self._sample_memory()\n\n        # \xed\x95\x99\xec\x8a\xb5\xec\x8b\x9c \xeb\x8b\xa4\xec\x9d\x8c \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xed\x83\x80\xea\xb2\x9f \xeb\x84\xa4\xed\x8a\xb8\xec\x9b\x8d\xec\x97\x90 \xeb\x84\xa3\xec\x96\xb4 target Q value\xeb\xa5\xbc \xea\xb5\xac\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4\n        target_Q_value = self.session.run(self.target_Q,\n                                          feed_dict={self.input_X: next_state})\n\n        # DQN \xec\x9d\x98 \xec\x86\x90\xec\x8b\xa4 \xed\x95\xa8\xec\x88\x98\xec\x97\x90 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa0 \xed\x95\xb5\xec\x8b\xac\xec\xa0\x81\xec\x9d\xb8 \xea\xb0\x92\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\x98\xeb\x8a\x94 \xeb\xb6\x80\xeb\xb6\x84\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. \xeb\x8b\xa4\xec\x9d\x8c \xec\x88\x98\xec\x8b\x9d\xec\x9d\x84 \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x98\xec\x84\xb8\xec\x9a\x94.\n        # if episode is terminates at step j+1 then r_j\n        # otherwise r_j + \xce\xb3*max_a'Q(\xc3\xb0_(j+1),a';\xce\xb8')\n        # input_Y \xec\x97\x90 \xeb\x93\xa4\xec\x96\xb4\xea\xb0\x88 \xea\xb0\x92\xeb\x93\xa4\xec\x9d\x84 \xea\xb3\x84\xec\x82\xb0\xed\x95\xb4\xec\x84\x9c \xeb\x84\xa3\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\n        Y = []\n        for i in range(self.BATCH_SIZE):\n            if terminal[i]:\n                Y.append(reward[i])\n            else:\n                Y.append(reward[i] + self.GAMMA * np.max(target_Q_value[i]))\n\n        self.session.run(self.train_op,\n                         feed_dict={\n                             self.input_X: state,\n                             self.input_A: action,\n                             self.input_Y: Y\n                         })\n"""
10 - RNN/ChatBot/chat.py,3,"b'import tensorflow as tf\nimport numpy as np\nimport math\nimport sys\n\nfrom config import FLAGS\nfrom model import Seq2Seq\nfrom dialog import Dialog\n\n\nclass ChatBot:\n\n    def __init__(self, voc_path, train_dir):\n        self.dialog = Dialog()\n        self.dialog.load_vocab(voc_path)\n\n        self.model = Seq2Seq(self.dialog.vocab_size)\n\n        self.sess = tf.Session()\n        ckpt = tf.train.get_checkpoint_state(train_dir)\n        self.model.saver.restore(self.sess, ckpt.model_checkpoint_path)\n\n    def run(self):\n        sys.stdout.write(""> "")\n        sys.stdout.flush()\n        line = sys.stdin.readline()\n\n        while line:\n            print(self._get_replay(line.strip()))\n\n            sys.stdout.write(""\\n> "")\n            sys.stdout.flush()\n\n            line = sys.stdin.readline()\n\n    def _decode(self, enc_input, dec_input):\n        if type(dec_input) is np.ndarray:\n            dec_input = dec_input.tolist()\n\n        # TODO: \xea\xb5\xac\xea\xb8\x80\xec\xb2\x98\xeb\x9f\xbc \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4 \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc \xec\xa0\x81\xeb\x8b\xb9\xed\x95\x9c \xeb\xb2\x84\xed\x82\xb7\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\x84\x9c \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d\n        input_len = int(math.ceil((len(enc_input) + 1) * 1.5))\n\n        enc_input, dec_input, _ = self.dialog.transform(enc_input, dec_input,\n                                                        input_len,\n                                                        FLAGS.max_decode_len)\n\n        return self.model.predict(self.sess, [enc_input], [dec_input])\n\n    def _get_replay(self, msg):\n        enc_input = self.dialog.tokenizer(msg)\n        enc_input = self.dialog.tokens_to_ids(enc_input)\n        dec_input = []\n\n        # TODO: \xea\xb5\xac\xea\xb8\x80\xec\xb2\x98\xeb\x9f\xbc Seq2Seq2 \xeb\xaa\xa8\xeb\x8d\xb8 \xec\x95\x88\xec\x9d\x98 RNN \xec\x85\x80\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xeb\xb6\x80\xeb\xb6\x84\xec\x97\x90 \xeb\x84\xa3\xec\x9d\x84\xea\xb2\x83\n        #       \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94\xec\x85\x80\xec\x9d\x98 \xec\x83\x81\xed\x83\x9c\xeb\xa5\xbc \xec\x88\x9c\xec\xb0\xa8\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xec\x84\xb1\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\xa8\n        #       \xec\x97\xac\xea\xb8\xb0\xec\x84\x9c\xeb\x8a\x94 \xec\xb5\x9c\xec\xa2\x85 \xec\xb6\x9c\xeb\xa0\xa5\xea\xb0\x92\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xec\x97\xac \xec\xa0\x90\xec\xa7\x84\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4\xeb\xa5\xbc \xeb\xa7\x8c\xeb\x93\x9c\xeb\x8a\x94 \xeb\xb0\xa9\xec\x8b\x9d\xec\x9d\x84 \xec\x82\xac\xec\x9a\xa9\n        #       \xeb\x8b\xa4\xeb\xa7\x8c \xec\x83\x81\xed\x99\xa9\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc\xec\x84\x9c\xeb\x8a\x94 \xec\x9d\xb4\xeb\x9f\xb0 \xeb\xb0\xa9\xec\x8b\x9d\xec\x9d\xb4 \xeb\x8d\x94 \xec\x9c\xa0\xec\x97\xb0\xed\x95\xa0 \xec\x88\x98\xeb\x8f\x84 \xec\x9e\x88\xec\x9d\x84 \xeb\x93\xaf\n        curr_seq = 0\n        for i in range(FLAGS.max_decode_len):\n            outputs = self._decode(enc_input, dec_input)\n            if self.dialog.is_eos(outputs[0][curr_seq]):\n                break\n            elif self.dialog.is_defined(outputs[0][curr_seq]) is not True:\n                dec_input.append(outputs[0][curr_seq])\n                curr_seq += 1\n\n        reply = self.dialog.decode([dec_input], True)\n\n        return reply\n\n\ndef main(_):\n    print(""\xea\xb9\xa8\xec\x96\xb4\xeb\x82\x98\xeb\x8a\x94 \xec\xa4\x91 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9e\xa0\xec\x8b\x9c\xeb\xa7\x8c \xea\xb8\xb0\xeb\x8b\xa4\xeb\xa0\xa4\xec\xa3\xbc\xec\x84\xb8\xec\x9a\x94...\\n"")\n\n    chatbot = ChatBot(FLAGS.voc_path, FLAGS.train_dir)\n    chatbot.run()\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
10 - RNN/ChatBot/config.py,14,"b'import tensorflow as tf\n\n\ntf.app.flags.DEFINE_string(""train_dir"", ""./model"", ""\xed\x95\x99\xec\x8a\xb5\xed\x95\x9c \xec\x8b\xa0\xea\xb2\xbd\xeb\xa7\x9d\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xed\x8f\xb4\xeb\x8d\x94"")\ntf.app.flags.DEFINE_string(""log_dir"", ""./logs"", ""\xeb\xa1\x9c\xea\xb7\xb8\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\xa0 \xed\x8f\xb4\xeb\x8d\x94"")\ntf.app.flags.DEFINE_string(""ckpt_name"", ""conversation.ckpt"", ""\xec\xb2\xb4\xed\x81\xac\xed\x8f\xac\xec\x9d\xb8\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xeb\xaa\x85"")\n\ntf.app.flags.DEFINE_boolean(""train"", False, ""\xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xec\xa7\x84\xed\x96\x89\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."")\ntf.app.flags.DEFINE_boolean(""test"", True, ""\xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."")\ntf.app.flags.DEFINE_boolean(""data_loop"", True, ""\xec\x9e\x91\xec\x9d\x80 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x85\x8b\xec\x9d\x84 \xec\x8b\xa4\xed\x97\x98\xed\x95\xb4\xeb\xb3\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xec\x82\xac\xec\x9a\xa9\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."")\ntf.app.flags.DEFINE_integer(""batch_size"", 100, ""\xeb\xaf\xb8\xeb\x8b\x88 \xeb\xb0\xb0\xec\xb9\x98 \xed\x81\xac\xea\xb8\xb0"")\ntf.app.flags.DEFINE_integer(""epoch"", 1000, ""\xec\xb4\x9d \xed\x95\x99\xec\x8a\xb5 \xeb\xb0\x98\xeb\xb3\xb5 \xed\x9a\x9f\xec\x88\x98"")\n\ntf.app.flags.DEFINE_string(""data_path"", ""./data/chat.log"", ""\xeb\x8c\x80\xed\x99\x94 \xed\x8c\x8c\xec\x9d\xbc \xec\x9c\x84\xec\xb9\x98"")\ntf.app.flags.DEFINE_string(""voc_path"", ""./data/chat.voc"", ""\xec\x96\xb4\xed\x9c\x98 \xec\x82\xac\xec\xa0\x84 \xed\x8c\x8c\xec\x9d\xbc \xec\x9c\x84\xec\xb9\x98"")\ntf.app.flags.DEFINE_boolean(""voc_test"", False, ""\xec\x96\xb4\xed\x9c\x98 \xec\x82\xac\xec\xa0\x84\xec\x9d\x84 \xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."")\ntf.app.flags.DEFINE_boolean(""voc_build"", False, ""\xec\xa3\xbc\xec\x96\xb4\xec\xa7\x84 \xeb\x8c\x80\xed\x99\x94 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\xb4 \xec\x96\xb4\xed\x9c\x98 \xec\x82\xac\xec\xa0\x84\xec\x9d\x84 \xec\x9e\x91\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."")\n\ntf.app.flags.DEFINE_integer(""max_decode_len"", 20, ""\xec\xb5\x9c\xeb\x8c\x80 \xeb\x94\x94\xec\xbd\x94\xeb\x8d\x94 \xec\x85\x80 \xed\x81\xac\xea\xb8\xb0 = \xec\xb5\x9c\xeb\x8c\x80 \xeb\x8b\xb5\xeb\xb3\x80 \xed\x81\xac\xea\xb8\xb0."")\n\n\nFLAGS = tf.app.flags.FLAGS\n'"
10 - RNN/ChatBot/dialog.py,1,"b'# \xec\x96\xb4\xed\x9c\x98 \xec\x82\xac\xec\xa0\x84\xea\xb3\xbc \xec\x9b\x8c\xeb\x93\x9c \xec\x9e\x84\xeb\xb2\xa0\xeb\x94\xa9\xec\x9d\x84 \xeb\xa7\x8c\xeb\x93\xa4\xea\xb3\xa0, \xed\x95\x99\xec\x8a\xb5\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xeb\x8c\x80\xed\x99\x94 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xec\x9d\xbd\xec\x96\xb4\xeb\x93\xa4\xec\x9d\xb4\xeb\x8a\x94 \xec\x9c\xa0\xed\x8b\xb8\xeb\xa6\xac\xed\x8b\xb0\xeb\x93\xa4\xec\x9d\x98 \xeb\xaa\xa8\xec\x9d\x8c\nimport tensorflow as tf\nimport numpy as np\nimport re\n\nfrom config import FLAGS\n\n\nclass Dialog():\n\n    _PAD_ = ""_PAD_""  # \xeb\xb9\x88\xec\xb9\xb8 \xec\xb1\x84\xec\x9a\xb0\xeb\x8a\x94 \xec\x8b\xac\xeb\xb3\xbc\n    _STA_ = ""_STA_""  # \xeb\x94\x94\xec\xbd\x94\xeb\x93\x9c \xec\x9e\x85\xeb\xa0\xa5 \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4\xec\x9d\x98 \xec\x8b\x9c\xec\x9e\x91 \xec\x8b\xac\xeb\xb3\xbc\n    _EOS_ = ""_EOS_""  # \xeb\x94\x94\xec\xbd\x94\xeb\x93\x9c \xec\x9e\x85\xec\xb6\x9c\xeb\xa0\xa5 \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4\xec\x9d\x98 \xec\xa2\x85\xeb\xa3\x8c \xec\x8b\xac\xeb\xb3\xbc\n    _UNK_ = ""_UNK_""  # \xec\x82\xac\xec\xa0\x84\xec\x97\x90 \xec\x97\x86\xeb\x8a\x94 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xeb\x82\x98\xed\x83\x80\xeb\x82\xb4\xeb\x8a\x94 \xec\x8b\xac\xeb\xb3\xbc\n\n    _PAD_ID_ = 0\n    _STA_ID_ = 1\n    _EOS_ID_ = 2\n    _UNK_ID_ = 3\n    _PRE_DEFINED_ = [_PAD_ID_, _STA_ID_, _EOS_ID_, _UNK_ID_]\n\n    def __init__(self):\n        self.vocab_list = []\n        self.vocab_dict = {}\n        self.vocab_size = 0\n        self.examples = []\n\n        self._index_in_epoch = 0\n\n    def decode(self, indices, string=False):\n        tokens = [[self.vocab_list[i] for i in dec] for dec in indices]\n\n        if string:\n            return self._decode_to_string(tokens[0])\n        else:\n            return tokens\n\n    def _decode_to_string(self, tokens):\n        text = \' \'.join(tokens)\n        return text.strip()\n\n    def cut_eos(self, indices):\n        eos_idx = indices.index(self._EOS_ID_)\n        return indices[:eos_idx]\n\n    def is_eos(self, voc_id):\n        return voc_id == self._EOS_ID_\n\n    def is_defined(self, voc_id):\n        return voc_id in self._PRE_DEFINED_\n\n    def _max_len(self, batch_set):\n        max_len_input = 0\n        max_len_output = 0\n\n        for i in range(0, len(batch_set), 2):\n            len_input = len(batch_set[i])\n            len_output = len(batch_set[i+1])\n            if len_input > max_len_input:\n                max_len_input = len_input\n            if len_output > max_len_output:\n                max_len_output = len_output\n\n        return max_len_input, max_len_output + 1\n\n    def _pad(self, seq, max_len, start=None, eos=None):\n        if start:\n            padded_seq = [self._STA_ID_] + seq\n        elif eos:\n            padded_seq = seq + [self._EOS_ID_]\n        else:\n            padded_seq = seq\n\n        if len(padded_seq) < max_len:\n            return padded_seq + ([self._PAD_ID_] * (max_len - len(padded_seq)))\n        else:\n            return padded_seq\n\n    def _pad_left(self, seq, max_len):\n        if len(seq) < max_len:\n            return ([self._PAD_ID_] * (max_len - len(seq))) + seq\n        else:\n            return seq\n\n    def transform(self, input, output, input_max, output_max):\n        enc_input = self._pad(input, input_max)\n        dec_input = self._pad(output, output_max, start=True)\n        target = self._pad(output, output_max, eos=True)\n\n        # \xea\xb5\xac\xea\xb8\x80 \xeb\xb0\xa9\xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xec\x9e\x85\xeb\xa0\xa5\xec\x9d\x84 \xec\x9d\xb8\xec\xbd\x94\xeb\x8d\x94\xec\x97\x90 \xec\x97\xad\xec\x88\x9c\xec\x9c\xbc\xeb\xa1\x9c \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4.\n        enc_input.reverse()\n\n        enc_input = np.eye(self.vocab_size)[enc_input]\n        dec_input = np.eye(self.vocab_size)[dec_input]\n\n        return enc_input, dec_input, target\n\n    def next_batch(self, batch_size):\n        enc_input = []\n        dec_input = []\n        target = []\n\n        start = self._index_in_epoch\n\n        if self._index_in_epoch + batch_size < len(self.examples) - 1:\n            self._index_in_epoch = self._index_in_epoch + batch_size\n        else:\n            self._index_in_epoch = 0\n\n        batch_set = self.examples[start:start+batch_size]\n\n        # \xec\x9e\x91\xec\x9d\x80 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x85\x8b\xec\x9d\x84 \xec\x8b\xa4\xed\x97\x98\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xea\xbc\xbc\xec\x88\x98\n        # \xed\x98\x84\xec\x9e\xac\xec\x9d\x98 \xeb\x8b\xb5\xeb\xb3\x80\xec\x9d\x84 \xeb\x8b\xa4\xec\x9d\x8c \xec\xa7\x88\xeb\xac\xb8\xec\x9d\x98 \xec\xa7\x88\xeb\xac\xb8\xec\x9c\xbc\xeb\xa1\x9c \xed\x95\x98\xea\xb3\xa0, \xeb\x8b\xa4\xec\x9d\x8c \xec\xa7\x88\xeb\xac\xb8\xec\x9d\x84 \xeb\x8b\xb5\xeb\xb3\x80\xec\x9c\xbc\xeb\xa1\x9c \xed\x95\x98\xec\x97\xac \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xeb\x8a\x98\xeb\xa6\xb0\xeb\x8b\xa4.\n        if FLAGS.data_loop is True:\n            batch_set = batch_set + batch_set[1:] + batch_set[0:1]\n\n        # TODO: \xea\xb5\xac\xea\xb8\x80\xec\xb2\x98\xeb\x9f\xbc \xeb\xb2\x84\xed\x82\xb7\xec\x9d\x84 \xec\x9d\xb4\xec\x9a\xa9\xed\x95\x9c \xeb\xb0\xa9\xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb3\x80\xea\xb2\xbd\n        # \xea\xb0\x84\xeb\x8b\xa8\xed\x95\x98\xea\xb2\x8c \xeb\xa7\x8c\xeb\x93\xa4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 \xea\xb5\xac\xea\xb8\x80\xec\xb2\x98\xeb\x9f\xbc \xeb\xb2\x84\xed\x82\xb7\xec\x9d\x84 \xec\x93\xb0\xec\xa7\x80 \xec\x95\x8a\xea\xb3\xa0 \xea\xb0\x99\xec\x9d\x80 \xeb\xb0\xb0\xec\xb9\x98\xeb\x8a\x94 \xea\xb0\x99\xec\x9d\x80 \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\xa5\xbc \xec\x82\xac\xec\x9a\xa9\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xeb\xa7\x8c\xeb\x93\xac\n        max_len_input, max_len_output = self._max_len(batch_set)\n\n        for i in range(0, len(batch_set) - 1, 2):\n            enc, dec, tar = self.transform(batch_set[i], batch_set[i+1],\n                                           max_len_input, max_len_output)\n\n            enc_input.append(enc)\n            dec_input.append(dec)\n            target.append(tar)\n\n        return enc_input, dec_input, target\n\n    def tokens_to_ids(self, tokens):\n        ids = []\n\n        for t in tokens:\n            if t in self.vocab_dict:\n                ids.append(self.vocab_dict[t])\n            else:\n                ids.append(self._UNK_ID_)\n\n        return ids\n\n    def ids_to_tokens(self, ids):\n        tokens = []\n\n        for i in ids:\n            tokens.append(self.vocab_list[i])\n\n        return tokens\n\n    def load_examples(self, data_path):\n        self.examples = []\n\n        with open(data_path, \'r\', encoding=\'utf-8\') as content_file:\n            for line in content_file:\n                tokens = self.tokenizer(line.strip())\n                ids = self.tokens_to_ids(tokens)\n                self.examples.append(ids)\n\n    def tokenizer(self, sentence):\n        # \xea\xb3\xb5\xeb\xb0\xb1\xec\x9c\xbc\xeb\xa1\x9c \xeb\x82\x98\xeb\x88\x84\xea\xb3\xa0 \xed\x8a\xb9\xec\x88\x98\xeb\xac\xb8\xec\x9e\x90\xeb\x8a\x94 \xeb\x94\xb0\xeb\xa1\x9c \xeb\xbd\x91\xec\x95\x84\xeb\x82\xb8\xeb\x8b\xa4.\n        words = []\n        _TOKEN_RE_ = re.compile(""([.,!?\\""\':;)(])"")\n\n        for fragment in sentence.strip().split():\n            words.extend(_TOKEN_RE_.split(fragment))\n\n        return [w for w in words if w]\n\n    def build_vocab(self, data_path, vocab_path):\n        with open(data_path, \'r\', encoding=\'utf-8\') as content_file:\n            content = content_file.read()\n            words = self.tokenizer(content)\n            words = list(set(words))\n\n        with open(vocab_path, \'w\') as vocab_file:\n            for w in words:\n                vocab_file.write(w + \'\\n\')\n\n    def load_vocab(self, vocab_path):\n        self.vocab_list = self._PRE_DEFINED_ + []\n\n        with open(vocab_path, \'r\', encoding=\'utf-8\') as vocab_file:\n            for line in vocab_file:\n                self.vocab_list.append(line.strip())\n\n        # {\'_PAD_\': 0, \'_STA_\': 1, \'_EOS_\': 2, \'_UNK_\': 3, \'Hello\': 4, \'World\': 5, ...}\n        self.vocab_dict = {n: i for i, n in enumerate(self.vocab_list)}\n        self.vocab_size = len(self.vocab_list)\n\n\ndef main(_):\n    dialog = Dialog()\n\n    if FLAGS.data_path and FLAGS.voc_test:\n        print(""\xeb\x8b\xa4\xec\x9d\x8c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa1\x9c \xec\x96\xb4\xed\x9c\x98 \xec\x82\xac\xec\xa0\x84\xec\x9d\x84 \xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."", FLAGS.data_path)\n        dialog.load_vocab(FLAGS.voc_path)\n        dialog.load_examples(FLAGS.data_path)\n\n        enc, dec, target = dialog.next_batch(10)\n        print(target)\n        enc, dec, target = dialog.next_batch(10)\n        print(target)\n\n    elif FLAGS.data_path and FLAGS.voc_build:\n        print(""\xeb\x8b\xa4\xec\x9d\x8c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x97\x90\xec\x84\x9c \xec\x96\xb4\xed\x9c\x98 \xec\x82\xac\xec\xa0\x84\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4."", FLAGS.data_path)\n        dialog.build_vocab(FLAGS.data_path, FLAGS.voc_path)\n\n    elif FLAGS.voc_test:\n        dialog.load_vocab(FLAGS.voc_path)\n        print(dialog.vocab_dict)\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
10 - RNN/ChatBot/model.py,28,"b'# \xec\x9e\x90\xec\x84\xb8\xed\x95\x9c \xec\x84\xa4\xeb\xaa\x85\xec\x9d\x80 \xec\x83\x81\xec\x9c\x84 \xed\x8f\xb4\xeb\x8d\x94\xec\x9d\x98 03 - Seq2Seq.py \xeb\x93\xb1\xec\x97\x90\xec\x84\x9c \xec\xb0\xbe\xec\x9c\xbc\xec\x8b\xa4 \xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\nimport tensorflow as tf\n\n\n# Seq2Seq \xea\xb8\xb0\xeb\xb3\xb8 \xed\x81\xb4\xeb\x9e\x98\xec\x8a\xa4\nclass Seq2Seq:\n\n    logits = None\n    outputs = None\n    cost = None\n    train_op = None\n\n    def __init__(self, vocab_size, n_hidden=128, n_layers=3):\n        self.learning_late = 0.001\n\n        self.vocab_size = vocab_size\n        self.n_hidden = n_hidden\n        self.n_layers = n_layers\n\n        self.enc_input = tf.placeholder(tf.float32, [None, None, self.vocab_size])\n        self.dec_input = tf.placeholder(tf.float32, [None, None, self.vocab_size])\n        self.targets = tf.placeholder(tf.int64, [None, None])\n\n        self.weights = tf.Variable(tf.ones([self.n_hidden, self.vocab_size]), name=""weights"")\n        self.bias = tf.Variable(tf.zeros([self.vocab_size]), name=""bias"")\n        self.global_step = tf.Variable(0, trainable=False, name=""global_step"")\n\n        self._build_model()\n\n        self.saver = tf.train.Saver(tf.global_variables())\n\n    def _build_model(self):\n        # self.enc_input = tf.transpose(self.enc_input, [1, 0, 2])\n        # self.dec_input = tf.transpose(self.dec_input, [1, 0, 2])\n\n        enc_cell, dec_cell = self._build_cells()\n\n        with tf.variable_scope(\'encode\'):\n            outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, self.enc_input, dtype=tf.float32)\n\n        with tf.variable_scope(\'decode\'):\n            outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, self.dec_input, dtype=tf.float32,\n                                                    initial_state=enc_states)\n\n        self.logits, self.cost, self.train_op = self._build_ops(outputs, self.targets)\n\n        self.outputs = tf.argmax(self.logits, 2)\n\n    def _cell(self, output_keep_prob):\n        rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(self.n_hidden)\n        rnn_cell = tf.nn.rnn_cell.DropoutWrapper(rnn_cell, output_keep_prob=output_keep_prob)\n        return rnn_cell\n\n    def _build_cells(self, output_keep_prob=0.5):\n        enc_cell = tf.nn.rnn_cell.MultiRNNCell([self._cell(output_keep_prob)\n                                                for _ in range(self.n_layers)])\n        dec_cell = tf.nn.rnn_cell.MultiRNNCell([self._cell(output_keep_prob)\n                                                for _ in range(self.n_layers)])\n\n        return enc_cell, dec_cell\n\n    def _build_ops(self, outputs, targets):\n        time_steps = tf.shape(outputs)[1]\n        outputs = tf.reshape(outputs, [-1, self.n_hidden])\n\n        logits = tf.matmul(outputs, self.weights) + self.bias\n        logits = tf.reshape(logits, [-1, time_steps, self.vocab_size])\n\n        cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets))\n        train_op = tf.train.AdamOptimizer(learning_rate=self.learning_late).minimize(cost, global_step=self.global_step)\n\n        tf.summary.scalar(\'cost\', cost)\n\n        return logits, cost, train_op\n\n    def train(self, session, enc_input, dec_input, targets):\n        return session.run([self.train_op, self.cost],\n                           feed_dict={self.enc_input: enc_input,\n                                      self.dec_input: dec_input,\n                                      self.targets: targets})\n\n    def test(self, session, enc_input, dec_input, targets):\n        prediction_check = tf.equal(self.outputs, self.targets)\n        accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n\n        return session.run([self.targets, self.outputs, accuracy],\n                           feed_dict={self.enc_input: enc_input,\n                                      self.dec_input: dec_input,\n                                      self.targets: targets})\n\n    def predict(self, session, enc_input, dec_input):\n        return session.run(self.outputs,\n                           feed_dict={self.enc_input: enc_input,\n                                      self.dec_input: dec_input})\n\n    def write_logs(self, session, writer, enc_input, dec_input, targets):\n        merged = tf.summary.merge_all()\n\n        summary = session.run(merged, feed_dict={self.enc_input: enc_input,\n                                                 self.dec_input: dec_input,\n                                                 self.targets: targets})\n\n        writer.add_summary(summary, self.global_step.eval())\n'"
10 - RNN/ChatBot/train.py,8,"b'import tensorflow as tf\nimport random\nimport math\nimport os\n\nfrom config import FLAGS\nfrom model import Seq2Seq\nfrom dialog import Dialog\n\n\ndef train(dialog, batch_size=100, epoch=100):\n    model = Seq2Seq(dialog.vocab_size)\n\n    with tf.Session() as sess:\n        # TODO: \xec\x84\xb8\xec\x85\x98\xec\x9d\x84 \xeb\xa1\x9c\xeb\x93\x9c\xed\x95\x98\xea\xb3\xa0 \xeb\xa1\x9c\xea\xb7\xb8\xeb\xa5\xbc \xec\x9c\x84\xed\x95\x9c summary \xec\xa0\x80\xec\x9e\xa5\xeb\x93\xb1\xec\x9d\x98 \xeb\xa1\x9c\xec\xa7\x81\xec\x9d\x84 Seq2Seq \xeb\xaa\xa8\xeb\x8d\xb8\xeb\xa1\x9c \xeb\x84\xa3\xec\x9d\x84 \xed\x95\x84\xec\x9a\x94\xea\xb0\x80 \xec\x9e\x88\xec\x9d\x8c\n        ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n        if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n            print(""\xeb\x8b\xa4\xec\x9d\x8c \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90\xec\x84\x9c \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x9d\xbd\xeb\x8a\x94 \xec\xa4\x91 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.."", ckpt.model_checkpoint_path)\n            model.saver.restore(sess, ckpt.model_checkpoint_path)\n        else:\n            print(""\xec\x83\x88\xeb\xa1\x9c\xec\x9a\xb4 \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x98\xeb\x8a\x94 \xec\xa4\x91 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4."")\n            sess.run(tf.global_variables_initializer())\n\n        writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n\n        total_batch = int(math.ceil(len(dialog.examples)/float(batch_size)))\n\n        for step in range(total_batch * epoch):\n            enc_input, dec_input, targets = dialog.next_batch(batch_size)\n\n            _, loss = model.train(sess, enc_input, dec_input, targets)\n\n            if (step + 1) % 100 == 0:\n                model.write_logs(sess, writer, enc_input, dec_input, targets)\n\n                print(\'Step:\', \'%06d\' % model.global_step.eval(),\n                      \'cost =\', \'{:.6f}\'.format(loss))\n\n        checkpoint_path = os.path.join(FLAGS.train_dir, FLAGS.ckpt_name)\n        model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n\n    print(\'\xec\xb5\x9c\xec\xa0\x81\xed\x99\x94 \xec\x99\x84\xeb\xa3\x8c!\')\n\n\ndef test(dialog, batch_size=100):\n    print(""\\n=== \xec\x98\x88\xec\xb8\xa1 \xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8 ==="")\n\n    model = Seq2Seq(dialog.vocab_size)\n\n    with tf.Session() as sess:\n        ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n        print(""\xeb\x8b\xa4\xec\x9d\x8c \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90\xec\x84\x9c \xeb\xaa\xa8\xeb\x8d\xb8\xec\x9d\x84 \xec\x9d\xbd\xeb\x8a\x94 \xec\xa4\x91 \xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.."", ckpt.model_checkpoint_path)\n        model.saver.restore(sess, ckpt.model_checkpoint_path)\n\n        enc_input, dec_input, targets = dialog.next_batch(batch_size)\n\n        expect, outputs, accuracy = model.test(sess, enc_input, dec_input, targets)\n\n        expect = dialog.decode(expect)\n        outputs = dialog.decode(outputs)\n\n        pick = random.randrange(0, len(expect) / 2)\n        input = dialog.decode([dialog.examples[pick * 2]], True)\n        expect = dialog.decode([dialog.examples[pick * 2 + 1]], True)\n        outputs = dialog.cut_eos(outputs[pick])\n\n        print(""\\n\xec\xa0\x95\xed\x99\x95\xeb\x8f\x84:"", accuracy)\n        print(""\xeb\x9e\x9c\xeb\x8d\xa4 \xea\xb2\xb0\xea\xb3\xbc\\n"")\n        print(""    \xec\x9e\x85\xeb\xa0\xa5\xea\xb0\x92:"", input)\n        print(""    \xec\x8b\xa4\xec\xa0\x9c\xea\xb0\x92:"", expect)\n        print(""    \xec\x98\x88\xec\xb8\xa1\xea\xb0\x92:"", \' \'.join(outputs))\n\n\ndef main(_):\n    dialog = Dialog()\n\n    dialog.load_vocab(FLAGS.voc_path)\n    dialog.load_examples(FLAGS.data_path)\n\n    if FLAGS.train:\n        train(dialog, batch_size=FLAGS.batch_size, epoch=FLAGS.epoch)\n    elif FLAGS.test:\n        test(dialog, batch_size=FLAGS.batch_size)\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
