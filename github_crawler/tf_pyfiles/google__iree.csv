file_path,api_count,code
configure_bazel.py,0,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport platform\nimport os\nimport subprocess\nimport sys\n\n\ndef normalize_path(p):\n  if platform.system() == ""Windows"":\n    # Sure. Good idea, bazel.\n    return p.replace(""\\\\"", ""/"")\n  return p\n\n\ndef write_platform(bazelrc):\n  platform_config = ""generic_clang""\n  if platform.system() == ""Windows"":\n    platform_config = ""windows""\n  print(""build --config={}"".format(platform_config), file=bazelrc)\n\n\ndef write_python_bin(bazelrc):\n  python_bin = normalize_path(sys.executable)\n  print(""build --python_path=\\""{}\\"""".format(python_bin), file=bazelrc)\n  # IREE extension compilation requires PYTHON_BIN\n  print(""build --action_env PYTHON_BIN=\\""{}\\"""".format(python_bin), file=bazelrc)\n  # TensorFlow defines this one. No idea why.\n  print(\n      ""build --action_env PYTHON_BIN_PATH=\\""{}\\"""".format(python_bin),\n      file=bazelrc)\n\n\ndef write_python_path(bazelrc):\n  # For some reason, bazel doesn\'t always find the user site path, which\n  # is typically where ""pip install --user"" libraries end up. Inject it.\n  try:\n    user_site = subprocess.check_output(\n        [sys.executable, ""-m"", ""site"", ""--user-site""]).decode(""utf-8"").strip()\n    print(""Found user site directory:"", user_site)\n  except OSError:\n    print(""Could not resolve user site directory"")\n    return\n  print(\n      ""build --action_env PYTHONPATH=\\""{}\\"""".format(normalize_path(user_site)),\n      file=bazelrc)\n\n\nlocal_bazelrc = os.path.join(os.path.dirname(__file__), ""configured.bazelrc"")\nwith open(local_bazelrc, ""wt"") as bazelrc:\n  write_platform(bazelrc)\n  write_python_bin(bazelrc)\n  write_python_path(bazelrc)\n\nprint(""Wrote"", local_bazelrc)\n'"
colab/dummy.py,0,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
colab/start_colab_kernel.py,0,"b'#!/usr/bin/env python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Usage:\n#   python3 colab/start_colab_kernel.py\n#\n# Note that in the case that multiple python interpreters are present on\n# your path, it is best to not risk it: use an explicit one.\n#\n# This will build the python bindings and start a colab kernel with them\n# on the path. It takes some care to ensure that the build is running with\n# the same python interpreter as is used to launch this script.\n#\n# Pre-requisites:\n# Install Jupyter (from https://jupyter.org/install)\n#   python3 -m pip install --upgrade pip\n#   python3 -m pip install jupyter\n# Setup colab (https://research.google.com/colaboratory/local-runtimes.html)\n#   python3 -m pip install jupyter_http_over_ws\n#   jupyter serverextension enable --py jupyter_http_over_ws\n# If you plan on using TensorFlow, enable the TensorFlow parts of IREE\'s\n# compiler by adding a define to your user.bazelrc file:\n#   build --define=iree_tensorflow=true\n\nimport os\nimport subprocess\nimport shutil\nimport sys\n\nrepo_root = None\nbazel_env = dict(os.environ)\nbazel_bin = None\nbazel_exe = None\n\n\ndef setup_environment():\n  """"""Sets up some environment globals.""""""\n  global bazel_bin\n  global repo_root\n  global bazel_exe\n\n  # Determine the repository root (one dir-level up).\n  repo_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n  print(""Repository root: %s"" % (repo_root,))\n\n  # Use \'bazelisk\' instead of \'bazel\' if it exists on the path.\n  # Bazelisk is an optional utility that pick versions of Bazel to use and\n  # passes through all command-line arguments to the real Bazel binary:\n  # https://github.com/bazelbuild/bazelisk\n  bazel_exe = ""bazelisk"" if shutil.which(""bazelisk"") else ""bazel""\n  print(""Using bazel executable: %s"" % (bazel_exe))\n\n  # Detect python and query bazel for its output.\n  print(""Setting Bazel PYTHON_BIN=%s"" % (sys.executable,))\n  bazel_env[""PYTHON_BIN""] = sys.executable\n  bazel_bin = subprocess.check_output([bazel_exe, ""info"", ""bazel-bin""],\n                                      cwd=repo_root,\n                                      env=bazel_env).decode(""utf-8"")\n  bazel_bin = bazel_bin.splitlines()[0]\n  # Bazel always reports the path with \'/\'. On windows, switch it\n  # since we need native path manipulation code below to have it the\n  # right way.\n  if os.path.sep == ""\\\\"":\n    bazel_bin = bazel_bin.replace(""/"", ""\\\\"")\n  print(""Found Bazel bin: %s"" % (bazel_bin))\n\n\ndef build():\n  """"""Builds the python bundle.""""""\n  print(""Building python bindings..."")\n  subprocess.check_call([bazel_exe, ""build"", ""//colab:everything_for_colab""],\n                        cwd=repo_root,\n                        env=bazel_env)\n\n\ndef run():\n  """"""Runs the Jupyter notebook.""""""\n  runfiles_suffix = "".runfiles""\n  if os.path.sep == ""\\\\"":\n    runfiles_suffix = "".exe.runfiles""  # Windows uses a special name\n\n  runfiles_dir = os.path.join(bazel_bin, ""colab"",\n                              ""everything_for_colab"" + runfiles_suffix)\n  # Top level directories under the runfiles get added to the sys path.\n  extra_python_path = []\n  # The iree_core/bindings/python directory under runfiles needs to come\n  # first on the path.\n  extra_python_path.append(\n      os.path.join(runfiles_dir, ""iree_core"", ""bindings"", ""python""))\n  extra_python_path.append(\n      os.path.join(runfiles_dir, ""iree_core"", ""integrations"", ""tensorflow"",\n                   ""bindings"", ""python""))\n  for python_module in os.listdir(runfiles_dir):\n    python_module_path = os.path.join(runfiles_dir, python_module)\n    if os.path.isdir(python_module_path):\n      extra_python_path.append(python_module_path)\n\n  print(""Augmented Python sys.path:"")\n  for p in extra_python_path:\n    print("" "", p)\n  launch_jupyter(extra_python_path)\n\n\ndef launch_jupyter(python_path):\n  """"""Launches Jupyter with a python path.""""""\n  try:\n    from jupyter_core.command import main as jupyter_main  # pylint: disable=g-import-not-at-top\n  except ImportError:\n    show_install_instructions()\n    sys.exit(1)\n\n  # Override the PYTHONPATH, which Jupyter propagates to its kernels.\n  path_sep = "":""\n  if os.path.sep == ""\\\\"":\n    path_sep = "";""  # Windows\n  os.environ[""PYTHONPATH""] = path_sep.join(python_path)\n\n  # Launch jupyter (this is all the ""jupyter"" shell command does).\n  sys.argv = [\n      ""jupyter"", ""notebook"",\n      ""--NotebookApp.allow_origin=\'https://colab.research.google.com\'"",\n      ""--port=8888"", ""--NotebookApp.port_retries=0""\n  ]\n  sys.exit(jupyter_main())\n\n\ndef show_install_instructions():\n  """"""Prints some install instructions.""""""\n  print(""ERROR: Unable to load Jupyter. Ensure that it is installed:"")\n  print(""  %s -m pip install --upgrade pip"" % (sys.executable,))\n  print(""  %s -m pip install jupyter"" % (sys.executable,))\n  print(""  %s -m pip install jupyter_http_over_ws"" % (sys.executable,))\n  print(""  jupyter serverextension enable --py jupyter_http_over_ws"")\n\n\nif __name__ == ""__main__"":\n  setup_environment()\n  build()\n  run()\n'"
scripts/add_license_header.py,0,"b'#!/usr/bin/env python3\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Prepends a license header to files that don\'t already have one.\n\nBy default, only operates on known filetypes but behavior can be overridden with\nflags. Ignores files already containing a license as determined by the presence\nof a block that looks like ""Copyright SOME_YEAR""\n""""""\n\nimport argparse\nimport datetime\nimport os\nimport re\nimport sys\n\nCOPYRIGHT_PATTERN = re.compile(r""Copyright\\s+\\d+"")\n\nLICENSE_HEADER_FORMATTER = """"""{shebang}{start_comment} Copyright {year} {holder}\n{middle_comment}\n{middle_comment} Licensed under the Apache License, Version 2.0 (the ""License"");\n{middle_comment} you may not use this file except in compliance with the License.\n{middle_comment} You may obtain a copy of the License at\n{middle_comment}\n{middle_comment}      https://www.apache.org/licenses/LICENSE-2.0\n{middle_comment}\n{middle_comment} Unless required by applicable law or agreed to in writing, software\n{middle_comment} distributed under the License is distributed on an ""AS IS"" BASIS,\n{middle_comment} WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n{middle_comment} See the License for the specific language governing permissions and\n{middle_comment} limitations under the License.{end_comment}\n\n""""""\n\n\nclass CommentSyntax(object):\n\n  def __init__(self, start_comment, middle_comment=None, end_comment=""""):\n    self.start_comment = start_comment\n    self.middle_comment = middle_comment if middle_comment else start_comment\n    self.end_comment = end_comment\n\n\ndef comment_arg_parser(v):\n  """"""Can be used to parse a comment syntax triple.""""""\n  if v is None:\n    return None\n  if not isinstance(v, str):\n    raise argparse.ArgumentTypeError(""String expected"")\n  return CommentSyntax(*v.split("",""))\n\n\ndef create_multikey(d):\n  # pylint: disable=g-complex-comprehension\n  return {k: v for keys, v in d.items() for k in keys}\n\n\nfilename_to_comment = create_multikey({\n    (""BUILD"", ""CMakeLists.txt""): CommentSyntax(""#""),\n})\n\next_to_comment = create_multikey({\n    ("".bzl"", "".cfg"", "".cmake"", "".overlay"", "".py"", "".sh"", "".yml""):\n        CommentSyntax(""#""),\n    ("".cc"", "".cpp"", "".comp"", "".fbs"", "".h"", "".hpp"", "".inc"", "".td""):\n        CommentSyntax(""//""),\n    ("".def"",):\n        CommentSyntax("";;""),\n})\n\n\ndef get_comment_syntax(args):\n  """"""Deterime the comment syntax to use.""""""\n  if args.comment:\n    return args.comment\n  basename = os.path.basename(args.filename)\n  from_filename = filename_to_comment.get(basename)\n  if from_filename:\n    return from_filename\n  _, ext = os.path.splitext(args.filename)\n  return ext_to_comment.get(ext, args.default_comment)\n\n\ndef parse_arguments():\n  """"""Parses command line arguments.""""""\n  current_year = datetime.date.today().year\n  parser = argparse.ArgumentParser()\n  input_group = parser.add_mutually_exclusive_group()\n  input_group.add_argument(\n      ""infile"",\n      nargs=""?"",\n      type=argparse.FileType(""r"", encoding=""UTF-8""),\n      help=""Input file to format. Default: stdin"",\n      default=sys.stdin)\n  parser.add_argument(\n      ""--filename"",\n      ""--assume-filename"",\n      type=str,\n      default=None,\n      help=(\n          ""Filename to use for determining comment syntax. Default: actual name""\n          ""of input file.""))\n  parser.add_argument(\n      ""--year"",\n      ""-y"",\n      help=""Year to add copyright. Default: the current year ({})"".format(\n          current_year),\n      default=current_year)\n  parser.add_argument(\n      ""--holder"",\n      help=""Copyright holder. Default: Google LLC"",\n      default=""Google LLC"")\n  parser.add_argument(\n      ""--quiet"",\n      help=(""Don\'t raise a runtime error on encountering an unhandled filetype.""\n            ""Useful for running across many files at once. Default: False""),\n      action=""store_true"",\n      default=False)\n  output_group = parser.add_mutually_exclusive_group()\n  output_group.add_argument(\n      ""-o"",\n      ""--outfile"",\n      ""--output"",\n      help=""File to send output. Default: stdout"",\n      type=argparse.FileType(""w"", encoding=""UTF-8""),\n      default=sys.stdout)\n  output_group.add_argument(\n      ""--in_place"",\n      ""-i"",\n      action=""store_true"",\n      help=""Run formatting in place. Default: False"",\n      default=False)\n  comment_group = parser.add_mutually_exclusive_group()\n  comment_group.add_argument(\n      ""--comment"",\n      ""-c"",\n      type=comment_arg_parser,\n      help=""Override comment syntax."",\n      default=None)\n  comment_group.add_argument(\n      ""--default_comment"",\n      type=comment_arg_parser,\n      help=""Fallback comment syntax if filename is unknown. Default: None"",\n      default=None)\n  args = parser.parse_args()\n\n  if args.in_place and args.infile == sys.stdin:\n    raise parser.error(""Cannot format stdin in place"")\n\n  if not args.filename and args.infile != sys.stdin:\n    args.filename = args.infile.name\n\n  return args\n\n\ndef main(args):\n  first_line = args.infile.readline()\n  already_has_license = False\n  shebang = """"\n  content_lines = []\n  if first_line.startswith(""#!""):\n    shebang = first_line\n  else:\n    content_lines = [first_line]\n  content_lines.extend(args.infile.readlines())\n  for line in content_lines:\n    if COPYRIGHT_PATTERN.search(line):\n      already_has_license = True\n      break\n  if already_has_license:\n    header = shebang\n  else:\n    comment_syntax = get_comment_syntax(args)\n    if not comment_syntax:\n      if args.quiet:\n        header = shebang\n      else:\n        raise ValueError(""Could not determine comment syntax for "" +\n                         args.filename)\n    else:\n      header = LICENSE_HEADER_FORMATTER.format(\n          # Add a blank line between shebang and license.\n          shebang=(shebang + ""\\n"" if shebang else """"),\n          start_comment=comment_syntax.start_comment,\n          middle_comment=comment_syntax.middle_comment,\n          # Add a blank line before the end comment.\n          end_comment=(""\\n"" + comment_syntax.end_comment\n                       if comment_syntax.end_comment else """"),\n          year=args.year,\n          holder=args.holder)\n\n  # Have to open for write after we\'re done reading.\n  if args.in_place:\n    args.outfile = open(args.filename, ""w"", encoding=""UTF-8"")\n  args.outfile.write(header)\n  args.outfile.writelines(content_lines)\n\n\nif __name__ == ""__main__"":\n  main(parse_arguments())\n'"
scripts/prepare_doc_publication.py,0,"b'#!/usr/bin/env python3\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Prepares MarkDown documentation publication.\n\nThe in-tree and auto-generated MarkDown documentation lacks necessary metadata\n(i.e., front matter) for specifying the layout, title, and others that are\nrequired by Jekyll for rendering the HTML. This script patches MarkDown\nfiles with that.\n""""""\n\nimport argparse\nimport os\n\n\ndef parse_arguments():\n  """"""Parses command-line options.""""""\n  parser = argparse.ArgumentParser(\n      description=\'Processes MarkDown files for publication\')\n  parser.add_argument(\n      \'base_dir\',\n      metavar=\'PATH\',\n      type=str,\n      help=\'Base documentation directory.\')\n\n  parsed_args = parser.parse_args()\n  if not os.path.isdir(parsed_args.base_dir):\n    raise parser.error(\'expected path to a directory\')\n\n  return parsed_args\n\n\n# A dictionary containing source file to doc title mappings.\n#\n# By default the generated doc will have a title matching the MarkDown H1\n# header. This dictionary will overrule that default behavior.\nDOC_TITLE_DICT = {\n    \'index.md\': \'Home\',\n    \'getting_started_linux_bazel.md\': \'Linux with Bazel\',\n    \'getting_started_linux_cmake.md\': \'Linux with CMake\',\n    \'getting_started_linux_vulkan.md\': \'Linux with Vulkan\',\n    \'getting_started_windows_bazel.md\': \'Windows with Bazel\',\n    \'getting_started_windows_cmake.md\': \'Windows with CMake\',\n    \'getting_started_windows_vulkan.md\': \'Windows with Vulkan\',\n    \'generic_vulkan_env_setup.md\': \'Generic Vulkan Setup\',\n    \'getting_started_python.md\': \'Python\',\n    \'op_coverage.md\': \'XLA HLO Operation Coverage\',\n    \'roadmap.md\': \'Short-term Focus Areas\',\n    \'roadmap_design.md\': \'Long-term Design Roadmap\',\n    \'iree_community.md\': \'Community\',\n}\n\n# A dictionary containing source file to permanent link mappings.\n#\n# By default a source file will have a permanent URL link following its\n# filename. For example, if we have docs/Foo/Bar.md, then the permanent link\n# for it would be https://google.github.io/iree/Foo/Bar. This dictionary\n# allows one to override the permanent link if necessary.\nPERMALINK_DICT = {\n    \'index.md\': \'/\',\n    \'getting_started_linux_bazel.md\': \'GetStarted/LinuxBazel\',\n    \'getting_started_linux_cmake.md\': \'GetStarted/LinuxCMake\',\n    \'getting_started_linux_vulkan.md\': \'GetStarted/LinuxVulkan\',\n    \'getting_started_windows_bazel.md\': \'GetStarted/WindowsBazel\',\n    \'getting_started_windows_cmake.md\': \'GetStarted/WindowsCMake\',\n    \'getting_started_windows_vulkan.md\': \'GetStarted/WindowsVulkan\',\n    \'generic_vulkan_env_setup.md\': \'GetStarted/GenericVulkanSetup\',\n    \'getting_started_python.md\': \'GetStarted/Python\',\n    \'developer_overview.md\': \'DeveloperOverview\',\n    \'testing_guide.md\': \'TestingGuide\',\n    \'op_coverage.md\': \'HLOOpCoverage\',\n    \'roadmap.md\': \'FocusAreas\',\n    \'roadmap_design.md\': \'DesignRoadmap\',\n    \'iree_community.md\': \'Community\',\n}\n\n# A dictionary containing source file to navigation order mappings.\n#\n# By default the rendered docs will be sort alphabetically and listed on\n# the left panel of https://google.github.io/iree website. This allows one\n# to specify an order for a specific doc.\nNAVI_ORDER_DICT = {\n    \'index.md\': 1,\n    # \'Getting Started\' is 2.\n    \'developer_overview.md\': 3,\n    \'roadmap_design.md\': 4,\n    \'roadmap.md\': 5,\n    \'op_coverage.md\': 6,\n    \'testing_guide.md\': 7,\n    \'iree_community.md\': 8,\n\n    # Within \'Getting Started\' use explicit ordering.\n    # Alphabetical would put \'bazel\' before \'cmake\' and \'python\' between \'linux\'\n    # and \'windows\'.\n    \'getting_started_linux_cmake.md\': 1,\n    \'getting_started_linux_bazel.md\': 2,\n    \'getting_started_linux_vulkan.md\': 3,\n    \'getting_started_windows_cmake.md\': 4,\n    \'getting_started_windows_bazel.md\': 5,\n    \'getting_started_windows_vulkan.md\': 6,\n    \'getting_started_python.md\': 7,\n    \'generic_vulkan_env_setup.md\': 8,\n}\n\n# A dictionary containing source directory to section tile mappings.\n#\n# To put a MarkDown file under a certain section, the front matter should\n# contain a `parent` field pointing to the section\'s title. By default we\n# use the subdirectory name as the section title. This allows customization.\n# Note that the title here must match with index.md file\'s title under the\n# subdirectory.\nDIRECTORY_TITLE_DICT = {\n    \'Dialects\': \'Dialect Definitions\',\n    \'GetStarted\': \'Getting Started\',\n}\n\n# A dictionary containing the supporting JavaScript files for each doc.\nJS_FILES_DICT = {\'op_coverage.md\': [\'js/add_classes.js\']}\n\n\ndef process_file(basedir, relpath, filename):\n  """"""Patches the given file in-place with metadata for publication.""""""\n\n  full_path = os.path.join(basedir, relpath, filename)\n  base_name = os.path.splitext(filename)[0]\n  with open(full_path, \'r\') as f:\n    content = f.read()\n\n  # Directly return if the file already has front matter.\n  if content.startswith(\'---\\n\'):\n    return\n\n  front_matter = {}\n  # Use the default layout for everything.\n  front_matter[\'layout\'] = \'default\'\n  # Use the base filename as permanent link.\n  front_matter[\'permalink\'] = base_name\n\n  # Organize each doc to a section matching its directory structure.\n  if relpath and relpath != \'.\':\n    front_matter[\'parent\'] = relpath\n    front_matter[\'permalink\'] = f\'{relpath}/{front_matter[""permalink""]}\'\n\n  # Find the title and TOC.\n  lines = content.splitlines()\n  title_line_index = None\n  toc_index = None\n  for (index, line) in enumerate(lines):\n    if line.startswith(\'# \'):\n      title_line_index = index\n    if line == \'[TOC]\':\n      toc_index = index\n    if title_line_index is not None and toc_index is not None:\n      break\n\n  # Replace \'[TOC]\' with the proper format that can be rendered.\n  if toc_index is not None:\n    lines[toc_index] = \'1. TOC\\n{:toc}\'\n\n  # Set the title in front matter and disable it to show up in TOC.\n  if title_line_index is not None:\n    front_matter[\'title\'] = f\'""{lines[title_line_index][2:]}""\'\n    lines.insert(title_line_index + 1, \'{: .no_toc }\')\n  else:\n    front_matter[\'title\'] = base_name\n\n  # Override with manually specified metadata if exists.\n  if filename in DOC_TITLE_DICT:\n    front_matter[\'title\'] = DOC_TITLE_DICT[filename]\n  if filename in PERMALINK_DICT:\n    front_matter[\'permalink\'] = PERMALINK_DICT[filename]\n  if filename in NAVI_ORDER_DICT:\n    front_matter[\'nav_order\'] = NAVI_ORDER_DICT[filename]\n  if relpath in DIRECTORY_TITLE_DICT:\n    front_matter[\'parent\'] = DIRECTORY_TITLE_DICT[relpath]\n  if filename in JS_FILES_DICT:\n    # js_files is a list, so we split each file onto a different line. We put\n    # an extra \\n on the front so the code below can treat it like the rest of\n    # the values in front_matter.\n    front_matter[\'js_files\'] = \'\\n\' + \'\\n\'.join(\n        [f\'- {file}\' for file in JS_FILES_DICT[filename]])\n\n  # Compose the content prefix for front matter.\n  prefix = \'\\n\'.join([f\'{k}: {v}\' for (k, v) in front_matter.items()])\n  prefix = \'\\n\'.join([\'---\', prefix, \'---\\n\\n\'])\n\n  # Compose the new content.\n  content = \'\\n\'.join(lines)\n\n  # Substitute specific pattern for callouts to make them prettier.\n  content = content.replace(\'> Tip:<br>\\n> &nbsp;&nbsp;&nbsp;&nbsp;\',\n                            \'> Tip\\n> {: .label .label-green }\\n> \')\n  content = content.replace(\'> Note:<br>\\n> &nbsp;&nbsp;&nbsp;&nbsp;\',\n                            \'> Note\\n> {: .label .label-blue }\\n> \')\n\n  # Update in place.\n  with open(full_path, \'w\') as f:\n    f.write(f\'{prefix}{content}\')\n\n\ndef process_directory(basedir):\n  """"""Walks the given base directory and processes each MarkDown file.""""""\n  for (dirpath, _, filenames) in os.walk(basedir):\n    for filename in filenames:\n      if filename.endswith(\'.md\'):\n        relpath = os.path.relpath(dirpath, basedir)\n        process_file(basedir, relpath, filename)\n\n\nif __name__ == \'__main__\':\n  args = parse_arguments()\n  process_directory(args.base_dir)\n'"
scripts/update_op_coverage.py,0,"b'#!/usr/bin/env python3\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Updates op coverage table.\n\nExample usage: ./update_op_coverage.py IREE_BUILD_DIR\n""""""\n\nimport argparse\nimport collections\nimport os\nimport subprocess\n\n# The symbols to show in the table if the operation is supported or not.\nSUCCESS_ELEMENT = \'<span class=""success-table-element"">\xe2\x9c\x93</span>\'\nFAILURE_ELEMENT = \'<span class=""failure-table-element"">\xe2\x9c\x97</span>\'\n\nE2E_XLA_OPS_PATH = \'iree/test/e2e/xla_ops\'\n\n# TODO(scotttodd): LLVM AOT (dylib-llvm-aot) HAL target(s)\nOP_COVERAGE_DESCRIPTION = """"""# HLO Op Coverage\nThere are three backend [targets](https://github.com/google/iree/tree/master/iree/compiler/Dialect/HAL/Target) in IREE:\n\n- vmla\n- llvm-ir\n- vulkan-spirv\n\nThe table shows the supported XLA HLO ops on each backend.\n\n""""""\n\n\ndef parse_arguments():\n  """"""Parses command-line options.""""""\n  parser = argparse.ArgumentParser(\n      description=\'Generates Markdown files for op coverage table\')\n  parser.add_argument(\n      \'build_dir\', metavar=\'BUILD_PATH\', type=str, help=\'Base build directory.\')\n\n  parsed_args = parser.parse_args()\n  if not os.path.isdir(parsed_args.build_dir):\n    raise parser.error(\'expected path to a directory\')\n\n  return parsed_args\n\n\ndef get_backend_op_pair(test):\n  """"""Returns the target backend and operation pair of the test.""""""\n  test_suite_backends = {\n      \'check_vmla_vmla\': \'vmla\',\n      \'check_llvm-ir_llvm\': \'llvm-ir\',\n      \'check_vulkan-spirv_vulkan\': \'vulkan-spirv\'\n  }\n  for (test_suite, backend) in test_suite_backends.items():\n    if test_suite in test:\n      # Format: ...TEST_SUITE_OP.mlir\n      start_idx = test.index(test_suite) + len(test_suite) + 1\n      return backend, test[start_idx:-len(\'.mlir\')]\n  raise LookupError(f\'Can not find a backend to match {test}\')\n\n\ndef get_tested_ops_for_backends(build_dir):\n  """"""Parses current op tests for each backend.""""""\n\n  ctest_output = subprocess.check_output(\n      [\'ctest\', \'-N\', \'-L\', E2E_XLA_OPS_PATH], cwd=build_dir)\n  tests = ctest_output.decode(\'ascii\').strip().split(\'\\n\')\n  res = collections.defaultdict(list)\n  for t in tests:\n    if not t.endswith(\'.mlir\'):\n      continue\n    backend, op = get_backend_op_pair(t)\n    res[backend].append(op)\n  return res\n\n\ndef create_markdown_table(rows):\n  """"""Converts a 2D array to a Markdown table.""""""\n  return \'\\n\'.join([\' | \'.join(row) for row in rows])\n\n\ndef generate_table(build_dir):\n  """"""Generates an op coverage Markdown table for each backend.""""""\n  backend_ops = get_tested_ops_for_backends(build_dir)\n  backends = list(backend_ops.keys())\n\n  all_ops = []\n  for ops in backend_ops.values():\n    all_ops.extend(ops)\n  all_ops = list(set(all_ops))\n  all_ops.sort()\n\n  first_row = [\'op\'] + backends\n  second_row = [\':-:\' for _ in first_row]\n  rows = [first_row, second_row]\n  for op in all_ops:\n    row = [op]\n    for backend in backends:\n      row.append(\n          SUCCESS_ELEMENT if (op in backend_ops[backend]) else FAILURE_ELEMENT)\n    rows.append(row)\n  return create_markdown_table(rows)\n\n\nif __name__ == \'__main__\':\n  args = parse_arguments()\n  content = generate_table(args.build_dir)\n  table_path = os.path.join(args.build_dir, \'doc\', \'op_coverage.md\')\n  with open(table_path, \'w\', encoding=\'utf-8\') as f:\n    f.write(OP_COVERAGE_DESCRIPTION)\n    f.write(content)\n'"
build_tools/bazel_to_cmake/__init__.py,0,b'\n'
build_tools/bazel_to_cmake/bazel_to_cmake.py,0,"b'#!/usr/bin/env python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This script assists with converting from Bazel BUILD files to CMakeLists.txt.\n\nBazel BUILD files should, where possible, be written to use simple features\nthat can be directly evaluated and avoid more advanced features like\nvariables, list comprehensions, etc.\n\nGenerated CMake files will be similar in structure to their source BUILD\nfiles by using the functions in build_tools/cmake/ that imitate corresponding\nBazel rules (e.g. cc_library -> iree_cc_library.cmake).\n\nFor usage, see:\n  python3 build_tools/bazel_to_cmake/bazel_to_cmake.py --help\n""""""\n# pylint: disable=missing-docstring\n\nimport argparse\nimport datetime\nimport os\nimport re\nimport sys\n\nimport bazel_to_cmake_converter\n\nrepo_root = None\n\nEDIT_BLOCKING_PATTERN = re.compile(\n    r""bazel[\\s_]*to[\\s_]*cmake[\\s_]*:?[\\s_]*do[\\s_]*not[\\s_]*edit"",\n    flags=re.IGNORECASE)\n\n\ndef parse_arguments():\n  global repo_root\n\n  parser = argparse.ArgumentParser(\n      description=""Bazel to CMake conversion helper."")\n  parser.add_argument(\n      ""--preview"",\n      help=""Prints results instead of writing files"",\n      action=""store_true"",\n      default=False)\n  parser.add_argument(\n      ""--allow_partial_conversion"",\n      help=""Generates partial files, ignoring errors during conversion"",\n      action=""store_true"",\n      default=False)\n\n  # Specify only one of these (defaults to --root_dir=iree).\n  group = parser.add_mutually_exclusive_group()\n  group.add_argument(\n      ""--dir"",\n      help=""Converts the BUILD file in the given directory"",\n      default=None)\n  group.add_argument(\n      ""--root_dir"",\n      help=""Converts all BUILD files under a root directory (defaults to iree/)"",\n      default=""iree"")\n\n  args = parser.parse_args()\n\n  # --dir takes precedence over --root_dir.\n  # They are mutually exclusive, but the default value is still set.\n  if args.dir:\n    args.root_dir = None\n\n  return args\n\n\ndef setup_environment():\n  """"""Sets up some environment globals.""""""\n  global repo_root\n\n  # Determine the repository root (two dir-levels up).\n  repo_root = os.path.dirname(\n      os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n\ndef log(*args, **kwargs):\n  print(*args, **kwargs, file=sys.stderr)\n\n\ndef convert_directory_tree(root_directory_path, write_files,\n                           allow_partial_conversion):\n  log(f""convert_directory_tree: {root_directory_path}"")\n  for root, _, _ in os.walk(root_directory_path):\n    convert_directory(root, write_files, allow_partial_conversion)\n\n\ndef convert_directory(directory_path, write_files, allow_partial_conversion):\n  if not os.path.isdir(directory_path):\n    raise FileNotFoundError(f""Cannot find directory \'{directory_path}\'"")\n\n  build_file_path = os.path.join(directory_path, ""BUILD"")\n  cmakelists_file_path = os.path.join(directory_path, ""CMakeLists.txt"")\n\n  if not os.path.isfile(build_file_path):\n    # No Bazel BUILD file in this directory to convert, skip.\n    return\n\n  global repo_root\n  rel_build_file_path = os.path.relpath(build_file_path, repo_root)\n  rel_cmakelists_file_path = os.path.relpath(cmakelists_file_path, repo_root)\n  log(f""Converting {rel_build_file_path} to {rel_cmakelists_file_path}"")\n\n  cmake_file_exists = os.path.isfile(cmakelists_file_path)\n  copyright_line = f""# Copyright {datetime.date.today().year} Google LLC""\n  write_allowed = write_files\n  if cmake_file_exists:\n    with open(cmakelists_file_path) as f:\n      for i, line in enumerate(f):\n        if line.startswith(""# Copyright""):\n          copyright_line = line.rstrip()\n        if EDIT_BLOCKING_PATTERN.search(line):\n          log(f""  {rel_cmakelists_file_path} already exists, and ""\n              f""line {i + 1}: \'{line.strip()}\' prevents edits. ""\n              f""Falling back to preview"")\n          write_allowed = False\n\n  if write_allowed:\n    # TODO(scotttodd): Attempt to merge instead of overwrite?\n    #   Existing CMakeLists.txt may have special logic that should be preserved\n    if cmake_file_exists:\n      log(f""  {rel_cmakelists_file_path} already exists; overwriting"")\n    else:\n      log(f""  {rel_cmakelists_file_path} does not exist yet; creating"")\n  log("""")\n\n  with open(build_file_path, ""rt"") as build_file:\n    build_file_code = compile(build_file.read(), build_file_path, ""exec"")\n    try:\n      converted_text = bazel_to_cmake_converter.convert_build_file(\n          build_file_code,\n          copyright_line,\n          allow_partial_conversion=allow_partial_conversion)\n      if write_allowed:\n        with open(cmakelists_file_path, ""wt"") as cmakelists_file:\n          cmakelists_file.write(converted_text)\n      else:\n        print(converted_text, end="""")\n    except (NameError, NotImplementedError) as e:\n      log(f""Failed to convert {rel_build_file_path}."", end="" "")\n      log(""Missing a rule handler in bazel_to_cmake.py?"")\n      log(f""  Reason: `{type(e).__name__}: {e}`"")\n    except KeyError as e:\n      log(f""Failed to convert {rel_build_file_path}."", end="" "")\n      log(""Missing a conversion in bazel_to_cmake_targets.py?"")\n      log(f""  Reason: `{type(e).__name__}: {e}`"")\n\n\ndef main(args):\n  """"""Runs Bazel to CMake conversion.""""""\n  global repo_root\n\n  write_files = not args.preview\n\n  if args.root_dir:\n    convert_directory_tree(\n        os.path.join(repo_root, args.root_dir), write_files,\n        args.allow_partial_conversion)\n  elif args.dir:\n    convert_directory(\n        os.path.join(repo_root, args.dir), write_files,\n        args.allow_partial_conversion)\n\n\nif __name__ == ""__main__"":\n  setup_environment()\n  main(parse_arguments())\n'"
build_tools/bazel_to_cmake/bazel_to_cmake_converter.py,0,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Converter class for converting Bazel BUILD files to CMakeLists.txt files.\n\nSee bazel_to_cmake.py for usage.\n""""""\n\n# pylint: disable=missing-docstring\n# pylint: disable=invalid-name\n# pylint: disable=unused-argument\n# pylint: disable=exec-used\n\nimport itertools\nimport textwrap\n\nimport bazel_to_cmake_targets\n\n\ndef _expand_cmake_var(var):\n  return ""${"" + var + ""}""\n\n\nclass BuildFileFunctions(object):\n  """"""Object passed to `exec` that has handlers for BUILD file functions.""""""\n\n  def __init__(self, converter):\n    self.converter = converter\n    # TODO(gcmn): Do this in a less hard-coded way\n    self.PLATFORM_VULKAN_DEPS = []\n    self.PLATFORM_VULKAN_TEST_DEPS = [""//iree/testing:gtest_main""]\n    self.FLATBUFFER_SUPPORTS_REFLECTIONS = False\n    self.PLATFORM_VULKAN_LOADER_COPTS = []\n    self.IREE_DRIVER_MODULES = [\n        # TODO(b/142004903): enable when Dawn HAL implementation is functional\n        # ""//iree/hal/dawn:dawn_driver_module"",\n        ""//iree/hal/vmla:vmla_driver_module"",\n        ""//iree/hal/vulkan:vulkan_driver_module"",\n        ""//iree/hal/llvmjit:llvmjit_driver_module"",\n    ]\n\n  # ------------------------------------------------------------------------- #\n  # Conversion utilities, written to reduce boilerplate and allow for reuse   #\n  # between similar rule conversions (e.g. cc_library and cc_binary).         #\n  # ------------------------------------------------------------------------- #\n\n  def _convert_string_arg_block(self, name, value):\n    #  NAME\n    #    value\n    return f""  {name}\\n    {value}\\n""\n\n  def _convert_name_block(self, name):\n    #  NAME\n    #    rule_name\n    return f""  NAME\\n    {name}\\n""\n\n  def _convert_out_block(self, out):\n    #  OUT\n    #    out_name\n    return f""  OUT\\n    {out}\\n""\n\n  def _convert_cc_namespace_block(self, cc_namespace):\n    #  CC_NAMESPACE\n    #    ""cc_namespace""\n    if not cc_namespace:\n      return """"\n    return f\'  CC_NAMESPACE\\n    ""{cc_namespace}""\\n\'\n\n  def _convert_cpp_namespace_block(self, cpp_namespace):\n    #  CPP_NAMESPACE\n    #    ""cpp_namespace""\n    if not cpp_namespace:\n      return """"\n    return f\'  CPP_NAMESPACE\\n    ""{cpp_namespace}""\\n\'\n\n  def _convert_string_list_block(self, name, values):\n    # Note this deliberately distinguishes between an empty list (argument\n    # explicitly specified) and None (argument left as default).\n    if values is None:\n      return """"\n    values_list = ""\\n"".join([f\'    ""{v}""\' for v in values])\n    return f""  {name}\\n{values_list}\\n""\n\n  def _convert_translate_tool_block(self, translate_tool):\n    if translate_tool and translate_tool != ""//iree/tools:iree-translate"":\n      # Bazel `//iree/base`     -> CMake `iree::base`\n      # Bazel `//iree/base:api` -> CMake `iree::base::api`\n      translate_tool = translate_tool.replace(""//iree"", ""iree"")  # iree/base:api\n      translate_tool = translate_tool.replace("":"", ""_"")  # iree/base::api\n      translate_tool = translate_tool.replace(""/"", ""_"")  # iree::base::api\n      return f""  TRANSLATE_TOOL\\n    {translate_tool}\\n""\n    else:\n      return """"\n\n  def _convert_option_block(self, option, option_value):\n    if option_value:\n      # Note: this is a truthiness check as well as an existence check, i.e.\n      # Bazel `testonly = False` will be handled correctly by this condition.\n      return f""  {option}\\n""\n    else:\n      return """"\n\n  def _convert_alwayslink_block(self, alwayslink):\n    return self._convert_option_block(""ALWAYSLINK"", alwayslink)\n\n  def _convert_testonly_block(self, testonly):\n    return self._convert_option_block(""TESTONLY"", testonly)\n\n  def _convert_flatten_block(self, flatten):\n    return self._convert_option_block(""FLATTEN"", flatten)\n\n  def _convert_file_list_block(self, list_name, files):\n    #  list_name\n    #    ""file_1.h""\n    #    ""file_2.h""\n    #    ""file_3.h""\n    if not files:\n      return """"\n    files_list = ""\\n"".join([f\'    ""{file}""\' for file in files])\n    return f""  {list_name}\\n{files_list}\\n""\n\n  def _convert_hdrs_block(self, hdrs):\n    return self._convert_file_list_block(""HDRS"", hdrs)\n\n  def _convert_textual_hdrs_block(self, textual_hdrs):\n    return self._convert_file_list_block(""TEXTUAL_HDRS"", textual_hdrs)\n\n  def _convert_srcs_block(self, srcs):\n    return self._convert_file_list_block(""SRCS"", srcs)\n\n  def _convert_src_block(self, src):\n    return f\'  SRC\\n    ""{src}""\\n\'\n\n  def _convert_cc_file_output_block(self, cc_file_output):\n    return f\'  CC_FILE_OUTPUT\\n    ""{cc_file_output}""\\n\'\n\n  def _convert_h_file_output_block(self, h_file_output):\n    return f\'  H_FILE_OUTPUT\\n    ""{h_file_output}""\\n\'\n\n  def _convert_td_file_block(self, td_file):\n    if td_file.startswith(""//iree""):\n      # Bazel `//iree/dir/td_file.td`\n      # -> CMake `${IREE_ROOT_DIR}/iree/dir/td_file.td\n      # Bazel `//iree/dir/IR:td_file.td`\n      # -> CMake `${IREE_ROOT_DIR}/iree/dir/IR/td_file.td\n      td_file = td_file.replace(""//iree"", ""${IREE_ROOT_DIR}/iree"")\n      td_file = td_file.replace("":"", ""/"")\n    return f\'  TD_FILE\\n    ""{td_file}""\\n\'\n\n  def _convert_tbl_outs_block(self, tbl_outs):\n    outs_list = ""\\n"".join([f""    {flag} {value}"" for flag, value in tbl_outs])\n    return f""  OUTS\\n{outs_list}\\n""\n\n  def _convert_tblgen_block(self, tblgen):\n    if tblgen.endswith(""iree-tblgen""):\n      return ""  TBLGEN\\n    IREE\\n""\n    else:\n      return """"\n\n  def _convert_target(self, target):\n    if target.startswith("":"") and target.endswith((""_gen"", ""Gen"")):\n      # Files created by gentbl have to be included as source and header files\n      # and not as a dependency. Adding these targets to the dependencies list,\n      # results in linkage failures if the library including the gentbl dep is\n      # marked as ALWAYSLINK.\n      # This drops deps in the local namespace ending with \'_gen\' and \'Gen\'\n      target = [""""]\n    elif not target.startswith((""//bindings"", ""//experimental"", ""//iree"", "":"")):\n      # External target, call helper method for special case handling.\n      target = bazel_to_cmake_targets.convert_external_target(target)\n    else:\n      # Bazel `:api`            -> CMake `::api`\n      # Bazel `//iree/base`     -> CMake `iree::base`\n      # Bazel `//iree/base:api` -> CMake `iree::base::api`\n      target = target.replace(""//bindings"", ""bindings"")  # bindings:api\n      # Support for experimental targets is best effort with no guarantees.\n      target = target.replace(""//experimental"",\n                              ""experimental"")  # experimental:api\n      target = target.replace(""//iree"", ""iree"")  # iree/base:api\n      target = target.replace("":"", ""::"")  # iree/base::api or ::api\n      target = target.replace(""/"", ""::"")  # iree::base::api\n      target = [target]\n    return target\n\n  def _convert_target_list_block(self, list_name, targets):\n    if not targets:\n      return """"\n\n    #  DEPS\n    #    package1::target1\n    #    package1::target2\n    #    package2::target\n    targets = [self._convert_target(t) for t in targets]\n    # Flatten lists\n    targets = list(itertools.chain.from_iterable(targets))\n    # Remove duplicates\n    targets = set(targets)\n    # Remove Falsey (None and empty string) values\n    targets = filter(None, targets)\n    # Sort the targets and convert to a list\n    targets = sorted(targets)\n    target_list_string = ""\\n"".join([f""    {target}"" for target in targets])\n    return f""  {list_name}\\n{target_list_string}\\n""\n\n  def _convert_data_block(self, data):\n    return self._convert_target_list_block(""DATA"", data)\n\n  def _convert_deps_block(self, deps):\n    return self._convert_target_list_block(""DEPS"", deps)\n\n  def _convert_flatc_args_block(self, flatc_args):\n    if not flatc_args:\n      return """"\n    flatc_args = ""\\n"".join([f\'    ""{flatc_arg}""\' for flatc_arg in flatc_args])\n    return f""  FLATC_ARGS\\n{flatc_args}\\n""\n\n  def _convert_unimplemented_function(self, function, details=""""):\n    message = f""Unimplemented {function}: {details}""\n    if not self.converter.first_error:\n      self.converter.first_error = NotImplementedError(message)\n    # Avoid submitting the raw results from non-strict runs. These are still\n    # useful but are generally not safe to submit as-is. An upstream check\n    # prevents changes with this phrase from being submitted.\n    # Written as separate literals to avoid the check triggering here.\n    submit_blocker = ""DO"" + "" NOT"" + "" SUBMIT.""\n    self.converter.body += f""# {submit_blocker} {message}\\n""\n\n  # ------------------------------------------------------------------------- #\n  # Function handlers that convert BUILD definitions to CMake definitions.    #\n  #                                                                           #\n  # Names and signatures must match 1:1 with those expected in BUILD files.   #\n  # Each function that may be found in a BUILD file must be listed here.      #\n  # ------------------------------------------------------------------------- #\n\n  def load(self, *args, **kwargs):\n    # No mapping to CMake, ignore.\n    pass\n\n  def package(self, **kwargs):\n    # No mapping to CMake, ignore.\n    pass\n\n  def iree_build_test(self, **kwargs):\n    pass\n\n  def test_suite(self, **kwargs):\n    # No CMake equivalent, ignore.\n    pass\n\n  def filegroup(self, name, **kwargs):\n    # Not implemented yet. Might be a no-op, or may want to evaluate the srcs\n    # attribute and pass them along to any targets that depend on the filegroup.\n    # Cross-package dependencies and complicated globs could be hard to handle.\n\n    # We have a bunch of filegroups that just contain TD files. CMake doesn\'t\n    # model this at all, so we\'ll just hardcode this special case.\n    # TODO(gcmn): Handle this robustly\n    if name == ""td_files"":\n      return\n\n    self._convert_unimplemented_function(""filegroup"", name)\n\n  def sh_binary(self, name, **kwargs):\n    self._convert_unimplemented_function(""sh_binary"", name)\n\n  def exports_files(self, *args, **kwargs):\n    # No mapping to CMake, ignore.\n    pass\n\n  def glob(self, include, exclude=None, exclude_directories=1):\n    if exclude_directories != 1:\n      self._convert_unimplemented_function(""glob"", ""with exclude_directories"")\n    if exclude is None:\n      exclude = []\n\n    glob_vars = []\n    for pattern in include:\n      if ""**"" in pattern:\n        # bazel\'s glob has some specific restrictions about crossing package\n        # boundaries. We have no uses of recursive globs. Rather than try to\n        # emulate them or silently give different behavior, just error out.\n        # See https://docs.bazel.build/versions/master/be/functions.html#glob\n        raise NotImplementedError(""Recursive globs not supported"")\n      # Bazel `*.mlir` glob -> CMake Variable `_GLOB_X_MLIR`\n      var = ""_GLOB_"" + pattern.replace(""*"", ""X"").replace(""."", ""_"").upper()\n      glob_vars.append(var)\n      self.converter.body += (\n          f""file(GLOB {var} LIST_DIRECTORIES false""\n          f"" RELATIVE {_expand_cmake_var(\'CMAKE_CURRENT_SOURCE_DIR\')}""\n          f"" CONFIGURE_DEPENDS {pattern})\\n"")\n    for pattern in exclude:\n      if ""**"" in pattern:\n        raise NotImplementedError(""Recursive globs not supported"")\n      exclude_var = (""_GLOB_"" +\n                     pattern.replace(""*"", ""X"").replace(""."", ""_"").upper())\n      self.converter.body += (\n          f""file(GLOB {exclude_var} LIST_DIRECTORIES false""\n          f"" RELATIVE {_expand_cmake_var(\'CMAKE_CURRENT_SOURCE_DIR\')}""\n          f"" CONFIGURE_DEPENDS {pattern})\\n"")\n      for glob_var in glob_vars:\n        self.converter.body += (\n            f""list(REMOVE_ITEM {glob_var} {_expand_cmake_var(exclude_var)})\\n"")\n    return [_expand_cmake_var(var) for var in glob_vars]\n\n  # TODO(gcmn) implement these types of functions in a less hard-coded way\n  def platform_trampoline_deps(self, basename, path=""base""):\n    return [f""//iree/{path}/internal:{basename}_internal""]\n\n  def select(self, d):\n    self._convert_unimplemented_function(""select"", str(d))\n    return d[""//conditions:default""]\n\n  def config_setting(self, **kwargs):\n    # No mapping to CMake, ignore.\n    pass\n\n  def cc_library(self,\n                 name,\n                 hdrs=None,\n                 textual_hdrs=None,\n                 srcs=None,\n                 data=None,\n                 deps=None,\n                 alwayslink=False,\n                 testonly=False,\n                 linkopts=None,\n                 **kwargs):\n    if linkopts:\n      self._convert_unimplemented_function(""linkopts"")\n    name_block = self._convert_name_block(name)\n    hdrs_block = self._convert_hdrs_block(hdrs)\n    textual_hdrs_block = self._convert_textual_hdrs_block(textual_hdrs)\n    srcs_block = self._convert_srcs_block(srcs)\n    data_block = self._convert_data_block(data)\n    deps_block = self._convert_deps_block(deps)\n    alwayslink_block = self._convert_alwayslink_block(alwayslink)\n    testonly_block = self._convert_testonly_block(testonly)\n\n    self.converter.body += (f""iree_cc_library(\\n""\n                            f""{name_block}""\n                            f""{hdrs_block}""\n                            f""{textual_hdrs_block}""\n                            f""{srcs_block}""\n                            f""{data_block}""\n                            f""{deps_block}""\n                            f""{alwayslink_block}""\n                            f""{testonly_block}""\n                            f""  PUBLIC\\n)\\n\\n"")\n\n  def cc_test(self,\n              name,\n              hdrs=None,\n              srcs=None,\n              data=None,\n              deps=None,\n              tags=None,\n              **kwargs):\n    name_block = self._convert_name_block(name)\n    hdrs_block = self._convert_hdrs_block(hdrs)\n    srcs_block = self._convert_srcs_block(srcs)\n    data_block = self._convert_data_block(data)\n    deps_block = self._convert_deps_block(deps)\n    labels_block = self._convert_string_list_block(""LABELS"", tags)\n\n    self.converter.body += (f""iree_cc_test(\\n""\n                            f""{name_block}""\n                            f""{hdrs_block}""\n                            f""{srcs_block}""\n                            f""{data_block}""\n                            f""{deps_block}""\n                            f""{labels_block}""\n                            f"")\\n\\n"")\n\n  def cc_binary(self,\n                name,\n                srcs=None,\n                data=None,\n                deps=None,\n                linkopts=None,\n                testonly=False,\n                **kwargs):\n    if linkopts:\n      self._convert_unimplemented_function(""linkopts"")\n    name_block = self._convert_name_block(name)\n    out_block = self._convert_out_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n    data_block = self._convert_data_block(data)\n    deps_block = self._convert_deps_block(deps)\n    testonly_block = self._convert_testonly_block(testonly)\n\n    self.converter.body += (f""iree_cc_binary(\\n""\n                            f""{name_block}""\n                            f""{out_block}""\n                            f""{srcs_block}""\n                            f""{data_block}""\n                            f""{deps_block}""\n                            f""{testonly_block}""\n                            f"")\\n\\n"")\n\n  # Effectively an alias in IREE code.\n  iree_cc_binary = cc_binary\n\n  def cc_embed_data(self,\n                    name,\n                    srcs,\n                    cc_file_output,\n                    h_file_output,\n                    cpp_namespace=None,\n                    strip_prefix=None,\n                    flatten=False,\n                    identifier=None,\n                    **kwargs):\n    if identifier:\n      self._convert_unimplemented_function(""cc_embed_data"",\n                                           name + "" has identifier"")\n    name_block = self._convert_name_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n    cc_file_output_block = self._convert_cc_file_output_block(cc_file_output)\n    h_file_output_block = self._convert_h_file_output_block(h_file_output)\n    namespace_block = self._convert_cpp_namespace_block(cpp_namespace)\n    flatten_block = self._convert_flatten_block(flatten)\n\n    self.converter.body += (f""iree_cc_embed_data(\\n""\n                            f""{name_block}""\n                            f""{srcs_block}""\n                            f""{cc_file_output_block}""\n                            f""{h_file_output_block}""\n                            f""{namespace_block}""\n                            f""{flatten_block}""\n                            f""  PUBLIC\\n)\\n\\n"")\n\n  def spirv_kernel_cc_library(self, name, srcs):\n    name_block = self._convert_name_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n\n    self.converter.body += (f""iree_spirv_kernel_cc_library(\\n""\n                            f""{name_block}""\n                            f""{srcs_block}""\n                            f"")\\n\\n"")\n\n  def iree_bytecode_module(self,\n                           name,\n                           src,\n                           flags=[""-iree-mlir-to-vm-bytecode-module""],\n                           translate_tool=""//iree/tools:iree-translate"",\n                           cc_namespace=None):\n    name_block = self._convert_name_block(name)\n    src_block = self._convert_src_block(src)\n    namespace_block = self._convert_cc_namespace_block(cc_namespace)\n    translate_tool_block = self._convert_translate_tool_block(translate_tool)\n    flags_block = self._convert_string_list_block(""FLAGS"", flags)\n\n    self.converter.body += (f""iree_bytecode_module(\\n""\n                            f""{name_block}""\n                            f""{src_block}""\n                            f""{namespace_block}""\n                            f""{translate_tool_block}""\n                            f""{flags_block}""\n                            f""  PUBLIC\\n)\\n\\n"")\n\n  def iree_flatbuffer_cc_library(self, name, srcs, flatc_args=None):\n    name_block = self._convert_name_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n    flatc_args_block = self._convert_flatc_args_block(flatc_args)\n\n    self.converter.body += (f""flatbuffer_cc_library(\\n""\n                            f""{name_block}""\n                            f""{srcs_block}""\n                            f""{flatc_args_block}""\n                            f""  PUBLIC\\n)\\n\\n"")\n\n  def gentbl(self,\n             name,\n             tblgen,\n             td_file,\n             tbl_outs,\n             td_srcs=None,\n             td_includes=None,\n             strip_include_prefix=None,\n             test=False):\n    name_block = self._convert_name_block(name)\n    tblgen_block = self._convert_tblgen_block(tblgen)\n    td_file_block = self._convert_td_file_block(td_file)\n    outs_block = self._convert_tbl_outs_block(tbl_outs)\n\n    self.converter.body += (f""iree_tablegen_library(\\n""\n                            f""{name_block}""\n                            f""{td_file_block}""\n                            f""{outs_block}""\n                            f""{tblgen_block}""\n                            f"")\\n\\n"")\n\n  def iree_tablegen_doc(self,\n                        name,\n                        tblgen,\n                        td_file,\n                        tbl_outs,\n                        td_srcs=None,\n                        td_includes=None,\n                        strip_include_prefix=None):\n    name_block = self._convert_name_block(name)\n    tblgen_block = self._convert_tblgen_block(tblgen)\n    td_file_block = self._convert_td_file_block(td_file)\n    outs_block = self._convert_tbl_outs_block(tbl_outs)\n\n    self.converter.body += (f""iree_tablegen_doc(\\n""\n                            f""{name_block}""\n                            f""{td_file_block}""\n                            f""{outs_block}""\n                            f""{tblgen_block}""\n                            f"")\\n\\n"")\n\n  def iree_lit_test_suite(self, name, srcs, data, tags=None, **kwargs):\n    name_block = self._convert_name_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n    data_block = self._convert_data_block(data)\n    labels_block = self._convert_string_list_block(""LABELS"", tags)\n\n    self.converter.body += (f""iree_lit_test_suite(\\n""\n                            f""{name_block}""\n                            f""{srcs_block}""\n                            f""{data_block}""\n                            f""{labels_block}""\n                            f"")\\n\\n"")\n\n  def iree_check_single_backend_test_suite(self,\n                                           name,\n                                           srcs,\n                                           target_backend,\n                                           driver,\n                                           compiler_flags=None,\n                                           target_backends_and_drivers=None,\n                                           runner_args=None,\n                                           tags=None,\n                                           **kwargs):\n    name_block = self._convert_name_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n    target_backend_block = self._convert_string_arg_block(\n        ""TARGET_BACKEND"", target_backend)\n    driver_block = self._convert_string_arg_block(""DRIVER"", driver)\n    compiler_flags_block = self._convert_string_list_block(\n        ""COMPILER_FLAGS"", compiler_flags)\n    runner_args_block = self._convert_string_list_block(""RUNNER_ARGS"",\n                                                        runner_args)\n    labels_block = self._convert_string_list_block(""LABELS"", tags)\n\n    self.converter.body += (f""iree_check_single_backend_test_suite(\\n""\n                            f""{name_block}""\n                            f""{srcs_block}""\n                            f""{target_backend_block}""\n                            f""{driver_block}""\n                            f""{compiler_flags_block}""\n                            f""{runner_args_block}""\n                            f""{labels_block}""\n                            f"")\\n\\n"")\n\n  def iree_check_test_suite(self,\n                            name,\n                            srcs,\n                            target_backends_and_drivers=None,\n                            compiler_flags=None,\n                            runner_args=None,\n                            tags=None,\n                            **kwargs):\n    target_backends = None\n    drivers = None\n    if target_backends_and_drivers is not None:\n      target_backends = [it[0] for it in target_backends_and_drivers]\n      drivers = [it[1] for it in target_backends_and_drivers]\n\n    name_block = self._convert_name_block(name)\n    srcs_block = self._convert_srcs_block(srcs)\n    target_backends_block = self._convert_string_list_block(\n        ""TARGET_BACKENDS"", target_backends)\n    drivers_block = self._convert_string_list_block(""DRIVERS"", drivers)\n    compiler_flags_block = self._convert_string_list_block(\n        ""COMPILER_FLAGS"", compiler_flags)\n    runner_args_block = self._convert_string_list_block(""RUNNER_ARGS"",\n                                                        runner_args)\n    labels_block = self._convert_string_list_block(""LABELS"", tags)\n\n    self.converter.body += (f""iree_check_test_suite(\\n""\n                            f""{name_block}""\n                            f""{srcs_block}""\n                            f""{target_backends_block}""\n                            f""{drivers_block}""\n                            f""{compiler_flags_block}""\n                            f""{runner_args_block}""\n                            f""{labels_block}""\n                            f"")\\n\\n"")\n\n\nclass Converter(object):\n  """"""Conversion state tracking and full file template substitution.""""""\n\n  def __init__(self):\n    self.body = """"\n    self.first_error = None\n\n  def convert(self, copyright_line):\n    converted_content = (f""{copyright_line}\\n""\n                         f""{self.apache_license}\\n\\n""\n                         f""iree_add_all_subdirs()\\n\\n""\n                         f""{self.body}"")\n\n    # Cleanup newline characters. This is more convenient than ensuring all\n    # conversions are careful with where they insert newlines.\n    converted_content = converted_content.replace(""\\n\\n\\n"", ""\\n"")\n    converted_content = converted_content.rstrip() + ""\\n""\n\n    return converted_content\n\n  apache_license = textwrap.dedent(""""""\\\n    #\n    # Licensed under the Apache License, Version 2.0 (the ""License"");\n    # you may not use this file except in compliance with the License.\n    # You may obtain a copy of the License at\n    #\n    #      https://www.apache.org/licenses/LICENSE-2.0\n    #\n    # Unless required by applicable law or agreed to in writing, software\n    # distributed under the License is distributed on an ""AS IS"" BASIS,\n    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    # See the License for the specific language governing permissions and\n    # limitations under the License."""""")\n\n\ndef GetDict(obj):\n  ret = {}\n  for k in dir(obj):\n    if not k.startswith(""_""):\n      ret[k] = getattr(obj, k)\n  return ret\n\n\ndef convert_build_file(build_file_code,\n                       copyright_line,\n                       allow_partial_conversion=False):\n  converter = Converter()\n  exec(build_file_code, GetDict(BuildFileFunctions(converter)))\n  converted_text = converter.convert(copyright_line)\n  if not allow_partial_conversion and converter.first_error:\n    raise converter.first_error  # pylint: disable=raising-bad-type\n  return converted_text\n'"
build_tools/bazel_to_cmake/bazel_to_cmake_targets.py,0,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Bazel to CMake target name conversions used by bazel_to_cmake.py.\n\nEXPLICIT_TARGET_MAPPING = {\n    # absl\n    ""@com_google_absl//absl/flags:flag"": [""absl::flags""],\n    ""@com_google_absl//absl/flags:parse"": [""absl::flags_parse""],\n    # dear_imgui\n    ""@dear_imgui"": [""dear_imgui::dear_imgui""],\n    ""@dear_imgui//:imgui_sdl_vulkan"": [\n        ""dear_imgui::impl_sdl"", ""dear_imgui::impl_vulkan""\n    ],\n    # LLVM\n    ""@llvm-project//llvm:asm_parser"": [""LLVMAsmParser""],\n    ""@llvm-project//llvm:ir"": [""LLVMCore""],\n    ""@llvm-project//llvm:execution_engine"": [""LLVMExecutionEngine""],\n    ""@llvm-project//llvm:passes"": [""LLVMPasses""],\n    ""@llvm-project//llvm:target_base"": [""LLVMTarget""],\n    ""@llvm-project//llvm:support"": [""LLVMSupport""],\n    ""@llvm-project//llvm:orcjit"": [""LLVMOrcJIT""],\n    ""@llvm-project//llvm:tablegen"": [""LLVMTableGen""],\n    ""@llvm-project//llvm:x86_target"": [""LLVMX86CodeGen""],\n    # MLIR\n    ""@llvm-project//mlir:AllPassesAndDialects"": [""MLIRAllDialects""],\n    ""@llvm-project//mlir:AllPassesAndDialectsNoRegistration"": [\n        ""MLIRAllDialects""\n    ],\n    ""@llvm-project//mlir:Affine"": [""MLIRAffineOps""],\n    ""@llvm-project//mlir:AffineToStandardTransforms"": [""MLIRAffineToStandard""],\n    ""@llvm-project//mlir:CFGTransforms"": [""MLIRSCFToStandard""],\n    ""@llvm-project//mlir:ExecutionEngineUtils"": [""MLIRExecutionEngine""],\n    ""@llvm-project//mlir:GPUDialect"": [""MLIRGPU""],\n    ""@llvm-project//mlir:GPUToSPIRVTransforms"": [""MLIRGPUtoSPIRVTransforms""],\n    ""@llvm-project//mlir:GPUTransforms"": [""MLIRGPU""],\n    ""@llvm-project//mlir:LLVMTransforms"": [""MLIRStandardToLLVM""],\n    ""@llvm-project//mlir:SCFToGPUPass"": [""MLIRSCFToGPU""],\n    ""@llvm-project//mlir:SCFDialect"": [""MLIRSCF""],\n    ""@llvm-project//mlir:SCFTransforms"": [""MLIRSCFTransforms""],\n    ""@llvm-project//mlir:SideEffects"": [""MLIRSideEffectInterfaces""],\n    ""@llvm-project//mlir:SPIRVDialect"": [""MLIRSPIRV""],\n    ""@llvm-project//mlir:SPIRVLowering"": [""MLIRSPIRV"", ""MLIRSPIRVTransforms""],\n    ""@llvm-project//mlir:SPIRVTranslateRegistration"": [\n        ""MLIRSPIRVSerialization""\n    ],\n    ""@llvm-project//mlir:StandardToSPIRVConversions"": [\n        ""MLIRStandardToSPIRVTransforms""\n    ],\n    ""@llvm-project//mlir:TableGen"": [""MLIRTableGen""],\n    ""@llvm-project//mlir:mlir_c_runner_utils"": [""MLIRExecutionEngine""],\n    ""@llvm-project//mlir:mlir-translate"": [""mlir-translate""],\n    ""@llvm-project//mlir:MlirTableGenMain"": [""MLIRTableGen""],\n    ""@llvm-project//mlir:MlirOptLib"": [""MLIROptLib""],\n    ""@llvm-project//mlir:VectorOps"": [""MLIRVector""],\n    # Vulkan\n    # TODO(scotttodd): Set -DVK_NO_PROTOTYPES to COPTS for _no_prototypes.\n    #   Maybe add a wrapper CMake lib within build_tools/third_party/?\n    ""@iree_vulkan_headers//:vulkan_headers"": [""Vulkan::Headers""],\n    ""@iree_vulkan_headers//:vulkan_headers_no_prototypes"": [""Vulkan::Headers""],\n    # The Bazel target maps to the IMPORTED target defined by FindVulkan().\n    ""@vulkan_sdk//:sdk"": [""Vulkan::Vulkan""],\n    # Misc single targets\n    ""@com_google_benchmark//:benchmark"": [""benchmark""],\n    ""@com_github_google_flatbuffers//:flatbuffers"": [""flatbuffers""],\n    ""@com_google_googletest//:gtest"": [""gmock"", ""gtest""],\n    ""@renderdoc_api//:renderdoc_app"": [""renderdoc_api::renderdoc_app""],\n    ""@sdl2//:SDL2"": [""SDL2-static""]\n}\n\n\ndef _convert_absl_target(target):\n  # Default to a pattern substitution approach.\n  # Take ""absl::"" and append the name part of the full target identifier, e.g.\n  #   ""@com_google_absl//absl/memory""         -> ""absl::memory""\n  #   ""@com_google_absl//absl/types:optional"" -> ""absl::optional""\n  #   ""@com_google_absl//absl/types:span""     -> ""absl::span""\n  if "":"" in target:\n    target_name = target.rsplit("":"")[-1]\n  else:\n    target_name = target.rsplit(""/"")[-1]\n  return [""absl::"" + target_name]\n\n\ndef _convert_mlir_target(target):\n  # Default to a pattern substitution approach.\n  # Take ""MLIR"" and append the name part of the full target identifier, e.g.\n  #   ""@llvm-project//mlir:IR""   -> ""MLIRIR""\n  #   ""@llvm-project//mlir:Pass"" -> ""MLIRPass""\n  return [""MLIR"" + target.rsplit("":"")[-1]]\n\n\ndef convert_external_target(target):\n  """"""Converts an external (non-IREE) Bazel target to a list of CMake targets.\n\n  IREE targets are expected to follow a standard form between Bazel and CMake\n  that facilitates conversion. External targets *may* have their own patterns,\n  or they may be purely special cases.\n\n  Multiple target in Bazel may map to a single target in CMake and a Bazel\n  target may map to multiple CMake targets.\n\n  Returns:\n    A list of converted targets if it was successfully converted.\n\n  Raises:\n    KeyError: No conversion was found for the target.\n  """"""\n  if target in EXPLICIT_TARGET_MAPPING:\n    return EXPLICIT_TARGET_MAPPING[target]\n  if target.startswith(""@com_google_absl//absl""):\n    return _convert_absl_target(target)\n  if target.startswith(""@llvm-project//mlir""):\n    return _convert_mlir_target(target)\n  if target.startswith(""@org_tensorflow//tensorflow/compiler/mlir""):\n    # All Bazel targets map to a single CMake target.\n    return [""tensorflow::mlir_xla""]\n  if target.startswith(""@com_google_ruy//ruy""):\n    # All Bazel targets map to a single CMake target.\n    return [""ruy""]\n\n  raise KeyError(""No conversion found for target \'%s\'"" % target)\n'"
packaging/python/__init__.py,0,b'\n'
packaging/python/common_setup.py,0,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport platform\nimport setuptools\nimport sys\nfrom datetime import date\n\n\ndef get_exe_suffix():\n  if platform.system() == ""Windows"":\n    return "".exe""\n  else:\n    return """"\n\n\ndef get_package_dir(prefix=(""bindings"", ""python"")):\n  cmake_build_root = os.environ.get(""PYIREE_CMAKE_BUILD_ROOT"")\n  bazel_build_root = os.environ.get(""PYIREE_BAZEL_BUILD_ROOT"")\n\n  if cmake_build_root and bazel_build_root:\n    print(""ERROR: Both PYIREE_CMAKE_BUILD_ROOT and PYIREE_BAZEL_BUILD_ROOT""\n          "" cannot be set at the same time"")\n    sys.exit(1)\n\n  if cmake_build_root:\n    print(""Using CMake build root:"", cmake_build_root)\n    pkg_dir = os.path.join(cmake_build_root, *prefix)\n  elif bazel_build_root:\n    print(""Using Bazel build root:"", bazel_build_root)\n    if not os.path.isdir(bazel_build_root):\n      print(""ERROR: Could not find bazel-bin:"", bazel_build_root)\n      sys.exit(1)\n    # Find the path to the runfiles of the built target:\n    #   //bindings/python/packaging:all_pyiree_packages\n    runfiles_dir = os.path.join(\n        bazel_build_root, ""packaging"", ""python"",\n        ""all_pyiree_packages%s.runfiles"" % (get_exe_suffix(),))\n    if not os.path.isdir(runfiles_dir):\n      print(""ERROR: Could not find build target \'all_pyiree_packages\':"",\n            runfiles_dir)\n      print(""Make sure to build target"",\n            ""//packaging/python:all_pyiree_packages"")\n      sys.exit(1)\n    # And finally seek into the corresponding path in the runfiles dir.\n    # Aren\'t bazel paths fun???\n    # Note that the ""iree_core"" path segment corresponds to the workspace name.\n    pkg_dir = os.path.join(runfiles_dir, ""iree_core"", *prefix)\n  else:\n    print(""ERROR: No build directory specified. Set one of these variables:"")\n    print(""  PYIREE_CMAKE_BUILD_ROOT=/path/to/cmake/build"")\n    sys.exit(1)\n\n  if not os.path.exists(pkg_dir):\n    print(""ERROR: Package path does not exist:"", pkg_dir)\n    sys.exit(1)\n  return pkg_dir\n\n\ndef get_default_date_version():\n  today = date.today()\n  return today.strftime(""%Y%m%d"")\n\n\ndef get_setup_defaults(sub_project, description, package_dir=None):\n  if not package_dir:\n    package_dir = get_package_dir()\n  return {\n      ""name"": ""google-iree-%s"" % (sub_project,),\n      ""version"": get_default_date_version(),\n      ""author"": ""The IREE Team at Google"",\n      ""author_email"": ""iree-discuss@googlegroups.com"",\n      ""description"": description,\n      ""long_description"": description,\n      ""long_description_content_type"": ""text/plain"",\n      ""url"": ""https://github.com/google/iree"",\n      ""package_dir"": {\n          """": package_dir,\n      },\n      ""classifiers"": [\n          ""Programming Language :: Python :: 3"",\n          ""License :: OSI Approved :: Apache License"",\n          ""Operating System :: OS Independent"",\n          ""Development Status :: 3 - Alpha"",\n      ],\n      ""python_requires"": "">=3.6"",\n  }\n\n\ndef get_native_file_extension():\n  if platform.system() == ""Windows"":\n    return ""pyd""\n  elif platform.system() == ""Darwin"":\n    return ""dylib""\n  else:\n    return ""so""\n\n\ndef setup(**kwargs):\n  # See: https://stackoverflow.com/q/45150304\n  try:\n    from wheel.bdist_wheel import bdist_wheel as _bdist_wheel\n\n    class bdist_wheel(_bdist_wheel):\n\n      def finalize_options(self):\n        _bdist_wheel.finalize_options(self)\n        self.root_is_pure = False\n  except ImportError:\n    bdist_wheel = None\n\n  # Need to include platform specific extensions binaries:\n  #  Windows: .pyd\n  #  MacOS: .dylib\n  #  Other: .so\n  # Unfortunately, bazel is imprecise and scatters .so files around, so\n  # need to be specific.\n  package_data = {\n      """": [""*.%s"" % (get_native_file_extension(),)],\n  }\n  setuptools.setup(\n      package_data=package_data,\n      cmdclass={""bdist_wheel"": bdist_wheel},\n      **kwargs)\n'"
packaging/python/dummy_exclude_from_package.py,0,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
packaging/python/setup_compiler.py,0,"b'#!/usr/bin/python3\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Build platform specific wheel files for the pyiree.rt package.\n# Built artifacts are per-platform and build out of the build tree.\n# Usage:\n# ------\n# Windows with CMake:\n#   export CMAKE_BUILD_ROOT=\'D:\\src\\build-iree\'  # Must be native path\n#   python ./setup_compiler.py bdist_wheel\n\nimport os\nimport setuptools\nimport sys\n\n# Ensure that path starts here for execution as a script.\nsys.path.insert(0, os.path.dirname(__file__))\nimport common_setup\n\n\ndef run():\n  packages = setuptools.find_namespace_packages(\n      common_setup.get_package_dir(),\n      include=[""pyiree.compiler"", ""pyiree.compiler.*""],\n      exclude=[""*.CMakeFiles""])\n  print(""Found packages:"", packages)\n  setup_kwargs = common_setup.get_setup_defaults(\n      sub_project=""compiler"", description=""IREE Generic Compiler"")\n  common_setup.setup(packages=packages, **setup_kwargs)\n\n\nif __name__ == ""__main__"":\n  run()\n'"
packaging/python/setup_rt.py,0,"b'#!/usr/bin/python3\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Build platform specific wheel files for the pyiree.rt package.\n# Built artifacts are per-platform and build out of the build tree.\n\nimport os\nimport setuptools\nimport sys\n\n# Ensure that path starts here for execution as a script.\nsys.path.insert(0, os.path.dirname(__file__))\nimport common_setup\n\n\ndef run():\n  packages = setuptools.find_namespace_packages(\n      common_setup.get_package_dir(),\n      include=[""pyiree.rt"", ""pyiree.rt.*""],\n      exclude=[""*.CMakeFiles""])\n  print(""Found packages:"", packages)\n  setup_kwargs = common_setup.get_setup_defaults(\n      sub_project=""rt"",\n      description=""IREE Runtime Components (for executing compiled programs)"")\n  common_setup.setup(packages=packages, **setup_kwargs)\n\n\nif __name__ == ""__main__"":\n  run()\n'"
packaging/python/setup_tf.py,2,"b'#!/usr/bin/python3\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Build platform specific wheel files for the pyiree.tf packages.\n# Built artifacts are per-platform and build out of the build tree.\n\nimport os\nimport platform\nimport setuptools\nimport sys\n\n# Ensure that path starts here for execution as a script.\nsys.path.insert(0, os.path.dirname(__file__))\nimport common_setup\n\n\ndef run():\n  package_dir = common_setup.get_package_dir(\n      prefix=(""integrations"", ""tensorflow"", ""bindings"", ""python""))\n  packages = setuptools.find_namespace_packages(\n      package_dir,\n      include=[\n          ""pyiree.tf.compiler"", ""pyiree.tf.compiler.*"", ""pyiree.tf.support"",\n          ""pyiree.tf.support.*""\n      ],\n      exclude=[""*.CMakeFiles""])\n  print(""Found packages:"", packages)\n  if not packages:\n    print(""ERROR: Did not find packages under"", package_dir)\n    sys.exit(1)\n  setup_kwargs = common_setup.get_setup_defaults(\n      sub_project=""tf"",\n      description=""IREE TensorFlow Compiler"",\n      package_dir=package_dir)\n  common_setup.setup(packages=packages, **setup_kwargs)\n\n\nif __name__ == ""__main__"":\n  run()\n'"
scripts/git/__init__.py,0,b'\n'
scripts/git/submodule_versions.py,0,"b'#!/usr/bin/env python3\n# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=missing-docstring\n""""""submodule_versions.\n\nSynchronizes the tracked SUBMODULE_VERSIONS file with the submodule state\nin git.\n\nTypical usage:\n--------------\nExporting current git submodule state to SUBMODULE_VERSIONS:\n  Syntax: ./scripts/git/submodule_versions.py export\n\nImporting versions in SUBMODULE_VERSIONS to git submodule state:\n  Syntax: ./scripts/git/submodule_versions.py import\n\nChecking whether SUBMODULE_VERSIONS and git state are in sync:\n  Syntax: ./scripts/git/submodule_versions.py check\n""""""\n\nimport argparse\nimport os\nimport re\nimport sys\n\nimport utils\n\nVERSIONS_FILE = ""SUBMODULE_VERSIONS""\n\n\ndef get_submodule_versions(repo_dir):\n  raw_status = utils.execute([""git"", ""submodule"", ""status""],\n                             cwd=repo_dir,\n                             silent=True,\n                             capture_output=True).decode(""UTF-8"")\n  status_lines = []\n  for line in raw_status.splitlines():\n    # Format is a status char followed by revision, space and path.\n    m = re.match(r""""""^.([0-9a-z]+)\\s+([^\\s]+)"""""", line)\n    if m:\n      # Output as just the commit hash followed by space and path.\n      status_lines.append(m.group(1) + "" "" + m.group(2))\n  return ""\\n"".join(status_lines) + ""\\n""\n\n\ndef export_versions(repo_dir):\n  current_versions = get_submodule_versions(repo_dir)\n  versions_file_path = os.path.join(repo_dir, VERSIONS_FILE)\n  print(""*** Exporting current submodule versions to:"", versions_file_path)\n  with open(versions_file_path, ""w"", encoding=""UTF-8"") as f:\n    f.write(current_versions)\n  utils.execute([""git"", ""add"", VERSIONS_FILE], cwd=repo_dir)\n\n\ndef parse_versions(versions_text):\n  versions = dict()\n  for line in versions_text.splitlines():\n    comps = line.split("" "", maxsplit=2)\n    if len(comps) != 2:\n      continue\n    versions[comps[1]] = comps[0]\n  return versions\n\n\ndef get_diff_versions(repo_dir):\n  current_versions = parse_versions(get_submodule_versions(repo_dir))\n  with open(os.path.join(repo_dir, VERSIONS_FILE), ""r"", encoding=""UTF-8"") as f:\n    written_versions = parse_versions(f.read())\n  diff_versions = current_versions.items() ^ written_versions.items()\n  return {\n      k: (current_versions.get(k), written_versions.get(k))\n      for k, _ in diff_versions\n  }\n\n\ndef sync_and_update_submodules(repo_dir):\n  print(""*** Synchronizing/updating submodules"")\n  utils.execute([""git"", ""submodule"", ""sync""], cwd=repo_dir)\n  utils.execute([""git"", ""submodule"", ""update""], cwd=repo_dir)\n\n\ndef import_versions(repo_dir):\n  print(""*** Importing versions to git submodule state"")\n  diff_versions = get_diff_versions(repo_dir)\n  if not diff_versions:\n    print(""*** No submodule updates required"")\n    return\n  for path, (current, written) in diff_versions.items():\n    if current is None:\n      print((""Warning: Submodule %s does not exist but is ""\n             ""still in the version file"") % (path,))\n      continue\n    if written is None:\n      print(""Warning: Submodule %s is not in the version file"" % (current,))\n      continue\n    # Directly update the submodule commit hash in the index.\n    # See: https://stackoverflow.com/questions/33514642\n    command = [""git"", ""update-index"", ""--cacheinfo"", ""160000"", written, path]\n    print(""Updating"", path, ""to"", written)\n    utils.execute(command, cwd=repo_dir)\n\n\ndef init_submodules(repo_dir):\n  print(""*** Initializing submodules"")\n  utils.execute([""git"", ""submodule"", ""init""], cwd=repo_dir)\n\n\ndef parallel_shallow_update_submodules(repo_dir):\n  print(""*** Making shallow clone of submodules"")\n  utils.execute([""git"", ""submodule"", ""update"", ""--jobs"", ""8"", ""--depth"", ""1""],\n                cwd=repo_dir)\n\n\ndef check_submodule_versions(repo_dir):\n  diff_versions = get_diff_versions(repo_dir)\n  if diff_versions:\n    print(\n        ""Submodule state differs from SUBMODULE_VERSIONS file. Run (and commit) one of:""\n    )\n    print(\n        ""  ./scripts/git/submodule_versions.py import # Use version in SUBMODULE_VERSIONS""\n    )\n    print(\n        ""  ./scripts/git/submodule_versions.py export # Use version in git state""\n    )\n    for k, (current, written) in diff_versions.items():\n      print(""%s : actual=%s written=%s"" % (k, current, written))\n    return False\n  return True\n\n\ndef parse_arguments():\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--repo"", help=""Repository root directory"")\n  parser.add_argument(\n      ""command"", help=""Command to run (show|import|export|check|init)"")\n  args = parser.parse_args()\n\n  # Default repo path.\n  if args.repo is None:\n    args.repo = utils.find_git_toplevel()\n  return args\n\n\ndef main(args):\n  if args.command == ""show"":\n    print(get_submodule_versions(args.repo))\n  elif args.command == ""export"":\n    sync_and_update_submodules(args.repo)\n    export_versions(args.repo)\n  elif args.command == ""check"":\n    if not check_submodule_versions(args.repo):\n      sys.exit(1)\n  elif args.command == ""import"":\n    import_versions(args.repo)\n    sync_and_update_submodules(args.repo)\n  elif args.command == ""init"":\n    init_submodules(args.repo)\n    # Redundant, since import_versions will only update if they differ,\n    # but good to only print output about the import if it\'s actually\n    # needed.\n    if not check_submodule_versions(args.repo):\n      print(""Warning: git submodule state does not match SUBMODULE_VERSIONS. ""\n            ""Using state in SUBMODULE_VERSIONS"")\n      import_versions(args.repo)\n    parallel_shallow_update_submodules(args.repo)\n  else:\n    print(""Unrecognized command:"", args.command)\n    sys.exit(1)\n\n\nif __name__ == ""__main__"":\n  main(parse_arguments())\n'"
scripts/git/update_tf_llvm_submodules.py,0,"b'#!/usr/bin/env python3\n# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=missing-docstring\n""""""update_tf_llvm_submodules.\n\nUpdates the third_party/tensorflow and third_party/llvm-project submodules\nto new commits. We have special conditions around these submodules since\nupstream will only accept an llvm-project version that is sync\'d with the\ncorresponding version that tensorflow depends on. In addition, some BUILD\nfiles must be sync\'d for the new version.\n\nTypical usage:\n  Syntax: ./scripts/git/update_tf_llvm_submodules.py\n\n  By default, this will update the tensorflow submodule to remote HEAD and\n  update the llvm-project submodule to the corresponding version. It will\n  also sync BUILD file changes as needed and export the version metadata.\n""""""\n\nimport argparse\nimport re\nimport os\nimport sys\n\nimport submodule_versions\nimport utils\n\n\ndef parse_arguments():\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--repo"", help=""Repository root directory"")\n  parser.add_argument(\n      ""--tensorflow"",\n      help=""Path to the tensorflow sources ""\n      ""(default to third_party/tensorflow)"",\n      default=None)\n  parser.add_argument(\n      ""--llvm"",\n      help=""Path to the LLVM sources ""\n      ""(defaults to third_party/llvm-project)"",\n      default=None)\n  parser.add_argument(\n      ""--tensorflow_commit"",\n      help=""Update TensorFlow to this commit (or \'KEEP\', \'REMOTE\')"",\n      default=""REMOTE"")\n  parser.add_argument(\n      ""--llvm_commit"",\n      help=""Update LLVM to this commit (or \'KEEP\', \'REMOTE\', \'TENSORFLOW\')"",\n      default=""TENSORFLOW"")\n  parser.add_argument(\n      ""--update_build_files"",\n      help=(""Updates the IREE LLVM build files from TensorFlow.""\n            ""Defaults to True iff llvm_commit==TENSORFLOW""),\n      type=utils.str2bool,\n      nargs=""?"",\n      default=None)\n  args = parser.parse_args()\n\n  # Default repo path.\n  if args.repo is None:\n    args.repo = utils.find_git_toplevel()\n\n  # Set some defaults.\n  if not args.tensorflow:\n    args.tensorflow = os.path.join(args.repo, ""third_party"", ""tensorflow"")\n  if not args.llvm:\n    args.llvm = os.path.join(args.repo, ""third_party"", ""llvm-project"")\n  return args\n\n\ndef main(args):\n  print(""IREE handy-dandy-LLVM-submodule-updater at your service..."")\n  print(""  IREE Path :"", args.repo)\n  print(""  LLVM Path :"", args.llvm)\n  print(""  TensorFlow Path :"", args.tensorflow)\n  print(""  Update Build files:"", args.update_build_files)\n  current_llvm_commit = get_commit(args.llvm)\n  current_tensorflow_commit = get_commit(args.tensorflow)\n\n  print(""Current Commits: llvm ="", current_llvm_commit, ""tensorflow ="",\n        current_tensorflow_commit)\n\n  # Update TensorFlow\n  if args.tensorflow_commit == ""KEEP"":\n    print(""Not updating TensorFlow (--tensorflow_commit == \'KEEP\')"")\n  else:\n    print(""\\n*** Updating TensorFlow to"", args.tensorflow_commit, ""***"")\n    update_submodule(args.tensorflow, args.tensorflow_commit)\n    stage_path(args.repo, ""third_party/tensorflow"")\n\n  # Update LLVM.\n  if args.llvm_commit == ""TENSORFLOW"":\n    args.llvm_commit = find_tensorflow_llvm_commit(args.tensorflow)\n    print(""Found TensorFlow\'s LLVM commit:"", args.llvm_commit)\n    if args.update_build_files is None:\n      print(""Will update build files from TensorFlow"",\n            ""because --update_build_files not specified"")\n      args.update_build_files = True\n  if args.llvm_commit == ""KEEP"":\n    print(""Not updating LLVM (--llvm_commit == \'KEEP\')"")\n  else:\n    print(""\\n*** Updating LLVM to"", args.llvm_commit, ""***"")\n    update_submodule(args.llvm, args.llvm_commit)\n    stage_path(args.repo, ""third_party/llvm-project"")\n\n  # Update build files.\n  if not args.update_build_files:\n    print(""Not updating build files (--update_build_files not specified)"")\n  else:\n    print(""\\n*** Updating BUILD.bazel files ***"")\n    update_build_files_from_tensorflow(args.repo, args.tensorflow)\n\n  # Export SUBMODULE_VERSIONS.\n  print()  # Add line break.\n  submodule_versions.export_versions(args.repo)\n\n\ndef get_commit(path, rev=""HEAD""):\n  return utils.execute([""git"", ""rev-parse"", rev],\n                       cwd=path,\n                       silent=True,\n                       capture_output=True).decode(""ISO-8859-1"").strip()\n\n\ndef update_submodule(path, commit, tracking=""origin/master""):\n  # Fetch.\n  utils.execute([""git"", ""fetch""], cwd=path)\n  # Determine commit.\n  if commit == ""REMOTE"":\n    commit = get_commit(path, rev=tracking)\n    print(""Resolved remote commit:"", commit)\n\n  # Rebase to commit (will fail if not fast-forward).\n  utils.execute([""git"", ""checkout"", commit], cwd=path)\n\n\ndef find_tensorflow_llvm_commit(tensorflow_path):\n  # TensorFlow keeps its commit in workspace.bzl on a line like:\n  # LLVM_COMMIT = ""...""\n  # Yeah. This is how we do it.\n  workspace_path = os.path.join(tensorflow_path, ""tensorflow"", ""workspace.bzl"")\n  pattern_text = r""""""\\s*LLVM_COMMIT\\s*=\\s*""(.+)""\\s*""""""\n  pattern = re.compile(pattern_text, flags=re.MULTILINE)\n  for line in open(workspace_path, ""r"", encoding=""UTF-8""):\n    m = re.match(pattern, line)\n    if m:\n      return m.group(1)\n\n  print(""ERROR: Could not find LLVM commit in %s."" % workspace_path)\n  print(""Request an explicit commit via --llvm_commit (and file a bug)"")\n  print(""Expected pattern match for:"", pattern_text)\n  sys.exit(1)\n\n\ndef update_build_files_from_tensorflow(repo_path, tensorflow_path):\n  src_llvm_build = os.path.join(tensorflow_path, ""third_party"", ""llvm"",\n                                ""llvm.autogenerated.BUILD"")\n  # NOTE(laurenzo): These will probably move upstream.\n  src_mlir_build = os.path.join(tensorflow_path, ""third_party"", ""mlir"", ""BUILD"")\n  src_mlir_test_build = os.path.join(tensorflow_path, ""third_party"", ""mlir"",\n                                     ""test.BUILD"")\n  overlay_path = os.path.join(repo_path, ""build_tools"", ""bazel"",\n                              ""third_party_import"", ""llvm-project"", ""overlay"")\n  copy_text_file(repo_path, src_llvm_build,\n                 os.path.join(overlay_path, ""llvm"", ""BUILD.bazel""))\n  copy_text_file(repo_path, src_mlir_build,\n                 os.path.join(overlay_path, ""mlir"", ""BUILD.bazel""))\n  copy_text_file(repo_path, src_mlir_test_build,\n                 os.path.join(overlay_path, ""mlir"", ""test"", ""BUILD.bazel""))\n\n\ndef copy_text_file(repo_path, src_file, dst_file):\n  print(""+ cp %s %s"" % (src_file, dst_file))\n  with open(src_file, ""r"", encoding=""UTF-8"") as f:\n    src_contents = f.read()\n\n  if not os.path.exists(dst_file):\n    print(""WARNING: Destination file does not exist:"", dst_file)\n  with open(dst_file, ""w"", encoding=""UTF-8"") as f:\n    f.write(src_contents)\n  stage_path(repo_path, dst_file)\n\n\ndef stage_path(repo_path, to_stage):\n  # TODO(laurenzo): Move to utils.py.\n  utils.execute([""git"", ""add"", to_stage], cwd=repo_path)\n\n\nif __name__ == ""__main__"":\n  main(parse_arguments())\n'"
scripts/git/utils.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=missing-docstring\n\nimport argparse\nimport os\nimport subprocess\n\n\ndef find_git_toplevel():\n  """"""Finds the containing git top-level directory that contains this script.""""""\n  return execute([""git"", ""rev-parse"", ""--show-toplevel""],\n                 cwd=os.path.dirname(__file__),\n                 capture_output=True,\n                 silent=True).strip().decode(""UTF-8"")\n\n\ndef str2bool(v):\n  """"""Can be used as an argparse type to parse a bool.""""""\n  if v is None:\n    return None\n  if isinstance(v, bool):\n    return v\n  if v.lower() in (""yes"", ""true"", ""t"", ""y"", ""1""):\n    return True\n  elif v.lower() in (""no"", ""false"", ""f"", ""n"", ""0""):\n    return False\n  else:\n    raise argparse.ArgumentTypeError(""Boolean value expected."")\n\n\ndef execute(args, cwd, capture_output=False, silent=False, **kwargs):\n  """"""Executes a command.\n\n  Args:\n    args: List of command line arguments.\n    cwd: Directory to execute in.\n    capture_output: Whether to capture the output.\n    silent: Whether to skip logging the invocation.\n    **kwargs: Extra arguments to pass to subprocess.exec\n\n  Returns:\n    The output if capture_output, otherwise None.\n  """"""\n  if not silent:\n    print(""+"", "" "".join(args), ""  [from %s]"" % cwd)\n  if capture_output:\n    return subprocess.check_output(args, cwd=cwd, **kwargs)\n  else:\n    return subprocess.check_call(args, cwd=cwd, **kwargs)\n'"
integrations/tensorflow/e2e/batch_norm_test.py,11,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Batch norm tests.""""""\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass BatchNormModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 16], tf.float32),\n      tf.TensorSpec([16], tf.float32),\n      tf.TensorSpec([16], tf.float32),\n      tf.TensorSpec([16], tf.float32),\n      tf.TensorSpec([16], tf.float32),\n  ])\n  def batch_norm_inference(self, x, mean, variance, offset, scale):\n    return tf.nn.batch_normalization(\n        x,\n        mean=mean,\n        variance=variance,\n        offset=offset,\n        scale=scale,\n        variance_epsilon=1e-4)\n\n\n@tf_test_utils.compile_modules(backends=[""iree_vmla""], bn=BatchNormModule)\nclass BatchNormTest(tf_test_utils.SavedModelTestCase):\n\n  def test_batch_norm_inference(self):\n    np.random.seed(12345)\n    # Note: scaling by a small value to increase numerical stability.\n    x = np.random.random((4, 16)).astype(np.float32) * 1e-3\n    mean = np.random.random((16,)).astype(np.float32) * 1e-3\n    variance = np.random.random((16,)).astype(np.float32) * 1e-3\n    offset = np.random.random((16,)).astype(np.float32) * 1e-3\n    scale = np.random.random((16,)).astype(np.float32) * 1e-3\n    r = self.modules.bn.all.batch_norm_inference(x, mean, variance, offset,\n                                                 scale)\n    r.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/broadcasting_test.py,10,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test broadcasting support.""""""\n\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass BroadcastingModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([None], tf.float32),\n      tf.TensorSpec([None], tf.float32),\n  ])\n  def add(self, lhs, rhs):\n    return lhs + rhs\n\n\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], m=BroadcastingModule)\nclass BroadcastingTest(tf_test_utils.SavedModelTestCase):\n\n  def test_add_same_shape(self):\n    m = self.modules.m.all\n    dst = m.add(tf.random.uniform([4]), tf.random.uniform([4]))\n    dst.print().assert_all_close()\n\n\n# TODO(silvasean): Make these work.\n#   def test_add_broadcast_lhs(self):\n#     m = self.modules.m.all\n#     dst = m.add(tf.random.uniform([1]), tf.random.uniform([4]))\n#     dst.print().assert_all_close()\n#\n#   def test_add_broadcast_rhs(self):\n#     m = self.modules.m.all\n#     dst = m.add(tf.random.uniform([4]), tf.random.uniform([1]))\n#     dst.print().assert_all_close()\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/control_flow_test.py,5,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass ControlFlowModule(tf.Module):\n\n  def __init__(self):\n    pass\n\n  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n  def collatz(self, a):\n    i = 0.\n    while a > 1.:\n      i = i + 1.\n      if (a % 2.) > 0.:\n        a = 3. * a + 1.\n      else:\n        a = a / 2.\n    return i\n\n\n# TODO(b/146900329): Triage op coverage for vulkan backend.\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], control_flow=ControlFlowModule)\nclass ControlFlowTest(tf_test_utils.SavedModelTestCase):\n\n  def test_short_sequence(self):\n    input_array = numpy.array(9., dtype=numpy.float32)\n    result = self.modules.control_flow.all.collatz(input_array)\n    result.print().assert_all_close()\n\n  def test_long_sequence(self):\n    input_array = numpy.array(178., dtype=numpy.float32)\n    result = self.modules.control_flow.all.collatz(input_array)\n    result.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/conv_test.py,48,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass Conv2dModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 1], tf.float32),\n      tf.TensorSpec([1, 1, 1, 1], tf.float32),\n  ])\n  def conv2d_1451x1111_valid(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""VALID"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([2, 4, 5, 1], tf.float32),\n      tf.TensorSpec([1, 1, 1, 1], tf.float32),\n  ])\n  def conv2d_2451x1111_valid(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""VALID"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 1], tf.float32),\n      tf.TensorSpec([2, 3, 1, 1], tf.float32),\n  ])\n  def conv2d_1451x2311_valid(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""VALID"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 1], tf.float32),\n      tf.TensorSpec([2, 3, 1, 1], tf.float32),\n  ])\n  def conv2d_1451x2311_same(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([2, 4, 5, 1], tf.float32),\n      tf.TensorSpec([2, 3, 1, 1], tf.float32),\n  ])\n  def conv2d_2451x2311_same(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 2], tf.float32),\n      tf.TensorSpec([3, 2, 2, 1], tf.float32),\n  ])\n  def conv2d_1452x3221_same(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 1], tf.float32),\n      tf.TensorSpec([1, 1, 1, 2], tf.float32),\n  ])\n  def conv2d_1451x1112_same(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 2], tf.float32),\n      tf.TensorSpec([1, 1, 2, 2], tf.float32),\n  ])\n  def conv2d_1452x1122_same(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 2], tf.float32),\n      tf.TensorSpec([2, 2, 2, 3], tf.float32),\n  ])\n  def conv2d_1452x2223_same(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 5, 2], tf.float32),\n      tf.TensorSpec([2, 2, 2, 3], tf.float32),\n  ])\n  def conv2d_1452x2223_valid(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""VALID"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([2, 4, 5, 2], tf.float32),\n      tf.TensorSpec([2, 2, 2, 3], tf.float32),\n  ])\n  def conv2d_2452x2223_valid(self, img, kernel):\n    return tf.nn.conv2d(img, kernel, [1, 1, 1, 1], ""VALID"", name=""result"")\n\n\n@tf_test_utils.compile_modules(conv2d=Conv2dModule)\nclass ConvTest(tf_test_utils.SavedModelTestCase):\n\n  def test_id_batch_size_1(self):\n    i = np.arange(20, dtype=np.float32).reshape([1, 4, 5, 1])\n    k = np.ones([1, 1, 1, 1], dtype=np.float32)\n    r = self.modules.conv2d.all.conv2d_1451x1111_valid(i, k)\n    r.print().assert_all_close()\n\n  def test_id_batch_size_2(self):\n    i = np.arange(40, dtype=np.float32).reshape([2, 4, 5, 1])\n    k = np.ones([1, 1, 1, 1], dtype=np.float32)\n    r = self.modules.conv2d.all.conv2d_2451x1111_valid(i, k)\n    r.print().assert_all_close()\n\n  def test_asym_kernel(self):\n    i = np.arange(20, dtype=np.float32).reshape([1, 4, 5, 1])\n    k = np.array([[1, 4, 2], [-2, 0, 1]], dtype=np.float32).reshape(2, 3, 1, 1)\n    r = self.modules.conv2d.all.conv2d_1451x2311_valid(i, k)\n    r.print().assert_all_close()\n\n  def test_padding(self):\n    i = np.arange(20, dtype=np.float32).reshape([1, 4, 5, 1])\n    k = np.array([[1, 4, 2], [-2, 0, 1]], dtype=np.float32).reshape(2, 3, 1, 1)\n    r = self.modules.conv2d.all.conv2d_1451x2311_same(i, k)\n    r.print().assert_all_close()\n\n  def test_batched_padding(self):\n    i = np.arange(40, dtype=np.float32).reshape([2, 4, 5, 1])\n    k = np.array([[1, 4, 2], [-2, 0, 1]], dtype=np.float32).reshape(2, 3, 1, 1)\n    r = self.modules.conv2d.all.conv2d_2451x2311_same(i, k)\n    r.print().assert_all_close()\n\n  def test_feature_reduce(self):\n    i = np.arange(40, dtype=np.float32).reshape([1, 4, 5, 2])\n    k = np.ones([3, 2, 2, 1], dtype=np.float32)\n    r = self.modules.conv2d.all.conv2d_1452x3221_same(i, k)\n    r.print().assert_all_close()\n\n  def test_feature_inflate(self):\n    i = np.arange(20, dtype=np.float32).reshape([1, 4, 5, 1])\n    k = np.arange(2, dtype=np.float32).reshape([1, 1, 1, 2])\n    r = self.modules.conv2d.all.conv2d_1451x1112_same(i, k)\n    r.print().assert_all_close()\n\n  def test_feature_mix(self):\n    i = np.arange(40, dtype=np.float32).reshape([1, 4, 5, 2])\n    k = np.arange(4, dtype=np.float32).reshape([1, 1, 2, 2])\n    r = self.modules.conv2d.all.conv2d_1452x1122_same(i, k)\n    r.print().assert_all_close()\n\n  def test_feature_padded(self):\n    i = np.arange(40, dtype=np.float32).reshape([1, 4, 5, 2])\n    k = np.arange(24, dtype=np.float32).reshape([2, 2, 2, 3])\n    r = self.modules.conv2d.all.conv2d_1452x2223_same(i, k)\n    r.print().assert_all_close()\n\n  def test_feature_unpadded(self):\n    i = np.arange(40, dtype=np.float32).reshape([1, 4, 5, 2])\n    k = np.arange(24, dtype=np.float32).reshape([2, 2, 2, 3])\n    r = self.modules.conv2d.all.conv2d_1452x2223_valid(i, k)\n    r.print().assert_all_close()\n\n  def test_batched_feature_unpadded(self):\n    i = np.arange(80, dtype=np.float32).reshape([2, 4, 5, 2])\n    k = np.arange(24, dtype=np.float32).reshape([2, 2, 2, 3])\n    r = self.modules.conv2d.all.conv2d_2452x2223_valid(i, k)\n    r.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/depth_conv_test.py,12,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass Conv2dModule(tf.Module):\n\n  # TODO(ataei): Add dilation and strided tests.\n  @tf.function(input_signature=[\n      tf.TensorSpec([2, 4, 5, 2], tf.float32),\n      tf.TensorSpec([2, 2, 2, 3], tf.float32),\n  ])\n  def conv2d_2452x2223_valid(self, img, kernel):\n    return tf.nn.depthwise_conv2d(\n        img, kernel, [1, 1, 1, 1], ""VALID"", name=""result"")\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([2, 4, 5, 2], tf.float32),\n      tf.TensorSpec([2, 4, 2, 3], tf.float32),\n  ])\n  def conv2d_2452x2223_same(self, img, kernel):\n    return tf.nn.depthwise_conv2d(\n        img, kernel, [1, 1, 1, 1], ""SAME"", name=""result"")\n\n\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], conv2d=Conv2dModule)\nclass ConvTest(tf_test_utils.SavedModelTestCase):\n\n  def test_batched_feature_unpadded(self):\n    i = np.arange(80, dtype=np.float32).reshape([2, 4, 5, 2])\n    k = np.arange(24, dtype=np.float32).reshape([2, 2, 2, 3])\n    r = self.modules.conv2d.all.conv2d_2452x2223_valid(i, k)\n    r.print().assert_all_close()\n\n  def test_batched_feature_unpadded_smae(self):\n    i = np.arange(80, dtype=np.float32).reshape([2, 4, 5, 2])\n    k = np.arange(48, dtype=np.float32).reshape([2, 4, 2, 3])\n    r = self.modules.conv2d.all.conv2d_2452x2223_same(i, k)\n    r.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/dynamic_mlp_relu_test.py,19,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# TODO(laurenzo): Delete this test once dynamic shape sigmoid is implemented.\n# This uses a relu instead, allowing it to get to the remaining issue\n# (unimplemented dynamic dot_general).\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nHIDDEN_1_DIM = 256\nHIDDEN_2_DIM = 256\nINPUT_DIM = 728  # 28 * 28\nCLASSES = 10\n\n\nclass Mlp(tf.Module):\n\n  def __init__(self,\n               hidden_1_dim=256,\n               hidden_2_dim=256,\n               input_dim=28 * 28,\n               classes=10):\n    super().__init__()\n    tf_test_utils.set_random_seed()\n    self.hidden_1_dim = hidden_1_dim\n    self.hidden_2_dim = hidden_2_dim\n    self.input_dim = input_dim\n    self.classes = classes\n    self.h1_weights = tf.Variable(tf.random.normal([input_dim, hidden_1_dim]))\n    self.h2_weights = tf.Variable(\n        tf.random.normal([hidden_1_dim, hidden_2_dim]))\n    self.out_weights = tf.Variable(tf.random.normal([hidden_2_dim, classes]))\n    self.h1_bias = tf.Variable(tf.random.normal([hidden_1_dim]))\n    self.h2_bias = tf.Variable(tf.random.normal([hidden_2_dim]))\n    self.out_bias = tf.Variable(tf.random.normal([classes]))\n\n    # Compile with dynamic batch dim.\n    self.predict = tf.function(\n        input_signature=[tf.TensorSpec([None, self.input_dim])])(\n            self.predict)\n\n  def mlp(self, x):\n    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, self.h1_weights), self.h1_bias))\n    layer_2 = tf.nn.relu(\n        tf.add(tf.matmul(layer_1, self.h2_weights), self.h2_bias))\n    return tf.nn.relu(\n        tf.add(tf.matmul(layer_2, self.out_weights), self.out_bias))\n\n  def predict(self, x):\n    return tf.nn.softmax(self.mlp(x))\n\n\n@tf_test_utils.compile_modules(\n    backends=[\n        ""tf"",\n        ""iree_vmla"",\n    ], mlp=(Mlp, [""predict""]))\nclass DynamicMlpTest(tf_test_utils.SavedModelTestCase):\n\n  def test_dynamic_batch(self):\n    m = self.modules.mlp.all\n    np.random.seed(12345)\n    x = np.random.random([3, 28 * 28]).astype(np.float32) * 1e-3\n    m.predict(x).print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/dynamic_mlp_test.py,19,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nHIDDEN_1_DIM = 256\nHIDDEN_2_DIM = 256\nINPUT_DIM = 728  # 28 * 28\nCLASSES = 10\n\n\nclass Mlp(tf.Module):\n\n  def __init__(self,\n               hidden_1_dim=256,\n               hidden_2_dim=256,\n               input_dim=28 * 28,\n               classes=10):\n    super().__init__()\n    tf_test_utils.set_random_seed()\n    self.hidden_1_dim = hidden_1_dim\n    self.hidden_2_dim = hidden_2_dim\n    self.input_dim = input_dim\n    self.classes = classes\n    self.h1_weights = tf.Variable(tf.random.normal([input_dim, hidden_1_dim]))\n    self.h2_weights = tf.Variable(\n        tf.random.normal([hidden_1_dim, hidden_2_dim]))\n    self.out_weights = tf.Variable(tf.random.normal([hidden_2_dim, classes]))\n    self.h1_bias = tf.Variable(tf.random.normal([hidden_1_dim]))\n    self.h2_bias = tf.Variable(tf.random.normal([hidden_2_dim]))\n    self.out_bias = tf.Variable(tf.random.normal([classes]))\n\n    # Compile with dynamic batch dim.\n    self.predict = tf.function(\n        input_signature=[tf.TensorSpec([None, self.input_dim])])(\n            self.predict)\n\n  def mlp(self, x):\n    layer_1 = tf.sigmoid(tf.add(tf.matmul(x, self.h1_weights), self.h1_bias))\n    layer_2 = tf.sigmoid(\n        tf.add(tf.matmul(layer_1, self.h2_weights), self.h2_bias))\n    return tf.sigmoid(\n        tf.add(tf.matmul(layer_2, self.out_weights), self.out_bias))\n\n  def predict(self, x):\n    return tf.nn.softmax(self.mlp(x))\n\n\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], mlp=(Mlp, [""predict""]))\nclass DynamicMlpTest(tf_test_utils.SavedModelTestCase):\n\n  def test_dynamic_batch(self):\n    m = self.modules.mlp.all\n    np.random.seed(12345)\n    x = np.random.random([3, 28 * 28]).astype(np.float32) * 1e-3\n    m.predict(x).print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/exported_names_test.py,7,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass DontExportEverything(tf.Module):\n\n  @tf.function(input_signature=[])\n  def exported_fn(self):\n    return tf.constant([42.])\n\n  # No input_signature, so it cannot be imported by the SavedModel importer.\n  # We need to ensure that\n  @tf.function\n  def unreachable_fn(self, x):\n    return x\n\n\n# To pass a set of exported names for the module, instead of passing just a\n# module ctor, instead pass a pair `(ctor, [list, of, exported, names])`.\n@tf_test_utils.compile_modules(\n    dont_export_everything=(DontExportEverything, [""exported_fn""]))\nclass DontExportEverythingTest(tf_test_utils.SavedModelTestCase):\n\n  def test_dont_export_everything(self):\n    self.modules.dont_export_everything.all.exported_fn().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/fill_test.py,8,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass FillModule(tf.Module):\n\n  def __init__(self):\n    pass\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([2], tf.int32),\n      tf.TensorSpec([], tf.float32)\n  ])\n  def fill(self, dims, value):\n    return tf.fill(dims, value)\n\n\n# TODO(jennik): Get this test working on IREE.\n@tf_test_utils.compile_modules(backends=[""tf""], fill=FillModule)\nclass FillTest(tf_test_utils.SavedModelTestCase):\n\n  def test_fill(self):\n    dims = np.array([2, 3], dtype=np.int32)\n    value = np.array(9., dtype=np.float32)\n\n    result = self.modules.fill.all.fill(dims, value)\n    result.assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/gather_test.py,20,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass GatherModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 8], tf.float32),\n      tf.TensorSpec([], tf.int32)\n  ])\n  def gather_axis0_scalar(self, params, indices):\n    return tf.gather(params, indices)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 8], tf.float32),\n      tf.TensorSpec([2], tf.int32)\n  ])\n  def gather_axis0_batch0(self, params, indices):\n    return tf.gather(params, indices)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 7, 8], tf.float32),\n      tf.TensorSpec([2], tf.int32)\n  ])\n  def gather_axis1_batch0(self, params, indices):\n    return tf.gather(params, indices, axis=1)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 7, 8, 2], tf.float32),\n      tf.TensorSpec([4, 1], tf.int32)\n  ])\n  def gather_axis2_batch1(self, params, indices):\n    return tf.gather(params, indices, axis=2, batch_dims=1)\n\n\n@tf_test_utils.compile_modules(gather=GatherModule)\nclass GatherTest(tf_test_utils.SavedModelTestCase):\n\n  def test_gather_axis0_scalar(self):\n    indices = np.array(2, dtype=np.int32)\n    params = np.arange(32, dtype=np.float32).reshape(4, 8)\n    result = self.modules.gather.all.gather_axis0_scalar(params, indices)\n    result.print().assert_all_close()\n\n  def test_gather_axis0_batch0(self):\n    indices = np.array([2, 3], dtype=np.int32)\n    params = np.arange(32, dtype=np.float32).reshape(4, 8)\n    result = self.modules.gather.all.gather_axis0_batch0(params, indices)\n    result.print().assert_all_close()\n\n  def test_gahter_axis1_batch0(self):\n    indices = np.array([2, 3], dtype=np.int32)\n    params = np.arange(4 * 7 * 8, dtype=np.float32).reshape(4, 7, 8)\n    result = self.modules.gather.all.gather_axis1_batch0(params, indices)\n    result.print().assert_all_close()\n\n  def test_gahter_axis2_batch1(self):\n    indices = np.array([[2], [3], [0], [1]], dtype=np.int32)\n    params = np.arange(4 * 7 * 8 * 2, dtype=np.float32).reshape(4, 7, 8, 2)\n    result = self.modules.gather.all.gather_axis2_batch1(params, indices)\n    result.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/linspace_test.py,8,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass LinSpaceModule(tf.Module):\n\n  def __init__(self):\n    pass\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([], tf.float32),\n      tf.TensorSpec([], tf.float32)\n  ])\n  def linspace(self, start, stop):\n    # \'num\' is const because XLA\'s iota operation does not support dynamic\n    # shapes.\n    num = np.array(3, dtype=np.int32)\n    return tf.linspace(start, stop, num)\n\n\n# TODO(laurenzo): Re-enable iree_vulkan once dynamic-slice is implemented\n# See https://github.com/google/iree/issues/1521\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], linspace=LinSpaceModule)\nclass LinspaceTest(tf_test_utils.SavedModelTestCase):\n\n  def test_linspace(self):\n    start = np.array(10., dtype=np.float32)\n    stop = np.array(12., dtype=np.float32)\n\n    result = self.modules.linspace.all.linspace(start, stop)\n    result.assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/mandelbrot_test.py,25,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\ndef complex_add(a_re, a_im, b_re, b_im):\n  return a_re + b_re, a_im + b_im\n\n\ndef complex_mul(a_re, a_im, b_re, b_im):\n  c_re = a_re * b_re - a_im * b_im\n  c_im = a_re * b_im + a_im * b_re\n  return c_re, c_im\n\n\n# This is a fun but quite interesting example because the return value and most\n# of the interior computations are dynamically shaped.\nclass MandelbrotModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([], tf.float32),\n      tf.TensorSpec([], tf.float32),\n      tf.TensorSpec([], tf.float32),\n      tf.TensorSpec([], tf.int32),\n      tf.TensorSpec([], tf.int32)\n  ])\n  def calculate(self, center_re, center_im, view_size, view_pixels,\n                num_iterations):\n    """"""Calculates an image which represents the Mandelbrot set.\n\n    Args:\n      center_re: The center point of the view (real part).\n      center_im: The center point of the view (imaginary part).\n      view_size: The view will display a square with this size.\n      view_pixels: The returned image will be a square with this many pixels on\n        a side.\n      num_iterations: The number of iterations to use for determining escape.\n\n    Returns:\n      A tensor of pixels with shape [view_size, view_size] which represents\n      the mandelbrot set.\n    """"""\n    re_min = center_re - view_size / 2.\n    re_max = center_re + view_size / 2.\n    im_min = center_im - view_size / 2.\n    im_max = center_im + view_size / 2.\n    re_coords = tf.linspace(re_min, re_max, view_pixels)\n    im_coords = tf.linspace(im_min, im_max, view_pixels)\n\n    # Generate flat list of real and imaginary parts of the points to test.\n    # This requires taking all pairs of re_coords and im_coords, which we\n    # do by broadcasting into a 2d matrix (real part is broadcasted ""vertically""\n    # and imaginary part is broadcasted ""horizontally"").\n    # We use a Nx1 * 1xN -> NxN matmul to do the broadcast.\n    c_re = tf.reshape(\n        tf.matmul(\n            tf.ones([view_pixels, 1]), tf.reshape(re_coords, [1, view_pixels])),\n        [-1])\n    c_im = tf.reshape(\n        tf.matmul(\n            tf.reshape(im_coords, [view_pixels, 1]), tf.ones([1, view_pixels])),\n        [-1])\n\n    z_re = tf.zeros_like(c_re)\n    z_im = tf.zeros_like(c_im)\n    for _ in range(num_iterations):\n      square_re, square_im = complex_mul(z_re, z_im, z_re, z_im)\n      z_re, z_im = complex_add(square_re, square_im, c_re, c_im)\n\n    # Calculate if the points are in the set (that is, if their orbit under the\n    # recurrence relationship has diverged).\n    z_abs = tf.sqrt(z_re**2 + z_im**2)\n    z_abs = tf.where(tf.math.is_nan(z_abs), 100. * tf.ones_like(z_abs), z_abs)\n    in_the_set = tf.where(z_abs > 50., tf.ones_like(z_abs),\n                          tf.zeros_like(z_abs))\n    # Return an image\n    return tf.reshape(in_the_set, shape=[view_pixels, view_pixels])\n\n\n# TODO(silvasean): Get this working on IREE.\n@tf_test_utils.compile_modules(backends=[""tf""], mandelbrot=MandelbrotModule)\nclass MandelbrotTest(tf_test_utils.SavedModelTestCase):\n\n  def test_mandelbrot(self):\n    mandelbrot = self.modules.mandelbrot.all\n\n    # Basic view of the entire set.\n    pixels = mandelbrot.calculate(-0.7, 0.0, 3.0, 400, 100)\n    pixels.assert_all_close()\n\n    # This is a much more detailed view, so more iterations are needed.\n    pixels = mandelbrot.calculate(-0.7436447860, 0.1318252536, 0.0000029336,\n                                  400, 3000)\n    pixels.assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/math_test.py,13,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for ops in the tf.math module.""""""\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass MathModule(tf.Module):\n\n  @tf.function(input_signature=[tf.TensorSpec([4], tf.float32)])\n  def abs(self, x):\n    return tf.math.abs(x)\n\n  @tf.function(input_signature=[tf.TensorSpec([4], tf.float32)])\n  def cos(self, x):\n    return tf.math.cos(x)\n\n  @tf.function(input_signature=[tf.TensorSpec([4], tf.float32)])\n  def log(self, x):\n    return tf.math.log(x)\n\n  @tf.function(input_signature=[tf.TensorSpec([4], tf.float32)])\n  def mod(self, x):\n    return tf.math.mod(x, 2.0)\n\n\n@tf_test_utils.compile_modules(\n    backends=[""iree_vmla"", ""iree_vulkan""], math=MathModule)\nclass MathTest(tf_test_utils.SavedModelTestCase):\n\n  def test_abs(self):\n    a = np.array([-0.5, 0.0, 0.5, 1.0], dtype=np.float32)\n    r = self.modules.math.all.abs(a)\n    r.print().assert_all_close()\n\n  def test_cos(self):\n    a = np.array([-0.5, 0.0, 0.5, 1.0], dtype=np.float32)\n    r = self.modules.math.all.cos(a)\n    r.print().assert_all_close()\n\n  def test_log(self):\n    a = np.array([0.1, 0.2, 0.5, 1.0], dtype=np.float32)\n    r = self.modules.math.all.log(a)\n    r.print().assert_all_close()\n\n  def test_mod(self):\n    a = np.array([0.0, 1.2, 1.5, 3.75], dtype=np.float32)\n    r = self.modules.math.all.mod(a)\n    r.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/matrix_ops_test.py,41,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test matrix ops.""""""\n\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass MatrixOpsModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 2], tf.float32),\n      tf.TensorSpec([2, 4], tf.float32),\n  ])\n  def basic_matmul(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([3, 4, 2], tf.float32),\n      tf.TensorSpec([2, 4], tf.float32),\n  ])\n  def matmul_lhs_batch(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4, 2], tf.float32),\n      tf.TensorSpec([3, 2, 4], tf.float32),\n  ])\n  def matmul_rhs_batch(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([1, 4, 2], tf.float32),\n      tf.TensorSpec([3, 2, 4], tf.float32),\n  ])\n  def matmul_broadcast_singleton_dimension(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([None, None, 4, 2], tf.float32),\n      tf.TensorSpec([None, None, 2, 4], tf.float32),\n  ])\n  def matmul_high_rank_batch(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([None, None, None], tf.float32),\n      tf.TensorSpec([None, None, None], tf.float32),\n  ])\n  def matmul_dynamic(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([None, None, None], tf.float32),\n      tf.TensorSpec([None, None], tf.float32),\n  ])\n  def matmul_dynamic_lhs_batch(self, lhs, rhs):\n    return tf.matmul(lhs, rhs)\n\n\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], mat=MatrixOpsModule)\nclass MatrixOpsTest(tf_test_utils.SavedModelTestCase):\n\n  def test_basic_matmul(self):\n    m = self.modules.mat.all\n    dst = m.basic_matmul(tf.random.uniform([4, 2]), tf.random.uniform([2, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_lhs_batch(self):\n    m = self.modules.mat.all\n    dst = m.matmul_lhs_batch(\n        tf.random.uniform([3, 4, 2]), tf.random.uniform([2, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_rhs_batch(self):\n    m = self.modules.mat.all\n    dst = m.matmul_rhs_batch(\n        tf.random.uniform([4, 2]), tf.random.uniform([3, 2, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_broadcast_singleton_dimension(self):\n    m = self.modules.mat.all\n    dst = m.matmul_broadcast_singleton_dimension(\n        tf.random.uniform([1, 4, 2]), tf.random.uniform([3, 2, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_high_rank_batch(self):\n    m = self.modules.mat.all\n    dst = m.matmul_high_rank_batch(\n        tf.random.uniform([1, 7, 4, 2]), tf.random.uniform([7, 1, 2, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_dynamic_matching_batch(self):\n    m = self.modules.mat.all\n    dst = m.matmul_dynamic(\n        tf.random.uniform([2, 2, 3]), tf.random.uniform([2, 3, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_dynamic_broadcast_lhs(self):\n    m = self.modules.mat.all\n    dst = m.matmul_dynamic(\n        tf.random.uniform([1, 2, 3]), tf.random.uniform([2, 3, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_dynamic_broadcast_rhs(self):\n    m = self.modules.mat.all\n    dst = m.matmul_dynamic(\n        tf.random.uniform([2, 2, 3]), tf.random.uniform([1, 3, 4]))\n    dst.assert_all_close()\n\n  def test_matmul_dynamic_rank_broadcasting(self):\n    m = self.modules.mat.all\n    dst = m.matmul_dynamic_lhs_batch(\n        tf.random.uniform([7, 2, 3]), tf.random.uniform([3, 4]))\n    dst.assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/resource_ops_test.py,6,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass ResourcesOpsModule(tf.Module):\n\n  def __init__(self):\n    super(ResourcesOpsModule, self).__init__()\n    self.counter = tf.Variable(0.0)\n\n  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n  def add_assign(self, value):\n    return self.counter.assign_add(value)\n\n\n@tf_test_utils.compile_modules(backends=[], resource_ops=ResourcesOpsModule)\nclass ResourcesOpsTest(tf_test_utils.SavedModelTestCase):\n\n  def test_add_assign(self):\n    result = self.modules.resource_ops.all.add_assign(\n        np.array(9., dtype=np.float32))\n    result.assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/ring_buffer_test.py,34,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nTIME_SIZE = 2\nFEATURE_SIZE = 2\nBATCH_SIZE = 1\n\n\nclass RingBuffer(tf.Module):\n  """"""Implements a RingBuffer.""""""\n\n  def __init__(self, buffer_size, dims, dtype):\n    self._buffer_size = buffer_size\n    self._dims = dims\n\n    # buffer has size [buffer_size, dims]\n    # only the first dimension is used for updating buffer in a ring manner\n    self._buffer = tf.Variable(\n        tf.zeros((self._buffer_size,) + dims, dtype=dtype),\n        trainable=False,\n        name=""RingBuffer"")\n    # Size of the data available for reading\n    self._data_size = tf.Variable(\n        0, trainable=False, dtype=tf.int32, name=""FramerBuffer/Size"")\n    # The index pointing to the head of the data available for reading\n    self._read_head = tf.Variable(\n        0, trainable=False, dtype=tf.int32, name=""FramerBuffer/Head"")\n\n  @property\n  def dtype(self):\n    return self._buffer.dtype\n\n  @property\n  def dims(self):\n    return self._dims\n\n  @tf.function\n  def get_write_headroom(self):\n    """"""Gets the available writable headroom.\n\n    Returns:\n      integer scalar tensor of headroom.\n    """"""\n    return self._buffer_size - self._data_size\n\n  @tf.function\n  def get_read_available(self):\n    """"""Gets the available readable entries.\n\n    Returns:\n      integer scalar tensor of headroom.\n    """"""\n    return self._data_size\n\n  @tf.function\n  def write(self, elements):\n    """"""Writes elements to the ringbuffer.\n\n    Args:\n      elements: Elements to write.\n\n    Returns:\n      Whether the write was successful (always True for now).\n    """"""\n    elements_size = tf.shape(elements)[0]\n    start = tf.math.floormod(\n        self._read_head.read_value() + self._data_size.read_value(),\n        self._buffer_size)\n    indices = tf.math.floormod(\n        tf.range(start, limit=start + elements_size), self._buffer_size)\n\n    tf.compat.v1.scatter_update(self._buffer, indices, elements)\n\n    # special case when addition of new data, exceed _buffer_size:\n    # we start overwriting existing data in circular manner\n    # and need to update _read_head\n    if tf.greater(self._data_size + elements_size, self._buffer_size):\n      self._read_head.assign(\n          tf.math.floormod(\n              self._read_head.read_value() + self._data_size +\n              tf.math.floormod(elements_size, self._buffer_size),\n              self._buffer_size))\n\n    self._data_size.assign(\n        tf.minimum(self._data_size + elements_size, self._buffer_size))\n    return tf.convert_to_tensor(True)\n\n  @tf.function\n  def read(self, length, offset=0, consume=True):\n    """"""Reads elements from the ringbuffer.\n\n    This will unconditionally read from the buffer and will produce undefined\n    outputs if attempting to read past the end. This does not consume from\n    the read buffer.\n\n    Args:\n      length: The length of data to read.\n      offset: The offset into the readable area to begin.\n      consume: Consumes the read data (default true).\n\n    Returns:\n      Tensor of elements with shape [length, dims...].\n    """"""\n    start = self._read_head + offset\n    indices = tf.math.floormod(\n        tf.range(start, limit=start + length), self._buffer_size)\n    result = tf.gather(self._buffer, indices)\n    if consume:\n      self.consume(length, offset)\n    return result\n\n  @tf.function\n  def consume(self, length, offset=0):\n    """"""Consumes elements from the buffer.\n\n    Args:\n      length: The length of data to read.\n      offset: The offset into the readable area to begin.\n    """"""\n    start = self._read_head + offset\n    self._read_head.assign(tf.math.floormod(start + length, self._buffer_size))\n    self._data_size.assign(self._data_size - length)\n\n\nclass StatefulRingBuffer(tf.keras.layers.Layer):\n\n  def __init__(self, state_shape=None, consume=False, **kwargs):\n    super(StatefulRingBuffer, self).__init__(**kwargs)\n    self.state_shape = state_shape\n    self.consume = consume\n\n  def build(self, input_shape):\n    super(StatefulRingBuffer, self).build(input_shape)\n    buffer_size = self.state_shape[1]\n    self.rb = RingBuffer(\n        buffer_size=buffer_size, dims=(self.state_shape[2],), dtype=tf.float32)\n\n  def call(self, inputs):\n    self.rb.write(inputs)\n    return self.rb.read(1, consume=self.consume)\n\n  def get_config(self):\n    config = {\n        ""state_shape"": self.state_shape,\n        ""consume"": self.consume,\n    }\n    base_config = super(StatefulRingBuffer, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))\n\n\nclass StatefulRingBufferM(tf.Module):\n\n  def __init__(self):\n    super(StatefulRingBufferM, self).__init__()\n    state_shape = [BATCH_SIZE, TIME_SIZE, FEATURE_SIZE]\n    self.rb = StatefulRingBuffer(state_shape=state_shape)\n\n  @tf.function(\n      input_signature=[tf.TensorSpec([BATCH_SIZE, FEATURE_SIZE], tf.float32)])\n  def predict(self, x):\n    return self.rb(x)\n\n\n# TODO(b/148747011)\n@tf_test_utils.compile_modules(\n    backends=[""tf""], rb=(StatefulRingBufferM, [""predict""]))\nclass StatefulRingBufferTest(tf_test_utils.SavedModelTestCase):\n\n  def test_statefulringbuffer(self):\n    input1 = np.array([[1.0, 2.0]], dtype=np.float32)\n    result1 = self.modules.rb.all.predict(input1)\n    output1 = np.array([[1.0, 2.0]], dtype=np.float32)\n    assert np.allclose(result1, output1)\n\n    # ring buffer is not filled yet,\n    # so data from first cycle will be returned\n    input2 = np.array([[3.0, 4.0]], dtype=np.float32)\n    result2 = self.modules.rb.all.predict(input2)\n    output2 = np.array([[1.0, 2.0]], dtype=np.float32)\n    assert np.allclose(result2, output2)\n\n    # on 3rd cycle we overwrite oldest data\n    # and return data from 2nd cycle\n    input3 = np.array([[5.0, 6.0]], dtype=np.float32)\n    result3 = self.modules.rb.all.predict(input3)\n    output3 = np.array([[3.0, 4.0]], dtype=np.float32)\n    assert np.allclose(result3, output3)\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/simple_arithmetic_test.py,12,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Several baseline e2e simple arithmetic tests.""""""\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass SimpleArithmeticModule(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    return a * b\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([128, 3072], tf.float32),\n      tf.TensorSpec([3072, 256], tf.float32),\n  ])\n  def simple_matmul(self, a, b):\n    return tf.matmul(a, b)\n\n\n@tf_test_utils.compile_modules(simple_arithmetic=SimpleArithmeticModule)\nclass SimpleArithmeticTest(tf_test_utils.SavedModelTestCase):\n\n  def test_simple_mul_explicit(self):\n    # Demonstrates simple, one by one invocation of functions against\n    # different explicit backends.\n    a = np.array([1., 2., 3., 4.], dtype=np.float32)\n    b = np.array([400., 5., 6., 7.], dtype=np.float32)\n    # Individual backends can be accessed off of the module by name (\'tf,\n    # \'iree_vmla\' below).\n    tf_c = self.modules.simple_arithmetic.tf.simple_mul(a, b)\n    print(""TF Result:"", tf_c)\n    iree_c = self.modules.simple_arithmetic.iree_vmla.simple_mul(a, b)\n    print(""IREE Result:"", iree_c)\n    self.assertAllClose(tf_c, iree_c)\n\n  def test_simple_mul_multi(self):\n    a = np.array([1., 2., 3., 4.], dtype=np.float32)\n    b = np.array([400., 5., 6., 7.], dtype=np.float32)\n\n    # Evaluating against multiple backends can be done with the multi() method,\n    # which takes a regex string matching backend names. This also returns a\n    # MultiResults tuple with actual results keyed by backend name. These also\n    # have convenience methods like print() and assert_all_close().\n    vmod = self.modules.simple_arithmetic.multi(""tf|iree"")\n    r = vmod.simple_mul(a, b)\n    r.print().assert_all_close()\n\n  def test_matmul(self):\n    np.random.seed(12345)\n    # Note: scaling by a small value to increase numerical stability.\n    a = np.random.random((128, 3072)).astype(np.float32) * 1e-3\n    b = np.random.random((3072, 256)).astype(np.float32) * 1e-3\n    # Evaluating against all backends can be done with the special \'all\'\n    # backend name. This also returns a MultiResults tuple with actual results\n    # keyed by backend name.\n    r = self.modules.simple_arithmetic.all.simple_matmul(a, b)\n    r.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/simple_stateful_test.py,8,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\n\nclass Stateful(tf.Module):\n\n  def __init__(self):\n    super(Stateful, self).__init__()\n    self.counter = tf.Variable(0.0)\n\n  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n  def inc_by(self, x):\n    self.counter.assign(self.counter + x)\n\n  @tf.function(input_signature=[])\n  def get_state(self):\n    return self.counter\n\n\n@tf_test_utils.compile_modules(stateful=Stateful)\nclass StatefulTest(tf_test_utils.SavedModelTestCase):\n\n  def test_stateful(self):\n    m = self.modules.stateful.all\n    m.inc_by(tf.constant(1.))\n    m.get_state().print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/sliding_window_test.py,10,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nTIME_SIZE = 3\nFEATURE_SIZE = 2\nBATCH_SIZE = 1\n\n\nclass SlidingWindow(tf.keras.layers.Layer):\n  # It is another version of a ring buffer\n  # during call() it appends new update and remove the oldest one\n\n  def __init__(self, state_shape=None, **kwargs):\n    super(SlidingWindow, self).__init__(**kwargs)\n\n    self.state_shape = state_shape\n\n  def build(self, input_shape):\n    super(SlidingWindow, self).build(input_shape)\n\n    self.states = self.add_weight(\n        name=""states"",\n        shape=self.state_shape,  # [batch, time, feature]\n        trainable=False,\n        initializer=tf.zeros_initializer)\n\n  def call(self, inputs):\n\n    # [batch_size, 1, feature_dim]\n    inputs_time = tf.keras.backend.expand_dims(inputs, -2)\n\n    # remove latest row [batch_size, (memory_size-1), feature_dim]\n    memory = self.states[:, 1:self.state_shape[1], :]\n\n    # add new row [batch_size, memory_size, feature_dim]\n    memory = tf.keras.backend.concatenate([memory, inputs_time], 1)\n\n    self.states.assign(memory)\n\n    return self.states\n\n  def get_config(self):\n    config = {\n        ""state_shape"": self.state_shape,\n    }\n    base_config = super(SlidingWindow, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))\n\n\nclass SlidingWindowM(tf.Module):\n\n  def __init__(self):\n    super(SlidingWindowM, self).__init__()\n    state_shape = [BATCH_SIZE, TIME_SIZE, FEATURE_SIZE]\n    self.sw = SlidingWindow(state_shape=state_shape)\n\n  @tf.function(\n      input_signature=[tf.TensorSpec([BATCH_SIZE, FEATURE_SIZE], tf.float32)])\n  def predict(self, x):\n    return self.sw(x)\n\n\n# TODO(b/148495516)\n@tf_test_utils.compile_modules(\n    backends=[""tf""], sw=(SlidingWindowM, [""predict""]))\nclass SlidingWindowTest(tf_test_utils.SavedModelTestCase):\n\n  def test_slidingwindow(self):\n    input1 = np.array([[1.0, 2.0]], dtype=np.float32)\n    result1 = self.modules.sw.all.predict(input1)\n    output1 = np.array([[0.0, 0.0], [0.0, 0.0], [1.0, 2.0]], dtype=np.float32)\n    assert np.allclose(result1, output1)\n\n    input2 = np.array([[3.0, 4.0]], dtype=np.float32)\n    result2 = self.modules.sw.all.predict(input2)\n    output2 = np.array([[0.0, 0.0], [1.0, 2.0], [3.0, 4.0]], dtype=np.float32)\n    assert np.allclose(result2, output2)\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/strings_test.py,13,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport string\nimport tensorflow.compat.v2 as tf\n\n\nclass StringsModule(tf.Module):\n  """"""A Module for converting a set of ids to the concatenated string.""""""\n\n  def __init__(self):\n    wordparts = [str(c) for c in string.printable]\n    self.wordparts = tf.constant(wordparts, tf.string)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec((None, None), dtype=tf.int32),\n  ])\n  def print_ids(self, ids):\n    string_tensor = tf.strings.as_string(ids)\n    tf.print(string_tensor)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec((None, None), dtype=tf.int32),\n  ])\n  def strings_to_ids(self, ids):\n    wps = tf.gather(self.wordparts, ids)\n    return tf.strings.reduce_join(wps, 1)\n\n\n@tf_test_utils.compile_modules(backends=[""tf""], strings=StringsModule)\nclass StringsTest(tf_test_utils.SavedModelTestCase):\n\n  def test_print_ids(self):\n    input_ids = np.asarray(\n        [[12, 10, 29, 28, 94, 15, 24, 27, 94, 25, 21, 10, 34],\n         [13, 24, 16, 28, 94, 15, 24, 27, 94, 28, 29, 10, 34]])\n    self.modules.strings.all.print_ids(input_ids)\n\n  def test_strings_to_ids(self):\n    input_ids = np.asarray(\n        [[12, 10, 29, 28, 94, 15, 24, 27, 94, 25, 21, 10, 34],\n         [13, 24, 16, 28, 94, 15, 24, 27, 94, 28, 29, 10, 34]])\n    result = self.modules.strings.all.strings_to_ids(input_ids)\n    result.assert_all_equal()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/tensorlist_test.py,26,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nSTATIC_SIZE = 20\n\n\nclass TensorListModule(tf.Module):\n\n  def __init__(self):\n    pass\n\n  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n  def identity_through_tensorlist(self, x):\n    ta = tf.TensorArray(dtype=tf.float32, size=1, element_shape=[])\n    ta = ta.write(0, x)\n    return ta.read(0)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([], tf.float32),\n      tf.TensorSpec([], tf.float32)\n  ])\n  def add_through_tensorlist(self, a, b):\n    ta = tf.TensorArray(dtype=tf.float32, size=2, element_shape=[])\n    ta = ta.write(0, a)\n    ta = ta.write(1, b)\n    return ta.read(0) + ta.read(1)\n\n  @tf.function(input_signature=[tf.TensorSpec([STATIC_SIZE], tf.float32)])\n  def slice_first_element_with_from_tensor(self, t):\n    ta = tf.TensorArray(dtype=tf.float32, size=STATIC_SIZE, element_shape=[])\n    ta = ta.unstack(t)\n    return ta.read(0)\n\n  @tf.function(\n      input_signature=[tf.TensorSpec([STATIC_SIZE, STATIC_SIZE], tf.float32)])\n  def slice_first_element_with_from_tensor_high_rank(self, t):\n    ta = tf.TensorArray(\n        dtype=tf.float32, size=STATIC_SIZE, element_shape=[STATIC_SIZE])\n    ta = ta.unstack(t)\n    return ta.read(0)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([], tf.float32),\n      tf.TensorSpec([], tf.float32)\n  ])\n  def concat_with_tensorlist_stack(self, a, b):\n    ta = tf.TensorArray(dtype=tf.float32, size=2, element_shape=[])\n    ta = ta.write(0, a)\n    ta = ta.write(1, b)\n    return ta.stack()\n\n\n# TODO(b/146900329): Triage op coverage for vulkan backend.\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], tensorlist=TensorListModule)\nclass TensorListTest(tf_test_utils.SavedModelTestCase):\n\n  def test_identity_through_tensorlist(self):\n    m = self.modules.tensorlist.all\n    result = m.identity_through_tensorlist(tf.constant(42.))\n    result.print().assert_all_close()\n\n  def test_add_through_tensorlist(self):\n    m = self.modules.tensorlist.all\n    result = m.add_through_tensorlist(tf.constant(42.), tf.constant(43.))\n    result.print().assert_all_close()\n\n  def test_slice_first_element_with_from_tensor(self):\n    m = self.modules.tensorlist.all\n    result = m.slice_first_element_with_from_tensor(\n        tf.range(STATIC_SIZE, dtype=tf.float32))\n    result.print().assert_all_close()\n\n  def test_slice_first_element_with_from_tensor_high_rank(self):\n    m = self.modules.tensorlist.all\n    result = m.slice_first_element_with_from_tensor_high_rank(\n        tf.broadcast_to(\n            tf.range(STATIC_SIZE, dtype=tf.float32),\n            [STATIC_SIZE, STATIC_SIZE]))\n    result.print().assert_all_close()\n\n  def test_concat_with_tensorlist_stack(self):\n    m = self.modules.tensorlist.all\n    result = m.concat_with_tensorlist_stack(tf.constant(42.), tf.constant(43.))\n    result.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
bindings/python/build_tools/python/generate_build.py,0,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Generates the BUILD file for the python package.\n# It includes special comment lines that instruct the hosting program\n# on how to setup the filesystem.\n# Debugging hint: Just runt his with python to see what it prints.\n""""""Generates a bazel BUILD file for the repo.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport sys\n\nfrom distutils import sysconfig\n\nextra_srcs = []\nexec_prefix = sys.base_exec_prefix\n\n# Print some directives for the calling starlark program.\nprint(""# SYMLINK: {abs}\\t{ws}"".format(\n    abs=sysconfig.get_python_inc(), ws=""include""))\n\n# If running on Windows, find the import library, which is named\n# libs/pythonXY.lib (where (X, Y) == (major, minor)).\n# See: https://docs.python.org/3/extending/windows.html\n# Note that while not strictly a ""header"" as the rule name implies,\n# this is integral to linking on Windows and parsing the header\n# will require it, so it is included.\nif os.name == ""nt"":\n  implib_basename = ""python{major}{minor}.lib"".format(\n      major=sys.version_info[0], minor=sys.version_info[1])\n  implib_abs_path = os.path.join(exec_prefix, ""libs"", implib_basename)\n  if not os.path.exists(implib_abs_path):\n    raise RuntimeError(""Could not find Windows python import library: %s"" %\n                       (implib_abs_path,))\n  implib_ws_path = ""libs/"" + implib_basename\n  print(""# SYMLINK: {abs}\\t{ws}"".format(abs=implib_abs_path, ws=implib_ws_path))\n  extra_srcs.append(implib_ws_path)\n\nprint(""""""\npackage(default_visibility = [""//visibility:public""])\n\nconfig_setting(\n    name = ""config_windows_any"",\n    constraint_values = [\n        ""@platforms//os:windows"",\n    ],\n)\n\ncc_library(\n    name = ""python_headers"",\n    hdrs = glob([""include/*.h""]),\n    srcs = [{extra_srcs}],\n    includes = [""include""],\n    linkopts = [],\n)\n\n"""""".format(extra_srcs="","".join([json.dumps(s) for s in extra_srcs]),))\n'"
bindings/python/pyiree/compiler/__init__.py,0,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Module init for the python bindings.""""""\n\n# pylint: disable=g-multiple-import\n# pylint: disable=g-bad-import-order\n# pylint: disable=g-import-not-at-top\n# pylint: disable=wildcard-import\n\nfrom . import binding as binding\n\n# Native aliases.\nllvm = binding.llvm\nContext = binding.CompilerContext\nModule = binding.CompilerModule\nCompileOptions = binding.CompileOptions\nOutputFormat = binding.OutputFormat\n'"
bindings/python/pyiree/compiler/compiler_test.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom absl.testing import absltest\nfrom pyiree import compiler\n\nSIMPLE_MUL_ASM = """"""\nfunc @simple_mul(%arg0: tensor<4xf32>, %arg1: tensor<4xf32>) -> tensor<4xf32>\n      attributes { iree.module.export } {\n    %0 = ""xla_hlo.multiply""(%arg0, %arg1) {name = ""mul.1""} : (tensor<4xf32>, tensor<4xf32>) -> tensor<4xf32>\n    return %0 : tensor<4xf32>\n}\n""""""\n\n\nclass CompilerTest(absltest.TestCase):\n\n  def testParseError(self):\n    ctx = compiler.Context()\n    with self.assertRaisesRegex(ValueError, ""custom op \'FOOBAR\' is unknown""):\n      ctx.parse_asm(""""""FOOBAR: I SHOULD NOT PARSE"""""")\n\n  def testParseAndCompileToFlatbuffer(self):\n    ctx = compiler.Context()\n    input_module = ctx.parse_asm(SIMPLE_MUL_ASM)\n    binary = input_module.compile()\n    b = binary.bytes\n    print(""Flatbuffer size ="", len(b))\n    self.assertTrue(binary.bytes)\n\n  def testParseAndCompileToFlatbufferText(self):\n    ctx = compiler.Context()\n    input_module = ctx.parse_asm(SIMPLE_MUL_ASM)\n    options = compiler.CompileOptions()\n    options.output_format = compiler.OutputFormat.FLATBUFFER_TEXT\n    blob = input_module.compile(options=options)\n    text = blob.text\n    self.assertTrue(text)\n\n  def testParseAndCompileToMlirText(self):\n    ctx = compiler.Context()\n    input_module = ctx.parse_asm(SIMPLE_MUL_ASM)\n    options = compiler.CompileOptions()\n    options.output_format = compiler.OutputFormat.MLIR_TEXT\n    blob = input_module.compile(options=options)\n    text = blob.text\n    self.assertTrue(text)\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
bindings/python/pyiree/rt/__init__.py,0,"b'""""""Module init for the python bindings.""""""\n\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=g-multiple-import\n# pylint: disable=g-bad-import-order\n# pylint: disable=wildcard-import\n\nfrom . import binding\n\n# Pull some of the native symbols into the public API.\n# FunctionAbi imports\nfrom .binding import FunctionAbi\n# Hal imports\nfrom .binding import BufferUsage, HalBuffer, HalDevice, HalDriver, MemoryAccess, MemoryType, Shape\n# HostTypeFactory imports\nfrom .binding import HostTypeFactory\n# Vm imports\nfrom .binding import create_hal_module, Linkage, VmVariantList, VmFunction, VmInstance, VmContext, VmModule\n# SystemApi\nfrom .system_api import *\n'"
bindings/python/pyiree/rt/function_abi_test.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for the function abi.""""""\n\nimport re\n\nfrom absl.testing import absltest\n\nimport numpy as np\nfrom pyiree import rt\n\nATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1 = (\n    (""fv"", ""1""),\n    # Equiv to:\n    # (Buffer<float32[10x128x64]>) -> (Buffer<sint32[32x8x64]>)\n    (""f"", ""I15!B11!d10d128d64R15!B11!t6d32d8d64""),\n)\n\nATTRS_1ARG_FLOAT32_DYNX128X64_TO_SINT32_DYNX8X64_V1 = (\n    (""fv"", ""1""),\n    # Equiv to:\n    # (Buffer<float32[?x128x64]>) -> (Buffer<sint32[?x8x64]>)\n    (""f"", ""I15!B11!d-1d128d64R15!B11!t6d-1d8d64""),\n)\n\n\nclass HostTypeFactory(absltest.TestCase):\n\n  def test_baseclass(self):\n    htf = rt.HostTypeFactory()\n    print(htf)\n\n\nclass FunctionAbiTest(absltest.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super().setUpClass()\n    driver_names = rt.HalDriver.query()\n    print(""DRIVER_NAMES ="", driver_names)\n    cls.driver = rt.HalDriver.create(""vulkan"")\n    cls.device = cls.driver.create_default_device()\n\n  def setUp(self):\n    super().setUp()\n    self.htf = rt.HostTypeFactory.get_numpy()\n\n  def test_static_arg_success(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    print(fabi)\n    self.assertEqual(\n        ""<FunctionAbi (Buffer<float32[10x128x64]>) -> ""\n        ""(Buffer<sint32[32x8x64]>)>"", repr(fabi))\n    self.assertEqual(1, fabi.raw_input_arity)\n    self.assertEqual(1, fabi.raw_result_arity)\n\n    arg = np.zeros((10, 128, 64), dtype=np.float32)\n    packed = fabi.raw_pack_inputs([arg])\n    print(packed)\n    self.assertEqual(""<VmVariantList(1): [HalBufferView(10x128x64:0x3000020)]>"",\n                     repr(packed))\n\n  def test_static_result_success(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    arg = np.zeros((10, 128, 64), dtype=np.float32)\n    f_args = fabi.raw_pack_inputs([arg])\n    f_results = fabi.allocate_results(f_args)\n    print(f_results)\n    self.assertEqual(""<VmVariantList(1): [HalBufferView(32x8x64:0x1000020)]>"",\n                     repr(f_results))\n    py_result, = fabi.raw_unpack_results(f_results)\n    self.assertEqual(np.int32, py_result.dtype)\n    self.assertEqual((32, 8, 64), py_result.shape)\n\n  def test_dynamic_alloc_result_success(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    arg = np.zeros((10, 128, 64), dtype=np.float32)\n    f_args = fabi.raw_pack_inputs([arg])\n    f_results = fabi.allocate_results(f_args, static_alloc=False)\n    print(f_results)\n    self.assertEqual(""<VmVariantList(0): []>"", repr(f_results))\n\n  def test_dynamic_arg_success(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_DYNX128X64_TO_SINT32_DYNX8X64_V1)\n    print(fabi)\n    self.assertEqual(\n        ""<FunctionAbi (Buffer<float32[?x128x64]>) -> ""\n        ""(Buffer<sint32[?x8x64]>)>"", repr(fabi))\n    self.assertEqual(1, fabi.raw_input_arity)\n    self.assertEqual(1, fabi.raw_result_arity)\n\n    arg = np.zeros((10, 128, 64), dtype=np.float32)\n    packed = fabi.raw_pack_inputs([arg])\n    print(packed)\n    self.assertEqual(""<VmVariantList(1): [HalBufferView(10x128x64:0x3000020)]>"",\n                     repr(packed))\n\n  def test_static_arg_rank_mismatch(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    print(fabi)\n    arg = np.zeros((10,), dtype=np.float32)\n    with self.assertRaisesRegex(\n        ValueError,\n        re.escape(""Mismatched buffer rank (received: 1, expected: 3)"")):\n      fabi.raw_pack_inputs([arg])\n\n  def test_static_arg_eltsize_mismatch(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    print(fabi)\n    arg = np.zeros((10, 128, 64), dtype=np.float64)\n    with self.assertRaisesRegex(\n        ValueError,\n        re.escape(""Mismatched buffer item size (received: 8, expected: 4)"")):\n      fabi.raw_pack_inputs([arg])\n\n  def test_static_arg_dtype_mismatch(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    print(fabi)\n    arg = np.zeros((10, 128, 64), dtype=np.int32)\n    with self.assertRaisesRegex(\n        ValueError,\n        re.escape(""Mismatched buffer format (received: i, expected: f)"")):\n      fabi.raw_pack_inputs([arg])\n\n  def test_static_arg_static_dim_mismatch(self):\n    fabi = rt.FunctionAbi(self.device, self.htf,\n                          ATTRS_1ARG_FLOAT32_10X128X64_TO_SINT32_32X8X64_V1)\n    print(fabi)\n    arg = np.zeros((10, 32, 64), dtype=np.float32)\n    with self.assertRaisesRegex(\n        ValueError,\n        re.escape(""Mismatched buffer dim (received: 32, expected: 128)"")):\n      fabi.raw_pack_inputs([arg])\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
bindings/python/pyiree/rt/hal_test.py,0,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import absltest\n\nimport numpy as np\nfrom pyiree import rt\n\n\nclass HalTest(absltest.TestCase):\n\n  def testEnums(self):\n    print(""MemoryType ="", rt.MemoryType)\n    print(""HOST_VISIBLE ="", int(rt.MemoryType.HOST_VISIBLE))\n\n  def testAllocateHeap(self):\n    b = rt.HalBuffer.allocate_heap(\n        memory_type=int(rt.MemoryType.HOST_LOCAL),\n        usage=int(rt.BufferUsage.ALL),\n        allocation_size=4096)\n    self.assertIsNot(b, None)\n    b.fill_zero(0, 4096)\n    shape = rt.Shape([1, 1024])\n    unused_bv = b.create_view(shape, 4)\n\n  def testStrideCalculation(self):\n    b = rt.HalBuffer.allocate_heap(\n        memory_type=int(rt.MemoryType.HOST_LOCAL),\n        usage=int(rt.BufferUsage.ALL),\n        allocation_size=4096)\n    self.assertIsNot(b, None)\n    b.fill_zero(0, 4096)\n    shape = rt.Shape([16, 1, 8, 4, 2])\n    bv = b.create_view(shape, 4)\n    self.assertEqual(\n        np.array(bv.map()).strides,\n        (1 * 8 * 4 * 2 * 4, 8 * 4 * 2 * 4, 4 * 2 * 4, 2 * 4, 4))\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
bindings/python/pyiree/rt/system_api.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Top-level python system API.\n\nThis facility layers on top of the underlying binding native facilities and\nexposes them in a way that allows general operation against contexts, modules\nand functions.\n""""""\n\n# pylint: disable=protected-access\n# pylint: disable=unused-argument\n# pylint: disable=g-explicit-length-test\n\n__all__ = [""load_module"", ""load_modules"", ""Config"", ""SystemContext""]\n\nimport os\nimport sys\n\nfrom typing import Optional, Sequence, Tuple\n\nfrom . import binding as _binding\n\n# Typing aliases (largely used for documentation).\nAnyModule = _binding.VmModule\n\n# Environment key for a comma-delimitted list of drivers to try to load.\nPREFERRED_DRIVER_ENV_KEY = ""IREE_DEFAULT_DRIVER""\n\n# Default value for IREE_DRIVER\nDEFAULT_IREE_DRIVER_VALUE = ""vulkan,vmla""\n\n\ndef _create_default_iree_driver(\n    driver_names: Optional[Sequence[str]] = None) -> _binding.HalDriver:\n  """"""Returns a default driver based on environment settings.""""""\n  # TODO(laurenzo): Ideally this should take a module and join any explicitly\n  # provided driver list with environmental constraints and what the module\n  # was compiled for.\n  if driver_names is None:\n    # Read from environment.\n    driver_names = os.environ.get(PREFERRED_DRIVER_ENV_KEY)\n    if driver_names is None:\n      driver_names = DEFAULT_IREE_DRIVER_VALUE\n    driver_names = driver_names.split("","")\n  available_driver_names = _binding.HalDriver.query()\n  driver_exceptions = {}\n  for driver_name in driver_names:\n    if driver_name not in available_driver_names:\n      print(\n          ""Could not create driver %s (not registered)"" % driver_name,\n          file=sys.stderr)\n      continue\n    try:\n      driver = _binding.HalDriver.create(driver_name)\n      print(\n          ""Created IREE driver %s: %r"" % (driver_name, driver), file=sys.stderr)\n      return driver\n      # TODO(laurenzo): Remove these prints to stderr (for now, more information\n      # is better and there is no better way to report it yet).\n    except Exception as ex:  # pylint: disable=broad-except\n      print(\n          ""Could not create default driver %s: %r"" % (driver_name, ex),\n          file=sys.stderr)\n      driver_exceptions[driver_name] = ex\n\n  # All failed.\n  raise RuntimeError(""Could not create any requested driver ""\n                     ""%r (available=%r) : %r"" %\n                     (driver_names, available_driver_names, driver_exceptions))\n\n\nclass Config:\n  """"""System configuration.""""""\n\n  driver: _binding.HalDriver\n  device: _binding.HalDevice\n  vm_instance: _binding.VmInstance\n  host_type_factory: _binding.HostTypeFactory\n  default_modules: Tuple[AnyModule]\n\n  def __init__(self, driver_name: Optional[str] = None):\n    self.vm_instance = _binding.VmInstance()\n    self.driver = _create_default_iree_driver(\n        driver_name.split("","") if driver_name is not None else None)\n    self.device = self.driver.create_default_device()\n    hal_module = _binding.create_hal_module(self.device)\n    strings_module = _binding.create_strings_module()\n    tensorlist_module = _binding.create_tensorlist_module()\n    self.host_type_factory = _binding.HostTypeFactory.get_numpy()\n    self.default_modules = (hal_module, strings_module, tensorlist_module)\n\n\n_global_config = None\n\n\ndef _get_global_config():\n  global _global_config\n  if _global_config is None:\n    _global_config = Config()\n  return _global_config\n\n\nclass BoundFunction:\n  """"""Wraps a VmFunction, VmContext and ABI into a pythonic function.""""""\n\n  def __init__(self, context: ""SystemContext"",\n               vm_function: _binding.VmFunction):\n    self._context = context\n    self._vm_function = vm_function\n    self._abi = context.create_function_abi(vm_function)\n\n  def __call__(self, *args):\n    # NOTE: This is just doing sync dispatch right now. In the future,\n    # this should default to async and potentially have some kind of policy\n    # flag that can allow it to be overriden.\n    inputs = self._abi.raw_pack_inputs(args)\n    results = self._abi.allocate_results(inputs, static_alloc=False)\n    self._context._vm_context.invoke(self._vm_function, inputs, results)\n    unpacked_results = self._abi.raw_unpack_results(results)\n    # TODO(laurenzo): When switching from \'raw\' to structured pack/unpack,\n    # the ABI should take care of this one-arg special case.\n    if len(unpacked_results) == 1:\n      return unpacked_results[0]\n    elif len(unpacked_results) == 0:\n      return None\n    else:\n      return unpacked_results\n\n  def __repr__(self):\n    return ""<BoundFunction %r (%r)>"" % (\n        self._abi,\n        self._vm_function,\n    )\n\n\nclass BoundModule:\n  """"""Wraps a VmModule with its context and provides nice python accessors.\n\n  Resolves item access ([""foo""]) as function resolution.\n  """"""\n\n  def __init__(self, context: ""SystemContext"", vm_module: AnyModule):\n    self._context = context\n    self._vm_module = vm_module\n    self._lazy_functions = dict()\n\n  @property\n  def name(self):\n    return self._vm_module.name\n\n  def __getattr__(self, name):\n    try:\n      return self[name]\n    except KeyError:\n      raise AttributeError(name)\n\n  def __getitem__(self, name):\n    vm_function = self._lazy_functions.get(name)\n    if vm_function is not None:\n      return vm_function\n\n    vm_function = self._vm_module.lookup_function(name)\n    if vm_function is None:\n      raise KeyError(""Function \'%s\' not found in module \'%s\'"" %\n                     (name, self.name))\n    bound_function = BoundFunction(self._context, vm_function)\n    self._lazy_functions[name] = bound_function\n    return bound_function\n\n  def __repr__(self):\n    return ""<BoundModule %r>"" % (self._vm_module,)\n\n\nclass Modules(dict):\n  """"""Provides nice python accessors for a dict of modules.""""""\n\n  def __getattr__(self, name):\n    try:\n      return self[name]\n    except KeyError:\n      raise AttributeError(name)\n\n\nclass SystemContext:\n  """"""Global system.""""""\n\n  def __init__(self, modules=None, config: Optional[Config] = None):\n    self._config = config if config is not None else _get_global_config()\n    print(""SystemContext driver=%r"" % self._config.driver, file=sys.stderr)\n    self._is_dynamic = modules is None\n    if not self._is_dynamic:\n      init_modules = self._config.default_modules + tuple(modules)\n    else:\n      init_modules = None\n\n    self._vm_context = _binding.VmContext(\n        instance=self._config.vm_instance, modules=init_modules)\n\n    if self._is_dynamic:\n      self._vm_context.register_modules(self._config.default_modules)\n      self._modules = Modules([\n          (m.name, BoundModule(self, m)) for m in self._config.default_modules\n      ])\n    else:\n      self._modules = Modules([\n          (m.name, BoundModule(self, m)) for m in init_modules\n      ])\n\n  @property\n  def is_dynamic(self) -> bool:\n    return self._is_dynamic\n\n  @property\n  def config(self) -> Config:\n    return self._config\n\n  @property\n  def instance(self) -> _binding.VmInstance:\n    return self._instance\n\n  @property\n  def modules(self) -> Modules:\n    return self._modules\n\n  def create_function_abi(self, f: _binding.VmFunction) -> _binding.FunctionAbi:\n    return self._vm_context.create_function_abi(self._config.device,\n                                                self._config.host_type_factory,\n                                                f)\n\n  def add_modules(self, modules):\n    assert self._is_dynamic, ""Cannot \'add_module\' on a static context""\n    for m in modules:\n      name = m.name\n      if name in self._modules:\n        raise ValueError(""Attempt to register duplicate module: \'%s\'"" % (name,))\n      self._modules[m.name] = BoundModule(self, m)\n    self._vm_context.register_modules(modules)\n\n  def add_module(self, module):\n    self.add_modules((module,))\n\n\ndef load_modules(*modules, config: Optional[Config] = None):\n  """"""Loads modules into a new or shared context and returns them.""""""\n  context = SystemContext(modules=modules, config=config)\n  context_modules = context.modules\n  bound_modules = [context_modules[m.name] for m in modules]\n  return bound_modules\n\n\ndef load_module(module, **kwargs):\n  """"""Loads a module into a new or shared context and returns them.""""""\n  return load_modules(module, **kwargs)[0]\n'"
bindings/python/pyiree/rt/system_api_test.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=unused-variable\n\nimport re\n\nfrom absl.testing import absltest\nimport numpy as np\nfrom pyiree import compiler\nfrom pyiree import rt\n\n\ndef create_simple_mul_module():\n  ctx = compiler.Context()\n  input_module = ctx.parse_asm(""""""\n  module @arithmetic {\n    func @simple_mul(%arg0: tensor<4xf32>, %arg1: tensor<4xf32>) -> tensor<4xf32>\n          attributes { iree.module.export } {\n        %0 = ""xla_hlo.multiply""(%arg0, %arg1) {name = ""mul.1""} : (tensor<4xf32>, tensor<4xf32>) -> tensor<4xf32>\n        return %0 : tensor<4xf32>\n    }\n  }\n  """""")\n  binary = input_module.compile()\n  m = rt.VmModule.from_flatbuffer(binary)\n  return m\n\n\nclass SystemApiTest(absltest.TestCase):\n\n  def test_non_existing_driver(self):\n    with self.assertRaisesRegex(RuntimeError,\n                                ""Could not create any requested driver""):\n      config = rt.Config(""nothere1,nothere2"")\n\n  def test_subsequent_driver(self):\n    config = rt.Config(""nothere1,vmla"")\n\n  def test_empty_dynamic(self):\n    ctx = rt.SystemContext()\n    self.assertTrue(ctx.is_dynamic)\n    self.assertIn(""hal"", ctx.modules)\n    self.assertEqual(ctx.modules.hal.name, ""hal"")\n\n  def test_empty_static(self):\n    ctx = rt.SystemContext(modules=())\n    self.assertFalse(ctx.is_dynamic)\n    self.assertIn(""hal"", ctx.modules)\n    self.assertEqual(ctx.modules.hal.name, ""hal"")\n\n  def test_custom_dynamic(self):\n    ctx = rt.SystemContext()\n    self.assertTrue(ctx.is_dynamic)\n    ctx.add_module(create_simple_mul_module())\n    self.assertEqual(ctx.modules.arithmetic.name, ""arithmetic"")\n    f = ctx.modules.arithmetic[""simple_mul""]\n    f_repr = repr(f)\n    print(f_repr)\n    self.assertRegex(\n        f_repr,\n        re.escape(\n            ""(Buffer<float32[4]>, Buffer<float32[4]>) -> (Buffer<float32[4]>)""))\n\n  def test_duplicate_module(self):\n    ctx = rt.SystemContext()\n    self.assertTrue(ctx.is_dynamic)\n    ctx.add_module(create_simple_mul_module())\n    with self.assertRaisesRegex(ValueError, ""arithmetic""):\n      ctx.add_module(create_simple_mul_module())\n\n  def test_static_invoke(self):\n    ctx = rt.SystemContext()\n    self.assertTrue(ctx.is_dynamic)\n    ctx.add_module(create_simple_mul_module())\n    self.assertEqual(ctx.modules.arithmetic.name, ""arithmetic"")\n    f = ctx.modules.arithmetic[""simple_mul""]\n    arg0 = np.array([1., 2., 3., 4.], dtype=np.float32)\n    arg1 = np.array([4., 5., 6., 7.], dtype=np.float32)\n    results = f(arg0, arg1)\n    np.testing.assert_allclose(results, [4., 10., 18., 28.])\n\n  def test_load_module(self):\n    arithmetic = rt.load_module(create_simple_mul_module())\n    arg0 = np.array([1., 2., 3., 4.], dtype=np.float32)\n    arg1 = np.array([4., 5., 6., 7.], dtype=np.float32)\n    results = arithmetic.simple_mul(arg0, arg1)\n    np.testing.assert_allclose(results, [4., 10., 18., 28.])\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
bindings/python/pyiree/rt/vm_test.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=unused-variable\n\nfrom absl.testing import absltest\nimport numpy as np\nfrom pyiree import compiler\nfrom pyiree import rt\n\n\ndef create_simple_static_mul_module():\n  ctx = compiler.Context()\n  input_module = ctx.parse_asm(""""""\n    func @simple_mul(%arg0: tensor<4xf32>, %arg1: tensor<4xf32>) -> tensor<4xf32>\n          attributes { iree.module.export } {\n        %0 = ""xla_hlo.multiply""(%arg0, %arg1) {name = ""mul.1""} : (tensor<4xf32>, tensor<4xf32>) -> tensor<4xf32>\n        return %0 : tensor<4xf32>\n    }\n    """""")\n  binary = input_module.compile()\n  m = rt.VmModule.from_flatbuffer(binary)\n  return m\n\n\ndef create_simple_dynamic_abs_module():\n  ctx = compiler.Context()\n  # TODO(laurenzo): Compile for more backends as dynamic shapes come online.\n  target_backends = [""vmla""]\n  input_module = ctx.parse_asm(""""""\n    func @simple_mul(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32>\n          attributes { iree.module.export } {\n        %0 = ""xla_hlo.abs""(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>\n        return %0 : tensor<?x?xf32>\n    }\n    """""")\n  binary = input_module.compile(target_backends=target_backends)\n  m = rt.VmModule.from_flatbuffer(binary)\n  return m\n\n\nclass VmTest(absltest.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super().setUpClass()\n    driver_names = rt.HalDriver.query()\n    print(""DRIVER_NAMES ="", driver_names)\n    cls.driver = rt.HalDriver.create(""vmla"")\n    cls.device = cls.driver.create_default_device()\n    cls.hal_module = rt.create_hal_module(cls.device)\n    cls.htf = rt.HostTypeFactory.get_numpy()\n\n  def test_variant_list(self):\n    l = rt.VmVariantList(5)\n    print(l)\n    self.assertEqual(l.size, 0)\n\n  def test_context_id(self):\n    instance = rt.VmInstance()\n    context1 = rt.VmContext(instance)\n    context2 = rt.VmContext(instance)\n    self.assertGreater(context2.context_id, context1.context_id)\n\n  def test_module_basics(self):\n    m = create_simple_static_mul_module()\n    f = m.lookup_function(""simple_mul"")\n    self.assertGreater(f.ordinal, 0)\n    notfound = m.lookup_function(""notfound"")\n    self.assertIs(notfound, None)\n\n  def test_dynamic_module_context(self):\n    instance = rt.VmInstance()\n    context = rt.VmContext(instance)\n    m = create_simple_static_mul_module()\n    context.register_modules([self.hal_module, m])\n\n  def test_static_module_context(self):\n    m = create_simple_static_mul_module()\n    print(m)\n    instance = rt.VmInstance()\n    print(instance)\n    context = rt.VmContext(instance, modules=[self.hal_module, m])\n    print(context)\n\n  def test_dynamic_shape_compile(self):\n    m = create_simple_dynamic_abs_module()\n    print(m)\n    instance = rt.VmInstance()\n    print(instance)\n    context = rt.VmContext(instance, modules=[self.hal_module, m])\n    print(context)\n\n  def test_synchronous_dynamic_shape_invoke_function(self):\n    m = create_simple_dynamic_abs_module()\n    instance = rt.VmInstance()\n    context = rt.VmContext(instance, modules=[self.hal_module, m])\n    f = m.lookup_function(""simple_mul"")\n    abi = context.create_function_abi(self.device, self.htf, f)\n    print(""INVOKING:"", abi)\n    arg0 = np.array([[-1., 2.], [3., -4.]], dtype=np.float32)\n    inputs = abi.raw_pack_inputs((arg0,))\n    print(""INPUTS:"", inputs)\n    allocated_results = abi.allocate_results(inputs, static_alloc=False)\n    print(""ALLOCATED RESULTS:"", allocated_results)\n    print(""--- INVOKE:"")\n    context.invoke(f, inputs, allocated_results)\n    print(""--- DONE."")\n    results = abi.raw_unpack_results(allocated_results)\n    print(""RESULTS:"", results)\n    np.testing.assert_allclose(results[0], [[1., 2.], [3., 4.]])\n\n  def test_synchronous_invoke_function(self):\n    m = create_simple_static_mul_module()\n    instance = rt.VmInstance()\n    context = rt.VmContext(instance, modules=[self.hal_module, m])\n    f = m.lookup_function(""simple_mul"")\n    abi = context.create_function_abi(self.device, self.htf, f)\n    print(""INVOKING:"", abi)\n    arg0 = np.array([1., 2., 3., 4.], dtype=np.float32)\n    arg1 = np.array([4., 5., 6., 7.], dtype=np.float32)\n    inputs = abi.raw_pack_inputs((arg0, arg1))\n    print(""INPUTS:"", inputs)\n    allocated_results = abi.allocate_results(inputs, static_alloc=False)\n    print(""ALLOCATED RESULTS:"", allocated_results)\n    print(""--- INVOKE:"")\n    context.invoke(f, inputs, allocated_results)\n    print(""--- DONE."")\n    results = abi.raw_unpack_results(allocated_results)\n    print(""RESULTS:"", results)\n    np.testing.assert_allclose(results[0], [4., 10., 18., 28.])\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
integrations/tensorflow/compiler/test/saved_model_adopt_exports.py,56,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests supported features of saved models.""""""\n\n# pylint: disable=invalid-name\n# pylint: disable=missing-docstring\n# pylint: disable=line-too-long\n\nfrom pyiree.tf.support import tf_test_driver\nimport tensorflow.compat.v2 as tf\n\nSAVED_MODEL_IMPORT_PASSES = [\n    ""tf-executor-graph-pruning"",\n    ""tf-standard-pipeline"",\n    ""iree-tf-import-pipeline"",\n    ""canonicalize"",\n]\n\n\n# Tests that a simple example with flat args and a single result and no\n# captures imports properly.\n# CHECK-LABEL: RUN_TEST: T0001_FlatArgsResultsNoBoundGlobals\n# CHECK: module\n# CHECK-NOT: tf_saved_model.semantics\n# CHECK: @simple_mul_no_capture\n# CHECK: iree.module.export\n# CHECK: FINISH_TEST\nclass T0001_FlatArgsResultsNoBoundGlobals(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul_no_capture(self, a, b):\n    return a * b\n\n\ntf_test_driver.add_test(\n    test_name=""T0001_FlatArgsResultsNoBoundGlobals"",\n    tf_module_builder=T0001_FlatArgsResultsNoBoundGlobals,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n# T0002: Tests that bound global vars import properly.\n\n\n# CHECK-LABEL: RUN_TEST: T0002a_SimpleVarRead\n# CHECK: flow.variable @v mutable dense<0.000000e+00> : tensor<f32>\n# CHECK: func @f() -> tensor<f32>\n# CHECK: attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I1!R3!_0""}\n# CHECK:   flow.variable.load @v : tensor<f32>\n# CHECK: FINISH_TEST\nclass T0002a_SimpleVarRead(tf.Module):\n\n  def __init__(self):\n    self.v = tf.Variable(0.)\n\n  @tf.function(input_signature=[])\n  def f(self):\n    return self.v\n\n\n# CHECK-LABEL: RUN_TEST: T0002b_SimpleVarWrite\n# CHECK: flow.variable @v mutable dense<0.000000e+00> : tensor<f32>\n# CHECK: func @f(%arg0: tensor<f32> {tf._user_specified_name = ""a""})\n# CHECK: attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I8!S5!k0_0R1!""}\n# CHECK: flow.variable.store %arg0, @v : tensor<f32>\n# CHECK: FINISH_TEST\nclass T0002b_SimpleVarWrite(tf.Module):\n\n  def __init__(self):\n    self.v = tf.Variable(0.)\n\n  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n  def f(self, a):\n    self.v.assign(a)\n\n\n# CHECK-LABEL: RUN_TEST: T0002c_SimpleConst\n# CHECK: flow.variable [[CONST:@.+]] dense<0.000000e+00> : tensor<f32>\n# CHECK: func @f() -> tensor<f32>\n# CHECK: attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I1!R3!_0""}\n# NOTE: the constant variable gets inlined:\n# CHECK: = constant dense<0.000000e+00> : tensor<f32>\n# CHECK: FINISH_TEST\nclass T0002c_SimpleConst(tf.Module):\n\n  def __init__(self):\n    self.c = tf.constant(0.)\n\n  @tf.function(input_signature=[])\n  def f(self):\n    return self.c\n\n\n# CHECK-LABEL: RUN_TEST: T0002d_VarCompatibleShapeChange\n# CHECK: flow.variable @v mutable dense<0.000000e+00> : tensor<1xf32>\n# CHECK: func @f()\n# CHECK: attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I1!R1!""}\n# CHECK-DAG:   [[CONST_2xf32:%.+]] = ""tf.Const""() {value = dense<[0.000000e+00, 1.000000e+00]> : tensor<2xf32>} : () -> tensor<2xf32>\n# CHECK-DAG:   [[CONST_3xf32:%.+]] = ""tf.Const""() {value = dense<[0.000000e+00, 1.000000e+00, 2.000000e+00]> : tensor<3xf32>} : () -> tensor<3xf32>\n# CHECK-DAG:   flow.variable.store [[CONST_2xf32]], @v : tensor<2xf32>\n# CHECK-DAG:   flow.variable.store [[CONST_3xf32]], @v : tensor<3xf32>\n# CHECK: FINISH_TEST\nclass T0002d_VarCompatibleShapeChange(tf.Module):\n\n  def __init__(self):\n    self.v = tf.Variable([0.], shape=[None])\n\n  @tf.function(input_signature=[])\n  def f(self):\n    self.v.assign(tf.constant([0., 1.]))\n    self.v.assign(tf.constant([0., 1., 2.]))\n\n\n# CHECK-LABEL: RUN_TEST: T0002e_Error_VarMultipleExportedNames\n# CHECK: [ERROR]: Multiple exported names for global tensor not supported yet\n# CHECK: FINISH_TEST\nclass T0002e_Error_VarMultipleExportedNames(tf.Module):\n\n  def __init__(self):\n    self.v = tf.Variable(0.)\n    self.v2 = self.v\n\n\n# CHECK-LABEL: RUN_TEST: T0002f_Error_UnsupportedResourceOp\n# CHECK: [ERROR]: could not lower resource op to flow\n# CHECK: FINISH_TEST\nclass T0002f_Error_UnsupportedResourceOp(tf.Module):\n\n  def __init__(self):\n    self.v = tf.Variable([0.], shape=[None])\n\n  @tf.function(input_signature=[])\n  def f(self):\n    self.v.assign_add(tf.constant([0., 1.]))\n\n\ntf_test_driver.add_test(\n    test_name=""T0002a_SimpleVarRead"",\n    tf_module_builder=T0002a_SimpleVarRead,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\ntf_test_driver.add_test(\n    test_name=""T0002b_SimpleVarWrite"",\n    tf_module_builder=T0002b_SimpleVarWrite,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\ntf_test_driver.add_test(\n    test_name=""T0002c_SimpleConst"",\n    tf_module_builder=T0002c_SimpleConst,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\ntf_test_driver.add_test(\n    test_name=""T0002d_VarCompatibleShapeChange"",\n    tf_module_builder=T0002d_VarCompatibleShapeChange,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\ntf_test_driver.add_test(\n    test_name=""T0002e_Error_VarMultipleExportedNames"",\n    tf_module_builder=T0002e_Error_VarMultipleExportedNames,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True,\n    expect_pass_failure=True)\ntf_test_driver.add_test(\n    test_name=""T0002f_Error_UnsupportedResourceOp"",\n    tf_module_builder=T0002f_Error_UnsupportedResourceOp,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True,\n    expect_pass_failure=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0003a_StructuredArgs\n# CHECK: func @simple_mul\n# CHECK:      attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I23!S19!k0D13!K2!x_0K2!y_1R3!_0""}\n# CHECK: FINISH_TEST\nclass T0003a_StructuredArgs(tf.Module):\n\n  @tf.function(input_signature=[{\n      ""x"": tf.TensorSpec([4], tf.float32),\n      ""y"": tf.TensorSpec([4], tf.float32)\n  }])\n  def simple_mul(self, d):\n    return d[""x""] * d[""y""]\n\n\ntf_test_driver.add_test(\n    test_name=""T0003a_StructuredArgs"",\n    tf_module_builder=T0003a_StructuredArgs,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0003b_StructuredMultipleDictResult\n# CHECK: func @simple_mul\n# CHECK:      attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I12!S9!k0_0k1_1R26!D22!K2!x_0K10!x_squared_1""}\n# CHECK: FINISH_TEST\nclass T0003b_StructuredMultipleDictResult(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    product = a * b\n    return {""x"": product, ""x_squared"": product * product}\n\n\ntf_test_driver.add_test(\n    test_name=""T0003b_StructuredMultipleDictResult"",\n    tf_module_builder=T0003b_StructuredMultipleDictResult,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0003c_StructuredSingleDictResult\n# CHECK: func @simple_mul\n# CHECK:      attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I12!S9!k0_0k1_1R10!D7!K2!x_0""}\n# CHECK: FINISH_TEST\nclass T0003c_StructuredSingleDictResult(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    product = a * b\n    return {""x"": product}\n\n\ntf_test_driver.add_test(\n    test_name=""T0003c_StructuredSingleDictResult"",\n    tf_module_builder=T0003c_StructuredSingleDictResult,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0003d_StructuredSingleResult\n# CHECK: func @simple_mul\n# CHECK:      attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I12!S9!k0_0k1_1R3!_0""}\n# CHECK: FINISH_TEST\nclass T0003d_StructuredSingleResult(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    product = a * b\n    return product\n\n\ntf_test_driver.add_test(\n    test_name=""T0003d_StructuredSingleResult"",\n    tf_module_builder=T0003d_StructuredSingleResult,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0003e_StructuredSequenceResult\n# CHECK: func @simple_mul\n# CHECK:      attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I12!S9!k0_0k1_1R17!S13!k0_0k1_1k2_2""}\n# CHECK: FINISH_TEST\nclass T0003e_StructuredSequenceResult(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    product = a * b\n    return product, a, b\n\n\ntf_test_driver.add_test(\n    test_name=""T0003e_StructuredSequenceResult"",\n    tf_module_builder=T0003e_StructuredSequenceResult,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0003f_StructuredNestedResult\n# CHECK: func @simple_mul\n# CHECK:      attributes\n# CHECK-SAME: iree.module.export\n# CHECK-SAME: iree.reflection = {abi = ""sip"", abiv = 1 : i32, sip = ""I12!S9!k0_0k1_1R27!S23!k0_0k1D13!K2!a_1K2!b_2""}\n# CHECK: FINISH_TEST\nclass T0003f_StructuredNestedResult(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    product = a * b\n    return product, {""a"": a, ""b"": b}\n\n\ntf_test_driver.add_test(\n    test_name=""T0003f_StructuredNestedResult"",\n    tf_module_builder=T0003f_StructuredNestedResult,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True)\n\n\n# Tests that a structured argument is handled properly.\n# NOTE: This is currently an error and needs to be implemented\n# CHECK-LABEL: RUN_TEST: T0005_MultipleExportedFuncNames\n# CHECK: [ERROR]: Multiple exported names not supported yet\n# CHECK: FINISH_TEST_WITH_EXCEPTION\nclass T0005_MultipleExportedFuncNames(tf.Module):\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def simple_mul(self, a, b):\n    product = a * b\n    return {""x"": product}\n\n\n# Force a function alias.\nT0005_MultipleExportedFuncNames.another_copy = (\n    T0005_MultipleExportedFuncNames.simple_mul)\n\ntf_test_driver.add_test(\n    test_name=""T0005_MultipleExportedFuncNames"",\n    tf_module_builder=T0005_MultipleExportedFuncNames,\n    passes=SAVED_MODEL_IMPORT_PASSES,\n    print_input_module=True,\n    expect_pass_failure=True)\n\nif __name__ == ""__main__"":\n  tf_test_driver.run_tests(__file__, with_filecheck=True)\n'"
integrations/tensorflow/e2e/keras/keras_lstm_static_test.py,10,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This test is the same as keras_lstm_test, but all shapes are static.\n# This stresses the TensorList lowering more specifically.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nNUM_UNITS = 10\nNUM_TIMESTEPS = 24\nNUM_BATCH = 7\nINPUT_SHAPE = [NUM_BATCH, NUM_TIMESTEPS, NUM_UNITS]\n\n\ndef lstm_module():\n  tf_test_utils.set_random_seed()\n  inputs = tf.keras.layers.Input(batch_size=NUM_BATCH, shape=INPUT_SHAPE[1:])\n  outputs = tf.keras.layers.LSTM(units=NUM_UNITS, return_sequences=True)(inputs)\n  model = tf.keras.Model(inputs, outputs)\n  module = tf.Module()\n  module.m = model\n  module.predict = tf.function(\n      input_signature=[tf.TensorSpec(INPUT_SHAPE, tf.float32)])(\n          model.call)\n  return module\n\n\n# TODO(silvasean): Get this test working on other backends.\n@tf_test_utils.compile_modules(\n    backends=[""tf"", ""iree_vmla""], lstm=(lstm_module, [""predict""]))\nclass LstmTest(tf_test_utils.SavedModelTestCase):\n\n  def test_lstm(self):\n    m = self.modules.lstm.all\n    m.predict(\n        tf.constant(\n            np.arange(NUM_BATCH * NUM_TIMESTEPS * NUM_UNITS,\n                      dtype=np.float32).reshape(\n                          [NUM_BATCH, NUM_TIMESTEPS, NUM_UNITS]),\n            shape=[NUM_BATCH, NUM_TIMESTEPS,\n                   NUM_UNITS])).print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/keras/keras_lstm_test.py,10,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nNUM_UNITS = 10\nNUM_TIMESTEPS = 24\nNUM_BATCH = 7\nINPUT_SHAPE = [None, None, NUM_UNITS]\n\n\ndef lstm_module():\n  tf_test_utils.set_random_seed()\n  inputs = tf.keras.layers.Input(batch_size=None, shape=INPUT_SHAPE[1:])\n  outputs = tf.keras.layers.LSTM(units=NUM_UNITS, return_sequences=True)(inputs)\n  model = tf.keras.Model(inputs, outputs)\n  module = tf.Module()\n  module.m = model\n  module.predict = tf.function(\n      input_signature=[tf.TensorSpec(INPUT_SHAPE, tf.float32)])(\n          model.call)\n  return module\n\n\n# TODO(silvasean): Get this test working on IREE.\n# Needs TensorList with current Keras implementation.\n@tf_test_utils.compile_modules(backends=[""tf""], lstm=(lstm_module, [""predict""]))\nclass LstmTest(tf_test_utils.SavedModelTestCase):\n\n  def test_lstm(self):\n    m = self.modules.lstm.all\n    m.predict(\n        tf.constant(\n            np.arange(NUM_BATCH * NUM_TIMESTEPS * NUM_UNITS,\n                      dtype=np.float32).reshape(\n                          [NUM_BATCH, NUM_TIMESTEPS, NUM_UNITS]),\n            shape=[NUM_BATCH, NUM_TIMESTEPS,\n                   NUM_UNITS])).print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/keras/keras_vision_model_test.py,26,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test all applications models in Keras.""""""\nimport os\nfrom absl import flags\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nimport tensorflow.compat.v2 as tf\n\nFLAGS = flags.FLAGS\n\n# Testing all applications models automatically can take time\n# so we test it one by one, with argument --model=MobileNet\nflags.DEFINE_string(\'model\', \'ResNet50\', \'model name\')\nflags.DEFINE_string(\n    \'url\', \'\', \'url with model weights \'\n    \'for example https://storage.googleapis.com/iree_models/\')\nflags.DEFINE_enum(\'data\', \'cifar10\', [\'cifar10\', \'imagenet\'],\n                  \'data sets on which model was trained: imagenet, cifar10\')\nflags.DEFINE_integer(\'include_top\', 0, \'if 1 top level is appended\')\n\nAPP_MODELS = {\n    \'ResNet50\':\n        tf.keras.applications.resnet.ResNet50,\n    \'ResNet101\':\n        tf.keras.applications.resnet.ResNet101,\n    \'ResNet152\':\n        tf.keras.applications.resnet.ResNet152,\n    \'ResNet50V2\':\n        tf.keras.applications.resnet_v2.ResNet50V2,\n    \'ResNet101V2\':\n        tf.keras.applications.resnet_v2.ResNet101V2,\n    \'ResNet152V2\':\n        tf.keras.applications.resnet_v2.ResNet152V2,\n    \'VGG16\':\n        tf.keras.applications.vgg16.VGG16,\n    \'VGG19\':\n        tf.keras.applications.vgg19.VGG19,\n    \'Xception\':\n        tf.keras.applications.xception.Xception,\n    \'InceptionV3\':\n        tf.keras.applications.inception_v3.InceptionV3,\n    \'InceptionResNetV2\':\n        tf.keras.applications.inception_resnet_v2.InceptionResNetV2,\n    \'MobileNet\':\n        tf.keras.applications.mobilenet.MobileNet,\n    \'MobileNetV2\':\n        tf.keras.applications.mobilenet_v2.MobileNetV2,\n    \'DenseNet121\':\n        tf.keras.applications.densenet.DenseNet121,\n    \'DenseNet169\':\n        tf.keras.applications.densenet.DenseNet169,\n    \'DenseNet201\':\n        tf.keras.applications.densenet.DenseNet201,\n    \'NASNetMobile\':\n        tf.keras.applications.nasnet.NASNetMobile,\n    \'NASNetLarge\':\n        tf.keras.applications.nasnet.NASNetLarge,\n}\n\n\ndef get_input_shape(data, model):\n  if data == \'imagenet\':\n    if (model == \'InceptionV3\' or model == \'Xception\' or\n        model == \'InceptionResNetV2\'):\n      return (1, 299, 299, 3)\n    elif model == \'NASNetLarge\':\n      return (1, 331, 331, 3)\n    else:\n      return (1, 224, 224, 3)\n  elif data == \'cifar10\':\n    return (1, 32, 32, 3)\n  else:\n    raise ValueError(\'Not supported data \', data)\n\n\ndef models():\n  tf.keras.backend.set_learning_phase(False)\n  tf_test_utils.set_random_seed()\n\n  input_shape = get_input_shape(FLAGS.data, FLAGS.model)\n  # keras model receives images size as input,\n  # where batch size is not specified - by default it is dynamic\n  if FLAGS.model in APP_MODELS:\n    weights = \'imagenet\' if FLAGS.data == \'imagenet\' else None\n\n    # if weights == \'imagenet\' it will load weights from external tf.keras URL\n    model = APP_MODELS[FLAGS.model](\n        weights=weights,\n        include_top=FLAGS.include_top,\n        input_shape=input_shape[1:])\n\n    if FLAGS.data == \'cifar10\' and FLAGS.url:\n      file_name = \'cifar10\' + FLAGS.model\n      # it will download model weights from publically available folder: PATH\n      # and save it to cache_dir=~/.keras and return path to it\n      weights_path = tf.keras.utils.get_file(\n          file_name,\n          os.path.join(\n              FLAGS.url,\n              \'cifar10_include_top_{}_{}\'.format(FLAGS.include_top,\n                                                 FLAGS.model + \'.h5\')))\n\n      model.load_weights(weights_path)\n  else:\n    raise ValueError(\'Unsupported model\', FLAGS.model)\n\n  module = tf.Module()\n  module.m = model\n  # specify input size with static batch size\n  # TODO(b/142948097): with support of dynamic shape\n  # replace input_shape by model.input_shape, so batch size will be dynamic (-1)\n  module.predict = tf.function(input_signature=[tf.TensorSpec(input_shape)])(\n      model.call)\n  return module\n\n\n@tf_test_utils.compile_modules(applications=(models, [\'predict\']))\nclass AppTest(tf_test_utils.SavedModelTestCase):\n\n  def test_application(self):\n    input_shape = get_input_shape(FLAGS.data, FLAGS.model)\n    input_data = np.random.rand(np.prod(np.array(input_shape))).astype(\n        np.float32)\n    input_data = input_data.reshape(input_shape)\n    self.modules.applications.all.predict(input_data).print().assert_all_close(\n        atol=1e-6)\n\n\nif __name__ == \'__main__\':\n  if hasattr(tf, \'enable_v2_behavior\'):\n    tf.enable_v2_behavior()\n  tf.test.main()\n'"
integrations/tensorflow/e2e/keras/train_vision_models_on_cifar.py,20,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Train vision models on CIFAR10.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import flags\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v1 as tf\n\nFLAGS = flags.FLAGS\nflags.DEFINE_string(\'model_name\', \'MobileNet\', \'keras vision model name\')\nflags.DEFINE_string(\'model_path\', \'\',\n                    \'Path to a location where model will be saved.\')\nflags.DEFINE_integer(\'include_top\', 0, \'if 1 top level is appended\')\n\nAPP_MODELS = {\n    \'ResNet50\':\n        tf.keras.applications.resnet.ResNet50,\n    \'ResNet101\':\n        tf.keras.applications.resnet.ResNet101,\n    \'ResNet152\':\n        tf.keras.applications.resnet.ResNet152,\n    \'ResNet50V2\':\n        tf.keras.applications.resnet_v2.ResNet50V2,\n    \'ResNet101V2\':\n        tf.keras.applications.resnet_v2.ResNet101V2,\n    \'ResNet152V2\':\n        tf.keras.applications.resnet_v2.ResNet152V2,\n    \'VGG16\':\n        tf.keras.applications.vgg16.VGG16,\n    \'VGG19\':\n        tf.keras.applications.vgg19.VGG19,\n    \'Xception\':\n        tf.keras.applications.xception.Xception,\n    \'InceptionV3\':\n        tf.keras.applications.inception_v3.InceptionV3,\n    \'InceptionResNetV2\':\n        tf.keras.applications.inception_resnet_v2.InceptionResNetV2,\n    \'MobileNet\':\n        tf.keras.applications.mobilenet.MobileNet,\n    \'MobileNetV2\':\n        tf.keras.applications.mobilenet_v2.MobileNetV2,\n    \'DenseNet121\':\n        tf.keras.applications.densenet.DenseNet121,\n    \'DenseNet169\':\n        tf.keras.applications.densenet.DenseNet169,\n    \'DenseNet201\':\n        tf.keras.applications.densenet.DenseNet201,\n    \'NASNetMobile\':\n        tf.keras.applications.nasnet.NASNetMobile,\n    \'NASNetLarge\':\n        tf.keras.applications.nasnet.NASNetLarge,\n}\n\n# minimum size for keras vision models\nINPUT_SHAPE = [1, 32, 32, 3]\n\n\ndef main(_):\n\n  # prepare training and testing data\n  (train_images,\n   train_labels), (test_images,\n                   test_labels) = tf.keras.datasets.cifar10.load_data()\n  train_labels = np.array([x[0] for x in train_labels])\n  test_labels = np.array([x[0] for x in test_labels])\n\n  # Normalize image values to be between 0 and 1\n  train_images, test_images = train_images / 255.0, test_images / 255.0\n\n  # reduce training samples for quick training\n  # we do not need to use all data for getting non zero output scores\n  train_images = train_images[:4000]\n  train_labels = train_labels[:4000]\n\n  # It is a toy model for debugging (not optimized for accuracy or speed).\n  model = APP_MODELS[FLAGS.model_name](\n      weights=None, include_top=FLAGS.include_top, input_shape=INPUT_SHAPE[1:])\n  model.summary()\n  model.compile(\n      optimizer=\'adam\',\n      loss=\'sparse_categorical_crossentropy\',\n      metrics=[\'accuracy\'])\n\n  # train model\n  model.fit(\n      train_images,\n      train_labels,\n      epochs=1,\n      validation_data=(test_images, test_labels))\n\n  file_name = os.path.join(\n      FLAGS.model_path,\n      \'cifar10_include_top_{}_{}\'.format(FLAGS.include_top,\n                                         FLAGS.model_name + \'.h5\'))\n  try:\n    model.save_weights(file_name)\n  except IOError as e:\n    raise IOError(\'Failed to save model at: %s, error: %s\' % (file_name, e))\n\n  # test model\n  _, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n  logging.info(\'Test accuracy: %f\', test_acc)\n\n\nif __name__ == \'__main__\':\n  tf.app.run(main=main)\n'"
integrations/tensorflow/e2e/keras/train/keras_model_train_test.py,13,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test keras Model training.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import flags\nimport numpy as np\nfrom pyiree.tf.support import tf_test_utils\nfrom sklearn.preprocessing import PolynomialFeatures\nimport tensorflow as tf\n\nFLAGS = flags.FLAGS\nflags.DEFINE_string(\n    ""optimizer_name"", ""sgd"",\n    ""optimizer name: sgd, rmsprop, nadam, adamax, adam, adagrad, adadelta"")\n\n_DEGREE = 3  # polynomial degree of input feature for regression test\n_FEATURE_SIZE = _DEGREE + 1  # input feature size\n_BATCH_SIZE = 8  # batch size has to be dynamic TODO(b/142948097)\n_INPUT_DATA_SHAPE = [_BATCH_SIZE, _FEATURE_SIZE]\n_OUTPUT_DATA_SHAPE = [_BATCH_SIZE, 1]\n\n\nclass ModelTrain(tf.Module):\n  """"""A module for model training.""""""\n\n  @staticmethod\n  def CreateModule(input_dim=_FEATURE_SIZE, output_dim=1):\n    """"""Creates a module for regression model training.\n\n    Args:\n      input_dim: input dimensionality\n      output_dim: output dimensionality\n\n    Returns:\n      model for linear regression\n    """"""\n\n    tf_test_utils.set_random_seed()\n\n    # build a single layer model\n    inputs = tf.keras.layers.Input((input_dim))\n    outputs = tf.keras.layers.Dense(output_dim)(inputs)\n    model = tf.keras.Model(inputs, outputs)\n    return ModelTrain(model)\n\n  def __init__(self, model):\n    self.model = model\n    self.loss = tf.keras.losses.MeanSquaredError()\n    self.optimizer = tf.keras.optimizers.get(FLAGS.optimizer_name)\n\n  @tf.function(input_signature=[\n      tf.TensorSpec(_INPUT_DATA_SHAPE, tf.float32),\n      tf.TensorSpec(_OUTPUT_DATA_SHAPE, tf.float32)\n  ])\n  def TrainStep(self, inputs, targets):\n    with tf.GradientTape() as tape:\n      predictions = self.model(inputs, training=True)\n      loss_value = self.loss(predictions, targets)\n    gradients = tape.gradient(loss_value, self.model.trainable_variables)\n    self.optimizer.apply_gradients(\n        zip(gradients, self.model.trainable_variables))\n    return loss_value\n\n\n@tf_test_utils.compile_modules(\n    backends=[""tf""], train_module=(ModelTrain.CreateModule, [""TrainStep""]))\nclass ModelTrainTest(tf_test_utils.SavedModelTestCase):\n\n  def generate_regression_data(self, size=8):\n    x = np.arange(size) - size // 2\n    y = 1.0 * x**3 + 1.0 * x**2 + 1.0 * x + np.random.randn(size) * size\n    return x, y\n\n  def test_model_train(self):\n\n    # generate input and output data for regression problem\n    inputs, targets = self.generate_regression_data()\n\n    # normalize data\n    inputs = inputs / max(inputs)\n    targets = targets / max(targets)\n\n    # generate plynomial features\n    inputs = np.expand_dims(inputs, axis=1)\n    polynomial = PolynomialFeatures(_DEGREE)  # returns: [1, a, b, a^2, ab, b^2]\n    inputs = polynomial.fit_transform(inputs)\n\n    targets = np.expand_dims(targets, axis=1)\n    # run one iteration of training step\n    result = self.modules.train_module.all.TrainStep(inputs, targets)\n    result.print().assert_all_close()\n\n\nif __name__ == ""__main__"":\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n\n  tf.test.main()\n'"
integrations/tensorflow/bindings/python/pyiree/tf/compiler/__init__.py,0,"b'# Lint-as: python3\n""""""Module init for the python bindings.""""""\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=g-multiple-import\n# pylint: disable=g-bad-import-order\n# pylint: disable=g-import-not-at-top\n# pylint: disable=wildcard-import\n\n__all__ = [\n    # Common\n    ""Context"",\n    ""Module"",\n    ""CompileOptions"",\n    ""OutputFormat"",\n    # TensorFlow\n    ""TF_IMPORT_PASS_PIPELINE"",\n    ""tf_load_saved_model"",\n    ""tf_load_signature_def_saved_model"",\n    ""tf_compile_saved_model"",\n]\n\nfrom typing import Collection, Optional, Sequence\n\nfrom . import binding as binding\n\n# Native aliases (matches those in the generic compiler).\nllvm = binding.llvm\nContext = binding.CompilerContext\nModule = binding.CompilerModule\nCompileOptions = binding.CompileOptions\nOutputFormat = binding.OutputFormat\n\n# Pass pipeline that should run to lower a TF saved_model to a form suitable\n# for input to the IREE compiler.\nTF_IMPORT_PASS_PIPELINE = (\n    # Clean up tf_executor and extraneous unused functions.\n    ""tf-saved-model-mark-func-visibility"",\n    ""symbol-dce"",\n    ""tf-executor-graph-pruning"",\n    ""iree-guarantee-all-funcs-one-use"",\n    ""tf-standard-pipeline"",\n\n    # Try to get the IR in good condition.\n    # In particular, because IREE doesn\'t handle dynamic shapes, we need to\n    # guarantee here that all dynamic shapes are gone.\n    # TODO(silvasean): Add a verifier pass that enforces that.\n    ""inline"",\n    ""canonicalize"",\n    ""tf-shape-inference"",\n\n    # Lower to CFG.\n    # After this point, most TF optimizations won\'t work properly besides\n    # simple canonicalizations.\n    ""tf-functional-control-flow-to-cfg"",\n    # Inline, as tf-functional-control-flow-to-cfg leaves in calls.\n    ""inline"",\n\n    # Some further cleanups now that control flow is in better shape.\n    ""tf-saved-model-mark-func-visibility"",\n    ""symbol-dce"",\n    ""canonicalize"",\n\n    # Legalize to XLA\n    ""tf-device-decompose-resource-ops"",\n    ""xla-legalize-tf{allow-partial-conversion=true}"",\n    ""canonicalize"",\n\n    # Now that the IR is starting to look nice, optimize global tensors.\n    ""tf-saved-model-optimize-global-tensors"",\n\n    # IREE-specific passes to prepare TF code for IREE compilation.\n    # In particular, this eliminates tf_saved_model.\n    ""iree-tf-import-pipeline"",\n\n    # Temporary: Does some special case fixups of HLO ops with dynamic\n    # shapes until these can be done properly upstream.\n    ""iree-shape-convert-hlo"",\n)\n\n\ndef tf_load_saved_model(\n    saved_model_dir: str,\n    compiler_context: Optional[Context] = None,\n    exported_names: Collection[str] = (),\n    pass_pipeline: Sequence[str] = TF_IMPORT_PASS_PIPELINE) -> Module:\n  """"""Loads a TensorFlow saved model from its persistent representation.\n\n  See also tf_compile_saved_model() for a one-shot API to load and compile.\n\n  Args:\n    saved_model_dir: Directory of the saved model.\n    compiler_context: The pyiree.compiler.Context() backing the module.\n    exported_names: Optional tuple of strings representing the exported names to\n      keep.\n    pass_pipeline: Passes to run on the imported module prior to returning.\n      Defaults to TF_IMPORT_PASS_PIPELINE.\n\n  Returns:\n    An MLIR Module suitable for compilation by the IREE compiler.\n    This can be further compiled to an IREE blob by calling\n    .compile_to_sequencer_blob.\n  """"""\n  if not compiler_context:\n    compiler_context = Context()\n  input_module = binding.load_saved_model(\n      compiler_context, saved_model_dir, exported_names=exported_names)\n  if pass_pipeline:\n    input_module.run_pass_pipeline(pass_pipeline)\n  return input_module\n\n\ndef tf_load_signature_def_saved_model(\n    saved_model_dir: str,\n    compiler_context: Optional[Context] = None,\n    tags: Collection[str] = set(),\n    exported_names: Collection[str] = [],\n    pass_pipeline: Sequence[str] = TF_IMPORT_PASS_PIPELINE) -> Module:\n  """"""Loads a TensorFlow SignatureDef saved model from persistent representation.\n\n  Args:\n    saved_model_dir: Directory of the saved model.\n    compiler_context: The pyiree.compiler.Context() backing the module.\n    tags: Optional tuple of tags to use when loading the model.\n    exported_names: Optional tuple of strings representing the exported names to\n      keep.\n    pass_pipeline: Passes to run on the imported module prior to returning.\n      Defaults to TF_IMPORT_PASS_PIPELINE.\n\n  Returns:\n    An MLIR Module suitable for compilation by the IREE compiler.\n    This can be further compiled to an IREE blob by calling\n    .compile_to_sequencer_blob.\n  """"""\n  if not compiler_context:\n    compiler_context = Context()\n  input_module = binding.load_signature_def_saved_model(\n      compiler_context, saved_model_dir, tags, exported_names=exported_names)\n  if pass_pipeline:\n    input_module.run_pass_pipeline(pass_pipeline)\n  return input_module\n\n\ndef tf_compile_saved_model(\n    saved_model_dir: str,\n    compiler_context: Optional[Context] = None,\n    exported_names: Collection[str] = (),\n    pass_pipeline: Sequence[str] = TF_IMPORT_PASS_PIPELINE,\n    target_backends: Collection[str] = ()\n) -> binding.OpaqueBlob:\n  """"""Loads and compiles a TensorFlow saved model in one shot.\n\n  Args:\n    saved_model_dir: Directory of the saved model.\n    compiler_context: The pyiree.compiler.Context() backing the module.\n    exported_names: Optional tuple of strings representing the exported names to\n      keep.\n    pass_pipeline: Passes to run on the imported module prior to returning.\n      Defaults to TF_IMPORT_PASS_PIPELINE.\n    target_backends: The specific target backends to compile for (defaults to\n      all compiled in targets).\n\n  Returns:\n    An OpaqueBlob representing the compiled module.\n  """"""\n  input_module = tf_load_saved_model(saved_model_dir, compiler_context,\n                                     exported_names, pass_pipeline)\n  return input_module.compile(target_backends=target_backends)\n'"
integrations/tensorflow/bindings/python/pyiree/tf/compiler/saved_model_test.py,11,"b'# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport importlib\nimport os\nimport sys\nimport tempfile\n\nfrom pyiree.tf import compiler\n\n# Dynamically import tensorflow.\ntry:\n  # Use a dynamic import so as to avoid hermetic dependency analysis\n  # (i.e. we only want the tensorflow from the environment).\n  tf = importlib.import_module(""tensorflow"")\n  # Just in case if linked against a pre-V2 defaulted version.\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf = tf.compat.v2\nexcept ImportError:\n  print(""Not running tests because tensorflow is not available"")\n  sys.exit(0)\n\n\nclass StatelessModule(tf.Module):\n\n  def __init__(self):\n    pass\n\n  @tf.function(input_signature=[\n      tf.TensorSpec([4], tf.float32),\n      tf.TensorSpec([4], tf.float32)\n  ])\n  def add(self, a, b):\n    return tf.tanh(a + b)\n\n\nclass RuntimeTest(tf.test.TestCase):\n\n  def testLoadSavedModelToXlaPipeline(self):\n    """"""Tests that a basic saved model to XLA workflow grossly functions.\n\n    This is largely here to verify that everything is linked in that needs to be\n    and that there are not no-ops, etc.\n    """"""\n    with tempfile.TemporaryDirectory() as temp_dir:\n      sm_dir = os.path.join(temp_dir, ""simple.sm"")\n      print(""Saving to:"", sm_dir)\n      my_module = StatelessModule()\n      options = tf.saved_model.SaveOptions(save_debug_info=True)\n      tf.saved_model.save(my_module, sm_dir, options=options)\n\n      # Load it up.\n      input_module = compiler.tf_load_saved_model(sm_dir)\n      xla_asm = input_module.to_asm()\n      print(""XLA ASM:"", xla_asm)\n      self.assertRegex(xla_asm, ""xla_hlo.tanh"")\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
integrations/tensorflow/bindings/python/pyiree/tf/compiler/signature_def_saved_model_test.py,10,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport importlib\nimport os\nimport sys\nimport tempfile\n\nfrom pyiree.tf import compiler\n\n# Dynamically import tensorflow.\ntry:\n  # Use a dynamic import so as to avoid hermetic dependency analysis\n  # (i.e. we only want the tensorflow from the environment).\n  tf = importlib.import_module(""tensorflow"")\n  # Just in case if linked against a pre-V2 defaulted version.\n  if hasattr(tf, ""enable_v2_behavior""):\n    tf.enable_v2_behavior()\n  tf = tf.compat.v2\nexcept ImportError:\n  print(""Not running tests because tensorflow is not available"")\n  sys.exit(0)\n\n\nclass RuntimeTest(tf.test.TestCase):\n\n  def testLoadSignatureDefSavedModel(self):\n    """"""Tests loading a SignatureDef saved model with a single variable.""""""\n\n    with tempfile.TemporaryDirectory() as temp_dir:\n      sm_dir = os.path.join(temp_dir, ""simple.sm"")\n      print(""Saving to:"", sm_dir)\n\n      with tf.Graph().as_default() as graph:\n        v = tf.Variable(10)\n        result = v.read_value()\n        tensor_info = tf.compat.v1.saved_model.utils.build_tensor_info(result)\n        sig = tf.compat.v1.saved_model.signature_def_utils.build_signature_def(\n            inputs={}, outputs={""result"": tensor_info}, method_name=""foo"")\n        builder = tf.compat.v1.saved_model.Builder(sm_dir)\n        with tf.compat.v1.Session(graph=graph) as sess:\n          sess.run(v.initializer)\n          builder.add_meta_graph_and_variables(\n              sess, [""bar""], {""baz"": sig}, strip_default_attrs=True)\n          builder.save()\n\n      module = compiler.tf_load_signature_def_saved_model(\n          sm_dir, tags=set([""bar""]), exported_names=[""baz""])\n\n      module_asm = module.to_asm(large_element_limit=100)\n      self.assertRegexpMatches(module_asm, ""flow.variable @[^ ]* dense<10>"")\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
integrations/tensorflow/bindings/python/pyiree/tf/support/__init__.py,0,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
integrations/tensorflow/bindings/python/pyiree/tf/support/tf_test_driver.py,3,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for running tests from TensorFlow models.""""""\n\nimport contextlib\nimport io\nimport os\nimport subprocess\nimport sys\nimport tempfile\nimport traceback\n\nfrom absl import app\nfrom absl import flags\nfrom pyiree.tf import compiler\nimport tensorflow.compat.v2 as tf\n\nflags.DEFINE_string(""filecheck_binary"", ""filecheck"",\n                    ""Location of the filecheck binary."")\nflags.DEFINE_bool(""disable_filecheck"", False,\n                  ""Disables filecheck redirection (for debugging)."")\nFLAGS = flags.FLAGS\n\nALL_TEST_DICTS = []\n\n\ndef add_test(**kwargs):\n  assert ""test_name"" in kwargs, ""\'test_name\' is a required argument""\n  ALL_TEST_DICTS.append(kwargs)\n\n\ndef _run_test(test_dict):\n  """"""Runs an individual test dict.""""""\n  tf_module_builder_lambda = test_dict[""tf_module_builder""]\n  tf_module = tf_module_builder_lambda()\n  ctx = compiler.Context()\n  with tempfile.TemporaryDirectory() as sm_path:\n    options = tf.saved_model.SaveOptions(save_debug_info=True)\n    tf.saved_model.save(tf_module, sm_path, options=options)\n    input_module = compiler.tf_load_saved_model(sm_path, ctx, pass_pipeline=())\n\n  passes = test_dict.get(""passes"")\n  expect_pass_failure = test_dict.get(""expect_pass_failure"")\n  if passes:\n    try:\n      input_module.run_pass_pipeline(passes)\n    except:  # pylint: disable=bare-except\n      if not expect_pass_failure:\n        print(\n            ""UNEXPECTED PASS FAILURE (INTERMEDIATE ASM FOLLOWS ON STDERR):"",\n            file=sys.stderr)\n        print(input_module.to_asm(), file=sys.stderr)\n      raise\n\n  # Print the input module ASM.\n  if test_dict.get(""print_input_module""):\n    print(input_module.to_asm())\n\n\ndef _internal_run_tests():\n  """"""Main function that runs all tests.""""""\n  test_count = 0\n  for test_dict in ALL_TEST_DICTS:\n    test_count += 1\n    test_name = test_dict[""test_name""]\n    print(""RUN_TEST:"", test_name)\n    try:\n      _run_test(test_dict)\n      print(""FINISH_TEST:"", test_name)\n    except:  # pylint: disable=bare-except\n      # Error goes to stdout for FileCheck.\n      traceback.print_exc(file=sys.stdout)\n      print(""FINISH_TEST_WITH_EXCEPTION:"", test_name)\n\n  print(""FINISHED: RAN"", test_count, ""TESTS"", file=sys.stderr)\n\n\ndef _find_filecheck():\n  """"""Finds the filecheck binary.""""""\n  filecheck_binary = FLAGS.filecheck_binary\n  if os.path.isabs(filecheck_binary):\n    return filecheck_binary\n  # TODO(laurenzo): Why is this runfiles resolution so hard and undocumented.\n  # Talk to bazel team.\n  runfiles_dir = os.environ.get(""RUNFILES_DIR"")\n  if runfiles_dir:\n    workspace_name = os.environ.get(""TEST_WORKSPACE"")\n    if workspace_name:\n      runfiles_dir = os.path.join(runfiles_dir, workspace_name)\n    filecheck_binary = os.path.join(runfiles_dir, filecheck_binary)\n  # Convert forward slash version to platform default (Windows).\n  filecheck_binary = filecheck_binary.replace(""/"", os.path.sep)\n  return filecheck_binary\n\n\ndef run_tests(main_file, with_filecheck=True):\n  """"""Main entry point.""""""\n\n  def internal_main(unused_argv):\n    """"""App main.""""""\n    # In case if running with a version prior to v2 defaulting.\n    tf.enable_v2_behavior()\n    if with_filecheck and not FLAGS.disable_filecheck:\n      # Capture and run through filecheck.\n      filecheck_capture_io = io.StringIO()\n      with contextlib.redirect_stdout(filecheck_capture_io):\n        _internal_run_tests()\n      filecheck_capture_io.flush()\n      filecheck_input = filecheck_capture_io.getvalue()\n      # Convert forward slash version to platform default (Windows).\n      filecheck_binary = _find_filecheck()\n      filecheck_args = [filecheck_binary, main_file, ""--dump-input=fail""]\n      print(""LAUNCHING FILECHECK:"", filecheck_args, file=sys.stderr)\n      p = subprocess.Popen(filecheck_args, stdin=subprocess.PIPE)\n      p.communicate(filecheck_input.encode(""UTF-8""))\n      sys.exit(p.returncode)\n    else:\n      # Just run directly.\n      _internal_run_tests()\n\n  app.run(internal_main)\n'"
integrations/tensorflow/bindings/python/pyiree/tf/support/tf_test_utils.py,11,"b'# Lint as: python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test utilities interop with TensorFlow.""""""\n\n# pylint: disable=not-callable\n# pylint: disable=invalid-name\n# pylint: disable=missing-docstring\n# pylint: disable=protected-access\n\nimport collections\nimport os\nimport re\nimport tempfile\n\nfrom absl import flags\nfrom absl import logging\nimport numpy as np\nfrom pyiree import rt\nfrom pyiree.tf import compiler\nimport random\nimport tensorflow.compat.v2 as tf\n\nflags.DEFINE_string(\n    ""override_backends"", None,\n    ""Explicit comma-delimited list of target backends. ""\n    ""(Overrides environment variables and auto detection)"")\nflags.DEFINE_string(\n    ""debug_dir"", None,\n    ""Specifies a directory to dump debug artifacts to. Defaults to ""\n    ""--test_tmpdir"")\nFLAGS = flags.FLAGS\n\nORIGINAL_SAVED_MODEL_PATH_ATTR = ""_ORIGINAL_SAVED_MODEL_PATH""\n\n# Per test directory where debug artifacts are dumped.\nglobal_debug_dir = None\n\n\ndef set_random_seed(seed=0):\n  """"""Set random seed for tf, np and random.""""""\n  tf.random.set_seed(seed)\n  random.seed(seed)\n  np.random.seed(seed)\n\n\ndef save_and_compile_tf_module(tf_module, exported_names=(),\n                               target_backends=()):\n  """"""Saves and compiles a TensorFlow tf.Module.\n\n  Note that if the module has the special _ORIGINAL_SAVED_MODEL_PATH attribute,\n  then it will be compiled directly from that path instead of saved and then\n  loaded.\n\n  Args:\n    tf_module: A tf.Module.\n    exported_names: Iterable of dotted function names to consider for\n      compilation.\n    target_backends: Iterable of string backend names to compile for.\n\n  Returns:\n    An _IreeCompiledModule.\n  """"""\n\n  def compile_from_path(sm_path):\n    compiler_context = compiler.Context()\n    # Break up the compilation so we can save debug artifacts.\n    compiler_module = compiler.tf_load_saved_model(\n        sm_path,\n        exported_names=exported_names,\n        compiler_context=compiler_context,\n        pass_pipeline=())\n\n    # Save the input MLIR module.\n    flattened_target_backends = re.sub(""[^0-9a-zA-Z]+"", ""_"",\n                                       ""__"".join(target_backends))\n    if global_debug_dir:\n      mlir_path = os.path.join(global_debug_dir,\n                               ""raw_%s.mlir"" % flattened_target_backends)\n      logging.info(""Saving raw TF input MLIR to: %s"", mlir_path)\n      with open(mlir_path, ""w"") as f:\n        f.write(compiler_module.to_asm())\n\n    # Now run the passes manually that tf_load_saved_model would usually do.\n    compiler_module.run_pass_pipeline(compiler.TF_IMPORT_PASS_PIPELINE)\n\n    if global_debug_dir:\n      mlir_path = os.path.join(global_debug_dir,\n                               ""input_%s.mlir"" % flattened_target_backends)\n      logging.info(""Saving IREE input MLIR to: %s"", mlir_path)\n      with open(mlir_path, ""w"") as f:\n        f.write(compiler_module.to_asm())\n\n    compiled_module = compiler_module.compile(target_backends=target_backends)\n    if global_debug_dir:\n      compiled_path = os.path.join(\n          global_debug_dir, ""compiled_%s.vmfb"" % flattened_target_backends)\n      logging.info(""Saving compiled IREE module to: %s"", compiled_path)\n      with open(compiled_path, ""wb"") as f:\n        f.write(compiled_module)\n\n    return compiled_module\n\n  if hasattr(tf_module, ORIGINAL_SAVED_MODEL_PATH_ATTR):\n    # Compile directly from the original path.\n    sm_path = getattr(tf_module, ORIGINAL_SAVED_MODEL_PATH_ATTR)\n    logging.info(\n        ""Compiling from original saved_model path (not round-tripping): %s"",\n        sm_path)\n    return compile_from_path(sm_path)\n  else:\n    options = tf.saved_model.SaveOptions(save_debug_info=True)\n    if FLAGS.debug_dir is None:\n      # Round-trip through a temporary directory.\n      with tempfile.TemporaryDirectory() as sm_path:\n        tf.saved_model.save(tf_module, sm_path, options=options)\n        return compile_from_path(sm_path)\n    else:\n      # Use the supplied directory.\n      sm_path = os.path.join(FLAGS.debug_dir, ""SavedModel"")\n      tf.saved_model.save(tf_module, sm_path, options=options)\n      return compile_from_path(sm_path)\n\n\ndef load_tf_module(path):\n  """"""Wrapper around tf.saved_model.load which preserves the path.\n\n  Args:\n    path: The path to load from.\n\n  Returns:\n    The loaded module with an extra property _ORIGINAL_SAVED_MODEL_PATH added.\n    This is used on subsequent compiles to load directly from the original\n    path, which gives us unmolested access to the original debug information,\n    which TensorFlow tends to lose on round-trip.\n  """"""\n  tf_module = tf.saved_model.load(path)\n  assert not hasattr(tf_module, ORIGINAL_SAVED_MODEL_PATH_ATTR), (\n      ""Saved model (%s) already has attribute %s"" %\n      (path, ORIGINAL_SAVED_MODEL_PATH_ATTR))\n  setattr(tf_module, ORIGINAL_SAVED_MODEL_PATH_ATTR, path)\n  return tf_module\n\n\nclass CompiledModule(object):\n  """"""Base class for per-backend compiled module facade.""""""\n\n  def __init__(self, ctor, exported_names, backend):\n    self._ctor = ctor\n    self._exported_names = exported_names\n    self._backend = backend\n\n  @staticmethod\n  def create(ctor, exported_names, backend):\n    compiled_module_class = backend.CompiledModule\n    return compiled_module_class(ctor, exported_names, backend)\n\n  @property\n  def ctor(self):\n    return self._ctor\n\n  def instantiate(self):\n    raise NotImplementedError()\n\n\nclass TfCompiledModule(CompiledModule):\n  """"""TensorFlow \'compiled\' module.\n\n  This just wraps the constructor.\n  """"""\n\n  def instantiate(self):\n    tf_module = self.ctor()\n    return _TfModuleInstance(tf_module)\n\n\nclass _TfModuleInstance(object):\n  """"""Instance of a TF module.""""""\n\n  def __init__(self, tf_module):\n    self._tf_module = tf_module\n\n  def __getattr__(self, attr):\n    # Try to resolve it as a function.\n    if not hasattr(self._tf_module, attr):\n      raise AttributeError(""The TensorFlow module does not have attr \'%s\'"" %\n                           (attr,))\n    f = getattr(self._tf_module, attr)\n    if not f or not hasattr(f, ""__call__""):\n      raise AttributeError(\n          ""The TensorFlow module does not have a callable attr \'%s\'"" % (attr,))\n    return _TfFunctionWrapper(f)\n\n\nclass _TfFunctionWrapper(object):\n  """"""Wraps a TF function, normalizing it to numpy.""""""\n\n  def __init__(self, f):\n    self._f = f\n\n  def __call__(self, *args, **kwargs):\n    # TensorFlow will auto-convert all inbound args.\n    results = self._f(*args, **kwargs)\n    # Then unmarshal them to numpy in the same way that the other backends do.\n    # Handle single result (technically ambiguous with return of a tuple,\n    # which is sad).\n    if not isinstance(results, tuple):\n      results = (results,)\n    return tf.nest.map_structure(\n        lambda t: t.numpy() if isinstance(t, tf.Tensor) else t,\n        *results,\n        check_types=False)\n\n\nclass IreeCompiledModule(CompiledModule):\n  """"""Iree compiled module.""""""\n\n  def __init__(self, ctor, exported_names, backend):\n    super().__init__(ctor, exported_names, backend)\n    self._iree_module_blob = save_and_compile_tf_module(\n        ctor(),\n        exported_names=exported_names,\n        target_backends=backend.iree_compiler_targets)\n    self._iree_module = rt.VmModule.from_flatbuffer(self._iree_module_blob)\n\n  def instantiate(self):\n    return _IreeModuleInstance(self._backend, self._iree_module_blob,\n                               self._iree_module)\n\n\nclass _IreeModuleInstance(object):\n  """"""An instance of an IREE module.""""""\n\n  def __init__(self, backend, iree_module_blob, iree_module):\n    self._backend = backend\n    self._iree_module_blob = iree_module_blob\n    self._iree_module = iree_module\n    self._iree_module_name = self._iree_module.name\n\n    self._system_config = rt.Config(driver_name=backend.iree_driver)\n    self._context = rt.SystemContext(\n        modules=[self._iree_module], config=self._system_config)\n\n  def __getattr__(self, attr):\n    # Try to resolve it as a function.\n    m = self._context.modules[self._iree_module_name]\n    f = m[attr]\n    return _IreeFunctionWrapper(self._context, f)\n\n\nclass _IreeFunctionWrapper(object):\n  """"""Wraps an IREE function, making it callable.""""""\n\n  def __init__(self, context, f):\n    self._context = context\n    self._f = f\n\n  def __call__(self, *args):\n    return self._f(*args)\n\n\nclass _VirtualModuleInstance(object):\n  """"""Wraps a namedtuple of modules and represents a union of them.""""""\n\n  def __init__(self, named_modules, match_spec):\n    self._named_modules = named_modules\n    self._match_spec = match_spec\n\n  def __getattr__(self, attr):\n    match_modules = {\n        k: v\n        for k, v in self._named_modules.items()\n        if re.search(self._match_spec, k)\n    }\n    if not match_modules:\n      raise AttributeError(\n          ""Module match spec \'%s\' did not match anything. (Have %r)"" %\n          (self._match_spec, self._named_modules.keys()))\n    # Resolve functions on each.\n    match_functions = {}\n    for backend, module in match_modules.items():\n      try:\n        match_functions[backend] = getattr(module, attr)\n      except:\n        raise AttributeError(\n            ""Could not resolve function \'%s\' on backend module \'%s\'"" %\n            (attr, backend))\n    return _VirtualFunctionWrapper(match_functions)\n\n\nclass _VirtualFunctionWrapper(object):\n  """"""Wrapper around a virtual dict of functions.""""""\n\n  def __init__(self, backend_function_dict):\n    self._backend_function_dict = backend_function_dict\n\n  def __call__(self, *args, **kwargs):\n    all_results = {\n        backend: f(*args, **kwargs)\n        for backend, f in self._backend_function_dict.items()\n    }\n    # Turn it into a named tuple so we get nice class-like access to it.\n    results_tuple_class = collections.namedtuple(""Results"", all_results.keys())\n    return _make_multi_result_class(results_tuple_class)(*all_results.values())\n\n\ndef _collect_disagreements(mr, predicate):\n  """"""Verifies that result structs.\n\n  Args:\n    mr: A MultiResults namedtuple where each entry corresponds to a backend set\n      of results.\n    predicate: A predicate function which takes (a, b) and returns whether they\n      should be considered equivalent.\n\n  Returns:\n    An equivalent MultiResults where each entry is an array of result names\n    that disagree.\n  """"""\n  has_disagreement = False\n  disagreement_list = [list() for _ in mr]\n  for i in range(len(mr)):\n    result_ref = mr[i]\n    for j in range(len(mr)):\n      if i == j:\n        continue  # Don\'t check self.\n      result_tgt = mr[j]\n      if not predicate(result_ref, result_tgt):\n        has_disagreement = True\n        disagreement_list[i].append(mr._fields[j])\n  disagreements_tuple = collections.namedtuple(""Disagreements"", mr._fields)\n  return has_disagreement, disagreements_tuple(*disagreement_list)\n\n\ndef _make_multi_result_class(named_tuple_class):\n  """"""Makes a class that wraps a mapping of backend results.""""""\n\n  class MultiResults(named_tuple_class):\n    """"""Wraps a mapping of results.""""""\n\n    def assert_all_close(self, rtol=1e-6, atol=1e-6):\n      predicate = (lambda a, b: np.allclose(a, b, rtol=rtol, atol=atol))\n      has_disagreement, disagreements = _collect_disagreements(self, predicate)\n      assert not has_disagreement, (""Multiple backends disagree (%r):\\n%r"" %\n                                    (disagreements, self))\n      return self\n\n    def assert_all_equal(self):\n      predicate = np.array_equal\n      has_disagreement, disagreements = _collect_disagreements(self, predicate)\n      assert not has_disagreement, (""Multiple backends disagree (%r):\\n%r"" %\n                                    (disagreements, self))\n      return self\n\n    def print(self):\n      print(self)\n      return self\n\n  return MultiResults\n\n\ndef _instantiate_modules(compiled_modules_dict):\n  """"""Given a dict of modules, instantiates them.\n\n  Args:\n    compiled_modules_dict: Dictionary of\n        {module_name:{backend_name:CompiledModule}} that should be instantiated.\n\n  Returns:\n    namedtuple mapping module_key:VirtualBackendsClass for every module\n    in compiled_modules_dict. The VirtualBackendsClass is a dynamically\n    generated namedtuple mapping backend_name:ModuleInstance, where the\n    ModuleInstance allows attribute resolution of public functions on the\n    module. The VirtualBackendsClass also contributes some convenience\n    methods for selecting all or a subset of matching backend modules.\n  """"""\n\n  def instantiate_backends(module_dict):\n    """"""Creates a VirtualBackend namedtuple class for a dict.\n\n    Args:\n      module_dict: Dictionary of backend_name:ModuleInstance.\n\n    Returns:\n      namedtuple subclass with a field for every backend and special\n      all and multi() helpers.\n    """"""\n    tuple_class = collections.namedtuple(""VirtualBackendsTuple"",\n                                         module_dict.keys())\n\n    class VirtualBackendsClass(tuple_class):\n      """"""Adds a __call__ method that creates a virtual module.""""""\n\n      def multi(self, match_spec="".""):\n        """"""Selects multiple backends that match a regular expression.""""""\n        return _VirtualModuleInstance(self._asdict(), match_spec)\n\n      @property\n      def all(self):\n        """"""Shorthand for multi() which selects all backends.""""""\n        return self.multi()\n\n    return VirtualBackendsClass(\n        *[m.instantiate() for m in module_dict.values()])\n\n  module_keys = [k for (k, _) in compiled_modules_dict.items()]\n  module_insts = [\n      instantiate_backends(module_dict)\n      for (_, module_dict) in compiled_modules_dict.items()\n  ]\n  tuple_class = collections.namedtuple(""Modules"", module_keys)\n  return tuple_class(*module_insts)\n\n\ndef compile_modules(backends=None, **kwargs):\n  """"""Decorator applied to a SavedModelTestCase subclass to compile modules.\n\n  Args:\n    backends: an iterable of backend names to include (or None to use\n      environment defaults).\n    **kwargs: name/Module constructor mappings. Each such arg will be added to\n      the classes \'compiled_modules\' field.\n\n  Returns:\n    Class decorator function.\n  """"""\n\n  def decorator(cls):\n    """"""Decorator function.""""""\n    assert issubclass(cls, SavedModelTestCase), (\n        ""The \'compile_modules\' decorator must be applied to a ""\n        ""SavedModelTestCase derived class."")\n    if not cls._modules_to_compile:\n      cls._modules_to_compile = {}\n    for name, ctor in kwargs.items():\n      assert name not in cls._modules_to_compile, (\n          ""@compile_modules called with duplicate module names \'%s\'"" % (name,))\n      exported_names = ()\n      if isinstance(ctor, tuple):\n        ctor, exported_names = ctor\n      cls._modules_to_compile[name] = (ctor, exported_names, backends)\n\n    return cls\n\n  return decorator\n\n\nclass BackendInfo(\n    collections.namedtuple(\n        ""BackendInfo"",\n        [""name"", ""CompiledModule"", ""iree_driver"", ""iree_compiler_targets""])):\n  """"""Info object describing a backend.""""""\n\n  # All BackendInfo entries by name.\n  ALL = {}\n\n  @classmethod\n  def add(cls, **kwargs):\n    backend_info = cls(**kwargs)\n    cls.ALL[backend_info.name] = backend_info\n\n\nBackendInfo.add(\n    name=""tf"",\n    CompiledModule=TfCompiledModule,\n    iree_driver=None,\n    iree_compiler_targets=None)\n# tf_also is used for checking test consistency\n# to catch any initialization/randomization issues between model runs\nBackendInfo.add(\n    name=""tf_also"",\n    CompiledModule=TfCompiledModule,\n    iree_driver=None,\n    iree_compiler_targets=None)\nBackendInfo.add(\n    name=""iree_vmla"",\n    CompiledModule=IreeCompiledModule,\n    iree_driver=""vmla"",\n    iree_compiler_targets=[""vmla""])\nBackendInfo.add(\n    name=""iree_vulkan"",\n    CompiledModule=IreeCompiledModule,\n    iree_driver=""vulkan"",\n    iree_compiler_targets=[""vulkan-*""])\nBackendInfo.add(\n    name=""iree_llvmjit"",\n    CompiledModule=IreeCompiledModule,\n    iree_driver=""llvm"",\n    iree_compiler_targets=[""llvm-ir""])\n\n\ndef _backend_spec_string_to_backends(backend_spec):\n  """"""Decodes a comma-delimited string of backends into BackendInfo objects.""""""\n  backends = []\n  for backend_name in backend_spec.split("",""):\n    if backend_name not in BackendInfo.ALL.keys():\n      raise ValueError(\n          ""Invalid backend specification string \'{}\', unexpected name \'{}\';""\n          "" valid names are \'{}\'"".format(backend_spec, backend_name,\n                                         BackendInfo.ALL.keys()))\n    backends.append(BackendInfo.ALL[backend_name])\n  return backends\n\n\ndef get_override_backends():\n  """"""Gets the BackendInfo instances to test, as overridden by the user.\n\n  Returns:\n    Sequence of BackendInfo that should be used, or None if there is no\n    override.\n  """"""\n\n  if FLAGS.override_backends is not None:\n    backends_spec = FLAGS.override_backends\n    logging.info(""Using backends from command line: %s"", backends_spec)\n  else:\n    backends_spec = os.environ.get(""IREE_OVERRIDE_BACKENDS"")\n    if backends_spec is not None:\n      logging.info(""Using backends from environment IREE_OVERRIDE_BACKENDS: %s"",\n                   backends_spec)\n\n  if backends_spec:\n    return _backend_spec_string_to_backends(backends_spec)\n  else:\n    logging.info(""No backend overrides."")\n    return None\n\n\ndef get_available_backends():\n  """"""Gets the BackendInfo instances considered available for use.""""""\n  backend_spec = os.environ.get(""IREE_AVAILABLE_BACKENDS"")\n  if backend_spec is None:\n    return BackendInfo.ALL.values()\n  return _backend_spec_string_to_backends(backend_spec)\n\n\nclass SavedModelTestCase(tf.test.TestCase):\n  """"""Tests against a SavedModel.""""""\n\n  # Will be initialized to a dict by the @compile_modules decorator.\n  # The dict maps module name to (ctor, exported_names, backend_names).\n  _modules_to_compile = None\n\n  # Will be initialized in setUpClass to a dict of (name, CompiledModule)\n  # instances mirroring _modules_to_compile.\n  compiled_modules = None\n\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.modules = None\n\n  @classmethod\n  def setUpClass(cls):\n    super().setUpClass()\n    cls.compiled_modules = {}\n    if cls._modules_to_compile:\n      for name, (ctor, exported_names,\n                 backends) in cls._modules_to_compile.items():\n\n        # Setup the debug directory.\n        debug_parent_dir = FLAGS.debug_dir\n        if not debug_parent_dir:\n          debug_parent_dir = FLAGS.test_tmpdir\n        debug_parent_dir = os.path.join(debug_parent_dir, cls.__name__)\n\n        try:\n          os.makedirs(debug_parent_dir)\n        except IOError:\n          logging.exception(""Error creating crash reproducer dir for: %s"",\n                            debug_parent_dir)\n\n        # Setup crash reproducer and global debug dir.\n        crash_reproducer_path = os.path.join(debug_parent_dir,\n                                             name + ""_reproducer.mlir"")\n        compiler.Context.default_crash_reproducer_path = crash_reproducer_path\n        global global_debug_dir\n        global_debug_dir = debug_parent_dir\n\n        try:\n          # Compile.\n          # Expand backend names to BackendInfo objects.\n          def _resolve(backend_spec):\n            if isinstance(backend_spec, BackendInfo):\n              return backend_spec\n            # Handle the string form.\n            return BackendInfo.ALL[backend_spec]\n\n          override_backends = get_override_backends()\n          if override_backends is not None:\n            backends = override_backends\n          elif backends is None:\n            backends = list(BackendInfo.ALL.keys())\n          backends = [_resolve(backend) for backend in backends]\n          # if ""tf"" is specified as a only backend then\n          # we will test it always against ""tf"" by adding ""tf_also"".\n          if len(backends) == 1 and ""tf"" == backends[0].name:\n            backends.append(BackendInfo.ALL[""tf_also""])\n          available_backends = get_available_backends()\n          backends = [\n              backend for backend in backends if backend in available_backends\n          ]\n          if not backends:\n            # If no backends are available, then to avoid errors down the line,\n            # just use ""tf"", which should always be safe.\n            backends = [BackendInfo.ALL[""tf""]]\n            logging.warning(\n                ""Falling back to just `tf` backend because no other requested backends are available. Available backends \'%s\'"",\n                [backend.name for backend in available_backends])\n          cls.compiled_modules[name] = dict([\n              (backend.name, CompiledModule.create(ctor, exported_names,\n                                                   backend))\n              for backend in backends\n          ])\n        finally:\n          # Disable crash reproducer (to avoid inadvertently overwriting this\n          # path on a subsequent interaction).\n          compiler.Context.default_crash_reproducer_path = None\n          global_debug_dir = None\n\n  @classmethod\n  def tearDownClass(cls):\n    super().tearDownClass()\n\n  def setUp(self):\n    super().setUp()\n    self.modules = _instantiate_modules(self.compiled_modules)\n'"
integrations/tensorflow/bindings/python/pyiree/xla/compiler/__init__.py,0,"b'# Lint-as: python3\n""""""Module init for the python bindings.""""""\n\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=g-multiple-import\n# pylint: disable=g-bad-import-order\n# pylint: disable=g-import-not-at-top\n# pylint: disable=wildcard-import\n\n__all__ = [\n    # Common\n    ""Context"",\n    ""Module"",\n    ""CompileOptions"",\n    ""OutputFormat"",\n    # XLA\n    ""XLA_IMPORT_PASS_PIPELINE"",\n    ""xla_load_module_proto"",\n    ""xla_compile_module_proto"",\n]\n\nfrom typing import Collection, Optional, Sequence\n\nfrom . import binding\n\n# Native aliases (matches those in the generic compiler).\nllvm = binding.llvm\nContext = binding.CompilerContext\nModule = binding.CompilerModule\nCompileOptions = binding.CompileOptions\nOutputFormat = binding.OutputFormat\n\n# Pass pipeline that should run to lower a XLA-HLO module to a form suitable\n# for input to the IREE compiler.\nXLA_IMPORT_PASS_PIPELINE = (\n    # Legalize to XLA\n    ""canonicalize"",)\n\n\n# TODO(suderman): Update PyType to check the xla_computation is an XLA builder.\ndef xla_load_module_proto(\n    xla_computation,\n    compiler_context: Optional[Context] = None,\n    exported_names: Collection[str] = (),\n    pass_pipeline: Sequence[str] = XLA_IMPORT_PASS_PIPELINE) -> Module:\n  """"""Loads a XLA saved model from its persistent representation.\n\n  See also xla_compile_module_proto() for a one-shot API to load and compile.\n\n  Args:\n    xla_computation: XLA Computation generate from XLA Python client\n    compiler_context: The pyiree.compiler.Context() backing the module.\n    exported_names: Optional tuple of strings representing the exported names to\n      keep.\n    pass_pipeline: Passes to run on the imported module prior to returning.\n      Defaults to XLA_IMPORT_PASS_PIPELINE.\n\n  Returns:\n    An MLIR Module suitable for compilation by the IREE compiler.\n    This can be further compiled to an IREE blob by calling\n    .compile_to_sequencer_blob.\n  """"""\n  if not compiler_context:\n    compiler_context = Context()\n  input_module = binding.load_xla_module_proto(\n      compiler_context, xla_computation, exported_names=exported_names)\n  if pass_pipeline:\n    input_module.run_pass_pipeline(pass_pipeline)\n  return input_module\n\n\ndef xla_compile_module_proto(\n    xla_computation,\n    compiler_context: Optional[Context] = None,\n    exported_names: Collection[str] = (),\n    pass_pipeline: Sequence[str] = XLA_IMPORT_PASS_PIPELINE,\n    target_backends: Collection[str] = ()\n) -> binding.OpaqueBlob:\n  """"""Loads and compiles a XLA saved model in one shot.\n\n  Args:\n    xla_computation: XLA Computation generate from XLA Python client\n    compiler_context: The pyiree.compiler.Context() backing the module.\n    exported_names: Optional tuple of strings representing the exported names to\n      keep.\n    pass_pipeline: Passes to run on the imported module prior to returning.\n      Defaults to XLA_IMPORT_PASS_PIPELINE.\n    target_backends: The specific target backends to compile for (defaults to\n      all compiled in targets).\n\n  Returns:\n    An OpaqueBlob representing the compiled module.\n  """"""\n  input_module = xla_load_module_proto(xla_computation, compiler_context,\n                                       exported_names, pass_pipeline)\n  return input_module.compile(target_backends=target_backends)\n'"
integrations/tensorflow/bindings/python/pyiree/xla/compiler/xla_module_proto_test.py,0,"b'# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import absltest\nimport numpy as np\nfrom pyiree.xla import compiler\n\n# pylint: disable=g-direct-tensorflow-import\nimport tensorflow.compiler.xla.python.xla_client as xla_client\n# pylint: enable=g-direct-tensorflow-import\n\nops = xla_client.ops\n\n\nclass RuntimeTest(absltest.TestCase):\n\n  def testXLA(self):\n    """"""Tests that a basic saved model to XLA workflow grossly functions.\n\n    This is largely here to verify that everything is linked in that needs to be\n    and that there are not no-ops, etc.\n    """"""\n    # Generate a sample XLA computation.\n    builder = xla_client.XlaBuilder(""testbuilder"")\n    in_shape = np.array([4], dtype=np.float32)\n    in_feed = ops.Parameter(builder, 0, xla_client.shape_from_pyval(in_shape))\n    result = ops.Add(in_feed, ops.Constant(builder, np.float32(1.0)))\n    xla_computation = builder.Build(result)\n\n    # Load into XLA Module.\n    module = compiler.xla_load_module_proto(xla_computation)\n\n    # Validate imported ASM.\n    xla_asm = module.to_asm()\n    print(""XLA ASM: "", xla_asm)\n    self.assertRegex(xla_asm, ""xla_hlo.add"")\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
