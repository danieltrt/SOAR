file_path,api_count,code
setup.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nPython package setup file.\n""""""\n\nfrom setuptools import setup\n\nsetup(\n    name=""seq2seq"",\n    version=""0.1"",\n    install_requires=[\n        ""numpy"",\n        ""matplotlib"",\n        ""pyyaml"",\n        ""pyrouge""\n    ],\n    extras_require={\'tensorflow\': [\'tensorflow\'],\n                    \'tensorflow with gpu\': [\'tensorflow-gpu\']},\n)\n'"
bin/__init__.py,0,b''
bin/infer.py,18,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"""""" Generates model predictions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom pydoc import locate\n\nimport yaml\nfrom six import string_types\n\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq import tasks, models\nfrom seq2seq.configurable import _maybe_load_yaml, _deep_merge_dict\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.inference import create_inference_graph\nfrom seq2seq.training import utils as training_utils\n\ntf.flags.DEFINE_string(""tasks"", ""{}"", ""List of inference tasks to run."")\ntf.flags.DEFINE_string(""model_params"", ""{}"", """"""Optionally overwrite model\n                        parameters for inference"""""")\n\ntf.flags.DEFINE_string(""config_path"", None,\n                       """"""Path to a YAML configuration file defining FLAG\n                       values and hyperparameters. Refer to the documentation\n                       for more details."""""")\n\ntf.flags.DEFINE_string(""input_pipeline"", None,\n                       """"""Defines how input data should be loaded.\n                       A YAML string."""""")\n\ntf.flags.DEFINE_string(""model_dir"", None, ""directory to load model from"")\ntf.flags.DEFINE_string(""checkpoint_path"", None,\n                       """"""Full path to the checkpoint to be loaded. If None,\n                       the latest checkpoint in the model dir is used."""""")\ntf.flags.DEFINE_integer(""batch_size"", 32, ""the train/dev batch size"")\n\nFLAGS = tf.flags.FLAGS\n\ndef main(_argv):\n  """"""Program entry point.\n  """"""\n\n  # Load flags from config file\n  if FLAGS.config_path:\n    with gfile.GFile(FLAGS.config_path) as config_file:\n      config_flags = yaml.load(config_file)\n      for flag_key, flag_value in config_flags.items():\n        setattr(FLAGS, flag_key, flag_value)\n\n  if isinstance(FLAGS.tasks, string_types):\n    FLAGS.tasks = _maybe_load_yaml(FLAGS.tasks)\n\n  if isinstance(FLAGS.input_pipeline, string_types):\n    FLAGS.input_pipeline = _maybe_load_yaml(FLAGS.input_pipeline)\n\n  input_pipeline_infer = input_pipeline.make_input_pipeline_from_def(\n      FLAGS.input_pipeline, mode=tf.contrib.learn.ModeKeys.INFER,\n      shuffle=False, num_epochs=1)\n\n  # Load saved training options\n  train_options = training_utils.TrainOptions.load(FLAGS.model_dir)\n\n  # Create the model\n  model_cls = locate(train_options.model_class) or \\\n    getattr(models, train_options.model_class)\n  model_params = train_options.model_params\n  model_params = _deep_merge_dict(\n      model_params, _maybe_load_yaml(FLAGS.model_params))\n  model = model_cls(\n      params=model_params,\n      mode=tf.contrib.learn.ModeKeys.INFER)\n\n  # Load inference tasks\n  hooks = []\n  for tdict in FLAGS.tasks:\n    if not ""params"" in tdict:\n      tdict[""params""] = {}\n    task_cls = locate(tdict[""class""]) or getattr(tasks, tdict[""class""])\n    task = task_cls(tdict[""params""])\n    hooks.append(task)\n\n  # Create the graph used for inference\n  predictions, _, _ = create_inference_graph(\n      model=model,\n      input_pipeline=input_pipeline_infer,\n      batch_size=FLAGS.batch_size)\n\n  saver = tf.train.Saver()\n  checkpoint_path = FLAGS.checkpoint_path\n  if not checkpoint_path:\n    checkpoint_path = tf.train.latest_checkpoint(FLAGS.model_dir)\n\n  def session_init_op(_scaffold, sess):\n    saver.restore(sess, checkpoint_path)\n    tf.logging.info(""Restored model from %s"", checkpoint_path)\n\n  scaffold = tf.train.Scaffold(init_fn=session_init_op)\n  session_creator = tf.train.ChiefSessionCreator(scaffold=scaffold)\n  with tf.train.MonitoredSession(\n      session_creator=session_creator,\n      hooks=hooks) as sess:\n\n    # Run until the inputs are exhausted\n    while not sess.should_stop():\n      sess.run([])\n\nif __name__ == ""__main__"":\n  tf.logging.set_verbosity(tf.logging.INFO)\n  tf.app.run()\n'"
bin/train.py,31,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Main script to run training and evaluation of models.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport tempfile\n\nimport yaml\n\nimport tensorflow as tf\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.contrib.learn.python.learn.estimators import run_config\nfrom tensorflow import gfile\n\nfrom seq2seq import models\nfrom seq2seq.contrib.experiment import Experiment as PatchedExperiment\nfrom seq2seq.configurable import _maybe_load_yaml, _create_from_dict\nfrom seq2seq.configurable import _deep_merge_dict\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.metrics import metric_specs\nfrom seq2seq.training import hooks\nfrom seq2seq.training import utils as training_utils\n\ntf.flags.DEFINE_string(""config_paths"", """",\n                       """"""Path to a YAML configuration files defining FLAG\n                       values. Multiple files can be separated by commas.\n                       Files are merged recursively. Setting a key in these\n                       files is equivalent to setting the FLAG value with\n                       the same name."""""")\ntf.flags.DEFINE_string(""hooks"", ""[]"",\n                       """"""YAML configuration string for the\n                       training hooks to use."""""")\ntf.flags.DEFINE_string(""metrics"", ""[]"",\n                       """"""YAML configuration string for the\n                       training metrics to use."""""")\ntf.flags.DEFINE_string(""model"", """",\n                       """"""Name of the model class.\n                       Can be either a fully-qualified name, or the name\n                       of a class defined in `seq2seq.models`."""""")\ntf.flags.DEFINE_string(""model_params"", ""{}"",\n                       """"""YAML configuration string for the model\n                       parameters."""""")\n\ntf.flags.DEFINE_string(""input_pipeline_train"", ""{}"",\n                       """"""YAML configuration string for the training\n                       data input pipeline."""""")\ntf.flags.DEFINE_string(""input_pipeline_dev"", ""{}"",\n                       """"""YAML configuration string for the development\n                       data input pipeline."""""")\n\ntf.flags.DEFINE_string(""buckets"", None,\n                       """"""Buckets input sequences according to these length.\n                       A comma-separated list of sequence length buckets, e.g.\n                       ""10,20,30"" would result in 4 buckets:\n                       <10, 10-20, 20-30, >30. None disabled bucketing. """""")\ntf.flags.DEFINE_integer(""batch_size"", 16,\n                        """"""Batch size used for training and evaluation."""""")\ntf.flags.DEFINE_string(""output_dir"", None,\n                       """"""The directory to write model checkpoints and summaries\n                       to. If None, a local temporary directory is created."""""")\n\n# Training parameters\ntf.flags.DEFINE_string(""schedule"", ""continuous_train_and_eval"",\n                       """"""Estimator function to call, defaults to\n                       continuous_train_and_eval for local run"""""")\ntf.flags.DEFINE_integer(""train_steps"", None,\n                        """"""Maximum number of training steps to run.\n                         If None, train forever."""""")\ntf.flags.DEFINE_integer(""eval_every_n_steps"", 1000,\n                        ""Run evaluation on validation data every N steps."")\n\n# RunConfig Flags\ntf.flags.DEFINE_integer(""tf_random_seed"", None,\n                        """"""Random seed for TensorFlow initializers. Setting\n                        this value allows consistency between reruns."""""")\ntf.flags.DEFINE_integer(""save_checkpoints_secs"", None,\n                        """"""Save checkpoints every this many seconds.\n                        Can not be specified with save_checkpoints_steps."""""")\ntf.flags.DEFINE_integer(""save_checkpoints_steps"", None,\n                        """"""Save checkpoints every this many steps.\n                        Can not be specified with save_checkpoints_secs."""""")\ntf.flags.DEFINE_integer(""keep_checkpoint_max"", 5,\n                        """"""Maximum number of recent checkpoint files to keep.\n                        As new files are created, older files are deleted.\n                        If None or 0, all checkpoint files are kept."""""")\ntf.flags.DEFINE_integer(""keep_checkpoint_every_n_hours"", 4,\n                        """"""In addition to keeping the most recent checkpoint\n                        files, keep one checkpoint file for every N hours of\n                        training."""""")\ntf.flags.DEFINE_float(""gpu_memory_fraction"", 1.0,\n                      """"""Fraction of GPU memory used by the process on\n                      each GPU uniformly on the same machine."""""")\ntf.flags.DEFINE_boolean(""gpu_allow_growth"", False,\n                        """"""Allow GPU memory allocation to grow\n                        dynamically."""""")\ntf.flags.DEFINE_boolean(""log_device_placement"", False,\n                        """"""Log the op placement to devices"""""")\n\n\nFLAGS = tf.flags.FLAGS\n\ndef create_experiment(output_dir):\n  """"""\n  Creates a new Experiment instance.\n\n  Args:\n    output_dir: Output directory for model checkpoints and summaries.\n  """"""\n\n  config = run_config.RunConfig(\n      tf_random_seed=FLAGS.tf_random_seed,\n      save_checkpoints_secs=FLAGS.save_checkpoints_secs,\n      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n      keep_checkpoint_max=FLAGS.keep_checkpoint_max,\n      keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,\n      gpu_memory_fraction=FLAGS.gpu_memory_fraction)\n  config.tf_config.gpu_options.allow_growth = FLAGS.gpu_allow_growth\n  config.tf_config.log_device_placement = FLAGS.log_device_placement\n\n  train_options = training_utils.TrainOptions(\n      model_class=FLAGS.model,\n      model_params=FLAGS.model_params)\n  # On the main worker, save training options\n  if config.is_chief:\n    gfile.MakeDirs(output_dir)\n    train_options.dump(output_dir)\n\n  bucket_boundaries = None\n  if FLAGS.buckets:\n    bucket_boundaries = list(map(int, FLAGS.buckets.split("","")))\n\n  # Training data input pipeline\n  train_input_pipeline = input_pipeline.make_input_pipeline_from_def(\n      def_dict=FLAGS.input_pipeline_train,\n      mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  # Create training input function\n  train_input_fn = training_utils.create_input_fn(\n      pipeline=train_input_pipeline,\n      batch_size=FLAGS.batch_size,\n      bucket_boundaries=bucket_boundaries,\n      scope=""train_input_fn"")\n\n  # Development data input pipeline\n  dev_input_pipeline = input_pipeline.make_input_pipeline_from_def(\n      def_dict=FLAGS.input_pipeline_dev,\n      mode=tf.contrib.learn.ModeKeys.EVAL,\n      shuffle=False, num_epochs=1)\n\n  # Create eval input function\n  eval_input_fn = training_utils.create_input_fn(\n      pipeline=dev_input_pipeline,\n      batch_size=FLAGS.batch_size,\n      allow_smaller_final_batch=True,\n      scope=""dev_input_fn"")\n\n\n  def model_fn(features, labels, params, mode):\n    """"""Builds the model graph""""""\n    model = _create_from_dict({\n        ""class"": train_options.model_class,\n        ""params"": train_options.model_params\n    }, models, mode=mode)\n    return model(features, labels, params)\n\n  estimator = tf.contrib.learn.Estimator(\n      model_fn=model_fn,\n      model_dir=output_dir,\n      config=config,\n      params=FLAGS.model_params)\n\n  # Create hooks\n  train_hooks = []\n  for dict_ in FLAGS.hooks:\n    hook = _create_from_dict(\n        dict_, hooks,\n        model_dir=estimator.model_dir,\n        run_config=config)\n    train_hooks.append(hook)\n\n  # Create metrics\n  eval_metrics = {}\n  for dict_ in FLAGS.metrics:\n    metric = _create_from_dict(dict_, metric_specs)\n    eval_metrics[metric.name] = metric\n\n  experiment = PatchedExperiment(\n      estimator=estimator,\n      train_input_fn=train_input_fn,\n      eval_input_fn=eval_input_fn,\n      min_eval_frequency=FLAGS.eval_every_n_steps,\n      train_steps=FLAGS.train_steps,\n      eval_steps=None,\n      eval_metrics=eval_metrics,\n      train_monitors=train_hooks)\n\n  return experiment\n\n\ndef main(_argv):\n  """"""The entrypoint for the script""""""\n\n  # Parse YAML FLAGS\n  FLAGS.hooks = _maybe_load_yaml(FLAGS.hooks)\n  FLAGS.metrics = _maybe_load_yaml(FLAGS.metrics)\n  FLAGS.model_params = _maybe_load_yaml(FLAGS.model_params)\n  FLAGS.input_pipeline_train = _maybe_load_yaml(FLAGS.input_pipeline_train)\n  FLAGS.input_pipeline_dev = _maybe_load_yaml(FLAGS.input_pipeline_dev)\n\n  # Load flags from config file\n  final_config = {}\n  if FLAGS.config_paths:\n    for config_path in FLAGS.config_paths.split("",""):\n      config_path = config_path.strip()\n      if not config_path:\n        continue\n      config_path = os.path.abspath(config_path)\n      tf.logging.info(""Loading config from %s"", config_path)\n      with gfile.GFile(config_path.strip()) as config_file:\n        config_flags = yaml.load(config_file)\n        final_config = _deep_merge_dict(final_config, config_flags)\n\n  tf.logging.info(""Final Config:\\n%s"", yaml.dump(final_config))\n\n  # Merge flags with config values\n  for flag_key, flag_value in final_config.items():\n    if hasattr(FLAGS, flag_key) and isinstance(getattr(FLAGS, flag_key), dict):\n      merged_value = _deep_merge_dict(flag_value, getattr(FLAGS, flag_key))\n      setattr(FLAGS, flag_key, merged_value)\n    elif hasattr(FLAGS, flag_key):\n      setattr(FLAGS, flag_key, flag_value)\n    else:\n      tf.logging.warning(""Ignoring config flag: %s"", flag_key)\n\n  if FLAGS.save_checkpoints_secs is None \\\n    and FLAGS.save_checkpoints_steps is None:\n    FLAGS.save_checkpoints_secs = 600\n    tf.logging.info(""Setting save_checkpoints_secs to %d"",\n                    FLAGS.save_checkpoints_secs)\n\n  if not FLAGS.output_dir:\n    FLAGS.output_dir = tempfile.mkdtemp()\n\n  if not FLAGS.input_pipeline_train:\n    raise ValueError(""You must specify input_pipeline_train"")\n\n  if not FLAGS.input_pipeline_dev:\n    raise ValueError(""You must specify input_pipeline_dev"")\n\n  learn_runner.run(\n      experiment_fn=create_experiment,\n      output_dir=FLAGS.output_dir,\n      schedule=FLAGS.schedule)\n\n\nif __name__ == ""__main__"":\n  tf.logging.set_verbosity(tf.logging.INFO)\n  tf.app.run()\n'"
seq2seq/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nseq2seq library base module\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom seq2seq.graph_module import GraphModule\n\nfrom seq2seq import contrib\nfrom seq2seq import data\nfrom seq2seq import decoders\nfrom seq2seq import encoders\nfrom seq2seq import global_vars\nfrom seq2seq import graph_utils\nfrom seq2seq import inference\nfrom seq2seq import losses\nfrom seq2seq import metrics\nfrom seq2seq import models\nfrom seq2seq import test\nfrom seq2seq import training\n'"
seq2seq/configurable.py,4,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAbstract base class for objects that are configurable using\na parameters dictionary.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport copy\nfrom pydoc import locate\n\nimport six\nimport yaml\n\nimport tensorflow as tf\n\n\nclass abstractstaticmethod(staticmethod):  #pylint: disable=C0111,C0103\n  """"""Decorates a method as abstract and static""""""\n  __slots__ = ()\n\n  def __init__(self, function):\n    super(abstractstaticmethod, self).__init__(function)\n    function.__isabstractmethod__ = True\n\n  __isabstractmethod__ = True\n\n\ndef _create_from_dict(dict_, default_module, *args, **kwargs):\n  """"""Creates a configurable class from a dictionary. The dictionary must have\n  ""class"" and ""params"" properties. The class can be either fully qualified, or\n  it is looked up in the modules passed via `default_module`.\n  """"""\n  class_ = locate(dict_[""class""]) or getattr(default_module, dict_[""class""])\n  params = {}\n  if ""params"" in dict_:\n    params = dict_[""params""]\n  instance = class_(params, *args, **kwargs)\n  return instance\n\n\ndef _maybe_load_yaml(item):\n  """"""Parses `item` only if it is a string. If `item` is a dictionary\n  it is returned as-is.\n  """"""\n  if isinstance(item, six.string_types):\n    return yaml.load(item)\n  elif isinstance(item, dict):\n    return item\n  else:\n    raise ValueError(""Got {}, expected YAML string or dict"", type(item))\n\n\ndef _deep_merge_dict(dict_x, dict_y, path=None):\n  """"""Recursively merges dict_y into dict_x.\n  """"""\n  if path is None: path = []\n  for key in dict_y:\n    if key in dict_x:\n      if isinstance(dict_x[key], dict) and isinstance(dict_y[key], dict):\n        _deep_merge_dict(dict_x[key], dict_y[key], path + [str(key)])\n      elif dict_x[key] == dict_y[key]:\n        pass  # same leaf value\n      else:\n        dict_x[key] = dict_y[key]\n    else:\n      dict_x[key] = dict_y[key]\n  return dict_x\n\n\ndef _parse_params(params, default_params):\n  """"""Parses parameter values to the types defined by the default parameters.\n  Default parameters are used for missing values.\n  """"""\n  # Cast parameters to correct types\n  if params is None:\n    params = {}\n  result = copy.deepcopy(default_params)\n  for key, value in params.items():\n    # If param is unknown, drop it to stay compatible with past versions\n    if key not in default_params:\n      raise ValueError(""%s is not a valid model parameter"" % key)\n    # Param is a dictionary\n    if isinstance(value, dict):\n      default_dict = default_params[key]\n      if not isinstance(default_dict, dict):\n        raise ValueError(""%s should not be a dictionary"", key)\n      if default_dict:\n        value = _parse_params(value, default_dict)\n      else:\n        # If the default is an empty dict we do not typecheck it\n        # and assume it\'s done downstream\n        pass\n    if value is None:\n      continue\n    if default_params[key] is None:\n      result[key] = value\n    else:\n      result[key] = type(default_params[key])(value)\n  return result\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Configurable(object):\n  """"""Interface for all classes that are configurable\n  via a parameters dictionary.\n\n  Args:\n    params: A dictionary of parameters.\n    mode: A value in tf.contrib.learn.ModeKeys\n  """"""\n\n  def __init__(self, params, mode):\n    self._params = _parse_params(params, self.default_params())\n    self._mode = mode\n    self._print_params()\n\n  def _print_params(self):\n    """"""Logs parameter values""""""\n    classname = self.__class__.__name__\n    tf.logging.info(""Creating %s in mode=%s"", classname, self._mode)\n    tf.logging.info(""\\n%s"", yaml.dump({classname: self._params}))\n\n  @property\n  def mode(self):\n    """"""Returns a value in tf.contrib.learn.ModeKeys.\n    """"""\n    return self._mode\n\n  @property\n  def params(self):\n    """"""Returns a dictionary of parsed parameters.\n    """"""\n    return self._params\n\n  @abstractstaticmethod\n  def default_params():\n    """"""Returns a dictionary of default parameters. The default parameters\n    are used to define the expected type of passed parameters. Missing\n    parameter values are replaced with the defaults returned by this method.\n    """"""\n    raise NotImplementedError\n'"
seq2seq/global_vars.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nCollection of global variables.\n""""""\n\nSYNC_REPLICAS_OPTIMIZER = None\n'"
seq2seq/graph_module.py,3,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAll graph components that create Variables should inherit from this\nbase class defined in this file.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\nclass GraphModule(object):\n  """"""\n  Convenience class that makes it easy to share variables.\n  Each insance of this class creates its own set of variables, but\n  each subsequent execution of an instance will re-use its variables.\n\n  Graph components that define variables should inherit from this class\n  and implement their logic in the `_build` method.\n  """"""\n\n  def __init__(self, name):\n    """"""\n    Initialize the module. Each subclass must call this constructor with a name.\n\n    Args:\n      name: Name of this module. Used for `tf.make_template`.\n    """"""\n    self.name = name\n    self._template = tf.make_template(name, self._build, create_scope_now_=True)\n    # Docstrings for the class should be the docstring for the _build method\n    self.__doc__ = self._build.__doc__\n    # pylint: disable=E1101\n    self.__call__.__func__.__doc__ = self._build.__doc__\n\n  def _build(self, *args, **kwargs):\n    """"""Subclasses should implement their logic here.\n    """"""\n    raise NotImplementedError\n\n  def __call__(self, *args, **kwargs):\n    # pylint: disable=missing-docstring\n    return self._template(*args, **kwargs)\n\n  def variable_scope(self):\n    """"""Returns the proper variable scope for this module.\n    """"""\n    return tf.variable_scope(self._template.variable_scope)\n'"
seq2seq/graph_utils.py,6,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Miscellaneous utility function.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndef templatemethod(name_):\n  """"""This decorator wraps a method with `tf.make_template`. For example,\n\n  @templatemethod\n  def my_method():\n    # Create variables\n  """"""\n\n  def template_decorator(func):\n    """"""Inner decorator function""""""\n\n    def func_wrapper(*args, **kwargs):\n      """"""Inner wrapper function""""""\n      templated_func = tf.make_template(name_, func)\n      return templated_func(*args, **kwargs)\n\n    return func_wrapper\n\n  return template_decorator\n\n\ndef add_dict_to_collection(dict_, collection_name):\n  """"""Adds a dictionary to a graph collection.\n\n  Args:\n    dict_: A dictionary of string keys to tensor values\n    collection_name: The name of the collection to add the dictionary to\n  """"""\n  key_collection = collection_name + ""_keys""\n  value_collection = collection_name + ""_values""\n  for key, value in dict_.items():\n    tf.add_to_collection(key_collection, key)\n    tf.add_to_collection(value_collection, value)\n\n\ndef get_dict_from_collection(collection_name):\n  """"""Gets a dictionary from a graph collection.\n\n  Args:\n    collection_name: A collection name to read a dictionary from\n\n  Returns:\n    A dictionary with string keys and tensor values\n  """"""\n  key_collection = collection_name + ""_keys""\n  value_collection = collection_name + ""_values""\n  keys = tf.get_collection(key_collection)\n  values = tf.get_collection(value_collection)\n  return dict(zip(keys, values))\n'"
seq2seq/losses.py,5,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Operations related to calculating sequence losses.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndef cross_entropy_sequence_loss(logits, targets, sequence_length):\n  """"""Calculates the per-example cross-entropy loss for a sequence of logits and\n    masks out all losses passed the sequence length.\n\n  Args:\n    logits: Logits of shape `[T, B, vocab_size]`\n    targets: Target classes of shape `[T, B]`\n    sequence_length: An int32 tensor of shape `[B]` corresponding\n      to the length of each input\n\n  Returns:\n    A tensor of shape [T, B] that contains the loss per example, per time step.\n  """"""\n  with tf.name_scope(""cross_entropy_sequence_loss""):\n    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits, labels=targets)\n\n    # Mask out the losses we don\'t care about\n    loss_mask = tf.sequence_mask(\n        tf.to_int32(sequence_length), tf.to_int32(tf.shape(targets)[0]))\n    losses = losses * tf.transpose(tf.to_float(loss_mask), [1, 0])\n\n    return losses\n'"
bin/tools/generate_beam_viz.py,0,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"""""" Generate beam search visualization.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport json\nimport shutil\nfrom string import Template\nimport numpy as np\n\nimport networkx as nx\nfrom networkx.readwrite import json_graph\n\nPARSER = argparse.ArgumentParser(\n    description=""Generate beam search visualizations"")\nPARSER.add_argument(\n    ""-d"", ""--data"", type=str, required=True,\n    help=""path to the beam search data file"")\nPARSER.add_argument(\n    ""-o"", ""--output_dir"", type=str, required=True,\n    help=""path to the output directory"")\nPARSER.add_argument(\n    ""-v"", ""--vocab"", type=str, required=False,\n    help=""path to the vocabulary file"")\nARGS = PARSER.parse_args()\n\n\nHTML_TEMPLATE = Template(""""""\n<!DOCTYPE html>\n<html lang=""en"">\n  <head>\n    <meta charset=""utf-8"">\n    <title>Beam Search</title>\n    <link rel=""stylesheet"" type=""text/css"" href=""tree.css"">\n    <script src=""http://d3js.org/d3.v3.min.js""></script>\n  </head>\n  <body>\n    <script>\n      var treeData = $DATA\n    </script>\n    <script src=""tree.js""></script>\n  </body>\n</html>"""""")\n\n\ndef _add_graph_level(graph, level, parent_ids, names, scores):\n  """"""Adds a levelto the passed graph""""""\n  for i, parent_id in enumerate(parent_ids):\n    new_node = (level, i)\n    parent_node = (level - 1, parent_id)\n    graph.add_node(new_node)\n    graph.node[new_node][""name""] = names[i]\n    graph.node[new_node][""score""] = str(scores[i])\n    graph.node[new_node][""size""] = 100\n    # Add an edge to the parent\n    graph.add_edge(parent_node, new_node)\n\ndef create_graph(predicted_ids, parent_ids, scores, vocab=None):\n  def get_node_name(pred):\n    return vocab[pred] if vocab else str(pred)\n\n  seq_length = predicted_ids.shape[0]\n  graph = nx.DiGraph()\n  for level in range(seq_length):\n    names = [get_node_name(pred) for pred in predicted_ids[level]]\n    _add_graph_level(graph, level + 1, parent_ids[level], names, scores[level])\n  graph.node[(0, 0)][""name""] = ""START""\n  return graph\n\n\ndef main():\n  beam_data = np.load(ARGS.data)\n\n  # Optionally load vocabulary data\n  vocab = None\n  if ARGS.vocab:\n    with open(ARGS.vocab) as file:\n      vocab = file.readlines()\n    vocab = [_.strip() for _ in vocab]\n    vocab += [""UNK"", ""SEQUENCE_START"", ""SEQUENCE_END""]\n\n  if not os.path.exists(ARGS.output_dir):\n    os.makedirs(ARGS.output_dir)\n\n  # Copy required files\n  shutil.copy2(""./bin/tools/beam_search_viz/tree.css"", ARGS.output_dir)\n  shutil.copy2(""./bin/tools/beam_search_viz/tree.js"", ARGS.output_dir)\n\n  for idx in range(len(beam_data[""predicted_ids""])):\n    predicted_ids = beam_data[""predicted_ids""][idx]\n    parent_ids = beam_data[""beam_parent_ids""][idx]\n    scores = beam_data[""scores""][idx]\n\n    graph = create_graph(\n        predicted_ids=predicted_ids,\n        parent_ids=parent_ids,\n        scores=scores,\n        vocab=vocab)\n\n    json_str = json.dumps(\n        json_graph.tree_data(graph, (0, 0)),\n        ensure_ascii=False)\n\n    html_str = HTML_TEMPLATE.substitute(DATA=json_str)\n    output_path = os.path.join(ARGS.output_dir, ""{:06d}.html"".format(idx))\n    with open(output_path, ""w"") as file:\n      file.write(html_str)\n    print(output_path)\n\n\nif __name__ == ""__main__"":\n  main()'"
bin/tools/generate_toy_data.py,0,"b'#! /usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nFunctions to generate various toy datasets.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport numpy as np\nimport io\n\nPARSER = argparse.ArgumentParser(description=""Generates toy datasets."")\nPARSER.add_argument(\n    ""--vocab_size"", type=int, default=100, help=""size of the vocabulary"")\nPARSER.add_argument(\n    ""--num_examples"", type=int, default=10000, help=""number of examples"")\nPARSER.add_argument(\n    ""--min_len"", type=int, default=5, help=""minimum sequence length"")\nPARSER.add_argument(\n    ""--max_len"", type=int, default=40, help=""maximum sequence length"")\nPARSER.add_argument(\n    ""--type"",\n    type=str,\n    default=""copy"",\n    choices=[""copy"", ""reverse""],\n    help=""Type of dataet to generate. One of \\""copy\\"" or \\""reverse\\"""")\nPARSER.add_argument(\n    ""--output_dir"",\n    type=str,\n    help=""path to the output directory"",\n    required=True)\nARGS = PARSER.parse_args()\n\nVOCABULARY = list([str(x) for x in range(ARGS.vocab_size - 1)])\nVOCABULARY += [""\xe7\xac\x91""]\n\n\ndef make_copy(num_examples, min_len, max_len):\n  """"""\n  Generates a dataset where the target is equal to the source.\n  Sequence lengths are chosen randomly from [min_len, max_len].\n\n  Args:\n    num_examples: Number of examples to generate\n    min_len: Minimum sequence length\n    max_len: Maximum sequence length\n\n  Returns:\n    An iterator of (source, target) string tuples.\n  """"""\n  for _ in range(num_examples):\n    turn_length = np.random.choice(np.arange(min_len, max_len + 1))\n    source_tokens = np.random.choice(\n        list(VOCABULARY), size=turn_length, replace=True)\n    target_tokens = source_tokens\n    yield "" "".join(source_tokens), "" "".join(target_tokens)\n\n\ndef make_reverse(num_examples, min_len, max_len):\n  """"""\n  Generates a dataset where the target is equal to the source reversed.\n  Sequence lengths are chosen randomly from [min_len, max_len].\n\n  Args:\n    num_examples: Number of examples to generate\n    min_len: Minimum sequence length\n    max_len: Maximum sequence length\n\n  Returns:\n    An iterator of (source, target) string tuples.\n  """"""\n  for _ in range(num_examples):\n    turn_length = np.random.choice(np.arange(min_len, max_len + 1))\n    source_tokens = np.random.choice(\n        list(VOCABULARY), size=turn_length, replace=True)\n    target_tokens = source_tokens[::-1]\n    yield "" "".join(source_tokens), "" "".join(target_tokens)\n\n\ndef write_parallel_text(sources, targets, output_prefix):\n  """"""\n  Writes two files where each line corresponds to one example\n    - [output_prefix].sources.txt\n    - [output_prefix].targets.txt\n\n  Args:\n    sources: Iterator of source strings\n    targets: Iterator of target strings\n    output_prefix: Prefix for the output file\n  """"""\n  source_filename = os.path.abspath(os.path.join(output_prefix, ""sources.txt""))\n  target_filename = os.path.abspath(os.path.join(output_prefix, ""targets.txt""))\n\n  with io.open(source_filename, ""w"", encoding=\'utf8\') as source_file:\n    for record in sources:\n      source_file.write(record + ""\\n"")\n  print(""Wrote {}"".format(source_filename))\n\n  with io.open(target_filename, ""w"", encoding=\'utf8\') as target_file:\n    for record in targets:\n      target_file.write(record + ""\\n"")\n  print(""Wrote {}"".format(target_filename))\n\n\ndef main():\n  """"""Main function""""""\n\n  if ARGS.type == ""copy"":\n    generate_fn = make_copy\n  elif ARGS.type == ""reverse"":\n    generate_fn = make_reverse\n\n  # Generate dataset\n  examples = list(generate_fn(ARGS.num_examples, ARGS.min_len, ARGS.max_len))\n  try:\n    os.makedirs(ARGS.output_dir)\n  except OSError:\n    if not os.path.isdir(ARGS.output_dir):\n      raise\n\n  # Write train data\n  train_sources, train_targets = zip(*examples)\n  write_parallel_text(train_sources, train_targets, ARGS.output_dir)\n\n\nif __name__ == ""__main__"":\n  main()\n'"
bin/tools/generate_vocab.py,0,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#pylint: disable=invalid-name\n""""""\nGenerate vocabulary for a tokenized text file.\n""""""\n\nimport sys\nimport argparse\nimport collections\nimport logging\n\nparser = argparse.ArgumentParser(\n    description=""Generate vocabulary for a tokenized text file."")\nparser.add_argument(\n    ""--min_frequency"",\n    dest=""min_frequency"",\n    type=int,\n    default=0,\n    help=""Minimum frequency of a word to be included in the vocabulary."")\nparser.add_argument(\n    ""--max_vocab_size"",\n    dest=""max_vocab_size"",\n    type=int,\n    help=""Maximum number of tokens in the vocabulary"")\nparser.add_argument(\n    ""--downcase"",\n    dest=""downcase"",\n    type=bool,\n    help=""If set to true, downcase all text before processing."",\n    default=False)\nparser.add_argument(\n    ""infile"",\n    nargs=""?"",\n    type=argparse.FileType(""r""),\n    default=sys.stdin,\n    help=""Input tokenized text file to be processed."")\nparser.add_argument(\n    ""--delimiter"",\n    dest=""delimiter"",\n    type=str,\n    default="" "",\n    help=""Delimiter character for tokenizing. Use \\"" \\"" and \\""\\"" for word and char level respectively.""\n)\nargs = parser.parse_args()\n\n# Counter for all tokens in the vocabulary\ncnt = collections.Counter()\n\nfor line in args.infile:\n  if args.downcase:\n    line = line.lower()\n  if args.delimiter == """":\n    tokens = list(line.strip())\n  else:\n    tokens = line.strip().split(args.delimiter)\n  tokens = [_ for _ in tokens if len(_) > 0]\n  cnt.update(tokens)\n\nlogging.info(""Found %d unique tokens in the vocabulary."", len(cnt))\n\n# Filter tokens below the frequency threshold\nif args.min_frequency > 0:\n  filtered_tokens = [(w, c) for w, c in cnt.most_common()\n                     if c > args.min_frequency]\n  cnt = collections.Counter(dict(filtered_tokens))\n\nlogging.info(""Found %d unique tokens with frequency > %d."",\n             len(cnt), args.min_frequency)\n\n# Sort tokens by 1. frequency 2. lexically to break ties\nword_with_counts = cnt.most_common()\nword_with_counts = sorted(\n    word_with_counts, key=lambda x: (x[1], x[0]), reverse=True)\n\n# Take only max-vocab\nif args.max_vocab_size is not None:\n  word_with_counts = word_with_counts[:args.max_vocab_size]\n\nfor word, count in word_with_counts:\n  print(""{}\\t{}"".format(word, count))\n'"
bin/tools/profile.py,7,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"""""" Script to generates model profiling information\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport six\n\n#pylint: disable=E0611\nfrom google.protobuf import text_format\n\nimport tensorflow as tf\nfrom tensorflow.contrib.tfprof import model_analyzer\nfrom tensorflow.contrib.tfprof.python.tools.tfprof import tfprof_logger\nfrom tensorflow import gfile\nfrom tensorflow.tools.tfprof import tfprof_log_pb2\nfrom tensorflow.python.framework import op_def_registry # pylint: disable=E0611\nfrom tensorflow.python.framework.ops import RegisterShape # pylint: disable=E0611\nfrom tensorflow.python.framework import common_shapes # pylint: disable=E0611\n\n# Import custom ops\nfrom seq2seq.decoders.attention import att_sum_bahdanau, att_sum_dot\n\n\ntf.flags.DEFINE_string(""model_dir"", None, ""path to model directory"")\n\nFLAGS = tf.flags.FLAGS\nCUSTOM_OP_FUNCTIONS = [att_sum_bahdanau, att_sum_dot]\n\ndef _register_function_ops(func_list):\n  """"""Registers custom ops in the default graph. This is needed\n  Because our checkpoint is saved with ops that are not part of Tensorflow.""""""\n  op_dict = op_def_registry.get_registered_ops()\n  for func in func_list:\n    #pylint: disable=W0212\n    func._create_definition_if_needed()\n    op_def = func._definition.signature\n    op_dict[op_def.name] = op_def\n    RegisterShape(op_def.name)(common_shapes.unknown_shape)\n\ndef load_metadata(model_dir):\n  """"""Loads RunMetadata, Graph and OpLog from files\n  """"""\n  # Import RunMetadata\n  run_meta_path = os.path.join(model_dir, ""metadata/run_meta"")\n  run_meta = tf.RunMetadata()\n  if gfile.Exists(run_meta_path):\n    with gfile.GFile(run_meta_path, ""rb"") as file:\n      run_meta.MergeFromString(file.read())\n    print(""Loaded RunMetadata from {}"".format(run_meta_path))\n  else:\n    print(""RunMetadata does not exist a {}. Skipping."".format(run_meta_path))\n\n  # Import Graph\n  graph_def_path = os.path.join(model_dir, ""graph.pbtxt"")\n  graph = tf.Graph()\n  if gfile.Exists(graph_def_path):\n    with graph.as_default():\n      _register_function_ops(CUSTOM_OP_FUNCTIONS)\n      graph_def = tf.GraphDef()\n      with gfile.GFile(graph_def_path, ""rb"") as file:\n        text_format.Parse(file.read(), graph_def)\n      tf.import_graph_def(graph_def, name="""")\n      print(""Loaded Graph from {}"".format(graph_def_path))\n  else:\n    print(""Graph does not exist a {}. Skipping."".format(graph_def_path))\n\n  # Import OpLog\n  op_log_path = os.path.join(model_dir, ""metadata/tfprof_log"")\n  op_log = tfprof_log_pb2.OpLog()\n  if gfile.Exists(op_log_path):\n    with gfile.GFile(op_log_path, ""rb"") as file:\n      op_log.MergeFromString(file.read())\n      print(""Loaded OpLog from {}"".format(op_log_path))\n  else:\n    print(""OpLog does not exist a {}. Skipping."".format(op_log_path))\n\n  return run_meta, graph, op_log\n\n\ndef merge_default_with_oplog(graph, op_log=None, run_meta=None):\n  """"""Monkeypatch. There currently is a bug in tfprof_logger that\n    prevents it from being used with Python 3. So we override the method\n    manually until the fix comes in.\n  """"""\n  tmp_op_log = tfprof_log_pb2.OpLog()\n  # pylint: disable=W0212\n  logged_ops = tfprof_logger._get_logged_ops(graph, run_meta)\n  if not op_log:\n    tmp_op_log.log_entries.extend(logged_ops.values())\n  else:\n    all_ops = dict()\n    for entry in op_log.log_entries:\n      all_ops[entry.name] = entry\n    for op_name, entry in six.iteritems(logged_ops):\n      if op_name in all_ops:\n        all_ops[op_name].types.extend(entry.types)\n        if entry.float_ops > 0 and all_ops[op_name].float_ops == 0:\n          all_ops[op_name].float_ops = entry.float_ops\n      else:\n        all_ops[op_name] = entry\n    tmp_op_log.log_entries.extend(all_ops.values())\n  return tmp_op_log\n\n\ndef param_analysis_options(output_dir):\n  """"""Options for model parameter analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""params"", ""bytes""]\n  options[""order_by""] = ""params""\n  options[""account_type_regexes""] = [""Variable""]\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""params.txt"")\n  return ""scope"", options\n\n\ndef micro_anaylsis_options(output_dir):\n  """"""Options for microsecond analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""micros"", ""device""]\n  options[""min_micros""] = 1000\n  options[""account_type_regexes""] = ["".*""]\n  options[""order_by""] = ""micros""\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""micro.txt"")\n  return ""graph"", options\n\n\ndef flops_analysis_options(output_dir):\n  """"""Options for FLOPS analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""float_ops"", ""micros"", ""device""]\n  options[""min_float_ops""] = 1\n  options[""order_by""] = ""float_ops""\n  options[""account_type_regexes""] = ["".*""]\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""flops.txt"")\n  return ""scope"", options\n\n\ndef device_analysis_options(output_dir):\n  """"""Options for device placement analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""device"", ""float_ops"", ""micros""]\n  options[""order_by""] = ""name""\n  options[""account_type_regexes""] = ["".*""]\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""device.txt"")\n  return ""scope"", options\n\n\ndef main(_argv):\n  """"""Main functions. Runs all anaylses.""""""\n  # pylint: disable=W0212\n  tfprof_logger._merge_default_with_oplog = merge_default_with_oplog\n\n  FLAGS.model_dir = os.path.abspath(os.path.expanduser(FLAGS.model_dir))\n  output_dir = os.path.join(FLAGS.model_dir, ""profile"")\n  gfile.MakeDirs(output_dir)\n\n  run_meta, graph, op_log = load_metadata(FLAGS.model_dir)\n\n  param_arguments = [\n      param_analysis_options(output_dir),\n      micro_anaylsis_options(output_dir),\n      flops_analysis_options(output_dir),\n      device_analysis_options(output_dir),\n  ]\n\n  for tfprof_cmd, params in param_arguments:\n    model_analyzer.print_model_analysis(\n        graph=graph,\n        run_meta=run_meta,\n        op_log=op_log,\n        tfprof_cmd=tfprof_cmd,\n        tfprof_options=params)\n\n    if params[""dump_to_file""] != """":\n      print(""Wrote {}"".format(params[""dump_to_file""]))\n\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
seq2seq/contrib/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
seq2seq/contrib/experiment.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""A patched tf.learn Experiment class to handle GPU memory\nsharing issues.\n""""""\n\nimport tensorflow as tf\n\nclass Experiment(tf.contrib.learn.Experiment):\n  """"""A patched tf.learn Experiment class to handle GPU memory\n  sharing issues.""""""\n\n  def __init__(self, train_steps_per_iteration=None, *args, **kwargs):\n    super(Experiment, self).__init__(*args, **kwargs)\n    self._train_steps_per_iteration = train_steps_per_iteration\n\n  def _has_training_stopped(self, eval_result):\n    """"""Determines whether the training has stopped.""""""\n    if not eval_result:\n      return False\n\n    global_step = eval_result.get(tf.GraphKeys.GLOBAL_STEP)\n    return global_step and self._train_steps and (\n        global_step >= self._train_steps)\n\n  def continuous_train_and_eval(self,\n                                continuous_eval_predicate_fn=None):\n    """"""Interleaves training and evaluation.\n\n    The frequency of evaluation is controlled by the `train_steps_per_iteration`\n    (via constructor). The model will be first trained for\n    `train_steps_per_iteration`, and then be evaluated in turns.\n\n    This differs from `train_and_evaluate` as follows:\n      1. The procedure will have train and evaluation in turns. The model\n      will be trained for a number of steps (usuallly smaller than `train_steps`\n      if provided) and then be evaluated.  `train_and_evaluate` will train the\n      model for `train_steps` (no small training iteraions).\n\n      2. Due to the different approach this schedule takes, it leads to two\n      differences in resource control. First, the resources (e.g., memory) used\n      by training will be released before evaluation (`train_and_evaluate` takes\n      double resources). Second, more checkpoints will be saved as a checkpoint\n      is generated at the end of each small trainning iteration.\n\n    Args:\n      continuous_eval_predicate_fn: A predicate function determining whether to\n        continue after each iteration. `predicate_fn` takes the evaluation\n        results as its arguments. At the beginning of evaluation, the passed\n        eval results will be None so it\'s expected that the predicate function\n        handles that gracefully. When `predicate_fn` is not specified, this will\n        run in an infinite loop or exit when global_step reaches `train_steps`.\n\n    Returns:\n      A tuple of the result of the `evaluate` call to the `Estimator` and the\n      export results using the specified `ExportStrategy`.\n\n    Raises:\n      ValueError: if `continuous_eval_predicate_fn` is neither None nor\n        callable.\n    """"""\n\n    if (continuous_eval_predicate_fn is not None and\n        not callable(continuous_eval_predicate_fn)):\n      raise ValueError(\n          ""`continuous_eval_predicate_fn` must be a callable, or None."")\n\n    eval_result = None\n\n    # Set the default value for train_steps_per_iteration, which will be\n    # overriden by other settings.\n    train_steps_per_iteration = 1000\n    if self._train_steps_per_iteration is not None:\n      train_steps_per_iteration = self._train_steps_per_iteration\n    elif self._train_steps is not None:\n      # train_steps_per_iteration = int(self._train_steps / 10)\n      train_steps_per_iteration = min(\n          self._min_eval_frequency, self._train_steps)\n\n    while (not continuous_eval_predicate_fn or\n           continuous_eval_predicate_fn(eval_result)):\n\n      if self._has_training_stopped(eval_result):\n        # Exits once max steps of training is satisfied.\n        tf.logging.info(""Stop training model as max steps reached"")\n        break\n\n      tf.logging.info(""Training model for %s steps"", train_steps_per_iteration)\n      self._estimator.fit(\n          input_fn=self._train_input_fn,\n          steps=train_steps_per_iteration,\n          monitors=self._train_monitors)\n\n      tf.logging.info(""Evaluating model now."")\n      eval_result = self._estimator.evaluate(\n          input_fn=self._eval_input_fn,\n          steps=self._eval_steps,\n          metrics=self._eval_metrics,\n          name=""one_pass"",\n          hooks=self._eval_hooks)\n\n    return eval_result, self._maybe_export(eval_result)\n'"
seq2seq/contrib/rnn_cell.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of RNN Cells\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport sys\nimport inspect\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import array_ops  # pylint: disable=E0611\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\nfrom tensorflow.contrib.rnn import MultiRNNCell  # pylint: disable=E0611\n\n# Import all cell classes from Tensorflow\nTF_CELL_CLASSES = [\n    x for x in tf.contrib.rnn.__dict__.values()\n    if inspect.isclass(x) and issubclass(x, tf.contrib.rnn.RNNCell)\n]\nfor cell_class in TF_CELL_CLASSES:\n  setattr(sys.modules[__name__], cell_class.__name__, cell_class)\n\n\nclass ExtendedMultiRNNCell(MultiRNNCell):\n  """"""Extends the Tensorflow MultiRNNCell with residual connections""""""\n\n  def __init__(self,\n               cells,\n               residual_connections=False,\n               residual_combiner=""add"",\n               residual_dense=False):\n    """"""Create a RNN cell composed sequentially of a number of RNNCells.\n\n    Args:\n      cells: list of RNNCells that will be composed in this order.\n      state_is_tuple: If True, accepted and returned states are n-tuples, where\n        `n = len(cells)`.  If False, the states are all\n        concatenated along the column axis.  This latter behavior will soon be\n        deprecated.\n      residual_connections: If true, add residual connections between all cells.\n        This requires all cells to have the same output_size. Also, iff the\n        input size is not equal to the cell output size, a linear transform\n        is added before the first layer.\n      residual_combiner: One of ""add"" or ""concat"". To create inputs for layer\n        t+1 either ""add"" the inputs from the prev layer or concat them.\n      residual_dense: Densely connect each layer to all other layers\n\n    Raises:\n      ValueError: if cells is empty (not allowed), or at least one of the cells\n        returns a state tuple but the flag `state_is_tuple` is `False`.\n    """"""\n    super(ExtendedMultiRNNCell, self).__init__(cells, state_is_tuple=True)\n    assert residual_combiner in [""add"", ""concat"", ""mean""]\n\n    self._residual_connections = residual_connections\n    self._residual_combiner = residual_combiner\n    self._residual_dense = residual_dense\n\n  def __call__(self, inputs, state, scope=None):\n    """"""Run this multi-layer cell on inputs, starting from state.""""""\n    if not self._residual_connections:\n      return super(ExtendedMultiRNNCell, self).__call__(\n          inputs, state, (scope or ""extended_multi_rnn_cell""))\n\n    with tf.variable_scope(scope or ""extended_multi_rnn_cell""):\n      # Adding Residual connections are only possible when input and output\n      # sizes are equal. Optionally transform the initial inputs to\n      # `cell[0].output_size`\n      if self._cells[0].output_size != inputs.get_shape().as_list()[1] and \\\n          (self._residual_combiner in [""add"", ""mean""]):\n        inputs = tf.contrib.layers.fully_connected(\n            inputs=inputs,\n            num_outputs=self._cells[0].output_size,\n            activation_fn=None,\n            scope=""input_transform"")\n\n      # Iterate through all layers (code from MultiRNNCell)\n      cur_inp = inputs\n      prev_inputs = [cur_inp]\n      new_states = []\n      for i, cell in enumerate(self._cells):\n        with tf.variable_scope(""cell_%d"" % i):\n          if not nest.is_sequence(state):\n            raise ValueError(\n                ""Expected state to be a tuple of length %d, but received: %s"" %\n                (len(self.state_size), state))\n          cur_state = state[i]\n          next_input, new_state = cell(cur_inp, cur_state)\n\n          # Either combine all previous inputs or only the current input\n          input_to_combine = prev_inputs[-1:]\n          if self._residual_dense:\n            input_to_combine = prev_inputs\n\n          # Add Residual connection\n          if self._residual_combiner == ""add"":\n            next_input = next_input + sum(input_to_combine)\n          if self._residual_combiner == ""mean"":\n            combined_mean = tf.reduce_mean(tf.stack(input_to_combine), 0)\n            next_input = next_input + combined_mean\n          elif self._residual_combiner == ""concat"":\n            next_input = tf.concat([next_input] + input_to_combine, 1)\n          cur_inp = next_input\n          prev_inputs.append(cur_inp)\n\n          new_states.append(new_state)\n    new_states = (tuple(new_states)\n                  if self._state_is_tuple else array_ops.concat(new_states, 1))\n    return cur_inp, new_states\n'"
seq2seq/data/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of input-related utlities.\n""""""\n\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.data import parallel_data_provider\nfrom seq2seq.data import postproc\nfrom seq2seq.data import split_tokens_decoder\nfrom seq2seq.data import vocab\n'"
seq2seq/data/input_pipeline.py,24,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nCollection of input pipelines.\n\nAn input pipeline defines how to read and parse data. It produces a tuple\nof (features, labels) that can be read by tf.learn estimators.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nimport sys\n\nimport six\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import tfexample_decoder\n\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.data import split_tokens_decoder, parallel_data_provider\nfrom seq2seq.data.sequence_example_decoder import TFSEquenceExampleDecoder\n\n\ndef make_input_pipeline_from_def(def_dict, mode, **kwargs):\n  """"""Creates an InputPipeline object from a dictionary definition.\n\n  Args:\n    def_dict: A dictionary defining the input pipeline.\n      It must have ""class"" and ""params"" that correspond to the class\n      name and constructor parameters of an InputPipeline, respectively.\n    mode: A value in tf.contrib.learn.ModeKeys\n\n  Returns:\n    A new InputPipeline object\n  """"""\n  if not ""class"" in def_dict:\n    raise ValueError(""Input Pipeline definition must have a class property."")\n\n  class_ = def_dict[""class""]\n  if not hasattr(sys.modules[__name__], class_):\n    raise ValueError(""Invalid Input Pipeline class: {}"".format(class_))\n\n  pipeline_class = getattr(sys.modules[__name__], class_)\n\n  # Constructor arguments\n  params = {}\n  if ""params"" in def_dict:\n    params.update(def_dict[""params""])\n  params.update(kwargs)\n\n  return pipeline_class(params=params, mode=mode)\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass InputPipeline(Configurable):\n  """"""Abstract InputPipeline class. All input pipelines must inherit from this.\n  An InputPipeline defines how data is read, parsed, and separated into\n  features and labels.\n\n  Params:\n    shuffle: If true, shuffle the data.\n    num_epochs: Number of times to iterate through the dataset. If None,\n      iterate forever.\n  """"""\n\n  def __init__(self, params, mode):\n    Configurable.__init__(self, params, mode)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""shuffle"": True,\n        ""num_epochs"": None,\n    }\n\n  def make_data_provider(self, **kwargs):\n    """"""Creates DataProvider instance for this input pipeline. Additional\n    keyword arguments are passed to the DataProvider.\n    """"""\n    raise NotImplementedError(""Not implemented."")\n\n  @property\n  def feature_keys(self):\n    """"""Defines the features that this input pipeline provides. Returns\n      a set of strings.\n    """"""\n    return set()\n\n  @property\n  def label_keys(self):\n    """"""Defines the labels that this input pipeline provides. Returns\n      a set of strings.\n    """"""\n    return set()\n\n  @staticmethod\n  def read_from_data_provider(data_provider):\n    """"""Utility function to read all available items from a DataProvider.\n    """"""\n    item_values = data_provider.get(list(data_provider.list_items()))\n    items_dict = dict(zip(data_provider.list_items(), item_values))\n    return items_dict\n\n\nclass ParallelTextInputPipeline(InputPipeline):\n  """"""An input pipeline that reads two parallel (line-by-line aligned) text\n  files.\n\n  Params:\n    source_files: An array of file names for the source data.\n    target_files: An array of file names for the target data. These must\n      be aligned to the `source_files`.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""source_files"": [],\n        ""target_files"": [],\n        ""source_delimiter"": "" "",\n        ""target_delimiter"": "" "",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n    decoder_source = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""source_tokens"",\n        length_feature_name=""source_len"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""source_delimiter""])\n\n    dataset_source = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""source_files""],\n        reader=tf.TextLineReader,\n        decoder=decoder_source,\n        num_samples=None,\n        items_to_descriptions={})\n\n    dataset_target = None\n    if len(self.params[""target_files""]) > 0:\n      decoder_target = split_tokens_decoder.SplitTokensDecoder(\n          tokens_feature_name=""target_tokens"",\n          length_feature_name=""target_len"",\n          prepend_token=""SEQUENCE_START"",\n          append_token=""SEQUENCE_END"",\n          delimiter=self.params[""target_delimiter""])\n\n      dataset_target = tf.contrib.slim.dataset.Dataset(\n          data_sources=self.params[""target_files""],\n          reader=tf.TextLineReader,\n          decoder=decoder_target,\n          num_samples=None,\n          items_to_descriptions={})\n\n    return parallel_data_provider.ParallelDataProvider(\n        dataset1=dataset_source,\n        dataset2=dataset_target,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""source_tokens"", ""source_len""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_len""])\n\n\nclass TFRecordInputPipeline(InputPipeline):\n  """"""An input pipeline that reads a TFRecords containing both source\n  and target sequences.\n\n  Params:\n    files: An array of file names to read from.\n    source_field: The TFRecord feature field containing the source text.\n    target_field: The TFRecord feature field containing the target text.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""files"": [],\n        ""source_field"": ""source"",\n        ""target_field"": ""target"",\n        ""source_delimiter"": "" "",\n        ""target_delimiter"": "" "",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n\n    splitter_source = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""source_tokens"",\n        length_feature_name=""source_len"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""source_delimiter""])\n\n    splitter_target = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""target_tokens"",\n        length_feature_name=""target_len"",\n        prepend_token=""SEQUENCE_START"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""target_delimiter""])\n\n    keys_to_features = {\n        self.params[""source_field""]: tf.FixedLenFeature((), tf.string),\n        self.params[""target_field""]: tf.FixedLenFeature(\n            (), tf.string, default_value="""")\n    }\n\n    items_to_handlers = {}\n    items_to_handlers[""source_tokens""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""source_field""]],\n        func=lambda dict: splitter_source.decode(\n            dict[self.params[""source_field""]], [""source_tokens""])[0])\n    items_to_handlers[""source_len""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""source_field""]],\n        func=lambda dict: splitter_source.decode(\n            dict[self.params[""source_field""]], [""source_len""])[0])\n    items_to_handlers[""target_tokens""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""target_field""]],\n        func=lambda dict: splitter_target.decode(\n            dict[self.params[""target_field""]], [""target_tokens""])[0])\n    items_to_handlers[""target_len""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""target_field""]],\n        func=lambda dict: splitter_target.decode(\n            dict[self.params[""target_field""]], [""target_len""])[0])\n\n    decoder = tfexample_decoder.TFExampleDecoder(keys_to_features,\n                                                 items_to_handlers)\n\n    dataset = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""files""],\n        reader=tf.TFRecordReader,\n        decoder=decoder,\n        num_samples=None,\n        items_to_descriptions={})\n\n    return tf.contrib.slim.dataset_data_provider.DatasetDataProvider(\n        dataset=dataset,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""source_tokens"", ""source_len""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_len""])\n\n\nclass ImageCaptioningInputPipeline(InputPipeline):\n  """"""An input pipeline that reads a TFRecords containing both source\n  and target sequences.\n\n  Params:\n    files: An array of file names to read from.\n    source_field: The TFRecord feature field containing the source text.\n    target_field: The TFRecord feature field containing the target text.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""files"": [],\n        ""image_field"": ""image/data"",\n        ""image_format"": ""jpg"",\n        ""caption_ids_field"": ""image/caption_ids"",\n        ""caption_tokens_field"": ""image/caption"",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n\n    context_keys_to_features = {\n        self.params[""image_field""]: tf.FixedLenFeature(\n            [], dtype=tf.string),\n        ""image/format"": tf.FixedLenFeature(\n            [], dtype=tf.string, default_value=self.params[""image_format""]),\n    }\n\n    sequence_keys_to_features = {\n        self.params[""caption_ids_field""]: tf.FixedLenSequenceFeature(\n            [], dtype=tf.int64),\n        self.params[""caption_tokens_field""]: tf.FixedLenSequenceFeature(\n            [], dtype=tf.string)\n    }\n\n    items_to_handlers = {\n        ""image"": tfexample_decoder.Image(\n            image_key=self.params[""image_field""],\n            format_key=""image/format"",\n            channels=3),\n        ""target_ids"":\n        tfexample_decoder.Tensor(self.params[""caption_ids_field""]),\n        ""target_tokens"":\n        tfexample_decoder.Tensor(self.params[""caption_tokens_field""]),\n        ""target_len"": tfexample_decoder.ItemHandlerCallback(\n            keys=[self.params[""caption_tokens_field""]],\n            func=lambda x: tf.size(x[self.params[""caption_tokens_field""]]))\n    }\n\n    decoder = TFSEquenceExampleDecoder(\n        context_keys_to_features, sequence_keys_to_features, items_to_handlers)\n\n    dataset = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""files""],\n        reader=tf.TFRecordReader,\n        decoder=decoder,\n        num_samples=None,\n        items_to_descriptions={})\n\n    return tf.contrib.slim.dataset_data_provider.DatasetDataProvider(\n        dataset=dataset,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""image""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_ids"", ""target_len""])\n'"
seq2seq/data/parallel_data_provider.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A Data Provder that reads parallel (aligned) data.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import data_provider\nfrom tensorflow.contrib.slim.python.slim.data import parallel_reader\n\nfrom seq2seq.data import split_tokens_decoder\n\n\ndef make_parallel_data_provider(data_sources_source,\n                                data_sources_target,\n                                reader=tf.TextLineReader,\n                                num_samples=None,\n                                source_delimiter="" "",\n                                target_delimiter="" "",\n                                **kwargs):\n  """"""Creates a DataProvider that reads parallel text data.\n\n  Args:\n    data_sources_source: A list of data sources for the source text files.\n    data_sources_target: A list of data sources for the target text files.\n      Can be None for inference mode.\n    num_samples: Optional, number of records in the dataset\n    delimiter: Split tokens in the data on this delimiter. Defaults to space.\n    kwargs: Additional arguments (shuffle, num_epochs, etc) that are passed\n      to the data provider\n\n  Returns:\n    A DataProvider instance\n  """"""\n\n  decoder_source = split_tokens_decoder.SplitTokensDecoder(\n      tokens_feature_name=""source_tokens"",\n      length_feature_name=""source_len"",\n      append_token=""SEQUENCE_END"",\n      delimiter=source_delimiter)\n\n  dataset_source = tf.contrib.slim.dataset.Dataset(\n      data_sources=data_sources_source,\n      reader=reader,\n      decoder=decoder_source,\n      num_samples=num_samples,\n      items_to_descriptions={})\n\n  dataset_target = None\n  if data_sources_target is not None:\n    decoder_target = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""target_tokens"",\n        length_feature_name=""target_len"",\n        prepend_token=""SEQUENCE_START"",\n        append_token=""SEQUENCE_END"",\n        delimiter=target_delimiter)\n\n    dataset_target = tf.contrib.slim.dataset.Dataset(\n        data_sources=data_sources_target,\n        reader=reader,\n        decoder=decoder_target,\n        num_samples=num_samples,\n        items_to_descriptions={})\n\n  return ParallelDataProvider(\n      dataset1=dataset_source, dataset2=dataset_target, **kwargs)\n\n\nclass ParallelDataProvider(data_provider.DataProvider):\n  """"""Creates a ParallelDataProvider. This data provider reads two datasets\n  in parallel, keeping them aligned.\n\n  Args:\n    dataset1: The first dataset. An instance of the Dataset class.\n    dataset2: The second dataset. An instance of the Dataset class.\n      Can be None. If None, only `dataset1` is read.\n    num_readers: The number of parallel readers to use.\n    shuffle: Whether to shuffle the data sources and common queue when\n      reading.\n    num_epochs: The number of times each data source is read. If left as None,\n      the data will be cycled through indefinitely.\n    common_queue_capacity: The capacity of the common queue.\n    common_queue_min: The minimum number of elements in the common queue after\n      a dequeue.\n    seed: The seed to use if shuffling.\n  """"""\n\n  def __init__(self,\n               dataset1,\n               dataset2,\n               shuffle=True,\n               num_epochs=None,\n               common_queue_capacity=4096,\n               common_queue_min=1024,\n               seed=None):\n\n    if seed is None:\n      seed = np.random.randint(10e8)\n\n    _, data_source = parallel_reader.parallel_read(\n        dataset1.data_sources,\n        reader_class=dataset1.reader,\n        num_epochs=num_epochs,\n        num_readers=1,\n        shuffle=False,\n        capacity=common_queue_capacity,\n        min_after_dequeue=common_queue_min,\n        seed=seed)\n\n    data_target = """"\n    if dataset2 is not None:\n      _, data_target = parallel_reader.parallel_read(\n          dataset2.data_sources,\n          reader_class=dataset2.reader,\n          num_epochs=num_epochs,\n          num_readers=1,\n          shuffle=False,\n          capacity=common_queue_capacity,\n          min_after_dequeue=common_queue_min,\n          seed=seed)\n\n    # Optionally shuffle the data\n    if shuffle:\n      shuffle_queue = tf.RandomShuffleQueue(\n          capacity=common_queue_capacity,\n          min_after_dequeue=common_queue_min,\n          dtypes=[tf.string, tf.string],\n          seed=seed)\n      enqueue_ops = []\n      enqueue_ops.append(shuffle_queue.enqueue([data_source, data_target]))\n      tf.train.add_queue_runner(\n          tf.train.QueueRunner(shuffle_queue, enqueue_ops))\n      data_source, data_target = shuffle_queue.dequeue()\n\n    # Decode source items\n    items = dataset1.decoder.list_items()\n    tensors = dataset1.decoder.decode(data_source, items)\n\n    if dataset2 is not None:\n      # Decode target items\n      items2 = dataset2.decoder.list_items()\n      tensors2 = dataset2.decoder.decode(data_target, items2)\n\n      # Merge items and results\n      items = items + items2\n      tensors = tensors + tensors2\n\n    super(ParallelDataProvider, self).__init__(\n        items_to_tensors=dict(zip(items, tensors)),\n        num_samples=dataset1.num_samples)\n'"
seq2seq/data/postproc.py,0,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nA collection of commonly used post-processing functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\ndef strip_bpe(text):\n  """"""Deodes text that was processed using BPE from\n  https://github.com/rsennrich/subword-nmt""""""\n  return text.replace(""@@ "", """").strip()\n\ndef decode_sentencepiece(text):\n  """"""Decodes text that uses https://github.com/google/sentencepiece encoding.\n  Assumes that pieces are separated by a space""""""\n  return """".join(text.split("" "")).replace(""\xe2\x96\x81"", "" "").strip()\n\ndef slice_text(text,\n               eos_token=""SEQUENCE_END"",\n               sos_token=""SEQUENCE_START""):\n  """"""Slices text from SEQUENCE_START to SEQUENCE_END, not including\n  these special tokens.\n  """"""\n  eos_index = text.find(eos_token)\n  text = text[:eos_index] if eos_index > -1 else text\n  sos_index = text.find(sos_token)\n  text = text[sos_index+len(sos_token):] if sos_index > -1 else text\n  return text.strip()\n'"
seq2seq/data/sequence_example_decoder.py,6,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A decoder for tf.SequenceExample""""""\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import data_decoder\n\n\nclass TFSEquenceExampleDecoder(data_decoder.DataDecoder):\n  """"""A decoder for TensorFlow Examples.\n  Decoding Example proto buffers is comprised of two stages: (1) Example parsing\n  and (2) tensor manipulation.\n  In the first stage, the tf.parse_example function is called with a list of\n  FixedLenFeatures and SparseLenFeatures. These instances tell TF how to parse\n  the example. The output of this stage is a set of tensors.\n  In the second stage, the resulting tensors are manipulated to provide the\n  requested \'item\' tensors.\n  To perform this decoding operation, an ExampleDecoder is given a list of\n  ItemHandlers. Each ItemHandler indicates the set of features for stage 1 and\n  contains the instructions for post_processing its tensors for stage 2.\n  """"""\n\n  def __init__(self, context_keys_to_features, sequence_keys_to_features,\n               items_to_handlers):\n    """"""Constructs the decoder.\n    Args:\n      keys_to_features: a dictionary from TF-Example keys to either\n        tf.VarLenFeature or tf.FixedLenFeature instances. See tensorflow\'s\n        parsing_ops.py.\n      items_to_handlers: a dictionary from items (strings) to ItemHandler\n        instances. Note that the ItemHandler\'s are provided the keys that they\n        use to return the final item Tensors.\n    """"""\n    self._context_keys_to_features = context_keys_to_features\n    self._sequence_keys_to_features = sequence_keys_to_features\n    self._items_to_handlers = items_to_handlers\n\n  def list_items(self):\n    """"""See base class.""""""\n    return list(self._items_to_handlers.keys())\n\n  def decode(self, serialized_example, items=None):\n    """"""Decodes the given serialized TF-example.\n    Args:\n      serialized_example: a serialized TF-example tensor.\n      items: the list of items to decode. These must be a subset of the item\n        keys in self._items_to_handlers. If `items` is left as None, then all\n        of the items in self._items_to_handlers are decoded.\n    Returns:\n      the decoded items, a list of tensor.\n    """"""\n    context, sequence = tf.parse_single_sequence_example(\n        serialized_example, self._context_keys_to_features,\n        self._sequence_keys_to_features)\n\n    # Merge context and sequence features\n    example = {}\n    example.update(context)\n    example.update(sequence)\n\n    all_features = {}\n    all_features.update(self._context_keys_to_features)\n    all_features.update(self._sequence_keys_to_features)\n\n    # Reshape non-sparse elements just once:\n    for k, value in all_features.items():\n      if isinstance(value, tf.FixedLenFeature):\n        example[k] = tf.reshape(example[k], value.shape)\n\n    if not items:\n      items = self._items_to_handlers.keys()\n\n    outputs = []\n    for item in items:\n      handler = self._items_to_handlers[item]\n      keys_to_tensors = {key: example[key] for key in handler.keys}\n      outputs.append(handler.tensors_to_item(keys_to_tensors))\n    return outputs\n'"
seq2seq/data/split_tokens_decoder.py,4,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A decoder that splits a string into tokens and returns the\nindividual tokens and the length.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import data_decoder\n\n\nclass SplitTokensDecoder(data_decoder.DataDecoder):\n  """"""A DataProvider that splits a string tensor into individual tokens and\n  returns the tokens and the length.\n  Optionally prepends or appends special tokens.\n\n  Args:\n    delimiter: Delimiter to split on. Must be a single character.\n    tokens_feature_name: A descriptive feature name for the token values\n    length_feature_name: A descriptive feature name for the length value\n  """"""\n\n  def __init__(self,\n               delimiter="" "",\n               tokens_feature_name=""tokens"",\n               length_feature_name=""length"",\n               prepend_token=None,\n               append_token=None):\n    self.delimiter = delimiter\n    self.tokens_feature_name = tokens_feature_name\n    self.length_feature_name = length_feature_name\n    self.prepend_token = prepend_token\n    self.append_token = append_token\n\n  def decode(self, data, items):\n    decoded_items = {}\n\n    # Split tokens\n    tokens = tf.string_split([data], delimiter=self.delimiter).values\n\n    # Optionally prepend a special token\n    if self.prepend_token is not None:\n      tokens = tf.concat([[self.prepend_token], tokens], 0)\n\n    # Optionally append a special token\n    if self.append_token is not None:\n      tokens = tf.concat([tokens, [self.append_token]], 0)\n\n    decoded_items[self.length_feature_name] = tf.size(tokens)\n    decoded_items[self.tokens_feature_name] = tokens\n    return [decoded_items[_] for _ in items]\n\n  def list_items(self):\n    return [self.tokens_feature_name, self.length_feature_name]\n'"
seq2seq/data/vocab.py,13,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Vocabulary related functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nSpecialVocab = collections.namedtuple(""SpecialVocab"",\n                                      [""UNK"", ""SEQUENCE_START"", ""SEQUENCE_END""])\n\n\nclass VocabInfo(\n    collections.namedtuple(""VocbabInfo"",\n                           [""path"", ""vocab_size"", ""special_vocab""])):\n  """"""Convenience structure for vocabulary information.\n  """"""\n\n  @property\n  def total_size(self):\n    """"""Returns size the the base vocabulary plus the size of extra vocabulary""""""\n    return self.vocab_size + len(self.special_vocab)\n\n\ndef get_vocab_info(vocab_path):\n  """"""Creates a `VocabInfo` instance that contains the vocabulary size and\n    the special vocabulary for the given file.\n\n  Args:\n    vocab_path: Path to a vocabulary file with one word per line.\n\n  Returns:\n    A VocabInfo tuple.\n  """"""\n  with gfile.GFile(vocab_path) as file:\n    vocab_size = sum(1 for _ in file)\n  special_vocab = get_special_vocab(vocab_size)\n  return VocabInfo(vocab_path, vocab_size, special_vocab)\n\n\ndef get_special_vocab(vocabulary_size):\n  """"""Returns the `SpecialVocab` instance for a given vocabulary size.\n  """"""\n  return SpecialVocab(*range(vocabulary_size, vocabulary_size + 3))\n\n\ndef create_vocabulary_lookup_table(filename, default_value=None):\n  """"""Creates a lookup table for a vocabulary file.\n\n  Args:\n    filename: Path to a vocabulary file containg one word per line.\n      Each word is mapped to its line number.\n    default_value: UNK tokens will be mapped to this id.\n      If None, UNK tokens will be mapped to [vocab_size]\n\n    Returns:\n      A tuple (vocab_to_id_table, id_to_vocab_table,\n      word_to_count_table, vocab_size). The vocab size does not include\n      the UNK token.\n    """"""\n  if not gfile.Exists(filename):\n    raise ValueError(""File does not exist: {}"".format(filename))\n\n  # Load vocabulary into memory\n  with gfile.GFile(filename) as file:\n    vocab = list(line.strip(""\\n"") for line in file)\n  vocab_size = len(vocab)\n\n  has_counts = len(vocab[0].split(""\\t"")) == 2\n  if has_counts:\n    vocab, counts = zip(*[_.split(""\\t"") for _ in vocab])\n    counts = [float(_) for _ in counts]\n    vocab = list(vocab)\n  else:\n    counts = [-1. for _ in vocab]\n\n  # Add special vocabulary items\n  special_vocab = get_special_vocab(vocab_size)\n  vocab += list(special_vocab._fields)\n  vocab_size += len(special_vocab)\n  counts += [-1. for _ in list(special_vocab._fields)]\n\n  if default_value is None:\n    default_value = special_vocab.UNK\n\n  tf.logging.info(""Creating vocabulary lookup table of size %d"", vocab_size)\n\n  vocab_tensor = tf.constant(vocab)\n  count_tensor = tf.constant(counts, dtype=tf.float32)\n  vocab_idx_tensor = tf.range(vocab_size, dtype=tf.int64)\n\n  # Create ID -> word mapping\n  id_to_vocab_init = tf.contrib.lookup.KeyValueTensorInitializer(\n      vocab_idx_tensor, vocab_tensor, tf.int64, tf.string)\n  id_to_vocab_table = tf.contrib.lookup.HashTable(id_to_vocab_init, ""UNK"")\n\n  # Create word -> id mapping\n  vocab_to_id_init = tf.contrib.lookup.KeyValueTensorInitializer(\n      vocab_tensor, vocab_idx_tensor, tf.string, tf.int64)\n  vocab_to_id_table = tf.contrib.lookup.HashTable(vocab_to_id_init,\n                                                  default_value)\n\n  # Create word -> count mapping\n  word_to_count_init = tf.contrib.lookup.KeyValueTensorInitializer(\n      vocab_tensor, count_tensor, tf.string, tf.float32)\n  word_to_count_table = tf.contrib.lookup.HashTable(word_to_count_init, -1)\n\n  return vocab_to_id_table, id_to_vocab_table, word_to_count_table, vocab_size\n'"
seq2seq/decoders/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of decoders and decoder-related functions.\n""""""\n\nfrom seq2seq.decoders.rnn_decoder import *\nfrom seq2seq.decoders.attention import *\nfrom seq2seq.decoders.basic_decoder import *\nfrom seq2seq.decoders.attention_decoder import *\n'"
seq2seq/decoders/attention.py,20,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n"""""" Implementations of attention layers.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nimport six\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import function  # pylint: disable=E0611\n\nfrom seq2seq.graph_module import GraphModule\nfrom seq2seq.configurable import Configurable\n\n\n@function.Defun(\n    tf.float32,\n    tf.float32,\n    tf.float32,\n    func_name=""att_sum_bahdanau"",\n    noinline=True)\ndef att_sum_bahdanau(v_att, keys, query):\n  """"""Calculates a batch- and timweise dot product with a variable""""""\n  return tf.reduce_sum(v_att * tf.tanh(keys + tf.expand_dims(query, 1)), [2])\n\n\n@function.Defun(tf.float32, tf.float32, func_name=""att_sum_dot"", noinline=True)\ndef att_sum_dot(keys, query):\n  """"""Calculates a batch- and timweise dot product""""""\n  return tf.reduce_sum(keys * tf.expand_dims(query, 1), [2])\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass AttentionLayer(GraphModule, Configurable):\n  """"""\n  Attention layer according to https://arxiv.org/abs/1409.0473.\n\n  Params:\n    num_units: Number of units used in the attention layer\n  """"""\n\n  def __init__(self, params, mode, name=""attention""):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n\n  @staticmethod\n  def default_params():\n    return {""num_units"": 128}\n\n  @abc.abstractmethod\n  def score_fn(self, keys, query):\n    """"""Computes the attention score""""""\n    raise NotImplementedError\n\n  def _build(self, query, keys, values, values_length):\n    """"""Computes attention scores and outputs.\n\n    Args:\n      query: The query used to calculate attention scores.\n        In seq2seq this is typically the current state of the decoder.\n        A tensor of shape `[B, ...]`\n      keys: The keys used to calculate attention scores. In seq2seq, these\n        are typically the outputs of the encoder and equivalent to `values`.\n        A tensor of shape `[B, T, ...]` where each element in the `T`\n        dimension corresponds to the key for that value.\n      values: The elements to compute attention over. In seq2seq, this is\n        typically the sequence of encoder outputs.\n        A tensor of shape `[B, T, input_dim]`.\n      values_length: An int32 tensor of shape `[B]` defining the sequence\n        length of the attention values.\n\n    Returns:\n      A tuple `(scores, context)`.\n      `scores` is vector of length `T` where each element is the\n      normalized ""score"" of the corresponding `inputs` element.\n      `context` is the final attention layer output corresponding to\n      the weighted inputs.\n      A tensor fo shape `[B, input_dim]`.\n    """"""\n    values_depth = values.get_shape().as_list()[-1]\n\n    # Fully connected layers to transform both keys and query\n    # into a tensor with `num_units` units\n    att_keys = tf.contrib.layers.fully_connected(\n        inputs=keys,\n        num_outputs=self.params[""num_units""],\n        activation_fn=None,\n        scope=""att_keys"")\n    att_query = tf.contrib.layers.fully_connected(\n        inputs=query,\n        num_outputs=self.params[""num_units""],\n        activation_fn=None,\n        scope=""att_query"")\n\n    scores = self.score_fn(att_keys, att_query)\n\n    # Replace all scores for padded inputs with tf.float32.min\n    num_scores = tf.shape(scores)[1]\n    scores_mask = tf.sequence_mask(\n        lengths=tf.to_int32(values_length),\n        maxlen=tf.to_int32(num_scores),\n        dtype=tf.float32)\n    scores = scores * scores_mask + ((1.0 - scores_mask) * tf.float32.min)\n\n    # Normalize the scores\n    scores_normalized = tf.nn.softmax(scores, name=""scores_normalized"")\n\n    # Calculate the weighted average of the attention inputs\n    # according to the scores\n    context = tf.expand_dims(scores_normalized, 2) * values\n    context = tf.reduce_sum(context, 1, name=""context"")\n    context.set_shape([None, values_depth])\n\n\n    return (scores_normalized, context)\n\n\nclass AttentionLayerDot(AttentionLayer):\n  """"""An attention layer that calculates attention scores using\n  a dot product.\n  """"""\n\n  def score_fn(self, keys, query):\n    return att_sum_dot(keys, query)\n\n\nclass AttentionLayerBahdanau(AttentionLayer):\n  """"""An attention layer that calculates attention scores using\n  a parameterized multiplication.""""""\n\n  def score_fn(self, keys, query):\n    v_att = tf.get_variable(\n        ""v_att"", shape=[self.params[""num_units""]], dtype=tf.float32)\n    return att_sum_bahdanau(v_att, keys, query)\n'"
seq2seq/decoders/attention_decoder.py,18,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nA basic sequence decoder that performs a softmax based on the RNN state.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\nimport tensorflow as tf\nfrom seq2seq.decoders.rnn_decoder import RNNDecoder\n\nfrom seq2seq.contrib.seq2seq.helper import CustomHelper\n\n\nclass AttentionDecoderOutput(\n    namedtuple(""DecoderOutput"", [\n        ""logits"", ""predicted_ids"", ""cell_output"", ""attention_scores"",\n        ""attention_context""\n    ])):\n  """"""Augmented decoder output that also includes the attention scores.\n  """"""\n  pass\n\n\nclass AttentionDecoder(RNNDecoder):\n  """"""An RNN Decoder that uses attention over an input sequence.\n\n  Args:\n    cell: An instance of ` tf.contrib.rnn.RNNCell`\n    helper: An instance of `tf.contrib.seq2seq.Helper` to assist decoding\n    initial_state: A tensor or tuple of tensors used as the initial cell\n      state.\n    vocab_size: Output vocabulary size, i.e. number of units\n      in the softmax layer\n    attention_keys: The sequence used to calculate attention scores.\n      A tensor of shape `[B, T, ...]`.\n    attention_values: The sequence to attend over.\n      A tensor of shape `[B, T, input_dim]`.\n    attention_values_length: Sequence length of the attention values.\n      An int32 Tensor of shape `[B]`.\n    attention_fn: The attention function to use. This function map from\n      `(state, inputs)` to `(attention_scores, attention_context)`.\n      For an example, see `seq2seq.decoder.attention.AttentionLayer`.\n    reverse_scores: Optional, an array of sequence length. If set,\n      reverse the attention scores in the output. This is used for when\n      a reversed source sequence is fed as an input but you want to\n      return the scores in non-reversed order.\n  """"""\n\n  def __init__(self,\n               params,\n               mode,\n               vocab_size,\n               attention_keys,\n               attention_values,\n               attention_values_length,\n               attention_fn,\n               reverse_scores_lengths=None,\n               name=""attention_decoder""):\n    super(AttentionDecoder, self).__init__(params, mode, name)\n    self.vocab_size = vocab_size\n    self.attention_keys = attention_keys\n    self.attention_values = attention_values\n    self.attention_values_length = attention_values_length\n    self.attention_fn = attention_fn\n    self.reverse_scores_lengths = reverse_scores_lengths\n\n  @property\n  def output_size(self):\n    return AttentionDecoderOutput(\n        logits=self.vocab_size,\n        predicted_ids=tf.TensorShape([]),\n        cell_output=self.cell.output_size,\n        attention_scores=tf.shape(self.attention_values)[1:-1],\n        attention_context=self.attention_values.get_shape()[-1])\n\n  @property\n  def output_dtype(self):\n    return AttentionDecoderOutput(\n        logits=tf.float32,\n        predicted_ids=tf.int32,\n        cell_output=tf.float32,\n        attention_scores=tf.float32,\n        attention_context=tf.float32)\n\n  def initialize(self, name=None):\n    finished, first_inputs = self.helper.initialize()\n\n    # Concat empty attention context\n    attention_context = tf.zeros([\n        tf.shape(first_inputs)[0],\n        self.attention_values.get_shape().as_list()[-1]\n    ])\n    first_inputs = tf.concat([first_inputs, attention_context], 1)\n\n    return finished, first_inputs, self.initial_state\n\n  def compute_output(self, cell_output):\n    """"""Computes the decoder outputs.""""""\n\n    # Compute attention\n    att_scores, attention_context = self.attention_fn(\n        query=cell_output,\n        keys=self.attention_keys,\n        values=self.attention_values,\n        values_length=self.attention_values_length)\n\n    # TODO: Make this a parameter: We may or may not want this.\n    # Transform attention context.\n    # This makes the softmax smaller and allows us to synthesize information\n    # between decoder state and attention context\n    # see https://arxiv.org/abs/1508.04025v5\n    softmax_input = tf.contrib.layers.fully_connected(\n        inputs=tf.concat([cell_output, attention_context], 1),\n        num_outputs=self.cell.output_size,\n        activation_fn=tf.nn.tanh,\n        scope=""attention_mix"")\n\n    # Softmax computation\n    logits = tf.contrib.layers.fully_connected(\n        inputs=softmax_input,\n        num_outputs=self.vocab_size,\n        activation_fn=None,\n        scope=""logits"")\n\n    return softmax_input, logits, att_scores, attention_context\n\n  def _setup(self, initial_state, helper):\n    self.initial_state = initial_state\n\n    def att_next_inputs(time, outputs, state, sample_ids, name=None):\n      """"""Wraps the original decoder helper function to append the attention\n      context.\n      """"""\n      finished, next_inputs, next_state = helper.next_inputs(\n          time=time,\n          outputs=outputs,\n          state=state,\n          sample_ids=sample_ids,\n          name=name)\n      next_inputs = tf.concat([next_inputs, outputs.attention_context], 1)\n      return (finished, next_inputs, next_state)\n\n    self.helper = CustomHelper(\n        initialize_fn=helper.initialize,\n        sample_fn=helper.sample,\n        next_inputs_fn=att_next_inputs)\n\n  def step(self, time_, inputs, state, name=None):\n    cell_output, cell_state = self.cell(inputs, state)\n    cell_output_new, logits, attention_scores, attention_context = \\\n      self.compute_output(cell_output)\n\n    if self.reverse_scores_lengths is not None:\n      attention_scores = tf.reverse_sequence(\n          input=attention_scores,\n          seq_lengths=self.reverse_scores_lengths,\n          seq_dim=1,\n          batch_dim=0)\n\n    sample_ids = self.helper.sample(\n        time=time_, outputs=logits, state=cell_state)\n\n    outputs = AttentionDecoderOutput(\n        logits=logits,\n        predicted_ids=sample_ids,\n        cell_output=cell_output_new,\n        attention_scores=attention_scores,\n        attention_context=attention_context)\n\n    finished, next_inputs, next_state = self.helper.next_inputs(\n        time=time_, outputs=outputs, state=cell_state, sample_ids=sample_ids)\n\n    return (outputs, next_state, next_inputs, finished)\n'"
seq2seq/decoders/basic_decoder.py,3,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nA basic sequence decoder that performs a softmax based on the RNN state.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom seq2seq.decoders.rnn_decoder import RNNDecoder, DecoderOutput\n\n\nclass BasicDecoder(RNNDecoder):\n  """"""Simple RNN decoder that performed a softmax operations on the cell output.\n  """"""\n\n  def __init__(self, params, mode, vocab_size, name=""basic_decoder""):\n    super(BasicDecoder, self).__init__(params, mode, name)\n    self.vocab_size = vocab_size\n\n  def compute_output(self, cell_output):\n    """"""Computes the decoder outputs.""""""\n    return tf.contrib.layers.fully_connected(\n        inputs=cell_output, num_outputs=self.vocab_size, activation_fn=None)\n\n  @property\n  def output_size(self):\n    return DecoderOutput(\n        logits=self.vocab_size,\n        predicted_ids=tf.TensorShape([]),\n        cell_output=self.cell.output_size)\n\n  @property\n  def output_dtype(self):\n    return DecoderOutput(\n        logits=tf.float32, predicted_ids=tf.int32, cell_output=tf.float32)\n\n  def initialize(self, name=None):\n    finished, first_inputs = self.helper.initialize()\n    return finished, first_inputs, self.initial_state\n\n  def step(self, time_, inputs, state, name=None):\n    cell_output, cell_state = self.cell(inputs, state)\n    logits = self.compute_output(cell_output)\n    sample_ids = self.helper.sample(\n        time=time_, outputs=logits, state=cell_state)\n    outputs = DecoderOutput(\n        logits=logits, predicted_ids=sample_ids, cell_output=cell_output)\n    finished, next_inputs, next_state = self.helper.next_inputs(\n        time=time_, outputs=outputs, state=cell_state, sample_ids=sample_ids)\n    return (outputs, next_state, next_inputs, finished)\n'"
seq2seq/decoders/beam_search_decoder.py,15,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A decoder that uses beam search. Can only be used for inference, not\ntraining.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\nfrom seq2seq.inference import beam_search\nfrom seq2seq.decoders.rnn_decoder import RNNDecoder\n\n\nclass FinalBeamDecoderOutput(\n    namedtuple(""FinalBeamDecoderOutput"",\n               [""predicted_ids"", ""beam_search_output""])):\n  """"""Final outputs returned by the beam search after all decoding is finished.\n\n  Args:\n    predicted_ids: The final prediction. A tensor of shape\n      `[T, 1, beam_width]`.\n    beam_search_output: An instance of `BeamDecoderOutput` that describes\n      the state of the beam search.\n  """"""\n  pass\n\n\nclass BeamDecoderOutput(\n    namedtuple(""BeamDecoderOutput"", [\n        ""logits"", ""predicted_ids"", ""log_probs"", ""scores"", ""beam_parent_ids"",\n        ""original_outputs""\n    ])):\n  """"""Structure for the output of a beam search decoder. This class is used\n  to define the output at each step as well as the final output of the decoder.\n  If used as the final output, a time dimension `T` is inserted after the\n  beam_size dimension.\n\n  Args:\n    logits: Logits at the current time step of shape `[beam_size, vocab_size]`\n    predicted_ids: Chosen softmax predictions at the current time step.\n      An int32 tensor of shape `[beam_size]`.\n    log_probs: Total log probabilities of all beams at the current time step.\n      A float32 tensor of shaep `[beam_size]`.\n    scores: Total scores of all beams at the current time step. This differs\n      from log probabilities in that the score may add additional processing\n      such as length normalization. A float32 tensor of shape `[beam_size]`.\n    beam_parent_ids: The indices of the beams that are being continued.\n      An int32 tensor of shape `[beam_size]`.\n  """"""\n  pass\n\n\nclass BeamSearchDecoder(RNNDecoder):\n  """"""The BeamSearchDecoder wraps another decoder to perform beam search instead\n  of greedy selection. This decoder must be used with batch size of 1, which\n  will result in an effective batch size of `beam_width`.\n\n  Args:\n    decoder: A instance of `RNNDecoder` to be used with beam search.\n    config: A `BeamSearchConfig` that defines beam search decoding parameters.\n  """"""\n\n  def __init__(self, decoder, config):\n    super(BeamSearchDecoder, self).__init__(decoder.params, decoder.mode,\n                                            decoder.name)\n    self.decoder = decoder\n    self.config = config\n\n  def __call__(self, *args, **kwargs):\n    with self.decoder.variable_scope():\n      return self._build(*args, **kwargs)\n\n  @property\n  def output_size(self):\n    return BeamDecoderOutput(\n        logits=self.decoder.vocab_size,\n        predicted_ids=tf.TensorShape([]),\n        log_probs=tf.TensorShape([]),\n        scores=tf.TensorShape([]),\n        beam_parent_ids=tf.TensorShape([]),\n        original_outputs=self.decoder.output_size)\n\n  @property\n  def output_dtype(self):\n    return BeamDecoderOutput(\n        logits=tf.float32,\n        predicted_ids=tf.int32,\n        log_probs=tf.float32,\n        scores=tf.float32,\n        beam_parent_ids=tf.int32,\n        original_outputs=self.decoder.output_dtype)\n\n  @property\n  def batch_size(self):\n    return self.config.beam_width\n\n  def initialize(self, name=None):\n    finished, first_inputs, initial_state = self.decoder.initialize()\n\n    # Create beam state\n    beam_state = beam_search.create_initial_beam_state(config=self.config)\n    return finished, first_inputs, (initial_state, beam_state)\n\n  def finalize(self, outputs, final_state):\n    # Gather according to beam search result\n    predicted_ids = beam_search.gather_tree(outputs.predicted_ids,\n                                            outputs.beam_parent_ids)\n\n    # We\'re using a batch size of 1, so we add an extra dimension to\n    # convert tensors to [1, beam_width, ...] shape. This way Tensorflow\n    # doesn\'t confuse batch_size with beam_width\n    outputs = nest.map_structure(lambda x: tf.expand_dims(x, 1), outputs)\n\n    final_outputs = FinalBeamDecoderOutput(\n        predicted_ids=tf.expand_dims(predicted_ids, 1),\n        beam_search_output=outputs)\n\n    return final_outputs, final_state\n\n  def _build(self, initial_state, helper):\n    # Tile initial state\n    initial_state = nest.map_structure(\n        lambda x: tf.tile(x, [self.batch_size, 1]), initial_state)\n    self.decoder._setup(initial_state, helper)  #pylint: disable=W0212\n    return super(BeamSearchDecoder, self)._build(self.decoder.initial_state,\n                                                 self.decoder.helper)\n\n  def step(self, time_, inputs, state, name=None):\n    decoder_state, beam_state = state\n\n    # Call the original decoder\n    (decoder_output, decoder_state, _, _) = self.decoder.step(time_, inputs,\n                                                              decoder_state)\n\n    # Perform a step of beam search\n    bs_output, beam_state = beam_search.beam_search_step(\n        time_=time_,\n        logits=decoder_output.logits,\n        beam_state=beam_state,\n        config=self.config)\n\n    # Shuffle everything according to beam search result\n    decoder_state = nest.map_structure(\n        lambda x: tf.gather(x, bs_output.beam_parent_ids), decoder_state)\n    decoder_output = nest.map_structure(\n        lambda x: tf.gather(x, bs_output.beam_parent_ids), decoder_output)\n\n    next_state = (decoder_state, beam_state)\n\n    outputs = BeamDecoderOutput(\n        logits=tf.zeros([self.config.beam_width, self.config.vocab_size]),\n        predicted_ids=bs_output.predicted_ids,\n        log_probs=beam_state.log_probs,\n        scores=bs_output.scores,\n        beam_parent_ids=bs_output.beam_parent_ids,\n        original_outputs=decoder_output)\n\n    finished, next_inputs, next_state = self.decoder.helper.next_inputs(\n        time=time_,\n        outputs=decoder_output,\n        state=next_state,\n        sample_ids=bs_output.predicted_ids)\n    next_inputs.set_shape([self.batch_size, None])\n\n    return (outputs, next_state, next_inputs, finished)\n'"
seq2seq/decoders/rnn_decoder.py,6,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nBase class for sequence decoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nfrom collections import namedtuple\n\nimport six\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\nfrom seq2seq.graph_module import GraphModule\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.contrib.seq2seq.decoder import Decoder, dynamic_decode\nfrom seq2seq.encoders.rnn_encoder import _default_rnn_cell_params\nfrom seq2seq.encoders.rnn_encoder import _toggle_dropout\nfrom seq2seq.training import utils as training_utils\n\n\nclass DecoderOutput(\n    namedtuple(""DecoderOutput"", [""logits"", ""predicted_ids"", ""cell_output""])):\n  """"""Output of an RNN decoder.\n\n  Note that we output both the logits and predictions because during\n  dynamic decoding the predictions may not correspond to max(logits).\n  For example, we may be sampling from the logits instead.\n  """"""\n  pass\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass RNNDecoder(Decoder, GraphModule, Configurable):\n  """"""Base class for RNN decoders.\n\n  Args:\n    cell: An instance of ` tf.contrib.rnn.RNNCell`\n    helper: An instance of `tf.contrib.seq2seq.Helper` to assist decoding\n    initial_state: A tensor or tuple of tensors used as the initial cell\n      state.\n    name: A name for this module\n  """"""\n\n  def __init__(self, params, mode, name):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n    self.params[""rnn_cell""] = _toggle_dropout(self.params[""rnn_cell""], mode)\n    self.cell = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n    # Not initialized yet\n    self.initial_state = None\n    self.helper = None\n\n  @abc.abstractmethod\n  def initialize(self, name=None):\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def step(self, name=None):\n    raise NotImplementedError\n\n  @property\n  def batch_size(self):\n    return tf.shape(nest.flatten([self.initial_state])[0])[0]\n\n  def _setup(self, initial_state, helper):\n    """"""Sets the initial state and helper for the decoder.\n    """"""\n    self.initial_state = initial_state\n    self.helper = helper\n\n  def finalize(self, outputs, final_state):\n    """"""Applies final transformation to the decoder output once decoding is\n    finished.\n    """"""\n    #pylint: disable=R0201\n    return (outputs, final_state)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""max_decode_length"": 100,\n        ""rnn_cell"": _default_rnn_cell_params(),\n        ""init_scale"": 0.04,\n    }\n\n  def _build(self, initial_state, helper):\n    if not self.initial_state:\n      self._setup(initial_state, helper)\n\n    scope = tf.get_variable_scope()\n    scope.set_initializer(tf.random_uniform_initializer(\n        -self.params[""init_scale""],\n        self.params[""init_scale""]))\n\n    maximum_iterations = None\n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      maximum_iterations = self.params[""max_decode_length""]\n\n    outputs, final_state = dynamic_decode(\n        decoder=self,\n        output_time_major=True,\n        impute_finished=False,\n        maximum_iterations=maximum_iterations)\n    return self.finalize(outputs, final_state)\n'"
seq2seq/encoders/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of encoders""""""\n\nimport seq2seq.encoders.encoder\nimport seq2seq.encoders.rnn_encoder\n\nfrom seq2seq.encoders.rnn_encoder import *\nfrom seq2seq.encoders.image_encoder import *\nfrom seq2seq.encoders.pooling_encoder import PoolingEncoder\nfrom seq2seq.encoders.conv_encoder import ConvEncoder\n'"
seq2seq/encoders/conv_encoder.py,10,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAn encoder that pools over embeddings, as described in\nhttps://arxiv.org/abs/1611.02344.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pydoc import locate\n\nimport tensorflow as tf\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\nfrom seq2seq.encoders.pooling_encoder import _create_position_embedding\n\n\nclass ConvEncoder(Encoder):\n  """"""A deep convolutional encoder, as described in\n  https://arxiv.org/abs/1611.02344. The encoder supports optional positions\n  embeddings.\n\n  Params:\n    attention_cnn.units: Number of units in `cnn_a`. Same in each layer.\n    attention_cnn.kernel_size: Kernel size for `cnn_a`.\n    attention_cnn.layers: Number of layers in `cnn_a`.\n    embedding_dropout_keep_prob: Dropout keep probability\n      applied to the embeddings.\n    output_cnn.units: Number of units in `cnn_c`. Same in each layer.\n    output_cnn.kernel_size: Kernel size for `cnn_c`.\n    output_cnn.layers: Number of layers in `cnn_c`.\n    position_embeddings.enable: If true, add position embeddings to the\n      inputs before pooling.\n    position_embeddings.combiner_fn: Function used to combine the\n      position embeddings with the inputs. For example, `tensorflow.add`.\n    position_embeddings.num_positions: Size of the position embedding matrix.\n      This should be set to the maximum sequence length of the inputs.\n  """"""\n\n  def __init__(self, params, mode, name=""conv_encoder""):\n    super(ConvEncoder, self).__init__(params, mode, name)\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n\n  @staticmethod\n  def default_params():\n    return {\n        ""attention_cnn.units"": 512,\n        ""attention_cnn.kernel_size"": 3,\n        ""attention_cnn.layers"": 15,\n        ""embedding_dropout_keep_prob"": 0.8,\n        ""output_cnn.units"": 256,\n        ""output_cnn.kernel_size"": 3,\n        ""output_cnn.layers"": 5,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.multiply"",\n        ""position_embeddings.num_positions"": 100,\n    }\n\n  def encode(self, inputs, sequence_length):\n    if self.params[""position_embeddings.enable""]:\n      positions_embed = _create_position_embedding(\n          embedding_dim=inputs.get_shape().as_list()[-1],\n          num_positions=self.params[""position_embeddings.num_positions""],\n          lengths=sequence_length,\n          maxlen=tf.shape(inputs)[1])\n      inputs = self._combiner_fn(inputs, positions_embed)\n\n    # Apply dropout to embeddings\n    inputs = tf.contrib.layers.dropout(\n        inputs=inputs,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n\n    with tf.variable_scope(""cnn_a""):\n      cnn_a_output = inputs\n      for layer_idx in range(self.params[""attention_cnn.layers""]):\n        next_layer = tf.contrib.layers.conv2d(\n            inputs=cnn_a_output,\n            num_outputs=self.params[""attention_cnn.units""],\n            kernel_size=self.params[""attention_cnn.kernel_size""],\n            padding=""SAME"",\n            activation_fn=None)\n        # Add a residual connection, except for the first layer\n        if layer_idx > 0:\n          next_layer += cnn_a_output\n        cnn_a_output = tf.tanh(next_layer)\n\n    with tf.variable_scope(""cnn_c""):\n      cnn_c_output = inputs\n      for layer_idx in range(self.params[""output_cnn.layers""]):\n        next_layer = tf.contrib.layers.conv2d(\n            inputs=cnn_c_output,\n            num_outputs=self.params[""output_cnn.units""],\n            kernel_size=self.params[""output_cnn.kernel_size""],\n            padding=""SAME"",\n            activation_fn=None)\n        # Add a residual connection, except for the first layer\n        if layer_idx > 0:\n          next_layer += cnn_c_output\n        cnn_c_output = tf.tanh(next_layer)\n\n    final_state = tf.reduce_mean(cnn_c_output, 1)\n\n    return EncoderOutput(\n        outputs=cnn_a_output,\n        final_state=final_state,\n        attention_values=cnn_c_output,\n        attention_values_length=sequence_length)\n'"
seq2seq/encoders/encoder.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAbstract base class for encoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom collections import namedtuple\n\nimport six\n\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.graph_module import GraphModule\n\nEncoderOutput = namedtuple(\n    ""EncoderOutput"",\n    ""outputs final_state attention_values attention_values_length"")\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Encoder(GraphModule, Configurable):\n  """"""Abstract encoder class. All encoders should inherit from this.\n\n  Args:\n    params: A dictionary of hyperparameters for the encoder.\n    name: A variable scope for the encoder graph.\n  """"""\n\n  def __init__(self, params, mode, name):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n\n  def _build(self, inputs, *args, **kwargs):\n    return self.encode(inputs, *args, **kwargs)\n\n  @abc.abstractmethod\n  def encode(self, *args, **kwargs):\n    """"""\n    Encodes an input sequence.\n\n    Args:\n      inputs: The inputs to encode. A float32 tensor of shape [B, T, ...].\n      sequence_length: The length of each input. An int32 tensor of shape [T].\n\n    Returns:\n      An `EncoderOutput` tuple containing the outputs and final state.\n    """"""\n    raise NotImplementedError\n'"
seq2seq/encoders/image_encoder.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nImage encoder classes\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.nets.inception_v3 \\\n  import inception_v3_base\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\n\n\nclass InceptionV3Encoder(Encoder):\n  """"""\n  A unidirectional RNN encoder. Stacking should be performed as\n  part of the cell.\n\n  Params:\n    resize_height: Resize the image to this height before feeding it\n      into the convolutional network.\n    resize_width: Resize the image to this width before feeding it\n      into the convolutional network.\n  """"""\n\n  def __init__(self, params, mode, name=""image_encoder""):\n    super(InceptionV3Encoder, self).__init__(params, mode, name)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""resize_height"": 299,\n        ""resize_width"": 299,\n    }\n\n  def encode(self, inputs):\n    inputs = tf.image.resize_images(\n        images=inputs,\n        size=[self.params[""resize_height""], self.params[""resize_width""]],\n        method=tf.image.ResizeMethod.BILINEAR)\n\n    outputs, _ = inception_v3_base(tf.to_float(inputs))\n    output_shape = outputs.get_shape()  #pylint: disable=E1101\n    shape_list = output_shape.as_list()\n\n    # Take attentin over output elemnts in width and height dimension:\n    # Shape: [B, W*H, ...]\n    outputs_flat = tf.reshape(outputs, [shape_list[0], -1, shape_list[-1]])\n\n    # Final state is the pooled output\n    # Shape: [B, W*H*...]\n    final_state = tf.contrib.slim.avg_pool2d(\n        outputs, output_shape[1:3], padding=""VALID"", scope=""pool"")\n    final_state = tf.contrib.slim.flatten(outputs, scope=""flatten"")\n\n    return EncoderOutput(\n        outputs=outputs_flat,\n        final_state=final_state,\n        attention_values=outputs_flat,\n        attention_values_length=tf.shape(outputs_flat)[1])\n'"
seq2seq/encoders/pooling_encoder.py,10,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAn encoder that pools over embeddings, as described in\nhttps://arxiv.org/abs/1611.02344.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pydoc import locate\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\n\n\ndef position_encoding(sentence_size, embedding_size):\n  """"""\n  Position Encoding described in section 4.1 of\n  End-To-End Memory Networks (https://arxiv.org/abs/1503.08895).\n\n  Args:\n    sentence_size: length of the sentence\n    embedding_size: dimensionality of the embeddings\n\n  Returns:\n    A numpy array of shape [sentence_size, embedding_size] containing\n    the fixed position encodings for each sentence position.\n  """"""\n  encoding = np.ones((sentence_size, embedding_size), dtype=np.float32)\n  ls = sentence_size + 1\n  le = embedding_size + 1\n  for k in range(1, le):\n    for j in range(1, ls):\n      encoding[j-1, k-1] = (1.0 - j/float(ls)) - (\n          k / float(le)) * (1. - 2. * j/float(ls))\n  return encoding\n\n\ndef _create_position_embedding(embedding_dim, num_positions, lengths, maxlen):\n  """"""Creates position embeddings.\n\n  Args:\n    embedding_dim: Dimensionality of the embeddings. An integer.\n    num_positions: The number of positions to be embedded. For example,\n      if you have inputs of length up to 100, this should be 100. An integer.\n    lengths: The lengths of the inputs to create position embeddings for.\n      An int32 tensor of shape `[batch_size]`.\n    maxlen: The maximum length of the input sequence to create position\n      embeddings for. An int32 tensor.\n\n  Returns:\n    A tensor of shape `[batch_size, maxlen, embedding_dim]` that contains\n    embeddings for each position. All elements past `lengths` are zero.\n  """"""\n  # Create constant position encodings\n  position_encodings = tf.constant(\n      position_encoding(num_positions, embedding_dim),\n      name=""position_encoding"")\n\n  # Slice to size of current sequence\n  pe_slice = position_encodings[:maxlen, :]\n  # Replicate encodings for each element in the batch\n  batch_size = tf.shape(lengths)[0]\n  pe_batch = tf.tile([pe_slice], [batch_size, 1, 1])\n\n  # Mask out positions that are padded\n  positions_mask = tf.sequence_mask(\n      lengths=lengths, maxlen=maxlen, dtype=tf.float32)\n  positions_embed = pe_batch * tf.expand_dims(positions_mask, 2)\n\n  return positions_embed\n\nclass PoolingEncoder(Encoder):\n  """"""An encoder that pools over embeddings, as described in\n  https://arxiv.org/abs/1611.02344. The encoder supports optional positions\n  embeddings and a configurable pooling window.\n\n  Params:\n    dropout_keep_prob: Dropout keep probability applied to the embeddings.\n    pooling_fn: The 1-d pooling function to use, e.g.\n      `tensorflow.layers.average_pooling1d`.\n    pool_size: The pooling window, passed as `pool_size` to\n      the pooling function.\n    strides: The stride during pooling, passed as `strides`\n      the pooling function.\n    position_embeddings.enable: If true, add position embeddings to the\n      inputs before pooling.\n    position_embeddings.combiner_fn: Function used to combine the\n      position embeddings with the inputs. For example, `tensorflow.add`.\n    position_embeddings.num_positions: Size of the position embedding matrix.\n      This should be set to the maximum sequence length of the inputs.\n  """"""\n\n  def __init__(self, params, mode, name=""pooling_encoder""):\n    super(PoolingEncoder, self).__init__(params, mode, name)\n    self._pooling_fn = locate(self.params[""pooling_fn""])\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n\n  @staticmethod\n  def default_params():\n    return {\n        ""dropout_keep_prob"": 0.8,\n        ""pooling_fn"": ""tensorflow.layers.average_pooling1d"",\n        ""pool_size"": 5,\n        ""strides"": 1,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.multiply"",\n        ""position_embeddings.num_positions"": 100,\n    }\n\n  def encode(self, inputs, sequence_length):\n    if self.params[""position_embeddings.enable""]:\n      positions_embed = _create_position_embedding(\n          embedding_dim=inputs.get_shape().as_list()[-1],\n          num_positions=self.params[""position_embeddings.num_positions""],\n          lengths=sequence_length,\n          maxlen=tf.shape(inputs)[1])\n      inputs = self._combiner_fn(inputs, positions_embed)\n\n    # Apply dropout\n    inputs = tf.contrib.layers.dropout(\n        inputs=inputs,\n        keep_prob=self.params[""dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n\n    outputs = self._pooling_fn(\n        inputs=inputs,\n        pool_size=self.params[""pool_size""],\n        strides=self.params[""strides""],\n        padding=""SAME"")\n\n    # Final state is the average representation of the pooled embeddings\n    final_state = tf.reduce_mean(outputs, 1)\n\n    return EncoderOutput(\n        outputs=outputs,\n        final_state=final_state,\n        attention_values=inputs,\n        attention_values_length=sequence_length)\n'"
