file_path,api_count,code
__init__.py,0,b''
kglib/__init__.py,0,b''
kglib/kgcn/learn/feed.py,3,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nfrom graph_nets import utils_tf, utils_np\n\n\ndef create_placeholders(input_graphs, target_graphs):\n    """"""\n    Creates placeholders for the model training and evaluation.\n    Returns:\n    input_ph: The input graph\'s placeholders, as a graph namedtuple.\n    target_ph: The target graph\'s placeholders, as a graph namedtuple.\n    """"""\n    input_ph = utils_tf.placeholders_from_networkxs(input_graphs, name=""input_placeholders_from_networksx"")\n    target_ph = utils_tf.placeholders_from_networkxs(target_graphs, name=""target_placeholders_from_networkxs"")\n    return input_ph, target_ph\n\n\ndef create_feed_dict(input_ph, target_ph, inputs, targets):\n    """"""Creates the feed dict for the placeholders for the model training and evaluation.\n\n    Args:\n        input_ph: The input graph\'s placeholders, as a graph namedtuple.\n        target_ph: The target graph\'s placeholders, as a graph namedtuple.\n        inputs: The input graphs\n        targets: The target graphs\n\n    Returns:\n        feed_dict: The feed `dict` of input and target placeholders and data.\n    """"""\n    input_graphs = utils_np.networkxs_to_graphs_tuple(inputs)\n    target_graphs = utils_np.networkxs_to_graphs_tuple(targets)\n    feed_dict = {input_ph: input_graphs, target_ph: target_graphs}\n    return feed_dict\n\n\ndef make_all_runnable_in_session(*args):\n    """"""Lets an iterable of TF graphs be output from a session as NP graphs.""""""\n    return [utils_tf.make_runnable_in_session(a) for a in args]'"
kglib/kgcn/learn/learn.py,10,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport time\n\nimport tensorflow as tf\n\nfrom kglib.kgcn.learn.feed import create_placeholders, create_feed_dict, make_all_runnable_in_session\nfrom kglib.kgcn.learn.loss import loss_ops_preexisting_no_penalty\nfrom kglib.kgcn.learn.metrics import existence_accuracy\n\n\nclass KGCNLearner:\n    """"""\n    Responsible for running a KGCN model\n    """"""\n    def __init__(self, model, num_processing_steps_tr=10, num_processing_steps_ge=10):\n        self._model = model\n        self._num_processing_steps_tr = num_processing_steps_tr\n        self._num_processing_steps_ge = num_processing_steps_ge\n\n    def __call__(self,\n                 tr_input_graphs,\n                 tr_target_graphs,\n                 ge_input_graphs,\n                 ge_target_graphs,\n                 num_training_iterations=1000,\n                 learning_rate=1e-3,\n                 log_every_epochs=20,\n                 log_dir=None):\n        """"""\n        Args:\n            tr_graphs: In-memory graphs of Grakn concepts for training\n            ge_graphs: In-memory graphs of Grakn concepts for generalisation\n            num_processing_steps_tr: Number of processing (message-passing) steps for training.\n            num_processing_steps_ge: Number of processing (message-passing) steps for generalization.\n            num_training_iterations: Number of training iterations\n            log_every_seconds: The time to wait between logging and printing the next set of results.\n            log_dir: Directory to store TensorFlow events files\n\n        Returns:\n\n        """"""\n\n        tf.set_random_seed(1)\n\n        input_ph, target_ph = create_placeholders(tr_input_graphs, tr_target_graphs)\n\n        # A list of outputs, one per processing step.\n        output_ops_tr = self._model(input_ph, self._num_processing_steps_tr)\n        output_ops_ge = self._model(input_ph, self._num_processing_steps_ge)\n\n        # Training loss.\n        loss_ops_tr = loss_ops_preexisting_no_penalty(target_ph, output_ops_tr)\n        # Loss across processing steps.\n        loss_op_tr = sum(loss_ops_tr) / self._num_processing_steps_tr\n\n        tf.summary.scalar(\'loss_op_tr\', loss_op_tr)\n        # Test/generalization loss.\n        loss_ops_ge = loss_ops_preexisting_no_penalty(target_ph, output_ops_ge)\n        loss_op_ge = loss_ops_ge[-1]  # Loss from final processing step.\n        tf.summary.scalar(\'loss_op_ge\', loss_op_ge)\n\n        # Optimizer\n        optimizer = tf.train.AdamOptimizer(learning_rate)\n        gradients, variables = zip(*optimizer.compute_gradients(loss_op_tr))\n\n        for grad, var in zip(gradients, variables):\n            try:\n                print(var.name)\n                tf.summary.histogram(\'gradients/\' + var.name, grad)\n            except:\n                pass\n\n        gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n        step_op = optimizer.apply_gradients(zip(gradients, variables))\n\n        input_ph, target_ph = make_all_runnable_in_session(input_ph, target_ph)\n\n        sess = tf.Session()\n        merged_summaries = tf.summary.merge_all()\n\n        train_writer = None\n\n        if log_dir is not None:\n            train_writer = tf.summary.FileWriter(log_dir, sess.graph)\n\n        sess.run(tf.global_variables_initializer())\n\n        logged_iterations = []\n        losses_tr = []\n        corrects_tr = []\n        solveds_tr = []\n        losses_ge = []\n        corrects_ge = []\n        solveds_ge = []\n\n        print(""# (iteration number), T (elapsed seconds), ""\n              ""Ltr (training loss), Lge (test/generalization loss), ""\n              ""Ctr (training fraction nodes/edges labeled correctly), ""\n              ""Str (training fraction examples solved correctly), ""\n              ""Cge (test/generalization fraction nodes/edges labeled correctly), ""\n              ""Sge (test/generalization fraction examples solved correctly)"")\n\n        start_time = time.time()\n        for iteration in range(num_training_iterations):\n            feed_dict = create_feed_dict(input_ph, target_ph, tr_input_graphs, tr_target_graphs)\n\n            if iteration % log_every_epochs == 0:\n\n                train_values = sess.run(\n                    {\n                        ""step"": step_op,\n                        ""target"": target_ph,\n                        ""loss"": loss_op_tr,\n                        ""outputs"": output_ops_tr,\n                        ""summary"": merged_summaries\n                    },\n                    feed_dict=feed_dict)\n\n                if train_writer is not None:\n                    train_writer.add_summary(train_values[""summary""], iteration)\n\n                feed_dict = create_feed_dict(input_ph, target_ph, ge_input_graphs, ge_target_graphs)\n                test_values = sess.run(\n                    {\n                        ""target"": target_ph,\n                        ""loss"": loss_op_ge,\n                        ""outputs"": output_ops_ge\n                    },\n                    feed_dict=feed_dict)\n                correct_tr, solved_tr = existence_accuracy(\n                    train_values[""target""], train_values[""outputs""][-1], use_edges=False)\n                correct_ge, solved_ge = existence_accuracy(\n                    test_values[""target""], test_values[""outputs""][-1], use_edges=False)\n\n                elapsed = time.time() - start_time\n                losses_tr.append(train_values[""loss""])\n                corrects_tr.append(correct_tr)\n                solveds_tr.append(solved_tr)\n                losses_ge.append(test_values[""loss""])\n                corrects_ge.append(correct_ge)\n                solveds_ge.append(solved_ge)\n                logged_iterations.append(iteration)\n                print(""# {:05d}, T {:.1f}, Ltr {:.4f}, Lge {:.4f}, Ctr {:.4f}, Str""\n                      "" {:.4f}, Cge {:.4f}, Sge {:.4f}"".format(\n                        iteration, elapsed, train_values[""loss""], test_values[""loss""],\n                        correct_tr, solved_tr, correct_ge, solved_ge))\n            else:\n                train_values = sess.run(\n                    {\n                        ""step"": step_op,\n                        ""target"": target_ph,\n                        ""loss"": loss_op_tr,\n                        ""outputs"": output_ops_tr\n                    },\n                    feed_dict=feed_dict)\n\n        training_info = logged_iterations, losses_tr, losses_ge, corrects_tr, corrects_ge, solveds_tr, solveds_ge\n        return train_values, test_values, training_info\n'"
kglib/kgcn/learn/learn_IT.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport networkx as nx\nimport numpy as np\n\nfrom kglib.kgcn.learn.learn import KGCNLearner\nfrom kglib.kgcn.models.core import KGCN\nfrom kglib.kgcn.models.embedding import ThingEmbedder, RoleEmbedder\n\n\nclass ITKGCNLearner(unittest.TestCase):\n    def test_learner_runs(self):\n        input_graph = nx.MultiDiGraph()\n        input_graph.add_node(0, features=np.array([0, 1, 2], dtype=np.float32))\n        input_graph.add_edge(1, 0, features=np.array([0, 1, 2], dtype=np.float32))\n        input_graph.add_node(1, features=np.array([0, 1, 2], dtype=np.float32))\n        input_graph.add_edge(1, 2, features=np.array([0, 1, 2], dtype=np.float32))\n        input_graph.add_node(2, features=np.array([0, 1, 2], dtype=np.float32))\n        input_graph.graph[\'features\'] = np.zeros(5, dtype=np.float32)\n\n        target_graph = nx.MultiDiGraph()\n        target_graph.add_node(0, features=np.array([0, 1, 0], dtype=np.float32))\n        target_graph.add_edge(1, 0, features=np.array([0, 0, 1], dtype=np.float32))\n        target_graph.add_node(1, features=np.array([0, 0, 1], dtype=np.float32))\n        target_graph.add_edge(1, 2, features=np.array([0, 0, 1], dtype=np.float32))\n        target_graph.add_node(2, features=np.array([0, 1, 0], dtype=np.float32))\n        target_graph.graph[\'features\'] = np.zeros(5, dtype=np.float32)\n\n        thing_embedder = ThingEmbedder(node_types=[\'a\', \'b\', \'c\'], type_embedding_dim=5,\n                                       attr_embedding_dim=6, categorical_attributes={}, continuous_attributes={})\n\n        role_embedder = RoleEmbedder(num_edge_types=2, type_embedding_dim=5)\n\n        kgcn = KGCN(thing_embedder, role_embedder, edge_output_size=3, node_output_size=3)\n\n        learner = KGCNLearner(kgcn, num_processing_steps_tr=2, num_processing_steps_ge=2)\n\n        learner([input_graph], [target_graph], [input_graph], [target_graph], num_training_iterations=50)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/learn/loss.py,6,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef loss_ops_from_difference(target_op, output_ops):\n    """"""\n    Loss operation which directly compares the target with the output over all nodes and edges\n    Args:\n        target_op: The target of the model\n        output_ops: A list of the outputs of the model, one for each message-passing step\n\n    Returns: The loss for each message-passing step\n\n    """"""\n    loss_ops = [\n        tf.losses.softmax_cross_entropy(target_op.nodes, output_op.nodes)\n        for output_op in output_ops\n    ]\n    return loss_ops\n\n\ndef loss_ops_preexisting_no_penalty(target_op, output_ops):\n    """"""\n    Loss operation which doesn\'t penalise the output values for pre-existing nodes and edges, treating them as slack\n    variables\n\n    Args:\n        target_op: The target of the model\n        output_ops: A list of the outputs of the model, one for each message-passing step\n\n    Returns: The loss for each message-passing step\n\n    """"""\n    loss_ops = []\n    for output_op in output_ops:\n        node_mask_op = tf.math.reduce_any(\n            tf.math.not_equal(target_op.nodes, tf.constant(np.array([1., 0., 0.]), dtype=tf.float32)), axis=1)\n        target_nodes = tf.boolean_mask(target_op.nodes, node_mask_op)\n        output_nodes = tf.boolean_mask(output_op.nodes, node_mask_op)\n\n        loss_op = tf.losses.softmax_cross_entropy(target_nodes, output_nodes)\n\n        loss_ops.append(loss_op)\n\n    return loss_ops'"
kglib/kgcn/learn/metrics.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport numpy as np\nfrom graph_nets import utils_np\n\nfrom scipy.special import softmax\n\n\ndef compute_accuracy(target, output, use_nodes=True, use_edges=True):\n    """"""Calculate model accuracy.\n\n    Returns the number of elements correctly predicted to exist, and the number of completely correct graphs\n    (100% correct predictions).\n\n    Args:\n        target: A `graphs.GraphsTuple` that contains the target graph.\n        output: A `graphs.GraphsTuple` that contains the output graph.\n        use_nodes: A `bool` indicator of whether to compute node accuracy or not.\n        use_edges: A `bool` indicator of whether to compute edge accuracy or not.\n\n    Returns:\n        correct: A `float` fraction of correctly labeled nodes/edges.\n        solved: A `float` fraction of graphs that are completely correctly labeled.\n\n    Raises:\n        ValueError: Nodes or edges (or both) must be used\n    """"""\n    if not use_nodes and not use_edges:\n        raise ValueError(""Nodes or edges (or both) must be used"")\n    tdds = utils_np.graphs_tuple_to_data_dicts(target)\n    odds = utils_np.graphs_tuple_to_data_dicts(output)\n    cs = []\n    ss = []\n    for td, od in zip(tdds, odds):\n        xn = np.argmax(td[""nodes""], axis=-1)\n        yn = np.argmax(od[""nodes""], axis=-1)\n        xe = np.argmax(td[""edges""], axis=-1)\n        ye = np.argmax(od[""edges""], axis=-1)\n        c = []\n        if use_nodes:\n            c.append(xn == yn)\n        if use_edges:\n            c.append(xe == ye)\n        c = np.concatenate(c, axis=0)\n        s = np.all(c)\n        cs.append(c)\n        ss.append(s)\n    correct = np.mean(np.concatenate(cs, axis=0))\n    solved = np.mean(np.stack(ss))\n    return correct, solved\n\n\ndef existence_accuracy(target, output, use_nodes=True, use_edges=True):\n    if not use_nodes and not use_edges:\n        raise ValueError(""Nodes or edges (or both) must be used"")\n    tdds = utils_np.graphs_tuple_to_data_dicts(target)\n    odds = utils_np.graphs_tuple_to_data_dicts(output)\n    cs = []\n    ss = []\n    for td, od in zip(tdds, odds):\n\n        nodes_to_predict = td[""nodes""][:, 0] == 0\n        xn = np.argmax(td[""nodes""][:, 1:], axis=-1)\n        xn = xn[nodes_to_predict]\n        yn = np.argmax(softmax(od[""nodes""][:, 1:], axis=1), axis=-1)\n        yn = yn[nodes_to_predict]\n\n        edges_to_predict = td[""edges""][:, 0] == 0\n        xe = np.argmax(td[""edges""][:, 1:], axis=-1)\n        xe = xe[edges_to_predict]\n        ye = np.argmax(softmax(od[""edges""][:, 1:], axis=1), axis=-1)\n        ye = ye[edges_to_predict]\n\n        c = []\n        if use_nodes:\n            c.append(xn == yn)\n        if use_edges:\n            c.append(xe == ye)\n        c = np.concatenate(c, axis=0)\n        s = np.all(c)\n        cs.append(c)\n        ss.append(s)\n    correct = np.mean(np.concatenate(cs, axis=0))\n    solved = np.mean(np.stack(ss))\n    return correct, solved\n'"
kglib/kgcn/learn/metrics_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\nfrom graph_nets.graphs import GraphsTuple\n\nfrom kglib.kgcn.learn.metrics import compute_accuracy, existence_accuracy\n\n\nclass TestComputeAccuracy(unittest.TestCase):\n\n    def test_compute_accuracy_is_as_expected(self):\n\n        t_nodes = np.array([[1, 0], [1, 0], [0, 1]], dtype=np.float32)\n        o_nodes = np.array([[0, 1], [1, 0], [1, 0]], dtype=np.float32)\n        t_edges = np.array([[0, 1], [1, 0]], dtype=np.float32)\n        o_edges = np.array([[1, 0], [1, 0]], dtype=np.float32)\n\n        globals = None\n        senders = np.array([0, 1])\n        receivers = np.array([1, 2])\n        n_node = np.array([3])\n        n_edge = np.array([2])\n\n        target = GraphsTuple(nodes=t_nodes,\n                             edges=t_edges,\n                             globals=globals,\n                             receivers=receivers,\n                             senders=senders,\n                             n_node=n_node,\n                             n_edge=n_edge)\n\n        output = GraphsTuple(nodes=o_nodes,\n                             edges=o_edges,\n                             globals=globals,\n                             receivers=receivers,\n                             senders=senders,\n                             n_node=n_node,\n                             n_edge=n_edge)\n\n        correct, solved = compute_accuracy(target, output)\n\n        expected_correct = 2 / 5\n        expected_solved = 0\n\n        self.assertEqual(expected_correct, correct)\n        self.assertEqual(expected_solved, solved)\n\n\nclass TestExistenceAccuracy(unittest.TestCase):\n\n    def test_compute_accuracy_is_as_expected(self):\n\n        t_nodes = np.array([[1, 0, 0], [0, 0, 1], [0, 0, 1]], dtype=np.float32)\n        o_nodes = np.array([[0, 1, 0], [0, 1, 0], [0, 0, 1]], dtype=np.float32)\n        t_edges = np.array([[0, 1, 0], [1, 0, 0]], dtype=np.float32)\n        o_edges = np.array([[1, 0, 0], [1, 0, 0]], dtype=np.float32)\n\n        globals = None\n        senders = np.array([0, 1])\n        receivers = np.array([1, 2])\n        n_node = np.array([3])\n        n_edge = np.array([2])\n\n        target = GraphsTuple(nodes=t_nodes,\n                             edges=t_edges,\n                             globals=globals,\n                             receivers=receivers,\n                             senders=senders,\n                             n_node=n_node,\n                             n_edge=n_edge)\n\n        output = GraphsTuple(nodes=o_nodes,\n                             edges=o_edges,\n                             globals=globals,\n                             receivers=receivers,\n                             senders=senders,\n                             n_node=n_node,\n                             n_edge=n_edge)\n\n        correct, solved = existence_accuracy(target, output)\n\n        expected_correct = 2/3\n        expected_solved = 0.0\n\n        self.assertEqual(expected_correct, correct)\n        self.assertEqual(expected_solved, solved)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/models/attribute.py,9,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport abc\n\nimport sonnet as snt\nimport tensorflow as tf\n\n\nclass Attribute(snt.AbstractModule, abc.ABC):\n    """"""\n    Abstract base class for Attribute value embedding models\n    """"""\n    def __init__(self, attr_embedding_dim, name=\'AttributeEmbedder\'):\n        super(Attribute, self).__init__(name=name)\n        self._attr_embedding_dim = attr_embedding_dim\n\n\nclass ContinuousAttribute(Attribute):\n    def __init__(self, attr_embedding_dim, name=\'ContinuousAttributeEmbedder\'):\n        super(ContinuousAttribute, self).__init__(attr_embedding_dim, name=name)\n\n    def _build(self, attribute_value):\n        tf.summary.histogram(\'cont_attribute_value_histogram\', attribute_value)\n        embedding = snt.Sequential([\n            snt.nets.MLP([self._attr_embedding_dim] * 3, activate_final=True, use_dropout=True),\n            snt.LayerNorm(),\n        ])(tf.cast(attribute_value, dtype=tf.float32))\n        tf.summary.histogram(\'cont_embedding_histogram\', embedding)\n        return embedding\n\n\nclass CategoricalAttribute(Attribute):\n    def __init__(self, num_categories, attr_embedding_dim, name=\'CategoricalAttributeEmbedder\'):\n        super(CategoricalAttribute, self).__init__(attr_embedding_dim, name=name)\n\n        self._num_categories = num_categories\n\n    def _build(self, attribute_value):\n        int_attribute_value = tf.cast(attribute_value, dtype=tf.int32)\n        tf.summary.histogram(\'cat_attribute_value_histogram\', int_attribute_value)\n        embedding = snt.Embed(self._num_categories, self._attr_embedding_dim)(int_attribute_value)\n        tf.summary.histogram(\'cat_embedding_histogram\', embedding)\n        return tf.squeeze(embedding, axis=1)\n\n\nclass BlankAttribute(Attribute):\n\n    def __init__(self, attr_embedding_dim, name=\'BlankAttributeEmbedder\'):\n        super(BlankAttribute, self).__init__(attr_embedding_dim, name=name)\n\n    def _build(self, attribute_value):\n        shape = tf.stack([tf.shape(attribute_value)[0], self._attr_embedding_dim])\n\n        encoded_features = tf.zeros(shape, dtype=tf.float32)\n        return encoded_features\n'"
kglib/kgcn/models/attribute_IT.py,3,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nfrom kglib.kgcn.models.attribute import CategoricalAttribute\nimport tensorflow as tf\nimport numpy as np\n\n\nclass ITCategoricalAttribute(unittest.TestCase):\n    def test_output_tensorspec(self):\n        cat = CategoricalAttribute(2, 5)\n        inp = tf.zeros((3, 1), dtype=tf.float32)\n        output = cat(inp)\n        np.testing.assert_array_equal(tf.TensorShape([3, 5]), output.shape)\n        np.testing.assert_equal(output.dtype, tf.float32)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/models/attribute_test.py,8,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nfrom unittest.mock import Mock, patch\n\nfrom kglib.kgcn.models.attribute import CategoricalAttribute\nimport tensorflow as tf\n\nfrom kglib.utils.test.utils import get_call_args\n\n\nclass TestCategoricalAttribute(tf.test.TestCase):\n\n    def setUp(self):\n        self._mock_embed_instance = Mock(return_value=tf.zeros((3, 1, 5), dtype=tf.float32))\n        self._mock_embed_class = Mock(return_value=self._mock_embed_instance)\n        self._patcher = patch(\'kglib.kgcn.models.attribute.snt.Embed\', new=self._mock_embed_class,\n                              spec=True)\n        self._patcher.start()\n\n    def tearDown(self):\n        self._patcher.stop()\n\n    def test_embed_invoked_correctly(self):\n        attr_embedding_dim = 5\n        cat = CategoricalAttribute(2, 5)\n        cat(tf.zeros((3, 1), tf.float32))\n        self._mock_embed_class.assert_called_once_with(2, attr_embedding_dim)\n\n    def test_output_is_as_expected(self):\n        inp = tf.zeros((3, 1), dtype=tf.float32)\n        expected_output = tf.zeros((3, 5), dtype=tf.float32)\n        cat = CategoricalAttribute(2, 5)\n        output = cat(inp)\n        self.assertAllClose(expected_output, output)\n        self.assertEqual(expected_output.dtype, output.dtype)\n\n    def test_embed_instance_called_correctly(self):\n        inp = tf.zeros((3, 1), dtype=tf.float32)\n        cat = CategoricalAttribute(2, 5)\n        cat(inp)\n        self.assertAllClose(get_call_args(self._mock_embed_instance), [[tf.zeros((3, 1), dtype=tf.int32)]])\n        self.assertEqual(get_call_args(self._mock_embed_instance)[0][0].dtype, tf.int32)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/models/core.py,1,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport numpy as np\nimport sonnet as snt\nfrom graph_nets import modules\nfrom graph_nets import utils_tf\nfrom graph_nets.modules import GraphIndependent\n\n\ndef softmax(x):\n    return np.exp(x) / np.sum(np.exp(x))\n\n\ndef make_mlp_model(latent_size=16, num_layers=2):\n    """"""Instantiates a new MLP, followed by LayerNorm.\n\n    The parameters of each new MLP are not shared with others generated by\n    this function.\n\n    Returns:\n      A Sonnet module which contains the MLP and LayerNorm.\n    """"""\n    return snt.Sequential([\n        snt.nets.MLP([latent_size] * num_layers, activate_final=True),\n        snt.LayerNorm()\n    ])\n\n\nclass MLPGraphIndependent(snt.AbstractModule):\n    """"""GraphIndependent with MLP edge, node, and global models.""""""\n\n    def __init__(self, name=""MLPGraphIndependent""):\n        super(MLPGraphIndependent, self).__init__(name=name)\n        with self._enter_variable_scope():\n            self._network = GraphIndependent(\n                edge_model_fn=make_mlp_model,\n                node_model_fn=make_mlp_model)\n\n    def _build(self, inputs):\n        return self._network(inputs)\n\n\nclass MLPInteractionNetwork(snt.AbstractModule):\n    """"""InteractionNetwork with MLP edge, node, and global models.""""""\n\n    def __init__(self, name=""MLPInteractionNetwork""):\n        super(MLPInteractionNetwork, self).__init__(name=name)\n        with self._enter_variable_scope():\n            self._network = modules.InteractionNetwork(make_mlp_model, make_mlp_model)\n\n    def _build(self, inputs):\n        return self._network(inputs)\n\n\nclass KGCN(snt.AbstractModule):\n    """"""\n    A KGCN Neural Network with Message Passing. Implemented as a Sonnet Module.\n    """"""\n\n    def __init__(self,\n                 thing_embedder,\n                 role_embedder,\n                 edge_output_size=3,\n                 node_output_size=3,\n                 latent_size=16,\n                 num_layers=2,\n                 name=""KGCN""):\n        super(KGCN, self).__init__(name=name)\n\n        self._thing_embedder = thing_embedder\n        self._role_embedder = role_embedder\n\n        self._latent_size = latent_size\n        self._num_layers = num_layers\n\n        # Transforms the outputs into the appropriate shapes.\n        if edge_output_size is None:\n            edge_fn = None\n        else:\n            edge_fn = lambda: snt.Linear(edge_output_size, name=""edge_output"")\n        if node_output_size is None:\n            node_fn = None\n        else:\n            node_fn = lambda: snt.Linear(node_output_size, name=""node_output"")\n        with self._enter_variable_scope():\n            self._encoder = self._kg_encoder()\n            self._core = MLPInteractionNetwork()\n            self._decoder = MLPGraphIndependent()\n            self._output_transform = modules.GraphIndependent(edge_fn, node_fn)\n\n    def _edge_model(self):\n        return snt.Sequential([self._role_embedder,\n                               snt.nets.MLP([self._latent_size] * self._num_layers, activate_final=True),\n                               snt.LayerNorm()])\n\n    def _node_model(self):\n        return snt.Sequential([self._thing_embedder,\n                               snt.nets.MLP([self._latent_size] * self._num_layers, activate_final=True),\n                               snt.LayerNorm()])\n\n    def _kg_encoder(self):\n        return GraphIndependent(self._edge_model, self._node_model, name=\'kg_encoder\')\n\n    def _build(self, input_op, num_processing_steps):\n        latent = self._encoder(input_op)\n        latent0 = latent\n        output_ops = []\n        for _ in range(num_processing_steps):\n            core_input = utils_tf.concat([latent0, latent], axis=1)\n            latent = self._core(core_input)\n            decoded_op = self._decoder(latent)\n            output_ops.append(self._output_transform(decoded_op))\n        return output_ops\n'"
kglib/kgcn/models/core_IT.py,9,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\nfrom graph_nets.graphs import GraphsTuple\n\nfrom kglib.kgcn.models.core import KGCN\nfrom kglib.kgcn.models.embedding import ThingEmbedder, RoleEmbedder\n\n\nclass ITKGCN(unittest.TestCase):\n\n    def test_kgcn_runs(self):\n        tf.enable_eager_execution()\n\n        graph = GraphsTuple(nodes=tf.convert_to_tensor(np.array([[1, 2, 0], [1, 0, 0], [1, 1, 0]], dtype=np.float32)),\n                            edges=tf.convert_to_tensor(np.array([[1, 0, 0], [1, 0, 0]], dtype=np.float32)),\n                            globals=tf.convert_to_tensor(np.array([[0, 0, 0, 0, 0]], dtype=np.float32)),\n                            receivers=tf.convert_to_tensor(np.array([1, 2], dtype=np.int32)),\n                            senders=tf.convert_to_tensor(np.array([0, 1], dtype=np.int32)),\n                            n_node=tf.convert_to_tensor(np.array([3], dtype=np.int32)),\n                            n_edge=tf.convert_to_tensor(np.array([2], dtype=np.int32)))\n\n        thing_embedder = ThingEmbedder(node_types=[\'a\', \'b\', \'c\'], type_embedding_dim=5, attr_embedding_dim=6,\n                                       categorical_attributes={\'a\': [\'a1\', \'a2\', \'a3\'], \'b\': [\'b1\', \'b2\', \'b3\']},\n                                       continuous_attributes={\'c\': (0, 1)})\n\n        role_embedder = RoleEmbedder(num_edge_types=2, type_embedding_dim=5)\n\n        kgcn = KGCN(thing_embedder, role_embedder, edge_output_size=3, node_output_size=3)\n\n        kgcn(graph, 2)\n\n\nif __name__ == ""__main__"":\n    tf.enable_eager_execution()\n    unittest.main()\n'"
kglib/kgcn/models/embedding.py,6,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport tensorflow as tf\nimport sonnet as snt\n\nfrom kglib.kgcn.models.attribute import CategoricalAttribute, ContinuousAttribute, BlankAttribute\nfrom kglib.kgcn.models.typewise import TypewiseEncoder\n\n\nclass ThingEmbedder(snt.AbstractModule):\n    def __init__(self, node_types, type_embedding_dim, attr_embedding_dim, categorical_attributes,\n                 continuous_attributes, name=""ThingEmbedder""):\n        super(ThingEmbedder, self).__init__(name=name)\n\n        self._node_types = node_types\n        self._type_embedding_dim = type_embedding_dim\n        self._attr_embedding_dim = attr_embedding_dim\n\n        # Create embedders for the different attribute types\n        self._attr_embedders = dict()\n\n        if categorical_attributes is not None:\n            self._attr_embedders.update(\n                construct_categorical_embedders(node_types, attr_embedding_dim, categorical_attributes))\n\n        if continuous_attributes is not None:\n            self._attr_embedders.update(\n                construct_continuous_embedders(node_types, attr_embedding_dim, continuous_attributes))\n\n        self._attr_embedders.update(\n            construct_non_attribute_embedders(node_types, attr_embedding_dim, categorical_attributes,\n                                              continuous_attributes))\n\n    def _build(self, features):\n        return tf.concat([embed_type(features, len(self._node_types), self._type_embedding_dim),\n                          embed_attribute(features, self._attr_embedders, self._attr_embedding_dim)], axis=1)\n\n\nclass RoleEmbedder(snt.AbstractModule):\n    def __init__(self, num_edge_types, type_embedding_dim, name=""RoleEmbedder""):\n        super(RoleEmbedder, self).__init__(name=name)\n        self._num_edge_types = num_edge_types\n        self._type_embedding_dim = type_embedding_dim\n\n    def _build(self, features):\n        return embed_type(features, self._num_edge_types, self._type_embedding_dim)\n\n\ndef embed_type(features, num_types, type_embedding_dim):\n    preexistance_feat = tf.expand_dims(tf.cast(features[:, 0], dtype=tf.float32), axis=1)\n    type_embedder = snt.Embed(num_types, type_embedding_dim)\n    norm = snt.LayerNorm()\n    type_embedding = norm(type_embedder(tf.cast(features[:, 1], tf.int32)))\n    tf.summary.histogram(\'type_embedding_histogram\', type_embedding)\n    return tf.concat([preexistance_feat, type_embedding], axis=1)\n\n\ndef embed_attribute(features, attr_encoders, attr_embedding_dim):\n    typewise_attribute_encoder = TypewiseEncoder(attr_encoders, attr_embedding_dim)\n    attr_embedding = typewise_attribute_encoder(features[:, 1:])\n    tf.summary.histogram(\'attribute_embedding_histogram\', attr_embedding)\n    return attr_embedding\n\n\ndef construct_categorical_embedders(node_types, attr_embedding_dim, categorical_attributes):\n    attr_embedders = dict()\n\n    # Construct attribute embedders\n    for attribute_type, categories in categorical_attributes.items():\n\n        attr_typ_index = node_types.index(attribute_type)\n\n        def make_embedder():\n            return CategoricalAttribute(len(categories), attr_embedding_dim,\n                                        name=attribute_type + \'_cat_embedder\')\n\n        # Record the embedder, and the index of the type that it should encode\n        attr_embedders[make_embedder] = [attr_typ_index]\n\n    return attr_embedders\n\n\ndef construct_continuous_embedders(node_types, attr_embedding_dim, continuous_attributes):\n    attr_embedders = dict()\n\n    # Construct attribute embedders\n    for attribute_type in continuous_attributes.keys():\n\n        attr_typ_index = node_types.index(attribute_type)\n\n        def make_embedder():\n            return ContinuousAttribute(attr_embedding_dim, name=attribute_type + \'_cat_embedder\')\n\n        # Record the embedder, and the index of the type that it should encode\n        attr_embedders[make_embedder] = [attr_typ_index]\n\n    return attr_embedders\n\n\ndef construct_non_attribute_embedders(node_types, attr_embedding_dim, categorical_attributes, continuous_attributes):\n\n    attribute_names = list(categorical_attributes.keys())\n    attribute_names.extend(list(continuous_attributes.keys()))\n\n    non_attribute_nodes = []\n    for i, type in enumerate(node_types):\n        if type not in attribute_names:\n            non_attribute_nodes.append(i)\n\n    # All entities and relations (non-attributes) also need an embedder with matching output dimension, which does\n    # nothing. This is provided as a list of their indices\n    def make_blank_embedder():\n        return BlankAttribute(attr_embedding_dim)\n\n    attr_embedders = dict()\n\n    if len(non_attribute_nodes) > 0:\n        attr_embedders[make_blank_embedder] = non_attribute_nodes\n    return attr_embedders\n'"
kglib/kgcn/models/embedding_IT.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nfrom kglib.kgcn.models.embedding import construct_categorical_embedders, construct_continuous_embedders, \\\n    construct_non_attribute_embedders\n\n\ndef construct_embedders(node_types, attr_embedding_dim, categorical_attributes, continuous_attributes):\n    attr_embedders = dict()\n\n    if categorical_attributes is not None:\n        attr_embedders.update(construct_categorical_embedders(node_types, attr_embedding_dim, categorical_attributes))\n\n    if continuous_attributes is not None:\n        attr_embedders.update(construct_continuous_embedders(node_types, attr_embedding_dim, continuous_attributes))\n\n    attr_embedders.update(construct_non_attribute_embedders(node_types, attr_embedding_dim, categorical_attributes,\n                                                            continuous_attributes))\n    return attr_embedders\n\n\nclass TestConstructingEmbedders(unittest.TestCase):\n\n    def test_all_types_encoded(self):\n        node_types = [\'a\', \'b\', \'c\']\n        attr_embedding_dim = 5\n        categorical_attributes = {\'a\': [\'option1\', \'option2\']}\n        continuous_attributes = {\'b\': (0, 1)}\n\n        attr_embedders = construct_embedders(node_types, attr_embedding_dim, categorical_attributes,\n                                             continuous_attributes)\n        all_types = [l for el in list(attr_embedders.values()) for l in el]\n\n        expected_types = [0, 1, 2]\n\n        self.assertListEqual(expected_types, all_types)\n\n    def test_multiple_categorical_embedders(self):\n        node_types = [\'a\', \'b\', \'c\']\n        attr_embedding_dim = 5\n        categorical_attributes = {\'a\': [\'option1\', \'option2\'], \'c\': [\'option3\', \'option4\']}\n        continuous_attributes = {\'b\': (0, 1)}\n\n        attr_embedders = construct_embedders(node_types, attr_embedding_dim, categorical_attributes,\n                                             continuous_attributes)\n\n        all_types = [l for el in list(attr_embedders.values()) for l in el]\n        all_types.sort()\n\n        expected_types = [0, 1, 2]\n        print(attr_embedders)\n\n        self.assertListEqual(expected_types, all_types)\n\n        for types in attr_embedders.values():\n            self.assertNotEqual(types, [])\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/models/embedding_test.py,3,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\nfrom unittest.mock import Mock\nfrom unittest.mock import patch\nfrom kglib.kgcn.models.embedding import embed_type, embed_attribute\nfrom kglib.utils.test.utils import get_call_args\n\n\nclass TestTypeEmbedding(unittest.TestCase):\n    def setUp(self):\n        tf.enable_eager_execution()\n\n    def test_embedding_output_shape_as_expected(self):\n        features = np.array([[1, 0, 0.7], [1, 2, 0.7], [0, 1, 0.5]], dtype=np.float32)\n        type_embedding_dim = 5\n        output = embed_type(features, 3, type_embedding_dim)\n\n        np.testing.assert_array_equal(np.array([3, 6]), output.shape)\n\n\nclass TestAttributeEmbedding(unittest.TestCase):\n    def setUp(self):\n        tf.enable_eager_execution()\n\n    def test_embedding_is_typewise(self):\n        features = np.array([[1, 0, 0.7], [1, 2, 0.7], [0, 1, 0.5]])\n\n        mock_instance = Mock(return_value=tf.convert_to_tensor(np.array([[1, 0.7], [1, 0.7], [0, 0.5]])))\n        mock = Mock(return_value=mock_instance)\n        patcher = patch(\'kglib.kgcn.models.embedding.TypewiseEncoder\', spec=True, new=mock)\n        mock_class = patcher.start()\n\n        attr_encoders = Mock()\n        attr_embedding_dim = Mock()\n\n        embed_attribute(features, attr_encoders, attr_embedding_dim)  # Function under test\n\n        mock_class.assert_called_once_with(attr_encoders, attr_embedding_dim)\n        call_args = get_call_args(mock_instance)\n\n        np.testing.assert_array_equal([[np.array([[0, 0.7], [2, 0.7], [1, 0.5]])]], call_args)\n\n        patcher.stop()\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/models/typewise.py,12,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport sonnet as snt\nimport tensorflow as tf\n\n\nclass TypewiseEncoder(snt.AbstractModule):\n    """"""\n    Orchestrates encoding elements according to their types. Defers encoding of each feature to the appropriate encoder\n    for the type of that feature. Assumes that the type is given categorically as an integer value in the 0th position\n    of the provided features Tensor.\n    """"""\n    def __init__(self, encoders_for_types, feature_length, name=""typewise_encoder""):\n        """"""\n        Args:\n            encoders_for_types: Dict - keys: encoders; values: a list of type categories the encoder should be used for\n            feature_length: The length of features to output for matrix initialisation\n            name: The name for this Module\n        """"""\n        super(TypewiseEncoder, self).__init__(name=name)\n\n        types_considered = []\n        for a in encoders_for_types.values():\n            types_considered.extend(a)\n        types_considered.sort()\n\n        expected_types = list(range(max(types_considered) + 1))\n\n        if types_considered != expected_types:\n            raise ValueError(\n                f\'Encoder categories are inconsistent. Expected {expected_types}, but got {types_considered}\')\n\n        self._feature_length = feature_length\n        self._encoders_for_types = encoders_for_types\n\n    def _build(self, features):\n\n        tf.summary.histogram(\'typewise_encoder_features_histogram\', features)\n\n        shape = tf.stack([tf.shape(features)[0], self._feature_length])\n\n        encoded_features = tf.zeros(shape, dtype=tf.float32)\n\n        for encoder, types in self._encoders_for_types.items():\n\n            feat_types = tf.cast(features[:, 0], tf.int32)  # The types for each feature, as integers\n\n            # Expand dimensions ready for element-wise equality comparison\n            exp_types = tf.expand_dims(types, axis=0)\n            exp_feat_types = tf.expand_dims(feat_types, axis=1)\n\n            elementwise_equality = tf.equal(exp_feat_types, exp_types)\n\n            # Use this encoder when the feat_type matches any of the types\n            applicable_types_mask = tf.reduce_any(elementwise_equality, axis=1)\n            indices_to_encode = tf.where(applicable_types_mask)\n\n            feats_to_encode = tf.squeeze(tf.gather(features[:, 1:], indices_to_encode), axis=1)\n            encoded_feats = encoder()(feats_to_encode)\n\n            encoded_features += tf.scatter_nd(tf.cast(indices_to_encode, dtype=tf.int32), encoded_feats, shape)\n\n        tf.summary.histogram(\'typewise_encoder_encoded_features_histogram\', encoded_features)\n\n        return encoded_features\n'"
kglib/kgcn/models/typewise_IT.py,4,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework.ops import EagerTensor\n\nfrom kglib.kgcn.models.typewise import TypewiseEncoder\n\n\nclass ITTypewiseEncoder(unittest.TestCase):\n\n    def setUp(self):\n        tf.enable_eager_execution()\n\n    def test_with_tensors(self):\n        tf.reset_default_graph()\n        tf.set_random_seed(1)\n\n        things = tf.convert_to_tensor(np.array([[0, 0], [1, 0], [2, 0.5673]], dtype=np.float32))\n\n        entity_relation = lambda x: x\n        continuous_attribute = lambda x: x\n\n        encoders_for_types = {lambda: entity_relation: [0, 1], lambda: continuous_attribute: [2]}\n\n        tm = TypewiseEncoder(encoders_for_types, 1)\n        encoded_things = tm(things)  # The function under test\n\n        # Check that tensorflow was actually used\n        self.assertEqual(EagerTensor, type(encoded_things))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
kglib/kgcn/models/typewise_test.py,1,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\nfrom unittest.mock import Mock\n\nfrom kglib.utils.test.utils import get_call_args\nfrom kglib.kgcn.models.typewise import TypewiseEncoder\n\n\nclass TestTypewiseEncoder(unittest.TestCase):\n    def setUp(self):\n        tf.enable_eager_execution()\n\n    def test_types_encoded_by_expected_functions(self):\n        things = np.array([[0, 0], [1, 0], [2, 0.5673]], dtype=np.float32)\n\n        mock_entity_relation_encoder = Mock(return_value=np.array([[0, 0, 0], [0, 0, 0]], dtype=np.float32))\n\n        mock_attribute_encoder = Mock(return_value=np.array([[0.9527, 0.2367, 0.7582]], dtype=np.float32))\n\n        encoders_for_types = {lambda: mock_entity_relation_encoder: [0, 1], lambda: mock_attribute_encoder: [2]}\n\n        tm = TypewiseEncoder(encoders_for_types, 3)\n        encoding = tm(things)  # The function under test\n\n        np.testing.assert_array_equal([[np.array([[0], [0]], dtype=np.float32)]],\n                                      get_call_args(mock_entity_relation_encoder))\n\n        np.testing.assert_array_equal([[np.array([[0.5673]], dtype=np.float32)]], get_call_args(mock_attribute_encoder))\n\n        expected_encoding = np.array([[0, 0, 0], [0, 0, 0], [0.9527, 0.2367, 0.7582]], dtype=np.float32)\n        np.testing.assert_array_equal(expected_encoding, encoding.numpy())\n\n    def test_basic_encoding(self):\n        things = np.array([[0], [1], [2]], dtype=np.float32)\n\n        mock_entity_relation_encoder = Mock(return_value=np.array([[0.1, 0, 0], [0.1, 0, 0], [0.1, 0, 0]], dtype=np.float32))\n\n        encoders_for_types = {lambda: mock_entity_relation_encoder: [0, 1, 2]}\n\n        tm = TypewiseEncoder(encoders_for_types, 3)\n        encoding = tm(things)  # The function under test\n\n        expected_encoding = np.array([[0.1, 0, 0], [0.1, 0, 0], [0.1, 0, 0]], dtype=np.float32)\n        np.testing.assert_array_equal(expected_encoding, encoding.numpy())\n\n    def test_encoders_do_not_fulfil_classes(self):\n        mock_entity_relation_encoder = Mock()\n\n        encoders_for_types = {lambda: mock_entity_relation_encoder: [0, 2]}\n\n        with self.assertRaises(ValueError) as context:\n            TypewiseEncoder(encoders_for_types, 3)\n\n        self.assertEqual(\'Encoder categories are inconsistent. Expected [0, 1, 2], but got [0, 2]\',\n                         str(context.exception))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
kglib/kgcn/pipeline/encode.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport numpy as np\n\nfrom kglib.utils.graph.iterate import multidigraph_data_iterator, multidigraph_node_data_iterator, \\\n    multidigraph_edge_data_iterator\n\n\ndef encode_values(graph, categorical_attributes, continuous_attributes):\n    for node_data in multidigraph_node_data_iterator(graph):\n        typ = node_data[\'type\']\n\n        if categorical_attributes is not None and typ in categorical_attributes.keys():\n            # Add the integer value of the category for each categorical attribute instance\n            category_values = categorical_attributes[typ]\n            node_data[\'encoded_value\'] = category_values.index(node_data[\'value\'])\n\n        elif continuous_attributes is not None and typ in continuous_attributes.keys():\n            min_val, max_val = continuous_attributes[typ]\n            node_data[\'encoded_value\'] = (node_data[\'value\'] - min_val) / (max_val - min_val)\n\n        else:\n            node_data[\'encoded_value\'] = 0\n    for edge_data in multidigraph_edge_data_iterator(graph):\n        edge_data[\'encoded_value\'] = 0\n\n    return graph\n\n\ndef encode_types(graph, iterator_func, types):\n    """"""\n    Encodes the type found in graph data as an integer according to the index it is found in `all_types`\n    Args:\n        graph: The graph to encode\n        iterator_func: An function to create an iterator of data in the graph (node data, edge data or combined node and edge data)\n        types: The full list of types to be encoded in this order\n        \n    Returns:\n        The graph, which is also is updated in-place\n\n    """"""\n    iterator = iterator_func(graph)\n\n    for data in iterator:\n        data[\'categorical_type\'] = types.index(data[\'type\'])\n\n    return graph\n\n\ndef create_input_graph(graph):\n    input_graph = graph.copy()\n\n    for data in multidigraph_data_iterator(input_graph):\n        if data[""solution""] == 0:\n            preexists = 1\n        else:\n            preexists = 0\n\n        features = stack_features([preexists, data[""categorical_type""], data[""encoded_value""]])\n        data.clear()\n        data[""features""] = features\n\n    input_graph.graph[""features""] = np.array([0.0] * 5, dtype=np.float32)\n    return input_graph\n\n\ndef create_target_graph(graph):\n    target_graph = graph.copy()\n    solution_one_hot_encoding = np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], dtype=np.float32)\n\n    for data in multidigraph_data_iterator(target_graph):\n        features = solution_one_hot_encoding[data[""solution""]]\n        data.clear()\n        data[""features""] = features\n\n    target_graph.graph[""features""] = np.array([0.0] * 5, dtype=np.float32)\n    return target_graph\n\n\ndef stack_features(features):\n    """"""\n    Stacks features together into a single vector\n\n    Args:\n        features: iterable of features, features can be a single value or iterable\n\n    Returns:\n        Numpy array (vector) of stacked features\n\n    """"""\n\n    return np.hstack([np.array(feature, dtype=np.float32) for feature in features])\n'"
kglib/kgcn/pipeline/encode_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\n\nfrom kglib.kgcn.pipeline.encode import stack_features\n\n\nclass TestAugmentDataFields(unittest.TestCase):\n\n    def test_numpy_fields_augmented_as_expected(self):\n        features = [np.array([0, 1, 0]), np.array([5])]\n\n        stacked = stack_features(features)\n\n        expected = np.array([0, 1, 0, 5])\n\n        np.testing.assert_equal(expected, stacked)\n\n    def test_augmenting_non_numpy_numeric(self):\n        data = [np.array([0, 1, 0]), 5]\n\n        stacked = stack_features(data)\n\n        expected = np.array([0, 1, 0, 5])\n\n        np.testing.assert_equal(stacked, expected)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/pipeline/pipeline.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport networkx as nx\nimport numpy as np\nfrom graph_nets.utils_np import graphs_tuple_to_networkxs\n\nfrom kglib.kgcn.learn.learn import KGCNLearner\nfrom kglib.kgcn.models.core import softmax, KGCN\nfrom kglib.kgcn.models.embedding import ThingEmbedder, RoleEmbedder\nfrom kglib.kgcn.pipeline.encode import encode_types, create_input_graph, create_target_graph, encode_values\nfrom kglib.kgcn.pipeline.utils import apply_logits_to_graphs, duplicate_edges_in_reverse\nfrom kglib.kgcn.plot.plotting import plot_across_training, plot_predictions\nfrom kglib.utils.graph.iterate import multidigraph_node_data_iterator, multidigraph_data_iterator, \\\n    multidigraph_edge_data_iterator\n\n\ndef pipeline(graphs,\n             tr_ge_split,\n             node_types,\n             edge_types,\n             num_processing_steps_tr=10,\n             num_processing_steps_ge=10,\n             num_training_iterations=10000,\n             continuous_attributes=None,\n             categorical_attributes=None,\n             type_embedding_dim=5,\n             attr_embedding_dim=6,\n             edge_output_size=3,\n             node_output_size=3,\n             output_dir=None):\n\n    ############################################################\n    # Manipulate the graph data\n    ############################################################\n\n    # Encode attribute values\n    graphs = [encode_values(graph, categorical_attributes, continuous_attributes) for graph in graphs]\n\n    indexed_graphs = [nx.convert_node_labels_to_integers(graph, label_attribute=\'concept\') for graph in graphs]\n    graphs = [duplicate_edges_in_reverse(graph) for graph in indexed_graphs]\n\n    graphs = [encode_types(graph, multidigraph_node_data_iterator, node_types) for graph in graphs]\n    graphs = [encode_types(graph, multidigraph_edge_data_iterator, edge_types) for graph in graphs]\n\n    input_graphs = [create_input_graph(graph) for graph in graphs]\n    target_graphs = [create_target_graph(graph) for graph in graphs]\n\n    tr_input_graphs = input_graphs[:tr_ge_split]\n    tr_target_graphs = target_graphs[:tr_ge_split]\n    ge_input_graphs = input_graphs[tr_ge_split:]\n    ge_target_graphs = target_graphs[tr_ge_split:]\n\n    ############################################################\n    # Build and run the KGCN\n    ############################################################\n\n    thing_embedder = ThingEmbedder(node_types, type_embedding_dim, attr_embedding_dim, categorical_attributes,\n                                   continuous_attributes)\n\n    role_embedder = RoleEmbedder(len(edge_types), type_embedding_dim)\n\n    kgcn = KGCN(thing_embedder,\n                role_embedder,\n                edge_output_size=edge_output_size,\n                node_output_size=node_output_size)\n\n    learner = KGCNLearner(kgcn,\n                          num_processing_steps_tr=num_processing_steps_tr,\n                          num_processing_steps_ge=num_processing_steps_ge)\n\n    train_values, test_values, tr_info = learner(tr_input_graphs,\n                                                 tr_target_graphs,\n                                                 ge_input_graphs,\n                                                 ge_target_graphs,\n                                                 num_training_iterations=num_training_iterations,\n                                                 log_dir=output_dir)\n\n    plot_across_training(*tr_info, output_file=f\'{output_dir}learning.png\')\n    plot_predictions(graphs[tr_ge_split:], test_values, num_processing_steps_ge, output_file=f\'{output_dir}graph.png\')\n\n    logit_graphs = graphs_tuple_to_networkxs(test_values[""outputs""][-1])\n\n    indexed_ge_graphs = indexed_graphs[tr_ge_split:]\n    ge_graphs = [apply_logits_to_graphs(graph, logit_graph) for graph, logit_graph in\n                 zip(indexed_ge_graphs, logit_graphs)]\n\n    for ge_graph in ge_graphs:\n        for data in multidigraph_data_iterator(ge_graph):\n            data[\'probabilities\'] = softmax(data[\'logits\'])\n            data[\'prediction\'] = int(np.argmax(data[\'probabilities\']))\n\n    _, _, _, _, _, solveds_tr, solveds_ge = tr_info\n    return ge_graphs, solveds_tr, solveds_ge\n'"
kglib/kgcn/pipeline/utils.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\n\ndef duplicate_edges_in_reverse(graph):\n    """"""\n    Takes in a directed multi graph, and creates duplicates of all edges, the duplicates having reversed direction to\n    the originals. This is useful since directed edges constrain the direction of messages passed. We want to permit\n    omni-directional message passing.\n    Args:\n        graph: The graph\n\n    Returns:\n        The graph with duplicated edges, reversed, with all original edge properties attached to the duplicates\n    """"""\n    for sender, receiver, keys, data in graph.edges(data=True, keys=True):\n        graph.add_edge(receiver, sender, keys, **data)\n    return graph\n\n\ndef apply_logits_to_graphs(graph, logits_graph):\n    """"""\n    Take in a graph that describes the logits of the graph of interest, and store those logits on the graph as the\n    property \'logits\'. The graphs must correspond with one another\n\n    Args:\n        graph: Graph to apply logits to\n        logits_graph: Graph containing logits\n\n    Returns:\n        graph with logits added as property \'logits\'\n    """"""\n\n    for node, data in logits_graph.nodes(data=True):\n        graph.nodes[node][\'logits\'] = list(data[\'features\'])\n\n    # TODO This is the desired implementation, but the graphs are altered by the model to have duplicated reversed\n    #  edges, so this won\'t work for now\n    # for sender, receiver, keys, data in logit_graph.edges(keys=True, data=True):\n    #     graph.edges[sender, receiver, keys][\'logits\'] = list(data[\'features\'])\n\n    for sender, receiver, keys, data in graph.edges(keys=True, data=True):\n        data[\'logits\'] = list(logits_graph.edges[sender, receiver, keys][\'features\'])\n\n    return graph\n'"
kglib/kgcn/pipeline/utils_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport networkx as nx\nimport numpy as np\n\nfrom kglib.kgcn.pipeline.utils import duplicate_edges_in_reverse, apply_logits_to_graphs\nfrom kglib.utils.grakn.object.thing import Thing\nfrom kglib.utils.graph.test.case import GraphTestCase\n\n\nclass TestDuplicateEdgesInReverse(GraphTestCase):\n\n    def test_edges_are_duplicated_as_expected(self):\n        graph = nx.MultiDiGraph(name=0)\n\n        p0 = Thing(\'V123\', \'person\', \'entity\')\n        p1 = Thing(\'V456\', \'person\', \'entity\')\n        par0 = Thing(\'V789\', \'parentship\', \'relation\')\n\n        # people\n        graph.add_node(p0, type=\'person\', solution=1)\n        graph.add_node(p1, type=\'person\', solution=1)\n\n        # parentships\n        graph.add_node(par0, type=\'parentship\', solution=1)\n        graph.add_edge(par0, p0, type=\'parent\', solution=1)\n        graph.add_edge(par0, p1, type=\'child\', solution=1)\n\n        duplicate_edges_in_reverse(graph)\n\n        expected_graph = nx.MultiDiGraph(name=0)\n\n        # people\n        expected_graph.add_node(p0, type=\'person\', solution=1)\n        expected_graph.add_node(p1, type=\'person\', solution=1)\n\n        # parentships\n        expected_graph.add_node(par0, type=\'parentship\', solution=1)\n        expected_graph.add_edge(par0, p0, type=\'parent\', solution=1)\n        expected_graph.add_edge(par0, p1, type=\'child\', solution=1)\n\n        # Duplicates\n        expected_graph.add_edge(p0, par0, type=\'parent\', solution=1)\n        expected_graph.add_edge(p1, par0, type=\'child\', solution=1)\n        self.assertGraphsEqual(expected_graph, graph)\n\n\nclass TestApplyLogitsToGraphs(GraphTestCase):\n    def test_logits_applied_as_expected(self):\n\n        graph = nx.MultiDiGraph(name=0)\n        graph.add_node(0)\n        graph.add_node(1)\n        graph.add_edge(0, 1)\n\n        logits_graph = nx.MultiDiGraph(name=0)\n        logits_graph.add_node(0, features=np.array([0.2, 0.3, 0.01]))\n        logits_graph.add_node(1, features=np.array([0.56, -0.04, 0.05]))\n        logits_graph.add_edge(0, 1, features=np.array([0.5, 0.008, -0.1]))\n        logits_graph.add_edge(1, 0, features=np.array([0.5, 0.008, -0.1]))\n\n        expected_graph = nx.MultiDiGraph(name=0)\n        expected_graph.add_node(0, logits=[0.2, 0.3, 0.01])\n        expected_graph.add_node(1, logits=[0.56, -0.04, 0.05])\n        expected_graph.add_edge(0, 1, logits=[0.5, 0.008, -0.1])\n\n        graph_with_logits = apply_logits_to_graphs(graph, logits_graph)\n\n        self.assertGraphsEqual(expected_graph, graph_with_logits)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
kglib/kgcn/plot/draw.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport networkx.utils\n\n\ndef draw_networkx_labels(G, pos,\n                         labels=None,\n                         font_size=12,\n                         font_color=None,\n                         font_family=\'sans-serif\',\n                         font_weight=\'normal\',\n                         alpha=None,\n                         bbox=None,\n                         ax=None,\n                         **kwds):\n    """"""Draw node labels on the graph G.\n\n    Parameters\n    ----------\n    G : graph\n       A networkx graph\n\n    pos : dictionary\n       A dictionary with nodes as keys and positions as values.\n       Positions should be sequences of length 2.\n\n    labels : dictionary, optional (default=None)\n       Node labels in a dictionary keyed by node of text labels\n       Node-keys in labels should appear as keys in `pos`.\n       If needed use: `{n:lab for n,lab in labels.items() if n in pos}`\n\n    font_size : int\n       Font size for text labels (default=12)\n\n    font_color : string\n       Font color string (default=\'k\' black)\n\n    font_family : string\n       Font family (default=\'sans-serif\')\n\n    font_weight : string\n       Font weight (default=\'normal\')\n\n    alpha : float\n       The text transparency (default=1.0)\n\n    ax : Matplotlib Axes object, optional\n       Draw the graph in the specified Matplotlib axes.\n\n    Returns\n    -------\n    dict\n        `dict` of labels keyed on the nodes\n\n    Examples\n    --------\n    >>> G = nx.dodecahedral_graph()\n    >>> labels = nx.draw_networkx_labels(G, pos=nx.spring_layout(G))\n\n    Also see the NetworkX drawing examples at\n    https://networkx.github.io/documentation/latest/auto_examples/index.html\n\n    See Also\n    --------\n    draw()\n    draw_networkx()\n    draw_networkx_nodes()\n    draw_networkx_edges()\n    draw_networkx_edge_labels()\n    """"""\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.cbook as cb\n    except ImportError:\n        raise ImportError(""Matplotlib required for draw()"")\n    except RuntimeError:\n        print(""Matplotlib unable to open display"")\n        raise\n\n    if ax is None:\n        ax = plt.gca()\n\n    if labels is None:\n        labels = dict((n, n) for n in G.nodes())\n\n    # set optional alignment\n    horizontalalignment = kwds.get(\'horizontalalignment\', \'center\')\n    verticalalignment = kwds.get(\'verticalalignment\', \'center\')\n\n    text_items = {}  # there is no text collection so we\'ll fake one\n    for n, label in labels.items():\n        (x, y) = pos[n]\n        if not networkx.utils.is_string_like(label):\n            label = str(label)  # this makes ""1"" and 1 labeled the same\n        t = ax.text(x, y,\n                    label,\n                    size=font_size,\n                    color=font_color[n],\n                    family=font_family,\n                    weight=font_weight,\n                    alpha=alpha[n],\n                    horizontalalignment=horizontalalignment,\n                    verticalalignment=verticalalignment,\n                    transform=ax.transData,\n                    bbox=bbox,\n                    clip_on=True,\n                    )\n        text_items[n] = t\n\n    plt.tick_params(\n        axis=\'both\',\n        which=\'both\',\n        bottom=False,\n        left=False,\n        labelbottom=False,\n        labelleft=False)\n\n    return text_items\n\n\ndef draw_networkx_edge_labels(G, pos,\n                              edge_labels=None,\n                              label_pos=0.5,\n                              font_size=10,\n                              font_color=None,\n                              font_family=\'sans-serif\',\n                              font_weight=\'normal\',\n                              alpha=None,\n                              bbox=None,\n                              ax=None,\n                              rotate=True,\n                              **kwds):\n    """"""Draw edge labels.\n\n    Parameters\n    ----------\n    G : graph\n       A networkx graph\n\n    pos : dictionary\n       A dictionary with nodes as keys and positions as values.\n       Positions should be sequences of length 2.\n\n    ax : Matplotlib Axes object, optional\n       Draw the graph in the specified Matplotlib axes.\n\n    alpha : float\n       The text transparency (default=1.0)\n\n    edge_labels : dictionary\n       Edge labels in a dictionary keyed by edge two-tuple of text\n       labels (default=None). Only labels for the keys in the dictionary\n       are drawn.\n\n    label_pos : float\n       Position of edge label along edge (0=head, 0.5=center, 1=tail)\n\n    font_size : int\n       Font size for text labels (default=12)\n\n    font_color : string\n       Font color string (default=\'k\' black)\n\n    font_weight : string\n       Font weight (default=\'normal\')\n\n    font_family : string\n       Font family (default=\'sans-serif\')\n\n    bbox : Matplotlib bbox\n       Specify text box shape and colors.\n\n    clip_on : bool\n       Turn on clipping at axis boundaries (default=True)\n\n    Returns\n    -------\n    dict\n        `dict` of labels keyed on the edges\n\n    Examples\n    --------\n    >>> G = nx.dodecahedral_graph()\n    >>> edge_labels = nx.draw_networkx_edge_labels(G, pos=nx.spring_layout(G))\n\n    Also see the NetworkX drawing examples at\n    https://networkx.github.io/documentation/latest/auto_examples/index.html\n\n    See Also\n    --------\n    draw()\n    draw_networkx()\n    draw_networkx_nodes()\n    draw_networkx_edges()\n    draw_networkx_labels()\n    """"""\n    try:\n        import matplotlib.pyplot as plt\n        import numpy as np\n    except ImportError:\n        raise ImportError(""Matplotlib required for draw()"")\n    except RuntimeError:\n        print(""Matplotlib unable to open display"")\n        raise\n\n    if ax is None:\n        ax = plt.gca()\n    if edge_labels is None:\n        labels = {(u, v): d for u, v, d in G.edges(data=True)}\n    else:\n        labels = edge_labels\n    text_items = {}\n    for (n1, n2), label in labels.items():\n        (x1, y1) = pos[n1]\n        (x2, y2) = pos[n2]\n        (x, y) = (x1 * label_pos + x2 * (1.0 - label_pos),\n                  y1 * label_pos + y2 * (1.0 - label_pos))\n\n        if rotate:\n            # in degrees\n            angle = np.arctan2(y2 - y1, x2 - x1) / (2.0 * np.pi) * 360\n            # make label orientation ""right-side-up""\n            if angle > 90:\n                angle -= 180\n            if angle < - 90:\n                angle += 180\n            # transform data coordinate angle to screen coordinate angle\n            xy = np.array((x, y))\n            trans_angle = ax.transData.transform_angles(np.array((angle,)),\n                                                        xy.reshape((1, 2)))[0]\n        else:\n            trans_angle = 0.0\n        # use default box of white with white border\n        if bbox is None:\n            bbox = dict(boxstyle=\'round\',\n                        ec=(1.0, 1.0, 1.0),\n                        fc=(1.0, 1.0, 1.0),\n                        )\n        if not networkx.utils.is_string_like(label):\n            label = str(label)  # this makes ""1"" and 1 labeled the same\n\n        # set optional alignment\n        horizontalalignment = kwds.get(\'horizontalalignment\', \'center\')\n        verticalalignment = kwds.get(\'verticalalignment\', \'center\')\n\n        t = ax.text(x, y,\n                    label,\n                    size=font_size,\n                    color=font_color[(n1, n2)],\n                    family=font_family,\n                    weight=font_weight,\n                    alpha=alpha[(n1, n2)],\n                    horizontalalignment=horizontalalignment,\n                    verticalalignment=verticalalignment,\n                    rotation=trans_angle,\n                    transform=ax.transData,\n                    bbox=bbox,\n                    zorder=1,\n                    clip_on=True,\n                    )\n        text_items[(n1, n2)] = t\n\n    plt.tick_params(\n        axis=\'both\',\n        which=\'both\',\n        bottom=False,\n        left=False,\n        labelbottom=False,\n        labelleft=False)\n\n    return text_items\n'"
kglib/kgcn/plot/plotting.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport math\n\nimport graph_nets.utils_np as utils_np\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\n\nimport kglib.kgcn.plot.draw as custom_nx\n\n\ndef plot_across_training(logged_iterations, losses_tr, losses_ge, corrects_tr, corrects_ge, solveds_tr, solveds_ge,\n                         output_file=\'./learning.png\'):\n    # Plot results curves.\n    fig = plt.figure(1, figsize=(18, 3))\n    fig.clf()\n    x = np.array(logged_iterations)\n    # Loss.\n    y_tr = losses_tr\n    y_ge = losses_ge\n    ax = fig.add_subplot(1, 3, 1)\n    ax.plot(x, y_tr, ""k"", label=""Training"")\n    ax.plot(x, y_ge, ""k--"", label=""Test/generalization"")\n    ax.set_title(""Loss across training"")\n    ax.set_xlabel(""Training iteration"")\n    ax.set_ylabel(""Loss (binary cross-entropy)"")\n    ax.legend()\n    # Correct.\n    y_tr = corrects_tr\n    y_ge = corrects_ge\n    ax = fig.add_subplot(1, 3, 2)\n    ax.plot(x, y_tr, ""k"", label=""Training"")\n    ax.plot(x, y_ge, ""k--"", label=""Test/generalization"")\n    ax.set_title(""Fraction correct across training"")\n    ax.set_xlabel(""Training iteration"")\n    ax.set_ylabel(""Fraction nodes/edges correct"")\n    # Solved.\n    y_tr = solveds_tr\n    y_ge = solveds_ge\n    ax = fig.add_subplot(1, 3, 3)\n    ax.plot(x, y_tr, ""k"", label=""Training"")\n    ax.plot(x, y_ge, ""k--"", label=""Test/generalization"")\n    ax.set_title(""Fraction solved across training"")\n    ax.set_xlabel(""Training iteration"")\n    ax.set_ylabel(""Fraction examples solved"")\n\n    plt.savefig(output_file, bbox_inches=\'tight\')\n\n\ndef plot_predictions(raw_graphs, test_values, num_processing_steps_ge, solution_weights=(-0.5, 0.5, 0.5),\n                     output_file=\'./graph.png\'):\n\n    # # Plot graphs and results after each processing step.\n    # The white node is the start, and the black is the end. Other nodes are colored\n    # from red to purple to blue, where red means the model is confident the node is\n    # off the shortest path, blue means the model is confident the node is on the\n    # shortest path, and purplish colors mean the model isn\'t sure.\n\n    max_graphs_to_plot = 10\n    num_steps_to_plot = 3\n    node_size = 120\n\n    num_graphs = len(raw_graphs)\n    targets = utils_np.graphs_tuple_to_data_dicts(test_values[""target""])\n    step_indices = np.floor(\n        np.linspace(0, num_processing_steps_ge - 1,\n                    num_steps_to_plot)).astype(int).tolist()\n    outputs = list(\n        zip(*(utils_np.graphs_tuple_to_data_dicts(test_values[""outputs""][i])\n              for i in step_indices)))\n    h = min(num_graphs, max_graphs_to_plot)\n    w = num_steps_to_plot + 2\n    fig = plt.figure(101, figsize=(18, h * 3))\n    fig.clf()\n    for j, (graph, target, output) in enumerate(zip(raw_graphs, targets, outputs)):\n        if j >= h:\n            break\n        for s, r, d in graph.edges(data=True):\n            d[\'weight\'] = solution_weights[d[\'solution\']]  # Looks good with high k\n        pos = nx.spring_layout(graph, k=3 / math.sqrt(graph.number_of_nodes()), seed=1, weight=\'weight\', iterations=50)\n        # pos = nx.circular_layout(graph, scale=2)\n        ground_truth_node_prob = target[""nodes""][:, -1]\n        ground_truth_edge_prob = target[""edges""][:, -1]\n\n        non_preexist_node_mask = mask_preexists(target[""nodes""])\n        non_preexist_edge_mask = mask_preexists(target[""edges""])\n\n        # Ground truth.\n        iax = j * (2 + num_steps_to_plot) + 1\n        ax = draw_subplot(graph, fig, pos, node_size, h, w, iax, ground_truth_node_prob, ground_truth_edge_prob, True)\n\n        # Format the ground truth plot axes\n        ax.set_axis_on()\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.spines[\'bottom\'].set_color(\'blue\')\n        ax.spines[\'top\'].set_color(\'blue\')\n        ax.spines[\'right\'].set_color(\'blue\')\n        ax.spines[\'left\'].set_color(\'blue\')\n        ax.grid(None)\n        ax.set_title(""Ground truth"")\n\n        # Prediction.\n        for k, outp in enumerate(output):\n            iax = j * (2 + num_steps_to_plot) + 2 + k\n            node_prob = softmax_prob_last_dim(outp[""nodes""]) * non_preexist_node_mask\n            edge_prob = softmax_prob_last_dim(outp[""edges""]) * non_preexist_edge_mask\n            ax = draw_subplot(graph, fig, pos, node_size, h, w, iax, node_prob, edge_prob, False)\n            ax.set_title(""Model-predicted\\nStep {:02d} / {:02d}"".format(\n                step_indices[k] + 1, step_indices[-1] + 1))\n\n        # Class Winners\n        # Displays whether the class represented by the last dimension was the winner\n        node_prob = last_dim_was_class_winner(output[-1][""nodes""]) * non_preexist_node_mask\n        edge_prob = last_dim_was_class_winner(output[-1][""edges""]) * non_preexist_edge_mask\n\n        iax = j * (2 + num_steps_to_plot) + 2 + len(output)\n        ax = draw_subplot(graph, fig, pos, node_size, h, w, iax, node_prob, edge_prob, False)\n\n        # Format the class winners plot axes\n        ax.set_axis_on()\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.spines[\'bottom\'].set_color(\'green\')\n        ax.spines[\'top\'].set_color(\'green\')\n        ax.spines[\'right\'].set_color(\'green\')\n        ax.spines[\'left\'].set_color(\'green\')\n        ax.grid(None)\n        ax.set_title(""Model-predicted winners"")\n\n    plt.savefig(output_file, bbox_inches=\'tight\')\n\n\ndef mask_preexists(arr):\n    return (arr[:, 0] == 0) * 1\n\n\ndef softmax_prob_last_dim(x):\n    e = np.exp(x)\n    return e[:, -1] / np.sum(e, axis=-1)\n\n\ndef last_dim_was_class_winner(x):\n    return (np.argmax(x, axis=-1) == 2) * 1\n\n\ndef element_color(gt_plot, probability, element_props):\n    """"""\n    Determine the color values to use for a node/edge and its label\n    gt plot:\n    blue for existing elements, green for those to infer, red candidates\n\n    output plot:\n    blue for existing elements, green for those to infer, red for candidates, all with transparency\n    """"""\n\n    existing = 0\n    candidate = 1\n    to_infer = 2\n\n    solution = element_props.get(\'solution\')\n\n    color_config = {\n        to_infer: {\'color\': [0.0, 1.0, 0.0], \'gt_opacity\': 1.0},\n        candidate: {\'color\': [1.0, 0.0, 0.0], \'gt_opacity\': 1.0},\n        existing: {\'color\': [0.0, 0.0, 1.0], \'gt_opacity\': 0.2}\n    }\n\n    chosen_config = color_config[solution]\n\n    if gt_plot:\n        opacity = chosen_config[\'gt_opacity\']\n    else:\n        opacity = probability\n\n    label = np.array([0.0, 0.0, 0.0] + [opacity])\n    color = np.array(chosen_config[\'color\'] + [opacity])\n\n    return dict(element=color, label=label)\n\n\ndef draw_subplot(graph, fig, pos, node_size, h, w, iax, node_prob, edge_prob, gt_plot):\n    ax = fig.add_subplot(h, w, iax)\n    node_color = {}\n    node_label_color = {}\n    edge_color = {}\n    edge_label_color = {}\n\n    for i, (n, props) in enumerate(graph.nodes(data=True)):\n        colors = element_color(gt_plot, node_prob[n], props)\n\n        node_color[n] = colors[\'element\']\n        node_label_color[n] = colors[\'label\']\n\n    for n, (sender, receiver, props) in enumerate(graph.edges(data=True)):\n        colors = element_color(gt_plot, edge_prob[n], props)\n\n        edge_color[(sender, receiver)] = colors[\'element\']\n        edge_label_color[(sender, receiver)] = colors[\'label\']\n\n    draw_graph(graph, pos, ax, node_size=node_size, node_color=node_color, node_label_color=node_label_color,\n               edge_color=edge_color, edge_label_color=edge_label_color)\n    return ax\n\n\ndef draw_graph(graph,\n               pos,\n               ax,\n               node_size=200,\n               node_color=(0.4, 0.8, 0.4),\n               node_label_color=None,\n               edge_color=(0.0, 0.0, 0.0),\n               edge_label_color=None,\n               node_linewidth=1.0,\n               edge_width=1.0,\n               font_size=6):\n\n    def _draw(draw_function, zorder=None, **kwargs):\n        # draw_kwargs = self._make_draw_kwargs(**kwargs)\n        _base_draw_kwargs = dict(G=graph, pos=pos, ax=ax)\n        kwargs.update(_base_draw_kwargs)\n        collection = draw_function(**kwargs)\n        if collection is not None and zorder is not None:\n            try:\n                # This is for compatibility with older matplotlib.\n                collection.set_zorder(zorder)\n            except AttributeError:\n                # This is for compatibility with newer matplotlib.\n                collection[0].set_zorder(zorder)\n        return collection\n\n    # Plot nodes.\n    c = [node_color[n] for n in graph.nodes()]\n    _draw(nx.draw_networkx_nodes,\n          node_size=node_size,\n          node_color=c,\n          linewidths=node_linewidth,\n          alpha=[node_color[n][-1] for n in graph.nodes()],\n          zorder=-10)\n\n    # Plot edges.\n    e = [edge_color[(s, r)] for s, r, k in graph.edges]\n    _draw(nx.draw_networkx_edges,\n          edgelist=graph.edges,\n          width=edge_width,\n          zorder=-20,\n          edge_color=e\n          )\n\n    bbox_props = dict(boxstyle=""square,pad=0.0"", fc=""none"", ec=""none"", lw=1)\n    labels_dict = {node_id: graph.nodes[node_id][\'type\'] for node_id in graph.nodes}\n    edge_labels_dict = {(edge_id[0], edge_id[1]): graph.edges[edge_id][\'type\'] for edge_id in graph.edges}\n\n    custom_nx.draw_networkx_labels(graph,\n                                   pos,\n                                   labels=labels_dict,\n                                   font_size=font_size,\n                                   font_color=node_label_color,\n                                   alpha=[node_label_color[n][-1] for n in graph.nodes()])\n\n    custom_nx.draw_networkx_edge_labels(graph,\n                                        pos,\n                                        edge_labels=edge_labels_dict,\n                                        font_size=font_size,\n                                        # font_color=np.array([0.0, 0.5, 0.0, 0.1]),\n                                        font_color=edge_label_color,\n                                        # alpha=0.2,\n                                        alpha={n: edge_label_color[n][-1] for n in graph.edges()},\n                                        bbox=bbox_props)\n'"
kglib/kgcn/plot/plotting_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport datetime\nimport os\nimport unittest\n\nimport networkx as nx\nimport numpy as np\nfrom graph_nets.graphs import GraphsTuple\n\nfrom kglib.kgcn.plot.plotting import plot_predictions\n\n\nclass TestPlotPredictions(unittest.TestCase):\n    def test_plot_is_created(self):\n        num_processing_steps_ge = 6\n\n        graph = nx.MultiDiGraph(name=0)\n\n        existing = dict(solution=0)\n        to_infer = dict(solution=2)\n        candidate = dict(solution=1)\n\n        # people\n        graph.add_node(0, type=\'person\', **existing)\n        graph.add_node(1, type=\'person\', **candidate)\n\n        # parentships\n        graph.add_node(2, type=\'parentship\', **to_infer)\n        graph.add_edge(2, 0, type=\'parent\', **to_infer)\n        graph.add_edge(2, 1, type=\'child\', **candidate)\n\n        graph_tuple_target = GraphsTuple(nodes=np.array([[1., 0., 0.],\n                                                         [0., 1., 0.],\n                                                         [0., 0., 1.]]),\n                                         edges=np.array([[0., 0., 1.],\n                                                         [0., 1., 0.]]),\n                                         receivers=np.array([1, 2], dtype=np.int32),\n                                         senders=np.array([0, 1], dtype=np.int32),\n                                         globals=np.array([[0., 0., 0., 0., 0.]], dtype=np.float32),\n                                         n_node=np.array([3], dtype=np.int32),\n                                         n_edge=np.array([2], dtype=np.int32))\n\n        graph_tuple_output = GraphsTuple(nodes=np.array([[1., 0., 0.],\n                                                         [1., 1., 0.],\n                                                         [1., 0., 1.]]),\n                                         edges=np.array([[1., 0., 0.],\n                                                         [1., 1., 0.]]),\n                                         receivers=np.array([1, 2], dtype=np.int32),\n                                         senders=np.array([0, 1], dtype=np.int32),\n                                         globals=np.array([[0., 0., 0., 0., 0.]], dtype=np.float32),\n                                         n_node=np.array([3], dtype=np.int32),\n                                         n_edge=np.array([2], dtype=np.int32))\n\n        test_values = {""target"": graph_tuple_target, ""outputs"": [graph_tuple_output for _ in range(6)]}\n\n        filename = f\'./graph_{datetime.datetime.now()}.png\'\n\n        plot_predictions([graph], test_values, num_processing_steps_ge, output_file=filename)\n\n        self.assertTrue(os.path.isfile(filename))\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/utils/graph/iterate.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nfrom itertools import chain\n\n\ndef multidigraph_edge_data_iterator(graph):\n    for _, _, _, edge_data in graph.edges(data=True, keys=True):\n        yield edge_data\n\n\ndef multidigraph_node_data_iterator(graph):\n    for _, node_data in graph.nodes(data=True):\n        yield node_data\n\n\ndef multidigraph_data_iterator(graph):\n    return chain(multidigraph_node_data_iterator(graph), multidigraph_edge_data_iterator(graph))'"
kglib/utils/test/utils.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\n\ndef get_call_args(mock):\n    """"""\n    Get the arguments used to call a mock for each call to the mock. Necessary since `.assert_has_calls` won\'t work\n    for numpy arrays\n    Args:\n        mock: the mock\n\n    Returns:\n        A list of lists. The outer list is the calls made, the inner list is the arguments given for that call\n    """"""\n    flat_args = []\n    args_list = mock.call_args_list\n    for call in args_list:\n        args, kwargs = call\n        flat_args.append(args)\n    return flat_args\n'"
tests/deployment/kgcn/diagnosis.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nfrom kglib.kgcn.examples.diagnosis.diagnosis import diagnosis_example\n\n\nclass TestDiagnosisExample(unittest.TestCase):\n\n    def test_example_runs_without_exception(self):\n        diagnosis_example(num_graphs=6,\n                          num_processing_steps_tr=2,\n                          num_processing_steps_ge=2,\n                          num_training_iterations=20)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/end_to_end/kgcn/diagnosis.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nfrom kglib.kgcn.examples.diagnosis.diagnosis import diagnosis_example\nfrom kglib.utils.grakn.test.base import GraknServer\n\nTEST_KEYSPACE = ""diagnosis""\nTEST_URI = ""localhost:48555""\n\n\nclass TestDiagnosisExample(unittest.TestCase):\n    def setUp(self):\n        self._gs = GraknServer()\n        self._gs.start()\n        self._gs.load_graql_file(TEST_KEYSPACE, \'/kglib/kglib/utils/grakn/synthetic/examples/diagnosis/schema.gql\')\n\n    def tearDown(self):\n        self._gs.stop()\n\n    def test_learning_is_done(self):\n        solveds_tr, solveds_ge = diagnosis_example()\n        self.assertGreaterEqual(solveds_tr[-1], 0.7)\n        self.assertLessEqual(solveds_tr[-1], 0.99)\n        self.assertGreaterEqual(solveds_ge[-1], 0.7)\n        self.assertLessEqual(solveds_ge[-1], 0.99)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/kgcn/examples/diagnosis/diagnosis.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport inspect\nimport time\n\nfrom grakn.client import GraknClient\n\nfrom kglib.kgcn.pipeline.pipeline import pipeline\nfrom kglib.utils.grakn.synthetic.examples.diagnosis.generate import generate_example_graphs\nfrom kglib.utils.grakn.type.type import get_thing_types, get_role_types\nfrom kglib.utils.graph.iterate import multidigraph_data_iterator\nfrom kglib.utils.graph.query.query_graph import QueryGraph\nfrom kglib.utils.graph.thing.queries_to_graph import build_graph_from_queries\n\nKEYSPACE = ""diagnosis""\nURI = ""localhost:48555""\n\n# Existing elements in the graph are those that pre-exist in the graph, and should be predicted to continue to exist\nPREEXISTS = 0\n\n# Candidates are neither present in the input nor in the solution, they are negative samples\nCANDIDATE = 1\n\n# Elements to infer are the graph elements whose existence we want to predict to be true, they are positive samples\nTO_INFER = 2\n\n# Categorical Attribute types and the values of their categories\nCATEGORICAL_ATTRIBUTES = {\'name\': [\'Diabetes Type II\', \'Multiple Sclerosis\', \'Blurred vision\', \'Fatigue\', \'Cigarettes\',\n                                   \'Alcohol\']}\n# Continuous Attribute types and their min and max values\nCONTINUOUS_ATTRIBUTES = {\'severity\': (0, 1), \'age\': (7, 80), \'units-per-week\': (3, 29)}\n\nTYPES_TO_IGNORE = [\'candidate-diagnosis\', \'example-id\', \'probability-exists\', \'probability-non-exists\', \'probability-preexists\']\nROLES_TO_IGNORE = [\'candidate-patient\', \'candidate-diagnosed-disease\']\n\n# The learner should see candidate relations the same as the ground truth relations, so adjust these candidates to\n# look like their ground truth counterparts\nTYPES_AND_ROLES_TO_OBFUSCATE = {\'candidate-diagnosis\': \'diagnosis\',\n                                \'candidate-patient\': \'patient\',\n                                \'candidate-diagnosed-disease\': \'diagnosed-disease\'}\n\n\ndef diagnosis_example(num_graphs=200,\n                      num_processing_steps_tr=5,\n                      num_processing_steps_ge=5,\n                      num_training_iterations=1000,\n                      keyspace=KEYSPACE, uri=URI):\n    """"""\n    Run the diagnosis example from start to finish, including traceably ingesting predictions back into Grakn\n\n    Args:\n        num_graphs: Number of graphs to use for training and testing combined\n        num_processing_steps_tr: The number of message-passing steps for training\n        num_processing_steps_ge: The number of message-passing steps for testing\n        num_training_iterations: The number of training epochs\n        keyspace: The name of the keyspace to retrieve example subgraphs from\n        uri: The uri of the running Grakn instance\n\n    Returns:\n        Final accuracies for training and for testing\n    """"""\n\n    tr_ge_split = int(num_graphs*0.5)\n\n    generate_example_graphs(num_graphs, keyspace=keyspace, uri=uri)\n\n    client = GraknClient(uri=uri)\n    session = client.session(keyspace=keyspace)\n\n    graphs = create_concept_graphs(list(range(num_graphs)), session)\n\n    with session.transaction().read() as tx:\n        # Change the terminology here onwards from thing -> node and role -> edge\n        node_types = get_thing_types(tx)\n        [node_types.remove(el) for el in TYPES_TO_IGNORE]\n\n        edge_types = get_role_types(tx)\n        [edge_types.remove(el) for el in ROLES_TO_IGNORE]\n        print(f\'Found node types: {node_types}\')\n        print(f\'Found edge types: {edge_types}\')\n\n    ge_graphs, solveds_tr, solveds_ge = pipeline(graphs,\n                                                 tr_ge_split,\n                                                 node_types,\n                                                 edge_types,\n                                                 num_processing_steps_tr=num_processing_steps_tr,\n                                                 num_processing_steps_ge=num_processing_steps_ge,\n                                                 num_training_iterations=num_training_iterations,\n                                                 continuous_attributes=CONTINUOUS_ATTRIBUTES,\n                                                 categorical_attributes=CATEGORICAL_ATTRIBUTES,\n                                                 output_dir=f""./events/{time.time()}/"")\n\n    with session.transaction().write() as tx:\n        write_predictions_to_grakn(ge_graphs, tx)\n\n    session.close()\n    client.close()\n\n    return solveds_tr, solveds_ge\n\n\ndef create_concept_graphs(example_indices, grakn_session):\n    """"""\n    Builds an in-memory graph for each example, with an example_id as an anchor for each example subgraph.\n    Args:\n        example_indices: The values used to anchor the subgraph queries within the entire knowledge graph\n        grakn_session: Grakn Session\n\n    Returns:\n        In-memory graphs of Grakn subgraphs\n    """"""\n\n    graphs = []\n    infer = True\n\n    for example_id in example_indices:\n        print(f\'Creating graph for example {example_id}\')\n        graph_query_handles = get_query_handles(example_id)\n        with grakn_session.transaction().read() as tx:\n            # Build a graph from the queries, samplers, and query graphs\n            graph = build_graph_from_queries(graph_query_handles, tx, infer=infer)\n\n        obfuscate_labels(graph, TYPES_AND_ROLES_TO_OBFUSCATE)\n\n        graph.name = example_id\n        graphs.append(graph)\n\n    return graphs\n\n\ndef obfuscate_labels(graph, types_and_roles_to_obfuscate):\n    # Remove label leakage - change type labels that indicate candidates into non-candidates\n    for data in multidigraph_data_iterator(graph):\n        for label_to_obfuscate, with_label in types_and_roles_to_obfuscate.items():\n            if data[\'type\'] == label_to_obfuscate:\n                data.update(type=with_label)\n                break\n\n\ndef get_query_handles(example_id):\n    """"""\n    Creates an iterable, each element containing a Graql query, a function to sample the answers, and a QueryGraph\n    object which must be the Grakn graph representation of the query. This tuple is termed a ""query_handle""\n\n    Args:\n        example_id: A uniquely identifiable attribute value used to anchor the results of the queries to a specific\n                    subgraph\n\n    Returns:\n        query handles\n    """"""\n\n    # === Hereditary Feature ===\n    hereditary_query = inspect.cleandoc(f\'\'\'match\n           $p isa person, has example-id {example_id};\n           $par isa person;\n           $ps(child: $p, parent: $par) isa parentship;\n           $diag(patient:$par, diagnosed-disease: $d) isa diagnosis;\n           $d isa disease, has name $n;\n           get;\'\'\')\n\n    vars = p, par, ps, d, diag, n = \'p\', \'par\', \'ps\', \'d\', \'diag\', \'n\'\n    hereditary_query_graph = (QueryGraph()\n                              .add_vars(vars, PREEXISTS)\n                              .add_role_edge(ps, p, \'child\', PREEXISTS)\n                              .add_role_edge(ps, par, \'parent\', PREEXISTS)\n                              .add_role_edge(diag, par, \'patient\', PREEXISTS)\n                              .add_role_edge(diag, d, \'diagnosed-disease\', PREEXISTS)\n                              .add_has_edge(d, n, PREEXISTS))\n\n    # === Consumption Feature ===\n    consumption_query = inspect.cleandoc(f\'\'\'match\n           $p isa person, has example-id {example_id};\n           $s isa substance, has name $n;\n           $c(consumer: $p, consumed-substance: $s) isa consumption, \n           has units-per-week $u; get;\'\'\')\n\n    vars = p, s, n, c, u = \'p\', \'s\', \'n\', \'c\', \'u\'\n    consumption_query_graph = (QueryGraph()\n                               .add_vars(vars, PREEXISTS)\n                               .add_has_edge(s, n, PREEXISTS)\n                               .add_role_edge(c, p, \'consumer\', PREEXISTS)\n                               .add_role_edge(c, s, \'consumed-substance\', PREEXISTS)\n                               .add_has_edge(c, u, PREEXISTS))\n\n    # === Age Feature ===\n    person_age_query = inspect.cleandoc(f\'\'\'match \n            $p isa person, has example-id {example_id}, has age $a; \n            get;\'\'\')\n\n    vars = p, a = \'p\', \'a\'\n    person_age_query_graph = (QueryGraph()\n                              .add_vars(vars, PREEXISTS)\n                              .add_has_edge(p, a, PREEXISTS))\n\n    # === Risk Factors Feature ===\n    risk_factor_query = inspect.cleandoc(f\'\'\'match \n            $d isa disease; \n            $p isa person, has example-id {example_id}; \n            $r(person-at-risk: $p, risked-disease: $d) isa risk-factor; \n            get;\'\'\')\n\n    vars = p, d, r = \'p\', \'d\', \'r\'\n    risk_factor_query_graph = (QueryGraph()\n                               .add_vars(vars, PREEXISTS)\n                               .add_role_edge(r, p, \'person-at-risk\', PREEXISTS)\n                               .add_role_edge(r, d, \'risked-disease\', PREEXISTS))\n\n    # === Symptom ===\n    vars = p, s, sn, d, dn, sp, sev, c = \'p\', \'s\', \'sn\', \'d\', \'dn\', \'sp\', \'sev\', \'c\'\n\n    symptom_query = inspect.cleandoc(f\'\'\'match\n           $p isa person, has example-id {example_id};\n           $s isa symptom, has name $sn;\n           $d isa disease, has name $dn;\n           $sp(presented-symptom: $s, symptomatic-patient: $p) isa symptom-presentation, has severity $sev;\n           $c(cause: $d, effect: $s) isa causality;\n           get;\'\'\')\n\n    symptom_query_graph = (QueryGraph()\n                           .add_vars(vars, PREEXISTS)\n                           .add_has_edge(s, sn, PREEXISTS)\n                           .add_has_edge(d, dn, PREEXISTS)\n                           .add_role_edge(sp, s, \'presented-symptom\', PREEXISTS)\n                           .add_has_edge(sp, sev, PREEXISTS)\n                           .add_role_edge(sp, p, \'symptomatic-patient\', PREEXISTS)\n                           .add_role_edge(c, s, \'effect\', PREEXISTS)\n                           .add_role_edge(c, d, \'cause\', PREEXISTS))\n\n    # === Diagnosis ===\n\n    diag, d, p, dn = \'diag\', \'d\', \'p\', \'dn\'\n\n    diagnosis_query = inspect.cleandoc(f\'\'\'match\n           $p isa person, has example-id {example_id};\n           $d isa disease, has name $dn;\n           $diag(patient: $p, diagnosed-disease: $d) isa diagnosis;\n           get;\'\'\')\n\n    diagnosis_query_graph = (QueryGraph()\n                             .add_vars([diag], TO_INFER)\n                             .add_vars([d, p, dn], PREEXISTS)\n                             .add_role_edge(diag, d, \'diagnosed-disease\', TO_INFER)\n                             .add_role_edge(diag, p, \'patient\', TO_INFER))\n\n    # === Candidate Diagnosis ===\n    candidate_diagnosis_query = inspect.cleandoc(f\'\'\'match\n           $p isa person, has example-id {example_id};\n           $d isa disease, has name $dn;\n           $diag(candidate-patient: $p, candidate-diagnosed-disease: $d) isa candidate-diagnosis; \n           get;\'\'\')\n\n    candidate_diagnosis_query_graph = (QueryGraph()\n                                       .add_vars([diag], CANDIDATE)\n                                       .add_vars([d, p, dn], PREEXISTS)\n                                       .add_role_edge(diag, d, \'candidate-diagnosed-disease\', CANDIDATE)\n                                       .add_role_edge(diag, p, \'candidate-patient\', CANDIDATE))\n\n    return [\n        (symptom_query, lambda x: x, symptom_query_graph),\n        (diagnosis_query, lambda x: x, diagnosis_query_graph),\n        (candidate_diagnosis_query, lambda x: x, candidate_diagnosis_query_graph),\n        (risk_factor_query, lambda x: x, risk_factor_query_graph),\n        (person_age_query, lambda x: x, person_age_query_graph),\n        (consumption_query, lambda x: x, consumption_query_graph),\n        (hereditary_query, lambda x: x, hereditary_query_graph)\n    ]\n\n\ndef write_predictions_to_grakn(graphs, tx):\n    """"""\n    Take predictions from the ML model, and insert representations of those predictions back into the graph.\n\n    Args:\n        graphs: graphs containing the concepts, with their class predictions and class probabilities\n        tx: Grakn write transaction to use\n\n    Returns: None\n\n    """"""\n    for graph in graphs:\n        for node, data in graph.nodes(data=True):\n            if data[\'prediction\'] == 2:\n                concept = data[\'concept\']\n                concept_type = concept.type_label\n                if concept_type == \'diagnosis\' or concept_type == \'candidate-diagnosis\':\n                    neighbours = graph.neighbors(node)\n\n                    for neighbour in neighbours:\n                        concept = graph.nodes[neighbour][\'concept\']\n                        if concept.type_label == \'person\':\n                            person = concept\n                        else:\n                            disease = concept\n\n                    p = data[\'probabilities\']\n                    query = (f\'match\'\n                             f\'$p id {person.id};\'\n                             f\'$d id {disease.id};\'\n                             f\'$kgcn isa kgcn;\'\n                             f\'insert\'\n                             f\'$pd(patient: $p, diagnosed-disease: $d, diagnoser: $kgcn) isa diagnosis,\'\n                             f\'has probability-exists {p[2]:.3f},\'\n                             f\'has probability-non-exists {p[1]:.3f},\'  \n                             f\'has probability-preexists {p[0]:.3f};\')\n                    tx.query(query)\n    tx.commit()\n\n\nif __name__ == ""__main__"":\n    diagnosis_example()\n'"
kglib/kgcn/examples/diagnosis/diagnosis_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\nfrom unittest.mock import MagicMock\n\nimport grakn.client\nimport networkx as nx\nimport numpy as np\n\nfrom kglib.kgcn.examples.diagnosis.diagnosis import write_predictions_to_grakn, obfuscate_labels\nfrom kglib.utils.grakn.object.thing import Thing\nfrom kglib.utils.graph.test.case import GraphTestCase\n\n\nclass TestWritePredictionsToGrakn(unittest.TestCase):\n    def test_query_made_as_expected(self):\n        graph = nx.MultiDiGraph()\n\n        graph.add_node(0, concept=Thing(\'V123\', \'person\', \'entity\'), probabilities=np.array([1.0, 0.0, 0.0]),\n                       prediction=0)\n        graph.add_node(1, concept=Thing(\'V1235\', \'disease\', \'entity\'), probabilities=np.array([1.0, 0.0, 0.0]),\n                       prediction=0)\n        graph.add_node(2, concept=Thing(\'V6543\', \'diagnosis\', \'relation\'), probabilities=np.array([0.0, 0.0071, 0.9927]),\n                       prediction=2)\n\n        graph.add_edge(2, 0)\n        graph.add_edge(2, 1)\n\n        graphs = [graph]\n        tx = MagicMock(grakn.client.Transaction)\n\n        tx.commit = MagicMock()\n        tx.query = MagicMock()\n\n        write_predictions_to_grakn(graphs, tx)\n\n        expected_query = (f\'match\'\n                          f\'$p id V123;\'\n                          f\'$d id V1235;\'\n                          f\'$kgcn isa kgcn;\'\n                          f\'insert\'\n                          f\'$pd(patient: $p, diagnosed-disease: $d, diagnoser: $kgcn) isa diagnosis,\'\n                          f\'has probability-exists 0.993,\'\n                          f\'has probability-non-exists 0.007,\'\n                          f\'has probability-preexists 0.000;\')\n\n        tx.query.assert_called_with(expected_query)\n\n        tx.commit.assert_called()\n\n    def test_query_made_only_if_relation_wins(self):\n        graph = nx.MultiDiGraph()\n\n        graph.add_node(0, concept=Thing(\'V123\', \'person\', \'entity\'),\n                       probabilities=np.array([1.0, 0.0, 0.0]), prediction=0)\n        graph.add_node(1, concept=Thing(\'V1235\', \'disease\', \'entity\'),\n                       probabilities=np.array([1.0, 0.0, 0.0]), prediction=0)\n        graph.add_node(2, concept=Thing(\'V6543\', \'diagnosis\', \'relation\'),\n                       probabilities=np.array([0.0, 0.0, 1.0]), prediction=1)\n\n        graph.add_edge(2, 0)\n        graph.add_edge(2, 1)\n\n        graphs = [graph]\n        tx = MagicMock(grakn.client.Transaction)\n\n        tx.commit = MagicMock()\n        tx.query = MagicMock()\n\n        write_predictions_to_grakn(graphs, tx)\n\n        tx.query.assert_not_called()\n\n        tx.commit.assert_called()\n\n\nclass TestObfuscateLabels(GraphTestCase):\n\n    def test_labels_obfuscated_as_expected(self):\n\n        graph = nx.MultiDiGraph()\n\n        graph.add_node(0, type=\'person\')\n        graph.add_node(1, type=\'disease\')\n        graph.add_node(2, type=\'candidate-diagnosis\')\n\n        graph.add_edge(2, 0, type=\'candidate-patient\')\n        graph.add_edge(2, 1, type=\'candidate-diagnosed-disease\')\n\n        obfuscate_labels(graph, {\'candidate-diagnosis\': \'diagnosis\',\n                                 \'candidate-patient\': \'patient\',\n                                 \'candidate-diagnosed-disease\': \'diagnosed-disease\'})\n\n        expected_graph = nx.MultiDiGraph()\n        expected_graph.add_node(0, type=\'person\')\n        expected_graph.add_node(1, type=\'disease\')\n        expected_graph.add_node(2, type=\'diagnosis\')\n\n        expected_graph.add_edge(2, 0, type=\'patient\')\n        expected_graph.add_edge(2, 1, type=\'diagnosed-disease\')\n\n        self.assertGraphsEqual(graph, expected_graph)\n\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/utils/grakn/object/comparable.py,0,"b'\n#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\n\nclass PropertyComparable:\n    """"""\n    Methods to give to an object such that it can be compared with another object based on their\n    properties/attributes. Avoided using the name \'Attribute\' since this is common Grakn terminology.\n    """"""\n    def __eq__(self, other):\n        """"""Overrides the default implementation""""""\n        if isinstance(other, self.__class__):\n            return self.__dict__ == other.__dict__\n        return NotImplemented\n\n    def __ne__(self, other):\n        """"""Overrides the default implementation (unnecessary in Python 3)""""""\n        x = self.__eq__(other)\n        if x is not NotImplemented:\n            return not x\n        return NotImplemented\n\n    def __hash__(self):\n        """"""Overrides the default implementation""""""\n        return hash(tuple(sorted(self.__dict__.items())))\n'"
kglib/utils/grakn/object/thing.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nfrom kglib.utils.grakn.object.comparable import PropertyComparable\n\nDATA_TYPE_NAMES = (\'long\', \'double\', \'boolean\', \'date\', \'string\')\n\n\nclass Thing(PropertyComparable):\n    def __init__(self, id, type_label, base_type_label, data_type=None, value=None):\n        self.id = id\n        self.type_label = type_label\n        self.base_type_label = base_type_label  # TODO rename to base_type in line with Client Python\n\n        # If the thing is an attribute\n        self.data_type = data_type\n        self.value = value\n\n        # TODO Make attribute a separate class\n        if self.base_type_label == \'attribute\':\n            if self.data_type is None:\n                raise ValueError(\'Attribute data_type must be provided\')\n            if self.value is None:\n                raise ValueError(\'Attribute value must be provided\')\n\n    def __str__(self):\n        string = f\'<{self.type_label}, {self.id}\'\n        if self.base_type_label == \'attribute\':\n            string += f\': {self.value}\'\n        return string + \'>\'\n\n    def __repr__(self):\n        return self.__str__()\n\n\ndef build_thing(grakn_thing, tx):\n\n    id = grakn_thing.id\n    type_label = grakn_thing.type().label()\n    base_type_label = grakn_thing.as_remote(tx).base_type.replace(\'_TYPE\', \'\').lower()\n\n    assert(base_type_label in [\'entity\', \'relation\', \'attribute\'])\n\n    if base_type_label == \'attribute\':\n        data_type = grakn_thing.as_remote(tx).type().data_type().name.lower()\n        assert data_type in DATA_TYPE_NAMES\n        value = grakn_thing.value()\n\n        return Thing(id, type_label, base_type_label, data_type, value)\n\n    return Thing(id, type_label, base_type_label)\n'"
kglib/utils/grakn/test/base.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport os\nimport shutil\nimport subprocess as sp\nimport tempfile\nimport zipfile\n\n\nclass ZipFile(zipfile.ZipFile):\n    """""" Custom ZipFile class handling file permissions. """"""\n    def _extract_member(self, member, targetpath, pwd):\n        if not isinstance(member, zipfile.ZipInfo):\n            member = self.getinfo(member)\n\n        targetpath = super()._extract_member(member, targetpath, pwd)\n\n        attr = member.external_attr >> 16\n        if attr != 0:\n            os.chmod(targetpath, attr)\n        return targetpath\n\n\nclass GraknServer(object):\n    DISTRIBUTION_LOCATION = \'external/graknlabs_grakn_core/grakn-core-all-mac.zip\'\n    DISTRIBUTION_ROOT_DIR = \'grakn-core-all-mac\'\n\n    def __init__(self):\n        self.__unpacked_dir = None\n\n    def __enter__(self):\n        return self.start()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        return self.stop()\n\n    def start(self):\n        if not self.__unpacked_dir:\n            self._unpack()\n        sp.check_call([\n            \'grakn\', \'server\', \'start\'\n        ], cwd=os.path.join(self.__unpacked_dir, GraknServer.DISTRIBUTION_ROOT_DIR))\n        return self\n\n    def stop(self):\n        sp.check_call([\n            \'grakn\', \'server\', \'stop\'\n        ], cwd=os.path.join(self.__unpacked_dir, GraknServer.DISTRIBUTION_ROOT_DIR))\n        shutil.rmtree(self.__unpacked_dir)\n        return self\n\n    def _unpack(self):\n        self.__unpacked_dir = tempfile.mkdtemp(prefix=\'grakn\')\n        with ZipFile(GraknServer.DISTRIBUTION_LOCATION) as zf:\n            zf.extractall(self.__unpacked_dir)\n\n    def load_graql_file(self, keyspace, graql_file_path):\n        sp.check_call([\n            \'grakn\', \'console\', \'-k\', keyspace, \'-f\',\n            os.getenv(""TEST_SRCDIR"") + graql_file_path\n        ], cwd=self.grakn_binary_location)\n\n    @property\n    def grakn_binary_location(self):\n        return os.path.join(self.__unpacked_dir, GraknServer.DISTRIBUTION_ROOT_DIR)\n'"
kglib/utils/grakn/type/type.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\n\ndef get_thing_types(tx):\n    """"""\n    Get all schema types, excluding those for implicit attribute relations and base types\n    Args:\n        tx: Grakn transaction\n\n    Returns:\n        Grakn types\n    """"""\n    schema_concepts = tx.query(\n        ""match $x sub thing; ""\n        ""not {$x sub @has-attribute;}; ""\n        ""not {$x sub @key-attribute;}; ""\n        ""get;"")\n    thing_types = [schema_concept.get(\'x\').label() for schema_concept in schema_concepts]\n    [thing_types.remove(el) for el in [\'thing\', \'relation\', \'entity\', \'attribute\']]\n    return thing_types\n\n\ndef get_role_types(tx):\n    """"""\n    Get all schema roles, excluding those for implicit attribute relations, the base role type\n    Args:\n        tx: Grakn transaction\n\n    Returns:\n        Grakn roles\n    """"""\n    schema_concepts = tx.query(\n        ""match $x sub role; ""\n        ""not{$x sub @key-attribute-value;}; ""\n        ""not{$x sub @key-attribute-owner;}; ""\n        ""not{$x sub @has-attribute-value;}; ""\n        ""not{$x sub @has-attribute-owner;};""\n        ""get;"")\n    role_types = [\'has\'] + [role.get(\'x\').label() for role in schema_concepts]\n    role_types.remove(\'role\')\n    return role_types\n'"
kglib/utils/graph/query/query_graph.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport networkx as nx\n\n\nclass QueryGraph(nx.MultiDiGraph):\n    """"""\n    A custom graph to represent a query. Has additional helper methods specific to adding Graql patterns.\n    """"""\n\n    def add_vars(self, vars, solution):\n        """"""\n        Add Graql variables, stored as nodes in the graph\n        Args:\n            vars: String variables\n            solution: Indicator of the ground truth class that the variables belongs to\n\n        Returns:\n            self\n        """"""\n        for var in vars:\n            self.add_node(var, solution=solution)\n        return self\n\n    def add_has_edge(self, owner_var, attribute_var, solution):\n        """"""\n        Add a ""has"" edge to represent ownership of an attribute\n        Args:\n            owner_var: The variable of the owner\n            attribute_var: The variable of the owned attribute\n            solution: Indicator of the ground truth class that the edge belongs to\n\n        Returns:\n            self\n        """"""\n        self.add_edge(owner_var, attribute_var, type=\'has\', solution=solution)\n        return self\n\n    def add_role_edge(self, relation_var, roleplayer_var, role_label, solution):\n        """"""\n        Add an edge to represent the role a variable plays in a relation\n        Args:\n            relation_var: The variable of the relation\n            roleplayer_var: The variable of the roleplayer in the relation\n            role_label: The role the roleplayer plays in the relation\n            solution: Indicator of the ground truth class that the edge belongs to\n\n        Returns:\n            self\n        """"""\n        self.add_edge(relation_var, roleplayer_var, type=role_label, solution=solution)\n        return self\n'"
kglib/utils/graph/query/query_graph_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nfrom kglib.utils.graph.query.query_graph import QueryGraph\n\n\nclass TestQueryGraph(unittest.TestCase):\n\n    def test_add_single_var_adds_variable_node_as_expected(self):\n        g = QueryGraph()\n        g.add_vars([\'a\'], 0)\n        self.assertDictEqual({\'solution\': 0}, g.nodes[\'a\'])\n\n    def test_add_vars_adds_variable_nodes_as_expected(self):\n        g = QueryGraph()\n        g.add_vars([\'a\', \'b\'], 0)\n        nodes = {node for node in g.nodes}\n        self.assertSetEqual({\'a\', \'b\'}, nodes)\n\n    def test_add_has_edge_adds_edge_as_expected(self):\n        g = QueryGraph()\n        g.add_vars(\'a\', \'b\')\n        g.add_has_edge(\'a\', \'b\', 0)\n        edges = [edge for edge in g.edges]\n        self.assertEqual(1, len(edges))\n        self.assertDictEqual({\'type\': \'has\', \'solution\': 0}, g.edges[\'a\', \'b\', 0])\n\n    def test_add_role_edge_adds_role_as_expected(self):\n        g = QueryGraph()\n        g.add_vars(\'a\', \'b\')\n        g.add_role_edge(\'a\', \'b\', \'role_label\', 1)\n        edges = [edge for edge in g.edges]\n        self.assertEqual(1, len(edges))\n        self.assertDictEqual({\'type\': \'role_label\', \'solution\': 1}, g.edges[\'a\', \'b\', 0])\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/utils/graph/test/case.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport networkx as nx\n\n\ndef match_node_things(data1, data2):\n    return data1 == data2\n\n\ndef match_edge_types(data1, data2):\n    return data1 == data2\n\n\nclass GraphTestCase(unittest.TestCase):\n\n    def assertNodesEqual(self, graph_1, graph_2):\n        try:\n            self.assertCountEqual(list(graph_1.nodes()), list(graph_2.nodes()))\n        except AssertionError as e:\n            raise AssertionError(\'Node counts do not match. \' + str(e))\n\n    def assertEdgesEqual(self, graph_1, graph_2):\n        try:\n            self.assertCountEqual(list(graph_1.edges()), list(graph_2.edges()))\n        except AssertionError as e:\n            raise AssertionError(\'Edge counts do not match. \' + str(e))\n\n    def assertIsIsomorphic(self, graph_1, graph_2):\n        try:\n            self.assertTrue(nx.is_isomorphic(graph_1, graph_2,\n                                             node_match=match_node_things,\n                                             edge_match=match_edge_types))\n        except AssertionError:\n            raise AssertionError(\n                ""The two graphs are not isomorphic based on the data attached to the nodes and/or edges"")\n\n    def assertGraphsEqual(self, graph_1, graph_2):\n        self.assertNodesEqual(graph_1, graph_2)\n        self.assertEdgesEqual(graph_1, graph_2)\n        self.assertIsIsomorphic(graph_1, graph_2)\n'"
kglib/utils/graph/thing/concept_dict_to_graph.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport networkx as nx\n\n\ndef concept_dict_to_graph(concept_dict, variable_graph):\n    """"""\n    Create a new graph from a concept_dict, based on a `variable_graph` that describes the interactions between the\n    variables in the `concept_dict`\n    Args:\n        concept_dict: A dictionary with variable names as keys, values are Things\n        variable_graph: A graph with variable names as nodes, edges represent roles and has connections, indicated by\n            the key ""type"" stored on each edge\n\n    Returns:\n        A graph with Things as nodes. Edges connecting the nodes have only role/has type information in their data\n    """"""\n    grakn_graph = nx.MultiDiGraph()\n    node_to_var = {}\n\n    if set(variable_graph.nodes()) != set(concept_dict.keys()):\n\n        in_var_graph_not_in_concept_dict = set(variable_graph).difference(set(concept_dict.keys()))\n        in_concept_dict_not_in_var_graph = set(concept_dict.keys()).difference(set(variable_graph))\n\n        raise ValueError(f\'The variables in the variable_graph must match those in the concept_dict\\n\'\n                         f\'In the variable graph but not in the concept dict: {in_var_graph_not_in_concept_dict}\\n\'\n                         f\'In the concept dict but not in the variable graph: {in_concept_dict_not_in_var_graph}\')\n\n    # This assumes that all variables are nodes, which would not be the case for variable roles\n    for variable, thing in concept_dict.items():\n        data = variable_graph.nodes[variable]\n        data.update(type=thing.type_label)\n        if thing.base_type_label == \'attribute\':\n            data.update(datatype=thing.data_type, value=thing.value)\n\n        grakn_graph.add_node(thing, **data)\n\n        # Record the mapping of nodes from one graph to the other\n        assert variable not in node_to_var\n        node_to_var[variable] = thing\n\n    for sending_var, receiving_var, data in variable_graph.edges(data=True):\n        sender = node_to_var[sending_var]\n        receiver = node_to_var[receiving_var]\n\n        if sender.base_type_label != \'relation\' and not (\n                receiver.base_type_label == \'attribute\' and data[\'type\'] == \'has\'):\n            raise ValueError(\'An edge in the variable_graph originates from a non-relation, check the variable_graph!\')\n\n        if data[\'type\'] == \'has\':\n            grakn_graph.add_edge(sender, receiver, **data)\n        else:\n            grakn_graph.add_edge(sender, receiver, **data)\n\n    return grakn_graph\n'"
kglib/utils/graph/thing/concept_dict_to_graph_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\nimport networkx as nx\n\nfrom kglib.utils.grakn.object.thing import Thing\nfrom kglib.utils.graph.thing.concept_dict_to_graph import concept_dict_to_graph\nfrom kglib.utils.graph.test.case import GraphTestCase\n\n\nclass TestConceptDictToGraknGraph(GraphTestCase):\n    def test_single_entity_graph_is_as_expected(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        concept_dict = {\'x\': person}\n\n        grakn_graph = concept_dict_to_graph(concept_dict, variable_graph)\n        expected_grakn_graph = nx.MultiDiGraph()\n        expected_grakn_graph.add_node(person, type=\'person\')\n\n        self.assertGraphsEqual(expected_grakn_graph, grakn_graph)\n\n    def test_single_attribute_graph_is_as_expected(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n\n        name = Thing(\'V123\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        concept_dict = {\'x\': name}\n\n        grakn_graph = concept_dict_to_graph(concept_dict, variable_graph)\n        expected_grakn_graph = nx.MultiDiGraph()\n        expected_grakn_graph.add_node(name, type=\'name\', datatype=\'string\', value=\'Bob\')\n\n        self.assertGraphsEqual(expected_grakn_graph, grakn_graph)\n\n    def test_single_entity_single_relation_graph_is_as_expected(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n        variable_graph.add_node(\'y\')\n        variable_graph.add_edge(\'y\', \'x\', type=\'employee\')\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        employment = Thing(\'V123\', \'employment\', \'relation\')\n        concept_dict = {\'x\': person, \'y\': employment}\n\n        grakn_graph = concept_dict_to_graph(concept_dict, variable_graph)\n        expected_grakn_graph = nx.MultiDiGraph()\n        expected_grakn_graph.add_node(person, type=\'person\')\n        expected_grakn_graph.add_node(employment, type=\'employment\')\n        expected_grakn_graph.add_edge(employment, person, type=\'employee\')\n\n        self.assertGraphsEqual(expected_grakn_graph, grakn_graph)\n\n    def test_two_entity_single_relation_graph_is_as_expected(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n        variable_graph.add_node(\'y\')\n        variable_graph.add_node(\'r\')\n        variable_graph.add_edge(\'r\', \'x\', type=\'employee\')\n        variable_graph.add_edge(\'r\', \'y\', type=\'employer\')\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        company = Thing(\'V1234\', \'company\', \'entity\')\n        employment = Thing(\'V12345\', \'employment\', \'relation\')\n        concept_dict = {\'x\': person, \'y\': company, \'r\': employment}\n\n        grakn_graph = concept_dict_to_graph(concept_dict, variable_graph)\n\n        expected_grakn_graph = nx.MultiDiGraph()\n        expected_grakn_graph.add_node(person, type=\'person\')\n        expected_grakn_graph.add_node(company, type=\'company\')\n        expected_grakn_graph.add_node(employment, type=\'employment\')\n        expected_grakn_graph.add_edge(employment, person, type=\'employee\')\n        expected_grakn_graph.add_edge(employment, company, type=\'employer\')\n\n        self.assertGraphsEqual(expected_grakn_graph, grakn_graph)\n\n    def test_same_thing_occurs_in_two_different_variables(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n        variable_graph.add_node(\'y\')\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        person2 = Thing(\'V123\', \'person\', \'entity\')\n        concept_dict = {\'x\': person,\n                        \'y\': person2}\n\n        grakn_graph = concept_dict_to_graph(concept_dict, variable_graph)\n        expected_grakn_graph = nx.MultiDiGraph()\n        expected_grakn_graph.add_node(person, type=\'person\')\n\n        self.assertGraphsEqual(expected_grakn_graph, grakn_graph)\n\n    def test_edge_starting_from_entity_throws_exception(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n        variable_graph.add_node(\'y\')\n        variable_graph.add_edge(\'x\', \'y\', type=\'employee\')\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        employment = Thing(\'V123\', \'employment\', \'relation\')\n        concept_dict = {\'x\': person, \'y\': employment}\n\n        with self.assertRaises(ValueError) as context:\n            _ = concept_dict_to_graph(concept_dict, variable_graph)\n\n        self.assertEqual(\'An edge in the variable_graph originates from a non-relation, check the variable_graph!\',\n                         str(context.exception))\n\n    def test_edge_starting_from_attribute_throws_exception(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n        variable_graph.add_node(\'y\')\n        variable_graph.add_edge(\'x\', \'y\', type=\'employee\')\n\n        name = Thing(\'V123\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        employment = Thing(\'V123\', \'employment\', \'relation\')\n        concept_dict = {\'x\': name, \'y\': employment}\n\n        with self.assertRaises(ValueError) as context:\n            _ = concept_dict_to_graph(concept_dict, variable_graph)\n\n        self.assertEqual(\'An edge in the variable_graph originates from a non-relation, check the variable_graph!\',\n                         str(context.exception))\n\n    def test_exception_if_sets_of_variables_differ(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\')\n        variable_graph.add_node(\'y\')\n        variable_graph.add_node(\'z\')\n\n        thing = Thing(\'V123\', \'person\', \'entity\')\n        concept_dict = {\'x\': thing,\n                        \'y\': thing,\n                        \'a\': thing}\n\n        with self.assertRaises(ValueError) as context:\n            _ = concept_dict_to_graph(concept_dict, variable_graph)\n\n        self.assertEqual(\n            \'The variables in the variable_graph must match those in the concept_dict\\n\'\n            \'In the variable graph but not in the concept dict: {\\\'z\\\'}\\n\'\n            \'In the concept dict but not in the variable graph: {\\\'a\\\'}\',\n            str(context.exception))\n\n    def test_variable_graph_properties_are_transferred_to_graph(self):\n        variable_graph = nx.MultiDiGraph()\n        variable_graph.add_node(\'x\', input=1, solution=1)\n        variable_graph.add_node(\'y\', input=1, solution=1)\n        variable_graph.add_edge(\'y\', \'x\', type=\'employee\', input=0, solution=1)\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        employment = Thing(\'V123\', \'employment\', \'relation\')\n        concept_dict = {\'x\': person, \'y\': employment}\n\n        grakn_graph = concept_dict_to_graph(concept_dict, variable_graph)\n        expected_grakn_graph = nx.MultiDiGraph()\n        expected_grakn_graph.add_node(person, type=\'person\', input=1, solution=1)\n        expected_grakn_graph.add_node(employment, type=\'employment\', input=1, solution=1)\n        expected_grakn_graph.add_edge(employment, person, type=\'employee\', input=0, solution=1)\n\n        self.assertGraphsEqual(expected_grakn_graph, grakn_graph)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/utils/graph/thing/queries_to_graph.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\nimport warnings\nfrom functools import reduce\n\nimport networkx as nx\n\nfrom kglib.utils.grakn.object.thing import build_thing\nfrom kglib.utils.graph.thing.concept_dict_to_graph import concept_dict_to_graph\n\n\ndef concept_dict_from_concept_map(concept_map, tx):\n    """"""\n    Given a concept map, build a dictionary of the variables present and the concepts they refer to, locally storing any\n    information required about those concepts.\n\n    Args:\n        concept_map: A dict of Concepts provided by Grakn keyed by query variables\n\n    Returns:\n        A dictionary of concepts keyed by query variables\n    """"""\n    return {variable: build_thing(grakn_concept, tx) for variable, grakn_concept in concept_map.map().items()}\n\n\ndef combine_2_graphs(graph1, graph2):\n    """"""\n    Combine two graphs into one. Do this by recognising common nodes between the two.\n\n    Args:\n        graph1: Graph to compare\n        graph2: Graph to compare\n\n    Returns:\n        Combined graph\n    """"""\n\n    for node, data in graph1.nodes(data=True):\n        if graph2.has_node(node):\n            data2 = graph2.nodes[node]\n            if data2 != data:\n                raise ValueError((f\'Found non-matching node properties for node {node} \'\n                                  f\'between graphs {graph1} and {graph2}:\\n\'\n                                  f\'In graph {graph1}: {data}\\n\'\n                                  f\'In graph {graph2}: {data2}\'))\n\n    for sender, receiver, keys, data in graph1.edges(data=True, keys=True):\n        if graph2.has_edge(sender, receiver, keys):\n            data2 = graph2.edges[sender, receiver, keys]\n            if data2 != data:\n                raise ValueError((f\'Found non-matching edge properties for edge {sender, receiver, keys} \'\n                                  f\'between graphs {graph1} and {graph2}:\\n\'\n                                  f\'In graph {graph1}: {data}\\n\'\n                                  f\'In graph {graph2}: {data2}\'))\n\n    return nx.compose(graph1, graph2)\n\n\ndef combine_n_graphs(graphs_list):\n    """"""\n    Combine N graphs into one. Do this by recognising common nodes between the two.\n\n    Args:\n        graphs_list: List of graphs to combine\n\n    Returns:\n        Combined graph\n    """"""\n    return reduce(lambda x, y: combine_2_graphs(x, y), graphs_list)\n\n\ndef build_graph_from_queries(query_sampler_variable_graph_tuples, grakn_transaction,\n                             concept_dict_converter=concept_dict_to_graph, infer=True):\n    """"""\n    Builds a graph of Things, interconnected by roles (and *has*), from a set of queries and graphs representing those\n    queries (variable graphs)of those queries, over a Grakn transaction\n\n    Args:\n        infer: whether to use Grakn\'s inference engine\n        query_sampler_variable_graph_tuples: A list of tuples, each tuple containing a query, a sampling function,\n            and a variable_graph\n        grakn_transaction: A Grakn transaction\n        concept_dict_converter: The function to use to convert from concept_dicts to a Grakn model. This could be\n            a typical model or a mathematical model\n\n    Returns:\n        A networkx graph\n    """"""\n\n    query_concept_graphs = []\n\n    for query, sampler, variable_graph in query_sampler_variable_graph_tuples:\n\n        concept_maps = sampler(grakn_transaction.query(query, infer=infer))\n\n        concept_dicts = [concept_dict_from_concept_map(concept_map, grakn_transaction) for concept_map in concept_maps]\n\n        answer_concept_graphs = []\n        for concept_dict in concept_dicts:\n            try:\n                answer_concept_graphs.append(concept_dict_converter(concept_dict, variable_graph))\n            except ValueError as e:\n                raise ValueError(str(e) + f\'Encountered processing query:\\n \\""{query}\\""\')\n\n        if len(answer_concept_graphs) > 1:\n            query_concept_graph = combine_n_graphs(answer_concept_graphs)\n            query_concept_graphs.append(query_concept_graph)\n        else:\n            if len(answer_concept_graphs) > 0:\n                query_concept_graphs.append(answer_concept_graphs[0])\n            else:\n                warnings.warn(f\'There were no results for query: \\n\\""{query}\\""\\nand so nothing will be added to the \'\n                              f\'graph for this query\')\n\n    if len(query_concept_graphs) == 0:\n        # Raise exception when none of the queries returned any results\n        raise RuntimeError(f\'The graph from queries: {[query_sampler_variable_graph_tuple[0] for query_sampler_variable_graph_tuple in query_sampler_variable_graph_tuples]}\\n\'\n                           f\'could not be created, since none of these queries returned results\')\n\n    concept_graph = combine_n_graphs(query_concept_graphs)\n    return concept_graph\n'"
kglib/utils/graph/thing/queries_to_graph_it.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\nimport unittest\n\nimport networkx as nx\nfrom grakn.client import GraknClient\n\nfrom kglib.utils.grakn.object.thing import Thing, build_thing\nfrom kglib.utils.grakn.test.base import GraknServer\nfrom kglib.utils.grakn.test.mock.answer import MockConceptMap\nfrom kglib.utils.grakn.test.mock.concept import MockType, MockAttributeType, MockThing, MockAttribute\nfrom kglib.utils.graph.thing.queries_to_graph import build_graph_from_queries\nfrom kglib.utils.graph.test.case import GraphTestCase\n\nTEST_URI = ""localhost:48555""\n\n\ndef mock_sampler(input_iter):\n    return input_iter\n\n\nclass MockTransaction:\n    def query(self, query, infer=True):\n\n        if query == \'match $x id V123; get;\':\n            return [MockConceptMap({\'x\': MockThing(\'V123\', MockType(\'V4123\', \'person\', \'ENTITY\'))})]\n        elif query == \'match $x id V123, has name $n; get;\':\n            return [\n                MockConceptMap({\n                    \'x\': MockThing(\'V123\', MockType(\'V4123\', \'person\', \'ENTITY\')),\n                    \'n\': MockAttribute(\'V987\', \'Bob\', MockAttributeType(\'V555\', \'name\', \'ATTRIBUTE\', \'STRING\'))\n                })]\n        elif query == \'match $x id V123; $r(child: $x, parent: $y); get;\':\n            return [\n                MockConceptMap({\n                    \'x\': MockThing(\'V123\', MockType(\'V4123\', \'person\', \'ENTITY\')),\n                    \'y\': MockThing(\'V123\', MockType(\'V4123\', \'person\', \'ENTITY\')),\n                    \'r\': MockThing(\'V567\', MockType(\'V9876\', \'parentship\', \'RELATION\'))\n                })]\n        else:\n            raise NotImplementedError\n\n\nclass ITBuildGraphFromQueries(GraphTestCase):\n    def test_graph_is_built_as_expected(self):\n        g1 = nx.MultiDiGraph()\n        g1.add_node(\'x\')\n\n        g2 = nx.MultiDiGraph()\n        g2.add_node(\'x\')\n        g2.add_node(\'n\')\n        g2.add_edge(\'x\', \'n\', type=\'has\')\n\n        g3 = nx.MultiDiGraph()\n        g3.add_node(\'x\')\n        g3.add_node(\'r\')\n        g3.add_node(\'y\')\n        g3.add_edge(\'r\', \'x\', type=\'child\')\n        g3.add_edge(\'r\', \'y\', type=\'parent\')\n\n        query_sampler_variable_graph_tuples = [(\'match $x id V123; get;\', mock_sampler, g1),\n                                               (\'match $x id V123, has name $n; get;\', mock_sampler, g2),\n                                               (\'match $x id V123; $r(child: $x, parent: $y); get;\', mock_sampler, g3),\n                                               # TODO Add functionality for loading schema at a later date\n                                               # (\'match $x sub person; $x sub $type; get;\', g4),\n                                               # (\'match $x sub $y; get;\', g5),\n                                               ]\n\n        mock_tx = MockTransaction()\n\n        combined_graph = build_graph_from_queries(query_sampler_variable_graph_tuples, mock_tx)\n\n        person_exp = Thing(\'V123\', \'person\', \'entity\')\n        parentship_exp = Thing(\'V567\', \'parentship\', \'relation\')\n        name_exp = Thing(\'V987\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        expected_combined_graph = nx.MultiDiGraph()\n        expected_combined_graph.add_node(person_exp, type=\'person\')\n        expected_combined_graph.add_node(name_exp, type=\'name\', datatype=\'string\', value=\'Bob\')\n        expected_combined_graph.add_node(parentship_exp, type=\'parentship\')\n        expected_combined_graph.add_edge(parentship_exp, person_exp, type=\'child\')\n        expected_combined_graph.add_edge(parentship_exp, person_exp, type=\'parent\')\n        expected_combined_graph.add_edge(person_exp, name_exp, type=\'has\')\n\n        self.assertGraphsEqual(expected_combined_graph, combined_graph)\n\n    def test_warning_given_when_one_query_gives_no_results(self):\n        g1 = nx.MultiDiGraph()\n        g1.add_node(\'x\')\n        g2 = nx.MultiDiGraph()\n        g2.add_node(\'y\')\n        query_sampler_variable_graph_tuples = [(\'match $x id V123; get;\', mock_sampler, g1),\n                                               (\'match $y id V123; get;\', mock_sampler, g2)]\n\n        class MockTransaction2:\n            def query(self, query, infer=True):\n                if query == \'match $x id V123; get;\':\n                    return [MockConceptMap({\'x\': MockThing(\'V123\', MockType(\'V4123\', \'person\', \'ENTITY\'))})]\n                elif query == \'match $y id V123; get;\':\n                    return []\n\n        mock_tx = MockTransaction2()\n\n        with self.assertWarns(UserWarning) as context:\n            build_graph_from_queries(query_sampler_variable_graph_tuples, mock_tx)\n\n        self.assertEqual(f\'There were no results for query: \\n\\""match $y id V123; get;\\""\\nand so nothing will be added to the graph for this query\', str(context.warning))\n\n    def test_exception_is_raised_when_there_are_no_results_for_any_query(self):\n        g1 = nx.MultiDiGraph()\n        g1.add_node(\'x\')\n        query_sampler_variable_graph_tuples = [(\'match $x id V123; get;\', mock_sampler, g1)]\n\n        class MockTransactionEmpty:\n            def query(self, query, infer=True):\n                return []\n\n        mock_tx = MockTransactionEmpty()\n\n        with self.assertRaises(RuntimeError) as context:\n            build_graph_from_queries(query_sampler_variable_graph_tuples, mock_tx)\n\n        self.assertEqual(f\'The graph from queries: {[query_sampler_variable_graph_tuple[0] for query_sampler_variable_graph_tuple in query_sampler_variable_graph_tuples]}\\n\'\n                         f\'could not be created, since none of these queries returned results\', str(context.exception))\n\n\nclass ITBuildGraphFromQueriesWithRealGrakn(GraphTestCase):\n\n    KEYSPACE = ""it_build_graph_from_queries""\n    SCHEMA = (""define ""\n              ""person sub entity, has name, plays parent, plays child;""\n              ""name sub attribute, datatype string;""\n              ""parentship sub relation, relates parent, relates child;"")\n    DATA = (\'insert \'\n            \'$p isa person, has name ""Bob"";\'\n            \'$r(parent: $p, child: $p) isa parentship;\')\n\n    def setUp(self):\n        self._keyspace = type(self).__name__.lower()  # Use the name of this test class as the keyspace name\n        print(self._keyspace)\n        self._client = GraknClient(uri=""localhost:48555"")\n\n    def tearDown(self):\n        self._client.keyspaces().delete(self._keyspace)\n        self._client.close()\n\n    def test_graph_is_built_from_grakn_as_expected(self):\n\n        g1 = nx.MultiDiGraph()\n        g1.add_node(\'x\')\n\n        g2 = nx.MultiDiGraph()\n        g2.add_node(\'x\')\n        g2.add_node(\'n\')\n        g2.add_edge(\'x\', \'n\', type=\'has\')\n\n        g3 = nx.MultiDiGraph()\n        g3.add_node(\'x\')\n        g3.add_node(\'r\')\n        g3.add_node(\'y\')\n        g3.add_edge(\'r\', \'x\', type=\'child\')\n        g3.add_edge(\'r\', \'y\', type=\'parent\')\n\n        query_sampler_variable_graph_tuples = [(\'match $x isa person; get;\', mock_sampler, g1),\n                                               (\'match $x isa person, has name $n; get;\', mock_sampler, g2),\n                                               (\'match $x isa person; $r(child: $x, parent: $y); get;\', mock_sampler, g3),\n                                               # TODO Add functionality for loading schema at a later date\n                                               # (\'match $x sub person; $x sub $type; get;\', g4),\n                                               # (\'match $x sub $y; get;\', g5),\n                                               ]\n\n        with self._client.session(keyspace=self._keyspace) as session:\n\n            with session.transaction().write() as tx:\n                tx.query(ITBuildGraphFromQueriesWithRealGrakn.SCHEMA)\n                tx.query(ITBuildGraphFromQueriesWithRealGrakn.DATA)\n                tx.commit()\n\n            with session.transaction().read() as tx:\n                combined_graph = build_graph_from_queries(query_sampler_variable_graph_tuples, tx)\n\n                person_exp = build_thing(next(tx.query(\'match $x isa person; get;\')).get(\'x\'), tx)\n                name_exp = build_thing(next(tx.query(\'match $x isa name; get;\')).get(\'x\'), tx)\n                parentship_exp = build_thing(next(tx.query(\'match $x isa parentship; get;\')).get(\'x\'), tx)\n\n        expected_combined_graph = nx.MultiDiGraph()\n        expected_combined_graph.add_node(person_exp, type=\'person\')\n        expected_combined_graph.add_node(name_exp, type=\'name\', datatype=\'string\', value=\'Bob\')\n        expected_combined_graph.add_node(parentship_exp, type=\'parentship\')\n        expected_combined_graph.add_edge(parentship_exp, person_exp, type=\'child\')\n        expected_combined_graph.add_edge(parentship_exp, person_exp, type=\'parent\')\n        expected_combined_graph.add_edge(person_exp, name_exp, type=\'has\')\n\n        self.assertGraphsEqual(expected_combined_graph, combined_graph)\n\n\nif __name__ == ""__main__"":\n\n    with GraknServer() as gs:\n        unittest.main()\n'"
kglib/utils/graph/thing/queries_to_graph_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport networkx as nx\n\nfrom kglib.utils.grakn.object.thing import Thing\nfrom kglib.utils.grakn.test.mock.answer import MockConceptMap\nfrom kglib.utils.grakn.test.mock.concept import MockType, MockThing\nfrom kglib.utils.graph.thing.queries_to_graph import concept_dict_from_concept_map, combine_2_graphs\nfrom kglib.utils.graph.test.case import GraphTestCase\n\n\nclass TestConceptDictsFromQuery(unittest.TestCase):\n    def test_concept_dicts_are_built_as_expected(self):\n        concept_map = MockConceptMap({\'x\': MockThing(\'V123\', MockType(\'V456\', \'person\', \'ENTITY\'))})\n        concept_dicts = concept_dict_from_concept_map(concept_map, None)\n\n        expected_concept_dicts = {\'x\': Thing(\'V123\', \'person\', \'entity\')}\n\n        self.assertEqual(expected_concept_dicts, concept_dicts)\n\n    def test_concept_dicts_are_built_as_expected_with_2_concepts(self):\n        concept_map = MockConceptMap({\n            \'x\': MockThing(\'V123\', MockType(\'V456\', \'person\', \'ENTITY\')),\n            \'y\': MockThing(\'V789\', MockType(\'V765\', \'employment\', \'RELATION\')),\n        })\n\n        concept_dicts = concept_dict_from_concept_map(concept_map, None)\n\n        expected_concept_dict = {\n            \'x\': Thing(\'V123\', \'person\', \'entity\'),\n            \'y\': Thing(\'V789\', \'employment\', \'relation\'),\n        }\n\n        self.assertEqual(expected_concept_dict, concept_dicts)\n\n\nclass TestCombineGraphs(GraphTestCase):\n\n    def test_graph_combined_as_expected(self):\n\n        person = Thing(\'V123\', \'person\', \'entity\')\n        employment = Thing(\'V567\', \'employment\', \'relation\')\n        grakn_graph_a = nx.MultiDiGraph()\n        grakn_graph_a.add_node(person)\n        grakn_graph_a.add_node(employment)\n        grakn_graph_a.add_edge(employment, person, type=\'employee\')\n\n        person_b = Thing(\'V123\', \'person\', \'entity\')\n        name = Thing(\'V1234\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        grakn_graph_b = nx.MultiDiGraph()\n        grakn_graph_b.add_node(person_b)\n        grakn_graph_b.add_node(name)\n        grakn_graph_b.add_edge(person_b, name, type=\'has\')\n\n        combined_graph = combine_2_graphs(grakn_graph_a, grakn_graph_b)\n\n        person_ex = Thing(\'V123\', \'person\', \'entity\')\n        employment_ex = Thing(\'V567\', \'employment\', \'relation\')\n        name_ex = Thing(\'V1234\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        expected_combined_graph = nx.MultiDiGraph()\n        expected_combined_graph.add_node(person_ex)\n        expected_combined_graph.add_node(name_ex)\n        expected_combined_graph.add_node(employment_ex)\n        expected_combined_graph.add_edge(employment_ex, person_ex, type=\'employee\')\n        expected_combined_graph.add_edge(person_ex, name_ex, type=\'has\')\n\n        self.assertGraphsEqual(expected_combined_graph, combined_graph)\n\n    def test_when_graph_node_properties_are_mismatched_exception_is_raised(self):\n        person_a = Thing(\'V123\', \'person\', \'entity\')\n        name_a = Thing(\'V1234\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        grakn_graph_a = nx.MultiDiGraph(name=\'a\')\n        grakn_graph_a.add_node(person_a, input=1, solution=1)\n        grakn_graph_a.add_node(name_a, input=1, solution=1)\n        grakn_graph_a.add_edge(person_a, name_a, type=\'has\', input=0, solution=1)\n\n        person_b = Thing(\'V123\', \'person\', \'entity\')\n        name_b = Thing(\'V1234\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        grakn_graph_b = nx.MultiDiGraph(name=\'b\')\n        grakn_graph_b.add_node(person_b, input=1, solution=1)\n        grakn_graph_b.add_node(name_b, input=0, solution=1)\n        grakn_graph_b.add_edge(person_b, name_b, type=\'has\', input=0, solution=1)\n\n        with self.assertRaises(ValueError) as context:\n            combine_2_graphs(grakn_graph_a, grakn_graph_b)\n\n        self.assertEqual((\'Found non-matching node properties for node <name, V1234: Bob> \'\n                          \'between graphs a and b:\\n\'\n                          \'In graph a: {\\\'input\\\': 1, \\\'solution\\\': 1}\\n\'\n                          \'In graph b: {\\\'input\\\': 0, \\\'solution\\\': 1}\'), str(context.exception))\n\n    def test_when_graph_edge_properties_are_mismatched_exception_is_raised(self):\n        person_a = Thing(\'V123\', \'person\', \'entity\')\n        name_a = Thing(\'V1234\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        grakn_graph_a = nx.MultiDiGraph(name=\'a\')\n        grakn_graph_a.add_node(person_a, input=1, solution=1)\n        grakn_graph_a.add_node(name_a, input=1, solution=1)\n        grakn_graph_a.add_edge(person_a, name_a, type=\'has\', input=0, solution=1)\n\n        person_b = Thing(\'V123\', \'person\', \'entity\')\n        name_b = Thing(\'V1234\', \'name\', \'attribute\', data_type=\'string\', value=\'Bob\')\n        grakn_graph_b = nx.MultiDiGraph(name=\'b\')\n        grakn_graph_b.add_node(person_b, input=1, solution=1)\n        grakn_graph_b.add_node(name_b, input=1, solution=1)\n        grakn_graph_b.add_edge(person_b, name_b, type=\'has\', input=1, solution=0)\n\n        with self.assertRaises(ValueError) as context:\n            combine_2_graphs(grakn_graph_a, grakn_graph_b)\n\n        self.assertEqual((\'Found non-matching edge properties for edge (<person, V123>, <name, V1234: Bob>, 0) \'\n                          \'between graphs a and b:\\n\'\n                          \'In graph a: {\\\'type\\\': \\\'has\\\', \\\'input\\\': 0, \\\'solution\\\': 1}\\n\'\n                          \'In graph b: {\\\'type\\\': \\\'has\\\', \\\'input\\\': 1, \\\'solution\\\': 0}\'), str(context.exception))\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
kglib/utils/grakn/synthetic/statistics/pmf.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport numpy as np\nimport pandas as pd\n\n\nclass PMF:\n    def __init__(self, variables, pmf_array, seed=None):\n        """"""\n        Probability Mass Function, the discrete equivalent of a Joint Probability Density Function\n\n        Args:\n            variables: An ordered dict, keys: the named variables of the function; values: the possible (discrete)\n                values for each variable\n            pmf_array: Probability Mass Function array: A numpy nd array of probabilities that corresponds with\n                `variables`. Each variable is represented by a dimension of the array. For example, when there are 3\n                variables, element (0, 0, 0) indicates the probability that all variables take the first value given\n                for them in `variables`\n\n        Raises:\n            IndexError if `variables` and `pmf_array` are inconsistent\n        """"""\n        self._variables = variables\n        self._pmf_array = pmf_array\n\n        # Check that `self._variables` and `self._pmf_array` are consistent\n        values_shape = tuple(\n            len(discrete_values) for i, (variable, discrete_values) in enumerate(self._variables.items()))\n\n        if values_shape != self._pmf_array.shape:\n            raise IndexError(f\'Variable values have combined shape {values_shape}, whereas the PMF array given has \'\n                             f\'shape {self._pmf_array.shape}\')\n\n        if seed is not None:\n            np.random.seed(seed)\n\n    def select(self):\n        """"""\n        Select a set of variable values from the PMF, using the probabilities supplied in `pmf_array` as weights.\n\n        Returns:\n            A dict key: variable names; values: the chosen value of each variable\n        """"""\n        flattened = self._pmf_array.flatten()\n\n        answer = {}\n\n        indices = list(np.ndindex(self._pmf_array.shape))\n        int_index = list(range(len(indices)))\n        chosen_int = np.random.choice(int_index, p=flattened)\n        chosen_index = indices[chosen_int]\n        for index, (variable, discrete_values) in zip(chosen_index, self._variables.items()):\n            answer[variable] = discrete_values[index]\n        return answer\n\n    def to_dataframe(self):\n        """"""\n        Creates a DataFrame of the PMF, most useful for visualisation purposes\n\n        Returns:\n            A pandas DataFrame, multi-indexed by the variables and their possible values\n\n        """"""\n        variables = list(self._variables.keys())\n        variable_values = list(self._variables.values())\n        index = pd.MultiIndex.from_product(variable_values, names=variables)\n\n        return pd.DataFrame(self._pmf_array.flatten(), index=index)\n'"
kglib/utils/grakn/synthetic/statistics/pmf_test.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport unittest\n\nimport numpy as np\nimport pandas as pd\n\nfrom kglib.utils.grakn.synthetic.statistics.pmf import PMF\n\n\nclass TestPMF(unittest.TestCase):\n\n    def test_high_probability_value_selected_as_expected(self):\n\n        a = np.zeros([2, 2, 2, 2], dtype=np.float)\n        a[0, 1, 1, 1] = 1.0\n\n        pmf = PMF({\'Flu\': [False, True], \'Meningitis\': [False, True], \'Light Sensitivity\': [False, True],\n                   \'Fever\': [False, True]}, a)\n        choice = pmf.select()\n        expected_choice = {\'Flu\': False, \'Meningitis\': True, \'Light Sensitivity\': True, \'Fever\': True}\n        self.assertDictEqual(expected_choice, choice)\n\n    def test_exception_raised_if_probabilities_and_values_inconsistent(self):\n\n        a = np.zeros([2, 2, 2, 1], dtype=np.float)\n\n        with self.assertRaises(IndexError) as context:\n            PMF({\'Flu\': [False, True], \'Meningitis\': [False, True], \'Light Sensitivity\': [False, True],\n                 \'Fever\': [False, True]}, a)\n\n        self.assertEqual(str(context.exception), (\'Variable values have combined shape (2, 2, 2, 2), whereas the PMF \'\n                                                  \'array given has shape (2, 2, 2, 1)\'))\n\n    def test_to_dataframe_is_as_expected(self):\n        features = [\'Flu\', \'Meningitis\', \'Light Sensitivity\', \'Fever\']\n        feat_values = [[False, True], [False, True], [False, True], [False, True]]\n        index = pd.MultiIndex.from_product(feat_values, names=features)\n\n        a = np.zeros([2, 2, 2, 2])\n        a[0, 1, 1, 1] = 1.0\n\n        pmf = PMF({\'Flu\': [False, True], \'Meningitis\': [False, True], \'Light Sensitivity\': [False, True],\n                   \'Fever\': [False, True]}, a)\n\n        df = pmf.to_dataframe()\n\n        expected_df = pd.DataFrame(a.flatten(), index=index)\n        pd.testing.assert_frame_equal(expected_df, df)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
kglib/utils/grakn/test/mock/answer.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\n\nclass MockConceptMap:\n    def __init__(self, concept_dict):\n        self._concept_dict = concept_dict\n\n    def map(self):\n        return self._concept_dict\n'"
kglib/utils/grakn/test/mock/concept.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\n\nclass MockConcept:\n    def __init__(self, id):\n        self.id = id\n\n\nclass MockType(MockConcept):\n    def __init__(self, id, label, base_type):\n        super().__init__(id)\n        self._label = label\n        assert base_type in {\'ENTITY\', \'RELATION\', \'ATTRIBUTE\'}\n        self.base_type = base_type\n\n    def label(self):\n        return self._label\n\n\nclass DataType:\n    def __init__(self, name):\n        self.name = name\n\n\nclass MockAttributeType(MockType):\n    def __init__(self, id, label, base_type, data_type):\n        super().__init__(id, label, base_type)\n        assert data_type in {\'STRING\', \'LONG\', \'DOUBLE\', \'DATE\', \'BOOLEAN\'}\n        self._data_type = DataType(data_type)\n\n    def data_type(self):\n        return self._data_type\n\n\nclass MockThing(MockConcept):\n    def __init__(self, id, type):\n        super().__init__(id)\n        assert(isinstance(type, MockType))\n        self._type = type\n\n    def type(self):\n        return self._type\n\n    def as_remote(self, tx):\n        return self\n\n    @property\n    def base_type(self):\n        return self._type.base_type\n\n\nclass MockAttribute(MockThing):\n    def __init__(self, id, value, type):\n        super().__init__(id, type)\n        self._value = value\n        assert isinstance(type, MockAttributeType)\n\n    def value(self):\n        return self._value\n'"
kglib/utils/grakn/synthetic/examples/diagnosis/generate.py,0,"b'#\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  ""License""); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing,\n#  software distributed under the License is distributed on an\n#  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n#  KIND, either express or implied.  See the License for the\n#  specific language governing permissions and limitations\n#  under the License.\n#\n\nimport inspect\n\nimport numpy as np\nfrom grakn.client import GraknClient\n\nfrom kglib.utils.grakn.synthetic.statistics.pmf import PMF\n\n\ndef get_example_queries(pmf, example_id):\n\n    variable_values = pmf.select()\n\n    queries = [f\'insert $p isa person, has example-id {example_id};\',\n               f\'insert $doc isa person, has example-id {20000 + example_id};\']\n\n    if variable_values[\'Multiple Sclerosis\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $d isa disease, has name ""Multiple Sclerosis"";\n                       $p isa person, has example-id {example_id};\n                       $doc isa person, has example-id {20000 + example_id};\n                       insert\n                       (patient: $p, diagnosed-disease: $d, doctor: $doc) isa diagnosis;\n                       $p has age {int(variable_values[\'Multiple Sclerosis\'][\'age\']())};\'\'\'))\n\n    if variable_values[\'Diabetes Type II\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $p isa person, has example-id {example_id};\n                       $d isa disease, has name ""Diabetes Type II"";\n                       $doc isa person, has example-id {20000 + example_id};\n                       insert\n                       (patient: $p, diagnosed-disease: $d, doctor: $doc) isa diagnosis;\n                       $p has age {int(variable_values[\'Diabetes Type II\'][\'age\']())};\'\'\'))\n\n    if variable_values[\'Fatigue\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $p isa person, has example-id {example_id};\n                       $s isa symptom, has name ""Fatigue"";\n                       insert\n                       (presented-symptom: $s, symptomatic-patient: $p) isa \n                       symptom-presentation, has severity {variable_values[\'Fatigue\'][\'severity\']()};\'\'\'))\n\n    if variable_values[\'Blurred vision\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $p isa person, has example-id {example_id};\n                       $s isa symptom, has name ""Blurred vision"";\n                       insert\n                       (presented-symptom: $s, symptomatic-patient: $p) isa \n                       symptom-presentation, has severity {variable_values[\'Blurred vision\'][\'severity\']()};\'\'\'))\n\n    if variable_values[\'Drinking\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $p isa person, has example-id {example_id};\n                       $s isa substance, has name ""Alcohol"";\n                       insert\n                       $c(consumer: $p, consumed-substance: $s) isa consumption, \n                       has units-per-week {int(variable_values[\'Drinking\'][\'units-per-week\']())};\'\'\'))\n\n    if variable_values[\'Parent has Diabetes Type II\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $p isa person, has example-id {example_id};\n                       $d isa disease, has name ""Diabetes Type II"";\n                       insert\n                       (parent: $parent, child: $p) isa parentship;\n                       $parent isa person, has example-id {example_id + 10000};\n                       (patient: $parent, diagnosed-disease: $d) isa diagnosis;\n                       \'\'\'))\n\n    if variable_values[\'Cigarettes\'] is not False:\n        queries.append(inspect.cleandoc(f\'\'\'match\n                       $p isa person, has example-id {example_id};\n                       $s isa substance, has name ""Cigarettes"";\n                       insert\n                       $c(consumer: $p, consumed-substance: $s) isa consumption, \n                       has units-per-week {int(variable_values[\'Cigarettes\'][\'units-per-week\']())};\'\'\'))\n\n    return queries\n\n\ndef generate_example_graphs(num_examples, keyspace=""diagnosis"", uri=""localhost:48555""):\n\n    client = GraknClient(uri=uri)\n    session = client.session(keyspace=keyspace)\n\n    pmf_array = np.zeros([2, 2, 2, 2, 3, 2, 3], dtype=np.float)\n    pmf_array[0, 1, 0, 1, 0, 0, 0] = 0.1\n    pmf_array[1, 0, 1, 0, 0, 0, 0] = 0.05\n    pmf_array[1, 0, 1, 0, 2, 0, 0] = 0.1\n    pmf_array[0, 1, 1, 0, 0, 0, 0] = 0.05\n    pmf_array[1, 0, 0, 1, 0, 0, 0] = 0.19\n    pmf_array[1, 0, 0, 1, 0, 1, 0] = 0.15\n    pmf_array[1, 1, 1, 1, 0, 0, 0] = 0.01\n    pmf_array[0, 1, 1, 1, 0, 0, 0] = 0.05\n    pmf_array[0, 1, 1, 1, 0, 0, 1] = 0.05\n    pmf_array[0, 1, 1, 1, 0, 0, 2] = 0.1\n    pmf_array[1, 0, 1, 1, 0, 0, 0] = 0.05\n    pmf_array[1, 0, 1, 1, 2, 1, 2] = 0.1\n\n    def normal_dist(mean, var):\n        return lambda: round(np.random.normal(mean, var, 1)[0], 2)\n\n    pmf = PMF({\n        \'Diabetes Type II\':             [False, {\'age\': normal_dist(60, 10)}],\n        \'Multiple Sclerosis\':           [False, {\'age\': normal_dist(30, 10)}],\n        \'Fatigue\':                      [False, {\'severity\': normal_dist(0.3, 0.1)}],\n        \'Blurred vision\':               [False, {\'severity\': normal_dist(0.5, 0.2)}],\n        \'Drinking\':                     [False, {\'units-per-week\': normal_dist(5, 1)}, {\'units-per-week\': normal_dist(20, 3)}],\n        \'Parent has Diabetes Type II\':  [False, True],\n        \'Cigarettes\':                   [False, {\'units-per-week\': normal_dist(5, 1)}, {\'units-per-week\': normal_dist(20, 3)}],\n    }, pmf_array, seed=0)\n\n    # print(pmf.to_dataframe()) # TODO Remove pandas if this is not needed now\n\n    for example_id in range(0, num_examples):\n        tx = session.transaction().write()\n        for query in get_example_queries(pmf, example_id):\n            print(query)\n            tx.query(query)\n        tx.commit()\n\n    session.close()\n    client.close()\n\n\nif __name__ == \'__main__\':\n    generate_example_graphs(100, keyspace=""diagnosis"", uri=""localhost:48555"")\n'"
