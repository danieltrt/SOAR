file_path,api_count,code
config_dataset_HAR_6_classes.py,0,"b'\nfrom lstm_architecture import one_hot, run_with_config\n\nimport numpy as np\n\nimport os\n\n\n#--------------------------------------------\n# Neural net\'s config.\n#--------------------------------------------\n\nclass Config(object):\n    """"""\n    define a class to store parameters,\n    the input should be feature mat of training and testing\n    """"""\n\n    def __init__(self, X_train, X_test):\n        # Data shaping\n        self.train_count = len(X_train)  # 7352 training series\n        self.test_data_count = len(X_test)  # 2947 testing series\n        self.n_steps = len(X_train[0])  # 128 time_steps per series\n        self.n_classes = 6  # Final output classes\n\n        # Training\n        self.learning_rate = 0.001\n        self.lambda_loss_amount = 0.005\n        self.training_epochs = 250\n        self.batch_size = 100\n        self.clip_gradients = 15.0\n        self.gradient_noise_scale = None\n        # Dropout is added on inputs and after each stacked layers (but not\n        # between residual layers).\n        self.keep_prob_for_dropout = 0.85  # **(1/3.0)\n\n        # Linear+relu structure\n        self.bias_mean = 0.3\n        # I would recommend between 0.1 and 1.0 or to change and use a xavier\n        # initializer\n        self.weights_stddev = 0.2\n\n        ########\n        # NOTE: I think that if any of the below parameters are changed,\n        # the best is to readjust every parameters in the ""Training"" section\n        # above to properly compare the architectures only once optimised.\n        ########\n\n        # LSTM structure\n        # Features count is of 9: three 3D sensors features over time\n        self.n_inputs = len(X_train[0][0])\n        self.n_hidden = 28  # nb of neurons inside the neural network\n        # Use bidir in every LSTM cell, or not:\n        self.use_bidirectionnal_cells = False\n\n        # High-level deep architecture\n        self.also_add_dropout_between_stacked_cells = False  # True\n        # NOTE: values of exactly 1 (int) for those 2 high-level parameters below totally disables them and result in only 1 starting LSTM.\n        # self.n_layers_in_highway = 1  # Number of residual connections to the LSTMs (highway-style), this is did for each stacked block (inside them).\n        # self.n_stacked_layers = 1  # Stack multiple blocks of residual\n        # layers.\n\n\n#--------------------------------------------\n# Dataset-specific constants and functions + loading\n#--------------------------------------------\n\n# Useful Constants\n\n# Those are separate normalised input features for the neural network\nINPUT_SIGNAL_TYPES = [\n    ""body_acc_x_"",\n    ""body_acc_y_"",\n    ""body_acc_z_"",\n    ""body_gyro_x_"",\n    ""body_gyro_y_"",\n    ""body_gyro_z_"",\n    ""total_acc_x_"",\n    ""total_acc_y_"",\n    ""total_acc_z_""\n]\n\n# Output classes to learn how to classify\nLABELS = [\n    ""WALKING"",\n    ""WALKING_UPSTAIRS"",\n    ""WALKING_DOWNSTAIRS"",\n    ""SITTING"",\n    ""STANDING"",\n    ""LAYING""\n]\n\nDATA_PATH = ""data/""\nDATASET_PATH = DATA_PATH + ""UCI HAR Dataset/""\n\nTRAIN = ""train/""\nTEST = ""test/""\n\n\n# Load ""X"" (the neural network\'s training and testing inputs)\n\ndef load_X(X_signals_paths):\n    """"""\n    Given attribute (train or test) of feature, read all 9 features into an\n    np ndarray of shape [sample_sequence_idx, time_step, feature_num]\n        argument:   X_signals_paths str attribute of feature: \'train\' or \'test\'\n        return:     np ndarray, tensor of features\n    """"""\n    X_signals = []\n\n    for signal_type_path in X_signals_paths:\n        file = open(signal_type_path, \'rb\')\n        # Read dataset from disk, dealing with text files\' syntax\n        X_signals.append(\n            [np.array(serie, dtype=np.float32) for serie in [\n                row.replace(\'  \', \' \').strip().split(\' \') for row in file\n            ]]\n        )\n        file.close()\n\n    return np.transpose(np.array(X_signals), (1, 2, 0))\n\nX_train_signals_paths = [\n    DATASET_PATH + TRAIN + ""Inertial Signals/"" + signal + ""train.txt"" for signal in INPUT_SIGNAL_TYPES\n]\nX_test_signals_paths = [\n    DATASET_PATH + TEST + ""Inertial Signals/"" + signal + ""test.txt"" for signal in INPUT_SIGNAL_TYPES\n]\n\nX_train = load_X(X_train_signals_paths)\nX_test = load_X(X_test_signals_paths)\n\n\n# Load ""y"" (the neural network\'s training and testing outputs)\n\ndef load_y(y_path):\n    """"""\n    Read Y file of values to be predicted\n        argument: y_path str attibute of Y: \'train\' or \'test\'\n        return: Y ndarray / tensor of the 6 one_hot labels of each sample\n    """"""\n    file = open(y_path, \'rb\')\n    # Read dataset from disk, dealing with text file\'s syntax\n    y_ = np.array(\n        [elem for elem in [\n            row.replace(\'  \', \' \').strip().split(\' \') for row in file\n        ]],\n        dtype=np.int32\n    )\n    file.close()\n\n    # Substract 1 to each output class for friendly 0-based indexing\n    return one_hot(y_ - 1)\n\ny_train_path = DATASET_PATH + TRAIN + ""y_train.txt""\ny_test_path = DATASET_PATH + TEST + ""y_test.txt""\n\ny_train = load_y(y_train_path)\ny_test = load_y(y_test_path)\n\n\n#--------------------------------------------\n# Training (maybe multiple) experiment(s)\n#--------------------------------------------\n\nn_layers_in_highway = 0\nn_stacked_layers = 3\ntrial_name = ""{}x{}"".format(n_layers_in_highway, n_stacked_layers)\n\nfor learning_rate in [0.001]:  # [0.01, 0.007, 0.001, 0.0007, 0.0001]:\n    for lambda_loss_amount in [0.005]:\n        for clip_gradients in [15.0]:\n            print ""learning_rate: {}"".format(learning_rate)\n            print ""lambda_loss_amount: {}"".format(lambda_loss_amount)\n            print """"\n\n            class EditedConfig(Config):\n                def __init__(self, X, Y):\n                    super(EditedConfig, self).__init__(X, Y)\n\n                    # Edit only some parameters:\n                    self.learning_rate = learning_rate\n                    self.lambda_loss_amount = lambda_loss_amount\n                    self.clip_gradients = clip_gradients\n                    # Architecture params:\n                    self.n_layers_in_highway = n_layers_in_highway\n                    self.n_stacked_layers = n_stacked_layers\n\n            # # Useful catch upon looping (e.g.: not enough memory)\n            # try:\n            #     accuracy_out, best_accuracy = run_with_config(EditedConfig)\n            # except:\n            #     accuracy_out, best_accuracy = -1, -1\n            accuracy_out, best_accuracy, f1_score_out, best_f1_score = (\n                run_with_config(EditedConfig, X_train, y_train, X_test, y_test)\n            )\n            print (accuracy_out, best_accuracy, f1_score_out, best_f1_score)\n\n            with open(\'{}_result_HAR_6.txt\'.format(trial_name), \'a\') as f:\n                f.write(str(learning_rate) + \' \\t\' + str(lambda_loss_amount) + \' \\t\' + str(clip_gradients) + \' \\t\' + str(\n                    accuracy_out) + \' \\t\' + str(best_accuracy) + \' \\t\' + str(f1_score_out) + \' \\t\' + str(best_f1_score) + \'\\n\\n\')\n\n            print ""________________________________________________________""\n        print """"\nprint ""Done.""\n'"
config_dataset_opportunity_18_classes.py,0,"b'# Some parts of the code are taken from: https://github.com/sussexwearlab/DeepConvLSTM\n\nfrom lstm_architecture import one_hot, run_with_config\nfrom sliding_window import sliding_window\n\nimport numpy as np\n\nimport cPickle as cp\nimport time\n\n\n#--------------------------------------------\n# Neural net\'s config.\n#--------------------------------------------\n\nclass Config(object):\n    """"""\n    define a class to store parameters,\n    the input should be feature mat of training and testing\n    """"""\n\n    def __init__(self, X_train, X_test):\n        # Data shaping\n        self.train_count = len(X_train)  # nb of training series\n        self.test_data_count = len(X_test)  # nb of testing series\n        self.n_steps = len(X_train[0])  # nb of time_steps per series\n        self.n_classes = 18  # Final output classes, one classification per series\n\n        # Training\n        self.learning_rate = 0.001\n        self.lambda_loss_amount = 0.005\n        self.training_epochs = 100\n        self.batch_size = 100\n        self.clip_gradients = 15.0\n        self.gradient_noise_scale = None\n        self.keep_prob_for_dropout = 0.85  # **(1/3.0)  # Dropout is added on inputs and after each stacked layers (but not between residual layers).\n\n        # Linear+relu structure\n        self.bias_mean = 0.3\n        self.weights_stddev = 0.2  # I would recommend between 0.1 and 1.0 or to change and use a xavier initializer\n\n        ########\n        # NOTE: I think that if any of the below parameters are changed,\n        # the best is to readjust every parameters in the ""Training"" section\n        # above to properly compare the architectures only once optimised.\n        ########\n\n        # LSTM structure\n        self.n_inputs = len(X_train[0][0])  # Features count\n        self.n_hidden = 28  # nb of neurons inside the neural network\n        self.use_bidirectionnal_cells = True  # Use bidir in every LSTM cell, or not:\n\n        # High-level deep architecture\n        self.also_add_dropout_between_stacked_cells = False  # True\n        # NOTE: values of exactly 1 (int) for those 2 high-level parameters below totally disables them and result in only 1 starting LSTM.\n        # self.n_layers_in_highway = 1  # Number of residual connections to the LSTMs (highway-style), this is did for each stacked block (inside them).\n        # self.n_stacked_layers = 1  # Stack multiple blocks of residual layers.\n\n\n#--------------------------------------------\n# Dataset-specific constants and functions\n#--------------------------------------------\n\n# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\nNB_SENSOR_CHANNELS = 113\nNB_SENSOR_CHANNELS_WITH_FILTERING = 149\n\n# Hardcoded number of classes in the gesture recognition problem\nNUM_CLASSES = 18\n\n# Hardcoded length of the sliding window mechanism employed to segment the data\nSLIDING_WINDOW_LENGTH = 24\n\n# Length of the input sequence after convolutional operations\nFINAL_SEQUENCE_LENGTH = 8\n\n# Hardcoded step of the sliding window mechanism employed to segment the data\nSLIDING_WINDOW_STEP = int(SLIDING_WINDOW_LENGTH/2)\nSLIDING_WINDOW_STEP_SHORT = SLIDING_WINDOW_STEP\n\n# Batch Size\nBATCH_SIZE = 100\n\n# Number filters convolutional layers\nNUM_FILTERS = 64\n\n# Size filters convolutional layers\nFILTER_SIZE = 5\n\n# Number of unit in the long short-term recurrent layers\nNUM_UNITS_LSTM = 128\n\n\ndef load_dataset(filename):\n\n    f = file(filename, \'rb\')\n    data = cp.load(f)\n    f.close()\n\n    X_train, y_train = data[0]\n    X_test, y_test = data[1]\n\n    print("" ..from file {}"".format(filename))\n    print("" ..reading instances: train {0}, test {1}"".format(X_train.shape, X_test.shape))\n\n    X_train = X_train.astype(np.float32)\n    X_test = X_test.astype(np.float32)\n\n    # The targets are casted to int8 for GPU compatibility.\n    y_train = y_train.astype(np.uint8)\n    y_test = y_test.astype(np.uint8)\n\n    return X_train, y_train, X_test, y_test\n\nprint(""Loading data..."")\nX_train, y_train, X_test, y_test = load_dataset(\'data/oppChallenge_gestures.data\')\n\nassert (NB_SENSOR_CHANNELS_WITH_FILTERING == X_train.shape[1] or NB_SENSOR_CHANNELS == X_train.shape[1])\n\ndef opp_sliding_window(data_x, data_y, ws, ss):\n    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n    data_x, data_y = data_x.astype(np.float32), one_hot(data_y.reshape(len(data_y)).astype(np.uint8))\n    print("" ..after sliding window (testing): inputs {0}, targets {1}"".format(X_test.shape, y_test.shape))\n    return data_x, data_y\n\n\n#--------------------------------------------\n# Loading dataset\n#--------------------------------------------\n\n\n# Sensor data is segmented using a sliding window mechanism\nX_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP_SHORT)\nX_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n\nfor mat in [X_train, y_train, X_test, y_test]:\n    print mat.shape\n\n\n#--------------------------------------------\n# Training (maybe multiple) experiment(s)\n#--------------------------------------------\n\nn_layers_in_highway = 3\nn_stacked_layers = 3\ntrial_name = ""{}x{}"".format(n_layers_in_highway, n_stacked_layers)\n\nfor learning_rate in [0.001]:\n    for lambda_loss_amount in [0.005]:\n        print ""learning_rate: {}"".format(learning_rate)\n        print ""lambda_loss_amount: {}"".format(lambda_loss_amount)\n        print """"\n\n        class EditedConfig(Config):\n            def __init__(self, X, Y):\n                super(EditedConfig, self).__init__(X, Y)\n\n                # Edit only some parameters:\n                self.learning_rate = learning_rate\n                self.lambda_loss_amount = lambda_loss_amount\n                # Architecture params:\n                self.n_layers_in_highway = n_layers_in_highway\n                self.n_stacked_layers = n_stacked_layers\n\n        accuracy_out, best_accuracy, f1_score_out, best_f1_score = run_with_config(EditedConfig, X_train, y_train, X_test, y_test)\n        print (accuracy_out, best_accuracy, f1_score_out, best_f1_score)\n\n        with open(\'{}_result_opportunity_18.txt\'.format(trial_name),\'a\') as f:\n            f.write(""""""str(learning_rate)+\' \\t\'+str(lambda_loss_amount)+\' \\t\'+str(accuracy_out)+\' \\t\'+str(best_accuracy)+\' \\t\'+str(f1_score_out)+\' \\t\'+str(best_f1_score)\\n"""""")\n            f.write(   str(learning_rate)+\' \\t\'+str(lambda_loss_amount)+\' \\t\'+str(accuracy_out)+\' \\t\'+str(best_accuracy)+\' \\t\'+str(f1_score_out)+\' \\t\'+str(best_f1_score)+\'\\n\\n\' )\n\n        print ""________________________________________________________""\n    print """"\nprint ""Done.""\n'"
lstm_architecture.py,52,"b'__author__ = \'gchevalier\'\n\nimport tensorflow as tf\nfrom sklearn import metrics\nfrom sklearn.utils import shuffle\nimport numpy as np\n\n\ndef one_hot(y):\n    """"""convert label from dense to one hot\n      argument:\n        label: ndarray dense label ,shape: [sample_num,1]\n      return:\n        one_hot_label: ndarray  one hot, shape: [sample_num,n_class]\n    """"""\n    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n\n    y = y.reshape(len(y))\n    n_values = np.max(y) + 1\n    return np.eye(n_values)[np.array(y, dtype=np.int32)]  # Returns FLOATS\n\n\ndef batch_norm(input_tensor, config, i):\n    # Implementing batch normalisation: this is used out of the residual layers\n    # to normalise those output neurons by mean and standard deviation.\n\n    if config.n_layers_in_highway == 0:\n        # There is no residual layers, no need for batch_norm:\n        return input_tensor\n\n    with tf.variable_scope(""batch_norm"") as scope:\n        if i != 0:\n            # Do not create extra variables for each time step\n            scope.reuse_variables()\n\n        # Mean and variance normalisation simply crunched over all axes\n        axes = list(range(len(input_tensor.get_shape())))\n\n        mean, variance = tf.nn.moments(input_tensor, axes=axes, shift=None, name=None, keep_dims=False)\n        stdev = tf.sqrt(variance+0.001)\n\n        # Rescaling\n        bn = input_tensor - mean\n        bn /= stdev\n        # Learnable extra rescaling\n\n        # tf.get_variable(""relu_fc_weights"", initializer=tf.random_normal(mean=0.0, stddev=0.0)\n        bn *= tf.get_variable(""a_noreg"", initializer=tf.random_normal([1], mean=0.5, stddev=0.0))\n        bn += tf.get_variable(""b_noreg"", initializer=tf.random_normal([1], mean=0.0, stddev=0.0))\n        # bn *= tf.Variable(0.5, name=(scope.name + ""/a_noreg""))\n        # bn += tf.Variable(0.0, name=(scope.name + ""/b_noreg""))\n\n    return bn\n\ndef relu_fc(input_2D_tensor_list, features_len, new_features_len, config):\n    """"""make a relu fully-connected layer, mainly change the shape of tensor\n       both input and output is a list of tensor\n        argument:\n            input_2D_tensor_list: list shape is [batch_size,feature_num]\n            features_len: int the initial features length of input_2D_tensor\n            new_feature_len: int the final features length of output_2D_tensor\n            config: Config used for weights initializers\n        return:\n            output_2D_tensor_list lit shape is [batch_size,new_feature_len]\n    """"""\n\n    W = tf.get_variable(\n        ""relu_fc_weights"",\n        initializer=tf.random_normal(\n            [features_len, new_features_len],\n            mean=0.0,\n            stddev=float(config.weights_stddev)\n        )\n    )\n    b = tf.get_variable(\n        ""relu_fc_biases_noreg"",\n        initializer=tf.random_normal(\n            [new_features_len],\n            mean=float(config.bias_mean),\n            stddev=float(config.weights_stddev)\n        )\n    )\n\n    # intra-timestep multiplication:\n    output_2D_tensor_list = [\n        tf.nn.relu(tf.matmul(input_2D_tensor, W) + b)\n            for input_2D_tensor in input_2D_tensor_list\n    ]\n\n    return output_2D_tensor_list\n\n\ndef single_LSTM_cell(input_hidden_tensor, n_outputs):\n    """""" define the basic LSTM layer\n        argument:\n            input_hidden_tensor: list a list of tensor,\n                                 shape: time_steps*[batch_size,n_inputs]\n            n_outputs: int num of LSTM layer output\n        return:\n            outputs: list a time_steps list of tensor,\n                     shape: time_steps*[batch_size,n_outputs]\n    """"""\n    with tf.variable_scope(""lstm_cell""):\n        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_outputs, state_is_tuple=True, forget_bias=0.999)\n        outputs, _ = tf.nn.rnn(lstm_cell, input_hidden_tensor, dtype=tf.float32)\n    return outputs\n\n\ndef bi_LSTM_cell(input_hidden_tensor, n_inputs, n_outputs, config):\n    """"""build bi-LSTM, concatenating the two directions in an inner manner.\n        argument:\n            input_hidden_tensor: list a time_steps series of tensor, shape: [sample_num, n_inputs]\n            n_inputs: int units of input tensor\n            n_outputs: int units of output tensor, each bi-LSTM will have half those internal units\n            config: Config used for the relu_fc\n        return:\n            layer_hidden_outputs: list a time_steps series of tensor, shape: [sample_num, n_outputs]\n    """"""\n    n_outputs = int(n_outputs/2)\n\n    print ""bidir:""\n\n    with tf.variable_scope(\'pass_forward\') as scope2:\n        hidden_forward = relu_fc(input_hidden_tensor, n_inputs, n_outputs, config)\n        forward = single_LSTM_cell(hidden_forward, n_outputs)\n\n    print (len(hidden_forward), str(hidden_forward[0].get_shape()))\n\n    # Backward pass is as simple as surrounding the cell with a double inversion:\n    with tf.variable_scope(\'pass_backward\') as scope2:\n        hidden_backward = relu_fc(input_hidden_tensor, n_inputs, n_outputs, config)\n        backward = list(reversed(single_LSTM_cell(list(reversed(hidden_backward)), n_outputs)))\n\n    with tf.variable_scope(\'bidir_concat\') as scope:\n        # Simply concatenating cells\' outputs at each timesteps on the innermost\n        # dimension, like if the two cells acted as one cell\n        # with twice the n_hidden size:\n        layer_hidden_outputs = [\n            tf.concat(len(f.get_shape()) - 1, [f, b])\n                for f, b in zip(forward, backward)]\n\n    return layer_hidden_outputs\n\n\ndef residual_bidirectional_LSTM_layers(input_hidden_tensor, n_input, n_output, layer_level, config, keep_prob_for_dropout):\n    """"""This architecture is only enabled if ""config.n_layers_in_highway"" has a\n    value only greater than int(0). The arguments are same than for bi_LSTM_cell.\n    arguments:\n        input_hidden_tensor: list a time_steps series of tensor, shape: [sample_num, n_inputs]\n        n_inputs: int units of input tensor\n        n_outputs: int units of output tensor, each bi-LSTM will have half those internal units\n        config: Config used for determining if there are residual connections and if yes, their number and with some batch_norm.\n    return:\n        layer_hidden_outputs: list a time_steps series of tensor, shape: [sample_num, n_outputs]\n    """"""\n    with tf.variable_scope(\'layer_{}\'.format(layer_level)) as scope:\n\n        if config.use_bidirectionnal_cells:\n            get_lstm = lambda input_tensor: bi_LSTM_cell(input_tensor, n_input, n_output, config)\n        else:\n            get_lstm = lambda input_tensor: single_LSTM_cell(relu_fc(input_tensor, n_input, n_output, config), n_output)\n        def add_highway_redisual(layer, residual_minilayer):\n            return [a + b for a, b in zip(layer, residual_minilayer)]\n\n        hidden_LSTM_layer = get_lstm(input_hidden_tensor)\n        # Adding K new (residual bidir) connections to this first layer:\n        for i in range(config.n_layers_in_highway - 1):\n            with tf.variable_scope(\'LSTM_residual_{}\'.format(i)) as scope2:\n                hidden_LSTM_layer = add_highway_redisual(\n                    hidden_LSTM_layer,\n                    get_lstm(input_hidden_tensor)\n                )\n\n        if config.also_add_dropout_between_stacked_cells:\n            hidden_LSTM_layer = [tf.nn.dropout(out, keep_prob_for_dropout) for out in hidden_LSTM_layer]\n\n        return [batch_norm(out, config, i) for i, out in enumerate(hidden_LSTM_layer)]\n\n\ndef LSTM_network(feature_mat, config, keep_prob_for_dropout):\n    """"""model a LSTM Network,\n      it stacks 2 LSTM layers, each layer has n_hidden=32 cells\n       and 1 output layer, it is a full connet layer\n      argument:\n        feature_mat: ndarray fature matrix, shape=[batch_size,time_steps,n_inputs]\n        config: class containing config of network\n      return:\n              : ndarray  output shape [batch_size, n_classes]\n    """"""\n\n    with tf.variable_scope(\'LSTM_network\') as scope:  # TensorFlow graph naming\n\n        feature_mat = tf.nn.dropout(feature_mat, keep_prob_for_dropout)\n\n        # Exchange dim 1 and dim 0\n        feature_mat = tf.transpose(feature_mat, [1, 0, 2])\n        print feature_mat.get_shape()\n        # New feature_mat\'s shape: [time_steps, batch_size, n_inputs]\n\n        # Temporarily crush the feature_mat\'s dimensions\n        feature_mat = tf.reshape(feature_mat, [-1, config.n_inputs])\n        print feature_mat.get_shape()\n        # New feature_mat\'s shape: [time_steps*batch_size, n_inputs]\n\n        # Split the series because the rnn cell needs time_steps features, each of shape:\n        hidden = tf.split(0, config.n_steps, feature_mat)\n        print (len(hidden), str(hidden[0].get_shape()))\n        # New shape: a list of lenght ""time_step"" containing tensors of shape [batch_size, n_hidden]\n\n        # Stacking LSTM cells, at least one is stacked:\n        print ""\\nCreating hidden #1:""\n        hidden = residual_bidirectional_LSTM_layers(hidden, config.n_inputs, config.n_hidden, 1, config, keep_prob_for_dropout)\n        print (len(hidden), str(hidden[0].get_shape()))\n\n        for stacked_hidden_index in range(config.n_stacked_layers - 1):\n            # If the config permits it, we stack more lstm cells:\n            print ""\\nCreating hidden #{}:"".format(stacked_hidden_index+2)\n            hidden = residual_bidirectional_LSTM_layers(hidden, config.n_hidden, config.n_hidden, stacked_hidden_index+2, config, keep_prob_for_dropout)\n            print (len(hidden), str(hidden[0].get_shape()))\n\n        print """"\n\n        # Final fully-connected activation logits\n        # Get the last output tensor of the inner loop output series, of shape [batch_size, n_classes]\n        last_hidden = tf.nn.dropout(hidden[-1], keep_prob_for_dropout)\n        last_logits = relu_fc(\n            [last_hidden],\n            config.n_hidden, config.n_classes, config\n        )[0]\n        return last_logits\n\n\ndef run_with_config(Config, X_train, y_train, X_test, y_test):\n    tf.reset_default_graph()  # To enable to run multiple things in a loop\n\n    #-----------------------------------\n    # Define parameters for model\n    #-----------------------------------\n    config = Config(X_train, X_test)\n    print(""Some useful info to get an insight on dataset\'s shape and normalisation:"")\n    print(""features shape, labels shape, each features mean, each features standard deviation"")\n    print(X_test.shape, y_test.shape,\n          np.mean(X_test), np.std(X_test))\n    print(""the dataset is therefore properly normalised, as expected."")\n\n    #------------------------------------------------------\n    # Let\'s get serious and build the neural network\n    #------------------------------------------------------\n    with tf.device(""/cpu:0""):  # Remove this line to use GPU. If you have a too small GPU, it crashes.\n        X = tf.placeholder(tf.float32, [\n                           None, config.n_steps, config.n_inputs], name=""X"")\n        Y = tf.placeholder(tf.float32, [\n                           None, config.n_classes], name=""Y"")\n\n        # is_train for dropout control:\n        is_train = tf.placeholder(tf.bool, name=""is_train"")\n        keep_prob_for_dropout = tf.cond(is_train,\n            lambda: tf.constant(\n                config.keep_prob_for_dropout,\n                name=""keep_prob_for_dropout""\n            ),\n            lambda: tf.constant(\n                1.0,\n                name=""keep_prob_for_dropout""\n            )\n        )\n\n        pred_y = LSTM_network(X, config, keep_prob_for_dropout)\n\n        # Loss, optimizer, evaluation\n\n        # Softmax loss with L2 and L1 layer-wise regularisation\n        print ""Unregularised variables:""\n        for unreg in [tf_var.name for tf_var in tf.trainable_variables() if (""noreg"" in tf_var.name or ""Bias"" in tf_var.name)]:\n            print unreg\n        l2 = config.lambda_loss_amount * sum(\n            tf.nn.l2_loss(tf_var)\n                for tf_var in tf.trainable_variables()\n                if not (""noreg"" in tf_var.name or ""Bias"" in tf_var.name)\n        )\n        # first_weights = [w for w in tf.all_variables() if w.name == \'LSTM_network/layer_1/pass_forward/relu_fc_weights:0\'][0]\n        # l1 = config.lambda_loss_amount * tf.reduce_mean(tf.abs(first_weights))\n        loss = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(pred_y, Y)) + l2  # + l1\n\n        # Gradient clipping Adam optimizer with gradient noise\n        optimize = tf.contrib.layers.optimize_loss(\n            loss,\n            global_step=tf.Variable(0),\n            learning_rate=config.learning_rate,\n            optimizer=tf.train.AdamOptimizer(learning_rate=config.learning_rate),\n            clip_gradients=config.clip_gradients,\n            gradient_noise_scale=config.gradient_noise_scale\n        )\n\n        correct_pred = tf.equal(tf.argmax(pred_y, 1), tf.argmax(Y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))\n\n    #--------------------------------------------\n    # Hooray, now train the neural network\n    #--------------------------------------------\n    # Note that log_device_placement can be turned of for less console spam.\n\n    sessconfig = tf.ConfigProto(log_device_placement=False)\n    with tf.Session(config=sessconfig) as sess:\n        tf.initialize_all_variables().run()\n\n        best_accuracy = (0.0, ""iter: -1"")\n        best_f1_score = (0.0, ""iter: -1"")\n\n        # Start training for each batch and loop epochs\n\n        worst_batches = []\n\n        for i in range(config.training_epochs):\n\n            # Loop batches for an epoch:\n            shuffled_X, shuffled_y = shuffle(X_train, y_train, random_state=i*42)\n            for start, end in zip(range(0, config.train_count, config.batch_size),\n                                  range(config.batch_size, config.train_count + 1, config.batch_size)):\n\n                _, train_acc, train_loss, train_pred = sess.run(\n                    [optimize, accuracy, loss, pred_y],\n                    feed_dict={\n                        X: shuffled_X[start:end],\n                        Y: shuffled_y[start:end],\n                        is_train: True\n                    }\n                )\n\n                worst_batches.append(\n                    (train_loss, shuffled_X[start:end], shuffled_y[start:end])\n                )\n                worst_batches = list(sorted(worst_batches))[-5:]  # Keep 5 poorest\n\n            # Train F1 score is not on boosting\n            train_f1_score = metrics.f1_score(\n                shuffled_y[start:end].argmax(1), train_pred.argmax(1), average=""weighted""\n            )\n\n            # Retrain on top worst batches of this epoch (boosting):\n            # a.k.a. ""focus on the hardest exercises while training"":\n            for _, x_, y_ in worst_batches:\n\n                _, train_acc, train_loss, train_pred = sess.run(\n                    [optimize, accuracy, loss, pred_y],\n                    feed_dict={\n                        X: x_,\n                        Y: y_,\n                        is_train: True\n                    }\n                )\n\n            # Test completely at the end of every epoch:\n            # Calculate accuracy and F1 score\n            pred_out, accuracy_out, loss_out = sess.run(\n                [pred_y, accuracy, loss],\n                feed_dict={\n                    X: X_test,\n                    Y: y_test,\n                    is_train: False\n                }\n            )\n\n            # ""y_test.argmax(1)"": could be optimised by being computed once...\n            f1_score_out = metrics.f1_score(\n                y_test.argmax(1), pred_out.argmax(1), average=""weighted""\n            )\n\n            print (\n                ""iter: {}, "".format(i) + \\\n                ""train loss: {}, "".format(train_loss) + \\\n                ""train accuracy: {}, "".format(train_acc) + \\\n                ""train F1-score: {}, "".format(train_f1_score) + \\\n                ""test loss: {}, "".format(loss_out) + \\\n                ""test accuracy: {}, "".format(accuracy_out) + \\\n                ""test F1-score: {}"".format(f1_score_out)\n            )\n\n            best_accuracy = max(best_accuracy, (accuracy_out, ""iter: {}"".format(i)))\n            best_f1_score = max(best_f1_score, (f1_score_out, ""iter: {}"".format(i)))\n\n        print("""")\n        print(""final test accuracy: {}"".format(accuracy_out))\n        print(""best epoch\'s test accuracy: {}"".format(best_accuracy))\n        print(""final F1 score: {}"".format(f1_score_out))\n        print(""best epoch\'s F1 score: {}"".format(best_f1_score))\n        print("""")\n\n    # returning both final and bests accuracies and f1 scores.\n    return accuracy_out, best_accuracy, f1_score_out, best_f1_score\n'"
sliding_window.py,0,"b""# From: https://github.com/sussexwearlab/DeepConvLSTM\n# Which is from http://www.johnvinyard.com/blog/?p=268\n\nimport numpy as np\nfrom numpy.lib.stride_tricks import as_strided as ast\n\ndef norm_shape(shape):\n    '''\n    Normalize numpy array shapes so they're always expressed as a tuple,\n    even for one-dimensional shapes.\n\n    Parameters\n        shape - an int, or a tuple of ints\n\n    Returns\n        a shape tuple\n    '''\n    try:\n        i = int(shape)\n        return (i,)\n    except TypeError:\n        # shape was not a number\n        pass\n\n    try:\n        t = tuple(shape)\n        return t\n    except TypeError:\n        # shape was not iterable\n        pass\n\n    raise TypeError('shape must be an int, or a tuple of ints')\n\ndef sliding_window(a,ws,ss = None,flatten = True):\n    '''\n    Return a sliding window over a in any number of dimensions\n\n    Parameters:\n        a  - an n-dimensional numpy array\n        ws - an int (a is 1D) or tuple (a is 2D or greater) representing the size\n             of each dimension of the window\n        ss - an int (a is 1D) or tuple (a is 2D or greater) representing the\n             amount to slide the window in each dimension. If not specified, it\n             defaults to ws.\n        flatten - if True, all slices are flattened, otherwise, there is an\n                  extra dimension for each dimension of the input.\n\n    Returns\n        an array containing each n-dimensional window from a\n    '''\n\n    if None is ss:\n        # ss was not provided. the windows will not overlap in any direction.\n        ss = ws\n    ws = norm_shape(ws)\n    ss = norm_shape(ss)\n\n    # convert ws, ss, and a.shape to numpy arrays so that we can do math in every\n    # dimension at once.\n    ws = np.array(ws)\n    ss = np.array(ss)\n    shape = np.array(a.shape)\n\n\n    # ensure that ws, ss, and a.shape all have the same number of dimensions\n    ls = [len(shape),len(ws),len(ss)]\n    if 1 != len(set(ls)):\n        raise ValueError(\\\n        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n\n    # ensure that ws is smaller than a in every dimension\n    if np.any(ws > shape):\n        raise ValueError(\\\n        'ws cannot be larger than a in any dimension.\\\n a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n\n    # how many slices will there be in each dimension?\n    newshape = norm_shape(((shape - ws) // ss) + 1)\n    # the shape of the strided array will be the number of slices in each dimension\n    # plus the shape of the window (tuple addition)\n    newshape += norm_shape(ws)\n    # the strides tuple will be the array's strides multiplied by step size, plus\n    # the array's strides (tuple addition)\n    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n    strided = ast(a,shape = newshape,strides = newstrides)\n    if not flatten:\n        return strided\n\n    # Collapse strided so that it has one more dimension than the window.  I.e.,\n    # the new array is a flat list of slices.\n    meat = len(ws) if ws.shape else 0\n    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n    dim = firstdim + (newshape[-meat:])\n    # remove any dimensions with size 1\n    dim = filter(lambda i : i != 1,dim)\n    return strided.reshape(dim)\n"""
data/download_datasets.py,0,"b'# !wget ""https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip""\n# !wget ""https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.names""\n# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip\n\n# import copy\nimport os\nfrom subprocess import call\n\nprint("""")\n\nprint(""Downloading UCI HAR Dataset..."")\nif not os.path.exists(""UCI HAR Dataset.zip""):\n    call(\n        \'wget ""https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip""\',\n        shell=True\n    )\n    print(""Downloading done.\\n"")\nelse:\n    print(""Dataset already downloaded. Did not download twice.\\n"")\n\n\nprint(""Extracting..."")\nextract_directory = os.path.abspath(""UCI HAR Dataset"")\nif not os.path.exists(extract_directory):\n    call(\n        \'unzip -nq ""UCI HAR Dataset.zip""\',\n        shell=True\n    )\n    print(""Extracting successfully done to {}."".format(extract_directory))\nelse:\n    print(""Dataset already extracted. Did not extract twice.\\n"")\n\n\nprint(""Downloading opportunity dataset..."")\nif not os.path.exists(""OpportunityUCIDataset.zip""):\n    call(\n        \'wget ""https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip""\',\n        shell=True\n    )\n    print(""Downloading done.\\n"")\nelse:\n    print(""Dataset already downloaded. Did not download twice.\\n"")\n\n\nprint(""Extracting..."")\nif not os.path.exists(""oppChallenge_gestures.data""):\n    from preprocess_data import generate_data\n    generate_data(""OpportunityUCIDataset.zip"", ""oppChallenge_gestures.data"", ""gestures"")\n    print(""Extracting successfully done to oppChallenge_gestures.data."")\nelse:\n    print(""Dataset already extracted. Did not extract twice.\\n"")\n'"
data/preprocess_data.py,0,"b'# Adapted from: https://github.com/sussexwearlab/DeepConvLSTM\n__author__ = \'fjordonez, gchevalier\'\n\nfrom signal_filtering import filter_opportunity_datasets_accelerometers\n\nimport os\nimport zipfile\nimport argparse\nimport numpy as np\nimport cPickle as cp\n\nfrom io import BytesIO\nfrom pandas import Series\n\n# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\nNB_SENSOR_CHANNELS = 113\nNB_SENSOR_CHANNELS_WITH_FILTERING = 149 # =77 gyros +36*2 accelerometer channels\n\n# Hardcoded names of the files defining the OPPORTUNITY challenge data. As named in the original data.\nOPPORTUNITY_DATA_FILES_TRAIN = [\n    \'OpportunityUCIDataset/dataset/S1-Drill.dat\',\n    \'OpportunityUCIDataset/dataset/S1-ADL1.dat\',\n    \'OpportunityUCIDataset/dataset/S1-ADL2.dat\',\n    \'OpportunityUCIDataset/dataset/S1-ADL3.dat\',\n    \'OpportunityUCIDataset/dataset/S1-ADL4.dat\',\n    \'OpportunityUCIDataset/dataset/S1-ADL5.dat\',\n    \'OpportunityUCIDataset/dataset/S2-Drill.dat\',\n    \'OpportunityUCIDataset/dataset/S2-ADL1.dat\',\n    \'OpportunityUCIDataset/dataset/S2-ADL2.dat\',\n    \'OpportunityUCIDataset/dataset/S2-ADL3.dat\',\n    \'OpportunityUCIDataset/dataset/S3-Drill.dat\',\n    \'OpportunityUCIDataset/dataset/S3-ADL1.dat\',\n    \'OpportunityUCIDataset/dataset/S3-ADL2.dat\',\n    \'OpportunityUCIDataset/dataset/S3-ADL3.dat\'\n]\n\nOPPORTUNITY_DATA_FILES_TEST = [\n    \'OpportunityUCIDataset/dataset/S2-ADL4.dat\',\n    \'OpportunityUCIDataset/dataset/S2-ADL5.dat\',\n    \'OpportunityUCIDataset/dataset/S3-ADL4.dat\',\n    \'OpportunityUCIDataset/dataset/S3-ADL5.dat\'\n]\n\ndef select_columns_opp(data):\n    """"""Selection of the 113 columns employed in the OPPORTUNITY challenge\n\n    :param data: numpy integer matrix\n        Sensor data (all features)\n    :return: tuple((numpy integer 2D matrix, numpy integer 1D matrix))\n        (Selection of features (N, f), feature_is_accelerometer (f,) one-hot)\n    """"""\n\n    # In term of column_names.txt\'s ranges: excluded-included (here 0-indexed)\n    features_delete = np.arange(46, 50)\n    features_delete = np.concatenate([features_delete, np.arange(59, 63)])\n    features_delete = np.concatenate([features_delete, np.arange(72, 76)])\n    features_delete = np.concatenate([features_delete, np.arange(85, 89)])\n    features_delete = np.concatenate([features_delete, np.arange(98, 102)])\n    features_delete = np.concatenate([features_delete, np.arange(134, 243)])\n    features_delete = np.concatenate([features_delete, np.arange(244, 249)])\n\n    # In term of column_names.txt\'s ranges: excluded-included\n    features_delete = np.arange(46, 50)\n    features_delete = np.concatenate([features_delete, np.arange(59, 63)])\n    features_delete = np.concatenate([features_delete, np.arange(72, 76)])\n    features_delete = np.concatenate([features_delete, np.arange(85, 89)])\n    features_delete = np.concatenate([features_delete, np.arange(98, 102)])\n    features_delete = np.concatenate([features_delete, np.arange(134, 243)])\n    features_delete = np.concatenate([features_delete, np.arange(244, 249)])\n\n    # In term of column_names.txt\'s ranges: excluded-included\n    features_acc = np.arange(1, 37)\n    features_acc = np.concatenate([features_acc, np.arange(134, 194)])\n    features_acc = np.concatenate([features_acc, np.arange(207, 231)])\n\n    # One-hot for everything that is an accelerometer\n    is_accelerometer = np.zeros([243])\n    is_accelerometer[features_acc] = 1\n\n    # Deleting some signals to keep only the 113 of the challenge\n    data = np.delete(data, features_delete, 1)\n    is_accelerometer = np.delete(is_accelerometer, features_delete, 0)\n\n    # Shape `(N, f), (f, )`\n    # where N is number of timesteps and f is 113 features, one-hot\n    return data, is_accelerometer\n\n\ndef normalize(x):\n    """"""Normalizes all sensor channels by mean substraction,\n    dividing by the standard deviation and by 2.\n\n    :param x: numpy integer matrix\n        Sensor data\n    :return:\n        Normalized sensor data\n    """"""\n    x = np.array(x, dtype=np.float32)\n    m = np.mean(x, axis=0)\n    x -= m\n    std = np.std(x, axis=0)\n    std += 0.000001\n    x /= (std * 2)  # 2 is for having smaller values\n    return x\n\ndef split_data_into_time_gyros_accelerometers(data, is_accelerometer):\n    # Assuming index 0 of features is reserved for time.\n    # Splitting data into gyros, accelerometers and time:\n\n    is_accelerometer = np.array(is_accelerometer*2-1, dtype=np.int32)\n    # is_accelerometer\'s zeros have been replaced by -1. 1\'s are untouched.\n    plane = np.arange(len(is_accelerometer)) * is_accelerometer\n    delete_gyros = [-e for e in plane if e <= 0]\n    delete_accms = [ e for e in plane if e >= 0]\n\n    time  = data[:,0]\n    gyros = np.delete(data, delete_accms, 1)\n    accms = np.delete(data, delete_gyros, 1)\n    return time, gyros, accms\n\ndef divide_x_y(data, label, filter_accelerometers):\n    """"""Segments each sample into (time+features) and (label)\n\n    :param data: numpy integer matrix\n        Sensor data\n    :param label: string, [\'gestures\' (default), \'locomotion\']\n        Type of activities to be recognized\n    :return: numpy integer matrix, numpy integer array\n        Features encapsulated into a matrix and labels as an array\n    """"""\n    if filter_accelerometers:\n        data_x = data[:, :114]\n    else:\n        data_x = data[:,1:114]\n\n    # Choose labels type for y\n    if label not in [\'locomotion\', \'gestures\']:\n            raise RuntimeError(""Invalid label: \'%s\'"" % label)\n    if label == \'locomotion\':\n        data_y = data[:, 114]  # Locomotion label\n    elif label == \'gestures\':\n        data_y = data[:, 115]  # Gestures label\n\n    return data_x, data_y\n\n\ndef adjust_idx_labels(data_y, label):\n    """"""Transforms original labels into the range [0, nb_labels-1]\n\n    :param data_y: numpy integer array\n        Sensor labels\n    :param label: string, [\'gestures\' (default), \'locomotion\']\n        Type of activities to be recognized\n    :return: numpy integer array\n        Modified sensor labels\n    """"""\n\n    if label == \'locomotion\':  # Labels for locomotion are adjusted\n        data_y[data_y == 4] = 3\n        data_y[data_y == 5] = 4\n    elif label == \'gestures\':  # Labels for gestures are adjusted\n        data_y[data_y == 406516] = 1\n        data_y[data_y == 406517] = 2\n        data_y[data_y == 404516] = 3\n        data_y[data_y == 404517] = 4\n        data_y[data_y == 406520] = 5\n        data_y[data_y == 404520] = 6\n        data_y[data_y == 406505] = 7\n        data_y[data_y == 404505] = 8\n        data_y[data_y == 406519] = 9\n        data_y[data_y == 404519] = 10\n        data_y[data_y == 406511] = 11\n        data_y[data_y == 404511] = 12\n        data_y[data_y == 406508] = 13\n        data_y[data_y == 404508] = 14\n        data_y[data_y == 408512] = 15\n        data_y[data_y == 407521] = 16\n        data_y[data_y == 405506] = 17\n    return data_y\n\n\ndef check_data(data_set):\n    """"""Try to access to the file and checks if dataset is in the data directory\n       In case the file is not found try to download it from original location\n\n    :param data_set:\n            Path with original OPPORTUNITY zip file\n    :return:\n    """"""\n    print \'Checking dataset {0}\'.format(data_set)\n    data_dir, data_file = os.path.split(data_set)\n    # When a directory is not provided, check if dataset is in the data directory\n    if data_dir == """" and not os.path.isfile(data_set):\n        new_path = os.path.join(os.path.split(__file__)[0], ""data"", data_set)\n        if os.path.isfile(new_path) or data_file == \'OpportunityUCIDataset.zip\':\n            data_set = new_path\n\n    # When dataset not found, try to download it from UCI repository\n    if (not os.path.isfile(data_set)) and data_file == \'OpportunityUCIDataset.zip\':\n        print \'... dataset path {0} not found\'.format(data_set)\n        import urllib\n        origin = (\n            \'https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip\'\n        )\n        if not os.path.exists(data_dir):\n            print \'... creating directory {0}\'.format(data_dir)\n            os.makedirs(data_dir)\n        print \'... downloading data from {0}\'.format(origin)\n        urllib.urlretrieve(origin, data_set)\n\n    return data_dir\n\n\ndef process_dataset_file(data, label, filter_accelerometers):\n    """"""Function defined as a pipeline to process individual OPPORTUNITY files\n\n    :param data: numpy integer matrix\n        Matrix containing data samples (rows) for every sensor channel (column)\n    :param label: string, [\'gestures\' (default), \'locomotion\']\n        Type of activities to be recognized\n    :return: numpy integer matrix, numy integer array\n        Processed sensor data, segmented into features (x) and labels (y)\n    """"""\n\n    # Select correct columns\n    data, is_accelerometer = select_columns_opp(data)\n\n    # Colums are segmentd into features and labels\n    data_x, data_y =  divide_x_y(data, label, filter_accelerometers)\n    data_y = adjust_idx_labels(data_y, label)\n    data_y = data_y.astype(int)\n\n    # Perform linear interpolation (a.k.a. filling in NaN)\n    data_x = np.array([Series(i).interpolate() for i in data_x.T]).T\n    # Remaining missing data are converted to zero\n    data_x[np.isnan(data_x)] = 0\n\n    # All sensor channels are normalized\n    data_x = normalize(data_x)\n\n    if filter_accelerometers:\n        # x\'s accelerometers, are filtered out by some LP passes for noise and gravity.\n        # Time is discarded, accelerometers are filtered to\n        # split gravity and remove noise.\n        _, x_gyros, x_accms = split_data_into_time_gyros_accelerometers(\n            data_x, is_accelerometer\n        )\n        print ""gyros\' shape: {}"".format(x_gyros.shape)\n        print ""old accelerometers\' shape: {}"".format(x_accms.shape)\n        x_accms = normalize(filter_opportunity_datasets_accelerometers(x_accms))\n        print ""new accelerometers\' shape: {}"".format(x_accms.shape)\n        # Put features together (inner concatenation with transposals)\n\n        data_x = np.hstack([x_gyros, x_accms])\n        print ""new total shape: {}"".format(data_x.shape)\n\n    return data_x, data_y\n\n\ndef load_data_files(zipped_dataset, label, data_files, filter_accelerometers=False):\n    """"""Loads specified data files\' features (x) and labels (y)\n\n    :param zipped_dataset: ZipFile\n        OPPORTUNITY zip file to read from\n    :param label: string, [\'gestures\' (default), \'locomotion\']\n        Type of activities to be recognized. The OPPORTUNITY dataset includes several annotations to perform\n        recognition modes of locomotion/postures and recognition of sporadic gestures.\n    :param data_files: list of strings\n        Data files to load.\n    :return: numpy integer matrix, numy integer array\n        Loaded sensor data, segmented into features (x) and labels (y)\n    """"""\n\n    nb_sensors = NB_SENSOR_CHANNELS_WITH_FILTERING if filter_accelerometers else NB_SENSOR_CHANNELS\n    data_x = np.empty((0, nb_sensors))\n    data_y = np.empty((0))\n\n    for filename in data_files:\n        try:\n            data = np.loadtxt(BytesIO(zipped_dataset.read(filename)))\n            print \'... file {0}\'.format(filename)\n            x, y = process_dataset_file(data, label, filter_accelerometers)\n            data_x = np.vstack((data_x, x))\n            data_y = np.concatenate([data_y, y])\n            print ""Data\'s shape yet: ""\n            print data_x.shape\n        except KeyError:\n            print \'ERROR: Did not find {0} in zip file\'.format(filename)\n\n    return data_x, data_y\n\n\ndef generate_data(dataset, target_filename, label):\n    """"""Function to read the OPPORTUNITY challenge raw data and process all sensor channels\n\n    :param dataset: string\n        Path with original OPPORTUNITY zip file\n    :param target_filename: string\n        Processed file\n    :param label: string, [\'gestures\' (default), \'locomotion\']\n        Type of activities to be recognized. The OPPORTUNITY dataset includes several annotations to perform\n        recognition modes of locomotion/postures and recognition of sporadic gestures.\n    """"""\n\n    data_dir = check_data(dataset)\n    zf = zipfile.ZipFile(dataset)\n\n    print \'\\nProcessing train dataset files...\\n\'\n    X_train, y_train = load_data_files(zf, label, OPPORTUNITY_DATA_FILES_TRAIN)\n    print \'\\nProcessing test dataset files...\\n\'\n    X_test,  y_test  = load_data_files(zf, label, OPPORTUNITY_DATA_FILES_TEST)\n\n    print ""Final datasets with size: | train {0} | test {1} | "".format(X_train.shape, X_test.shape)\n\n    obj = [(X_train, y_train), (X_test, y_test)]\n    f = file(os.path.join(data_dir, target_filename), \'wb\')\n    cp.dump(obj, f, protocol=cp.HIGHEST_PROTOCOL)\n    f.close()\n\n\ndef get_args():\n    \'\'\'This function parses and return arguments passed in\'\'\'\n    parser = argparse.ArgumentParser(\n        description=\'Preprocess OPPORTUNITY dataset\')\n    # Add arguments\n    parser.add_argument(\n        \'-i\', \'--input\', type=str, help=\'OPPORTUNITY zip file\', required=True)\n    parser.add_argument(\n        \'-o\', \'--output\', type=str, help=\'Processed data file\', required=True)\n    parser.add_argument(\n        \'-t\', \'--task\', type=str.lower, help=\'Type of activities to be recognized\', default=""gestures"", choices = [""gestures"", ""locomotion""], required=False)\n    # Array for all arguments passed to script\n    args = parser.parse_args()\n    # Assign args to variables\n    dataset = args.input\n    target_filename = args.output\n    label = args.task\n    # Return all variable values\n    return dataset, target_filename, label\n\nif __name__ == \'__main__\':\n\n    OpportunityUCIDataset_zip, output, l = get_args();\n    generate_data(OpportunityUCIDataset_zip, output, l)\n'"
data/signal_filtering.py,0,"b""# Explanations here about what this file does:\n# https://github.com/guillaume-chevalier/python-signal-filtering-stft\n\n# However our signal here is sampled and processed differently.\n# See function filter_opportunity_datasets_accelerometers below.\n__author__ = 'gchevalier'\n\nimport numpy as np\nfrom scipy import signal\n\n\ndef butter_lowpass(cutoff, nyq_freq, order=4):\n    # Build the filter\n    normal_cutoff = float(cutoff) / nyq_freq\n    b, a = signal.butter(order, normal_cutoff, btype='lowpass')\n    return b, a\n\ndef butter_lowpass_filter(data, cutoff_freq, nyq_freq, order=4):\n    # Build and apply filter to data (signal)\n    b, a = butter_lowpass(cutoff_freq, nyq_freq, order=order)\n    y = signal.filtfilt(b, a, data)\n    return y\n\ndef filter_opportunity_datasets_accelerometers(accelerometer_data):\n    # Cutoff frequencies and filters inspired from:\n    # https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf\n    # Their butterworth filter's order is of 3.\n\n    # Note: here we have a 30 Hz sampling rate on the opportunity dataset,\n    # which is diffrerent than in the paper above.\n    opportunity_dataset_sampling_rate = 30.0\n    nyq_freq = opportunity_dataset_sampling_rate / 2.0\n\n    new_channels = []\n    for channel in accelerometer_data.transpose():\n        # LP filter to 0.3 Hz for splitting gravity component from body.\n        gravity = butter_lowpass_filter(channel, 0.3, nyq_freq, order=3)\n\n        body = channel\n        # We assume that body acc has lost its gravity componenent\n        body -= gravity\n\n        new_channels.append(body)\n        new_channels.append(gravity)\n\n    preprocessed_data = np.array(new_channels).transpose()\n    return preprocessed_data\n"""
