file_path,api_count,code
datasets.py,0,"b'import json\nimport random\nimport urllib\nfrom typing import Callable\n\nimport math\nimport numpy as np\n\n\ndef generate_data(\n        exercice_number,\n        window_size_past=None,\n        window_size_future=None,\n        n_samples=None\n):\n    if exercice_number == 1:\n        return generate_data_v1(n_samples, window_size_past)\n\n    if exercice_number == 2:\n        return generate_data_v2(n_samples, window_size_past)\n\n    if exercice_number == 3:\n        return generate_data_v3(n_samples, window_size_past)\n\n    if exercice_number == 4:\n        return generate_data_v4(n_samples, window_size_future, window_size_past)\n\n\ndef generate_data_v1(n_samples, sequence_length):\n    """"""\n    Data for exercise 1.\n\n    returns: tuple (X, Y)\n        X is a sine and a cosine from 0.0*pi to 1.5*pi\n        Y is a sine and a cosine from 1.5*pi to 3.0*pi\n    Therefore, Y follows X. There is also a random offset\n    commonly applied to X an Y.\n\n    The returned arrays are of shape:\n        (seq_length, batch_size, output_dim)\n        Therefore: (10, batch_size, 2)\n\n    For this exercise, let\'s ignore the ""isTrain""\n    argument and test on the same data.\n    """"""\n    if n_samples is None:\n        n_samples = 1000\n    if sequence_length is None:\n        sequence_length = 10\n\n    batch_x = []\n    batch_y = []\n    for _ in range(n_samples):\n        rand = random.random() * 2 * math.pi\n\n        sig1 = np.sin(np.linspace(0.0 * math.pi + rand,\n                                  3.0 * math.pi + rand, sequence_length * 2))\n        sig2 = np.cos(np.linspace(0.0 * math.pi + rand,\n                                  3.0 * math.pi + rand, sequence_length * 2))\n        x1 = sig1[:sequence_length]\n        y1 = sig1[sequence_length:]\n        x2 = sig2[:sequence_length]\n        y2 = sig2[sequence_length:]\n\n        x_ = np.array([x1, x2])\n        y_ = np.array([y1, y2])\n        x_, y_ = x_.T, y_.T\n\n        batch_x.append(x_)\n        batch_y.append(y_)\n\n    batch_x = np.array(batch_x)\n    batch_y = np.array(batch_y)\n    # shape: (batch_size, seq_length, output_dim)\n\n    return batch_x, batch_y\n\n\ndef generate_data_v2(n_samples, sequence_length):\n    """"""\n    Similar the the ""v1"" function, but here we generate a signal with\n    2 frequencies chosen randomly - and this for the 2 signals. Plus,\n    the lenght of the examples is of 15 rather than 10.\n    So we have 30 total values for past and future.\n    """"""\n    if n_samples is None:\n        n_samples = 10000\n    if sequence_length is None:\n        sequence_length = 15\n\n    return generate_data_two_freqs(n_samples, seq_length=sequence_length)\n\n\ndef generate_data_v3(n_samples, sequence_length):\n    """"""\n    Similar to the ""v2"" function, but here we generate a signal\n    with noise in the X values.\n    """"""\n    if n_samples is None:\n        n_samples = 10000\n    if sequence_length is None:\n        sequence_length = 30\n\n    x, y = generate_data_two_freqs(n_samples, seq_length=sequence_length)\n    noise_amount = random.random() * 0.15 + 0.10\n    x = x + noise_amount * np.random.randn(n_samples, sequence_length, 1)\n\n    avg = np.average(x)\n    std = np.std(x) + 0.0001\n    x = x - avg\n    y = y - avg\n    x = x / std / 2.5\n    y = y / std / 2.5\n\n    return x, y\n\n\ndef generate_data_two_freqs(batch_size, seq_length):\n    batch_x = []\n    batch_y = []\n    for _ in range(batch_size):\n        offset_rand = random.random() * 2 * math.pi\n        freq_rand = (random.random() - 0.5) / 1.5 * 15 + 0.5\n        amp_rand = random.random() + 0.1\n\n        sig1 = amp_rand * np.sin(np.linspace(\n            seq_length / 15.0 * freq_rand * 0.0 * math.pi + offset_rand,\n            seq_length / 15.0 * freq_rand * 3.0 * math.pi + offset_rand,\n            seq_length * 2\n        )\n        )\n\n        offset_rand = random.random() * 2 * math.pi\n        freq_rand = (random.random() - 0.5) / 1.5 * 15 + 0.5\n        amp_rand = random.random() * 1.2\n\n        sig1 = amp_rand * np.cos(np.linspace(\n            seq_length / 15.0 * freq_rand * 0.0 * math.pi + offset_rand,\n            seq_length / 15.0 * freq_rand * 3.0 * math.pi + offset_rand,\n            seq_length * 2\n        )\n        ) + sig1\n\n        x1 = sig1[:seq_length]\n        y1 = sig1[seq_length:]\n\n        x_ = np.array([x1])\n        y_ = np.array([y1])\n        x_, y_ = x_.T, y_.T\n\n        batch_x.append(x_)\n        batch_y.append(y_)\n\n    batch_x = np.array(batch_x)\n    batch_y = np.array(batch_y)\n    # shape: (batch_size, seq_length, output_dim)\n\n    return batch_x, batch_y\n\n\ndef load_currency(currency):\n    """"""\n    Return the historical data for the USD or EUR bitcoin value. Is done with an web API call.\n    curr = ""USD"" | ""EUR""\n    """"""\n    # For more info on the URL call, it is inspired by :\n    # https://github.com/Levino/coindesk-api-node\n    req = urllib.request.Request(\n        ""http://api.coindesk.com/v1/bpi/historical/close.json?start=2010-07-17&end=2017-12-01&currency={}"".format(\n            currency),\n        method=""GET"",\n        headers={\'content-type\': \'application/json\'}\n    )\n    response = urllib.request.urlopen(req)\n    data = json.loads(response.read())\n\n    time_to_values = sorted(data[""bpi""].items())\n    values = [val for key, val in time_to_values]\n    kept_values = values[1000:]\n\n    return kept_values\n\n\ndef generate_data_v4(n_samples, window_size_future, window_size_past):\n    if n_samples is None:\n        n_samples = 2000\n    if window_size_past is None:\n        window_size_past = 40\n    if window_size_future is None:\n        window_size_future = 40\n\n    data_inputs_usd = load_currency(""USD"")\n    data_inputs_eur = load_currency(""EUR"")\n\n    data_inputs_usd = np.expand_dims(np.array(data_inputs_usd), axis=1)\n    data_inputs_eur = np.expand_dims(np.array(data_inputs_eur), axis=1)\n\n    data_inputs = np.concatenate((data_inputs_usd, data_inputs_eur), axis=1)\n    data_inputs = data_inputs[:n_samples]\n\n    return window_time_series(\n        data_inputs=data_inputs,\n        window_size_past=window_size_past,\n        window_size_future=window_size_future\n    )\n\n\ndef window_time_series(data_inputs, window_size_past, window_size_future):\n    new_data_inputs = []\n    new_expected_outputs = []\n\n    for i in range(len(data_inputs) - window_size_past - window_size_future):\n        new_data_inputs.append(data_inputs[i: i + window_size_past])\n        new_expected_outputs.append(\n            data_inputs[i + window_size_past: i + window_size_past + window_size_future])\n\n    return np.array(new_data_inputs), np.array(new_expected_outputs)\n\n\ndef metric_3d_to_2d_wrapper(metric_fun: Callable):\n    def metric(data_inputs, expected_outputs):\n        # We keep axis 0 for evaluation on USD only (or on first dim only when we have multidim output).\n        return metric_fun(np.array(data_inputs)[..., 0], np.array(expected_outputs)[..., 0])\n\n    return metric\n'"
plotting.py,0,"b'import numpy as np\nfrom matplotlib import pyplot as plt\n\n\ndef plot_predictions(data_inputs, expected_outputs, predicted_outputs, save=False):\n    plt.figure(figsize=(12, 3))\n\n    for output_dim_index in range(predicted_outputs.shape[-1]):\n        past = data_inputs[:, output_dim_index]\n        expected = expected_outputs[:, output_dim_index]\n        pred = predicted_outputs[:, output_dim_index]\n\n        label1 = ""Seen (past) values"" if output_dim_index == 0 else ""_nolegend_""\n        label2 = ""True future values"" if output_dim_index == 0 else ""_nolegend_""\n        label3 = ""Predictions"" if output_dim_index == 0 else ""_nolegend_""\n\n        plt.plot(range(past.shape[0]), past, ""o--b"", label=label1)\n        plt.plot(range(past.shape[0], expected.shape[0] + past.shape[0]), expected, ""x--b"", label=label2)\n        plt.plot(range(past.shape[0], pred.shape[0] + past.shape[0]), pred, ""o--y"", label=label3)\n\n    plt.legend(loc=\'best\')\n    title = ""Exercice Predictions v.s. true values""\n    plt.title(title)\n\n    if save:\n        plt.savefig(title + \'.png\')\n\n    plt.show()\n\n\ndef plot_metrics(pipeline, exercice_number):\n    mse_train = pipeline.get_step_by_name(\'epoch_metrics\').get_metric_train(\'mse\')\n    print(\'last mse train: {}\'.format(mse_train[-1]))\n    print(\'best mse train: {}\'.format(min(mse_train)))\n\n    mse_validation = pipeline.get_step_by_name(\'epoch_metrics\').get_metric_validation(\'mse\')\n    print(\'last mse validation: {}\'.format(mse_validation[-1]))\n    print(\'best mse validation: {}\'.format(min(mse_validation)))\n\n    plot_metric(\n        mse_train,\n        mse_validation,\n        xlabel=\'epoch\',\n        ylabel=\'mse\',\n        title=\'Exercice {} Model Mean Squared Error\'.format(exercice_number)\n    )\n\n\ndef plot_metric(metric_train, metric_validation=None, xlabel=\'x\', ylabel=\'y\', title=\'Metric\', save=False):\n    plt.plot(range(len(metric_train)), metric_train)\n\n    if len(metric_validation) <= len(metric_train):\n        domain_val = list(np.linspace(0, len(metric_train) - 1, num=len(metric_validation)))\n    else:\n        domain_val = list(range(len(metric_validation)))\n\n    legend = [\'training\']\n    if metric_validation is not None:\n        plt.plot(domain_val, metric_validation)\n        legend.append(\'validation\')\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n\n    plt.legend(legend, loc=\'upper left\')\n    if save:\n        plt.savefig(title + \'.png\')\n    plt.show()\n    plt.close()\n'"
seq2seq.py,13,"b'from logging import warning\nfrom typing import List\n\nimport tensorflow as tf\nfrom neuraxle.data_container import DataContainer\nfrom neuraxle.hyperparams.space import HyperparameterSamples\nfrom neuraxle.metaopt.random import ValidationSplitWrapper\nfrom neuraxle.metrics import MetricsWrapper\nfrom neuraxle.pipeline import Pipeline, MiniBatchSequentialPipeline\nfrom neuraxle.steps.data import EpochRepeater, DataShuffler\nfrom neuraxle.steps.flow import TrainOnlyWrapper\nfrom neuraxle.steps.loop import ForEachDataInput\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow_core.python.client import device_lib\nfrom tensorflow_core.python.keras import Input, Model\nfrom tensorflow_core.python.keras.layers import GRUCell, RNN, Dense\nfrom tensorflow_core.python.training.adam import AdamOptimizer\n\nfrom datasets import generate_data\nfrom datasets import metric_3d_to_2d_wrapper\nfrom neuraxle_tensorflow.tensorflow_v1 import TensorflowV1ModelStep\nfrom neuraxle_tensorflow.tensorflow_v2 import Tensorflow2ModelStep\nfrom plotting import plot_metrics\nfrom steps import MeanStdNormalizer, ToNumpy, PlotPredictionsWrapper\n\n\ndef create_model(step: Tensorflow2ModelStep) -> tf.keras.Model:\n    """"""\n    Create a TensorFlow v2 sequence to sequence (seq2seq) encoder-decoder model.\n\n    :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n    :return: TensorFlow v2 Keras model\n    """"""\n    # shape: (batch_size, seq_length, input_dim)\n    encoder_inputs = Input(\n        shape=(None, step.hyperparams[\'input_dim\']),\n        batch_size=None,\n        dtype=tf.dtypes.float32,\n        name=\'encoder_inputs\'\n    )\n\n    last_encoder_outputs, last_encoders_states = _create_encoder(step, encoder_inputs)\n    decoder_outputs = _create_decoder(step, last_encoder_outputs, last_encoders_states)\n\n    return Model(encoder_inputs, decoder_outputs)\n\n\ndef _create_encoder(step: Tensorflow2ModelStep, encoder_inputs: Input) -> (tf.Tensor, List[tf.Tensor]):\n    """"""\n    Create an encoder RNN using GRU Cells. GRU cells are similar to LSTM cells.\n\n    :param step: The base Neuraxle step for TensorFlow v2 (class Tensorflow2ModelStep)\n    :param encoder_inputs: encoder inputs layer of shape (batch_size, seq_length, input_dim)\n    :return: (last encoder outputs, last stacked encoders states)\n                last_encoder_outputs shape: (batch_size, hidden_dim)\n                last_encoder_states shape: (layers_stacked_count, batch_size, hidden_dim)\n    """"""\n    encoder = RNN(cell=_create_stacked_rnn_cells(step), return_sequences=False, return_state=True)\n\n    last_encoder_outputs_and_states = encoder(encoder_inputs)\n    # last_encoder_outputs shape: (batch_size, hidden_dim)\n    # last_encoder_states shape: (layers_stacked_count, batch_size, hidden_dim)\n\n    # refer to: https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN?version=stable#output_shape_2\n    last_encoder_outputs, *last_encoders_states = last_encoder_outputs_and_states\n    return last_encoder_outputs, last_encoders_states\n\n\ndef _create_decoder(\n        step: Tensorflow2ModelStep, last_encoder_outputs: tf.Tensor,last_encoders_states: List[tf.Tensor]\n) -> tf.Tensor:\n    """"""\n    Create a decoder RNN using GRU cells.\n\n    :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n    :param last_encoders_states: last encoder states tensor\n    :param last_encoder_outputs: last encoder output tensor\n    :return: decoder output\n    """"""\n    decoder_lstm = RNN(cell=_create_stacked_rnn_cells(step), return_sequences=True, return_state=False)\n\n    last_encoder_output = tf.expand_dims(last_encoder_outputs, axis=1)\n    # last encoder output shape: (batch_size, 1, hidden_dim)\n\n    replicated_last_encoder_output = tf.repeat(\n        input=last_encoder_output,\n        repeats=step.hyperparams[\'window_size_future\'],\n        axis=1\n    )\n    # replicated last encoder output shape: (batch_size, window_size_future, hidden_dim)\n\n    decoder_outputs = decoder_lstm(replicated_last_encoder_output, initial_state=last_encoders_states)\n    # decoder outputs shape: (batch_size, window_size_future, hidden_dim)\n\n    decoder_dense = Dense(step.hyperparams[\'output_dim\'])\n    # decoder outputs shape: (batch_size, window_size_future, output_dim)\n\n    return decoder_dense(decoder_outputs)\n\n\ndef _create_stacked_rnn_cells(step: Tensorflow2ModelStep) -> List[GRUCell]:\n    """"""\n    Create a `layers_stacked_count` amount of GRU cells and stack them on top of each other.\n    They have a `hidden_dim` number of neuron layer size.\n\n    :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n    :return: list of gru cells\n    """"""\n    cells = []\n    for _ in range(step.hyperparams[\'layers_stacked_count\']):\n        cells.append(GRUCell(step.hyperparams[\'hidden_dim\']))\n\n    return cells\n\n\ndef create_loss(step: Tensorflow2ModelStep, expected_outputs: tf.Tensor, predicted_outputs: tf.Tensor) -> tf.Tensor:\n    """"""\n    Create model loss.\n\n    :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n    :param expected_outputs: expected outputs of shape (batch_size, window_size_future, output_dim)\n    :param predicted_outputs: expected outputs of shape (batch_size, window_size_future, output_dim)\n    :return: loss (a tf Tensor that is a float)\n    """"""\n    l2 = step.hyperparams[\'lambda_loss_amount\'] * sum(\n        tf.reduce_mean(tf.nn.l2_loss(tf_var))\n        for tf_var in step.model.trainable_variables\n    )\n\n    output_loss = sum(\n        tf.reduce_mean(tf.nn.l2_loss(pred - expected))\n        for pred, expected in zip(predicted_outputs, expected_outputs)\n    ) / float(len(predicted_outputs))\n\n    return output_loss + l2\n\n\ndef create_optimizer(step: TensorflowV1ModelStep) -> AdamOptimizer:\n    """"""\n    Create a TensorFlow 2 Optimizer: here the AdamOptimizer.\n\n    :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n    :return: optimizer\n    """"""\n    return AdamOptimizer(learning_rate=step.hyperparams[\'learning_rate\'])\n\n\ndef main(chosen_device):\n    exercice_number = 1\n    print(\'exercice {}\\n==================\'.format(exercice_number))\n\n    data_inputs, expected_outputs = generate_data(\n        # See: https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/datasets.py\n        exercice_number=exercice_number,\n        n_samples=None,\n        window_size_past=None,\n        window_size_future=None\n    )\n\n    print(\'data_inputs shape: {} => (n_samples, window_size_past, input_dim)\'.format(data_inputs.shape))\n    print(\'expected_outputs shape: {} => (n_samples, window_size_future, output_dim)\'.format(expected_outputs.shape))\n\n    sequence_length = data_inputs.shape[1]\n    input_dim = data_inputs.shape[2]\n    output_dim = expected_outputs.shape[2]\n\n    batch_size = 100\n    epochs = 3\n    validation_size = 0.15\n    max_plotted_validation_predictions = 10\n\n    seq2seq_pipeline_hyperparams = HyperparameterSamples({\n        \'hidden_dim\': 100,\n        \'layers_stacked_count\': 2,\n        \'lambda_loss_amount\': 0.0003,\n        \'learning_rate\': 0.006,\n        \'window_size_future\': sequence_length,\n        \'output_dim\': output_dim,\n        \'input_dim\': input_dim\n    })\n    feature_0_metric = metric_3d_to_2d_wrapper(mean_squared_error)\n    metrics = {\'mse\': feature_0_metric}\n\n    signal_prediction_pipeline = Pipeline([\n        ForEachDataInput(MeanStdNormalizer()),\n        ToNumpy(),\n        PlotPredictionsWrapper(Tensorflow2ModelStep(\n            # See: https://github.com/Neuraxio/Neuraxle-TensorFlow\n            create_model=create_model,\n            create_loss=create_loss,\n            create_optimizer=create_optimizer,\n            expected_outputs_dtype=tf.dtypes.float32,\n            data_inputs_dtype=tf.dtypes.float32,\n            print_loss=True\n        ).set_hyperparams(seq2seq_pipeline_hyperparams))\n    ]).set_name(\'SignalPrediction\')\n\n    pipeline = Pipeline([EpochRepeater(\n        ValidationSplitWrapper(\n            MetricsWrapper(Pipeline([\n                TrainOnlyWrapper(DataShuffler()),\n                MiniBatchSequentialPipeline([\n                    MetricsWrapper(\n                        signal_prediction_pipeline,\n                        metrics=metrics,\n                        name=\'batch_metrics\'\n                    )\n                ], batch_size=batch_size)\n            ]), metrics=metrics,\n                name=\'epoch_metrics\',\n                print_metrics=True\n            ),\n            test_size=validation_size,\n            scoring_function=feature_0_metric\n        ), epochs=epochs)])\n\n    pipeline, outputs = pipeline.fit_transform(data_inputs, expected_outputs)\n\n    plot_metrics(pipeline=pipeline, exercice_number=exercice_number)\n    plot_predictions(data_inputs, expected_outputs, pipeline, max_plotted_validation_predictions)\n\n\ndef plot_predictions(data_inputs, expected_outputs, pipeline, max_plotted_predictions):\n    _, _, data_inputs_validation, expected_outputs_validation = \\\n        pipeline.get_step_by_name(\'ValidationSplitWrapper\').split(data_inputs, expected_outputs)\n\n    pipeline.apply(\'toggle_plotting\')\n    pipeline.apply(\'set_max_plotted_predictions\', max_plotted_predictions)\n\n    signal_prediction_pipeline = pipeline.get_step_by_name(\'SignalPrediction\')\n    signal_prediction_pipeline.transform_data_container(DataContainer(\n        data_inputs=data_inputs_validation,\n        expected_outputs=expected_outputs_validation\n    ))\n\n\ndef choose_tf_device():\n    """"""\n    Choose a TensorFlow device (e.g.: GPU if available) to compute on.\n    """"""\n    tf.debugging.set_log_device_placement(True)\n    devices = [x.name for x in device_lib.list_local_devices()]\n    print(\'You can use the following tf devices: {}\'.format(devices))\n    try:\n        chosen_device = [d for d in devices if \'gpu\' in d.lower()][0]\n    except:\n        warning(\n            ""No GPU device found. Please make sure to do `Runtime > Change Runtime Type` and select GPU for Python 3."")\n        chosen_device = devices[0]\n    print(\'Chosen Device: {}\'.format(chosen_device))\n    return chosen_device\n\n\nif __name__ == \'__main__\':\n    chosen_device = choose_tf_device()\n    main(chosen_device)\n'"
steps.py,0,"b""from typing import Callable\n\nimport numpy as np\nfrom neuraxle.base import NonFittableMixin, BaseStep, Identity, ExecutionContext\nfrom neuraxle.data_container import DataContainer\nfrom neuraxle.steps.output_handlers import InputAndOutputTransformerMixin\nfrom neuraxle.union import FeatureUnion\n\nfrom plotting import plot_predictions\n\n\nclass MeanStdNormalizer(NonFittableMixin, InputAndOutputTransformerMixin, BaseStep):\n    def __init__(self):\n        BaseStep.__init__(self)\n        InputAndOutputTransformerMixin.__init__(self)\n        NonFittableMixin.__init__(self)\n\n    def transform(self, data_inputs):\n        di, eo = data_inputs\n        mean = np.mean(di, axis=0) + 0.00001\n        stddev = np.std(di, axis=0) + 0.00001\n        di = (di - mean) / (2.5 * stddev)\n\n        if eo is not None:\n            eo = (eo - mean) / (2.5 * stddev)\n\n        return di, eo\n\n\nclass WindowTimeSeries(NonFittableMixin, InputAndOutputTransformerMixin, BaseStep):\n    def __init__(self, window_size_past, window_size_future):\n        BaseStep.__init__(self)\n        InputAndOutputTransformerMixin.__init__(self)\n        NonFittableMixin.__init__(self)\n        self.window_size_past = window_size_past\n        self.window_size_future = window_size_future\n\n    def transform(self, data_inputs):\n        data_inputs, expected_outputs = data_inputs\n\n        new_data_inputs = []\n        new_expected_outputs = []\n        for i in range(len(data_inputs) - self.window_size_past - self.window_size_future):\n            new_data_inputs.append(data_inputs[i: i + self.window_size_past])\n            new_expected_outputs.append(\n                data_inputs[i + self.window_size_past: i + self.window_size_past + self.window_size_future])\n\n        return np.array(new_data_inputs), np.array(new_expected_outputs)\n\n\nclass ToNumpy(NonFittableMixin, InputAndOutputTransformerMixin, BaseStep):\n    def __init__(self):\n        BaseStep.__init__(self)\n        InputAndOutputTransformerMixin.__init__(self)\n        NonFittableMixin.__init__(self)\n\n    def transform(self, data_inputs):\n        data_inputs, expected_outputs = data_inputs\n        return np.array(data_inputs), np.array(expected_outputs)\n\n\nclass PlotPredictionsWrapper(FeatureUnion):\n    def __init__(self, wrapped, max_plotted_predictions=None):\n        if max_plotted_predictions is None:\n            max_plotted_predictions = 10\n\n        FeatureUnion.__init__(self, [\n            Identity(),\n            wrapped\n        ], joiner=PlotPredictionsJoiner(plot_predictions, max_plotted_predictions), n_jobs=1)\n\n\nclass PlotPredictionsJoiner(NonFittableMixin, BaseStep):\n    def __init__(self, plotting_function: Callable, max_plotted_predictions, enabled=False):\n        NonFittableMixin.__init__(self)\n        BaseStep.__init__(self)\n        self.max_plotted_predictions = max_plotted_predictions\n        self.enabled = enabled\n        self.plotting_function = plotting_function\n\n    def set_max_plotted_predictions(self, max_plotted_predictions):\n        self.max_plotted_predictions = max_plotted_predictions\n\n    def toggle_plotting(self):\n        self.enabled = not self.enabled\n\n    def transform(self, data_inputs):\n        raise NotImplementedError('must be used inside a pipeline')\n\n    def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n        past = data_container.data_inputs[0].data_inputs\n        predicted = data_container.data_inputs[1].data_inputs\n        expected = data_container.expected_outputs\n\n        if self.enabled:\n            self._plot_predictions(expected, past, predicted)\n\n        data_container.set_data_inputs(predicted)\n\n        return data_container\n\n    def _plot_predictions(self, expected, past, predicted):\n        i = 0\n        for past_sequence, expected_sequence, predicted_sequence in zip(past, expected, predicted):\n            if i > self.max_plotted_predictions:\n                break\n\n            self.plotting_function(past_sequence, expected_sequence, predicted_sequence)\n            i += 1\n"""
