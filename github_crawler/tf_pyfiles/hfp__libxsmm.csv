file_path,api_count,code
documentation/conf.py,0,"b'###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\nimport sphinx_rtd_theme\n\nproject = \'LIBXSMM\'\ncopyright = \'2009-2020, Intel Corporation.\'\nauthor = \'Intel Corporation\'\n\n# m2r implies recommonmark\nextensions = [\n    ""m2r""\n]\n\nmaster_doc = ""index""\nsource_suffix = [\n    "".rst"", "".md""\n]\n\nexclude_patterns = [\n    ""Thumbs.db"",\n    "".DS_Store"",\n    ""_build""\n]\n\nhtml_theme = ""sphinx_rtd_theme""\nhtml_theme_options = {\n    ""navigation_depth"": 2\n}\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_static_path = [""../.theme""]\n\ntemplates_path = [""_templates""]\npygments_style = ""sphinx""\n\nlanguage = None\n'"
scripts/libxsmm_config.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\nfrom string import Template\nfrom datetime import date\nimport libxsmm_utilities\nimport fnmatch\nimport sys\n\n\nif __name__ == ""__main__"":\n    argc = len(sys.argv)\n    if 1 < argc:\n        # required argument(s)\n        filename = sys.argv[1]\n\n        # default configuration if no arguments are given\n        ilp64 = offload = precision = flags = threshold = 0\n        sync = jit = 1\n        alpha = beta = 1\n        cacheline = 64\n        prefetch = -1\n        wrap = 1\n        malloc = 0\n        mnklist = list()\n\n        # optional argument(s)\n        if 2 < argc:\n            ilp64 = int(sys.argv[2])\n        if 3 < argc:\n            offload = int(sys.argv[3])\n        if 4 < argc:\n            cacheline = libxsmm_utilities.sanitize_alignment(int(sys.argv[4]))\n        if 5 < argc:\n            precision = int(sys.argv[5])\n        if 6 < argc:\n            prefetch = int(sys.argv[6])\n        if 7 < argc:\n            threshold = int(sys.argv[7])\n        if 8 < argc:\n            sync = int(sys.argv[8])\n        if 9 < argc:\n            jit = int(sys.argv[9])\n        if 10 < argc:\n            flags = int(sys.argv[10])\n        if 11 < argc:\n            alpha = int(sys.argv[11])\n        if 12 < argc:\n            beta = int(sys.argv[12])\n        if 13 < argc:\n            wrap = int(sys.argv[13])\n        if 14 < argc:\n            malloc = int(sys.argv[14])\n        if 15 < argc:\n            mnklist = sorted(libxsmm_utilities.load_mnklist(sys.argv[15:], 0))\n\n        version, branch, realversion = libxsmm_utilities.version_branch()\n        major, minor, update, patch = libxsmm_utilities.version_numbers(\n            version\n        )\n\n        if 0 == threshold:\n            threshold = 64 * 64 * 64\n        maxmnk = libxsmm_utilities.max_mnk(mnklist, threshold)\n        maxdim = int(maxmnk ** (1.0 / 3.0) + 0.5)\n        avgdim = int(0.5 * maxdim + 0.5)\n\n        avgm = libxsmm_utilities.median(\n            list(map(lambda mnk: mnk[0], mnklist)), avgdim, False\n        )\n        avgn = libxsmm_utilities.median(\n            list(map(lambda mnk: mnk[1], mnklist)), avgdim, False\n        )\n        avgk = libxsmm_utilities.median(\n            list(map(lambda mnk: mnk[2], mnklist)), avgdim, False\n        )\n\n        maxm = libxsmm_utilities.max_mnk(mnklist, avgdim, 0)\n        maxn = libxsmm_utilities.max_mnk(mnklist, avgdim, 1)\n        maxk = libxsmm_utilities.max_mnk(mnklist, avgdim, 2)\n\n        substitute = {\n            ""VERSION"": realversion,\n            ""BRANCH"": branch,\n            ""MAJOR"": major,\n            ""MINOR"": minor,\n            ""UPDATE"": update,\n            ""PATCH"": patch,\n            ""DATE"": date.today().strftime(""%Y%m%d""),\n            ""CACHELINE"": cacheline,\n            ""PREFETCH"": [-1, prefetch][0 <= prefetch],\n            ""MAX_MNK"": maxmnk,\n            ""MAX_DIM"": maxdim,\n            ""AVG_DIM"": int((maxdim + 1) / 2),\n            ""MAX_M"": [maxdim, maxm][avgm < maxm],\n            ""MAX_N"": [maxdim, maxn][avgn < maxn],\n            ""MAX_K"": [maxdim, maxk][avgk < maxk],\n            ""FLAGS"": flags,\n            ""ILP64"": [0, 1][0 != ilp64],\n            ""ALPHA"": alpha,\n            ""BETA"": beta,\n            ""WRAP"": wrap,\n            ""MALLOC"": malloc,\n            ""SYNC"": [0, 1][0 != sync],\n            ""JIT"": [0, 1][0 != jit],\n            ""LIBXSMM_OFFLOAD_BUILD"": ["""", ""\\n#define LIBXSMM_OFFLOAD_BUILD""][\n                0 != offload\n            ],\n            ""MNK_PREPROCESSOR_LIST"": """",\n        }\n\n        template = Template(open(filename, ""r"").read())\n        if fnmatch.fnmatch(filename, ""*.h*""):\n            if mnklist:\n                first = mnklist[0]\n            for mnk in mnklist:\n                mnkstr = ""_"".join(map(str, mnk))\n                if mnk != first:\n                    substitute[""MNK_PREPROCESSOR_LIST""] += ""\\n""\n                if 2 != precision:\n                    substitute[""MNK_PREPROCESSOR_LIST""] += (\n                        ""#define LIBXSMM_SMM_"" + mnkstr\n                    )\n                if mnk != first or 0 == precision:\n                    substitute[""MNK_PREPROCESSOR_LIST""] += ""\\n""\n                if 1 != precision:\n                    substitute[""MNK_PREPROCESSOR_LIST""] += (\n                        ""#define LIBXSMM_DMM_"" + mnkstr\n                    )\n\n            print(template.substitute(substitute))\n        else:\n            substitute[""BLASINT_KIND""] = [""C_INT"", ""C_LONG_LONG""][0 != ilp64]\n            print(template.safe_substitute(substitute))\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(sys.argv[0] + "": wrong number of arguments!"")\n'"
scripts/libxsmm_dispatch.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\nimport libxsmm_utilities\nimport sys\nimport os\n\n\nif __name__ == ""__main__"":\n    argc = len(sys.argv)\n    if 1 < argc:\n        arg1_filename = [sys.argv[1], """"][""0"" == sys.argv[1]]\n        arg1_isfile = os.path.isfile(arg1_filename)\n        base = 1\n        if arg1_isfile:\n            print(""#if !defined(_WIN32)"")\n            print(""{ static const char *const build_state ="")\n            print(\'#   include ""../\' + os.path.basename(arg1_filename) + \'""\')\n            print(""  ;"")\n            print(""  internal_build_state = build_state;"")\n            print(""}"")\n            print(""#endif"")\n            base = 2\n        if (base + 2) < argc:\n            precision = int(sys.argv[base + 0])\n            threshold = int(sys.argv[base + 1])\n            mnklist = libxsmm_utilities.load_mnklist(sys.argv[base + 2:], 0)\n            print(\n                ""/* omit registering code if JIT is enabled""\n                "" and if an ISA extension is found""\n            )\n            print(\n                "" * which is beyond the static code""\n                "" path used to compile the library""\n            )\n            print("" */"")\n            print(""#if (0 != LIBXSMM_JIT) && !defined(__MIC__)"")\n            print(\n                ""if (LIBXSMM_X86_SSE3 > libxsmm_target_archid ""\n                ""/* JIT code gen. is not available */""\n            )\n            print(\n                ""   /* conditions allows to avoid JIT ""\n                ""(if static code is good enough) */""\n            )\n            print(\n                ""   || (LIBXSMM_STATIC_TARGET_ARCH == libxsmm_target_archid)""\n            )\n            print(\n                ""   || (LIBXSMM_X86_AVX512_CORE <= libxsmm_target_archid &&""\n            )\n            print(\n                ""       libxsmm_cpuid_vlen32(LIBXSMM_STATIC_TARGET_ARCH) ==""\n            )\n            print(\n                ""       libxsmm_cpuid_vlen32(libxsmm_target_archid)))""\n            )\n            print(""#endif"")\n            print(""{"")\n            print(""  libxsmm_xmmfunction func;"")\n            for mnk in mnklist:\n                mstr, nstr, kstr, mnkstr = (\n                    str(mnk[0]),\n                    str(mnk[1]),\n                    str(mnk[2]),\n                    ""_"".join(map(str, mnk)),\n                )\n                mnksig = mstr + "", "" + nstr + "", "" + kstr\n                # prefer registering double-precision kernels\n                # when approaching an exhausted registry\n                if 1 != precision:  # only double-precision\n                    print(\n                        ""  func.dmm = (libxsmm_dmmfunction)libxsmm_dmm_""\n                        + mnkstr\n                        + "";""\n                    )\n                    print(\n                        ""  internal_register_static_code(""\n                        + ""LIBXSMM_GEMM_PRECISION_F64, ""\n                        + mnksig\n                        + "", func, new_registry);""\n                    )\n            for mnk in mnklist:\n                mstr, nstr, kstr, mnkstr = (\n                    str(mnk[0]),\n                    str(mnk[1]),\n                    str(mnk[2]),\n                    ""_"".join(map(str, mnk)),\n                )\n                mnksig = mstr + "", "" + nstr + "", "" + kstr\n                # prefer registering double-precision kernels\n                # when approaching an exhausted registry\n                if 2 != precision:  # only single-precision\n                    print(\n                        ""  func.smm = (libxsmm_smmfunction)libxsmm_smm_""\n                        + mnkstr\n                        + "";""\n                    )\n                    print(\n                        ""  internal_register_static_code(""\n                        + ""LIBXSMM_GEMM_PRECISION_F32, ""\n                        + mnksig\n                        + "", func, new_registry);""\n                    )\n            print(""}"")\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(sys.argv[0] + "": wrong number of arguments!"")\n'"
scripts/libxsmm_interface.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\nfrom string import Template\nimport libxsmm_utilities\nimport fnmatch\nimport sys\n\n\nif __name__ == ""__main__"":\n    argc = len(sys.argv)\n    if 1 < argc:\n        # required argument(s)\n        filename = sys.argv[1]\n\n        # default configuration if no arguments are given\n        precision = 0  # all\n        prefetch = -1  # auto\n        mnklist = list()\n\n        # optional argument(s)\n        if 2 < argc:\n            precision = int(sys.argv[2])\n        if 3 < argc:\n            prefetch = int(sys.argv[3])\n        if 4 < argc:\n            mnklist = sorted(libxsmm_utilities.load_mnklist(sys.argv[4:], 0))\n\n        template = Template(open(filename, ""r"").read())\n        if fnmatch.fnmatch(filename, ""*.h*""):\n            optional = ["", ..."", """"][0 <= prefetch]\n            substitute = {""MNK_INTERFACE_LIST"": """"}\n            for mnk in mnklist:\n                mnkstr = ""_"".join(map(str, mnk))\n                if 2 != precision:\n                    pfsig = [\n                        optional + "");"",\n                        "",\\n  ""\n                        ""const float* pa, ""\n                        ""const float* pb, ""\n                        ""const float* pc);"",\n                    ][0 < prefetch]\n                    substitute[""MNK_INTERFACE_LIST""] += (\n                        ""\\nLIBXSMM_API void libxsmm_smm_""\n                        + mnkstr\n                        + ""(const float* a, const float* b, float* c""\n                        + pfsig\n                    )\n                if 1 != precision:\n                    pfsig = [\n                        optional + "");"",\n                        "",\\n  ""\n                        ""const double* pa, ""\n                        ""const double* pb, ""\n                        ""const double* pc);"",\n                    ][0 < prefetch]\n                    substitute[""MNK_INTERFACE_LIST""] += (\n                        ""\\nLIBXSMM_API void libxsmm_dmm_""\n                        + mnkstr\n                        + ""(const double* a, const double* b, double* c""\n                        + pfsig\n                    )\n                if 0 == precision:\n                    substitute[""MNK_INTERFACE_LIST""] += ""\\n""\n            if mnklist and 0 != precision:\n                substitute[""MNK_INTERFACE_LIST""] += ""\\n""\n            print(template.substitute(substitute))\n        else:  # Fortran interface\n            # Fortran\'s OPTIONAL allows to always generate an interface\n            # with prefetch signature (more flexible usage)\n            if 0 == prefetch:\n                prefetch = -1\n            version, branch, realversion = libxsmm_utilities.version_branch(16)\n            major, minor, update, patch = libxsmm_utilities.version_numbers(\n                version\n            )\n            substitute = {\n                ""VERSION"": realversion,\n                ""BRANCH"": branch,\n                ""MAJOR"": major,\n                ""MINOR"": minor,\n                ""UPDATE"": update,\n                ""PATCH"": patch,\n                ""MNK_INTERFACE_LIST"": """",\n            }\n            if mnklist:\n                substitute[""MNK_INTERFACE_LIST""] += ""\\n""\n                for mnk in mnklist:\n                    mnkstr = ""_"".join(map(str, mnk))\n                    if 0 == precision:\n                        substitute[""MNK_INTERFACE_LIST""] += (\n                            ""\\n        ""\n                            ""!DIR$ ATTRIBUTES OFFLOAD:MIC :: libxsmm_smm_""\n                            + mnkstr\n                            + "", libxsmm_dmm_""\n                            + mnkstr\n                        )\n                    elif 2 != precision:\n                        substitute[""MNK_INTERFACE_LIST""] += (\n                            ""\\n        ""\n                            ""!DIR$ ATTRIBUTES OFFLOAD:MIC :: libxsmm_smm_""\n                            + mnkstr\n                        )\n                    elif 1 != precision:\n                        substitute[""MNK_INTERFACE_LIST""] += (\n                            ""\\n        ""\n                            ""!DIR$ ATTRIBUTES OFFLOAD:MIC :: libxsmm_dmm_""\n                            + mnkstr\n                        )\n                substitute[""MNK_INTERFACE_LIST""] += ""\\n        INTERFACE""\n                optional = ["", OPTIONAL"", """"][0 < prefetch]\n                bindc = ["""", ""BIND(C)""][0 < prefetch]\n                for mnk in mnklist:\n                    mnkstr = ""_"".join(map(str, mnk))\n                    if 2 != precision:\n                        pfsiga = [\n                            "") BIND(C)\\n"",\n                            "",""\n                            + ""&"".rjust(26 - len(mnkstr))\n                            + ""\\n     &    pa, pb, pc) ""\n                            + bindc\n                            + ""\\n"",\n                        ][0 != prefetch]\n                        pfsigb = [\n                            """",\n                            ""            REAL(C_FLOAT), ""\n                            ""INTENT(IN)"" + optional + "" :: ""\n                            ""pa(*), ""\n                            ""pb(*), ""\n                            ""pc(*)\\n"",\n                        ][0 != prefetch]\n                        substitute[""MNK_INTERFACE_LIST""] += (\n                            ""\\n          ""\n                            ""PURE SUBROUTINE libxsmm_smm_""\n                            + mnkstr\n                            + ""(a, b, c""\n                            + pfsiga\n                            + ""            IMPORT :: C_FLOAT\\n""\n                            ""            REAL(C_FLOAT), ""\n                            ""INTENT(IN) :: a(*), b(*)\\n""\n                            ""            REAL(C_FLOAT), ""\n                            ""INTENT(INOUT) :: c(*)\\n""\n                            + pfsigb\n                            + ""          END SUBROUTINE""\n                        )\n                    if 1 != precision:\n                        pfsiga = [\n                            "") BIND(C)\\n"",\n                            "",""\n                            + ""&"".rjust(26 - len(mnkstr))\n                            + ""\\n     &    pa, pb, pc) ""\n                            + bindc\n                            + ""\\n"",\n                        ][0 != prefetch]\n                        pfsigb = [\n                            """",\n                            ""            REAL(C_DOUBLE), ""\n                            ""INTENT(IN)"" + optional + "" :: ""\n                            ""pa(*), ""\n                            ""pb(*), ""\n                            ""pc(*)\\n"",\n                        ][0 != prefetch]\n                        substitute[""MNK_INTERFACE_LIST""] += (\n                            ""\\n          ""\n                            ""PURE SUBROUTINE libxsmm_dmm_""\n                            + mnkstr\n                            + ""(a, b, c""\n                            + pfsiga\n                            + ""            IMPORT :: C_DOUBLE\\n""\n                            ""            REAL(C_DOUBLE), ""\n                            ""INTENT(IN) :: a(*), b(*)\\n""\n                            ""            REAL(C_DOUBLE), ""\n                            ""INTENT(INOUT) :: c(*)\\n""\n                            + pfsigb\n                            + ""          END SUBROUTINE""\n                        )\n                substitute[""MNK_INTERFACE_LIST""] += ""\\n        END INTERFACE""\n            print(template.safe_substitute(substitute))\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(sys.argv[0] + "": wrong number of arguments!"")\n'"
scripts/libxsmm_specialized.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\nimport sys\n\n\nif __name__ == ""__main__"":\n    argc = len(sys.argv)\n    if 6 == argc:\n        precision = int(sys.argv[1])\n        m, n, k = int(sys.argv[2]), int(sys.argv[3]), int(sys.argv[4])\n        prefetch = int(sys.argv[5])\n\n        mnkstr = str(m) + ""_"" + str(n) + ""_"" + str(k)\n        optional = ["""", "", ...""][0 > prefetch]\n        signature = [""a, b, c"", ""a, b, c, pa, pb, pc""][0 < prefetch]\n        if 2 != precision:\n            pfsig = [\n                optional + "")"",\n                ""\\n""\n                "", const float* pa""\n                "", const float* pb""\n                "", const float* pc)"",\n            ][0 < prefetch]\n            print\n            print\n            print(\n                ""LIBXSMM_API void libxsmm_smm_""\n                + mnkstr\n                + ""(const float* a, const float* b, float* c""\n                + pfsig\n            )\n            print(""{"")\n            print(\n                ""#if defined(__AVX512F__) && ""\n                ""defined(LIBXSMM_GENTARGET_skx_sp) && \\\\""\n            )\n            print(""  !(defined(__AVX512PF__) && defined(__AVX512ER__))"")\n            print(""  libxsmm_smm_"" + mnkstr + ""_skx("" + signature + "");"")\n            print(\n                ""#elif defined(__AVX512F__) && ""\n                ""defined(LIBXSMM_GENTARGET_knl_sp)""\n            )\n            print(""  libxsmm_smm_"" + mnkstr + ""_knl("" + signature + "");"")\n            print(\n                ""#elif defined(__AVX2__) && ""\n                ""defined(LIBXSMM_GENTARGET_hsw_sp)""\n            )\n            print(""  libxsmm_smm_"" + mnkstr + ""_hsw("" + signature + "");"")\n            print(\n                ""#elif defined(__AVX__) && ""\n                ""defined(LIBXSMM_GENTARGET_snb_sp)""\n            )\n            print(""  libxsmm_smm_"" + mnkstr + ""_snb("" + signature + "");"")\n            print(\n                ""#elif defined(__SSE3__) && ""\n                ""defined(LIBXSMM_GENTARGET_wsm_sp)""\n            )\n            print(""  libxsmm_smm_"" + mnkstr + ""_wsm("" + signature + "");"")\n            print(""#else"")\n            print(\n                ""  const char transa = (0 == (LIBXSMM_GEMM_FLAG_TRANS_A & ""\n                ""LIBXSMM_FLAGS) ? \'N\' : \'T\');""\n            )\n            print(\n                ""  const char transb = (0 == (LIBXSMM_GEMM_FLAG_TRANS_B & ""\n                ""LIBXSMM_FLAGS) ? \'N\' : \'T\');""\n            )\n            print(""  const float alpha = LIBXSMM_ALPHA, beta = LIBXSMM_BETA;"")\n            print(\n                ""  const libxsmm_blasint ""\n                ""m = "" + str(m) + "", ""\n                ""n = "" + str(n) + "", ""\n                ""k = "" + str(k) + "";""\n            )\n            if 0 < prefetch:\n                print(\n                    ""  LIBXSMM_UNUSED(pa);""\n                    "" LIBXSMM_UNUSED(pb);""\n                    "" LIBXSMM_UNUSED(pc);""\n                )\n            print(\n                ""  LIBXSMM_INLINE_XGEMM(float, float, &transa, &transb,""\n                "" &m, &n, &k, &alpha, a, &m, b, &k, &beta, c, &m);""\n            )\n            print(""#endif"")\n            print(""}"")\n            print\n            print\n            print(\n                ""LIBXSMM_API void LIBXSMM_FSYMBOL(libxsmm_smm_""\n                + mnkstr\n                + "")(const float* a, const float* b, float* c""\n                + pfsig\n                + "";""\n            )\n            print(\n                ""LIBXSMM_API void LIBXSMM_FSYMBOL(libxsmm_smm_""\n                + mnkstr\n                + "")(const float* a, const float* b, float* c""\n                + pfsig\n            )\n            print(""{"")\n            print(""  libxsmm_smm_"" + mnkstr + ""("" + signature + "");"")\n            print(""}"")\n        if 1 != precision:\n            pfsig = [\n                optional + "")"",\n                ""\\n""\n                "", const double* pa""\n                "", const double* pb""\n                "", const double* pc)"",\n            ][0 < prefetch]\n            print\n            print\n            print(\n                ""LIBXSMM_API void libxsmm_dmm_""\n                + mnkstr\n                + ""(const double* a, const double* b, double* c""\n                + pfsig\n            )\n            print(""{"")\n            print(\n                ""#if defined(__AVX512F__) && ""\n                ""defined(LIBXSMM_GENTARGET_skx_dp) && \\\\""\n            )\n            print(""  !(defined(__AVX512PF__) && defined(__AVX512ER__))"")\n            print(""  libxsmm_dmm_"" + mnkstr + ""_skx("" + signature + "");"")\n            print(\n                ""#elif defined(__AVX512F__) && ""\n                ""defined(LIBXSMM_GENTARGET_knl_dp)""\n            )\n            print(""  libxsmm_dmm_"" + mnkstr + ""_knl("" + signature + "");"")\n            print(\n                ""#elif defined(__AVX2__) && ""\n                ""defined(LIBXSMM_GENTARGET_hsw_dp)""\n            )\n            print(""  libxsmm_dmm_"" + mnkstr + ""_hsw("" + signature + "");"")\n            print(\n                ""#elif defined(__AVX__) && ""\n                ""defined(LIBXSMM_GENTARGET_snb_dp)""\n            )\n            print(""  libxsmm_dmm_"" + mnkstr + ""_snb("" + signature + "");"")\n            print(\n                ""#elif defined(__SSE3__) && ""\n                ""defined(LIBXSMM_GENTARGET_wsm_dp)""\n            )\n            print(""  libxsmm_dmm_"" + mnkstr + ""_wsm("" + signature + "");"")\n            print(""#else"")\n            print(\n                ""  const char transa = (0 == (LIBXSMM_GEMM_FLAG_TRANS_A & ""\n                ""LIBXSMM_FLAGS) ? \'N\' : \'T\');""\n            )\n            print(\n                ""  const char transb = (0 == (LIBXSMM_GEMM_FLAG_TRANS_B & ""\n                ""LIBXSMM_FLAGS) ? \'N\' : \'T\');""\n            )\n            print(""  const double alpha = LIBXSMM_ALPHA, beta = LIBXSMM_BETA;"")\n            print(\n                ""  const libxsmm_blasint ""\n                ""m = "" + str(m) + "", ""\n                ""n = "" + str(n) + "", ""\n                ""k = "" + str(k) + "";""\n            )\n            if 0 < prefetch:\n                print(\n                    ""  LIBXSMM_UNUSED(pa);""\n                    "" LIBXSMM_UNUSED(pb);""\n                    "" LIBXSMM_UNUSED(pc);""\n                )\n            print(\n                ""  LIBXSMM_INLINE_XGEMM(double, double, &transa, &transb,""\n                "" &m, &n, &k, &alpha, a, &m, b, &k, &beta, c, &m);""\n            )\n            print(""#endif"")\n            print(""}"")\n            print\n            print\n            print(\n                ""LIBXSMM_API void LIBXSMM_FSYMBOL(libxsmm_dmm_""\n                + mnkstr\n                + "")(const double* a, const double* b, double* c""\n                + pfsig\n                + "";""\n            )\n            print(\n                ""LIBXSMM_API void LIBXSMM_FSYMBOL(libxsmm_dmm_""\n                + mnkstr\n                + "")(const double* a, const double* b, double* c""\n                + pfsig\n            )\n            print(""{"")\n            print(""  libxsmm_dmm_"" + mnkstr + ""("" + signature + "");"")\n            print(""}"")\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(sys.argv[0] + "": wrong number of arguments!"")\n'"
scripts/libxsmm_utilities.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\nimport itertools\nimport operator\nimport inspect\nimport sys\nimport os\n\ntry:\n    from functools import reduce\nexcept ImportError:\n    pass\n\n\ndef upper_list(lists, level):\n    nlist = len(lists)\n    upper = [level, level + nlist][1 > level] - 1\n    above = lists[upper]\n    if above:\n        return above\n    elif -nlist <= level:\n        return upper_list(lists, level - 1)\n    else:\n        return []\n\n\n# https://docs.python.org/3/library/itertools.html#itertools.product\ndef itertools_product(*args):\n    # product(\'ABCD\', \'xy\') --> Ax Ay Bx By Cx Cy Dx Dy\n    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111\n    pools = [tuple(pool) for pool in args]\n    result = [[]]\n    for pool in pools:\n        result = [x + [y] for x in result for y in pool]\n    for prod in result:\n        yield tuple(prod)\n\n\ndef load_mnklist(argv, threshold, inputformat=0, resultset=None):\n    if resultset is None:\n        resultset = set()\n    if 0 == inputformat:  # indexes format\n        resultset = set(map(lambda mnk: tuple(map(int, mnk.split(""_""))), argv))\n    elif -1 == inputformat:  # new input format\n        groups = map(\n            lambda group: [int(i) for i in group.split()],\n            "" "".join(argv[0:]).split("",""),\n        )\n        resultset = set(\n            itertools.chain(\n                *[list(itertools_product(*(i, i, i))) for i in groups]\n            )\n        )\n    elif -2 == inputformat:  # legacy format\n        mlist = list(\n            map(\n                int,\n                map(\n                    lambda s: str(s).replace("","", "" "").strip(),\n                    argv[2:2 + int(argv[0])],\n                ),\n            )\n        )\n        nlist = list(\n            map(\n                int,\n                map(\n                    lambda s: str(s).replace("","", "" "").strip(),\n                    argv[2 + int(argv[0]):2 + int(argv[0]) + int(argv[1])],\n                ),\n            )\n        )\n        klist = list(\n            map(\n                int,\n                map(\n                    lambda s: str(s).replace("","", "" "").strip(),\n                    argv[2 + int(argv[0]) + int(argv[1]):],\n                ),\n            )\n        )\n        mnk = [mlist, nlist, klist]\n        top = [\n            [mlist, upper_list(mnk, 0)][0 == len(mlist)],\n            [nlist, upper_list(mnk, 1)][0 == len(nlist)],\n            [klist, upper_list(mnk, 2)][0 == len(klist)],\n        ]\n        for m in top[0]:\n            for n in top[1]:\n                if not nlist:\n                    n = m\n                for k in top[2]:\n                    if not klist:\n                        k = n\n                    if not mlist:\n                        m = k\n                    resultset.add((m, n, k))\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(""load_mnklist: unexpected input format!"")\n    if 0 != threshold:  # threshold requested\n        return set(\n            filter(\n                lambda mnk: (0 < mnk[0])\n                and (0 < mnk[1])\n                and (0 < mnk[2])\n                and (threshold >= (mnk[0] * mnk[1] * mnk[2])),\n                resultset,\n            )\n        )\n    else:\n        return set(\n            filter(\n                lambda mnk: (0 < mnk[0]) and (0 < mnk[1]) and (0 < mnk[2]),\n                resultset,\n            )\n        )\n\n\ndef max_mnk(mnklist, init=0, index=None):\n    if index is not None and 0 <= index and index < 3:\n        mapped = map(lambda mnk: mnk[index], mnklist)\n    else:\n        mapped = map(lambda mnk: mnk[0] * mnk[1] * mnk[2], mnklist)\n    return reduce(max, mapped, init)\n\n\ndef median(list_of_numbers, fallback=None, average=True):\n    size = len(list_of_numbers)\n    if 0 < size:\n        # TODO: use nth element\n        list_of_numbers.sort()\n        size2 = int(size / 2)\n        if average and 0 == (size - size2 * 2):\n            medval = int(\n                0.5 * (list_of_numbers[size2 - 1] + list_of_numbers[size2])\n                + 0.5\n            )\n        else:\n            medval = list_of_numbers[size2]\n        if fallback is not None:\n            result = min(medval, fallback)\n        else:\n            result = medval\n    elif fallback is not None:\n        result = fallback\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(""median: empty list!"")\n    return result\n\n\ndef is_pot(num):\n    return 0 <= num or 0 == (num & (num - 1))\n\n\ndef sanitize_alignment(alignment):\n    if 0 >= alignment:\n        alignment = [1, 64][0 != alignment]\n    elif not is_pot(alignment):\n        sys.tracebacklimit = 0\n        raise ValueError(\n            ""sanitize_alignment: alignment must be a Power of Two (POT)!""\n        )\n    return alignment\n\n\ndef align_value(n, typesize, alignment):\n    if 0 < typesize and 0 < alignment:\n        return (\n            ((n * typesize + alignment - 1) / alignment) * alignment\n        ) / typesize\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(""align_value: invalid input!"")\n\n\ndef version_branch_from_file(version_filepath):\n    version_file = open(version_filepath, ""r"")\n    version, branch, sep = ""1.0"", """", ""-""\n    try:\n        version_list, n = version_file.read().replace(""\\n"", """").split(sep), 0\n        for word in version_list:\n            if not reduce(\n                operator.and_,\n                (subword.isdigit() for subword in word.split(""."")),\n                True,\n            ):\n                branch += [sep + word, word][0 == n]\n                n += 1\n            else:\n                break\n        version = sep.join(version_list[n:])\n    finally:\n        version_file.close()\n    return (version, branch)\n\n\ndef version_branch(max_strlen=-1):\n    version_filename = ""version.txt""\n    filepath_default = os.path.realpath(\n        os.path.join(\n            os.path.dirname(inspect.getfile(inspect.currentframe())),\n            "".."",\n            version_filename,\n        )\n    )\n    filepath_local = os.path.realpath(version_filename)  # local version file\n    realversion, branch = version_branch_from_file(filepath_default)\n    version = realversion\n    out_of_tree = filepath_default != filepath_local\n    if out_of_tree and os.path.isfile(filepath_local):\n        local, ignored = version_branch_from_file(filepath_local)\n        if version_numbers(realversion) < version_numbers(local):\n            version = local\n    if 0 < max_strlen:\n        start = int(max_strlen / 3)\n        cut = max(\n            branch.rfind(""-"", start, max_strlen),\n            branch.rfind(""_"", start, max_strlen),\n            branch.rfind(""."", start, max_strlen),\n        )\n        if start < cut:\n            branch = branch[0:cut]\n        else:\n            branch = branch[0:max_strlen]\n    return (version, branch, realversion)\n\n\ndef version_numbers(version):\n    version_list = version.split(""-"")\n    minor = update = patch = 0\n    major = 1\n    n = len(version_list)\n    if 1 < n:\n        patch_list = version_list[n - 1]\n        if 1 == len(patch_list.split(""."")):\n            version_list = version_list[n - 2].split(""."")\n            patch = int(patch_list)\n        else:\n            version_list = patch_list.split(""."")\n    else:\n        version_list = version.split(""."")\n    n = len(version_list)\n    if 0 < n:\n        major = int(version_list[0])\n    if 1 < n:\n        minor = int(version_list[1])\n    if 2 < n:\n        update = int(version_list[2])\n    return major, minor, update, patch\n\n\nif __name__ == ""__main__"":\n    argc = len(sys.argv)\n    if 1 < argc:\n        arg1 = int(sys.argv[1])\n    else:\n        arg1 = 0\n    if -1 == arg1 and 5 < argc:\n        # threshold = int(sys.argv[2])\n        mnk_size = int(sys.argv[3])\n        dims = load_mnklist(sys.argv[4:4 + mnk_size], 0, -1)\n        dims = load_mnklist(sys.argv[4 + mnk_size:], 0, -2, dims)\n        print("" "".join(map(lambda mnk: ""_"".join(map(str, mnk)), sorted(dims))))\n    elif 0 <= arg1:\n        if 0 == arg1 and 3 == argc:\n            major, minor, update, patch = version_numbers(sys.argv[2])\n            print(major)  # soname version\n        else:\n            version, branch, realversion = version_branch()\n            major, minor, update, patch = version_numbers(version)\n            if 1 == arg1:\n                print(major)\n            elif 2 == arg1:\n                print(minor)\n            elif 3 == arg1:\n                print(update)\n            elif 4 == arg1:\n                print(patch)\n            elif """" != branch:\n                print(branch + ""-"" + realversion)\n            else:\n                print(realversion)\n    else:\n        sys.tracebacklimit = 0\n        raise ValueError(\n            sys.argv[0]\n            + "": wrong (""\n            + str(argc - 1)\n            + \') number of arguments (""\'\n            + "" "".join(sys.argv[1:])\n            + \'"") given!\'\n        )\n'"
samples/matcopy/matcopy_opentuner.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\n#\n# This script is based on OpenTuner\'s tutorial:\n# ""Optimizing Block Matrix Multiplication"".\n#\nimport opentuner\nfrom opentuner import ConfigurationManipulator\nfrom opentuner import IntegerParameter\nfrom opentuner import MeasurementInterface\nfrom opentuner import Result\nimport random\nimport json\nimport time\nimport sys\nimport re\n\n\nclass MatcopyTune(MeasurementInterface):\n    def manipulator(self):\n        """"""\n        Define the search space by creating a\n        ConfigurationManipulator\n        """"""\n        self.mintilesize = 2\n        self.granularity = 1\n        assert(0 < self.granularity)\n        minsize = max(self.mintilesize / self.granularity, 1)\n        maxsize = minsize + self.granularity\n        m_max = max(min(self.args.maxm, self.args.end), maxsize)\n        n_max = max(min(self.args.maxn, self.args.end), maxsize)\n        m_max = (m_max + self.granularity - 1) / self.granularity\n        n_max = (n_max + self.granularity - 1) / self.granularity\n        m_param = IntegerParameter(""M"", minsize, m_max)\n        n_param = IntegerParameter(""N"", minsize, n_max)\n        manipulator = ConfigurationManipulator()\n        manipulator.add_parameter(m_param)\n        manipulator.add_parameter(n_param)\n        return manipulator\n\n    def seed_configurations(self):\n        m_seed = [self.args.n, self.args.m][0 != self.args.m]\n        n_seed = [self.args.m, self.args.n][0 != self.args.n]\n        if 0 == m_seed or 0 == n_seed:\n            return []\n        else:\n            return [{""M"": max(m_seed, self.mintilesize),\n                     ""N"": max(n_seed, self.mintilesize)}]\n\n    def objective(self):\n        return opentuner.search.objective.MaximizeAccuracyMinimizeSize()\n\n    def run(self, desired_result, input, limit):\n        """"""\n        Compile and run a given configuration then\n        return performance\n        """"""\n        cfg = desired_result.configuration.data\n        nruns = max(self.args.nruns, 1)\n        begin = max(self.args.begin, self.mintilesize)\n        end = max(self.args.end, self.mintilesize)\n        m = random.randint(begin, end)\n        n = random.randint(begin, end)\n        if (self.args.tight):\n            ldi = ldo = m\n        else:\n            ldi = max(random.randint(begin, end), m)\n            ldo = max(random.randint(begin, end), m)\n        kind = [""COPY"", ""ZERO""][self.args.zero]\n        run_cmd = (\n            ""CHECK=0 "" +  # no checks and only LIBXSMM measurement\n            [""ZERO=0"", ""ZERO=1""][self.args.zero] +\n            "" LIBXSMM_M"" + kind + ""_M="" + str(self.granularity * cfg[""M""]) +\n            "" LIBXSMM_M"" + kind + ""_N="" + str(self.granularity * cfg[""N""]) +\n            "" ./matcopyf ""\n            + str(m) + "" "" + str(n) + "" "" + str(ldi) + "" "" + str(ldo) + "" ""\n            + str(nruns)) + "" "" + str(self.args.nmb)\n        run_result = self.call_program(run_cmd)\n        if (0 == run_result[""returncode""]):\n            match = re.search(\n                ""LIBXSMM \\\\("" + kind.lower() +\n                ""\\\\):\\\\s+([0-9]+(\\\\.[0-9]*)*)"",\n                str(run_result[""stdout""]))\n            assert(match is not None)\n            bandwidth = float(match.group(1))\n            assert(0 < bandwidth)\n            kernelsize = (self.granularity**2) * cfg[""M""] * cfg[""N""]\n            return Result(time=1/bandwidth,\n                          accuracy=bandwidth,\n                          size=kernelsize)\n        else:\n            sys.tracebacklimit = 0\n            raise RuntimeError(""Execution failed for \\"""" + run_cmd + ""\\""!"")\n\n    def save_final_config(self, configuration):\n        """"""\n        called at the end of tuning\n        """"""\n        filename = (\n            ""matcopy-""\n            + str(max(self.args.begin, 1)) + ""_""\n            + str(max(self.args.end,   1))\n            + [""_"", ""_zero_""][self.args.zero]\n            + [""_"", ""_tight_""][self.args.tight]\n            + str(max(self.args.nruns, 1)) + ""_""\n            + str(self.args.nmb) +\n            time.strftime(""-%Y%m%d-%H%M%S"") + "".json"")\n        print(""Optimal block size written to "" + filename +\n              "": "", configuration.data)\n        # self.manipulator().save_to_file(configuration.data, filename)\n        with open(filename, \'w\') as fd:\n            json.dump(configuration.data, fd)\n\n\n# https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse\ndef str2bool(v):\n    argparser = opentuner.default_argparser()\n    if isinstance(v, bool):\n        return v\n    if v.lower() in (\'yes\', \'true\', \'t\', \'y\', \'1\'):\n        return True\n    elif v.lower() in (\'no\', \'false\', \'f\', \'n\', \'0\'):\n        return False\n    else:\n        raise argparser.ArgumentTypeError(\'Boolean value expected.\')\n\n\nif __name__ == ""__main__"":\n    argparser = opentuner.default_argparser()\n    argparser.add_argument(\n        ""begin"", type=int,\n        help=""Begin of the range (min. M and N)"")\n    argparser.add_argument(\n        ""end"", type=int,\n        help=""End of the range (exclusive)"")\n    argparser.add_argument(\n        ""m"", type=int, default=0, nargs=\'?\',\n        help=""Initial tile size (M)"")\n    argparser.add_argument(\n        ""n"", type=int, default=0, nargs=\'?\',\n        help=""Initial tile size (N)"")\n    argparser.add_argument(\n        ""nruns"", type=int, default=1, nargs=\'?\',\n        help=""Number of experiments per epoch"")\n    argparser.add_argument(\n        ""nmb"", type=int, default=512, nargs=\'?\',\n        help=""Problem size (MB)"")\n    argparser.add_argument(\n        ""maxm"", type=int, default=160, nargs=\'?\',\n        help=""Max. tile size (M)"")\n    argparser.add_argument(\n        ""maxn"", type=int, default=160, nargs=\'?\',\n        help=""Max. tile size (N)"")\n    argparser.add_argument(\n        ""zero"", type=str2bool, nargs=\'?\',\n        const=True, default=False,\n        help=""Zeroing instead of copy"")\n    argparser.add_argument(\n        ""tight"", type=str2bool, nargs=\'?\',\n        const=True, default=True,\n        help=""Use tight leading dimension"")\n    MatcopyTune.main(argparser.parse_args())\n'"
samples/transpose/transpose_opentuner.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\n#\n# This script is based on OpenTuner\'s tutorial:\n# ""Optimizing Block Matrix Multiplication"".\n#\nimport opentuner\nfrom opentuner import ConfigurationManipulator\nfrom opentuner import IntegerParameter\nfrom opentuner import MeasurementInterface\nfrom opentuner import Result\nimport json\nimport time\nimport sys\nimport re\n\n\nclass TransposeTune(MeasurementInterface):\n    def manipulator(self):\n        """"""\n        Define the search space by creating a\n        ConfigurationManipulator\n        """"""\n        self.mintilesize = 2\n        self.granularity = 1\n        assert(0 < self.granularity)\n        minsize = max(self.mintilesize / self.granularity, 1)\n        maxsize = minsize + self.granularity\n        m_max = max(min(self.args.maxm, self.args.end), maxsize)\n        n_max = max(min(self.args.maxn, self.args.end), maxsize)\n        m_max = (m_max + self.granularity - 1) / self.granularity\n        n_max = (n_max + self.granularity - 1) / self.granularity\n        m_param = IntegerParameter(""M"", minsize, m_max)\n        n_param = IntegerParameter(""N"", minsize, n_max)\n        manipulator = ConfigurationManipulator()\n        manipulator.add_parameter(m_param)\n        manipulator.add_parameter(n_param)\n        return manipulator\n\n    def seed_configurations(self):\n        m_seed = [self.args.n, self.args.m][0 != self.args.m]\n        n_seed = [self.args.m, self.args.n][0 != self.args.n]\n        if 0 == m_seed or 0 == n_seed:\n            return []\n        else:\n            return [{""M"": max(m_seed, self.mintilesize),\n                     ""N"": max(n_seed, self.mintilesize)}]\n\n    def objective(self):\n        return opentuner.search.objective.MaximizeAccuracyMinimizeSize()\n\n    def run(self, desired_result, input, limit):\n        """"""\n        Compile and run a given configuration then\n        return performance\n        """"""\n        cfg = desired_result.configuration.data\n        nruns = max(self.args.nruns, 1)\n        begin = max(self.args.begin, self.mintilesize)\n        end = max(self.args.end, self.mintilesize)\n        run_cmd = (\n            ""CHECK=-1""  # repeatable runs\n            "" LIBXSMM_TCOPY_M="" + str(self.granularity * cfg[""M""]) +\n            "" LIBXSMM_TCOPY_N="" + str(self.granularity * cfg[""N""]) +\n            "" ./transpose.sh o"" + "" "" + str(end) + "" "" + str(end) +\n            "" "" + str(end) + "" "" + str(end) + "" "" + str(nruns) +\n            "" -"" + str(begin))\n        run_result = self.call_program(run_cmd)\n        if (0 == run_result[""returncode""]):\n            match = re.search(\n                ""\\\\s*duration:\\\\s+([0-9]+(\\\\.[0-9]*)*)"",\n                str(run_result[""stdout""]))\n            assert(match is not None)\n            mseconds = float(match.group(1)) / nruns\n            assert(0 < mseconds)\n            frequency = 1000.0 / mseconds\n            kernelsize = (self.granularity**2) * cfg[""M""] * cfg[""N""]\n            return Result(time=mseconds, accuracy=frequency, size=kernelsize)\n        else:\n            sys.tracebacklimit = 0\n            raise RuntimeError(""Execution failed for \\"""" + run_cmd + ""\\""!"")\n\n    def save_final_config(self, configuration):\n        """"""\n        called at the end of tuning\n        """"""\n        filename = (\n            ""transpose-"" + str(max(self.args.begin, 1)) +\n            ""_"" + str(max(self.args.end,   1)) +\n            ""_"" + str(max(self.args.nruns, 1)) +\n            time.strftime(""-%Y%m%d-%H%M%S"") + "".json"")\n        print(""Optimal block size written to "" + filename +\n              "": "", configuration.data)\n        # self.manipulator().save_to_file(configuration.data, filename)\n        with open(filename, \'w\') as fd:\n            json.dump(configuration.data, fd)\n\n\nif __name__ == ""__main__"":\n    argparser = opentuner.default_argparser()\n    argparser.add_argument(\n        ""begin"", type=int,\n        help=""Begin of the range (min. M and N)"")\n    argparser.add_argument(\n        ""end"", type=int,\n        help=""End of the range (max. M and N)"")\n    argparser.add_argument(\n        ""nruns"", type=int, default=100, nargs=\'?\',\n        help=""Number of experiments per epoch"")\n    argparser.add_argument(\n        ""m"", type=int, default=0, nargs=\'?\',\n        help=""Initial tile size (M)"")\n    argparser.add_argument(\n        ""n"", type=int, default=0, nargs=\'?\',\n        help=""Initial tile size (N)"")\n    argparser.add_argument(\n        ""maxm"", type=int, default=160, nargs=\'?\',\n        help=""Max. tile size (M)"")\n    argparser.add_argument(\n        ""maxn"", type=int, default=160, nargs=\'?\',\n        help=""Max. tile size (N)"")\n    TransposeTune.main(argparser.parse_args())\n'"
samples/xgemm/xgemm_opentuner.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Hans Pabst (Intel Corp.)\n###############################################################################\n#\n# This script is based on OpenTuner\'s tutorial:\n# ""Optimizing Block Matrix Multiplication"".\n#\nimport opentuner\nfrom opentuner import ConfigurationManipulator\nfrom opentuner import IntegerParameter\nfrom opentuner import MeasurementInterface\nfrom opentuner import Result\nimport inspect\nimport json\nimport time\nimport math\nimport sys\nimport os\nimport re\n\ntry:\n    here = os.path.dirname(inspect.getfile(inspect.currentframe()))\n    scripts = os.path.realpath(os.path.join(here, "".."", "".."", ""scripts""))\n    if scripts not in sys.path:\n        sys.path.insert(0, scripts)\n    import libxsmm_utilities\nexcept ImportError:\n    pass\n\n\nclass XgemmTuner(MeasurementInterface):\n    def manipulator(self):\n        """"""\n        Define the search space by creating a\n        ConfigurationManipulator\n        """"""\n        self.dimset = libxsmm_utilities.load_mnklist(self.args.mnk, 0, -1)\n        self.granularity = 1\n        assert(0 < self.granularity)\n        m_max = (64 + self.granularity - 1) / self.granularity\n        n_max = (256 + self.granularity - 1) / self.granularity\n        k_max = (256 + self.granularity - 1) / self.granularity\n        m_param = IntegerParameter(""M"", self.granularity, m_max)\n        n_param = IntegerParameter(""N"", self.granularity, n_max)\n        k_param = IntegerParameter(""K"", self.granularity, k_max)\n        manipulator = ConfigurationManipulator()\n        manipulator.add_parameter(m_param)\n        manipulator.add_parameter(n_param)\n        manipulator.add_parameter(k_param)\n        return manipulator\n\n    def seed_configurations(self):\n        m_seed = self.args.m\n        n_seed = [self.args.n, m_seed][0 == self.args.n]\n        k_seed = [self.args.k, n_seed][0 == self.args.k]\n        if 0 == m_seed or 0 == n_seed or 0 == k_seed:\n            return []\n        else:\n            return [{""M"": (m_seed + self.granularity - 1) / self.granularity,\n                     ""N"": (n_seed + self.granularity - 1) / self.granularity,\n                     ""K"": (k_seed + self.granularity - 1) / self.granularity}]\n\n    def objective(self):\n        return opentuner.search.objective.MaximizeAccuracyMinimizeSize()\n\n    def run(self, desired_result, input, limit):\n        """"""\n        Compile and run a given configuration then\n        return performance\n        """"""\n        cfg = desired_result.configuration.data\n        run_cmd = (\n            ""CHECK=0""\n            "" LIBXSMM_TGEMM_M="" + str(self.granularity * cfg[""M""]) +\n            "" LIBXSMM_TGEMM_N="" + str(self.granularity * cfg[""N""]) +\n            "" LIBXSMM_TGEMM_K="" + str(self.granularity * cfg[""K""]) +\n            "" ./xgemm.sh"")\n        geoperf = 0  # geometric mean\n        compensation = 0  # see Kahan\n        for dims in self.dimset:\n            run_result = self.call_program(\n                run_cmd + "" "" + "" "".join(map(str, dims)))\n            assert(run_result[""returncode""] == 0)\n            match = re.search(\n                ""\\\\s*LIBXSMM:\\\\s+([0-9]+(\\\\.[0-9]*)*)"",\n                str(run_result[""stdout""]))\n            assert(match is not None)\n            gflops = float(match.group(1))\n            assert(0 < gflops)\n            kha = math.log(gflops) - compensation\n            khb = geoperf + kha\n            compensation = (khb - geoperf) - kha\n            geoperf = khb\n        geoperf = math.exp(geoperf / len(self.dimset))\n        geotime = 1000000.0 / geoperf\n        mnk = (self.granularity**3) * cfg[""M""] * cfg[""N""] * cfg[""K""]\n        return Result(time=geotime, accuracy=geoperf, size=mnk)\n\n    def save_final_config(self, configuration):\n        """"""called at the end of tuning""""""\n        matrices = (  # collects requested matrix shapes into string\n            ""-"".join(map(str, map(lambda mnk: ""x"".join(\n                     map(str, mnk)), self.dimset))))\n        filename = ""xgemm-"" + matrices + time.strftime(\n                   ""-%Y%m%d-%H%M%S"") + "".json""\n        print(""Optimal block size written to "" + filename +\n              "": "", configuration.data)\n        # self.manipulator().save_to_file(configuration.data, filename)\n        with open(filename, \'w\') as fd:\n            json.dump(configuration.data, fd)\n\n\nif __name__ == ""__main__"":\n    argparser = opentuner.default_argparser()\n    argparser.add_argument(\n        ""mnk"", nargs=""*"", default=[""1024,1280,1536,1792""],\n        help=""Set of MNK parameters to be tuned"")\n    argparser.add_argument(\n        ""-m"", ""--initial-m"", type=int, default=0, nargs=\'?\',\n        dest=""m"", help=""Initial tile size (M)"")\n    argparser.add_argument(\n        ""-n"", ""--initial-n"", type=int, default=0, nargs=\'?\',\n        dest=""n"", help=""Initial tile size (N)"")\n    argparser.add_argument(\n        ""-k"", ""--initial-k"", type=int, default=0, nargs=\'?\',\n        dest=""k"", help=""Initial tile size (K)"")\n    XgemmTuner.main(argparser.parse_args())\n'"
samples/deeplearning/tf_lstm_ops/setup.py,0,"b'import setuptools\nwith open(""README.md"", ""r"") as fh:\n    long_description = fh.read()\nsetuptools.setup(\n     name=\'xsmm_lstm\',\n     version=\'0.1\',\n     author=""Dhiraj Kalamkar"",\n     author_email=""dhiraj.d.kalamkar@intel.com"",\n     description=""Tensorflow wrapper for libxsmm LSTM Cell"",\n     long_description=long_description,\n     #long_description_content_type=""text/markdown"",\n     url=""https://github.com/ddkalamk/libxsmm"",\n     #packages=setuptools.find_packages(),\n     packages=[\'xsmm_lstm\'],\n     #package_dir={\'\': \'.\'},\n     package_data={\'xsmm_lstm\': [\'libxsmm_lstm.so\']},\n     include_package_data=True,\n     classifiers=[\n         ""License :: OSI Approved :: MIT License"",\n         ""Operating System :: Linux"",\n     ],\n )\n\n'"
samples/deeplearning/tvm_cnnlayer/mb1_tuned_latest.py,0,"b'#!/usr/bin/env python3\n###############################################################################\n# Copyright (c) Intel Corporation - All rights reserved.                      #\n# This file is part of the LIBXSMM library.                                   #\n#                                                                             #\n# For information on the license, see the LICENSE file.                       #\n# Further information: https://github.com/hfp/libxsmm/                        #\n# SPDX-License-Identifier: BSD-3-Clause                                       #\n###############################################################################\n# Anand Venkat (Intel Corp.)\n###############################################################################\n\nimport logging\nimport sys\nimport numpy as np\nimport tvm\nimport topi\nimport time\nfrom topi.util import get_const_tuple\nimport math\nimport topi.testing\nimport xlwt\nimport argparse\n\nimport os\nimport ctypes\nfrom tvm import autotvm\nfrom tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""-d"", nargs=1, type=str, default=[""resnet3""])\nargs = parser.parse_args()\nlayer = args.d[0]\n\n#Resnet-50  layers (excluding first layer)\n_resnet_layers ={\n    \'resnet2\':[1,256,64,56,56,1,1,0],\n    \'resnet3\':[1,64,64,56,56,1,1,0],\n    \'resnet4\':[1,64,64,56,56,3,1,1],\n    \'resnet5\':[1,64,256,56,56,1,1,0],\n    \'resnet6\':[1,512,256,56,56,1,2,0],\n    \'resnet7\':[1,128,256,56,56,1,2,0],\n    \'resnet8\':[1,128,128,28,28,3,1,1],\n    \'resnet9\':[1,512,128,28,28,1,1,0],\n    \'resnet10\':[1,128,512,28,28,1,1,0],\n    \'resnet11\':[1,1024,512,28,28,1,2,0],\n    \'resnet12\':[1,256,512,28,28,1,2,0],\n    \'resnet13\':[1,256,256,14,14,3,1,1],\n    \'resnet14\':[1,1024,256,14,14,1,1,0],\n    \'resnet15\':[1,256,1024,14,14,1,1,0],\n    \'resnet16\':[1,2048,1024,14,14,1,2,0],\n    \'resnet17\':[1,512,1024,14,14,1,2,0],\n    \'resnet18\':[1,512,512,7,7,3,1,1],\n    \'resnet19\':[1,2048,512,7,7,1,1,0],\n    \'resnet20\':[1,512,2048,7,7,1,1,0]\n}\n\n\'\'\'\nConvert input from NCHW format to NCHW16C format where the innermost data dimension is vectorized for AVX-512\n\'\'\'\ndef convert_input(a_np, batch, in_channel,input_height,input_width,pad_height,pad_width,vlen,A):\n    to_return = np.zeros((batch, math.ceil(in_channel/vlen),input_height + 2*pad_height, input_width+ 2*pad_width,vlen),dtype = A.dtype)\n\n    for i in range(batch):\n      for j in range(math.ceil(in_channel/vlen)):\n        for k in range(input_height + 2*pad_height):\n          for l in range(input_width + 2*pad_width):\n              for m in range(vlen):\n                if k < pad_height or k >= input_height + pad_height or l < pad_width or l >= input_width+ pad_width or j*vlen + m >= in_channel:\n                      to_return[i,j,k,l,m] = float(0)\n                else:\n                      to_return[i,j,k,l,m] = a_np[i,j*vlen + m,k-pad_height,l-pad_width]\n\n    return to_return\n\'\'\'\nConvert output from NCHW format to NCHW16C format where the innermost data dimension is vectorized for AVX-512\n\'\'\'\n\ndef convert_output(a_np, batch, out_channel,output_height,output_width,vlen):\n    to_return = np.zeros((batch, out_channel,output_height, output_width), dtype = float)\n    for i in range(batch):\n      for j in range(math.ceil(out_channel/vlen)):\n        for k in range(output_height):\n          for l in range(output_width):\n              for m in range(vlen):\n                  to_return[i,j*vlen + m,k,l] = a_np[i,j,k,l,m]\n\n\n\n    return to_return\n\n\'\'\'\nConvert weights from KCRS format to KCRS16C16K format where the innermost data dimension is vectorized for AVX-512\n\'\'\'\n\ndef convert_weight(w_np, in_channel, out_channel, kernel_height, kernel_width, vlen,W):\n    to_return = np.zeros((math.ceil(out_channel/vlen), math.ceil(in_channel/vlen),kernel_height, kernel_width,vlen,vlen), dtype = W.dtype)\n\n    for i in range(math.ceil(out_channel/vlen)):\n      for j in range(math.ceil(in_channel/vlen)):\n        for k in range(kernel_height):\n          for l in range(kernel_width):\n            for m in range(vlen):\n              for n in range(vlen):\n                if i*vlen + n >= out_channel or j*vlen + m >= in_channel:\n                   to_return[i,j,k,l,m,n] =float(0)\n                else:\n                   to_return[i,j,k,l,m,n] = w_np[i*vlen + n,j*vlen+ m,k,l]\n\n\n\n    return to_return\n\n\n# Get the reference output tensor for correctness check\ndef get_ref_data(batch,out_channel,in_channel,input_height,input_width,kernel_height,kernel_width,stride_height,padding):\n            a_np = np.random.uniform(size=(batch,in_channel,input_height,input_width)).astype(float)\n            w_np = np.random.uniform(size=(out_channel,in_channel,kernel_height,kernel_width)).astype(float)\n            if batch == 1:\n                b_np = topi.testing.conv2d_nchw_python(a_np, w_np, stride_height, padding)\n            #b_np =  topi.nn.conv2d_NCHWc(a_np, w_np,out_channel,kernel_height,stride_height,\n            #     padding, layout=""NCHWc"", out_layout=""NCHWc"", out_dtype=\'float32\')\n\n            if batch == 1:\n                  return a_np, w_np, b_np\n            else:\n                  return a_np, w_np\n\n\n#special case for small height and width (e.g.. h = w = 7), where (h*w) becomes dimension of the brgemm (M)\ndef intrin_libxsmm_hxw(ofmblock,ofw,ifmblock, stride_width,ifw,rco, ifh,r,s, ifh_stride, ifw_stride,\\\n                       ofh, stride_height, out_channel,output_height, output_width, in_channel):\n\n    last_input_width_index = (ofw-1)*stride_width + s-1\n\n    last_input_height_index = (ofh-1)*stride_height + r-1\n    ry = tvm.reduce_axis((0, r), name=\'ry\')\n    rx = tvm.reduce_axis((0, s), name=\'rx\')\n\n\n    A = tvm.placeholder((rco,r,s,ifmblock, ofmblock), name=\'w\')\n    B = tvm.placeholder((rco,last_input_height_index + 1,last_input_width_index + 1,ifmblock), name=\'b\')\n    k = tvm.reduce_axis((0, ifmblock), name=\'k\')\n    k_outer = tvm.reduce_axis((0, rco), name=\'k_outer\')\n    C = tvm.compute(\n          (ofh,ofw,ofmblock),\n           lambda z,m,n: tvm.sum(A[k_outer,ry,rx,k,n] * B[k_outer,ry + z*stride_height,rx + m*stride_width,k], axis=[k_outer,ry,rx,k]),\n           name=\'out\')\n\n    s1 = tvm.create_schedule(C.op)\n\n    ifw1,ofw1,ofmblock1  = s1[C].op.axis\n\n    rco_outer,ry,rx,rci = s1[C].op.reduce_axis\n    s1[C].reorder(ifw1,rco_outer,ry,rx,ofw1,ofmblock1,rci)\n\n    xx_ptr = tvm.decl_buffer(A.shape, A.dtype,\n                        name=""W"",offset_factor = 1,\n                        data_alignment=64)\n\n\n    yy_ptr = tvm.decl_buffer(B.shape, B.dtype,\n                        name=""X"",offset_factor=1,\\\n                        strides=[tvm.var(""s3""),tvm.var(""s2""), ifmblock, 1],#offset_factor=16\n                        data_alignment=64)\n\n    zz_ptr = tvm.decl_buffer(C.shape, C.dtype,\n                        name=""OUT"",offset_factor=1,#offset_factor=1,\n                        strides=[output_width*ofmblock, ofmblock, 1],\n                        data_alignment=64)\n\n    def intrin_func(ins, outs):\n         # tvm call extern is used to interface to libxsmm bacth reduce kernel gemm implementation\n         # rco*r*s is the number of batches\n         init_and_compute = tvm.call_extern (""int32"",""batch_reduce_kernel_init_update"", ins[0].access_ptr(""r""),ins[1].access_ptr(""r""),outs[0].access_ptr(""w""),\\\n                                                rco*r*s,ofmblock,ifmblock,r,s,ifh_stride,ifw_stride, ofw*ofh, stride_width)\n         reset = tvm.call_extern (""int32"",""batch_reduce_kernel_init"", outs[0].access_ptr(""w""),ofmblock, ofw*ofh)\n         body = tvm.call_extern (""int32"",""batch_reduce_kernel_update"", ins[0].access_ptr(""r""),ins[1].access_ptr(""r""),outs[0].access_ptr(""w""), rco*r*s,ofmblock,\\\n                                        ifmblock,ofw*ofh, stride_width,r,s, ifh_stride,ifw_stride)\n         if math.ceil(in_channel/ifmblock) == rco:\n            return init_and_compute, None, init_and_compute\n         else:\n            return init_and_compute,reset,body\n\n    with tvm.build_config(data_alignment=64):\n        return tvm.decl_tensor_intrin(C.op, intrin_func,   name=""GEMM"",\n                                  binds= {A: xx_ptr,\n                                         B: yy_ptr,\n                                         C: zz_ptr})\n\n# regular case of batch reduce gemm with ofw corresponding to batch reduce brgemm dimension(M)\ndef intrin_libxsmm_tuned(ofmblock,ofw,ifmblock, stride_width,ifw,rco, ifh,r,s, ifh_stride, ifw_stride, in_channel):\n    last_input_width_index = (ofw-1)*stride_width + s-1\n    A = tvm.placeholder((rco,r,s,ifmblock, ofmblock), name=\'w\')\n    B = tvm.placeholder((rco,r,last_input_width_index + 1,ifmblock), name=\'b\')\n    k = tvm.reduce_axis((0, ifmblock), name=\'k\')\n    k_outer = tvm.reduce_axis((0, rco), name=\'k_outer\')\n    ry = tvm.reduce_axis((0, r), name=\'ry\')\n    rx = tvm.reduce_axis((0, s), name=\'rx\')\n    C = tvm.compute(\n          (ofw,ofmblock),\n           lambda m,n: tvm.sum(A[k_outer,ry,rx,k,n] * B[k_outer,ry, rx + m*stride_width,k], axis=[k_outer,ry,rx,k]),\n           name=\'out\')\n    s1 = tvm.create_schedule(C.op)\n    w,ofm  = s1[C].op.axis\n    kco,ky,kx,kci = s1[C].op.reduce_axis\n    s1[C].reorder(kco,ky,kx,w,ofm,kci)\n    xx_ptr = tvm.decl_buffer(A.shape, A.dtype,\n                        name=""W"",offset_factor=1,\n                        data_alignment=64)\n\n    yy_ptr = tvm.decl_buffer(B.shape, B.dtype,\n                        name=""some"", offset_factor=1,strides=[tvm.var(""s3""), tvm.var(""s2""), ifmblock, 1],\n                        data_alignment=64)\n\n    zz_ptr = tvm.decl_buffer(C.shape, C.dtype,\n                        name=""OUT"",offset_factor=1,\n                        data_alignment=64)\n\n    def intrin_func(ins, outs):\n         # tvm call extern is used to interface to libxsmm batch reduce kernel gemm implementation\n         # rco*r*s is the number of batches\n         init_and_compute = tvm.call_extern (""int32"",""batch_reduce_kernel_init_update"", ins[0].access_ptr(""r""),ins[1].access_ptr(""r""),outs[0].access_ptr(""w""),\\\n                                                rco*r*s,ofmblock,ifmblock,r,s,ifh_stride,ifw_stride, ofw, stride_width)\n         reset = tvm.call_extern (""int32"",""batch_reduce_kernel_init"", outs[0].access_ptr(""w""),ofmblock, ofw)\n         body = tvm.call_extern (""int32"",""batch_reduce_kernel_update"", ins[0].access_ptr(""r""),ins[1].access_ptr(""r""),outs[0].access_ptr(""w""), rco*r*s,ofmblock,\\\n                                        ifmblock,ofw, stride_width,r,s, ifh_stride,ifw_stride)\n         if math.ceil(in_channel/ifmblock) == rco:\n            return init_and_compute, None, init_and_compute\n         else:\n            return init_and_compute,reset,body\n\n    with tvm.build_config(data_alignment=64):\n        return tvm.decl_tensor_intrin(C.op, intrin_func,   name=""GEMM"",\n                                         binds={A: xx_ptr,\n                                                B: yy_ptr,\n                                                C: zz_ptr})\n\n#AutoTVM template for libxmm brgemm based tensorize implementation\n@autotvm.template\ndef conv_auto_tuned(ofmblock,ofw, ifmblock, stride_width,input_width,\\\n                    in_channel,input_height, filter_height, filter_width,ofh, stride_height, batch, out_channel):\n\n  A1 = tvm.placeholder((batch,math.ceil(in_channel/ifmblock),input_height, input_width, ifmblock), name=\'input\')\n  W1 = tvm.placeholder((math.ceil(out_channel/ofmblock), math.ceil(in_channel/ifmblock), filter_height, filter_width, ifmblock,ofmblock), name=\'weight\')\n\n  rco1 = tvm.reduce_axis((0, math.ceil(in_channel/ifmblock)), name=\'rco1\')\n  ry1 = tvm.reduce_axis((0, filter_height), name=\'ry1\')\n  rx1 = tvm.reduce_axis((0, filter_width), name=\'rx1\')\n  rci1 = tvm.reduce_axis((0, ifmblock), name=\'rci1\')\n  cfg = autotvm.get_config()\n\n  cfg.define_knob(""pack"", [0,1])\n  pack = False\n  w_tile =  []\n\n  factor_found = False\n\n\n  for i in range(6, min(ofw+1,29)):\n      if ofw % i == 0:\n          w_tile.append((i, ofw//i) )\n          factor_found = True\n\n  if factor_found == False:\n      w_tile.append((ofw,1))\n\n  #tile factors for output width\n  cfg.define_knob(""tile_w"", w_tile)\n\n  # pack data when stride > 1 and pack flag set so that data for brgemm is continuous\n  if filter_height == 1 and filter_width == 1 and stride_width >  1 and stride_height > 1 and cfg[\'pack\'].val == 1 :\n      A2 =  tvm.compute((batch, math.ceil(in_channel/ifmblock),ofh,ofw,ifmblock),\n          lambda n,c,h,w,vlen1: A1[n, c,h*stride_height,w*stride_width,vlen1])\n      B1 = tvm.compute((batch, math.ceil(out_channel/ofmblock),ofh, ofw,ofmblock),\n          lambda nn,ff,yy, xx, vlen1: tvm.sum(\n               W1[ff,rco1,ry1,rx1,rci1,vlen1] * A2[nn, rco1, ry1 + yy, rx1 + xx,rci1],\n        axis=[rco1,ry1, rx1, rci1]),name=\'output\')\n      pack = True\n  else:\n     # Compute the convolution\n      B1 = tvm.compute((batch, math.ceil(out_channel/ofmblock),ofh, ofw,ofmblock),\n          lambda nn,ff,yy, xx, vlen1: tvm.sum(\n               W1[ff,rco1,ry1,rx1,rci1,vlen1] * A1[nn, rco1, ry1 + stride_height*yy, rx1 + stride_width*xx,rci1],\n              axis=[rco1,ry1, rx1, rci1]), name=\'output\')\n\n  s = tvm.create_schedule(B1.op)\n  n,ko,h,w,ki  = s[B1].op.axis\n  rco,ry,rx, rci = s[B1].op.reduce_axis\n  cfg.define_split(""tile_h"", h, num_outputs=3)#output height\n  cfg.define_split(""tile_c"", rco, num_outputs=2) #input channel dimension\n  cfg.define_split(""tile_k"",ko, num_outputs=2)   #output channel dimension\n  w_factor_inner, _ =  cfg[""tile_w""].val\n  wo, wi = s[B1].split(w, w_factor_inner)        #tiling\n  rco_o,rco_i =           cfg[""tile_c""].apply(s, B1, rco)\n  ko_o, ko_i =      cfg[""tile_k""].apply(s, B1, ko)\n  ho,hm, hi =  cfg[""tile_h""].apply(s, B1, h)\n\n  s[B1].reorder(n,ko_o,ho,ko_i,rco_o,hm,wo,hi,rco_i,ry,rx,wi,ki,rci)\n  cfg.define_reorder(""reorder_outer"", [ko_i,rco_o,hm,wo], policy=""all"")\n  cfg.add_flop(np.prod(get_const_tuple(B1.shape))*in_channel*filter_height*filter_width*2)\n  cfg[""reorder_outer""].apply(s, B1,[ko_i,rco_o,hm,wo])\n  if (filter_height == 1 and filter_width == 1 and stride_width == 1 and stride_height == 1) or pack:\n      if cfg[""tile_h""].size[1] > 1 and w_factor_inner == ofw:#cfg[""tile_w""].size[2] == ofw:\n          libxsmm_tensorize = intrin_libxsmm_hxw(ofmblock,w_factor_inner,ifmblock, 1, w_factor_inner,\n                                              cfg[""tile_c""].size[1],cfg[""tile_h""].size[2],\\\n                                               filter_height, filter_width,ofh,ofw,cfg[""tile_h""].size[2],1, out_channel, ofh,ofw, in_channel)\n          s[B1].tensorize(hi, libxsmm_tensorize)\n      else:\n          libxsmm_tensorize = intrin_libxsmm_tuned(ofmblock,w_factor_inner,ifmblock, 1, w_factor_inner,\n                                              cfg[""tile_c""].size[1], cfg[""tile_h""].size[2],\\\n                                               filter_height, filter_width,ofh, ofw, in_channel)\n          s[B1].tensorize(rco_i, libxsmm_tensorize)\n\n  else:\n\n      libxsmm_tensorize = intrin_libxsmm_tuned(ofmblock,w_factor_inner,ifmblock, stride_width, w_factor_inner,\\\n                                              cfg[""tile_c""].size[1],  cfg[""tile_h""].size[2],\\\n                                              filter_height, filter_width,input_height,input_width, in_channel)\n      s[B1].tensorize(rco_i, libxsmm_tensorize)\n\n  par = s[B1].fuse(n,ko_o,ho)\n  s[B1].parallel(par)\n  if pack:\n     n1,c1,h1,w1,v1 = s[A2].op.axis\n     par2 = s[A2].fuse(n1,c1,h1)\n     s[A2].parallel(par)\n     s[A2].vectorize(v1)\n\n  s = s.normalize()\n\n  return s, [W1, A1, B1]\n\ndef driver():\n\n\n        book = xlwt.Workbook(encoding=""utf-8"")\n        sheet1 = book.add_sheet(""Sheet 1"")\n        row1=0\n        sheet1.write(0,0,""Layer"")\n        sheet1.write(0,1,""AutoTVM_FLOPS"")\n        row1 = row1 + 1\n\n\n\n        batch = _resnet_layers[layer][0]\n        in_channel = _resnet_layers[layer][2]\n        out_channel = _resnet_layers[layer][1]\n        input_height = _resnet_layers[layer][3]\n        input_width = _resnet_layers[layer][4]\n        kernel_height = _resnet_layers[layer][5]\n        kernel_width = _resnet_layers[layer][5]\n        pad_height = _resnet_layers[layer][7]\n        pad_width = _resnet_layers[layer][7]\n        stride_height = _resnet_layers[layer][6]\n        stride_width = _resnet_layers[layer][6]\n        vlen = 64\n        assert(pad_height == pad_width)\n        assert(stride_height == stride_width)\n        assert(kernel_height == kernel_width)\n\n        output_width = ((input_width + 2 * pad_width - kernel_width) // stride_width) + 1\n        output_height = ((input_height + 2 * pad_height - kernel_height) // stride_height) + 1\n        assert(output_height == output_width)\n        assert(input_height == input_width)\n\n\n        ctx = tvm.context(\'llvm\', 0)\n        sheet1.write(row1,0,layer)\n\n\n\n        if not ctx.exist:\n            print(""Skip because %s is not enabled"" % device)\n            return\n\n\n        task = autotvm.task.create(conv_auto_tuned, args=(vlen,output_width, vlen, stride_width,input_width + 2*pad_width, in_channel,\\\n               input_height + 2*pad_height, kernel_height, kernel_width,output_height, stride_height, batch, out_channel),\\\n                       target=\'llvm -mtriple=x86_64 -mcpu=skylake-avx512 -mattr=+skx,+fma,+fma4,+avx512ifma,+avx512f,+avx512cd,+avx512bw,+avx512vl,+avx512dq\')\n\n        logging.getLogger(\'autotvm\').setLevel(logging.DEBUG)\n        logging.getLogger(\'autotvm\').addHandler(logging.StreamHandler(sys.stdout))\n\n        measure_option = autotvm.measure_option(builder=autotvm.LocalBuilder(), runner=autotvm.LocalRunner(number=1000, repeat=1,min_repeat_ms=1000))\n\n        tuner = autotvm.tuner.RandomTuner(task)\n        #Please limit n_trial to reduce tuning time\n        n_trial= len(task.config_space)\n        log_file = layer + "".log""\n\n        #comment out the following call to tuner to just run the best case from log file history\n        tuner.tune(n_trial=n_trial,\n           measure_option=measure_option,\n           callbacks=[\n                           autotvm.callback.progress_bar(n_trial, prefix=layer),\n\n                           autotvm.callback.log_to_file(log_file)])\n        with autotvm.apply_history_best( layer+\'.log\'):\n            with tvm.target.create(""llvm""):\n\n                  a_np, w_np, b_np  = get_ref_data(batch,out_channel,in_channel,input_height,input_width,kernel_height, kernel_width,stride_height,pad_height)\n                  s, arg_bufs = conv_auto_tuned(vlen,output_width, vlen, stride_width,input_width + 2*pad_width, in_channel,\\\n                                      input_height + 2*pad_height, kernel_height, kernel_width,output_height, stride_height, batch, out_channel)\n\n                  a_np2 = convert_input(a_np, batch, in_channel,input_height,input_width,pad_height,pad_width,vlen, arg_bufs[1])\n                  w_np2 = convert_weight(w_np, in_channel, out_channel, kernel_height, kernel_width,vlen,arg_bufs[0])\n                  ctx = tvm.context(\'llvm\', 0)\n                  b = tvm.nd.array(np.zeros((batch, math.ceil(out_channel/vlen),output_height, output_width,vlen), dtype=arg_bufs[2].dtype), ctx)\n                  a = tvm.nd.array(a_np2, ctx)\n                  w = tvm.nd.array(w_np2, ctx)\n\n                  func = tvm.build(s, arg_bufs,target=\\\n                          \'llvm -mtriple=x86_64 -mcpu=skylake-avx512 -mattr=+skx,+fma,+fma4,+avx512ifma,+avx512f,+avx512cd,+avx512bw,+avx512vl,+avx512dq\', name=""conv2d"")\n                  func(w,a,b)\n                  b_np_A = convert_output(b.asnumpy(), 1,out_channel, output_height, output_width,vlen)\n                  np.testing.assert_allclose(b_np_A, b_np, rtol=1e-5)\n                  evaluator1 = func.time_evaluator(func.entry_name, ctx, number=1000,repeat=1, min_repeat_ms=1)\n\n                  t1 = evaluator1(w,a, b).mean\n                  gflops_tvm1 = np.prod(get_const_tuple(arg_bufs[2].shape))*in_channel*kernel_height*kernel_width*2\n                  gflops_tvm1 = gflops_tvm1/1e9/t1\n\n                  print(""Time for conv(tuned) is : {0:.6f}"".format(t1))\n                  print(""GFLOPS  : {0:.3f} "".format( gflops_tvm1))\n\n\n                  sheet1.write(row1,1,gflops_tvm1)\n\n        row1 = row1 + 1\n        book.save( ""AutoTVM_tensorize_resnet"" + layer +"".xls"")\n\n\nif __name__ == ""__main__"":\n    driver()\n\n'"
samples/deeplearning/tf_lstm_ops/xsmm_lstm/__init__.py,13,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n#import abc\n\nfrom tensorflow.contrib.rnn.ops import gen_lstm_ops\nfrom tensorflow.contrib.util import loader\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.layers import base as base_layer\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.ops import rnn_cell_impl\nfrom tensorflow.python.platform import resource_loader\nfrom tensorflow.contrib.rnn import LSTMBlockWrapper\nfrom tensorflow.python.keras.utils import tf_utils\nimport tensorflow as tf\nimport os\n\nmodule_dir = os.path.dirname(__file__)\nlib_name = os.path.join(module_dir, \'libxsmm_lstm.so\')\n\nxsmm_lstm = tf.load_op_library(lib_name)\n\n@tf.RegisterGradient(""XsmmLSTMCell"")\ndef _LSTMBlockCellGrad(op, *grad):\n  """"""Gradient for XsmmLSTMCell.""""""\n  w_in_kcck = False\n  try:\n    w_in_kcck = op.get_attr(""w_in_kcck"")\n  except:\n    pass\n\n  if w_in_kcck:\n    (x, cs_prev, h_prev, w, wT, wci, wcf, wco, b) = op.inputs\n  else:\n    (x, cs_prev, h_prev, w, wci, wcf, wco, b) = op.inputs\n    wT = w\n  (i, cs, f, o, ci, co, _) = op.outputs\n  (_, cs_grad, _, _, _, _, h_grad) = grad\n\n  (cs_prev_grad, h_prev_grad, x_grad, w_grad, b_grad, wci_grad, wcf_grad,\n   wco_grad) = xsmm_lstm.xsmm_lstm_cell_grad(\n       x=x,\n       cs_prev=cs_prev,\n       h_prev=h_prev,\n       w=w,\n       w_t=wT,\n       wci=wci,\n       wcf=wcf,\n       wco=wco,\n       b=b,\n       i=i,\n       cs=cs,\n       f=f,\n       o=o,\n       ci=ci,\n       co=co,\n       cs_grad=cs_grad,\n       h_grad=h_grad,\n       use_peephole=op.get_attr(""use_peephole""),\n       w_in_kcck=w_in_kcck)\n\n  if w_in_kcck:\n    return (x_grad, cs_prev_grad, h_prev_grad, w_grad, None, wci_grad, wcf_grad,\n          wco_grad, b_grad)\n  else:\n    return (x_grad, cs_prev_grad, h_prev_grad, w_grad, wci_grad, wcf_grad,\n          wco_grad, b_grad)\n\n\n@ops.RegisterGradient(""XsmmFusedLSTM"")\ndef _XsmmFusedLSTMGrad(op, *grad):\n  """"""Gradient for XsmmFusedLSTM.""""""\n  seq_len_max, x, cs_prev, h_prev, w, wci, wcf, wco, b = op.inputs\n  i, cs, f, o, ci, co, h = op.outputs\n\n  cs_grad = grad[1]\n  h_grad = grad[6]\n\n  (x_grad, cs_prev_grad, h_prev_grad, w_grad, wci_grad, wcf_grad, wco_grad,\n   b_grad) = xsmm_lstm.xsmm_fused_lstm_grad(\n       seq_len_max,\n       x,\n       cs_prev,\n       h_prev,\n       w,\n       wci,\n       wcf,\n       wco,\n       b,\n       i,\n       cs,\n       f,\n       o,\n       ci,\n       co,\n       h,\n       cs_grad,\n       h_grad,\n       use_peephole=op.get_attr(""use_peephole""),\n       use_residue=op.get_attr(""use_residue""),\n       use_dropout=op.get_attr(""use_dropout""))\n\n  return [\n      None, x_grad, cs_prev_grad, h_prev_grad, w_grad, wci_grad, wcf_grad,\n      wco_grad, b_grad\n  ]\n\nclass XsmmFusedLSTM(LSTMBlockWrapper):\n  """"""XsmmFusedLSTM implementation of LSTM.\n  This is an extremely efficient LSTM implementation, that uses a single TF op\n  for the entire LSTM. It should be both faster and more memory-efficient than\n  LSTMBlockCell defined above.\n  The implementation is based on: http://arxiv.org/abs/1409.2329.\n  We add forget_bias (default: 1) to the biases of the forget gate in order to\n  reduce the scale of forgetting in the beginning of the training.\n  The variable naming is consistent with `rnn_cell_impl.LSTMCell`.\n  """"""\n\n  def __init__(self,\n               num_units,\n               forget_bias=1.0,\n               cell_clip=None,\n               use_peephole=False,\n               dropout=0.0,\n               residual_connection=False,\n               reuse=None,\n               dtype=None,\n               name=""lstm_fused_cell""):\n    """"""Initialize the LSTM cell.\n    Args:\n      num_units: int, The number of units in the LSTM cell.\n      forget_bias: float, The bias added to forget gates (see above).\n      cell_clip: clip the cell to this value. Default is no cell clipping.\n      use_peephole: Whether to use peephole connections or not.\n      residual_connection: Whether to add residue connections or not.\n      dropout: Whether to apply dropout or not.\n      reuse: (optional) boolean describing whether to reuse variables in an\n        existing scope.  If not `True`, and the existing scope already has the\n        given variables, an error is raised.\n      dtype: the dtype of variables of this layer.\n      name: String, the name of the layer. Layers with the same name will\n        share weights, but to avoid mistakes we require reuse=True in such\n        cases.  By default this is ""lstm_cell"", for variable-name compatibility\n        with `tf.nn.rnn_cell.LSTMCell`.\n    """"""\n    super(XsmmFusedLSTM, self).__init__(\n        _reuse=reuse, name=name, dtype=dtype)\n    self._num_units = num_units\n    self._forget_bias = forget_bias\n    self._cell_clip = cell_clip if cell_clip is not None else -1\n    self._use_peephole = use_peephole\n    self._residual_connection = residual_connection\n    self._dropout = dropout\n\n    # Inputs must be 3-dimensional.\n    self.input_spec = base_layer.InputSpec(ndim=3)\n\n  @property\n  def num_units(self):\n    """"""Number of units in this cell (output dimension).""""""\n    return self._num_units\n\n  def build(self, input_shape):\n    input_size = input_shape[2].value\n    self._kernel = self.add_variable(\n        ""kernel"", [input_size + self._num_units, self._num_units * 4])\n    self._bias = self.add_variable(\n        ""bias"", [self._num_units * 4],\n        initializer=init_ops.constant_initializer(0.0))\n    if self._use_peephole:\n      self._w_i_diag = self.add_variable(""w_i_diag"", [self._num_units])\n      self._w_f_diag = self.add_variable(""w_f_diag"", [self._num_units])\n      self._w_o_diag = self.add_variable(""w_o_diag"", [self._num_units])\n\n    self.built = True\n\n  def _call_cell(self,\n                 inputs,\n                 initial_cell_state=None,\n                 initial_output=None,\n                 dtype=None,\n                 sequence_length=None):\n    """"""Run this LSTM on inputs, starting from the given state.\n    Args:\n      inputs: `3-D` tensor with shape `[time_len, batch_size, input_size]`\n      initial_cell_state: initial value for cell state, shape `[batch_size,\n        self._num_units]`\n      initial_output: initial value of cell output, shape `[batch_size,\n        self._num_units]`\n      dtype: The data type for the initial state and expected output.\n      sequence_length: Specifies the length of each sequence in inputs. An\n        `int32` or `int64` vector (tensor) size `[batch_size]`, values in `[0,\n        time_len)` or None.\n    Returns:\n      A pair containing:\n      - Cell state (cs): A `3-D` tensor of shape `[time_len, batch_size,\n                         output_size]`\n      - Output (h): A `3-D` tensor of shape `[time_len, batch_size,\n                    output_size]`\n    """"""\n\n    inputs_shape = inputs.get_shape().with_rank(3)\n    time_len = inputs_shape[0].value\n    if time_len is None:\n      time_len = array_ops.shape(inputs)[0]\n\n    if self._use_peephole:\n      wci = self._w_i_diag\n      wco = self._w_o_diag\n      wcf = self._w_f_diag\n    else:\n      wci = wcf = wco = array_ops.zeros([self._num_units], dtype=dtype)\n\n    if sequence_length is None:\n      max_seq_len = math_ops.to_int64(time_len)\n    else:\n      max_seq_len = math_ops.to_int64(math_ops.reduce_max(sequence_length))\n\n    print(""  Xsmm LSTM Fused Cell: dropout = %.3f, Resudue = %s"" % (self._dropout, self._residual_connection))\n    orig_inputs = inputs\n    if self._dropout > 0.0:\n      inputs = tf.nn.dropout(inputs, 1 - self._dropout)\n\n    \'\'\'\n    _, cs, _, _, _, _, h = gen_lstm_ops.block_lstm(\n        seq_len_max=max_seq_len,\n        x=inputs,\n        cs_prev=initial_cell_state,\n        h_prev=initial_output,\n        w=self._kernel,\n        wci=wci,\n        wcf=wcf,\n        wco=wco,\n        b=self._bias,\n        forget_bias=self._forget_bias,\n        cell_clip=self._cell_clip,\n        use_peephole=self._use_peephole)\n        \'\'\'\n\n    _, cs, _, _, _, _, h = xsmm_lstm.xsmm_fused_lstm(\n        seq_len_max=max_seq_len,\n        x=inputs,\n        cs_prev=initial_cell_state,\n        h_prev=initial_output,\n        w=self._kernel,\n        wci=wci,\n        wcf=wcf,\n        wco=wco,\n        b=self._bias,\n        forget_bias=self._forget_bias,\n        cell_clip=self._cell_clip,\n        use_peephole=self._use_peephole,\n        use_residue=False,\n        use_dropout=False)\n\n    if self._residual_connection:\n      with tf.name_scope(""fused_residual_connection""):\n        h = h + orig_inputs\n\n    return cs, h\n\n\nclass XsmmLSTMCell(rnn_cell_impl.RNNCell):\n  """"""LIbxsmm LSTM Cell""""""\n  def __init__(self,\n               num_units,\n               forget_bias=1.0,\n               state_is_tuple=True,\n               activation=None,\n               reuse=None,\n               name=None,\n               dtype=None,\n               w_in_kcck=True,\n               **kwargs):\n    """"""Initialize the libxsmm LSTM cell.\n    Args:\n      num_units: int, The number of units in the LSTM cell.\n      forget_bias: float, The bias added to forget gates (see above).\n        Must set to `0.0` manually when restoring from CudnnLSTM-trained\n        checkpoints.\n      state_is_tuple: If True, accepted and returned states are 2-tuples of\n        the `c_state` and `m_state`.  If False, they are concatenated\n        along the column axis.  The latter behavior will soon be deprecated.\n      activation: Activation function of the inner states.  Default: `tanh`. It\n        could also be string that is within Keras activation function names.\n      reuse: (optional) Python boolean describing whether to reuse variables\n        in an existing scope.  If not `True`, and the existing scope already has\n        the given variables, an error is raised.\n      name: String, the name of the layer. Layers with the same name will\n        share weights, but to avoid mistakes we require reuse=True in such\n        cases.\n      dtype: Default dtype of the layer (default of `None` means use the type\n        of the first input). Required when `build` is called before `call`.\n      **kwargs: Dict, keyword named properties for common layer attributes, like\n        `trainable` etc when constructing the cell from configs of get_config().\n      When restoring from CudnnLSTM-trained checkpoints, must use\n      `CudnnCompatibleLSTMCell` instead.\n    """"""\n    super(XsmmLSTMCell, self).__init__(\n        _reuse=reuse, name=name, dtype=dtype, **kwargs)\n    if not state_is_tuple:\n      logging.warn(""%s: Using a concatenated state is slower and will soon be ""\n                   ""deprecated.  Use state_is_tuple=True."", self)\n    # Inputs must be 2-dimensional.\n    self.input_spec = base_layer.InputSpec(ndim=2)\n\n    self._num_units = num_units\n    self._forget_bias = forget_bias\n    self._state_is_tuple = state_is_tuple\n    self._w_in_kcck = w_in_kcck\n    if activation:\n      self._activation = activations.get(activation)\n    else:\n      self._activation = math_ops.tanh\n\n  @property\n  def state_size(self):\n    return (rnn_cell_impl.LSTMStateTuple(self._num_units, self._num_units)\n            if self._state_is_tuple else 2 * self._num_units)\n\n  @property\n  def output_size(self):\n    return self._num_units\n\n  @tf_utils.shape_type_conversion\n  def build(self, inputs_shape):\n    if inputs_shape[-1] is None:\n      raise ValueError(""Expected inputs.shape[-1] to be known, saw shape: %s""\n                       % str(inputs_shape))\n\n    input_depth = inputs_shape[-1]\n    h_depth = self._num_units\n    C = input_depth + h_depth\n    K = 4 * self._num_units\n    ctxt = tf.get_default_graph()._get_control_flow_context()\n    if ctxt: ctxt = ctxt.GetWhileContext()\n    self._kernel = self.add_variable(\n        ""kernel"",\n        shape=[input_depth + h_depth, 4 * self._num_units])\n    self._bias = self.add_variable(\n        ""bias"",\n        shape=[4 * self._num_units],\n        initializer=init_ops.zeros_initializer(dtype=self.dtype))\n\n    if self._w_in_kcck:\n      if ctxt: ctxt.Exit()\n      def block_transpose(inp, C, BC, K, BK):\n        inp_packed = tf.reshape(tf.transpose(tf.reshape(inp, [C//BC, BC, K//BK, BK]), perm=[2, 0, 1, 3]), [C, K])\n        inp_packed_trans = tf.reshape(tf.transpose(tf.reshape(inp, [C//BC, BC, 4, K//(BK*4), BK]), perm=[2, 0, 3, 4, 1]), [C, K])\n        return inp_packed, inp_packed_trans\n      with tf.variable_scope(""kernel_transpose"") as vs:\n       with tf.name_scope(""""), tf.name_scope(vs.name):\n        BC = 64 if input_depth % 64 == 0 else input_depth\n        BK = 64 if h_depth % 64 == 0 else h_depth\n        W, R = tf.split(self._kernel, [input_depth, h_depth], 0)\n        W, WT = block_transpose(W, input_depth, BC, K, BK)\n        R, RT = block_transpose(R, h_depth, BK, K, BK)\n        self._kernel = tf.concat([W, R], 0)\n        self._kernel_trans = tf.concat([WT, RT], 0)\n      if ctxt: ctxt.Enter()\n    else:\n      self._kernel_trans = self._kernel\n    self.built = True\n\n  def call(self, inputs, state):\n    """"""Long short-term memory cell (LSTM).\n    Args:\n      inputs: `2-D` tensor with shape `[batch_size, input_size]`.\n      state: An `LSTMStateTuple` of state tensors, each shaped\n        `[batch_size, num_units]`, if `state_is_tuple` has been set to\n        `True`.  Otherwise, a `Tensor` shaped\n        `[batch_size, 2 * num_units]`.\n    Returns:\n      A pair containing the new hidden state, and the new state (either a\n        `LSTMStateTuple` or a concatenated state, depending on\n        `state_is_tuple`).\n    """"""\n\n    if len(state) != 2:\n      raise ValueError(""Expecting state to be a tuple with length 2."")\n\n    if False: #self._use_peephole:\n      wci = self._w_i_diag\n      wcf = self._w_f_diag\n      wco = self._w_o_diag\n    else:\n      wci = wcf = wco = array_ops.zeros([self._num_units])\n\n    (cs_prev, h_prev) = state\n\n    (_, cs, _, _, _, _, h) = xsmm_lstm.xsmm_lstm_cell(\n        x=inputs,\n        cs_prev=cs_prev,\n        h_prev=h_prev,\n        w=self._kernel,\n        w_t=self._kernel_trans,\n        wci=wci,\n        wcf=wcf,\n        wco=wco,\n        b=self._bias,\n        forget_bias=self._forget_bias,\n        cell_clip=-1,\n        use_peephole=False,\n        w_in_kcck=self._w_in_kcck,\n        name=self._name)\n\n    new_state = rnn_cell_impl.LSTMStateTuple(cs, h)\n    return h, new_state\n\n  def get_config(self):\n    config = {\n        ""num_units"": self._num_units,\n        ""forget_bias"": self._forget_bias,\n        ""state_is_tuple"": self._state_is_tuple,\n        ""activation"": activations.serialize(self._activation),\n        ""reuse"": self._reuse,\n    }\n    base_config = super(XsmmLSTMCell, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))\n\n'"
samples/deeplearning/tf_lstm_ops/xsmm_lstm/test.py,16,"b'import tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport numpy as np\nimport xsmm_lstm\nimport sys\nfrom os import isatty\n\nGREEN=\'\'\nRED=\'\'\nBOLD=\'\'\nENDC=\'\'\nif isatty(sys.stdout.fileno()):\n  GREEN=\'\\033[92m\'\n  RED =\'\\033[91m\'\n  BOLD=\'\\033[1m\'\n  ENDC=\'\\033[0m\'\n\ndef isclose(buf, ref, xmm):\n  avg_ref = np.mean(ref)\n  avg_abs_ref_orig = np.mean(np.absolute(ref))\n  avg_abs_ref = avg_abs_ref_orig if avg_abs_ref_orig != 0 else 0.1\n  avg_xmm = np.mean(xmm)\n  avg_abs_xmm = np.mean(np.absolute(xmm))\n  if avg_abs_ref_orig == avg_abs_xmm == 0: return\n  size = ref.size\n  it = np.nditer([ref, xmm], flags=[\'multi_index\'])\n  count = 0\n  print_count = 0\n  max_print = 5\n  print_always = 1\n  for x, y in it:\n    rdiff = abs(x - y) / avg_abs_ref\n    diff = abs((x - y) / x) if x != 0 else rdiff\n    if (diff > 1e-5 and rdiff > 1e-5) or print_count < print_always:\n      if print_count < max_print: print(""  %-10s %-10s: ref: %10s  xmm: %10s  diff: %9e"" % (buf, it.multi_index, x, y, diff))\n      if diff > 1e-5: count += 1\n      print_count += 1\n  if count > 0:\n    print(""%s %sdoes NOT match%s, error count = %d (out of %d) AVG=%g ABSAVG=%g"" % (buf, RED+BOLD, ENDC, count, size, avg_ref, avg_abs_ref_orig))\n  else:\n    print(""%s %sDOES match%s, size = %d AVG=%g ABSAVG=%g"" % (buf, GREEN+BOLD, ENDC, size, avg_ref, avg_abs_ref_orig))\n\nN=64\nC=128\nK=192\nT=10\nforget_bias=1.0\ntf.set_random_seed(1)\n#x = tf.constant(-0.1, shape=[N,C], dtype = tf.float32)\n#x2 = tf.constant(0.1, shape=[N,C], dtype = tf.float32)\nx = tf.random_normal(shape=[N,C], dtype = tf.float32) #+ 0.5\nx2 = tf.random_normal(shape=[N,C], dtype = tf.float32) #+ 0.5\nlstm_cell_ref = rnn.LSTMBlockCell(K, forget_bias=forget_bias, name=\'test\')\n#lstm_cell_ref = rnn.BasicLSTMCell(K, forget_bias=forget_bias, name=\'test\')\n#lstm_cell = rnn.LSTMBlockCell(K, forget_bias=forget_bias, name=\'test\', reuse=True)\nlstm_cell = xsmm_lstm.XsmmLSTMCell(K, forget_bias=forget_bias, name=\'test\', reuse=True)\ninit_state = lstm_cell_ref.zero_state(N, dtype=tf.float32)\nx_fused = tf.convert_to_tensor([x] + [x2 for _ in range(T-1)])\nprint(""x_fused is: %s"" % x_fused)\noutputs_ref, states_ref = tf.nn.dynamic_rnn(lstm_cell_ref, x_fused, dtype=tf.float32, initial_state=init_state, time_major=True)\noutputs, states = tf.nn.dynamic_rnn(lstm_cell, x_fused, dtype=tf.float32, initial_state=init_state, time_major=True)\n\ninit = tf.global_variables_initializer()\nW = tf.global_variables()[0]\nB = tf.global_variables()[1]\n\ng_ref = tf.gradients(outputs_ref, [x_fused] + [W, B, init_state.c, init_state.h])\ng = tf.gradients(outputs, [x_fused] + [W, B, init_state.c, init_state.h])\ng_names = [""dx_fused""] + [""dW"", ""dB"", ""dcsp"", ""dhp""]\n#print(tf.get_default_graph().as_graph_def())\n\nwith tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=1)) as sess:\n    sess.run(init)\n    g_print, g_print_ref = sess.run([g,g_ref])\n\n    for t,t_ref, p, p_ref, name in zip(g, g_ref, g_print, g_print_ref, g_names):\n      if t.name != t_ref.name: isclose(""TEST: %-4s "" % name + t.name, p_ref, p)\n'"
