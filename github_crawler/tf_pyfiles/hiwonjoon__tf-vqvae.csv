file_path,api_count,code
cifar10.py,86,"b'from __future__ import print_function\nfrom six.moves import xrange\nimport os\nimport better_exceptions\nimport tensorflow as tf\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom model import VQVAE, _cifar10_arch, PixelCNN\n\n# The codes are borrowed from\n# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10.py\n# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_input.py\nDATA_DIR = \'datasets/cifar10\'\nDATA_URL = \'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\'\ndef maybe_download_and_extract():\n    import sys, tarfile\n    from six.moves import urllib\n    """"""Download and extract the tarball from Alex\'s website.""""""\n    if not os.path.exists(DATA_DIR):\n        os.makedirs(DATA_DIR)\n    filename = DATA_URL.split(\'/\')[-1]\n    filepath = os.path.join(DATA_DIR, filename)\n    if not os.path.exists(filepath):\n        def _progress(count, block_size, total_size):\n            sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' % (filename,\n                float(count * block_size) / float(total_size) * 100.0))\n            sys.stdout.flush()\n        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n        print()\n        statinfo = os.stat(filepath)\n        print(\'Successfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    extracted_dir_path = os.path.join(DATA_DIR, \'cifar-10-batches-bin\')\n    if not os.path.exists(extracted_dir_path):\n        tarfile.open(filepath, \'r:gz\').extractall(DATA_DIR)\n\ndef read_cifar10(filename_queue):\n    class CIFAR10Record(object):\n        pass\n    result = CIFAR10Record()\n    record_bytes = 1 + 32*32*3\n\n    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n    result.key, value = reader.read(filename_queue)\n    record_bytes = tf.decode_raw(value, tf.uint8)\n\n    result.label = tf.cast(\n        tf.strided_slice(record_bytes, [0], [1]), tf.int32)\n    depth_major = tf.reshape(\n        tf.strided_slice(record_bytes, [1],\n                         [1 + 32*32*3]),\n        [3, 32, 32])\n    # Convert from [depth, height, width] to [height, width, depth].\n    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n    return result\n\ndef get_image(train=True,num_epochs=None):\n    maybe_download_and_extract()\n    if train:\n        filenames = [os.path.join(DATA_DIR, \'cifar-10-batches-bin\', \'data_batch_%d.bin\' % i) for i in xrange(1, 6)]\n    else:\n        filenames = [os.path.join(DATA_DIR, \'cifar-10-batches-bin\', \'test_batch.bin\')]\n    filename_queue = tf.train.string_input_producer(filenames,num_epochs=num_epochs)\n    read_input = read_cifar10(filename_queue)\n    return tf.cast(read_input.uint8image, tf.float32) / 255.0, tf.reshape(read_input.label,[])\n\n\ndef main(config,\n         RANDOM_SEED,\n         LOG_DIR,\n         TRAIN_NUM,\n         BATCH_SIZE,\n         LEARNING_RATE,\n         DECAY_VAL,\n         DECAY_STEPS,\n         DECAY_STAIRCASE,\n         BETA,\n         K,\n         D,\n         SAVE_PERIOD,\n         SUMMARY_PERIOD,\n         **kwargs):\n    np.random.seed(RANDOM_SEED)\n    tf.set_random_seed(RANDOM_SEED)\n\n    # >>>>>>> DATASET\n    image,_ = get_image()\n    images = tf.train.shuffle_batch(\n        [image],\n        batch_size=BATCH_SIZE,\n        num_threads=4,\n        capacity=BATCH_SIZE*10,\n        min_after_dequeue=BATCH_SIZE*2)\n    valid_image,_ = get_image(False)\n    valid_images = tf.train.shuffle_batch(\n        [valid_image],\n        batch_size=BATCH_SIZE,\n        num_threads=1,\n        capacity=BATCH_SIZE*10,\n        min_after_dequeue=BATCH_SIZE*2)\n    # <<<<<<<\n\n    # >>>>>>> MODEL\n    with tf.variable_scope(\'train\'):\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.exponential_decay(LEARNING_RATE, global_step, DECAY_STEPS, DECAY_VAL, staircase=DECAY_STAIRCASE)\n        tf.summary.scalar(\'lr\',learning_rate)\n\n        with tf.variable_scope(\'params\') as params:\n            pass\n        net = VQVAE(learning_rate,global_step,BETA,images,K,D,_cifar10_arch,params,True)\n\n    with tf.variable_scope(\'valid\'):\n        params.reuse_variables()\n        valid_net = VQVAE(None,None,BETA,valid_images,K,D,_cifar10_arch,params,False)\n\n    with tf.variable_scope(\'misc\'):\n        # Summary Operations\n        tf.summary.scalar(\'loss\',net.loss)\n        tf.summary.scalar(\'recon\',net.recon)\n        tf.summary.scalar(\'vq\',net.vq)\n        tf.summary.scalar(\'commit\',BETA*net.commit)\n        tf.summary.scalar(\'nll\',tf.reduce_mean(net.nll))\n        tf.summary.image(\'origin\',images,max_outputs=4)\n        tf.summary.image(\'recon\',net.p_x_z,max_outputs=4)\n        # TODO: logliklihood\n\n        summary_op = tf.summary.merge_all()\n\n        # Initialize op\n        init_op = tf.group(tf.global_variables_initializer(),\n                        tf.local_variables_initializer())\n        config_summary = tf.summary.text(\'TrainConfig\', tf.convert_to_tensor(config.as_matrix()), collections=[])\n\n        extended_summary_op = tf.summary.merge([\n            tf.summary.scalar(\'valid_loss\',valid_net.loss),\n            tf.summary.scalar(\'valid_recon\',valid_net.recon),\n            tf.summary.scalar(\'valid_vq\',valid_net.vq),\n            tf.summary.scalar(\'valid_commit\',BETA*valid_net.commit),\n            tf.summary.scalar(\'valid_nll\',tf.reduce_mean(valid_net.nll)),\n            tf.summary.image(\'valid_origin\',valid_images,max_outputs=4),\n            tf.summary.image(\'valid_recon\',valid_net.p_x_z,max_outputs=4),\n        ])\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n\n    summary_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n    summary_writer.add_summary(config_summary.eval(session=sess))\n\n    try:\n        # Start Queueing\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord,sess=sess)\n        for step in tqdm(xrange(TRAIN_NUM),dynamic_ncols=True):\n            it,loss,_ = sess.run([global_step,net.loss,net.train_op])\n\n            if( it % SAVE_PERIOD == 0 ):\n                net.save(sess,LOG_DIR,step=it)\n\n            if( it % SUMMARY_PERIOD == 0 ):\n                tqdm.write(\'[%5d] Loss: %1.3f\'%(it,loss))\n                summary = sess.run(summary_op)\n                summary_writer.add_summary(summary,it)\n\n            if( it % (SUMMARY_PERIOD*2) == 0 ): #Extended Summary\n                summary = sess.run(extended_summary_op)\n                summary_writer.add_summary(summary,it)\n\n    except Exception as e:\n        coord.request_stop(e)\n    finally :\n        net.save(sess,LOG_DIR)\n\n        coord.request_stop()\n        coord.join(threads)\n\ndef test(MODEL,\n         BETA,\n         K,\n         D,\n         **kwargs):\n    # >>>>>>> DATASET\n    image,_ = get_image(num_epochs=1)\n    images = tf.train.batch(\n        [image],\n        batch_size=100,\n        num_threads=1,\n        capacity=100,\n        allow_smaller_final_batch=True)\n    valid_image,_ = get_image(False,num_epochs=1)\n    valid_images = tf.train.batch(\n        [valid_image],\n        batch_size=100,\n        num_threads=1,\n        capacity=100,\n        allow_smaller_final_batch=True)\n    # <<<<<<<\n\n    # >>>>>>> MODEL\n    with tf.variable_scope(\'net\'):\n        with tf.variable_scope(\'params\') as params:\n            pass\n        x = tf.placeholder(tf.float32,[None,32,32,3])\n        net= VQVAE(None,None,BETA,x,K,D,_cifar10_arch,params,False)\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                    tf.local_variables_initializer())\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n    net.load(sess,MODEL)\n\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord,sess=sess)\n    try:\n        nlls = []\n        while not coord.should_stop():\n            nlls.append(\n                sess.run(net.nll,feed_dict={x:sess.run(valid_images)}))\n            print(\'.\', end=\'\', flush=True)\n    except tf.errors.OutOfRangeError:\n        nlls = np.concatenate(nlls,axis=0)\n        print(nlls.shape)\n        print(\'NLL for test set: %f bits/dims\'%(np.mean(nlls)))\n\n    try:\n        nlls = []\n        while not coord.should_stop():\n            nlls.append(\n                sess.run(net.nll,feed_dict={x:sess.run(images)}))\n            print(\'.\', end=\'\', flush=True)\n    except tf.errors.OutOfRangeError:\n        nlls = np.concatenate(nlls,axis=0)\n        print(nlls.shape)\n        print(\'NLL for training set: %f bits/dims\'%(np.mean(nlls)))\n\n    coord.request_stop()\n    coord.join(threads)\n\ndef extract_z(MODEL,\n              BATCH_SIZE,\n              BETA,\n              K,\n              D,\n              **kwargs):\n    # >>>>>>> DATASET\n    image,label = get_image(num_epochs=1)\n    images,labels = tf.train.batch(\n        [image,label],\n        batch_size=BATCH_SIZE,\n        num_threads=1,\n        capacity=BATCH_SIZE,\n        allow_smaller_final_batch=True)\n    # <<<<<<<\n\n    # >>>>>>> MODEL\n    with tf.variable_scope(\'net\'):\n        with tf.variable_scope(\'params\') as params:\n            pass\n        x_ph = tf.placeholder(tf.float32,[None,32,32,3])\n        net= VQVAE(None,None,BETA,x_ph,K,D,_cifar10_arch,params,False)\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                    tf.local_variables_initializer())\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n    net.load(sess,MODEL)\n\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord,sess=sess)\n    try:\n        ks = []\n        ys = []\n        while not coord.should_stop():\n            x,y = sess.run([images,labels])\n            k = sess.run(net.k,feed_dict={x_ph:x})\n            ks.append(k)\n            ys.append(y)\n            print(\'.\', end=\'\', flush=True)\n    except tf.errors.OutOfRangeError:\n        print(\'Extracting Finished\')\n\n    ks = np.concatenate(ks,axis=0)\n    ys = np.concatenate(ys,axis=0)\n    np.savez(os.path.join(os.path.dirname(MODEL),\'ks_ys.npz\'),ks=ks,ys=ys)\n\n    coord.request_stop()\n    coord.join(threads)\n\ndef train_prior(config,\n                RANDOM_SEED,\n                MODEL,\n                TRAIN_NUM,\n                BATCH_SIZE,\n                LEARNING_RATE,\n                DECAY_VAL,\n                DECAY_STEPS,\n                DECAY_STAIRCASE,\n                GRAD_CLIP,\n                K,\n                D,\n                BETA,\n                NUM_LAYERS,\n                NUM_FEATURE_MAPS,\n                SUMMARY_PERIOD,\n                SAVE_PERIOD,\n                **kwargs):\n    np.random.seed(RANDOM_SEED)\n    tf.set_random_seed(RANDOM_SEED)\n    LOG_DIR = os.path.join(os.path.dirname(MODEL),\'pixelcnn_6\')\n    # >>>>>>> DATASET\n    class Latents():\n        def __init__(self,path,validation_size=1):\n            from tensorflow.contrib.learn.python.learn.datasets.mnist import DataSet\n            from tensorflow.contrib.learn.python.learn.datasets import base\n\n            data = np.load(path)\n            train = DataSet(data[\'ks\'][validation_size:], data[\'ys\'][validation_size:],reshape=False,dtype=np.uint8,one_hot=False) #dtype won\'t bother even in the case when latent is int32 type.\n            validation = DataSet(data[\'ks\'][:validation_size], data[\'ys\'][:validation_size],reshape=False,dtype=np.uint8,one_hot=False)\n            #test = DataSet(data[\'test_x\'],np.argmax(data[\'test_y\'],axis=1),reshape=False,dtype=np.float32,one_hot=False)\n            self.size = data[\'ks\'].shape[1]\n            self.data = base.Datasets(train=train, validation=validation, test=None)\n    latent = Latents(os.path.join(os.path.dirname(MODEL),\'ks_ys.npz\'))\n    # <<<<<<<\n\n    # >>>>>>> MODEL for Generate Images\n    with tf.variable_scope(\'net\'):\n        with tf.variable_scope(\'params\') as params:\n            pass\n        _not_used = tf.placeholder(tf.float32,[None,32,32,3])\n        vq_net = VQVAE(None,None,BETA,_not_used,K,D,_cifar10_arch,params,False)\n    # <<<<<<<\n\n    # >>>>>> MODEL for Training Prior\n    with tf.variable_scope(\'pixelcnn\'):\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.exponential_decay(LEARNING_RATE, global_step, DECAY_STEPS, DECAY_VAL, staircase=DECAY_STAIRCASE)\n        tf.summary.scalar(\'lr\',learning_rate)\n\n        net = PixelCNN(learning_rate,global_step,GRAD_CLIP,\n                       latent.size,vq_net.embeds,K,D,\n                       10,NUM_LAYERS,NUM_FEATURE_MAPS)\n    # <<<<<<\n    with tf.variable_scope(\'misc\'):\n        # Summary Operations\n        tf.summary.scalar(\'loss\',net.loss)\n        summary_op = tf.summary.merge_all()\n\n        # Initialize op\n        init_op = tf.group(tf.global_variables_initializer(),\n                        tf.local_variables_initializer())\n        config_summary = tf.summary.text(\'TrainConfig\', tf.convert_to_tensor(config.as_matrix()), collections=[])\n\n        sample_images = tf.placeholder(tf.float32,[None,32,32,3])\n        sample_summary_op = tf.summary.image(\'samples\',sample_images,max_outputs=20)\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n    vq_net.load(sess,MODEL)\n\n    summary_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n    summary_writer.add_summary(config_summary.eval(session=sess))\n\n    for step in tqdm(xrange(TRAIN_NUM),dynamic_ncols=True):\n        batch_xs, batch_ys = latent.data.train.next_batch(BATCH_SIZE)\n        it,loss,_ = sess.run([global_step,net.loss,net.train_op],feed_dict={net.X:batch_xs,net.h:batch_ys})\n\n        if( it % SAVE_PERIOD == 0 ):\n            net.save(sess,LOG_DIR,step=it)\n\n        if( it % SUMMARY_PERIOD == 0 ):\n            tqdm.write(\'[%5d] Loss: %1.3f\'%(it,loss))\n            summary = sess.run(summary_op,feed_dict={net.X:batch_xs,net.h:batch_ys})\n            summary_writer.add_summary(summary,it)\n\n        if( it % (SUMMARY_PERIOD * 2) == 0 ):\n            sampled_zs,log_probs = net.sample_from_prior(sess,np.arange(10),2)\n            sampled_ims = sess.run(vq_net.gen,feed_dict={vq_net.latent:sampled_zs})\n            summary_writer.add_summary(\n                sess.run(sample_summary_op,feed_dict={sample_images:sampled_ims}),it)\n\n    net.save(sess,LOG_DIR)\n\ndef get_default_param():\n    from datetime import datetime\n    now = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")\n    return {\n        \'LOG_DIR\':\'./log/cifar10/%s\'%(now),\n        \'MODEL\' : \'./log/cifar10/%s/last.ckpt\'%(now),\n\n        \'TRAIN_NUM\' : 250000, #Size corresponds to one epoch\n        \'BATCH_SIZE\': 128,\n\n        \'LEARNING_RATE\' : 0.0002,\n        \'DECAY_VAL\' : 1.0,\n        \'DECAY_STEPS\' : 20000, # Half of the training procedure.\n        \'DECAY_STAIRCASE\' : False,\n\n        \'BETA\':0.25,\n        \'K\':10,\n        \'D\':256,\n\n        # PixelCNN Params\n        \'GRAD_CLIP\' : 5.0,\n        \'NUM_LAYERS\' : 12,\n        \'NUM_FEATURE_MAPS\' : 64,\n\n        \'SUMMARY_PERIOD\' : 100,\n        \'SAVE_PERIOD\' : 10000,\n        \'RANDOM_SEED\': 0,\n    }\n\nif __name__ == ""__main__"":\n    class MyConfig(dict):\n        pass\n    params = get_default_param()\n    config = MyConfig(params)\n    def as_matrix() :\n        return [[k, str(w)] for k, w in config.items()]\n    config.as_matrix = as_matrix\n\n    main(config=config,**config)\n    extract_z(**config)\n    config[\'TRAIN_NUM\'] = 300000\n    config[\'LEARNING_RATE\'] = 0.001\n    config[\'DECAY_VAL\'] = 0.5\n    config[\'DECAY_STEPS\'] = 100000\n    train_prior(config=config,**config)\n\n    #test(MODEL=\'models/cifar10/last.ckpt\',**config)\n'"
imagenet.py,56,"b'from six.moves import xrange\nimport os\nimport better_exceptions\nimport tensorflow as tf\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom model import VQVAE, _imagenet_arch, PixelCNN\n\nimport sys\nsys.path.append(\'slim_models/research/slim\')\nfrom datasets import imagenet\nslim = tf.contrib.slim\ndef _build_batch(dataset,batch_size,num_threads):\n    with tf.device(\'/cpu\'):\n        provider = slim.dataset_data_provider.DatasetDataProvider(\n            dataset,\n            num_readers=num_threads,\n            common_queue_capacity=20*batch_size,\n            common_queue_min=10*batch_size,\n            shuffle=True)\n        image,label = provider.get([\'image\',\'label\'])\n        # Slim module has a background label as 0. By changing this, you need to use (label_num-1)\n        # on Jupyter notebook to generate class conditioned samples.\n        #label -= 1\n        pp_image = tf.image.resize_images(image,[128,128]) / 255.0\n\n        images,labels = tf.train.batch(\n            [pp_image,label],\n            batch_size=batch_size,\n            num_threads=num_threads,\n            capacity=5*batch_size,\n            allow_smaller_final_batch=True)\n        return images, labels\n\ndef main(config,\n         RANDOM_SEED,\n         LOG_DIR,\n         TRAIN_NUM,\n         BATCH_SIZE,\n         LEARNING_RATE,\n         DECAY_VAL,\n         DECAY_STEPS,\n         DECAY_STAIRCASE,\n         BETA,\n         K,\n         D,\n         SAVE_PERIOD,\n         SUMMARY_PERIOD,\n         **kwargs):\n    np.random.seed(RANDOM_SEED)\n    tf.set_random_seed(RANDOM_SEED)\n\n    # >>>>>>> DATASET\n    train_dataset = imagenet.get_split(\'train\',\'datasets/ILSVRC2012\')\n    valid_dataset = imagenet.get_split(\'validation\',\'datasets/ILSVRC2012\')\n    train_ims,_ = _build_batch(train_dataset,BATCH_SIZE,4)\n    valid_ims,_ = _build_batch(valid_dataset,4,1)\n\n    # >>>>>>> MODEL\n    with tf.variable_scope(\'train\'):\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.exponential_decay(LEARNING_RATE, global_step, DECAY_STEPS, DECAY_VAL, staircase=DECAY_STAIRCASE)\n        tf.summary.scalar(\'lr\',learning_rate)\n\n        with tf.variable_scope(\'params\') as params:\n            pass\n        net = VQVAE(learning_rate,global_step,BETA,train_ims,K,D,_imagenet_arch,params,True)\n\n    with tf.variable_scope(\'valid\'):\n        params.reuse_variables()\n        valid_net = VQVAE(None,None,BETA,valid_ims,K,D,_imagenet_arch,params,False)\n\n    with tf.variable_scope(\'misc\'):\n        # Summary Operations\n        tf.summary.scalar(\'loss\',net.loss)\n        tf.summary.scalar(\'recon\',net.recon)\n        tf.summary.scalar(\'vq\',net.vq)\n        tf.summary.scalar(\'commit\',BETA*net.commit)\n        tf.summary.scalar(\'nll\',tf.reduce_mean(net.nll))\n        tf.summary.image(\'origin\',train_ims,max_outputs=4)\n        tf.summary.image(\'recon\',net.p_x_z,max_outputs=4)\n        summary_op = tf.summary.merge_all()\n\n        # Initialize op\n        init_op = tf.group(tf.global_variables_initializer(),\n                        tf.local_variables_initializer())\n        config_summary = tf.summary.text(\'TrainConfig\', tf.convert_to_tensor(config.as_matrix()), collections=[])\n\n        extended_summary_op = tf.summary.merge([\n            tf.summary.scalar(\'valid_loss\',valid_net.loss),\n            tf.summary.scalar(\'valid_recon\',valid_net.recon),\n            tf.summary.scalar(\'valid_vq\',valid_net.vq),\n            tf.summary.scalar(\'valid_commit\',BETA*valid_net.commit),\n            tf.summary.scalar(\'valid_nll\',tf.reduce_mean(valid_net.nll)),\n            tf.summary.image(\'valid_origin\',valid_ims,max_outputs=4),\n            tf.summary.image(\'valid_recon\',valid_net.p_x_z,max_outputs=4),\n        ])\n    # <<<<<<<<<<\n\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n\n    summary_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n    summary_writer.add_summary(config_summary.eval(session=sess))\n\n    try:\n        # Start Queueing\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord,sess=sess)\n        for step in tqdm(xrange(TRAIN_NUM),dynamic_ncols=True):\n            it,loss,_ = sess.run([global_step,net.loss,net.train_op])\n\n            if( it % SAVE_PERIOD == 0 ):\n                net.save(sess,LOG_DIR,step=it)\n\n            if( it % SUMMARY_PERIOD == 0 ):\n                tqdm.write(\'[%5d] Loss: %1.3f\'%(it,loss))\n                summary = sess.run(summary_op)\n                summary_writer.add_summary(summary,it)\n\n            if( it % (SUMMARY_PERIOD*2) == 0 ): #Extended Summary\n                summary = sess.run(extended_summary_op)\n                summary_writer.add_summary(summary,it)\n\n    except Exception as e:\n        coord.request_stop(e)\n    finally :\n        net.save(sess,LOG_DIR)\n\n        coord.request_stop()\n        coord.join(threads)\n\ndef train_prior(config,\n                RANDOM_SEED,\n                MODEL,\n                TRAIN_NUM,\n                BATCH_SIZE,\n                LEARNING_RATE,\n                DECAY_VAL,\n                DECAY_STEPS,\n                DECAY_STAIRCASE,\n                GRAD_CLIP,\n                K,\n                D,\n                BETA,\n                NUM_LAYERS,\n                NUM_FEATURE_MAPS,\n                SUMMARY_PERIOD,\n                SAVE_PERIOD,\n                **kwargs):\n    np.random.seed(RANDOM_SEED)\n    tf.set_random_seed(RANDOM_SEED)\n    LOG_DIR = os.path.join(os.path.dirname(MODEL),\'pixelcnn\')\n    # >>>>>>> DATASET\n    train_dataset = imagenet.get_split(\'train\',\'datasets/ILSVRC2012\')\n    ims,labels = _build_batch(train_dataset,BATCH_SIZE,4)\n    # <<<<<<<\n\n    # >>>>>>> MODEL for Generate Images\n    with tf.variable_scope(\'net\'):\n        with tf.variable_scope(\'params\') as params:\n            pass\n        vq_net = VQVAE(None,None,BETA,ims,K,D,_imagenet_arch,params,False)\n    # <<<<<<<\n\n    # >>>>>> MODEL for Training Prior\n    with tf.variable_scope(\'pixelcnn\'):\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.exponential_decay(LEARNING_RATE, global_step, DECAY_STEPS, DECAY_VAL, staircase=DECAY_STAIRCASE)\n        tf.summary.scalar(\'lr\',learning_rate)\n\n        net = PixelCNN(learning_rate,global_step,GRAD_CLIP,\n                       vq_net.k.get_shape()[1],vq_net.embeds,K,D,\n                       1000,NUM_LAYERS,NUM_FEATURE_MAPS)\n    # <<<<<<\n    with tf.variable_scope(\'misc\'):\n        # Summary Operations\n        tf.summary.scalar(\'loss\',net.loss)\n        summary_op = tf.summary.merge_all()\n\n        # Initialize op\n        init_op = tf.group(tf.global_variables_initializer(),\n                        tf.local_variables_initializer())\n        config_summary = tf.summary.text(\'TrainConfig\', tf.convert_to_tensor(config.as_matrix()), collections=[])\n\n        sample_images = tf.placeholder(tf.float32,[None,128,128,3])\n        sample_summary_op = tf.summary.image(\'samples\',sample_images,max_outputs=20)\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n    vq_net.load(sess,MODEL)\n\n    summary_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n    summary_writer.add_summary(config_summary.eval(session=sess))\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord,sess=sess)\n    try:\n        for step in tqdm(xrange(TRAIN_NUM),dynamic_ncols=True):\n            batch_xs,batch_ys = sess.run([vq_net.k,labels])\n            it,loss,_ = sess.run([global_step,net.loss,net.train_op],feed_dict={net.X:batch_xs,net.h:batch_ys})\n\n            if( it % SAVE_PERIOD == 0 ):\n                net.save(sess,LOG_DIR,step=it)\n                sampled_zs,log_probs = net.sample_from_prior(sess,np.random.randint(0,1000,size=(10,)),2)\n                sampled_ims = sess.run(vq_net.gen,feed_dict={vq_net.latent:sampled_zs})\n                summary_writer.add_summary(\n                    sess.run(sample_summary_op,feed_dict={sample_images:sampled_ims}),it)\n\n            if( it % SUMMARY_PERIOD == 0 ):\n                tqdm.write(\'[%5d] Loss: %1.3f\'%(it,loss))\n                summary = sess.run(summary_op,feed_dict={net.X:batch_xs,net.h:batch_ys})\n                summary_writer.add_summary(summary,it)\n\n    except Exception as e:\n        coord.request_stop(e)\n    finally :\n        net.save(sess,LOG_DIR)\n\n        coord.request_stop()\n        coord.join(threads)\n\ndef get_default_param():\n    from datetime import datetime\n    now = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")\n    return {\n        #\'LOG_DIR\':\'./log/imagenet/%s\'%(\'test\'),\n        \'LOG_DIR\':\'./log/imagenet/%s\'%(now),\n\n        \'TRAIN_NUM\' : 50000, #Size corresponds to one epoch\n        \'BATCH_SIZE\': 16,\n\n        \'LEARNING_RATE\' : 0.0002,\n        \'DECAY_VAL\' : 0.5,\n        \'DECAY_STEPS\' : 25000, # Half of the training procedure.\n        \'DECAY_STAIRCASE\' : False,\n\n        \'BETA\':0.25,\n        \'K\':512,\n        \'D\':128,\n\n        # PixelCNN Params\n        \'GRAD_CLIP\' : 5.0,\n        \'NUM_LAYERS\' : 18,\n        \'NUM_FEATURE_MAPS\' : 256,\n\n        \'SUMMARY_PERIOD\' : 50,\n        \'SAVE_PERIOD\' : 10000,\n        \'RANDOM_SEED\': 0,\n    }\n\nif __name__ == ""__main__"":\n    class MyConfig(dict):\n        pass\n    params = get_default_param()\n    config = MyConfig(params)\n    def as_matrix() :\n        return [[k, str(w)] for k, w in config.items()]\n    config.as_matrix = as_matrix\n\n    main(config=config,**config)\n    config[\'LEARNING_RATE\'] = 0.0004\n    config[\'TRAIN_NUM\'] = 300000\n    config[\'BATCH_SIZE\'] = 16\n    config[\'DECAY_STEPS\'] = 100000\n    train_prior(config=config,**config)\n\n    #TODO:\n    # Reduce memory usage by batch learn batch_xs gathering process with batchsize 1\n    # Only training for specific class labels. (1000 is too large classes)\n    # Find correct ys...(Coral Reef, or something)\n\n    #Warning:\n    # Uncomment line 20 for training from scratch... The slim module assigns 0 for background.\n'"
mnist.py,60,"b'from six.moves import xrange\nimport os\nimport better_exceptions\nimport tensorflow as tf\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom model import VQVAE, _mnist_arch, PixelCNN\n\ndef main(config,\n         RANDOM_SEED,\n         LOG_DIR,\n         TRAIN_NUM,\n         BATCH_SIZE,\n         LEARNING_RATE,\n         DECAY_VAL,\n         DECAY_STEPS,\n         DECAY_STAIRCASE,\n         BETA,\n         K,\n         D,\n         SAVE_PERIOD,\n         SUMMARY_PERIOD,\n         **kwargs):\n    np.random.seed(RANDOM_SEED)\n    tf.set_random_seed(RANDOM_SEED)\n\n    # >>>>>>> DATASET\n    from tensorflow.examples.tutorials.mnist import input_data\n    mnist = input_data.read_data_sets(""datasets/mnist"", one_hot=False)\n    # <<<<<<<\n\n    # >>>>>>> MODEL\n    x = tf.placeholder(tf.float32,[None,784])\n    resized = tf.image.resize_images(\n        tf.reshape(x,[-1,28,28,1]),\n        (24,24),\n        method=tf.image.ResizeMethod.BILINEAR)\n\n    with tf.variable_scope(\'train\'):\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.exponential_decay(LEARNING_RATE, global_step, DECAY_STEPS, DECAY_VAL, staircase=DECAY_STAIRCASE)\n        tf.summary.scalar(\'lr\',learning_rate)\n\n        with tf.variable_scope(\'params\') as params:\n            pass\n        net = VQVAE(learning_rate,global_step,BETA,resized,K,D,_mnist_arch,params,True)\n\n    with tf.variable_scope(\'valid\'):\n        params.reuse_variables()\n        valid_net = VQVAE(None,None,BETA,resized,K,D,_mnist_arch,params,False)\n\n    with tf.variable_scope(\'misc\'):\n        # Summary Operations\n        tf.summary.scalar(\'loss\',net.loss)\n        tf.summary.scalar(\'recon\',net.recon)\n        tf.summary.scalar(\'vq\',net.vq)\n        tf.summary.scalar(\'commit\',BETA*net.commit)\n        tf.summary.image(\'origin\',resized,max_outputs=4)\n        tf.summary.image(\'recon\',net.p_x_z,max_outputs=4)\n        # TODO: logliklihood\n\n        summary_op = tf.summary.merge_all()\n\n        # Initialize op\n        init_op = tf.group(tf.global_variables_initializer(),\n                        tf.local_variables_initializer())\n        config_summary = tf.summary.text(\'TrainConfig\', tf.convert_to_tensor(config.as_matrix()), collections=[])\n\n        extended_summary_op = tf.summary.merge([\n            tf.summary.scalar(\'valid_loss\',valid_net.loss),\n            tf.summary.scalar(\'valid_recon\',valid_net.recon),\n            tf.summary.scalar(\'valid_vq\',valid_net.vq),\n            tf.summary.scalar(\'valid_commit\',BETA*valid_net.commit),\n            tf.summary.image(\'valid_recon\',valid_net.p_x_z,max_outputs=10),\n        ])\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n\n    summary_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n    summary_writer.add_summary(config_summary.eval(session=sess))\n\n    for step in tqdm(xrange(TRAIN_NUM),dynamic_ncols=True):\n        batch_xs, _= mnist.train.next_batch(BATCH_SIZE)\n        it,loss,_ = sess.run([global_step,net.loss,net.train_op],feed_dict={x:batch_xs})\n\n        if( it % SAVE_PERIOD == 0 ):\n            net.save(sess,LOG_DIR,step=it)\n\n        if( it % SUMMARY_PERIOD == 0 ):\n            tqdm.write(\'[%5d] Loss: %1.3f\'%(it,loss))\n            summary = sess.run(summary_op,feed_dict={x:batch_xs})\n            summary_writer.add_summary(summary,it)\n\n        if( it % (SUMMARY_PERIOD*2) == 0 ): #Extended Summary\n            batch_xs, _= mnist.test.next_batch(BATCH_SIZE)\n            summary = sess.run(extended_summary_op,feed_dict={x:batch_xs})\n            summary_writer.add_summary(summary,it)\n\n    net.save(sess,LOG_DIR)\n\ndef extract_z(MODEL,\n              BATCH_SIZE,\n              BETA,\n              K,\n              D,\n              **kwargs):\n    # >>>>>>> DATASET\n    from tensorflow.examples.tutorials.mnist import input_data\n    mnist = input_data.read_data_sets(""datasets/mnist"", one_hot=False)\n    # <<<<<<<\n\n    # >>>>>>> MODEL\n    x = tf.placeholder(tf.float32,[None,784])\n    resized = tf.image.resize_images(\n        tf.reshape(x,[-1,28,28,1]),\n        (24,24),\n        method=tf.image.ResizeMethod.BILINEAR)\n\n    with tf.variable_scope(\'net\'):\n        with tf.variable_scope(\'params\') as params:\n            pass\n        net = VQVAE(None,None,BETA,resized,K,D,_mnist_arch,params,False)\n\n    # Initialize op\n    init_op = tf.group(tf.global_variables_initializer(),\n                    tf.local_variables_initializer())\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n    net.load(sess,MODEL)\n\n    xs,ys = mnist.train.images, mnist.train.labels\n    ks = []\n    for i in tqdm(range(0,len(xs),BATCH_SIZE)):\n        batch = xs[i:i+BATCH_SIZE]\n\n        k = sess.run(net.k,feed_dict={x:batch})\n        ks.append(k)\n    ks = np.concatenate(ks,axis=0)\n\n    np.savez(os.path.join(os.path.dirname(MODEL),\'ks_ys.npz\'),ks=ks,ys=ys)\n\ndef train_prior(config,\n                RANDOM_SEED,\n                MODEL,\n                TRAIN_NUM,\n                BATCH_SIZE,\n                LEARNING_RATE,\n                DECAY_VAL,\n                DECAY_STEPS,\n                DECAY_STAIRCASE,\n                GRAD_CLIP,\n                K,\n                D,\n                BETA,\n                NUM_LAYERS,\n                NUM_FEATURE_MAPS,\n                SUMMARY_PERIOD,\n                SAVE_PERIOD,\n                **kwargs):\n    np.random.seed(RANDOM_SEED)\n    tf.set_random_seed(RANDOM_SEED)\n    LOG_DIR = os.path.join(os.path.dirname(MODEL),\'pixelcnn\')\n    # >>>>>>> DATASET\n    class Latents():\n        def __init__(self,path,validation_size=5000):\n            from tensorflow.contrib.learn.python.learn.datasets.mnist import DataSet\n            from tensorflow.contrib.learn.python.learn.datasets import base\n\n            data = np.load(path)\n            train = DataSet(data[\'ks\'][validation_size:], data[\'ys\'][validation_size:],reshape=False,dtype=np.uint8,one_hot=False) #dtype won\'t bother even in the case when latent is int32 type.\n            validation = DataSet(data[\'ks\'][:validation_size], data[\'ys\'][:validation_size],reshape=False,dtype=np.uint8,one_hot=False)\n            #test = DataSet(data[\'test_x\'],np.argmax(data[\'test_y\'],axis=1),reshape=False,dtype=np.float32,one_hot=False)\n            self.size = data[\'ks\'].shape[1]\n            self.data = base.Datasets(train=train, validation=validation, test=None)\n    latent = Latents(os.path.join(os.path.dirname(MODEL),\'ks_ys.npz\'))\n    # <<<<<<<\n\n    # >>>>>>> MODEL for Generate Images\n    with tf.variable_scope(\'net\'):\n        with tf.variable_scope(\'params\') as params:\n            pass\n        _not_used = tf.placeholder(tf.float32,[None,24,24,1])\n        vq_net = VQVAE(None,None,BETA,_not_used,K,D,_mnist_arch,params,False)\n    # <<<<<<<\n\n    # >>>>>> MODEL for Training Prior\n    with tf.variable_scope(\'pixelcnn\'):\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.exponential_decay(LEARNING_RATE, global_step, DECAY_STEPS, DECAY_VAL, staircase=DECAY_STAIRCASE)\n        tf.summary.scalar(\'lr\',learning_rate)\n\n        net = PixelCNN(learning_rate,global_step,GRAD_CLIP,\n                       latent.size,vq_net.embeds,K,D,\n                       10,NUM_LAYERS,NUM_FEATURE_MAPS)\n    # <<<<<<\n    with tf.variable_scope(\'misc\'):\n        # Summary Operations\n        tf.summary.scalar(\'loss\',net.loss)\n        summary_op = tf.summary.merge_all()\n\n        # Initialize op\n        init_op = tf.group(tf.global_variables_initializer(),\n                        tf.local_variables_initializer())\n        config_summary = tf.summary.text(\'TrainConfig\', tf.convert_to_tensor(config.as_matrix()), collections=[])\n\n        sample_images = tf.placeholder(tf.float32,[None,24,24,1])\n        sample_summary_op = tf.summary.image(\'samples\',sample_images,max_outputs=20)\n\n    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Run!\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n    vq_net.load(sess,MODEL)\n\n    summary_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n    summary_writer.add_summary(config_summary.eval(session=sess))\n\n    for step in tqdm(xrange(TRAIN_NUM),dynamic_ncols=True):\n        batch_xs, batch_ys = latent.data.train.next_batch(BATCH_SIZE)\n        it,loss,_ = sess.run([global_step,net.loss,net.train_op],feed_dict={net.X:batch_xs,net.h:batch_ys})\n\n        if( it % SAVE_PERIOD == 0 ):\n            net.save(sess,LOG_DIR,step=it)\n\n        if( it % SUMMARY_PERIOD == 0 ):\n            tqdm.write(\'[%5d] Loss: %1.3f\'%(it,loss))\n            summary = sess.run(summary_op,feed_dict={net.X:batch_xs,net.h:batch_ys})\n            summary_writer.add_summary(summary,it)\n\n        if( it % (SUMMARY_PERIOD * 2) == 0 ):\n            sampled_zs,log_probs = net.sample_from_prior(sess,np.arange(10),2)\n            sampled_ims = sess.run(vq_net.gen,feed_dict={vq_net.latent:sampled_zs})\n            summary_writer.add_summary(\n                sess.run(sample_summary_op,feed_dict={sample_images:sampled_ims}),it)\n\n    net.save(sess,LOG_DIR)\n\n\ndef get_default_param():\n    from datetime import datetime\n    now = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")\n    return {\n        \'LOG_DIR\':\'./log/mnist/%s\'%(now),\n        \'MODEL\' : \'./log/mnist/%s/last.ckpt\'%(now),\n\n        \'TRAIN_NUM\' : 60000, #Size corresponds to one epoch\n        \'BATCH_SIZE\': 32,\n\n        \'LEARNING_RATE\' : 0.0002,\n        \'DECAY_VAL\' : 1.0,\n        \'DECAY_STEPS\' : 20000, # Half of the training procedure.\n        \'DECAY_STAIRCASE\' : False,\n\n        \'BETA\':0.25,\n        \'K\':5,\n        \'D\':64,\n\n        # PixelCNN Params\n        \'GRAD_CLIP\' : 1.0,\n        \'NUM_LAYERS\' : 12,\n        \'NUM_FEATURE_MAPS\' : 32,\n\n        \'SUMMARY_PERIOD\' : 100,\n        \'SAVE_PERIOD\' : 10000,\n        \'RANDOM_SEED\': 0,\n    }\n\nif __name__ == ""__main__"":\n    class MyConfig(dict):\n        pass\n    params = get_default_param()\n    config = MyConfig(params)\n    def as_matrix() :\n        return [[k, str(w)] for k, w in config.items()]\n    config.as_matrix = as_matrix\n\n    main(config=config,**config)\n    extract_z(**config)\n    train_prior(config=config,**config)\n'"
model.py,82,"b'from six.moves import xrange\nimport better_exceptions\nimport tensorflow as tf\nimport numpy as np\nfrom commons.ops import *\n\ndef _mnist_arch(d):\n    with tf.variable_scope(\'enc\') as enc_param_scope :\n        enc_spec = [\n            Conv2d(\'conv2d_1\',1,d//4,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            Conv2d(\'conv2d_2\',d//4,d//2,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            Conv2d(\'conv2d_3\',d//2,d,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n        ]\n    with tf.variable_scope(\'dec\') as dec_param_scope :\n        dec_spec = [\n            TransposedConv2d(\'tconv2d_1\',d,d//2,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            TransposedConv2d(\'tconv2d_2\',d//2,d//4,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            TransposedConv2d(\'tconv2d_3\',d//4,1,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.sigmoid(t),\n        ]\n    return enc_spec,enc_param_scope,dec_spec,dec_param_scope\n\ndef _cifar10_arch(d):\n    def _residual(t,conv3,conv1):\n        return conv1(tf.nn.relu(conv3(tf.nn.relu(t))))+t\n    from functools import partial\n\n    with tf.variable_scope(\'enc\') as enc_param_scope :\n        enc_spec = [\n            Conv2d(\'conv2d_1\',3,d,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            Conv2d(\'conv2d_2\',d,d,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            partial(_residual,\n                    conv3=Conv2d(\'res_1_3\',d,d,3,3,1,1,data_format=\'NHWC\'),\n                    conv1=Conv2d(\'res_1_1\',d,d,1,1,1,1,data_format=\'NHWC\')),\n            partial(_residual,\n                    conv3=Conv2d(\'res_2_3\',d,d,3,3,1,1,data_format=\'NHWC\'),\n                    conv1=Conv2d(\'res_2_1\',d,d,1,1,1,1,data_format=\'NHWC\')),\n        ]\n    with tf.variable_scope(\'dec\') as dec_param_scope :\n        dec_spec = [\n            partial(_residual,\n                    conv3=Conv2d(\'res_1_3\',d,d,3,3,1,1,data_format=\'NHWC\'),\n                    conv1=Conv2d(\'res_1_1\',d,d,1,1,1,1,data_format=\'NHWC\')),\n            partial(_residual,\n                    conv3=Conv2d(\'res_2_3\',d,d,3,3,1,1,data_format=\'NHWC\'),\n                    conv1=Conv2d(\'res_2_1\',d,d,1,1,1,1,data_format=\'NHWC\')),\n            TransposedConv2d(\'tconv2d_1\',d,d,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            TransposedConv2d(\'tconv2d_2\',d,3,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.sigmoid(t),\n        ]\n    return enc_spec,enc_param_scope,dec_spec,dec_param_scope\n\ndef _imagenet_arch(d,num_residual=4):\n    def _residual(t,conv3,conv1):\n        return conv1(tf.nn.relu(conv3(tf.nn.relu(t))))+t\n    from functools import partial\n\n    with tf.variable_scope(\'enc\') as enc_param_scope :\n        enc_spec = [\n            Conv2d(\'conv2d_1\',3,d//2,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            Conv2d(\'conv2d_2\',d//2,d,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n        ]\n        enc_spec += [\n            partial(_residual,\n                    conv3=Conv2d(\'res_%d_3\'%i,d,d,3,3,1,1,data_format=\'NHWC\'),\n                    conv1=Conv2d(\'res_%d_1\'%i,d,d,1,1,1,1,data_format=\'NHWC\'))\n            for i in range(num_residual)\n        ]\n    with tf.variable_scope(\'dec\') as dec_param_scope :\n        dec_spec = [\n            partial(_residual,\n                    conv3=Conv2d(\'res_%d_3\'%i,d,d,3,3,1,1,data_format=\'NHWC\'),\n                    conv1=Conv2d(\'res_%d_1\'%i,d,d,1,1,1,1,data_format=\'NHWC\'))\n            for i in range(num_residual)\n        ]\n        dec_spec += [\n            lambda t,**kwargs : tf.nn.relu(t),\n            TransposedConv2d(\'tconv2d_1\',d,d//2,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.relu(t),\n            TransposedConv2d(\'tconv2d_2\',d//2,3,data_format=\'NHWC\'),\n            lambda t,**kwargs : tf.nn.sigmoid(t),\n        ]\n    return enc_spec,enc_param_scope,dec_spec,dec_param_scope\n\nclass VQVAE():\n    def __init__(self,lr,global_step,beta,\n                 x,K,D,\n                 arch_fn,\n                 param_scope,is_training=False):\n        with tf.variable_scope(param_scope):\n            enc_spec,enc_param_scope,dec_spec,dec_param_scope = arch_fn(D)\n            with tf.variable_scope(\'embed\') :\n                embeds = tf.get_variable(\'embed\', [K,D],\n                                        initializer=tf.truncated_normal_initializer(stddev=0.02))\n                self.embeds = embeds\n\n        with tf.variable_scope(\'forward\') as forward_scope:\n            # Encoder Pass\n            _t = x\n            for block in enc_spec :\n                _t = block(_t)\n            z_e = _t\n\n            # Middle Area (Compression or Discretize)\n            _t = tf.expand_dims(z_e, axis=-2)\n            _e = embeds\n            _t = tf.norm(_t-_e,axis=-1)\n            k = tf.argmin(_t,axis=-1) # -> [latent_h,latent_w]\n            z_q = tf.gather(embeds,k)\n\n            self.z_e = z_e # -> [batch,latent_h,latent_w,D]\n            self.k = k\n            self.z_q = z_q # -> [batch,latent_h,latent_w,D]\n\n            # Decoder Pass\n            _t = z_q\n            for block in dec_spec:\n                _t = block(_t)\n            self.p_x_z = _t\n\n            # Losses\n            self.recon = tf.reduce_mean((self.p_x_z - x)**2,axis=[0,1,2,3])\n            self.vq = tf.reduce_mean(\n                tf.norm(tf.stop_gradient(self.z_e) - z_q,axis=-1)**2,\n                axis=[0,1,2])\n            self.commit = tf.reduce_mean(\n                tf.norm(self.z_e - tf.stop_gradient(z_q),axis=-1)**2,\n                axis=[0,1,2])\n            self.loss = self.recon + self.vq + beta * self.commit\n\n            # NLL\n            # TODO: is it correct impl?\n            # it seems tf.reduce_prod(tf.shape(self.z_q)[1:2]) should be multipled\n            # in front of log(1/K) if we assume uniform prior on z.\n            self.nll = -1.*(tf.reduce_mean(tf.log(self.p_x_z),axis=[1,2,3]) + tf.log(1/tf.cast(K,tf.float32)))/tf.log(2.)\n\n        if( is_training ):\n            with tf.variable_scope(\'backward\'):\n                # Decoder Grads\n                decoder_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,dec_param_scope.name)\n                decoder_grads = list(zip(tf.gradients(self.loss,decoder_vars),decoder_vars))\n                # Encoder Grads\n                encoder_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,enc_param_scope.name)\n                grad_z = tf.gradients(self.recon,z_q)\n                encoder_grads = [(tf.gradients(z_e,var,grad_z)[0]+beta*tf.gradients(self.commit,var)[0],var)\n                                 for var in encoder_vars]\n                # Embedding Grads\n                embed_grads = list(zip(tf.gradients(self.vq,embeds),[embeds]))\n\n                optimizer = tf.train.AdamOptimizer(lr)\n                self.train_op= optimizer.apply_gradients(decoder_grads+encoder_grads+embed_grads,global_step=global_step)\n        else :\n            # Another decoder pass that we can play with!\n            size = self.z_e.get_shape()[1]\n            self.latent = tf.placeholder(tf.int64,[None,size,size])\n            _t = tf.gather(embeds,self.latent)\n            for block in dec_spec:\n                _t = block(_t)\n            self.gen = _t\n\n        save_vars = {(\'train/\'+\'/\'.join(var.name.split(\'/\')[1:])).split(\':\')[0] : var for var in\n                     tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,param_scope.name) }\n        #for name,var in save_vars.items():\n        #    print(name,var)\n\n        self.saver = tf.train.Saver(var_list=save_vars,max_to_keep = 3)\n\n    def save(self,sess,dir,step=None):\n        if(step is not None):\n            self.saver.save(sess,dir+\'/model.ckpt\',global_step=step)\n        else :\n            self.saver.save(sess,dir+\'/last.ckpt\')\n\n    def load(self,sess,model):\n        self.saver.restore(sess,model)\n\nclass PixelCNN(object):\n    def __init__(self,lr,global_step,grad_clip,\n                 size, embeds, K, D,\n                 num_classes, num_layers, num_maps,\n                 is_training=True):\n        import sys\n        sys.path.append(\'pixelcnn\')\n        from layers import GatedCNN\n        self.X = tf.placeholder(tf.int32,[None,size,size])\n\n        if( num_classes is not None ):\n            self.h = tf.placeholder(tf.int32,[None,])\n            onehot_h = tf.one_hot(self.h,num_classes,axis=-1)\n        else:\n            onehot_h = None\n\n        if( embeds is not None ):\n            X_processed = tf.gather(tf.stop_gradient(embeds),self.X)\n        else:\n            embeds = tf.get_variable(\'embed\', [K,D],\n                                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n            X_processed = tf.gather(embeds,self.X)\n\n        v_stack_in, h_stack_in = X_processed, X_processed\n        for i in range(num_layers):\n            filter_size = 3 if i > 0 else 7\n            mask = \'b\' if i > 0 else \'a\'\n            residual = True if i > 0 else False\n            i = str(i)\n            with tf.variable_scope(""v_stack""+i):\n                v_stack = GatedCNN([filter_size, filter_size, num_maps], v_stack_in, mask=mask, conditional=onehot_h).output()\n                v_stack_in = v_stack\n\n            with tf.variable_scope(""v_stack_1""+i):\n                v_stack_1 = GatedCNN([1, 1, num_maps], v_stack_in, gated=False, mask=mask).output()\n\n            with tf.variable_scope(""h_stack""+i):\n                h_stack = GatedCNN([1, filter_size, num_maps], h_stack_in, payload=v_stack_1, mask=mask, conditional=onehot_h).output()\n\n            with tf.variable_scope(""h_stack_1""+i):\n                h_stack_1 = GatedCNN([1, 1, num_maps], h_stack, gated=False, mask=mask).output()\n                if residual:\n                    h_stack_1 += h_stack_in # Residual connection\n                h_stack_in = h_stack_1\n\n        with tf.variable_scope(""fc_1""):\n            fc1 = GatedCNN([1, 1, num_maps], h_stack_in, gated=False, mask=\'b\').output()\n\n        with tf.variable_scope(""fc_2""):\n            self.fc2 = GatedCNN([1, 1, K], fc1, gated=False, mask=\'b\', activation=False).output()\n            self.dist = tf.distributions.Categorical(logits=self.fc2)\n            self.sampled = self.dist.sample()\n            self.log_prob = self.dist.log_prob(self.sampled)\n\n        loss_per_batch = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.fc2,\n                                                                                      labels=self.X),axis=[1,2])\n        self.loss = tf.reduce_mean(loss_per_batch,axis=0)\n\n        save_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,tf.contrib.framework.get_name_scope())\n        self.saver = tf.train.Saver(var_list=save_vars,max_to_keep = 3)\n\n        if( is_training ):\n            with tf.variable_scope(\'backward\'):\n                optimizer = tf.train.AdamOptimizer(lr)\n\n                gradients = optimizer.compute_gradients(self.loss,var_list=save_vars)\n                if( grad_clip is None ):\n                    clipped_gradients = gradients\n                else :\n                    clipped_gradients = [(tf.clip_by_value(_[0], -grad_clip, grad_clip), _[1]) for _ in gradients]\n                    #clipped_gradients = [(tf.clip_by_average_norm(_[0], grad_clip), _[1]) for _ in gradients]\n                self.train_op = optimizer.apply_gradients(clipped_gradients,global_step)\n        #for var in save_vars:\n        #    print(var,var.name)\n\n    def sample_from_prior(self,sess,classes,batch_size):\n        # Generates len(classes)*batch_size Z samples.\n        size = self.X.get_shape()[1]\n        feed_dict={\n            self.X: np.zeros([len(classes)*batch_size,size,size],np.int32)\n        }\n        if( classes is not None ):\n            feed_dict[self.h] = np.repeat(classes,batch_size).astype(np.int32)\n\n        log_probs = np.zeros((len(classes)*batch_size,))\n        for i in xrange(size):\n            for j in xrange(size):\n                sampled,log_prob = sess.run([self.sampled,self.log_prob],feed_dict=feed_dict)\n                feed_dict[self.X][:,i,j]= sampled[:,i,j]\n                log_probs += log_prob[:,i,j]\n        return feed_dict[self.X], log_probs\n\n    def save(self,sess,dir,step=None):\n        if(step is not None):\n            self.saver.save(sess,dir+\'/model-pixelcnn.ckpt\',global_step=step)\n        else :\n            self.saver.save(sess,dir+\'/last-pixelcnn.ckpt\')\n\n    def load(self,sess,model):\n        self.saver.restore(sess,model)\n\nif __name__ == ""__main__"":\n    with tf.variable_scope(\'params\') as params:\n        pass\n\n    x = tf.placeholder(tf.float32,[None,32,32,3])\n    global_step = tf.Variable(0, trainable=False)\n\n    net = VQVAE(0.1,global_step,0.1,x,20,256,_cifar10_arch,params,True)\n\n    with tf.variable_scope(\'pixelcnn\'):\n        latent = tf.placeholder(tf.int32,[None,3,3])\n        embeds = net.embeds\n\n        pixelcnn = PixelCNN(0.1,global_step,1.0,\n                            3,embeds,20,32,\n                            True,10,20)\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                    tf.local_variables_initializer())\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    sess.graph.finalize()\n    sess.run(init_op)\n\n    #print(sess.run(net.train_op,feed_dict={x:np.random.random((10,32,32,3))}))\n    sampled,log_prob = pixelcnn.sample_from_prior(sess,np.arange(10),1)\n    print(sampled[0], np.exp(log_prob[0]))\n\n'"
commons/__init__.py,0,b''
commons/ops.py,25,"b""import tensorflow as tf\n\nclass Conv2d(object) :\n    def __init__(self,name,input_dim,output_dim,k_h=4,k_w=4,d_h=2,d_w=2,\n                 stddev=0.02, data_format='NCHW') :\n        with tf.variable_scope(name) :\n            assert(data_format == 'NCHW' or data_format == 'NHWC')\n            self.w = tf.get_variable('w', [k_h, k_w, input_dim, output_dim],\n                                initializer=tf.truncated_normal_initializer(stddev=stddev))\n            self.b = tf.get_variable('b',[output_dim], initializer=tf.constant_initializer(0.0))\n            if( data_format == 'NCHW' ) :\n                self.strides = [1, 1, d_h, d_w]\n            else :\n                self.strides = [1, d_h, d_w, 1]\n            self.data_format = data_format\n    def __call__(self,input_var,name=None,w=None,b=None,**kwargs) :\n        w = w if w is not None else self.w\n        b = b if b is not None else self.b\n\n        if( self.data_format =='NCHW' ) :\n            return tf.nn.bias_add(\n                        tf.nn.conv2d(input_var, w,\n                                    use_cudnn_on_gpu=True,data_format='NCHW',\n                                    strides=self.strides, padding='SAME'),\n                        b,data_format='NCHW',name=name)\n        else :\n            return tf.nn.bias_add(\n                        tf.nn.conv2d(input_var, w,data_format='NHWC',\n                                    strides=self.strides, padding='SAME'),\n                        b,data_format='NHWC',name=name)\n    def get_variables(self):\n        return {'w':self.w,'b':self.b}\n\nclass Linear(object) :\n    def __init__(self,name,input_dim,output_dim,stddev=0.02) :\n        with tf.variable_scope(name) :\n            self.w = tf.get_variable('w',[input_dim, output_dim],\n                                initializer=tf.random_normal_initializer(stddev=stddev))\n            self.b = tf.get_variable('b',[output_dim],\n                                initializer=tf.constant_initializer(0.0))\n\n    def __call__(self,input_var,name=None,w=None,b=None,**kwargs) :\n        w = w if w is not None else self.w\n        b = b if b is not None else self.b\n\n        if( len(input_var.get_shape().dims) > 2 ) :\n            dims = tf.reduce_prod(tf.shape(input_var)[1:])\n            return tf.matmul(tf.reshape(input_var,[-1,dims]),w) + b\n        else :\n            return tf.matmul(input_var,w)+b\n    def get_variables(self):\n        return {'w':self.w,'b':self.b}\n\nclass TransposedConv2d(object):\n    def __init__(self,name,input_dim,out_dim,\n                 k_h=4,k_w=4,d_h=2,d_w=2,stddev=0.02,data_format='NCHW') :\n        with tf.variable_scope(name) :\n            self.w = tf.get_variable('w', [k_h, k_w, out_dim, input_dim],\n                                initializer=tf.random_normal_initializer(stddev=stddev))\n            self.b = tf.get_variable('b',[out_dim], initializer=tf.constant_initializer(0.0))\n\n        self.data_format = data_format\n        if( data_format =='NCHW' ):\n            self.strides = [1, 1, d_h, d_w]\n        else:\n            self.strides = [1, d_h, d_w, 1]\n\n    def __call__(self,input_var,name=None,**xargs):\n        shapes = tf.shape(input_var)\n        if( self.data_format == 'NCHW' ):\n            shapes = tf.stack([shapes[0],tf.shape(self.b)[0],shapes[2]*2,shapes[3]*2])\n        else:\n            shapes = tf.stack([shapes[0],shapes[1]*2,shapes[2]*2,tf.shape(self.b)[0]])\n\n        return tf.nn.bias_add(\n            tf.nn.conv2d_transpose(input_var,self.w,output_shape=shapes,\n                                data_format=self.data_format,\n                                strides=self.strides,padding='SAME'),\n            self.b,data_format=self.data_format,name=name)\n\n"""
