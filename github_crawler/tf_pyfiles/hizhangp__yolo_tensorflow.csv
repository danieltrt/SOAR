file_path,api_count,code
test.py,3,"b'import os\r\nimport cv2\r\nimport argparse\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport yolo.config as cfg\r\nfrom yolo.yolo_net import YOLONet\r\nfrom utils.timer import Timer\r\n\r\n\r\nclass Detector(object):\r\n\r\n    def __init__(self, net, weight_file):\r\n        self.net = net\r\n        self.weights_file = weight_file\r\n\r\n        self.classes = cfg.CLASSES\r\n        self.num_class = len(self.classes)\r\n        self.image_size = cfg.IMAGE_SIZE\r\n        self.cell_size = cfg.CELL_SIZE\r\n        self.boxes_per_cell = cfg.BOXES_PER_CELL\r\n        self.threshold = cfg.THRESHOLD\r\n        self.iou_threshold = cfg.IOU_THRESHOLD\r\n        self.boundary1 = self.cell_size * self.cell_size * self.num_class\r\n        self.boundary2 = self.boundary1 +\\\r\n            self.cell_size * self.cell_size * self.boxes_per_cell\r\n\r\n        self.sess = tf.Session()\r\n        self.sess.run(tf.global_variables_initializer())\r\n\r\n        print(\'Restoring weights from: \' + self.weights_file)\r\n        self.saver = tf.train.Saver()\r\n        self.saver.restore(self.sess, self.weights_file)\r\n\r\n    def draw_result(self, img, result):\r\n        for i in range(len(result)):\r\n            x = int(result[i][1])\r\n            y = int(result[i][2])\r\n            w = int(result[i][3] / 2)\r\n            h = int(result[i][4] / 2)\r\n            cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (0, 255, 0), 2)\r\n            cv2.rectangle(img, (x - w, y - h - 20),\r\n                          (x + w, y - h), (125, 125, 125), -1)\r\n            lineType = cv2.LINE_AA if cv2.__version__ > \'3\' else cv2.CV_AA\r\n            cv2.putText(\r\n                img, result[i][0] + \' : %.2f\' % result[i][5],\r\n                (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\r\n                (0, 0, 0), 1, lineType)\r\n\r\n    def detect(self, img):\r\n        img_h, img_w, _ = img.shape\r\n        inputs = cv2.resize(img, (self.image_size, self.image_size))\r\n        inputs = cv2.cvtColor(inputs, cv2.COLOR_BGR2RGB).astype(np.float32)\r\n        inputs = (inputs / 255.0) * 2.0 - 1.0\r\n        inputs = np.reshape(inputs, (1, self.image_size, self.image_size, 3))\r\n\r\n        result = self.detect_from_cvmat(inputs)[0]\r\n\r\n        for i in range(len(result)):\r\n            result[i][1] *= (1.0 * img_w / self.image_size)\r\n            result[i][2] *= (1.0 * img_h / self.image_size)\r\n            result[i][3] *= (1.0 * img_w / self.image_size)\r\n            result[i][4] *= (1.0 * img_h / self.image_size)\r\n\r\n        return result\r\n\r\n    def detect_from_cvmat(self, inputs):\r\n        net_output = self.sess.run(self.net.logits,\r\n                                   feed_dict={self.net.images: inputs})\r\n        results = []\r\n        for i in range(net_output.shape[0]):\r\n            results.append(self.interpret_output(net_output[i]))\r\n\r\n        return results\r\n\r\n    def interpret_output(self, output):\r\n        probs = np.zeros((self.cell_size, self.cell_size,\r\n                          self.boxes_per_cell, self.num_class))\r\n        class_probs = np.reshape(\r\n            output[0:self.boundary1],\r\n            (self.cell_size, self.cell_size, self.num_class))\r\n        scales = np.reshape(\r\n            output[self.boundary1:self.boundary2],\r\n            (self.cell_size, self.cell_size, self.boxes_per_cell))\r\n        boxes = np.reshape(\r\n            output[self.boundary2:],\r\n            (self.cell_size, self.cell_size, self.boxes_per_cell, 4))\r\n        offset = np.array(\r\n            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell)\r\n        offset = np.transpose(\r\n            np.reshape(\r\n                offset,\r\n                [self.boxes_per_cell, self.cell_size, self.cell_size]),\r\n            (1, 2, 0))\r\n\r\n        boxes[:, :, :, 0] += offset\r\n        boxes[:, :, :, 1] += np.transpose(offset, (1, 0, 2))\r\n        boxes[:, :, :, :2] = 1.0 * boxes[:, :, :, 0:2] / self.cell_size\r\n        boxes[:, :, :, 2:] = np.square(boxes[:, :, :, 2:])\r\n\r\n        boxes *= self.image_size\r\n\r\n        for i in range(self.boxes_per_cell):\r\n            for j in range(self.num_class):\r\n                probs[:, :, i, j] = np.multiply(\r\n                    class_probs[:, :, j], scales[:, :, i])\r\n\r\n        filter_mat_probs = np.array(probs >= self.threshold, dtype=\'bool\')\r\n        filter_mat_boxes = np.nonzero(filter_mat_probs)\r\n        boxes_filtered = boxes[filter_mat_boxes[0],\r\n                               filter_mat_boxes[1], filter_mat_boxes[2]]\r\n        probs_filtered = probs[filter_mat_probs]\r\n        classes_num_filtered = np.argmax(\r\n            filter_mat_probs, axis=3)[\r\n            filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\r\n\r\n        argsort = np.array(np.argsort(probs_filtered))[::-1]\r\n        boxes_filtered = boxes_filtered[argsort]\r\n        probs_filtered = probs_filtered[argsort]\r\n        classes_num_filtered = classes_num_filtered[argsort]\r\n\r\n        for i in range(len(boxes_filtered)):\r\n            if probs_filtered[i] == 0:\r\n                continue\r\n            for j in range(i + 1, len(boxes_filtered)):\r\n                if self.iou(boxes_filtered[i], boxes_filtered[j]) > self.iou_threshold:\r\n                    probs_filtered[j] = 0.0\r\n\r\n        filter_iou = np.array(probs_filtered > 0.0, dtype=\'bool\')\r\n        boxes_filtered = boxes_filtered[filter_iou]\r\n        probs_filtered = probs_filtered[filter_iou]\r\n        classes_num_filtered = classes_num_filtered[filter_iou]\r\n\r\n        result = []\r\n        for i in range(len(boxes_filtered)):\r\n            result.append(\r\n                [self.classes[classes_num_filtered[i]],\r\n                 boxes_filtered[i][0],\r\n                 boxes_filtered[i][1],\r\n                 boxes_filtered[i][2],\r\n                 boxes_filtered[i][3],\r\n                 probs_filtered[i]])\r\n\r\n        return result\r\n\r\n    def iou(self, box1, box2):\r\n        tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\r\n            max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\r\n        lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\r\n            max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\r\n        inter = 0 if tb < 0 or lr < 0 else tb * lr\r\n        return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\r\n\r\n    def camera_detector(self, cap, wait=10):\r\n        detect_timer = Timer()\r\n        ret, _ = cap.read()\r\n\r\n        while ret:\r\n            ret, frame = cap.read()\r\n            detect_timer.tic()\r\n            result = self.detect(frame)\r\n            detect_timer.toc()\r\n            print(\'Average detecting time: {:.3f}s\'.format(\r\n                detect_timer.average_time))\r\n\r\n            self.draw_result(frame, result)\r\n            cv2.imshow(\'Camera\', frame)\r\n            cv2.waitKey(wait)\r\n\r\n            ret, frame = cap.read()\r\n\r\n    def image_detector(self, imname, wait=0):\r\n        detect_timer = Timer()\r\n        image = cv2.imread(imname)\r\n\r\n        detect_timer.tic()\r\n        result = self.detect(image)\r\n        detect_timer.toc()\r\n        print(\'Average detecting time: {:.3f}s\'.format(\r\n            detect_timer.average_time))\r\n\r\n        self.draw_result(image, result)\r\n        cv2.imshow(\'Image\', image)\r\n        cv2.waitKey(wait)\r\n\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\'--weights\', default=""YOLO_small.ckpt"", type=str)\r\n    parser.add_argument(\'--weight_dir\', default=\'weights\', type=str)\r\n    parser.add_argument(\'--data_dir\', default=""data"", type=str)\r\n    parser.add_argument(\'--gpu\', default=\'\', type=str)\r\n    args = parser.parse_args()\r\n\r\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = args.gpu\r\n\r\n    yolo = YOLONet(False)\r\n    weight_file = os.path.join(args.data_dir, args.weight_dir, args.weights)\r\n    detector = Detector(yolo, weight_file)\r\n\r\n    # detect from camera\r\n    # cap = cv2.VideoCapture(-1)\r\n    # detector.camera_detector(cap)\r\n\r\n    # detect from image file\r\n    imname = \'test/person.jpg\'\r\n    detector.image_detector(imname)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\r\n'"
train.py,12,"b'import os\r\nimport argparse\r\nimport datetime\r\nimport tensorflow as tf\r\nimport yolo.config as cfg\r\nfrom yolo.yolo_net import YOLONet\r\nfrom utils.timer import Timer\r\nfrom utils.pascal_voc import pascal_voc\r\n\r\nslim = tf.contrib.slim\r\n\r\n\r\nclass Solver(object):\r\n\r\n    def __init__(self, net, data):\r\n        self.net = net\r\n        self.data = data\r\n        self.weights_file = cfg.WEIGHTS_FILE\r\n        self.max_iter = cfg.MAX_ITER\r\n        self.initial_learning_rate = cfg.LEARNING_RATE\r\n        self.decay_steps = cfg.DECAY_STEPS\r\n        self.decay_rate = cfg.DECAY_RATE\r\n        self.staircase = cfg.STAIRCASE\r\n        self.summary_iter = cfg.SUMMARY_ITER\r\n        self.save_iter = cfg.SAVE_ITER\r\n        self.output_dir = os.path.join(\r\n            cfg.OUTPUT_DIR, datetime.datetime.now().strftime(\'%Y_%m_%d_%H_%M\'))\r\n        if not os.path.exists(self.output_dir):\r\n            os.makedirs(self.output_dir)\r\n        self.save_cfg()\r\n\r\n        self.variable_to_restore = tf.global_variables()\r\n        self.saver = tf.train.Saver(self.variable_to_restore, max_to_keep=None)\r\n        self.ckpt_file = os.path.join(self.output_dir, \'yolo\')\r\n        self.summary_op = tf.summary.merge_all()\r\n        self.writer = tf.summary.FileWriter(self.output_dir, flush_secs=60)\r\n\r\n        self.global_step = tf.train.create_global_step()\r\n        self.learning_rate = tf.train.exponential_decay(\r\n            self.initial_learning_rate, self.global_step, self.decay_steps,\r\n            self.decay_rate, self.staircase, name=\'learning_rate\')\r\n        self.optimizer = tf.train.GradientDescentOptimizer(\r\n            learning_rate=self.learning_rate)\r\n        self.train_op = slim.learning.create_train_op(\r\n            self.net.total_loss, self.optimizer, global_step=self.global_step)\r\n\r\n        gpu_options = tf.GPUOptions()\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        self.sess = tf.Session(config=config)\r\n        self.sess.run(tf.global_variables_initializer())\r\n\r\n        if self.weights_file is not None:\r\n            print(\'Restoring weights from: \' + self.weights_file)\r\n            self.saver.restore(self.sess, self.weights_file)\r\n\r\n        self.writer.add_graph(self.sess.graph)\r\n\r\n    def train(self):\r\n\r\n        train_timer = Timer()\r\n        load_timer = Timer()\r\n\r\n        for step in range(1, self.max_iter + 1):\r\n\r\n            load_timer.tic()\r\n            images, labels = self.data.get()\r\n            load_timer.toc()\r\n            feed_dict = {self.net.images: images,\r\n                         self.net.labels: labels}\r\n\r\n            if step % self.summary_iter == 0:\r\n                if step % (self.summary_iter * 10) == 0:\r\n\r\n                    train_timer.tic()\r\n                    summary_str, loss, _ = self.sess.run(\r\n                        [self.summary_op, self.net.total_loss, self.train_op],\r\n                        feed_dict=feed_dict)\r\n                    train_timer.toc()\r\n\r\n                    log_str = \'\'\'{} Epoch: {}, Step: {}, Learning rate: {},\'\'\'\r\n                    \'\'\' Loss: {:5.3f}\\nSpeed: {:.3f}s/iter,\'\'\'\r\n                    \'\'\'\' Load: {:.3f}s/iter, Remain: {}\'\'\'.format(\r\n                        datetime.datetime.now().strftime(\'%m-%d %H:%M:%S\'),\r\n                        self.data.epoch,\r\n                        int(step),\r\n                        round(self.learning_rate.eval(session=self.sess), 6),\r\n                        loss,\r\n                        train_timer.average_time,\r\n                        load_timer.average_time,\r\n                        train_timer.remain(step, self.max_iter))\r\n                    print(log_str)\r\n\r\n                else:\r\n                    train_timer.tic()\r\n                    summary_str, _ = self.sess.run(\r\n                        [self.summary_op, self.train_op],\r\n                        feed_dict=feed_dict)\r\n                    train_timer.toc()\r\n\r\n                self.writer.add_summary(summary_str, step)\r\n\r\n            else:\r\n                train_timer.tic()\r\n                self.sess.run(self.train_op, feed_dict=feed_dict)\r\n                train_timer.toc()\r\n\r\n            if step % self.save_iter == 0:\r\n                print(\'{} Saving checkpoint file to: {}\'.format(\r\n                    datetime.datetime.now().strftime(\'%m-%d %H:%M:%S\'),\r\n                    self.output_dir))\r\n                self.saver.save(\r\n                    self.sess, self.ckpt_file, global_step=self.global_step)\r\n\r\n    def save_cfg(self):\r\n\r\n        with open(os.path.join(self.output_dir, \'config.txt\'), \'w\') as f:\r\n            cfg_dict = cfg.__dict__\r\n            for key in sorted(cfg_dict.keys()):\r\n                if key[0].isupper():\r\n                    cfg_str = \'{}: {}\\n\'.format(key, cfg_dict[key])\r\n                    f.write(cfg_str)\r\n\r\n\r\ndef update_config_paths(data_dir, weights_file):\r\n    cfg.DATA_PATH = data_dir\r\n    cfg.PASCAL_PATH = os.path.join(data_dir, \'pascal_voc\')\r\n    cfg.CACHE_PATH = os.path.join(cfg.PASCAL_PATH, \'cache\')\r\n    cfg.OUTPUT_DIR = os.path.join(cfg.PASCAL_PATH, \'output\')\r\n    cfg.WEIGHTS_DIR = os.path.join(cfg.PASCAL_PATH, \'weights\')\r\n\r\n    cfg.WEIGHTS_FILE = os.path.join(cfg.WEIGHTS_DIR, weights_file)\r\n\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\'--weights\', default=""YOLO_small.ckpt"", type=str)\r\n    parser.add_argument(\'--data_dir\', default=""data"", type=str)\r\n    parser.add_argument(\'--threshold\', default=0.2, type=float)\r\n    parser.add_argument(\'--iou_threshold\', default=0.5, type=float)\r\n    parser.add_argument(\'--gpu\', default=\'\', type=str)\r\n    args = parser.parse_args()\r\n\r\n    if args.gpu is not None:\r\n        cfg.GPU = args.gpu\r\n\r\n    if args.data_dir != cfg.DATA_PATH:\r\n        update_config_paths(args.data_dir, args.weights)\r\n\r\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = cfg.GPU\r\n\r\n    yolo = YOLONet()\r\n    pascal = pascal_voc(\'train\')\r\n\r\n    solver = Solver(yolo, pascal)\r\n\r\n    print(\'Start training ...\')\r\n    solver.train()\r\n    print(\'Done training.\')\r\n\r\n\r\nif __name__ == \'__main__\':\r\n\r\n    # python train.py --weights YOLO_small.ckpt --gpu 0\r\n    main()\r\n'"
utils/__init__.py,0,b''
utils/pascal_voc.py,0,"b'import os\nimport xml.etree.ElementTree as ET\nimport numpy as np\nimport cv2\nimport pickle\nimport copy\nimport yolo.config as cfg\n\n\nclass pascal_voc(object):\n    def __init__(self, phase, rebuild=False):\n        self.devkil_path = os.path.join(cfg.PASCAL_PATH, \'VOCdevkit\')\n        self.data_path = os.path.join(self.devkil_path, \'VOC2007\')\n        self.cache_path = cfg.CACHE_PATH\n        self.batch_size = cfg.BATCH_SIZE\n        self.image_size = cfg.IMAGE_SIZE\n        self.cell_size = cfg.CELL_SIZE\n        self.classes = cfg.CLASSES\n        self.class_to_ind = dict(zip(self.classes, range(len(self.classes))))\n        self.flipped = cfg.FLIPPED\n        self.phase = phase\n        self.rebuild = rebuild\n        self.cursor = 0\n        self.epoch = 1\n        self.gt_labels = None\n        self.prepare()\n\n    def get(self):\n        images = np.zeros(\n            (self.batch_size, self.image_size, self.image_size, 3))\n        labels = np.zeros(\n            (self.batch_size, self.cell_size, self.cell_size, 25))\n        count = 0\n        while count < self.batch_size:\n            imname = self.gt_labels[self.cursor][\'imname\']\n            flipped = self.gt_labels[self.cursor][\'flipped\']\n            images[count, :, :, :] = self.image_read(imname, flipped)\n            labels[count, :, :, :] = self.gt_labels[self.cursor][\'label\']\n            count += 1\n            self.cursor += 1\n            if self.cursor >= len(self.gt_labels):\n                np.random.shuffle(self.gt_labels)\n                self.cursor = 0\n                self.epoch += 1\n        return images, labels\n\n    def image_read(self, imname, flipped=False):\n        image = cv2.imread(imname)\n        image = cv2.resize(image, (self.image_size, self.image_size))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image = (image / 255.0) * 2.0 - 1.0\n        if flipped:\n            image = image[:, ::-1, :]\n        return image\n\n    def prepare(self):\n        gt_labels = self.load_labels()\n        if self.flipped:\n            print(\'Appending horizontally-flipped training examples ...\')\n            gt_labels_cp = copy.deepcopy(gt_labels)\n            for idx in range(len(gt_labels_cp)):\n                gt_labels_cp[idx][\'flipped\'] = True\n                gt_labels_cp[idx][\'label\'] =\\\n                    gt_labels_cp[idx][\'label\'][:, ::-1, :]\n                for i in range(self.cell_size):\n                    for j in range(self.cell_size):\n                        if gt_labels_cp[idx][\'label\'][i, j, 0] == 1:\n                            gt_labels_cp[idx][\'label\'][i, j, 1] = \\\n                                self.image_size - 1 -\\\n                                gt_labels_cp[idx][\'label\'][i, j, 1]\n            gt_labels += gt_labels_cp\n        np.random.shuffle(gt_labels)\n        self.gt_labels = gt_labels\n        return gt_labels\n\n    def load_labels(self):\n        cache_file = os.path.join(\n            self.cache_path, \'pascal_\' + self.phase + \'_gt_labels.pkl\')\n\n        if os.path.isfile(cache_file) and not self.rebuild:\n            print(\'Loading gt_labels from: \' + cache_file)\n            with open(cache_file, \'rb\') as f:\n                gt_labels = pickle.load(f)\n            return gt_labels\n\n        print(\'Processing gt_labels from: \' + self.data_path)\n\n        if not os.path.exists(self.cache_path):\n            os.makedirs(self.cache_path)\n\n        if self.phase == \'train\':\n            txtname = os.path.join(\n                self.data_path, \'ImageSets\', \'Main\', \'trainval.txt\')\n        else:\n            txtname = os.path.join(\n                self.data_path, \'ImageSets\', \'Main\', \'test.txt\')\n        with open(txtname, \'r\') as f:\n            self.image_index = [x.strip() for x in f.readlines()]\n\n        gt_labels = []\n        for index in self.image_index:\n            label, num = self.load_pascal_annotation(index)\n            if num == 0:\n                continue\n            imname = os.path.join(self.data_path, \'JPEGImages\', index + \'.jpg\')\n            gt_labels.append({\'imname\': imname,\n                              \'label\': label,\n                              \'flipped\': False})\n        print(\'Saving gt_labels to: \' + cache_file)\n        with open(cache_file, \'wb\') as f:\n            pickle.dump(gt_labels, f)\n        return gt_labels\n\n    def load_pascal_annotation(self, index):\n        """"""\n        Load image and bounding boxes info from XML file in the PASCAL VOC\n        format.\n        """"""\n\n        imname = os.path.join(self.data_path, \'JPEGImages\', index + \'.jpg\')\n        im = cv2.imread(imname)\n        h_ratio = 1.0 * self.image_size / im.shape[0]\n        w_ratio = 1.0 * self.image_size / im.shape[1]\n        # im = cv2.resize(im, [self.image_size, self.image_size])\n\n        label = np.zeros((self.cell_size, self.cell_size, 25))\n        filename = os.path.join(self.data_path, \'Annotations\', index + \'.xml\')\n        tree = ET.parse(filename)\n        objs = tree.findall(\'object\')\n\n        for obj in objs:\n            bbox = obj.find(\'bndbox\')\n            # Make pixel indexes 0-based\n            x1 = max(min((float(bbox.find(\'xmin\').text) - 1) * w_ratio, self.image_size - 1), 0)\n            y1 = max(min((float(bbox.find(\'ymin\').text) - 1) * h_ratio, self.image_size - 1), 0)\n            x2 = max(min((float(bbox.find(\'xmax\').text) - 1) * w_ratio, self.image_size - 1), 0)\n            y2 = max(min((float(bbox.find(\'ymax\').text) - 1) * h_ratio, self.image_size - 1), 0)\n            cls_ind = self.class_to_ind[obj.find(\'name\').text.lower().strip()]\n            boxes = [(x2 + x1) / 2.0, (y2 + y1) / 2.0, x2 - x1, y2 - y1]\n            x_ind = int(boxes[0] * self.cell_size / self.image_size)\n            y_ind = int(boxes[1] * self.cell_size / self.image_size)\n            if label[y_ind, x_ind, 0] == 1:\n                continue\n            label[y_ind, x_ind, 0] = 1\n            label[y_ind, x_ind, 1:5] = boxes\n            label[y_ind, x_ind, 5 + cls_ind] = 1\n\n        return label, len(objs)\n'"
utils/timer.py,0,"b""import time\r\nimport datetime\r\n\r\n\r\nclass Timer(object):\r\n    '''\r\n    A simple timer.\r\n    '''\r\n\r\n    def __init__(self):\r\n        self.init_time = time.time()\r\n        self.total_time = 0.\r\n        self.calls = 0\r\n        self.start_time = 0.\r\n        self.diff = 0.\r\n        self.average_time = 0.\r\n        self.remain_time = 0.\r\n\r\n    def tic(self):\r\n        # using time.time instead of time.clock because time time.clock\r\n        # does not normalize for multithreading\r\n        self.start_time = time.time()\r\n\r\n    def toc(self, average=True):\r\n        self.diff = time.time() - self.start_time\r\n        self.total_time += self.diff\r\n        self.calls += 1\r\n        self.average_time = self.total_time / self.calls\r\n        if average:\r\n            return self.average_time\r\n        else:\r\n            return self.diff\r\n\r\n    def remain(self, iters, max_iters):\r\n        if iters == 0:\r\n            self.remain_time = 0\r\n        else:\r\n            self.remain_time = (time.time() - self.init_time) * \\\r\n                (max_iters - iters) / iters\r\n        return str(datetime.timedelta(seconds=int(self.remain_time)))\r\n"""
yolo/__init__.py,0,b''
yolo/config.py,0,"b""import os\r\n\r\n#\r\n# path and dataset parameter\r\n#\r\n\r\nDATA_PATH = 'data'\r\n\r\nPASCAL_PATH = os.path.join(DATA_PATH, 'pascal_voc')\r\n\r\nCACHE_PATH = os.path.join(PASCAL_PATH, 'cache')\r\n\r\nOUTPUT_DIR = os.path.join(PASCAL_PATH, 'output')\r\n\r\nWEIGHTS_DIR = os.path.join(PASCAL_PATH, 'weights')\r\n\r\nWEIGHTS_FILE = None\r\n# WEIGHTS_FILE = os.path.join(DATA_PATH, 'weights', 'YOLO_small.ckpt')\r\n\r\nCLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\r\n           'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\r\n           'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\r\n           'train', 'tvmonitor']\r\n\r\nFLIPPED = True\r\n\r\n\r\n#\r\n# model parameter\r\n#\r\n\r\nIMAGE_SIZE = 448\r\n\r\nCELL_SIZE = 7\r\n\r\nBOXES_PER_CELL = 2\r\n\r\nALPHA = 0.1\r\n\r\nDISP_CONSOLE = False\r\n\r\nOBJECT_SCALE = 1.0\r\nNOOBJECT_SCALE = 1.0\r\nCLASS_SCALE = 2.0\r\nCOORD_SCALE = 5.0\r\n\r\n\r\n#\r\n# solver parameter\r\n#\r\n\r\nGPU = ''\r\n\r\nLEARNING_RATE = 0.0001\r\n\r\nDECAY_STEPS = 30000\r\n\r\nDECAY_RATE = 0.1\r\n\r\nSTAIRCASE = True\r\n\r\nBATCH_SIZE = 45\r\n\r\nMAX_ITER = 15000\r\n\r\nSUMMARY_ITER = 10\r\n\r\nSAVE_ITER = 1000\r\n\r\n\r\n#\r\n# test parameter\r\n#\r\n\r\nTHRESHOLD = 0.2\r\n\r\nIOU_THRESHOLD = 0.5\r\n"""
yolo/yolo_net.py,65,"b'import numpy as np\nimport tensorflow as tf\nimport yolo.config as cfg\n\nslim = tf.contrib.slim\n\n\nclass YOLONet(object):\n\n    def __init__(self, is_training=True):\n        self.classes = cfg.CLASSES\n        self.num_class = len(self.classes)\n        self.image_size = cfg.IMAGE_SIZE\n        self.cell_size = cfg.CELL_SIZE\n        self.boxes_per_cell = cfg.BOXES_PER_CELL\n        self.output_size = (self.cell_size * self.cell_size) *\\\n            (self.num_class + self.boxes_per_cell * 5)\n        self.scale = 1.0 * self.image_size / self.cell_size\n        self.boundary1 = self.cell_size * self.cell_size * self.num_class\n        self.boundary2 = self.boundary1 +\\\n            self.cell_size * self.cell_size * self.boxes_per_cell\n\n        self.object_scale = cfg.OBJECT_SCALE\n        self.noobject_scale = cfg.NOOBJECT_SCALE\n        self.class_scale = cfg.CLASS_SCALE\n        self.coord_scale = cfg.COORD_SCALE\n\n        self.learning_rate = cfg.LEARNING_RATE\n        self.batch_size = cfg.BATCH_SIZE\n        self.alpha = cfg.ALPHA\n\n        self.offset = np.transpose(np.reshape(np.array(\n            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell),\n            (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0))\n\n        self.images = tf.placeholder(\n            tf.float32, [None, self.image_size, self.image_size, 3],\n            name=\'images\')\n        self.logits = self.build_network(\n            self.images, num_outputs=self.output_size, alpha=self.alpha,\n            is_training=is_training)\n\n        if is_training:\n            self.labels = tf.placeholder(\n                tf.float32,\n                [None, self.cell_size, self.cell_size, 5 + self.num_class])\n            self.loss_layer(self.logits, self.labels)\n            self.total_loss = tf.losses.get_total_loss()\n            tf.summary.scalar(\'total_loss\', self.total_loss)\n\n    def build_network(self,\n                      images,\n                      num_outputs,\n                      alpha,\n                      keep_prob=0.5,\n                      is_training=True,\n                      scope=\'yolo\'):\n        with tf.variable_scope(scope):\n            with slim.arg_scope(\n                [slim.conv2d, slim.fully_connected],\n                activation_fn=leaky_relu(alpha),\n                weights_regularizer=slim.l2_regularizer(0.0005),\n                weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)\n            ):\n                net = tf.pad(\n                    images, np.array([[0, 0], [3, 3], [3, 3], [0, 0]]),\n                    name=\'pad_1\')\n                net = slim.conv2d(\n                    net, 64, 7, 2, padding=\'VALID\', scope=\'conv_2\')\n                net = slim.max_pool2d(net, 2, padding=\'SAME\', scope=\'pool_3\')\n                net = slim.conv2d(net, 192, 3, scope=\'conv_4\')\n                net = slim.max_pool2d(net, 2, padding=\'SAME\', scope=\'pool_5\')\n                net = slim.conv2d(net, 128, 1, scope=\'conv_6\')\n                net = slim.conv2d(net, 256, 3, scope=\'conv_7\')\n                net = slim.conv2d(net, 256, 1, scope=\'conv_8\')\n                net = slim.conv2d(net, 512, 3, scope=\'conv_9\')\n                net = slim.max_pool2d(net, 2, padding=\'SAME\', scope=\'pool_10\')\n                net = slim.conv2d(net, 256, 1, scope=\'conv_11\')\n                net = slim.conv2d(net, 512, 3, scope=\'conv_12\')\n                net = slim.conv2d(net, 256, 1, scope=\'conv_13\')\n                net = slim.conv2d(net, 512, 3, scope=\'conv_14\')\n                net = slim.conv2d(net, 256, 1, scope=\'conv_15\')\n                net = slim.conv2d(net, 512, 3, scope=\'conv_16\')\n                net = slim.conv2d(net, 256, 1, scope=\'conv_17\')\n                net = slim.conv2d(net, 512, 3, scope=\'conv_18\')\n                net = slim.conv2d(net, 512, 1, scope=\'conv_19\')\n                net = slim.conv2d(net, 1024, 3, scope=\'conv_20\')\n                net = slim.max_pool2d(net, 2, padding=\'SAME\', scope=\'pool_21\')\n                net = slim.conv2d(net, 512, 1, scope=\'conv_22\')\n                net = slim.conv2d(net, 1024, 3, scope=\'conv_23\')\n                net = slim.conv2d(net, 512, 1, scope=\'conv_24\')\n                net = slim.conv2d(net, 1024, 3, scope=\'conv_25\')\n                net = slim.conv2d(net, 1024, 3, scope=\'conv_26\')\n                net = tf.pad(\n                    net, np.array([[0, 0], [1, 1], [1, 1], [0, 0]]),\n                    name=\'pad_27\')\n                net = slim.conv2d(\n                    net, 1024, 3, 2, padding=\'VALID\', scope=\'conv_28\')\n                net = slim.conv2d(net, 1024, 3, scope=\'conv_29\')\n                net = slim.conv2d(net, 1024, 3, scope=\'conv_30\')\n                net = tf.transpose(net, [0, 3, 1, 2], name=\'trans_31\')\n                net = slim.flatten(net, scope=\'flat_32\')\n                net = slim.fully_connected(net, 512, scope=\'fc_33\')\n                net = slim.fully_connected(net, 4096, scope=\'fc_34\')\n                net = slim.dropout(\n                    net, keep_prob=keep_prob, is_training=is_training,\n                    scope=\'dropout_35\')\n                net = slim.fully_connected(\n                    net, num_outputs, activation_fn=None, scope=\'fc_36\')\n        return net\n\n    def calc_iou(self, boxes1, boxes2, scope=\'iou\'):\n        """"""calculate ious\n        Args:\n          boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n          boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n        Return:\n          iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n        """"""\n        with tf.variable_scope(scope):\n            # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n            boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n                                 boxes1[..., 1] - boxes1[..., 3] / 2.0,\n                                 boxes1[..., 0] + boxes1[..., 2] / 2.0,\n                                 boxes1[..., 1] + boxes1[..., 3] / 2.0],\n                                axis=-1)\n\n            boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n                                 boxes2[..., 1] - boxes2[..., 3] / 2.0,\n                                 boxes2[..., 0] + boxes2[..., 2] / 2.0,\n                                 boxes2[..., 1] + boxes2[..., 3] / 2.0],\n                                axis=-1)\n\n            # calculate the left up point & right down point\n            lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n            rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n\n            # intersection\n            intersection = tf.maximum(0.0, rd - lu)\n            inter_square = intersection[..., 0] * intersection[..., 1]\n\n            # calculate the boxs1 square and boxs2 square\n            square1 = boxes1[..., 2] * boxes1[..., 3]\n            square2 = boxes2[..., 2] * boxes2[..., 3]\n\n            union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n\n        return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n\n    def loss_layer(self, predicts, labels, scope=\'loss_layer\'):\n        with tf.variable_scope(scope):\n            predict_classes = tf.reshape(\n                predicts[:, :self.boundary1],\n                [self.batch_size, self.cell_size, self.cell_size, self.num_class])\n            predict_scales = tf.reshape(\n                predicts[:, self.boundary1:self.boundary2],\n                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell])\n            predict_boxes = tf.reshape(\n                predicts[:, self.boundary2:],\n                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell, 4])\n\n            response = tf.reshape(\n                labels[..., 0],\n                [self.batch_size, self.cell_size, self.cell_size, 1])\n            boxes = tf.reshape(\n                labels[..., 1:5],\n                [self.batch_size, self.cell_size, self.cell_size, 1, 4])\n            boxes = tf.tile(\n                boxes, [1, 1, 1, self.boxes_per_cell, 1]) / self.image_size\n            classes = labels[..., 5:]\n\n            offset = tf.reshape(\n                tf.constant(self.offset, dtype=tf.float32),\n                [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n            offset = tf.tile(offset, [self.batch_size, 1, 1, 1])\n            offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n            predict_boxes_tran = tf.stack(\n                [(predict_boxes[..., 0] + offset) / self.cell_size,\n                 (predict_boxes[..., 1] + offset_tran) / self.cell_size,\n                 tf.square(predict_boxes[..., 2]),\n                 tf.square(predict_boxes[..., 3])], axis=-1)\n\n            iou_predict_truth = self.calc_iou(predict_boxes_tran, boxes)\n\n            # calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n            object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n            object_mask = tf.cast(\n                (iou_predict_truth >= object_mask), tf.float32) * response\n\n            # calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n            noobject_mask = tf.ones_like(\n                object_mask, dtype=tf.float32) - object_mask\n\n            boxes_tran = tf.stack(\n                [boxes[..., 0] * self.cell_size - offset,\n                 boxes[..., 1] * self.cell_size - offset_tran,\n                 tf.sqrt(boxes[..., 2]),\n                 tf.sqrt(boxes[..., 3])], axis=-1)\n\n            # class_loss\n            class_delta = response * (predict_classes - classes)\n            class_loss = tf.reduce_mean(\n                tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]),\n                name=\'class_loss\') * self.class_scale\n\n            # object_loss\n            object_delta = object_mask * (predict_scales - iou_predict_truth)\n            object_loss = tf.reduce_mean(\n                tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]),\n                name=\'object_loss\') * self.object_scale\n\n            # noobject_loss\n            noobject_delta = noobject_mask * predict_scales\n            noobject_loss = tf.reduce_mean(\n                tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]),\n                name=\'noobject_loss\') * self.noobject_scale\n\n            # coord_loss\n            coord_mask = tf.expand_dims(object_mask, 4)\n            boxes_delta = coord_mask * (predict_boxes - boxes_tran)\n            coord_loss = tf.reduce_mean(\n                tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]),\n                name=\'coord_loss\') * self.coord_scale\n\n            tf.losses.add_loss(class_loss)\n            tf.losses.add_loss(object_loss)\n            tf.losses.add_loss(noobject_loss)\n            tf.losses.add_loss(coord_loss)\n\n            tf.summary.scalar(\'class_loss\', class_loss)\n            tf.summary.scalar(\'object_loss\', object_loss)\n            tf.summary.scalar(\'noobject_loss\', noobject_loss)\n            tf.summary.scalar(\'coord_loss\', coord_loss)\n\n            tf.summary.histogram(\'boxes_delta_x\', boxes_delta[..., 0])\n            tf.summary.histogram(\'boxes_delta_y\', boxes_delta[..., 1])\n            tf.summary.histogram(\'boxes_delta_w\', boxes_delta[..., 2])\n            tf.summary.histogram(\'boxes_delta_h\', boxes_delta[..., 3])\n            tf.summary.histogram(\'iou\', iou_predict_truth)\n\n\ndef leaky_relu(alpha):\n    def op(inputs):\n        return tf.nn.leaky_relu(inputs, alpha=alpha, name=\'leaky_relu\')\n    return op\n'"
