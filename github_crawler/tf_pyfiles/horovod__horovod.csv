file_path,api_count,code
setup.py,8,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport re\nimport shlex\nimport subprocess\nimport sys\nimport textwrap\nimport traceback\nimport pipes\nimport warnings\nfrom copy import deepcopy\nfrom distutils.errors import CompileError, DistutilsError, \\\n    DistutilsPlatformError, LinkError\nfrom distutils.sysconfig import customize_compiler\nfrom distutils.version import LooseVersion\n\nfrom setuptools import setup, Extension, find_packages\nfrom setuptools.command.build_ext import build_ext\n\nfrom horovod import __version__\nfrom horovod.common.util import env\n\n\nclass CMakeExtension(Extension):\n    def __init__(self, name, cmake_lists_dir=\'.\', sources=[], **kwa):\n        Extension.__init__(self, name, sources=sources, **kwa)\n        self.cmake_lists_dir = os.path.abspath(cmake_lists_dir)\n\n\ntensorflow_mpi_lib = Extension(\'horovod.tensorflow.mpi_lib\', [])\ntorch_mpi_lib = Extension(\'horovod.torch.mpi_lib\', [])\ntorch_mpi_lib_impl = Extension(\'horovod.torch.mpi_lib_impl\', [])\ntorch_mpi_lib_v2 = Extension(\'horovod.torch.mpi_lib_v2\', [])\nmxnet_mpi_lib = Extension(\'horovod.mxnet.mpi_lib\', [])\ngloo_lib = CMakeExtension(\'gloo\', cmake_lists_dir=\'third_party/gloo\',\n                          sources=[])\n\nccl_root = os.environ.get(\'CCL_ROOT\')\nhave_ccl = ccl_root is not None\n\n\ndef is_build_action():\n    if len(sys.argv) <= 1:\n        return False\n\n    if sys.argv[1].startswith(\'build\'):\n        return True\n\n    if sys.argv[1].startswith(\'bdist\'):\n        return True\n\n    if sys.argv[1].startswith(\'install\'):\n        return True\n\n\ndef check_tf_version():\n    try:\n        import tensorflow as tf\n        if LooseVersion(tf.__version__) < LooseVersion(\'1.1.0\'):\n            raise DistutilsPlatformError(\n                \'Your TensorFlow version %s is outdated.  \'\n                \'Horovod requires tensorflow>=1.1.0\' % tf.__version__)\n    except ImportError:\n        raise DistutilsPlatformError(\n            \'import tensorflow failed, is it installed?\\n\\n%s\' % traceback.format_exc())\n    except AttributeError:\n        # This means that tf.__version__ was not exposed, which makes it *REALLY* old.\n        raise DistutilsPlatformError(\n            \'Your TensorFlow version is outdated.  Horovod requires tensorflow>=1.1.0\')\n\n\ndef check_mx_version():\n    try:\n        import mxnet as mx\n        if mx.__version__ < \'1.4.0\':\n            raise DistutilsPlatformError(\n                \'Your MXNet version %s is outdated.  \'\n                \'Horovod requires mxnet>=1.4.0\' % mx.__version__)\n    except ImportError:\n        raise DistutilsPlatformError(\n            \'import mxnet failed, is it installed?\\n\\n%s\' % traceback.format_exc())\n    except AttributeError:\n        raise DistutilsPlatformError(\n            \'Your MXNet version is outdated.  Horovod requires mxnet>1.3.0\')\n\n\ndef get_supported_instruction_set_flags(flags_to_check):\n    supported = []\n    try:\n        flags_output = subprocess.check_output(\n            \'gcc -march=native -E -v - </dev/null 2>&1 | grep cc1\',\n            shell=True, universal_newlines=True).strip()\n        flags = shlex.split(flags_output)\n        supported = [x for x in flags_to_check if x in flags or x.replace(\'-m\', \'+\') in flags]\n    except subprocess.CalledProcessError:\n        # Fallback to no advanced instruction set flags if were not able to get flag information.\n        pass\n    return supported\n\n\ndef get_cpp_flags(build_ext):\n    last_err = None\n    default_flags = [\'-std=c++11\', \'-fPIC\', \'-O3\', \'-Wall\', \'-fassociative-math\', \'-ffast-math\', \'-ftree-vectorize\', \'-funsafe-math-optimizations\']\n    build_arch_flags_env = os.environ.get(\'HOROVOD_BUILD_ARCH_FLAGS\')\n    build_arch_flags = get_supported_instruction_set_flags([\'-mf16c\', \'-mavx\', \'-mfma\']) if build_arch_flags_env is None else build_arch_flags_env.split()\n    if sys.platform == \'darwin\':\n        # Darwin most likely will have Clang, which has libc++.\n        flags_to_try = [default_flags + [\'-stdlib=libc++\'] + build_arch_flags,\n                        default_flags + build_arch_flags,\n                        default_flags + [\'-stdlib=libc++\'],\n                        default_flags]\n    else:\n        flags_to_try = [default_flags + build_arch_flags,\n                        default_flags + [\'-stdlib=libc++\'] + build_arch_flags,\n                        default_flags,\n                        default_flags + [\'-stdlib=libc++\']]\n    for cpp_flags in flags_to_try:\n        try:\n            test_compile(build_ext, \'test_cpp_flags\',\n                         extra_compile_preargs=cpp_flags,\n                         code=textwrap.dedent(\'\'\'\\\n                    #include <unordered_map>\n                    void test() {\n                    }\n                    \'\'\'))\n\n            return cpp_flags\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine C++ compilation flags (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine C++ compilation flags.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_link_flags(build_ext):\n    last_err = None\n    libtool_flags = [\'-Wl,-exported_symbols_list,horovod.exp\']\n    ld_flags = [\'-Wl,--version-script=horovod.lds\']\n    if sys.platform == \'darwin\':\n        flags_to_try = [libtool_flags, ld_flags]\n    else:\n        flags_to_try = [ld_flags, libtool_flags]\n    for link_flags in flags_to_try:\n        try:\n            test_compile(build_ext, \'test_link_flags\',\n                         extra_link_preargs=link_flags,\n                         code=textwrap.dedent(\'\'\'\\\n                    void test() {\n                    }\n                    \'\'\'))\n\n            return link_flags\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine C++ link flags (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine C++ link flags.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_tf_include_dirs():\n    import tensorflow as tf\n    tf_inc = tf.sysconfig.get_include()\n    return [tf_inc, \'%s/external/nsync/public\' % tf_inc]\n\n\ndef get_tf_lib_dirs():\n    import tensorflow as tf\n    tf_lib = tf.sysconfig.get_lib()\n    return [tf_lib]\n\n\ndef get_tf_libs(build_ext, lib_dirs, cpp_flags):\n    last_err = None\n    for tf_libs in [[\'tensorflow_framework\'], []]:\n        try:\n            lib_file = test_compile(build_ext, \'test_tensorflow_libs\',\n                                    library_dirs=lib_dirs, libraries=tf_libs,\n                                    extra_compile_preargs=cpp_flags,\n                                    code=textwrap.dedent(\'\'\'\\\n                    void test() {\n                    }\n                    \'\'\'))\n\n            from tensorflow.python.framework import load_library\n            load_library.load_op_library(lib_file)\n\n            return tf_libs\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine -l link flags to use with TensorFlow (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine -l link flags to use with TensorFlow.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_tf_abi(build_ext, include_dirs, lib_dirs, libs, cpp_flags):\n    last_err = None\n    cxx11_abi_macro = \'_GLIBCXX_USE_CXX11_ABI\'\n    for cxx11_abi in [\'0\', \'1\']:\n        try:\n            lib_file = test_compile(build_ext, \'test_tensorflow_abi\',\n                                    macros=[(cxx11_abi_macro, cxx11_abi)],\n                                    include_dirs=include_dirs,\n                                    library_dirs=lib_dirs,\n                                    libraries=libs,\n                                    extra_compile_preargs=cpp_flags,\n                                    code=textwrap.dedent(\'\'\'\\\n                #include <string>\n                #include ""tensorflow/core/framework/op.h""\n                #include ""tensorflow/core/framework/op_kernel.h""\n                #include ""tensorflow/core/framework/shape_inference.h""\n                void test() {\n                    auto ignore = tensorflow::strings::StrCat(""a"", ""b"");\n                }\n                \'\'\'))\n\n            from tensorflow.python.framework import load_library\n            load_library.load_op_library(lib_file)\n\n            return cxx11_abi_macro, cxx11_abi\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine CXX11 ABI to use with TensorFlow (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine CXX11 ABI to use with TensorFlow.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_tf_flags(build_ext, cpp_flags):\n    import tensorflow as tf\n    try:\n        return tf.sysconfig.get_compile_flags(), tf.sysconfig.get_link_flags()\n    except AttributeError:\n        # fallback to the previous logic\n        tf_include_dirs = get_tf_include_dirs()\n        tf_lib_dirs = get_tf_lib_dirs()\n        tf_libs = get_tf_libs(build_ext, tf_lib_dirs, cpp_flags)\n        tf_abi = get_tf_abi(build_ext, tf_include_dirs,\n                            tf_lib_dirs, tf_libs, cpp_flags)\n\n        compile_flags = []\n        for include_dir in tf_include_dirs:\n            compile_flags.append(\'-I%s\' % include_dir)\n        if tf_abi:\n            compile_flags.append(\'-D%s=%s\' % tf_abi)\n\n        link_flags = []\n        for lib_dir in tf_lib_dirs:\n            link_flags.append(\'-L%s\' % lib_dir)\n        for lib in tf_libs:\n            link_flags.append(\'-l%s\' % lib)\n\n        return compile_flags, link_flags\n\n\ndef get_mx_include_dirs():\n    import mxnet as mx\n    return [mx.libinfo.find_include_path()]\n\n\ndef get_mx_lib_dirs():\n    import mxnet as mx\n    mx_libs = mx.libinfo.find_lib_path()\n    mx_lib_dirs = [os.path.dirname(mx_lib) for mx_lib in mx_libs]\n    return mx_lib_dirs\n\n\ndef get_mx_libs(build_ext, lib_dirs, cpp_flags):\n    last_err = None\n    for mx_libs in [[\'mxnet\'], []]:\n        try:\n            lib_file = test_compile(build_ext, \'test_mx_libs\',\n                                    library_dirs=lib_dirs, libraries=mx_libs,\n                                    extra_compile_preargs=cpp_flags,\n                                    code=textwrap.dedent(\'\'\'\\\n                    void test() {\n                    }\n                    \'\'\'))\n\n            return mx_libs\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine -l link flags to use with MXNet (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine -l link flags to use with MXNet.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_mx_flags(build_ext, cpp_flags):\n    mx_include_dirs = get_mx_include_dirs()\n    mx_lib_dirs = get_mx_lib_dirs()\n    mx_libs = get_mx_libs(build_ext, mx_lib_dirs, cpp_flags)\n\n    compile_flags = []\n    has_mkldnn = is_mx_mkldnn()\n    for include_dir in mx_include_dirs:\n        compile_flags.append(\'-I%s\' % include_dir)\n        if has_mkldnn:\n            mkldnn_include = os.path.join(include_dir, \'mkldnn\')\n            compile_flags.append(\'-I%s\' % mkldnn_include)\n\n    link_flags = []\n    for lib_dir in mx_lib_dirs:\n        link_flags.append(\'-Wl,-rpath,%s\' % lib_dir)\n        link_flags.append(\'-L%s\' % lib_dir)\n\n    for lib in mx_libs:\n        link_flags.append(\'-l%s\' % lib)\n\n    return compile_flags, link_flags\n\n\ndef get_mpi_flags():\n    show_command = os.environ.get(\'HOROVOD_MPICXX_SHOW\', \'mpicxx -show\')\n    try:\n        mpi_show_output = subprocess.check_output(\n            shlex.split(show_command), universal_newlines=True).strip()\n        mpi_show_args = shlex.split(mpi_show_output)\n        if not mpi_show_args[0].startswith(\'-\'):\n            # Open MPI and MPICH print compiler name as a first word, skip it\n            mpi_show_args = mpi_show_args[1:]\n        # strip off compiler call portion and always escape each arg\n        return \' \'.join([\'""\' + arg.replace(\'""\', \'""\\\'""\\\'""\') + \'""\'\n                         for arg in mpi_show_args])\n    except Exception:\n        raise DistutilsPlatformError(\n            \'%s failed (see error below), is MPI in $PATH?\\n\'\n            \'Note: If your version of MPI has a custom command to show compilation flags, \'\n            \'please specify it with the HOROVOD_MPICXX_SHOW environment variable.\\n\\n\'\n            \'%s\' % (show_command, traceback.format_exc()))\n\n\ndef test_compile(build_ext, name, code, libraries=None, include_dirs=None,\n                 library_dirs=None,\n                 macros=None, extra_compile_preargs=None,\n                 extra_link_preargs=None):\n    test_compile_dir = os.path.join(build_ext.build_temp, \'test_compile\')\n    if not os.path.exists(test_compile_dir):\n        os.makedirs(test_compile_dir)\n\n    source_file = os.path.join(test_compile_dir, \'%s.cc\' % name)\n    with open(source_file, \'w\') as f:\n        f.write(code)\n\n    compiler = build_ext.compiler\n    [object_file] = compiler.object_filenames([source_file])\n    shared_object_file = compiler.shared_object_filename(\n        name, output_dir=test_compile_dir)\n\n    compiler.compile([source_file], extra_preargs=extra_compile_preargs,\n                     include_dirs=include_dirs, macros=macros)\n    compiler.link_shared_object(\n        [object_file], shared_object_file, libraries=libraries,\n        library_dirs=library_dirs,\n        extra_preargs=extra_link_preargs)\n\n    return shared_object_file\n\n\ndef get_cuda_dirs(build_ext, cpp_flags):\n    cuda_include_dirs = []\n    cuda_lib_dirs = []\n\n    cuda_home = os.environ.get(\'HOROVOD_CUDA_HOME\')\n    if cuda_home:\n        cuda_include_dirs += [\'%s/include\' % cuda_home]\n        cuda_lib_dirs += [\'%s/lib\' % cuda_home, \'%s/lib64\' % cuda_home]\n\n    cuda_include = os.environ.get(\'HOROVOD_CUDA_INCLUDE\')\n    if cuda_include:\n        cuda_include_dirs += [cuda_include]\n\n    cuda_lib = os.environ.get(\'HOROVOD_CUDA_LIB\')\n    if cuda_lib:\n        cuda_lib_dirs += [cuda_lib]\n\n    if not cuda_include_dirs and not cuda_lib_dirs:\n        # default to /usr/local/cuda\n        cuda_include_dirs += [\'/usr/local/cuda/include\']\n        cuda_lib_dirs += [\'/usr/local/cuda/lib\', \'/usr/local/cuda/lib64\']\n\n    try:\n        test_compile(build_ext, \'test_cuda\', libraries=[\'cudart\'],\n                     include_dirs=cuda_include_dirs,\n                     library_dirs=cuda_lib_dirs,\n                     extra_compile_preargs=cpp_flags,\n                     code=textwrap.dedent(\'\'\'\\\n            #include <cuda_runtime.h>\n            void test() {\n                cudaSetDevice(0);\n            }\n            \'\'\'))\n    except (CompileError, LinkError):\n        raise DistutilsPlatformError(\n            \'CUDA library was not found (see error above).\\n\'\n            \'Please specify correct CUDA location with the HOROVOD_CUDA_HOME \'\n            \'environment variable or combination of HOROVOD_CUDA_INCLUDE and \'\n            \'HOROVOD_CUDA_LIB environment variables.\\n\\n\'\n            \'HOROVOD_CUDA_HOME - path where CUDA include and lib directories can be found\\n\'\n            \'HOROVOD_CUDA_INCLUDE - path to CUDA include directory\\n\'\n            \'HOROVOD_CUDA_LIB - path to CUDA lib directory\')\n\n    return cuda_include_dirs, cuda_lib_dirs\n\n\ndef get_rocm_dirs(build_ext, cpp_flags):\n    rocm_include_dirs = []\n    rocm_lib_dirs = []\n    rocm_libs = [\'hip_hcc\']\n    rocm_macros = [(\'__HIP_PLATFORM_HCC__\',1)]\n\n    rocm_path = os.environ.get(\'HOROVOD_ROCM_HOME\', \'/opt/rocm\')\n    rocm_include_dirs += [\n            \'%s/include\' % rocm_path,\n            \'%s/hcc/include\' % rocm_path,\n            \'%s/hip/include\' % rocm_path,\n            \'%s/hsa/include\' % rocm_path,\n            ]\n    rocm_lib_dirs += [\n            \'%s/lib\' % rocm_path,\n            ]\n\n    try:\n        test_compile(build_ext, \'test_hip\', libraries=rocm_libs, include_dirs=rocm_include_dirs,\n                     library_dirs=rocm_lib_dirs, extra_compile_preargs=cpp_flags, macros=rocm_macros,\n                     code=textwrap.dedent(\'\'\'\\\n            #include <hip/hip_runtime.h>\n            void test() {\n                hipSetDevice(0);\n            }\n            \'\'\'))\n    except (CompileError, LinkError):\n        raise DistutilsPlatformError(\n            \'HIP library and/or ROCm header files not found (see error above).\\n\'\n            \'Please specify correct ROCm location with the HOROVOD_ROCM_HOME environment variable\')\n\n    return rocm_include_dirs, rocm_lib_dirs, rocm_macros\n\n\ndef get_nccl_vals(build_ext, gpu_include_dirs, gpu_lib_dirs, gpu_macros, cpp_flags, have_rocm):\n    nccl_include_dirs = []\n    nccl_lib_dirs = []\n    nccl_libs = []\n\n    nccl_home = os.environ.get(\'HOROVOD_NCCL_HOME\')\n    if nccl_home:\n        nccl_include_dirs += [\'%s/include\' % nccl_home]\n        nccl_lib_dirs += [\'%s/lib\' % nccl_home, \'%s/lib64\' % nccl_home]\n\n    nccl_include_dir = os.environ.get(\'HOROVOD_NCCL_INCLUDE\')\n    if nccl_include_dir:\n        nccl_include_dirs += [nccl_include_dir]\n\n    nccl_lib_dir = os.environ.get(\'HOROVOD_NCCL_LIB\')\n    if nccl_lib_dir:\n        nccl_lib_dirs += [nccl_lib_dir]\n\n    nccl_link_mode = os.environ.get(\'HOROVOD_NCCL_LINK\', \'SHARED\' if have_rocm else \'STATIC\')\n    if nccl_link_mode.upper() == \'SHARED\':\n        if have_rocm:\n            nccl_libs += [\'rccl\']\n        else:\n            nccl_libs += [\'nccl\']\n    else:\n        nccl_libs += [\'nccl_static\']\n        if have_rocm:\n            raise DistutilsPlatformError(\'RCCL must be a shared library\')\n\n    try:\n        test_compile(build_ext, \'test_nccl\', libraries=nccl_libs,\n                     include_dirs=nccl_include_dirs + gpu_include_dirs,\n                     library_dirs=nccl_lib_dirs + gpu_lib_dirs,\n                     extra_compile_preargs=cpp_flags,\n                     macros=gpu_macros,\n                     code=textwrap.dedent(\'\'\'\\\n            #include <%s>\n            #if NCCL_MAJOR < 2\n            #error Horovod requires NCCL 2.0 or later version, please upgrade.\n            #endif\n            void test() {\n                ncclUniqueId nccl_id;\n                ncclGetUniqueId(&nccl_id);\n            }\n            \'\'\'%(\'rccl.h\' if have_rocm else \'nccl.h\')))\n    except (CompileError, LinkError):\n        raise DistutilsPlatformError(\n            \'NCCL 2.0 library or its later version was not found (see error above).\\n\'\n            \'Please specify correct NCCL location with the HOROVOD_NCCL_HOME \'\n            \'environment variable or combination of HOROVOD_NCCL_INCLUDE and \'\n            \'HOROVOD_NCCL_LIB environment variables.\\n\\n\'\n            \'HOROVOD_NCCL_HOME - path where NCCL include and lib directories can be found\\n\'\n            \'HOROVOD_NCCL_INCLUDE - path to NCCL include directory\\n\'\n            \'HOROVOD_NCCL_LIB - path to NCCL lib directory\')\n\n    return nccl_include_dirs, nccl_lib_dirs, nccl_libs\n\n\ndef get_ddl_dirs(build_ext, cuda_include_dirs, cuda_lib_dirs, cpp_flags):\n    ddl_include_dirs = []\n    ddl_lib_dirs = []\n\n    ddl_home = os.environ.get(\'HOROVOD_DDL_HOME\')\n    if ddl_home:\n        ddl_include_dirs += [\'%s/include\' % ddl_home]\n        ddl_lib_dirs += [\'%s/lib\' % ddl_home, \'%s/lib64\' % ddl_home]\n\n    ddl_include_dir = os.environ.get(\'HOROVOD_DDL_INCLUDE\')\n    if ddl_include_dir:\n        ddl_include_dirs += [ddl_include_dir]\n\n    ddl_lib_dir = os.environ.get(\'HOROVOD_DDL_LIB\')\n    if ddl_lib_dir:\n        ddl_lib_dirs += [ddl_lib_dir]\n\n    # Keep DDL legacy folders for backward compatibility\n    if not ddl_include_dirs:\n        ddl_include_dirs += [\'/opt/DL/ddl/include\']\n    if not ddl_lib_dirs:\n        ddl_lib_dirs += [\'/opt/DL/ddl/lib\']\n\n    try:\n        test_compile(build_ext, \'test_ddl\', libraries=[\'ddl\', \'ddl_pack\'],\n                     include_dirs=ddl_include_dirs + cuda_include_dirs,\n                     library_dirs=ddl_lib_dirs + cuda_lib_dirs,\n                     extra_compile_preargs=cpp_flags,\n                     code=textwrap.dedent(\'\'\'\\\n                     #include <ddl.hpp>\n                     void test() {\n                     }\n                     \'\'\'))\n    except (CompileError, LinkError):\n        raise DistutilsPlatformError(\n            \'IBM PowerAI DDL library was not found (see error above).\\n\'\n            \'Please specify correct DDL location with the HOROVOD_DDL_HOME \'\n            \'environment variable or combination of HOROVOD_DDL_INCLUDE and \'\n            \'HOROVOD_DDL_LIB environment variables.\\n\\n\'\n            \'HOROVOD_DDL_HOME - path where DDL include and lib directories can be found\\n\'\n            \'HOROVOD_DDL_INCLUDE - path to DDL include directory\\n\'\n            \'HOROVOD_DDL_LIB - path to DDL lib directory\')\n\n    return ddl_include_dirs, ddl_lib_dirs\n\n\ndef set_cuda_options(build_ext, COMPILE_FLAGS, MACROS, INCLUDES, SOURCES, BUILD_MPI, LIBRARY_DIRS, LIBRARIES, **kwargs):\n    cuda_include_dirs, cuda_lib_dirs = get_cuda_dirs(build_ext, COMPILE_FLAGS)\n    MACROS += [(\'HAVE_CUDA\', \'1\'), (\'HAVE_GPU\', \'1\')]\n    INCLUDES += cuda_include_dirs\n    SOURCES += [\'horovod/common/ops/cuda_operations.cc\',\n                \'horovod/common/ops/gpu_operations.cc\']\n    if BUILD_MPI:\n        SOURCES += [\'horovod/common/ops/mpi_gpu_operations.cc\']\n    LIBRARY_DIRS += cuda_lib_dirs\n    LIBRARIES += [\'cudart\']\n\n\ndef get_common_options(build_ext):\n    cpp_flags = get_cpp_flags(build_ext)\n    link_flags = get_link_flags(build_ext)\n\n    is_mac = sys.platform == \'darwin\'\n    compile_without_gloo = os.environ.get(\'HOROVOD_WITHOUT_GLOO\')\n    if compile_without_gloo:\n        print(\'INFO: HOROVOD_WITHOUT_GLOO detected, skip compiling Horovod with Gloo.\')\n        have_gloo = False\n        have_cmake = False\n    else:\n        # determining if system has cmake installed\n        compile_with_gloo = os.environ.get(\'HOROVOD_WITH_GLOO\')\n        try:\n            cmake_bin = get_cmake_bin()\n            subprocess.check_output([cmake_bin, \'--version\'])\n            have_cmake = True\n        except Exception:\n            if compile_with_gloo:\n                # Require Gloo to succeed, otherwise fail the install.\n                raise RuntimeError(\'Cannot find CMake. CMake is required to build Horovod with Gloo.\')\n\n            print(\'INFO: Cannot find CMake, will skip compiling Horovod with Gloo.\')\n            have_cmake = False\n\n        # TODO: remove system check if gloo support MacOX in the future\n        #  https://github.com/facebookincubator/gloo/issues/182\n        if is_mac:\n            if compile_with_gloo:\n                raise RuntimeError(\'Gloo cannot be compiled on MacOS. Unset HOROVOD_WITH_GLOO to use MPI.\')\n            print(\'INFO: Gloo cannot be compiled on MacOS, will skip compiling Horovod with Gloo.\')\n\n        have_gloo = not is_mac and have_cmake\n\n    compile_without_mpi = os.environ.get(\'HOROVOD_WITHOUT_MPI\')\n    mpi_flags = \'\'\n    if compile_without_mpi:\n        print(\'INFO: HOROVOD_WITHOUT_MPI detected, skip compiling Horovod with MPI.\')\n        have_mpi = False\n    else:\n        # If without_mpi flag is not set by user, try to get mpi flags\n        try:\n            mpi_flags = get_mpi_flags()\n            have_mpi = True\n        except Exception:\n            if os.environ.get(\'HOROVOD_WITH_MPI\'):\n                # Require MPI to succeed, otherwise fail the install.\n                raise\n\n            # If exceptions happen, will not use mpi during compilation.\n            print(traceback.format_exc(), file=sys.stderr)\n            print(\'INFO: Cannot find MPI compilation flags, will skip compiling with MPI.\')\n            have_mpi = False\n\n    if not have_gloo and not have_mpi:\n        raise RuntimeError(\'One of Gloo or MPI are required for Horovod to run. Check the logs above for more info.\')\n\n    gpu_operations = os.environ.get(\'HOROVOD_GPU_OPERATIONS\')\n    if gpu_operations and gpu_operations not in {\'NCCL\', \'MPI\'}:\n        raise DistutilsError(f\'HOROVOD_GPU_OPERATIONS={gpu_operations} is invalid, \'\n                             f\'supported values are: NCCL, MPI.\')\n\n    def get_gpu_op_variable(op_variable_name, options):\n        gpu_operation = os.environ.get(op_variable_name)\n        if gpu_operations:\n            if gpu_operation:\n                raise DistutilsError(f\'Cannot specify both HOROVOD_GPU_OPERATIONS and {op_variable_name} options. \'\n                                     \'Try unsetting one of these variables and reinstalling.\')\n            return gpu_operations\n\n        if gpu_operation and gpu_operation not in options:\n            options_str = \', \'.join(options)\n            raise DistutilsError(f\'{op_variable_name}={gpu_operation} is invalid, \'\n                                 f\'supported values are: {options_str}.\')\n\n        return gpu_operation\n\n    gpu_allreduce = get_gpu_op_variable(\'HOROVOD_GPU_ALLREDUCE\', [\'NCCL\', \'MPI\', \'DDL\'])\n    gpu_allgather = get_gpu_op_variable(\'HOROVOD_GPU_ALLGATHER\', [\'NCCL\', \'MPI\'])\n    gpu_broadcast = get_gpu_op_variable(\'HOROVOD_GPU_BROADCAST\', [\'NCCL\', \'MPI\'])\n\n    have_cuda = False\n    have_rocm = False\n    gpu_include_dirs = gpu_lib_dirs = gpu_macros = []\n    if gpu_allreduce or gpu_allgather or gpu_broadcast:\n        gpu_type = os.environ.get(\'HOROVOD_GPU\', \'CUDA\')\n        if gpu_type == \'CUDA\':\n            have_cuda = True\n            gpu_include_dirs, gpu_lib_dirs = get_cuda_dirs(build_ext, cpp_flags)\n        elif gpu_type == \'ROCM\':\n            have_rocm = True\n            gpu_include_dirs, gpu_lib_dirs, gpu_macros = get_rocm_dirs(build_ext, cpp_flags)\n        else:\n            raise DistutilsError(""Unknown HOROVOD_GPU type \'%s\'"" % gpu_type)\n\n    if gpu_allreduce == \'NCCL\' or gpu_allgather == \'NCCL\' or gpu_broadcast == \'NCCL\':\n        have_nccl = True\n        nccl_include_dirs, nccl_lib_dirs, nccl_libs = get_nccl_vals(\n            build_ext, gpu_include_dirs, gpu_lib_dirs, gpu_macros, cpp_flags, have_rocm)\n    else:\n        have_nccl = False\n        nccl_include_dirs = nccl_lib_dirs = nccl_libs = []\n\n    if gpu_allreduce == \'DDL\':\n        warnings.warn(\'DDL backend has been deprecated. Please, start using the NCCL backend \'\n                      \'by building Horovod with ""HOROVOD_GPU_OPERATIONS=NCCL"". \'\n                      \'Will be removed in v0.21.0.\',\n                      DeprecationWarning)\n        have_ddl = True\n        ddl_include_dirs, ddl_lib_dirs = get_ddl_dirs(build_ext,\n                                                      gpu_include_dirs,\n                                                      gpu_lib_dirs, cpp_flags)\n    else:\n        have_ddl = False\n        ddl_include_dirs = ddl_lib_dirs = []\n\n    if gpu_allreduce == \'NCCL\' \\\n            and (gpu_allgather == \'MPI\' or gpu_broadcast == \'MPI\') \\\n            and not os.environ.get(\'HOROVOD_ALLOW_MIXED_GPU_IMPL\'):\n        raise DistutilsError(\n            \'You should not mix NCCL and MPI GPU due to a possible deadlock.\\n\'\n            \'If you\\\'re sure you want to mix them, set the \'\n            \'HOROVOD_ALLOW_MIXED_GPU_IMPL environment variable to \\\'1\\\'.\')\n\n    MACROS = [(\'EIGEN_MPL2_ONLY\', 1)]\n    INCLUDES = [\'third_party/HTTPRequest/include\',\n                \'third_party/boost/assert/include\',\n                \'third_party/boost/config/include\',\n                \'third_party/boost/core/include\',\n                \'third_party/boost/detail/include\',\n                \'third_party/boost/iterator/include\',\n                \'third_party/boost/lockfree/include\',\n                \'third_party/boost/mpl/include\',\n                \'third_party/boost/parameter/include\',\n                \'third_party/boost/predef/include\',\n                \'third_party/boost/preprocessor/include\',\n                \'third_party/boost/static_assert/include\',\n                \'third_party/boost/type_traits/include\',\n                \'third_party/boost/utility/include\',\n                \'third_party/eigen\',\n                \'third_party/flatbuffers/include\',\n                \'third_party/lbfgs/include\']\n    SOURCES = [\'horovod/common/common.cc\',\n               \'horovod/common/controller.cc\',\n               \'horovod/common/fusion_buffer_manager.cc\',\n               \'horovod/common/logging.cc\',\n               \'horovod/common/message.cc\',\n               \'horovod/common/operations.cc\',\n               \'horovod/common/parameter_manager.cc\',\n               \'horovod/common/response_cache.cc\',\n               \'horovod/common/stall_inspector.cc\',\n               \'horovod/common/thread_pool.cc\',\n               \'horovod/common/timeline.cc\',\n               \'horovod/common/tensor_queue.cc\',\n               \'horovod/common/ops/collective_operations.cc\',\n               \'horovod/common/ops/operation_manager.cc\',\n               \'horovod/common/optim/bayesian_optimization.cc\',\n               \'horovod/common/optim/gaussian_process.cc\',\n               \'horovod/common/utils/env_parser.cc\'\n               ]\n    COMPILE_FLAGS = cpp_flags + shlex.split(mpi_flags)\n    LINK_FLAGS = link_flags + shlex.split(mpi_flags)\n    LIBRARY_DIRS = []\n    LIBRARIES = []\n\n    cpu_operation = os.environ.get(\'HOROVOD_CPU_OPERATIONS\')\n    if cpu_operation:\n        print(\'INFO: Set default CPU operation to \' + cpu_operation)\n        if cpu_operation.upper() == \'MPI\':\n            if not have_mpi:\n                raise RuntimeError(\'MPI is not installed, try changing HOROVOD_CPU_OPERATIONS.\')\n            MACROS += [(\'HOROVOD_CPU_OPERATIONS_DEFAULT\', ""\'M\'"")]\n        elif cpu_operation.upper() == \'MLSL\':\n            raise RuntimeError(\'Intel(R) MLSL was removed. Upgrade to oneCCL and set HOROVOD_CPU_OPERATIONS=CCL.\')\n        elif cpu_operation.upper() == \'CCL\':\n            if not have_ccl:\n                raise RuntimeError(\'oneCCL is not installed, try changing HOROVOD_CPU_OPERATIONS.\')\n            MACROS += [(\'HOROVOD_CPU_OPERATIONS_DEFAULT\', ""\'C\'"")]\n        elif cpu_operation.upper() == \'GLOO\':\n            if compile_without_gloo:\n                raise ValueError(\'Cannot set both HOROVOD_WITHOUT_GLOO and HOROVOD_CPU_OPERATIONS=GLOO.\')\n            if is_mac:\n                raise RuntimeError(\'Cannot compile Gloo on MacOS, try changing HOROVOD_CPU_OPERATIONS.\')\n            elif not have_cmake:\n                raise RuntimeError(\'Cannot compile Gloo without CMake, try installing CMake first.\')\n            MACROS += [(\'HOROVOD_CPU_OPERATIONS_DEFAULT\', ""\'G\'"")]\n\n    if have_mpi:\n        MACROS += [(\'HAVE_MPI\', \'1\')]\n        SOURCES += [\'horovod/common/half.cc\',\n                    \'horovod/common/mpi/mpi_context.cc\',\n                    \'horovod/common/mpi/mpi_controller.cc\',\n                    \'horovod/common/ops/mpi_operations.cc\',\n                    \'horovod/common/ops/adasum/adasum_mpi.cc\',\n                    \'horovod/common/ops/adasum_mpi_operations.cc\']\n        COMPILE_FLAGS += shlex.split(mpi_flags)\n        LINK_FLAGS += shlex.split(mpi_flags)\n\n    if have_gloo:\n        MACROS += [(\'HAVE_GLOO\', \'1\')]\n        INCLUDES += [\'third_party/gloo\']\n        SOURCES += [\'horovod/common/gloo/gloo_context.cc\',\n                    \'horovod/common/gloo/gloo_controller.cc\',\n                    \'horovod/common/gloo/http_store.cc\',\n                    \'horovod/common/gloo/memory_store.cc\',\n                    \'horovod/common/ops/gloo_operations.cc\']\n\n    if have_ccl:\n        MACROS += [(\'HAVE_CCL\', \'1\')]\n        INCLUDES += [ccl_root + \'/include/\']\n        SOURCES += [\'horovod/common/ops/ccl_operations.cc\']\n        LIBRARY_DIRS += [ccl_root + \'/lib/\']\n        LINK_FLAGS += [\'-lccl\']\n\n    if have_cuda:\n        set_cuda_options(build_ext, COMPILE_FLAGS, MACROS, INCLUDES, SOURCES, have_mpi, LIBRARY_DIRS, LIBRARIES)\n        INCLUDES += [\'horovod/common/ops/cuda\']\n\n    if have_rocm:\n        MACROS += [(\'HAVE_ROCM\', \'1\'), (\'HAVE_GPU\', \'1\')] + gpu_macros\n        INCLUDES += gpu_include_dirs\n        SOURCES += [\'horovod/common/ops/hip_operations.cc\',\n                    \'horovod/common/ops/gpu_operations.cc\']\n        if have_mpi:\n            SOURCES += [\'horovod/common/ops/mpi_gpu_operations.cc\']\n        LIBRARY_DIRS += gpu_lib_dirs\n        LIBRARIES += [\'hip_hcc\']\n\n    if have_nccl:\n        MACROS += [(\'HAVE_NCCL\', \'1\')]\n        INCLUDES += nccl_include_dirs\n        SOURCES += [\'horovod/common/ops/nccl_operations.cc\']\n        if have_mpi:\n            SOURCES += [\'horovod/common/ops/adasum_gpu_operations.cc\']\n        LIBRARY_DIRS += nccl_lib_dirs\n        LIBRARIES += nccl_libs\n\n    if have_ddl and have_mpi:\n        MACROS += [(\'HAVE_DDL\', \'1\')]\n        INCLUDES += ddl_include_dirs\n        SOURCES += [\'horovod/common/mpi/ddl_mpi_context_manager.cc\',\n                    \'horovod/common/ops/ddl_operations.cc\']\n        LIBRARY_DIRS += ddl_lib_dirs\n        LIBRARIES += [\'ddl\', \'ddl_pack\']\n\n    if gpu_allreduce:\n        MACROS += [(\'HOROVOD_GPU_ALLREDUCE\', ""\'%s\'"" % gpu_allreduce[0])]\n\n    if gpu_allgather:\n        MACROS += [(\'HOROVOD_GPU_ALLGATHER\', ""\'%s\'"" % gpu_allgather[0])]\n\n    if gpu_broadcast:\n        MACROS += [(\'HOROVOD_GPU_BROADCAST\', ""\'%s\'"" % gpu_broadcast[0])]\n\n    return dict(MACROS=MACROS,\n                INCLUDES=INCLUDES,\n                SOURCES=SOURCES,\n                COMPILE_FLAGS=COMPILE_FLAGS,\n                LINK_FLAGS=LINK_FLAGS,\n                LIBRARY_DIRS=LIBRARY_DIRS,\n                LIBRARIES=LIBRARIES,\n                BUILD_GLOO=have_gloo,\n                BUILD_MPI=have_mpi,\n                )\n\n\ndef enumerate_binaries_in_path():\n    for path_dir in os.getenv(\'PATH\', \'\').split(\':\'):\n        if os.path.isdir(path_dir):\n            for bin_file in sorted(os.listdir(path_dir)):\n                yield path_dir, bin_file\n\n\ndef determine_gcc_version(compiler):\n    try:\n        compiler_macros = subprocess.check_output(\n            \'%s -dM -E - </dev/null\' % compiler,\n            shell=True, universal_newlines=True).split(\'\\n\')\n        for m in compiler_macros:\n            version_match = re.match(\'^#define __VERSION__ ""(.*?)""$\', m)\n            if version_match:\n                return LooseVersion(version_match.group(1))\n        print(\'INFO: Unable to determine version of the compiler %s.\' % compiler)\n\n    except subprocess.CalledProcessError:\n        print(\'INFO: Unable to determine version of the compiler %s.\\n%s\'\n              \'\' % (compiler, traceback.format_exc()))\n\n    return None\n\n\ndef find_gxx_compiler_in_path():\n    compilers = []\n\n    for path_dir, bin_file in enumerate_binaries_in_path():\n        if re.match(\'^g\\\\+\\\\+(?:-\\\\d+(?:\\\\.\\\\d+)*)?$\', bin_file):\n            # g++, or g++-7, g++-4.9, or g++-4.8.5\n            compiler = os.path.join(path_dir, bin_file)\n            compiler_version = determine_gcc_version(compiler)\n            if compiler_version:\n                compilers.append((compiler, compiler_version))\n\n    return compilers\n\n\ndef find_matching_gcc_compiler_path(gxx_compiler_version):\n    for path_dir, bin_file in enumerate_binaries_in_path():\n        if re.match(\'^gcc(?:-\\\\d+(?:\\\\.\\\\d+)*)?$\', bin_file):\n            # gcc, or gcc-7, gcc-4.9, or gcc-4.8.5\n            compiler = os.path.join(path_dir, bin_file)\n            compiler_version = determine_gcc_version(compiler)\n            if compiler_version and compiler_version == gxx_compiler_version:\n                return compiler\n\n    print(\'INFO: Unable to find gcc compiler (version %s).\' % gxx_compiler_version)\n    return None\n\n\ndef remove_offensive_gcc_compiler_options(compiler_version):\n    offensive_replacements = dict()\n    if compiler_version < LooseVersion(\'4.9\'):\n        offensive_replacements = {\n            \'-Wdate-time\': \'\',\n            \'-fstack-protector-strong\': \'-fstack-protector\'\n        }\n\n    if offensive_replacements:\n        from sysconfig import get_config_var\n        cflags = get_config_var(\'CONFIGURE_CFLAGS\')\n        cppflags = get_config_var(\'CONFIGURE_CPPFLAGS\')\n        ldshared = get_config_var(\'LDSHARED\')\n\n        for k, v in offensive_replacements.items():\n            if cflags:\n                cflags = cflags.replace(k, v)\n            if cppflags:\n                cppflags = cppflags.replace(k, v)\n            if ldshared:\n                ldshared = ldshared.replace(k, v)\n\n        return cflags, cppflags, ldshared\n\n    # Use defaults\n    return None, None, None\n\n\n# Filter out all the compiler macros (starts with -D)\n# that need to be passed to compiler\ndef filter_compile_macros(compile_flags):\n    res = []\n    for flag in compile_flags:\n        if flag.startswith(\'-D\'):\n            res.append(flag)\n    return res\n\n\ndef build_tf_extension(build_ext, global_options):\n    # Backup the options, preventing other plugins access libs that\n    # compiled with compiler of this plugin\n    options = deepcopy(global_options)\n\n    check_tf_version()\n    tf_compile_flags, tf_link_flags = get_tf_flags(\n        build_ext, options[\'COMPILE_FLAGS\'])\n\n    gloo_compile_macros = filter_compile_macros(tf_compile_flags)\n\n    tensorflow_mpi_lib.define_macros = options[\'MACROS\']\n    tensorflow_mpi_lib.include_dirs = options[\'INCLUDES\']\n    tensorflow_mpi_lib.sources = options[\'SOURCES\'] + \\\n                                 [\'horovod/tensorflow/mpi_ops.cc\']\n    tensorflow_mpi_lib.extra_compile_args = options[\'COMPILE_FLAGS\'] + \\\n                                            tf_compile_flags\n    tensorflow_mpi_lib.extra_link_args = options[\'LINK_FLAGS\'] + tf_link_flags\n\n    tensorflow_mpi_lib.library_dirs = options[\'LIBRARY_DIRS\']\n    tensorflow_mpi_lib.libraries = options[\'LIBRARIES\']\n\n    cc_compiler = cxx_compiler = cflags = cppflags = ldshared = None\n    if sys.platform.startswith(\'linux\') and not os.getenv(\'CC\') and not os.getenv(\'CXX\'):\n        # Determine g++ version compatible with this TensorFlow installation\n        import tensorflow as tf\n        if hasattr(tf, \'version\'):\n            # Since TensorFlow 1.13.0\n            tf_compiler_version = LooseVersion(tf.version.COMPILER_VERSION)\n        else:\n            tf_compiler_version = LooseVersion(tf.COMPILER_VERSION)\n\n        if tf_compiler_version.version[0] == 4:\n            # g++ 4.x is ABI-incompatible with g++ 5.x+ due to std::function change\n            # See: https://github.com/tensorflow/tensorflow/issues/27067\n            maximum_compiler_version = LooseVersion(\'5\')\n        else:\n            maximum_compiler_version = LooseVersion(\'999\')\n\n        # Find the compatible compiler of the highest version\n        compiler_version = LooseVersion(\'0\')\n        for candidate_cxx_compiler, candidate_compiler_version in find_gxx_compiler_in_path():\n            if candidate_compiler_version >= tf_compiler_version and \\\n                    candidate_compiler_version < maximum_compiler_version:\n                candidate_cc_compiler = \\\n                    find_matching_gcc_compiler_path(candidate_compiler_version)\n                if candidate_cc_compiler and candidate_compiler_version > compiler_version:\n                    cc_compiler = candidate_cc_compiler\n                    cxx_compiler = candidate_cxx_compiler\n                    compiler_version = candidate_compiler_version\n            else:\n                print(\'INFO: Compiler %s (version %s) is not usable for this TensorFlow \'\n                      \'installation. Require g++ (version >=%s, <%s).\' %\n                      (candidate_cxx_compiler, candidate_compiler_version,\n                       tf_compiler_version, maximum_compiler_version))\n\n        if cc_compiler:\n            print(\'INFO: Compilers %s and %s (version %s) selected for TensorFlow plugin build.\'\n                  \'\' % (cc_compiler, cxx_compiler, compiler_version))\n        else:\n            raise DistutilsPlatformError(\n                \'Could not find compiler compatible with this TensorFlow installation.\\n\'\n                \'Please check the Horovod website for recommended compiler versions.\\n\'\n                \'To force a specific compiler version, set CC and CXX environment variables.\')\n\n        cflags, cppflags, ldshared = remove_offensive_gcc_compiler_options(compiler_version)\n\n    try:\n        with env(CC=cc_compiler, CXX=cxx_compiler, CFLAGS=cflags, CPPFLAGS=cppflags,\n                 LDSHARED=ldshared):\n            if options[\'BUILD_GLOO\']:\n                build_cmake(build_ext, gloo_lib, \'tf\', gloo_compile_macros, options, tensorflow_mpi_lib)\n            customize_compiler(build_ext.compiler)\n            build_ext.build_extension(tensorflow_mpi_lib)\n    finally:\n        # Revert to the default compiler settings\n        customize_compiler(build_ext.compiler)\n\n\ndef parse_version(version_str):\n    if ""dev"" in version_str:\n        return 9999999999\n    m = re.match(r\'^(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?(?:\\.(\\d+))?\', version_str)\n    if m is None:\n        return None\n\n    # turn version string to long integer\n    version = int(m.group(1)) * 10 ** 9\n    if m.group(2) is not None:\n        version += int(m.group(2)) * 10 ** 6\n    if m.group(3) is not None:\n        version += int(m.group(3)) * 10 ** 3\n    if m.group(4) is not None:\n        version += int(m.group(4))\n    return version\n\n\ndef is_mx_mkldnn():\n    try:\n        from mxnet import runtime\n        features = runtime.Features()\n        return features.is_enabled(\'MKLDNN\')\n    except Exception:\n        msg = \'INFO: Cannot detect if MKLDNN is enabled in MXNet. Please \\\n            set MXNET_USE_MKLDNN=1 if MKLDNN is enabled in your MXNet build.\'\n        if \'linux\' not in sys.platform:\n            # MKLDNN is only enabled by default in MXNet Linux build. Return\n            # False by default for non-linux build but still allow users to\n            # enable it by using MXNET_USE_MKLDNN env variable.\n            print(msg)\n            return os.environ.get(\'MXNET_USE_MKLDNN\', \'0\') == \'1\'\n        else:\n            try:\n                import mxnet as mx\n                mx_libs = mx.libinfo.find_lib_path()\n                for mx_lib in mx_libs:\n                    output = subprocess.check_output([\'readelf\', \'-d\', mx_lib])\n                    if \'mkldnn\' in str(output):\n                        return True\n                return False\n            except Exception:\n                print(msg)\n                return os.environ.get(\'MXNET_USE_MKLDNN\', \'0\') == \'1\'\n\n\ndef is_mx_cuda():\n    try:\n        from mxnet import runtime\n        features = runtime.Features()\n        return features.is_enabled(\'CUDA\')\n    except Exception:\n        if \'linux\' in sys.platform:\n            try:\n                import mxnet as mx\n                mx_libs = mx.libinfo.find_lib_path()\n                for mx_lib in mx_libs:\n                    output = subprocess.check_output([\'readelf\', \'-d\', mx_lib])\n                    if \'cuda\' in str(output):\n                        return True\n                return False\n            except Exception:\n                return False\n    return False\n\n\ndef build_mx_extension(build_ext, global_options):\n    # Backup the options, preventing other plugins access libs that\n    # compiled with compiler of this plugin\n    options = deepcopy(global_options)\n\n    # First build gloo\n    if options[\'BUILD_GLOO\']:\n        build_cmake(build_ext, gloo_lib, \'mxnet\', [], options=options)\n\n    check_mx_version()\n    mx_compile_flags, mx_link_flags = get_mx_flags(\n        build_ext, options[\'COMPILE_FLAGS\'])\n\n    mx_have_cuda = is_mx_cuda()\n    macro_have_cuda = check_macro(options[\'MACROS\'], \'HAVE_CUDA\')\n    if not mx_have_cuda and macro_have_cuda:\n        raise DistutilsPlatformError(\n            \'Horovod build with GPU support was requested, but this MXNet \'\n            \'installation does not support CUDA.\')\n\n    # Update HAVE_CUDA to mean that MXNet supports CUDA. Internally, we will be checking\n    # HOROVOD_GPU_(ALLREDUCE|ALLGATHER|BROADCAST) to decide whether we should use GPU\n    # version or transfer tensors to CPU memory for those operations.\n    if mx_have_cuda and not macro_have_cuda:\n        set_cuda_options(build_ext, **options)\n\n    mxnet_mpi_lib.define_macros = options[\'MACROS\']\n    if check_macro(options[\'MACROS\'], \'HAVE_CUDA\'):\n        mxnet_mpi_lib.define_macros += [(\'MSHADOW_USE_CUDA\', \'1\')]\n    else:\n        mxnet_mpi_lib.define_macros += [(\'MSHADOW_USE_CUDA\', \'0\')]\n    if is_mx_mkldnn():\n        mxnet_mpi_lib.define_macros += [(\'MXNET_USE_MKLDNN\', \'1\')]\n    else:\n        mxnet_mpi_lib.define_macros += [(\'MXNET_USE_MKLDNN\', \'0\')]\n    mxnet_mpi_lib.define_macros += [(\'MSHADOW_USE_MKL\', \'0\')]\n    mxnet_mpi_lib.define_macros += [(\'MSHADOW_USE_F16C\', \'0\')]\n    mxnet_mpi_lib.include_dirs = options[\'INCLUDES\']\n    mxnet_mpi_lib.sources = options[\'SOURCES\'] + \\\n                            [\'horovod/mxnet/mpi_ops.cc\',\n                             \'horovod/mxnet/tensor_util.cc\',\n                             \'horovod/mxnet/cuda_util.cc\',\n                             \'horovod/mxnet/adapter.cc\']\n    mxnet_mpi_lib.extra_compile_args = options[\'COMPILE_FLAGS\'] + \\\n                                       mx_compile_flags\n    mxnet_mpi_lib.extra_link_args = options[\'LINK_FLAGS\'] + mx_link_flags\n    mxnet_mpi_lib.library_dirs = options[\'LIBRARY_DIRS\']\n    mxnet_mpi_lib.libraries = options[\'LIBRARIES\']\n\n    build_ext.build_extension(mxnet_mpi_lib)\n\n\ndef dummy_import_torch():\n    try:\n        import torch\n    except:\n        pass\n\n\ndef check_torch_version():\n    try:\n        import torch\n        if LooseVersion(torch.__version__) < LooseVersion(\'0.4.0\'):\n            raise DistutilsPlatformError(\n                \'Your PyTorch version %s is outdated.  \'\n                \'Horovod requires torch>=0.4.0\' % torch.__version__)\n    except ImportError:\n        raise DistutilsPlatformError(\n            \'import torch failed, is it installed?\\n\\n%s\' % traceback.format_exc())\n\n    # parse version\n    version = parse_version(torch.__version__)\n    if version is None:\n        raise DistutilsPlatformError(\n            \'Unable to determine PyTorch version from the version string \\\'%s\\\'\' % torch.__version__)\n    return version\n\n\ndef is_torch_cuda():\n    try:\n        from torch.utils.ffi import create_extension\n        cuda_test_ext = create_extension(\n            name=\'horovod.torch.test_cuda\',\n            headers=[\'horovod/torch/dummy.h\'],\n            sources=[],\n            with_cuda=True,\n            extra_compile_args=[\'-std=c11\', \'-fPIC\', \'-O3\']\n        )\n        cuda_test_ext.build()\n        return True\n    except:\n        print(\n            \'INFO: Above error indicates that this PyTorch installation does not support CUDA.\')\n        return False\n\n\ndef is_torch_cuda_v2(build_ext, include_dirs, extra_compile_args):\n    try:\n        from torch.utils.cpp_extension import include_paths\n        test_compile(build_ext, \'test_torch_cuda\',\n                     include_dirs=include_dirs + include_paths(cuda=True),\n                     extra_compile_preargs=extra_compile_args,\n                     code=textwrap.dedent(\'\'\'\\\n            #include <THC/THC.h>\n            void test() {\n            }\n            \'\'\'))\n        return True\n    except (CompileError, LinkError, EnvironmentError):\n        print(\n            \'INFO: Above error indicates that this PyTorch installation does not support CUDA.\')\n        return False\n\n\ndef get_torch_rocm_macros():\n    try:\n        from torch.utils.cpp_extension import COMMON_HIPCC_FLAGS\n        pattern = re.compile(r\'-D(\\w+)=?(\\w+)?\')\n        return [pattern.match(flag).groups() for flag in COMMON_HIPCC_FLAGS if pattern.match(flag)]\n    except:\n        return []\n\n\ndef is_torch_rocm_v2(build_ext, include_dirs, extra_compile_args):\n    try:\n        from torch.utils.cpp_extension import include_paths\n        rocm_macros = get_torch_rocm_macros()\n        test_compile(build_ext, \'test_torch_rocm\',\n                     include_dirs=include_dirs + include_paths(cuda=True),\n                     extra_compile_preargs=extra_compile_args,\n                     macros=rocm_macros,\n                     code=textwrap.dedent(\'\'\'\\\n            #include <THH/THH.h>\n            void test() {\n            }\n            \'\'\'))\n        return True\n    except (CompileError, LinkError, EnvironmentError):\n        print(\n            \'INFO: Above error indicates that this PyTorch installation does not support ROCm.\')\n        return False\n\n\ndef check_macro(macros, key):\n    return any(k == key and v for k, v in macros)\n\n\ndef set_macro(macros, key, new_value):\n    if any(k == key for k, _ in macros):\n        return [(k, new_value if k == key else v) for k, v in macros]\n    else:\n        return macros + [(key, new_value)]\n\n\ndef set_flag(flags, flag, value):\n    flag = \'-\' + flag\n    if any(f.split(\'=\')[0] == flag for f in flags):\n        return [(\'{}={}\'.format(flag, value) if f.split(\'=\')[0] == flag else f) for f in flags]\n    else:\n        return flags + [\'{}={}\'.format(flag, value)]\n\n\nclass protect_files(object):\n    def __init__(self, *files):\n        self.files = files\n\n    def __enter__(self):\n        for file in self.files:\n            os.rename(file, file + \'.protected\')\n\n    def __exit__(self, type, value, traceback):\n        for file in self.files:\n            os.rename(file + \'.protected\', file)\n\n\ndef build_torch_extension(build_ext, global_options, torch_version):\n    # Backup the options, preventing other plugins access libs that\n    # compiled with compiler of this plugin\n    options = deepcopy(global_options)\n\n    have_cuda = is_torch_cuda()\n    have_cuda_macro = check_macro(options[\'MACROS\'], \'HAVE_CUDA\')\n    if not have_cuda and have_cuda_macro:\n        raise DistutilsPlatformError(\n            \'Horovod build with GPU support was requested, but this PyTorch \'\n            \'installation does not support CUDA.\')\n\n    # Build gloo\n    if options[\'BUILD_GLOO\']:\n        build_cmake(build_ext, gloo_lib, \'torch\', [], options)\n\n    # Update HAVE_CUDA to mean that PyTorch supports CUDA. Internally, we will be checking\n    # HOROVOD_GPU_(ALLREDUCE|ALLGATHER|BROADCAST) to decide whether we should use GPU\n    # version or transfer tensors to CPU memory for those operations.\n    if have_cuda and not have_cuda_macro:\n        set_cuda_options(build_ext, **options)\n\n    # Export TORCH_VERSION equal to our representation of torch.__version__. Internally it\'s\n    # used for backwards compatibility checks.\n    updated_macros = set_macro(\n        options[\'MACROS\'], \'TORCH_VERSION\', str(torch_version))\n\n    # Create_extension overwrites these files which are customized, we need to protect them.\n    with protect_files(\'horovod/torch/mpi_lib/__init__.py\',\n                       \'horovod/torch/mpi_lib_impl/__init__.py\'):\n        from torch.utils.ffi import create_extension\n        ffi_iface = create_extension(\n            name=\'horovod.torch.mpi_lib\',\n            headers=[\'horovod/torch/interface.h\'] +\n                    ([\'horovod/torch/interface_cuda.h\'] if have_cuda else []),\n            with_cuda=have_cuda,\n            language=\'c\',\n            package=True,\n            sources=[],\n            extra_compile_args=[\'-std=c11\', \'-fPIC\', \'-O3\']\n        )\n        ffi_impl = create_extension(\n            name=\'horovod.torch.mpi_lib_impl\',\n            headers=[],\n            with_cuda=have_cuda,\n            language=\'c++\',\n            package=True,\n            source_extension=\'.cc\',\n            define_macros=updated_macros,\n            include_dirs=options[\'INCLUDES\'],\n            sources=options[\'SOURCES\'] + [\'horovod/torch/mpi_ops.cc\',\n                                          \'horovod/torch/handle_manager.cc\',\n                                          \'horovod/torch/ready_event.cc\',\n                                          \'horovod/torch/tensor_util.cc\',\n                                          \'horovod/torch/cuda_util.cc\',\n                                          \'horovod/torch/adapter.cc\'],\n            extra_compile_args=options[\'COMPILE_FLAGS\'],\n            extra_link_args=options[\'LINK_FLAGS\'],\n            library_dirs=options[\'LIBRARY_DIRS\'],\n            libraries=options[\'LIBRARIES\']\n        )\n\n    for ffi, setuptools_ext in [(ffi_iface, torch_mpi_lib),\n                                (ffi_impl, torch_mpi_lib_impl)]:\n        ffi_ext = ffi.distutils_extension()\n        # ffi_ext is distutils Extension, not setuptools Extension\n        for k, v in ffi_ext.__dict__.items():\n            setuptools_ext.__dict__[k] = v\n        build_ext.build_extension(setuptools_ext)\n\n\ndef build_torch_extension_v2(build_ext, global_options, torch_version):\n    # Backup the options, preventing other plugins access libs that\n    # compiled with compiler of this plugin\n    options = deepcopy(global_options)\n\n    # Versions of PyTorch > 1.3.0 require C++14\n    import torch\n    compile_flags = options[\'COMPILE_FLAGS\']\n    if LooseVersion(torch.__version__) >= LooseVersion(\'1.3.0\'):\n        compile_flags = set_flag(compile_flags, \'std\', \'c++14\')\n\n    have_cuda = is_torch_cuda_v2(build_ext, include_dirs=options[\'INCLUDES\'],\n                                 extra_compile_args=compile_flags)\n    have_cuda_macro = check_macro(options[\'MACROS\'], \'HAVE_CUDA\')\n    if not have_cuda and have_cuda_macro:\n        raise DistutilsPlatformError(\n            \'Horovod build with GPU support was requested, but this PyTorch \'\n            \'installation does not support CUDA.\')\n    elif have_cuda and not have_cuda_macro:\n        # Update HAVE_GPU to mean that PyTorch supports CUDA. Internally, we will be checking\n        # HOROVOD_GPU_(ALLREDUCE|ALLGATHER|BROADCAST) to decide whether we should use GPU\n        # version or transfer tensors to CPU memory for those operations.\n        set_cuda_options(build_ext, **options)\n\n    # hereafter, macros are maintained outside of options dict\n    updated_macros = options[\'MACROS\']\n\n    have_rocm = is_torch_rocm_v2(build_ext, include_dirs=options[\'INCLUDES\'],\n                                 extra_compile_args=compile_flags)\n    have_rocm_macro = check_macro(updated_macros, \'HAVE_ROCM\')\n    if not have_rocm and have_rocm_macro:\n        raise DistutilsPlatformError(\n            \'Horovod build with GPU support was requested, but this PyTorch \'\n            \'installation does not support ROCm.\')\n    elif have_rocm and not have_rocm_macro:\n        # ROCm PyTorch requires extensions to be hipified with the provided utility.\n        # The utility does not change \'HAVE_CUDA\', so those were renamed \'HAVE_GPU\'.\n        # Update HAVE_GPU to mean that PyTorch supports ROCm. Internally, we will be checking\n        # HOROVOD_GPU_(ALLREDUCE|ALLGATHER|BROADCAST) to decide whether we should use GPU\n        # version or transfer tensors to CPU memory for those operations.\n        updated_macros = set_macro(updated_macros, \'HAVE_ROCM\', str(int(have_rocm)))\n        updated_macros = set_macro(updated_macros, \'HAVE_GPU\', str(int(have_rocm)))\n        # ROCm PyTorch requires additional macros.\n        for (k,v) in get_torch_rocm_macros():\n            updated_macros = set_macro(updated_macros, k, v)\n\n    # Export TORCH_VERSION equal to our representation of torch.__version__. Internally it\'s\n    # used for backwards compatibility checks.\n    updated_macros = set_macro(updated_macros, \'TORCH_VERSION\', str(torch_version))\n\n    # Always set _GLIBCXX_USE_CXX11_ABI, since PyTorch can only detect whether it was set to 1.\n    updated_macros = set_macro(updated_macros, \'_GLIBCXX_USE_CXX11_ABI\',\n                               str(int(torch.compiled_with_cxx11_abi())))\n\n    gloo_abi_flag = [\'-D_GLIBCXX_USE_CXX11_ABI=\' + str(int(torch.compiled_with_cxx11_abi()))]\n\n    # PyTorch requires -DTORCH_API_INCLUDE_EXTENSION_H\n    updated_macros = set_macro(updated_macros, \'TORCH_API_INCLUDE_EXTENSION_H\', \'1\')\n\n    if have_rocm:\n        from torch.utils.cpp_extension import CUDAExtension as TorchExtension\n        from torch.utils.hipify import hipify_python\n        this_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), ""horovod"")\n        hipify_python.hipify(\n                project_directory=this_dir,\n                output_directory=this_dir,\n                includes=(""torch/*.cc"",""torch/*.h""),\n                show_detailed=True,\n                is_pytorch_extension=True)\n    elif have_cuda:\n        from torch.utils.cpp_extension import CUDAExtension as TorchExtension\n    else:\n        # CUDAExtension fails with `ld: library not found for -lcudart` if CUDA is not present\n        from torch.utils.cpp_extension import CppExtension as TorchExtension\n\n    ext = TorchExtension(torch_mpi_lib_v2.name,\n                         define_macros=updated_macros,\n                         include_dirs=options[\'INCLUDES\'],\n                         sources=options[\'SOURCES\'] + [\n                            \'horovod/torch/mpi_ops_v2.cc\',\n                            \'horovod/torch/handle_manager.cc\',\n                            \'horovod/torch/ready_event.cc\',\n                            \'horovod/torch/cuda_util.cc\',\n                            \'horovod/torch/adapter_v2.cc\'],\n                         extra_compile_args=compile_flags,\n                         extra_link_args=options[\'LINK_FLAGS\'],\n                         library_dirs=options[\'LIBRARY_DIRS\'],\n                         libraries=options[\'LIBRARIES\'])\n\n    # Patch an existing torch_mpi_lib_v2 extension object.\n    for k, v in ext.__dict__.items():\n        torch_mpi_lib_v2.__dict__[k] = v\n\n    cc_compiler = cxx_compiler = cflags = cppflags = ldshared = None\n    if sys.platform.startswith(\'linux\') and not os.getenv(\'CC\') and not os.getenv(\'CXX\'):\n        from torch.utils.cpp_extension import check_compiler_abi_compatibility\n\n        # Find the compatible compiler of the highest version\n        compiler_version = LooseVersion(\'0\')\n        for candidate_cxx_compiler, candidate_compiler_version in find_gxx_compiler_in_path():\n            if check_compiler_abi_compatibility(candidate_cxx_compiler):\n                candidate_cc_compiler = \\\n                    find_matching_gcc_compiler_path(candidate_compiler_version)\n                if candidate_cc_compiler and candidate_compiler_version > compiler_version:\n                    cc_compiler = candidate_cc_compiler\n                    cxx_compiler = candidate_cxx_compiler\n                    compiler_version = candidate_compiler_version\n            else:\n                print(\'INFO: Compiler %s (version %s) is not usable for this PyTorch \'\n                      \'installation, see the warning above.\' %\n                      (candidate_cxx_compiler, candidate_compiler_version))\n\n        if cc_compiler:\n            print(\'INFO: Compilers %s and %s (version %s) selected for PyTorch plugin build.\'\n                  \'\' % (cc_compiler, cxx_compiler, compiler_version))\n        else:\n            raise DistutilsPlatformError(\n                \'Could not find compiler compatible with this PyTorch installation.\\n\'\n                \'Please check the Horovod website for recommended compiler versions.\\n\'\n                \'To force a specific compiler version, set CC and CXX environment variables.\')\n\n        cflags, cppflags, ldshared = remove_offensive_gcc_compiler_options(compiler_version)\n\n    try:\n        with env(CC=cc_compiler, CXX=cxx_compiler, CFLAGS=cflags, CPPFLAGS=cppflags,\n                 LDSHARED=ldshared):\n            if options[\'BUILD_GLOO\']:\n                build_cmake(build_ext, gloo_lib, \'torchv2\', gloo_abi_flag, options, torch_mpi_lib_v2)\n            customize_compiler(build_ext.compiler)\n            build_ext.build_extension(torch_mpi_lib_v2)\n    finally:\n        # Revert to the default compiler settings\n        customize_compiler(build_ext.compiler)\n\n\ndef get_cmake_bin():\n    return os.environ.get(\'HOROVOD_CMAKE\', \'cmake\')\n\n\ndef build_cmake(build_ext, ext, prefix, additional_flags, options, plugin_ext=None):\n    cmake_bin = get_cmake_bin()\n\n    # All statically linked libraries will be placed here\n    lib_output_dir = os.path.abspath(os.path.join(build_ext.build_temp, \'lib\', prefix))\n    if not os.path.exists(lib_output_dir):\n        os.makedirs(lib_output_dir)\n\n    if plugin_ext:\n        plugin_ext.library_dirs.append(lib_output_dir)\n    options[\'LIBRARY_DIRS\'].append(lib_output_dir)\n\n    extdir = os.path.abspath(\n        os.path.dirname(build_ext.get_ext_fullpath(ext.name)))\n    config = \'Debug\' if build_ext.debug else \'Release\'\n\n    # Pass additional compiler flags by setting CMAKE_CXX_FLAGS_[DEBUG/RELEASE]\n    # so that cmake will append these flags to CMAKE_CXX_FLAGS\n    additional_cxx_flags = pipes.quote(\' \'.join(additional_flags))\n    cmake_cxx_flag = \'-DCMAKE_CXX_FLAGS_{type}:STRING={flags}\'.format(\n        type=config.upper(), flags=additional_cxx_flags)\n\n    use_mpi_flag = \'ON\' if options[\'BUILD_MPI\'] else \'OFF\'\n    cmake_args = [\'-DUSE_MPI=\' + use_mpi_flag,\n                  \'-DCMAKE_BUILD_TYPE=\' + config,\n                  cmake_cxx_flag,\n                  \'-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{}={}\'.format(config.upper(), extdir),\n                  \'-DCMAKE_ARCHIVE_OUTPUT_DIRECTORY_{}={}\'.format(config.upper(),\n                                                                  lib_output_dir),\n                  ]\n\n    cmake_build_args = [\n        \'--config\', config,\n        \'--\', \'-j4\',\n    ]\n\n    # Keep temp build files within a unique subdirectory\n    build_temp = os.path.abspath(os.path.join(build_ext.build_temp, ext.name, prefix))\n    if not os.path.exists(build_temp):\n        os.makedirs(build_temp)\n\n    # Config and build the extension\n    try:\n        subprocess.check_call([cmake_bin, ext.cmake_lists_dir] + cmake_args,\n                              cwd=build_temp)\n        subprocess.check_call([cmake_bin, \'--build\', \'.\'] + cmake_build_args,\n                              cwd=build_temp)\n    except OSError as e:\n        raise RuntimeError(\'CMake failed: {}\'.format(str(e)))\n\n    # Add the library so the plugin will link against it during compilation\n    options[\'LIBRARIES\'].append(ext.name)\n    if plugin_ext:\n        plugin_ext.libraries.append(ext.name)\n\n\n# run the customize_compiler\nclass custom_build_ext(build_ext):\n    def build_extensions(self):\n        options = get_common_options(self)\n        built_plugins = []\n\n        # If PyTorch is installed, it must be imported before TensorFlow, otherwise\n        # we may get an error: dlopen: cannot load any more object with static TLS\n        if not os.environ.get(\'HOROVOD_WITHOUT_PYTORCH\'):\n            dummy_import_torch()\n        if not os.environ.get(\'HOROVOD_WITHOUT_TENSORFLOW\'):\n            try:\n                build_tf_extension(self, options)\n                built_plugins.append(True)\n            except:\n                if not os.environ.get(\'HOROVOD_WITH_TENSORFLOW\'):\n                    print(\n                        \'INFO: Unable to build TensorFlow plugin, will skip it.\\n\\n\'\n                        \'%s\' % traceback.format_exc(), file=sys.stderr)\n                    built_plugins.append(False)\n                else:\n                    raise\n        if not os.environ.get(\'HOROVOD_WITHOUT_PYTORCH\'):\n            try:\n                torch_version = check_torch_version()\n                if torch_version >= 1000000000:\n                    build_torch_extension_v2(self, options, torch_version)\n                else:\n                    build_torch_extension(self, options, torch_version)\n                built_plugins.append(True)\n            except:\n                if not os.environ.get(\'HOROVOD_WITH_PYTORCH\'):\n                    print(\n                        \'INFO: Unable to build PyTorch plugin, will skip it.\\n\\n\'\n                        \'%s\' % traceback.format_exc(), file=sys.stderr)\n                    built_plugins.append(False)\n                else:\n                    raise\n        if not os.environ.get(\'HOROVOD_WITHOUT_MXNET\'):\n            try:\n                build_mx_extension(self, options)\n                built_plugins.append(True)\n            except:\n                if not os.environ.get(\'HOROVOD_WITH_MXNET\'):\n                    print(\n                        \'INFO: Unable to build MXNet plugin, will skip it.\\n\\n\'\n                        \'%s\' % traceback.format_exc(), file=sys.stderr)\n                    built_plugins.append(False)\n                else:\n                    raise\n        if not built_plugins:\n            raise DistutilsError(\n                \'TensorFlow, PyTorch, and MXNet plugins were excluded from build. Aborting.\')\n        if not any(built_plugins):\n            raise DistutilsError(\n                \'None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\')\n\n\nrequire_list = [\'cloudpickle\', \'psutil\', \'pyyaml\']\ntest_require_list = [\'mock\', \'pytest\', \'pytest-forked\']\n\n# framework dependencies\ntensorflow_require_list = [\'tensorflow\']\ntensorflow_cpu_require_list = [\'tensorflow-cpu\']\ntensorflow_gpu_require_list = [\'tensorflow-gpu\']\nkeras_require_list = [\'keras>=2.0.8,!=2.0.9,!=2.1.0,!=2.1.1\']\npytorch_require_list = [\'torch\']\nmxnet_require_list = [\'mxnet>=1.4.1\']\npyspark_require_list = [\'pyspark>=2.3.2;python_version<""3.8""\',\n                        # TODO: change to \'pyspark>=3.0.0\' once spark3 is released\n                        \'pyspark>=3.0.0.dev;python_version>=""3.8""\']\nspark_require_list = [\'h5py>=2.9\', \'numpy\', \'petastorm>=0.9.0\', \'pyarrow>=0.15.0\'] + \\\n                     pyspark_require_list\n# all frameworks\' dependencies\nall_frameworks_require_list = tensorflow_require_list + \\\n                              tensorflow_gpu_require_list + \\\n                              keras_require_list + \\\n                              pytorch_require_list + \\\n                              mxnet_require_list + \\\n                              spark_require_list\n\n# Skip cffi if pytorch extension explicitly disabled\nif not os.environ.get(\'HOROVOD_WITHOUT_PYTORCH\'):\n    require_list.append(\'cffi>=1.4.0\')\n\n\ndef get_package_version():\n    return __version__ + ""+"" + os.environ[\'HOROVOD_LOCAL_VERSION\'] if \'HOROVOD_LOCAL_VERSION\' in os.environ else __version__\n\n\nsetup(name=\'horovod\',\n      version=get_package_version(),\n      packages=find_packages(),\n      description=\'Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\',\n      author=\'The Horovod Authors\',\n      long_description=textwrap.dedent(\'\'\'\\\n          Horovod is a distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\n          The goal of Horovod is to make distributed Deep Learning fast and easy to use.\'\'\'),\n      url=\'https://github.com/horovod/horovod\',\n      keywords=[\'deep learning\', \'tensorflow\', \'keras\', \'pytorch\', \'mxnet\', \'spark\', \'AI\'],\n      classifiers=[\n          \'License :: OSI Approved :: Apache Software License\',\n          \'Development Status :: 4 - Beta\',\n          \'Intended Audience :: Developers\',\n          \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n      ],\n      ext_modules=[tensorflow_mpi_lib, torch_mpi_lib, torch_mpi_lib_impl,\n                   torch_mpi_lib_v2, mxnet_mpi_lib, gloo_lib],\n      cmdclass={\'build_ext\': custom_build_ext},\n      # cffi is required for PyTorch\n      # If cffi is specified in setup_requires, it will need libffi to be installed on the machine,\n      # which is undesirable.  Luckily, `install` action will install cffi before executing build,\n      # so it\'s only necessary for `build*` or `bdist*` actions.\n      setup_requires=require_list if is_build_action() else [],\n      install_requires=require_list,\n      tests_require=test_require_list,\n      extras_require={\n          \'all-frameworks\': all_frameworks_require_list,\n          \'tensorflow\': tensorflow_require_list,\n          \'tensorflow-cpu\': tensorflow_cpu_require_list,\n          \'tensorflow-gpu\': tensorflow_gpu_require_list,\n          \'keras\': keras_require_list,\n          \'pytorch\': pytorch_require_list,\n          \'mxnet\': mxnet_require_list,\n          \'spark\': spark_require_list\n      },\n      python_requires=\'>=3.6\',\n      zip_safe=False,\n      entry_points={\n          \'console_scripts\': [\n              \'horovodrun = horovod.run.runner:run_commandline\'\n          ]\n      })\n'"
docs/conf.py,0,"b'# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'.\'))\nsys.path.insert(0, os.path.abspath(\'..\'))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'Horovod\'\ncopyright = \'2019, The Horovod Authors\'\nauthor = \'The Horovod Authors\'\n\nfrom horovod import __version__\nversion = __version__\n\n\n# -- Mocking configuration ---------------------------------------------------\n\nimport mocks\nmocks.instrument()\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.viewcode\',\n    \'sphinxcontrib.napoleon\',\n    \'nbsphinx\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n\n# -- Autodoc configuration ---------------------------------------------------\n\nautodoc_default_options = {\n    \'members\': None,\n    \'member-order\': \'bysource\',\n    \'imported-members\': None,\n    \'exclude-members\': \'contextmanager, LooseVersion, tf, keras, torch, mx, pyspark\',\n}\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# For alabaster: https://alabaster.readthedocs.io/en/latest/customization.html\n#\nhtml_theme_options = {\n    \'logo\': \'logo.png\',\n    \'description\': \'Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\',\n    \'github_user\': \'horovod\',\n    \'github_repo\': \'horovod\',\n    \'github_button\': True,\n    \'github_type\': \'star\',\n    \'github_count\': \'true\',\n    \'fixed_sidebar\': False,\n    \'sidebar_collapse\': True,\n    \'font_family\': \'Helvetica Neue\'\n}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n'"
docs/mocks.py,0,"b'# Copyright 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport sys\nfrom unittest.mock import MagicMock\n\n\nclass Empty(object):\n    pass\n\n\nclass HasOutputCols(object):\n    pass\n\n\nclass Params(object):\n    @staticmethod\n    def _dummy():\n        return MagicMock()\n\n\nMOCK_MODULES = [\n    \'cloudpickle\',\n    \'ctypes\',\n    \'h5py\',\n    \'psutil\',\n\n    \'pyarrow\',\n    \'pyarrow.parquet\',\n\n    \'numpy\',\n    \'numpy.core.multiarray\',\n    \'numpy.dtype\',\n\n    \'pyspark\',\n    \'pyspark.ml\',\n    \'pyspark.ml.linalg\',\n    \'pyspark.ml.param\',\n    \'pyspark.ml.param.shared\',\n    \'pyspark.ml.util\',\n    \'pyspark.sql\',\n    \'pyspark.sql.functions\',\n    \'pyspark.sql.types\',\n\n    \'tensorflow\',\n    \'tensorflow.python\',\n    \'tensorflow.python.framework\',\n    \'tensorflow.python.platform\',\n    \'tensorflow.python.eager\',\n    \'tensorflow.python.keras\',\n\n    \'keras\',\n    \'keras.backend\',\n\n    \'torch\',\n    \'torch.autograd.function\',\n    \'torch.nn.functional\',\n    \'torch.nn.modules.batchnorm\',\n    \'torch.utils\',\n    \'torch.utils.data\',\n    \'torch.utils.tensorboard\',\n\n    \'mxnet\',\n    \'mxnet.base\',\n\n    \'horovod.common.util\',\n    \'horovod.torch.mpi_lib_v2\',\n]\n\n\nMOCK_TREE = {\n    \'tensorflow\': {\n        \'__version__\': \'1.14.0\',\n        \'train\': {\n            \'Optimizer\': MagicMock,\n            \'SessionRunHook\': MagicMock,\n        },\n        \'estimator\': {\n            \'SessionRunHook\': MagicMock,\n        },\n        \'keras\': {\n            \'callbacks\': {\n                \'Callback\': MagicMock,\n            },\n        },\n    },\n    \'keras\': {\n        \'callbacks\': {\n            \'Callback\': MagicMock,\n        },\n    },\n    \'torch\': {\n        \'__version__\': \'1.0.0\',\n        \'nn\': {\n            \'modules\': {\n                \'batchnorm\': {\n                    \'_BatchNorm\': MagicMock,\n                }\n            },\n        },\n    },\n    \'pyspark\': {\n        \'ml\': {\n            \'Estimator\': Empty,\n            \'Model\': Empty,\n            \'param\': {\n                \'shared\': {\n                    \'HasOutputCols\': HasOutputCols,\n                    \'Param\': MagicMock,\n                    \'Params\': Params,\n                    \'TypeConverters\': MagicMock(),\n                },\n            },\n            \'util\': {\n                \'MLReadable\': Empty,\n                \'MLWritable\': Empty,\n            }\n        },\n    },\n    \'horovod\': {\n        \'common\': {\n            \'util\': {\n                \'get_ext_suffix\': lambda: \'xyz\',\n            },\n        },\n        \'spark\': {\n            \'keras\': {\n                \'estimator\': {\n                    \'KerasEstimatorParamsReadable\': MagicMock,\n                    \'KerasEstimatorParamsWritable\': MagicMock,\n                },\n            },\n            \'torch\': {\n                \'estimator\': {\n                    \'TorchEstimatorParamsReadable\': MagicMock,\n                    \'TorchEstimatorParamsWritable\': MagicMock,\n                },\n            },\n        },\n    },\n}\n\n\ndef gen_mock_package(path):\n    if type(path) == str:\n        path = path.split(\'.\')\n\n    class TreeMock(MagicMock):\n        @classmethod\n        def __getattr__(cls, name):\n            full_path = path + [name]\n            tree_ptr = MOCK_TREE\n            for path_part in full_path:\n                if path_part in tree_ptr:\n                    if type(tree_ptr[path_part]) != dict:\n                        return tree_ptr[path_part]\n                    else:\n                        tree_ptr = tree_ptr[path_part]\n                else:\n                    return MagicMock()\n            return gen_mock_package(full_path)\n\n    return TreeMock()\n\n\ndef instrument():\n    sys.modules.update((mod_name, gen_mock_package(mod_name))\n                       for mod_name in MOCK_MODULES)\n'"
examples/adasum_small_model.py,0,"b'import torch\nimport random\nimport horovod.torch as hvd\nimport numpy as np\nimport argparse\nimport os\n\ndef sq(x):\n    m2 = 1.\n    m1 = -20.\n    m0 = 50.\n    return m2*x*x + m1*x + m0\n\ndef qu(x):\n    m3 = 10.\n    m2 = 5.\n    m1 = -20.\n    m0 = -5.\n    return m3*x*x*x + m2*x*x + m1*x + m0\n\nclass Net(torch.nn.Module):    \n    def __init__(self, mode = ""sq""):\n        super(Net, self).__init__()\n        \n        if mode == ""square"":\n            self.mode = 0\n            self.param = torch.nn.Parameter(torch.FloatTensor([1., -1.]))\n        else:\n            self.mode = 1\n            self.param = torch.nn.Parameter(torch.FloatTensor([1., -1., 1.]))\n\n    def forward(self, x):\n        if ~self.mode:\n            return x*x + self.param[0]*x + self.param[1]\n        else:\n            return 10*x*x*x + self.param[0]*x*x + self.param[1]*x + self.param[2]\n\ndef train(args):\n    hvd.init()\n\n    net = Net(args.mode)\n    optimizer = torch.optim.SGD(\n        net.parameters(),\n        lr=args.learning_rate,\n    )\n\n    num_steps = 50\n\n    np.random.seed(1 + hvd.rank())\n    torch.manual_seed(1234)\n\n    prev_zero = False\n\n    for step in range(1, num_steps + 1):\n        features = torch.Tensor(np.random.rand(1) * 2 * args.x_max - args.x_max)\n        if args.mode == ""square"": \n            labels = sq(features)  \n        else: \n            labels = qu(features)\n        optimizer.zero_grad()\n        outputs = net(features)\n        loss = torch.nn.MSELoss()(outputs, labels)\n        loss.backward()\n\n        if args.op == ""Average"":\n            net.param.grad.data = hvd.allreduce(net.param.grad.data, op=hvd.Average)\n        elif args.op == ""Adasum"":\n            net.param.grad.data = hvd.allreduce(net.param.grad.data, op=hvd.Adasum)\n\n        optimizer.step()\n\n        #Uncomment below lines to see how loss and gradients change with Adasum\n        #if hvd.rank() == 0:\n        #    print(step, loss.item(), net.param.grad.data[0].item(), net.param.grad.data[1].item())\n\n        if net.param.grad.data[0].item() == 0 and net.param.grad.data[1].item() == 0:\n            if prev_zero:\n                break\n            else:\n                prev_zero = True\n        else:\n            prev_zero = False\n\n\n    if step == num_steps:\n        step = 100\n\n    if hvd.rank() == 0:\n            print(args.x_max, args.op, args.learning_rate, hvd.size(), step)\n\nif __name__ == ""__main__"":\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--mode\', type=str, default=""square"", choices=[""square"", ""cubic""])\n    parser.add_argument(\'--op\', type=str, default=""Average"", choices=[""Average"", ""Adasum""], dest=\'op\')\n    parser.add_argument(\'--learning_rate\', type=float, default=0.1, dest=\'learning_rate\')\n    parser.add_argument(\'--x_max\', type=float, default=1., dest=\'x_max\')\n    args = parser.parse_args()\n\n    train(args)'"
examples/keras_imagenet_resnet50.py,2,"b""#\n# ResNet-50 model training using Keras and Horovod.\n#\n# This model is an example of a computation-intensive model that achieves good accuracy on an image\n# classification task.  It brings together distributed training concepts such as learning rate\n# schedule adjustments with a warmup, randomized data reading, and checkpointing on the first worker\n# only.\n#\n# Note: This model uses Keras native ImageDataGenerator and not the sophisticated preprocessing\n# pipeline that is typically used to train state-of-the-art ResNet-50 model.  This results in ~0.5%\n# increase in the top-1 validation error compared to the single-crop top-1 validation error from\n# https://github.com/KaimingHe/deep-residual-networks.\n#\nimport argparse\nimport keras\nfrom keras import backend as K\nfrom keras.preprocessing import image\nimport tensorflow as tf\nimport horovod.keras as hvd\nimport os\n\nparser = argparse.ArgumentParser(description='Keras ImageNet Example',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--train-dir', default=os.path.expanduser('~/imagenet/train'),\n                    help='path to training data')\nparser.add_argument('--val-dir', default=os.path.expanduser('~/imagenet/validation'),\n                    help='path to validation data')\nparser.add_argument('--log-dir', default='./logs',\n                    help='tensorboard log directory')\nparser.add_argument('--checkpoint-format', default='./checkpoint-{epoch}.h5',\n                    help='checkpoint file format')\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\n                    help='use fp16 compression during allreduce')\n\n# Default settings from https://arxiv.org/abs/1706.02677.\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size for training')\nparser.add_argument('--val-batch-size', type=int, default=32,\n                    help='input batch size for validation')\nparser.add_argument('--epochs', type=int, default=90,\n                    help='number of epochs to train')\nparser.add_argument('--base-lr', type=float, default=0.0125,\n                    help='learning rate for a single GPU')\nparser.add_argument('--warmup-epochs', type=float, default=5,\n                    help='number of warmup epochs')\nparser.add_argument('--momentum', type=float, default=0.9,\n                    help='SGD momentum')\nparser.add_argument('--wd', type=float, default=0.00005,\n                    help='weight decay')\n\nargs = parser.parse_args()\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\nK.set_session(tf.Session(config=config))\n\n# If set > 0, will resume training from a given checkpoint.\nresume_from_epoch = 0\nfor try_epoch in range(args.epochs, 0, -1):\n    if os.path.exists(args.checkpoint_format.format(epoch=try_epoch)):\n        resume_from_epoch = try_epoch\n        break\n\n# Horovod: broadcast resume_from_epoch from rank 0 (which will have\n# checkpoints) to other ranks.\nresume_from_epoch = hvd.broadcast(resume_from_epoch, 0, name='resume_from_epoch')\n\n# Horovod: print logs on the first worker.\nverbose = 1 if hvd.rank() == 0 else 0\n\n# Training data iterator.\ntrain_gen = image.ImageDataGenerator(\n    width_shift_range=0.33, height_shift_range=0.33, zoom_range=0.5, horizontal_flip=True,\n    preprocessing_function=keras.applications.resnet50.preprocess_input)\ntrain_iter = train_gen.flow_from_directory(args.train_dir,\n                                           batch_size=args.batch_size,\n                                           target_size=(224, 224))\n\n# Validation data iterator.\ntest_gen = image.ImageDataGenerator(\n    zoom_range=(0.875, 0.875), preprocessing_function=keras.applications.resnet50.preprocess_input)\ntest_iter = test_gen.flow_from_directory(args.val_dir,\n                                         batch_size=args.val_batch_size,\n                                         target_size=(224, 224))\n\n# Set up standard ResNet-50 model.\nmodel = keras.applications.resnet50.ResNet50(weights=None)\n\n# Horovod: (optional) compression algorithm.\ncompression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n# Horovod: adjust learning rate based on number of GPUs.\ninitial_lr = args.base_lr * hvd.size()\n\n# Restore from a previous checkpoint, if initial_epoch is specified.\n# Horovod: restore on the first worker which will broadcast both model and optimizer weights\n# to other workers.\nif resume_from_epoch > 0 and hvd.rank() == 0:\n    model = hvd.load_model(args.checkpoint_format.format(epoch=resume_from_epoch),\n                           compression=compression)\nelse:\n    # ResNet-50 model that is included with Keras is optimized for inference.\n    # Add L2 weight decay & adjust BN settings.\n    model_config = model.get_config()\n    for layer, layer_config in zip(model.layers, model_config['layers']):\n        if hasattr(layer, 'kernel_regularizer'):\n            regularizer = keras.regularizers.l2(args.wd)\n            layer_config['config']['kernel_regularizer'] = \\\n                {'class_name': regularizer.__class__.__name__,\n                 'config': regularizer.get_config()}\n        if type(layer) == keras.layers.BatchNormalization:\n            layer_config['config']['momentum'] = 0.9\n            layer_config['config']['epsilon'] = 1e-5\n\n    model = keras.models.Model.from_config(model_config)\n    opt = keras.optimizers.SGD(lr=initial_lr, momentum=args.momentum)\n\n    # Horovod: add Horovod Distributed Optimizer.\n    opt = hvd.DistributedOptimizer(opt, compression=compression)\n\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=opt,\n                  metrics=['accuracy', 'top_k_categorical_accuracy'])\n\ncallbacks = [\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n\n    # Horovod: average metrics among workers at the end of every epoch.\n    #\n    # Note: This callback must be in the list before the ReduceLROnPlateau,\n    # TensorBoard, or other metrics-based callbacks.\n    hvd.callbacks.MetricAverageCallback(),\n\n    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n    # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n    hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=args.warmup_epochs, initial_lr=initial_lr,\n                                             verbose=verbose),\n\n    # Horovod: after the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.\n    hvd.callbacks.LearningRateScheduleCallback(start_epoch=args.warmup_epochs, end_epoch=30, multiplier=1.,\n                                               initial_lr=initial_lr),\n    hvd.callbacks.LearningRateScheduleCallback(start_epoch=30, end_epoch=60, multiplier=1e-1, initial_lr=initial_lr),\n    hvd.callbacks.LearningRateScheduleCallback(start_epoch=60, end_epoch=80, multiplier=1e-2, initial_lr=initial_lr),\n    hvd.callbacks.LearningRateScheduleCallback(start_epoch=80, multiplier=1e-3, initial_lr=initial_lr),\n]\n\n# Horovod: save checkpoints only on the first worker to prevent other workers from corrupting them.\nif hvd.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint(args.checkpoint_format))\n    callbacks.append(keras.callbacks.TensorBoard(args.log_dir))\n\n# Train the model. The training will randomly sample 1 / N batches of training data and\n# 3 / N batches of validation data on every worker, where N is the number of workers.\n# Over-sampling of validation data helps to increase probability that every validation\n# example will be evaluated.\nmodel.fit_generator(train_iter,\n                    steps_per_epoch=len(train_iter) // hvd.size(),\n                    callbacks=callbacks,\n                    epochs=args.epochs,\n                    verbose=verbose,\n                    workers=4,\n                    initial_epoch=resume_from_epoch,\n                    validation_data=test_iter,\n                    validation_steps=3 * len(test_iter) // hvd.size())\n\n# Evaluate the model on the full data set.\nscore = hvd.allreduce(model.evaluate_generator(test_iter, len(test_iter), workers=4))\nif verbose:\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n"""
examples/keras_mnist.py,2,"b""import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nimport math\nimport tensorflow as tf\nimport horovod.keras as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\nK.set_session(tf.Session(config=config))\n\nbatch_size = 128\nnum_classes = 10\n\n# Horovod: adjust number of epochs based on number of GPUs.\nepochs = int(math.ceil(12.0 / hvd.size()))\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# The data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Horovod: adjust learning rate based on number of GPUs.\nopt = keras.optimizers.Adadelta(1.0 * hvd.size())\n\n# Horovod: add Horovod Distributed Optimizer.\nopt = hvd.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n]\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif hvd.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          callbacks=callbacks,\n          epochs=epochs,\n          verbose=1 if hvd.rank() == 0 else 0,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
examples/keras_mnist_advanced.py,2,"b""import argparse\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nimport tensorflow as tf\nimport horovod.keras as hvd\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\nparser.add_argument('--batch-size', type=int, default=128, metavar='N',\n                    help='input batch size for training (default: 128)')\nparser.add_argument('--epochs', type=int, default=24, metavar='N',\n                    help='number of epochs to train (default: 24)')\nparser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n                    help='learning rate (default: 1.0)')\n\nargs = parser.parse_args()\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\nK.set_session(tf.Session(config=config))\n\nbatch_size = args.batch_size\nnum_classes = 10\n\n# Enough epochs to demonstrate learning rate warmup and the reduction of\n# learning rate when training plateaues.\nepochs = args.epochs\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# The data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Determine how many batches are there in train and test sets\ntrain_batches = len(x_train) // batch_size\ntest_batches = len(x_test) // batch_size\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Horovod: adjust learning rate based on number of GPUs.\nscaled_lr = args.lr * hvd.size()\nopt = keras.optimizers.Adadelta(lr=scaled_lr)\n\n# Horovod: add Horovod Distributed Optimizer.\nopt = hvd.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n\n    # Horovod: average metrics among workers at the end of every epoch.\n    #\n    # Note: This callback must be in the list before the ReduceLROnPlateau,\n    # TensorBoard or other metrics-based callbacks.\n    hvd.callbacks.MetricAverageCallback(),\n\n    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n    # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n    hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=5, initial_lr=scaled_lr, verbose=1),\n\n    # Reduce the learning rate if training plateaues.\n    keras.callbacks.ReduceLROnPlateau(patience=10, verbose=1),\n]\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif hvd.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\n# Set up ImageDataGenerators to do data augmentation for the training images.\ntrain_gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                               height_shift_range=0.08, zoom_range=0.08)\ntest_gen = ImageDataGenerator()\n\n# Train the model.\n# Horovod: the training will randomly sample 1 / N batches of training data and\n# 3 / N batches of validation data on every worker, where N is the number of workers.\n# Over-sampling of validation data helps to increase probability that every validation\n# example will be evaluated.\nmodel.fit_generator(train_gen.flow(x_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=train_batches // hvd.size(),\n                    callbacks=callbacks,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=test_gen.flow(x_test, y_test, batch_size=batch_size),\n                    validation_steps=3 * test_batches // hvd.size())\n\n# Evaluate the model on the full data set.\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
examples/keras_spark3_rossmann.py,29,"b'# Copyright 2017 onwards, fast.ai, Inc.\n# Modifications copyright (C) 2018 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport datetime\nimport h5py\nimport io\nimport os\nimport pyarrow as pa\nfrom pyspark import SparkConf, Row\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.types as T\nimport pyspark.sql.functions as F\n\nparser = argparse.ArgumentParser(description=\'Keras Spark3 Rossmann Run Example\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--processing-master\',\n                    help=\'spark cluster to use for light processing (data preparation & prediction).\'\n                         \'If set to None, uses current default cluster. Cluster should be set up to provide\'\n                         \'one task per CPU core. Example: spark://hostname:7077\')\nparser.add_argument(\'--training-master\', default=\'local-cluster[2,1,1024]\',\n                    help=\'spark cluster to use for training. If set to None, uses current default cluster. Cluster\'\n                         \'should be set up to provide a Spark task per multiple CPU cores, or per GPU, e.g. by\'\n                         \'supplying `-c <NUM_GPUS>` in Spark Standalone mode. Example: spark://hostname:7077\')\nparser.add_argument(\'--num-proc\', type=int, default=4,\n                    help=\'number of worker processes for training, default: `spark.default.parallelism`\')\nparser.add_argument(\'--learning-rate\', type=float, default=0.0001,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--batch-size\', type=int, default=100,\n                    help=\'batch size\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs to train\')\nparser.add_argument(\'--sample-rate\', type=float,\n                    help=\'desired sampling rate. Useful to set to low number (e.g. 0.01) to make sure that \'\n                         \'end-to-end process works\')\nparser.add_argument(\'--data-dir\', default=\'file://\' + os.getcwd(),\n                    help=\'location of data on local filesystem (prefixed with file://) or on HDFS\')\nparser.add_argument(\'--local-submission-csv\', default=\'submission.csv\',\n                    help=\'output submission predictions CSV on local filesystem (without file:// prefix)\')\nparser.add_argument(\'--local-checkpoint-file\', default=\'checkpoint.h5\',\n                    help=\'model checkpoint on local filesystem (without file:// prefix)\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n\n    # Location of discovery script on local filesystem.\n    DISCOVERY_SCRIPT = \'get_gpu_resources.sh\'\n\n    # HDFS driver to use with Petastorm.\n    PETASTORM_HDFS_DRIVER = \'libhdfs\'\n\n    # Whether to infer on GPU.\n    GPU_INFERENCE_ENABLED = False\n\n    # Cluster for GPU inference.\n    GPU_INFERENCE_CLUSTER = \'local-cluster[2,1,1024]\'  # or \'spark://hostname:7077\'\n\n    # ================ #\n    # DATA PREPARATION #\n    # ================ #\n\n    print(\'================\')\n    print(\'Data preparation\')\n    print(\'================\')\n\n    # Create Spark session for data preparation.\n    conf = SparkConf().setAppName(\'data_prep\').set(\'spark.sql.shuffle.partitions\', \'16\')\n    if args.processing_master:\n        conf.setMaster(args.processing_master)\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    train_csv = spark.read.csv(\'%s/train.csv\' % args.data_dir, header=True)\n    test_csv = spark.read.csv(\'%s/test.csv\' % args.data_dir, header=True)\n\n    store_csv = spark.read.csv(\'%s/store.csv\' % args.data_dir, header=True)\n    store_states_csv = spark.read.csv(\'%s/store_states.csv\' % args.data_dir, header=True)\n    state_names_csv = spark.read.csv(\'%s/state_names.csv\' % args.data_dir, header=True)\n    google_trend_csv = spark.read.csv(\'%s/googletrend.csv\' % args.data_dir, header=True)\n    weather_csv = spark.read.csv(\'%s/weather.csv\' % args.data_dir, header=True)\n\n\n    def expand_date(df):\n        df = df.withColumn(\'Date\', df.Date.cast(T.DateType()))\n        return df \\\n            .withColumn(\'Year\', F.year(df.Date)) \\\n            .withColumn(\'Month\', F.month(df.Date)) \\\n            .withColumn(\'Week\', F.weekofyear(df.Date)) \\\n            .withColumn(\'Day\', F.dayofmonth(df.Date))\n\n\n    def prepare_google_trend():\n        # Extract week start date and state.\n        google_trend_all = google_trend_csv \\\n            .withColumn(\'Date\', F.regexp_extract(google_trend_csv.week, \'(.*?) -\', 1)) \\\n            .withColumn(\'State\', F.regexp_extract(google_trend_csv.file, \'Rossmann_DE_(.*)\', 1))\n\n        # Map state NI -> HB,NI to align with other data sources.\n        google_trend_all = google_trend_all \\\n            .withColumn(\'State\', F.when(google_trend_all.State == \'NI\', \'HB,NI\').otherwise(google_trend_all.State))\n\n        # Expand dates.\n        return expand_date(google_trend_all)\n\n\n    def add_elapsed(df, cols):\n        def add_elapsed_column(col, asc):\n            def fn(rows):\n                last_store, last_date = None, None\n                for r in rows:\n                    if last_store != r.Store:\n                        last_store = r.Store\n                        last_date = r.Date\n                    if r[col]:\n                        last_date = r.Date\n                    fields = r.asDict().copy()\n                    fields[(\'After\' if asc else \'Before\') + col] = (r.Date - last_date).days\n                    yield Row(**fields)\n            return fn\n\n        df = df.repartition(df.Store)\n        for asc in [False, True]:\n            sort_col = df.Date.asc() if asc else df.Date.desc()\n            rdd = df.sortWithinPartitions(df.Store.asc(), sort_col).rdd\n            for col in cols:\n                rdd = rdd.mapPartitions(add_elapsed_column(col, asc))\n            df = rdd.toDF()\n        return df\n\n\n    def prepare_df(df):\n        num_rows = df.count()\n\n        # Expand dates.\n        df = expand_date(df)\n\n        df = df \\\n            .withColumn(\'Open\', df.Open != \'0\') \\\n            .withColumn(\'Promo\', df.Promo != \'0\') \\\n            .withColumn(\'StateHoliday\', df.StateHoliday != \'0\') \\\n            .withColumn(\'SchoolHoliday\', df.SchoolHoliday != \'0\')\n\n        # Merge in store information.\n        store = store_csv.join(store_states_csv, \'Store\')\n        df = df.join(store, \'Store\')\n\n        # Merge in Google Trend information.\n        google_trend_all = prepare_google_trend()\n        df = df.join(google_trend_all, [\'State\', \'Year\', \'Week\']).select(df[\'*\'], google_trend_all.trend)\n\n        # Merge in Google Trend for whole Germany.\n        google_trend_de = google_trend_all[google_trend_all.file == \'Rossmann_DE\']\n        google_trend_de = google_trend_de.withColumnRenamed(\'trend\', \'trend_de\')\n        df = df.join(google_trend_de, [\'Year\', \'Week\']).select(df[\'*\'], google_trend_de.trend_de)\n\n        # Merge in weather.\n        weather = weather_csv.join(state_names_csv, weather_csv.file == state_names_csv.StateName)\n        df = df.join(weather, [\'State\', \'Date\'])\n\n        # Fix null values.\n        df = df \\\n            .withColumn(\'CompetitionOpenSinceYear\', F.coalesce(df.CompetitionOpenSinceYear, F.lit(1900))) \\\n            .withColumn(\'CompetitionOpenSinceMonth\', F.coalesce(df.CompetitionOpenSinceMonth, F.lit(1))) \\\n            .withColumn(\'Promo2SinceYear\', F.coalesce(df.Promo2SinceYear, F.lit(1900))) \\\n            .withColumn(\'Promo2SinceWeek\', F.coalesce(df.Promo2SinceWeek, F.lit(1)))\n\n        # Days & months competition was open, cap to 2 years.\n        df = df.withColumn(\'CompetitionOpenSince\',\n                           F.to_date(F.format_string(\'%s-%s-15\', df.CompetitionOpenSinceYear,\n                                                     df.CompetitionOpenSinceMonth)))\n        df = df.withColumn(\'CompetitionDaysOpen\',\n                           F.when(df.CompetitionOpenSinceYear > 1900,\n                                  F.greatest(F.lit(0), F.least(F.lit(360 * 2), F.datediff(df.Date, df.CompetitionOpenSince))))\n                           .otherwise(0))\n        df = df.withColumn(\'CompetitionMonthsOpen\', (df.CompetitionDaysOpen / 30).cast(T.IntegerType()))\n\n        # Days & weeks of promotion, cap to 25 weeks.\n        df = df.withColumn(\'Promo2Since\',\n                           F.expr(\'date_add(format_string(""%s-01-01"", Promo2SinceYear), (cast(Promo2SinceWeek as int) - 1) * 7)\'))\n        df = df.withColumn(\'Promo2Days\',\n                           F.when(df.Promo2SinceYear > 1900,\n                                  F.greatest(F.lit(0), F.least(F.lit(25 * 7), F.datediff(df.Date, df.Promo2Since))))\n                           .otherwise(0))\n        df = df.withColumn(\'Promo2Weeks\', (df.Promo2Days / 7).cast(T.IntegerType()))\n\n        # Check that we did not lose any rows through inner joins.\n        assert num_rows == df.count(), \'lost rows in joins\'\n        return df\n\n\n    def build_vocabulary(df, cols):\n        vocab = {}\n        for col in cols:\n            values = [r[0] for r in df.select(col).distinct().collect()]\n            col_type = type([x for x in values if x is not None][0])\n            default_value = col_type()\n            vocab[col] = sorted(values, key=lambda x: x or default_value)\n        return vocab\n\n\n    def cast_columns(df, cols):\n        for col in cols:\n            df = df.withColumn(col, F.coalesce(df[col].cast(T.FloatType()), F.lit(0.0)))\n        return df\n\n\n    def lookup_columns(df, vocab):\n        def lookup(mapping):\n            def fn(v):\n                return mapping.index(v)\n            return F.udf(fn, returnType=T.IntegerType())\n\n        for col, mapping in vocab.items():\n            df = df.withColumn(col, lookup(mapping)(df[col]))\n        return df\n\n\n    if args.sample_rate:\n        train_csv = train_csv.sample(withReplacement=False, fraction=args.sample_rate)\n        test_csv = test_csv.sample(withReplacement=False, fraction=args.sample_rate)\n\n    # Prepare data frames from CSV files.\n    train_df = prepare_df(train_csv).cache()\n    test_df = prepare_df(test_csv).cache()\n\n    # Add elapsed times from holidays & promos, the data spanning training & test datasets.\n    elapsed_cols = [\'Promo\', \'StateHoliday\', \'SchoolHoliday\']\n    elapsed = add_elapsed(train_df.select(\'Date\', \'Store\', *elapsed_cols)\n                                  .unionAll(test_df.select(\'Date\', \'Store\', *elapsed_cols)),\n                          elapsed_cols)\n\n    # Join with elapsed times.\n    train_df = train_df \\\n        .join(elapsed, [\'Date\', \'Store\']) \\\n        .select(train_df[\'*\'], *[prefix + col for prefix in [\'Before\', \'After\'] for col in elapsed_cols])\n    test_df = test_df \\\n        .join(elapsed, [\'Date\', \'Store\']) \\\n        .select(test_df[\'*\'], *[prefix + col for prefix in [\'Before\', \'After\'] for col in elapsed_cols])\n\n    # Filter out zero sales.\n    train_df = train_df.filter(train_df.Sales > 0)\n\n    print(\'===================\')\n    print(\'Prepared data frame\')\n    print(\'===================\')\n    train_df.show()\n\n    categorical_cols = [\n        \'Store\', \'State\', \'DayOfWeek\', \'Year\', \'Month\', \'Day\', \'Week\', \'CompetitionMonthsOpen\', \'Promo2Weeks\', \'StoreType\',\n        \'Assortment\', \'PromoInterval\', \'CompetitionOpenSinceYear\', \'Promo2SinceYear\', \'Events\', \'Promo\',\n        \'StateHoliday\', \'SchoolHoliday\'\n    ]\n\n    continuous_cols = [\n        \'CompetitionDistance\', \'Max_TemperatureC\', \'Mean_TemperatureC\', \'Min_TemperatureC\', \'Max_Humidity\',\n        \'Mean_Humidity\', \'Min_Humidity\', \'Max_Wind_SpeedKm_h\', \'Mean_Wind_SpeedKm_h\', \'CloudCover\', \'trend\', \'trend_DE\',\n        \'BeforePromo\', \'AfterPromo\', \'AfterStateHoliday\', \'BeforeStateHoliday\', \'BeforeSchoolHoliday\', \'AfterSchoolHoliday\'\n    ]\n\n    all_cols = categorical_cols + continuous_cols\n\n    # Select features.\n    train_df = train_df.select(*(all_cols + [\'Sales\', \'Date\'])).cache()\n    test_df = test_df.select(*(all_cols + [\'Id\', \'Date\'])).cache()\n\n    # Build vocabulary of categorical columns.\n    vocab = build_vocabulary(train_df.select(*categorical_cols)\n                                     .unionAll(test_df.select(*categorical_cols)).cache(),\n                             categorical_cols)\n\n    # Cast continuous columns to float & lookup categorical columns.\n    train_df = cast_columns(train_df, continuous_cols + [\'Sales\'])\n    train_df = lookup_columns(train_df, vocab)\n    test_df = cast_columns(test_df, continuous_cols)\n    test_df = lookup_columns(test_df, vocab)\n\n    # Split into training & validation.\n    # Test set is in 2015, use the same period in 2014 from the training set as a validation set.\n    test_min_date = test_df.agg(F.min(test_df.Date)).collect()[0][0]\n    test_max_date = test_df.agg(F.max(test_df.Date)).collect()[0][0]\n    a_year = datetime.timedelta(365)\n    val_df = train_df.filter((test_min_date - a_year <= train_df.Date) & (train_df.Date < test_max_date - a_year))\n    train_df = train_df.filter((train_df.Date < test_min_date - a_year) | (train_df.Date >= test_max_date - a_year))\n\n    # Determine max Sales number.\n    max_sales = train_df.agg(F.max(train_df.Sales)).collect()[0][0]\n\n    print(\'===================================\')\n    print(\'Data frame with transformed columns\')\n    print(\'===================================\')\n    train_df.show()\n\n    print(\'================\')\n    print(\'Data frame sizes\')\n    print(\'================\')\n    train_rows, val_rows, test_rows = train_df.count(), val_df.count(), test_df.count()\n    print(\'Training: %d\' % train_rows)\n    print(\'Validation: %d\' % val_rows)\n    print(\'Test: %d\' % test_rows)\n\n    # Save data frames as Parquet files.\n    train_df.write.parquet(\'%s/train_df.parquet\' % args.data_dir, mode=\'overwrite\')\n    val_df.write.parquet(\'%s/val_df.parquet\' % args.data_dir, mode=\'overwrite\')\n    test_df.write.parquet(\'%s/test_df.parquet\' % args.data_dir, mode=\'overwrite\')\n\n    spark.stop()\n\n    # ============== #\n    # MODEL TRAINING #\n    # ============== #\n\n    print(\'==============\')\n    print(\'Model training\')\n    print(\'==============\')\n\n    import tensorflow as tf\n    from tensorflow.keras.layers import Input, Embedding, Concatenate, Dense, Flatten, Reshape, BatchNormalization, Dropout\n    import tensorflow.keras.backend as K\n    import horovod.spark\n    import horovod.tensorflow.keras as hvd\n\n\n    def exp_rmspe(y_true, y_pred):\n        """"""Competition evaluation metric, expects logarithic inputs.""""""\n        pct = tf.square((tf.exp(y_true) - tf.exp(y_pred)) / tf.exp(y_true))\n        # Compute mean excluding stores with zero denominator.\n        x = tf.reduce_sum(tf.where(y_true > 0.001, pct, tf.zeros_like(pct)))\n        y = tf.reduce_sum(tf.where(y_true > 0.001, tf.ones_like(pct), tf.zeros_like(pct)))\n        return tf.sqrt(x / y)\n\n\n    def act_sigmoid_scaled(x):\n        """"""Sigmoid scaled to logarithm of maximum sales scaled by 20%.""""""\n        return tf.nn.sigmoid(x) * tf.log(max_sales) * 1.2\n\n\n    CUSTOM_OBJECTS = {\'exp_rmspe\': exp_rmspe,\n                      \'act_sigmoid_scaled\': act_sigmoid_scaled}\n\n\n    def serialize_model(model):\n        """"""Serialize model into byte array.""""""\n        bio = io.BytesIO()\n        with h5py.File(bio) as f:\n            model.save(f)\n        return bio.getvalue()\n\n\n    def deserialize_model(model_bytes, load_model_fn):\n        """"""Deserialize model from byte array.""""""\n        bio = io.BytesIO(model_bytes)\n        with h5py.File(bio) as f:\n            return load_model_fn(f, custom_objects=CUSTOM_OBJECTS)\n\n\n    # Do not use GPU for the session creation.\n    config = tf.ConfigProto(device_count={\'GPU\': 0})\n    K.set_session(tf.Session(config=config))\n\n    # Build the model.\n    inputs = {col: Input(shape=(1,), name=col) for col in all_cols}\n    embeddings = [Embedding(len(vocab[col]), 10, input_length=1, name=\'emb_\' + col)(inputs[col])\n                  for col in categorical_cols]\n    continuous_bn = Concatenate()([Reshape((1, 1), name=\'reshape_\' + col)(inputs[col])\n                                   for col in continuous_cols])\n    continuous_bn = BatchNormalization()(continuous_bn)\n    x = Concatenate()(embeddings + [continuous_bn])\n    x = Flatten()(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(500, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dropout(0.5)(x)\n    output = Dense(1, activation=act_sigmoid_scaled)(x)\n    model = tf.keras.Model([inputs[f] for f in all_cols], output)\n    model.summary()\n\n    # Horovod: add Distributed Optimizer.\n    opt = tf.keras.optimizers.Adam(lr=args.learning_rate, epsilon=1e-3)\n    opt = hvd.DistributedOptimizer(opt)\n    model.compile(opt, \'mae\', metrics=[exp_rmspe])\n    model_bytes = serialize_model(model)\n\n\n    def train_fn(model_bytes):\n        # Make sure pyarrow is referenced before anything else to avoid segfault due to conflict\n        # with TensorFlow libraries.  Use `pa` package reference to ensure it\'s loaded before\n        # functions like `deserialize_model` which are implemented at the top level.\n        # See https://jira.apache.org/jira/browse/ARROW-3346\n        pa\n\n        import atexit\n        import horovod.tensorflow.keras as hvd\n        from horovod.spark.task import get_available_devices\n        import os\n        from petastorm import make_batch_reader\n        from petastorm.tf_utils import make_petastorm_dataset\n        import tempfile\n        import tensorflow as tf\n        import tensorflow.keras.backend as K\n        import shutil\n\n        # Horovod: initialize Horovod inside the trainer.\n        hvd.init()\n\n        # Horovod: pin GPU to be used to process local rank (one GPU per process), if GPUs are available.\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.gpu_options.visible_device_list = get_available_devices()[0]\n        K.set_session(tf.Session(config=config))\n\n        # Horovod: restore from checkpoint, use hvd.load_model under the hood.\n        model = deserialize_model(model_bytes, hvd.load_model)\n\n        # Horovod: adjust learning rate based on number of processes.\n        scaled_lr = K.get_value(model.optimizer.lr) * hvd.size()\n        K.set_value(model.optimizer.lr, scaled_lr)\n\n        # Horovod: print summary logs on the first worker.\n        verbose = 2 if hvd.rank() == 0 else 0\n\n        callbacks = [\n            # Horovod: broadcast initial variable states from rank 0 to all other processes.\n            # This is necessary to ensure consistent initialization of all workers when\n            # training is started with random weights or restored from a checkpoint.\n            hvd.callbacks.BroadcastGlobalVariablesCallback(root_rank=0),\n\n            # Horovod: average metrics among workers at the end of every epoch.\n            #\n            # Note: This callback must be in the list before the ReduceLROnPlateau,\n            # TensorBoard, or other metrics-based callbacks.\n            hvd.callbacks.MetricAverageCallback(),\n\n            # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n            # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n            # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n            hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=5, initial_lr=scaled_lr, verbose=verbose),\n\n            # Reduce LR if the metric is not improved for 10 epochs, and stop training\n            # if it has not improved for 20 epochs.\n            tf.keras.callbacks.ReduceLROnPlateau(monitor=\'val_exp_rmspe\', patience=10, verbose=verbose),\n            tf.keras.callbacks.EarlyStopping(monitor=\'val_exp_rmspe\', mode=\'min\', patience=20, verbose=verbose),\n            tf.keras.callbacks.TerminateOnNaN()\n        ]\n\n        # Model checkpoint location.\n        ckpt_dir = tempfile.mkdtemp()\n        ckpt_file = os.path.join(ckpt_dir, \'checkpoint.h5\')\n        atexit.register(lambda: shutil.rmtree(ckpt_dir))\n\n        # Horovod: save checkpoints only on the first worker to prevent other workers from corrupting them.\n        if hvd.rank() == 0:\n            callbacks.append(tf.keras.callbacks.ModelCheckpoint(ckpt_file, monitor=\'val_exp_rmspe\', mode=\'min\',\n                                                                save_best_only=True))\n\n        # Make Petastorm readers.\n        with make_batch_reader(\'%s/train_df.parquet\' % args.data_dir, num_epochs=None,\n                               cur_shard=hvd.rank(), shard_count=hvd.size(),\n                               hdfs_driver=PETASTORM_HDFS_DRIVER) as train_reader:\n            with make_batch_reader(\'%s/val_df.parquet\' % args.data_dir, num_epochs=None,\n                                   cur_shard=hvd.rank(), shard_count=hvd.size(),\n                                   hdfs_driver=PETASTORM_HDFS_DRIVER) as val_reader:\n                # Convert readers to tf.data.Dataset.\n                train_ds = make_petastorm_dataset(train_reader) \\\n                    .apply(tf.data.experimental.unbatch()) \\\n                    .shuffle(int(train_rows / hvd.size())) \\\n                    .batch(args.batch_size) \\\n                    .map(lambda x: (tuple(getattr(x, col) for col in all_cols), tf.log(x.Sales)))\n\n                val_ds = make_petastorm_dataset(val_reader) \\\n                    .apply(tf.data.experimental.unbatch()) \\\n                    .batch(args.batch_size) \\\n                    .map(lambda x: (tuple(getattr(x, col) for col in all_cols), tf.log(x.Sales)))\n\n                history = model.fit(train_ds,\n                                    validation_data=val_ds,\n                                    steps_per_epoch=int(train_rows / args.batch_size / hvd.size()),\n                                    validation_steps=int(val_rows / args.batch_size / hvd.size()),\n                                    callbacks=callbacks,\n                                    verbose=verbose,\n                                    epochs=args.epochs)\n\n        # Dataset API usage currently displays a wall of errors upon termination.\n        # This global model registration ensures clean termination.\n        # Tracked in https://github.com/tensorflow/tensorflow/issues/24570\n        globals()[\'_DATASET_FINALIZATION_HACK\'] = model\n\n        if hvd.rank() == 0:\n            with open(ckpt_file, \'rb\') as f:\n                return history.history, f.read()\n\n\n    def set_gpu_conf(conf):\n        # This config will change depending on your cluster setup.\n        #\n        # 1. Standalone Cluster\n        # - Must configure spark.worker.* configs as below.\n        #\n        # 2. YARN\n        # - Requires YARN 3.1 or higher to support GPUs\n        # - Cluster should be configured to have isolation on so that\n        #   multiple executors don\xe2\x80\x99t see the same GPU on the same host.\n        # - If you don\xe2\x80\x99t have isolation then you would require a different discovery script\n        #   or other way to make sure that 2 executors don\xe2\x80\x99t try to use same GPU.\n        #\n        # 3. Kubernetes\n        # - Requires GPU support and isolation.\n        # - Add conf.set(\xe2\x80\x9cspark.executor.resource.gpu.discoveryScript\xe2\x80\x9d, DISCOVERY_SCRIPT)\n        # - Add conf.set(\xe2\x80\x9cspark.executor.resource.gpu.vendor\xe2\x80\x9d, \xe2\x80\x9cnvidia.com\xe2\x80\x9d)\n        conf = conf.set(""spark.test.home"", os.environ.get(\'SPARK_HOME\'))\n        conf = conf.set(""spark.worker.resource.gpu.discoveryScript"", DISCOVERY_SCRIPT)\n        conf = conf.set(""spark.worker.resource.gpu.amount"", 1)\n        conf = conf.set(""spark.task.resource.gpu.amount"", ""1"")\n        conf = conf.set(""spark.executor.resource.gpu.amount"", ""1"")\n        return conf\n\n\n    # Create Spark session for training.\n    conf = SparkConf().setAppName(\'training\')\n    if args.training_master:\n        conf.setMaster(args.training_master)\n    conf = set_gpu_conf(conf)\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    # Horovod: run training.\n    history, best_model_bytes = \\\n        horovod.spark.run(train_fn, args=(model_bytes,), num_proc=args.num_proc, verbose=2)[0]\n\n    best_val_rmspe = min(history[\'val_exp_rmspe\'])\n    print(\'Best RMSPE: %f\' % best_val_rmspe)\n\n    # Write checkpoint.\n    with open(args.local_checkpoint_file, \'wb\') as f:\n        f.write(best_model_bytes)\n    print(\'Written checkpoint to %s\' % args.local_checkpoint_file)\n\n    spark.stop()\n\n    # ================ #\n    # FINAL PREDICTION #\n    # ================ #\n\n    print(\'================\')\n    print(\'Final prediction\')\n    print(\'================\')\n\n    # Create Spark session for prediction.\n    conf = SparkConf().setAppName(\'prediction\') \\\n        .setExecutorEnv(\'LD_LIBRARY_PATH\', os.environ.get(\'LD_LIBRARY_PATH\')) \\\n        .setExecutorEnv(\'PATH\', os.environ.get(\'PATH\'))\n\n    if GPU_INFERENCE_ENABLED:\n        if GPU_INFERENCE_CLUSTER:\n            conf.setMaster(GPU_INFERENCE_CLUSTER)\n        conf = set_gpu_conf(conf)\n    else:\n        if args.processing_master:\n            conf.setMaster(args.processing_master)\n\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n\n    def predict_fn(model_bytes):\n        def fn(rows):\n            import math\n            import tensorflow as tf\n            import tensorflow.keras.backend as K\n\n            if GPU_INFERENCE_ENABLED:\n                from pyspark import TaskContext\n                config = tf.ConfigProto()\n                config.gpu_options.allow_growth = True\n                config.gpu_options.visible_device_list = TaskContext.get().resources()[\'gpu\'].addresses[0]\n                K.set_session(tf.Session(config=config))\n            else:\n                # Do not use GPUs for prediction, use single CPU core per task.\n                config = tf.ConfigProto(device_count={\'GPU\': 0})\n                config.inter_op_parallelism_threads = 1\n                config.intra_op_parallelism_threads = 1\n                K.set_session(tf.Session(config=config))\n\n            # Restore from checkpoint.\n            model = deserialize_model(model_bytes, tf.keras.models.load_model)\n\n            # Perform predictions.\n            for row in rows:\n                fields = row.asDict().copy()\n                # Convert from log domain to real Sales numbers.\n                log_sales = model.predict_on_batch([[row[col]] for col in all_cols])[0]\n                # Add \'Sales\' column with prediction results.\n                fields[\'Sales\'] = math.exp(log_sales)\n                yield Row(**fields)\n\n        return fn\n\n\n    # Submit a Spark job to do inference. Horovod framework is not involved here.\n    pred_df = spark.read.parquet(\'%s/test_df.parquet\' % args.data_dir) \\\n        .rdd.mapPartitions(predict_fn(best_model_bytes)).toDF()\n    submission_df = pred_df.select(pred_df.Id.cast(T.IntegerType()), pred_df.Sales).toPandas()\n    submission_df.sort_values(by=[\'Id\']).to_csv(args.local_submission_csv, index=False)\n    print(\'Saved predictions to %s\' % args.local_submission_csv)\n\n    spark.stop()\n'"
examples/keras_spark_mnist.py,2,"b""import argparse\nimport os\nimport subprocess\nfrom distutils.version import LooseVersion\n\nimport numpy as np\n\nimport pyspark\nimport pyspark.sql.types as T\nfrom pyspark import SparkConf\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nif LooseVersion(pyspark.__version__) < LooseVersion('3.0.0'):\n    from pyspark.ml.feature import OneHotEncoderEstimator as OneHotEncoder\nelse:\n    from pyspark.ml.feature import OneHotEncoder\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import udf\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nimport horovod.spark.keras as hvd\nfrom horovod.spark.common.store import Store\n\nparser = argparse.ArgumentParser(description='Keras Spark MNIST Example',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--master',\n                    help='spark master to connect to')\nparser.add_argument('--num-proc', type=int,\n                    help='number of worker processes for training, default: `spark.default.parallelism`')\nparser.add_argument('--batch-size', type=int, default=128,\n                    help='input batch size for training')\nparser.add_argument('--epochs', type=int, default=12,\n                    help='number of epochs to train')\nparser.add_argument('--work-dir', default='/tmp',\n                    help='temporary working directory to write intermediate files (prefix with hdfs:// to use HDFS)')\nparser.add_argument('--data-dir', default='/tmp',\n                    help='location of the training dataset in the local filesystem (will be downloaded if needed)')\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n\n    # Initialize SparkSession\n    conf = SparkConf().setAppName('keras_spark_mnist').set('spark.sql.shuffle.partitions', '16')\n    if args.master:\n        conf.setMaster(args.master)\n    elif args.num_proc:\n        conf.setMaster('local[{}]'.format(args.num_proc))\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    # Setup our store for intermediate data\n    store = Store.create(args.work_dir)\n\n    # Download MNIST dataset\n    data_url = 'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/mnist.bz2'\n    libsvm_path = os.path.join(args.data_dir, 'mnist.bz2')\n    if not os.path.exists(libsvm_path):\n        subprocess.check_output(['wget', data_url, '-O', libsvm_path])\n\n    # Load dataset into a Spark DataFrame\n    df = spark.read.format('libsvm') \\\n        .option('numFeatures', '784') \\\n        .load(libsvm_path)\n\n    # One-hot encode labels into SparseVectors\n    encoder = OneHotEncoder(inputCols=['label'],\n                            outputCols=['label_vec'],\n                            dropLast=False)\n    model = encoder.fit(df)\n    train_df = model.transform(df)\n\n    # Train/test split\n    train_df, test_df = train_df.randomSplit([0.9, 0.1])\n\n    # Disable GPUs when building the model to prevent memory leaks\n    if LooseVersion(tf.__version__) >= LooseVersion('2.0.0'):\n        # See https://github.com/tensorflow/tensorflow/issues/33168\n        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n    else:\n        keras.backend.set_session(tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})))\n\n    # Define the Keras model without any Horovod-specific parameters\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=(28, 28, 1)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))\n\n    optimizer = keras.optimizers.Adadelta(1.0)\n    loss = keras.losses.categorical_crossentropy\n\n    # Train a Horovod Spark Estimator on the DataFrame\n    keras_estimator = hvd.KerasEstimator(num_proc=args.num_proc,\n                                         store=store,\n                                         model=model,\n                                         optimizer=optimizer,\n                                         loss=loss,\n                                         metrics=['accuracy'],\n                                         feature_cols=['features'],\n                                         label_cols=['label_vec'],\n                                         batch_size=args.batch_size,\n                                         epochs=args.epochs,\n                                         verbose=1)\n\n    keras_model = keras_estimator.fit(train_df).setOutputCols(['label_prob'])\n\n    # Evaluate the model on the held-out test DataFrame\n    pred_df = keras_model.transform(test_df)\n    argmax = udf(lambda v: float(np.argmax(v)), returnType=T.DoubleType())\n    pred_df = pred_df.withColumn('label_pred', argmax(pred_df.label_prob))\n    evaluator = MulticlassClassificationEvaluator(predictionCol='label_pred', labelCol='label', metricName='accuracy')\n    print('Test accuracy:', evaluator.evaluate(pred_df))\n\n    spark.stop()\n"""
examples/keras_spark_rossmann_estimator.py,13,"b'# Copyright 2017 onwards, fast.ai, Inc.\n# Modifications copyright (C) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport datetime\nimport os\nfrom distutils.version import LooseVersion\n\nimport pyspark.sql.types as T\nimport pyspark.sql.functions as F\nfrom pyspark import SparkConf, Row\nfrom pyspark.sql import SparkSession\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Embedding, Concatenate, Dense, Flatten, Reshape, BatchNormalization, Dropout\n\nimport horovod.spark.keras as hvd\nfrom horovod.spark.common.store import Store\n\nparser = argparse.ArgumentParser(description=\'Keras Spark Rossmann Estimator Example\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--master\',\n                    help=\'spark cluster to use for training. If set to None, uses current default cluster. Cluster\'\n                         \'should be set up to provide a Spark task per multiple CPU cores, or per GPU, e.g. by\'\n                         \'supplying `-c <NUM_GPUS>` in Spark Standalone mode\')\nparser.add_argument(\'--num-proc\', type=int,\n                    help=\'number of worker processes for training, default: `spark.default.parallelism`\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.0001,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--batch-size\', type=int, default=100,\n                    help=\'batch size\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs to train\')\nparser.add_argument(\'--sample-rate\', type=float,\n                    help=\'desired sampling rate. Useful to set to low number (e.g. 0.01) to make sure that \'\n                         \'end-to-end process works\')\nparser.add_argument(\'--data-dir\', default=\'file://\' + os.getcwd(),\n                    help=\'location of data on local filesystem (prefixed with file://) or on HDFS\')\nparser.add_argument(\'--local-submission-csv\', default=\'submission.csv\',\n                    help=\'output submission predictions CSV\')\nparser.add_argument(\'--local-checkpoint-file\', default=\'checkpoint\',\n                    help=\'model checkpoint\')\nparser.add_argument(\'--work-dir\', default=\'/tmp\',\n                    help=\'temporary working directory to write intermediate files (prefix with hdfs:// to use HDFS)\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n\n    # ================ #\n    # DATA PREPARATION #\n    # ================ #\n\n    print(\'================\')\n    print(\'Data preparation\')\n    print(\'================\')\n\n    # Create Spark session for data preparation.\n    conf = SparkConf().setAppName(\'Keras Spark Rossmann Estimator Example\').set(\'spark.sql.shuffle.partitions\', \'16\')\n    if args.master:\n        conf.setMaster(args.master)\n    elif args.num_proc:\n        conf.setMaster(\'local[{}]\'.format(args.num_proc))\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    train_csv = spark.read.csv(\'%s/train.csv\' % args.data_dir, header=True)\n    test_csv = spark.read.csv(\'%s/test.csv\' % args.data_dir, header=True)\n\n    store_csv = spark.read.csv(\'%s/store.csv\' % args.data_dir, header=True)\n    store_states_csv = spark.read.csv(\'%s/store_states.csv\' % args.data_dir, header=True)\n    state_names_csv = spark.read.csv(\'%s/state_names.csv\' % args.data_dir, header=True)\n    google_trend_csv = spark.read.csv(\'%s/googletrend.csv\' % args.data_dir, header=True)\n    weather_csv = spark.read.csv(\'%s/weather.csv\' % args.data_dir, header=True)\n\n\n    def expand_date(df):\n        df = df.withColumn(\'Date\', df.Date.cast(T.DateType()))\n        return df \\\n            .withColumn(\'Year\', F.year(df.Date)) \\\n            .withColumn(\'Month\', F.month(df.Date)) \\\n            .withColumn(\'Week\', F.weekofyear(df.Date)) \\\n            .withColumn(\'Day\', F.dayofmonth(df.Date))\n\n\n    def prepare_google_trend():\n        # Extract week start date and state.\n        google_trend_all = google_trend_csv \\\n            .withColumn(\'Date\', F.regexp_extract(google_trend_csv.week, \'(.*?) -\', 1)) \\\n            .withColumn(\'State\', F.regexp_extract(google_trend_csv.file, \'Rossmann_DE_(.*)\', 1))\n\n        # Map state NI -> HB,NI to align with other data sources.\n        google_trend_all = google_trend_all \\\n            .withColumn(\'State\', F.when(google_trend_all.State == \'NI\', \'HB,NI\').otherwise(google_trend_all.State))\n\n        # Expand dates.\n        return expand_date(google_trend_all)\n\n\n    def add_elapsed(df, cols):\n        def add_elapsed_column(col, asc):\n            def fn(rows):\n                last_store, last_date = None, None\n                for r in rows:\n                    if last_store != r.Store:\n                        last_store = r.Store\n                        last_date = r.Date\n                    if r[col]:\n                        last_date = r.Date\n                    fields = r.asDict().copy()\n                    fields[(\'After\' if asc else \'Before\') + col] = (r.Date - last_date).days\n                    yield Row(**fields)\n            return fn\n\n        df = df.repartition(df.Store)\n        for asc in [False, True]:\n            sort_col = df.Date.asc() if asc else df.Date.desc()\n            rdd = df.sortWithinPartitions(df.Store.asc(), sort_col).rdd\n            for col in cols:\n                rdd = rdd.mapPartitions(add_elapsed_column(col, asc))\n            df = rdd.toDF()\n        return df\n\n\n    def prepare_df(df):\n        num_rows = df.count()\n\n        # Expand dates.\n        df = expand_date(df)\n\n        df = df \\\n            .withColumn(\'Open\', df.Open != \'0\') \\\n            .withColumn(\'Promo\', df.Promo != \'0\') \\\n            .withColumn(\'StateHoliday\', df.StateHoliday != \'0\') \\\n            .withColumn(\'SchoolHoliday\', df.SchoolHoliday != \'0\')\n\n        # Merge in store information.\n        store = store_csv.join(store_states_csv, \'Store\')\n        df = df.join(store, \'Store\')\n\n        # Merge in Google Trend information.\n        google_trend_all = prepare_google_trend()\n        df = df.join(google_trend_all, [\'State\', \'Year\', \'Week\']).select(df[\'*\'], google_trend_all.trend)\n\n        # Merge in Google Trend for whole Germany.\n        google_trend_de = google_trend_all[google_trend_all.file == \'Rossmann_DE\']\n        google_trend_de = google_trend_de.withColumnRenamed(\'trend\', \'trend_de\')\n        df = df.join(google_trend_de, [\'Year\', \'Week\']).select(df[\'*\'], google_trend_de.trend_de)\n\n        # Merge in weather.\n        weather = weather_csv.join(state_names_csv, weather_csv.file == state_names_csv.StateName)\n        df = df.join(weather, [\'State\', \'Date\'])\n\n        # Fix null values.\n        df = df \\\n            .withColumn(\'CompetitionOpenSinceYear\', F.coalesce(df.CompetitionOpenSinceYear, F.lit(1900))) \\\n            .withColumn(\'CompetitionOpenSinceMonth\', F.coalesce(df.CompetitionOpenSinceMonth, F.lit(1))) \\\n            .withColumn(\'Promo2SinceYear\', F.coalesce(df.Promo2SinceYear, F.lit(1900))) \\\n            .withColumn(\'Promo2SinceWeek\', F.coalesce(df.Promo2SinceWeek, F.lit(1)))\n\n        # Days & months competition was open, cap to 2 years.\n        df = df.withColumn(\'CompetitionOpenSince\',\n                           F.to_date(F.format_string(\'%s-%s-15\', df.CompetitionOpenSinceYear,\n                                                     df.CompetitionOpenSinceMonth)))\n        df = df.withColumn(\'CompetitionDaysOpen\',\n                           F.when(df.CompetitionOpenSinceYear > 1900,\n                                  F.greatest(F.lit(0), F.least(F.lit(360 * 2), F.datediff(df.Date, df.CompetitionOpenSince))))\n                           .otherwise(0))\n        df = df.withColumn(\'CompetitionMonthsOpen\', (df.CompetitionDaysOpen / 30).cast(T.IntegerType()))\n\n        # Days & weeks of promotion, cap to 25 weeks.\n        df = df.withColumn(\'Promo2Since\',\n                           F.expr(\'date_add(format_string(""%s-01-01"", Promo2SinceYear), (cast(Promo2SinceWeek as int) - 1) * 7)\'))\n        df = df.withColumn(\'Promo2Days\',\n                           F.when(df.Promo2SinceYear > 1900,\n                                  F.greatest(F.lit(0), F.least(F.lit(25 * 7), F.datediff(df.Date, df.Promo2Since))))\n                           .otherwise(0))\n        df = df.withColumn(\'Promo2Weeks\', (df.Promo2Days / 7).cast(T.IntegerType()))\n\n        # Check that we did not lose any rows through inner joins.\n        assert num_rows == df.count(), \'lost rows in joins\'\n        return df\n\n\n    def build_vocabulary(df, cols):\n        vocab = {}\n        for col in cols:\n            values = [r[0] for r in df.select(col).distinct().collect()]\n            col_type = type([x for x in values if x is not None][0])\n            default_value = col_type()\n            vocab[col] = sorted(values, key=lambda x: x or default_value)\n        return vocab\n\n\n    def cast_columns(df, cols):\n        for col in cols:\n            df = df.withColumn(col, F.coalesce(df[col].cast(T.FloatType()), F.lit(0.0)))\n        return df\n\n\n    def lookup_columns(df, vocab):\n        def lookup(mapping):\n            def fn(v):\n                return mapping.index(v)\n            return F.udf(fn, returnType=T.IntegerType())\n\n        for col, mapping in vocab.items():\n            df = df.withColumn(col, lookup(mapping)(df[col]))\n        return df\n\n\n    if args.sample_rate:\n        train_csv = train_csv.sample(withReplacement=False, fraction=args.sample_rate)\n        test_csv = test_csv.sample(withReplacement=False, fraction=args.sample_rate)\n\n    # Prepare data frames from CSV files.\n    train_df = prepare_df(train_csv).cache()\n    test_df = prepare_df(test_csv).cache()\n\n    # Add elapsed times from holidays & promos, the data spanning training & test datasets.\n    elapsed_cols = [\'Promo\', \'StateHoliday\', \'SchoolHoliday\']\n    elapsed = add_elapsed(train_df.select(\'Date\', \'Store\', *elapsed_cols)\n                          .unionAll(test_df.select(\'Date\', \'Store\', *elapsed_cols)),\n                          elapsed_cols)\n\n    # Join with elapsed times.\n    train_df = train_df \\\n        .join(elapsed, [\'Date\', \'Store\']) \\\n        .select(train_df[\'*\'], *[prefix + col for prefix in [\'Before\', \'After\'] for col in elapsed_cols])\n    test_df = test_df \\\n        .join(elapsed, [\'Date\', \'Store\']) \\\n        .select(test_df[\'*\'], *[prefix + col for prefix in [\'Before\', \'After\'] for col in elapsed_cols])\n\n    # Filter out zero sales.\n    train_df = train_df.filter(train_df.Sales > 0)\n\n    print(\'===================\')\n    print(\'Prepared data frame\')\n    print(\'===================\')\n    train_df.show()\n\n    categorical_cols = [\n        \'Store\', \'State\', \'DayOfWeek\', \'Year\', \'Month\', \'Day\', \'Week\', \'CompetitionMonthsOpen\', \'Promo2Weeks\', \'StoreType\',\n        \'Assortment\', \'PromoInterval\', \'CompetitionOpenSinceYear\', \'Promo2SinceYear\', \'Events\', \'Promo\',\n        \'StateHoliday\', \'SchoolHoliday\'\n    ]\n\n    continuous_cols = [\n        \'CompetitionDistance\', \'Max_TemperatureC\', \'Mean_TemperatureC\', \'Min_TemperatureC\', \'Max_Humidity\',\n        \'Mean_Humidity\', \'Min_Humidity\', \'Max_Wind_SpeedKm_h\', \'Mean_Wind_SpeedKm_h\', \'CloudCover\', \'trend\', \'trend_DE\',\n        \'BeforePromo\', \'AfterPromo\', \'AfterStateHoliday\', \'BeforeStateHoliday\', \'BeforeSchoolHoliday\', \'AfterSchoolHoliday\'\n    ]\n\n    all_cols = categorical_cols + continuous_cols\n\n    # Select features.\n    train_df = train_df.select(*(all_cols + [\'Sales\', \'Date\'])).cache()\n    test_df = test_df.select(*(all_cols + [\'Id\', \'Date\'])).cache()\n\n    # Build vocabulary of categorical columns.\n    vocab = build_vocabulary(train_df.select(*categorical_cols)\n                             .unionAll(test_df.select(*categorical_cols)).cache(),\n                             categorical_cols)\n\n    # Cast continuous columns to float & lookup categorical columns.\n    train_df = cast_columns(train_df, continuous_cols + [\'Sales\'])\n    train_df = lookup_columns(train_df, vocab)\n    test_df = cast_columns(test_df, continuous_cols)\n    test_df = lookup_columns(test_df, vocab)\n\n    # Split into training & validation.\n    # Test set is in 2015, use the same period in 2014 from the training set as a validation set.\n    test_min_date = test_df.agg(F.min(test_df.Date)).collect()[0][0]\n    test_max_date = test_df.agg(F.max(test_df.Date)).collect()[0][0]\n    one_year = datetime.timedelta(365)\n    train_df = train_df.withColumn(\'Validation\',\n                                   (train_df.Date > test_min_date - one_year) & (train_df.Date <= test_max_date - one_year))\n\n    # Determine max Sales number.\n    max_sales = train_df.agg(F.max(train_df.Sales)).collect()[0][0]\n\n    # Convert Sales to log domain\n    train_df = train_df.withColumn(\'Sales\', F.log(train_df.Sales))\n\n    print(\'===================================\')\n    print(\'Data frame with transformed columns\')\n    print(\'===================================\')\n    train_df.show()\n\n    print(\'================\')\n    print(\'Data frame sizes\')\n    print(\'================\')\n    train_rows = train_df.filter(~train_df.Validation).count()\n    val_rows = train_df.filter(train_df.Validation).count()\n    test_rows = test_df.count()\n    print(\'Training: %d\' % train_rows)\n    print(\'Validation: %d\' % val_rows)\n    print(\'Test: %d\' % test_rows)\n\n    # ============== #\n    # MODEL TRAINING #\n    # ============== #\n\n    print(\'==============\')\n    print(\'Model training\')\n    print(\'==============\')\n\n\n    def exp_rmspe(y_true, y_pred):\n        """"""Competition evaluation metric, expects logarithic inputs.""""""\n        pct = tf.square((tf.exp(y_true) - tf.exp(y_pred)) / tf.exp(y_true))\n        # Compute mean excluding stores with zero denominator.\n        x = tf.reduce_sum(tf.where(y_true > 0.001, pct, tf.zeros_like(pct)))\n        y = tf.reduce_sum(tf.where(y_true > 0.001, tf.ones_like(pct), tf.zeros_like(pct)))\n        return tf.sqrt(x / y)\n\n\n    def act_sigmoid_scaled(x):\n        """"""Sigmoid scaled to logarithm of maximum sales scaled by 20%.""""""\n        return tf.nn.sigmoid(x) * tf.math.log(max_sales) * 1.2\n\n\n    CUSTOM_OBJECTS = {\'exp_rmspe\': exp_rmspe,\n                      \'act_sigmoid_scaled\': act_sigmoid_scaled}\n\n    # Disable GPUs when building the model to prevent memory leaks\n    if LooseVersion(tf.__version__) >= LooseVersion(\'2.0.0\'):\n        # See https://github.com/tensorflow/tensorflow/issues/33168\n        os.environ[\'CUDA_VISIBLE_DEVICES\'] = \'-1\'\n    else:\n        K.set_session(tf.Session(config=tf.ConfigProto(device_count={\'GPU\': 0})))\n\n    # Build the model.\n    inputs = {col: Input(shape=(1,), name=col) for col in all_cols}\n    embeddings = [Embedding(len(vocab[col]), 10, input_length=1, name=\'emb_\' + col)(inputs[col])\n                  for col in categorical_cols]\n    continuous_bn = Concatenate()([Reshape((1, 1), name=\'reshape_\' + col)(inputs[col])\n                                   for col in continuous_cols])\n    continuous_bn = BatchNormalization()(continuous_bn)\n    x = Concatenate()(embeddings + [continuous_bn])\n    x = Flatten()(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(500, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dropout(0.5)(x)\n    output = Dense(1, activation=act_sigmoid_scaled)(x)\n    model = tf.keras.Model([inputs[f] for f in all_cols], output)\n    model.summary()\n\n    opt = tf.keras.optimizers.Adam(lr=args.learning_rate, epsilon=1e-3)\n\n    # Horovod: run training.\n    store = Store.create(args.work_dir)\n    keras_estimator = hvd.KerasEstimator(num_proc=args.num_proc,\n                                         store=store,\n                                         model=model,\n                                         optimizer=opt,\n                                         loss=\'mae\',\n                                         metrics=[exp_rmspe],\n                                         custom_objects=CUSTOM_OBJECTS,\n                                         feature_cols=all_cols,\n                                         label_cols=[\'Sales\'],\n                                         validation=\'Validation\',\n                                         batch_size=args.batch_size,\n                                         epochs=args.epochs,\n                                         verbose=2)\n\n    keras_model = keras_estimator.fit(train_df).setOutputCols([\'Sales\'])\n\n    history = keras_model.getHistory()\n    best_val_rmspe = min(history[\'val_exp_rmspe\'])\n    print(\'Best RMSPE: %f\' % best_val_rmspe)\n\n    # Save the trained model.\n    keras_model.save(args.local_checkpoint_file)\n    print(\'Written checkpoint to %s\' % args.local_checkpoint_file)\n\n    # ================ #\n    # FINAL PREDICTION #\n    # ================ #\n\n    print(\'================\')\n    print(\'Final prediction\')\n    print(\'================\')\n\n    pred_df = keras_model.transform(test_df)\n    # Convert from log domain to real Sales numbers\n    pred_df = pred_df.withColumn(\'Sales\', F.exp(pred_df.Sales))\n    submission_df = pred_df.select(pred_df.Id.cast(T.IntegerType()), pred_df.Sales).toPandas()\n    submission_df.sort_values(by=[\'Id\']).to_csv(args.local_submission_csv, index=False)\n    print(\'Saved predictions to %s\' % args.local_submission_csv)\n\n    spark.stop()\n'"
examples/keras_spark_rossmann_run.py,27,"b'# Copyright 2017 onwards, fast.ai, Inc.\n# Modifications copyright (C) 2018 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport datetime\nimport h5py\nimport io\nimport os\nimport pyarrow as pa\nfrom pyspark import SparkConf, Row\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.types as T\nimport pyspark.sql.functions as F\n\nparser = argparse.ArgumentParser(description=\'Keras Spark Rossmann Run Example\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--processing-master\',\n                    help=\'spark cluster to use for light processing (data preparation & prediction).\'\n                         \'If set to None, uses current default cluster. Cluster should be set up to provide\'\n                         \'one task per CPU core. Example: spark://hostname:7077\')\nparser.add_argument(\'--training-master\',\n                    help=\'spark cluster to use for training. If set to None, uses current default cluster. Cluster\'\n                         \'should be set up to provide a Spark task per multiple CPU cores, or per GPU, e.g. by\'\n                         \'supplying `-c <NUM_GPUS>` in Spark Standalone mode. Example: spark://hostname:7077\')\nparser.add_argument(\'--num-proc\', type=int, default=4,\n                    help=\'number of worker processes for training, default: `spark.default.parallelism`\')\nparser.add_argument(\'--learning-rate\', type=float, default=0.0001,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--batch-size\', type=int, default=100,\n                    help=\'batch size\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs to train\')\nparser.add_argument(\'--sample-rate\', type=float,\n                    help=\'desired sampling rate. Useful to set to low number (e.g. 0.01) to make sure that \'\n                         \'end-to-end process works\')\nparser.add_argument(\'--data-dir\', default=\'file://\' + os.getcwd(),\n                    help=\'location of data on local filesystem (prefixed with file://) or on HDFS\')\nparser.add_argument(\'--local-submission-csv\', default=\'submission.csv\',\n                    help=\'output submission predictions CSV on local filesystem (without file:// prefix)\')\nparser.add_argument(\'--local-checkpoint-file\', default=\'checkpoint.h5\',\n                    help=\'model checkpoint on local filesystem (without file:// prefix)\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n\n    # HDFS driver to use with Petastorm.\n    PETASTORM_HDFS_DRIVER = \'libhdfs\'\n\n    # ================ #\n    # DATA PREPARATION #\n    # ================ #\n\n    print(\'================\')\n    print(\'Data preparation\')\n    print(\'================\')\n\n    # Create Spark session for data preparation.\n    conf = SparkConf().setAppName(\'data_prep\').set(\'spark.sql.shuffle.partitions\', \'16\')\n    if args.processing_master:\n        conf.setMaster(args.processing_master)\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    train_csv = spark.read.csv(\'%s/train.csv\' % args.data_dir, header=True)\n    test_csv = spark.read.csv(\'%s/test.csv\' % args.data_dir, header=True)\n\n    store_csv = spark.read.csv(\'%s/store.csv\' % args.data_dir, header=True)\n    store_states_csv = spark.read.csv(\'%s/store_states.csv\' % args.data_dir, header=True)\n    state_names_csv = spark.read.csv(\'%s/state_names.csv\' % args.data_dir, header=True)\n    google_trend_csv = spark.read.csv(\'%s/googletrend.csv\' % args.data_dir, header=True)\n    weather_csv = spark.read.csv(\'%s/weather.csv\' % args.data_dir, header=True)\n\n\n    def expand_date(df):\n        df = df.withColumn(\'Date\', df.Date.cast(T.DateType()))\n        return df \\\n            .withColumn(\'Year\', F.year(df.Date)) \\\n            .withColumn(\'Month\', F.month(df.Date)) \\\n            .withColumn(\'Week\', F.weekofyear(df.Date)) \\\n            .withColumn(\'Day\', F.dayofmonth(df.Date))\n\n\n    def prepare_google_trend():\n        # Extract week start date and state.\n        google_trend_all = google_trend_csv \\\n            .withColumn(\'Date\', F.regexp_extract(google_trend_csv.week, \'(.*?) -\', 1)) \\\n            .withColumn(\'State\', F.regexp_extract(google_trend_csv.file, \'Rossmann_DE_(.*)\', 1))\n\n        # Map state NI -> HB,NI to align with other data sources.\n        google_trend_all = google_trend_all \\\n            .withColumn(\'State\', F.when(google_trend_all.State == \'NI\', \'HB,NI\').otherwise(google_trend_all.State))\n\n        # Expand dates.\n        return expand_date(google_trend_all)\n\n\n    def add_elapsed(df, cols):\n        def add_elapsed_column(col, asc):\n            def fn(rows):\n                last_store, last_date = None, None\n                for r in rows:\n                    if last_store != r.Store:\n                        last_store = r.Store\n                        last_date = r.Date\n                    if r[col]:\n                        last_date = r.Date\n                    fields = r.asDict().copy()\n                    fields[(\'After\' if asc else \'Before\') + col] = (r.Date - last_date).days\n                    yield Row(**fields)\n            return fn\n\n        df = df.repartition(df.Store)\n        for asc in [False, True]:\n            sort_col = df.Date.asc() if asc else df.Date.desc()\n            rdd = df.sortWithinPartitions(df.Store.asc(), sort_col).rdd\n            for col in cols:\n                rdd = rdd.mapPartitions(add_elapsed_column(col, asc))\n            df = rdd.toDF()\n        return df\n\n\n    def prepare_df(df):\n        num_rows = df.count()\n\n        # Expand dates.\n        df = expand_date(df)\n\n        df = df \\\n            .withColumn(\'Open\', df.Open != \'0\') \\\n            .withColumn(\'Promo\', df.Promo != \'0\') \\\n            .withColumn(\'StateHoliday\', df.StateHoliday != \'0\') \\\n            .withColumn(\'SchoolHoliday\', df.SchoolHoliday != \'0\')\n\n        # Merge in store information.\n        store = store_csv.join(store_states_csv, \'Store\')\n        df = df.join(store, \'Store\')\n\n        # Merge in Google Trend information.\n        google_trend_all = prepare_google_trend()\n        df = df.join(google_trend_all, [\'State\', \'Year\', \'Week\']).select(df[\'*\'], google_trend_all.trend)\n\n        # Merge in Google Trend for whole Germany.\n        google_trend_de = google_trend_all[google_trend_all.file == \'Rossmann_DE\']\n        df = df.join(google_trend_de, [\'Year\', \'Week\']).select(df[\'*\'], google_trend_all.trend.alias(\'trend_de\'))\n\n        # Merge in weather.\n        weather = weather_csv.join(state_names_csv, weather_csv.file == state_names_csv.StateName)\n        df = df.join(weather, [\'State\', \'Date\'])\n\n        # Fix null values.\n        df = df \\\n            .withColumn(\'CompetitionOpenSinceYear\', F.coalesce(df.CompetitionOpenSinceYear, F.lit(1900))) \\\n            .withColumn(\'CompetitionOpenSinceMonth\', F.coalesce(df.CompetitionOpenSinceMonth, F.lit(1))) \\\n            .withColumn(\'Promo2SinceYear\', F.coalesce(df.Promo2SinceYear, F.lit(1900))) \\\n            .withColumn(\'Promo2SinceWeek\', F.coalesce(df.Promo2SinceWeek, F.lit(1)))\n\n        # Days & months competition was open, cap to 2 years.\n        df = df.withColumn(\'CompetitionOpenSince\',\n                           F.to_date(F.format_string(\'%s-%s-15\', df.CompetitionOpenSinceYear,\n                                                     df.CompetitionOpenSinceMonth)))\n        df = df.withColumn(\'CompetitionDaysOpen\',\n                           F.when(df.CompetitionOpenSinceYear > 1900,\n                                  F.greatest(F.lit(0), F.least(F.lit(360 * 2), F.datediff(df.Date, df.CompetitionOpenSince))))\n                           .otherwise(0))\n        df = df.withColumn(\'CompetitionMonthsOpen\', (df.CompetitionDaysOpen / 30).cast(T.IntegerType()))\n\n        # Days & weeks of promotion, cap to 25 weeks.\n        df = df.withColumn(\'Promo2Since\',\n                           F.expr(\'date_add(format_string(""%s-01-01"", Promo2SinceYear), (Promo2SinceWeek - 1) * 7)\'))\n        df = df.withColumn(\'Promo2Days\',\n                           F.when(df.Promo2SinceYear > 1900,\n                                  F.greatest(F.lit(0), F.least(F.lit(25 * 7), F.datediff(df.Date, df.Promo2Since))))\n                           .otherwise(0))\n        df = df.withColumn(\'Promo2Weeks\', (df.Promo2Days / 7).cast(T.IntegerType()))\n\n        # Check that we did not lose any rows through inner joins.\n        assert num_rows == df.count(), \'lost rows in joins\'\n        return df\n\n\n    def build_vocabulary(df, cols):\n        vocab = {}\n        for col in cols:\n            values = [r[0] for r in df.select(col).distinct().collect()]\n            col_type = type([x for x in values if x is not None][0])\n            default_value = col_type()\n            vocab[col] = sorted(values, key=lambda x: x or default_value)\n        return vocab\n\n\n    def cast_columns(df, cols):\n        for col in cols:\n            df = df.withColumn(col, F.coalesce(df[col].cast(T.FloatType()), F.lit(0.0)))\n        return df\n\n\n    def lookup_columns(df, vocab):\n        def lookup(mapping):\n            def fn(v):\n                return mapping.index(v)\n            return F.udf(fn, returnType=T.IntegerType())\n\n        for col, mapping in vocab.items():\n            df = df.withColumn(col, lookup(mapping)(df[col]))\n        return df\n\n\n    if args.sample_rate:\n        train_csv = train_csv.sample(withReplacement=False, fraction=args.sample_rate)\n        test_csv = test_csv.sample(withReplacement=False, fraction=args.sample_rate)\n\n    # Prepare data frames from CSV files.\n    train_df = prepare_df(train_csv).cache()\n    test_df = prepare_df(test_csv).cache()\n\n    # Add elapsed times from holidays & promos, the data spanning training & test datasets.\n    elapsed_cols = [\'Promo\', \'StateHoliday\', \'SchoolHoliday\']\n    elapsed = add_elapsed(train_df.select(\'Date\', \'Store\', *elapsed_cols)\n                                  .unionAll(test_df.select(\'Date\', \'Store\', *elapsed_cols)),\n                          elapsed_cols)\n\n    # Join with elapsed times.\n    train_df = train_df \\\n        .join(elapsed, [\'Date\', \'Store\']) \\\n        .select(train_df[\'*\'], *[prefix + col for prefix in [\'Before\', \'After\'] for col in elapsed_cols])\n    test_df = test_df \\\n        .join(elapsed, [\'Date\', \'Store\']) \\\n        .select(test_df[\'*\'], *[prefix + col for prefix in [\'Before\', \'After\'] for col in elapsed_cols])\n\n    # Filter out zero sales.\n    train_df = train_df.filter(train_df.Sales > 0)\n\n    print(\'===================\')\n    print(\'Prepared data frame\')\n    print(\'===================\')\n    train_df.show()\n\n    categorical_cols = [\n        \'Store\', \'State\', \'DayOfWeek\', \'Year\', \'Month\', \'Day\', \'Week\', \'CompetitionMonthsOpen\', \'Promo2Weeks\', \'StoreType\',\n        \'Assortment\', \'PromoInterval\', \'CompetitionOpenSinceYear\', \'Promo2SinceYear\', \'Events\', \'Promo\',\n        \'StateHoliday\', \'SchoolHoliday\'\n    ]\n\n    continuous_cols = [\n        \'CompetitionDistance\', \'Max_TemperatureC\', \'Mean_TemperatureC\', \'Min_TemperatureC\', \'Max_Humidity\',\n        \'Mean_Humidity\', \'Min_Humidity\', \'Max_Wind_SpeedKm_h\', \'Mean_Wind_SpeedKm_h\', \'CloudCover\', \'trend\', \'trend_DE\',\n        \'BeforePromo\', \'AfterPromo\', \'AfterStateHoliday\', \'BeforeStateHoliday\', \'BeforeSchoolHoliday\', \'AfterSchoolHoliday\'\n    ]\n\n    all_cols = categorical_cols + continuous_cols\n\n    # Select features.\n    train_df = train_df.select(*(all_cols + [\'Sales\', \'Date\'])).cache()\n    test_df = test_df.select(*(all_cols + [\'Id\', \'Date\'])).cache()\n\n    # Build vocabulary of categorical columns.\n    vocab = build_vocabulary(train_df.select(*categorical_cols)\n                                     .unionAll(test_df.select(*categorical_cols)).cache(),\n                             categorical_cols)\n\n    # Cast continuous columns to float & lookup categorical columns.\n    train_df = cast_columns(train_df, continuous_cols + [\'Sales\'])\n    train_df = lookup_columns(train_df, vocab)\n    test_df = cast_columns(test_df, continuous_cols)\n    test_df = lookup_columns(test_df, vocab)\n\n    # Split into training & validation.\n    # Test set is in 2015, use the same period in 2014 from the training set as a validation set.\n    test_min_date = test_df.agg(F.min(test_df.Date)).collect()[0][0]\n    test_max_date = test_df.agg(F.max(test_df.Date)).collect()[0][0]\n    a_year = datetime.timedelta(365)\n    val_df = train_df.filter((test_min_date - a_year <= train_df.Date) & (train_df.Date < test_max_date - a_year))\n    train_df = train_df.filter((train_df.Date < test_min_date - a_year) | (train_df.Date >= test_max_date - a_year))\n\n    # Determine max Sales number.\n    max_sales = train_df.agg(F.max(train_df.Sales)).collect()[0][0]\n\n    print(\'===================================\')\n    print(\'Data frame with transformed columns\')\n    print(\'===================================\')\n    train_df.show()\n\n    print(\'================\')\n    print(\'Data frame sizes\')\n    print(\'================\')\n    train_rows, val_rows, test_rows = train_df.count(), val_df.count(), test_df.count()\n    print(\'Training: %d\' % train_rows)\n    print(\'Validation: %d\' % val_rows)\n    print(\'Test: %d\' % test_rows)\n\n    # Save data frames as Parquet files.\n    train_df.write.parquet(\'%s/train_df.parquet\' % args.data_dir, mode=\'overwrite\')\n    val_df.write.parquet(\'%s/val_df.parquet\' % args.data_dir, mode=\'overwrite\')\n    test_df.write.parquet(\'%s/test_df.parquet\' % args.data_dir, mode=\'overwrite\')\n\n    spark.stop()\n\n    # ============== #\n    # MODEL TRAINING #\n    # ============== #\n\n    print(\'==============\')\n    print(\'Model training\')\n    print(\'==============\')\n\n    import tensorflow as tf\n    from tensorflow.keras.layers import Input, Embedding, Concatenate, Dense, Flatten, Reshape, BatchNormalization, Dropout\n    import tensorflow.keras.backend as K\n    import horovod.spark\n    import horovod.tensorflow.keras as hvd\n\n\n    def exp_rmspe(y_true, y_pred):\n        """"""Competition evaluation metric, expects logarithic inputs.""""""\n        pct = tf.square((tf.exp(y_true) - tf.exp(y_pred)) / tf.exp(y_true))\n        # Compute mean excluding stores with zero denominator.\n        x = tf.reduce_sum(tf.where(y_true > 0.001, pct, tf.zeros_like(pct)))\n        y = tf.reduce_sum(tf.where(y_true > 0.001, tf.ones_like(pct), tf.zeros_like(pct)))\n        return tf.sqrt(x / y)\n\n\n    def act_sigmoid_scaled(x):\n        """"""Sigmoid scaled to logarithm of maximum sales scaled by 20%.""""""\n        return tf.nn.sigmoid(x) * tf.log(max_sales) * 1.2\n\n\n    CUSTOM_OBJECTS = {\'exp_rmspe\': exp_rmspe,\n                      \'act_sigmoid_scaled\': act_sigmoid_scaled}\n\n\n    def serialize_model(model):\n        """"""Serialize model into byte array.""""""\n        bio = io.BytesIO()\n        with h5py.File(bio) as f:\n            model.save(f)\n        return bio.getvalue()\n\n\n    def deserialize_model(model_bytes, load_model_fn):\n        """"""Deserialize model from byte array.""""""\n        bio = io.BytesIO(model_bytes)\n        with h5py.File(bio) as f:\n            return load_model_fn(f, custom_objects=CUSTOM_OBJECTS)\n\n\n    # Do not use GPU for the session creation.\n    config = tf.ConfigProto(device_count={\'GPU\': 0})\n    K.set_session(tf.Session(config=config))\n\n    # Build the model.\n    inputs = {col: Input(shape=(1,), name=col) for col in all_cols}\n    embeddings = [Embedding(len(vocab[col]), 10, input_length=1, name=\'emb_\' + col)(inputs[col])\n                  for col in categorical_cols]\n    continuous_bn = Concatenate()([Reshape((1, 1), name=\'reshape_\' + col)(inputs[col])\n                                   for col in continuous_cols])\n    continuous_bn = BatchNormalization()(continuous_bn)\n    x = Concatenate()(embeddings + [continuous_bn])\n    x = Flatten()(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(1000, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dense(500, activation=\'relu\', kernel_regularizer=tf.keras.regularizers.l2(0.00005))(x)\n    x = Dropout(0.5)(x)\n    output = Dense(1, activation=act_sigmoid_scaled)(x)\n    model = tf.keras.Model([inputs[f] for f in all_cols], output)\n    model.summary()\n\n    # Horovod: add Distributed Optimizer.\n    opt = tf.keras.optimizers.Adam(lr=args.learning_rate, epsilon=1e-3)\n    opt = hvd.DistributedOptimizer(opt)\n    model.compile(opt, \'mae\', metrics=[exp_rmspe])\n    model_bytes = serialize_model(model)\n\n\n    def train_fn(model_bytes):\n        # Make sure pyarrow is referenced before anything else to avoid segfault due to conflict\n        # with TensorFlow libraries.  Use `pa` package reference to ensure it\'s loaded before\n        # functions like `deserialize_model` which are implemented at the top level.\n        # See https://jira.apache.org/jira/browse/ARROW-3346\n        pa\n\n        import atexit\n        import horovod.tensorflow.keras as hvd\n        import os\n        from petastorm import make_batch_reader\n        from petastorm.tf_utils import make_petastorm_dataset\n        import tempfile\n        import tensorflow as tf\n        import tensorflow.keras.backend as K\n        import shutil\n\n        # Horovod: initialize Horovod inside the trainer.\n        hvd.init()\n\n        # Horovod: pin GPU to be used to process local rank (one GPU per process), if GPUs are available.\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.gpu_options.visible_device_list = str(hvd.local_rank())\n        K.set_session(tf.Session(config=config))\n\n        # Horovod: restore from checkpoint, use hvd.load_model under the hood.\n        model = deserialize_model(model_bytes, hvd.load_model)\n\n        # Horovod: adjust learning rate based on number of processes.\n        scaled_lr = K.get_value(model.optimizer.lr) * hvd.size()\n        K.set_value(model.optimizer.lr, scaled_lr)\n\n        # Horovod: print summary logs on the first worker.\n        verbose = 2 if hvd.rank() == 0 else 0\n\n        callbacks = [\n            # Horovod: broadcast initial variable states from rank 0 to all other processes.\n            # This is necessary to ensure consistent initialization of all workers when\n            # training is started with random weights or restored from a checkpoint.\n            hvd.callbacks.BroadcastGlobalVariablesCallback(root_rank=0),\n\n            # Horovod: average metrics among workers at the end of every epoch.\n            #\n            # Note: This callback must be in the list before the ReduceLROnPlateau,\n            # TensorBoard, or other metrics-based callbacks.\n            hvd.callbacks.MetricAverageCallback(),\n\n            # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n            # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n            # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n            hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=5, initial_lr=scaled_lr, verbose=verbose),\n\n            # Reduce LR if the metric is not improved for 10 epochs, and stop training\n            # if it has not improved for 20 epochs.\n            tf.keras.callbacks.ReduceLROnPlateau(monitor=\'val_exp_rmspe\', patience=10, verbose=verbose),\n            tf.keras.callbacks.EarlyStopping(monitor=\'val_exp_rmspe\', mode=\'min\', patience=20, verbose=verbose),\n            tf.keras.callbacks.TerminateOnNaN()\n        ]\n\n        # Model checkpoint location.\n        ckpt_dir = tempfile.mkdtemp()\n        ckpt_file = os.path.join(ckpt_dir, \'checkpoint.h5\')\n        atexit.register(lambda: shutil.rmtree(ckpt_dir))\n\n        # Horovod: save checkpoints only on the first worker to prevent other workers from corrupting them.\n        if hvd.rank() == 0:\n            callbacks.append(tf.keras.callbacks.ModelCheckpoint(ckpt_file, monitor=\'val_exp_rmspe\', mode=\'min\',\n                                                                save_best_only=True))\n\n        # Make Petastorm readers.\n        with make_batch_reader(\'%s/train_df.parquet\' % args.data_dir, num_epochs=None,\n                               cur_shard=hvd.rank(), shard_count=hvd.size(),\n                               hdfs_driver=PETASTORM_HDFS_DRIVER) as train_reader:\n            with make_batch_reader(\'%s/val_df.parquet\' % args.data_dir, num_epochs=None,\n                                   cur_shard=hvd.rank(), shard_count=hvd.size(),\n                                   hdfs_driver=PETASTORM_HDFS_DRIVER) as val_reader:\n                # Convert readers to tf.data.Dataset.\n                train_ds = make_petastorm_dataset(train_reader) \\\n                    .apply(tf.data.experimental.unbatch()) \\\n                    .shuffle(int(train_rows / hvd.size())) \\\n                    .batch(args.batch_size) \\\n                    .map(lambda x: (tuple(getattr(x, col) for col in all_cols), tf.log(x.Sales)))\n\n                val_ds = make_petastorm_dataset(val_reader) \\\n                    .apply(tf.data.experimental.unbatch()) \\\n                    .batch(args.batch_size) \\\n                    .map(lambda x: (tuple(getattr(x, col) for col in all_cols), tf.log(x.Sales)))\n\n                history = model.fit(train_ds,\n                                    validation_data=val_ds,\n                                    steps_per_epoch=int(train_rows / args.batch_size / hvd.size()),\n                                    validation_steps=int(val_rows / args.batch_size / hvd.size()),\n                                    callbacks=callbacks,\n                                    verbose=verbose,\n                                    epochs=args.epochs)\n\n        # Dataset API usage currently displays a wall of errors upon termination.\n        # This global model registration ensures clean termination.\n        # Tracked in https://github.com/tensorflow/tensorflow/issues/24570\n        globals()[\'_DATASET_FINALIZATION_HACK\'] = model\n\n        if hvd.rank() == 0:\n            with open(ckpt_file, \'rb\') as f:\n                return history.history, f.read()\n\n\n    # Create Spark session for training.\n    conf = SparkConf().setAppName(\'training\')\n    if args.training_master:\n        conf.setMaster(args.training_master)\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    # Horovod: run training.\n    history, best_model_bytes = \\\n        horovod.spark.run(train_fn, args=(model_bytes,), num_proc=args.num_proc, verbose=2)[0]\n\n    best_val_rmspe = min(history[\'val_exp_rmspe\'])\n    print(\'Best RMSPE: %f\' % best_val_rmspe)\n\n    # Write checkpoint.\n    with open(args.local_checkpoint_file, \'wb\') as f:\n        f.write(best_model_bytes)\n    print(\'Written checkpoint to %s\' % args.local_checkpoint_file)\n\n    spark.stop()\n\n    # ================ #\n    # FINAL PREDICTION #\n    # ================ #\n\n    print(\'================\')\n    print(\'Final prediction\')\n    print(\'================\')\n\n    # Create Spark session for prediction.\n    conf = SparkConf().setAppName(\'prediction\') \\\n        .setExecutorEnv(\'LD_LIBRARY_PATH\', os.environ.get(\'LD_LIBRARY_PATH\')) \\\n        .setExecutorEnv(\'PATH\', os.environ.get(\'PATH\'))\n    if args.processing_master:\n        conf.setMaster(args.processing_master)\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n\n    def predict_fn(model_bytes):\n        def fn(rows):\n            import math\n            import tensorflow as tf\n            import tensorflow.keras.backend as K\n\n            # Do not use GPUs for prediction, use single CPU core per task.\n            config = tf.ConfigProto(device_count={\'GPU\': 0})\n            config.inter_op_parallelism_threads = 1\n            config.intra_op_parallelism_threads = 1\n            K.set_session(tf.Session(config=config))\n\n            # Restore from checkpoint.\n            model = deserialize_model(model_bytes, tf.keras.models.load_model)\n\n            # Perform predictions.\n            for row in rows:\n                fields = row.asDict().copy()\n                # Convert from log domain to real Sales numbers.\n                log_sales = model.predict_on_batch([[row[col]] for col in all_cols])[0]\n                # Add \'Sales\' column with prediction results.\n                fields[\'Sales\'] = math.exp(log_sales)\n                yield Row(**fields)\n\n        return fn\n\n\n    # Submit a Spark job to do inference. Horovod framework is not involved here.\n    pred_df = spark.read.parquet(\'%s/test_df.parquet\' % args.data_dir) \\\n        .rdd.mapPartitions(predict_fn(best_model_bytes)).toDF()\n    submission_df = pred_df.select(pred_df.Id.cast(T.IntegerType()), pred_df.Sales).toPandas()\n    submission_df.sort_values(by=[\'Id\']).to_csv(args.local_submission_csv, index=False)\n    print(\'Saved predictions to %s\' % args.local_submission_csv)\n\n    spark.stop()\n'"
examples/mxnet_imagenet_resnet50.py,0,"b'# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport argparse\nimport logging\nimport math\nimport os\nimport time\n\nfrom gluoncv.model_zoo import get_model\nimport horovod.mxnet as hvd\nimport mxnet as mx\nimport numpy as np\nfrom mxnet import autograd, gluon, lr_scheduler\nfrom mxnet.io import DataBatch, DataIter\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'MXNet ImageNet Example\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--use-rec\', action=\'store_true\', default=False,\n                    help=\'use image record iter for data input (default: False)\')\nparser.add_argument(\'--data-nthreads\', type=int, default=2,\n                    help=\'number of threads for data decoding (default: 2)\')\nparser.add_argument(\'--rec-train\', type=str, default=\'\',\n                    help=\'the training data\')\nparser.add_argument(\'--rec-train-idx\', type=str, default=\'\',\n                    help=\'the index of training data\')\nparser.add_argument(\'--rec-val\', type=str, default=\'\',\n                    help=\'the validation data\')\nparser.add_argument(\'--rec-val-idx\', type=str, default=\'\',\n                    help=\'the index of validation data\')\nparser.add_argument(\'--batch-size\', type=int, default=128,\n                    help=\'training batch size per device (default: 128)\')\nparser.add_argument(\'--dtype\', type=str, default=\'float32\',\n                    help=\'data type for training (default: float32)\')\nparser.add_argument(\'--num-epochs\', type=int, default=90,\n                    help=\'number of training epochs (default: 90)\')\nparser.add_argument(\'--lr\', type=float, default=0.05,\n                    help=\'learning rate for a single GPU (default: 0.05)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9,\n                    help=\'momentum value for optimizer (default: 0.9)\')\nparser.add_argument(\'--wd\', type=float, default=0.0001,\n                    help=\'weight decay rate (default: 0.0001)\')\nparser.add_argument(\'--lr-mode\', type=str, default=\'poly\',\n                    help=\'learning rate scheduler mode. Options are step, \\\n                    poly and cosine (default: poly)\')\nparser.add_argument(\'--lr-decay\', type=float, default=0.1,\n                    help=\'decay rate of learning rate (default: 0.1)\')\nparser.add_argument(\'--lr-decay-epoch\', type=str, default=\'40,60\',\n                    help=\'epoches at which learning rate decays (default: 40,60)\')\nparser.add_argument(\'--warmup-lr\', type=float, default=0.0,\n                    help=\'starting warmup learning rate (default: 0.0)\')\nparser.add_argument(\'--warmup-epochs\', type=int, default=10,\n                    help=\'number of warmup epochs (default: 10)\')\nparser.add_argument(\'--last-gamma\', action=\'store_true\', default=False,\n                    help=\'whether to init gamma of the last BN layer in \\\n                    each bottleneck to 0 (default: False)\')\nparser.add_argument(\'--model\', type=str, default=\'resnet50_v1\',\n                    help=\'type of model to use. see vision_model for options.\')\nparser.add_argument(\'--mode\', type=str, default=\'module\',\n                    help=\'mode in which to train the model. options are \\\n                    module, gluon (default: module)\')\nparser.add_argument(\'--use-pretrained\', action=\'store_true\', default=False,\n                    help=\'load pretrained model weights (default: False)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training (default: False)\')\nparser.add_argument(\'--eval-epoch\', action=\'store_true\', default=False,\n                    help=\'evaluate validation accuracy after each epoch \\\n                    when training in module mode (default: False)\')\nparser.add_argument(\'--eval-frequency\', type=int, default=0,\n                    help=\'frequency of evaluating validation accuracy \\\n                    when training with gluon mode (default: 0)\')\nparser.add_argument(\'--log-interval\', type=int, default=0,\n                    help=\'number of batches to wait before logging (default: 0)\')\nparser.add_argument(\'--save-frequency\', type=int, default=0,\n                    help=\'frequency of model saving (default: 0)\')\n\n\nargs = parser.parse_args()\n\nlogging.basicConfig(level=logging.INFO)\nlogging.info(args)\n\n# Horovod: initialize Horovod\nhvd.init()\nnum_workers = hvd.size()\nrank = hvd.rank()\nlocal_rank = hvd.local_rank()\n\nnum_classes = 1000\nnum_training_samples = 1281167\nbatch_size = args.batch_size\nepoch_size = \\\n    int(math.ceil(int(num_training_samples // num_workers) / batch_size))\n\nif args.lr_mode == \'step\':\n    lr_decay_epoch = [int(i) for i in args.lr_decay_epoch.split(\',\')]\n    steps = [epoch_size * x for x in lr_decay_epoch]\n    lr_sched = lr_scheduler.MultiFactorScheduler(\n        step=steps,\n        factor=args.lr_decay,\n        base_lr=(args.lr * num_workers),\n        warmup_steps=(args.warmup_epochs * epoch_size),\n        warmup_begin_lr=args.warmup_lr\n    )\nelif args.lr_mode == \'poly\':\n    lr_sched = lr_scheduler.PolyScheduler(\n        args.num_epochs * epoch_size,\n        base_lr=(args.lr * num_workers),\n        pwr=2,\n        warmup_steps=(args.warmup_epochs * epoch_size),\n        warmup_begin_lr=args.warmup_lr\n    )\nelif args.lr_mode == \'cosine\':\n    lr_sched = lr_scheduler.CosineScheduler(\n        args.num_epochs * epoch_size,\n        base_lr=(args.lr * num_workers),\n        warmup_steps=(args.warmup_epochs * epoch_size),\n        warmup_begin_lr=args.warmup_lr\n    )\nelse:\n    raise ValueError(\'Invalid lr mode\')\n\n\n# Function for reading data from record file\n# For more details about data loading in MXNet, please refer to\n# https://mxnet.incubator.apache.org/tutorials/basic/data.html?highlight=imagerecorditer\ndef get_data_rec(rec_train, rec_train_idx, rec_val, rec_val_idx, batch_size,\n                 data_nthreads):\n    rec_train = os.path.expanduser(rec_train)\n    rec_train_idx = os.path.expanduser(rec_train_idx)\n    rec_val = os.path.expanduser(rec_val)\n    rec_val_idx = os.path.expanduser(rec_val_idx)\n    jitter_param = 0.4\n    lighting_param = 0.1\n    mean_rgb = [123.68, 116.779, 103.939]\n\n    train_iter = mx.io.ImageRecordIter(\n        path_imgrec=rec_train,\n        path_imgidx=rec_train_idx,\n        preprocess_threads=data_nthreads,\n        shuffle=True,\n        batch_size=batch_size,\n        label_width=1,\n        data_shape=(3, 224, 224),\n        mean_r=mean_rgb[0],\n        mean_g=mean_rgb[1],\n        mean_b=mean_rgb[2],\n        rand_mirror=True,\n        rand_crop=False,\n        random_resized_crop=True,\n        max_aspect_ratio=4. / 3.,\n        min_aspect_ratio=3. / 4.,\n        max_random_area=1,\n        min_random_area=0.08,\n        verbose=False,\n        brightness=jitter_param,\n        saturation=jitter_param,\n        contrast=jitter_param,\n        pca_noise=lighting_param,\n        num_parts=num_workers,\n        part_index=rank,\n        device_id=local_rank\n    )\n    # Kept each node to use full val data to make it easy to monitor results\n    val_iter = mx.io.ImageRecordIter(\n        path_imgrec=rec_val,\n        path_imgidx=rec_val_idx,\n        preprocess_threads=data_nthreads,\n        shuffle=False,\n        batch_size=batch_size,\n        resize=256,\n        label_width=1,\n        rand_crop=False,\n        rand_mirror=False,\n        data_shape=(3, 224, 224),\n        mean_r=mean_rgb[0],\n        mean_g=mean_rgb[1],\n        mean_b=mean_rgb[2],\n        device_id=local_rank\n    )\n\n    return train_iter, val_iter\n\n\n# Return data and label from batch data\ndef get_data_label(batch, ctx):\n    data = batch.data[0].as_in_context(ctx)\n    label = batch.label[0].as_in_context(ctx)\n    return data, label\n\n\n# Create data iterator for synthetic data\nclass SyntheticDataIter(DataIter):\n    def __init__(self, num_classes, data_shape, max_iter, dtype, ctx):\n        self.batch_size = data_shape[0]\n        self.cur_iter = 0\n        self.max_iter = max_iter\n        self.dtype = dtype\n        label = np.random.randint(0, num_classes, [self.batch_size, ])\n        data = np.random.uniform(-1, 1, data_shape)\n        self.data = mx.nd.array(data, dtype=self.dtype,\n                                ctx=ctx)\n        self.label = mx.nd.array(label, dtype=self.dtype,\n                                 ctx=ctx)\n\n    def __iter__(self):\n        return self\n\n    @property\n    def provide_data(self):\n        return [mx.io.DataDesc(\'data\', self.data.shape, self.dtype)]\n\n    @property\n    def provide_label(self):\n        return [mx.io.DataDesc(\'softmax_label\',\n                               (self.batch_size,), self.dtype)]\n\n    def next(self):\n        self.cur_iter += 1\n        if self.cur_iter <= self.max_iter:\n            return DataBatch(data=(self.data,),\n                             label=(self.label,),\n                             pad=0,\n                             index=None,\n                             provide_data=self.provide_data,\n                             provide_label=self.provide_label)\n        else:\n            raise StopIteration\n\n    def __next__(self):\n        return self.next()\n\n    def reset(self):\n        self.cur_iter = 0\n\n\n# Horovod: pin GPU to local rank\ncontext = mx.cpu(local_rank) if args.no_cuda else mx.gpu(local_rank)\n\nif args.use_rec:\n    # Fetch training and validation data if present\n    train_data, val_data = get_data_rec(args.rec_train,\n                                        args.rec_train_idx,\n                                        args.rec_val,\n                                        args.rec_val_idx,\n                                        batch_size,\n                                        args.data_nthreads)\nelse:\n    # Otherwise use synthetic data\n    image_shape = (3, 224, 224)\n    data_shape = (batch_size,) + image_shape\n    train_data = SyntheticDataIter(num_classes, data_shape, epoch_size,\n                                   np.float32, context)\n    val_data = None\n\n\n# Get model from GluonCV model zoo\n# https://gluon-cv.mxnet.io/model_zoo/index.html\nkwargs = {\'ctx\': context,\n          \'pretrained\': args.use_pretrained,\n          \'classes\': num_classes}\nif args.last_gamma:\n    kwargs[\'last_gamma\'] = True\nnet = get_model(args.model, **kwargs)\nnet.cast(args.dtype)\n\n# Create initializer\ninitializer = mx.init.Xavier(rnd_type=\'gaussian\', factor_type=""in"",\n                             magnitude=2)\n\n\ndef train_gluon():\n    def evaluate(epoch):\n        if not args.use_rec:\n            return\n\n        val_data.reset()\n        acc_top1 = mx.metric.Accuracy()\n        acc_top5 = mx.metric.TopKAccuracy(5)\n        for _, batch in enumerate(val_data):\n            data, label = get_data_label(batch, context)\n            output = net(data.astype(args.dtype, copy=False))\n            acc_top1.update([label], [output])\n            acc_top5.update([label], [output])\n\n        top1_name, top1_acc = acc_top1.get()\n        top5_name, top5_acc = acc_top5.get()\n        logging.info(\'Epoch[%d] Rank[%d]\\tValidation-%s=%f\\tValidation-%s=%f\',\n                     epoch, rank, top1_name, top1_acc, top5_name, top5_acc)\n\n    # Hybridize and initialize model\n    net.hybridize()\n    net.initialize(initializer, ctx=context)\n\n    # Horovod: fetch and broadcast parameters\n    params = net.collect_params()\n    if params is not None:\n        hvd.broadcast_parameters(params, root_rank=0)\n\n    # Create optimizer\n    optimizer_params = {\'wd\': args.wd,\n                        \'momentum\': args.momentum,\n                        \'lr_scheduler\': lr_sched}\n    if args.dtype == \'float16\':\n        optimizer_params[\'multi_precision\'] = True\n    opt = mx.optimizer.create(\'sgd\', **optimizer_params)\n\n    # Horovod: create DistributedTrainer, a subclass of gluon.Trainer\n    trainer = hvd.DistributedTrainer(params, opt)\n\n    # Create loss function and train metric\n    loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n    metric = mx.metric.Accuracy()\n\n    # Train model\n    for epoch in range(args.num_epochs):\n        tic = time.time()\n        if args.use_rec:\n            train_data.reset()\n        metric.reset()\n\n        btic = time.time()\n        for nbatch, batch in enumerate(train_data, start=1):\n            data, label = get_data_label(batch, context)\n            with autograd.record():\n                output = net(data.astype(args.dtype, copy=False))\n                loss = loss_fn(output, label)\n            loss.backward()\n            trainer.step(batch_size)\n\n            metric.update([label], [output])\n            if args.log_interval and nbatch % args.log_interval == 0:\n                name, acc = metric.get()\n                logging.info(\'Epoch[%d] Rank[%d] Batch[%d]\\t%s=%f\\tlr=%f\',\n                             epoch, rank, nbatch, name, acc, trainer.learning_rate)\n                if rank == 0:\n                    batch_speed = num_workers * batch_size * args.log_interval / (time.time() - btic)\n                    logging.info(\'Epoch[%d] Batch[%d]\\tSpeed: %.2f samples/sec\',\n                                 epoch, nbatch, batch_speed)\n                btic = time.time()\n\n        # Report metrics\n        elapsed = time.time() - tic\n        _, acc = metric.get()\n        logging.info(\'Epoch[%d] Rank[%d] Batch[%d]\\tTime cost=%.2f\\tTrain-accuracy=%f\',\n                     epoch, rank, nbatch, elapsed, acc)\n        if rank == 0:\n            epoch_speed = num_workers * batch_size * nbatch / elapsed\n            logging.info(\'Epoch[%d]\\tSpeed: %.2f samples/sec\', epoch, epoch_speed)\n\n        # Evaluate performance\n        if args.eval_frequency and (epoch + 1) % args.eval_frequency == 0:\n            evaluate(epoch)\n\n        # Save model\n        if args.save_frequency and (epoch + 1) % args.save_frequency == 0:\n            net.export(\'%s-%d\' % (args.model, rank), epoch=epoch)\n\n    # Evaluate performance at the end of training\n    evaluate(epoch)\n\n\ndef train_module():\n    # Create input symbol\n    data = mx.sym.var(\'data\')\n    if args.dtype == \'float16\':\n        data = mx.sym.Cast(data=data, dtype=np.float16)\n        net.cast(np.float16)\n\n    # Create output symbol\n    out = net(data)\n    if args.dtype == \'float16\':\n        out = mx.sym.Cast(data=out, dtype=np.float32)\n    softmax = mx.sym.SoftmaxOutput(out, name=\'softmax\')\n\n    # Create model\n    mod = mx.mod.Module(softmax, context=context)\n\n    # Initialize parameters\n    if args.use_pretrained:\n        arg_params = {}\n        for x in net.collect_params().values():\n            x.reset_ctx(mx.cpu())\n            arg_params[x.name] = x.data()\n    else:\n        arg_params = None\n    aux_params = None\n    mod.bind(data_shapes=train_data.provide_data,\n             label_shapes=train_data.provide_label)\n    mod.init_params(initializer, arg_params=arg_params, aux_params=aux_params)\n\n    # Horovod: fetch and broadcast parameters\n    (arg_params, aux_params) = mod.get_params()\n    if arg_params is not None:\n        hvd.broadcast_parameters(arg_params, root_rank=0)\n    if aux_params is not None:\n        hvd.broadcast_parameters(aux_params, root_rank=0)\n    mod.set_params(arg_params=arg_params, aux_params=aux_params)\n\n    # Create optimizer\n    # Note that when using Module API, we need to specify rescale_grad since\n    # we create optimizer first and wrap it with DistributedOptimizer. For\n    # Gluon API, it is handled in Trainer.step() function so there is no need\n    # to specify rescale_grad (see above train_gluon() function). \n    optimizer_params = {\'wd\': args.wd,\n                        \'momentum\': args.momentum,\n                        \'rescale_grad\': 1.0 / batch_size,\n                        \'lr_scheduler\': lr_sched}\n    if args.dtype == \'float16\':\n        optimizer_params[\'multi_precision\'] = True\n    opt = mx.optimizer.create(\'sgd\', **optimizer_params)\n\n    # Horovod: wrap optimizer with DistributedOptimizer\n    dist_opt = hvd.DistributedOptimizer(opt)\n\n    # Setup validation data and callback during training\n    eval_data = None\n    if args.eval_epoch:\n        eval_data = val_data\n    batch_callback = None\n    if args.log_interval > 0 and rank == 0:\n        batch_callback = mx.callback.Speedometer(batch_size * num_workers,\n                                                 args.log_interval)\n\n    epoch_callback = None\n    if args.save_frequency > 0:\n        epoch_callback = mx.callback.do_checkpoint(\n            \'%s-%d\' % (args.model, rank),\n            period=args.save_frequency)\n\n    # Train model\n    mod.fit(train_data,\n            eval_data=eval_data,\n            num_epoch=args.num_epochs,\n            kvstore=None,\n            batch_end_callback=batch_callback,\n            epoch_end_callback=epoch_callback,\n            optimizer=dist_opt)\n\n    # Evaluate performance if not using synthetic data\n    if args.use_rec:\n        acc_top1 = mx.metric.Accuracy()\n        acc_top5 = mx.metric.TopKAccuracy(5)\n        res = mod.score(val_data, [acc_top1, acc_top5])\n        for name, val in res:\n            logging.info(\'Epoch[%d] Rank[%d] Validation-%s=%f\',\n                         args.num_epochs - 1, rank, name, val)\n\n\nif __name__ == \'__main__\':\n    if args.mode == \'module\':\n        train_module()\n    elif args.mode == \'gluon\':\n        train_gluon()\n    else:\n        raise ValueError(\'Invalid training mode.\')\n'"
examples/mxnet_mnist.py,0,"b'import argparse\nimport logging\nimport os\nimport zipfile\nimport time\n\nimport mxnet as mx\nimport horovod.mxnet as hvd\nfrom mxnet import autograd, gluon, nd\nfrom mxnet.test_utils import download\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'MXNet MNIST Example\')\n\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'training batch size (default: 64)\')\nparser.add_argument(\'--dtype\', type=str, default=\'float32\',\n                    help=\'training data type (default: float32)\')\nparser.add_argument(\'--epochs\', type=int, default=5,\n                    help=\'number of training epochs (default: 5)\')\nparser.add_argument(\'--lr\', type=float, default=0.01,\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9,\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disable training on GPU (default: False)\')\nargs = parser.parse_args()\n\nif not args.no_cuda:\n    # Disable CUDA if there are no GPUs.\n    if not mx.test_utils.list_gpus():\n        args.no_cuda = True\n\nlogging.basicConfig(level=logging.INFO)\nlogging.info(args)\n\n\n# Function to get mnist iterator given a rank\ndef get_mnist_iterator(rank):\n    data_dir = ""data-%d"" % rank\n    if not os.path.isdir(data_dir):\n        os.makedirs(data_dir)\n    zip_file_path = download(\'http://data.mxnet.io/mxnet/data/mnist.zip\',\n                             dirname=data_dir)\n    with zipfile.ZipFile(zip_file_path) as zf:\n        zf.extractall(data_dir)\n\n    input_shape = (1, 28, 28)\n    batch_size = args.batch_size\n\n    train_iter = mx.io.MNISTIter(\n        image=""%s/train-images-idx3-ubyte"" % data_dir,\n        label=""%s/train-labels-idx1-ubyte"" % data_dir,\n        input_shape=input_shape,\n        batch_size=batch_size,\n        shuffle=True,\n        flat=False,\n        num_parts=hvd.size(),\n        part_index=hvd.rank()\n    )\n\n    val_iter = mx.io.MNISTIter(\n        image=""%s/t10k-images-idx3-ubyte"" % data_dir,\n        label=""%s/t10k-labels-idx1-ubyte"" % data_dir,\n        input_shape=input_shape,\n        batch_size=batch_size,\n        flat=False,\n    )\n\n    return train_iter, val_iter\n\n\n# Function to define neural network\ndef conv_nets():\n    net = gluon.nn.HybridSequential()\n    with net.name_scope():\n        net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation=\'relu\'))\n        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n        net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation=\'relu\'))\n        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n        net.add(gluon.nn.Flatten())\n        net.add(gluon.nn.Dense(512, activation=""relu""))\n        net.add(gluon.nn.Dense(10))\n    return net\n\n\n# Function to evaluate accuracy for a model\ndef evaluate(model, data_iter, context):\n    data_iter.reset()\n    metric = mx.metric.Accuracy()\n    for _, batch in enumerate(data_iter):\n        data = batch.data[0].as_in_context(context)\n        label = batch.label[0].as_in_context(context)\n        output = model(data.astype(args.dtype, copy=False))\n        metric.update([label], [output])\n\n    return metric.get()\n\n\n# Initialize Horovod\nhvd.init()\n\n# Horovod: pin context to local rank\ncontext = mx.cpu(hvd.local_rank()) if args.no_cuda else mx.gpu(hvd.local_rank())\nnum_workers = hvd.size()\n\n# Load training and validation data\ntrain_data, val_data = get_mnist_iterator(hvd.rank())\n\n# Build model\nmodel = conv_nets()\nmodel.cast(args.dtype)\nmodel.hybridize()\n\n# Create optimizer\noptimizer_params = {\'momentum\': args.momentum,\n                    \'learning_rate\': args.lr * hvd.size()}\nopt = mx.optimizer.create(\'sgd\', **optimizer_params)\n\n# Initialize parameters\ninitializer = mx.init.Xavier(rnd_type=\'gaussian\', factor_type=""in"",\n                             magnitude=2)\nmodel.initialize(initializer, ctx=context)\n\n# Horovod: fetch and broadcast parameters\nparams = model.collect_params()\nif params is not None:\n    hvd.broadcast_parameters(params, root_rank=0)\n\n# Horovod: create DistributedTrainer, a subclass of gluon.Trainer\ntrainer = hvd.DistributedTrainer(params, opt)\n\n# Create loss function and train metric\nloss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\nmetric = mx.metric.Accuracy()\n\n# Train model\nfor epoch in range(args.epochs):\n    tic = time.time()\n    train_data.reset()\n    metric.reset()\n    for nbatch, batch in enumerate(train_data, start=1):\n        data = batch.data[0].as_in_context(context)\n        label = batch.label[0].as_in_context(context)\n        with autograd.record():\n            output = model(data.astype(args.dtype, copy=False))\n            loss = loss_fn(output, label)\n        loss.backward()\n        trainer.step(args.batch_size)\n        metric.update([label], [output])\n\n        if nbatch % 100 == 0:\n            name, acc = metric.get()\n            logging.info(\'[Epoch %d Batch %d] Training: %s=%f\' %\n                         (epoch, nbatch, name, acc))\n\n    if hvd.rank() == 0:\n        elapsed = time.time() - tic\n        speed = nbatch * args.batch_size * hvd.size() / elapsed\n        logging.info(\'Epoch[%d]\\tSpeed=%.2f samples/s\\tTime cost=%f\',\n                     epoch, speed, elapsed)\n\n    # Evaluate model accuracy\n    _, train_acc = metric.get()\n    name, val_acc = evaluate(model, val_data, context)\n    if hvd.rank() == 0:\n        logging.info(\'Epoch[%d]\\tTrain: %s=%f\\tValidation: %s=%f\', epoch, name,\n                     train_acc, name, val_acc)\n\n    if hvd.rank() == 0 and epoch == args.epochs - 1:\n        assert val_acc > 0.96, ""Achieved accuracy (%f) is lower than expected\\\n                                (0.96)"" % val_acc\n'"
examples/pytorch_imagenet_resnet50.py,0,"b""import torch\nimport argparse\nimport torch.backends.cudnn as cudnn\nimport torch.multiprocessing as mp\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import datasets, transforms, models\nimport horovod.torch as hvd\nimport os\nimport math\nfrom tqdm import tqdm\nfrom distutils.version import LooseVersion\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch ImageNet Example',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--train-dir', default=os.path.expanduser('~/imagenet/train'),\n                    help='path to training data')\nparser.add_argument('--val-dir', default=os.path.expanduser('~/imagenet/validation'),\n                    help='path to validation data')\nparser.add_argument('--log-dir', default='./logs',\n                    help='tensorboard log directory')\nparser.add_argument('--checkpoint-format', default='./checkpoint-{epoch}.pth.tar',\n                    help='checkpoint file format')\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\n                    help='use fp16 compression during allreduce')\nparser.add_argument('--batches-per-allreduce', type=int, default=1,\n                    help='number of batches processed locally before '\n                         'executing allreduce across workers; it multiplies '\n                         'total batch size.')\nparser.add_argument('--use-adasum', action='store_true', default=False,\n                    help='use adasum algorithm to do reduction')\n\n# Default settings from https://arxiv.org/abs/1706.02677.\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size for training')\nparser.add_argument('--val-batch-size', type=int, default=32,\n                    help='input batch size for validation')\nparser.add_argument('--epochs', type=int, default=90,\n                    help='number of epochs to train')\nparser.add_argument('--base-lr', type=float, default=0.0125,\n                    help='learning rate for a single GPU')\nparser.add_argument('--warmup-epochs', type=float, default=5,\n                    help='number of warmup epochs')\nparser.add_argument('--momentum', type=float, default=0.9,\n                    help='SGD momentum')\nparser.add_argument('--wd', type=float, default=0.00005,\n                    help='weight decay')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--seed', type=int, default=42,\n                    help='random seed')\n\n\ndef train(epoch):\n    model.train()\n    train_sampler.set_epoch(epoch)\n    train_loss = Metric('train_loss')\n    train_accuracy = Metric('train_accuracy')\n\n    with tqdm(total=len(train_loader),\n              desc='Train Epoch     #{}'.format(epoch + 1),\n              disable=not verbose) as t:\n        for batch_idx, (data, target) in enumerate(train_loader):\n            adjust_learning_rate(epoch, batch_idx)\n\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            optimizer.zero_grad()\n            # Split data into sub-batches of size batch_size\n            for i in range(0, len(data), args.batch_size):\n                data_batch = data[i:i + args.batch_size]\n                target_batch = target[i:i + args.batch_size]\n                output = model(data_batch)\n                train_accuracy.update(accuracy(output, target_batch))\n                loss = F.cross_entropy(output, target_batch)\n                train_loss.update(loss)\n                # Average gradients among sub-batches\n                loss.div_(math.ceil(float(len(data)) / args.batch_size))\n                loss.backward()\n            # Gradient is applied across all ranks\n            optimizer.step()\n            t.set_postfix({'loss': train_loss.avg.item(),\n                           'accuracy': 100. * train_accuracy.avg.item()})\n            t.update(1)\n\n    if log_writer:\n        log_writer.add_scalar('train/loss', train_loss.avg, epoch)\n        log_writer.add_scalar('train/accuracy', train_accuracy.avg, epoch)\n\n\ndef validate(epoch):\n    model.eval()\n    val_loss = Metric('val_loss')\n    val_accuracy = Metric('val_accuracy')\n\n    with tqdm(total=len(val_loader),\n              desc='Validate Epoch  #{}'.format(epoch + 1),\n              disable=not verbose) as t:\n        with torch.no_grad():\n            for data, target in val_loader:\n                if args.cuda:\n                    data, target = data.cuda(), target.cuda()\n                output = model(data)\n\n                val_loss.update(F.cross_entropy(output, target))\n                val_accuracy.update(accuracy(output, target))\n                t.set_postfix({'loss': val_loss.avg.item(),\n                               'accuracy': 100. * val_accuracy.avg.item()})\n                t.update(1)\n\n    if log_writer:\n        log_writer.add_scalar('val/loss', val_loss.avg, epoch)\n        log_writer.add_scalar('val/accuracy', val_accuracy.avg, epoch)\n\n\n# Horovod: using `lr = base_lr * hvd.size()` from the very beginning leads to worse final\n# accuracy. Scale the learning rate `lr = base_lr` ---> `lr = base_lr * hvd.size()` during\n# the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n# After the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.\ndef adjust_learning_rate(epoch, batch_idx):\n    if epoch < args.warmup_epochs:\n        epoch += float(batch_idx + 1) / len(train_loader)\n        lr_adj = 1. / hvd.size() * (epoch * (hvd.size() - 1) / args.warmup_epochs + 1)\n    elif epoch < 30:\n        lr_adj = 1.\n    elif epoch < 60:\n        lr_adj = 1e-1\n    elif epoch < 80:\n        lr_adj = 1e-2\n    else:\n        lr_adj = 1e-3\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = args.base_lr * hvd.size() * args.batches_per_allreduce * lr_adj\n\n\ndef accuracy(output, target):\n    # get the index of the max log-probability\n    pred = output.max(1, keepdim=True)[1]\n    return pred.eq(target.view_as(pred)).cpu().float().mean()\n\n\ndef save_checkpoint(epoch):\n    if hvd.rank() == 0:\n        filepath = args.checkpoint_format.format(epoch=epoch + 1)\n        state = {\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n        }\n        torch.save(state, filepath)\n\n\n# Horovod: average metrics from distributed training.\nclass Metric(object):\n    def __init__(self, name):\n        self.name = name\n        self.sum = torch.tensor(0.)\n        self.n = torch.tensor(0.)\n\n    def update(self, val):\n        self.sum += hvd.allreduce(val.detach().cpu(), name=self.name)\n        self.n += 1\n\n    @property\n    def avg(self):\n        return self.sum / self.n\n\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n    args.cuda = not args.no_cuda and torch.cuda.is_available()\n\n    allreduce_batch_size = args.batch_size * args.batches_per_allreduce\n\n    hvd.init()\n    torch.manual_seed(args.seed)\n\n    if args.cuda:\n        # Horovod: pin GPU to local rank.\n        torch.cuda.set_device(hvd.local_rank())\n        torch.cuda.manual_seed(args.seed)\n\n    cudnn.benchmark = True\n\n    # If set > 0, will resume training from a given checkpoint.\n    resume_from_epoch = 0\n    for try_epoch in range(args.epochs, 0, -1):\n        if os.path.exists(args.checkpoint_format.format(epoch=try_epoch)):\n            resume_from_epoch = try_epoch\n            break\n\n    # Horovod: broadcast resume_from_epoch from rank 0 (which will have\n    # checkpoints) to other ranks.\n    resume_from_epoch = hvd.broadcast(torch.tensor(resume_from_epoch), root_rank=0,\n                                      name='resume_from_epoch').item()\n\n    # Horovod: print logs on the first worker.\n    verbose = 1 if hvd.rank() == 0 else 0\n\n    # Horovod: write TensorBoard logs on first worker.\n    try:\n        if LooseVersion(torch.__version__) >= LooseVersion('1.2.0'):\n            from torch.utils.tensorboard import SummaryWriter\n        else:\n            from tensorboardX import SummaryWriter\n        log_writer = SummaryWriter(args.log_dir) if hvd.rank() == 0 else None\n    except ImportError:\n        log_writer = None\n\n    # Horovod: limit # of CPU threads to be used per worker.\n    torch.set_num_threads(4)\n\n    kwargs = {'num_workers': 4, 'pin_memory': True} if args.cuda else {}\n    # When supported, use 'forkserver' to spawn dataloader workers instead of 'fork' to prevent\n    # issues with Infiniband implementations that are not fork-safe\n    if (kwargs.get('num_workers', 0) > 0 and hasattr(mp, '_supports_context') and\n            mp._supports_context and 'forkserver' in mp.get_all_start_methods()):\n        kwargs['multiprocessing_context'] = 'forkserver'\n\n    train_dataset = \\\n        datasets.ImageFolder(args.train_dir,\n                             transform=transforms.Compose([\n                                 transforms.RandomResizedCrop(224),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                      std=[0.229, 0.224, 0.225])\n                             ]))\n    # Horovod: use DistributedSampler to partition data among workers. Manually specify\n    # `num_replicas=hvd.size()` and `rank=hvd.rank()`.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=allreduce_batch_size,\n        sampler=train_sampler, **kwargs)\n\n    val_dataset = \\\n        datasets.ImageFolder(args.val_dir,\n                             transform=transforms.Compose([\n                                 transforms.Resize(256),\n                                 transforms.CenterCrop(224),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                      std=[0.229, 0.224, 0.225])\n                             ]))\n    val_sampler = torch.utils.data.distributed.DistributedSampler(\n        val_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.val_batch_size,\n                                             sampler=val_sampler, **kwargs)\n\n\n    # Set up standard ResNet-50 model.\n    model = models.resnet50()\n\n    # By default, Adasum doesn't need scaling up learning rate.\n    # For sum/average with gradient Accumulation: scale learning rate by batches_per_allreduce\n    lr_scaler = args.batches_per_allreduce * hvd.size() if not args.use_adasum else 1\n\n    if args.cuda:\n        # Move model to GPU.\n        model.cuda()\n        # If using GPU Adasum allreduce, scale learning rate by local_size.\n        if args.use_adasum and hvd.nccl_built():\n            lr_scaler = args.batches_per_allreduce * hvd.local_size()\n\n    # Horovod: scale learning rate by the number of GPUs.\n    optimizer = optim.SGD(model.parameters(),\n                          lr=(args.base_lr *\n                              lr_scaler),\n                          momentum=args.momentum, weight_decay=args.wd)\n\n    # Horovod: (optional) compression algorithm.\n    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n    # Horovod: wrap optimizer with DistributedOptimizer.\n    optimizer = hvd.DistributedOptimizer(\n        optimizer, named_parameters=model.named_parameters(),\n        compression=compression,\n        backward_passes_per_step=args.batches_per_allreduce,\n        op=hvd.Adasum if args.use_adasum else hvd.Average)\n\n    # Restore from a previous checkpoint, if initial_epoch is specified.\n    # Horovod: restore on the first worker which will broadcast weights to other workers.\n    if resume_from_epoch > 0 and hvd.rank() == 0:\n        filepath = args.checkpoint_format.format(epoch=resume_from_epoch)\n        checkpoint = torch.load(filepath)\n        model.load_state_dict(checkpoint['model'])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n\n    # Horovod: broadcast parameters & optimizer state.\n    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n    for epoch in range(resume_from_epoch, args.epochs):\n        train(epoch)\n        validate(epoch)\n        save_checkpoint(epoch)\n"""
examples/pytorch_mnist.py,0,"b""import argparse\nimport torch.multiprocessing as mp\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport torch.utils.data.distributed\nimport horovod.torch as hvd\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='input batch size for training (default: 64)')\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                    help='input batch size for testing (default: 1000)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='number of epochs to train (default: 10)')\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n                    help='learning rate (default: 0.01)')\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n                    help='SGD momentum (default: 0.5)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--seed', type=int, default=42, metavar='S',\n                    help='random seed (default: 42)')\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                    help='how many batches to wait before logging training status')\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\n                    help='use fp16 compression during allreduce')\nparser.add_argument('--use-adasum', action='store_true', default=False,\n                    help='use adasum algorithm to do reduction')\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\ndef train(epoch):\n    model.train()\n    # Horovod: set epoch to sampler for shuffling.\n    train_sampler.set_epoch(epoch)\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            # Horovod: use train_sampler to determine the number of examples in\n            # this worker's partition.\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_sampler),\n                100. * batch_idx / len(train_loader), loss.item()))\n\n\ndef metric_average(val, name):\n    tensor = torch.tensor(val)\n    avg_tensor = hvd.allreduce(tensor, name=name)\n    return avg_tensor.item()\n\n\ndef test():\n    model.eval()\n    test_loss = 0.\n    test_accuracy = 0.\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        # sum up batch loss\n        test_loss += F.nll_loss(output, target, size_average=False).item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n\n    # Horovod: use test_sampler to determine the number of examples in\n    # this worker's partition.\n    test_loss /= len(test_sampler)\n    test_accuracy /= len(test_sampler)\n\n    # Horovod: average metric values across workers.\n    test_loss = metric_average(test_loss, 'avg_loss')\n    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\n\n    # Horovod: print output only on first rank.\n    if hvd.rank() == 0:\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n            test_loss, 100. * test_accuracy))\n\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n    args.cuda = not args.no_cuda and torch.cuda.is_available()\n\n    # Horovod: initialize library.\n    hvd.init()\n    torch.manual_seed(args.seed)\n\n    if args.cuda:\n        # Horovod: pin GPU to local rank.\n        torch.cuda.set_device(hvd.local_rank())\n        torch.cuda.manual_seed(args.seed)\n\n\n    # Horovod: limit # of CPU threads to be used per worker.\n    torch.set_num_threads(1)\n\n    kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n    # When supported, use 'forkserver' to spawn dataloader workers instead of 'fork' to prevent\n    # issues with Infiniband implementations that are not fork-safe\n    if (kwargs.get('num_workers', 0) > 0 and hasattr(mp, '_supports_context') and\n            mp._supports_context and 'forkserver' in mp.get_all_start_methods()):\n        kwargs['multiprocessing_context'] = 'forkserver'\n\n    train_dataset = \\\n        datasets.MNIST('data-%d' % hvd.rank(), train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ]))\n    # Horovod: use DistributedSampler to partition the training data.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\n\n    test_dataset = \\\n        datasets.MNIST('data-%d' % hvd.rank(), train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ]))\n    # Horovod: use DistributedSampler to partition the test data.\n    test_sampler = torch.utils.data.distributed.DistributedSampler(\n        test_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\n                                              sampler=test_sampler, **kwargs)\n\n    model = Net()\n\n    # By default, Adasum doesn't need scaling up learning rate.\n    lr_scaler = hvd.size() if not args.use_adasum else 1\n\n    if args.cuda:\n        # Move model to GPU.\n        model.cuda()\n        # If using GPU Adasum allreduce, scale learning rate by local_size.\n        if args.use_adasum and hvd.nccl_built():\n            lr_scaler = hvd.local_size()\n\n    # Horovod: scale learning rate by lr_scaler.\n    optimizer = optim.SGD(model.parameters(), lr=args.lr * lr_scaler,\n                          momentum=args.momentum)\n\n    # Horovod: broadcast parameters & optimizer state.\n    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n    # Horovod: (optional) compression algorithm.\n    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n    # Horovod: wrap optimizer with DistributedOptimizer.\n    optimizer = hvd.DistributedOptimizer(optimizer,\n                                         named_parameters=model.named_parameters(),\n                                         compression=compression,\n                                         op=hvd.Adasum if args.use_adasum else hvd.Average)\n\n    for epoch in range(1, args.epochs + 1):\n        train(epoch)\n        test()\n"""
examples/pytorch_spark_mnist.py,0,"b""import argparse\nimport os\nimport subprocess\nfrom distutils.version import LooseVersion\n\nimport numpy as np\n\nimport pyspark\nimport pyspark.sql.types as T\nfrom pyspark import SparkConf\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nif LooseVersion(pyspark.__version__) < LooseVersion('3.0.0'):\n    from pyspark.ml.feature import OneHotEncoderEstimator as OneHotEncoder\nelse:\n    from pyspark.ml.feature import OneHotEncoder\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import udf\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport horovod.spark.torch as hvd\nfrom horovod.spark.common.store import Store\n\nparser = argparse.ArgumentParser(description='Keras Spark MNIST Example',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--master',\n                    help='spark master to connect to')\nparser.add_argument('--num-proc', type=int,\n                    help='number of worker processes for training, default: `spark.default.parallelism`')\nparser.add_argument('--batch-size', type=int, default=128,\n                    help='input batch size for training')\nparser.add_argument('--epochs', type=int, default=12,\n                    help='number of epochs to train')\nparser.add_argument('--work-dir', default='/tmp',\n                    help='temporary working directory to write intermediate files (prefix with hdfs:// to use HDFS)')\nparser.add_argument('--data-dir', default='/tmp',\n                    help='location of the training dataset in the local filesystem (will be downloaded if needed)')\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n\n    # Initialize SparkSession\n    conf = SparkConf().setAppName('keras_spark_mnist').set('spark.sql.shuffle.partitions', '16')\n    if args.master:\n        conf.setMaster(args.master)\n    elif args.num_proc:\n        conf.setMaster('local[{}]'.format(args.num_proc))\n    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n    # Setup our store for intermediate data\n    store = Store.create(args.work_dir)\n\n    # Download MNIST dataset\n    data_url = 'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/mnist.bz2'\n    libsvm_path = os.path.join(args.data_dir, 'mnist.bz2')\n    if not os.path.exists(libsvm_path):\n        subprocess.check_output(['wget', data_url, '-O', libsvm_path])\n\n    # Load dataset into a Spark DataFrame\n    df = spark.read.format('libsvm') \\\n        .option('numFeatures', '784') \\\n        .load(libsvm_path)\n\n    # One-hot encode labels into SparseVectors\n    encoder = OneHotEncoder(inputCols=['label'],\n                            outputCols=['label_vec'],\n                            dropLast=False)\n    model = encoder.fit(df)\n    train_df = model.transform(df)\n\n    # Train/test split\n    train_df, test_df = train_df.randomSplit([0.9, 0.1])\n\n\n    # Define the PyTorch model without any Horovod-specific parameters\n    class Net(nn.Module):\n        def __init__(self):\n            super(Net, self).__init__()\n            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n            self.conv2_drop = nn.Dropout2d()\n            self.fc1 = nn.Linear(320, 50)\n            self.fc2 = nn.Linear(50, 10)\n\n        def forward(self, x):\n            x = x.float()\n            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n            x = x.view(-1, 320)\n            x = F.relu(self.fc1(x))\n            x = F.dropout(x, training=self.training)\n            x = self.fc2(x)\n            return F.log_softmax(x)\n\n\n    model = Net()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n    loss = nn.NLLLoss()\n\n    # Train a Horovod Spark Estimator on the DataFrame\n    torch_estimator = hvd.TorchEstimator(num_proc=args.num_proc,\n                                         store=store,\n                                         model=model,\n                                         optimizer=optimizer,\n                                         loss=lambda input, target: loss(input, target.long()),\n                                         input_shapes=[[-1, 1, 28, 28]],\n                                         feature_cols=['features'],\n                                         label_cols=['label'],\n                                         batch_size=args.batch_size,\n                                         epochs=args.epochs,\n                                         verbose=1)\n\n    torch_model = torch_estimator.fit(train_df).setOutputCols(['label_prob'])\n\n    # Evaluate the model on the held-out test DataFrame\n    pred_df = torch_model.transform(test_df)\n    argmax = udf(lambda v: float(np.argmax(v)), returnType=T.DoubleType())\n    pred_df = pred_df.withColumn('label_pred', argmax(pred_df.label_prob))\n    evaluator = MulticlassClassificationEvaluator(predictionCol='label_pred', labelCol='label', metricName='accuracy')\n    print('Test accuracy:', evaluator.evaluate(pred_df))\n\n    spark.stop()\n"""
examples/pytorch_synthetic_benchmark.py,0,"b""import argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import models\nimport horovod.torch as hvd\nimport timeit\nimport numpy as np\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description='PyTorch Synthetic Benchmark',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\n                    help='use fp16 compression during allreduce')\n\nparser.add_argument('--model', type=str, default='resnet50',\n                    help='model to benchmark')\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size')\n\nparser.add_argument('--num-warmup-batches', type=int, default=10,\n                    help='number of warm-up batches that don\\'t count towards benchmark')\nparser.add_argument('--num-batches-per-iter', type=int, default=10,\n                    help='number of batches per benchmark iteration')\nparser.add_argument('--num-iters', type=int, default=10,\n                    help='number of benchmark iterations')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\n\nparser.add_argument('--use-adasum', action='store_true', default=False,\n                    help='use adasum algorithm to do reduction')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nhvd.init()\n\nif args.cuda:\n    # Horovod: pin GPU to local rank.\n    torch.cuda.set_device(hvd.local_rank())\n\ncudnn.benchmark = True\n\n# Set up standard model.\nmodel = getattr(models, args.model)()\n\n# By default, Adasum doesn't need scaling up learning rate.\nlr_scaler = hvd.size() if not args.use_adasum else 1\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n    # If using GPU Adasum allreduce, scale learning rate by local_size.\n    if args.use_adasum and hvd.nccl_built():\n        lr_scaler = hvd.local_size()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01 * lr_scaler)\n\n# Horovod: (optional) compression algorithm.\ncompression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n# Horovod: wrap optimizer with DistributedOptimizer.\noptimizer = hvd.DistributedOptimizer(optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression,\n                                     op=hvd.Adasum if args.use_adasum else hvd.Average)\n\n# Horovod: broadcast parameters & optimizer state.\nhvd.broadcast_parameters(model.state_dict(), root_rank=0)\nhvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n# Set up fixed fake data\ndata = torch.randn(args.batch_size, 3, 224, 224)\ntarget = torch.LongTensor(args.batch_size).random_() % 1000\nif args.cuda:\n    data, target = data.cuda(), target.cuda()\n\n\ndef benchmark_step():\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n\ndef log(s, nl=True):\n    if hvd.rank() != 0:\n        return\n    print(s, end='\\n' if nl else '')\n\n\nlog('Model: %s' % args.model)\nlog('Batch size: %d' % args.batch_size)\ndevice = 'GPU' if args.cuda else 'CPU'\nlog('Number of %ss: %d' % (device, hvd.size()))\n\n# Warm-up\nlog('Running warmup...')\ntimeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n# Benchmark\nlog('Running benchmark...')\nimg_secs = []\nfor x in range(args.num_iters):\n    time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n    img_sec = args.batch_size * args.num_batches_per_iter / time\n    log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))\n    img_secs.append(img_sec)\n\n# Results\nimg_sec_mean = np.mean(img_secs)\nimg_sec_conf = 1.96 * np.std(img_secs)\nlog('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))\nlog('Total img/sec on %d %s(s): %.1f +-%.1f' %\n    (hvd.size(), device, hvd.size() * img_sec_mean, hvd.size() * img_sec_conf))\n"""
examples/tensorflow2_keras_mnist.py,19,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\nimport horovod.tensorflow.keras as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\ngpus = tf.config.experimental.list_physical_devices(\'GPU\')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\n\n(mnist_images, mnist_labels), _ = \\\n    tf.keras.datasets.mnist.load_data(path=\'mnist-%d.npz\' % hvd.rank())\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n             tf.cast(mnist_labels, tf.int64))\n)\ndataset = dataset.repeat().shuffle(10000).batch(128)\n\nmnist_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, [3, 3], activation=\'relu\'),\n    tf.keras.layers.Conv2D(64, [3, 3], activation=\'relu\'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\'relu\'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation=\'softmax\')\n])\n\n# Horovod: adjust learning rate based on number of GPUs.\nscaled_lr = 0.001 * hvd.size()\nopt = tf.optimizers.Adam(scaled_lr)\n\n# Horovod: add Horovod DistributedOptimizer.\nopt = hvd.DistributedOptimizer(opt)\n\n# Horovod: Specify `experimental_run_tf_function=False` to ensure TensorFlow\n# uses hvd.DistributedOptimizer() to compute gradients.\nmnist_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(),\n                    optimizer=opt,\n                    metrics=[\'accuracy\'],\n                    experimental_run_tf_function=False)\n\ncallbacks = [\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n\n    # Horovod: average metrics among workers at the end of every epoch.\n    #\n    # Note: This callback must be in the list before the ReduceLROnPlateau,\n    # TensorBoard or other metrics-based callbacks.\n    hvd.callbacks.MetricAverageCallback(),\n\n    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n    # the first three epochs. See https://arxiv.org/abs/1706.02677 for details.\n    hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=3, initial_lr=scaled_lr, verbose=1),\n]\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif hvd.rank() == 0:\n    callbacks.append(tf.keras.callbacks.ModelCheckpoint(\'./checkpoint-{epoch}.h5\'))\n\n# Horovod: write logs on worker 0.\nverbose = 1 if hvd.rank() == 0 else 0\n\n# Train the model.\n# Horovod: adjust number of steps based on number of GPUs.\nmnist_model.fit(dataset, steps_per_epoch=500 // hvd.size(), callbacks=callbacks, epochs=24, verbose=verbose)\n'"
examples/tensorflow2_mnist.py,21,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\ngpus = tf.config.experimental.list_physical_devices(\'GPU\')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\n\n(mnist_images, mnist_labels), _ = \\\n    tf.keras.datasets.mnist.load_data(path=\'mnist-%d.npz\' % hvd.rank())\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n             tf.cast(mnist_labels, tf.int64))\n)\ndataset = dataset.repeat().shuffle(10000).batch(128)\n\nmnist_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, [3, 3], activation=\'relu\'),\n    tf.keras.layers.Conv2D(64, [3, 3], activation=\'relu\'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\'relu\'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation=\'softmax\')\n])\nloss = tf.losses.SparseCategoricalCrossentropy()\n\n# Horovod: adjust learning rate based on number of GPUs.\nopt = tf.optimizers.Adam(0.001 * hvd.size())\n\ncheckpoint_dir = \'./checkpoints\'\ncheckpoint = tf.train.Checkpoint(model=mnist_model, optimizer=opt)\n\n\n@tf.function\ndef training_step(images, labels, first_batch):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    # Horovod: add Horovod Distributed GradientTape.\n    tape = hvd.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    #\n    # Note: broadcast should be done after the first gradient step to ensure optimizer\n    # initialization.\n    if first_batch:\n        hvd.broadcast_variables(mnist_model.variables, root_rank=0)\n        hvd.broadcast_variables(opt.variables(), root_rank=0)\n\n    return loss_value\n\n\n# Horovod: adjust number of steps based on number of GPUs.\nfor batch, (images, labels) in enumerate(dataset.take(10000 // hvd.size())):\n    loss_value = training_step(images, labels, batch == 0)\n\n    if batch % 10 == 0 and hvd.local_rank() == 0:\n        print(\'Step #%d\\tLoss: %.6f\' % (batch, loss_value))\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from\n# corrupting it.\nif hvd.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n'"
examples/tensorflow2_synthetic_benchmark.py,10,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\nimport argparse\nimport os\nimport numpy as np\nimport timeit\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\nfrom tensorflow.keras import applications\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'TensorFlow Synthetic Benchmark\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-allreduce\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during allreduce\')\n\nparser.add_argument(\'--model\', type=str, default=\'ResNet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\n\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nif args.cuda:\n    gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    if gpus:\n        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\nelse:\n    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n\n# Set up standard model.\nmodel = getattr(applications, args.model)(weights=None)\nopt = tf.optimizers.SGD(0.01)\n\ndata = tf.random.uniform([args.batch_size, 224, 224, 3])\ntarget = tf.random.uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64)\n\n\n@tf.function\ndef benchmark_step(first_batch):\n    # Horovod: (optional) compression algorithm.\n    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n    # Horovod: use DistributedGradientTape\n    with tf.GradientTape() as tape:\n        probs = model(data, training=True)\n        loss = tf.losses.sparse_categorical_crossentropy(target, probs)\n\n    # Horovod: add Horovod Distributed GradientTape.\n    tape = hvd.DistributedGradientTape(tape, compression=compression)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    opt.apply_gradients(zip(gradients, model.trainable_variables))\n\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    #\n    # Note: broadcast should be done after the first gradient step to ensure optimizer\n    # initialization.\n    if first_batch:\n        hvd.broadcast_variables(model.variables, root_rank=0)\n        hvd.broadcast_variables(opt.variables(), root_rank=0)\n\n\ndef log(s, nl=True):\n    if hvd.rank() != 0:\n        return\n    print(s, end=\'\\n\' if nl else \'\')\n\n\nlog(\'Model: %s\' % args.model)\nlog(\'Batch size: %d\' % args.batch_size)\ndevice = \'GPU\' if args.cuda else \'CPU\'\nlog(\'Number of %ss: %d\' % (device, hvd.size()))\n\n\nwith tf.device(device):\n    # Warm-up\n    log(\'Running warmup...\')\n    benchmark_step(first_batch=True)\n    timeit.timeit(lambda: benchmark_step(first_batch=False),\n                  number=args.num_warmup_batches)\n\n    # Benchmark\n    log(\'Running benchmark...\')\n    img_secs = []\n    for x in range(args.num_iters):\n        time = timeit.timeit(lambda: benchmark_step(first_batch=False),\n                             number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log(\'Iter #%d: %.1f img/sec per %s\' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n    # Results\n    img_sec_mean = np.mean(img_secs)\n    img_sec_conf = 1.96 * np.std(img_secs)\n    log(\'Img/sec per %s: %.1f +-%.1f\' % (device, img_sec_mean, img_sec_conf))\n    log(\'Total img/sec on %d %s(s): %.1f +-%.1f\' %\n        (hvd.size(), device, hvd.size() * img_sec_mean, hvd.size() * img_sec_conf))\n'"
examples/tensorflow_keras_mnist.py,2,"b""import math\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\n\nimport horovod.tensorflow.keras as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\nK.set_session(tf.Session(config=config))\n\nbatch_size = 128\nnum_classes = 10\n\n# Horovod: adjust number of epochs based on number of GPUs.\nepochs = int(math.ceil(12.0 / hvd.size()))\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# The data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Horovod: adjust learning rate based on number of GPUs.\nopt = keras.optimizers.Adadelta(1.0 * hvd.size())\n\n# Horovod: add Horovod Distributed Optimizer.\nopt = hvd.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n]\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif hvd.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          callbacks=callbacks,\n          epochs=epochs,\n          verbose=1 if hvd.rank() == 0 else 0,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
examples/tensorflow_mnist.py,26,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport errno\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\nimport numpy as np\nimport argparse\n\nfrom tensorflow import keras\n\nlayers = tf.layers\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'Tensorflow MNIST Example\')\nparser.add_argument(\'--use-adasum\', action=\'store_true\', default=False,\n                    help=\'use adasum algorithm to do reduction\')\nargs = parser.parse_args()\n\ndef conv_model(feature, target, mode):\n    """"""2-layer convolution model.""""""\n    # Convert the target to a one-hot tensor of shape (batch_size, 10) and\n    # with a on-value of 1 for each one-hot vector of length 10.\n    target = tf.one_hot(tf.cast(target, tf.int32), 10, 1, 0)\n\n    # Reshape feature to 4d tensor with 2nd and 3rd dimensions being\n    # image width and height final dimension being the number of color channels.\n    feature = tf.reshape(feature, [-1, 28, 28, 1])\n\n    # First conv layer will compute 32 features for each 5x5 patch\n    with tf.variable_scope(\'conv_layer1\'):\n        h_conv1 = layers.conv2d(feature, 32, kernel_size=[5, 5],\n                                activation=tf.nn.relu, padding=""SAME"")\n        h_pool1 = tf.nn.max_pool(\n            h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n    # Second conv layer will compute 64 features for each 5x5 patch.\n    with tf.variable_scope(\'conv_layer2\'):\n        h_conv2 = layers.conv2d(h_pool1, 64, kernel_size=[5, 5],\n                                activation=tf.nn.relu, padding=""SAME"")\n        h_pool2 = tf.nn.max_pool(\n            h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n        # reshape tensor into a batch of vectors\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n\n    # Densely connected layer with 1024 neurons.\n    h_fc1 = layers.dropout(\n        layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu),\n        rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    # Compute logits (1 per class) and compute loss.\n    logits = layers.dense(h_fc1, 10, activation=None)\n    loss = tf.losses.softmax_cross_entropy(target, logits)\n\n    return tf.argmax(logits, 1), loss\n\n\ndef train_input_generator(x_train, y_train, batch_size=64):\n    assert len(x_train) == len(y_train)\n    while True:\n        p = np.random.permutation(len(x_train))\n        x_train, y_train = x_train[p], y_train[p]\n        index = 0\n        while index <= len(x_train) - batch_size:\n            yield x_train[index:index + batch_size], \\\n                  y_train[index:index + batch_size],\n            index += batch_size\n\n\ndef main(_):\n    # Horovod: initialize Horovod.\n    hvd.init()\n\n    # Keras automatically creates a cache directory in ~/.keras/datasets for\n    # storing the downloaded MNIST data. This creates a race\n    # condition among the workers that share the same filesystem. If the\n    # directory already exists by the time this worker gets around to creating\n    # it, ignore the resulting exception and continue.\n    cache_dir = os.path.join(os.path.expanduser(\'~\'), \'.keras\', \'datasets\')\n    if not os.path.exists(cache_dir):\n        try:\n            os.mkdir(cache_dir)\n        except OSError as e:\n            if e.errno == errno.EEXIST and os.path.isdir(cache_dir):\n                pass\n            else:\n                raise\n\n    # Download and load MNIST dataset.\n    (x_train, y_train), (x_test, y_test) = \\\n        keras.datasets.mnist.load_data(\'MNIST-data-%d\' % hvd.rank())\n\n    # The shape of downloaded data is (-1, 28, 28), hence we need to reshape it\n    # into (-1, 784) to feed into our network. Also, need to normalize the\n    # features between 0 and 1.\n    x_train = np.reshape(x_train, (-1, 784)) / 255.0\n    x_test = np.reshape(x_test, (-1, 784)) / 255.0\n\n    # Build model...\n    with tf.name_scope(\'input\'):\n        image = tf.placeholder(tf.float32, [None, 784], name=\'image\')\n        label = tf.placeholder(tf.float32, [None], name=\'label\')\n    predict, loss = conv_model(image, label, tf.estimator.ModeKeys.TRAIN)\n\n    lr_scaler = hvd.size()\n    # By default, Adasum doesn\'t need scaling when increasing batch size. If used with NCCL,\n    # scale lr by local_size\n    if args.use_adasum:\n        lr_scaler = hvd.local_size() if hvd.nccl_built() else 1\n\n    # Horovod: adjust learning rate based on lr_scaler.\n    opt = tf.train.AdamOptimizer(0.001 * lr_scaler)\n\n    # Horovod: add Horovod Distributed Optimizer.\n    opt = hvd.DistributedOptimizer(opt, op=hvd.Adasum if args.use_adasum else hvd.Average)\n\n    global_step = tf.train.get_or_create_global_step()\n    train_op = opt.minimize(loss, global_step=global_step)\n\n    hooks = [\n        # Horovod: BroadcastGlobalVariablesHook broadcasts initial variable states\n        # from rank 0 to all other processes. This is necessary to ensure consistent\n        # initialization of all workers when training is started with random weights\n        # or restored from a checkpoint.\n        hvd.BroadcastGlobalVariablesHook(0),\n\n        # Horovod: adjust number of steps based on number of GPUs.\n        tf.train.StopAtStepHook(last_step=20000 // hvd.size()),\n\n        tf.train.LoggingTensorHook(tensors={\'step\': global_step, \'loss\': loss},\n                                   every_n_iter=10),\n    ]\n\n    # Horovod: pin GPU to be used to process local rank (one GPU per process)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    # Horovod: save checkpoints only on worker 0 to prevent other workers from\n    # corrupting them.\n    checkpoint_dir = \'./checkpoints\' if hvd.rank() == 0 else None\n    training_batch_generator = train_input_generator(x_train,\n                                                     y_train, batch_size=100)\n    # The MonitoredTrainingSession takes care of session initialization,\n    # restoring from a checkpoint, saving to a checkpoint, and closing when done\n    # or an error occurs.\n    with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                           hooks=hooks,\n                                           config=config) as mon_sess:\n        while not mon_sess.should_stop():\n            # Run a training step synchronously.\n            image_, label_ = next(training_batch_generator)\n            mon_sess.run(train_op, feed_dict={image: image_, label: label_})\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
examples/tensorflow_mnist_eager.py,18,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\n\n\ndef main(_):\n    # Horovod: initialize Horovod.\n    hvd.init()\n\n    # Horovod: pin GPU to be used to process local rank (one GPU per process)\n    config = tf.ConfigProto()\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    tf.enable_eager_execution(config=config)\n\n    mnist_model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(16, [3, 3], activation=\'relu\'),\n        tf.keras.layers.Conv2D(16, [3, 3], activation=\'relu\'),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(10)\n    ])\n\n    # Horovod: adjust learning rate based on number of GPUs.\n    opt = tf.train.AdamOptimizer(0.001 * hvd.size())\n\n    (mnist_images, mnist_labels), _ = \\\n        tf.keras.datasets.mnist.load_data(path=\'mnist-%d.npz\' % hvd.rank())\n\n    dataset = tf.data.Dataset.from_tensor_slices(\n        (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n         tf.cast(mnist_labels, tf.int64))\n    )\n    dataset = dataset.repeat().shuffle(1000).batch(32)\n\n    checkpoint_dir = \'./checkpoints\'\n    step_counter = tf.train.get_or_create_global_step()\n    checkpoint = tf.train.Checkpoint(model=mnist_model, optimizer=opt,\n                                     step_counter=step_counter)\n\n    # Horovod: adjust number of steps based on number of GPUs.\n    for (batch, (images, labels)) in enumerate(\n            dataset.take(20000 // hvd.size())):\n        with tf.GradientTape() as tape:\n            logits = mnist_model(images, training=True)\n            loss_value = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n\n        # Horovod: add Horovod Distributed GradientTape.\n        tape = hvd.DistributedGradientTape(tape)\n\n        grads = tape.gradient(loss_value, mnist_model.variables)\n        opt.apply_gradients(zip(grads, mnist_model.variables),\n                            global_step=tf.train.get_or_create_global_step())\n\n        # Horovod: broadcast initial variable states from rank 0 to all other processes.\n        # This is necessary to ensure consistent initialization of all workers when\n        # training is started with random weights or restored from a checkpoint.\n        if batch == 0:\n            hvd.broadcast_variables(mnist_model.variables, root_rank=0)\n            hvd.broadcast_variables(opt.variables(), root_rank=0)\n\n        if batch % 10 == 0 and hvd.local_rank() == 0:\n            print(\'Step #%d\\tLoss: %.6f\' % (batch, loss_value))\n\n    # Horovod: save checkpoints only on worker 0 to prevent other workers from\n    # corrupting it.\n    if hvd.rank() == 0:\n        checkpoint.save(checkpoint_dir)\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
examples/tensorflow_mnist_estimator.py,34,"b'#  Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n""""""Convolutional Neural Network Estimator for MNIST, built with tf.layers.""""""\n\nimport os\nimport errno\nimport numpy as np\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\n\nfrom tensorflow import keras\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_model_fn(features, labels, mode):\n    """"""Model function for CNN.""""""\n    # Input Layer\n    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n    # MNIST images are 28x28 pixels, and have one color channel\n    input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1])\n\n    # Convolutional Layer #1\n    # Computes 32 features using a 5x5 filter with ReLU activation.\n    # Padding is added to preserve width and height.\n    # Input Tensor Shape: [batch_size, 28, 28, 1]\n    # Output Tensor Shape: [batch_size, 28, 28, 32]\n    conv1 = tf.layers.conv2d(\n        inputs=input_layer,\n        filters=32,\n        kernel_size=[5, 5],\n        padding=""same"",\n        activation=tf.nn.relu)\n\n    # Pooling Layer #1\n    # First max pooling layer with a 2x2 filter and stride of 2\n    # Input Tensor Shape: [batch_size, 28, 28, 32]\n    # Output Tensor Shape: [batch_size, 14, 14, 32]\n    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #2\n    # Computes 64 features using a 5x5 filter.\n    # Padding is added to preserve width and height.\n    # Input Tensor Shape: [batch_size, 14, 14, 32]\n    # Output Tensor Shape: [batch_size, 14, 14, 64]\n    conv2 = tf.layers.conv2d(\n        inputs=pool1,\n        filters=64,\n        kernel_size=[5, 5],\n        padding=""same"",\n        activation=tf.nn.relu)\n\n    # Pooling Layer #2\n    # Second max pooling layer with a 2x2 filter and stride of 2\n    # Input Tensor Shape: [batch_size, 14, 14, 64]\n    # Output Tensor Shape: [batch_size, 7, 7, 64]\n    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n    # Flatten tensor into a batch of vectors\n    # Input Tensor Shape: [batch_size, 7, 7, 64]\n    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n    # Dense Layer\n    # Densely connected layer with 1024 neurons\n    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n    # Output Tensor Shape: [batch_size, 1024]\n    dense = tf.layers.dense(inputs=pool2_flat, units=1024,\n                            activation=tf.nn.relu)\n\n    # Add dropout operation; 0.6 probability that element will be kept\n    dropout = tf.layers.dropout(\n        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    # Logits layer\n    # Input Tensor Shape: [batch_size, 1024]\n    # Output Tensor Shape: [batch_size, 10]\n    logits = tf.layers.dense(inputs=dropout, units=10)\n\n    predictions = {\n        # Generate predictions (for PREDICT and EVAL mode)\n        ""classes"": tf.argmax(input=logits, axis=1),\n        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n        # `logging_hook`.\n        ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")\n    }\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n    loss = tf.losses.softmax_cross_entropy(\n        onehot_labels=onehot_labels, logits=logits)\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        # Horovod: scale learning rate by the number of workers.\n        optimizer = tf.train.MomentumOptimizer(\n            learning_rate=0.001 * hvd.size(), momentum=0.9)\n\n        # Horovod: add Horovod Distributed Optimizer.\n        optimizer = hvd.DistributedOptimizer(optimizer)\n\n        train_op = optimizer.minimize(\n            loss=loss,\n            global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss,\n                                          train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\n        ""accuracy"": tf.metrics.accuracy(\n            labels=labels, predictions=predictions[""classes""])}\n    return tf.estimator.EstimatorSpec(\n        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n    # Horovod: initialize Horovod.\n    hvd.init()\n\n    # Keras automatically creates a cache directory in ~/.keras/datasets for\n    # storing the downloaded MNIST data. This creates a race\n    # condition among the workers that share the same filesystem. If the\n    # directory already exists by the time this worker gets around to creating\n    # it, ignore the resulting exception and continue.\n    cache_dir = os.path.join(os.path.expanduser(\'~\'), \'.keras\', \'datasets\')\n    if not os.path.exists(cache_dir):\n        try:\n            os.mkdir(cache_dir)\n        except OSError as e:\n            if e.errno == errno.EEXIST and os.path.isdir(cache_dir):\n                pass\n            else:\n                raise\n\n    # Download and load MNIST dataset.\n    (train_data, train_labels), (eval_data, eval_labels) = \\\n        keras.datasets.mnist.load_data(\'MNIST-data-%d\' % hvd.rank())\n\n    # The shape of downloaded data is (-1, 28, 28), hence we need to reshape it\n    # into (-1, 784) to feed into our network. Also, need to normalize the\n    # features between 0 and 1.\n    train_data = np.reshape(train_data, (-1, 784)) / 255.0\n    eval_data = np.reshape(eval_data, (-1, 784)) / 255.0\n\n    # Horovod: pin GPU to be used to process local rank (one GPU per process)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    # Horovod: save checkpoints only on worker 0 to prevent other workers from\n    # corrupting them.\n    model_dir = \'./mnist_convnet_model\' if hvd.rank() == 0 else None\n\n    # Create the Estimator\n    mnist_classifier = tf.estimator.Estimator(\n        model_fn=cnn_model_fn, model_dir=model_dir,\n        config=tf.estimator.RunConfig(session_config=config))\n\n    # Set up logging for predictions\n    # Log the values in the ""Softmax"" tensor with label ""probabilities""\n    tensors_to_log = {""probabilities"": ""softmax_tensor""}\n    logging_hook = tf.train.LoggingTensorHook(\n        tensors=tensors_to_log, every_n_iter=500)\n\n    # Horovod: BroadcastGlobalVariablesHook broadcasts initial variable states from\n    # rank 0 to all other processes. This is necessary to ensure consistent\n    # initialization of all workers when training is started with random weights or\n    # restored from a checkpoint.\n    bcast_hook = hvd.BroadcastGlobalVariablesHook(0)\n\n    # Train the model\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n        x={""x"": train_data},\n        y=train_labels,\n        batch_size=100,\n        num_epochs=None,\n        shuffle=True)\n\n    # Horovod: adjust number of steps based on number of GPUs.\n    mnist_classifier.train(\n        input_fn=train_input_fn,\n        steps=20000 // hvd.size(),\n        hooks=[logging_hook, bcast_hook])\n\n    # Evaluate the model and print results\n    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n        x={""x"": eval_data},\n        y=eval_labels,\n        num_epochs=1,\n        shuffle=False)\n    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n    print(eval_results)\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
examples/tensorflow_synthetic_benchmark.py,10,"b'import argparse\nimport os\nimport numpy as np\nimport timeit\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\nfrom tensorflow.keras import applications\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'TensorFlow Synthetic Benchmark\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-allreduce\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during allreduce\')\n\nparser.add_argument(\'--model\', type=str, default=\'ResNet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\n\nparser.add_argument(\'--eager\', action=\'store_true\', default=False,\n                    help=\'enables eager execution\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--use-adasum\', action=\'store_true\', default=False,\n                    help=\'use adasum algorithm to do reduction\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda\n\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nif args.cuda:\n    config.gpu_options.allow_growth = True\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\nelse:\n    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n    config.gpu_options.allow_growth = False\n    config.gpu_options.visible_device_list = \'\'\n\nif args.eager:\n    tf.enable_eager_execution(config)\n\n# Set up standard model.\nmodel = getattr(applications, args.model)(weights=None)\n\nlr_scaler = hvd.size()\n# By default, Adasum doesn\'t need scaling when increasing batch size. If used with NCCL,\n# scale lr by local_size\nif args.use_adasum:\n    lr_scaler = hvd.local_size() if args.cuda and hvd.nccl_built() else 1\n\nopt = tf.train.GradientDescentOptimizer(0.01 * lr_scaler)\n\n# Horovod: (optional) compression algorithm.\ncompression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n# Horovod: wrap optimizer with DistributedOptimizer.\nopt = hvd.DistributedOptimizer(opt, compression=compression, op=hvd.Adasum if args.use_adasum else hvd.Average)\n\ninit = tf.global_variables_initializer()\nbcast_op = hvd.broadcast_global_variables(0)\n\ndata = tf.random_uniform([args.batch_size, 224, 224, 3])\ntarget = tf.random_uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64)\n\n\ndef loss_function():\n    probs = model(data, training=True)\n    return tf.losses.sparse_softmax_cross_entropy(target, probs)\n\n\ndef log(s, nl=True):\n    if hvd.rank() != 0:\n        return\n    print(s, end=\'\\n\' if nl else \'\')\n\n\nlog(\'Model: %s\' % args.model)\nlog(\'Batch size: %d\' % args.batch_size)\ndevice = \'GPU\' if args.cuda else \'CPU\'\nlog(\'Number of %ss: %d\' % (device, hvd.size()))\n\n\ndef run(benchmark_step):\n    # Warm-up\n    log(\'Running warmup...\')\n    timeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n    # Benchmark\n    log(\'Running benchmark...\')\n    img_secs = []\n    for x in range(args.num_iters):\n        time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log(\'Iter #%d: %.1f img/sec per %s\' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n    # Results\n    img_sec_mean = np.mean(img_secs)\n    img_sec_conf = 1.96 * np.std(img_secs)\n    log(\'Img/sec per %s: %.1f +-%.1f\' % (device, img_sec_mean, img_sec_conf))\n    log(\'Total img/sec on %d %s(s): %.1f +-%.1f\' %\n        (hvd.size(), device, hvd.size() * img_sec_mean, hvd.size() * img_sec_conf))\n\n\nif tf.executing_eagerly():\n    with tf.device(device):\n        run(lambda: opt.minimize(loss_function, var_list=model.trainable_variables))\nelse:\n    with tf.Session(config=config) as session:\n        init.run()\n        bcast_op.run()\n\n        loss = loss_function()\n        train_opt = opt.minimize(loss)\n        run(lambda: session.run(train_opt))\n'"
examples/tensorflow_word2vec.py,21,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2017 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Basic word2vec example.""""""\n\nimport collections\nimport math\nimport os\nimport random\nimport urllib\nimport zipfile\n\nimport numpy as np\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n\n# Step 1: Download the data.\nurl = \'http://mattmahoney.net/dc/text8.zip\'\n\n\ndef maybe_download(filename, expected_bytes):\n    """"""Download a file if not present, and make sure it\'s the right size.""""""\n    if not os.path.exists(filename):\n        filename, _ = urllib.request.urlretrieve(url, filename)\n    statinfo = os.stat(filename)\n    if statinfo.st_size == expected_bytes:\n        print(\'Found and verified\', filename)\n    else:\n        print(statinfo.st_size)\n        raise Exception(\n            \'Failed to verify \' + url + \'. Can you get to it with a browser?\')\n    return filename\n\nfilename = maybe_download(\'text8-%d.zip\' % hvd.rank(), 31344016)\n\n\n# Read the data into a list of strings.\ndef read_data(filename):\n    """"""Extract the first file enclosed in a zip file as a list of words.""""""\n    with zipfile.ZipFile(filename) as f:\n        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n    return data\n\nvocabulary = read_data(filename)\nprint(\'Data size\', len(vocabulary))\n\n# Step 2: Build the dictionary and replace rare words with UNK token.\nvocabulary_size = 50000\n\n\ndef build_dataset(words, n_words):\n    """"""Process raw inputs into a dataset.""""""\n    count = [[\'UNK\', -1]]\n    count.extend(collections.Counter(words).most_common(n_words - 1))\n    dictionary = dict()\n    for word, _ in count:\n        dictionary[word] = len(dictionary)\n    data = list()\n    unk_count = 0\n    for word in words:\n        if word in dictionary:\n            index = dictionary[word]\n        else:\n            index = 0  # dictionary[\'UNK\']\n            unk_count += 1\n        data.append(index)\n    count[0][1] = unk_count\n    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    return data, count, dictionary, reversed_dictionary\n\ndata, count, dictionary, reverse_dictionary = build_dataset(vocabulary,\n                                                            vocabulary_size)\ndel vocabulary  # Hint to reduce memory.\nprint(\'Most common words (+UNK)\', count[:5])\nprint(\'Sample data\', data[:10], [reverse_dictionary[i] for i in data[:10]])\n\n\n# Step 3: Function to generate a training batch for the skip-gram model.\ndef generate_batch(batch_size, num_skips, skip_window):\n    assert num_skips <= 2 * skip_window\n    # Adjust batch_size to match num_skips\n    batch_size = batch_size // num_skips * num_skips\n    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n    # Backtrack a little bit to avoid skipping words in the end of a batch\n    data_index = random.randint(0, len(data) - span - 1)\n    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n    buffer = collections.deque(maxlen=span)\n    for _ in range(span):\n        buffer.append(data[data_index])\n        data_index = (data_index + 1) % len(data)\n    for i in range(batch_size // num_skips):\n        target = skip_window  # target label at the center of the buffer\n        targets_to_avoid = [skip_window]\n        for j in range(num_skips):\n            while target in targets_to_avoid:\n                target = random.randint(0, span - 1)\n            targets_to_avoid.append(target)\n            batch[i * num_skips + j] = buffer[skip_window]\n            labels[i * num_skips + j, 0] = buffer[target]\n        buffer.append(data[data_index])\n        data_index = (data_index + 1) % len(data)\n    return batch, labels\n\nbatch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\nfor i in range(8):\n    print(batch[i], reverse_dictionary[batch[i]],\n          \'->\', labels[i, 0], reverse_dictionary[labels[i, 0]])\n\n# Step 4: Build and train a skip-gram model.\n\nmax_batch_size = 128\nembedding_size = 128  # Dimension of the embedding vector.\nskip_window = 1       # How many words to consider left and right.\nnum_skips = 2         # How many times to reuse an input to generate a label.\n\n# We pick a random validation set to sample nearest neighbors. Here we limit the\n# validation samples to the words that have a low numeric ID, which by\n# construction are also the most frequent.\nvalid_size = 16     # Random set of words to evaluate similarity on.\nvalid_window = 100  # Only pick dev samples in the head of the distribution.\nvalid_examples = np.random.choice(valid_window, valid_size, replace=False)\nnum_sampled = 64    # Number of negative examples to sample.\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n\n    # Input data.\n    train_inputs = tf.placeholder(tf.int32, shape=[None])\n    train_labels = tf.placeholder(tf.int32, shape=[None, 1])\n    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n\n    # Look up embeddings for inputs.\n    embeddings = tf.Variable(\n        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n\n    # Construct the variables for the NCE loss\n    nce_weights = tf.Variable(\n        tf.truncated_normal([vocabulary_size, embedding_size],\n                            stddev=1.0 / math.sqrt(embedding_size)))\n    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n\n    # Compute the average NCE loss for the batch.\n    # tf.nce_loss automatically draws a new sample of the negative labels each\n    # time we evaluate the loss.\n    loss = tf.reduce_mean(\n        tf.nn.nce_loss(weights=nce_weights,\n                       biases=nce_biases,\n                       labels=train_labels,\n                       inputs=embed,\n                       num_sampled=num_sampled,\n                       num_classes=vocabulary_size))\n\n    # Horovod: adjust learning rate based on number of GPUs.\n    optimizer = tf.train.GradientDescentOptimizer(1.0 * hvd.size())\n\n    # Horovod: add Horovod Distributed Optimizer.\n    optimizer = hvd.DistributedOptimizer(optimizer)\n\n    train_op = optimizer.minimize(loss)\n\n    # Compute the cosine similarity between minibatch examples and all embeddings.\n    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n    normalized_embeddings = embeddings / norm\n    valid_embeddings = tf.nn.embedding_lookup(\n        normalized_embeddings, valid_dataset)\n    similarity = tf.matmul(\n        valid_embeddings, normalized_embeddings, transpose_b=True)\n\n    # Add variable initializer.\n    init = tf.global_variables_initializer()\n\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bcast = hvd.broadcast_global_variables(0)\n\n# Step 5: Begin training.\n\n# Horovod: adjust number of steps based on number of GPUs.\nnum_steps = 100000 // hvd.size() + 1\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\n\nwith tf.Session(graph=graph, config=config) as session:\n    # We must initialize all variables before we use them.\n    init.run()\n    bcast.run()\n    print(\'Initialized\')\n\n    average_loss = 0\n    for step in range(num_steps):\n        # simulate various sentence length by randomization\n        batch_size = random.randint(max_batch_size // 2, max_batch_size)\n        batch_inputs, batch_labels = generate_batch(\n            batch_size, num_skips, skip_window)\n        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n\n        # We perform one update step by evaluating the optimizer op (including it\n        # in the list of returned values for session.run()\n        _, loss_val = session.run([train_op, loss], feed_dict=feed_dict)\n        average_loss += loss_val\n\n        if step % 2000 == 0:\n            if step > 0:\n                average_loss /= 2000\n            # The average loss is an estimate of the loss over the last 2000 batches.\n            print(\'Average loss at step \', step, \': \', average_loss)\n            average_loss = 0\n    final_embeddings = normalized_embeddings.eval()\n\n    # Evaluate similarity in the end on worker 0.\n    if hvd.rank() == 0:\n        sim = similarity.eval()\n        for i in range(valid_size):\n            valid_word = reverse_dictionary[valid_examples[i]]\n            top_k = 8  # number of nearest neighbors\n            nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n            log_str = \'Nearest to %s:\' % valid_word\n            for k in range(top_k):\n                close_word = reverse_dictionary[nearest[k]]\n                log_str = \'%s %s,\' % (log_str, close_word)\n            print(log_str)\n'"
horovod/__init__.py,0,"b""__version__ = '0.19.2'\n"""
test/common.py,0,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2018 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport contextlib\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport time\n\nimport mock\n\nfrom horovod.run.util.threads import in_thread\n\n\ndef mpi_env_rank_and_size():\n    """"""Get MPI rank and size from environment variables and return them as a\n    tuple of integers.\n\n    Most MPI implementations have an `mpirun` or `mpiexec` command that will\n    run an MPI executable and set up all communication necessary between the\n    different processors. As part of that set up, they will set environment\n    variables that contain the rank and size of the MPI_COMM_WORLD\n    communicator. We can read those environment variables from Python in order\n    to ensure that `hvd.rank()` and `hvd.size()` return the expected values.\n\n    Since MPI is just a standard, not an implementation, implementations\n    typically choose their own environment variable names. This function tries\n    to support several different implementation, but really it only needs to\n    support whatever implementation we want to use for the TensorFlow test\n    suite.\n\n    If this is not running under MPI, then defaults of rank zero and size one\n    are returned. (This is appropriate because when you call MPI_Init in an\n    application not started with mpirun, it will create a new independent\n    communicator with only one process in it.)\n    """"""\n    rank_env = \'PMI_RANK OMPI_COMM_WORLD_RANK\'.split()\n    size_env = \'PMI_SIZE OMPI_COMM_WORLD_SIZE\'.split()\n\n    for rank_var, size_var in zip(rank_env, size_env):\n        rank = os.environ.get(rank_var)\n        size = os.environ.get(size_var)\n        if rank is not None and size is not None:\n            return int(rank), int(size)\n\n    # Default to rank zero and size one if there are no environment variables\n    return 0, 1\n\n\ndef delay(func, seconds):\n    """"""Delays the execution of func in a separate thread by given seconds.""""""\n    def fn():\n        time.sleep(seconds)\n        func()\n\n    t = in_thread(target=fn)\n\n\ndef wait(func, timeout=None):\n    """"""Wait for func to return True until timeout.""""""\n    start = int(time.time())\n    while not func():\n        time.sleep(0.1)\n        if timeout is not None and int(time.time()) - start > timeout:\n            raise TimeoutError(\'Timed out waiting for func to return True\')\n\n\n@contextlib.contextmanager\ndef tempdir():\n    dirpath = tempfile.mkdtemp()\n    try:\n        yield dirpath\n    finally:\n        shutil.rmtree(dirpath)\n\n\n@contextlib.contextmanager\ndef temppath():\n    path = tempfile.mktemp()\n    try:\n        yield path\n    finally:\n        if os.path.exists(path):\n            if os.path.isfile(path):\n                os.remove(path)\n            else:\n                shutil.rmtree(path)\n\n\n@contextlib.contextmanager\ndef override_args(tool=None, *args):\n    old = sys.argv[:]\n    try:\n        if tool:\n            sys.argv[0] = tool\n        sys.argv[1:] = args\n        yield\n    finally:\n        sys.argv = old\n\n\n@contextlib.contextmanager\ndef override_env(env):\n    old = os.environ\n    try:\n        os.environ = env\n        yield\n    finally:\n        os.environ = old\n\n\n@contextlib.contextmanager\ndef undo(fn):\n    try:\n        yield\n    finally:\n        fn()\n\n\n@contextlib.contextmanager\ndef is_built(gloo_is_built, mpi_is_built):\n    """"""\n    Patches the gloo_built and mpi_built methods called from horovod.run.run.run_controller\n    to return the given booleans. That method is used by horovod.spark.run to determine which\n    controller to use. Patching these methods allows to test horovod.spark.run without an MPI\n    implementation to be installed.\n\n    :param gloo_is_built: boolean returned by gloo_built\n    :param mpi_is_built: boolean returned by mpi_built\n    :return: mocked gloo_built and mpi_built methods\n    """"""\n    with mock.patch(""horovod.run.runner.gloo_built"", return_value=gloo_is_built) as g:\n        with mock.patch(""horovod.run.runner.mpi_built"", return_value=mpi_is_built) as m:\n            yield g, m\n\n\n@contextlib.contextmanager\ndef mpi_implementation_flags(flags=[""--mock-mpi-impl-flags""],\n                             binding_args=[""--mock-mpi-binding-args""]):\n    """"""\n    Patches the _get_mpi_implementation_flags method used by horovod.run.mpi_run to retrieve\n    MPI implementation specific command line flags. Patching this method allows to test mpi_run\n    without an MPI implementation to be installed.\n\n    :param flags: mock flags\n    :return: the mocked method\n    """"""\n    with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", return_value=(flags, binding_args)) as m:\n        yield m\n\n\n@contextlib.contextmanager\ndef lsf_and_jsrun(lsf_exists, jsrun_installed):\n    """"""\n    Patches the lsf.LSFUtils.using_lsf and is_jsrun_installed methods called from\n    horovod.run.run.run_controller to return the given booleans.\n    :param lsf_exists: boolean returned by lsf.LSFUtils.using_lsf\n    :param jsrun_installed: boolean returned by is_jsrun_installed\n    :return: mocked methods\n    """"""\n    with mock.patch(""horovod.run.runner.lsf.LSFUtils.using_lsf"", return_value=lsf_exists) as u:\n        with mock.patch(""horovod.run.runner.is_jsrun_installed"", return_value=jsrun_installed) as i:\n            yield u, i\n'"
test/spark_common.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport contextlib\nimport os\nimport platform\nimport stat\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import DenseVector, VectorUDT\nfrom pyspark.sql.types import FloatType, IntegerType, StructField, StructType\n\nfrom horovod.spark.common.store import LocalStore\n\nfrom common import tempdir, temppath\n\n# Spark will fail to initialize correctly locally on Mac OS without this\nif platform.system() == \'Darwin\':\n    os.environ[\'OBJC_DISABLE_INITIALIZE_FORK_SAFETY\'] = \'YES\'\n\n\nclass CallbackBackend(object):\n    def run(self, fn, args=(), kwargs={}, env={}):\n        return [fn(*args, **kwargs)] * self.num_processes()\n\n    def num_processes(self):\n        return 1\n\n\n@contextlib.contextmanager\ndef local_store():\n    with tempdir() as tmp:\n        store = LocalStore(tmp)\n        yield store\n\n\n@contextlib.contextmanager\ndef spark_session(app, cores=2, gpus=0, *args):\n    from pyspark import SparkConf\n    from pyspark.sql import SparkSession\n\n    master = \'local-cluster[{},1,1024]\'.format(cores) if gpus > 0 else \'local[{}]\'.format(cores)\n    conf = SparkConf().setAppName(app).setMaster(master)\n\n    with temppath() as temp_filename:\n        if gpus > 0:\n            with open(temp_filename, \'wb\') as temp_file:\n                addresses = \', \'.join(\'\\\\""{}\\\\""\'.format(i) for i in range(gpus))\n                temp_file.write(b\'echo {\\\\""name\\\\"": \\\\""gpu\\\\"", \\\\""addresses\\\\"": [\' +\n                                addresses.encode(\'ascii\') + b\']}\')\n\n            os.chmod(temp_file.name, stat.S_IRWXU | stat.S_IXGRP | stat.S_IRGRP |\n                     stat.S_IROTH | stat.S_IXOTH)\n\n            conf = conf.set(""spark.test.home"", os.environ.get(\'SPARK_HOME\'))\n            conf = conf.set(""spark.worker.resource.gpu.discoveryScript"", temp_filename)\n            conf = conf.set(""spark.worker.resource.gpu.amount"", 1)\n            conf = conf.set(""spark.task.resource.gpu.amount"", ""1"")\n            conf = conf.set(""spark.executor.resource.gpu.amount"", ""1"")\n\n        session = SparkSession \\\n            .builder \\\n            .config(conf=conf) \\\n            .getOrCreate()\n\n        try:\n            yield session\n        finally:\n            session.stop()\n\n\ndef create_xor_data(spark):\n    data = [[0, 0, 0.0, 0.1], [0, 1, 1.0, 0.2], [1, 0, 1.0, 0.3], [1, 1, 0.0, 0.4]]\n    schema = StructType([StructField(\'x1\', IntegerType()),\n                         StructField(\'x2\', IntegerType()),\n                         StructField(\'y\', FloatType()),\n                         StructField(\'weight\', FloatType())])\n    raw_df = create_test_data_from_schema(spark, data, schema)\n\n    vector_assembler = VectorAssembler().setInputCols([\'x1\', \'x2\']).setOutputCol(\'features\')\n    pipeline = Pipeline().setStages([vector_assembler])\n\n    df = pipeline.fit(raw_df).transform(raw_df)\n    return df\n\n\ndef create_mnist_data(spark):\n    features = DenseVector([1.0] * 64)\n    label_vec = DenseVector([0.0, 0.0, 1.0] + [0.0] * 7)\n    label = 2.0\n    data = [[features, label_vec, label]] * 10\n    schema = StructType([StructField(\'features\', VectorUDT()),\n                         StructField(\'label_vec\', VectorUDT()),\n                         StructField(\'label\', FloatType())])\n    df = create_test_data_from_schema(spark, data, schema)\n    return df\n\n\ndef create_test_data_from_schema(spark, data, schema):\n    return spark.createDataFrame(data, schema=schema)\n'"
test/test_adasum_pytorch.py,0,"b'# Copyright 2019 Microsoft. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport torch\nimport horovod.torch as hvd\nimport numpy as np\nimport time\nfrom horovod.torch.mpi_ops import synchronize\nimport os\nimport math\nimport unittest\nimport warnings\nfrom distutils.version import LooseVersion\n\n_fp16_supported = LooseVersion(torch.__version__) >= LooseVersion(\'1.0.0\')\n\nclass TorchAdasumTests(unittest.TestCase):\n  """"""\n  Tests for Adasum reduction logic in horovod.torch.\n  """"""\n  def __init__(self, *args, **kwargs):\n    super(TorchAdasumTests, self).__init__(*args, **kwargs)\n    warnings.simplefilter(\'module\')\n    self.data_types = [np.float32]\n    if _fp16_supported:\n      self.data_types.append(np.float16)\n\n  def diff_ratio(self, true_vec, comp_vec):\n    norm_diff = np.linalg.norm(true_vec-comp_vec)\n    norm_true = np.linalg.norm(true_vec)\n    return norm_diff/norm_true/100.\n\n  def are_close(self, data_type, true_vec, comp_vec):\n    return self.diff_ratio(true_vec, comp_vec) < np.finfo(data_type).eps\n\n  def test_orthogonal(self):\n    hvd.init()\n    # TODO support non-MPI Adasum operation\n    # Only do this test if there are GPUs available.\n    if not hvd.mpi_enabled() or not torch.cuda.is_available():\n      self.skipTest(""No GPUs available"")\n\n    device = torch.device(\'cuda:{}\'.format(hvd.local_rank()))\n    np.random.seed(2)\n    torch.manual_seed(2)\n    size = hvd.size()\n    local_size = hvd.local_size()\n    rank = hvd.rank()\n\n    for data_type in self.data_types:\n      denominator = local_size if hvd.nccl_built() else 1\n      all_Ns = [size*20 - 17, size*2+1, size+2, 2**19]\n      tensors = []\n      all_qs = []\n      for N in all_Ns:\n        a = np.random.normal(0, 1, (N,size)).astype(np.float64)\n        q, r = np.linalg.qr(a)\n        q = q.astype(data_type)\n        all_qs.append(q.astype(np.float64))\n        tensors.append(q[:,hvd.rank()])\n\n      tensors = list(map(lambda x: torch.from_numpy(x).to(device), tensors))\n\n      handles = [\n        hvd.allreduce_async(tensor, op=hvd.Adasum)\n        for tensor in tensors\n      ]\n\n      reduced_tensors = [synchronize(h) for h in handles]\n\n      expected = [np.sum(q,axis=1) / denominator for q in all_qs]\n      all_comp = [self.are_close(data_type, e, rt.cpu().numpy()) for e,rt in zip(expected,reduced_tensors)]\n      if np.alltrue(all_comp):\n        print(\'Orthogonal test passed\')\n      else:\n        for c,e,rt in zip(all_comp, expected, reduced_tensors):\n          if c == False:\n            print(\'computed: \', rt)\n            print(\'expected: \', e)\n            print(\'off by: \', self.diff_ratio(e,rt.cpu().numpy()))\n      assert np.alltrue(all_comp)\n\n  def test_parallel(self):\n    hvd.init()\n    # TODO support non-MPI Adasum operation\n    # Only do this test if there are GPUs available.\n    if not hvd.mpi_enabled() or not torch.cuda.is_available():\n      self.skipTest(""No GPUs available"")\n\n    device = torch.device(\'cuda:{}\'.format(hvd.local_rank()))\n    np.random.seed(2)\n    torch.manual_seed(2)\n    size = hvd.size()\n    local_size = hvd.local_size()\n    rank = hvd.rank()\n\n    for data_type in self.data_types:\n      all_Ns = [size*20 - 13, size*2+1, size+2, 2**19]\n      tensors = []\n      all_qs = []\n      for N in all_Ns:\n        a = np.random.normal(0, 1, (N, 1)).astype(np.float64)\n        r = np.random.normal(0, 1, (size, 1)).astype(np.float64)\n        q = np.dot(a,r.T)\n        q = q.astype(data_type)\n        all_qs.append(q.astype(np.float64))\n        tensors.append(q[:,hvd.rank()])\n\n      tensors = list(map(lambda x: torch.from_numpy(x).to(device), tensors))\n\n      handles = [\n        hvd.allreduce_async(tensor, op=hvd.Adasum)\n        for tensor in tensors\n      ]\n\n      reduced_tensors = [synchronize(h) for h in handles]\n\n      expected = [np.sum(q,axis=1) / size for q in all_qs]\n      all_comp = [self.are_close(data_type, e, rt.cpu().numpy()) for e,rt in zip(expected,reduced_tensors)]\n      if np.alltrue(all_comp):\n        print(\'Parallel test passed\')\n      else:\n        for c,e,rt in zip(all_comp, expected, reduced_tensors):\n          if c == False:\n            print(\'computed: \', rt)\n            print(\'expected: \', e)\n            print(\'off by: \', self.diff_ratio(e,rt.cpu().numpy()))\n      assert np.alltrue(all_comp)\n\n  def test_stability(self):\n    hvd.init()\n    # TODO support non-MPI Adasum operation\n    if not hvd.mpi_enabled():\n      self.skipTest(""MPI not enabled"")\n\n    device = torch.device(\'cuda:{}\'.format(hvd.local_rank())) if torch.cuda.is_available() else torch.device(\'cpu\')\n    np.random.seed(2)\n    torch.manual_seed(2)\n    size = hvd.size()\n    local_size = hvd.local_size()\n    rank = hvd.rank()\n\n    for data_type in self.data_types:\n      N = 1024\n      a = np.random.normal(0, np.finfo(data_type).tiny, (N, 1)).astype(np.float64)\n      r = np.random.normal(0, 1, (size, 1)).astype(np.float64)\n      q = np.dot(a,r.T).astype(data_type).astype(np.float64)\n      tensor = np.zeros(N,dtype=data_type)\n      tensor[:] = q[:,hvd.rank()]\n\n      tensor = torch.from_numpy(tensor).to(device)\n\n      hvd.allreduce_(tensor, op=hvd.Adasum)\n\n      expected = np.sum(q,axis=1) / size\n      comp = self.are_close(data_type, expected, tensor.cpu().numpy()) \n      if comp:\n        print(\'Stability test passed\')\n      else:\n        print(\'computed: \', tensor)\n        print(\'expected: \', expected)\n        print(\'off by: \', self.diff_ratio(expected,tensor.cpu().numpy()))\n      assert comp\n\n  def test_stability_2(self):\n    hvd.init()\n    # TODO support non-MPI Adasum operation\n    if not hvd.mpi_enabled():\n      self.skipTest(""MPI not enabled"")\n\n    device = torch.device(\'cuda:{}\'.format(hvd.local_rank())) if torch.cuda.is_available() else torch.device(\'cpu\')\n    np.random.seed(2)\n    torch.manual_seed(2)\n    size = hvd.size()\n    local_size = hvd.local_size()\n    rank = hvd.rank()\n\n    for data_type in self.data_types:\n      N = 1024\n      dt_min = np.finfo(data_type).tiny.astype(np.float64)\n      dt_max = math.sqrt(np.finfo(data_type).max.astype(np.float64))\n      a = np.random.normal(0, 1, (N, 1)).astype(np.float64)\n      r = np.array([dt_max**(float(i+1)/float(size))*dt_min**(float(size-i-1)/float(size)) for i in range(size)]).reshape(size,1).astype(np.float64)\n      np.random.shuffle(r)\n      q = np.dot(a,r.T).astype(data_type).astype(np.float64)\n      tensor = np.zeros(N,dtype=data_type)\n      tensor[:] = q[:,hvd.rank()]\n\n      tensor = torch.from_numpy(tensor).to(device)\n\n      hvd.allreduce_(tensor, op=hvd.Adasum)\n\n      expected = np.sum(q,axis=1) / size\n      comp = self.are_close(data_type, expected, tensor.cpu().numpy()) \n      if comp:\n        print(\'Stability 2 test passed\')\n      else:\n        print(\'computed: \', tensor)\n        print(\'expected: \', expected)\n        print(\'off by: \', self.diff_ratio(expected,tensor.cpu().numpy()))\n      assert comp\n\nif __name__ == ""__main__"":\n   unittest.main()\n'"
test/test_adasum_tensorflow.py,18,"b'# Copyright 2019 Microsoft. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom horovod.tensorflow.util import _executing_eagerly, _has_eager\nimport warnings\nimport horovod.tensorflow as hvd\nimport math\nimport copy\n\ndef adasum_reference_operation(a,b):\n    assert a.size == b.size\n    assert a.size > 0 and b.size > 0\n    assert a.dtype == b.dtype\n    # Adasum logic in numpy\n    anormsq = np.inner(a.ravel(), a.ravel())\n    bnormsq = np.inner(b.ravel(), b.ravel())\n    dotProduct = np.dot(a.ravel(), b.ravel())\n    acoeff = 1.0\n    bcoeff = 1.0\n    if anormsq != 0:\n        acoeff = 1.0 - dotProduct / anormsq * 0.5\n    if bnormsq != 0:\n        bcoeff = 1.0 - dotProduct / bnormsq * 0.5\n    answer = acoeff * a + bcoeff * b\n    return answer\n\ndef is_power2(num):\n    return num != 0 and ((num & (num -1)) == 0)\n\ndef reference_tree_reduction(tensors, hvd_size):\n    if hvd_size == 1:\n        return tensors[0]\n    temp = copy.copy(tensors)\n    power_of_2 = int(math.log(hvd_size, 2))\n    for level in range(power_of_2):\n        for i in range(int(hvd_size / pow(2, level + 1))):\n            answer = []\n            for a,b in zip(temp[i * 2], temp[i * 2 + 1]):\n                answer.append(adasum_reference_operation(a, b))\n            temp[i] = copy.copy(answer)\n    return temp[0]\n\nif hasattr(tf, \'ConfigProto\'):\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n\nif hasattr(tf, \'config\') and hasattr(tf.config, \'experimental\') \\\n        and hasattr(tf.config.experimental, \'set_memory_growth\'):\n    gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\nelse:\n    if _has_eager:\n        # Specifies the config to use with eager execution. Does not preclude\n        # tests from running in the graph mode.\n        tf.enable_eager_execution(config=config)\nclass MPITests(tf.test.TestCase):\n    """"""\n    Tests for ops in horovod.tensorflow.\n    """"""\n    def __init__(self, *args, **kwargs):\n        super(MPITests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n        if _has_eager:\n            if hasattr(tf, \'contrib\') and hasattr(tf.contrib, \'eager\'):\n                self.tfe = tf.contrib.eager\n            else:\n                self.tfe = tf\n\n    def evaluate(self, tensors):\n        if _executing_eagerly():\n            return self._eval_helper(tensors)\n        sess = ops.get_default_session()\n        if sess is None:\n            with self.test_session(config=config) as sess:\n                return sess.run(tensors)\n        else:\n            return sess.run(tensors)\n\n\n    def test_horovod_adasum_multiple_allreduce_cpu(self):\n        """"""Test on CPU that the Adasum correctly computes 2D tensors.""""""\n        hvd.init()\n        # TODO support non-MPI Adasum operation\n        if not hvd.mpi_enabled():\n            self.skipTest(""MPI not enabled"")\n\n        size = hvd.size()\n        # TODO support testing with non-power 2 ranks\n        if not is_power2(size):\n            self.skipTest(""MPI rank is not power of 2"")\n\n        rank = hvd.rank()\n        rank_tensors = []\n        for _ in range(size):\n            rank_tensors.append([np.random.random_sample((2,2)), np.random.random_sample((2,2))])\n        answer = reference_tree_reduction(rank_tensors, size)\n\n        for dtype in [tf.float16, tf.float32, tf.float64]:\n            with tf.device(""/cpu:0""):\n                tensors = map(tf.constant, rank_tensors[rank])\n                # cast to the corresponding dtype\n                tensors = map(lambda tensor: tf.cast(tensor, dtype), tensors)\n                # and away we go: do reduction\n                reduced_tensors = [\n                    self.evaluate(hvd.allreduce(tensor, op=hvd.Adasum))\n                    for tensor in tensors\n                ]\n                # cast expected result to the type of the tensorflow values\n                np_type = dtype.as_numpy_dtype\n                tmp = [t.astype(np_type) for t in answer]\n                self.assertAllCloseAccordingToType(tmp, reduced_tensors)\n\n    def test_horovod_adasum_multiple_allreduce_gpu_nccl(self):\n        """"""Test on GPU using NCCL that the Adasum correctly computes 2D tensors.""""""\n        hvd.init()\n        # TODO support non-MPI Adasum operation\n        if not hvd.mpi_enabled() or not hvd.gpu_available(\'tensorflow\') or not hvd.nccl_built():\n            self.skipTest(""MPI, GPU or NCCL not available"")\n\n        rank = hvd.rank()\n        rank_tensors = []\n        size = hvd.size()\n        # TODO support testing with non-power 2 ranks\n        if not is_power2(size):\n            self.skipTest(""MPI rank is not power of 2"")\n\n        local_size = hvd.local_size()\n\n        # Only run on homogeneous cluster\n        if not hvd.is_homogeneous():\n            self.skipTest(""Horovod cluster is not homogeneous"")\n\n        num_nodes = int(size / local_size)\n        for _ in range(size):\n            rank_tensors.append([np.random.random_sample((2,2)), np.random.random_sample((2,2))])\n        sum_local_ranks_tensor = []\n        for i in range(num_nodes):\n            sum_local_ranks_tensor.append([np.zeros((2,2)), np.zeros((2,2))])\n            for j in range(local_size):\n                sum_local_ranks_tensor[i] = np.add(sum_local_ranks_tensor[i], rank_tensors[j])\n\n        answer = reference_tree_reduction(sum_local_ranks_tensor, num_nodes)\n        answer = np.true_divide(answer, local_size)\n        for dtype in [tf.float16, tf.float32, tf.float64]:\n            with tf.device(""/gpu:{}"".format(hvd.local_rank())):\n                tensors = map(tf.constant, rank_tensors[rank])\n                # cast to the corresponding dtype\n                tensors = map(lambda tensor: tf.cast(tensor, dtype), tensors)\n                # and away we go: do reduction\n                reduced_tensors = [\n                    self.evaluate(hvd.allreduce(tensor, op=hvd.Adasum))\n                    for tensor in tensors\n                ]\n                # cast expected result to the type of the tensorflow values\n                np_type = dtype.as_numpy_dtype\n                tmp = [t.astype(np_type) for t in answer]\n                self.assertAllCloseAccordingToType(tmp, reduced_tensors)\n\nif __name__ == \'__main__\':\n    tf.test.main()\n'"
test/test_buildkite.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport unittest\nimport warnings\n\nfrom horovod.run.common.util import tiny_shell_exec\n\n\nclass BuildKiteTests(unittest.TestCase):\n    """"""\n    Tests for .buildkite directory\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(BuildKiteTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    """"""\n    Tests the generated buildkite pipeline.\n    \n    Compares output of .buildkite/gen_pipeline.sh with test/data/expected_buildkite_pipeline.yaml.\n    To see the changes in the output, run the following in your Horovod project root:\n    \n        BUILDKITE_PIPELINE_SLUG=SLUG BUILDKITE_BRANCH=BRANCH .buildkite/gen-pipeline.sh > test/data/expected_buildkite_pipeline.yaml\n    \n    Then run `git diff` to see the changes in the generated pipeline YAML.\n    Commit `test/data/expected_buildkite_pipeline.yaml` to get those changes into your PR.\n    """"""\n    def test_gen_pipeline(self):\n        with open(\'data/expected_buildkite_pipeline.yaml\', \'r\') as f:\n            lines = f.readlines()\n            expected_pipeline = \'\'.join(lines)\n\n        gen_pipeline_env = \'BUILDKITE_PIPELINE_SLUG=SLUG BUILDKITE_BRANCH=BRANCH\'\n        gen_pipeline_cmd = \'{env} ../.buildkite/gen-pipeline.sh\'.format(env=gen_pipeline_env)\n        actual_pipeline, exit_code = tiny_shell_exec.execute(gen_pipeline_cmd)\n\n        self.assertEqual(0, exit_code)\n        self.assertEqual(expected_pipeline, actual_pipeline)\n'"
test/test_common.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport unittest\nimport warnings\n\nfrom horovod.common.util import _cache, extension_available, gloo_built, mpi_built\n\n\nclass CommonTests(unittest.TestCase):\n    """"""\n    Tests for horovod.common.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(CommonTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_gloo_built(self):\n        """"""Test that Gloo has been built if env is set.""""""\n        gloo_rank = int(os.getenv(\'HOROVOD_RANK\', -1))\n        if gloo_rank >= 0:\n            self.assertTrue(gloo_built())\n\n    def test_mpi_built(self):\n        """"""Test that MPI has been built if env is set.""""""\n        gloo_rank = int(os.getenv(\'HOROVOD_RANK\', -1))\n        if gloo_rank == -1:\n            self.assertTrue(mpi_built())\n\n    def test_tensorflow_available(self):\n        """"""Test that TensorFLow support has been built.""""""\n        available = extension_available(\'tensorflow\')\n        try:\n            self.assertTrue(available)\n        except:\n            self.assertFalse(available)\n\n    def test_torch_available(self):\n        """"""Test that PyTorch support has been built.""""""\n        available = extension_available(\'torch\')\n        try:\n            self.assertTrue(available)\n        except:\n            self.assertFalse(available)\n\n    def test_mxnet_available(self):\n        """"""Test that MXNet support has been built.""""""\n        available = extension_available(\'mxnet\')\n        try:\n            self.assertTrue(available)\n        except:\n            self.assertFalse(available)\n\n    def test_cache(self):\n        """"""Test that caching of expensive functions only computes values once.""""""\n        state = {}\n\n        @_cache\n        def fn():\n            return state[\'key\']\n\n        # Not yet cached\n        state[\'key\'] = 1\n        value = fn()\n        assert value == 1\n\n        # Cached\n        state[\'key\'] = 2\n        value = fn()\n        assert value == 1\n'"
test/test_elastic_driver.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport time\nimport unittest\nimport warnings\n\nimport mock\nimport pytest\n\nfrom horovod.run.util import network\nfrom horovod.run.elastic.discovery import FixedHosts, HostManager\nfrom horovod.run.elastic.driver import ElasticDriver\nfrom horovod.run.elastic.rendezvous import create_rendezvous_handler\nfrom horovod.run.elastic.worker import WorkerNotificationManager\nfrom horovod.run.http.http_server import RendezvousServer\n\n\ndef wait_for_one(events):\n    while True:\n        for event in events:\n            if event.is_set():\n                return\n        time.sleep(0.01)\n\n\ndef sequence(lst):\n    for v in lst:\n        yield v\n    while True:\n        yield lst[-1]\n\n\nclass ElasticDriverTests(unittest.TestCase):\n    """"""\n    Tests for async processing logic in horovod.elastic.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(ElasticDriverTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_rank_and_size(self):\n        """"""Tests two hosts, two slots each in standard happy path.""""""\n        slots = {\'host-1\': 2, \'host-2\': 2}\n        discovery = FixedHosts(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n\n        rank_results = {}\n\n        def exec_command(slot_info, events):\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n            updated_slot_info = driver.get_slot_info(slot_info.hostname, slot_info.local_rank)\n            rank_results[slot_info.rank] = (slot_info, updated_slot_info)\n            return 0, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 4\n        for name, (exit_code, timestamp) in res.items():\n            assert exit_code == 0, name\n\n        assert len(rank_results) == 4\n        for rank, (slot_info, updated_slot_info) in rank_results.items():\n            assert slot_info.to_response_string() == updated_slot_info.to_response_string(), rank\n\n    def test_rank_and_size_with_host_failure(self):\n        """"""Tests two hosts, two slots each with second host failing before rendezvous completes.""""""\n        slots = {\'host-1\': 2, \'host-2\': 2}\n        discovery = FixedHosts(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n\n        rank_results = {}\n\n        def exec_command(slot_info, events):\n            if slot_info.hostname == \'host-2\':\n                return 1, time.time()\n\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n            updated_slot_info = driver.get_slot_info(slot_info.hostname, slot_info.local_rank)\n            rank_results[slot_info.rank] = (slot_info, updated_slot_info)\n            return 0, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 2\n        for name, (exit_code, timestamp) in res.items():\n            assert exit_code == 0, name\n\n        assert len(rank_results) == 2\n        for rank, (slot_info, updated_slot_info) in rank_results.items():\n            assert updated_slot_info.size == 2, rank\n            assert updated_slot_info.rank == slot_info.rank % 2, rank\n            assert updated_slot_info.local_size == slot_info.local_size, rank\n            assert updated_slot_info.local_rank == slot_info.local_rank, rank\n            assert updated_slot_info.cross_size == 1, rank\n            assert updated_slot_info.cross_rank == 0, rank\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    def test_rank_and_size_with_host_added(self):\n        """"""Tests training starts with one host two slots, then a second host is added.""""""\n        slots = {\'host-1\': 2}\n        discovery = FixedHosts(slots)\n\n        def add_host():\n            slots = {\'host-1\': 2, \'host-2\': 2}\n            discovery.set(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n\n        rank_results = {}\n\n        def exec_command(slot_info, events):\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n\n            if slot_info.hostname == \'host-1\':\n                if slot_info.rank == 0:\n                    add_host()\n                driver.wait_for_available_slots(4)\n                driver.record_ready(slot_info.hostname, slot_info.local_rank)\n\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n            updated_slot_info = driver.get_slot_info(slot_info.hostname, slot_info.local_rank)\n            rank_results[slot_info.rank] = (slot_info, updated_slot_info)\n            return 0, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 4\n        for name, (exit_code, timestamp) in res.items():\n            assert exit_code == 0, name\n\n        assert len(rank_results) == 4\n        for rank, (slot_info, updated_slot_info) in rank_results.items():\n            assert updated_slot_info.size == 4, rank\n            assert updated_slot_info.rank == slot_info.rank, rank\n            assert updated_slot_info.local_size == slot_info.local_size, rank\n            assert updated_slot_info.local_rank == slot_info.local_rank, rank\n            assert updated_slot_info.cross_size == 2, rank\n            assert updated_slot_info.cross_rank == slot_info.cross_rank, rank\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.elastic.driver.ElasticDriver.get_coordinator_info\')\n    @mock.patch(\'horovod.run.elastic.driver.ElasticDriver.get_worker_client\')\n    def test_wait_for_available_slots(self, mock_get_worker_client, mock_get_coordinator_info):\n        """"""Tests that driver blocks until the min number of slots are available.""""""\n        slots = [{\'host-1\': 4},\n                 {\'host-1\': 4, \'host-2\': 8},\n                 {\'host-1\': 4, \'host-2\': 8, \'host-3\': 4}]\n        mock_discovery = mock.Mock()\n        mock_discovery.find_available_hosts_and_slots.side_effect = sequence(slots)\n\n        driver = ElasticDriver(mock.Mock(), mock_discovery, min_np=8, max_np=20)\n        driver.wait_for_available_slots(min_np=16)\n        assert driver._host_manager.current_hosts.count_available_slots() >= 16\n        driver.stop()\n\n        # Notify coordinator 2 times, as the first time we are below min_np and the existing host assignments\n        # are empty\n        assert mock_get_worker_client.call_count == 2\n        assert mock_get_coordinator_info.call_count == 2\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    def test_wait_for_min_hosts(self):\n        """"""Tests that driver blocks until the min number of hosts and slots are available.""""""\n        slots = [{\'host-1\': 4},\n                 {\'host-1\': 4, \'host-2\': 8},\n                 {\'host-1\': 4, \'host-2\': 8, \'host-3\': 4}]\n        mock_discovery = mock.Mock()\n        mock_discovery.find_available_hosts_and_slots.side_effect = sequence(slots)\n\n        driver = ElasticDriver(mock.Mock(), mock_discovery, min_np=2, max_np=12)\n        driver.wait_for_available_slots(min_np=2, min_hosts=2)\n\n        # Even though we only needed 2 slots, because we also needed 2 hosts, we will at least 12 slots total\n        assert driver._host_manager.current_hosts.count_available_slots() >= 12\n        driver.stop()\n\n    def test_all_workers_fail(self):\n        """"""Tests that training fails when all workers fail.""""""\n        slots = {\'host-1\': 2, \'host-2\': 2}\n        discovery = FixedHosts(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n\n        def exec_command(slot_info, events):\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n            return 1, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 4\n        for name, (exit_code, timestamp) in res.items():\n            assert exit_code == 1, name\n\n    def test_shutdown_on_success(self):\n        """"""Tests that shutdown event is triggered when one worker succeeds but the others are still working.""""""\n        slots = {\'host-1\': 2, \'host-2\': 2}\n        discovery = FixedHosts(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n\n        def exec_command(slot_info, events):\n            if slot_info.rank == 0:\n                return 0, time.time()\n\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n            wait_for_one(events)\n            return 1, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 4\n\n        exit_code_sum = 0\n        for name, (exit_code, timestamp) in res.items():\n            exit_code_sum += exit_code\n        assert exit_code_sum == 3\n\n    def test_host_shutdown_on_worker_failure(self):\n        """"""Tests two hosts, two slots each with one process on second host failing, causing host shutdown.""""""\n        slots = {\'host-1\': 2, \'host-2\': 2}\n        discovery = FixedHosts(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n\n        rank_results = {}\n\n        def exec_command(slot_info, events):\n            if slot_info.hostname == \'host-1\':\n                if slot_info.local_rank == 0:\n                    return 1, time.time()\n\n                driver.record_ready(slot_info.hostname, slot_info.local_rank)\n                wait_for_one(events)\n                return 1, time.time()\n\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n            updated_slot_info = driver.get_slot_info(slot_info.hostname, slot_info.local_rank)\n            rank_results[slot_info.rank] = (slot_info, updated_slot_info)\n            return 0, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 2\n        for name, (exit_code, timestamp) in res.items():\n            assert exit_code == 0, name\n\n        assert len(rank_results) == 2\n        for rank, (slot_info, updated_slot_info) in rank_results.items():\n            assert updated_slot_info.size == 2, rank\n            assert updated_slot_info.rank == slot_info.rank % 2, rank\n            assert updated_slot_info.local_size == slot_info.local_size, rank\n            assert updated_slot_info.local_rank == slot_info.local_rank, rank\n            assert updated_slot_info.cross_size == 1, rank\n            assert updated_slot_info.cross_rank == 0, rank\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    def test_worker_notification_manager(self):\n        """"""Tests that host add events are sent to the worker notification service and consumed.""""""\n        slots = {\'host-1\': 2}\n        discovery = FixedHosts(slots)\n\n        rendezvous = RendezvousServer()\n        driver = ElasticDriver(rendezvous, discovery, min_np=2, max_np=4)\n        driver.wait_for_available_slots(min_np=2)\n        handler = create_rendezvous_handler(driver)\n\n        common_intfs = network.get_local_intfs()\n        addr = network.get_driver_ip(common_intfs)\n        port = rendezvous.start_server(handler)\n        nic = list(common_intfs)[0]\n\n        rank_results = {}\n\n        class NotificationReceiver:\n            def __init__(self):\n                self.events = []\n\n            def on_hosts_updated(self, timestamp):\n                self.events.append(timestamp)\n\n        def add_host():\n            slots = {\'host-1\': 2, \'host-2\': 2}\n            discovery.set(slots)\n\n        def remove_host():\n            slots = {\'host-2\': 2}\n            discovery.set(slots)\n\n        def exec_command(slot_info, events):\n            manager = WorkerNotificationManager()\n            manager.init(rendezvous_addr=addr,\n                         rendezvous_port=port,\n                         nic=nic,\n                         hostname=slot_info.hostname,\n                         local_rank=slot_info.local_rank)\n\n            notification_receiver = NotificationReceiver()\n            manager.register_listener(notification_receiver)\n\n            driver.record_ready(slot_info.hostname, slot_info.local_rank)\n\n            if slot_info.rank == 0:\n                add_host()\n            driver.wait_for_available_slots(4)\n\n            if slot_info.rank == 0:\n                remove_host()\n\n            # Busy wait for the number of available slots to decrease\n            while driver._host_manager.current_hosts.count_available_slots() > 2:\n                time.sleep(0.01)\n\n            rank_results[slot_info.rank] = notification_receiver.events\n            return 0, time.time()\n\n        driver.start(np=2, create_worker_fn=exec_command)\n        res = driver.get_results()\n        driver.stop()\n\n        assert len(res) == 2\n        for name, (exit_code, timestamp) in res.items():\n            assert exit_code == 0, name\n\n        assert len(rank_results) == 2\n        for rank, timestamps in rank_results.items():\n            expected = 2 if rank == 0 else 0\n            assert len(timestamps) == expected, rank\n\n        rendezvous.stop_server()\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.elastic.driver.ElasticDriver.host_assignments\')\n    @mock.patch(\'horovod.run.elastic.driver.ElasticDriver.get_coordinator_info\')\n    @mock.patch(\'horovod.run.elastic.driver.ElasticDriver.get_worker_client\')\n    def test_send_notifications_without_assignments(self, mock_get_worker_client, mock_get_coordinator_info,\n                                                    mock_host_assignments):\n        """"""Tests that notifications are still sent correctly even if host assignments cannot be generated.""""""\n        slots = [{\'host-1\': 8, \'host-2\': 4},\n                 {\'host-1\': 8, \'host-2\': 4},\n                 {\'host-2\': 4},\n                 {\'host-2\': 4},\n                 {\'host-2\': 4, \'host-3\': 12}]\n        discovery = mock.Mock()\n        discovery.find_available_hosts_and_slots.side_effect = sequence(slots)\n\n        driver = ElasticDriver(mock.Mock(), discovery, min_np=8, max_np=12)\n        driver.wait_for_available_slots(min_np=16)\n        driver.stop()\n\n        # On the second call, we should see the number of slots dip below the minimum, but we still want to ensure\n        # we notify workers every time there is a change, so in total we should observe 3 calls.\n        assert mock_get_worker_client.call_count == 3\n        assert mock_get_coordinator_info.call_count == 3\n\n    def test_order_available_hosts(self):\n        """"""Tests the order is preserved for host assignment as available hosts are updated.""""""\n        # This will be a set in practice, but use a list here to guarantee order.\n        available_hosts = [\'a\', \'b\', \'c\']\n        ordered_hosts = []\n        ordered_hosts = HostManager.order_available_hosts(available_hosts, ordered_hosts)\n        assert ordered_hosts == available_hosts\n\n        # We remove a host, add a host, and chance the order, but relative order should be preserved\n        available_hosts = [\'d\', \'c\', \'b\']\n        ordered_hosts = HostManager.order_available_hosts(available_hosts, ordered_hosts)\n        assert ordered_hosts == [\'b\', \'c\', \'d\']\n\n    def test_update_available_hosts(self):\n        """"""Tests that the current hosts object is immutable, while fetching the latest is correctly updated.""""""\n        mock_discovery = mock.Mock()\n        mock_discovery.find_available_hosts_and_slots.side_effect = [\n            {\'a\': 2},\n            {\'a\': 2, \'b\': 2},\n            {\'b\': 2}\n        ]\n        host_manager = HostManager(mock_discovery)\n\n        # Should be empty initially\n        current_hosts = host_manager.current_hosts\n        assert current_hosts.available_hosts == set()\n        assert current_hosts.count_available_slots() == 0\n\n        host_manager.update_available_hosts()\n\n        # First, check that nothing changed with our existing object, which is immutable\n        assert current_hosts.available_hosts == set()\n        assert current_hosts.count_available_slots() == 0\n\n        # Now verify that the new object has the correct sets\n        current_hosts = host_manager.current_hosts\n        assert current_hosts.available_hosts == {\'a\'}\n        assert current_hosts.count_available_slots() == 2\n\n        # Now check again\n        host_manager.update_available_hosts()\n        current_hosts = host_manager.current_hosts\n        assert current_hosts.available_hosts == {\'a\', \'b\'}\n        assert current_hosts.count_available_slots() == 4\n\n        # And again\n        host_manager.update_available_hosts()\n        current_hosts = host_manager.current_hosts\n        assert current_hosts.available_hosts == {\'b\'}\n        assert current_hosts.count_available_slots() == 2\n\n    def test_blacklist_host(self):\n        """"""Tests the hosts are blacklisted, resulting in changes to the available hosts.""""""\n        mock_discovery = mock.Mock()\n        mock_discovery.find_available_hosts_and_slots.return_value = {\'a\': 2, \'b\': 2}\n        host_manager = HostManager(mock_discovery)\n\n        host_manager.update_available_hosts()\n\n        # Sanity check before we blacklist\n        current_hosts = host_manager.current_hosts\n        assert current_hosts.available_hosts == {\'a\', \'b\'}\n        assert current_hosts.count_available_slots() == 4\n\n        # Now blacklist, our existing object should not change (immutable)\n        host_manager.blacklist(\'a\')\n        assert current_hosts.available_hosts == {\'a\', \'b\'}\n        assert current_hosts.count_available_slots() == 4\n\n        # Check the new object, make sure we\'ve blacklisted the host\n        current_hosts = host_manager.current_hosts\n        assert current_hosts.available_hosts == {\'b\'}\n        assert current_hosts.count_available_slots() == 2\n\n    def test_shutdown_on_initial_discovery_failure(self):\n        """"""Tests that the driver will shutdown immediately if initial host discovery fails.""""""\n        discovery = mock.Mock()\n        discovery.find_available_hosts_and_slots.side_effect = RuntimeError()\n\n        discover_hosts = ElasticDriver._discover_hosts\n\n        def wrapped_discover_hosts(obj):\n            try:\n                discover_hosts(obj)\n            except RuntimeError:\n                # Suppress the error message from the background discovery thread to clean up unit tests\n                pass\n\n        try:\n            ElasticDriver._discover_hosts = wrapped_discover_hosts\n            driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)\n            with pytest.raises(RuntimeError):\n                driver.wait_for_available_slots(min_np=2)\n            assert driver.finished()\n        finally:\n            ElasticDriver._discover_hosts = discover_hosts\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
test/test_interactiverun.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport unittest\nimport warnings\n\nimport pytest\nimport torch\n\nimport horovod.torch as hvd\n\nfrom horovod.common.util import gloo_built, mpi_built\nfrom horovod.run import run\n\n\nclass InteractiveRunTests(unittest.TestCase):\n\n    def __init__(self, *args, **kwargs):\n        super(InteractiveRunTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_happy_run(self):\n        def fn(a, b, c, d):\n            hvd.init()\n            rank = hvd.rank()\n            v = a + b + c + d\n            res = hvd.allgather(torch.tensor([rank, v])).tolist()\n            if rank == 0:\n                return res\n            elif rank == 1:\n                return ""ret_val_of_rank_1""\n            else:\n                return None\n\n        assert gloo_built() or mpi_built()\n        for use_gloo, use_mpi in [(True, False), (False, True)]:\n            if use_mpi and not mpi_built():\n                continue\n\n            if use_gloo and not gloo_built():\n                continue\n\n            res1 = run(fn, (1, 20), {""c"": 300, ""d"": 4000}, np=1, use_gloo=use_gloo, use_mpi=use_mpi)\n            self.assertListEqual([[0, 4321]], res1)\n            res2 = run(fn, (1, 20), {""c"": 300, ""d"": 4000}, np=3, use_gloo=use_gloo, use_mpi=use_mpi)\n            self.assertListEqual([[0, 4321, 1, 4321, 2, 4321],\n                                  ""ret_val_of_rank_1"",\n                                  None], res2)\n\n    def test_failed_run(self):\n        def fn():\n            hvd.init()\n            rank = hvd.rank()\n            if rank == 1:\n                raise RuntimeError()\n\n        assert gloo_built() or mpi_built()\n\n        if gloo_built():\n            with pytest.raises(RuntimeError, match=\'Horovod detected that one or more processes exited\'):\n                run(fn, np=2, use_gloo=True)\n\n        if mpi_built():\n            with pytest.raises(RuntimeError, match=\'mpirun failed\'):\n                run(fn, np=2, use_mpi=True)\n'"
test/test_keras.py,3,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Tests for horovod.keras.""""""\n\nfrom distutils.version import LooseVersion\n\nimport keras\nfrom keras import backend as K\n\nimport numpy as np\nimport pytest\nimport tensorflow as tf\nimport warnings\n\nimport horovod.keras as hvd\n\nfrom common import temppath\n\n\nclass KerasTests(tf.test.TestCase):\n    """"""\n    Tests for ops in horovod.keras.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(KerasTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n        hvd.init()\n\n        self.config = tf.ConfigProto()\n        self.config.gpu_options.allow_growth = True\n        self.config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    def test_sparse_as_dense(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt, sparse_as_dense=True)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Embedding(1000, 64, input_length=10))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt)\n\n            x = np.random.randint(1000, size=(32, 10))\n            y = np.random.random((32, 10, 64))\n            # No assertions, we just need to verify that it doesn\'t hang\n            model.train_on_batch(x, y)\n\n    def test_load_model(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n            model.train_on_batch(x, y)\n\n            with temppath() as fname:\n                model.save(fname)\n\n                new_model = hvd.load_model(fname)\n                new_opt = new_model.optimizer\n\n            self.assertEqual(type(new_opt).__module__, \'horovod._keras\')\n            self.assertEqual(type(new_opt).__name__, \'RMSprop\')\n            self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))\n            self._check_optimizer_weights(opt, new_opt)\n\n    def test_load_model_custom_optimizers(self):\n        class TestOptimizer(keras.optimizers.RMSprop):\n            def __init__(self, **kwargs):\n                super(TestOptimizer, self).__init__(**kwargs)\n\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = TestOptimizer(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n            model.train_on_batch(x, y)\n\n            with temppath() as fname:\n                model.save(fname)\n\n                custom_optimizers = [TestOptimizer]\n                new_model = hvd.load_model(fname, custom_optimizers=custom_optimizers)\n                new_opt = new_model.optimizer\n\n            self.assertEqual(type(new_opt).__module__, \'horovod._keras\')\n            self.assertEqual(type(new_opt).__name__, \'TestOptimizer\')\n            self._check_optimizer_weights(opt, new_opt)\n\n    def test_load_model_custom_objects(self):\n        class TestOptimizer(keras.optimizers.RMSprop):\n            def __init__(self, **kwargs):\n                super(TestOptimizer, self).__init__(**kwargs)\n\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = TestOptimizer(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n            model.train_on_batch(x, y)\n\n            with temppath() as fname:\n                model.save(fname)\n\n                custom_objects = {\n                    \'TestOptimizer\': lambda **kwargs: hvd.DistributedOptimizer(\n                        TestOptimizer(**kwargs))\n                }\n                new_model = hvd.load_model(fname, custom_objects=custom_objects)\n                new_opt = new_model.optimizer\n\n            self.assertEqual(type(new_opt).__module__, \'horovod._keras\')\n            self.assertEqual(type(new_opt).__name__, \'TestOptimizer\')\n            self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))\n            self._check_optimizer_weights(opt, new_opt)\n\n    def test_load_model_broadcast(self):\n        def create_model():\n            opt = keras.optimizers.SGD(lr=0.01 * hvd.size(), momentum=0.9)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            return model\n\n        with temppath() as fname:\n            with self.test_session(config=self.config) as sess:\n                K.set_session(sess)\n\n                model = create_model()\n\n                x = np.random.random((1, 3))\n                y = np.random.random((1, 3, 3))\n                model.train_on_batch(x, y)\n\n                if hvd.rank() == 0:\n                    model.save(fname)\n\n            K.clear_session()\n            with self.test_session(config=self.config) as sess:\n                K.set_session(sess)\n\n                if hvd.rank() == 0:\n                    model = hvd.load_model(fname)\n                else:\n                    model = create_model()\n\n                def generator():\n                    while 1:\n                        yield (x, y)\n\n                if hvd.rank() == 0:\n                    self.assertEqual(len(model.optimizer.weights), 5)\n                else:\n                    self.assertEqual(len(model.optimizer.weights), 0)\n\n                # No assertions, we just need to verify that it doesn\'t hang\n                callbacks = [hvd.callbacks.BroadcastGlobalVariablesCallback(0)]\n                model.fit_generator(generator(),\n                                    steps_per_epoch=10,\n                                    callbacks=callbacks,\n                                    epochs=0,\n                                    verbose=0,\n                                    workers=4,\n                                    initial_epoch=1)\n\n                self.assertEqual(len(model.optimizer.weights), 5)\n\n    def _check_optimizer_weights(self, opt, new_opt):\n        self.assertEqual(len(opt.get_weights()), len(new_opt.get_weights()))\n        for weights, new_weights in zip(opt.get_weights(),\n                                        new_opt.get_weights()):\n            if np.isscalar(weights):\n                self.assertEqual(weights, new_weights)\n            else:\n                self.assertListEqual(weights.tolist(), new_weights.tolist())\n\n    def test_from_config(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.Adam()\n            hopt = hvd.DistributedOptimizer(opt)\n            cfg = hopt.get_config()\n\n            hopt_copy1 = hopt.from_config(cfg)\n            self.assertEqual(cfg, hopt_copy1.get_config())\n\n            hopt_copy2 = hopt.__class__.from_config(cfg)\n            self.assertEqual(cfg, hopt_copy2.get_config())\n\n    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion(\'1.15.0\'),\n                        reason=\'Synchronizing state requires TensorFlow 1.15 or above\')\n    def test_elastic_state(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            v = 1.0 if hvd.rank() == 0 else 2.0\n            model1 = keras.models.Sequential([\n                keras.layers.Dense(2, activation=\'softmax\')\n            ])\n            model1.build((2, 2))\n            model1.set_weights(\n                [np.array([[v,  v], [v, v]], dtype=np.float32),\n                 np.array([v, v], dtype=np.float32)])\n\n            model2 = keras.models.Sequential([\n                keras.layers.Dense(2, activation=\'softmax\')\n            ])\n            model2.build((2, 2))\n            model2.set_weights(\n                [np.array([[1.0,  2.0], [3.0, 4.0]], dtype=np.float32),\n                 np.array([0.0, 0.0], dtype=np.float32)])\n\n            optimizer = keras.optimizers.Adam(0.001 * hvd.size())\n\n            state = hvd.elastic.KerasState(model1, optimizer, batch=20 + hvd.rank(), epoch=10 + hvd.rank())\n            state.sync()\n\n            model1_weights = model1.get_weights()\n            model2_weights = model2.get_weights()\n\n            # After sync, all values should match the root rank\n            for w in state.model.get_weights():\n                self.assertAllClose(w, np.ones_like(w))\n            assert state.batch == 20\n            assert state.epoch == 10\n\n            # Partially modify then restore\n            model1.set_weights(model2_weights)\n            state.batch = 21\n            state.epoch = 11\n\n            state.restore()\n\n            for w1, w2 in zip(model1.get_weights(), model1_weights):\n                self.assertAllClose(w1, w2)\n            assert state.batch == 20\n            assert state.epoch == 10\n\n            # Partially modify then commit\n            model1.set_weights(model2_weights)\n            state.batch = 21\n            state.epoch = 11\n\n            state.commit()\n            state.restore()\n\n            for w1, w2 in zip(model1.get_weights(), model2_weights):\n                self.assertAllClose(w1, w2)\n            assert state.batch == 21\n            assert state.epoch == 11\n'"
test/test_mxnet.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport itertools\nimport unittest\nimport numpy as np\nimport mxnet as mx\n\nfrom mxnet.base import MXNetError\nfrom mxnet.test_utils import same\n\nimport horovod.mxnet as hvd\n\nhas_gpu = mx.context.num_gpus() > 0\n\nccl_supported_types = set([\'int32\', \'int64\', \'float32\', \'float64\'])\n\n\nclass MXTests(unittest.TestCase):\n    """"""\n    Tests for ops in horovod.mxnet.\n    """"""\n\n    def _current_context(self):\n        if has_gpu:\n            return mx.gpu(hvd.local_rank())\n        else:\n            return mx.current_context()\n\n    def filter_supported_types(self, types):\n        if \'CCL_ROOT\' in os.environ:\n           types = [t for t in types if t in ccl_supported_types]\n        return types\n\n    def test_horovod_allreduce(self):\n        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([\'int32\',   \'int64\',\n                                              \'float32\', \'float64\'])\n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        for dtype, dim in itertools.product(dtypes, dims):\n            # MXNet uses gpu_id as part of the seed, so to get identical seeds\n            # we must set a context.\n            mx.random.seed(1234, ctx=ctx)\n            tensor = mx.nd.random.uniform(-100, 100, shape=shapes[dim],\n                                          ctx=ctx)\n            tensor = tensor.astype(dtype)\n            summed = hvd.allreduce(tensor, average=False, name=str(count))\n            multiplied = tensor * size\n            max_difference = mx.nd.max(mx.nd.subtract(summed, multiplied))\n            count += 1\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [\'int32\', \'int64\']:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            if max_difference > threshold:\n                print(""allreduce"", count, dtype, dim, max_difference,\n                      threshold)\n                print(""tensor"", hvd.rank(), tensor)\n                print(""summed"", hvd.rank(), summed)\n                print(""multiplied"", hvd.rank(), multiplied)\n            assert max_difference <= threshold, \'hvd.allreduce produces \\\n                                                 incorrect results\'\n\n    def test_horovod_allreduce_average(self):\n        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([\'int32\',   \'int64\',\n                                              \'float32\', \'float64\'])\n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        for dtype, dim in itertools.product(dtypes, dims):\n            mx.random.seed(1234, ctx=ctx)\n            tensor = mx.nd.random.uniform(-100, 100, shape=shapes[dim],\n                                          ctx=ctx)\n            tensor = tensor.astype(dtype)\n            averaged = hvd.allreduce(tensor, average=True, name=str(count))\n            tensor *= size\n            tensor /= size\n            max_difference = mx.nd.max(mx.nd.subtract(averaged, tensor))\n            count += 1\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [\'int32\', \'int64\']:\n                threshold = 1\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            if max_difference > threshold:\n                print(""average"", count, dtype, dim, max_difference, threshold)\n                print(""tensor"", hvd.rank(), tensor)\n                print(""averaged"", hvd.rank(), averaged)\n            assert max_difference <= threshold, \'hvd.allreduce produces \\\n                                                 incorrect results for average\'\n\n    def test_horovod_allreduce_inplace(self):\n        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([\'int32\',   \'int64\',\n                                              \'float32\', \'float64\'])\n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        for dtype, dim in itertools.product(dtypes, dims):\n            mx.random.seed(1234, ctx=ctx)\n            tensor = mx.nd.random.uniform(-100, 100, shape=shapes[dim],\n                                          ctx=ctx)\n            tensor = tensor.astype(dtype)\n            multiplied = tensor * size\n            hvd.allreduce_(tensor, average=False, name=str(count))\n            max_difference = mx.nd.max(mx.nd.subtract(tensor, multiplied))\n            count += 1\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [\'int32\', \'int64\']:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            if max_difference > threshold:\n                print(""self"", count, dtype, dim, max_difference, threshold)\n                print(""tensor"", hvd.rank(), tensor)\n                print(""multiplied"", hvd.rank(), multiplied)\n            assert max_difference <= threshold, \'hvd.allreduce produces \\\n                                                 incorrect results for self\'\n\n    def test_horovod_allreduce_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n           send tensors of different rank or dimension.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Same rank, different dimension\n        ctx = self._current_context()\n\n        shape = (17 + rank, 3)\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n        try:\n            output = hvd.allreduce(tensor)\n            output.wait_to_read()\n            assert False, \'hvd.allreduce did not throw error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n        # Same number of elements, different rank\n        if rank == 0:\n            shape = (17, 23 * 57)\n        else:\n            shape = (17, 23, 57)\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n        try:\n            output = hvd.allreduce(tensor)\n            output.wait_to_read()\n            assert False, \'hvd.allreduce did not throw error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n    def test_horovod_allreduce_type_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n           send tensors of different type.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        ctx = self._current_context()\n        shape = (17, 3)\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n        if rank % 2 == 0:\n            tensor = tensor.astype(\'int32\')\n        else:\n            tensor = tensor.astype(\'float32\')\n\n        try:\n            output = hvd.allreduce(tensor)\n            output.wait_to_read()\n            assert False, \'hvd.allreduce did not throw error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n    @unittest.skipUnless(has_gpu, ""no gpu detected"")\n    def test_horovod_allreduce_cpu_gpu_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n           perform reduction on CPU and GPU.""""""\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        shape = (17, 17, 17)\n        if rank % 2 == 0:\n            ctx = mx.gpu(hvd.rank())\n        else:\n            ctx = mx.cpu(hvd.rank())\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n\n        try:\n            output = hvd.allreduce(tensor)\n            output.wait_to_read()\n            assert False, \'hvd.allreduce did not throw cpu-gpu error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n\n    def test_horovod_allreduce_ndarray_lifetime(self):\n        """"""Test that the input NDArray remains valid during async allreduce""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        for i, dim in enumerate(dims):\n            tensor = mx.nd.ones(shape=shapes[dim], ctx=ctx)\n            # tensor*(i+1) result will be destroyed immediately after this call\n            # See https://github.com/horovod/horovod/issues/1533\n            sum = hvd.allreduce(tensor * (i + 1), average=False)\n            expected = tensor * (i + 1) * size\n            assert same(sum.asnumpy(), expected.asnumpy())\n\n    def test_horovod_broadcast(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [\'int32\',   \'int64\',\n                  \'float32\', \'float64\'] \n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims,\n                                                       root_ranks):\n            tensor = mx.nd.ones(shapes[dim], ctx=ctx) * rank\n            root_tensor = mx.nd.ones(shapes[dim], ctx=ctx) * root_rank\n            tensor = tensor.astype(dtype)\n            root_tensor = root_tensor.astype(dtype)\n\n            broadcast_tensor = hvd.broadcast(tensor, root_rank=root_rank,\n                                             name=str(count))\n            if rank != root_rank:\n                if same(tensor.asnumpy(), root_tensor.asnumpy()):\n                    print(""broadcast"", count, dtype, dim,\n                          mx.nd.max(tensor == root_tensor))\n                    print(""tensor"", hvd.rank(), tensor)\n                    print(""root_tensor"", hvd.rank(), root_tensor)\n                    print(""comparison"", hvd.rank(), tensor == root_tensor)\n                assert not same(tensor.asnumpy(), root_tensor.asnumpy()), \\\n                    \'hvd.broadcast modifies source tensor\'\n            if not same(broadcast_tensor.asnumpy(), root_tensor.asnumpy()):\n                print(""broadcast"", count, dtype, dim)\n                print(""broadcast_tensor"", hvd.rank(), broadcast_tensor)\n                print(""root_tensor"", hvd.rank(), root_tensor)\n                print(""comparison"", hvd.rank(),\n                      broadcast_tensor == root_tensor)\n            assert same(broadcast_tensor.asnumpy(), root_tensor.asnumpy()), \\\n                \'hvd.broadcast produces incorrect broadcasted tensor\'\n\n    def test_horovod_broadcast_inplace(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [\'int32\',   \'int64\',\n                  \'float32\', \'float64\'] \n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims,\n                                                       root_ranks):\n            tensor = mx.nd.ones(shapes[dim], ctx=ctx) * rank\n            root_tensor = mx.nd.ones(shapes[dim], ctx=ctx) * root_rank\n            tensor = tensor.astype(dtype)\n            root_tensor = root_tensor.astype(dtype)\n\n            # Only do broadcasting using broadcast_tensor\n            broadcast_tensor = tensor.copy()\n            hvd.broadcast_(broadcast_tensor, root_rank=root_rank,\n                           name=str(count))\n            if rank != root_rank:\n                if same(tensor.asnumpy(), root_tensor.asnumpy()):\n                    print(""broadcast"", count, dtype, dim,\n                          mx.nd.max(tensor == root_tensor))\n                    print(""tensor"", hvd.rank(), tensor)\n                    print(""root_tensor"", hvd.rank(), root_tensor)\n                    print(""comparison"", hvd.rank(), tensor == root_tensor)\n                assert not same(tensor.asnumpy(), root_tensor.asnumpy()), \\\n                    \'hvd.broadcast modifies source tensor\'\n            if not same(broadcast_tensor.asnumpy(), root_tensor.asnumpy()):\n                print(""broadcast"", count, dtype, dim)\n                print(""broadcast_tensor"", hvd.rank(), broadcast_tensor)\n                print(""root_tensor"", hvd.rank(), root_tensor)\n                print(""comparison"", hvd.rank(),\n                      broadcast_tensor == root_tensor)\n            assert same(broadcast_tensor.asnumpy(), root_tensor.asnumpy()), \\\n                \'hvd.broadcast produces incorrect broadcasted tensor\'\n\n    def test_horovod_broadcast_grad(self):\n        """"""Test the correctness of the broadcast gradient.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [\'int32\',   \'int64\',\n                  \'float32\', \'float64\'] \n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 0\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        root_rank = 1\n        tensor_dict = {}\n        root_dict = {}\n        for dtype, dim, in itertools.product(dtypes, dims):\n            tensor_dict[count] = mx.nd.ones(shapes[dim], ctx=ctx) * rank\n            root_dict[count] = mx.nd.ones(shapes[dim], ctx=ctx) * root_rank\n            tensor_dict[count] = tensor_dict[count].astype(dtype)\n            root_dict[count] = root_dict[count].astype(dtype)\n\n            # Only do broadcasting using and on broadcast_tensor\n            count += 1\n\n        hvd.broadcast_parameters(tensor_dict, root_rank=root_rank)\n        for i in range(count):\n            if not same(tensor_dict[i].asnumpy(), root_dict[i].asnumpy()):\n                print(""broadcast"", count, dtype, dim)\n                print(""broadcast_tensor"", hvd.rank(), tensor_dict[i])\n                print(""root_tensor"", hvd.rank(), root_dict[i])\n                print(""comparison"", hvd.rank(), tensor_dict[i] == root_dict[i])\n            assert same(tensor_dict[i].asnumpy(), root_dict[i].asnumpy()), \\\n                \'hvd.broadcast produces incorrect broadcasted tensor\'\n\n    def test_horovod_broadcast_error(self):\n        """"""Test that the broadcast returns an error if any dimension besides\n           the first is different among the tensors being broadcasted.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        ctx = self._current_context()\n        shape = (17, rank+1)\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n\n        try:\n            output = hvd.broadcast(tensor, 0)\n            output.wait_to_read()\n            assert False, \'hvd.broadcast did not throw error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n    def test_horovod_broadcast_type_error(self):\n        """"""Test that the broadcast returns an error if the types being broadcasted\n           differ among the processes""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        ctx = self._current_context()\n        shape = (17, 3)\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n        if rank % 2 == 0:\n            tensor = tensor.astype(\'int32\')\n        else:\n            tensor = tensor.astype(\'float32\')\n\n        try:\n            output = hvd.broadcast(tensor, 0)\n            output.wait_to_read()\n            assert False, \'hvd.broadcast did not throw error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n    def test_horovod_broadcast_rank_error(self):\n        """"""Test that the broadcast returns an error if different ranks\n           specify different root rank.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        ctx = self._current_context()\n        shape = (17, 17, 17)\n        tensor = mx.nd.ones(shape=shape, ctx=ctx)\n        try:\n            output = hvd.broadcast(tensor, root_rank=rank)\n            output.wait_to_read()\n            assert False, \'hvd.broadcast did not throw rank error\'\n        except (MXNetError, RuntimeError):\n            pass\n\n    def test_horovod_broadcast_deferred_init_parameters(self):\n        """"""Test that the deferred initialized parameters are broadcasted.""""""\n        hvd.init()\n        root_rank = 0\n        rank = hvd.rank()\n\n        # This test does not apply if there is only one worker.\n        if hvd.size() == 1:\n            self.skipTest(""Only one worker available"")\n\n        mx.random.seed(rank)\n        layer = mx.gluon.nn.Conv2D(10, 2)\n        layer.initialize()\n        hvd.broadcast_parameters(layer.collect_params(), root_rank=root_rank)\n\n        x = mx.nd.ones((5, 4, 10, 10))\n        layer(x)\n        tensors = [p.data() for _, p in sorted(layer.collect_params().items())]\n        root_tensors = []\n        for tensor in tensors:\n            root_tensors.append(hvd.broadcast(tensor, root_rank=root_rank))\n\n        for tensor, root_tensor in zip(tensors, root_tensors):\n            assert same(tensor.asnumpy(), root_tensor.asnumpy()), \\\n                \'horovod did not broadcast deferred initialized parameter correctly\'\n\n    @unittest.skipUnless(has_gpu, ""no gpu detected"")\n    def test_gluon_trainer(self):\n        """"""Test using horovod allreduce in MXNet Gluon trainer.""""""\n        from mxnet import gluon\n        from mxnet.gluon import Block, nn, HybridBlock\n\n        hvd.init()\n        rank = hvd.rank()\n        np.random.seed(1000 + 10 * rank)\n        mx.random.seed(1000 + 10 * rank)\n        ctx = mx.gpu(rank)\n\n        def gen_random_dataset(batch_size=64, dim=32, min_len=20, max_len=100,\n                               size=1000):\n            for _ in range(size):\n                length = np.random.randint(min_len, max_len + 1)\n                rand_src = mx.nd.random.normal(0, 1, (length, dim))\n                rand_dst = mx.nd.random.normal(0, 1, (length, dim))\n                yield rand_src, rand_dst\n\n        class SimpleNet(HybridBlock):\n            def __init__(self, layer_num=6, **kwargs):\n                super(SimpleNet, self).__init__(**kwargs)\n                self._layer_num = layer_num\n                with self.name_scope():\n                    self.ln_l = nn.HybridSequential()\n                    self.dense_l = nn.HybridSequential()\n                    for i in range(layer_num):\n                        self.dense_l.add(nn.Dense(units=32 + layer_num - 1 - i,\n                            flatten=False))\n                        self.ln_l.add(nn.LayerNorm())\n\n            def hybrid_forward(self, F, data):\n                """"""\n\n                Parameters\n                ----------\n                data :\n                    Shape (batch_size, seq_len, fea_dim)\n\n                Returns\n                -------\n                out :\n                    Shape (batch_size, seq_len, fea_dim)\n                """"""\n                for i in range(self._layer_num):\n                   data = self.ln_l[i](data)\n                   data = self.dense_l[i](data)\n                return data\n\n        net = SimpleNet()\n        net.initialize(ctx=ctx)\n        net.hybridize(static_alloc=True)\n\n        params = net.collect_params()\n        cnt = 0\n        lr = 1E-4\n        trainer = gluon.Trainer(params, \'adam\', {\'learning_rate\': lr},\n            update_on_kvstore=False)\n\n        data_gen = gen_random_dataset()\n        for (src_data, dst_data) in data_gen:\n            src_data = src_data.as_in_context(ctx).astype(np.float32)\n            dst_data = dst_data.as_in_context(ctx).astype(np.float32)\n            with mx.autograd.record():\n                pred = net(src_data)\n                loss = mx.nd.abs(pred - dst_data).mean()\n                loss.backward()\n            # Begin to update the parameter\n            trainer.step(1.0)\n            cnt += 1\n            l = loss.asscalar()\n            if cnt >= 10:\n                for key, param in params.items():\n                    hvd.allreduce_(param.list_data()[0])\n                cnt = 0\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
test/test_run.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport copy\nimport io\nimport itertools\nimport os\nimport subprocess\nimport sys\nimport threading\nimport time\nimport unittest\nimport warnings\n\nimport psutil\nimport pytest\nimport mock\n\nfrom mock import MagicMock\n\nimport horovod\nfrom horovod.run.common.util import codec, config_parser, safe_shell_exec, secret, \\\n    settings as hvd_settings, timeout\nfrom horovod.run.common.util.host_hash import _hash, host_hash\nfrom horovod.run.js_run import js_run, generate_jsrun_rankfile\nfrom horovod.run.mpi_run import _get_mpi_implementation, _get_mpi_implementation_flags,\\\n    _LARGE_CLUSTER_THRESHOLD as large_cluster_threshold, mpi_available, mpi_run,\\\n    _OMPI_IMPL, _SMPI_IMPL, _MPICH_IMPL, _UNKNOWN_IMPL, _MISSING_IMPL\nfrom horovod.run.runner import parse_args, parse_host_files, run_controller, HorovodArgs, _run\nfrom horovod.run.util.threads import in_thread, on_event\n\nfrom common import is_built, lsf_and_jsrun, override_args, override_env, temppath, delay, wait\n\n\nclass RunTests(unittest.TestCase):\n    """"""\n    Tests for horovod.run.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(RunTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_params_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--fusion-threshold-mb\', \'10\',\n                           \'--cycle-time-ms\', \'20\',\n                           \'--cache-capacity\', \'512\',\n                           \'--hierarchical-allreduce\',\n                           \'--hierarchical-allgather\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertEqual(env.get(config_parser.HOROVOD_FUSION_THRESHOLD), str(10 * 1024 * 1024))\n            self.assertEqual(env.get(config_parser.HOROVOD_CYCLE_TIME), \'20.0\')\n            self.assertEqual(env.get(config_parser.HOROVOD_CACHE_CAPACITY), \'512\')\n            self.assertEqual(env.get(config_parser.HOROVOD_HIERARCHICAL_ALLREDUCE), \'1\')\n            self.assertEqual(env.get(config_parser.HOROVOD_HIERARCHICAL_ALLGATHER), \'1\')\n\n    def test_autotune_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--autotune\',\n                           \'--autotune-log-file\', \'/tmp/autotune.txt\',\n                           \'--autotune-warmup-samples\', \'1\',\n                           \'--autotune-steps-per-sample\', \'5\',\n                           \'--autotune-bayes-opt-max-samples\', \'10\',\n                           \'--autotune-gaussian-process-noise\', \'0.2\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE), \'1\')\n            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_LOG), \'/tmp/autotune.txt\')\n            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_WARMUP_SAMPLES), \'1\')\n            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_STEPS_PER_SAMPLE), \'5\')\n            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_BAYES_OPT_MAX_SAMPLES), \'10\')\n            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_GAUSSIAN_PROCESS_NOISE), \'0.2\')\n\n    def test_autotuning_with_fixed_param(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--autotune\',\n                           \'--cache-capacity\', \'1024\',\n                           \'--no-hierarchical-allgather\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertNotIn(config_parser.HOROVOD_FUSION_THRESHOLD, env)\n            self.assertNotIn(config_parser.HOROVOD_CYCLE_TIME, env)\n            self.assertEqual(env.get(config_parser.HOROVOD_CACHE_CAPACITY), \'1024\')\n            self.assertNotIn(config_parser.HOROVOD_HIERARCHICAL_ALLREDUCE, env)\n            self.assertEqual(env.get(config_parser.HOROVOD_HIERARCHICAL_ALLGATHER), \'0\')\n\n    def test_timeline_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--timeline-filename\', \'/tmp/timeline.json\',\n                           \'--timeline-mark-cycles\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertEqual(env.get(config_parser.HOROVOD_TIMELINE), \'/tmp/timeline.json\')\n            self.assertEqual(env.get(config_parser.HOROVOD_TIMELINE_MARK_CYCLES), \'1\')\n\n    def test_stall_check_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--no-stall-check\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertEqual(env.get(config_parser.HOROVOD_STALL_CHECK_DISABLE), \'1\')\n\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--stall-check-warning-time-seconds\', \'10\',\n                           \'--stall-check-shutdown-time-seconds\', \'20\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertNotIn(config_parser.HOROVOD_STALL_CHECK_DISABLE, env)\n            self.assertEqual(env.get(config_parser.HOROVOD_STALL_CHECK_TIME_SECONDS), \'10\')\n            self.assertEqual(env.get(config_parser.HOROVOD_STALL_SHUTDOWN_TIME_SECONDS), \'20\')\n\n    def test_library_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--mpi-threads-disable\',\n                           \'--num-nccl-streams\', \'2\',\n                           \'--ccl-bgt-affinity\', \'1\',\n                           \'--gloo-timeout-seconds\', \'60\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertEqual(env.get(config_parser.HOROVOD_MPI_THREADS_DISABLE), \'1\')\n            self.assertEqual(env.get(config_parser.HOROVOD_NUM_NCCL_STREAMS), \'2\')\n            self.assertEqual(env.get(config_parser.HOROVOD_CCL_BGT_AFFINITY), \'1\')\n            self.assertEqual(env.get(config_parser.HOROVOD_GLOO_TIMEOUT_SECONDS), \'60\')\n\n    def test_logging_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--log-level\', \'INFO\',\n                           \'--log-hide-timestamp\'):\n            args = parse_args()\n            env = {}\n            config_parser.set_env_from_args(env, args)\n\n            self.assertEqual(env.get(config_parser.HOROVOD_LOG_LEVEL), \'INFO\')\n            self.assertEqual(env.get(config_parser.HOROVOD_LOG_HIDE_TIME), \'1\')\n\n    def test_config_file(self):\n        config_filename = os.path.join(os.path.dirname(__file__), \'data/config.test.yaml\')\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--config-file\', config_filename):\n            args = parse_args()\n\n            self.assertTrue(args.use_gloo)\n\n            # Params\n            self.assertEqual(args.fusion_threshold_mb, 32)\n            self.assertEqual(args.cycle_time_ms, 10)\n            self.assertEqual(args.cache_capacity, 2048)\n            self.assertTrue(args.hierarchical_allreduce)\n            self.assertTrue(args.hierarchical_allgather)\n\n            # Autotune\n            self.assertTrue(args.autotune)\n            self.assertEqual(args.autotune_log_file, \'horovod_autotune_log.txt\')\n            self.assertEqual(args.autotune_warmup_samples, 5)\n            self.assertEqual(args.autotune_steps_per_sample, 20)\n            self.assertEqual(args.autotune_bayes_opt_max_samples, 50)\n            self.assertEqual(args.autotune_gaussian_process_noise, 0.9)\n\n            # Timeline\n            self.assertEqual(args.timeline_filename, \'horovod_timeline.json\')\n            self.assertTrue(args.timeline_mark_cycles)\n\n            # Stall Check\n            self.assertFalse(args.no_stall_check)\n            self.assertEqual(args.stall_check_warning_time_seconds, 120)\n            self.assertEqual(args.stall_check_shutdown_time_seconds, 240)\n\n            # Library Options\n            self.assertTrue(args.mpi_threads_disable)\n            self.assertEqual(args.num_nccl_streams, 2)\n            self.assertEqual(args.ccl_bgt_affinity, 1)\n            self.assertEqual(args.gloo_timeout_seconds, 60)\n\n            # Logging\n            self.assertEqual(args.log_level, \'INFO\')\n            self.assertTrue(args.log_hide_timestamp)\n\n    def test_config_file_override_args(self):\n        config_filename = os.path.join(os.path.dirname(__file__), \'data/config.test.yaml\')\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--fusion-threshold-mb\', \'128\',\n                           \'--config-file\', config_filename,\n                           \'--cycle-time-ms\', \'20\',):\n            args = parse_args()\n            self.assertEqual(args.fusion_threshold_mb, 128)\n            self.assertEqual(args.cycle_time_ms, 20)\n\n    def test_validate_config_args(self):\n        with override_args(\'horovodrun\', \'-np\', \'2\',\n                           \'--fusion-threshold-mb\', \'-1\'):\n            with pytest.raises(ValueError):\n                parse_args()\n\n    # test_on_event tests in_thread as well, but it does not test args\n    def test_in_thread_args(self):\n        fn = mock.Mock()\n        thread = in_thread(fn, args=(1,))\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once_with(1)\n\n        fn = mock.Mock()\n        thread = in_thread(fn, args=(1, 2))\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once_with(1, 2)\n\n        fn = mock.Mock()\n        thread = in_thread(fn, args=(1, 2), silent=True)\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once_with(1, 2)\n\n        fn = mock.Mock()\n        with pytest.raises(ValueError, match=""^args must be a tuple, not <(class|type) \'int\'>, ""\n                                             ""for a single argument use \\\\(arg,\\\\)$""):\n            in_thread(fn, args=1)\n        fn.assert_not_called()\n\n    def test_on_event(self):\n        # a happy run without args and stop event\n        event = threading.Event()\n        fn = mock.Mock()\n        thread = on_event(event, fn)\n        fn.assert_not_called()\n        event.set()\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once()\n\n        # a happy run with args but without stop event\n        event = threading.Event()\n        fn = mock.Mock()\n        thread = on_event(event, fn, (\'a\', 1))\n        fn.assert_not_called()\n        event.set()\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once()\n        fn.assert_called_once_with(\'a\', 1)\n\n        # a happy run with stop event but unused\n        event = threading.Event()\n        stop = threading.Event()\n        fn = mock.Mock()\n        thread = on_event(event, fn, stop=stop, check_interval_seconds=0.01)\n        fn.assert_not_called()\n        event.set()\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once()\n        stop.set()\n        time.sleep(0.1)\n        fn.assert_called_once()\n\n        # stop the thread before we set the event\n        event = threading.Event()\n        stop = threading.Event()\n        fn = mock.Mock()\n        thread = on_event(event, fn, stop=stop, check_interval_seconds=0.01)\n        fn.assert_not_called()\n        stop.set()\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_not_called()\n        event.set()\n        time.sleep(0.1)\n        fn.assert_not_called()\n\n        # test with exception\n        def exception():\n            raise Exception(""Test Exception"")\n\n        event = threading.Event()\n        fn = mock.Mock(side_effect=exception)\n        thread = on_event(event, fn)\n        fn.assert_not_called()\n        event.set()\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once()\n\n        # test with exception but silent\n        event = threading.Event()\n        fn = mock.Mock(side_effect=exception)\n        thread = on_event(event, fn)\n        fn.assert_not_called()\n        event.set()\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n        fn.assert_called_once()\n\n        # test non-tuple args\n        event = threading.Event()\n        fn = mock.Mock()\n        with pytest.raises(ValueError, match=""^args must be a tuple, not <(class|type) \'int\'>, ""\n                                             ""for a single argument use \\\\(arg,\\\\)$""):\n            on_event(event, fn, args=1)\n        fn.assert_not_called()\n\n    def test_safe_shell_exec_captures_stdout(self):\n        self.do_test_safe_shell_exec(\'echo hello\', 0, \'hello\\n\', \'\')\n\n    def test_safe_shell_exec_captures_stderr(self):\n        self.do_test_safe_shell_exec(\'echo hello >&2\', 0, \'\', \'hello\\n\')\n\n    def test_safe_shell_exec_captures_last_line_wo_eol(self):\n        cmd = \'bash -c ""echo -e -n \\\\""hello\\nstdout\\\\""; echo -e -n \\\\""hello\\nstderr\\\\"" >&2""\'\n        self.do_test_safe_shell_exec(cmd, 0, \'hello\\nstdout\', \'hello\\nstderr\')\n\n    def test_safe_shell_exec_returns_exit_code(self):\n        self.do_test_safe_shell_exec(\'false\', 1, \'\', \'\')\n\n    def test_safe_shell_exec_interrupts_on_event(self):\n        # interrupt execute in one second\n        interrupt = threading.Event()\n        delay(lambda: interrupt.set(), 1.0)\n\n        sleep = 10\n        start = time.time()\n        self.do_test_safe_shell_exec(\'sleep {}\'.format(sleep), 143, \'\', None, interrupt)\n        duration = time.time() - start\n\n        self.assertGreaterEqual(duration, 1.0)\n        self.assertLess(duration, 2.0 + safe_shell_exec.GRACEFUL_TERMINATION_TIME_S, \'sleep should not finish\')\n        self.assertGreater(sleep, 2.0 + safe_shell_exec.GRACEFUL_TERMINATION_TIME_S, \'sleep should allow for GRACEFUL_TERMINATION_TIME_S\')\n\n    def test_safe_shell_exec_interrupts_on_parent_shutdown(self):\n        sleep = 20\n        parent_script = os.path.join(os.path.dirname(__file__), \'data/run_safe_shell_exec.py\')\n        child_script = os.path.join(os.path.dirname(__file__), \'data/sleep.py\')\n\n        def get_pid(logfile):\n            # Wait until the script has written its PID to the logfile\n            wait(lambda: os.path.exists(logfile), timeout=5)\n            with open(logfile, \'r\') as f:\n                return int(f.read())\n\n        with temppath() as parent_logfile, temppath() as child_logfile:\n            # It\'s important that this executes in an entirely different interpreter with as little shared\n            # state as possible, to avoid issues with the semaphore tracker.\n            cmd = \' \'.join([sys.executable, parent_script, parent_logfile, child_script, str(sleep), child_logfile])\n            p = subprocess.Popen(cmd, shell=True)\n\n            parent = psutil.Process(get_pid(parent_logfile))\n            child = psutil.Process(get_pid(child_logfile))\n\n            self.assertTrue(parent.is_running())\n            self.assertTrue(child.is_running())\n\n            # Hard kill the parent process\n            parent.kill()\n            parent.wait(timeout=safe_shell_exec.GRACEFUL_TERMINATION_TIME_S)\n            p.wait()\n\n            # Child process will exit when pipe breaks\n            child.wait(timeout=2 * safe_shell_exec.GRACEFUL_TERMINATION_TIME_S + 1)\n\n            self.assertFalse(parent.is_running())\n            self.assertFalse(child.is_running())\n\n    def do_test_safe_shell_exec(self, cmd, expected_exit_code, expected_stdout, expected_stderr, event=None):\n        stdout = io.StringIO()\n        stderr = io.StringIO()\n        res = safe_shell_exec.execute(cmd, stdout=stdout, stderr=stderr, events=[event])\n        self.assertEqual(expected_exit_code, res)\n        if expected_stdout is not None:\n            self.assertEqual(expected_stdout, stdout.getvalue())\n        if expected_stderr is not None:\n            self.assertEqual(expected_stderr, stderr.getvalue())\n\n    def test_hash(self):\n        hash = _hash(""test string"")\n        self.assertEqual(hash, \'6f8db599de986fab7a21625b7916589c\')\n\n    def test_host_hash(self):\n        hash = host_hash()\n        # host_hash should consider CONTAINER_ID environment variable\n        with override_env({\'CONTAINER_ID\': \'a container id\'}):\n            self.assertNotEqual(host_hash(), hash)\n        self.assertEqual(host_hash(), hash)\n\n    def test_get_mpi_implementation(self):\n        def test(output, expected, exit_code=0):\n            ret = (output, exit_code) if output is not None else None\n            env = {\'VAR\': \'val\'}\n            with mock.patch(""horovod.run.mpi_run.tiny_shell_exec.execute"", return_value=ret) as m:\n                implementation = _get_mpi_implementation(env)\n                self.assertEqual(expected, implementation)\n                m.assert_called_once_with(\'mpirun --version\', env)\n\n        test((""mpirun (Open MPI) 2.1.1\\n""\n              ""Report bugs to http://www.open-mpi.org/community/help/\\n""), _OMPI_IMPL)\n\n        test(""OpenRTE"", _OMPI_IMPL)\n\n        test(""IBM Spectrum MPI"", _SMPI_IMPL)\n\n        test((""HYDRA build details:\\n""\n              ""    Version:           3.3a2\\n""\n              ""    Configure options: \'MPICHLIB_CFLAGS=-g -O2\'\\n""), _MPICH_IMPL)\n\n        test(""Unknown MPI v1.00"", _UNKNOWN_IMPL)\n\n        test(""output"", exit_code=1, expected=_MISSING_IMPL)\n\n        test(None, _MISSING_IMPL)\n\n    def test_run_controller(self):\n        def test(use_gloo, use_mpi, use_js,\n                 gloo_is_built, mpi_is_built,\n                 lsf_exists, jsrun_installed,\n                 expected, exception):\n            gloo_run = MagicMock()\n            mpi_run = MagicMock()\n            js_run = MagicMock()\n\n            with is_built(gloo_is_built, mpi_is_built):\n                with lsf_and_jsrun(lsf_exists, jsrun_installed):\n                    if exception is not None:\n                        with pytest.raises(ValueError, match=exception) as e:\n                            run_controller(use_gloo, gloo_run, use_mpi, mpi_run, use_js, js_run, verbosity=2)\n                        return\n                    run_controller(use_gloo, gloo_run, use_mpi, mpi_run, use_js, js_run, verbosity=2)\n\n            if expected == ""gloo"":\n                gloo_run.assert_called_once()\n                mpi_run.assert_not_called()\n                js_run.assert_not_called()\n            elif expected == ""mpi"":\n                gloo_run.assert_not_called()\n                mpi_run.assert_called_once()\n                js_run.assert_not_called()\n            elif expected == ""js"":\n                gloo_run.assert_not_called()\n                mpi_run.assert_not_called()\n                js_run.assert_called_once()\n            else:\n                raise ValueError(""unsupported framework: {}"".format(expected))\n\n        bool_values = [False, True]\n        bool_values_and_none = [None, False, True]\n\n        for use_gloo, use_mpi, use_js, \\\n            gloo_is_built, mpi_is_built, \\\n            lsf_exists, jsrun_installed in \\\n            itertools.product(bool_values_and_none, bool_values_and_none, bool_values_and_none,\n                              bool_values, bool_values,\n                              bool_values, bool_values):\n\n            expected = exception = None\n            if use_gloo:\n                if gloo_is_built:\n                    expected = \'gloo\'\n                else:\n                    exception = r\'^Gloo support has not been built\\.  If this is not expected, ensure CMake is installed \' \\\n                                r\'and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error\\.$\'\n            elif use_mpi:\n                if mpi_is_built:\n                    expected = \'mpi\'\n                else:\n                    exception = r\'^MPI support has not been built\\.  If this is not expected, ensure MPI is installed \' \\\n                                r\'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error\\.$\'\n            elif use_js:\n                if mpi_is_built:\n                    if lsf_exists:\n                        expected = \'js\'\n                    else:\n                        exception = \'Horovod did not detect an LSF job.  The jsrun launcher can only be used in that environment. \' \\\n                                    \'Please, pick a different launcher for other environments.\'\n                else:\n                    exception = r\'^MPI support has not been built\\.  If this is not expected, ensure MPI is installed \' \\\n                                r\'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error\\.$\'\n            elif mpi_is_built:\n                if lsf_exists and jsrun_installed:\n                    expected = \'js\'\n                else:\n                    expected = \'mpi\'\n            elif gloo_is_built:\n                expected = \'gloo\'\n            else:\n                exception = r\'Neither MPI nor Gloo support has been built\\. Try reinstalling Horovod ensuring that \' \\\n                            r\'either MPI is installed \\(MPI\\) or CMake is installed \\(Gloo\\)\\.\'\n\n            test(use_gloo, use_mpi, use_js,\n                 gloo_is_built, mpi_is_built,\n                 lsf_exists, jsrun_installed,\n                 expected, exception)\n\n    """"""\n    Minimal mpi_run settings for tests.\n    """"""\n    minimal_settings = hvd_settings.Settings(\n        verbose=0,\n        num_hosts=1,\n        num_proc=2,\n        hosts=\'host\',\n        run_func_mode=True\n    )\n\n    """"""\n    Tests mpi_run with minimal settings.\n    """"""\n    def test_mpi_run_minimal(self):\n        if not mpi_available():\n            self.skipTest(""MPI is not available"")\n\n        cmd = [\'cmd\']\n        settings = self.minimal_settings\n\n        def mpi_impl_flags(tcp, env=None):\n            return [""--mock-mpi-impl-flags""], [""--mock-mpi-binding-args""]\n\n        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):\n            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", return_value=0) as execute:\n                mpi_run(settings, None, {}, cmd)\n\n                # call the mocked _get_mpi_implementation_flags method\n                mpi_flags, binding_args = horovod.run.mpi_run._get_mpi_implementation_flags(False)\n                self.assertIsNotNone(mpi_flags)\n                expected_cmd = (\'mpirun \'\n                                \'--allow-run-as-root --tag-output \'\n                                \'-np 2 -H host \'\n                                \'{binding_args} \'\n                                \'{mpi_flags}       \'\n                                \'cmd\').format(binding_args=\' \'.join(binding_args), mpi_flags=\' \'.join(mpi_flags))\n                expected_env = {\'PATH\': os.environ.get(\'PATH\')}\n                execute.assert_called_once_with(expected_cmd, env=expected_env, stdout=None, stderr=None)\n\n    """"""\n    Tests mpi_run on a large cluster.\n    """"""\n    def test_mpi_run_on_large_cluster(self):\n        if not mpi_available():\n            self.skipTest(""MPI is not available"")\n\n        cmd = [\'cmd\']\n        settings = copy.copy(self.minimal_settings)\n        settings.num_hosts = large_cluster_threshold\n\n        def mpi_impl_flags(tcp, env=None):\n            return [""--mock-mpi-impl-flags""], [""--mock-mpi-binding-args""]\n\n        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):\n            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", return_value=0) as execute:\n                mpi_run(settings, None, {}, cmd)\n\n                # call the mocked _get_mpi_implementation_flags method\n                mpi_flags, binding_args = horovod.run.mpi_run._get_mpi_implementation_flags(False)\n                self.assertIsNotNone(mpi_flags)\n                mpi_flags.append(\'-mca plm_rsh_no_tree_spawn true\')\n                mpi_flags.append(\'-mca plm_rsh_num_concurrent {}\'.format(settings.num_hosts))\n                expected_cmd = (\'mpirun \'\n                                \'--allow-run-as-root --tag-output \'\n                                \'-np 2 -H host \'\n                                \'{binding_args} \'\n                                \'{mpi_flags}       \'\n                                \'cmd\').format(binding_args=\' \'.join(binding_args), mpi_flags=\' \'.join(mpi_flags))\n                expected_env = {\'PATH\': os.environ.get(\'PATH\')}\n                execute.assert_called_once_with(expected_cmd, env=expected_env, stdout=None, stderr=None)\n\n    """"""\n    Tests mpi_run with full settings.\n    """"""\n    def test_mpi_run_full(self):\n        if not mpi_available():\n            self.skipTest(""MPI is not available"")\n\n        cmd = [\'cmd\', \'arg1\', \'arg2\']\n        nics = [\'eth0\', \'eth1\']\n        env = {\'env1\': \'val1\', \'env2\': \'val2\'}\n        stdout = \'<stdout>\'\n        stderr = \'<stderr>\'\n        tmout = timeout.Timeout(5, message=\'Timed out waiting for something.\')\n        settings = hvd_settings.Settings(\n            verbose=0,\n            ssh_port=1022,\n            extra_mpi_args=\'>mpi-extra args go here<\',\n            binding_args=\'>binding args go here<\',\n            key=secret.make_secret_key(),\n            start_timeout=tmout,\n            num_hosts=1,\n            num_proc=1,\n            hosts=\'>host names go here<\',\n            output_filename=\'>output filename goes here<\',\n            run_func_mode=True\n        )\n\n        def mpi_impl_flags(tcp, env=None):\n            return [""--mock-mpi-impl-flags""], []\n\n        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags) as impl:\n            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", return_value=0) as execute:\n                mpi_run(settings, nics, env, cmd, stdout=stdout, stderr=stderr)\n\n                # assert call on _get_mpi_implementation_flags\n                impl.assert_called_once_with(None, env=env)\n\n                # call the mocked _get_mpi_implementation_flags method ourselves\n                mpi_flags, _ = horovod.run.mpi_run._get_mpi_implementation_flags(False)\n                self.assertIsNotNone(mpi_flags)\n                expected_command = (\'mpirun \'\n                                    \'--allow-run-as-root --tag-output \'\n                                    \'-np 1 -H >host names go here< \'\n                                    \'>binding args go here< \'\n                                    \'{mpi_flags} \'\n                                    \'-mca plm_rsh_args ""-p 1022"" \'\n                                    \'-mca btl_tcp_if_include eth0,eth1 -x NCCL_SOCKET_IFNAME=eth0,eth1 \'\n                                    \'--output-filename >output filename goes here< \'\n                                    \'-x env1 -x env2 \'\n                                    \'>mpi-extra args go here< \'\n                                    \'cmd arg1 arg2\').format(mpi_flags=\' \'.join(mpi_flags))\n                expected_env = {\'env1\': \'val1\', \'env2\': \'val2\', \'PATH\': os.environ.get(\'PATH\')}\n                execute.assert_called_once_with(expected_command, env=expected_env, stdout=stdout, stderr=stderr)\n\n    def test_mpi_run_with_non_zero_exit(self):\n        if not mpi_available():\n            self.skipTest(""MPI is not available"")\n\n        cmd = [\'cmd\']\n        settings = self.minimal_settings\n\n        def mpi_impl_flags(tcp, env=None):\n            return [], []\n\n        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):\n            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", return_value=1):\n                with pytest.raises(RuntimeError, match=""^mpirun failed with exit code 1$""):\n                    mpi_run(settings, None, {}, cmd)\n\n    def test_horovodrun_hostfile(self):\n        with temppath() as host_filename:\n            with open(host_filename, \'w+\') as fp:\n                fp.write(\'172.31.32.7 slots=8\\n\')\n                fp.write(\'172.31.33.9 slots=8\\n\')\n\n            hosts = parse_host_files(host_filename)\n            self.assertEqual(hosts, \'172.31.32.7:8,172.31.33.9:8\')\n\n    """"""\n    Tests js_run.\n    """"""\n    @mock.patch(\'horovod.run.js_run.is_jsrun_installed\', MagicMock(return_value=True))\n    @mock.patch(\'horovod.run.js_run.generate_jsrun_rankfile\', MagicMock(return_value=\'/tmp/rankfile\'))\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_num_gpus\', MagicMock(return_value=2))\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_num_cores\', MagicMock(return_value=2))\n    def test_js_run(self):\n        if _get_mpi_implementation_flags(False)[0] is None:\n            self.skipTest(""MPI is not available"")\n\n        cmd = [\'cmd\', \'arg1\', \'arg2\']\n        env = {\'env1\': \'val1\', \'env2\': \'val2\'}\n        stdout = \'<stdout>\'\n        stderr = \'<stderr>\'\n        settings = hvd_settings.Settings(\n            verbose=0,\n            extra_mpi_args=\'>mpi-extra args go here<\',\n            num_hosts=2,\n            num_proc=4,\n            hosts=\'>host names go here<\',\n            output_filename=\'>output filename goes here<\',\n            run_func_mode=True\n        )\n\n        def mpi_impl_flags(tcp, env=None):\n            return [""--mock-mpi-impl-flags""], []\n\n        with mock.patch(""horovod.run.js_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):\n            with mock.patch(""horovod.run.js_run.safe_shell_exec.execute"", return_value=0) as execute:\n                js_run(settings, None, env, cmd, stdout=stdout, stderr=stderr)\n\n                # call the mocked _get_mpi_implementation_flags method\n                mpi_flags, _ = horovod.run.js_run._get_mpi_implementation_flags(False)\n                self.assertIsNotNone(mpi_flags)\n                expected_command = (\'jsrun \'\n                                    \'--erf_input /tmp/rankfile \'\n                                    \'--stdio_stderr >output filename goes here< \'\n                                    \'--stdio_stdout >output filename goes here< \'\n                                    \'--smpiargs \\\'{mpi_args} >mpi-extra args go here<\\\' \'\n                                    \'cmd arg1 arg2\').format(mpi_args=\' \'.join(mpi_flags))\n                expected_env = {\'env1\': \'val1\', \'env2\': \'val2\'}\n                execute.assert_called_once_with(expected_command, env=expected_env, stdout=stdout, stderr=stderr)\n\n    """"""\n    Tests generate_jsrun_rankfile.\n    """"""\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_num_gpus\', MagicMock(return_value=4))\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_num_cores\', MagicMock(return_value=4))\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_num_threads\', MagicMock(return_value=4))\n    def test_generate_jsrun_rankfile(self):\n        settings = hvd_settings.Settings(\n            num_proc=5,\n            hosts=\'host1:4,host2:4,host3:4\',\n        )\n\n        with temppath() as rankfile_path:\n            rankfile_path = generate_jsrun_rankfile(settings, rankfile_path)\n\n            with open(rankfile_path, \'r\') as file:\n                gen_rankfile = file.read()\n\n            expected_rankfile = (\n""""""overlapping_rs: allow\ncpu_index_using: logical\n\nrank: 0: { hostname: host1; cpu: {0-3} ; gpu: * ; mem: * }\nrank: 1: { hostname: host1; cpu: {4-7} ; gpu: * ; mem: * }\nrank: 2: { hostname: host1; cpu: {8-11} ; gpu: * ; mem: * }\nrank: 3: { hostname: host1; cpu: {12-15} ; gpu: * ; mem: * }\n\nrank: 4: { hostname: host2; cpu: {0-3} ; gpu: * ; mem: * }\n"""""")\n\n            self.assertMultiLineEqual(gen_rankfile, expected_rankfile)\n\n    """"""\n    Tests horovod.run.runner._run with jsrun\n    """"""\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.using_lsf\', MagicMock(return_value=True))\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_compute_hosts\', MagicMock(return_value=[\'host1\', \'host2\']))\n    @mock.patch(\'horovod.run.util.lsf.LSFUtils.get_num_gpus\', MagicMock(return_value=2))\n    @mock.patch(\'horovod.run.util.network.filter_local_addresses\', MagicMock(return_value=[\'host1\', \'host2\']))\n    @mock.patch(\'horovod.run.runner._check_all_hosts_ssh_successful\', MagicMock())\n    @mock.patch(\'horovod.run.runner.run_controller\')\n    def test_run_with_jsrun(self, mocked_run_controller):\n        hargs = HorovodArgs()\n        _run(hargs)\n        mocked_run_controller.assert_called_once()\n'"
test/test_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport queue\nimport threading\nimport time\nimport unittest\nimport warnings\n\nimport pytest\n\nfrom horovod.run.common.service.task_service import BasicTaskClient, BasicTaskService\nfrom horovod.run.common.util import network, secret\nfrom horovod.run.util.threads import in_thread\n\n\nclass SleepRequest(object):\n    pass\n\n\nclass TestSleepService(network.BasicService):\n    def __init__(self, key, duration):\n        super(TestSleepService, self).__init__(\'test service\', key, nics=None)\n        self._duration = duration\n\n    def _handle(self, req, client_address):\n        if isinstance(req, SleepRequest):\n            print(\'{}: sleeping for client {}\'.format(time.time(), client_address))\n            time.sleep(self._duration)\n            return network.AckResponse()\n\n        return super(TestSleepService, self)._handle(req, client_address)\n\n\nclass TestSleepClient(network.BasicClient):\n    def __init__(self, service_addresses, key, attempts=1):\n        super(TestSleepClient, self).__init__(\'test service\',\n                                              service_addresses,\n                                              key,\n                                              verbose=2,\n                                              attempts=attempts)\n\n    def sleep(self):\n        self._send(SleepRequest())\n\n\nclass NetworkTests(unittest.TestCase):\n    """"""\n    Tests for horovod.run.common.service.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(NetworkTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_concurrent_requests_basic(self):\n        sleep = 2.0\n        key = secret.make_secret_key()\n        service = TestSleepService(key, duration=sleep)\n        client = TestSleepClient(service.addresses(), key, attempts=1)\n\n        start = time.time()\n        threads = list([in_thread(client.sleep, daemon=False) for _ in range(1)])\n        for thread in threads:\n            thread.join(sleep + 1.0)\n            self.assertFalse(thread.is_alive(), \'thread should have terminated by now\')\n        duration = time.time() - start\n        print(\'concurrent requests completed in {} seconds\'.format(duration))\n\n        self.assertGreaterEqual(duration, sleep, \'sleep requests should have been completed\')\n        self.assertLess(duration, sleep + 1.0, \'sleep requests should have been concurrent\')\n\n    def test_shutdown_during_request_basic(self):\n        sleep = 2.0\n        key = secret.make_secret_key()\n        service = TestSleepService(key, duration=sleep)\n        client = TestSleepClient(service.addresses(), key, attempts=1)\n\n        start = time.time()\n        threads = list([in_thread(client.sleep, name=\'request {}\'.format(i+1), daemon=False) for i in range(5)])\n        time.sleep(sleep / 2.0)\n        service.shutdown()\n        duration = time.time() - start\n        print(\'shutdown completed in {} seconds\'.format(duration))\n        self.assertGreaterEqual(duration, sleep, \'sleep requests should have been completed\')\n        self.assertLess(duration, sleep + 1.0, \'sleep requests should have been concurrent\')\n\n        for thread in threads:\n            thread.join(0.1)\n            self.assertFalse(thread.is_alive(), \'thread should have terminated by now\')\n\n    def test_shutdown_during_request_basic_task(self):\n        result_queue = queue.Queue(1)\n\n        def wait_for_exit_code(client, queue):\n            queue.put(client.wait_for_command_exit_code())\n\n        key = secret.make_secret_key()\n        service_name = \'test-service\'\n        service = BasicTaskService(service_name, key, nics=None, verbose=2)\n        client = BasicTaskClient(service_name, service.addresses(), key, verbose=2, attempts=1)\n        thread = threading.Thread(target=wait_for_exit_code, args=(client, result_queue))\n\n        start = time.time()\n        thread.start()  # wait for command exit code\n        client.run_command(\'sleep 2\', {})  # execute command\n        time.sleep(0.5)  # give the thread some time to connect before shutdown\n        service.shutdown()  # shutdown should wait on request to finish\n        duration = time.time() - start\n        self.assertGreaterEqual(duration, 2)\n\n        # we cannot call after shutdown\n        with pytest.raises(Exception, match=r\'^(\\[[Ee]rrno 104\\] Connection reset by peer)\'\n                                            r\'|(\\[[Ee]rrno 111\\] Connection refused)$\'):\n            client.command_result()\n\n        # but still our long running request succeeded\n        thread.join(1.0)\n        self.assertFalse(thread.is_alive())\n\n    def test_exit_code(self):\n        """"""test non-zero exit code""""""\n        key = secret.make_secret_key()\n        service_name = \'test-service\'\n        service = BasicTaskService(service_name, key, nics=None, verbose=2)\n        client = BasicTaskClient(service_name, service.addresses(), key, verbose=2, attempts=1)\n\n        client.run_command(\'false\', {})\n        res = client.wait_for_command_exit_code()\n        self.assertEqual(1, res)\n'"
test/test_spark.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport copy\nimport itertools\nimport os\nimport platform\nimport pytest\nimport re\nimport sys\nimport threading\nimport time\nimport unittest\nimport warnings\n\nfrom distutils.version import LooseVersion\n\nimport mock\nimport torch\n\nimport pyspark\n\nfrom pyspark.ml.linalg import DenseVector, SparseVector, VectorUDT\nfrom pyspark.sql.types import ArrayType, BooleanType, DoubleType, FloatType, IntegerType, \\\n    NullType, StructField, StructType\n\nimport horovod.spark\nimport horovod.torch as hvd\n\nfrom horovod.common.util import gloo_built, mpi_built\nfrom horovod.run.common.util import codec, secret, safe_shell_exec\nfrom horovod.run.common.util import settings as hvd_settings\nfrom horovod.run.mpi_run import is_open_mpi\nfrom horovod.spark.common import constants, util\nfrom horovod.spark.common.store import HDFSStore\nfrom horovod.spark.driver.rsh import rsh\nfrom horovod.spark.task import get_available_devices, gloo_exec_fn, mpirun_exec_fn\nfrom horovod.spark.driver.driver_service import SparkDriverService, SparkDriverClient\nfrom horovod.spark.task.task_service import SparkTaskService, SparkTaskClient\n\nfrom spark_common import spark_session, create_test_data_from_schema, create_xor_data, local_store\n\nfrom common import is_built, mpi_implementation_flags, tempdir, override_env, undo, delay\n\n\n# Spark will fail to initialize correctly locally on Mac OS without this\nif platform.system() == \'Darwin\':\n    os.environ[\'OBJC_DISABLE_INITIALIZE_FORK_SAFETY\'] = \'YES\'\n\n\nclass SparkTests(unittest.TestCase):\n    """"""\n    Tests for horovod.spark.run().\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(SparkTests, self).__init__(*args, **kwargs)\n        self.maxDiff = None\n        warnings.simplefilter(\'module\')\n\n    def run(self, result=None):\n        # These unit tests should not be run with horovodrun as some tests\n        # setup their own Horovod cluster, where both will then interfere.\n        if \'OMPI_COMM_WORLD_RANK\' in os.environ or \'HOROVOD_RANK\' in os.environ:\n            self.skipTest(""These tests should not be executed via horovodrun, just pytest"")\n\n        super(SparkTests, self).run(result)\n\n    """"""\n    Test that horovod.spark.run works properly in a simple setup using MPI.\n    """"""\n    def test_happy_run_with_mpi(self):\n        if not (mpi_built() and is_open_mpi()):\n            self.skipTest(""Open MPI is not available"")\n\n        self.do_test_happy_run(use_mpi=True, use_gloo=False)\n\n    """"""\n    Test that horovod.spark.run works properly in a simple setup using Gloo.\n    """"""\n    def test_happy_run_with_gloo(self):\n        if not gloo_built():\n            self.skipTest(""Gloo is not available"")\n\n        self.do_test_happy_run(use_mpi=False, use_gloo=True)\n\n    """"""\n    Actually tests that horovod.spark.run works properly in a simple setup.\n    """"""\n    def do_test_happy_run(self, use_mpi, use_gloo):\n        def fn():\n            hvd.init()\n            res = hvd.allgather(torch.tensor([hvd.rank()])).tolist()\n            return res, hvd.rank()\n\n        with spark_session(\'test_happy_run\'):\n            with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):\n                res = horovod.spark.run(fn, start_timeout=10,\n                                        use_mpi=use_mpi, use_gloo=use_gloo,\n                                        verbose=2)\n                self.assertListEqual([([0, 1], 0), ([0, 1], 1)], res)\n\n    """"""\n    Test that horovod.spark.run times out when it does not start up fast enough using MPI.\n    """"""\n    def test_timeout_with_mpi(self):\n        if not (mpi_built() and is_open_mpi()):\n            self.skipTest(""Open MPI is not available"")\n\n        self.do_test_timeout(use_mpi=True, use_gloo=False)\n\n    """"""\n    Test that horovod.spark.run times out when it does not start up fast enough using Gloo.\n    """"""\n    def test_timeout_with_gloo(self):\n        if not gloo_built():\n            self.skipTest(""Gloo is not available"")\n\n        self.do_test_timeout(use_mpi=False, use_gloo=True)\n\n    """"""\n    Actually tests that horovod.spark.run times out when it does not start up fast enough.\n    """"""\n    def do_test_timeout(self, use_mpi, use_gloo):\n        # with 2 cores and 4 num_proc this spark run will never start up completely and time out\n        with spark_session(\'test_timeout\', cores=2):\n            with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):\n                with pytest.raises(Exception, match=\'^Timed out waiting for Spark tasks to start.\'):\n                    horovod.spark.run(None, num_proc=4, start_timeout=5,\n                                      use_mpi=use_mpi, use_gloo=use_gloo,\n                                      verbose=0)\n\n    """"""\n    Test that horovod.spark.run fails with meaningful exception when mpirun cannot be found.\n    This test does not require MPI to be installed.\n    """"""\n    def test_mpirun_not_found(self):\n        start = time.time()\n        with spark_session(\'test_mpirun_not_found\'):\n            with is_built(gloo_is_built=False, mpi_is_built=True):\n                with mpi_implementation_flags():\n                    with pytest.raises(Exception, match=\'^mpirun failed with exit code 127$\'):\n                        horovod.spark.run(None, start_timeout=20, env={\'PATH\': \'/nonexistent\'}, verbose=0)\n        self.assertLessEqual(time.time() - start, 10, \'Failure propagation took too long\')\n\n    """"""\n    Test that horovod.spark.run uses MPI properly.\n    """"""\n    def test_spark_run_with_mpi(self):\n        with mpi_implementation_flags():\n            self.do_test_spark_run(use_mpi=True, use_gloo=False)\n\n    """"""\n    Test that horovod.spark.run uses Gloo properly.\n    """"""\n    def test_spark_run_with_gloo(self):\n        self.do_test_spark_run(use_mpi=False, use_gloo=True)\n\n    """"""\n    Actually tests that horovod.spark.run invokes mpi_run properly.\n    """"""\n    def do_test_spark_run(self, use_mpi, use_gloo):\n        env = {\'env1\': \'val1\', \'env2\': \'val2\'}\n        expected_env = \'-x env1 -x env2\'\n        extra_mpi_args = \'<extra args go here>\'\n        with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):\n            self._do_test_spark_run(num_proc=2, use_mpi=use_mpi, use_gloo=use_gloo,\n                                    extra_mpi_args=extra_mpi_args,\n                                    env=env, stdout=\'<stdout>\', stderr=\'<stderr>\',\n                                    cores=2, expected_np=2, expected_env=expected_env)\n\n    """"""\n    Test that horovod.spark.run does not default to spark parallelism given num_proc using MPI.\n    """"""\n    def test_spark_run_num_proc_precedes_spark_cores_with_mpi(self):\n        with mpi_implementation_flags():\n            self.do_test_spark_run_num_proc_precedes_spark_cores(use_mpi=True, use_gloo=False)\n\n    """"""\n    Test that horovod.spark.run does not default to spark parallelism given num_proc using Gloo.\n    """"""\n    def test_spark_run_num_proc_precedes_spark_cores_with_gloo(self):\n        self.do_test_spark_run_num_proc_precedes_spark_cores(use_mpi=False, use_gloo=True)\n\n    """"""\n    Actually tests that horovod.spark.run does not default to spark parallelism given num_proc.\n    """"""\n    def do_test_spark_run_num_proc_precedes_spark_cores(self, use_mpi, use_gloo):\n        self._do_test_spark_run(num_proc=1, cores=2, expected_np=1,\n                                use_mpi=use_mpi, use_gloo=use_gloo)\n\n    """"""\n    Tests that horovod.spark.run invokes mpi_run with a given PATH properly.\n    """"""\n    def test_spark_run_with_path_with_mpi(self):\n        env = {\'env1\': \'val1\', \'env2\': \'val2\', \'PATH\': \'path\'}\n        expected_env = \'-x PATH -x env1 -x env2\'\n        extra_mpi_args = \'<extra args go here>\'\n        with is_built(gloo_is_built=False, mpi_is_built=True):\n            self._do_test_spark_run(num_proc=2, use_mpi=True, use_gloo=False,\n                                    extra_mpi_args=extra_mpi_args,\n                                    env=env, stdout=\'<stdout>\', stderr=\'<stderr>\',\n                                    cores=4, expected_np=2, expected_env=expected_env)\n\n    """"""\n    Test that horovod.spark.run defaults num_proc to spark parallelism using MPI.\n    """"""\n    def test_spark_run_defaults_num_proc_to_spark_cores_with_mpi(self):\n        with mpi_implementation_flags():\n            self.do_test_spark_run_defaults_num_proc_to_spark_cores(use_mpi=True, use_gloo=False)\n\n    """"""\n    Test that horovod.spark.run defaults num_proc to spark parallelism using Gloo.\n    """"""\n    def test_spark_run_defaults_num_proc_to_spark_cores_with_gloo(self):\n        self.do_test_spark_run_defaults_num_proc_to_spark_cores(use_mpi=False, use_gloo=True)\n\n    """"""\n    Actually tests that horovod.spark.run defaults num_proc to spark parallelism.\n    """"""\n    def do_test_spark_run_defaults_num_proc_to_spark_cores(self, use_mpi, use_gloo):\n        self._do_test_spark_run(num_proc=None, cores=2, expected_np=2,\n                                use_mpi=use_mpi, use_gloo=use_gloo)\n\n    """"""\n    Test that horovod.spark.run defaults env to the full system env using MPI.\n    """"""\n    def test_spark_run_does_not_default_env_to_os_env_with_mpi(self):\n        with mpi_implementation_flags():\n            self.do_test_spark_run_does_not_default_env_to_os_env(use_mpi=True, use_gloo=False)\n\n    """"""\n    Test that horovod.spark.run defaults env to the full system env using Gloo.\n    """"""\n    def test_spark_run_does_not_default_env_to_os_env_with_gloo(self):\n        self.do_test_spark_run_does_not_default_env_to_os_env(use_mpi=False, use_gloo=True)\n\n    """"""\n    Actually tests that horovod.spark.run defaults env to the full system env.\n    """"""\n    def do_test_spark_run_does_not_default_env_to_os_env(self, use_mpi, use_gloo):\n        env = {\'env1\': \'val1\', \'env2\': \'val2\'}\n        expected_env = \'\'\n\n        with override_env(env):\n            self._do_test_spark_run(env=None, use_mpi=use_mpi, use_gloo=use_gloo,\n                                    expected_env=expected_env)\n\n    """"""\n    Test that horovod.spark.run raises an exception on non-zero exit code of mpi_run using MPI.\n    """"""\n    def test_spark_run_with_non_zero_exit_with_mpi(self):\n        expected = \'^mpirun failed with exit code 1$\'\n        with mpi_implementation_flags():\n            self.do_test_spark_run_with_non_zero_exit(use_mpi=True, use_gloo=False,\n                                                      expected=expected)\n\n    """"""\n    Test that horovod.spark.run raises an exception on non-zero exit code of mpi_run using Gloo.\n    """"""\n    def test_spark_run_with_non_zero_exit_with_gloo(self):\n        expected = \'^Horovod detected that one or more processes exited with non-zero \' \\\n                   \'status, thus causing the job to be terminated. The first process \' \\\n                   \'to do so was:\\nProcess name: 0\\nExit code: 1$\'\n        self.do_test_spark_run_with_non_zero_exit(use_mpi=False, use_gloo=True,\n                                                  expected=expected)\n\n    """"""\n    Actually tests that horovod.spark.run raises an exception on non-zero exit code of mpi_run.\n    """"""\n    def do_test_spark_run_with_non_zero_exit(self, use_mpi, use_gloo, expected):\n        def fn():\n            return 0\n\n        def mpi_impl_flags(tcp, env=None):\n            return [""--mock-mpi-impl-flags""], [""--mock-mpi-binding-args""]\n\n        def gloo_exec_command_fn(driver_addresses, key, settings, env):\n            def _exec_command(command, alloc_info, event):\n                return 1, alloc_info.rank\n            return _exec_command\n\n        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):\n            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", return_value=1):\n                with mock.patch(""horovod.spark.gloo_run._exec_command_fn"", side_effect=gloo_exec_command_fn):\n                    with spark_session(\'test_spark_run\'):\n                        with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):\n                            with pytest.raises(Exception, match=expected):\n                                horovod.spark.run(fn, start_timeout=10, use_mpi=use_mpi, use_gloo=use_gloo, verbose=2)\n\n    """"""\n    Performs an actual horovod.spark.run test using MPI or Gloo.\n    """"""\n    def _do_test_spark_run(self, args=(), kwargs={}, num_proc=1, extra_mpi_args=None,\n                           env=None, use_mpi=None, use_gloo=None,\n                           stdout=None, stderr=None, verbose=2,\n                           cores=2, expected_np=1, expected_env=\'\'):\n        if use_mpi:\n            self._do_test_spark_run_with_mpi(args, kwargs, num_proc, extra_mpi_args, env,\n                                             stdout, stderr, verbose, cores,\n                                             expected_np, expected_env)\n        if use_gloo:\n            self._do_test_spark_run_with_gloo(args, kwargs, num_proc, extra_mpi_args, env,\n                                              stdout, stderr, verbose, cores,\n                                              expected_np)\n\n    """"""\n    Performs an actual horovod.spark.run test using MPI.\n    """"""\n    def _do_test_spark_run_with_mpi(self, args=(), kwargs={}, num_proc=1, extra_mpi_args=None,\n                                    env=None, stdout=None, stderr=None, verbose=2,\n                                    cores=2, expected_np=1, expected_env=\'\'):\n        if env is None:\n            env = {}\n\n        def fn():\n            return 1\n\n        def mpi_impl_flags(tcp, env=None):\n            return [""--mock-mpi-impl-flags""], [""--mock-mpi-binding-args""]\n\n        def exception(*args, **argv):\n            raise Exception(\'Test Exception\')\n\n        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):\n            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", side_effect=exception) as execute:\n                with spark_session(\'test_spark_run\', cores=cores):\n                    with is_built(gloo_is_built=False, mpi_is_built=True):\n                        # we make the run fail just after we caught our mocked method calls\n                        with pytest.raises(Exception) as e:\n                            horovod.spark.run(fn, args=args, kwargs=kwargs,\n                                              num_proc=num_proc, start_timeout=10,\n                                              use_mpi=True, use_gloo=False,\n                                              extra_mpi_args=extra_mpi_args, env=env,\n                                              stdout=stdout, stderr=stderr, verbose=verbose)\n\n                self.assertFalse(str(e.value).startswith(\'Timed out waiting for Spark tasks to start.\'),\n                                 \'Spark timed out before mpi_run was called, test setup is broken.\')\n                self.assertEqual(str(e.value), \'Test Exception\')\n\n                # call the mocked _get_mpi_implementation_flags method\n                mpi_flags, binding_args = horovod.run.mpi_run._get_mpi_implementation_flags(False)\n                self.assertIsNotNone(mpi_flags)\n                expected_command = (\'mpirun \'\n                                    \'--allow-run-as-root --tag-output \'\n                                    \'-np {expected_np} -H [^ ]+ \'\n                                    \'{binding_args} \'\n                                    \'{mpi_flags}  \'\n                                    \'-mca btl_tcp_if_include [^ ]+ -x NCCL_SOCKET_IFNAME=[^ ]+  \'\n                                    \'{expected_env} \'\n                                    \'{extra_mpi_args} \'\n                                    \'-x NCCL_DEBUG=INFO \'\n                                    r\'-mca plm_rsh_agent ""[^""]+python[0-9.]* -m horovod.spark.driver.mpirun_rsh [^ ]+ [^ ]+"" \'\n                                    r\'[^""]+python[0-9.]* -m horovod.spark.task.mpirun_exec_fn [^ ]+ [^ ]+\'.format(\n                    expected_np=expected_np,\n                    binding_args=\' \'.join(binding_args),\n                    expected_env=expected_env if expected_env else \'\',\n                    mpi_flags=\' \'.join(mpi_flags),\n                    extra_mpi_args=extra_mpi_args if extra_mpi_args else \'\'))\n\n                execute.assert_called_once()\n                execute_args, execute_kwargs = execute.call_args\n\n        self.assertIsNotNone(execute_args)\n        actual_command = execute_args[0]\n        actual_env = execute_kwargs.get(\'env\')\n        actual_stdout = execute_kwargs.get(\'stdout\')\n        actual_stderr = execute_kwargs.get(\'stderr\')\n\n        # the settings should not contain the key\n        serialized_settings = actual_command.split(\' \')[-1]\n        actual_settings = codec.loads_base64(serialized_settings)\n        self.assertIsNone(actual_settings.key)\n\n        # the settings for the rsh agent should not contain the key\n        actual_rsh_command_match = re.match(\'.* -mca plm_rsh_agent ""([^""]+)"" .*\', actual_command)\n        self.assertTrue(actual_rsh_command_match, \'could not extract rsh agent from mpirun command\')\n        actual_rsh_command = actual_rsh_command_match.group(1)\n        serialized_rsh_settings = actual_rsh_command.split(\' \')[-1]\n        actual_rsh_settings = codec.loads_base64(serialized_rsh_settings)\n        self.assertIsNone(actual_rsh_settings.key)\n\n        # for better comparison replace sections in actual_command that change across runs / hosts\n        for replacement in [\'-H [^ ]+\', \'-mca btl_tcp_if_include [^ ]+\', \'-x NCCL_SOCKET_IFNAME=[^ ]+\',\n                            r\'""[^""]+python[0-9.]*\', r\' [^""]+python[0-9.]*\',\n                            \'-m horovod.spark.driver.mpirun_rsh [^ ]+ [^ ]+""\',\n                            \'-m horovod.spark.task.mpirun_exec_fn [^ ]+ [^ ]+\']:\n            actual_command = re.sub(replacement, replacement, actual_command, 1)\n\n        actual_secret = actual_env.pop(secret.HOROVOD_SECRET_KEY, None)\n        self.assertEqual(expected_command, actual_command)\n        if env:\n            if \'PATH\' not in env and \'PATH\' in os.environ:\n                env = copy.copy(env)\n                env[\'PATH\'] = os.environ[\'PATH\']\n            self.assertEqual(env, actual_env)\n        else:\n            self.assertIsNotNone(actual_env)\n        self.assertIsNotNone(actual_secret)\n        self.assertTrue(len(actual_secret) > 0)\n        self.assertEqual(stdout, actual_stdout)\n        self.assertEqual(stderr, actual_stderr)\n\n    """"""\n    Performs an actual horovod.spark.run test using Gloo.\n    """"""\n    def _do_test_spark_run_with_gloo(self, args=(), kwargs={}, num_proc=1, extra_mpi_args=None,\n                                     env=None, stdout=None, stderr=None, verbose=2,\n                                     cores=2, expected_np=1):\n        if env is None:\n            env = {}\n\n        def fn():\n            return 1\n\n        def _exec_command(command, alloc_info, event):\n            return 1, alloc_info.rank\n\n        exec_command = mock.MagicMock(side_effect=_exec_command)\n        gloo_exec_command_fn = mock.MagicMock(return_value=exec_command)\n\n        with mock.patch(""horovod.spark.gloo_run._exec_command_fn"", side_effect=gloo_exec_command_fn):\n            with spark_session(\'test_spark_run\', cores=cores):\n                with is_built(gloo_is_built=True, mpi_is_built=False):\n                    # we make the run fail just after we caught our mocked method calls\n                    with pytest.raises(Exception) as e:\n                        # we need to timeout horovod because our mocked methods will block Spark\n                        # this raises above exception, but allows us to catch execute\'s arguments\n                        horovod.spark.run(fn, args=args, kwargs=kwargs,\n                                          num_proc=num_proc, start_timeout=10,\n                                          use_mpi=False, use_gloo=True,\n                                          extra_mpi_args=extra_mpi_args, env=env,\n                                          stdout=stdout, stderr=stderr, verbose=verbose)\n\n        self.assertFalse(str(e.value).startswith(\'Timed out waiting for Spark tasks to start.\'),\n                         \'Spark timed out before mpi_run was called, test setup is broken.\')\n        self.assertEqual(\'Horovod detected that one or more processes exited with non-zero status, \'\n                         \'thus causing the job to be terminated. The first process to do so was:\\n\'\n                         \'Process name: 0\\n\'\n                         \'Exit code: 1\\n\', str(e.value))\n\n        num_proc = cores if num_proc is None else num_proc\n        self.assertEqual(expected_np, num_proc)\n        self.assertEqual(1, gloo_exec_command_fn.call_count)\n        _, _, _, call_env = gloo_exec_command_fn.call_args[0]\n        self.assertEqual(env or {}, call_env)\n        self.assertEqual({}, gloo_exec_command_fn.call_args[1])\n        self.assertEqual(num_proc, exec_command.call_count)\n        self.assertEqual(num_proc, len(exec_command.call_args_list))\n\n        # expect all ranks exist\n        # exec_command.call_args_list is [(args, kwargs)] with args = (command, alloc_info, event)\n        actual_ranks = sorted([call_args[0][1].rank for call_args in exec_command.call_args_list])\n        self.assertEqual(list(range(0, num_proc)), actual_ranks)\n\n        first_event = exec_command.call_args_list[0][0][2]\n        first_host = exec_command.call_args_list[0][0][1].hostname\n        for call_args in exec_command.call_args_list:\n            # all events are the same instance\n            self.assertEqual(first_event, call_args[0][2])\n            # all kwargs are empty\n            self.assertEqual({}, call_args[1])\n\n            # all alloc_info refer to the same host\n            alloc_info = call_args[0][1]\n            self.assertEqual(first_host, alloc_info.hostname)\n            self.assertEqual(num_proc, alloc_info.size)\n            self.assertEqual(num_proc, alloc_info.local_size)\n            self.assertEqual(alloc_info.local_rank, alloc_info.rank)\n\n            # command fully derived from alloc_info\n            expected_command = (\'HOROVOD_HOSTNAME=[^ ]+ \'\n                                \'HOROVOD_RANK={rank} \'\n                                \'HOROVOD_SIZE={size} \'\n                                \'HOROVOD_LOCAL_RANK={local_rank} \'\n                                \'HOROVOD_LOCAL_SIZE={local_size} \'\n                                \'HOROVOD_CROSS_RANK=0 \'\n                                \'HOROVOD_CROSS_SIZE=1  \'\n                                \'PYTHONUNBUFFERED=1 \'\n                                \'HOROVOD_GLOO_RENDEZVOUS_ADDR=[^ ]+ \'\n                                \'HOROVOD_GLOO_RENDEZVOUS_PORT=[0-9]+ \'\n                                \'HOROVOD_CONTROLLER=gloo \'\n                                \'HOROVOD_CPU_OPERATIONS=gloo \'\n                                \'HOROVOD_GLOO_IFACE=[^ ]+ \'\n                                \'NCCL_SOCKET_IFNAME=[^ ]+ \'\n                                \'[^ ]+python[0-9.]* -m horovod.spark.task.gloo_exec_fn \'\n                                \'[^ ]+ [^ ]+$\'.format(rank=alloc_info.rank,\n                                                      size=alloc_info.size,\n                                                      local_rank=alloc_info.local_rank,\n                                                      local_size=alloc_info.local_size,\n                                                      np=num_proc))\n\n            actual_command = call_args[0][0]\n\n            # the settings should not contain the key\n            serialized_settings = actual_command.split(\' \')[-1]\n            actual_settings = codec.loads_base64(serialized_settings)\n            self.assertIsNone(actual_settings.key)\n\n            # for better comparison replace sections in actual_command that change across runs / hosts\n            for replacement in [\'_HOROVOD_SECRET_KEY=[^ ]+\',\n                                \'HOROVOD_HOSTNAME=[^ ]+\',\n                                \'HOROVOD_GLOO_RENDEZVOUS_ADDR=[^ ]+\',\n                                \'HOROVOD_GLOO_RENDEZVOUS_PORT=[0-9]+\',\n                                \'HOROVOD_GLOO_IFACE=[^ ]+\',\n                                \'NCCL_SOCKET_IFNAME=[^ ]+\',\n                                \'[^ ]+python[0-9.]*\',\n                                \'[^ ]+ [^ ]+$\']:\n                actual_command = re.sub(replacement, replacement, actual_command, 1)\n\n            self.assertEqual(expected_command, actual_command)\n\n    def test_rsh_with_zero_exit_code(self):\n        self.do_test_rsh(\'true\', 0)\n\n    def test_rsh_with_non_zero_exit_code(self):\n        self.do_test_rsh(\'false\', 1)\n\n    def test_rsh_event(self):\n        self.do_test_rsh_events(1)\n\n    def test_rsh_events(self):\n        self.do_test_rsh_events(3)\n\n    def do_test_rsh_events(self, test_events):\n        self.assertGreater(test_events, 0, \'test should not be trivial\')\n\n        sleep = 10\n        command = \'sleep {}\'.format(sleep)\n        for triggered_event in range(test_events):\n            events = [threading.Event() for _ in range(test_events)]\n            delay(lambda: events[triggered_event].set(), 1.0)\n\n            start = time.time()\n            self.do_test_rsh(command, 143, events=events)\n            duration = time.time() - start\n\n            self.assertGreaterEqual(duration, 1.0)\n            self.assertLess(duration, 2.00 + safe_shell_exec.GRACEFUL_TERMINATION_TIME_S,\n                            \'sleep should not finish\')\n            self.assertGreater(sleep, 2.00 + safe_shell_exec.GRACEFUL_TERMINATION_TIME_S,\n                               \'sleep should be large enough\')\n\n    def do_test_rsh(self, command, expected_result, events=None):\n        def fn():\n            return 0\n\n        # setup infrastructure so we can call rsh\n        key = secret.make_secret_key()\n        host_hash = \'test-host\'\n        driver = SparkDriverService(1, fn, (), {}, key, None)\n        client = SparkDriverClient(driver.addresses(), key, 2)\n        task = SparkTaskService(0, key, None, 2)\n        client.register_task(0, task.addresses(), host_hash)\n        settings = hvd_settings.Settings(verbose=2, key=key)\n        env = {}\n\n        res = rsh(driver.addresses(), key, host_hash, command, env, 0, settings.verbose, False, events=events)\n        self.assertEqual(expected_result, res)\n\n    def test_mpirun_exec_fn(self):\n        bool_values = [False, True]\n        for work_dir_env_set, python_path_is_set, hvd_python_path_is_set in \\\n            itertools.product(bool_values, bool_values, bool_values):\n            with tempdir() as tmp_path:\n                driver = mock.MagicMock()\n                settings = mock.MagicMock()\n                settings.verbose = 2\n\n                test_env = {}\n                test_dir = os.getcwd()\n                test_sys_path = copy.copy(sys.path)\n\n                def reset():\n                    os.chdir(test_dir)\n                    sys.path = test_sys_path\n\n                if work_dir_env_set:\n                    # ask mpirun_exec_fn to change cwd to test_dir\n                    test_env[\'HOROVOD_SPARK_WORK_DIR\'] = test_dir\n                if python_path_is_set:\n                    test_python_path = [\'python/path\', \'python/path2\']\n                    test_env[\'PYTHONPATH\'] = os.pathsep.join(test_python_path)\n                if hvd_python_path_is_set:\n                    # ingest tmp_path into workers PYTHONPATH\n                    test_horovod_python_path = [\'horovod\', \'horovod/python\']\n                    test_env[\'HOROVOD_SPARK_PYTHONPATH\'] = os.pathsep.join(test_horovod_python_path)\n\n                with override_env(test_env):\n                    with undo(reset):  # restores current working dir and sys.path after test\n                        with mock.patch(\'horovod.spark.task.mpirun_exec_fn.task_exec\') as task_exec:\n                            msg = \'work_dir_env_set={} python_path_is_set={} hvd_python_path_is_set={}\'\\\n                                .format(work_dir_env_set, python_path_is_set, hvd_python_path_is_set)\n                            print(\'testing with {}\'.format(msg))\n\n                            # change cwd to tmp_path and test mpirun_exec_fn\n                            os.chdir(tmp_path)\n                            mpirun_exec_fn.main(driver, settings)\n\n                            # work dir changed if HOROVOD_SPARK_WORK_DIR set\n                            if work_dir_env_set:\n                                self.assertEqual(test_dir, os.getcwd(), msg)\n                            else:\n                                self.assertEqual(tmp_path, os.getcwd(), msg)\n\n                            # PYTHONPATH prepended with HOROVOD_SPARK_PYTHONPATH\n                            expected_python_path = []\n                            if hvd_python_path_is_set:\n                                expected_python_path = test_horovod_python_path\n                            if python_path_is_set:\n                                expected_python_path = expected_python_path + test_python_path\n                            if \'PYTHONPATH\' in os.environ:\n                                actual_python_path = os.environ[\'PYTHONPATH\']\n                            else:\n                                actual_python_path = """"\n                            self.assertEqual(os.pathsep.join(expected_python_path), actual_python_path, msg)\n\n                            # HOROVOD_SPARK_PYTHONPATH injected at sys.path[1]\n                            expected_sys_path = copy.copy(test_sys_path)\n                            if hvd_python_path_is_set:\n                                expected_sys_path = expected_sys_path[0:1] + \\\n                                                    test_horovod_python_path + \\\n                                                    expected_sys_path[1:]\n                            self.assertEqual(expected_sys_path, sys.path, msg)\n\n                            task_exec.assert_called_once()\n                            task_exec_args, task_exec_kwargs = task_exec.call_args\n                            expected_task_exec_args = (driver, settings, \'OMPI_COMM_WORLD_RANK\')\n                            expected_task_exec_kwargs = {}\n                            self.assertEqual(expected_task_exec_args, task_exec_args, msg)\n                            self.assertEqual(expected_task_exec_kwargs, task_exec_kwargs, msg)\n\n    def test_gloo_exec_fn(self):\n        driver = mock.MagicMock()\n        settings = mock.MagicMock()\n        settings.verbose = 2\n\n        with mock.patch(\'horovod.spark.task.gloo_exec_fn.task_exec\') as task_exec:\n            gloo_exec_fn.main(driver, settings)\n\n            task_exec.assert_called_once()\n            task_exec_args, task_exec_kwargs = task_exec.call_args\n            expected_task_exec_args = (driver, settings, \'HOROVOD_RANK\')\n            expected_task_exec_kwargs = {}\n            self.assertEqual(expected_task_exec_args, task_exec_args)\n            self.assertEqual(expected_task_exec_kwargs, task_exec_kwargs)\n\n    def test_df_cache(self):\n        # Clean the cache before starting the test\n        util.clear_training_cache()\n        util._training_cache.get_dataset = mock.Mock(side_effect=util._training_cache.get_dataset)\n\n        with spark_session(\'test_df_cache\') as spark:\n            with local_store() as store:\n                df = create_xor_data(spark)\n                df2 = create_xor_data(spark)\n                df3 = create_xor_data(spark)\n\n                key = util._training_cache.create_key(df, store, None)\n                key2 = util._training_cache.create_key(df2, store, None)\n                key3 = util._training_cache.create_key(df3, store, None)\n\n                # All keys are distinct\n                assert key != key2\n                assert key != key3\n                assert key2 != key3\n\n                # The cache should be empty to start\n                assert not util._training_cache.is_cached(key, store)\n                assert not util._training_cache.is_cached(key2, store)\n                assert not util._training_cache.is_cached(key3, store)\n\n                # First insertion into the cache\n                with util.prepare_data(num_processes=2,\n                                       store=store,\n                                       df=df,\n                                       feature_columns=[\'features\'],\n                                       label_columns=[\'y\']) as dataset_idx:\n                    train_rows, val_rows, metadata, avg_row_size = util.get_dataset_properties(dataset_idx)\n                    util._training_cache.get_dataset.assert_not_called()\n                    assert len(util._training_cache._key_to_dataset) == 1\n                    assert util._training_cache.is_cached(key, store)\n                    assert dataset_idx == 0\n\n                    # The first dataset is still in use, so we assign the next integer in sequence to this\n                    # dataset\n                    assert not util._training_cache.is_cached(key2, store)\n                    with util.prepare_data(num_processes=2,\n                                           store=store,\n                                           df=df2,\n                                           feature_columns=[\'features\'],\n                                           label_columns=[\'y\']) as dataset_idx2:\n                        util._training_cache.get_dataset.assert_not_called()\n                        assert len(util._training_cache._key_to_dataset) == 2\n                        assert util._training_cache.is_cached(key2, store)\n                        assert dataset_idx2 == 1\n\n                # Even though the first dataset is no longer in use, it is still cached\n                with util.prepare_data(num_processes=2,\n                                       store=store,\n                                       df=df,\n                                       feature_columns=[\'features\'],\n                                       label_columns=[\'y\']) as dataset_idx1:\n                    train_rows1, val_rows1, metadata1, avg_row_size1 = util.get_dataset_properties(dataset_idx1)\n                    util._training_cache.get_dataset.assert_called()\n                    assert train_rows == train_rows1\n                    assert val_rows == val_rows1\n                    assert metadata == metadata1\n                    assert avg_row_size == avg_row_size1\n                    assert dataset_idx1 == 0\n\n                # The first dataset is no longer in use, so we can reclaim its dataset index\n                assert not util._training_cache.is_cached(key3, store)\n                with util.prepare_data(num_processes=2,\n                                       store=store,\n                                       df=df3,\n                                       feature_columns=[\'features\'],\n                                       label_columns=[\'y\']) as dataset_idx3:\n                    train_rows3, val_rows3, metadata3, avg_row_size3 = util.get_dataset_properties(dataset_idx3)\n                    assert train_rows == train_rows3\n                    assert val_rows == val_rows3\n                    assert metadata == metadata3\n                    assert avg_row_size == avg_row_size3\n                    assert dataset_idx3 == 0\n\n                # Same dataframe, different validation\n                bad_key = util._training_cache.create_key(df, store, 0.1)\n                assert not util._training_cache.is_cached(bad_key, store)\n\n    def test_get_col_info(self):\n        with spark_session(\'test_get_col_info\') as spark:\n            data = [[\n                0,\n                0.0,\n                None,\n                [1, 1],\n                DenseVector([1.0, 1.0]),\n                SparseVector(2, {1: 1.0}),\n                DenseVector([1.0, 1.0])\n            ], [\n                1,\n                None,\n                None,\n                [1, 1],\n                DenseVector([1.0, 1.0]),\n                SparseVector(2, {1: 1.0}),\n                SparseVector(2, {1: 1.0})\n            ]]\n\n            schema = StructType([\n                StructField(\'int\', IntegerType()),\n                StructField(\'float\', FloatType()),\n                StructField(\'null\', NullType()),\n                StructField(\'array\', ArrayType(IntegerType())),\n                StructField(\'dense\', VectorUDT()),\n                StructField(\'sparse\', VectorUDT()),\n                StructField(\'mixed\', VectorUDT())\n            ])\n\n            df = create_test_data_from_schema(spark, data, schema)\n            all_col_types, col_shapes, col_max_sizes = util._get_col_info(df)\n\n            expected = [\n                (\'int\', {int}, 1, 1),\n                (\'float\', {float, type(None)}, 1, 1),\n                (\'null\', {type(None)}, 1, 1),\n                (\'array\', {list}, 2, 2),\n                (\'dense\', {DenseVector}, 2, 2),\n                (\'sparse\', {SparseVector}, 2, 1),\n                (\'mixed\', {DenseVector, SparseVector}, 2, 2)\n            ]\n\n            for expected_col_info in expected:\n                col_name, col_types, col_shape, col_size = expected_col_info\n                assert all_col_types[col_name] == col_types, col_name\n                assert col_shapes[col_name] == col_shape, col_name\n                assert col_max_sizes[col_name] == col_size, col_name\n\n    def test_get_col_info_error_bad_shape(self):\n        with spark_session(\'test_get_col_info_error_bad_shape\') as spark:\n            data_bad_shape = [\n                [SparseVector(2, {0: 1.0})],\n                [SparseVector(1, {0: 1.0})]\n            ]\n            schema = StructType([StructField(\'data\', VectorUDT())])\n            df = create_test_data_from_schema(spark, data_bad_shape, schema)\n\n            with pytest.raises(ValueError):\n                util._get_col_info(df)\n\n    def test_get_col_info_error_bad_size(self):\n        with spark_session(\'test_get_col_info_error_bad_size\') as spark:\n            data_bad_size = [\n                [DenseVector([1.0, 1.0])],\n                [DenseVector([1.0])]\n            ]\n            schema = StructType([StructField(\'data\', VectorUDT())])\n            df = create_test_data_from_schema(spark, data_bad_size, schema)\n\n            with pytest.raises(ValueError):\n                util._get_col_info(df)\n\n    def test_train_val_split_ratio(self):\n        with spark_session(\'test_train_val_split_ratio\') as spark:\n            data = [\n                [1.0], [1.0], [1.0], [1.0], [1.0]\n            ]\n            schema = StructType([StructField(\'data\', FloatType())])\n            df = create_test_data_from_schema(spark, data, schema)\n\n            validation = 0.2\n            train_df, val_df, validation_ratio = util._train_val_split(df, validation)\n\n            # Only check validation ratio, as we can\'t rely on random splitting to produce an exact\n            # result of 4 training and 1 validation samples.\n            assert validation_ratio == validation\n\n    def test_train_val_split_col_integer(self):\n        with spark_session(\'test_train_val_split_col_integer\') as spark:\n            data = [\n                [1.0, 0], [1.0, 0], [1.0, 0], [1.0, 0], [1.0, 1]\n            ]\n            schema = StructType([StructField(\'data\', FloatType()), StructField(\'val\', IntegerType())])\n            df = create_test_data_from_schema(spark, data, schema)\n\n            validation = \'val\'\n            train_df, val_df, validation_ratio = util._train_val_split(df, validation)\n\n            # Only check counts as validation ratio cannot be guaranteed due to approx calculation\n            assert train_df.count() == 4\n            assert val_df.count() == 1\n\n    def test_train_val_split_col_boolean(self):\n        with spark_session(\'test_train_val_split_col_boolean\') as spark:\n            data = [\n                [1.0, False], [1.0, False], [1.0, False], [1.0, False], [1.0, True]\n            ]\n            schema = StructType([StructField(\'data\', FloatType()), StructField(\'val\', BooleanType())])\n            df = create_test_data_from_schema(spark, data, schema)\n\n            validation = \'val\'\n            train_df, val_df, validation_ratio = util._train_val_split(df, validation)\n\n            # Only check counts as validation ratio cannot be guaranteed due to approx calculation\n            assert train_df.count() == 4\n            assert val_df.count() == 1\n\n    def test_get_metadata(self):\n        expected_metadata = \\\n            {\n                \'float\': {\n                    \'spark_data_type\': FloatType,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n                \'dense\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.ARRAY,\n                    \'max_size\': 2,\n                    \'shape\': 2\n                },\n                \'sparse\': {\n                    \'spark_data_type\': SparseVector,\n                    \'is_sparse_vector_only\': True,\n                    \'intermediate_format\': constants.CUSTOM_SPARSE,\n                    \'max_size\': 1,\n                    \'shape\': 2\n                },\n                \'mixed\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.ARRAY,\n                    \'max_size\': 2,\n                    \'shape\': 2\n                },\n            }\n\n        with spark_session(\'test_get_metadata\') as spark:\n            data = [\n                [1.0, DenseVector([1.0, 1.0]), SparseVector(2, {0: 1.0}), DenseVector([1.0, 1.0])],\n                [1.0, DenseVector([1.0, 1.0]), SparseVector(2, {1: 1.0}), SparseVector(2, {1: 1.0})]\n            ]\n            schema = StructType([\n                StructField(\'float\', FloatType()),\n                StructField(\'dense\', VectorUDT()),\n                StructField(\'sparse\', VectorUDT()),\n                StructField(\'mixed\', VectorUDT())\n            ])\n            df = create_test_data_from_schema(spark, data, schema)\n\n            metadata = util._get_metadata(df)\n            self.assertDictEqual(metadata, expected_metadata)\n\n    def test_prepare_data_no_compression(self):\n        util.clear_training_cache()\n\n        expected_metadata = \\\n            {\n                \'float\': {\n                    \'spark_data_type\': DoubleType,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': None,\n                    \'shape\': None\n                },\n                \'dense\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': None,\n                    \'shape\': None\n                },\n                \'sparse\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': None,\n                    \'shape\': None\n                },\n                \'mixed\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': None,\n                    \'shape\': None\n                },\n            }\n\n        with mock.patch(\'horovod.spark.common.util._get_metadata\',\n                        side_effect=util._get_metadata) as mock_get_metadata:\n            with spark_session(\'test_prepare_data\') as spark:\n                data = [[\n                    0.0,\n                    DenseVector([1.0, 1.0]),\n                    SparseVector(2, {1: 1.0}),\n                    DenseVector([1.0, 1.0])\n                ], [\n                    1.0,\n                    DenseVector([1.0, 1.0]),\n                    SparseVector(2, {1: 1.0}),\n                    SparseVector(2, {1: 1.0})\n                ]]\n\n                schema = StructType([\n                    StructField(\'float\', FloatType()),\n                    StructField(\'dense\', VectorUDT()),\n                    StructField(\'sparse\', VectorUDT()),\n                    StructField(\'mixed\', VectorUDT())\n                ])\n\n                df = create_test_data_from_schema(spark, data, schema)\n\n                with local_store() as store:\n                    with util.prepare_data(num_processes=2,\n                                           store=store,\n                                           df=df,\n                                           feature_columns=[\'dense\', \'sparse\', \'mixed\'],\n                                           label_columns=[\'float\']) as dataset_idx:\n                        mock_get_metadata.assert_not_called()\n                        assert dataset_idx == 0\n\n                        train_rows, val_rows, metadata, avg_row_size = util.get_dataset_properties(dataset_idx)\n                        self.assertDictEqual(metadata, expected_metadata)\n\n    def test_prepare_data_compress_sparse(self):\n        util.clear_training_cache()\n\n        expected_metadata = \\\n            {\n                \'float\': {\n                    \'spark_data_type\': FloatType,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n                \'dense\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.ARRAY,\n                    \'max_size\': 2,\n                    \'shape\': 2\n                },\n                \'sparse\': {\n                    \'spark_data_type\': SparseVector,\n                    \'is_sparse_vector_only\': True,\n                    \'intermediate_format\': constants.CUSTOM_SPARSE,\n                    \'max_size\': 1,\n                    \'shape\': 2\n                },\n                \'mixed\': {\n                    \'spark_data_type\': DenseVector,\n                    \'is_sparse_vector_only\': False,\n                    \'intermediate_format\': constants.ARRAY,\n                    \'max_size\': 2,\n                    \'shape\': 2\n                },\n            }\n\n        with mock.patch(\'horovod.spark.common.util._get_metadata\',\n                        side_effect=util._get_metadata) as mock_get_metadata:\n            with spark_session(\'test_prepare_data\') as spark:\n                data = [[\n                    0.0,\n                    DenseVector([1.0, 1.0]),\n                    SparseVector(2, {1: 1.0}),\n                    DenseVector([1.0, 1.0])\n                ], [\n                    1.0,\n                    DenseVector([1.0, 1.0]),\n                    SparseVector(2, {1: 1.0}),\n                    SparseVector(2, {1: 1.0})\n                ]]\n\n                schema = StructType([\n                    StructField(\'float\', FloatType()),\n                    StructField(\'dense\', VectorUDT()),\n                    StructField(\'sparse\', VectorUDT()),\n                    StructField(\'mixed\', VectorUDT())\n                ])\n\n                df = create_test_data_from_schema(spark, data, schema)\n\n                with local_store() as store:\n                    with util.prepare_data(num_processes=2,\n                                           store=store,\n                                           df=df,\n                                           feature_columns=[\'dense\', \'sparse\', \'mixed\'],\n                                           label_columns=[\'float\'],\n                                           compress_sparse=True) as dataset_idx:\n                        mock_get_metadata.assert_called()\n                        assert dataset_idx == 0\n\n                        train_rows, val_rows, metadata, avg_row_size = util.get_dataset_properties(dataset_idx)\n                        self.assertDictEqual(metadata, expected_metadata)\n\n    def test_check_shape_compatibility(self):\n        feature_columns = [\'x1\', \'x2\', \'features\']\n        label_columns = [\'y1\', \'y_embedding\']\n\n        schema = StructType([StructField(\'x1\', DoubleType()),\n                             StructField(\'x2\', IntegerType()),\n                             StructField(\'features\', VectorUDT()),\n                             StructField(\'y1\', FloatType()),\n                             StructField(\'y_embedding\', VectorUDT())])\n        data = [[1.0, 1, DenseVector([1.0] * 12), 1.0, DenseVector([1.0] * 12)]] * 10\n\n        with spark_session(\'test_df_cache\') as spark:\n                df = create_test_data_from_schema(spark, data, schema)\n                metadata = util._get_metadata(df)\n\n                input_shapes = [[1], [1], [-1, 3, 4]]\n                output_shapes = [[1], [-1, 3, 4]]\n                util.check_shape_compatibility(metadata, feature_columns, label_columns,\n                                               input_shapes, output_shapes)\n\n                input_shapes = [[1], [1], [3, 2, 2]]\n                output_shapes = [[1, 1], [-1, 2, 3, 2]]\n                util.check_shape_compatibility(metadata, feature_columns, label_columns,\n                                               input_shapes, output_shapes)\n\n                bad_input_shapes = [[1], [1], [-1, 3, 5]]\n                with pytest.raises(ValueError):\n                    util.check_shape_compatibility(metadata, feature_columns, label_columns,\n                                                   bad_input_shapes, output_shapes)\n\n                bad_input_shapes = [[2], [1], [-1, 3, 4]]\n                with pytest.raises(ValueError):\n                    util.check_shape_compatibility(metadata, feature_columns, label_columns,\n                                                   bad_input_shapes, output_shapes)\n\n                bad_output_shapes = [[7], [-1, 3, 4]]\n                with pytest.raises(ValueError):\n                    util.check_shape_compatibility(metadata, feature_columns, label_columns,\n                                                   input_shapes, bad_output_shapes)\n\n    @mock.patch(\'horovod.spark.common.store.HDFSStore._get_filesystem_fn\')\n    def test_sync_hdfs_store(self, mock_get_fs_fn):\n        mock_fs = mock.Mock()\n        mock_get_fs_fn.return_value = lambda: mock_fs\n\n        hdfs_root = \'/user/test/output\'\n        store = HDFSStore(hdfs_root)\n\n        run_id = \'run_001\'\n        get_local_output_dir = store.get_local_output_dir_fn(run_id)\n        sync_to_store = store.sync_fn(run_id)\n        run_root = store.get_run_path(run_id)\n\n        def touch(fname, times=None):\n            with open(fname, \'a\'):\n                os.utime(fname, times)\n\n        with get_local_output_dir() as local_dir:\n            touch(os.path.join(local_dir, \'a.txt\'), (1330712280, 1330712280))\n            sync_to_store(local_dir)\n            mock_fs.upload.assert_called_with(os.path.join(run_root, \'a.txt\'), mock.ANY)\n\n            touch(os.path.join(local_dir, \'b.txt\'), (1330712280, 1330712280))\n            sync_to_store(local_dir)\n            mock_fs.upload.assert_called_with(os.path.join(run_root, \'b.txt\'), mock.ANY)\n\n            subdir = os.path.join(local_dir, \'subdir\')\n            os.mkdir(subdir)\n            touch(os.path.join(subdir, \'c.txt\'), (1330712280, 1330712280))\n            sync_to_store(local_dir)\n            mock_fs.upload.assert_called_with(os.path.join(run_root, \'subdir/c.txt\'), mock.ANY)\n\n            touch(os.path.join(local_dir, \'a.txt\'), (1330712292, 1330712292))\n            touch(os.path.join(local_dir, \'b.txt\'), (1330712292, 1330712292))\n            assert mock_fs.upload.call_count == 3\n\n            sync_to_store(local_dir)\n            assert mock_fs.upload.call_count == 5\n\n    @mock.patch(\'horovod.spark.common.store.HDFSStore._get_filesystem_fn\')\n    def test_hdfs_store_parse_url(self, mock_get_filesystem_fn):\n        # Case 1: full path\n        hdfs_root = \'hdfs://namenode01:8020/user/test/output\'\n        store = HDFSStore(hdfs_root)\n        assert store.path_prefix() == \'hdfs://namenode01:8020\', hdfs_root\n        assert store.get_full_path(\'/user/test/output\') == \'hdfs://namenode01:8020/user/test/output\', hdfs_root\n        assert store.get_localized_path(\'hdfs://namenode01:8020/user/test/output\') == \'/user/test/output\', hdfs_root\n        assert store._hdfs_kwargs[\'host\'] == \'namenode01\', hdfs_root\n        assert store._hdfs_kwargs[\'port\'] == 8020, hdfs_root\n\n        # Case 2: no host and port\n        hdfs_root = \'hdfs:///user/test/output\'\n        store = HDFSStore(hdfs_root)\n        assert store.path_prefix() == \'hdfs://\', hdfs_root\n        assert store.get_full_path(\'/user/test/output\') == \'hdfs:///user/test/output\', hdfs_root\n        assert store.get_localized_path(\'hdfs:///user/test/output\') == \'/user/test/output\', hdfs_root\n        assert store._hdfs_kwargs[\'host\'] == \'default\', hdfs_root\n        assert store._hdfs_kwargs[\'port\'] == 0, hdfs_root\n\n        # Case 3: no prefix\n        hdfs_root = \'/user/test/output\'\n        store = HDFSStore(hdfs_root)\n        assert store.path_prefix() == \'hdfs://\', hdfs_root\n        assert store.get_full_path(\'/user/test/output\') == \'hdfs:///user/test/output\', hdfs_root\n        assert store.get_localized_path(\'hdfs:///user/test/output\') == \'/user/test/output\', hdfs_root\n        assert store._hdfs_kwargs[\'host\'] == \'default\', hdfs_root\n        assert store._hdfs_kwargs[\'port\'] == 0, hdfs_root\n\n        # Case 4: no namespace\n        hdfs_root = \'hdfs://namenode01:8020/user/test/output\'\n        store = HDFSStore(hdfs_root)\n        assert store.path_prefix() == \'hdfs://namenode01:8020\', hdfs_root\n        assert store.get_full_path(\'/user/test/output\') == \'hdfs://namenode01:8020/user/test/output\', hdfs_root\n        assert store.get_localized_path(\'hdfs://namenode01:8020/user/test/output\') == \'/user/test/output\', hdfs_root\n        assert store._hdfs_kwargs[\'host\'] == \'namenode01\', hdfs_root\n        assert store._hdfs_kwargs[\'port\'] == 8020, hdfs_root\n\n        # Case 5: bad prefix\n        with pytest.raises(ValueError):\n            hdfs_root = \'file:///user/test/output\'\n            HDFSStore(hdfs_root)\n\n        # Case 6: override paths, no prefix\n        hdfs_root = \'/user/prefix\'\n        store = HDFSStore(hdfs_root,\n                          train_path=\'/user/train_path\',\n                          val_path=\'/user/val_path\',\n                          test_path=\'/user/test_path\')\n        assert store.get_train_data_path() == \'hdfs:///user/train_path\', hdfs_root\n        assert store.get_val_data_path() == \'hdfs:///user/val_path\', hdfs_root\n        assert store.get_test_data_path() == \'hdfs:///user/test_path\', hdfs_root\n\n        # Case 7: override paths, prefix\n        hdfs_root = \'hdfs:///user/prefix\'\n        store = HDFSStore(hdfs_root,\n                          train_path=\'hdfs:///user/train_path\',\n                          val_path=\'hdfs:///user/val_path\',\n                          test_path=\'hdfs:///user/test_path\')\n        assert store.get_train_data_path() == \'hdfs:///user/train_path\', hdfs_root\n        assert store.get_val_data_path() == \'hdfs:///user/val_path\', hdfs_root\n        assert store.get_test_data_path() == \'hdfs:///user/test_path\', hdfs_root\n\n    def test_spark_task_service_env(self):\n        key = secret.make_secret_key()\n        service_env = {\n            \'HADOOP_TOKEN_FILE_LOCATION\': \'path\',\n            \'PYTHONPATH\': \'pypath\',\n            \'other\': \'values\'\n        }\n        with override_env(service_env):\n            service = SparkTaskService(1, key, None)\n            client = SparkTaskClient(1, service.addresses(), key, 3)\n\n            with tempdir() as d:\n                file = \'{}/env\'.format(d)\n                command = ""env | grep -v \'^PWD=\'> {}"".format(file)\n                command_env = {""test"": ""value""}\n\n                try:\n                    client.run_command(command, command_env)\n                    client.wait_for_command_termination()\n                finally:\n                    service.shutdown()\n\n                with open(file) as f:\n                    env = sorted([line.strip() for line in f.readlines()])\n                    expected = [\n                        \'HADOOP_TOKEN_FILE_LOCATION=path\',\n                        \'HOROVOD_SPARK_WORK_DIR={cwd}\'.format(cwd=os.getcwd()),\n                        \'PYTHONPATH=pypath\',\n                        \'{}={}\'.format(secret.HOROVOD_SECRET_KEY, codec.dumps_base64(key)),\n                        \'other=values\',\n                        \'test=value\'\n                    ]\n                    self.assertEqual(expected, env)\n\n    @pytest.mark.skipif(LooseVersion(pyspark.__version__) < LooseVersion(\'3.0.0\'),\n                        reason=\'get_available_devices only supported in Spark 3.0 and above\')\n    def test_get_available_devices(self):\n        def fn():\n            hvd.init()\n            devices = get_available_devices()\n            return devices, hvd.local_rank()\n\n        with spark_session(\'test_get_available_devices\', gpus=2):\n            res = horovod.spark.run(fn, env={\'PATH\': os.environ.get(\'PATH\')}, verbose=0)\n            self.assertListEqual([([\'0\'], 0), ([\'1\'], 1)], res)\n\n    def test_to_list(self):\n        none_output = util.to_list(None, 1)\n        assert none_output is none_output\n\n        out1 = util.to_list(\'one_item\', 1)\n        assert out1 == [\'one_item\']\n\n        out2 = util.to_list(\'one_item\', 2)\n        assert out2 == [\'one_item\', \'one_item\']\n\n        out3 = util.to_list([\'one_item\'], 1)\n        assert out3 == [\'one_item\']\n\n        out4 = util.to_list([\'item1\', \'item2\'], 2)\n        assert out4 == [\'item1\', \'item2\']\n\n        with pytest.raises(ValueError):\n            util.to_list([\'item1\', \'item2\'], 4)\n'"
test/test_spark_keras.py,33,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport collections\nimport warnings\n\nimport mock\nimport numpy as np\nimport tensorflow as tf\n\nimport pyspark.sql.types as T\nfrom pyspark.ml.linalg import DenseVector, SparseVector\nfrom pyspark.sql.functions import udf\n\nimport horovod.spark.keras as hvd\nfrom horovod.spark.common import constants, util\nfrom horovod.spark.keras import remote\nfrom horovod.spark.keras.estimator import EstimatorParams\nfrom horovod.spark.keras.util import _custom_sparse_to_dense_fn, _serialize_param_value, BareKerasUtil, TFKerasUtil\n\nfrom common import temppath\nfrom spark_common import CallbackBackend, create_mnist_data, create_xor_data, local_store, spark_session\n\n\ndef create_xor_model():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(8, input_dim=2))\n    model.add(tf.keras.layers.Activation(\'tanh\'))\n    model.add(tf.keras.layers.Dense(1))\n    model.add(tf.keras.layers.Activation(\'sigmoid\'))\n    return model\n\n\ndef create_mnist_model():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n                                     activation=\'relu\',\n                                     input_shape=(8, 8, 1)))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(tf.keras.layers.Dropout(0.25))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(10, activation=\'softmax\'))\n    return model\n\n\ndef get_mock_fit_fn():\n    def fit(model, train_data, val_data, steps_per_epoch, validation_steps, callbacks, verbose):\n        for callback in callbacks:\n            callback.set_model(model)\n            callback.on_epoch_end(0, logs={})\n        return mock.Mock()\n    return fit\n\n\nclass SparkKerasTests(tf.test.TestCase):\n    def __init__(self, *args, **kwargs):\n        super(SparkKerasTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_fit_model(self):\n        model = create_xor_model()\n        optimizer = tf.keras.optimizers.SGD(lr=0.1)\n        loss = \'binary_crossentropy\'\n\n        with spark_session(\'test_fit_model\') as spark:\n            df = create_xor_data(spark)\n\n            with local_store() as store:\n                keras_estimator = hvd.KerasEstimator(\n                    num_proc=2,\n                    store=store,\n                    model=model,\n                    optimizer=optimizer,\n                    loss=loss,\n                    feature_cols=[\'features\'],\n                    label_cols=[\'y\'],\n                    batch_size=1,\n                    epochs=3,\n                    verbose=2)\n\n                keras_model = keras_estimator.fit(df)\n\n                trained_model = keras_model.getModel()\n                pred = trained_model.predict([np.ones([1, 2], dtype=np.float32)])\n                assert len(pred) == 1\n                assert pred.dtype == np.float32\n\n    def test_fit_model_multiclass(self):\n        model = create_mnist_model()\n        optimizer = tf.keras.optimizers.Adadelta(1.0)\n        loss = tf.keras.losses.categorical_crossentropy\n\n        for num_cores in [2, constants.TOTAL_BUFFER_MEMORY_CAP_GIB + 1]:\n            with spark_session(\'test_fit_model_multiclass\', cores=num_cores) as spark:\n                df = create_mnist_data(spark)\n\n                with local_store() as store:\n                    keras_estimator = hvd.KerasEstimator(\n                        num_proc=num_cores,\n                        store=store,\n                        model=model,\n                        optimizer=optimizer,\n                        loss=loss,\n                        metrics=[\'accuracy\'],\n                        feature_cols=[\'features\'],\n                        label_cols=[\'label_vec\'],\n                        batch_size=2,\n                        epochs=2,\n                        verbose=2)\n\n                    keras_model = keras_estimator.fit(df).setOutputCols([\'label_prob\'])\n                    pred_df = keras_model.transform(df)\n\n                    argmax = udf(lambda v: float(np.argmax(v)), returnType=T.DoubleType())\n                    pred_df = pred_df.withColumn(\'label_pred\', argmax(pred_df.label_prob))\n\n                    preds = pred_df.collect()\n                    assert len(preds) == df.count()\n\n                    row = preds[0]\n                    label_prob = row.label_prob.toArray().tolist()\n                    assert label_prob[int(row.label_pred)] == max(label_prob)\n\n    @mock.patch(\'horovod.spark.keras.remote._pin_gpu_fn\')\n    @mock.patch(\'horovod.spark.keras.util.TFKerasUtil.fit_fn\')\n    def test_restore_from_checkpoint(self, mock_fit_fn, mock_pin_gpu_fn):\n        mock_fit_fn.return_value = get_mock_fit_fn()\n        mock_pin_gpu_fn.return_value = mock.Mock()\n\n        model = create_xor_model()\n        optimizer = tf.keras.optimizers.SGD(lr=0.1)\n        loss = \'binary_crossentropy\'\n\n        with spark_session(\'test_restore_from_checkpoint\') as spark:\n            df = create_xor_data(spark)\n\n            backend = CallbackBackend()\n\n            run_id = \'run01\'\n            with local_store() as store:\n                keras_estimator = hvd.KerasEstimator(\n                    backend=backend,\n                    store=store,\n                    model=model,\n                    optimizer=optimizer,\n                    loss=loss,\n                    feature_cols=[\'features\'],\n                    label_cols=[\'y\'],\n                    batch_size=1,\n                    epochs=3,\n                    verbose=2,\n                    run_id=run_id)\n\n                keras_estimator._load_model_from_checkpoint = mock.Mock(\n                    side_effect=keras_estimator._load_model_from_checkpoint)\n\n                ckpt_path = store.get_checkpoint_path(run_id)\n                assert not store.exists(ckpt_path)\n                keras_estimator._load_model_from_checkpoint.assert_not_called()\n                keras_model = keras_estimator.fit(df)\n\n                trained_model = keras_model.getModel()\n                pred = trained_model.predict([np.ones([1, 2], dtype=np.float64)])\n                assert len(pred) == 1\n\n                assert store.exists(ckpt_path)\n\n                keras_estimator.fit(df)\n                keras_estimator._load_model_from_checkpoint.assert_called()\n\n    @mock.patch(\'horovod.spark.keras.remote._pin_gpu_fn\')\n    @mock.patch(\'horovod.spark.keras.util.TFKerasUtil.fit_fn\')\n    def test_keras_direct_parquet_train(self, mock_fit_fn, mock_pin_gpu_fn):\n        mock_fit_fn.return_value = get_mock_fit_fn()\n        mock_pin_gpu_fn.return_value = mock.Mock()\n\n        with spark_session(\'test_keras_direct_parquet_train\') as spark:\n            df = create_xor_data(spark)\n\n            backend = CallbackBackend()\n            with local_store() as store:\n                store.get_train_data_path = lambda v=None: store._train_path\n                store.get_val_data_path = lambda v=None: store._val_path\n\n                with util.prepare_data(backend.num_processes(),\n                                       store,\n                                       df,\n                                       feature_columns=[\'features\'],\n                                       label_columns=[\'y\']):\n                    model = create_xor_model()\n                    optimizer = tf.keras.optimizers.SGD(lr=0.1)\n                    loss = \'binary_crossentropy\'\n\n                    est = hvd.KerasEstimator(\n                        backend=backend,\n                        store=store,\n                        model=model,\n                        optimizer=optimizer,\n                        loss=loss,\n                        feature_cols=[\'features\'],\n                        label_cols=[\'y\'],\n                        batch_size=1,\n                        epochs=3,\n                        verbose=2)\n\n                    transformer = est.fit_on_parquet()\n                    predictions = transformer.transform(df)\n                assert predictions.count() == df.count()\n\n    @mock.patch(\'horovod.spark.keras.estimator.remote.RemoteTrainer\')\n    def test_model_serialization(self, mock_remote_trainer):\n        model = create_xor_model()\n        optimizer = tf.keras.optimizers.SGD(lr=0.1)\n        loss = \'binary_crossentropy\'\n\n        def train(serialized_model, train_rows, val_rows, avg_row_size):\n            return None, serialized_model, 2\n        mock_remote_trainer.return_value = train\n\n        with spark_session(\'test_model_serialization\') as spark:\n            df = create_xor_data(spark)\n\n            keras_estimator = hvd.KerasEstimator(\n                model=model,\n                optimizer=optimizer,\n                loss=loss,\n                feature_cols=[\'features\'],\n                label_cols=[\'y\'],\n                batch_size=1,\n                epochs=3,\n                verbose=2)\n\n            backend = CallbackBackend()\n            with local_store() as store:\n                with temppath() as saved_path:\n                    keras_estimator.save(saved_path)\n                    keras_estimator_loaded = hvd.KerasEstimator.load(saved_path)\n\n                keras_model = keras_estimator_loaded.fit(df, params={\n                    keras_estimator_loaded.backend: backend,\n                    keras_estimator_loaded.store: store\n                })\n\n                trained_model = keras_model.getModel()\n                pred = trained_model.predict([np.ones([1, 2], dtype=np.float32)])\n                assert len(pred) == 1\n                assert pred.dtype == np.float32\n\n    def test_serialize_param_value(self):\n        serialized_backend = _serialize_param_value(EstimatorParams.backend.name, \'dummy_value\', None, None)\n        assert serialized_backend is None\n\n        serialized_store = _serialize_param_value(EstimatorParams.store.name, \'dummy_value\', None, None)\n        assert serialized_store is None\n\n        serialized_dummy_param = _serialize_param_value(\'dummy_param_name\', None, None, None)\n        assert serialized_dummy_param is None\n\n    def test_calculate_shuffle_buffer_size_small_row_size(self):\n        hvd_size = 4\n        local_size = 2\n        hvd_mock = mock.MagicMock()\n        hvd_mock.local_size.return_value = local_size\n        hvd_mock.allgather.return_value = [local_size for _ in range(hvd_size)]\n\n        avg_row_size = 100\n        train_row_count_per_worker = 100\n\n        calculate_shuffle_buffer_size = remote._calculate_shuffle_buffer_size_fn()\n        shuffle_size = calculate_shuffle_buffer_size(hvd_mock, avg_row_size, train_row_count_per_worker)\n        assert shuffle_size == train_row_count_per_worker\n\n    def test_calculate_shuffle_buffer_size(self):\n        # case with 2 workers, one with 5 ranks and second with 3 ranks\n        hvd_mock = mock.MagicMock()\n        hvd_mock.allgather.return_value = [5, 5, 5, 5, 5, 3, 3, 3]\n        hvd_mock.local_size.return_value = 2\n\n        avg_row_size = 100000\n        train_row_count_per_worker = 1000000\n\n        calculate_shuffle_buffer_size = remote._calculate_shuffle_buffer_size_fn()\n        shuffle_size = calculate_shuffle_buffer_size(hvd_mock, avg_row_size, train_row_count_per_worker)\n\n        assert int(shuffle_size) == int(constants.TOTAL_BUFFER_MEMORY_CAP_GIB * constants.BYTES_PER_GIB / avg_row_size / 5)\n\n    def test_custom_sparse_to_dense_fn(self):\n        dense_shape = 10\n        custom_sparse_to_dense = _custom_sparse_to_dense_fn()\n        dense_vector = tf.constant([3., 1., 3., 6., 10., 30., 60., 0, 0, 0])\n        sparse_vector = custom_sparse_to_dense(dense_vector, dense_shape)\n        sparse_vector_values = self.evaluate(sparse_vector)[0]\n        assert sparse_vector_values[1] == 10\n        assert sparse_vector_values[3] == 30\n        assert sparse_vector_values[6] == 60\n        assert len(sparse_vector_values) == dense_shape\n\n    def test_convert_custom_sparse_to_dense_bare_keras_fn(self):\n        convert_custom_sparse_to_dense_bare_keras = BareKerasUtil._convert_custom_sparse_to_dense_fn()\n        custom_sparse_row = np.array([2, 1, 2, 0.1, 0.2])\n        sparse_row = convert_custom_sparse_to_dense_bare_keras(custom_sparse_row, 4)\n        assert np.array_equal(sparse_row, np.array([0., 0.1, 0.2, 0.]))\n\n    def test_prepare_data_bare_keras_fn(self):\n        metadata = \\\n            {\n                \'col1\': {\n                    \'dtype\': float,\n                    \'intermediate_format\': \'nochange\',\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n                \'col2\': {\n                    \'dtype\': \'float\',\n                    \'intermediate_format\': \'nochange\',\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n                \'col3\': {\n                    \'dtype\': SparseVector,\n                    \'intermediate_format\': \'custom_sparse_format\',\n                    \'max_size\': 7,\n                    \'shape\': 10\n                }\n            }\n        prepare_data_bare_keras = BareKerasUtil._prepare_data_fn(metadata)\n\n        col1 = np.array([1., 2., 3.])\n        col1_prepared = prepare_data_bare_keras(col1, \'col1\', [-1, 3])\n        assert col1_prepared.shape == (1, 3)\n        assert np.array_equal(col1_prepared, np.array([[1., 2., 3.]]))\n\n        col3 = [np.array([3., 0., 2., 5., 0., 0.2, 0.5, 0, 0]),\n                np.array([4., 0., 2., 5., 6., 0.2, 0.5, 0.6, 0])]\n\n        col3_prepared = prepare_data_bare_keras(col3, \'col3\', [-1, 10])\n\n        assert col3_prepared.shape == (2, 10)\n        assert np.array_equal(col3_prepared, np.array(\n            [[0., 0., 0.2, 0., 0., 0.5, 0., 0., 0., 0.], [0.2, 0., 0.5, 0., 0., 0.6, 0., 0., 0., 0.]]))\n\n    def test_batch_generator_fn(self):\n        shuffle_buffer_size = 10\n        rows_in_row_group = 100\n        batch_size = 32\n\n        def _create_numpy_array(n_rows, shape):\n            return np.array([[i for i in range(j, j + shape)] for j in range(n_rows)])\n\n        def dummy_reader():\n            Row = collections.namedtuple(\'row\', [\'col1\', \'col2\', \'sample_weight\', \'label\'])\n\n            col11 = _create_numpy_array(rows_in_row_group, 1)\n            col21 = _create_numpy_array(rows_in_row_group, 10)\n            label1 = _create_numpy_array(rows_in_row_group, 8)\n            sw1 = np.array([i / 100. for i in range(rows_in_row_group)])\n\n            row1 = Row(col1=col11, col2=col21, label=label1, sample_weight=sw1)\n\n            col12 = _create_numpy_array(rows_in_row_group, 1)\n            col22 = _create_numpy_array(rows_in_row_group, 10)\n            label2 = _create_numpy_array(rows_in_row_group, 8)\n            sw2 = np.array([i / 100. for i in range(rows_in_row_group)])\n            row2 = Row(col1=col12, col2=col22, label=label2, sample_weight=sw2)\n\n            while True:\n                yield row1\n                yield row2\n\n        metadata = \\\n            {\n                \'col1\': {\n                    \'dtype\': float,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n                \'col2\': {\n                    \'dtype\': DenseVector,\n                    \'intermediate_format\': constants.ARRAY,\n                    \'max_size\': 10,\n                    \'shape\': 10\n                },\n                \'label\': {\n                    \'dtype\': float,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n            }\n\n        reader = dummy_reader()\n\n        feature_columns = [\'col1\', \'col2\']\n        label_columns = [\'label\']\n        sample_weight_col = \'sample_weight\'\n\n        input_shapes = [[-1, 1], [-1, 2, 5]]\n        output_shapes = [[-1, 2, 4]]\n\n        batch_generator = BareKerasUtil._batch_generator_fn(\n            feature_columns, label_columns, sample_weight_col,\n            input_shapes, output_shapes, batch_size, metadata)\n\n        for shuffle in [True, False]:\n            batch_gen = batch_generator(reader, shuffle_buffer_size, shuffle=shuffle)\n\n            for _ in range(10):\n                batch = next(batch_gen)\n                assert batch[0][0][0].shape == (1,)\n                assert batch[0][1][0].shape == (2, 5)\n                assert batch[1][0][0].shape == (2, 4)\n                # sample weight has to be a singel np array with shape (batch_size,)\n                assert batch[2][0].shape == (batch_size,)\n\n    def test_reshape(self):\n        metadata = \\\n            {\n                \'col1\': {\n                    \'dtype\': float,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n                \'col2\': {\n                    \'dtype\': SparseVector,\n                    \'intermediate_format\': constants.CUSTOM_SPARSE,\n                    \'max_size\': 5,\n                    \'shape\': 10\n                },\n                \'label\': {\n                    \'dtype\': float,\n                    \'intermediate_format\': constants.NOCHANGE,\n                    \'max_size\': 1,\n                    \'shape\': 1\n                },\n            }\n\n        feature_columns = [\'col1\', \'col2\']\n        label_columns = [\'label\']\n        sample_weight_col = \'sample_weight\'\n\n        Row = collections.namedtuple(\'row\', [\'col1\', \'col2\', \'sample_weight\', \'label\'])\n\n        col11 = tf.constant([3.])\n        col21 = tf.constant([3., 1., 3., 6., 10., 30., 60., 0, 0, 0, 0])\n        label1 = tf.constant([1.])\n        sw1 = tf.constant([.06])\n        row1 = Row(col1=col11, col2=col21, label=label1, sample_weight=sw1)\n\n        reshape_fn = TFKerasUtil._reshape_fn(\n            sample_weight_col, feature_columns, label_columns, metadata)\n\n        reshaped_row = reshape_fn(row1)\n        reshaped_row_value = self.evaluate(reshaped_row)\n\n        assert np.allclose(reshaped_row_value[\'sample_weight\'], np.array([0.06]))\n        assert np.allclose(reshaped_row_value[\'col1\'], np.array([3.]))\n        assert np.allclose(reshaped_row_value[\'col2\'],\n                           np.array([[0., 10., 0., 30., 0., 0., 60., 0., 0., 0.]]))\n        assert np.allclose(reshaped_row_value[\'label\'], np.array([1.]))\n\n    def test_prep_data_tf_keras_fn_with_sparse_col(self):\n        has_sparse_col = True\n\n        feature_columns = [\'col1\', \'col2\']\n        label_columns = [\'label1\', \'label2\']\n        sample_weight_col = \'sample_weight\'\n\n        col1 = tf.constant([3.])\n        col2 = tf.constant([3., 1., 3., 6., 10., 30., 60., 0, 0, 0])\n        label1 = tf.constant([1., 2., 3., 4.])\n        label2 = tf.constant([1., 2., 3., 4.])\n        sw1 = tf.constant([.06])\n\n        input_shapes = [[-1, 1], [-1, 2, 5]]\n        output_shapes = [[-1, 4], [-1, 2, 2]]\n        output_names = [\'label1\', \'label2\']\n\n        prep_data_tf_keras = \\\n            TFKerasUtil._prep_data_fn(has_sparse_col, sample_weight_col,\n                                      feature_columns, label_columns, input_shapes,\n                                      output_shapes, output_names)\n\n        row = {\'col1\': col1, \'col2\': col2, \'label1\': label1, \'label2\': label2, sample_weight_col: sw1}\n\n        prepped_row = prep_data_tf_keras(row)\n        prepped_row_vals = self.evaluate(prepped_row)\n\n        assert np.array_equal(prepped_row_vals[0][0], np.array([[3.]]))\n        assert np.array_equal(prepped_row_vals[0][1],\n                              np.array([[[3., 1., 3., 6., 10.], [30., 60., 0., 0., 0.]]]))\n\n        assert np.array_equal(prepped_row_vals[1][0], np.array([[1., 2., 3., 4.]]))\n        assert np.array_equal(prepped_row_vals[1][1], np.array([[[1., 2.], [3., 4.]]]))\n\n        assert np.allclose(prepped_row_vals[2][\'label1\'], np.array([0.06]))\n        assert np.allclose(prepped_row_vals[2][\'label2\'], np.array([0.06]))\n\n    def test_prep_data_tf_keras_fn_without_sparse_col(self):\n        has_sparse_col = False\n\n        feature_columns = [\'col1\', \'col2\']\n        label_columns = [\'label1\', \'label2\']\n        sample_weight_col = \'sample_weight\'\n\n        col1 = tf.constant([3.])\n        col2 = tf.constant([float(i) for i in range(10)])\n        label1 = tf.constant([1., 2., 3., 4.])\n        label2 = tf.constant([1., 2., 3., 4.])\n        sw1 = tf.constant([.06])\n\n        input_shapes = [[-1, 1], [-1, 2, 5]]\n        output_shapes = [[-1, 4], [-1, 2, 2]]\n        output_names = [\'label1\', \'label2\']\n\n        prep_data_tf_keras = \\\n            TFKerasUtil._prep_data_fn(has_sparse_col, sample_weight_col,\n                                      feature_columns, label_columns, input_shapes,\n                                      output_shapes, output_names)\n\n        Row = collections.namedtuple(\'row\', [\'col1\', \'col2\', sample_weight_col, \'label1\', \'label2\'])\n        row = Row(col1=col1, col2=col2, label1=label1, label2=label2, sample_weight=sw1)\n\n        prepped_row = prep_data_tf_keras(row)\n        prepped_row_vals = self.evaluate(prepped_row)\n\n        assert np.array_equal(prepped_row_vals[0][0], np.array([[3.]]))\n        assert np.array_equal(prepped_row_vals[0][1],\n                              np.array([[[0., 1., 2., 3., 4.], [5., 6., 7., 8., 9.]]]))\n\n        assert np.array_equal(prepped_row_vals[1][0], np.array([[1., 2., 3., 4.]]))\n        assert np.array_equal(prepped_row_vals[1][1], np.array([[[1., 2.], [3., 4.]]]))\n\n        assert np.allclose(prepped_row_vals[2][\'label1\'], np.array([0.06]))\n        assert np.allclose(prepped_row_vals[2][\'label2\'], np.array([0.06]))\n'"
test/test_spark_torch.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport unittest\nimport warnings\n\nimport numpy as np\n\nfrom pyspark.ml.linalg import VectorUDT\nfrom pyspark.sql.types import DoubleType, LongType\n\nimport mock\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\n\nimport horovod.spark.torch as hvd\nfrom horovod.spark.common import constants, util\nfrom horovod.spark.torch import remote\nfrom horovod.spark.torch.estimator import EstimatorParams, _torch_param_serialize\n\nfrom spark_common import CallbackBackend, create_xor_data, local_store, spark_session\n\n\nclass XOR(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(XOR, self).__init__()\n        self.lin1 = nn.Linear(input_dim, 8)\n        self.lin2 = nn.Linear(8, output_dim)\n\n    def forward(self, features):\n        x = features.float()\n        x = self.lin1(x)\n        x = torch.tanh(x)\n        x = self.lin2(x)\n        x = torch.sigmoid(x)\n        return x\n\n\ndef create_xor_model(input_dim=2, output_dim=1):\n    return XOR(input_dim, output_dim)\n\n\nclass SparkTorchTests(unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        super(SparkTorchTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_fit_model(self):\n        model = create_xor_model()\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n        loss = F.binary_cross_entropy\n\n        with spark_session(\'test_fit_model\') as spark:\n            df = create_xor_data(spark)\n\n            with local_store() as store:\n                torch_estimator = hvd.TorchEstimator(\n                    num_proc=2,\n                    store=store,\n                    model=model,\n                    optimizer=optimizer,\n                    loss=loss,\n                    input_shapes=[[2]],\n                    feature_cols=[\'features\'],\n                    label_cols=[\'y\'],\n                    batch_size=1,\n                    epochs=3,\n                    verbose=2,\n                    sample_weight_col=\'weight\')\n\n                torch_model = torch_estimator.fit(df)\n\n                trained_model = torch_model.getModel()\n                pred = trained_model(torch.ones([1, 2], dtype=torch.int32))\n                assert len(pred) == 1\n                assert pred.dtype == torch.float32\n\n    def test_restore_from_checkpoint(self):\n        model = create_xor_model()\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n        loss = nn.BCELoss()\n\n        with spark_session(\'test_restore_from_checkpoint\') as spark:\n            df = create_xor_data(spark)\n\n            ctx = CallbackBackend()\n\n            run_id = \'run01\'\n            with local_store() as store:\n                torch_estimator = hvd.TorchEstimator(\n                    backend=ctx,\n                    store=store,\n                    model=model,\n                    optimizer=optimizer,\n                    loss=loss,\n                    input_shapes=[[2]],\n                    feature_cols=[\'features\'],\n                    label_cols=[\'y\'],\n                    batch_size=1,\n                    epochs=1,\n                    verbose=2,\n                    run_id=run_id)\n\n                torch_estimator._load_checkpoint = mock.Mock(side_effect=torch_estimator._load_checkpoint)\n\n                ckpt_path = store.get_checkpoint_path(run_id)\n                assert not store.exists(ckpt_path)\n                torch_estimator._load_checkpoint.assert_not_called()\n                torch_estimator.fit(df)\n\n                assert store.exists(ckpt_path)\n                torch_estimator.fit(df)\n                torch_estimator._load_checkpoint.assert_called()\n\n    def test_transform_multi_class(self):\n        model = create_xor_model(output_dim=2)\n\n        with spark_session(\'test_transform_multi_class\') as spark:\n            df = create_xor_data(spark)\n            metadata = util._get_metadata(df)\n\n            torch_model = hvd.TorchModel(history=None,\n                                         model=model,\n                                         input_shapes=[[2]],\n                                         feature_columns=[\'features\'],\n                                         label_columns=[\'y\'],\n                                         _metadata=metadata)\n            out_df = torch_model.transform(df)\n\n            expected_types = {\n                \'x1\': LongType,\n                \'x2\': LongType,\n                \'features\': VectorUDT,\n                \'weight\': DoubleType,\n                \'y\': DoubleType,\n                \'y__output\': VectorUDT\n            }\n\n            for field in out_df.schema.fields:\n                assert type(field.dataType) == expected_types[field.name]\n\n    def test_pytorch_get_optimizer_with_unscaled_lr(self):\n        hvd_size = 4\n        init_learning_rate = 0.001\n        hvd_mock = mock.MagicMock()\n        hvd_mock.size.return_value = hvd_size\n\n        get_optimizer_with_unscaled_lr_fn = remote._get_optimizer_with_unscaled_lr_fn()\n        model = create_xor_model()\n        current_optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n        optimizer_cls = current_optimizer.__class__\n        opt_unscaled_lr = get_optimizer_with_unscaled_lr_fn(hvd_mock, current_optimizer,\n                                                            optimizer_cls, model)\n\n        optimizer_state = opt_unscaled_lr.state_dict()\n        for i in range(len(optimizer_state[\'param_groups\'])):\n            assert optimizer_state[\'param_groups\'][i][\'lr\'] == init_learning_rate / hvd_size\n\n    def test_calculate_shuffle_buffer_size_small_row_size(self):\n        hvd_size = 4\n        local_size = 2\n        hvd_mock = mock.MagicMock()\n        hvd_mock.local_size = lambda: local_size\n        hvd_mock.allgather = lambda x: torch.tensor([local_size for _ in range(hvd_size)])\n\n        avg_row_size = 100\n        train_row_count_per_worker = 100\n\n        calculate_shuffle_buffer_size = remote._calculate_shuffle_buffer_size_fn()\n        shuffle_size = calculate_shuffle_buffer_size(hvd_mock, avg_row_size, train_row_count_per_worker)\n        assert shuffle_size == train_row_count_per_worker\n\n    def test_calculate_shuffle_buffer_size(self):\n        # case with 2 workers, one with 5 ranks and second with 3 ranks\n        hvd_mock = mock.MagicMock()\n        hvd_mock.allgather = lambda x: torch.tensor([5, 5, 5, 5, 5, 3, 3, 3])\n        hvd_mock.local_size = lambda: 2\n\n        avg_row_size = 100000\n        train_row_count_per_worker = 1000000\n\n        calculate_shuffle_buffer_size = remote._calculate_shuffle_buffer_size_fn()\n        shuffle_size = calculate_shuffle_buffer_size(hvd_mock, avg_row_size, train_row_count_per_worker)\n\n        assert int(shuffle_size) == \\\n               int(constants.TOTAL_BUFFER_MEMORY_CAP_GIB * constants.BYTES_PER_GIB / avg_row_size / 5)\n\n    def test_metric_class(self):\n        hvd_mock = mock.MagicMock()\n        hvd_mock.allreduce = lambda tensor, name: 2 * tensor\n        hvd_mock.local_size = lambda: 2\n\n        metric_class = remote._metric_cls()\n        metric = metric_class(\'dummy_metric\', hvd_mock)\n        metric.update(torch.tensor(1.0))\n        metric.update(torch.tensor(2.0))\n\n        assert metric.sum.item() == 6.0\n        assert metric.n.item() == 2.0\n        assert metric.avg.item() == 6.0 / 2.0\n\n    def test_construct_metric_value_holders_one_metric_for_all_labels(self):\n        hvd_mock = mock.MagicMock()\n        hvd_mock.allreduce = lambda tensor, name: 2 * tensor\n        hvd_mock.local_size = lambda: 2\n        metric_class = remote._metric_cls()\n\n        def torch_dummy_metric(outputs, labels):\n            count = torch.tensor(0.)\n            for output, label in zip(outputs, labels):\n                count += 1\n            return count\n\n        metric_fn_groups = [[torch_dummy_metric], [torch_dummy_metric]]\n        label_columns = [\'l1\', \'l2\']\n\n        construct_metric_value_holders = remote._construct_metric_value_holders_fn()\n        metric_values = construct_metric_value_holders(metric_class, metric_fn_groups, label_columns,\n                                                       hvd_mock)\n\n        assert metric_values[0][0].name == \'group_0_l1\'\n        assert metric_values[0][1].name == \'group_0_l2\'\n        assert metric_values[1][0].name == \'group_1_l1\'\n        assert metric_values[1][1].name == \'group_1_l2\'\n\n    def test_prepare_np_data(self):\n        with spark_session(\'test_prepare_np_data\') as spark:\n            df = create_xor_data(spark)\n\n            train_rows = df.count()\n            schema_cols = [\'features\', \'y\']\n            metadata = util._get_metadata(df)\n            assert metadata[\'features\'][\'intermediate_format\'] == constants.ARRAY\n\n            to_petastorm = util.to_petastorm_fn(schema_cols, metadata)\n            modified_df = df.rdd.map(to_petastorm).toDF()\n            data = modified_df.collect()\n\n            prepare_np_data = remote._prepare_np_data_fn()\n            features = torch.tensor([data[i].features for i in range(train_rows)])\n            features_prepared = prepare_np_data(features, \'features\', metadata)\n            assert np.array_equal(features_prepared, features)\n\n    def test_get_metric_avgs(self):\n        get_metric_avgs = remote._get_metric_avgs_fn()\n\n        def _generate_mock_metric(name, val):\n            metric = mock.MagicMock()\n            metric.name = name\n            metric.avg.item.return_value = val\n            return metric\n\n        metric11 = _generate_mock_metric(\'11\', 11)\n        metric12 = _generate_mock_metric(\'12\', 12)\n        metric21 = _generate_mock_metric(\'21\', 21)\n        metric22 = _generate_mock_metric(\'22\', 22)\n\n        metric_value_groups = [[metric11, metric12], [metric21, metric22]]\n        all_metric_groups_values = get_metric_avgs(metric_value_groups)\n\n        assert all_metric_groups_values[0][\'11\'] == 11\n        assert all_metric_groups_values[0][\'12\'] == 12\n        assert all_metric_groups_values[1][\'21\'] == 21\n        assert all_metric_groups_values[1][\'22\'] == 22\n\n    def test_update_metrics(self):\n        def dummy_metric_add(output, label):\n            return output + label\n\n        def dummy_metric_sub(output, label):\n            return output - label\n\n        metric_fn_groups = [[dummy_metric_add, dummy_metric_sub], [dummy_metric_add]]\n\n        update_metrics = remote._update_metrics_fn(metric_fn_groups)\n\n        def _generate_mock_metric(name, val):\n            metric = mock.MagicMock()\n            metric.name = name\n            metric.avg.item.return_value = val\n            return metric\n\n        metric11 = _generate_mock_metric(\'11\', 11)\n        metric12 = _generate_mock_metric(\'12\', 12)\n        metric21 = _generate_mock_metric(\'21\', 21)\n        metric22 = _generate_mock_metric(\'22\', 22)\n\n        metric_value_groups = [[metric11, metric12], [metric21, metric22]]\n\n        outputs = [15, 4]\n        labels = [10, 2]\n\n        updated_metric_value_groups = update_metrics(metric_value_groups, outputs, labels)\n\n        updated_metric_value_groups[0][0].update.assert_called_once_with(25)\n        updated_metric_value_groups[0][1].update.assert_called_once_with(2)\n        updated_metric_value_groups[1][0].update.assert_called_once_with(25)\n        updated_metric_value_groups[1][1].update.assert_called_once_with(6)\n\n    def test_torch_param_serialize(self):\n        serialized_backend = _torch_param_serialize(EstimatorParams.backend.name, \'dummy_value\')\n        assert serialized_backend is None\n\n        serialized_store = _torch_param_serialize(EstimatorParams.store.name, \'dummy_value\')\n        assert serialized_store is None\n\n        serialized_dummy_param = _torch_param_serialize(\'dummy_param_name\', None)\n        assert serialized_dummy_param is None\n\n    def test_torch_direct_parquet_train(self):\n        with spark_session(\'test_torch_direct_parquet_train\') as spark:\n            df = create_xor_data(spark)\n\n            backend = CallbackBackend()\n            with local_store() as store:\n                store.get_train_data_path = lambda v=None: store._train_path\n                store.get_val_data_path = lambda v=None: store._val_path\n\n                with util.prepare_data(backend.num_processes(),\n                                       store,\n                                       df,\n                                       feature_columns=[\'features\'],\n                                       label_columns=[\'y\']):\n                    model = create_xor_model()\n                    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n                    loss = nn.BCELoss()\n\n                    est = hvd.TorchEstimator(\n                        backend=backend,\n                        store=store,\n                        model=model,\n                        optimizer=optimizer,\n                        input_shapes=[[2]],\n                        feature_cols=[\'features\'],\n                        label_cols=[\'y\'],\n                        batch_size=1,\n                        epochs=3,\n                        verbose=2)\n\n                    # To make sure that setLoss works with non-list loss.\n                    est.setLoss(loss)\n\n                    transformer = est.fit_on_parquet()\n                    predictions = transformer.transform(df)\n                    assert predictions.count() == df.count()\n\n    def test_calculate_loss_with_sample_weight(self):\n        calculate_loss = remote._calculate_loss_fn()\n\n        labels = torch.tensor([[1.0, 2.0, 3.0]])\n        outputs = torch.tensor([[1.0, 0.0, 2.0]])\n\n        def fn_minus(output, label, reduction=None):\n            losses = label-output\n            if reduction == \'none\':\n                return losses\n            else:\n                return losses.mean()\n\n        def fn_add(output, label, reduction=None):\n            losses = label+output\n            if reduction == \'none\':\n                return losses\n            else:\n                return losses.mean()\n\n        loss = calculate_loss(outputs, labels, [1], [fn_minus], sample_weights=torch.tensor([1.0, 6.0, 3.0]))\n        assert loss == 5.0\n\n        labels = torch.tensor([[1.0, 2.0, 3.0], [0.0, 2.0, 4.0]])\n        outputs = torch.tensor([[1.0, 0.0, 2.0], [0.0, 0.0, 2.0]])\n\n        loss = calculate_loss(outputs, labels, [0.2, 0.8], [fn_minus, fn_add], sample_weights=torch.tensor([1.0, 6.0, 3.0]))\n        assert loss == torch.tensor(9.0)\n\n    def test_calculate_loss_without_sample_weight(self):\n        calculate_loss = remote._calculate_loss_fn()\n\n        labels = torch.tensor([[1.0, 2.0, 3.0]])\n        outputs = torch.tensor([[1.0, 0.0, 2.0]])\n\n        def fn_minus(output, label, reduction=None):\n            losses = label-output\n            if reduction == \'none\':\n                return losses\n            else:\n                return losses.mean()\n\n        def fn_add(output, label, reduction=None):\n            losses = label+output\n            if reduction == \'none\':\n                return losses\n            else:\n                return losses.mean()\n\n        loss = calculate_loss(outputs, labels, [1], [fn_minus])\n        assert loss == 1.0\n\n        labels = torch.tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 4.0]])\n        outputs = torch.tensor([[1.0, 0.0, 2.0], [0.0, 0.0, 2.0]])\n\n        loss = calculate_loss(outputs, labels, [0.2, 0.8], [fn_minus, fn_add])\n        assert torch.isclose(loss, torch.tensor(2.6))\n'"
test/test_stall.py,0,"b'import horovod.torch as hvd\nfrom horovod.common.util import env\nimport torch\nimport time\nimport signal\n\n\ndef test():\n    signal.alarm(45)\n    with env(HOROVOD_STALL_CHECK_TIME_SECONDS=""2"",\n             HOROVOD_STALL_SHUTDOWN_TIME_SECONDS=""5""):\n        hvd.init()\n        tensor = torch.IntTensor([[1, 2], [3, 4]])\n        if hvd.rank() != 0:\n            time.sleep(10 * hvd.rank());\n        try:\n            summed = hvd.allreduce(tensor, average=False)\n        except:\n            pass\n        finally:\n            hvd.shutdown()\n\n\nif __name__ == ""__main__"":\n    test()\n'"
test/test_tensorflow.py,248,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2018 Uber Technologies, Inc.\n# Modifications copyright (C) 2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\n""""""Tests for horovod.tensorflow.mpi_ops.""""""\n\nfrom distutils.version import LooseVersion\n\nimport itertools\nimport numpy as np\nimport os\nimport pytest\nimport tensorflow as tf\nfrom horovod.tensorflow.util import _executing_eagerly, _has_eager\nfrom tensorflow.python.framework import ops\nimport warnings\n\nimport horovod.tensorflow as hvd\n\nfrom common import mpi_env_rank_and_size\n\nif hasattr(tf, \'ConfigProto\'):\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n\nif hasattr(tf, \'config\') and hasattr(tf.config, \'experimental\') \\\n        and hasattr(tf.config.experimental, \'set_memory_growth\'):\n    gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\nelse:\n    if _has_eager:\n        # Specifies the config to use with eager execution. Does not preclude\n        # tests from running in the graph mode.\n        tf.enable_eager_execution(config=config)\n\nccl_supported_types = set([tf.uint8, tf.int32, tf.int64, tf.float32, tf.float64])\n\n_IS_TF2 = LooseVersion(tf.__version__) >= LooseVersion(\'2.0.0\')\n\n\nclass TensorFlowTests(tf.test.TestCase):\n    """"""\n    Tests for ops in horovod.tensorflow.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(TensorFlowTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n        if _has_eager:\n            if hasattr(tf, \'contrib\') and hasattr(tf.contrib, \'eager\'):\n                self.tfe = tf.contrib.eager\n            else:\n                self.tfe = tf\n\n    def evaluate(self, tensors):\n        if _executing_eagerly():\n            return self._eval_helper(tensors)\n        sess = ops.get_default_session()\n        if sess is None:\n            with self.test_session(config=config) as sess:\n                return sess.run(tensors)\n        else:\n            return sess.run(tensors)\n\n    def assign(self, variables, values):\n        if _executing_eagerly():\n            for var, val in zip(variables, values):\n                var.assign(val)\n        else:\n            sess = ops.get_default_session()\n            if sess is None:\n                with self.test_session(config=config) as sess:\n                    for var, val in zip(variables, values):\n                        var.load(val, sess)\n            else:\n                for var, val in zip(variables, values):\n                    var.load(val, sess)\n\n    def random_uniform(self, *args, **kwargs):\n        if hasattr(tf, \'random\') and hasattr(tf.random, \'set_seed\'):\n            tf.random.set_seed(1234)\n            return tf.random.uniform(*args, **kwargs)\n        else:\n            tf.set_random_seed(1234)\n            return tf.random_uniform(*args, **kwargs)\n\n    def filter_supported_types(self, types):\n        if \'CCL_ROOT\' in os.environ:\n           types = [t for t in types if t in ccl_supported_types]\n        return types\n\n    def test_horovod_rank(self):\n        """"""Test that the rank returned by hvd.rank() is correct.""""""\n        mpi_rank, _ = mpi_env_rank_and_size()\n        gloo_rank = int(os.getenv(\'HOROVOD_RANK\', -1))\n\n        # The mpi rank does not match gloo rank, we need to figure which one\n        # we are using to run the test.\n        is_mpi = gloo_rank == -1\n        hvd.init()\n        rank = hvd.rank()\n\n        if is_mpi:\n            assert mpi_rank == rank\n        else:\n            assert gloo_rank == rank\n\n    def test_horovod_size(self):\n        """"""Test that the size returned by hvd.size() is correct.""""""\n        _, mpi_size = mpi_env_rank_and_size()\n        gloo_size = int(os.getenv(\'HOROVOD_SIZE\', -1))\n\n        # The mpi size does not match gloo size, we need to figure which one\n        # we are using to run the test.\n        is_mpi = gloo_size == -1\n        hvd.init()\n        size = hvd.size()\n        if is_mpi:\n            assert mpi_size == size\n        else:\n            assert gloo_size == size\n\n    def test_horovod_allreduce_cpu(self):\n        """"""Test on CPU that the allreduce correctly sums 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([tf.int32, tf.int64, tf.float16, tf.float32, tf.float64])\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/cpu:0""):\n                tensor = self.random_uniform(\n                    [17] * dim, -100, 100, dtype=dtype)\n                summed = hvd.allreduce(tensor, average=False)\n            multiplied = tensor * size\n            max_difference = tf.reduce_max(tf.abs(summed - multiplied))\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [tf.int32, tf.int64]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                self.skipTest(""Horovod cluster too large for precise multiplication comparison"")\n\n            diff = self.evaluate(max_difference)\n            self.assertTrue(diff <= threshold, ""hvd.allreduce produces incorrect results"")\n\n    def test_horovod_allreduce_cpu_fused(self):\n        """"""Test on CPU that the allreduce correctly sums 1D, 2D, 3D tensors\n        with Tensor Fusion.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([tf.int32, tf.int64, tf.float16, tf.float32, tf.float64])\n        dims = [1, 2, 3]\n        tests = []\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/cpu:0""):\n                tensor = self.random_uniform(\n                    [17] * dim, -100, 100, dtype=dtype)\n                summed = hvd.allreduce(tensor, average=False)\n            multiplied = tensor * size\n            max_difference = tf.reduce_max(tf.abs(summed - multiplied))\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [tf.int32, tf.int64]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                self.skipTest(""Horovod cluster too large for precise multiplication comparison"")\n\n            test = max_difference <= threshold\n            tests.append(test)\n        self.assertTrue(self.evaluate(tf.reduce_all(tests)),\n                        ""hvd.allreduce produces incorrect results"")\n\n    def test_horovod_allreduce_gpu(self):\n        """"""Test that the allreduce works on GPUs.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        dtypes = [tf.int32, tf.int64, tf.float16, tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/gpu:%d"" % local_rank):\n                tensor = self.random_uniform(\n                    [17] * dim, -100, 100, dtype=dtype)\n                summed = hvd.allreduce(tensor, average=False)\n            multiplied = tensor * size\n            max_difference = tf.reduce_max(tf.abs(summed - multiplied))\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [tf.int32, tf.int64]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                self.skipTest(""Horovod cluster too large for precise multiplication comparison"")\n\n            diff = self.evaluate(max_difference)\n            self.assertTrue(diff <= threshold, ""hvd.allreduce on GPU produces incorrect results"")\n\n    def test_horovod_allreduce_gpu_fused(self):\n        """"""Test that the allreduce works on GPUs with Tensor Fusion.\n\n        This test will crash badly if used with an MPI implementation that does\n        not support GPU memory transfers directly, as it will call MPI_Send on\n        a GPU data pointer.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        dtypes = [tf.int32, tf.int64, tf.float16, tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        tests = []\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/gpu:%d"" % local_rank):\n                tensor = self.random_uniform(\n                    [17] * dim, -100, 100, dtype=dtype)\n                summed = hvd.allreduce(tensor, average=False)\n            multiplied = tensor * size\n            max_difference = tf.reduce_max(tf.abs(summed - multiplied))\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [tf.int32, tf.int64]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                self.skipTest(""Horovod cluster too large for precise multiplication comparison"")\n\n            test = max_difference <= threshold\n            tests.append(test)\n        self.assertTrue(self.evaluate(tf.reduce_all(tests)),\n                        ""hvd.allreduce produces incorrect results"")\n\n    def test_horovod_allreduce_multi_gpu(self):\n        """"""Test that the allreduce works on multiple GPUs.\n\n        This test will crash badly if used with an MPI implementation that does\n        not support GPU memory transfers directly, as it will call MPI_Send on\n        a GPU data pointer.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        # Only do this test if there are enough GPUs available.\n        if len(tf.config.experimental.list_physical_devices(\'GPU\')) < 2:\n            self.skipTest((""Too few GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        iter = 0\n        gpu_ids = [local_rank * 2, local_rank * 2 + 1]\n        dtypes = [tf.int32, tf.int64, tf.float16, tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            iter += 1\n            with tf.device(""/gpu:%d"" % gpu_ids[(iter + local_rank) % 2]):\n                tensor = self.random_uniform(\n                    [17] * dim, -100, 100, dtype=dtype)\n                summed = hvd.allreduce(tensor, average=False)\n            multiplied = tensor * size\n            max_difference = tf.reduce_max(tf.abs(summed - multiplied))\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [tf.int32, tf.int64]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                self.skipTest(""Horovod cluster too large for precise multiplication comparison"")\n\n            diff = self.evaluate(max_difference)\n            self.assertTrue(diff <= threshold,\n                            ""hvd.allreduce on GPU produces incorrect results"")\n\n    def test_horovod_allreduce_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n        send tensors of different rank or dimension.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Same rank, different dimension\n        dims = [17 + rank] * 3\n        tensor = self.random_uniform(dims, -1.0, 1.0)\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.allreduce(tensor))\n\n        # Same number of elements, different rank\n        if rank == 0:\n            dims = [17, 23 * 57]\n        else:\n            dims = [17, 23, 57]\n        tensor = self.random_uniform(dims, -1.0, 1.0)\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.allreduce(tensor))\n\n    def test_horovod_allreduce_type_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n        send tensors of different type.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Same rank, different dimension\n        dims = [17] * 3\n        tensor = tf.ones(dims,\n                         dtype=tf.int32 if rank % 2 == 0 else tf.float32)\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.allreduce(tensor))\n\n    def test_horovod_allreduce_cpu_gpu_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n        perform reduction on CPU and GPU.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        device = ""/gpu:%d"" % local_rank if local_rank % 2 == 0 else ""/cpu:0""\n        with tf.device(device):\n            # Same rank, different dimension\n            dims = [17] * 3\n            tensor = tf.ones(dims, dtype=tf.int32)\n            with self.assertRaises(tf.errors.FailedPreconditionError):\n                self.evaluate(hvd.allreduce(tensor))\n\n    def test_horovod_allreduce_grad_cpu(self):\n        """"""Test the correctness of the allreduce gradient on CPU.""""""\n        hvd.init()\n        size = hvd.size()\n\n        # As of TensorFlow v1.9, gradients are not supported on\n        # integer tensors\n        dtypes = [tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/cpu:0""):\n                if _executing_eagerly():\n                    tensor = self.tfe.Variable(self.random_uniform(\n                        [5] * dim, -100, 100, dtype=dtype))\n                    with tf.GradientTape() as tape:\n                        summed = hvd.allreduce(tensor, average=False)\n                else:\n                    tensor = self.random_uniform(\n                        [5] * dim, -100, 100, dtype=dtype)\n                    summed = hvd.allreduce(tensor, average=False)\n\n                grad_ys = tf.ones([5] * dim)\n                if _executing_eagerly():\n                    grad_out = tape.gradient(summed, tensor, grad_ys)\n                else:\n                    grad = tf.gradients(summed, tensor, grad_ys)[0]\n                    grad_out = self.evaluate(grad)\n\n            expected = np.ones([5] * dim) * size\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_allreduce_grad_gpu(self):\n        """"""Test the correctness of the allreduce gradient on GPU.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # As of TensorFlow v1.9, gradients are not supported on\n        # integer tensors\n        dtypes = [tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/gpu:%d"" % local_rank):\n                if _executing_eagerly():\n                    tensor = self.tfe.Variable(\n                        self.random_uniform([5] * dim, -100, 100, dtype=dtype))\n                    with tf.GradientTape() as tape:\n                        summed = hvd.allreduce(tensor, average=False)\n                else:\n                    tensor = self.random_uniform([5] * dim, -100, 100, dtype=dtype)\n                    summed = hvd.allreduce(tensor, average=False)\n\n                grad_ys = tf.ones([5] * dim)\n                if _executing_eagerly():\n                    grad_out = tape.gradient(summed, tensor, grad_ys)\n                else:\n                    grad = tf.gradients(summed, tensor, grad_ys)[0]\n                    grad_out = self.evaluate(grad)\n\n            expected = np.ones([5] * dim) * size\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_allgather_cpu(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/cpu:0""):\n                tensor = tf.ones([17] * dim) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                gathered = hvd.allgather(tensor)\n\n            gathered_tensor = self.evaluate(gathered)\n            self.assertEqual(list(gathered_tensor.shape),\n                             [17 * size] + [17] * (dim - 1))\n\n            for i in range(size):\n                rank_tensor = tf.slice(gathered_tensor,\n                                       [i * 17] + [0] * (dim - 1),\n                                       [17] + [-1] * (dim - 1))\n                self.assertEqual(list(rank_tensor.shape), [17] * dim)\n                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,\n                # so need to cast rank_tensor to tf.int32.\n                if dtype != tf.bool:\n                    value = i\n                else:\n                    value = i % 2\n                self.assertTrue(\n                    self.evaluate(tf.reduce_all(\n                        tf.equal(tf.cast(rank_tensor, tf.int32), value))),\n                    ""hvd.allgather produces incorrect gathered tensor"")\n\n    def test_horovod_allgather_gpu(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/gpu:%d"" % local_rank):\n                tensor = tf.ones([17] * dim) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                gathered = hvd.allgather(tensor)\n\n            gathered_tensor = self.evaluate(gathered)\n            self.assertEqual(list(gathered_tensor.shape),\n                             [17 * size] + [17] * (dim - 1))\n\n            for i in range(size):\n                rank_tensor = tf.slice(gathered_tensor,\n                                       [i * 17] + [0] * (dim - 1),\n                                       [17] + [-1] * (dim - 1))\n                self.assertEqual(list(rank_tensor.shape), [17] * dim)\n                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,\n                # so need to cast rank_tensor to tf.int32.\n                if dtype != tf.bool:\n                    value = i\n                else:\n                    value = i % 2\n                self.assertTrue(\n                    self.evaluate(tf.reduce_all(\n                        tf.equal(tf.cast(rank_tensor, tf.int32), value))),\n                    ""hvd.allgather produces incorrect gathered tensor"")\n\n    def test_horovod_allgather_fused_cpu(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors\n        with Tensor Fusion.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        tests = []\n        shape_tests = []\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/cpu:0""):\n                tensor = tf.ones([17] * dim) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                gathered = hvd.allgather(tensor)\n\n            shape_tests.append(\n                tf.reduce_all(tf.equal(tf.shape(gathered),\n                                       [17 * size] + [17] * (dim - 1))))\n\n            for i in range(size):\n                rank_tensor = tf.slice(gathered,\n                                       [i * 17] + [0] * (dim - 1),\n                                       [17] + [-1] * (dim - 1))\n                if dtype != tf.bool:\n                    value = i\n                else:\n                    value = i % 2\n\n                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,\n                # so need to cast rank_tensor to tf.int32.\n                tests.append(\n                    tf.reduce_all(\n                        tf.equal(tf.cast(rank_tensor, tf.int32), value)))\n\n            shape_tests_passed, value_tests_passed = \\\n                self.evaluate([tf.reduce_all(shape_tests), tf.reduce_all(tests)])\n\n            self.assertTrue(shape_tests_passed,\n                            ""hvd.allgather produces incorrect gathered tensor"")\n\n            self.assertTrue(value_tests_passed,\n                            ""hvd.allgather produces incorrect gathered tensor"")\n\n    def test_horovod_allgather_fused_gpu(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors\n        with Tensor Fusion.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        tests = []\n        shape_tests = []\n        for dtype, dim in itertools.product(dtypes, dims):\n            with tf.device(""/gpu:%d"" % local_rank):\n                tensor = tf.ones([17] * dim) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                gathered = hvd.allgather(tensor)\n\n            shape_tests.append(\n                tf.reduce_all(tf.equal(tf.shape(gathered),\n                                       [17 * size] + [17] * (dim - 1))))\n\n            for i in range(size):\n                rank_tensor = tf.slice(gathered,\n                                       [i * 17] + [0] * (dim - 1),\n                                       [17] + [-1] * (dim - 1))\n                if dtype != tf.bool:\n                    value = i\n                else:\n                    value = i % 2\n\n                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,\n                # so need to cast rank_tensor to tf.int32.\n                tests.append(\n                    tf.reduce_all(\n                        tf.equal(tf.cast(rank_tensor, tf.int32), value)))\n\n            shape_tests_passed, value_tests_passed = \\\n                self.evaluate([tf.reduce_all(shape_tests), tf.reduce_all(tests)])\n\n            self.assertTrue(shape_tests_passed,\n                            ""hvd.allgather produces incorrect gathered tensor"")\n\n            self.assertTrue(value_tests_passed,\n                            ""hvd.allgather produces incorrect gathered tensor"")\n\n    def test_horovod_allgather_variable_size_fused(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors with\n        Tensor Fusion, even if those tensors have different sizes along the\n        first dim.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        tests = []\n        shape_tests = []\n\n        for dtype, dim in itertools.product(dtypes, dims):\n            # Support tests up to MPI Size of 35\n            if size > 35:\n                break\n\n            tensor_sizes = [17, 32, 81, 12, 15, 23, 22] * 5\n            tensor_sizes = tensor_sizes[:size]\n\n            tensor = tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank\n            if dtype == tf.bool:\n                tensor = tensor % 2\n            tensor = tf.cast(tensor, dtype=dtype)\n            gathered = hvd.allgather(tensor)\n            shape_tests.append(\n                tf.reduce_all(tf.equal(tf.shape(gathered),\n                             [sum(tensor_sizes)] + [17] * (dim - 1))))\n\n            for i in range(size):\n                rank_size = [tensor_sizes[i]] + [17] * (dim - 1)\n                rank_tensor = tf.slice(\n                    gathered, [sum(tensor_sizes[:i])] + [0] * (dim - 1),\n                    rank_size)\n                self.assertEqual(list(rank_tensor.shape), rank_size)\n                if dtype != tf.bool:\n                    value = i\n                else:\n                    value = i % 2\n\n                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,\n                # so need to cast rank_tensor to tf.int32.\n                tests.append(tf.reduce_all(\n                    tf.equal(tf.cast(rank_tensor, tf.int32), value)))\n\n            shape_tests_passed, value_tests_passed = \\\n                self.evaluate([tf.reduce_all(shape_tests), tf.reduce_all(tests)])\n\n            self.assertTrue(shape_tests_passed,\n                            ""hvd.allgather produces incorrect gathered tensor"")\n\n            self.assertTrue(value_tests_passed,\n                            ""hvd.allgather produces incorrect gathered tensor"")\n\n    def test_horovod_allgather_variable_size(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors,\n        even if those tensors have different sizes along the first dim.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            # Support tests up to MPI Size of 35\n            if size > 35:\n                break\n\n            tensor_sizes = [17, 32, 81, 12, 15, 23, 22] * 5\n            tensor_sizes = tensor_sizes[:size]\n\n            tensor = tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank\n            if dtype == tf.bool:\n                tensor = tensor % 2\n            tensor = tf.cast(tensor, dtype=dtype)\n            gathered = hvd.allgather(tensor)\n\n            gathered_tensor = self.evaluate(gathered)\n            expected_size = sum(tensor_sizes)\n            self.assertEqual(list(gathered_tensor.shape),\n                             [expected_size] + [17] * (dim - 1))\n\n            for i in range(size):\n                rank_size = [tensor_sizes[i]] + [17] * (dim - 1)\n                rank_tensor = tf.slice(\n                    gathered, [sum(tensor_sizes[:i])] + [0] * (dim - 1),\n                    rank_size)\n                self.assertEqual(list(rank_tensor.shape), rank_size)\n                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,\n                # so need to cast rank_tensor to tf.int32.\n                if dtype != tf.bool:\n                    value = i\n                else:\n                    value = i % 2\n                self.assertTrue(\n                    self.evaluate(tf.reduce_all(\n                        tf.equal(tf.cast(rank_tensor, tf.int32), value))),\n                    ""hvd.allgather produces incorrect gathered tensor"")\n\n    def test_horovod_allgather_error(self):\n        """"""Test that the allgather returns an error if any dimension besides\n        the first is different among the tensors being gathered.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        tensor_size[1] = 10 * (rank + 1)\n        tensor = tf.ones(tensor_size, dtype=tf.float32) * rank\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.allgather(tensor))\n\n    def test_horovod_allgather_type_error(self):\n        """"""Test that the allgather returns an error if the types being gathered\n        differ among the processes""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        dtype = tf.int32 if rank % 2 == 0 else tf.float32\n        tensor = tf.ones(tensor_size, dtype=dtype) * rank\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.allgather(tensor))\n\n    def test_horovod_allgather_grad_cpu(self):\n        """"""Test the correctness of the allgather gradient on CPU.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # As of TensorFlow v1.9, gradients are not supported on\n        # integer tensors\n        dtypes = [tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            tensor_sizes = [3, 2, 7, 4, 6, 8, 10] * 5\n            tensor_sizes = tensor_sizes[:size]\n\n            if _executing_eagerly():\n                with tf.GradientTape() as tape:\n                    tensor = self.tfe.Variable(\n                        tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank)\n                    if dtype == tf.bool:\n                        tensor = tensor % 2\n                    tensor = tf.cast(tensor, dtype=dtype)\n                    gathered = hvd.allgather(tensor)\n                    grad_list = []\n                    for r, tensor_size in enumerate(tensor_sizes):\n                        g = tf.ones([tensor_size] + [17] * (dim - 1)) * r\n                        grad_list.append(g)\n                    grad_ys = tf.concat(grad_list, axis=0)\n                with tf.device(""/cpu:0""):\n                    grad_out = tape.gradient(gathered, tensor, grad_ys)\n            else:\n                tensor = tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                gathered = hvd.allgather(tensor)\n\n                grad_list = []\n                for r, tensor_size in enumerate(tensor_sizes):\n                    g = tf.ones([tensor_size] + [17] * (dim - 1)) * r\n                    grad_list.append(g)\n                grad_ys = tf.concat(grad_list, axis=0)\n\n                with tf.device(""/cpu:0""):\n                    grad = tf.gradients(gathered, tensor, grad_ys)[0]\n                grad_out = self.evaluate(grad)\n\n            expected = np.ones(\n                [tensor_sizes[rank]] + [17] * (dim - 1)\n            ) * rank * size\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" %\n                            (grad_out, expected, str(err)))\n\n    def test_horovod_allgather_grad_gpu(self):\n        """"""Test the correctness of the allgather gradient on GPU.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # As of TensorFlow v1.9, gradients are not supported on\n        # integer tensors\n        dtypes = [tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            tensor_sizes = [3, 2, 7, 4, 6, 8, 10] * 5\n            tensor_sizes = tensor_sizes[:size]\n\n            if _executing_eagerly():\n                with tf.GradientTape() as tape:\n                    tensor = self.tfe.Variable(\n                        tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank)\n                    if dtype == tf.bool:\n                        tensor = tensor % 2\n                    tensor = tf.cast(tensor, dtype=dtype)\n                    gathered = hvd.allgather(tensor)\n                    grad_list = []\n                    for r, tensor_size in enumerate(tensor_sizes):\n                        g = tf.ones([tensor_size] + [17] * (dim - 1)) * r\n                        grad_list.append(g)\n                    grad_ys = tf.concat(grad_list, axis=0)\n                with tf.device(""/gpu:%d"" % local_rank):\n                    grad_out = tape.gradient(gathered, tensor, grad_ys)\n            else:\n                tensor = tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                gathered = hvd.allgather(tensor)\n\n                grad_list = []\n                for r, tensor_size in enumerate(tensor_sizes):\n                    g = tf.ones([tensor_size] + [17] * (dim - 1)) * r\n                    grad_list.append(g)\n                grad_ys = tf.concat(grad_list, axis=0)\n\n                with tf.device(""/gpu:%d"" % local_rank):\n                    grad = tf.gradients(gathered, tensor, grad_ys)[0]\n                grad_out = self.evaluate(grad)\n\n            expected = np.ones(\n                [tensor_sizes[rank]] + [17] * (dim - 1)\n            ) * rank * size\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" %\n                            (grad_out, expected, str(err)))\n\n    def test_horovod_broadcast_cpu(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors on CPU.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            with tf.device(""/cpu:0""):\n                tensor = tf.ones([17] * dim) * rank\n                root_tensor = tf.ones([17] * dim) * root_rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                    root_tensor = root_tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                root_tensor = tf.cast(root_tensor, dtype=dtype)\n                broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n            self.assertTrue(\n                self.evaluate(tf.reduce_all(tf.equal(\n                    tf.cast(root_tensor, tf.int32), tf.cast(broadcasted_tensor, tf.int32)))),\n                ""hvd.broadcast produces incorrect broadcasted tensor"")\n\n    def test_horovod_broadcast_gpu(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors on GPU.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                  tf.int32, tf.int64, tf.float16, tf.float32,\n                  tf.float64, tf.bool]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            with tf.device(""/gpu:%d"" % local_rank):\n                tensor = tf.ones([17] * dim) * rank\n                root_tensor = tf.ones([17] * dim) * root_rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                    root_tensor = root_tensor % 2\n                tensor = tf.cast(tensor, dtype=dtype)\n                root_tensor = tf.cast(root_tensor, dtype=dtype)\n                broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n            self.assertTrue(\n                self.evaluate(tf.reduce_all(tf.equal(\n                    tf.cast(root_tensor, tf.int32), tf.cast(broadcasted_tensor, tf.int32)))),\n                ""hvd.broadcast produces incorrect broadcasted tensor"")\n\n    def test_horovod_broadcast_error(self):\n        """"""Test that the broadcast returns an error if any dimension besides\n        the first is different among the tensors being broadcasted.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        tensor_size[1] = 10 * (rank + 1)\n        tensor = tf.ones(tensor_size, dtype=tf.float32) * rank\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.broadcast(tensor, 0))\n\n    def test_horovod_broadcast_type_error(self):\n        """"""Test that the broadcast returns an error if the types being broadcasted\n        differ among the processes""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        dtype = tf.int32 if rank % 2 == 0 else tf.float32\n        tensor = tf.ones(tensor_size, dtype=dtype) * rank\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.broadcast(tensor, 0))\n\n    def test_horovod_broadcast_rank_error(self):\n        """"""Test that the broadcast returns an error if different ranks\n        specify different root rank.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor = tf.ones([17] * 3, dtype=tf.float32)\n        with self.assertRaises(tf.errors.FailedPreconditionError):\n            self.evaluate(hvd.broadcast(tensor, rank))\n\n    def test_horovod_broadcast_grad_cpu(self):\n        """"""Test the correctness of the broadcast gradient on CPU.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # As of TensorFlow v1.9, gradients are not supported on\n        # integer tensors\n        dtypes = [tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            with tf.device(""/cpu:0""):\n                if _executing_eagerly():\n                    tensor = self.tfe.Variable(tf.ones([5] * dim) * rank)\n                else:\n                    tensor = tf.ones([5] * dim) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                if _executing_eagerly():\n                    with tf.GradientTape() as tape:\n                        tensor = tf.cast(tensor, dtype=dtype)\n                        broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n                    grad_out = tape.gradient(broadcasted_tensor, tensor)\n                else:\n                    tensor = tf.cast(tensor, dtype=dtype)\n                    broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n                    grad_ys = tf.ones([5] * dim)\n                    grad = tf.gradients(broadcasted_tensor, tensor, grad_ys)[0]\n                    grad_out = self.evaluate(grad)\n\n            c = size if rank == root_rank else 0\n            expected = np.ones([5] * dim) * c\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_broadcast_grad_gpu(self):\n        """"""Test the correctness of the broadcast gradient on GPU.""""""\n        # Only do this test if there are GPUs available.\n        if not tf.test.is_gpu_available(cuda_only=True):\n            self.skipTest((""No GPUs available""))\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # As of TensorFlow v1.9, gradients are not supported on\n        # integer tensors\n        dtypes = [tf.float32, tf.float64]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            with tf.device(""/gpu:%d"" % local_rank):\n                if _executing_eagerly():\n                    tensor = self.tfe.Variable(tf.ones([5] * dim) * rank)\n                else:\n                    tensor = tf.ones([5] * dim) * rank\n                if dtype == tf.bool:\n                    tensor = tensor % 2\n                if _executing_eagerly():\n                    with tf.GradientTape() as tape:\n                        tensor = tf.cast(tensor, dtype=dtype)\n                        broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n                    grad_out = tape.gradient(broadcasted_tensor, tensor)\n                else:\n                    tensor = tf.cast(tensor, dtype=dtype)\n                    broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n                    grad_ys = tf.ones([5] * dim)\n                    grad = tf.gradients(broadcasted_tensor, tensor, grad_ys)[0]\n                    grad_out = self.evaluate(grad)\n\n            c = size if rank == root_rank else 0\n            expected = np.ones([5] * dim) * c\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_broadcast_eager_mode_error(self):\n        """"""Test that tries to broadcast tensorflow global variables\n        in eager execution mode. This call should raise a RuntimeError.""""""\n\n        if not hvd.util._executing_eagerly():\n            self.skipTest(""Only in eager execution mode"")\n\n        with self.assertRaises(RuntimeError):\n            hvd.broadcast_global_variables(root_rank=0)\n\n    def test_horovod_broadcast_graph_mode(self):\n        """"""Test that tries to broadcast tensorflow global variables\n        in graph execution mode. This call should not raise any exception.""""""\n\n        if hvd.util._executing_eagerly():\n            self.skipTest(""Not in eager execution mode"")\n\n        hvd.broadcast_global_variables(root_rank=0)\n\n    def test_compression_fp16(self):\n        valid_dtypes = [tf.float16, tf.float32, tf.float64]\n        invalid_dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,\n                          tf.int32, tf.int64, tf.bool]\n\n        tensor_size = [17] * 3\n        compression = hvd.Compression.fp16\n\n        for dtype in valid_dtypes:\n            tensor = tf.ones(tensor_size, dtype=dtype)\n\n            tensor_compressed, ctx = compression.compress(tensor)\n            self.assertEqual(tensor_compressed.dtype, tf.float16)\n\n            tensor_decompressed = compression.decompress(tensor_compressed, ctx)\n            self.assertEqual(tensor_decompressed.dtype, dtype)\n\n            actual = self.evaluate(tensor_decompressed)\n            expected = np.ones(tensor_size)\n            err = np.linalg.norm(expected - actual)\n            self.assertLess(err, 0.00000001)\n\n        for dtype in invalid_dtypes:\n            tensor = tf.ones(tensor_size, dtype=dtype)\n\n            tensor_compressed, ctx = compression.compress(tensor)\n            self.assertEqual(tensor_compressed.dtype, dtype)\n\n            tensor_decompressed = compression.decompress(tensor_compressed, ctx)\n            self.assertEqual(tensor_decompressed.dtype, dtype)\n\n            actual = self.evaluate(tensor_decompressed)\n            expected = np.ones(tensor_size)\n            err = np.linalg.norm(expected - actual)\n            self.assertLess(err, 0.00000001)\n\n    def test_broadcast_object(self):\n        if LooseVersion(tf.__version__) < LooseVersion(\'1.15.0\'):\n            self.skipTest(""Broadcasting object requires TensorFlow 1.15 or above"")\n\n        hvd.init()\n\n        with tf.device(""/cpu:0""):\n            expected_obj = {\n                \'hello\': 123,\n                0: [1, 2]\n            }\n            obj = expected_obj if hvd.rank() == 0 else {}\n\n            obj = hvd.broadcast_object(obj, root_rank=0)\n            self.assertDictEqual(obj, expected_obj)\n\n    def test_broadcast_object_fn(self):\n        if LooseVersion(tf.__version__) < LooseVersion(\'1.15.0\'):\n            self.skipTest(""Broadcasting object requires TensorFlow 1.15 or above"")\n\n        if hvd._executing_eagerly() or _IS_TF2:\n            # Only for TF 1.0 in graph mode\n            return\n\n        hvd.init()\n\n        with tf.device(""/cpu:0""):\n            expected_obj = {\n                \'hello\': 123,\n                0: [1, 2]\n            }\n            obj = expected_obj if hvd.rank() == 0 else {}\n\n            bcast = hvd.broadcast_object_fn(root_rank=0)\n            obj = bcast(obj)\n            self.assertDictEqual(obj, expected_obj)\n\n    def test_elastic_state(self):\n        if LooseVersion(tf.__version__) < LooseVersion(\'1.15.0\'):\n            self.skipTest(""Broadcasting object requires TensorFlow 1.15 or above"")\n\n        if not hvd._executing_eagerly() and _IS_TF2:\n            # Only support TF 2.0 in eager mode\n            return\n\n        hvd.init()\n\n        with tf.device(""/cpu:0""):\n            v = 1.0 if hvd.rank() == 0 else 2.0\n            weights1 = [\n                np.array([[v, v], [v, v]]),\n                np.array([v, v])\n            ]\n            vars1 = [tf.Variable(arr) for arr in weights1]\n\n            weights2 = [\n                np.array([[1.0, 2.0], [3.0, 4.0]]),\n                np.array([0.0, 0.0])\n            ]\n\n            if not hvd._executing_eagerly():\n                init = tf.global_variables_initializer()\n                self.evaluate(init)\n\n            state = hvd.elastic.TensorFlowState(vars1, batch=20 + hvd.rank(), epoch=10 + hvd.rank())\n            state.sync()\n\n            weights1 = [np.ones_like(w) for w in weights1]\n\n            # After sync, all values should match the root rank\n            for w in self.evaluate(vars1):\n                self.assertAllClose(w, np.ones_like(w))\n            assert state.batch == 20\n            assert state.epoch == 10\n\n            # Partially modify then restore\n            self.assign(vars1, weights2)\n            state.batch = 21\n            state.epoch = 11\n\n            state.restore()\n\n            for w1, w2 in zip(self.evaluate(vars1), weights1):\n                self.assertAllClose(w1, w2)\n            assert state.batch == 20\n            assert state.epoch == 10\n\n            # Partially modify then commit\n            self.assign(vars1, weights2)\n            state.batch = 21\n            state.epoch = 11\n\n            state.commit()\n            state.restore()\n\n            for w1, w2 in zip(self.evaluate(vars1), weights2):\n                self.assertAllClose(w1, w2)\n            assert state.batch == 21\n            assert state.epoch == 11\n\n\nif _has_eager:\n    from tensorflow.python.framework.test_util import run_all_in_graph_and_eager_modes\n    run_all_in_graph_and_eager_modes(TensorFlowTests)\n\nif __name__ == \'__main__\':\n    tf.test.main()\n'"
test/test_tensorflow2_keras.py,11,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Tests for horovod.tensorflow.keras.""""""\n\nimport tensorflow as tf\nimport numpy as np\nimport warnings\n\nfrom tensorflow import keras\n\nimport horovod.tensorflow.keras as hvd\n\n\nclass Tf2KerasTests(tf.test.TestCase):\n    """"""\n    Tests for ops in horovod.tensorflow.keras.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(Tf2KerasTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n        hvd.init()\n\n        gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        if gpus:\n            tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\n\n    def test_train_model_lr_schedule(self):\n        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n            0.001 * hvd.size(),\n            decay_steps=100000,\n            decay_rate=0.96,\n            staircase=True)\n        opt = tf.keras.optimizers.Adam(lr_schedule)\n        opt = hvd.DistributedOptimizer(opt)\n\n        model = keras.models.Sequential()\n        model.add(keras.layers.Dense(2, input_shape=(3,)))\n        model.add(keras.layers.RepeatVector(3))\n        model.add(keras.layers.ThresholdedReLU(0.5))\n        model.compile(loss=keras.losses.mean_squared_error,\n                      optimizer=opt,\n                      metrics=[keras.metrics.categorical_accuracy],\n                      experimental_run_tf_function=False)\n\n        x = np.random.random((1, 3))\n        y = np.random.random((1, 3, 2))\n\n        # No assertions, we just need to verify that it doesn\'t hang or error\n        callbacks = [hvd.callbacks.BroadcastGlobalVariablesCallback(0)]\n        model.fit(x,\n                  y,\n                  steps_per_epoch=10,\n                  callbacks=callbacks,\n                  epochs=1)\n\n    def test_sparse_as_dense(self):\n        opt = keras.optimizers.RMSprop(lr=0.0001)\n        opt = hvd.DistributedOptimizer(opt, sparse_as_dense=True)\n\n        model = keras.models.Sequential()\n        model.add(keras.layers.Embedding(1000, 64, input_length=10))\n        model.compile(loss=keras.losses.mean_squared_error,\n                      optimizer=opt,\n                      experimental_run_tf_function=False)\n\n        x = np.random.randint(1000, size=(32, 10))\n        y = np.random.random((32, 10, 64))\n        # No assertions, we just need to verify that it doesn\'t hang\n        model.train_on_batch(x, y)\n\n    def test_from_config(self):\n        opt = keras.optimizers.Adam()\n        hopt = hvd.DistributedOptimizer(opt)\n        cfg = hopt.get_config()\n\n        hopt_copy1 = hopt.from_config(cfg)\n        self.assertEqual(cfg, hopt_copy1.get_config())\n\n        hopt_copy2 = hopt.__class__.from_config(cfg)\n        self.assertEqual(cfg, hopt_copy2.get_config())\n\n    def test_elastic_state(self):\n        v = 1.0 if hvd.rank() == 0 else 2.0\n        model1 = tf.keras.Sequential([\n            tf.keras.layers.Dense(2, activation=\'softmax\')\n        ])\n        model1.build((2, 2))\n        model1.set_weights(\n            [np.array([[v,  v], [v, v]], dtype=np.float32),\n             np.array([v, v], dtype=np.float32)])\n\n        model2 = tf.keras.Sequential([\n            tf.keras.layers.Dense(2, activation=\'softmax\')\n        ])\n        model2.build((2, 2))\n        model2.set_weights(\n            [np.array([[1.0,  2.0], [3.0, 4.0]], dtype=np.float32),\n             np.array([0.0, 0.0], dtype=np.float32)])\n\n        optimizer = tf.optimizers.Adam(0.001 * hvd.size())\n\n        state = hvd.elastic.KerasState(model1, optimizer, batch=20 + hvd.rank(), epoch=10 + hvd.rank())\n        state.sync()\n\n        model1_weights = model1.get_weights()\n        model2_weights = model2.get_weights()\n\n        # After sync, all values should match the root rank\n        for w in state.model.get_weights():\n            self.assertAllClose(w, np.ones_like(w))\n        assert state.batch == 20\n        assert state.epoch == 10\n\n        # Partially modify then restore\n        model1.set_weights(model2_weights)\n        state.batch = 21\n        state.epoch = 11\n\n        state.restore()\n\n        for w1, w2 in zip(model1.get_weights(), model1_weights):\n            self.assertAllClose(w1, w2)\n        assert state.batch == 20\n        assert state.epoch == 10\n\n        # Partially modify then commit\n        model1.set_weights(model2_weights)\n        state.batch = 21\n        state.epoch = 11\n\n        state.commit()\n        state.restore()\n\n        for w1, w2 in zip(model1.get_weights(), model2_weights):\n            self.assertAllClose(w1, w2)\n        assert state.batch == 21\n        assert state.epoch == 11\n'"
test/test_tensorflow_keras.py,13,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Tests for horovod.tensorflow.keras.""""""\n\nimport numpy as np\nimport pytest\nimport tensorflow as tf\nimport warnings\n\nfrom distutils.version import LooseVersion\nif LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):\n    from tensorflow import keras\n    from tensorflow.python.keras import backend as K\nelse:\n    from tensorflow.contrib import keras\n    from tensorflow.contrib.keras import backend as K\n\nimport horovod.tensorflow.keras as hvd\n\nfrom common import temppath\n\n\nclass TfKerasTests(tf.test.TestCase):\n    """"""\n    Tests for ops in horovod.tensorflow.keras.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(TfKerasTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n        hvd.init()\n\n        self.config = tf.ConfigProto()\n        self.config.gpu_options.allow_growth = True\n        self.config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    def test_train_model(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.ThresholdedReLU(0.5))\n            model.compile(loss=keras.losses.mean_squared_error,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n\n            def generator():\n                while 1:\n                    yield (x, y)\n\n            # No assertions, we just need to verify that it doesn\'t hang\n            callbacks = [hvd.callbacks.BroadcastGlobalVariablesCallback(0)]\n            model.fit_generator(generator(),\n                                steps_per_epoch=10,\n                                callbacks=callbacks,\n                                epochs=0,\n                                verbose=0,\n                                workers=4,\n                                initial_epoch=1)\n\n    def test_sparse_as_dense(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt, sparse_as_dense=True)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Embedding(1000, 64, input_length=10))\n            model.compile(loss=keras.losses.mean_squared_error,\n                          optimizer=opt)\n\n            x = np.random.randint(1000, size=(32, 10))\n            y = np.random.random((32, 10, 64))\n            # No assertions, we just need to verify that it doesn\'t hang\n            model.train_on_batch(x, y)\n\n    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion(\'1.12.0\'), reason=\'TensorFlow version too low\')\n    def test_load_model(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n            model.train_on_batch(x, y)\n\n            with temppath() as fname:\n                model.save(fname)\n\n                new_model = hvd.load_model(fname)\n                new_opt = new_model.optimizer\n\n            self.assertEqual(type(new_opt).__module__, \'horovod._keras\')\n            self.assertEqual(type(new_opt).__name__, \'RMSprop\')\n            self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))\n            self._check_optimizer_weights(opt, new_opt)\n\n    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion(\'1.12.0\'), reason=\'TensorFlow version too low\')\n    def test_load_model_custom_optimizers(self):\n        class TestOptimizer(keras.optimizers.RMSprop):\n            def __init__(self, **kwargs):\n                super(TestOptimizer, self).__init__(**kwargs)\n\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = TestOptimizer(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n            model.train_on_batch(x, y)\n\n            with temppath() as fname:\n                model.save(fname)\n\n                custom_optimizers = [TestOptimizer]\n                new_model = hvd.load_model(fname, custom_optimizers=custom_optimizers)\n                new_opt = new_model.optimizer\n\n            self.assertEqual(type(new_opt).__module__, \'horovod._keras\')\n            self.assertEqual(type(new_opt).__name__, \'TestOptimizer\')\n            self._check_optimizer_weights(opt, new_opt)\n\n    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion(\'1.12.0\'), reason=\'TensorFlow version too low\')\n    def test_load_model_custom_objects(self):\n        class TestOptimizer(keras.optimizers.RMSprop):\n            def __init__(self, **kwargs):\n                super(TestOptimizer, self).__init__(**kwargs)\n\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = TestOptimizer(lr=0.0001)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n            model.train_on_batch(x, y)\n\n            with temppath() as fname:\n                model.save(fname)\n\n                custom_objects = {\n                    \'TestOptimizer\': lambda **kwargs: hvd.DistributedOptimizer(\n                        TestOptimizer(**kwargs))\n                }\n                new_model = hvd.load_model(fname, custom_objects=custom_objects)\n                new_opt = new_model.optimizer\n\n            self.assertEqual(type(new_opt).__module__, \'horovod._keras\')\n            self.assertEqual(type(new_opt).__name__, \'TestOptimizer\')\n            self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))\n            self._check_optimizer_weights(opt, new_opt)\n\n    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion(\'1.12.0\'), reason=\'TensorFlow version too low\')\n    def test_load_model_broadcast(self):\n        def create_model():\n            opt = keras.optimizers.SGD(lr=0.01 * hvd.size(), momentum=0.9)\n            opt = hvd.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))\n            model.compile(loss=keras.losses.MSE,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            return model\n\n        with temppath() as fname:\n            with self.session(config=self.config) as sess:\n                K.set_session(sess)\n\n                model = create_model()\n\n                x = np.random.random((1, 3))\n                y = np.random.random((1, 3, 3))\n                model.train_on_batch(x, y)\n\n                if hvd.rank() == 0:\n                    model.save(fname)\n\n            K.clear_session()\n            with self.session(config=self.config) as sess:\n                K.set_session(sess)\n\n                weight = np.random.random((1, 3))\n\n                if hvd.rank() == 0:\n                    model = hvd.load_model(fname)\n                else:\n                    model = create_model()\n\n                def generator():\n                    while 1:\n                        yield (x, y, weight)\n\n                if hvd.rank() == 0:\n                    self.assertEqual(len(model.optimizer.weights), 5)\n                else:\n                    self.assertEqual(len(model.optimizer.weights), 0)\n\n                # No assertions, we just need to verify that it doesn\'t hang\n                callbacks = [hvd.callbacks.BroadcastGlobalVariablesCallback(0)]\n                model.fit_generator(generator(),\n                                    steps_per_epoch=1,\n                                    callbacks=callbacks,\n                                    epochs=1,\n                                    verbose=0,\n                                    workers=4,\n                                    initial_epoch=0)\n\n                self.assertEqual(len(model.optimizer.weights), 5)\n\n    def _check_optimizer_weights(self, opt, new_opt):\n        self.assertEqual(len(opt.get_weights()), len(new_opt.get_weights()))\n        for weights, new_weights in zip(opt.get_weights(),\n                                        new_opt.get_weights()):\n            if np.isscalar(weights):\n                self.assertEqual(weights, new_weights)\n            else:\n                self.assertListEqual(weights.tolist(), new_weights.tolist())\n\n    def test_from_config(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.Adam()\n            hopt = hvd.DistributedOptimizer(opt)\n            cfg = hopt.get_config()\n\n            hopt_copy1 = hopt.from_config(cfg)\n            self.assertEqual(cfg, hopt_copy1.get_config())\n\n            hopt_copy2 = hopt.__class__.from_config(cfg)\n            self.assertEqual(cfg, hopt_copy2.get_config())\n\n    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion(\'1.15.0\'),\n                        reason=\'Synchronizing state requires TensorFlow 1.15 or above\')\n    def test_elastic_state(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            v = 1.0 if hvd.rank() == 0 else 2.0\n            model1 = tf.keras.Sequential([\n                tf.keras.layers.Dense(2, activation=\'softmax\')\n            ])\n            model1.build((2, 2))\n            model1.set_weights(\n                [np.array([[v,  v], [v, v]], dtype=np.float32),\n                 np.array([v, v], dtype=np.float32)])\n\n            model2 = tf.keras.Sequential([\n                tf.keras.layers.Dense(2, activation=\'softmax\')\n            ])\n            model2.build((2, 2))\n            model2.set_weights(\n                [np.array([[1.0,  2.0], [3.0, 4.0]], dtype=np.float32),\n                 np.array([0.0, 0.0], dtype=np.float32)])\n\n            optimizer = tf.keras.optimizers.Adam(0.001 * hvd.size())\n\n            state = hvd.elastic.KerasState(model1, optimizer, batch=20 + hvd.rank(), epoch=10 + hvd.rank())\n            state.sync()\n\n            model1_weights = model1.get_weights()\n            model2_weights = model2.get_weights()\n\n            # After sync, all values should match the root rank\n            for w in state.model.get_weights():\n                self.assertAllClose(w, np.ones_like(w))\n            assert state.batch == 20\n            assert state.epoch == 10\n\n            # Partially modify then restore\n            model1.set_weights(model2_weights)\n            state.batch = 21\n            state.epoch = 11\n\n            state.restore()\n\n            for w1, w2 in zip(model1.get_weights(), model1_weights):\n                self.assertAllClose(w1, w2)\n            assert state.batch == 20\n            assert state.epoch == 10\n\n            # Partially modify then commit\n            model1.set_weights(model2_weights)\n            state.batch = 21\n            state.epoch = 11\n\n            state.commit()\n            state.restore()\n\n            for w1, w2 in zip(model1.get_weights(), model2_weights):\n                self.assertAllClose(w1, w2)\n            assert state.batch == 21\n            assert state.epoch == 11\n'"
test/test_timeline.py,1,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport time\nimport torch\nimport unittest\nimport warnings\n\nimport horovod.torch as hvd\nfrom horovod.common.util import env\n\nfrom common import temppath\n\n\nclass TimelineTests(unittest.TestCase):\n    """"""\n    Tests for ops in horovod.torch.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(TimelineTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def test_timeline(self):\n        with temppath() as t:\n            with env(HOROVOD_TIMELINE=t, HOROVOD_TIMELINE_MARK_CYCLES=\'1\'):\n                hvd.init()\n\n                # Perform a simple allreduce operation\n                hvd.allreduce(torch.tensor([1, 2, 3], dtype=torch.float32), name=\'test_allreduce\')\n\n                # Wait for it to register in the timeline.\n                time.sleep(0.1)\n\n                if hvd.rank() == 0:\n                    with open(t, \'r\') as tf:\n                        timeline_text = tf.read()\n                        assert \'allreduce.test_allreduce\' in timeline_text, timeline_text\n                        assert \'NEGOTIATE_ALLREDUCE\' in timeline_text, timeline_text\n                        assert \'ALLREDUCE\' in timeline_text, timeline_text\n                        assert \'CYCLE_START\' in timeline_text, timeline_text\n'"
test/test_torch.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright (C) 2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom distutils.version import LooseVersion\n\nimport inspect\nimport itertools\nimport os\nimport pytest\nimport unittest\nimport warnings\n\nfrom collections.abc import Iterable\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport horovod.torch as hvd\n\nfrom common import mpi_env_rank_and_size, temppath\n\n_v2_api = LooseVersion(torch.__version__) >= LooseVersion(\'1.0.0\')\n_fp16_supported = _v2_api\n\nccl_supported_types = set([torch.CharTensor, torch.IntTensor,\n                           torch.LongTensor, torch.FloatTensor, \n                           torch.DoubleTensor])\n\n\nclass TorchTests(unittest.TestCase):\n    """"""\n    Tests for ops in horovod.torch.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(TorchTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n\n    def convert_cpu_fp16_to_fp32(self, *values):\n        # PyTorch doesn\'t support any CPU ops on FP16 tensors.\n        # In case we need to do ops, we will convert tensor to FP32 here.\n        result = []\n        for value in values:\n            if value.dtype in [torch.float16, torch.HalfTensor]:\n                result.append(value.float())\n            else:\n                result.append(value)\n        return result\n\n    def cast_and_place(self, tensor, dtype):\n        if dtype.is_cuda:\n            return tensor.cuda(hvd.local_rank()).type(dtype)\n        return tensor.type(dtype)\n\n    def filter_supported_types(self, types):\n        if \'CCL_ROOT\' in os.environ:\n           types = [t for t in types if t in ccl_supported_types]\n        return types\n\n    def test_horovod_reinit(self):\n        """"""Test that Horovod can init -> shutdown -> init successfully.""""""\n        mpi_rank, _ = mpi_env_rank_and_size()\n        gloo_rank = int(os.getenv(\'HOROVOD_RANK\', -1))\n\n        is_mpi = gloo_rank == -1\n        if is_mpi:\n            # Only applies for Gloo\n            self.skipTest(""Gloo is not available"")\n\n        hvd.init()\n        rank, size = hvd.rank(), hvd.size()\n\n        hvd.shutdown()\n        hvd.init()\n        rank2, size2 = hvd.rank(), hvd.size()\n\n        assert rank == rank2\n        assert size == size2\n\n    def test_horovod_rank(self):\n        """"""Test that the rank returned by hvd.rank() is correct.""""""\n        mpi_rank, _ = mpi_env_rank_and_size()\n        gloo_rank = int(os.getenv(\'HOROVOD_RANK\', -1))\n\n        # The mpi rank does not match gloo rank, we need to figure which one\n        # we are using to run the test.\n        is_mpi = gloo_rank == -1\n        hvd.init()\n        rank = hvd.rank()\n\n        if is_mpi:\n            assert mpi_rank == rank\n        else:\n            assert gloo_rank == rank\n\n    def test_horovod_size(self):\n        """"""Test that the size returned by hvd.size() is correct.""""""\n        _, mpi_size = mpi_env_rank_and_size()\n        gloo_size = int(os.getenv(\'HOROVOD_SIZE\', -1))\n\n        # The mpi size does not match gloo size, we need to figure which one\n        # we are using to run the test.\n        is_mpi = gloo_size == -1\n        hvd.init()\n        size = hvd.size()\n        if is_mpi:\n            assert mpi_size == size\n        else:\n            assert gloo_size == size\n\n    def test_horovod_allreduce(self):\n        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([torch.IntTensor, torch.LongTensor,\n                     torch.FloatTensor, torch.DoubleTensor])\n        if _fp16_supported:\n            dtypes += self.filter_supported_types([torch.HalfTensor])\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            tensor = self.cast_and_place(tensor, dtype)\n            summed = hvd.allreduce(tensor, average=False)\n            tensor, summed = self.convert_cpu_fp16_to_fp32(tensor, summed)\n            multiplied = tensor * size\n            max_difference = summed.data.sub(multiplied).max()\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [torch.IntTensor, torch.LongTensor,\n                                      torch.cuda.IntTensor, torch.cuda.LongTensor]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            assert max_difference <= threshold, \'hvd.allreduce produces incorrect results\'\n\n    def test_horovod_allreduce_average(self):\n        """"""Test that the allreduce correctly averages 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([torch.IntTensor, torch.LongTensor,\n                     torch.FloatTensor, torch.DoubleTensor])\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            tensor = self.cast_and_place(tensor, dtype)\n            averaged = hvd.allreduce(tensor, average=True)\n            max_difference = averaged.data.sub(tensor).max()\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [torch.IntTensor, torch.LongTensor,\n                                      torch.cuda.IntTensor, torch.cuda.LongTensor]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            assert max_difference <= threshold, \'hvd.allreduce produces incorrect results\'\n\n    def test_horovod_allreduce_inplace(self):\n        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([torch.IntTensor, torch.LongTensor,\n                     torch.FloatTensor, torch.DoubleTensor])\n        if _fp16_supported:\n            dtypes += self.filter_supported_types([torch.HalfTensor])\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            multiplied = self.cast_and_place(tensor * size, dtype)\n            tensor = self.cast_and_place(tensor, dtype)\n            hvd.allreduce_(tensor, average=False)\n            tensor, multiplied = self.convert_cpu_fp16_to_fp32(tensor, multiplied)\n            max_difference = tensor.sub(multiplied).max()\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [torch.IntTensor, torch.LongTensor,\n                                      torch.cuda.IntTensor, torch.cuda.LongTensor]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            assert max_difference <= threshold, \'hvd.allreduce produces incorrect results\'\n\n    def test_horovod_allreduce_async_fused(self):\n        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors\n        with Tensor Fusion.""""""\n        hvd.init()\n        size = hvd.size()\n        dtypes = self.filter_supported_types([torch.IntTensor, torch.LongTensor,\n                  torch.FloatTensor, torch.DoubleTensor])\n        if _fp16_supported:\n            dtypes += self.filter_supported_types([torch.HalfTensor])\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        tests = []\n        is_hvd_poll_false_once = False\n        for dtype, dim in itertools.product(dtypes, dims):\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            tensor = self.cast_and_place(tensor, dtype)\n            handle = hvd.allreduce_async(tensor, average=False)\n            if not hvd.poll(handle):\n                is_hvd_poll_false_once = True\n            tensor, = self.convert_cpu_fp16_to_fp32(tensor)\n            multiplied = tensor * size\n            tests.append((dtype, multiplied, handle))\n\n        # Make sure it\'s an asynchronous operation.\n        assert is_hvd_poll_false_once, \'hvd.poll() always returns True, not an async op?\'\n\n        for dtype, multiplied, handle in tests:\n            summed = hvd.synchronize(handle)\n            summed, = self.convert_cpu_fp16_to_fp32(summed)\n            max_difference = summed.sub(multiplied).max()\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [torch.IntTensor, torch.LongTensor,\n                                      torch.cuda.IntTensor, torch.cuda.LongTensor]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            assert max_difference <= threshold, \'hvd.allreduce produces incorrect results\'\n\n    def test_horovod_allreduce_multi_gpu(self):\n        """"""Test that the allreduce works on multiple GPUs.""""""\n        # Only do this test if there are GPUs available.\n        if not torch.cuda.is_available():\n            self.skipTest(""No GPUs available"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # Skip the test if there are not enough GPUs.\n        if torch.cuda.device_count() < hvd.local_size() * 2:\n            self.skipTest(""Not enough GPUs available"")\n\n        iter = 0\n        dtypes = [torch.cuda.IntTensor, torch.cuda.LongTensor,\n                  torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n        if _fp16_supported:\n            dtypes += [torch.cuda.HalfTensor]\n\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            iter += 1\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            device = local_rank * 2 + (iter + local_rank) % 2\n            tensor = tensor.cuda(device).type(dtype)\n            multiplied = tensor * size\n            hvd.allreduce_(tensor, average=False)\n            max_difference = tensor.sub(multiplied).max()\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [torch.cuda.IntTensor, torch.cuda.LongTensor]:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            assert max_difference <= threshold, \'hvd.allreduce produces incorrect results\'\n\n    def test_horovod_allreduce_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n        send tensors of different rank or dimension.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Same rank, different dimension\n        torch.manual_seed(1234)\n        dims = [17 + rank] * 3\n        tensor = torch.FloatTensor(*dims).random_(-100, 100)\n        try:\n            hvd.allreduce(tensor)\n            assert False, \'hvd.allreduce did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n        # Same number of elements, different rank\n        torch.manual_seed(1234)\n        if rank == 0:\n            dims = [17, 23 * 57]\n        else:\n            dims = [17, 23, 57]\n        tensor = torch.FloatTensor(*dims).random_(-100, 100)\n        try:\n            hvd.allreduce(tensor)\n            assert False, \'hvd.allreduce did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_allreduce_type_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n        send tensors of different type.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Same rank, different dimension\n        dims = [17] * 3\n        if rank % 2 == 0:\n            tensor = torch.IntTensor(*dims)\n        else:\n            tensor = torch.FloatTensor(*dims)\n\n        try:\n            hvd.allreduce(tensor)\n            assert False, \'hvd.allreduce did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_allreduce_cpu_gpu_error(self):\n        """"""Test that the allreduce raises an error if different ranks try to\n        perform reduction on CPU and GPU.""""""\n        # Only do this test if there are GPUs available.\n        if not torch.cuda.is_available():\n            self.skipTest(""No GPUs available"")\n\n        if os.environ.get(\'HOROVOD_MIXED_INSTALL\'):\n            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.\n            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")\n\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Same rank, different dimension\n        dims = [17] * 3\n        if rank % 2 == 0:\n            tensor = torch.cuda.FloatTensor(*dims)\n        else:\n            tensor = torch.FloatTensor(*dims)\n\n        try:\n            hvd.allreduce(tensor)\n            assert False, \'hvd.allreduce did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_allreduce_duplicate_name_error(self):\n        """"""Test that the allreduce raises an error if there are\n        two concurrent operations with the same name.""""""\n        hvd.init()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dims = [17] * 3\n        tensor = torch.FloatTensor(*dims)\n\n        hvd.allreduce_async(tensor, name=\'duplicate_name\')\n        try:\n            for i in range(10):\n                hvd.allreduce_async(tensor, name=\'duplicate_name\')\n            assert False, \'hvd.allreduce_async did not throw error\'\n        except (torch.FatalError, ValueError):\n            pass\n\n    def test_horovod_allreduce_grad(self):\n        """"""Test the correctness of the allreduce gradient.""""""\n        hvd.init()\n        size = hvd.size()\n        # Only Tensors of floating point dtype can require gradients\n        dtypes = [torch.FloatTensor, torch.DoubleTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            tensor = self.cast_and_place(tensor, dtype)\n            tensor.requires_grad_()\n            summed = hvd.allreduce(tensor, average=False)\n\n            summed.backward(self.cast_and_place(torch.ones([17] * dim), dtype))\n            grad_out = tensor.grad.data.cpu().numpy()\n\n            expected = np.ones([17] * dim) * size\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_allreduce_grad_average(self):\n        """"""Test the correctness of the allreduce averaged gradient.""""""\n        hvd.init()\n        # Only Tensors of floating point dtype can require gradients\n        dtypes = [torch.FloatTensor, torch.DoubleTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            torch.manual_seed(1234)\n            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            tensor = self.cast_and_place(tensor, dtype)\n            tensor.requires_grad_()\n            summed = hvd.allreduce(tensor, average=True)\n\n            summed.backward(self.cast_and_place(torch.ones([17] * dim), dtype))\n            grad_out = tensor.grad.data.cpu().numpy()\n\n            expected = np.ones([17] * dim)\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_allgather(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [torch.ByteTensor, torch.CharTensor, torch.ShortTensor,\n                  torch.IntTensor, torch.LongTensor, torch.FloatTensor, torch.DoubleTensor]\n        if _fp16_supported:\n            dtypes += [torch.HalfTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.ByteTensor, torch.cuda.CharTensor, torch.cuda.ShortTensor,\n                       torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            tensor = torch.FloatTensor(*([17] * dim)).fill_(1).mul_(rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            gathered = hvd.allgather(tensor)\n            tensor, gathered = self.convert_cpu_fp16_to_fp32(tensor, gathered)\n\n            assert list(gathered.shape) == [17 * size] + [17] * (dim - 1)\n\n            for i in range(size):\n                rank_tensor = gathered[i * 17:(i + 1) * 17]\n                assert list(rank_tensor.shape) == [17] * dim, \\\n                    \'hvd.allgather produces incorrect gathered shape\'\n                assert rank_tensor.data.min() == i, \'hvd.allgather produces incorrect gathered tensor\'\n                assert rank_tensor.data.max() == i, \'hvd.allgather produces incorrect gathered tensor\'\n\n    def test_horovod_allgather_variable_size(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors,\n        even if those tensors have different sizes along the first dim.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [torch.ByteTensor, torch.CharTensor, torch.ShortTensor,\n                  torch.IntTensor, torch.LongTensor, torch.FloatTensor, torch.DoubleTensor]\n        if _fp16_supported:\n            dtypes += [torch.HalfTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.ByteTensor, torch.cuda.CharTensor, torch.cuda.ShortTensor,\n                       torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            # Support tests up to MPI Size of 35\n            if size > 35:\n                break\n\n            tensor_sizes = [17, 32, 81, 12, 15, 23, 22] * 5\n            tensor_sizes = tensor_sizes[:size]\n\n            tensor = torch.FloatTensor(\n                *([tensor_sizes[rank]] + [17] * (dim - 1))).fill_(1).mul_(rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            gathered = hvd.allgather(tensor)\n            tensor, gathered = self.convert_cpu_fp16_to_fp32(tensor, gathered)\n\n            expected_size = sum(tensor_sizes)\n            assert list(gathered.shape) == [expected_size] + [17] * (dim - 1)\n\n            for i in range(size):\n                rank_size = [tensor_sizes[i]] + [17] * (dim - 1)\n                rank_tensor = gathered[sum(\n                    tensor_sizes[:i]):sum(tensor_sizes[:i + 1])]\n                assert list(rank_tensor.shape) == rank_size\n                assert rank_tensor.data.min() == i\n                assert rank_tensor.data.max() == i\n\n    def test_horovod_allgather_async_fused(self):\n        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors\n        with Tensor Fusion.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = [torch.ByteTensor, torch.CharTensor, torch.ShortTensor,\n                  torch.IntTensor, torch.LongTensor, torch.FloatTensor, torch.DoubleTensor]\n        if _fp16_supported:\n            dtypes += [torch.HalfTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.ByteTensor, torch.cuda.CharTensor, torch.cuda.ShortTensor,\n                       torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        tests = []\n        is_hvd_poll_false_once = False\n        for dtype, dim in itertools.product(dtypes, dims):\n            rank_shape = [17] * dim\n            tensor = torch.FloatTensor(*(rank_shape)).fill_(1).mul_(rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            handle = hvd.allgather_async(tensor)\n            if not hvd.poll(handle):\n                is_hvd_poll_false_once = True\n            tests.append((handle, rank_shape))\n\n        # Make sure it\'s an asynchronous operation.\n        assert is_hvd_poll_false_once, \'hvd.poll() always returns True, not an async op?\'\n\n        for handle, rank_shape in tests:\n            gathered = hvd.synchronize(handle)\n            gathered, = self.convert_cpu_fp16_to_fp32(gathered)\n\n            for i in range(size):\n                rank_tensor = gathered[i * 17:(i + 1) * 17]\n                assert list(rank_tensor.shape) == rank_shape, \\\n                    \'hvd.allgather produces incorrect gathered shape\'\n                assert rank_tensor.data.min() == i, \'hvd.allgather produces incorrect gathered tensor\'\n                assert rank_tensor.data.max() == i, \'hvd.allgather produces incorrect gathered tensor\'\n\n    def test_horovod_allgather_error(self):\n        """"""Test that the allgather returns an error if any dimension besides\n        the first is different among the tensors being gathered.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        tensor_size[1] = 10 * (rank + 1)\n        tensor = torch.FloatTensor(*tensor_size).fill_(1).mul_(rank)\n\n        try:\n            hvd.allgather(tensor)\n            assert False, \'hvd.allgather did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_allgather_type_error(self):\n        """"""Test that the allgather returns an error if the types being gathered\n        differ among the processes""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        if rank % 2 == 0:\n            tensor = torch.IntTensor(*tensor_size)\n        else:\n            tensor = torch.FloatTensor(*tensor_size)\n\n        try:\n            hvd.allgather(tensor)\n            assert False, \'hvd.allgather did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_allgather_duplicate_name_error(self):\n        """"""Test that the allgather raises an error if there are\n        two concurrent operations with the same name.""""""\n        hvd.init()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dims = [17] * 3\n        tensor = torch.FloatTensor(*dims)\n\n        hvd.allgather_async(tensor, name=\'duplicate_name\')\n        try:\n            for i in range(10):\n                hvd.allgather_async(tensor, name=\'duplicate_name\')\n            assert False, \'hvd.allgather_async did not throw error\'\n        except (torch.FatalError, ValueError):\n            pass\n\n    def test_horovod_allgather_grad(self):\n        """"""Test the correctness of the allgather gradient.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # Only Tensors of floating point dtype can require gradients\n        dtypes = [torch.FloatTensor, torch.DoubleTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        for dtype, dim in itertools.product(dtypes, dims):\n            # Support tests up to MPI Size of 35\n            if size > 35:\n                break\n\n            tensor_sizes = [3, 2, 7, 4, 6, 8, 10] * 5\n            tensor_sizes = tensor_sizes[:size]\n\n            tensor = torch.FloatTensor(\n                *([tensor_sizes[rank]] + [17] * (dim - 1))).fill_(1).mul_(rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            tensor.requires_grad_()\n\n            grad_list = []\n            for r, size in enumerate(tensor_sizes):\n                grad_list.append(self.cast_and_place(\n                    torch.ones([size] + [17] * (dim - 1)), dtype) * r)\n            grad_ys = torch.cat(grad_list, dim=0)\n\n            gathered = hvd.allgather(tensor)\n            gathered.backward(grad_ys)\n            grad_out = tensor.grad.data.cpu().numpy()\n\n            expected = np.ones(\n                [tensor_sizes[rank]] + [17] * (dim - 1)\n            ) * rank * size\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_horovod_broadcast(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [torch.ByteTensor, torch.CharTensor, torch.ShortTensor,\n                  torch.IntTensor, torch.LongTensor, torch.FloatTensor, torch.DoubleTensor]\n        if _fp16_supported:\n            dtypes += [torch.HalfTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.ByteTensor, torch.cuda.CharTensor, torch.cuda.ShortTensor,\n                       torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            tensor = torch.FloatTensor(*([17] * dim)).fill_(1).mul_(rank)\n            root_tensor = torch.FloatTensor(*([17] * dim)).fill_(1).mul_(root_rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            root_tensor = self.cast_and_place(root_tensor, dtype)\n            broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n            tensor, root_tensor, broadcasted_tensor = \\\n                self.convert_cpu_fp16_to_fp32(tensor, root_tensor, broadcasted_tensor)\n            if rank != root_rank:\n                assert (tensor == root_tensor).max() == 0, \\\n                    \'hvd.broadcast modifies source tensor\'\n            assert (broadcasted_tensor.data == root_tensor).min() == 1, \\\n                \'hvd.broadcast produces incorrect broadcasted tensor\'\n\n    def test_horovod_broadcast_inplace(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dtypes = [torch.ByteTensor, torch.CharTensor, torch.ShortTensor,\n                  torch.IntTensor, torch.LongTensor, torch.FloatTensor, torch.DoubleTensor]\n        if _fp16_supported:\n            dtypes += [torch.HalfTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.ByteTensor, torch.cuda.CharTensor, torch.cuda.ShortTensor,\n                       torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            tensor = torch.FloatTensor(*([17] * dim)).fill_(1).mul_(rank)\n            root_tensor = torch.FloatTensor(*([17] * dim)).fill_(1).mul_(root_rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            root_tensor = self.cast_and_place(root_tensor, dtype)\n            broadcasted_tensor = hvd.broadcast_(tensor, root_rank)\n            tensor, root_tensor, broadcasted_tensor = \\\n                self.convert_cpu_fp16_to_fp32(tensor, root_tensor, broadcasted_tensor)\n            assert (tensor == broadcasted_tensor).min() == 1, \\\n                \'hvd.broadcast does not modify source tensor\'\n            assert (broadcasted_tensor == root_tensor).min() == 1, \\\n                \'hvd.broadcast produces incorrect broadcasted tensor\'\n\n    def test_horovod_broadcast_error(self):\n        """"""Test that the broadcast returns an error if any dimension besides\n        the first is different among the tensors being broadcasted.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        tensor_size[1] = 10 * (rank + 1)\n        tensor = torch.FloatTensor(*tensor_size).fill_(1).mul_(rank)\n\n        try:\n            hvd.broadcast(tensor, 0)\n            assert False, \'hvd.broadcast did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_broadcast_type_error(self):\n        """"""Test that the broadcast returns an error if the types being broadcasted\n        differ among the processes""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor_size = [17] * 3\n        if rank % 2 == 0:\n            tensor = torch.IntTensor(*tensor_size)\n        else:\n            tensor = torch.FloatTensor(*tensor_size)\n\n        try:\n            hvd.broadcast(tensor, 0)\n            assert False, \'hvd.broadcast did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_broadcast_rank_error(self):\n        """"""Test that the broadcast returns an error if different ranks\n        specify different root rank.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        tensor = torch.FloatTensor(*([17] * 3)).fill_(1)\n\n        try:\n            hvd.broadcast(tensor, rank)\n            assert False, \'hvd.broadcast did not throw error\'\n        except (torch.FatalError, RuntimeError):\n            pass\n\n    def test_horovod_broadcast_duplicate_name_error(self):\n        """"""Test that the broadcast raises an error if there are\n        two concurrent operations with the same name.""""""\n        hvd.init()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dims = [17] * 3\n        tensor = torch.FloatTensor(*dims)\n\n        hvd.broadcast_async(tensor, root_rank=0, name=\'duplicate_name\')\n        try:\n            for i in range(10):\n                hvd.broadcast_async(tensor, root_rank=0, name=\'duplicate_name\')\n            assert False, \'hvd.broadcast_async did not throw error\'\n        except (torch.FatalError, ValueError):\n            pass\n\n    def test_horovod_broadcast_grad(self):\n        """"""Test the correctness of the broadcast gradient.""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Only Tensors of floating point dtype can require gradients\n        dtypes = [torch.FloatTensor, torch.DoubleTensor]\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims, root_ranks):\n            tensor = torch.FloatTensor(*([17] * dim)).fill_(1).mul_(rank)\n            tensor = self.cast_and_place(tensor, dtype)\n            tensor.requires_grad_()\n\n            broadcasted_tensor = hvd.broadcast(tensor, root_rank)\n            broadcasted_tensor.backward(self.cast_and_place(torch.ones([17] * dim), dtype))\n            grad_out = tensor.grad.data.cpu().numpy()\n\n            c = size if rank == root_rank else 0\n            expected = np.ones([17] * dim) * c\n            err = np.linalg.norm(expected - grad_out)\n            self.assertLess(err, 0.00000001,\n                            ""gradient %s differs from expected %s, ""\n                            ""error: %s"" % (grad_out, expected, str(err)))\n\n    def test_broadcast_state(self):\n        hvd.init()\n\n        N, D_in, H, D_out = 64, 100, 10, 10\n        x = torch.randn(N, D_in).requires_grad_()\n        y = torch.randn(N, D_out).requires_grad_()\n\n        def new_optimizer(cls, opt_params, model):\n            p = {\n                k: v for k, v in opt_params.items()\n                if k in inspect.getargspec(cls.__init__).args\n            }\n            return cls(model.parameters(), **p)\n\n        def create_model(opt_class, opt_params):\n            model = torch.nn.Sequential(\n                torch.nn.Linear(D_in, H),\n                torch.nn.ReLU(),\n                torch.nn.Linear(H, D_out),\n            )\n\n            optimizer = new_optimizer(opt_class, opt_params, model)\n            optimizer = hvd.DistributedOptimizer(\n                optimizer, named_parameters=model.named_parameters())\n\n            return model, optimizer\n\n        def get_model_param_values(model):\n            params = sorted(model.state_dict().items())\n            return [(k, v.clone()) for k, v in params]\n\n        def get_optimizer_param_values(optimizer):\n            results = []\n            state_dict = optimizer.state_dict()\n            for group in state_dict[\'param_groups\']:\n                for param_id in group[\'params\']:\n                    if param_id not in state_dict[\'state\']:\n                        continue\n                    params = sorted(state_dict[\'state\'][param_id].items())\n                    for k, v in params:\n                        results.append(\n                            (k, v.clone() if torch.is_tensor(v) else v))\n            return results\n\n        # L-BFGS is currently unsupported, as are sparse tensors, which are\n        # required by SparseAdam optimizer\n        optimizers = [\n            (subclass.__name__, subclass)\n            for subclass in torch.optim.Optimizer.__subclasses__()\n            if subclass.__module__.startswith(\'torch.optim\') and\n               subclass != torch.optim.LBFGS and\n               subclass != torch.optim.SparseAdam\n        ]\n        optimizers.sort()\n\n        opt_params_list = [\n            dict(lr=0.2, momentum=0.9, weight_decay=0.1, centered=True),\n            dict(lr=0.2)\n        ]\n\n        for (opt_name, opt_class), opt_params in itertools.product(optimizers, opt_params_list):\n            model, optimizer = create_model(opt_class, opt_params)\n            y_pred = model(x)\n            loss = F.mse_loss(y_pred, y, size_average=False)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            model_param_values = get_model_param_values(model)\n            for name, model_param_value in model_param_values:\n                hvd.broadcast_(model_param_value, root_rank=0)\n\n            opt_param_values_updated = []\n            opt_param_values = get_optimizer_param_values(optimizer)\n            for name, opt_param_value in opt_param_values:\n                is_tensor = torch.is_tensor(opt_param_value)\n                if not is_tensor:\n                    t = type(opt_param_value)\n                    opt_param_value = torch.Tensor([opt_param_value])\n                hvd.broadcast_(opt_param_value, root_rank=0)\n                if not is_tensor:\n                    opt_param_value = t(opt_param_value.cpu().numpy()[0])\n                opt_param_values_updated.append((name, opt_param_value))\n            opt_param_values = opt_param_values_updated\n\n            with temppath() as fname:\n                if hvd.rank() == 0:\n                    state = {\n                        \'model\': model.state_dict(),\n                        \'optimizer\': optimizer.state_dict(),\n                    }\n                    torch.save(state, fname)\n\n                model, optimizer = create_model(opt_class, opt_params)\n                if hvd.rank() == 0:\n                    checkpoint = torch.load(fname)\n                    model.load_state_dict(checkpoint[\'model\'])\n                    optimizer.load_state_dict(checkpoint[\'optimizer\'])\n\n            hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n            model_param_value_after = get_model_param_values(model)\n            for before, after in zip(model_param_values,\n                                     model_param_value_after):\n                name, model_param_value = before\n                name_after, model_param_value_after = after\n                self.assertEqual(name, name_after)\n                self.assertEqual(type(model_param_value),\n                                 type(model_param_value_after))\n                self.assertTrue(\n                    (model_param_value == model_param_value_after).all())\n\n            hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n            expected_tensors = 4\n            if \'momentum\' not in opt_params and opt_class == torch.optim.SGD:\n                # SGD only maintains state when momentum is specified, otherwise\n                # it does not populate the state dict, so it will contain no tensors.\n                expected_tensors = 0\n            self.assertEqual(len(optimizer.state_dict()[\'state\'].values()), expected_tensors)\n\n            opt_param_values_after = get_optimizer_param_values(optimizer)\n            for before, after in zip(opt_param_values, opt_param_values_after):\n                name, opt_param_value = before\n                name_after, opt_param_value_after = after\n                self.assertEqual(name, name_after)\n                self.assertEqual(type(opt_param_value),\n                                 type(opt_param_value_after))\n                if torch.is_tensor(opt_param_value):\n                    self.assertTrue(\n                        (opt_param_value == opt_param_value_after).all())\n                else:\n                    self.assertEqual(opt_param_value, opt_param_value_after)\n\n    # TODO: investigate why this hangs on K80s\n    @unittest.skip\n    def test_broadcast_state_gpu(self):\n        # Only do this test if there are GPUs available.\n        if not torch.cuda.is_available():\n            self.skipTest(""No GPUs available"")\n        # Set default tensor type, ensuring optimizer tensor-wrapping is robust\n        # to this setting.\n        try:\n            torch.set_default_tensor_type(torch.cuda.FloatTensor)\n            self.test_broadcast_state()\n        finally:\n            torch.set_default_tensor_type(torch.FloatTensor)\n\n    def test_broadcast_state_options(self):\n        hvd.init()\n\n        N, D_in, H, D_out = 64, 100, 10, 10\n        x = torch.randn(N, D_in).requires_grad_()\n        y = torch.randn(N, D_out).requires_grad_()\n\n        params_0 = dict(lr=0.1, momentum=0.8, weight_decay=0.2, nesterov=True,\n                        betas=(0.9, 0.999), etas=(0.8, 2.4), step_sizes=(1e-5, 100))\n        params_1 = dict(lr=0.2, momentum=0.9, weight_decay=0.1, nesterov=False,\n                        betas=(0.8, 0.9), etas=(0.25, 1.75), step_sizes=(1e-7, 5))\n\n        def create_model(opt_class):\n            model = torch.nn.Sequential(\n                torch.nn.Linear(D_in, H),\n                torch.nn.ReLU(),\n                torch.nn.Linear(H, D_out),\n            )\n\n            params = params_0 if hvd.rank() == 0 else params_1\n            p = {\n                k: v for k, v in params.items()\n                if k in inspect.getargspec(opt_class.__init__).args\n            }\n            opt = opt_class(model.parameters(), **p)\n            opt = hvd.DistributedOptimizer(opt, named_parameters=model.named_parameters())\n\n            return model, opt\n\n        # Include subclass name so we can sort them lexicographically, otherwise different\n        # ranks will have different optimizer orderings\n        optimizers = [\n            (subclass.__name__, subclass)\n            for subclass in torch.optim.Optimizer.__subclasses__()\n            if subclass.__module__.startswith(\'torch.optim\') and\n               subclass != torch.optim.LBFGS and\n               subclass != torch.optim.SparseAdam\n        ]\n        optimizers.sort()\n\n        for _, opt_class in optimizers:\n            model, optimizer = create_model(opt_class)\n            y_pred = model(x)\n            loss = F.mse_loss(y_pred, y, size_average=False)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n            p0 = {\n                k: v for k, v in params_0.items()\n                if k in inspect.getargspec(opt_class.__init__).args\n            }\n            for k, p in p0.items():\n                p_actual = optimizer.param_groups[0][k]\n                if not isinstance(p, Iterable):\n                    p_actual = [p_actual]\n                    p = [p]\n                for i in range(len(p)):\n                    self.assertEqual(type(p_actual[i]), type(p[i]))\n                    self.assertAlmostEqual(p_actual[i], p[i], delta=1e-5)\n\n            # Ensure that the parameter option types are compatible with ops\n            y_pred = model(x)\n            loss = F.mse_loss(y_pred, y, size_average=False)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n    @pytest.mark.skipif(LooseVersion(torch.__version__) < LooseVersion(\'0.4.1\'),\n                        reason=\'Cannot optimize parameters that do not require gradients before PyTorch 0.4.1\')\n    def test_broadcast_state_no_grad(self):\n        class ModelNoGrad(nn.Module):\n            def __init__(self, a, b):\n                super(ModelNoGrad, self).__init__()\n                self.a = nn.Parameter(a.int(), requires_grad=False)\n                self.b = nn.Parameter(b)\n\n            def forward(self, x):\n                return torch.index_select(self.b, 0, self.a.long()) * x\n\n        hvd.init()\n\n        a = torch.Tensor([1, 3])\n        b = torch.rand(4)\n\n        model = ModelNoGrad(a, b)\n\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-6, momentum=0.9, nesterov=True)\n        optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\n\n        hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n        hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n        grad = optimizer.param_groups[0][\'params\'][1].grad\n        bgrad = hvd.broadcast(grad, root_rank=0)\n\n        assert optimizer.param_groups[0][\'params\'][0].grad is None\n        assert torch.all(torch.eq(grad, bgrad)).item()\n\n    def test_broadcast_object(self):\n        hvd.init()\n\n        expected_obj = {\n            \'hello\': 123,\n            0: [1, 2]\n        }\n        obj = expected_obj if hvd.rank() == 0 else {}\n\n        obj = hvd.broadcast_object(obj, root_rank=0)\n        self.assertDictEqual(obj, expected_obj)\n\n    def test_compression_fp16(self):\n        valid_dtypes = [torch.float32, torch.float64]\n        invalid_dtypes = [torch.uint8, torch.int8, torch.int16,\n                          torch.int32, torch.int64]\n\n        tensor_size = [5] * 3\n        compression = hvd.Compression.fp16\n\n        for dtype in valid_dtypes:\n            tensor = torch.ones(tensor_size, dtype=dtype)\n\n            tensor_compressed, ctx = compression.compress(tensor)\n            self.assertEqual(tensor_compressed.dtype, torch.float16)\n\n            tensor_decompressed = compression.decompress(tensor_compressed, ctx)\n            self.assertEqual(tensor_decompressed.dtype, dtype)\n\n            expected = np.ones(tensor_size)\n            err = np.linalg.norm(expected - tensor_decompressed.data.numpy())\n            self.assertLess(err, 0.00000001)\n\n        for dtype in invalid_dtypes:\n            tensor = torch.ones(tensor_size, dtype=dtype)\n\n            tensor_compressed, ctx = compression.compress(tensor)\n            self.assertEqual(tensor_compressed.dtype, dtype)\n\n            tensor_decompressed = compression.decompress(tensor_compressed, ctx)\n            self.assertEqual(tensor_decompressed.dtype, dtype)\n\n            if dtype != torch.int8:  # Cannot cast to NumPy with a CharTensor\n                expected = np.ones(tensor_size)\n                err = np.linalg.norm(expected - tensor_decompressed.data.numpy())\n                self.assertLess(err, 0.00000001)\n\n    def test_force_allreduce(self):\n        """"""Test that allreduce is forced on all gradients during opt.step().""""""\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        N, D_in, H, D_out = 64, 100, 10, 10\n        x = torch.randn(N, D_in).requires_grad_()\n        y = torch.randn(N, D_out).requires_grad_()\n\n        def new_optimizer(cls, opt_params, model):\n            p = {\n                k: v for k, v in opt_params.items()\n                if k in inspect.getargspec(cls.__init__).args\n            }\n            return cls(model.parameters(), **p)\n\n        class Net(torch.nn.Module):\n            def __init__(self):\n                super(Net, self).__init__()\n                self.fc1 = torch.nn.Linear(D_in, H)\n                self.fc2 = torch.nn.Linear(H, D_out)\n                self.fc3 = torch.nn.Linear(D_out, D_out)\n\n            def forward(self, x_):\n                x_ = F.relu(self.fc1(x_))\n                x1_ = self.fc2(x_)\n                x2_ = self.fc3(F.relu(x1_))\n                return x1_, x2_\n\n        def create_model(opt_class, opt_params):\n            model = Net()\n            hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n            opt = new_optimizer(opt_class, opt_params, model)\n            opt = hvd.DistributedOptimizer(\n                opt, named_parameters=model.named_parameters())\n            return model, opt\n\n        # L-BFGS is currently unsupported, as are sparse tensors, which are\n        # required by SparseAdam optimizer\n        optimizers = [\n            (subclass.__name__, subclass)\n            for subclass in torch.optim.Optimizer.__subclasses__()\n            if subclass.__module__.startswith(\'torch.optim\') and\n               subclass != torch.optim.LBFGS and\n               subclass != torch.optim.SparseAdam\n        ]\n        optimizers.sort()\n\n        opt_params_list = [\n            dict(lr=0.2, momentum=0.9, weight_decay=0.1, centered=True),\n            dict(lr=0.2)\n        ]\n\n        for (opt_name, opt_class), opt_params in itertools.product(optimizers, opt_params_list):\n            model, optimizer = create_model(opt_class, opt_params)\n            y_pred1, y_pred2 = model(x)\n            if rank == 0:\n                loss = F.mse_loss(y_pred1, y, size_average=False)\n            else:\n                loss = F.mse_loss(y_pred2, y, size_average=False)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n    def test_model_parallelism(self):\n        """"""Test that tensors on different GPUs are supported.""""""\n        # Only do this test if there are GPUs available.\n        if not torch.cuda.is_available():\n            self.skipTest(""No GPUs available"")\n\n        hvd.init()\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        # Skip the test if there are not enough GPUs.\n        if torch.cuda.device_count() < hvd.local_size() * 2:\n            self.skipTest(""Not enough GPUs available"")\n\n        first_device = local_rank * 2\n        second_device = local_rank * 2 + 1\n\n        class Net(torch.nn.Module):\n            def __init__(self):\n                super(Net, self).__init__()\n                # Place parts of model on different GPUs.\n                self.conv1 = torch.nn.Conv2d(1, 100, 1).cuda(first_device)\n                self.conv2 = torch.nn.Conv2d(100, 1, 1).cuda(second_device)\n\n            def forward(self, x):\n                x = x.cuda(first_device)\n                x = self.conv1(x)\n                x = x.cuda(second_device)\n                x = self.conv2(x)\n                return x\n\n        model = Net()\n        inp = torch.rand([1, 1, 1000, 1000])\n\n        opt = torch.optim.SGD(model.parameters(), lr=0.1)\n        opt = hvd.DistributedOptimizer(opt, named_parameters=model.named_parameters())\n\n        loss = model(inp).sum()\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    def test_delta_optimizer(self):\n        """"""Test that delta optimizer.""""""\n        hvd.init()\n        # TODO support non-MPI Adasum operation\n        # Only do this test if there are GPUs available.\n        if not hvd.mpi_enabled() or not torch.cuda.is_available():\n            self.skipTest(""No GPUs available"")\n\n        local_rank = hvd.local_rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        class Net(torch.nn.Module):\n            def __init__(self):\n                super(Net, self).__init__()\n                self.conv1 = torch.nn.Conv2d(1, 100, 1).cuda(local_rank)\n                self.conv2 = torch.nn.Conv2d(100, 1, 1).cuda(local_rank)\n\n            def forward(self, x):\n                x = x.cuda(local_rank)\n                x = self.conv1(x)\n                x = x.cuda(local_rank)\n                x = self.conv2(x)\n                return x\n\n        model = Net()\n        inp = torch.rand([1, 1, 1000, 1000])\n\n        opt = torch.optim.SGD(model.parameters(), lr=0.1)\n\n        opt = hvd.DistributedOptimizer(opt, named_parameters=model.named_parameters(), op=hvd.Adasum)\n        loss = model(inp).sum()\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    def test_duplicate_names(self):\n        """"""Test that passing duplicate names to optimizer will fail.""""""\n        net1 = torch.nn.Conv2d(1, 1, 1)\n        net2 = torch.nn.Conv2d(1, 1, 1)\n\n        parameters = itertools.chain(net1.parameters(), net2.parameters())\n        opt = torch.optim.SGD(parameters, lr=0.1)\n\n        # This will have duplicate names, since both net1 and net2 have \'weight\' and \'bias\'\n        named_parameters = itertools.chain(net1.named_parameters(), net2.named_parameters())\n        try:\n            hvd.DistributedOptimizer(opt, named_parameters=named_parameters)\n            assert False, \'hvd.DistributedOptimizer did not throw error\'\n        except ValueError:\n            pass\n\n    def test_dynamic_requires_grad(self):\n        """"""Test that makes sure that gradients can be turned off/on dynamically.""""""\n        hvd.init()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        gen = torch.nn.Conv2d(1, 10, 1)\n        disc = torch.nn.Conv2d(10, 1, 1)\n        inp = torch.rand([1, 1, 100, 100])\n\n        gen_opt = torch.optim.SGD(gen.parameters(), lr=0.1)\n        gen_opt = hvd.DistributedOptimizer(gen_opt, named_parameters=gen.named_parameters())\n\n        disc_opt = torch.optim.SGD(disc.parameters(), lr=0.1)\n        disc_opt = hvd.DistributedOptimizer(disc_opt, named_parameters=disc.named_parameters())\n\n        def train_step(train_generator=False, train_discriminator=False):\n            for p in gen.parameters():\n                p.requires_grad_(train_generator)\n            for p in disc.parameters():\n                p.requires_grad_(train_discriminator)\n\n            gen_opt.zero_grad()\n            disc_opt.zero_grad()\n\n            loss = disc(gen(inp)).sum()\n            loss.backward()\n\n            for p in gen.parameters():\n                assert train_generator == p.grad.max().is_nonzero(), \\\n                    \'Gradient for generator is zero but it should be trained or vice versa.\'\n            for p in disc.parameters():\n                assert train_discriminator == p.grad.max().is_nonzero(), \\\n                    \'Gradient for discriminator is zero but it should be trained or vice versa.\'\n\n            if train_generator:\n                gen_opt.step()\n            if train_discriminator:\n                disc_opt.step()\n\n        for x in range(10):\n            # Step 1: train generator.\n            train_step(train_generator=True)\n\n            # Step 2: train discriminator.\n            train_step(train_discriminator=True)\n\n    def test_gradient_clipping(self):\n        """"""Test gradient clipping example.""""""\n        hvd.init()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        x = torch.ones(1, 1).requires_grad_()\n        y = torch.ones(1, 1).requires_grad_()\n\n        model = torch.nn.Linear(1, 1)\n        model.weight = torch.nn.Parameter(torch.zeros(1, 1) + 0.5)\n        model.bias = torch.nn.Parameter(torch.zeros(1))\n        hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n        optimizer = hvd.DistributedOptimizer(\n            optimizer, named_parameters=model.named_parameters())\n\n        y_pred = model(x)\n        loss = F.mse_loss(y_pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.synchronize()\n        prior_grad = model.weight.grad.item()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        clipped_grad = model.weight.grad.item()\n        assert abs(prior_grad) > abs(clipped_grad)\n        with optimizer.skip_synchronize():\n            optimizer.step()\n\n    def test_synchronize_step_warning(self):\n        """"""\n        Test that .synchronize() followed by .step() without\n        optimizer.skip_synchronize() context will produce a warning.\n        """"""\n        hvd.init()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        x = torch.zeros(1, 1).requires_grad_()\n        y = torch.ones(1, 1).requires_grad_()\n\n        model = torch.nn.Linear(1, 1)\n        hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n        optimizer = hvd.DistributedOptimizer(\n            optimizer, named_parameters=model.named_parameters())\n\n        y_pred = model(x)\n        loss = F.mse_loss(y_pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.synchronize()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        with warnings.catch_warnings(record=True) as ws:\n            optimizer.step()\n            assert len(ws) == 1\n            assert \'optimizer.step() called without optimizer.skip_synchronize()\' \\\n                in str(ws[0].message)\n\n    def test_no_named_parameters(self):\n        """"""Test that leaving the default named_parameters=None will not throw an error.""""""\n        hvd.init()\n\n        class Net(torch.nn.Module):\n            def __init__(self):\n                super(Net, self).__init__()\n                self.conv1 = torch.nn.Conv2d(1, 100, 1)\n                self.conv2 = torch.nn.Conv2d(100, 1, 1)\n\n            def forward(self, x):\n                x = self.conv1(x)\n                x = self.conv2(x)\n                return x\n\n        model = Net()\n        inp = torch.rand([1, 1, 1000, 1000])\n\n        opt = torch.optim.SGD(model.parameters(), lr=0.1)\n        opt = hvd.DistributedOptimizer(opt)\n\n        loss = model(inp).sum()\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    def test_missing_named_parameters(self):\n        """"""Test that naming half of the model parameters will throw an error.""""""\n        hvd.init()\n\n        class Net(torch.nn.Module):\n            def __init__(self):\n                super(Net, self).__init__()\n                self.conv1 = torch.nn.Conv2d(1, 100, 1)\n                self.conv2 = torch.nn.Conv2d(100, 1, 1)\n\n            def forward(self, x):\n                x = self.conv1(x)\n                x = self.conv2(x)\n                return x\n\n        model = Net()\n        opt = torch.optim.SGD(model.parameters(), lr=0.1)\n        try:\n            hvd.DistributedOptimizer(opt,\n                named_parameters=list(model.named_parameters())[0:1])\n            assert False, \'hvd.DistributedOptimizer did not throw error\'\n        except ValueError:\n            pass\n\n    def test_horovod_join_allreduce(self):\n        """"""Test Join op with allreduce.""""""\n        # ""Join Op is not supported for PyTorch < 1.0""\n        if not _v2_api:\n            self.skipTest(""Join Op not available"")\n\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        dtypes = self.filter_supported_types([torch.IntTensor, torch.LongTensor,\n                     torch.FloatTensor, torch.DoubleTensor])\n        if torch.cuda.is_available():\n            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,\n                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]\n            if _fp16_supported:\n                dtypes += [torch.cuda.HalfTensor]\n        dims = [1, 2, 3]\n        first_join_ranks = [0, 1]\n        cachings = [False, True]\n        for dtype, dim, first_join_rank, caching in itertools.product(dtypes, dims, first_join_ranks, cachings):\n            torch.manual_seed(1234)\n\n            # Use two tensors to test fusion\n            tensor_a = torch.FloatTensor(*([5] * dim)).random_(-100, 100)\n            tensor_a = self.cast_and_place(tensor_a, dtype)\n            tensor_b = torch.FloatTensor(*([17] * dim)).random_(-100, 100)\n            tensor_b = self.cast_and_place(tensor_b, dtype)\n\n            if caching:\n                handle_a = hvd.allreduce_async(tensor_a, name=""tensor_a"", average=True)\n                handle_b = hvd.allreduce_async(tensor_b, name=""tensor_b"", average=True)\n                averaged_a = hvd.synchronize(handle_a)\n                averaged_b = hvd.synchronize(handle_b)\n\n            if rank == first_join_rank:\n                if dtype.is_cuda:\n                    ret = hvd.join(hvd.local_rank())\n                else:\n                    ret = hvd.join()\n            else:\n                handle_a = hvd.allreduce_async(tensor_a, name=""tensor_a"", average=True)\n                handle_b = hvd.allreduce_async(tensor_b, name=""tensor_b"", average=True)\n                averaged_a = hvd.synchronize(handle_a)\n                averaged_b = hvd.synchronize(handle_b)\n                if dtype.is_cuda:\n                    ret = hvd.join(hvd.local_rank())\n                else:\n                    ret = hvd.join()\n\n                max_difference_a = averaged_a.data.sub(tensor_a * (size - 1) / size).max()\n                max_difference_b = averaged_b.data.sub(tensor_b * (size - 1) / size).max()\n                # Threshold for floating point equality depends on number of\n                # ranks, since we\'re comparing against precise multiplication.\n                if size <= 3 or dtype in [torch.IntTensor, torch.LongTensor,\n                                        torch.cuda.IntTensor, torch.cuda.LongTensor]:\n                    threshold = 0\n                elif size < 10:\n                    threshold = 1e-4\n                elif size < 15:\n                    threshold = 5e-4\n                else:\n                    break\n                assert max_difference_a <= threshold, \'hvd.join with hvd.allreduce produces incorrect results\'\n                assert max_difference_b <= threshold, \'hvd.join with hvd.allreduce produces incorrect results\'\n\n    def test_horovod_join_allgather(self):\n        """"""Test Join op with allgather.""""""\n        # ""Join Op is not supported for PyTorch < 1.0""\n        if not _v2_api:\n            self.skipTest(""Join Op not available"")\n\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dims = [17] * 3\n        tensor = torch.FloatTensor(*dims)\n\n        if rank == 0:\n            if torch.cuda.is_available():\n                ret = hvd.join(hvd.local_rank())\n            else:\n                ret = hvd.join()\n        else:\n            try:\n                hvd.allgather(tensor)\n                assert False, \'hvd.allgather did not throw error\'\n            except (torch.FatalError, RuntimeError):\n                pass\n\n            ret = hvd.join(hvd.local_rank())\n\n    def test_horovod_join_broadcast(self):\n        """"""Test Join op with allgather.""""""\n        # ""Join Op is not supported for PyTorch < 1.0""\n        if not _v2_api:\n            self.skipTest(""Join Op not available"")\n\n        hvd.init()\n        rank = hvd.rank()\n        size = hvd.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            self.skipTest(""Only one worker available"")\n\n        dims = [17] * 3\n        tensor = torch.FloatTensor(*dims)\n\n        if rank == 0:\n            ret = hvd.join(hvd.local_rank())\n        else:\n            try:\n                broadcasted_tensor = hvd.broadcast(tensor, 1)\n                assert False, \'hvd.broadcast did not throw error\'\n            except (torch.FatalError, RuntimeError):\n                pass\n\n            if torch.cuda.is_available():\n                ret = hvd.join(hvd.local_rank())\n            else:\n                ret = hvd.join()\n    \n    def test_horovod_sync_batch_norm(self):\n        """"""Tests Horovod version of SyncBatchNorm.""""""\n        if not torch.cuda.is_available():\n            self.skipTest(""No GPUs available"")\n\n        hvd.init()\n\n        ts_list = [\n            torch.stack([\n                torch.tensor([\n                    [r, r + 1],\n                    [r * 2, r * 2 + 1],\n                    [r * 3, r * 3 + 1],\n                    [r * 4, r * 4 + 1]\n                ])\n                for r in range(hvd.size())\n            ]),\n            torch.stack([\n                torch.tensor([\n                    [r + 1],\n                    [r * 2 + 1],\n                    [r * 3 + 1],\n                    [r * 4 + 1]\n                ])\n                for r in range(hvd.size())\n            ]),\n        ]\n\n        for ts in ts_list:\n            sync_bn = hvd.SyncBatchNorm(num_features=4)\n            sync_bn.cuda(hvd.local_rank())\n\n            bn = torch.nn.BatchNorm1d(num_features=4)\n            bn.cuda(hvd.local_rank())\n\n            ts = ts.cuda(hvd.local_rank()).float()\n            ts1 = ts.clone().requires_grad_()\n            ts2 = ts.clone().requires_grad_()\n\n            # Training\n            sync_bn_out = sync_bn(ts1[hvd.rank()].unsqueeze(0))\n            bn_out = bn(ts2)\n            assert (sync_bn_out - bn_out[hvd.rank()].unsqueeze(0)).abs().sum() < 1e-6\n            assert (sync_bn.running_mean - bn.running_mean).abs().sum() < 1e-6\n            assert (sync_bn.running_var - bn.running_var).abs().sum() < 1e-6\n\n            # Gradients\n            sync_bn_out.sum().backward()\n            bn_out.mean(dim=0).sum().backward()\n            assert (hvd.allreduce(sync_bn.weight.grad, name=\'sync_bn.weight.grad\') - bn.weight.grad).abs().sum() < 1e-6\n            assert (hvd.allreduce(sync_bn.bias.grad, name=\'sync_bn.bias.grad\') - bn.bias.grad).abs().sum() < 1e-6\n            assert (hvd.allreduce(ts1.grad, name=\'ts1.grad\') - ts2.grad).abs().sum() < 1e-6\n\n    @pytest.mark.skipif(LooseVersion(torch.__version__) < LooseVersion(\'1.0.0\'),\n                        reason=\'Synchronizing state requires PyTorch 1.0 or above\')\n    def test_elastic_state(self):\n        hvd.init()\n\n        v = 1.0 if hvd.rank() == 0 else 2.0\n        model1 = torch.nn.Sequential(torch.nn.Linear(2, 2))\n        model1.load_state_dict({\n            \'0.weight\': torch.tensor([[v, v], [v, v]]),\n            \'0.bias\': torch.tensor([v, v])\n        })\n\n        model2 = torch.nn.Sequential(torch.nn.Linear(2, 2))\n        model2.load_state_dict({\n            \'0.weight\': torch.tensor([[1.0, 2.0], [3.0, 4.0]]),\n            \'0.bias\': torch.tensor([0.0, 0.0])\n        })\n\n        optimizer = torch.optim.SGD(model1.parameters(), lr=0.001 * hvd.size())\n\n        state = hvd.elastic.TorchState(model1, optimizer, batch=20 + hvd.rank(), epoch=10 + hvd.rank())\n        state.sync()\n\n        model1_weights = model1.state_dict().values()\n        model2_weights = model2.state_dict().values()\n\n        # After sync, all values should match the root rank\n        for w in state.model.state_dict().values():\n            np.testing.assert_allclose(w, np.ones_like(w))\n        assert state.batch == 20\n        assert state.epoch == 10\n\n        # Partially modify then restore\n        model1.load_state_dict(model2.state_dict())\n        state.batch = 21\n        state.epoch = 11\n\n        state.restore()\n\n        for w1, w2 in zip(model1.state_dict().values(), model1_weights):\n            np.testing.assert_allclose(w1, w2)\n        assert state.batch == 20\n        assert state.epoch == 10\n\n        # Partially modify then commit\n        model1.load_state_dict(model2.state_dict())\n        state.batch = 21\n        state.epoch = 11\n\n        state.commit()\n        state.restore()\n\n        for w1, w2 in zip(model1.state_dict().values(), model2_weights):\n            np.testing.assert_allclose(w1, w2)\n        assert state.batch == 21\n        assert state.epoch == 11\n\n\nif __name__ == ""__main__"":\n   unittest.main()\n'"
examples/elastic/pytorch_mnist_elastic.py,0,"b""import argparse\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport torch.utils.data.distributed\nimport horovod.torch as hvd\nimport os\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='input batch size for training (default: 64)')\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                    help='input batch size for testing (default: 1000)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='number of epochs to train (default: 10)')\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n                    help='learning rate (default: 0.01)')\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n                    help='SGD momentum (default: 0.5)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--seed', type=int, default=42, metavar='S',\n                    help='random seed (default: 42)')\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                    help='how many batches to wait before logging training status')\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\n                    help='use fp16 compression during allreduce')\nparser.add_argument('--use-adasum', action='store_true', default=False,\n                    help='use adasum algorithm to do reduction')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\n# Horovod: initialize library.\nhvd.init()\ntorch.manual_seed(args.seed)\n\nif args.cuda:\n    # Horovod: pin GPU to local rank.\n    torch.cuda.set_device(hvd.local_rank())\n    torch.cuda.manual_seed(args.seed)\n\n\n# Horovod: limit # of CPU threads to be used per worker.\ntorch.set_num_threads(1)\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\ntrain_dataset = \\\n    datasets.MNIST('data-%d' % hvd.rank(), train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ]))\n# Horovod: use DistributedSampler to partition the training data.\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(\n    train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\n\ntest_dataset = \\\n    datasets.MNIST('data-%d' % hvd.rank(), train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ]))\n# Horovod: use DistributedSampler to partition the test data.\ntest_sampler = torch.utils.data.distributed.DistributedSampler(\n    test_dataset, num_replicas=hvd.size(), rank=hvd.rank())\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\n                                          sampler=test_sampler, **kwargs)\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Net()\n\n# By default, Adasum doesn't need scaling up learning rate.\nlr_scaler = hvd.size() if not args.use_adasum else 1\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n    # If using GPU Adasum allreduce, scale learning rate by local_size.\n    if args.use_adasum and hvd.nccl_built():\n        lr_scaler = hvd.local_size()\n\n# Horovod: scale learning rate by lr_scaler.\noptimizer = optim.SGD(model.parameters(), lr=args.lr * lr_scaler,\n                      momentum=args.momentum)\n\n# Horovod: (optional) compression algorithm.\ncompression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n\ndef metric_average(val, name):\n    tensor = torch.tensor(val)\n    avg_tensor = hvd.allreduce(tensor, name=name)\n    return avg_tensor.item()\n\n\ndef check_rank(epoch):\n    if epoch == 2 and int(os.environ.get('HOROVOD_RANK')) == 0:\n        print('exit rank {}'.format(hvd.rank()))\n        raise RuntimeError('check_rank and exit')\n        # exit(1)\n\n\n@hvd.elastic.run\ndef train(state):\n    # post synchronization event (worker added, worker removed) init ...\n    for state.epoch in range(state.epoch, args.epochs + 1):\n        state.model.train()\n\n        train_sampler.set_epoch(state.epoch)\n        steps_remaining = len(train_loader) - state.batch\n\n        for state.batch, (data, target) in enumerate(train_loader):\n            if state.batch >= steps_remaining:\n                break\n\n            check_rank(state.epoch)\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            state.optimizer.zero_grad()\n            output = state.model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            state.optimizer.step()\n            if state.batch % args.log_interval == 0:\n                # Horovod: use train_sampler to determine the number of examples in\n                # this worker's partition.\n                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                    state.epoch, state.batch * len(data), len(train_sampler),\n                    100.0 * state.batch / len(train_loader), loss.item()))\n            state.commit()\n        state.batch = 0\n\n\ndef test():\n    model.eval()\n    test_loss = 0.\n    test_accuracy = 0.\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        # sum up batch loss\n        test_loss += F.nll_loss(output, target, size_average=False).item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n\n    # Horovod: use test_sampler to determine the number of examples in\n    # this worker's partition.\n    test_loss /= len(test_sampler)\n    test_accuracy /= len(test_sampler)\n\n    # Horovod: average metric values across workers.\n    test_loss = metric_average(test_loss, 'avg_loss')\n    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\n\n    # Horovod: print output only on first rank.\n    if hvd.rank() == 0:\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n            test_loss, 100. * test_accuracy))\n\n\n# Horovod: wrap optimizer with DistributedOptimizer.\noptimizer = hvd.DistributedOptimizer(optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression,\n                                     op=hvd.Adasum if args.use_adasum else hvd.Average)\n\n\n# adjust learning rate on reset\ndef on_state_reset():\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = args.lr * hvd.size()\n\n\nstate = hvd.elastic.TorchState(model, optimizer, epoch=1, batch=0)\nstate.register_reset_callbacks([on_state_reset])\ntrain(state)\ntest()\n"""
examples/elastic/pytorch_synthetic_benchmark_elastic.py,0,"b""import argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import models\nimport horovod.torch as hvd\nimport timeit\nimport numpy as np\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description='PyTorch Synthetic Benchmark',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\n                    help='use fp16 compression during allreduce')\n\nparser.add_argument('--model', type=str, default='resnet50',\n                    help='model to benchmark')\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size')\n\nparser.add_argument('--num-warmup-batches', type=int, default=10,\n                    help='number of warm-up batches that don\\'t count towards benchmark')\nparser.add_argument('--num-batches-per-iter', type=int, default=10,\n                    help='number of batches per benchmark iteration')\nparser.add_argument('--num-iters', type=int, default=10,\n                    help='number of benchmark iterations')\nparser.add_argument('--num-batches-per-commit', type=int, default=1,\n                    help='number of batches per commit of the elastic state object')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\n\nparser.add_argument('--use-adasum', action='store_true', default=False,\n                    help='use adasum algorithm to do reduction')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nhvd.init()\n\nif args.cuda:\n    # Horovod: pin GPU to local rank.\n    torch.cuda.set_device(hvd.local_rank())\n\ncudnn.benchmark = True\n\n# Set up standard model.\nmodel = getattr(models, args.model)()\n\n\n# By default, Adasum doesn't need scaling up learning rate.\ndef lr_scaler():\n    return hvd.size() if not args.use_adasum else 1\n\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n    # If using GPU Adasum allreduce, scale learning rate by local_size.\n    if args.use_adasum and hvd.nccl_built():\n        lr_scaler = hvd.local_size()\n\nlr = 0.01\noptimizer = optim.SGD(model.parameters(), lr=lr * lr_scaler())\n\n# Horovod: (optional) compression algorithm.\ncompression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n# Horovod: wrap optimizer with DistributedOptimizer.\noptimizer = hvd.DistributedOptimizer(optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression,\n                                     op=hvd.Adasum if args.use_adasum else hvd.Average)\n\n# Horovod: broadcast parameters & optimizer state.\nhvd.broadcast_parameters(model.state_dict(), root_rank=0)\nhvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n# Set up fixed fake data\ndata = torch.randn(args.batch_size, 3, 224, 224)\ntarget = torch.LongTensor(args.batch_size).random_() % 1000\nif args.cuda:\n    data, target = data.cuda(), target.cuda()\n\n\ndef benchmark_step(state):\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n    state.batch += 1\n    if state.batch == args.num_batches_per_commit:\n        state.batch = 0\n        state.commit()\n\n\ndef log(s, nl=True):\n    if hvd.rank() != 0:\n        return\n    print(s, end='\\n' if nl else '')\n\n\nlog('Model: %s' % args.model)\nlog('Batch size: %d' % args.batch_size)\ndevice = 'GPU' if args.cuda else 'CPU'\nlog('Number of %ss: %d' % (device, hvd.size()))\n\n\n@hvd.elastic.run\ndef run_benchmark(state):\n    # Warm-up\n    if not state.warm:\n        log('Running warmup...')\n        timeit.timeit(lambda: benchmark_step(state), number=args.num_warmup_batches)\n        state.warm = True\n        state.commit()\n\n    # Benchmark\n    if state.iter == 0:\n        log('Running benchmark...')\n    for x in range(state.iter, args.num_iters):\n        time = timeit.timeit(lambda: benchmark_step(state), number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))\n        state.img_secs.append(img_sec)\n        state.iter = x\n        state.commit()\n\n\n# adjust learning rate on reset\ndef on_state_reset():\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr * lr_scaler()\n\n\nstate = hvd.elastic.TorchState(model, optimizer, img_secs=[], iter=0, batch=0, warm=False)\nstate.register_reset_callbacks([on_state_reset])\nrun_benchmark(state)\n\n# Results\nimg_sec_mean = np.mean(state.img_secs)\nimg_sec_conf = 1.96 * np.std(state.img_secs)\nlog('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))\nlog('Total img/sec on %d %s(s): %.1f +-%.1f' %\n    (hvd.size(), device, hvd.size() * img_sec_mean, hvd.size() * img_sec_conf))\n"""
examples/elastic/tensorflow2_mnist_elastic.py,21,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\ngpus = tf.config.experimental.list_physical_devices(\'GPU\')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\n\n(mnist_images, mnist_labels), _ = \\\n    tf.keras.datasets.mnist.load_data(path=\'mnist-%d.npz\' % hvd.rank())\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n     tf.cast(mnist_labels, tf.int64))\n)\ndataset = dataset.repeat().shuffle(10000).batch(128)\n\nmnist_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, [3, 3], activation=\'relu\'),\n    tf.keras.layers.Conv2D(64, [3, 3], activation=\'relu\'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\'relu\'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation=\'softmax\')\n])\nloss = tf.losses.SparseCategoricalCrossentropy()\n\n# Horovod: adjust learning rate based on number of GPUs.\nlr = 0.001\nopt = tf.optimizers.Adam(lr * hvd.size())\n\n\n@tf.function\ndef training_step(images, labels, allreduce=True):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    # Horovod: add Horovod Distributed GradientTape.\n    if allreduce:\n        tape = hvd.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n    return loss_value\n\n\n# Horovod: initialize model and optimizer state so we can synchronize across workers\nfor batch_idx, (images, labels) in enumerate(dataset.take(1)):\n    training_step(images, labels, allreduce=False)\n\n\n@hvd.elastic.run\ndef train(state):\n    start_batch = state.batch\n\n    # Horovod: adjust number of steps based on number of GPUs.\n    for batch_idx, (images, labels) in enumerate(dataset.skip(state.batch).take(10000 // hvd.size())):\n        state.batch = start_batch + batch_idx\n        loss_value = training_step(images, labels)\n\n        if state.batch % 10 == 0 and hvd.local_rank() == 0:\n            print(\'Step #%d\\tLoss: %.6f\' % (state.batch, loss_value))\n\n        # Horovod: commit state at the end of each batch\n        state.commit()\n\n\ndef on_state_reset():\n    opt.lr.assign(lr * hvd.size())\n\n\nstate = hvd.elastic.TensorFlowKerasState(mnist_model, opt, batch=0)\nstate.register_reset_callbacks([on_state_reset])\n\ntrain(state)\n\ncheckpoint_dir = \'./checkpoints\'\ncheckpoint = tf.train.Checkpoint(model=mnist_model, optimizer=opt)\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from\n# corrupting it.\nif hvd.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n'"
examples/elastic/tensorflow2_synthetic_benchmark_elastic.py,11,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\nimport argparse\nimport os\nimport numpy as np\nimport timeit\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\nfrom tensorflow.keras import applications\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'TensorFlow Synthetic Benchmark\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-allreduce\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during allreduce\')\n\nparser.add_argument(\'--model\', type=str, default=\'ResNet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\nparser.add_argument(\'--num-batches-per-commit\', type=int, default=1,\n                    help=\'number of batches per commit of the elastic state object\')\n\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nif args.cuda:\n    gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    if gpus:\n        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\nelse:\n    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n\n# Set up standard model.\nlr = 0.01\nmodel = getattr(applications, args.model)(weights=None)\nopt = tf.optimizers.SGD(lr * hvd.size())\n\ndata = tf.random.uniform([args.batch_size, 224, 224, 3])\ntarget = tf.random.uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64)\n\n\n@tf.function\ndef train_one_batch():\n    # Horovod: (optional) compression algorithm.\n    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n\n    # Horovod: use DistributedGradientTape\n    with tf.GradientTape() as tape:\n        probs = model(data, training=True)\n        loss = tf.losses.categorical_crossentropy(target, probs)\n\n    # Horovod: add Horovod Distributed GradientTape.\n    tape = hvd.DistributedGradientTape(tape, compression=compression)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    opt.apply_gradients(zip(gradients, model.trainable_variables))\n\n\ndef benchmark_step(state):\n    train_one_batch()\n    if state is not None:\n        state.batch += 1\n        if state.batch == args.num_batches_per_commit:\n            state.batch = 0\n            state.commit()\n\n\ndef log(s, nl=True):\n    if hvd.rank() != 0:\n        return\n    print(s, end=\'\\n\' if nl else \'\')\n\n\nlog(\'Model: %s\' % args.model)\nlog(\'Batch size: %d\' % args.batch_size)\ndevice = \'GPU\' if args.cuda else \'CPU\'\nlog(\'Number of %ss: %d\' % (device, hvd.size()))\n\n\n# Run one batch to initialize weights before synchronization\ntrain_one_batch()\n\n\n@hvd.elastic.run\ndef run_benchmark(state):\n    with tf.device(device):\n        # Warm-up\n        if not state.warm:\n            log(\'Running warmup...\')\n            timeit.timeit(lambda: benchmark_step(state), number=args.num_warmup_batches)\n            state.warm = True\n            state.commit()\n\n        # Benchmark\n        if state.iter == 0:\n            log(\'Running benchmark...\')\n        for x in range(state.iter, args.num_iters):\n            time = timeit.timeit(lambda: benchmark_step(state), number=args.num_batches_per_iter)\n            img_sec = args.batch_size * args.num_batches_per_iter / time\n            log(\'Iter #%d: %.1f img/sec per %s\' % (x, img_sec, device))\n            state.img_secs.append(img_sec)\n            state.iter = x\n            state.commit()\n\n\ndef on_state_reset():\n    tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size())\n\n\nstate = hvd.elastic.TensorFlowKerasState(model, opt, img_secs=[], iter=0, batch=0, warm=False)\nstate.register_reset_callbacks([on_state_reset])\nrun_benchmark(state)\n\n# Results\nimg_sec_mean = np.mean(state.img_secs)\nimg_sec_conf = 1.96 * np.std(state.img_secs)\nlog(\'Img/sec per %s: %.1f +-%.1f\' % (device, img_sec_mean, img_sec_conf))\nlog(\'Total img/sec on %d %s(s): %.1f +-%.1f\' %\n    (hvd.size(), device, hvd.size() * img_sec_mean, hvd.size() * img_sec_conf))\n'"
examples/elastic/tensorflow_keras_mnist_elastic.py,7,"b""import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\n\nimport horovod.tensorflow.keras as hvd\n\n# Horovod: initialize Horovod.\nhvd.init()\n\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\nK.set_session(tf.Session(config=config))\n\nlr = 1.0\nbatch_size = 128\nepochs = 24\nnum_classes = 10\n\n(mnist_images, mnist_labels), _ = \\\n    tf.keras.datasets.mnist.load_data(path='mnist-%d.npz' % hvd.rank())\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n     tf.cast(mnist_labels, tf.int64))\n)\ndataset = dataset.repeat().shuffle(10000).batch(batch_size)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(28, 28, 1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Horovod: adjust learning rate based on number of GPUs.\nopt = keras.optimizers.Adadelta(lr * hvd.size())\n\n# Horovod: add Horovod Distributed Optimizer.\nopt = hvd.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.sparse_categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\n\ndef on_state_reset():\n    tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size())\n\n\nstate = hvd.elastic.KerasState(model, batch=100, epoch=0)\nstate.register_reset_callbacks([on_state_reset])\n\ncallbacks = [\n    # Horovod: elastic training callbacks to update and commit state.\n    hvd.elastic.CommitStateCallback(state),\n    hvd.elastic.UpdateBatchStateCallback(state),\n    hvd.elastic.UpdateEpochStateCallback(state),\n]\n\n# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif hvd.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\n\n@hvd.elastic.run\ndef train(state):\n    # Horovod: adjust number of steps based on number of GPUs.\n    state.model.fit(dataset,\n                    steps_per_epoch=500 // hvd.size(),\n                    callbacks=callbacks,\n                    epochs=epochs - state.epoch,\n                    verbose=1 if hvd.rank() == 0 else 0)\n\n\ntrain(state)\n"""
horovod/_keras/__init__.py,6,"b'# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.tensorflow as hvd\nimport tensorflow as tf\n\n\ndef create_distributed_optimizer(keras, optimizer, name, device_dense, device_sparse,\n                                 compression, sparse_as_dense):\n    class _DistributedOptimizer(keras.optimizers.Optimizer):\n        _HAS_AGGREGATE_GRAD = True\n\n        def __init__(self, **kwargs):\n            self._name = name or ""Distributed%s"" % self.__class__.__base__.__name__\n            self._device_dense = device_dense\n            self._device_sparse = device_sparse\n            self._compression = compression\n            self._sparse_as_dense = sparse_as_dense\n            self._aggregated_gradients = False\n            super(self.__class__, self).__init__(**kwargs)\n\n        def get_gradients(self, loss, params):\n            """"""\n            Compute gradients of all trainable variables.\n\n            See Optimizer.get_gradients() for more info.\n\n            In DistributedOptimizer, get_gradients() is overriden to also\n            allreduce the gradients before returning them.\n            """"""\n            gradients = super(self.__class__, self).get_gradients(loss, params)\n            return self._allreduce(gradients)\n\n        def _aggregate_gradients(self, grads_and_vars):\n            gradients = [grad for grad, var in grads_and_vars]\n            return self._allreduce(gradients)\n\n        def _allreduce(self, gradients):\n            self._aggregated_gradients = True\n            if hvd.size() > 1:\n                averaged_gradients = []\n                with tf.name_scope(self._name + ""_Allreduce""):\n                    for grad in gradients:\n                        if grad is not None:\n                            if self._sparse_as_dense and \\\n                                    isinstance(grad, tf.IndexedSlices):\n                                grad = tf.convert_to_tensor(grad)\n                            avg_grad = hvd.allreduce(grad,\n                                                     device_dense=self._device_dense,\n                                                     device_sparse=self._device_sparse,\n                                                     compression=self._compression)\n                            averaged_gradients.append(avg_grad)\n                        else:\n                            averaged_gradients.append(None)\n                    return averaged_gradients\n            else:\n                return gradients\n\n        def apply_gradients(self, *args, **kwargs):\n            if not self._aggregated_gradients:\n                raise Exception(\'`apply_gradients()` was called without a call to \'\n                                \'`get_gradients()` or `_aggregate_gradients`. If you\\\'re \'\n                                \'using TensorFlow 2.0, please specify \'\n                                \'`experimental_run_tf_function=False` in `compile()`.\')\n            return super(self.__class__, self).apply_gradients(*args, **kwargs)\n\n    # We dynamically create a new class that inherits from the optimizer that was passed in.\n    # The goal is to override get_gradients() method with an allreduce implementation.\n    # This class will have the same name as the optimizer it\'s wrapping, so that the saved\n    # model could be easily restored without Horovod.\n    cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n               dict(_DistributedOptimizer.__dict__))\n    return cls.from_config(optimizer.get_config())\n\n\ndef _eval(backend, op_or_result):\n    if hvd._executing_eagerly():\n        return op_or_result\n    else:\n        return backend.get_session().run(op_or_result)\n\n\nif hasattr(hvd, \'broadcast_global_variables\'):\n    def broadcast_global_variables(backend, root_rank):\n        return _eval(backend, hvd.broadcast_global_variables(root_rank))\n\n\ndef allreduce(backend, value, name, average):\n    return _eval(backend, hvd.allreduce(tf.constant(value, name=name), average=average))\n\n\ndef allgather(backend, value, name):\n    return _eval(backend, hvd.allgather(tf.constant(value, name=name)))\n\n\ndef broadcast(backend, value, root_rank, name):\n    return _eval(backend, hvd.broadcast(tf.constant(value, name=name), root_rank))\n\n\ndef load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects):\n    horovod_objects = {\n        subclass.__name__.lower(): wrap_optimizer(subclass)\n        for subclass in keras.optimizers.Optimizer.__subclasses__()\n        if subclass.__module__ in optimizer_modules\n    }\n\n    if custom_optimizers is not None:\n        horovod_objects.update({\n            cls.__name__: wrap_optimizer(cls)\n            for cls in custom_optimizers\n        })\n\n    if custom_objects is not None:\n        horovod_objects.update(custom_objects)\n\n    return keras.models.load_model(filepath, custom_objects=horovod_objects)\n'"
horovod/_keras/callbacks.py,1,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport warnings\n\nimport horovod.tensorflow as hvd\nimport tensorflow as tf\n\n\nclass BroadcastGlobalVariablesCallbackImpl(object):\n    def __init__(self, backend, root_rank, device=\'\', *args):\n        super(BroadcastGlobalVariablesCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.root_rank = root_rank\n        self.device = device\n        self.broadcast_done = False\n\n    def on_batch_end(self, batch, logs=None):\n        if self.broadcast_done:\n            return\n\n        with tf.device(self.device):\n            if hvd._executing_eagerly() and hasattr(self.model, \'variables\'):\n                # TensorFlow 2.0 or TensorFlow eager\n                hvd.broadcast_variables(self.model.variables,\n                                        root_rank=self.root_rank)\n                hvd.broadcast_variables(self.model.optimizer.variables(),\n                                        root_rank=self.root_rank)\n            else:\n                bcast_op = hvd.broadcast_global_variables(self.root_rank)\n                self.backend.get_session().run(bcast_op)\n\n        self.broadcast_done = True\n\n\nclass MetricAverageCallbackImpl(object):\n    def __init__(self, backend, device=\'\', *args):\n        super(MetricAverageCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.variables = {}\n        self.allreduce_ops = {}\n        self.device = device\n\n    def _make_variable(self, metric, value):\n        with self.backend.name_scope(\'MetricAverageCallback\'):\n            var = self.backend.variable(value, name=metric)\n            self.backend.get_session().run(var.initializer)\n            allreduce_op = hvd.allreduce(var, device_dense=self.device)\n            return var, allreduce_op\n\n    def _average_metrics_in_place(self, logs):\n        logs = logs or {}\n        reduced_logs = {}\n        # Reduce every metric among workers. Sort metrics by name\n        # to ensure consistent order.\n        for metric, value in sorted(logs.items()):\n            if hvd._executing_eagerly():\n                reduced_logs[metric] = \\\n                    hvd.allreduce(self.backend.constant(value, name=metric)).numpy()\n            else:\n                if metric not in self.variables:\n                    self.variables[metric], self.allreduce_ops[metric] = \\\n                        self._make_variable(metric, value)\n                else:\n                    self.backend.set_value(self.variables[metric], value)\n                reduced_logs[metric] = \\\n                    self.backend.get_session().run(self.allreduce_ops[metric])\n        # Override the reduced values back into logs dictionary\n        # for other callbacks to use.\n        for metric, value in reduced_logs.items():\n            logs[metric] = value\n\n    def on_epoch_end(self, epoch, logs=None):\n        self._average_metrics_in_place(logs)\n\n\nclass LearningRateScheduleCallbackImpl(object):\n    def __init__(self, backend, multiplier, start_epoch=0, end_epoch=None, staircase=True,\n                 momentum_correction=True, steps_per_epoch=None, initial_lr=None, *args):\n        super(LearningRateScheduleCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.start_epoch = start_epoch\n        self.end_epoch = end_epoch\n        self.staircase = staircase\n        self.momentum_correction = momentum_correction\n        self.initial_lr = initial_lr\n        self.restore_momentum = None\n        self.steps_per_epoch = steps_per_epoch\n        self.current_epoch = None\n\n        if not callable(multiplier):\n            self.staircase = True\n            self.multiplier = lambda epoch: multiplier\n        else:\n            self.multiplier = multiplier\n\n        if self.initial_lr is None:\n            warnings.warn(\'Parameter `initial_lr` will be required in v0.21.0\', DeprecationWarning)\n\n    def _autodetect_steps_per_epoch(self):\n        if self.params.get(\'steps\'):\n            # The number of steps is provided in the parameters.\n            return self.params[\'steps\']\n        elif self.params.get(\'samples\') and self.params.get(\'batch_size\'):\n            # Compute the number of steps per epoch using # of samples and a batch size.\n            return self.params[\'samples\'] // self.params[\'batch_size\']\n        else:\n            raise ValueError(\'Could not autodetect the number of steps per epoch. \'\n                             \'Please specify the steps_per_epoch parameter to the \'\n                             \'%s() or upgrade to the latest version of Keras.\'\n                             % self.__class__.__name__)\n\n    def _adjust_learning_rate(self, epoch):\n        old_lr = self.backend.get_value(self.model.optimizer.lr)\n        new_lr = self.initial_lr * self.multiplier(epoch)\n        self.backend.set_value(self.model.optimizer.lr, new_lr)\n\n        if hasattr(self.model.optimizer, \'momentum\') and self.momentum_correction:\n            # See the paper cited above for more information about momentum correction.\n            self.restore_momentum = self.backend.get_value(self.model.optimizer.momentum)\n            self.backend.set_value(self.model.optimizer.momentum,\n                                   self.restore_momentum * new_lr / old_lr)\n\n    def _restore_momentum_if_needed(self):\n        if self.restore_momentum:\n            self.backend.set_value(self.model.optimizer.momentum, self.restore_momentum)\n            self.restore_momentum = None\n\n    def on_train_begin(self, logs=None):\n        if self.initial_lr is None:\n            self.initial_lr = self.backend.get_value(self.model.optimizer.lr)\n        if not self.staircase and not self.steps_per_epoch:\n            self.steps_per_epoch = self._autodetect_steps_per_epoch()\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.current_epoch = epoch\n\n    def on_batch_begin(self, batch, logs=None):\n        if (self.current_epoch < self.start_epoch or\n                (self.end_epoch is not None and self.current_epoch >= self.end_epoch)):\n            # Outside of the adjustment scope.\n            return\n\n        if self.staircase and batch == 0:\n            # Do on first batch of every epoch.\n            self._adjust_learning_rate(self.current_epoch)\n        elif not self.staircase:\n            epoch = self.current_epoch + float(batch) / self.steps_per_epoch\n            self._adjust_learning_rate(epoch)\n\n    def on_batch_end(self, batch, logs=None):\n        self._restore_momentum_if_needed()\n\n    def on_epoch_end(self, epoch, logs=None):\n        if logs is not None:\n            # Log current learning rate.\n            logs[\'lr\'] = self.backend.get_value(self.model.optimizer.lr)\n\n\nclass LearningRateWarmupCallbackImpl(LearningRateScheduleCallbackImpl):\n    def __init__(self, backend, warmup_epochs=5, momentum_correction=True, steps_per_epoch=None,\n                 verbose=0, initial_lr=None, *args):\n        def multiplier(epoch):\n            # Adjust epoch to produce round numbers at the end of each epoch, so that TensorBoard\n            # learning rate graphs look better.\n            epoch += 1. / self.steps_per_epoch\n            return 1. / hvd.size() * (epoch * (hvd.size() - 1) / warmup_epochs + 1)\n        super(LearningRateWarmupCallbackImpl, self).__init__(\n            backend, multiplier, start_epoch=0, end_epoch=warmup_epochs, staircase=False,\n            momentum_correction=momentum_correction, steps_per_epoch=steps_per_epoch, initial_lr=initial_lr,\n            *args)\n        self.verbose = verbose\n\n    def on_epoch_end(self, epoch, logs=None):\n        super(LearningRateWarmupCallbackImpl, self).on_epoch_end(epoch, logs)\n\n        if epoch == self.end_epoch - 1 and self.verbose > 0:\n            new_lr = self.backend.get_value(self.model.optimizer.lr)\n            print(\'\\nEpoch %d: finished gradual learning rate warmup to %g.\' %\n                  (epoch + 1, new_lr))\n'"
horovod/_keras/elastic.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\nclass CommitStateCallbackImpl(object):\n    def __init__(self, backend, state, batches_per_commit, *args):\n        super(CommitStateCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.state = state\n        self.batches_per_commit = batches_per_commit\n        self.batches_remaining = batches_per_commit\n\n    def on_batch_end(self, batch, logs=None):\n        self.batches_remaining -= 1\n        if self.batches_remaining == 0:\n            self.state.commit()\n            self.batches_remaining = self.batches_per_commit\n\n\nclass UpdateBatchStateCallbackImpl(object):\n    def __init__(self, backend, state, *args):\n        super(UpdateBatchStateCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.state = state\n        self.steps_per_epoch = None\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if self.params.get(\'steps\'):\n            if self.steps_per_epoch is None:\n                self.steps_per_epoch = self.params.get(\'steps\')\n            self.params[\'steps\'] = self.steps_per_epoch - self.state.batch\n\n    def on_batch_end(self, batch, logs=None):\n        self.state.batch = batch\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.state.batch = 0\n\n\nclass UpdateEpochStateCallbackImpl(object):\n    def __init__(self, backend, state, *args):\n        super(UpdateEpochStateCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.state = state\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.state.epoch = epoch\n'"
horovod/common/__init__.py,0,b''
horovod/common/basics.py,0,"b'# Copyright (C) 2019 Uber Technologies, Inc.\n# Modifications copyright Microsoft\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport atexit\nimport ctypes\n\nfrom horovod.common import util as util\n\n\nclass HorovodBasics(object):\n    """"""Wrapper class for the basic Horovod API.""""""\n\n    def __init__(self, pkg_path, *args):\n        full_path = util.get_extension_full_path(pkg_path, *args)\n        self.MPI_LIB_CTYPES = ctypes.CDLL(full_path, mode=ctypes.RTLD_GLOBAL)\n\n        self.Average = self.MPI_LIB_CTYPES.horovod_reduce_op_average()\n        self.Sum = self.MPI_LIB_CTYPES.horovod_reduce_op_sum()\n        self.Adasum = self.MPI_LIB_CTYPES.horovod_reduce_op_adasum()\n\n    def init(self, comm=None):\n        """"""A function that initializes Horovod.\n\n        Args:\n          comm: List specifying ranks for the communicator, relative to the MPI_COMM_WORLD\n            communicator OR the MPI communicator to use. Given communicator will be duplicated.\n            If None, Horovod will use MPI_COMM_WORLD Communicator.\n        """"""\n        if comm is None:\n            comm = []\n\n        atexit.register(self.shutdown)\n\n        if not isinstance(comm, list):\n            mpi_built = self.MPI_LIB_CTYPES.horovod_mpi_built()\n            if not bool(mpi_built):\n                raise ValueError(\n                    ""Horovod has not been built with MPI support. Ensure MPI is installed and ""\n                    ""reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error."")\n\n            from mpi4py import MPI\n            if MPI._sizeof(MPI.Comm) == ctypes.sizeof(ctypes.c_int):\n                MPI_Comm = ctypes.c_int\n            else:\n                MPI_Comm = ctypes.c_void_p\n                self.MPI_LIB_CTYPES.horovod_init_comm.argtypes = [MPI_Comm]\n\n            comm_obj = MPI_Comm.from_address(MPI._addressof(comm))\n            self.MPI_LIB_CTYPES.horovod_init_comm(comm_obj)\n        else:\n            comm_size = len(comm)\n            self.MPI_LIB_CTYPES.horovod_init(\n                (ctypes.c_int * comm_size)(*comm), ctypes.c_int(comm_size))\n\n    def shutdown(self):\n        """"""A function that shuts Horovod down.""""""\n        self.MPI_LIB_CTYPES.horovod_shutdown()\n\n    def size(self):\n        """"""A function that returns the number of Horovod processes.\n\n        Returns:\n          An integer scalar containing the number of Horovod processes.\n        """"""\n        size = self.MPI_LIB_CTYPES.horovod_size()\n        if size == -1:\n            raise ValueError(\n                \'Horovod has not been initialized; use hvd.init().\')\n        return size\n\n    def local_size(self):\n        """"""A function that returns the number of Horovod processes within the\n        node the current process is running on.\n\n        Returns:\n          An integer scalar containing the number of local Horovod processes.\n        """"""\n        local_size = self.MPI_LIB_CTYPES.horovod_local_size()\n        if local_size == -1:\n            raise ValueError(\n                \'Horovod has not been initialized; use hvd.init().\')\n        return local_size\n\n    def rank(self):\n        """"""A function that returns the Horovod rank of the calling process.\n\n        Returns:\n          An integer scalar with the Horovod rank of the calling process.\n        """"""\n        rank = self.MPI_LIB_CTYPES.horovod_rank()\n        if rank == -1:\n            raise ValueError(\n                \'Horovod has not been initialized; use hvd.init().\')\n        return rank\n\n    def local_rank(self):\n        """"""A function that returns the local Horovod rank of the calling process, within the\n        node that it is running on. For example, if there are seven processes running\n        on a node, their local ranks will be zero through six, inclusive.\n\n        Returns:\n          An integer scalar with the local Horovod rank of the calling process.\n        """"""\n        local_rank = self.MPI_LIB_CTYPES.horovod_local_rank()\n        if local_rank == -1:\n            raise ValueError(\n                \'Horovod has not been initialized; use hvd.init().\')\n        return local_rank\n\n    def is_homogeneous(self):\n        """"""Returns True if the cluster is homogeneous.\n\n        Returns:\n          A boolean value indicating whether every node in the cluster has same number of ranks.\n        """"""\n        is_homogeneous = self.MPI_LIB_CTYPES.horovod_is_homogeneous()\n        return bool(is_homogeneous)\n\n    def mpi_threads_supported(self):\n        """"""A function that returns a flag indicating whether MPI multi-threading is supported.\n\n        If MPI multi-threading is supported, users may mix and match Horovod usage with other\n        MPI libraries, such as `mpi4py`.\n\n        Returns:\n          A boolean value indicating whether MPI multi-threading is supported.\n        """"""\n        mpi_enabled = self.MPI_LIB_CTYPES.horovod_mpi_enabled()\n        if not bool(mpi_enabled):\n            raise ValueError(\n                \'Horovod MPI is not enabled; Please make sure it\\\'s installed and enabled.\')\n\n        mpi_threads_supported = self.MPI_LIB_CTYPES.horovod_mpi_threads_supported()\n        if mpi_threads_supported == -1:\n            raise ValueError(\n                \'Horovod has not been initialized; use hvd.init().\')\n        return bool(mpi_threads_supported)\n\n    def mpi_enabled(self):\n        """"""Returns True if MPI is mode is currently enabled at runtime.\n\n        If MPI is enabled, users can use it for controller or data transfer operations.\n\n        Returns:\n          A boolean value indicating whether MPI is enabled.\n        """"""\n        mpi_enabled = self.MPI_LIB_CTYPES.horovod_mpi_enabled()\n        return bool(mpi_enabled)\n\n    def mpi_built(self):\n        """"""Returns True if Horovod was compiled with MPI support.\n\n        Returns:\n          A boolean value indicating whether MPI support was compiled.\n        """"""\n        return bool(self.MPI_LIB_CTYPES.horovod_mpi_built())\n\n    def gloo_enabled(self):\n        """"""Returns True if Gloo is mode is currently enabled at runtime.\n\n        If Gloo is enabled, users can use it for controller or data transfer operations.\n\n        Returns:\n          A boolean value indicating whether Gloo is enabled.\n        """"""\n        gloo_enabled = self.MPI_LIB_CTYPES.horovod_gloo_enabled()\n        return bool(gloo_enabled)\n\n    def gloo_built(self):\n        """"""Returns True if Horovod was compiled with Gloo support.\n\n        Returns:\n          A boolean value indicating whether Gloo support was compiled.\n        """"""\n        return bool(self.MPI_LIB_CTYPES.horovod_gloo_built())\n\n    def nccl_built(self):\n        """"""Returns True if Horovod was compiled with NCCL support.\n\n        Returns:\n          A boolean value indicating whether NCCL support was compiled.\n        """"""\n        return bool(self.MPI_LIB_CTYPES.horovod_nccl_built())\n\n    def ddl_built(self):\n        """"""Returns True if Horovod was compiled with DDL support.\n\n        Returns:\n          A boolean value indicating whether DDL support was compiled.\n        """"""\n        return bool(self.MPI_LIB_CTYPES.horovod_ddl_built())\n\n    def ccl_built(self):\n        """"""Returns True if Horovod was compiled with oneCCL support.\n\n        Returns:\n          A boolean value indicating whether oneCCL support was compiled.\n        """"""\n        return bool(self.MPI_LIB_CTYPES.horovod_ccl_built())\n'"
horovod/common/elastic.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport functools\nimport queue\n\nfrom horovod.common.exceptions import HorovodInternalError, HostsUpdatedInterrupt\nfrom horovod.run.elastic.worker import WorkerNotificationManager\n\n\nnotification_manager = WorkerNotificationManager()\n\n\nclass State(object):\n    """"""State representation used for tracking in memory state across workers.\n\n    Args:\n        bcast_object: Function used to broadcast a variable from rank 0 to the other workers.\n        get_rank: Function that returns the current rank of this worker.\n    """"""\n    def __init__(self, bcast_object, get_rank):\n        self._bcast_object = bcast_object\n        self._rank = get_rank\n        self._host_messages = queue.Queue()\n        self._last_updated_timestamp = 0\n        self._reset_callbacks = []\n\n    def register_reset_callbacks(self, callbacks):\n        """"""Register callbacks that will be invoked following a reset event (worker added or removed).\n\n        For example, a common use of a reset callback would be to update the learning rate scale with the\n        new number of workers.\n\n        Args:\n            callbacks: list of functions to execute.\n        """"""\n        self._reset_callbacks.extend(callbacks)\n\n    def on_reset(self):\n        self._host_messages = queue.Queue()\n        self.reset()\n        for callback in self._reset_callbacks:\n            callback()\n\n    def on_hosts_updated(self, timestamp):\n        self._host_messages.put(timestamp)\n\n    def commit(self):\n        """"""Commits all modifications to state tracked by this object to host memory.\n\n        This call will also check for any changes to known hosts, and raise a `HostsUpdatedInterrupt`\n        if any were detected.\n\n        Because commits are a heavy operation involving data copy (potentially from GPU to host), it is\n        recommended to consider committing less frequently than once per batch. This allows users to tradeoff\n        between per-batch execution time and lost training steps in the event of a worker failure.\n        """"""\n        self.save()\n        self.check_host_updates()\n\n    def check_host_updates(self):\n        """"""Checks that a notification has been sent indicating that hosts can be added or will be removed.\n\n        Raises a `HostsUpdatedInterrupt` if such a notification has been received.\n        """"""\n        # Iterate through the update messages sent from the server. If the update timestamp\n        # is greater than the last update timestamp, then trigger a HostsUpdatedException.\n        last_updated_timestamp = prev_timestamp = self._last_updated_timestamp\n        while not self._host_messages.empty():\n            timestamp = self._host_messages.get()\n            if timestamp > last_updated_timestamp:\n                last_updated_timestamp = timestamp\n\n        # In order to ensure all workers raise the exception at the same time, we need to sync\n        # the updated state across all the workers.\n        # TODO(travis): this should be a max allreduce to account for changes in rank 0\n        prev_timestamp, self._last_updated_timestamp = self._bcast_object((prev_timestamp, last_updated_timestamp))\n\n        # At this point, updated state is globally consistent across all ranks.\n        if self._last_updated_timestamp > prev_timestamp:\n            raise HostsUpdatedInterrupt()\n\n    def save(self):\n        """"""Saves state to host memory.""""""\n        raise NotImplementedError()\n\n    def restore(self):\n        """"""Restores the last committed state, undoing any uncommitted modifications.""""""\n        raise NotImplementedError()\n\n    def sync(self):\n        """"""Synchronize state across workers.""""""\n        raise NotImplementedError()\n\n    def reset(self):\n        """"""Reset objects and variables following a reset event (before synchronization).""""""\n        pass\n\n\nclass ObjectState(State):\n    """"""State for simple Python objects.\n\n    Every object is specified as a keyword argument, and will be assigned as an attribute.\n\n    Args:\n        bcast_object: Horovod broadcast object function used to sync state dictionary.\n        get_rank: Horovod rank function used to identify is this process is the coordinator.\n        kwargs: Properties to sync, will be exposed as attributes of the object.\n    """"""\n    def __init__(self, bcast_object, get_rank, **kwargs):\n        self._bcast_object = bcast_object\n        self._saved_state = kwargs\n        self._set_attrs()\n        super(ObjectState, self).__init__(bcast_object=bcast_object, get_rank=get_rank)\n\n    def save(self):\n        new_state = {}\n        for attr in self._saved_state.keys():\n            new_state[attr] = getattr(self, attr)\n        self._saved_state = new_state\n\n    def restore(self):\n        self._set_attrs()\n\n    def sync(self):\n        if self._saved_state:\n            self._saved_state = self._bcast_object(self._saved_state)\n            self._set_attrs()\n\n    def _set_attrs(self):\n        for attr, value in self._saved_state.items():\n            setattr(self, attr, value)\n\n\ndef run_fn(func, reset):\n    @functools.wraps(func)\n    def wrapper(state, *args, **kwargs):\n        notification_manager.init()\n        notification_manager.register_listener(state)\n\n        try:\n            while True:\n                state.sync()\n\n                try:\n                    return func(state, *args, **kwargs)\n                except HorovodInternalError:\n                    state.restore()\n                except HostsUpdatedInterrupt:\n                    pass\n\n                reset()\n                state.on_reset()\n        finally:\n            notification_manager.remove_listener(state)\n    return wrapper\n'"
horovod/common/exceptions.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\nclass HorovodInternalError(RuntimeError):\n    """"""Internal error raised when a Horovod collective operation (e.g., allreduce) fails.\n\n    This is handled in elastic mode as a recoverable error, and will result in a reset event.\n    """"""\n    pass\n\n\nclass HostsUpdatedInterrupt(RuntimeError):\n    """"""Internal interrupt event indicating that the set of hosts in the job has changed.\n\n    In elastic mode, this will result in a reset event without a restore to committed state.\n    """"""\n    pass\n'"
horovod/common/util.py,0,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2019 Uber Technologies, Inc.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport multiprocessing\nimport os\nimport sys\nimport sysconfig\nimport warnings\n\nfrom contextlib import contextmanager\n\n\nEXTENSIONS = [\'tensorflow\', \'torch\', \'mxnet\']\n\n\ndef get_ext_suffix():\n    """"""Determine library extension for various versions of Python.""""""\n    ext_suffix = sysconfig.get_config_var(\'EXT_SUFFIX\')\n    if ext_suffix:\n        return ext_suffix\n\n    ext_suffix = sysconfig.get_config_var(\'SO\')\n    if ext_suffix:\n        return ext_suffix\n\n    return \'.so\'\n\n\ndef get_extension_full_path(pkg_path, *args):\n    assert len(args) >= 1\n    dir_path = os.path.join(os.path.dirname(pkg_path), *args[:-1])\n    full_path = os.path.join(dir_path, args[-1] + get_ext_suffix())\n    return full_path\n\n\ndef check_extension(ext_name, ext_env_var, pkg_path, *args):\n    full_path = get_extension_full_path(pkg_path, *args)\n    if not os.path.exists(full_path):\n        raise ImportError(\n            \'Extension %s has not been built.  If this is not expected, reinstall \'\n            \'Horovod with %s=1 to debug the build error.\' % (ext_name, ext_env_var))\n\n\ndef _check_extension_lambda(ext_base_name, fn, fn_desc, verbose):\n    """"""\n    Tries to load the extension in a new process.  If successful, puts fn(ext)\n    to the queue or False otherwise.  Mutes all stdout/stderr.\n    """"""\n    def _target_fn(ext_base_name, fn, fn_desc, queue, verbose):\n        import importlib\n        import sys\n        import traceback\n\n        if verbose:\n            print(\'Checking whether extension {ext_base_name} was {fn_desc}.\'.format(\n                ext_base_name=ext_base_name, fn_desc=fn_desc))\n        else:\n            # Suppress output\n            sys.stdout = open(os.devnull, \'w\')\n            sys.stderr = open(os.devnull, \'w\')\n\n        try:\n            ext = importlib.import_module(\'.\' + ext_base_name, \'horovod\')\n            result = fn(ext)\n        except:\n            traceback.print_exc()\n            result = None\n\n        if verbose:\n            print(\'Extension {ext_base_name} {flag} {fn_desc}.\'.format(\n                ext_base_name=ext_base_name, flag=(\'was\' if result else \'was NOT\'),\n                fn_desc=fn_desc))\n\n        queue.put(result)\n\n    # \'fork\' is required because horovodrun is a frozen executable\n    ctx = multiprocessing.get_context(\'fork\')\n    queue = ctx.Queue()\n    p = ctx.Process(target=_target_fn,\n                    args=(ext_base_name, fn, fn_desc, queue, verbose))\n    p.daemon = True\n    p.start()\n    p.join()\n    return queue.get_nowait()\n\n\ndef extension_available(ext_base_name, verbose=False):\n    available_fn = lambda ext: ext is not None\n    return _check_extension_lambda(\n        ext_base_name, available_fn, \'built\', verbose) or False\n\n\ndef _cache(f):\n    cache = dict()\n\n    def wrapper(*args, **kwargs):\n        key = (args, frozenset(kwargs.items()))\n\n        if key in cache:\n            return cache[key]\n        else:\n            retval = f(*args, **kwargs)\n            cache[key] = retval\n            return retval\n\n    return wrapper\n\n\n@_cache\ndef gpu_available(ext_base_name, verbose=False):\n    available_fn = lambda ext: ext._check_has_gpu()\n    return _check_extension_lambda(\n        ext_base_name, available_fn, \'running with GPU\', verbose) or False\n\n\n@_cache\ndef mpi_built(verbose=False):\n    for ext_base_name in EXTENSIONS:\n        built_fn = lambda ext: ext.mpi_built()\n        result = _check_extension_lambda(\n            ext_base_name, built_fn, \'built with MPI\', verbose)\n        if result is not None:\n            return result\n    return False\n\n\n@_cache\ndef gloo_built(verbose=False):\n    for ext_base_name in EXTENSIONS:\n        built_fn = lambda ext: ext.gloo_built()\n        result = _check_extension_lambda(\n            ext_base_name, built_fn, \'built with Gloo\', verbose)\n        if result is not None:\n            return result\n    raise RuntimeError(\'Failed to determine if Gloo support has been built. \'\n                       \'Run again with --verbose for more details.\')\n\n\n@_cache\ndef nccl_built(verbose=False):\n    for ext_base_name in EXTENSIONS:\n        built_fn = lambda ext: ext.nccl_built()\n        result = _check_extension_lambda(\n            ext_base_name, built_fn, \'built with NCCL\', verbose)\n        if result is not None:\n            return result\n    raise RuntimeError(\'Failed to determine if NCCL support has been built. \'\n                       \'Run again with --verbose for more details.\')\n\n\n@_cache\ndef ddl_built(verbose=False):\n    for ext_base_name in EXTENSIONS:\n        built_fn = lambda ext: ext.ddl_built()\n        result = _check_extension_lambda(\n            ext_base_name, built_fn, \'built with DDL\', verbose)\n        if result is not None:\n            return result\n    raise RuntimeError(\'Failed to determine if DDL support has been built. \'\n                       \'Run again with --verbose for more details.\')\n\n\n@_cache\ndef ccl_built(verbose=False):\n    for ext_base_name in EXTENSIONS:\n        built_fn = lambda ext: ext.ccl_built()\n        result = _check_extension_lambda(\n            ext_base_name, built_fn, \'built with CCL\', verbose)\n        if result is not None:\n            return result\n    raise RuntimeError(\'Failed to determine if CCL support has been built. \'\n                       \'Run again with --verbose for more details.\')\n\n\n@contextmanager\ndef env(**kwargs):\n    # ignore args with None values\n    for k in list(kwargs.keys()):\n        if kwargs[k] is None:\n            del kwargs[k]\n\n    # backup environment\n    backup = {}\n    for k in kwargs.keys():\n        backup[k] = os.environ.get(k)\n\n    # set new values & yield\n    for k, v in kwargs.items():\n        os.environ[k] = v\n\n    try:\n        yield\n    finally:\n        # restore environment\n        for k in kwargs.keys():\n            if backup[k] is not None:\n                os.environ[k] = backup[k]\n            else:\n                del os.environ[k]\n\n\ndef get_average_backwards_compatibility_fun(reduce_ops):\n    """"""\n    Handle backwards compatibility between the old average and the new op parameters.\n    Old code using the average parameter (e.g. hvd.allreduce(tensor, average=False))\n    gets unchanged behavior, but mixing old and new is disallowed (e.g. no\n    hvd.allreduce(tensor, average=False, op=hvd.Adasum)).\n    """"""\n    def impl(op, average):\n        if op != None:\n            if average != None:\n                raise ValueError(\'The op parameter supersedes average. Please provide only one of them.\')\n            return op\n        elif average != None:\n            warnings.warn(\'Parameter `average` has been replaced with `op` and will be removed in v0.21.0\',\n                          DeprecationWarning)\n            return reduce_ops.Average if average else reduce_ops.Sum\n        else:\n            return reduce_ops.Average\n    return impl\n\n\ndef num_rank_is_power_2(num_rank):\n    """"""\n    Tests if the given number of ranks is of power of 2. This check is required\n    for Adasum allreduce.\n    TODO support non-power of 2 ranks.\n    """"""\n    return num_rank != 0 and ((num_rank & (num_rank -1)) == 0)\n'"
horovod/keras/__init__.py,0,"b'# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport keras\nimport keras.backend as K\n\nfrom horovod.tensorflow import init\nfrom horovod.tensorflow import shutdown\nfrom horovod.tensorflow import size\nfrom horovod.tensorflow import local_size\nfrom horovod.tensorflow import rank\nfrom horovod.tensorflow import local_rank\nfrom horovod.tensorflow import mpi_threads_supported, mpi_enabled, mpi_built\nfrom horovod.tensorflow import gloo_enabled, gloo_built\nfrom horovod.tensorflow import nccl_built, ddl_built, ccl_built\nfrom horovod.tensorflow import Compression\n\nfrom horovod.keras import callbacks, elastic\nimport horovod._keras as _impl\n\n\ndef DistributedOptimizer(optimizer, name=None,\n                         device_dense=\'\', device_sparse=\'\',\n                         compression=Compression.none,\n                         sparse_as_dense=False):\n    """"""\n    An optimizer that wraps another keras.optimizers.Optimizer, using an allreduce to\n    average gradient values before applying gradients to model weights.\n\n    Args:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        name: Optional name prefix for the operations created when applying\n              gradients. Defaults to ""Distributed"" followed by the provided\n              optimizer type.\n        device_dense: Device to be used for dense tensors. Uses GPU by default\n                      if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        device_sparse: Device to be used for sparse tensors. Uses GPU by default\n                       if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n        sparse_as_dense: Treat all sparse gradients as dense tensors.  This can\n                         help improve performance and memory utilization if\n                         the original sparse gradient has high density.\n                         Defaults to false.\n    """"""\n    return _impl.create_distributed_optimizer(keras, optimizer, name,\n                                              device_dense, device_sparse, compression,\n                                              sparse_as_dense)\n\n\ndef broadcast_global_variables(root_rank):\n    """"""Broadcasts all global variables from root rank to all other processes.\n\n    Arguments:\n        root_rank: Rank of the process from which global variables will be broadcasted\n                   to all other processes.\n    """"""\n    return _impl.broadcast_global_variables(K, root_rank)\n\n\ndef allreduce(value, name=None, average=True):\n    """"""\n    Perform an allreduce on a tensor-compatible value.\n\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        name: Optional name for the constants created by this operation.\n        average: If True, computes the average over all ranks.\n                 Otherwise, computes the sum over all ranks.\n    """"""\n    return _impl.allreduce(K, value, name, average)\n\n\ndef allgather(value, name=None):\n    """"""\n    Perform an allgather on a tensor-compatible value.\n\n    The concatenation is done on the first dimension, so the input values on the\n    different processes must have the same rank and shape, except for the first\n    dimension, which is allowed to be different.\n\n    Arguments:\n        value: A tensor-compatible value to gather.\n        name: Optional name prefix for the constants created by this operation.\n    """"""\n    return _impl.allgather(K, value, name)\n\n\ndef broadcast(value, root_rank, name=None):\n    """"""\n    Perform a broadcast on a tensor-compatible value.\n\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        root_rank: Rank of the process from which global variables will be\n                   broadcasted to all other processes.\n        name: Optional name for the constants created by this operation.\n    """"""\n    return _impl.broadcast(K, value, root_rank, name)\n\n\ndef load_model(filepath, custom_optimizers=None, custom_objects=None, compression=Compression.none):\n    """"""\n    Loads a saved Keras model with a Horovod DistributedOptimizer.\n\n    The DistributedOptimizer will wrap the underlying optimizer used to train\n    the saved model, so that the optimizer state (params and weights) will\n    be picked up for retraining.\n\n    By default, all optimizers in the module `keras.optimizers` will be loaded\n    and wrapped without needing to specify any `custom_optimizers` or\n    `custom_objects`.\n\n    Arguments:\n        filepath: One of the following:\n            - string, path to the saved model, or\n            - h5py.File object from which to load the model\n        custom_optimizers: Optional list of Optimizer subclasses to support\n            during loading.\n        custom_objects: Optional dictionary mapping names (strings) to custom\n            classes or functions to be considered during deserialization.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n\n    Returns:\n        A Keras model instance.\n\n    Raises:\n        ImportError: If h5py is not available.\n        ValueError: In case of an invalid savefile.\n    """"""\n    def wrap_optimizer(cls):\n        return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)\n    optimizer_modules = {keras.optimizers.Optimizer.__module__}\n    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)\n'"
horovod/keras/callbacks.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport keras\nimport keras.backend as K\n\nfrom horovod._keras import callbacks as _impl\n\n\nclass BroadcastGlobalVariablesCallback(_impl.BroadcastGlobalVariablesCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will broadcast all global variables from root rank\n    to all other processes during initialization.\n\n    This is necessary to ensure consistent initialization of all workers when\n    training is started with random weights or restored from a checkpoint.\n    """"""\n\n    def __init__(self, root_rank, device=\'\'):\n        """"""\n        Construct a new BroadcastGlobalVariablesCallback that will broadcast all\n        global variables from root rank to all other processes during initialization.\n\n        Args:\n            root_rank: Rank that will send data, other ranks will receive data.\n            device: Device to be used for broadcasting. Uses GPU by default\n                    if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        """"""\n        super(BroadcastGlobalVariablesCallback, self).__init__(K, root_rank, device)\n\n\nclass MetricAverageCallback(_impl.MetricAverageCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will average metrics across all processes at the\n    end of the epoch. Useful in conjuction with ReduceLROnPlateau,\n    TensorBoard and other metrics-based callbacks.\n\n    Note: This callback must be added to the callback list before the\n    ReduceLROnPlateau, TensorBoard or other metrics-based callbacks.\n    """"""\n\n    def __init__(self, device=\'\'):\n        """"""\n        Construct a new MetricAverageCallback that will average metrics\n        across all processes at the end of the epoch.\n\n        Args:\n            device: Device to be used for allreduce. Uses GPU by default\n                    if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        """"""\n        super(MetricAverageCallback, self).__init__(K, device)\n\n\nclass LearningRateScheduleCallback(_impl.LearningRateScheduleCallbackImpl, keras.callbacks.Callback):\n    """"""\n    LearningRateScheduleCallback sets learning rate between epochs `start_epoch` and\n    `end_epoch` to be `initial_lr * multiplier`.  `multiplier` can be a constant or\n    a function `f(epoch) = lr\'`.\n\n    If `multiplier` is a function and `staircase=True`, learning rate adjustment will\n    happen at the beginning of each epoch and the epoch passed to the `multiplier`\n    function will be an integer.\n\n    If `multiplier` is a function and `staircase=False`, learning rate adjustment will\n    happen at the beginning of each batch and the epoch passed to the `multiplier`\n    function will be a floating number: `epoch\' = epoch + batch / steps_per_epoch`.\n    This functionality is useful for smooth learning rate adjustment schedulers, such\n    as `LearningRateWarmupCallback`.\n\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n    """"""\n\n    def __init__(self, multiplier, start_epoch=0, end_epoch=None, staircase=True,\n                 momentum_correction=True, steps_per_epoch=None, initial_lr=None):\n        """"""\n        Construct a new LearningRateScheduleCallback.\n\n        Args:\n            multiplier: A constant multiplier or a function `f(epoch) = lr\'`\n            start_epoch: The first epoch this adjustment will be applied to. Defaults to 0.\n            end_epoch: The epoch this adjustment will stop applying (exclusive end).\n                       Defaults to None.\n            staircase: Whether to adjust learning rate at the start of epoch (`staircase=True`)\n                       or at the start of every batch (`staircase=False`).\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in v0.21.0.\n\n        """"""\n        super(LearningRateScheduleCallback, self).__init__(K, multiplier, start_epoch, end_epoch,\n                                                           staircase, momentum_correction, steps_per_epoch,\n                                                           initial_lr)\n\n\nclass LearningRateWarmupCallback(_impl.LearningRateWarmupCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Implements gradual learning rate warmup:\n\n        `lr = initial_lr / hvd.size()` ---> `lr = initial_lr`\n\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n\n    This technique was described in the paper ""Accurate, Large Minibatch SGD: Training\n    ImageNet in 1 Hour"". See https://arxiv.org/pdf/1706.02677.pdf for details.\n\n    Math recap:\n\n    .. math::\n\n        epoch &= full\\\\_epochs + \\\\frac{batch}{steps\\\\_per\\\\_epoch}\n\n        lr\'(epoch) &= \\\\frac{lr}{size} * (\\\\frac{size - 1}{warmup} * epoch + 1)\n\n        lr\'(epoch = 0) &= \\\\frac{lr}{size}\n\n        lr\'(epoch = warmup) &= lr\n    """"""\n\n    def __init__(self, warmup_epochs=5, momentum_correction=True, steps_per_epoch=None,\n                 verbose=0, initial_lr=None):\n        """"""\n        Construct a new LearningRateWarmupCallback that will gradually warm up the learning rate.\n\n        Args:\n            warmup_epochs: The number of epochs of the warmup phase. Defaults to 5.\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            verbose: verbosity mode, 0 or 1.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in v0.21.0.\n        """"""\n        super(LearningRateWarmupCallback, self).__init__(K, warmup_epochs, momentum_correction,\n                                                         steps_per_epoch, verbose, initial_lr)\n'"
horovod/keras/elastic.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport keras\n\nfrom horovod._keras import elastic as _impl\nfrom horovod.tensorflow.elastic import TensorFlowKerasState\n\n\nclass KerasState(TensorFlowKerasState):\n    """"""State representation of a `keras` model and optimizer.\n\n    Args:\n        model: Keras model.\n        optimizer: Optional optimizer, can be compiled into model instead.\n        kwargs: Additional properties to sync, will be exposed as attributes of the object.\n    """"""\n    def __init__(self, model, optimizer=None, **kwargs):\n        super(KerasState, self).__init__(model, optimizer=optimizer, backend=keras.backend, **kwargs)\n\n\nclass CommitStateCallback(_impl.CommitStateCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will commit the `state` object every `batches_per_commit`\n    batches at the end of each batch.\n    """"""\n\n    def __init__(self, state, batches_per_commit=1):\n        """"""\n        Constructs a new CommitStateCallback.\n\n        Args:\n            state: `horovod.common.elastic.State` object to be committed.\n            batches_per_commit: Number of batches to complete between each commit (default: 1).\n        """"""\n        super(CommitStateCallback, self).__init__(keras.backend, state, batches_per_commit)\n\n\nclass UpdateBatchStateCallback(_impl.UpdateBatchStateCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will update the value of `state.batch` with the current batch number at\n    the end of each batch. Batch will reset to 0 at the end of each epoch.\n\n    If `steps_per_epoch` is set, then this callback will also ensure that the number of steps\n    in the first epoch following a reset is shortened by the number of batches already processed.\n    """"""\n\n    def __init__(self, state):\n        """"""\n        Constructs a new UpdateBatchStateCallback.\n\n        Args:\n            state: `horovod.common.elastic.State` object to be updated.\n        """"""\n        super(UpdateBatchStateCallback, self).__init__(keras.backend, state)\n\n\nclass UpdateEpochStateCallback(_impl.UpdateEpochStateCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will update the value of `state.epoch` with the current epoch number at\n    the end of each epoch.\n    """"""\n\n    def __init__(self, state):\n        """"""\n        Constructs a new UpdateEpochStateCallback.\n\n        Args:\n            state: `horovod.common.elastic.State` object to be updated.\n        """"""\n        super(UpdateEpochStateCallback, self).__init__(keras.backend, state)\n'"
horovod/mxnet/__init__.py,0,"b'# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.common.util import check_extension\n\ncheck_extension(\'horovod.mxnet\', \'HOROVOD_WITH_MXNET\',\n                __file__, \'mpi_lib\')\n\nfrom horovod.mxnet.mpi_ops import allgather\nfrom horovod.mxnet.mpi_ops import allreduce, allreduce_\nfrom horovod.mxnet.mpi_ops import broadcast, broadcast_\nfrom horovod.mxnet.mpi_ops import init, shutdown\nfrom horovod.mxnet.mpi_ops import size, local_size, rank, local_rank\nfrom horovod.mxnet.mpi_ops import mpi_threads_supported, mpi_enabled, mpi_built\nfrom horovod.mxnet.mpi_ops import gloo_enabled, gloo_built\nfrom horovod.mxnet.mpi_ops import nccl_built, ddl_built, ccl_built\n\nimport mxnet as mx\nimport types\nimport warnings\n\n\n# This is where Horovod\'s DistributedOptimizer wrapper for MXNet goes\nclass DistributedOptimizer(mx.optimizer.Optimizer):\n    def __init__(self, optimizer):\n        self._optimizer = optimizer\n        # Normalizing rescale_grad by Horovod size, which is equivalent to\n        # performing average in allreduce, has better performance.\n        self._optimizer.rescale_grad /= size()\n\n    def __getattr__(self, item):\n        return getattr(self._optimizer, item)\n\n    def create_state_multi_precision(self, index, weight):\n        return self._optimizer.create_state_multi_precision(index, weight)\n\n    def _do_allreduce(self, index, grad):\n        if size() == 1: return\n\n        if isinstance(index, (tuple, list)):\n            for i in range(len(index)):\n                allreduce_(grad[i], average=False,\n                           name=str(index[i]), priority=-i)\n        else:\n            allreduce_(grad, average=False, name=str(index))\n\n    def update(self, index, weight, grad, state):\n        self._do_allreduce(index, grad)\n        self._optimizer.update(index, weight, grad, state)\n\n    def update_multi_precision(self, index, weight, grad, state):\n        self._do_allreduce(index, grad)\n        self._optimizer.update_multi_precision(index, weight, grad, state)\n\n    def set_learning_rate(self, lr):\n        self._optimizer.set_learning_rate(lr)\n\n    def set_lr_mult(self, args_lr_mult):\n        self._optimizer.set_lr_mult(args_lr_mult)\n\n    def set_wd_mult(self, args_wd_mult):\n        self._optimizer.set_wd_mult(args_wd_mult)\n\n\n# DistributedTrainer, a subclass of MXNet gluon.Trainer.\n# There are two differences between DistributedTrainer and Trainer:\n# 1. DistributedTrainer calculates gradients using Horovod allreduce\n#    API while Trainer does it using kvstore push/pull APIs;\n# 2. DistributedTrainer performs allreduce(summation) and average\n#    while Trainer only performs allreduce(summation).\nclass DistributedTrainer(mx.gluon.Trainer):\n    def __init__(self, params, optimizer, optimizer_params=None):\n        if isinstance(optimizer, DistributedOptimizer):\n            optimizer = optimizer._optimizer\n            warnings.warn(""DistributedTrainer does not take DistributedOptimizer ""\n                          ""as its optimizer. We have unwrapped it for you."")\n\n        super(DistributedTrainer, self).__init__(\n            params, optimizer, optimizer_params=optimizer_params, kvstore=None)\n\n        # _scale is used to check and set rescale_grad for optimizer in Trainer.step()\n        # function. Normalizing it by Horovod size, which is equivalent to performing\n        # average in allreduce, has better performance. \n        self._scale /= size()\n\n    def _allreduce_grads(self):\n        if size() == 1: return\n\n        for i, param in enumerate(self._params):\n            if param.grad_req != \'null\':\n                allreduce_(param.list_grad()[0], average=False,\n                           name=param.name, priority=-i)\n\n\n# Wrapper to inject Horovod broadcast after parameter initialization\ndef _append_broadcast_init(param, root_rank):\n    init_impl = getattr(param, \'_init_impl\')\n    def wrapped_init_impl(self, *args, **kwargs):\n        init_impl(*args, **kwargs)\n        broadcast_(self.data(), root_rank=root_rank, name=self.name)\n    return wrapped_init_impl\n\n\ndef broadcast_parameters(params, root_rank=0):\n    """"""\n    Broadcasts the parameters from root rank to all other processes.\n    Typical usage is to broadcast the `Module.get_params()` or the\n    `Block.collect_params()`.\n\n    Arguments:\n        params: One of the following:\n            - dict of parameters to broadcast\n            - ParameterDict to broadcast\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n    """"""\n    if size() == 1: return\n\n    tensors = []\n    names = []\n    if isinstance(params, dict):\n        names, tensors = zip(*params.items())\n    elif isinstance(params, mx.gluon.parameter.ParameterDict):\n        for name, p in sorted(params.items()):\n            try:\n                tensors.append(p.data())\n                names.append(name)\n            except mx.gluon.parameter.DeferredInitializationError:\n                # Inject wrapper method with post-initialization broadcast to\n                # handle parameters with deferred initialization\n                new_init = _append_broadcast_init(p, root_rank)\n                p._init_impl = types.MethodType(new_init, p)\n    else:\n        raise ValueError(\'invalid params of type: %s\' % type(params))\n\n    # Run broadcasts.\n    for tensor, name in zip(tensors, names):\n        broadcast_(tensor, root_rank, name=str(name))\n'"
horovod/mxnet/mpi_ops.py,0,"b'# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n# Load all the necessary MXNet C types.\nimport ctypes\nimport os\n\nimport mxnet as mx\nfrom mxnet.base import c_str, check_call, string_types\n\nfrom horovod.common.util import get_ext_suffix\nfrom horovod.common.basics import HorovodBasics as _HorovodBasics\n_basics = _HorovodBasics(__file__, \'mpi_lib\')\n\n# import basic methods\ninit = _basics.init\nshutdown = _basics.shutdown\nsize = _basics.size\nlocal_size = _basics.local_size\nrank = _basics.rank\nlocal_rank = _basics.local_rank\nmpi_threads_supported = _basics.mpi_threads_supported\nmpi_enabled = _basics.mpi_enabled\nmpi_built = _basics.mpi_built\ngloo_enabled = _basics.gloo_enabled\ngloo_built = _basics.gloo_built\nnccl_built = _basics.nccl_built\nddl_built = _basics.ddl_built\nccl_built = _basics.ccl_built\n\ndll_path = os.path.join(os.path.dirname(__file__),\n                        \'mpi_lib\' + get_ext_suffix())\nMPI_MXNET_LIB_CTYPES = ctypes.CDLL(dll_path, ctypes.RTLD_GLOBAL)\n\n\ndef allreduce(tensor, average=True, name=None, priority=0):\n    """"""\n    A function that performs averaging or summation of the input tensor over\n    all the Horovod processes. The input tensor is not modified.\n\n    The reduction operation is keyed by the name. If name is not provided, an\n    incremented auto-generated name is used. The tensor type and shape must be\n    the same on all Horovod processes for a given name. The reduction will not\n    start until all processes are ready to send and receive the tensor.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n        priority: The priority of this operation. Higher priority operations\n                  are likely to be executed before other operations.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, averaged or summed\n        across all processes.\n    """"""\n    output = mx.nd.zeros(shape=tensor.shape, ctx=tensor.context,\n                         dtype=tensor.dtype)\n    c_in = tensor.handle\n    c_out = output.handle\n    if isinstance(name, string_types):\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allreduce_async(\n            c_in, c_out, c_str(name), ctypes.c_bool(average),\n            ctypes.c_int(priority)))\n    else:\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allreduce_async(\n            c_in, c_out, name, ctypes.c_bool(average),\n            ctypes.c_int(priority)))\n\n    return output\n\n\ndef allreduce_(tensor, average=True, name=None, priority=0):\n    """"""\n    A function that performs in-place averaging or summation of the input\n    tensor over all the Horovod processes.\n\n    The reduction operation is keyed by the name. If name is not provided, an\n    incremented auto-generated name is used. The tensor type and shape must be\n    the same on all Horovod processes for a given name. The reduction will not\n    start until all processes are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n        priority: The priority of this operation. Higher priority operations\n                  are likely to be executed before other operations.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, averaged or summed\n        across all processes.\n    """"""\n    c_in = tensor.handle\n    c_out = tensor.handle\n    if isinstance(name, string_types):\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allreduce_async(\n            c_in, c_out, c_str(name), ctypes.c_bool(average),\n            ctypes.c_int(priority)))\n    else:\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allreduce_async(\n            c_in, c_out, name, ctypes.c_bool(average),\n            ctypes.c_int(priority)))\n    return tensor\n\n\ndef allgather(tensor, name=None, priority=0):\n    """"""\n    A function that concatenates the input tensor with the same input tensor on\n    all other Horovod processes. The input tensor is not modified.\n\n    The concatenation is done on the first dimension, so the input tensors on\n    the different processes must have the same rank and shape, except for the\n    first dimension, which is allowed to be different.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to allgather.\n        name: A name of the allgather operation.\n        priority: The priority of this operation. Higher priority operations\n                  are likely to be executed before other operations.\n\n    Returns:\n        A tensor of the same type as `tensor`, concatenated on dimension zero\n        across all processes. The shape is identical to the input shape, except\n        for the first dimension, which may be greater and is the sum of all\n        first dimensions of the tensors in different Horovod processes.\n    """"""\n    assert(isinstance(tensor, mx.nd.NDArray))\n    output = mx.nd.zeros(shape=tensor.shape, ctx=tensor.context,\n                         dtype=tensor.dtype)\n    c_in = tensor.handle\n    c_out = output.handle\n    if isinstance(name, string_types):\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allgather_async(\n            c_in, c_out, c_str(name), ctypes.c_int(priority)))\n    else:\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allgather_async(\n            c_in, c_out, name, ctypes.c_int(priority)))\n    return output\n\n\ndef broadcast(tensor, root_rank, name=None, priority=0):\n    """"""\n    A function that broadcasts the input tensor on root rank to the same input\n    tensor on all other Horovod processes. The input tensor is not modified.\n\n    The broadcast operation is keyed by the name. If name is not provided, an\n    incremented auto-generated name is used. The tensor type and shape must be\n    the same on all Horovod processes for a given name. The broadcast will not\n    start until all processes are ready to send and receive the tensor.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to broadcast.\n        root_rank: The rank to broadcast the value from.\n        name: A name of the broadcast operation.\n        priority: The priority of this operation. Higher priority operations\n                  are likely to be executed before other operations.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, with the value\n        broadcasted from root rank.\n    """"""\n    if rank() == root_rank:\n        output = tensor.copy()\n    else:\n        output = mx.nd.zeros(shape=tensor.shape, ctx=tensor.context,\n                             dtype=tensor.dtype)\n    c_in = tensor.handle\n    c_out = output.handle\n    if isinstance(name, string_types):\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_broadcast_async(\n            c_in, c_out, c_str(name), ctypes.c_int(root_rank),\n            ctypes.c_int(priority)))\n    else:\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_broadcast_async(\n            c_in, c_out, name, ctypes.c_int(root_rank),\n            ctypes.c_int(priority)))\n    return output\n\n\ndef broadcast_(tensor, root_rank, name=None, priority=0):\n    """"""\n    A function that broadcasts the input tensor on root rank to the same input\n    tensor on all other Horovod processes. The operation is performed in-place.\n\n    The broadcast operation is keyed by the name. If name is not provided, an\n    incremented auto-generated name is used. The tensor type and shape must be\n    the same on all Horovod processes for a given name. The broadcast will not\n    start until all processes are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to broadcast.\n        root_rank: The rank to broadcast the value from.\n        name: A name of the broadcast operation.\n        priority: The priority of this operation. Higher priority operations\n                  are likely to be executed before other operations.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, with the value\n        broadcasted from root rank.\n    """"""\n    c_in = tensor.handle\n    c_out = tensor.handle\n    if isinstance(name, string_types):\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_broadcast_async(\n            c_in, c_out, c_str(name), ctypes.c_int(root_rank),\n            ctypes.c_int(priority)))\n    else:\n        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_broadcast_async(\n            c_in, c_out, name, ctypes.c_int(root_rank),\n            ctypes.c_int(priority)))\n    return tensor\n'"
horovod/run/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nfrom .runner import run\n'"
horovod/run/gloo_run.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport copy\nimport errno\nimport math\nimport os\nimport signal\nimport sys\nimport threading\nimport time\n\nfrom shlex import quote\n\nfrom horovod.run.common.util import env as env_util, safe_shell_exec\nfrom horovod.run.common.util.hosts import get_host_assignments, parse_hosts\nfrom horovod.run.driver import driver_service\nfrom horovod.run.elastic.driver import ElasticDriver\nfrom horovod.run.elastic.rendezvous import create_rendezvous_handler\nfrom horovod.run.http.http_server import RendezvousServer\nfrom horovod.run.util import network, threads\n\n\ndef _pad_rank(rank, size):\n    width = int(math.log10(size - 1)) + 1\n    return str(rank).zfill(width)\n\n\ndef _mkdir_p(path):\n    try:\n        os.makedirs(path)\n    except OSError as exc:\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\n\nclass MultiFile(object):\n    def __init__(self, files):\n        self._files = files\n\n    def write(self, text):\n        for f in self._files:\n            f.write(text)\n\n    def flush(self):\n        for f in self._files:\n            f.flush()\n\n\ndef _slot_info_to_command_fn(run_command, env):\n    # TODO: Workaround for over-buffered outputs. Investigate how mpirun avoids this problem.\n    env = copy.copy(env)  # copy env so we do not leak env modifications\n    env[\'PYTHONUNBUFFERED\'] = \'1\'\n\n    def slot_info_to_command(slot_info):\n        """"""\n        Given a slot_info, creates a command used by gloo to launch a single job.\n\n        :param slot_info: host and slot to execute the run command on\n        :return:\n        """"""\n        host_name = slot_info.hostname\n        horovod_rendez_env = (\n            \'HOROVOD_HOSTNAME={hostname} \'\n            \'HOROVOD_RANK={rank} \'\n            \'HOROVOD_SIZE={size} \'\n            \'HOROVOD_LOCAL_RANK={local_rank} \'\n            \'HOROVOD_LOCAL_SIZE={local_size} \'\n            \'HOROVOD_CROSS_RANK={cross_rank} \'\n            \'HOROVOD_CROSS_SIZE={cross_size} \'\n                .format(hostname=host_name,\n                        rank=slot_info.rank,\n                        size=slot_info.size,\n                        local_rank=slot_info.local_rank,\n                        local_size=slot_info.local_size,\n                        cross_rank=slot_info.cross_rank,\n                        cross_size=slot_info.cross_size))\n\n        return \'{horovod_env} {env} {run_command}\' .format(\n            horovod_env=horovod_rendez_env,\n            env=\' \'.join([\'%s=%s\' % (key, quote(value)) for key, value in env.items()\n                          if env_util.is_exportable(key)]),\n            run_command=run_command)\n\n    return slot_info_to_command\n\n\ndef _create_elastic_worker_fn(exec_command, run_command, env, event):\n    get_command_with_env = _slot_info_to_command_fn(run_command, env)\n\n    def create_worker(slot_info, events):\n        command = get_command_with_env(slot_info)\n        events = [event] + (events or [])\n        return exec_command(command, slot_info, events)\n    return create_worker\n\n\ndef _exec_command_fn(settings):\n    """"""\n    executes the jobs defined by run command on hosts.\n    :param hosts_alloc: list of dict indicating the allocating info.\n    For example,\n        [{\'Hostname\':\'worker-0\', \'Rank\': 0, \'Local_rank\': 0, \'Cross_rank\':0,\n            \'Size\':2, \'Local_size\':1, \'Cross_size\':2},\n        {\'Hostname\':\'worker-1\', \'Rank\': 1, \'Local_rank\': 0, \'Cross_rank\':1,\n            \'Size\':2, \'Local_size\':1, \'Cross_size\':2}\n        ]\n    :type hosts_alloc: list(dict)\n    :param remote_host_names: names that are resolved to one of the addresses\n    of remote hosts interfaces.\n    :type remote_host_names: set\n    :param _run_command: command to execute\n    :type _run_command: string\n    :return:\n    :rtype:\n    """"""\n    ssh_port_arg = \'-p {ssh_port}\'.format(ssh_port=settings.ssh_port) if settings.ssh_port else \'\'\n\n    def _exec_command(command, slot_info, events):\n        index = slot_info.rank\n        host_name = slot_info.hostname\n\n        host_address = network.resolve_host_address(host_name)\n        local_addresses = network.get_local_host_addresses()\n        if host_address not in local_addresses:\n            command = \'ssh -o StrictHostKeyChecking=no {host} {ssh_port_arg} \' \\\n                      \'{local_command}\'\\\n                .format(host=host_name,\n                        ssh_port_arg=ssh_port_arg,\n                        local_command=quote(\'cd {pwd} > /dev/null 2>&1 ; {local_command}\'\n                                            .format(pwd=os.getcwd(), local_command=command)))\n\n        if settings.verbose:\n            print(command)\n\n        # Redirect output if requested\n        stdout = stderr = None\n        stdout_file = stderr_file = None\n        if settings.output_filename:\n            padded_rank = _pad_rank(index, settings.num_proc)\n            output_dir_rank = os.path.join(settings.output_filename, \'rank.{rank}\'.format(rank=padded_rank))\n            if not os.path.exists(output_dir_rank):\n                os.mkdir(output_dir_rank)\n\n            stdout_file = open(os.path.join(output_dir_rank, \'stdout\'), \'w\')\n            stderr_file = open(os.path.join(output_dir_rank, \'stderr\'), \'w\')\n\n            stdout = MultiFile([sys.stdout, stdout_file])\n            stderr = MultiFile([sys.stderr, stderr_file])\n\n        try:\n            exit_code = safe_shell_exec.execute(command, index=index, stdout=stdout, stderr=stderr, events=events)\n            if exit_code != 0:\n                print(\'Process {idx} exit with status code {ec}.\'.format(idx=index, ec=exit_code))\n        except Exception as e:\n            print(\'Exception happened during safe_shell_exec, exception \'\n                  \'message: {message}\'.format(message=e))\n            exit_code = 1\n        finally:\n            if stdout_file:\n                stdout_file.close()\n            if stderr_file:\n                stderr_file.close()\n        return exit_code, time.time()\n\n    return _exec_command\n\n\ndef get_run_command(command, server_ip, nics, port, elastic=False):\n    run_command = (\n        \'HOROVOD_GLOO_RENDEZVOUS_ADDR={addr} \'\n        \'HOROVOD_GLOO_RENDEZVOUS_PORT={port} \'\n        \'HOROVOD_CONTROLLER=gloo \'\n        \'HOROVOD_CPU_OPERATIONS=gloo \'\n        \'HOROVOD_GLOO_IFACE={iface} \'\n        \'NCCL_SOCKET_IFNAME={nics} \'\n        \'{elastic}\'\n        \'{command}\'  # expect a lot of environment variables\n        .format(addr=server_ip,\n                port=port,\n                iface=list(nics)[0],  # TODO: add multiple ifaces in future\n                nics=\',\'.join(nics),\n                elastic=\'HOROVOD_ELASTIC=1 \' if elastic else \'\',\n                command=\' \'.join(quote(par) for par in command)))\n    return run_command\n\n\ndef register_shutdown_event():\n    # Create a event for communication between threads\n    event = threading.Event()\n\n    def set_event_on_signal(signum, frame):\n        event.set()\n\n    signal.signal(signal.SIGINT, set_event_on_signal)\n    signal.signal(signal.SIGTERM, set_event_on_signal)\n    return event\n\n\ndef launch_gloo(command, exec_command, settings, nics, env, server_ip):\n    """"""\n    Launches the given command multiple times using gloo.\n    Each command is launched via exec_command.\n\n    :param command: command to launch\n    :param exec_command: means to execute a single command\n    :param settings: settings for the distribution\n    :param nics: common interfaces\n    :param env: environment to use\n    :param server_ip: ip to use for rendezvous server\n    """"""\n    # Make the output directory if it does not exist\n    if settings.output_filename:\n        _mkdir_p(settings.output_filename)\n\n    # start global rendezvous server and get port that it is listening on\n    rendezvous = RendezvousServer(settings.verbose)\n\n    # allocate processes into slots\n    hosts = parse_hosts(settings.hosts)\n    host_alloc_plan = get_host_assignments(hosts, settings.num_proc)\n\n    # start global rendezvous server and get port that it is listening on\n    global_rendezv_port = rendezvous.start_server()\n    rendezvous.httpd.init(host_alloc_plan)\n    run_command = get_run_command(command, server_ip, nics, global_rendezv_port)\n\n    slot_info_to_command = _slot_info_to_command_fn(run_command, env)\n    event = register_shutdown_event()\n    args_list = [[slot_info_to_command(slot_info), slot_info, [event]]\n                 for slot_info in host_alloc_plan]\n\n    # If an error occurs in one thread, entire process will be terminated.\n    # Otherwise, threads will keep running.\n    res = threads.execute_function_multithreaded(exec_command,\n                                                 args_list,\n                                                 block_until_all_done=True)\n\n    for name, value in sorted(res.items(), key=lambda item: item[1][1]):\n        exit_code, timestamp = value\n        if exit_code != 0:\n            raise RuntimeError(\'Horovod detected that one or more processes exited with non-zero \'\n                               \'status, thus causing the job to be terminated. The first process \'\n                               \'to do so was:\\nProcess name: {name}\\nExit code: {code}\\n\'\n                               .format(name=name, code=exit_code))\n\n\ndef _get_min_start_hosts(settings):\n    # This function exists for the purpose of mocking in tests\n    return 2 if settings.elastic and not settings.nics else 1\n\n\ndef gloo_run(settings, nics, env, server_ip, command):\n    # Each thread will use ssh command to launch the job on each remote host. If an\n    # error occurs in one thread, entire process will be terminated. Otherwise,\n    # threads will keep running and ssh session.\n    exec_command = _exec_command_fn(settings)\n    launch_gloo(command, exec_command, settings, nics, env, server_ip)\n\n\ndef gloo_run_elastic(settings, env, command):\n    # Make the output directory if it does not exist\n    if settings.output_filename:\n        _mkdir_p(settings.output_filename)\n\n    rendezvous = RendezvousServer(settings.verbose)\n    driver = ElasticDriver(rendezvous, settings.discovery,\n                           settings.min_np, settings.max_np,\n                           timeout=settings.elastic_timeout,\n                           verbose=settings.verbose)\n\n    handler = create_rendezvous_handler(driver)\n    global_rendezv_port = rendezvous.start_server(handler)\n\n    # Host-to-host common interface detection requires at least 2 hosts in an elastic job.\n    min_hosts = _get_min_start_hosts(settings)\n    current_hosts = driver.wait_for_available_slots(settings.num_proc, min_hosts=min_hosts)\n\n    nics = driver_service.get_common_interfaces(settings, current_hosts.host_assignment_order)\n    server_ip = network.get_driver_ip(nics)\n\n    exec_command = _exec_command_fn(settings)\n    event = register_shutdown_event()\n    run_command = get_run_command(command, server_ip, nics, global_rendezv_port, elastic=True)\n    create_worker = _create_elastic_worker_fn(exec_command, run_command, env, event)\n\n    driver.start(settings.num_proc, create_worker)\n    res = driver.get_results()\n    driver.stop()\n    rendezvous.stop_server()\n\n    for name, value in sorted(res.items(), key=lambda item: item[1][1]):\n        exit_code, timestamp = value\n        if exit_code != 0:\n            raise RuntimeError(\'Horovod detected that one or more processes exited with non-zero \'\n                               \'status, thus causing the job to be terminated. The first process \'\n                               \'to do so was:\\nProcess name: {name}\\nExit code: {code}\\n\'\n                               .format(name=name, code=exit_code))\n'"
horovod/run/js_run.py,0,"b'# Copyright IBM Corp. 2020. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport tempfile\n\nfrom shlex import quote\n\nfrom horovod.run.common.util import safe_shell_exec\nfrom horovod.run.util import lsf\nfrom distutils.spawn import find_executable\nfrom horovod.run.mpi_run import _get_mpi_implementation_flags, _MPI_NOT_FOUND_ERROR_MSG\n\n\ndef is_jsrun_installed():\n    """"""Returns True if jsrun is installed.""""""\n    return find_executable(\'jsrun\') is not None\n\n\ndef js_run(settings, nics, env, command, stdout=None, stderr=None):\n    """"""\n    Runs Horovod with jsrun.\n\n    Args:\n        settings: Settings for running jsrun.\n                  Note: settings.num_proc and settings.hosts must not be None.\n        nics: Interfaces to include by jsrun.\n        env: Environment dictionary to use for running jsrun.\n        command: Command and arguments to run as a list of string.\n        stdout: Stdout of the mpi process.\n                Only used when settings.run_func_mode is True.\n        stderr: Stderr of the mpi process.\n                Only used when settings.run_func_mode is True.\n    """"""\n    mpi_impl_flags, _ = _get_mpi_implementation_flags(settings.tcp_flag, env=env)\n    if mpi_impl_flags is None:\n        raise Exception(_MPI_NOT_FOUND_ERROR_MSG)\n\n    if not is_jsrun_installed():\n        raise Exception(\n            \'horovod does not find the jsrun command.\\n\\n\'\n            \'Please, make sure you are running on a cluster with jsrun installed or \'\n            \'use one of the other launchers.\')\n\n    if nics and \'NCCL_SOCKET_IFNAME\' not in env:\n        env[\'NCCL_SOCKET_IFNAME\'] = \',\'.join(nics)\n\n    smpiargs = \' \'.join(mpi_impl_flags)\n    if settings.extra_mpi_args:\n        smpiargs += \' \' + settings.extra_mpi_args\n\n    if settings.binding_args:\n        binding_args = settings.binding_args\n    else:\n        rf = generate_jsrun_rankfile(settings)\n        if settings.verbose >= 2:\n            safe_shell_exec.execute(\'cat {rf}\'.format(rf=rf))\n        binding_args = \'--erf_input {rf}\'.format(rf=rf)\n\n    jsrun_command = (\n        \'jsrun {binding_args} \'\n        \'{output_filename_arg} \'\n        \'{smpiargs} \'\n        \'{command}\'\n        .format(binding_args = binding_args,\n                output_filename_arg=\'--stdio_stderr {file} --stdio_stdout {file}\'.format(file=settings.output_filename)\n                                    if settings.output_filename else \'\',\n                smpiargs= \'--smpiargs {args}\'.format(args=quote(smpiargs)) if smpiargs else \'\',\n                command=\' \'.join(quote(par) for par in command))\n    )\n\n    if settings.verbose >= 2:\n        print(jsrun_command)\n\n    # Execute the jsrun command.\n    if settings.run_func_mode:\n        exit_code = safe_shell_exec.execute(jsrun_command, env=env, stdout=stdout, stderr=stderr)\n        if exit_code != 0:\n            raise RuntimeError(""jsrun failed with exit code {exit_code}"".format(exit_code=exit_code))\n    else:\n        os.execve(\'/bin/sh\', [\'/bin/sh\', \'-c\', jsrun_command], env)\n\n\ndef generate_jsrun_rankfile(settings, path=None):\n    """"""\n    Generates rankfile to use with jsrun.\n    It splits the cores among the processes, which leads to best performance according to experiments.\n\n    Args:\n        settings: Settings for running jsrun.\n                  Note: settings.num_proc and settings.hosts must not be None.\n        path: Optional path of the rankfile.\n              Note: this file will be overwritten.\n    """"""\n    cpu_per_gpu = (lsf.LSFUtils.get_num_cores() * lsf.LSFUtils.get_num_threads()) // lsf.LSFUtils.get_num_gpus()\n    host_list = (x.split(\':\') for x in settings.hosts.split(\',\'))\n\n    # Verify and truncate host list if necessary\n    validated_list = []\n    remaining_slots = settings.num_proc\n    for host, slots in host_list:\n        slots = int(slots)\n        if slots > lsf.LSFUtils.get_num_gpus():\n            raise ValueError(\'Invalid host input, slot count for host \\\'{host}:{slots}\\\' is greater \'\n                             \'than number of GPUs per host \\\'{gpus}\\\'.\'.format(\n                host=host, slots=slots, gpus=lsf.LSFUtils.get_num_gpus()))\n        needed_slots = min(slots, remaining_slots)\n        validated_list.append((host, needed_slots))\n        remaining_slots -= needed_slots\n        if remaining_slots == 0:\n            break\n    if remaining_slots != 0:\n        raise ValueError(\'Not enough slots on the hosts to fulfill the {slots} requested.\'.format(\n            slots=settings.num_proc))\n\n    # Generate rankfile\n    path = tempfile.mktemp() if path is None else path\n    with open(path, \'w\') as tmp:\n        tmp.write(\'overlapping_rs: allow\\n\')\n        tmp.write(\'cpu_index_using: logical\\n\')\n        rank = 0\n        for host, slots in validated_list:\n            cpu_val = 0\n            tmp.write(\'\\n\')\n            for s in range(slots):\n                tmp.write(\'rank: {rank}: {{ hostname: {host}; cpu: {{{scpu}-{ecpu}}} ; gpu: * ; mem: * }}\\n\'.format(\n                    rank=rank,\n                    host=host,\n                    scpu=cpu_val,\n                    ecpu=cpu_val + cpu_per_gpu - 1\n                ))\n                rank += 1\n                cpu_val += cpu_per_gpu\n    return path\n'"
horovod/run/mpi_run.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport copy\nimport os\nimport sys\n\nfrom shlex import quote\n\nfrom horovod.run.common.util import env as env_util, safe_shell_exec, tiny_shell_exec\n\n# MPI implementations\n_OMPI_IMPL = \'OpenMPI\'\n_SMPI_IMPL = \'SpectrumMPI\'\n_MPICH_IMPL = \'MPICH\'\n_UNKNOWN_IMPL = \'Unknown\'\n_MISSING_IMPL = \'Missing\'\n\n# Open MPI Flags\n_OMPI_FLAGS = [\'-mca pml ob1\', \'-mca btl ^openib\']\n# Spectrum MPI Flags\n_SMPI_FLAGS = []\n_SMPI_FLAGS_TCP = [\'-tcp\']\n# MPICH Flags\n_MPICH_FLAGS = []\n\n# Threshold for large cluster MPI issues:\n_LARGE_CLUSTER_THRESHOLD = 64\n# No process binding args\n_NO_BINDING_ARGS = [\'-bind-to none\', \'-map-by slot\']\n# Process socket binding args\n_SOCKET_BINDING_ARGS = [\'-bind-to socket\', \'-map-by socket\', \'-rank-by core\']\n\n# MPI not found error message\n_MPI_NOT_FOUND_ERROR_MSG= (\'horovod does not find an installed MPI.\\n\\n\'\n                           \'Choose one of:\\n\'\n                           \'1. Install Open MPI 4.0.0+ or IBM Spectrum MPI or MPICH and re-install Horovod \'\n                           \'(use --no-cache-dir pip option).\\n\'\n                           \'2. Run distributed \'\n                           \'training script using the standard way provided by your\'\n                           \' MPI distribution (usually mpirun, srun, or jsrun).\\n\'\n                           \'3. Use built-in gloo option (horovodrun --gloo ...).\')\n\n\ndef mpi_available(env=None):\n    return _get_mpi_implementation(env) not in {_UNKNOWN_IMPL, _MISSING_IMPL}\n\n\ndef is_open_mpi(env=None):\n    return _get_mpi_implementation(env) == _OMPI_IMPL\n\n\ndef is_spectrum_mpi(env=None):\n    return _get_mpi_implementation(env) == _SMPI_IMPL\n\n\ndef is_mpich(env=None):\n    return _get_mpi_implementation(env) == _MPICH_IMPL\n\n\ndef _get_mpi_implementation(env=None):\n    """"""\n    Detects the available MPI implementation by invoking `mpirun --version`.\n    This command is executed by the given execute function, which takes the\n    command as the only argument and returns (output, exit code). Output\n    represents the stdout and stderr as a string.\n\n    Returns one of:\n    - _OMPI_IMPL, _SMPI_IMPL or _MPICH_IMPL for known implementations\n    - _UNKNOWN_IMPL for any unknown implementation\n    - _MISSING_IMPL if `mpirun --version` could not be executed.\n\n    :param env: environment variable to use to run mpirun\n    :return: string representing identified implementation\n    """"""\n    command = \'mpirun --version\'\n    res = tiny_shell_exec.execute(command, env)\n    if res is None:\n        return _MISSING_IMPL\n    (output, exit_code) = res\n\n    if exit_code == 0:\n        if \'Open MPI\' in output or \'OpenRTE\' in output:\n            return _OMPI_IMPL\n        elif \'IBM Spectrum MPI\' in output:\n            return _SMPI_IMPL\n        elif \'MPICH\' in output:\n            return _MPICH_IMPL\n\n        print(\'Unknown MPI implementation given in output of mpirun --version:\', file=sys.stderr)\n        print(output, file=sys.stderr)\n        return _UNKNOWN_IMPL\n    else:\n        print(\'Was unable to run {command}:\'.format(command=command), file=sys.stderr)\n        print(output, file=sys.stderr)\n        return _MISSING_IMPL\n\n\ndef _get_mpi_implementation_flags(tcp_flag, env=None):\n    if is_open_mpi(env):\n        return list(_OMPI_FLAGS), list(_NO_BINDING_ARGS)\n    elif is_spectrum_mpi(env):\n        return list(_SMPI_FLAGS) if not tcp_flag else list(_SMPI_FLAGS_TCP), list(_SOCKET_BINDING_ARGS)\n    elif is_mpich(env):\n        return list(_MPICH_FLAGS), list(_NO_BINDING_ARGS)\n    else:\n        return None, None\n\n\ndef mpi_run(settings, nics, env, command, stdout=None, stderr=None):\n    """"""\n    Runs mpi_run.\n\n    Args:\n        settings: Settings for running MPI.\n                  Note: settings.num_proc and settings.hosts must not be None.\n        nics: Interfaces to include by MPI.\n        env: Environment dictionary to use for running command.\n        command: Command and arguments to run as a list of string.\n        stdout: Stdout of the mpi process.\n                Only used when settings.run_func_mode is True.\n        stderr: Stderr of the mpi process.\n                Only used when settings.run_func_mode is True.\n    """"""\n    mpi_impl_flags, impl_binding_args = _get_mpi_implementation_flags(settings.tcp_flag, env=env)\n    if mpi_impl_flags is None:\n        raise Exception(_MPI_NOT_FOUND_ERROR_MSG)\n\n    ssh_port_arg = \'-mca plm_rsh_args \\""-p {ssh_port}\\""\'.format(\n            ssh_port=settings.ssh_port) if settings.ssh_port else \'\'\n\n    # if user does not specify any hosts, mpirun by default uses local host.\n    # There is no need to specify localhost.\n    hosts_arg = \'-H {hosts}\'.format(hosts=settings.hosts)\n\n    tcp_intf_arg = \'-mca btl_tcp_if_include {nics}\'.format(\n        nics=\',\'.join(nics)) if nics else \'\'\n    nccl_socket_intf_arg = \'-x NCCL_SOCKET_IFNAME={nics}\'.format(\n        nics=\',\'.join(nics)) if nics else \'\'\n\n    # On large cluster runs (e.g. Summit), we need extra settings to work around OpenMPI issues\n    if settings.num_hosts and settings.num_hosts >= _LARGE_CLUSTER_THRESHOLD:\n        mpi_impl_flags.append(\'-mca plm_rsh_no_tree_spawn true\')\n        mpi_impl_flags.append(\'-mca plm_rsh_num_concurrent {}\'.format(settings.num_hosts))\n\n    binding_args = settings.binding_args if settings.binding_args else \' \'.join(impl_binding_args)\n\n    # Pass all the env variables to the mpirun command.\n    mpirun_command = (\n        \'mpirun --allow-run-as-root --tag-output \'\n        \'-np {num_proc} {hosts_arg} \'\n        \'{binding_args} \'\n        \'{mpi_args} \'\n        \'{ssh_port_arg} \'\n        \'{tcp_intf_arg} \'\n        \'{nccl_socket_intf_arg} \'\n        \'{output_filename_arg} \'\n        \'{env} {extra_mpi_args} {command}\'  # expect a lot of environment variables\n        .format(num_proc=settings.num_proc,\n                hosts_arg=hosts_arg,\n                binding_args=binding_args,\n                mpi_args=\' \'.join(mpi_impl_flags),\n                tcp_intf_arg=tcp_intf_arg,\n                nccl_socket_intf_arg=nccl_socket_intf_arg,\n                ssh_port_arg=ssh_port_arg,\n                output_filename_arg=\'--output-filename \' + settings.output_filename\n                                    if settings.output_filename else \'\',\n                env=\' \'.join(\'-x %s\' % key for key in sorted(env.keys())\n                             if env_util.is_exportable(key)),\n\n                extra_mpi_args=settings.extra_mpi_args if settings.extra_mpi_args else \'\',\n                command=\' \'.join(quote(par) for par in command))\n    )\n\n    if settings.verbose >= 2:\n        print(mpirun_command)\n\n    # we need the driver\'s PATH in env to run mpirun,\n    # env for mpirun is different to env encoded in mpirun_command\n    if \'PATH\' not in env and \'PATH\' in os.environ:\n        env = copy.copy(env)  # copy env so we do not leak env modifications\n        env[\'PATH\'] = os.environ[\'PATH\']\n\n    # Execute the mpirun command.\n    if settings.run_func_mode:\n        exit_code = safe_shell_exec.execute(mpirun_command, env=env, stdout=stdout, stderr=stderr)\n        if exit_code != 0:\n            raise RuntimeError(""mpirun failed with exit code {exit_code}"".format(exit_code=exit_code))\n    else:\n        os.execve(\'/bin/sh\', [\'/bin/sh\', \'-c\', mpirun_command], env)\n'"
horovod/run/run_task.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport sys\n\nfrom horovod.run.common.util.env import get_env_rank_and_size\nfrom horovod.run.http.http_client import read_data_from_kvstore, put_data_into_kvstore\n\n\ndef main(addr, port):\n    func = read_data_from_kvstore(addr, port, \'runfunc\', \'func\')\n    try:\n        ret_val = func()\n    except BaseException as e:\n        sys.stderr.write(""User function raise error: {error}"".format(error=str(e)))\n        raise e\n\n    rank, size = get_env_rank_and_size()\n    put_data_into_kvstore(addr, port, \'runfunc_result\', str(rank), ret_val)\n\n\nif __name__ == \'__main__\':\n    _, driver_addr, run_func_server_port_str = sys.argv\n    run_func_server_port = int(run_func_server_port_str)\n    main(driver_addr, run_func_server_port)\n'"
horovod/run/runner.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \'License\');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \'AS IS\' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport hashlib\nimport logging\nimport io\nimport os\nimport re\nimport sys\nimport textwrap\n\nfrom shlex import quote\n\nimport yaml\n\nimport horovod\n\nfrom horovod.common.util import (extension_available,\n                                 gloo_built, mpi_built,\n                                 nccl_built, ddl_built, ccl_built)\nfrom horovod.run.common.util import config_parser, safe_shell_exec, timeout, secret\nfrom horovod.run.common.util import settings as hvd_settings\nfrom horovod.run.driver import driver_service\nfrom horovod.run.elastic import settings as elastic_settings\nfrom horovod.run.elastic import discovery\nfrom horovod.run.util import cache, threads, network, lsf\nfrom horovod.run.gloo_run import gloo_run, gloo_run_elastic\nfrom horovod.run.mpi_run import mpi_run\nfrom horovod.run.js_run import js_run, is_jsrun_installed\nfrom horovod.run.http.http_client import read_data_from_kvstore, put_data_into_kvstore\nfrom horovod.run.http.http_server import KVStoreServer\n\n\n# Cached information of horovod functions be stored in this directory\nCACHE_FOLDER = os.path.join(os.path.expanduser(\'~\'), \'.horovod\')\n\n# Cache entries will be stale if they are older than this number of minutes\nCACHE_STALENESS_THRESHOLD_MINUTES = 60\n\n# Number of attempts for sshing into the hosts\nSSH_ATTEMPTS = 5\n\n\n@cache.use_cache()\ndef _check_all_hosts_ssh_successful(host_addresses, ssh_port=None):\n    """"""\n    checks if ssh can successfully be performed to all the hosts.\n    :param host_addresses: list of addresses to ssh into. for example,\n        [\'worker-0\',\'worker-1\']\n        [\'10.11.11.11\', \'10.11.11.12\']\n    :type host_addresses: list(strings)\n    :return: Returns True if all ssh was successful into all the addresses.\n    """"""\n\n    def exec_command(command):\n        exit_code = 1\n        output_msg = \'\'\n\n        # Try ssh 5 times\n        for i in range(SSH_ATTEMPTS):\n            output = io.StringIO()\n            try:\n                exit_code = safe_shell_exec.execute(command,\n                                                    stdout=output,\n                                                    stderr=output)\n                if exit_code == 0:\n                    break\n                output_msg = output.getvalue()\n            finally:\n                output.close()\n        return exit_code, output_msg\n\n    ssh_port_arg = \'-p {ssh_port}\'.format(\n        ssh_port=ssh_port) if ssh_port else \'\'\n\n    ssh_command_format = \'ssh -o StrictHostKeyChecking=no {host} {ssh_port_arg} date\'\n\n    args_list = [[ssh_command_format.format(host=host_address,\n                                            ssh_port_arg=ssh_port_arg)]\n                 for host_address in host_addresses]\n    ssh_exit_codes = \\\n        threads.execute_function_multithreaded(exec_command,\n                                               args_list)\n\n    ssh_successful_to_all_hosts = True\n    for index, ssh_status in ssh_exit_codes.items():\n        exit_code, output_msg = ssh_status[0], ssh_status[1]\n        if exit_code != 0:\n            print(\'ssh not successful for host {host}:\\n{msg_output}\'\n                  .format(host=host_addresses[index],\n                          msg_output=output_msg))\n\n            ssh_successful_to_all_hosts = False\n    if not ssh_successful_to_all_hosts:\n        exit(1)\n    return True\n\n\ndef check_build(verbose):\n    def get_check(value):\n        return \'X\' if value else \' \'\n\n    output = \'\'\'{verbose_newline}\\\n    Horovod v{version}:\n\n    Available Frameworks:\n        [{tensorflow}] TensorFlow\n        [{torch}] PyTorch\n        [{mxnet}] MXNet\n\n    Available Controllers:\n        [{mpi}] MPI\n        [{gloo}] Gloo\n\n    Available Tensor Operations:\n        [{nccl_ops}] NCCL\n        [{ddl_ops}] DDL\n        [{ccl_ops}] CCL\n        [{mpi_ops}] MPI\n        [{gloo_ops}] Gloo\\\n    \'\'\'.format(verbose_newline=\'\\n\' if verbose else \'\',\n               version=horovod.__version__,\n               tensorflow=get_check(extension_available(\'tensorflow\', verbose=verbose)),\n               torch=get_check(extension_available(\'torch\', verbose=verbose)),\n               mxnet = get_check(extension_available(\'mxnet\', verbose=verbose)),\n               mpi=get_check(mpi_built(verbose=verbose)),\n               gloo=get_check(gloo_built(verbose=verbose)),\n               nccl_ops=get_check(nccl_built(verbose=verbose)),\n               ddl_ops=get_check(ddl_built(verbose=verbose)),\n               mpi_ops=get_check(mpi_built(verbose=verbose)),\n               ccl_ops=get_check(ccl_built(verbose=verbose)),\n               gloo_ops=get_check(gloo_built(verbose=verbose)))\n    print(textwrap.dedent(output))\n    os._exit(0)\n\n\ndef make_check_build_action(np_arg):\n    class CheckBuildAction(argparse.Action):\n        def __call__(self, parser, args, values, option_string=None):\n            # If -cb is specified, make -np optional\n            np_arg.required = False\n            args.check_build = True\n\n    return CheckBuildAction\n\n\ndef make_override_action(override_args):\n    class StoreOverrideAction(argparse.Action):\n        def __init__(self,\n                     option_strings,\n                     dest,\n                     default=None,\n                     type=None,\n                     choices=None,\n                     required=False,\n                     help=None):\n            super(StoreOverrideAction, self).__init__(\n                option_strings=option_strings,\n                dest=dest,\n                nargs=1,\n                default=default,\n                type=type,\n                choices=choices,\n                required=required,\n                help=help)\n\n        def __call__(self, parser, args, values, option_string=None):\n            override_args.add(self.dest)\n            setattr(args, self.dest, values[0])\n\n    return StoreOverrideAction\n\n\ndef make_override_bool_action(override_args, bool_value):\n    class StoreOverrideBoolAction(argparse.Action):\n        def __init__(self,\n                     option_strings,\n                     dest,\n                     required=False,\n                     help=None):\n            super(StoreOverrideBoolAction, self).__init__(\n                option_strings=option_strings,\n                dest=dest,\n                const=bool_value,\n                nargs=0,\n                default=None,\n                required=required,\n                help=help)\n\n        def __call__(self, parser, args, values, option_string=None):\n            override_args.add(self.dest)\n            setattr(args, self.dest, self.const)\n\n    return StoreOverrideBoolAction\n\n\ndef make_override_true_action(override_args):\n    return make_override_bool_action(override_args, True)\n\n\ndef make_override_false_action(override_args):\n    return make_override_bool_action(override_args, False)\n\n\ndef parse_args():\n    override_args = set()\n\n    parser = argparse.ArgumentParser(description=\'Horovod Runner\')\n\n    parser.add_argument(\'-v\', \'--version\', action=\'version\', version=horovod.__version__,\n                        help=\'Shows Horovod version.\')\n\n    np_arg = parser.add_argument(\'-np\', \'--num-proc\', action=\'store\', dest=\'np\',\n                                 type=int, required=not lsf.LSFUtils.using_lsf(),\n                                 help=\'Total number of training processes. In elastic mode, \'\n                                      \'number of processes required before training can start.\')\n\n    parser.add_argument(\'-cb\', \'--check-build\', action=make_check_build_action(np_arg), nargs=0,\n                        help=\'Shows which frameworks and libraries have been built into Horovod.\')\n\n    parser.add_argument(\'-p\', \'--ssh-port\', action=\'store\', dest=\'ssh_port\',\n                        type=int, help=\'SSH port on all the hosts.\')\n\n    parser.add_argument(\'--disable-cache\', action=\'store_true\',\n                        dest=\'disable_cache\',\n                        help=\'If the flag is not set, horovodrun will perform \'\n                             \'the initialization checks only once every 60 \'\n                             \'minutes -- if the checks successfully pass. \'\n                             \'Otherwise, all the checks will run every time \'\n                             \'horovodrun is called.\')\n\n    parser.add_argument(\'--start-timeout\', action=\'store\',\n                        dest=\'start_timeout\', type=int,\n                        help=\'Horovodrun has to perform all the checks and \'\n                             \'start the processes before the specified \'\n                             \'timeout. The default value is 30 seconds. \'\n                             \'Alternatively, The environment variable \'\n                             \'HOROVOD_START_TIMEOUT can also be used to \'\n                             \'specify the initialization timeout.\')\n\n    parser.add_argument(\'--network-interface\', action=\'store\', dest=\'nics\',\n                        help=\'Network interfaces that can be used for communication separated by \'\n                             \'comma. If not specified, Horovod will find the common NICs among all \'\n                             \'the workers and use it; example, --network-interface ""eth0,eth1"".\')\n\n    parser.add_argument(\'--output-filename\', action=\'store\',\n                        help=\'For Gloo, writes stdout / stderr of all processes to a filename of the form \'\n                             \'<output_filename>/rank.<rank>/<stdout | stderr>. The <rank> will be padded with 0 \'\n                             \'characters to ensure lexicographical order. For MPI, delegates its behavior to mpirun.\')\n\n    parser.add_argument(\'--verbose\', action=\'store_true\',\n                        dest=\'verbose\',\n                        help=\'If this flag is set, extra messages will \'\n                             \'be printed.\')\n\n    parser.add_argument(\'command\', nargs=argparse.REMAINDER,\n                        help=\'Command to be executed.\')\n\n    parser.add_argument(\'--config-file\', action=\'store\', dest=\'config_file\',\n                        help=\'Path to YAML file containing runtime parameter configuration for Horovod. \'\n                             \'Note that this will override any command line arguments provided before \'\n                             \'this argument, and will be overridden by any arguments that come after it.\')\n\n    group_params = parser.add_argument_group(\'tuneable parameter arguments\')\n    group_params.add_argument(\'--fusion-threshold-mb\', action=make_override_action(override_args),type=int,\n                              help=\'Fusion buffer threshold in MB. This is the maximum amount of \'\n                                   \'tensor data that can be fused together into a single batch \'\n                                   \'during allreduce / allgather. Setting 0 disables tensor fusion. \'\n                                   \'(default: 64)\')\n    group_params.add_argument(\'--cycle-time-ms\', action=make_override_action(override_args), type=float,\n                              help=\'Cycle time in ms. This is the delay between each tensor fusion \'\n                                   \'cycle. The larger the cycle time, the more batching, but the \'\n                                   \'greater latency between each allreduce / allgather operations. \'\n                                   \'(default: 5\')\n    group_params.add_argument(\'--cache-capacity\', action=make_override_action(override_args), type=int,\n                              help=\'Maximum number of tensor names that will be cached to reduce amount \'\n                                   \'of coordination required between workers before performing allreduce / \'\n                                   \'allgather. (default: 1024\')\n\n    group_hierarchical_allreduce = group_params.add_mutually_exclusive_group()\n    group_hierarchical_allreduce.add_argument(\'--hierarchical-allreduce\',\n                                              action=make_override_true_action(override_args),\n                                              help=\'Perform hierarchical allreduce between workers instead of \'\n                                                   \'ring allreduce. Hierarchical allreduce performs a local \'\n                                                   \'allreduce / gather within a host, then a parallel cross allreduce \'\n                                                   \'between equal local ranks across workers, and finally a \'\n                                                   \'local gather.\')\n    group_hierarchical_allreduce.add_argument(\'--no-hierarchical-allreduce\', dest=\'hierarchical_allreduce\',\n                                              action=make_override_false_action(override_args),\n                                              help=\'Explicitly disable hierarchical allreduce to prevent autotuning \'\n                                                   \'from adjusting it.\')\n\n    group_hierarchical_allgather = group_params.add_mutually_exclusive_group()\n    group_hierarchical_allgather.add_argument(\'--hierarchical-allgather\',\n                                              action=make_override_true_action(override_args),\n                                              help=\'Perform hierarchical allgather between workers instead of \'\n                                                   \'ring allgather. See hierarchical allreduce for algorithm details.\')\n    group_hierarchical_allgather.add_argument(\'--no-hierarchical-allgather\', dest=\'hierarchical_allgather\',\n                                              action=make_override_false_action(override_args),\n                                              help=\'Explicitly disable hierarchical allgather to prevent autotuning \'\n                                                   \'from adjusting it.\')\n\n    group_autotune = parser.add_argument_group(\'autotune arguments\')\n    group_autotune_enabled = group_autotune.add_mutually_exclusive_group()\n    group_autotune_enabled.add_argument(\'--autotune\', action=make_override_true_action(override_args),\n                                        help=\'Perform autotuning to select parameter argument values that maximimize \'\n                                             \'throughput for allreduce / allgather. Any parameter explicitly set will \'\n                                             \'be held constant during tuning.\')\n    group_autotune_enabled.add_argument(\'--no-autotune\', dest=\'autotune\',\n                                        action=make_override_false_action(override_args), help=argparse.SUPPRESS)\n    group_autotune.add_argument(\'--autotune-log-file\', action=make_override_action(override_args),\n                                help=\'Comma-separated log of trials containing each hyperparameter and the \'\n                                     \'score of the trial. The last row will always contain the best value \'\n                                     \'found.\')\n    group_autotune.add_argument(\'--autotune-warmup-samples\', action=make_override_action(override_args),\n                                type=int, default=3,\n                                help=\'Number of samples to discard before beginning the optimization process \'\n                                     \'during autotuning. Performance during the first few batches can be \'\n                                     \'affected by initialization and cache warmups. (default: %(default)s)\')\n    group_autotune.add_argument(\'--autotune-steps-per-sample\', action=make_override_action(override_args),\n                                type=int, default=10,\n                                help=\'Number of steps (approximate) to record before observing a sample. The sample \'\n                                     \'score is defined to be the median score over all batches within the sample. The \'\n                                     \'more batches per sample, the less variance in sample scores, but the longer \'\n                                     \'autotuning will take. (default: %(default)s)\')\n    group_autotune.add_argument(\'--autotune-bayes-opt-max-samples\', action=make_override_action(override_args),\n                                type=int, default=20,\n                                help=\'Maximum number of samples to collect for each Bayesian optimization process. \'\n                                     \'(default: %(default)s)\')\n    group_autotune.add_argument(\'--autotune-gaussian-process-noise\', action=make_override_action(override_args),\n                                type=float, default=0.8,\n                                help=\'Regularization value [0, 1] applied to account for noise in samples. \'\n                                     \'(default: %(default)s)\')\n\n    group_elastic = parser.add_argument_group(\'elastic arguments\')\n    group_elastic.add_argument(\'--min-np\', action=\'store\', dest=\'min_np\', type=int,\n                               help=\'Minimum number of processes running for training to continue. If number of \'\n                                    \'available processes dips below this threshold, then training will wait for \'\n                                    \'more instances to become available. Defaults to --num-proc.\')\n    group_elastic.add_argument(\'--max-np\', action=\'store\', dest=\'max_np\', type=int,\n                               help=\'Maximum number of training processes, beyond which no additional \'\n                                    \'processes will be created. If not specified, then will be unbounded.\')\n    group_elastic.add_argument(\'--slots-per-host\', action=\'store\', dest=\'slots\', type=int,\n                               help=\'Number of slots for processes per host. Normally 1 slot per GPU per host. \'\n                                    \'If slots are provided by the output of the host discovery script, then \'\n                                    \'that value will override this parameter.\')\n    group_elastic.add_argument(\'--elastic-timeout\', action=\'store\', dest=\'elastic_timeout\', type=int,\n                               help=\'Timeout for elastic initialisation after re-scaling the cluster. \'\n                                    \'The default value is 600 seconds. Alternatively, \'\n                                    \'The environment variable HOROVOD_ELASTIC_TIMEOUT \'\n                                    \'can also be used to.\')\n\n    group_timeline = parser.add_argument_group(\'timeline arguments\')\n    group_timeline.add_argument(\'--timeline-filename\', action=make_override_action(override_args),\n                                help=\'JSON file containing timeline of Horovod events used for debugging \'\n                                     \'performance. If this is provided, timeline events will be recorded, \'\n                                     \'which can have a negative impact on training performance.\')\n    group_timeline_cycles = group_timeline.add_mutually_exclusive_group()\n    group_timeline_cycles.add_argument(\'--timeline-mark-cycles\', action=make_override_true_action(override_args),\n                                       help=\'Mark cycles on the timeline. Only enabled if the timeline filename \'\n                                            \'is provided.\')\n    group_timeline_cycles.add_argument(\'--no-timeline-mark-cycles\', dest=\'timeline_mark_cycles\',\n                                       action=make_override_false_action(override_args), help=argparse.SUPPRESS)\n\n    group_stall_check = parser.add_argument_group(\'stall check arguments\')\n    group_stall_check_enabled = group_stall_check.add_mutually_exclusive_group()\n    group_stall_check_enabled.add_argument(\'--no-stall-check\', action=make_override_true_action(override_args),\n                                           help=\'Disable the stall check. The stall check will log a warning when \'\n                                                \'workers have stalled waiting for other ranks to submit tensors.\')\n    group_stall_check_enabled.add_argument(\'--stall-check\', dest=\'no_stall_check\',\n                                           action=make_override_false_action(override_args), help=argparse.SUPPRESS)\n    group_stall_check.add_argument(\'--stall-check-warning-time-seconds\', action=make_override_action(override_args),\n                                   type=int, default=60,\n                                   help=\'Seconds until the stall warning is logged to stderr. (default: %(default)s)\')\n    group_stall_check.add_argument(\'--stall-check-shutdown-time-seconds\', action=make_override_action(override_args),\n                                   type=int, default=0,\n                                   help=\'Seconds until Horovod is shutdown due to stall. Shutdown will only take \'\n                                        \'place if this value is greater than the warning time. (default: %(default)s)\')\n\n    group_library_options = parser.add_argument_group(\'library arguments\')\n    group_mpi_threads_disable = group_library_options.add_mutually_exclusive_group()\n    group_mpi_threads_disable.add_argument(\'--mpi-threads-disable\', action=make_override_true_action(override_args),\n                                           help=\'Disable MPI threading support. Only applies when running in MPI \'\n                                                \'mode. In some cases, multi-threaded MPI can slow down other \'\n                                                \'components, but is necessary if you wish to run mpi4py on top \'\n                                                \'of Horovod.\')\n    group_mpi_threads_disable.add_argument(\'--no-mpi-threads-disable\', dest=\'mpi_threads_disable\',\n                                           action=make_override_false_action(override_args), help=argparse.SUPPRESS)\n    group_library_options.add_argument(\'--mpi-args\', action=\'store\', dest=\'mpi_args\',\n                                       help=\'Extra MPI arguments to pass to mpirun. \'\n                                       \'They need to be passed with the equal sign to avoid parsing issues. \'\n                                       \'e.g. --mpi-args=""--map-by ppr:6:node""\')\n    group_library_options.add_argument(\'--tcp\', action=\'store_true\', dest=\'tcp_flag\',\n                                       help=\'If this flag is set, only TCP is used for communication.\')\n    group_library_options.add_argument(\'--binding-args\', action=\'store\', dest=\'binding_args\',\n                                       help=\'Process binding arguments. Default is socket for Spectrum MPI \'\n                                       \'and no binding for other cases. e.g. --binding-args=""--rankfile myrankfile""\')\n    group_library_options.add_argument(\'--num-nccl-streams\', action=make_override_action(override_args),\n                                       type=int, default=1,\n                                       help=\'Number of NCCL streams. Only applies when running with NCCL support. \'\n                                            \'(default: %(default)s)\')\n    group_library_options.add_argument(\'--ccl-bgt-affinity\', action=make_override_action(override_args),\n                                       type=int, default=0,\n                                       help=\'CCL background thread affinity. Only applies when running with CCL \'\n                                            \'support. (default: %(default)s)\')\n    group_library_options.add_argument(\'--gloo-timeout-seconds\', action=make_override_action(override_args),\n                                       type=int, default=30,\n                                       help=\'Timeout in seconds for Gloo operations to complete. \'\n                                            \'(default: %(default)s)\')\n\n    group_logging = parser.add_argument_group(\'logging arguments\')\n    group_logging.add_argument(\'--log-level\', action=make_override_action(override_args),\n                               choices=config_parser.LOG_LEVELS,\n                               help=\'Minimum level to log to stderr from the Horovod backend. (default: WARNING).\')\n    group_logging_timestamp = group_logging.add_mutually_exclusive_group()\n    group_logging_timestamp.add_argument(\'--log-hide-timestamp\', action=make_override_true_action(override_args),\n                                         help=\'Hide the timestamp from Horovod log messages.\')\n    group_logging_timestamp.add_argument(\'--no-log-hide-timestamp\', dest=\'log_hide_timestamp\',\n                                         action=make_override_false_action(override_args), help=argparse.SUPPRESS)\n\n    group_hosts_parent = parser.add_argument_group(\'host arguments\')\n    group_hosts = group_hosts_parent.add_mutually_exclusive_group()\n    group_hosts.add_argument(\'-H\', \'--hosts\', action=\'store\', dest=\'hosts\',\n                             help=\'List of host names and the number of available slots \'\n                                  \'for running processes on each, of the form: <hostname>:<slots> \'\n                                  \'(e.g.: host1:2,host2:4,host3:1 indicating 2 processes can run on host1, \'\n                                  \'4 on host2, and 1 on host3). If not specified, defaults to using \'\n                                  \'localhost:<np>\')\n    group_hosts.add_argument(\'-hostfile\', \'--hostfile\', action=\'store\', dest=\'hostfile\',\n                             help=\'Path to a host file containing the list of host names and the number of \'\n                                  \'available slots. Each line of the file must be of the form: \'\n                                  \'<hostname> slots=<slots>\')\n    group_hosts.add_argument(\'--host-discovery-script\', action=make_override_action(override_args),\n                             help=\'Used for elastic training (autoscaling and fault tolerance). \'\n                                  \'An executable script that will print to stdout every available host (one per \'\n                                  \'newline character) that can be used to run worker processes. Optionally \'\n                                  \'specifies number of slots on the same line as the hostname as: ""hostname:slots"".\'\n                                  \'Providing a discovery script enables elastic training (see elastic arguments).\'\n                                  \'The job will fail immediately if execution of the script returns a non-zero exit \'\n                                  \'code on the first call. Subsequent calls will be retried until timeout.\')\n\n    group_controller_parent = parser.add_argument_group(\'controller arguments\')\n    group_controller = group_controller_parent.add_mutually_exclusive_group()\n    group_controller.add_argument(\'--gloo\', action=\'store_true\', dest=\'use_gloo\',\n                                  help=\'Run Horovod using the Gloo controller. This will \'\n                                       \'be the default if Horovod was not built with MPI support.\')\n    group_controller.add_argument(\'--mpi\', action=\'store_true\', dest=\'use_mpi\',\n                                  help=\'Run Horovod using the MPI controller. This will \'\n                                       \'be the default if Horovod was built with MPI support.\')\n    group_controller.add_argument(\'--jsrun\', action=\'store_true\', dest=\'use_jsrun\',\n                                  help=\'Launch Horovod processes with jsrun and use the MPI controller. \'\n                                       \'This will be the default if jsrun is installed and Horovod \'\n                                       \'was built with MPI support.\')\n\n    args = parser.parse_args()\n\n    if args.config_file:\n        with open(args.config_file, \'r\') as f:\n            config = yaml.load(f, Loader=yaml.FullLoader)\n        config_parser.set_args_from_config(args, config, override_args)\n    config_parser.validate_config_args(args)\n\n    args.run_func = None\n\n    if args.check_build:\n        check_build(args.verbose)\n\n    return args\n\n\nclass HorovodArgs(object):\n    def __init__(self):\n        self.np = 1\n        self.check_build = None\n        self.ssh_port = None\n        self.disable_cache = None\n        self.start_timeout = None\n        self.nic = None\n        self.output_filename = None\n        self.verbose = None\n        self.command = None\n        self.run_func = None\n        self.config_file = None\n        self.nics = None\n\n        # tuneable parameter arguments\n        self.fusion_threshold_mb = None\n        self.cycle_time_ms = None,\n        self.cache_capacity = None,\n\n        # hierarchy\n        self.hierarchical_allreduce = None\n        self.hierarchical_allgather = None\n\n        # autotune arguments\n        self.autotune = None\n        self.autotune_log_file = None\n        self.autotune_warmup_samples = None\n        self.autotune_steps_per_sample = None\n        self.autotune_bayes_opt_max_samples = None\n        self.autotune_gaussian_process_noise = None\n\n        # elastic arguments\n        self.min_np = None\n        self.max_np = None\n        self.slots = None\n        self.elastic_timeout = None\n\n        # timeline arguments\n        self.timeline_filename = None\n        self.timeline_mark_cycles = None\n\n        # stall check arguments\n        self.no_stall_check = None\n        self.stall_check_warning_time_seconds = None\n        self.stall_check_shutdown_time_seconds = None\n\n        # library arguments\n        self.mpi_threads_disable = None\n        self.mpi_args = None\n        self.tcp_flag = None\n        self.binding_args = None\n        self.num_nccl_streams = None\n        self.ccl_bgt_affinity = None\n        self.gloo_timeout_seconds = None\n\n        # logging arguments\n        self.log_level = None\n        self.log_hide_timestamp = None\n\n        # host arguments\n        self.hosts = None\n        self.hostfile = None\n        self.host_discovery_script = None\n\n        # controller arguments\n        self.use_gloo = None\n        self.use_mpi = None\n        self.use_jsrun = None\n\n\ndef parse_host_files(filename):\n    """"""\n    Transform the hostfile into a format of\n    <IP address> or <host name>:<Number of GPUs>\n    :param filename: Should be in <IP address> or <host name> slots=<number of GPUs>\n    :return: Comma separated string of <IP address> or <host name>:<Number of GPUs>\n    """"""\n    hosts = []\n    with open(filename, \'r\') as f:\n        for line in f.readlines():\n            line = line.rstrip()\n            hostname = line.split()[0]\n            slots = line.split(\'=\')[1]\n            hosts.append(\'{name}:{slots}\'.format(name=hostname, slots=slots))\n    return \',\'.join(hosts)\n\n\ndef parse_hosts_and_slots(hosts):\n    host_names = []\n    host_to_slots = {}\n\n    host_list = hosts.split(\',\')\n    pattern = re.compile(r\'^[\\w.-]+:[0-9]+$\')\n    for host in host_list:\n        if not pattern.match(host.strip()):\n            raise ValueError(\'Invalid host input, please make sure it has \'\n                             \'format as : worker-0:2,worker-1:2.\')\n        hostname, slots = host.strip().split(\':\')\n        host_names.append(hostname)\n        host_to_slots[hostname] = int(slots)\n    return host_names, host_to_slots\n\n\ndef _run_static(args):\n    all_host_names, _ = parse_hosts_and_slots(args.hosts)\n\n    nics_set = set(args.nics.split(\',\')) if args.nics else None\n\n    # horovodrun has to finish all the checks before this timeout runs out.\n    if args.start_timeout:\n        start_timeout = args.start_timeout\n    else:\n        # Lookup default timeout from the environment variable.\n        start_timeout = int(os.getenv(\'HOROVOD_START_TIMEOUT\', \'30\'))\n\n    tmout = timeout.Timeout(start_timeout,\n                            message=\'Timed out waiting for {activity}. Please \'\n                                    \'check connectivity between servers. You \'\n                                    \'may need to increase the --start-timeout \'\n                                    \'parameter if you have too many servers.\')\n    settings = hvd_settings.Settings(verbose=2 if args.verbose else 0,\n                                     ssh_port=args.ssh_port,\n                                     extra_mpi_args=args.mpi_args,\n                                     tcp_flag=args.tcp_flag,\n                                     binding_args=args.binding_args,\n                                     key=secret.make_secret_key(),\n                                     start_timeout=tmout,\n                                     num_proc=args.np,\n                                     hosts=args.hosts,\n                                     num_hosts=len(all_host_names),\n                                     output_filename=args.output_filename,\n                                     run_func_mode=args.run_func is not None,\n                                     nics=nics_set)\n\n    # This cache stores the results of checks performed by horovod\n    # during the initialization step. It can be disabled by setting\n    # --disable-cache flag.\n    fn_cache = None\n    if not args.disable_cache:\n        params = \'\'\n        if args.np:\n            params += str(args.np) + \' \'\n        if args.hosts:\n            params += str(args.hosts) + \' \'\n        if args.ssh_port:\n            params += str(args.ssh_port)\n        parameters_hash = hashlib.md5(params.encode(\'utf-8\')).hexdigest()\n        fn_cache = cache.Cache(CACHE_FOLDER, CACHE_STALENESS_THRESHOLD_MINUTES,\n                               parameters_hash)\n\n    if settings.verbose >= 2:\n        print(\'Filtering local host names.\')\n    remote_host_names = network.filter_local_addresses(all_host_names)\n    if settings.verbose >= 2:\n        print(\'Remote host found: \' + \' \'.join(remote_host_names))\n\n    if len(remote_host_names) > 0:\n        if settings.verbose >= 2:\n            print(\'Checking ssh on all remote hosts.\')\n        # Check if we can ssh into all remote hosts successfully.\n        _check_all_hosts_ssh_successful(remote_host_names, args.ssh_port,\n                                        fn_cache=fn_cache)\n        if settings.verbose >= 2:\n            print(\'SSH was successful into all the remote hosts.\')\n\n    nics = driver_service.get_common_interfaces(settings, all_host_names,\n                                                remote_host_names, fn_cache)\n\n    if args.run_func:\n        # get the driver IPv4 address\n        driver_ip = network.get_driver_ip(nics)\n        run_func_server = KVStoreServer(verbose=settings.verbose)\n        run_func_server_port = run_func_server.start_server()\n        put_data_into_kvstore(driver_ip, run_func_server_port,\n                              \'runfunc\', \'func\', args.run_func)\n\n        command = [sys.executable, \'-m\', \'horovod.run.run_task\', str(driver_ip), str(run_func_server_port)]\n\n        try:\n            _launch_job(args, settings, nics, command)\n            results = [None] * args.np\n            # TODO: make it parallel to improve performance\n            for i in range(args.np):\n                results[i] = read_data_from_kvstore(driver_ip, run_func_server_port,\n                                                    \'runfunc_result\', str(i))\n            return results\n        finally:\n            run_func_server.shutdown_server()\n    else:\n        command = args.command\n        _launch_job(args, settings, nics, command)\n        return None\n\n\ndef _run_elastic(args):\n    # construct host discovery component\n    if args.host_discovery_script:\n        discover_hosts = discovery.HostDiscoveryScript(args.host_discovery_script, args.slots)\n    elif args.hosts:\n        _, available_host_slots = parse_hosts_and_slots(args.hosts)\n        if len(available_host_slots) < 2:\n            raise ValueError(\'Cannot run in fault tolerance mode with fewer than 2 hosts.\')\n        discover_hosts = discovery.FixedHosts(available_host_slots)\n    else:\n        raise ValueError(\'One of --host-discovery-script, --hosts, or --hostnames must be provided\')\n\n    # horovodrun has to finish all the checks before this timeout runs out.\n    if args.start_timeout:\n        start_timeout = args.start_timeout\n    else:\n        # Lookup default timeout from the environment variable.\n        start_timeout = int(os.getenv(\'HOROVOD_START_TIMEOUT\', \'30\'))\n\n    tmout = timeout.Timeout(start_timeout,\n                            message=\'Timed out waiting for {activity}. Please \'\n                                    \'check connectivity between servers. You \'\n                                    \'may need to increase the --start-timeout \'\n                                    \'parameter if you have too many servers.\')\n    settings = elastic_settings.ElasticSettings(discovery=discover_hosts,\n                                                num_proc=args.np,\n                                                min_np=args.min_np or args.np,\n                                                max_np=args.max_np,\n                                                verbose=2 if args.verbose else 0,\n                                                ssh_port=args.ssh_port,\n                                                extra_mpi_args=args.mpi_args,\n                                                key=secret.make_secret_key(),\n                                                start_timeout=tmout,\n                                                elastic_timeout=args.elastic_timeout,\n                                                output_filename=args.output_filename,\n                                                run_func_mode=args.run_func is not None,\n                                                nics=args.nics)\n\n    if not gloo_built(verbose=(settings.verbose >= 2)):\n        raise ValueError(\'Gloo support is required to use elastic training, but has not been built.  Ensure CMake is \'\n                         \'installed and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error.\')\n\n    env = os.environ.copy()\n    config_parser.set_env_from_args(env, args)\n    gloo_run_elastic(settings, env, args.command)\n\n\ndef is_gloo_used(use_gloo=None, use_mpi=None, use_jsrun=None):\n    # determines whether run_controller will run gloo\n    # for the given (use_gloo, _, use_mpi, _, use_jsrun, _, _)\n    return use_gloo or (not use_mpi and not use_jsrun and not mpi_built())\n\n\ndef run_controller(use_gloo, gloo_run, use_mpi, mpi_run, use_jsrun, js_run, verbosity):\n    # keep logic in sync with is_gloo_used(...)\n    verbose = verbosity is not None and verbosity >= 2\n    if use_gloo:\n        if not gloo_built(verbose=verbose):\n            raise ValueError(\'Gloo support has not been built.  If this is not expected, ensure CMake is installed \'\n                             \'and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error.\')\n        gloo_run()\n    elif use_mpi:\n        if not mpi_built(verbose=verbose):\n            raise ValueError(\'MPI support has not been built.  If this is not expected, ensure MPI is installed \'\n                             \'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error.\')\n        mpi_run()\n    elif use_jsrun:\n        if not mpi_built(verbose=verbose):\n            raise ValueError(\'MPI support has not been built.  If this is not expected, ensure MPI is installed \'\n                             \'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error.\')\n        if not lsf.LSFUtils.using_lsf():\n            raise ValueError(\'Horovod did not detect an LSF job.  The jsrun launcher can only be used in that environment. \'\n                             \'Please, pick a different launcher for other environments.\')\n        js_run()\n    else:\n        if mpi_built(verbose=verbose):\n            if lsf.LSFUtils.using_lsf() and is_jsrun_installed():\n                js_run()\n            else:\n                mpi_run()\n        elif gloo_built(verbose=verbose):\n            gloo_run()\n        else:\n            raise ValueError(\'Neither MPI nor Gloo support has been built. Try reinstalling Horovod ensuring that \'\n                             \'either MPI is installed (MPI) or CMake is installed (Gloo).\')\n\n\ndef _is_elastic(args):\n    return args.host_discovery_script is not None or args.min_np is not None\n\n\ndef _launch_job(args, settings, nics, command):\n    env = os.environ.copy()\n    config_parser.set_env_from_args(env, args)\n\n    def gloo_run_fn():\n        driver_ip = network.get_driver_ip(nics)\n        gloo_run(settings, nics, env, driver_ip, command)\n\n    def mpi_run_fn():\n        mpi_run(settings, nics, env, command)\n\n    def js_run_fn():\n        js_run(settings, nics, env, command)\n\n    run_controller(args.use_gloo, gloo_run_fn,\n                   args.use_mpi, mpi_run_fn,\n                   args.use_jsrun, js_run_fn,\n                   args.verbose)\n\n\ndef _run(args):\n    # If LSF is used, use default values from job config\n    if lsf.LSFUtils.using_lsf():\n        if not args.np:\n            args.np = lsf.LSFUtils.get_num_processes()\n        if not args.hosts and not args.hostfile and not args.host_discovery_script:\n            args.hosts = \',\'.join(\'{host}:{np}\'.format(host=host, np=lsf.LSFUtils.get_num_gpus())\n                                  for host in lsf.LSFUtils.get_compute_hosts())\n\n    # if hosts are not specified, either parse from hostfile, or default as\n    # localhost\n    if not args.hosts and not args.host_discovery_script:\n        if args.hostfile:\n            args.hosts = parse_host_files(args.hostfile)\n        else:\n            # Set hosts to localhost if not specified\n            args.hosts = \'localhost:{np}\'.format(np=args.np)\n\n    if _is_elastic(args):\n        return _run_elastic(args)\n    else:\n        return _run_static(args)\n\n\ndef run_commandline():\n    args = parse_args()\n\n    if args.log_level:\n        logging.addLevelName(logging.NOTSET, \'TRACE\')\n        logging.basicConfig(level=logging.getLevelName(args.log_level))\n\n    _run(args)\n\n\ndef run(\n        func,\n        args=(),\n        kwargs=None,\n        np=1,\n        min_np=None,\n        max_np=None,\n        slots=None,\n        hosts=None,\n        hostfile=None,\n        start_timeout=None,\n        ssh_port=None,\n        disable_cache=None,\n        output_filename=None,\n        verbose=None,\n        use_gloo=None,\n        use_mpi=None,\n        mpi_args=None,\n        network_interface=None):\n    """"""\n    Launch a Horovod job to run the specified process function and get the return value.\n\n    :param func: The function to be run in Horovod job processes. The function return value will\n                 be collected as the corresponding Horovod process return value.\n                 This function must be compatible with pickle.\n    :param args: Arguments to pass to `func`.\n    :param kwargs: Keyword arguments to pass to `func`.\n    :param np: Number of Horovod processes.\n    :param min_np: Minimum number of processes running for training to continue. If number of\n                   available processes dips below this threshold, then training will wait for\n                   more instances to become available. Defaults to np\n    :param max_np: Maximum number of training processes, beyond which no additional processes\n                   will be created. If not specified, then will be unbounded.\n    :param slots: Number of slots for processes per host. Normally 1 slot per GPU per host.\n                  If slots are provided by the output of the host discovery script, then that\n                  value will override this parameter.\n\n    :param hosts: List of host names and the number of available slots\n                  for running processes on each, of the form: <hostname>:<slots>\n                  (e.g.: host1:2,host2:4,host3:1 indicating 2 processes can run on host1,\n                  4 on host2, and 1 on host3). If not specified, defaults to using localhost:<np>\n    :param hostfile: Path to a host file containing the list of host names and the number of\n                     available slots. Each line of the file must be of the form:\n                     <hostname> slots=<slots>\n    :param start_timeout: Horovodrun has to perform all the checks and\n                          start the processes before the specified\n                          timeout. The default value is 30 seconds.\n                          Alternatively, The environment variable\n                          HOROVOD_START_TIMEOUT can also be used to\n                          specify the initialization timeout.\n    :param ssh_port: SSH port on all the hosts.\n    :param disable_cache: If the flag is not set, horovodrun will perform\n                          the initialization checks only once every 60\n                          minutes -- if the checks successfully pass.\n                          Otherwise, all the checks will run every time\n                          horovodrun is called.\'\n    :param output_filename: For Gloo, writes stdout / stderr of all processes to a filename of the form\n                            <output_filename>/rank.<rank>/<stdout | stderr>. The <rank> will be padded with 0\n                            characters to ensure lexicographical order.\n                            For MPI, delegates its behavior to mpirun.\n    :param verbose: If this flag is set, extra messages will be printed.\n    :param use_gloo: Run Horovod using the Gloo controller. This will\n                     be the default if Horovod was not built with MPI support.\n    :param use_mpi: Run Horovod using the MPI controller. This will\n                    be the default if Horovod was built with MPI support.\n    :param mpi_args: Extra arguments for the MPI controller. This is only used when use_mpi is True.\n    :param network_interface: Network interfaces to use for communication separated by comma. If\n                             not specified, Horovod will find the common NICs among all the\n                             workers and use those; example, eth0,eth1.\n    :return: Return a list which contains values return by all Horovod processes.\n             The index of the list corresponds to the rank of each Horovod process.\n    """"""\n\n    if kwargs is None:\n        kwargs = {}\n\n    def wrapped_func():\n        return func(*args, **kwargs)\n\n    if hosts is not None and hostfile is not None:\n        raise ValueError(\'Argument hosts and hostfile only allow one provided.\')\n\n    if use_gloo and use_mpi:\n        raise ValueError(\'Argument use_gloo and use_mpi only allow one set True.\')\n\n    hargs = HorovodArgs()\n\n    hargs.np = np\n    hargs.min_np = min_np\n    hargs.max_np = max_np\n    hargs.slots = slots\n    hargs.hosts = hosts\n    hargs.hostfile = hostfile\n    hargs.start_timeout = start_timeout\n    hargs.ssh_port = ssh_port\n    hargs.mpi_args = mpi_args\n    hargs.disable_cache = disable_cache\n    hargs.output_filename = output_filename\n    hargs.verbose = verbose\n    hargs.use_gloo = use_gloo\n    hargs.use_mpi = use_mpi\n    hargs.nics = network_interface\n    hargs.run_func = wrapped_func\n\n    return _run(hargs)\n\n\nif __name__ == \'__main__\':\n    run_commandline()\n'"
horovod/run/task_fn.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport sys\n\nfrom horovod.run.common.util import codec, host_hash\nfrom horovod.run.driver import driver_service\nfrom horovod.run.task import task_service\n\n\ndef _task_fn(index, num_hosts, driver_addresses, settings):\n    task = task_service.HorovodRunTaskService(index, settings.key, settings.nics)\n    try:\n        driver = driver_service.HorovodRunDriverClient(\n            driver_addresses, settings.key, settings.verbose)\n        driver.register_task(index,\n                             task.addresses(),\n                             host_hash.host_hash())\n        task.wait_for_initial_registration(settings.start_timeout)\n        # Tasks ping each other in a circular fashion to determine interfaces\n        # reachable within the cluster.\n        next_task_index = (index + 1) % num_hosts\n        next_task_addresses = driver.all_task_addresses(next_task_index)\n        # We request interface matching to weed out all the NAT\'ed interfaces.\n        next_task = task_service.HorovodRunTaskClient(\n            next_task_index,\n            next_task_addresses,\n            settings.key,\n            settings.verbose,\n            match_intf=True,\n            attempts=10)\n        driver.register_task_to_task_addresses(next_task_index,\n                                               next_task.addresses())\n        # Notify the next task that the address checks are completed.\n        next_task.task_to_task_address_check_completed()\n        # Wait to get a notification from previous task that its address checks\n        # are completed as well.\n        task.wait_for_task_to_task_address_check_finish_signal(settings.start_timeout)\n\n    finally:\n        task.shutdown()\n\n\nif __name__ == \'__main__\':\n    if len(sys.argv) != 5:\n        print(\'Usage: {} <index> <num_hosts> <driver_addresses> <settings>\'.format(sys.argv[0]))\n        sys.exit(1)\n\n    index = codec.loads_base64(sys.argv[1])\n    num_hosts = codec.loads_base64(sys.argv[2])\n    driver_addresses = codec.loads_base64(sys.argv[3])\n    settings = codec.loads_base64(sys.argv[4])\n\n    _task_fn(index, num_hosts, driver_addresses, settings)\n'"
horovod/spark/__init__.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nfrom .runner import run\n'"
horovod/spark/gloo_run.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport sys\nimport time\n\nfrom horovod.run.gloo_run import launch_gloo\nfrom horovod.run.common.util import codec\nfrom horovod.spark.driver.rsh import rsh\n\n\ndef _exec_command_fn(driver_addresses, key, settings, env):\n    def _exec_command(command, slot_info, events):\n        host = slot_info.hostname\n        local_rank = slot_info.local_rank\n        verbose = settings.verbose\n        result = rsh(driver_addresses, key, host, command, env, local_rank, verbose, False, events)\n        return result, time.time()\n    return _exec_command\n\n\ndef gloo_run(settings, nics, driver, env):\n    """"""\n    Run distributed gloo jobs.\n\n    :param settings: Settings for running the distributed jobs.\n                     Note: settings.num_proc and settings.hosts must not be None.\n    :param nics: Interfaces to use by gloo.\n    :param driver: The Spark driver service that tasks are connected to.\n    :param env: Environment dictionary to use for running gloo jobs.  Can be None.\n    """"""\n    if env is None:\n        env = {}\n\n    # we don\'t want the key to be serialized along with settings from here on\n    key = settings.key\n    settings.key = None\n\n    # Each thread will use SparkTaskClient to launch the job on each remote host. If an\n    # error occurs in one thread, entire process will be terminated. Otherwise,\n    # threads will keep running and ssh session.\n    iface = list(nics)[0]\n    server_ip = driver.addresses()[iface][0][0]\n    command = (sys.executable,\n               \'-m\', \'horovod.spark.task.gloo_exec_fn\',\n               codec.dumps_base64(driver.addresses()),\n               codec.dumps_base64(settings))\n\n    exec_command = _exec_command_fn(driver.addresses(), key, settings, env)\n    launch_gloo(command, exec_command, settings, nics, {}, server_ip)\n'"
horovod/spark/mpi_run.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport copy\nimport sys\n\nfrom horovod.run.mpi_run import mpi_run as hr_mpi_run\nfrom horovod.run.common.util import codec, secret\n\n\ndef mpi_run(settings, nics, driver, env, stdout=None, stderr=None):\n    """"""\n    Runs mpirun.\n\n    :param settings: Settings for running MPI.\n                     Note: settings.num_proc and settings.hosts must not be None.\n    :param nics: Interfaces to include by MPI.\n    :param driver: The Spark driver service that tasks are connected to.\n    :param env: Environment dictionary to use for running MPI.  Can be None.\n    :param stdout: Stdout of the mpi process.\n                   Only used when settings.run_func_mode is True.\n    :param stderr: Stderr of the mpi process.\n                   Only used when settings.run_func_mode is True.\n    """"""\n    env = {} if env is None else copy.copy(env)  # copy env so we do not leak env modifications\n\n    # Pass secret key through the environment variables.\n    env[secret.HOROVOD_SECRET_KEY] = codec.dumps_base64(settings.key)\n    # we don\'t want the key to be serialized along with settings from here on\n    settings.key = None\n\n    rsh_agent = (sys.executable,\n                 \'-m\', \'horovod.spark.driver.mpirun_rsh\',\n                 codec.dumps_base64(driver.addresses()),\n                 codec.dumps_base64(settings))\n    settings.extra_mpi_args = (\'{extra_mpi_args} -x NCCL_DEBUG=INFO -mca plm_rsh_agent ""{rsh_agent}""\'\n                               .format(extra_mpi_args=settings.extra_mpi_args if settings.extra_mpi_args else \'\',\n                                       rsh_agent=\' \'.join(rsh_agent)))\n    command = (sys.executable,\n               \'-m\', \'horovod.spark.task.mpirun_exec_fn\',\n               codec.dumps_base64(driver.addresses()),\n               codec.dumps_base64(settings))\n    hr_mpi_run(settings, nics, env, command, stdout=stdout, stderr=stderr)\n'"
horovod/spark/runner.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport platform\nimport queue\nimport time\n\nimport pyspark\n\nfrom horovod.run.util.threads import in_thread\nfrom horovod.spark.task import task_service\nfrom horovod.spark.gloo_run import gloo_run\nfrom horovod.spark.mpi_run import mpi_run\nfrom horovod.run.runner import is_gloo_used, run_controller\nfrom horovod.run.common.util import timeout, host_hash, secret\nfrom horovod.run.common.util import settings as hvd_settings\nfrom horovod.spark.driver import driver_service, job_id\n\n\nMINIMUM_COMMAND_LIFETIME_S = 3\n\n# Spark will fail to initialize correctly locally on Mac OS without this\nif platform.system() == \'Darwin\':\n    os.environ[\'OBJC_DISABLE_INITIALIZE_FORK_SAFETY\'] = \'YES\'\n\n\ndef _task_fn(index, driver_addresses, key, settings, use_gloo):\n    # deserialized on Spark workers, settings do not contain the key, so it is given here explicitly\n    # Spark RPC communicates the key and supports encryption\n    # for convenience, we put it back into settings\n    settings.key = key\n\n    task = task_service.SparkTaskService(index, settings.key, settings.nics, settings.verbose)\n    try:\n        driver_client = driver_service.SparkDriverClient(driver_addresses, settings.key, settings.verbose)\n        driver_client.register_task(index, task.addresses(), host_hash.host_hash())\n        task.wait_for_initial_registration(settings.start_timeout)\n        task_indices_on_this_host = driver_client.task_host_hash_indices(host_hash.host_hash())\n\n        # With Gloo all tasks wait for the command\n        # With MPI task with first index executes orted which will run mpirun_exec_fn for all tasks.\n        minimum_lifetime_after_start = None\n        if use_gloo or task_indices_on_this_host[0] == index:\n            task.wait_for_command_start(settings.start_timeout)\n            minimum_lifetime_after_start = timeout.Timeout(MINIMUM_COMMAND_LIFETIME_S,\n                                                           message=\'Just measuring runtime\')\n            task.wait_for_command_termination()\n        else:\n            # The rest of tasks need to wait for the first task to finish.\n            first_task_addresses = driver_client.all_task_addresses(task_indices_on_this_host[0])\n            first_task_client = \\\n                task_service.SparkTaskClient(task_indices_on_this_host[0],\n                                             first_task_addresses, settings.key,\n                                             settings.verbose)\n            first_task_client.wait_for_command_termination()\n\n        # command terminated, make sure this task service does not shutdown too quickly after\n        # the client started the command as it needs some time to connect again\n        # to wait for the result after starting the command (see horovod.spark.driver.rsh).\n        if minimum_lifetime_after_start is not None:\n            time.sleep(minimum_lifetime_after_start.remaining())\n\n        return task.fn_result()\n    finally:\n        # this has to block on running requests (wait_for_command_exit_code)\n        # so they can finish serving the exit code\n        # shutdown does block with network.BasicService._server._block_on_close = True\n        task.shutdown()\n\n\ndef _make_mapper(driver_addresses, settings, use_gloo):\n    # serialised settings do not have a key so we have to copy it and provide it explicitly here\n    key = settings.key\n\n    def _mapper(index, _):\n        yield _task_fn(index, driver_addresses, key, settings, use_gloo)\n\n    return _mapper\n\n\ndef _make_spark_thread(spark_context, spark_job_group, driver, result_queue,\n                       settings, use_gloo):\n    """"""Creates `settings.num_proc` Spark tasks in a parallel thread.""""""\n    def run_spark():\n        """"""Creates `settings.num_proc` Spark tasks, each executing `_task_fn` and waits for them to terminate.""""""\n        try:\n            spark_context.setJobGroup(spark_job_group,\n                                      ""Horovod Spark Run"",\n                                      interruptOnCancel=True)\n            procs = spark_context.range(0, numSlices=settings.num_proc)\n            # We assume that folks caring about security will enable Spark RPC encryption,\n            # thus ensuring that key that is passed here remains secret.\n            result = procs.mapPartitionsWithIndex(_make_mapper(driver.addresses(), settings, use_gloo)).collect()\n            result_queue.put(result)\n        except:\n            driver.notify_spark_job_failed()\n            raise\n\n    spark_thread = in_thread(target=run_spark, daemon=False)\n    return spark_thread\n\n\ndef _launch_job(use_mpi, use_gloo, settings, driver, env, stdout=None, stderr=None):\n    # Determine a set of common interfaces for task-to-task communication.\n    nics = set(driver.task_addresses_for_tasks(0).keys())\n    for index in range(1, settings.num_proc):\n        nics.intersection_update(driver.task_addresses_for_tasks(index).keys())\n    if not nics:\n        raise Exception(\'Unable to find a set of common task-to-task communication interfaces: %s\'\n                        % [(index, driver.task_addresses_for_tasks(index)) for index in range(settings.num_proc)])\n\n    run_controller(use_gloo, lambda: gloo_run(settings, nics, driver, env),\n                   use_mpi, lambda: mpi_run(settings, nics, driver, env, stdout, stderr),\n                   False, lambda: None,\n                   settings.verbose)\n\n\ndef run(fn, args=(), kwargs={}, num_proc=None, start_timeout=None,\n        use_mpi=None, use_gloo=None, extra_mpi_args=None,\n        env=None, stdout=None, stderr=None, verbose=1, nics=None):\n    """"""\n    Runs Horovod in Spark.  Runs `num_proc` processes executing `fn` using the same amount of Spark tasks.\n\n    Args:\n        fn: Function to run.\n        args: Arguments to pass to `fn`.\n        kwargs: Keyword arguments to pass to `fn`.\n        num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.\n        start_timeout: Timeout for Spark tasks to spawn, register and start running the code, in seconds.\n                       If not set, falls back to `HOROVOD_SPARK_START_TIMEOUT` environment variable value.\n                       If it is not set as well, defaults to 600 seconds.\n        extra_mpi_args: Extra arguments for mpi_run. Defaults to no extra args.\n        env: Environment dictionary to use in Horovod run.\n        stdout: Horovod stdout is redirected to this stream. Defaults to sys.stdout.\n        stderr: Horovod stderr is redirected to this stream. Defaults to sys.stderr.\n        verbose: Debug output verbosity (0-2). Defaults to 1.\n        nics: List of NICs for tcp network communication.\n\n    Returns:\n        List of results returned by running `fn` on each rank.\n    """"""\n\n    if start_timeout is None:\n        # Lookup default timeout from the environment variable.\n        start_timeout = int(os.getenv(\'HOROVOD_SPARK_START_TIMEOUT\', \'600\'))\n\n    # nics needs to be a set\n    if nics and not isinstance(nics, set):\n        nics = set(nics)\n\n    tmout = timeout.Timeout(start_timeout,\n                            message=\'Timed out waiting for {activity}. Please check that you have \'\n                                    \'enough resources to run all Horovod processes. Each Horovod \'\n                                    \'process runs in a Spark task. You may need to increase the \'\n                                    \'start_timeout parameter to a larger value if your Spark resources \'\n                                    \'are allocated on-demand.\')\n    settings = hvd_settings.Settings(verbose=verbose,\n                                     extra_mpi_args=extra_mpi_args,\n                                     key=secret.make_secret_key(),\n                                     start_timeout=tmout,\n                                     nics=nics,\n                                     run_func_mode=True)\n\n    spark_context = pyspark.SparkContext._active_spark_context\n    if spark_context is None:\n        raise Exception(\'Could not find an active SparkContext, are you \'\n                        \'running in a PySpark session?\')\n\n    if num_proc is None:\n        num_proc = spark_context.defaultParallelism\n        if settings.verbose >= 1:\n            print(\'Running %d processes (inferred from spark.default.parallelism)...\' % num_proc)\n    else:\n        if settings.verbose >= 1:\n            print(\'Running %d processes...\' % num_proc)\n    settings.num_proc = num_proc\n\n    result_queue = queue.Queue(1)\n\n    # start Spark driver service and launch settings.num_proc Spark tasks\n    spark_job_group = \'horovod.spark.run.%d\' % job_id.next_job_id()\n    driver = driver_service.SparkDriverService(settings.num_proc, fn, args, kwargs,\n                                               settings.key, settings.nics)\n    gloo_is_used = is_gloo_used(use_gloo=use_gloo, use_mpi=use_mpi, use_jsrun=False)\n    spark_thread = _make_spark_thread(spark_context, spark_job_group, driver,\n                                      result_queue, settings, gloo_is_used)\n    try:\n        # wait for all tasks to register, notify them and initiate task-to-task address registration\n        _notify_and_register_task_addresses(driver, settings)\n\n        # Determine the index grouping based on host hashes.\n        # Barrel shift until index 0 is in the first host.\n        host_hashes = list(driver.task_host_hash_indices().keys())\n        host_hashes.sort()\n        while 0 not in driver.task_host_hash_indices()[host_hashes[0]]:\n            host_hashes = host_hashes[1:] + host_hashes[:1]\n\n        settings.hosts = \',\'.join(\'%s:%d\' % (host_hash, len(driver.task_host_hash_indices()[host_hash]))\n                                  for host_hash in host_hashes)\n\n        # Determine the ranks to indicies\n        ranks_to_indices = []\n        for host_hash in host_hashes:\n            ranks_to_indices += driver.task_host_hash_indices()[host_hash]\n        driver.set_ranks_to_indices(ranks_to_indices)\n\n        # Run the job\n        _launch_job(use_mpi, use_gloo, settings, driver, env, stdout, stderr)\n    except:\n        # Terminate Spark job.\n        spark_context.cancelJobGroup(spark_job_group)\n\n        # Re-raise exception.\n        raise\n    finally:\n        spark_thread.join()\n        driver.shutdown()\n\n    # Make sure Spark Job did not fail.\n    driver.check_for_spark_job_failure()\n\n    # If there\'s no exception, execution results are in this queue.\n    results = result_queue.get_nowait()\n    return [results[index] for index in ranks_to_indices]\n\n\ndef _notify_and_register_task_addresses(driver, settings):\n    # wait for num_proc tasks to register\n    driver.wait_for_initial_registration(settings.start_timeout)\n    if settings.verbose >= 2:\n        print(\'Initial Spark task registration is complete.\')\n\n    def notify_and_register(index):\n        task_client = task_service.SparkTaskClient(index,\n                                                   driver.task_addresses_for_driver(index),\n                                                   settings.key, settings.verbose)\n        task_client.notify_initial_registration_complete()\n        next_task_index = (index + 1) % settings.num_proc\n        next_task_addresses = driver.all_task_addresses(next_task_index)\n        task_to_task_addresses = task_client.get_task_addresses_for_task(next_task_index, next_task_addresses)\n        driver.register_task_to_task_addresses(next_task_index, task_to_task_addresses)\n\n    for index in range(settings.num_proc):\n        in_thread(notify_and_register, (index,))\n\n    driver.wait_for_task_to_task_address_updates(settings.start_timeout)\n\n    if settings.verbose >= 2:\n        print(\'Spark task-to-task address registration is complete.\')\n'"
horovod/tensorflow/__init__.py,40,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2019 Uber Technologies, Inc.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=g-short-docstring-punctuation\n\nimport os\nimport warnings\n\nfrom horovod.common.util import check_extension, gpu_available\n\ncheck_extension(\'horovod.tensorflow\', \'HOROVOD_WITH_TENSORFLOW\', __file__, \'mpi_lib\')\n\nfrom horovod.tensorflow import elastic\nfrom horovod.tensorflow.compression import Compression\nfrom horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables\nfrom horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\nfrom horovod.tensorflow.mpi_ops import init, shutdown\nfrom horovod.tensorflow.mpi_ops import size, local_size, rank, local_rank, is_homogeneous\nfrom horovod.tensorflow.mpi_ops import mpi_threads_supported, mpi_enabled, mpi_built\nfrom horovod.tensorflow.mpi_ops import gloo_enabled, gloo_built\nfrom horovod.tensorflow.mpi_ops import nccl_built, ddl_built, ccl_built\nfrom horovod.tensorflow.mpi_ops import Average, Sum, Adasum\nfrom horovod.tensorflow.mpi_ops import handle_average_backwards_compatibility, check_num_rank_power_of_2\nfrom horovod.tensorflow.util import _executing_eagerly, _make_subgraph, _cache\n\nimport tensorflow as tf\n\n# @DEKHTIARJonathan: Do not remove, this fixes issues: \n# - https://github.com/tensorflow/tensorflow/issues/38516\n# - https://github.com/tensorflow/tensorflow/issues/39894\nif tf.__version__.startswith(\'2.2.\'):\n  from tensorflow.python.keras.mixed_precision.experimental import device_compatibility_check\n  device_compatibility_check.log_device_compatibility_check = lambda policy_name, skip_local: None\n\n\ndef allreduce(tensor, average=None, device_dense=\'\', device_sparse=\'\',\n              compression=Compression.none, op=None):\n    """"""Perform an allreduce on a tf.Tensor or tf.IndexedSlices.\n\n    This function performs a bandwidth-optimal ring allreduce on the input\n    tensor. If the input is an tf.IndexedSlices, the function instead does an\n    allgather on the values and the indices, effectively doing an allreduce on\n    the represented tensor.\n\n    Arguments:\n        tensor: tf.Tensor, tf.Variable, or tf.IndexedSlices to reduce.\n                The shape of the input must be identical across all ranks.\n        average:\n            .. warning:: .. deprecated:: 0.19.0\n\n                Use `op` instead. Will be removed in v0.21.0.\n\n        device_dense: Device to be used for dense tensors. Uses GPU by default\n                      if Horovod was built with HOROVOD_GPU_OPERATIONS.\n        device_sparse: Device to be used for sparse tensors. Uses GPU by default\n                       if Horovod was built with HOROVOD_GPU_OPERATIONS.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n        op: The reduction operation to combine tensors across different ranks.\n            Defaults to Average if None is given.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, summed across all\n        processes.\n    """"""\n    op = handle_average_backwards_compatibility(op, average)\n    # Averaging happens in framework code, so translate that to Sum for the actual call\n    true_op = Sum if op == Average else op\n\n    if isinstance(tensor, tf.IndexedSlices):\n        # TODO: Need to fix this to actuall call Adasum\n        if op == Adasum:\n            raise NotImplementedError(\'The Adasum reduction does not currently support sparse tensors. As a \'\n                                      \'workaround please pass sparse_as_dense=True to DistributedOptimizer\')\n        with tf.device(device_sparse):\n            # For IndexedSlices, do two allgathers instead of an allreduce.\n            horovod_size = tf.cast(size(), dtype=tensor.values.dtype)\n            values = allgather(tensor.values)\n            indices = allgather(tensor.indices)\n\n            # To make this operation into an average, divide allgathered values by\n            # the Horovod size.\n            new_values = (values / horovod_size) if op == Average else values\n        return tf.IndexedSlices(new_values, indices,\n                                dense_shape=tensor.dense_shape)\n    else:\n        with tf.device(device_dense):\n            horovod_size = tf.cast(size(), dtype=tensor.dtype)\n            tensor_compressed, ctx = compression.compress(tensor)\n            summed_tensor_compressed = _allreduce(tensor_compressed, op=true_op)\n            summed_tensor = compression.decompress(summed_tensor_compressed, ctx)\n            if op == Adasum:\n                if \'CPU\' not in tensor.device and gpu_available(\'tensorflow\'):\n                    if nccl_built():\n                        if not is_homogeneous:\n                            raise NotImplementedError(\n                                \'Running GPU Adasum on heterogeneous cluster is not supported yet.\')\n                        elif not check_num_rank_power_of_2(int(size() / local_size())):\n                            raise NotImplementedError(\n                                \'Running GPU Adasum with non-power of 2 nodes is not supported yet.\')\n                        horovod_local_size = tf.cast(local_size(), dtype=tensor.dtype)\n                        new_tensor = summed_tensor / horovod_local_size\n                    else:\n                        warnings.warn(\'Adasum reduction does not currently support GPU reduction using MPI. Tensors \'\n                                      \'are copied to CPU memory instead. To use Adasum for GPU reduction, please \'\n                                      \'compile Horovod with HOROVOD_GPU_OPERATIONS=NCCL.\')\n                        new_tensor = summed_tensor\n                else:\n                    if not check_num_rank_power_of_2(size()):\n                        raise NotImplementedError(\'Running Adasum with non-power of 2 ranks is not supported yet.\')\n                    new_tensor = summed_tensor\n            else:\n                new_tensor = (summed_tensor / horovod_size) if op == Average else summed_tensor\n        return new_tensor\n\n\ntry:\n    _global_variables = tf.global_variables\nexcept AttributeError:\n    try:\n        _global_variables = tf.compat.v1.global_variables\n    except AttributeError:\n        _global_variables = None\n\nif _global_variables is not None:\n    def broadcast_global_variables(root_rank):\n        """"""Broadcasts all global variables from root rank to all other processes.\n\n        **NOTE:** deprecated in TensorFlow 2.0.\n\n        Arguments:\n            root_rank: rank of the process from which global variables will be broadcasted\n                       to all other processes.\n        """"""\n        if _executing_eagerly():\n            raise RuntimeError(\n                ""hvd.broadcast_global_variables() does not support eager execution. ""\n                ""Please use `hvd.broadcast_variables(<model/optimizer variables>)` instead.""\n            )\n\n        return broadcast_variables(_global_variables(), root_rank)\n\ntry:\n    _get_default_graph = tf.get_default_graph\nexcept AttributeError:\n    try:\n        _get_default_graph = tf.compat.v1.get_default_graph\n    except AttributeError:\n        _get_default_graph = None\n\ntry:\n    _SessionRunHook = tf.estimator.SessionRunHook\nexcept AttributeError:\n    try:\n        _SessionRunHook = tf.train.SessionRunHook\n    except AttributeError:\n        _SessionRunHook = None\n\nif _SessionRunHook is not None and _get_default_graph is not None:\n    class BroadcastGlobalVariablesHook(_SessionRunHook):\n        """"""\n        SessionRunHook that will broadcast all global variables from root rank\n        to all other processes during initialization.\n\n        This is necessary to ensure consistent initialization of all workers when\n        training is started with random weights or restored from a checkpoint.\n\n        **NOTE:** deprecated in TensorFlow 2.0.\n        """"""\n\n        def __init__(self, root_rank, device=\'\'):\n            """"""Construct a new BroadcastGlobalVariablesHook that will broadcast all\n            global variables from root rank to all other processes during initialization.\n\n            Args:\n              root_rank:\n                Rank that will send data, other ranks will receive data.\n              device:\n                Device to be used for broadcasting. Uses GPU by default\n                if Horovod was built with HOROVOD_GPU_OPERATIONS.\n            """"""\n            super(BroadcastGlobalVariablesHook, self).__init__()\n            self.root_rank = root_rank\n            self.bcast_op = None\n            self.device = device\n\n        def begin(self):\n            if not self.bcast_op or self.bcast_op.graph != _get_default_graph():\n                with tf.device(self.device):\n                    self.bcast_op = broadcast_global_variables(self.root_rank)\n\n        def after_create_session(self, session, coord):\n            session.run(self.bcast_op)\n\n\n@_cache\ndef _make_allreduce_grads_fn(name, device_dense, device_sparse,\n                             compression, sparse_as_dense, op):\n    def allreduce_grads(grads):\n        with tf.name_scope(name + ""_Allreduce""):\n            if sparse_as_dense:\n                grads = [tf.convert_to_tensor(grad)\n                         if grad is not None and isinstance(grad, tf.IndexedSlices)\n                         else grad for grad in grads]\n\n            return [allreduce(grad,\n                              device_dense=device_dense,\n                              device_sparse=device_sparse,\n                              compression=compression,\n                              op=op)\n                    if grad is not None else grad\n                    for grad in grads]\n\n    if _executing_eagerly():\n        return _make_subgraph(allreduce_grads)\n    else:\n        return allreduce_grads\n\n\ntry:\n    # TensorFlow 2.x\n    _LegacyOptimizer = tf.compat.v1.train.Optimizer\nexcept AttributeError:\n    try:\n        # TensorFlow 1.x\n        _LegacyOptimizer = tf.train.Optimizer\n    except AttributeError:\n        # Future TensorFlow versions\n        _LegacyOptimizer = None\n\nif _LegacyOptimizer is not None:\n    class _DistributedOptimizer(_LegacyOptimizer):\n        """"""An optimizer that wraps another tf.Optimizer, using an allreduce to\n        combine gradient values before applying gradients to model weights.""""""\n\n        def __init__(self, optimizer, name=None, use_locking=False, device_dense=\'\',\n                    device_sparse=\'\', compression=Compression.none,\n                    sparse_as_dense=False, op=Average):\n            if name is None:\n                name = ""Distributed{}"".format(type(optimizer).__name__)\n            super(_DistributedOptimizer, self).__init__(name=name, use_locking=use_locking)\n\n            self._optimizer = optimizer\n            self._allreduce_grads = _make_allreduce_grads_fn(\n                name, device_dense, device_sparse, compression, sparse_as_dense, op)\n\n        def compute_gradients(self, *args, **kwargs):\n            """"""Compute gradients of all trainable variables.\n\n            See Optimizer.compute_gradients() for more info.\n\n            In DistributedOptimizer, compute_gradients() is overriden to also\n            allreduce the gradients before returning them.\n            """"""\n            gradients = self._optimizer.compute_gradients(*args, **kwargs)\n            if size() > 1 or os.environ.get(\'HOROVOD_ELASTIC\') == \'1\':\n                grads, vars = zip(*gradients)\n                avg_grads = self._allreduce_grads(grads)\n                return list(zip(avg_grads, vars))\n            else:\n                return gradients\n\n        def apply_gradients(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.apply_gradients(*args, **kwargs)\n\n        def get_slot(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.get_slot(*args, **kwargs)\n\n        def get_slot_names(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.get_slot_names(*args, **kwargs)\n\n        def variables(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.variables(*args, **kwargs)\n\n    class _DistributedAdasumOptimizer(_LegacyOptimizer):\n        """"""An optimizer that wraps another tf.Optimizer, using an allreduce to\n        combine model deltas after applying gradients to model weights.""""""\n\n        def __init__(self, optimizer, name=None, use_locking=False, device_dense=\'\',\n                    device_sparse=\'\', compression=Compression.none, backward_passes_per_step=1):\n            if name is None:\n                name = ""DistributedDelta{}"".format(type(optimizer).__name__)\n            super(_DistributedAdasumOptimizer, self).__init__(name=name, use_locking=use_locking)\n\n            self._optimizer = optimizer\n            self._name = name\n            self._device_dense = device_dense\n            self._device_sparse = device_sparse\n            self._compression = compression\n            self._backward_passes_per_step = backward_passes_per_step\n\n        def _prepare(self):\n            self._step_count = tf.get_variable(\n                name=""step_count"", shape=[], dtype=tf.int64, trainable=False,\n                initializer=tf.zeros_initializer)\n            self._is_first_step = tf.cast(tf.math.equal(self._step_count, 0), dtype=tf.bool)\n            self._is_comm_step  = tf.cast(tf.math.equal(self._step_count % self._backward_passes_per_step, self._backward_passes_per_step - 1), dtype=tf.bool)\n        \n        def _apply_shared(self, var, get_update_op):\n            start_slot = self._get_or_make_slot(var, ""delta_start"")\n\n            # initialize start on the first step\n            assign_op = tf.cond(self._is_first_step, \n                lambda: start_slot.assign(var, use_locking=self.use_locking).op, \n                tf.no_op)\n            \n            with tf.control_dependencies([assign_op]):\n                update_op = get_update_op()\n                with tf.control_dependencies([update_op]):\n                    def update():\n                        # delta = var - start\n                        local_delta = var.assign_sub(start_slot, use_locking=self.use_locking) # reuse var\'s memory\n                        # delta = allreduce (delta)\n                        global_delta = allreduce(local_delta,\n                                                 device_dense=self._device_dense,\n                                                 device_sparse=self._device_sparse,\n                                                 compression=self._compression,\n                                                 op=Adasum)\n                        # start = start + delta\n                        new_start = start_slot.assign_add(global_delta, use_locking=self.use_locking)\n                        # var = start\n                        return var.assign(new_start, use_locking=self.use_locking).op\n                    \n                    # if its a communication step, then apply logic above\n                    # if its not a communication step then just have the underlying\n                    # optimizer update the model parameters according to its logic\n                    return tf.cond(self._is_comm_step, update, tf.no_op)\n\n        def _apply_dense(self, grad, var):\n            return self._apply_shared(var, lambda: self._optimizer._apply_dense(grad, var))\n\n        def _resource_apply_dense(self, grad, handle):\n            return self._apply_shared(handle, lambda: self._optimizer._resource_apply_dense(grad, handle))\n\n        def _apply_sparse(self, grad, var):\n            return self._apply_shared(var, lambda: self._optimizer._apply_sparse(grad, var))\n\n        def _resource_apply_sparse(self, grad, handle, indices):\n            return self._apply_shared(handle, lambda: self._optimizer._resource_apply_sparse(grad, handle, indices))\n\n        def _finish(self, update_ops, name_scope):\n            with tf.control_dependencies(update_ops):\n                return tf.assign_add(self._step_count, 1)\n\n        def compute_gradients(self, *args, **kwargs):\n            """"""Compute gradients of all trainable variables.\n            See Optimizer.compute_gradients() for more info.\n            """"""\n            return self._optimizer.compute_gradients(*args, **kwargs)\n\n        def apply_gradients(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.apply_gradients(*args, **kwargs)\n\n        def get_slot(self, var, name):\n            """"""Calls this same method on the underlying optimizer.""""""\n            tmp = super(_DistributedAdasumOptimizer, self).get_slot(var, name)\n            if tmp is not None:\n                return tmp\n            return self._optimizer.get_slot(var, name)\n\n        def get_slot_names(self):\n            """"""Appends local slot names to those of the underlying optimizer.""""""\n            return super(_DistributedAdasumOptimizer, self).get_slot_names() +\\\n                self._optimizer.get_slot_names()\n\n        def variables(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.variables(*args, **kwargs)\n\n\ndef DistributedOptimizer(optimizer, name=None, use_locking=False, device_dense=\'\',\n                         device_sparse=\'\', compression=Compression.none,\n                         sparse_as_dense=False, backward_passes_per_step=1,\n                         op=Average):\n    """"""Construct a new DistributedOptimizer, which uses another optimizer\n    under the hood for computing single-process gradient values and\n    applying gradient updates after the gradient values have been combined\n    across all the Horovod ranks.\n\n    Args:\n      optimizer:\n        Optimizer to use for computing gradients and applying updates.\n      name:\n        Optional name prefix for the operations created when applying\n        gradients. Defaults to ""Distributed"" followed by the provided\n        optimizer type.\n      use_locking:\n        Whether to use locking when updating variables.\n        See Optimizer.__init__ for more info.\n      device_dense:\n        Device to be used for dense tensors. Uses GPU by default\n        if Horovod was built with HOROVOD_GPU_OPERATIONS.\n      device_sparse:\n        Device to be used for sparse tensors. Uses GPU by default\n        if Horovod was built with HOROVOD_GPU_OPERATIONS.\n      compression:\n        Compression algorithm used during allreduce to reduce the amount\n        of data sent during each parameter update step.  Defaults to\n        not using compression.\n      sparse_as_dense:\n        Treat all sparse gradients as dense tensors.  This can help improve\n        performance and memory utilization if the original sparse gradient\n        has high density.  Defaults to false.\n      backward_passes_per_step:\n        Number of backward passes to perform before calling hvd.allreduce.\n        This allows accumulating updates over multiple mini-batches before\n        reducing and applying them.\n      op:\n        The reduction operation to use when combining gradients across\n        different ranks.\n    """"""\n    if isinstance(optimizer, _LegacyOptimizer):\n        if op == Adasum:\n            return _DistributedAdasumOptimizer(optimizer, name, use_locking, device_dense,\n                                            device_sparse, compression, backward_passes_per_step)\n        else:\n            if backward_passes_per_step > 1:\n                raise ValueError(\'backward_passes_per_step>1 is not supported yet with \'\n                                 \'op != Adasum\')\n            return _DistributedOptimizer(optimizer, name, use_locking, device_dense,\n                                        device_sparse, compression, sparse_as_dense, op)\n    elif isinstance(optimizer, tf.keras.optimizers.Optimizer):\n        if op == Adasum:\n            raise ValueError(\'op == Adasum is not supported yet with Keras\')\n        if backward_passes_per_step > 1:\n            raise ValueError(\'backward_passes_per_step > 1 is not supported yet with Keras\')\n        import horovod.tensorflow.keras as hvd_k\n        return hvd_k.DistributedOptimizer(optimizer, name, device_dense, device_sparse,\n                                          compression, sparse_as_dense)\n    else:\n        raise ValueError(\'Provided optimizer doesn\\\'t inherit from either legacy \'\n                         \'TensorFlow or Keras optimizer: %s\' % optimizer)\n\n\nif hasattr(tf, \'GradientTape\'):\n    class _DistributedGradientTape(tf.GradientTape):\n        def __init__(self, tape, device_dense, device_sparse, compression, sparse_as_dense, op,\n                     persistent=False, watch_accessed_variables=True):\n            if hasattr(tape, \'_watch_accessed_variables\'):\n                super(self.__class__, self).__init__(persistent, watch_accessed_variables)\n            else:\n                super(self.__class__, self).__init__(persistent)\n\n            self._tape = tape\n            self._allreduce_grads = _make_allreduce_grads_fn(\n                \'DistributedGradientTape\', device_dense, device_sparse, compression,\n                sparse_as_dense, op)\n\n        def gradient(self, target, sources, output_gradients=None):\n            gradients = super(self.__class__, self).gradient(target, sources, output_gradients)\n            if size() > 1 or os.environ.get(\'HOROVOD_ELASTIC\') == \'1\':\n                return self._allreduce_grads(gradients)\n            else:\n                return gradients\n\n\n    def DistributedGradientTape(gradtape, device_dense=\'\', device_sparse=\'\',\n                                compression=Compression.none, sparse_as_dense=False,\n                                op=Average):\n        """"""A tape that wraps another tf.GradientTape, using an allreduce to\n        combine gradient values before applying gradients to model weights.\n\n        Args:\n          gradtape:\n            GradientTape to use for computing gradients and applying updates.\n          device_dense:\n            Device to be used for dense tensors. Uses GPU by default\n            if Horovod was built with HOROVOD_GPU_OPERATIONS.\n          device_sparse:\n            Device to be used for sparse tensors. Uses GPU by default\n            if Horovod was built with HOROVOD_GPU_OPERATIONS.\n          compression:\n            Compression algorithm used during allreduce to reduce the amount\n            of data sent during each parameter update step.  Defaults to\n            not using compression.\n          sparse_as_dense:\n            Treat all sparse gradients as dense tensors.  This can help improve\n            performance and memory utilization if the original sparse gradient\n            has high density.  Defaults to false.\n          op:\n            The reduction operation to use when combining gradients across\n            different ranks.\n        """"""\n        cls = type(gradtape.__class__.__name__, (gradtape.__class__,),\n                   dict(_DistributedGradientTape.__dict__))\n        if hasattr(gradtape, \'_watch_accessed_variables\'):\n            return cls(gradtape._tape, device_dense, device_sparse, compression,\n                       sparse_as_dense, op, gradtape._persistent,\n                       gradtape._watch_accessed_variables)\n        else:\n            return cls(gradtape._tape, device_dense, device_sparse, compression,\n                       sparse_as_dense, op, gradtape._persistent)\n'"
horovod/tensorflow/compression.py,2,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Gradient compression algorithms.""""""\n\nimport tensorflow as tf\n\n\nclass Compressor(object):\n    """"""Interface for compressing and decompressing a given tensor.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Compresses a tensor and returns it with the context needed to decompress it.""""""\n        pass\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Decompress the tensor with the given context.""""""\n        pass\n\n\nclass NoneCompressor(Compressor):\n    """"""Default no-op compression.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Returns the tensor unmodified.""""""\n        return tensor, None\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Returns the tensor unmodified.""""""\n        return tensor\n\n\nclass FP16Compressor(Compressor):\n    """"""Compress all floating point gradients to 16-bit.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Downcasts the tensor to 16-bit.""""""\n        tensor_compressed = tensor\n        if tensor.dtype.is_floating:\n            # Only allow compression from other floating point types\n            tensor_compressed = tf.cast(tensor, dtype=tf.float16)\n        return tensor_compressed, tensor.dtype\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Upcasts the tensor to the initialization dtype.""""""\n        tensor_decompressed = tensor\n        dtype = ctx\n        if dtype.is_floating:\n            tensor_decompressed = tf.cast(tensor, dtype=dtype)\n        return tensor_decompressed\n\n\nclass Compression(object):\n    """"""Optional gradient compression algorithm used during allreduce.""""""\n\n    """"""Do not compress the gradients. This is the default.""""""\n    none = NoneCompressor\n\n    """"""Compress all floating point gradients to 16-bit.""""""\n    fp16 = FP16Compressor\n'"
horovod/tensorflow/elastic.py,6,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom distutils.version import LooseVersion\n\nimport tensorflow as tf\n\nfrom tensorflow.python.framework import ops\n\nfrom horovod.common.elastic import run_fn, ObjectState\nfrom horovod.common.exceptions import HorovodInternalError\nfrom horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables\nfrom horovod.tensorflow.mpi_ops import _executing_eagerly, init, rank, shutdown\n\n\n_IS_TF2 = LooseVersion(tf.__version__) >= LooseVersion(\'2.0.0\')\n\n\ndef run(func):\n    """"""Decorator used to run the elastic training process.\n\n    The purpose of this decorator is to allow for uninterrupted execution of the wrapped function\n    across multiple workers in parallel, as workers come and go from the system. When a new worker is added,\n    its state needs to be brought to the same point as the other workers, which is done by synchronizing\n    the state object before executing `func`.\n\n    When a worker is added or removed, other workers will raise an exception to bring them back to such a sync\n    point before executing `func` again. This ensures that workers do not diverge when such reset events occur.\n\n    It\'s important to note that collective operations (e.g., broadcast, allreduce) cannot be the call to\n    the wrapped function. Otherwise, new workers could execute these operations during their initialization\n    while other workers are attempting to sync state, resulting in deadlock.\n\n    Args:\n        func: a wrapped function taking any number of args or kwargs. The first argument\n              must be a `horovod.common.elastic.State` object used to synchronize state across\n              workers.\n    """"""\n    from tensorflow.python.framework.errors_impl import UnknownError\n\n    def wrapper(state, *args, **kwargs):\n        try:\n            return func(state, *args, **kwargs)\n        except UnknownError as e:\n            if \'HorovodAllreduce\' in e.message or \\\n                    \'HorovodAllgather\' in e.message or \\\n                    \'HorovodBroadcast\' in e.message:\n                raise HorovodInternalError(e)\n    return run_fn(wrapper, _reset)\n\n\ndef _reset():\n    shutdown()\n    init()\n\n\ndef _broadcast_model(model, optimizer, backend):\n    if _executing_eagerly():\n        # TensorFlow 2.0 or TensorFlow eager\n        broadcast_variables(model.variables, root_rank=0)\n        broadcast_variables(optimizer.variables(), root_rank=0)\n    else:\n        bcast_op = broadcast_variables(_global_variables(), root_rank=0)\n        backend.get_session().run(bcast_op)\n\n\ndef _model_built(model):\n    return model.built if hasattr(model, \'build\') else True\n\n\ndef _global_variables():\n    return tf.global_variables() if not _IS_TF2 else tf.compat.v1.global_variables()\n\n\ndef _default_session():\n    return ops.get_default_session() if not _IS_TF2 else None\n\n\nclass TensorFlowKerasState(ObjectState):\n    """"""State representation of a TensorFlow Keras model and optimizer.\n\n    Supports TensorFlow 2 models and optimizers, as well as `keras` and `tf.keras`.\n\n    Args:\n        model: TensorFlow Keras model.\n        optimizer: Optional optimizer, can be compiled into model instead.\n        backend: For TensorFlow v1, backend used by Keras for obtaining the session.\n        kwargs: Additional properties to sync, will be exposed as attributes of the object.\n    """"""\n    def __init__(self, model, optimizer=None, backend=None, **kwargs):\n        self.model = model\n        if not _model_built(model):\n            raise ValueError(\'Model must be built first. Run `model.build(input_shape)`.\')\n\n        self.optimizer = optimizer or model.optimizer\n        self.backend = backend\n        self._save_model()\n\n        def broadcast_object_with_session(obj):\n            return broadcast_object(obj, session=backend.get_session())\n\n        broadcast_object_fn = broadcast_object if not backend or _executing_eagerly() else broadcast_object_with_session\n\n        super(TensorFlowKerasState, self).__init__(bcast_object=broadcast_object_fn,\n                                                   get_rank=rank,\n                                                   **kwargs)\n\n    def save(self):\n        self._save_model()\n        super(TensorFlowKerasState, self).save()\n\n    def restore(self):\n        self._load_model()\n        super(TensorFlowKerasState, self).restore()\n\n    def sync(self):\n        _broadcast_model(self.model, self.optimizer, backend=self.backend)\n        self._save_model()\n        super(TensorFlowKerasState, self).sync()\n\n    def _save_model(self):\n        if _executing_eagerly():\n            self._saved_model_state = [tf.identity(var) for var in self.model.variables]\n            self._saved_optimizer_state = [tf.identity(var) for var in self.optimizer.variables()]\n        else:\n            self._saved_model_state = self.model.get_weights()\n            self._saved_optimizer_state = self.optimizer.get_weights()\n\n    def _load_model(self):\n        if _executing_eagerly():\n            for var, saved_var in zip(self.model.variables, self._saved_model_state):\n                var.assign(saved_var)\n            for var, saved_var in zip(self.optimizer.variables(), self._saved_optimizer_state):\n                var.assign(saved_var)\n        else:\n            self.model.set_weights(self._saved_model_state)\n            self.optimizer.set_weights(self._saved_optimizer_state)\n\n\nclass TensorFlowState(ObjectState):\n    """"""State representation of a list of TensorFlow variables.\n\n    Supports both TensorFlow v1 and v2. For TensorFlow v2, can only be used when eager execution is enabled.\n\n    Args:\n        variables: List of `tf.Variable` objects to track (default: `tf.global_variables()`).\n        session: For TensorFlow v1, session used to materialize variables (default: `ops.get_default_session()`).\n        kwargs: Additional properties to sync, will be exposed as attributes of the object.\n    """"""\n    def __init__(self, variables=None, session=None, **kwargs):\n        self.variables = variables or _global_variables()\n        self.session = session or _default_session()\n        self._bcast_op = broadcast_variables(self.variables, root_rank=0)\n        self._eval_fn = self._to_numpy if _executing_eagerly() else self._eval_var\n        self._assign_fn = self._assign_var if _IS_TF2 else self._load_var\n        self._save_model()\n\n        bcast_obj = broadcast_object_fn(session=session) if not _executing_eagerly() else broadcast_object\n\n        def broadcast_object_with_session(obj):\n            return bcast_obj(obj)\n\n        super(TensorFlowState, self).__init__(bcast_object=broadcast_object_with_session,\n                                              get_rank=rank,\n                                              **kwargs)\n\n    def save(self):\n        self._save_model()\n        super(TensorFlowState, self).save()\n\n    def restore(self):\n        self._load_model()\n        super(TensorFlowState, self).restore()\n\n    def sync(self):\n        if self.session is not None:\n            self.session.run(self._bcast_op)\n        self._save_model()\n        super(TensorFlowState, self).sync()\n\n    def _save_model(self):\n        self._values = [self._eval_fn(var) for var in self.variables]\n\n    def _eval_var(self, var):\n        return var.eval(self.session)\n\n    def _to_numpy(self, var):\n        return var.numpy()\n\n    def _load_model(self):\n        for var, value in zip(self.variables, self._values):\n            self._assign_fn(var, value)\n\n    def _load_var(self, var, value):\n        var.load(value, self.session)\n\n    def _assign_var(self, var, value):\n        var.assign(value)\n'"
horovod/tensorflow/functions.py,7,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\n\nimport cloudpickle\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python.framework import ops\n\nfrom horovod.tensorflow.mpi_ops import broadcast\nfrom horovod.tensorflow.mpi_ops import local_size, rank, size\nfrom horovod.tensorflow.util import _cache, _executing_eagerly, _make_subgraph\n\n\n@_cache\ndef _make_broadcast_group_fn():\n    if _executing_eagerly():\n        # Eager mode will parallelize independent control flow\n        def broadcast_group(variables, root_rank):\n            for var in variables:\n                var.assign(broadcast(var, root_rank))\n\n        return _make_subgraph(broadcast_group)\n    else:\n        # Graph mode requires an Op\n        def broadcast_group(variables, root_rank):\n            return tf.group(*[var.assign(broadcast(var, root_rank))\n                              for var in variables])\n\n        return broadcast_group\n\n\ndef broadcast_variables(variables, root_rank):\n    """"""Broadcasts variables from root rank to all other processes.\n\n    Arguments:\n        variables: variables for broadcast\n        root_rank: rank of the process from which global variables will be broadcasted\n                   to all other processes.\n    """"""\n    broadcast_group = _make_broadcast_group_fn()\n    return broadcast_group(variables, root_rank)\n\n\ndef broadcast_object(obj, root_rank=0, session=None, name=None):\n    """"""\n    Serializes and broadcasts an object from root rank to all other processes.\n\n    Arguments:\n        obj: An object capable of being serialized without losing any context.\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n        session: Session for TensorFlow v1 compatibility.\n        name: Optional name to use during broadcast, will default to the class\n              type.\n    Returns:\n        The object that was broadcast from the `root_rank`.\n    """"""\n    if name is None:\n        name = type(obj).__name__\n\n    def to_numpy(v):\n        if not _executing_eagerly():\n            sess = session or ops.get_default_session()\n            return sess.run(v)\n        else:\n            return v.numpy()\n\n    if rank() == root_rank:\n        b = io.BytesIO()\n        cloudpickle.dump(obj, b)\n        t = tf.convert_to_tensor(bytearray(b.getvalue()), dtype=tf.uint8)\n        sz = tf.convert_to_tensor([t.shape[0]], dtype=tf.int32)\n        to_numpy(broadcast(sz, root_rank, name + \'.sz\'))\n    else:\n        sz = tf.convert_to_tensor([0], dtype=tf.int32)\n        sz = to_numpy(broadcast(sz, root_rank, name + \'.sz\'))\n        t = tf.zeros(sz.tolist()[0], dtype=tf.uint8)\n\n    t = to_numpy(broadcast(t, root_rank, name + \'.t\'))\n\n    if rank() != root_rank:\n        buf = io.BytesIO(t.tobytes())\n        obj = cloudpickle.load(buf)\n\n    return obj\n\n\ndef broadcast_object_fn(root_rank=0, session=None, name=None):\n    name = name or \'broadcast_object_fn\'\n\n    sz = tf.placeholder(tf.int32, [1], name=\'bcast_object_size\')\n    bcast_size = broadcast(sz, root_rank, name + \'.sz\')\n\n    t = tf.placeholder(tf.uint8, [None], name=\'bcast_object_data\')\n    bcast_data = broadcast(t, root_rank, name + \'.t\')\n\n    session = session or ops.get_default_session()\n\n    def _bcast(obj):\n        if rank() == root_rank:\n            b = io.BytesIO()\n            cloudpickle.dump(obj, b)\n            t_ = bytearray(b.getvalue())\n            sz_ = [len(t_)]\n            session.run(bcast_size, feed_dict={sz: sz_})\n        else:\n            sz_ = [0]\n            sz_ = session.run(bcast_size, feed_dict={sz: sz_})\n            t_ = np.zeros(sz_, dtype=np.uint8)\n\n        t_ = session.run(bcast_data, feed_dict={t: t_})\n\n        if rank() != root_rank:\n            buf = io.BytesIO(t_.tobytes())\n            obj = cloudpickle.load(buf)\n\n        return obj\n    return _bcast\n'"
horovod/tensorflow/mpi_ops.py,5,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2019 Uber Technologies, Inc.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n""""""Inter-process communication using MPI.""""""\n\nimport re\nimport tensorflow as tf\nfrom tensorflow.python.framework import load_library\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.platform import resource_loader\n\nfrom horovod.common.util import get_ext_suffix, get_average_backwards_compatibility_fun, gpu_available, \\\n    num_rank_is_power_2\nfrom horovod.common.basics import HorovodBasics as _HorovodBasics\nfrom horovod.tensorflow.util import _executing_eagerly\n\n\ndef _load_library(name):\n    """"""Loads a .so file containing the specified operators.\n\n    Args:\n      name: The name of the .so file to load.\n\n    Raises:\n      NotFoundError if were not able to load .so file.\n    """"""\n    filename = resource_loader.get_path_to_datafile(name)\n    library = load_library.load_op_library(filename)\n    return library\n\n\nMPI_LIB = _load_library(\'mpi_lib\' + get_ext_suffix())\n\n_basics = _HorovodBasics(__file__, \'mpi_lib\')\n\n# import basic methods\ninit = _basics.init\nshutdown = _basics.shutdown\nsize = _basics.size\nlocal_size = _basics.local_size\nrank = _basics.rank\nlocal_rank = _basics.local_rank\nmpi_threads_supported = _basics.mpi_threads_supported\nmpi_enabled = _basics.mpi_enabled\nmpi_built = _basics.mpi_built\ngloo_enabled = _basics.gloo_enabled\ngloo_built = _basics.gloo_built\nnccl_built = _basics.nccl_built\nddl_built = _basics.ddl_built\nccl_built = _basics.ccl_built\n\n# import reduction op values\nAverage = _basics.Average\nSum = _basics.Sum\nAdasum = _basics.Adasum\n\nis_homogeneous = _basics.is_homogeneous\n\nhandle_average_backwards_compatibility = get_average_backwards_compatibility_fun(_basics)\n\ncheck_num_rank_power_of_2 = num_rank_is_power_2\n\n\n# This function will create a default device map which includes all visible devices.\n# Please run this function in a subprocess\ndef _check_has_gpu():\n    import tensorflow as tf\n    return tf.test.is_gpu_available()\n\n\ndef _normalize_name(name):\n    """"""Normalizes operation name to TensorFlow rules.""""""\n    return re.sub(\'[^a-zA-Z0-9_]\', \'_\', name)\n\n\ndef _allreduce(tensor, name=None, op=Sum):\n    """"""An op which reduces an input tensor over all the Horovod processes. The\n    default reduction is a sum.\n\n    The reduction operation is keyed by the name of the op. The tensor type and\n    shape must be the same on all Horovod processes for a given name. The reduction\n    will not start until all processes are ready to send and receive the tensor.\n\n    Returns:\n      A tensor of the same shape and type as `tensor`, summed across all\n      processes.\n    """"""\n    if name is None and not _executing_eagerly():\n        name = \'HorovodAllreduce_%s\' % _normalize_name(tensor.name)\n    return MPI_LIB.horovod_allreduce(tensor, name=name, reduce_op=op)\n\n\n@ops.RegisterGradient(\'HorovodAllreduce\')\ndef _allreduce_grad(op, grad):\n    """"""Gradient for allreduce op.\n\n    Args:\n      op: An operation.\n      grad: `Tensor` gradient with respect to the output of the op.\n\n    Returns:\n      The gradient with respect to the input of the op.\n    """"""\n    return _allreduce(grad)\n\n\ndef allgather(tensor, name=None):\n    """"""An op which concatenates the input tensor with the same input tensor on\n    all other Horovod processes.\n\n    The concatenation is done on the first dimension, so the input tensors on the\n    different processes must have the same rank and shape, except for the first\n    dimension, which is allowed to be different.\n\n    Returns:\n      A tensor of the same type as `tensor`, concatenated on dimension zero\n      across all processes. The shape is identical to the input shape, except for\n      the first dimension, which may be greater and is the sum of all first\n      dimensions of the tensors in different Horovod processes.\n    """"""\n    if name is None and not _executing_eagerly():\n        name = \'HorovodAllgather_%s\' % _normalize_name(tensor.name)\n    return MPI_LIB.horovod_allgather(tensor, name=name)\n\n\n@ops.RegisterGradient(\'HorovodAllgather\')\ndef _allgather_grad(op, grad):\n    """"""Gradient for allgather op.\n\n    Args:\n      op: An operation.\n      grad: `Tensor` gradient with respect to the output of the op.\n\n    Returns:\n      The gradient with respect to the input of the op.\n    """"""\n    grad = _allreduce(grad)\n\n    with tf.device(\'/cpu:0\'):\n        # Keep the tensor of split sizes on CPU.\n        x = op.inputs[0]\n        d0 = x.get_shape().as_list()[0]\n        d = tf.convert_to_tensor([d0], dtype=tf.int32)\n\n        s = size()\n        d = tf.reshape(allgather(d), [s])\n\n    splits = tf.split(grad, num_or_size_splits=d, axis=0)\n    return splits[rank()]\n\n\ndef broadcast(tensor, root_rank, name=None):\n    """"""An op which broadcasts the input tensor on root rank to the same input tensor\n    on all other Horovod processes.\n\n    The broadcast operation is keyed by the name of the op. The tensor type and\n    shape must be the same on all Horovod processes for a given name. The broadcast\n    will not start until all processes are ready to send and receive the tensor.\n\n    Returns:\n      A tensor of the same shape and type as `tensor`, with the value broadcasted\n      from root rank.\n    """"""\n    if name is None and not _executing_eagerly():\n        name = \'HorovodBroadcast_%s\' % _normalize_name(tensor.name)\n    return MPI_LIB.horovod_broadcast(tensor, name=name, root_rank=root_rank)\n\n\n@ops.RegisterGradient(\'HorovodBroadcast\')\ndef _broadcast_grad(op, grad):\n    """"""Gradient for broadcast op.\n\n    Args:\n      op: An operation.\n      grad: `Tensor` gradient with respect to the output of the op.\n\n    Returns:\n      The gradient with respect to the input of the op.\n    """"""\n    root_rank = op.get_attr(\'root_rank\')\n    grad_reduced = _allreduce(grad)\n    if rank() != root_rank:\n        return grad_reduced * 0\n    return grad_reduced\n'"
horovod/tensorflow/util.py,3,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom distutils.version import LooseVersion\n\nimport tensorflow as tf\n\n\nif LooseVersion(tf.__version__) >= LooseVersion(\'1.7.0\'):  # Eager Mode has been introduced in TF 1.7.0\n    from tensorflow.python.eager import context\n    _has_eager = True\nelse:\n    _has_eager = False\n\n\ndef _executing_eagerly():\n    """"""Returns true if eager execution is supported and enabled.""""""\n    return _has_eager and context.executing_eagerly()\n\n\ndef _make_subgraph(f):\n    if hasattr(tf, \'function\'):\n        # TensorFlow 1.14.0+\n        return tf.function(f)\n    return tf.contrib.eager.defun(f)\n\n\ndef _cache(f):\n    cache = dict()\n\n    def wrapper(*args):\n        key = (args, _executing_eagerly())\n\n        if key in cache:\n            return cache[key]\n        else:\n            retval = f(*args)\n            cache[key] = retval\n            return retval\n\n    return wrapper\n'"
horovod/torch/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.common.util import check_extension\n\ntry:\n    check_extension(\'horovod.torch\', \'HOROVOD_WITH_PYTORCH\',\n                    __file__, \'mpi_lib_v2\')\nexcept:\n    check_extension(\'horovod.torch\', \'HOROVOD_WITH_PYTORCH\',\n                    __file__, \'mpi_lib\', \'_mpi_lib\')\n\nfrom horovod.torch import elastic\nfrom horovod.torch.compression import Compression\nfrom horovod.torch.functions import broadcast_object, broadcast_optimizer_state, broadcast_parameters\nfrom horovod.torch.mpi_ops import allreduce, allreduce_async, allreduce_, allreduce_async_\nfrom horovod.torch.mpi_ops import allgather, allgather_async\nfrom horovod.torch.mpi_ops import broadcast, broadcast_async, broadcast_, broadcast_async_\nfrom horovod.torch.mpi_ops import join\nfrom horovod.torch.mpi_ops import poll, synchronize\nfrom horovod.torch.mpi_ops import init, shutdown\nfrom horovod.torch.mpi_ops import size, local_size, rank, local_rank\nfrom horovod.torch.mpi_ops import mpi_threads_supported, mpi_enabled, mpi_built\nfrom horovod.torch.mpi_ops import gloo_enabled, gloo_built\nfrom horovod.torch.mpi_ops import nccl_built, ddl_built, ccl_built\nfrom horovod.torch.mpi_ops import Average, Sum, Adasum\nfrom horovod.torch.optimizer import DistributedOptimizer\nfrom horovod.torch.sync_batch_norm import SyncBatchNorm\n\n\n# Please run this function in a subprocess\ndef _check_has_gpu():\n    import torch\n    return torch.cuda.is_available()\n'"
horovod/torch/compression.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Gradient compression algorithms.""""""\n\nimport torch\n\n\nclass Compressor(object):\n    """"""Interface for compressing and decompressing a given tensor.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Compresses a tensor and returns it with the context needed to decompress it.""""""\n        pass\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Decompress the tensor with the given context.""""""\n        pass\n\n\nclass NoneCompressor(Compressor):\n    """"""Default no-op compression.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Returns the tensor unmodified.""""""\n        return tensor, None\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Returns the tensor unmodified.""""""\n        return tensor\n\n\nclass FP16Compressor(Compressor):\n    """"""Compress all floating point gradients to 16-bit.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Downcasts the tensor to 16-bit.""""""\n        tensor_compressed = tensor\n        if tensor.dtype.is_floating_point:\n            # Only allow compression from other floating point types\n            tensor_compressed = tensor.type(torch.float16)\n        return tensor_compressed, tensor.dtype\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Upcasts the tensor to the initialization dtype.""""""\n        tensor_decompressed = tensor\n        dtype = ctx\n        if dtype.is_floating_point:\n            tensor_decompressed = tensor.type(dtype)\n        return tensor_decompressed\n\n\nclass Compression(object):\n    """"""Optional gradient compression algorithm used during allreduce.""""""\n\n    """"""Do not compress the gradients. This is the default.""""""\n    none = NoneCompressor\n\n    """"""Compress all floating point gradients to 16-bit.""""""\n    fp16 = FP16Compressor\n'"
horovod/torch/elastic.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport copy\n\nfrom horovod.common.elastic import run_fn, ObjectState\nfrom horovod.torch.mpi_ops import init, rank, shutdown\nfrom horovod.torch.functions import broadcast_object, broadcast_optimizer_state, broadcast_parameters\n\n\ndef run(func):\n    """"""Decorator used to run the elastic training process.\n\n    The purpose of this decorator is to allow for uninterrupted execution of the wrapped function\n    across multiple workers in parallel, as workers come and go from the system. When a new worker is added,\n    its state needs to be brought to the same point as the other workers, which is done by synchronizing\n    the state object before executing `func`.\n\n    When a worker is added or removed, other workers will raise an exception to bring them back to such a sync\n    point before executing `func` again. This ensures that workers do not diverge when such reset events occur.\n\n    It\'s important to note that collective operations (e.g., broadcast, allreduce) cannot be the call to\n    the wrapped function. Otherwise, new workers could execute these operations during their initialization\n    while other workers are attempting to sync state, resulting in deadlock.\n\n    Args:\n        func: a wrapped function taking any number of args or kwargs. The first argument\n              must be a `horovod.common.elastic.State` object used to synchronize state across\n              workers.\n    """"""\n    return run_fn(func, _reset)\n\n\ndef _reset():\n    shutdown()\n    init()\n\n\nclass TorchState(ObjectState):\n    """"""State representation of a PyTorch model and optimizer.\n\n    Args:\n        model: PyTorch model.\n        optimizer: PyTorch optimizer.\n        kwargs: Additional properties to sync, will be exposed as attributes of the object.\n    """"""\n    def __init__(self, model, optimizer, **kwargs):\n        self.model = model\n        self._saved_model_state = copy.deepcopy(model.state_dict())\n\n        self.optimizer = optimizer\n        self._saved_optimizer_state = copy.deepcopy(optimizer.state_dict())\n\n        super(TorchState, self).__init__(bcast_object=broadcast_object,\n                                         get_rank=rank,\n                                         **kwargs)\n\n    def save(self):\n        self._saved_model_state = copy.deepcopy(self.model.state_dict())\n        self._saved_optimizer_state = copy.deepcopy(self.optimizer.state_dict())\n        super(TorchState, self).save()\n\n    def restore(self):\n        self.model.load_state_dict(self._saved_model_state)\n        self.optimizer.load_state_dict(self._saved_optimizer_state)\n        super(TorchState, self).restore()\n\n    def sync(self):\n        broadcast_parameters(self.model.state_dict(), root_rank=0)\n        broadcast_optimizer_state(self.optimizer, root_rank=0)\n        super(TorchState, self).sync()\n'"
horovod/torch/functions.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport collections\nimport io\n\nfrom collections.abc import Iterable\n\nimport cloudpickle\nimport torch\n\nfrom horovod.torch.mpi_ops import broadcast_, broadcast_async_\nfrom horovod.torch.mpi_ops import synchronize\nfrom horovod.torch.mpi_ops import rank\nfrom horovod.torch.optimizer import DistributedOptimizer\n\n\ndef broadcast_parameters(params, root_rank):\n    """"""\n    Broadcasts the parameters from root rank to all other processes.\n    Typical usage is to broadcast the ``model.state_dict()``,\n    ``model.named_parameters()``, or ``model.parameters()``.\n\n    Arguments:\n        params: One of the following:\n            - list of parameters to broadcast\n            - dict of parameters to broadcast\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n    """"""\n    if isinstance(params, dict):\n        params = sorted(params.items())\n    elif isinstance(params, list):\n        # support both named_parameters() and regular parameters()\n        params = [p if isinstance(p, tuple) else (None, p) for p in params]\n    else:\n        raise ValueError(\'invalid params of type: %s\' % type(params))\n\n    # Run asynchronous broadcasts.\n    handles = []\n    for name, p in params:\n        handle = broadcast_async_(p, root_rank, name)\n        handles.append(handle)\n\n    # Wait for completion.\n    for handle in handles:\n        synchronize(handle)\n\n\ndef broadcast_optimizer_state(optimizer, root_rank):\n    """"""\n    Broadcasts an optimizer state from root rank to all other processes.\n\n    Arguments:\n        optimizer: An optimizer.\n        root_rank: The rank of the process from which the optimizer will be\n                   broadcasted to all other processes.\n    """"""\n    if isinstance(optimizer, torch.optim.LBFGS):\n        # TODO(travis): L-BFGS cannot be easily supported without serializing\n        #  the entire state_dict, as its structure is deeply nested and contains\n        #  None type parameter values\n        raise ValueError(\'cannot broadcast torch.optim.LBFGS state\')\n\n    state_dict = optimizer.state_dict()\n\n    # Newly created optimizers will not have their state initialized, so\n    # do that initialization here\n    if len(state_dict[\'state\']) == 0:\n        for group in optimizer.param_groups:\n            for p in group[\'params\']:\n                if p.requires_grad and id(p) not in state_dict[\'state\']:\n                    p.grad = p.data.new(p.size()).zero_()\n        # This function accepts a torch.optim.Optimizer or a DistributedOptimizer\n        # wrapped around a torch optimizer. Calling step() with a DistributedOptimizer\n        # forces allreduce on all model parameters, which will result in deadlock\n        # unless every rank calls step(). Therefore, to finish state initialization\n        # only call optimizer.step() with a torch.optim.Optimizer.\n        if optimizer.__module__ == DistributedOptimizer.__module__:\n            super(optimizer.__class__, optimizer).step()\n        else:\n            optimizer.step()\n        state_dict = optimizer.state_dict()\n\n    # If the state_dict is still empty after initialization, then\n    # the optimizer is stateless, and there is nothing to broadcast.\n    # Furthermore, attempting to access the state dict would result in\n    # an error.\n    if len(state_dict[\'state\']) == 0:\n        return\n\n    params = []\n    callbacks = {}\n    occurrences = collections.defaultdict(int)\n\n    # Returns the full type structure of the possibly nested objects for recursive casting back\n    def _get_types(x):\n        if isinstance(x, Iterable):\n            return type(x), [_get_types(xi) for xi in x]\n        else:\n            return type(x)\n\n    # Casts an object encoded in a tensor back into its original type and subtypes\n    def _recursive_cast(x, dtype):\n        if isinstance(dtype, tuple):\n            t, dtypes = dtype\n            x = t(x)\n            return t([_recursive_cast(x[i], dtypes[i]) for i in range(len(x))])\n        else:\n            return dtype(x)\n\n    # Some optimizer parameters may be represented as scalars instead of\n    # tensors.  In such cases, we need to wrap the scalar in a tensor, then\n    # broadcast, then update the appropriate value in the state_dict with the\n    # new unwrapped scalar value via a callback.\n    def _create_callback(pid, name, t, p):\n        def _from_tensor():\n            state_dict[\'state\'][pid][name] = t(p.cpu().numpy()[0])\n        return _from_tensor\n\n    def _create_option_callback(index, option_key, option_tensor, dtypes):\n        def _from_tensor():\n            optimizer.param_groups[index][option_key] = _recursive_cast(option_tensor.cpu().numpy()[0], dtypes)\n        return _from_tensor\n\n    # Param groups are an ordered list, normally there is only one per model,\n    # but users can add additional param groups for example to train\n    # previously frozen layers\n    for index, group in enumerate(state_dict[\'param_groups\']):\n        # Broadcast options like learning rate\n        for option_key, option_value in group.items():\n            if option_key == \'params\':\n                continue\n\n            # Options like the learning rate are scalar, and need to be wrapped in tensors\n            key = \'%s.%d\' % (option_key, index)\n            dtypes = _get_types(option_value)\n            option_tensor = torch.Tensor([option_value])\n            callbacks[key] = _create_option_callback(index, option_key, option_tensor, dtypes)\n            params.append((key, option_tensor))\n\n        # The params list here is ordered by the layers in the model\n        for pid in group[\'params\']:\n            if pid not in state_dict[\'state\']:\n                # The param has not set requires_grad, so skip broadcast\n                continue\n\n            param_state = state_dict[\'state\'][pid]\n            for name, p in param_state.items():\n                # Some parameter names may appear more than once, in which\n                # case we ensure they have a unique identifier defined by\n                # their order\n                occurrences[name] += 1\n                key = \'%s.%d\' % (str(name), occurrences[name])\n\n                if not torch.is_tensor(p):\n                    # Wrap the scalar in a FloatTensor, and remember its type\n                    # so we can cast it back after unwrapping\n                    t = type(p)\n                    p = torch.Tensor([p])\n                    callbacks[key] = _create_callback(pid, name, t, p)\n\n                params.append((key, p))\n\n    # Synchronized broadcast of all parameters\n    broadcast_parameters(params, root_rank)\n\n    # Post-broadcast cleanup for non-tensor parameters\n    for key, p in params:\n        if key in callbacks:\n            callbacks[key]()\n\n\ndef broadcast_object(obj, root_rank=0, name=None):\n    """"""\n    Serializes and broadcasts an object from root rank to all other processes.\n    Typical usage is to broadcast the `optimizer.state_dict()`, for example:\n\n    .. code-block:: python\n\n        state_dict = broadcast_object(optimizer.state_dict(), 0)\n        if hvd.rank() > 0:\n            optimizer.load_state_dict(state_dict)\n\n    Arguments:\n        obj: An object capable of being serialized without losing any context.\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n        name: Optional name to use during broadcast, will default to the class\n              type.\n    Returns:\n        The object that was broadcast from the `root_rank`.\n    """"""\n    if name is None:\n        name = type(obj).__name__\n\n    if rank() == root_rank:\n        b = io.BytesIO()\n        cloudpickle.dump(obj, b)\n        t = torch.ByteTensor(bytearray(b.getvalue()))\n        sz = torch.IntTensor([t.shape[0]])\n        broadcast_(sz, root_rank, name + \'.sz\')\n    else:\n        sz = torch.IntTensor([0])\n        broadcast_(sz, root_rank, name + \'.sz\')\n        t = torch.ByteTensor(sz.tolist()[0])\n\n    broadcast_(t, root_rank, name + \'.t\')\n\n    if rank() != root_rank:\n        buf = io.BytesIO(t.numpy().tobytes())\n        obj = cloudpickle.load(buf)\n\n    return obj\n'"
horovod/torch/mpi_ops.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom distutils.version import LooseVersion\n\n# Load all the necessary PyTorch C types.\nimport torch\n\nimport warnings\n\n# PyTorch v2 API starts with 1.0.0 (including nightly builds)\n_v2_api = LooseVersion(torch.__version__) >= LooseVersion(\'1.0.0\')\nif _v2_api:\n    from horovod.torch import mpi_lib_v2 as mpi_lib\n    from horovod.common.basics import HorovodBasics as _HorovodBasics\n    _NULL = """"\n    _basics = _HorovodBasics(__file__, \'mpi_lib_v2\')\nelse:\n    from horovod.torch import mpi_lib_impl\n    from horovod.torch import mpi_lib\n    from horovod.common.basics import HorovodBasics as _HorovodBasics\n    _NULL = mpi_lib._ffi.NULL\n    _basics = _HorovodBasics(__file__, \'mpi_lib_impl\', \'_mpi_lib_impl\')\n\nfrom horovod.common.exceptions import HorovodInternalError\nfrom horovod.common.util import get_average_backwards_compatibility_fun, gpu_available, num_rank_is_power_2\n\nfrom horovod.torch.compression import Compression\n\n# import basic methods\ninit = _basics.init\nshutdown = _basics.shutdown\nsize = _basics.size\nlocal_size = _basics.local_size\nrank = _basics.rank\nlocal_rank = _basics.local_rank\nmpi_threads_supported = _basics.mpi_threads_supported\nmpi_enabled = _basics.mpi_enabled\nmpi_built = _basics.mpi_built\ngloo_enabled = _basics.gloo_enabled\ngloo_built = _basics.gloo_built\nnccl_built = _basics.nccl_built\nddl_built = _basics.ddl_built\nccl_built = _basics.ccl_built\n\n# import reduction op values\nAverage = _basics.Average\nSum = _basics.Sum\nAdasum = _basics.Adasum\n\nis_homogeneous = _basics.is_homogeneous\n\nhandle_average_backwards_compatibility = get_average_backwards_compatibility_fun(_basics)\n\n\n# Schema: handle -> input, output\n# We keep input in order to make sure it does not get garbage collected\n# before the operation is finished.\n_handle_map = {}\n\n# Only support fp16 allreduce for PyTorch versions using v2 API.\n_fp16_supported = _v2_api\n\n\ndef _check_function(function_factory, tensor):\n    function = function_factory(tensor)\n    if not hasattr(mpi_lib, function):\n        raise ValueError(\'Tensor type %s is not supported.\' % tensor.type())\n    if not tensor.is_contiguous():\n        raise ValueError(\'Tensor is required to be contiguous.\')\n    return function\n\n\ndef _allreduce_function_factory(tensor):\n    return \'horovod_torch_allreduce_async_\' + tensor.type().replace(\'.\', \'_\')\n\n\ndef _allreduce_async(tensor, output, name, op):\n    if tensor.dtype == torch.float16 and not _fp16_supported:\n        raise NotImplementedError(\n            \'float16 allreduce is not supported for PyTorch version {} < 1.0.0\'\n            .format(torch.__version__))\n\n    # Set the divisor for reduced gradients to average when necessary\n    if op == Average:\n        divisor = size()\n    elif op == Adasum:\n        if tensor.device.type != \'cpu\' and gpu_available(\'torch\'):\n            if nccl_built():\n                if not is_homogeneous():\n                    raise NotImplementedError(\'Running GPU Adasum on heterogeneous cluster is not supported yet.\')\n                elif not num_rank_is_power_2(int(size() / local_size())):\n                    raise NotImplementedError(\'Running GPU Adasum with non-power of 2 nodes is not supported yet.\')\n                divisor = local_size()\n            else:\n                warnings.warn(\'Adasum reduction does not currently support GPU reduction using MPI. Tensors are \'\n                              \'copied to CPU memory instead. To use Adasum for GPU reduction, please compile Horovod \'\n                              \'with HOROVOD_GPU_OPERATIONS=NCCL.\')\n                divisor = 1\n        else:\n            if not num_rank_is_power_2(size()):\n                raise NotImplementedError(\'Running Adasum with non-power of 2 ranks is not supported yet.\')\n            divisor = 1\n    else:\n        divisor = 1\n    # Averaging happens in framework code, so translate that to Sum for the actual call\n    true_op = Sum if op == Average else op\n\n    function = _check_function(_allreduce_function_factory, tensor)\n    try:\n        handle = getattr(mpi_lib, function)(tensor, output, divisor,\n                                            name.encode() if name is not None else _NULL, true_op)\n    except RuntimeError as e:\n        raise HorovodInternalError(e)\n    _handle_map[handle] = (tensor, output)\n    return handle\n\n\ndef allreduce_async(tensor, average=None, name=None, op=None):\n    """"""\n    A function that performs asynchronous averaging or summation of the input tensor\n    over all the Horovod processes. The input tensor is not modified.\n\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to reduce.\n        average:\n            .. warning:: .. deprecated:: 0.19.0\n\n                Use `op` instead. Will be removed in v0.21.0.\n\n        name: A name of the reduction operation.\n        op: The reduction operation to combine tensors across different \n                   ranks. Defaults to Average if None is given.\n\n    Returns:\n        A handle to the allreduce operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    op = handle_average_backwards_compatibility(op, average)\n    output = tensor.new(tensor.shape)\n    return _allreduce_async(tensor, output, name, op)\n\n\nclass HorovodAllreduce(torch.autograd.Function):\n    """"""An autograd function that performs allreduce on a tensor.""""""\n\n    @staticmethod\n    def forward(ctx, tensor, average, name, op):\n        ctx.average = average\n        ctx.op = op\n        handle = allreduce_async(tensor, average, name, op)\n        return synchronize(handle)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        return allreduce(grad_output, average=ctx.average, op=ctx.op), None, None, None\n\n\ndef allreduce(tensor, average=None, name=None, compression=Compression.none, op=None):\n    """"""\n    A function that performs averaging or summation of the input tensor over all the\n    Horovod processes. The input tensor is not modified.\n\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to reduce.\n        average:\n            .. warning:: .. deprecated:: 0.19.0\n\n                Use `op` instead. Will be removed in v0.21.0.\n\n        name: A name of the reduction operation.\n        compression: Compression algorithm used during allreduce to reduce the amount\n                     of data sent during the each parameter update step.  Defaults to\n                     not using compression.\n        op: The reduction operation to combine tensors across different ranks. Defaults\n            to Average if None is given.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, averaged or summed across all\n        processes.\n    """"""\n    tensor_compressed, ctx = compression.compress(tensor)\n    summed_tensor_compressed = HorovodAllreduce.apply(tensor_compressed, average, name, op)\n    return compression.decompress(summed_tensor_compressed, ctx)\n\n\ndef allreduce_async_(tensor, average=None, name=None, op=None):\n    """"""\n    A function that performs asynchronous in-place averaging or summation of the input\n    tensor over all the Horovod processes.\n\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to reduce.\n        average:\n            .. warning:: .. deprecated:: 0.19.0\n\n                Use `op` instead. Will be removed in v0.21.0.\n\n        name: A name of the reduction operation.\n        op: The reduction operation to combine tensors across different ranks. Defaults to\n            Average if None is given.\n\n    Returns:\n        A handle to the allreduce operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    op = handle_average_backwards_compatibility(op, average)\n    return _allreduce_async(tensor, tensor, name, op)\n\n\ndef allreduce_(tensor, average=None, name=None, op=None):\n    """"""\n    A function that performs in-place averaging or summation of the input tensor over\n    all the Horovod processes.\n\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to reduce.\n        average:\n            .. warning:: .. deprecated:: 0.19.0\n\n                Use `op` instead. Will be removed in v0.21.0.\n\n        name: A name of the reduction operation.\n        op: The reduction operation to combine tensors across different ranks. Defaults to\n            Average if None is given.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, averaged or summed across all\n        processes.\n    """"""\n    handle = allreduce_async_(tensor, average, name, op)\n    return synchronize(handle)\n\n\ndef _allgather_function_factory(tensor):\n    return \'horovod_torch_allgather_async_\' + tensor.type().replace(\'.\', \'_\')\n\n\ndef _allgather_async(tensor, output, name):\n    function = _check_function(_allgather_function_factory, tensor)\n    try:\n        handle = getattr(mpi_lib, function)(\n            tensor, output, name.encode() if name is not None else _NULL)\n    except RuntimeError as e:\n        raise HorovodInternalError(e)\n    _handle_map[handle] = (tensor, output)\n    return handle\n\n\ndef allgather_async(tensor, name=None):\n    """"""\n    A function that asynchronously concatenates the input tensor with the same input\n    tensor on all other Horovod processes. The input tensor is not modified.\n\n    The concatenation is done on the first dimension, so the input tensors on the\n    different processes must have the same rank and shape, except for the first\n    dimension, which is allowed to be different.\n\n    Arguments:\n        tensor: A tensor to allgather.\n        name: A name of the allgather operation.\n\n    Returns:\n        A handle to the allgather operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    output = tensor.new()\n    return _allgather_async(tensor, output, name)\n\n\nclass HorovodAllgather(torch.autograd.Function):\n    """"""An autograd function that performs allgather on a tensor.""""""\n\n    @staticmethod\n    def forward(ctx, tensor, name):\n        ctx.dim = tensor.shape[0]\n        handle = allgather_async(tensor, name)\n        return synchronize(handle)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        grad_reduced = allreduce(grad_output, average=False)\n\n        dim_t = torch.IntTensor([ctx.dim])\n        dim = allgather(dim_t).view(size())\n\n        r = rank()\n        offset = torch.sum(dim.narrow(0, 0, r)).item() if r != 0 else 0\n        return grad_reduced.narrow(0, offset, ctx.dim), None\n\n\ndef allgather(tensor, name=None):\n    """"""\n    A function that concatenates the input tensor with the same input tensor on\n    all other Horovod processes. The input tensor is not modified.\n\n    The concatenation is done on the first dimension, so the input tensors on the\n    different processes must have the same rank and shape, except for the first\n    dimension, which is allowed to be different.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to allgather.\n        name: A name of the allgather operation.\n\n    Returns:\n        A tensor of the same type as `tensor`, concatenated on dimension zero\n        across all processes. The shape is identical to the input shape, except for\n        the first dimension, which may be greater and is the sum of all first\n        dimensions of the tensors in different Horovod processes.\n    """"""\n    return HorovodAllgather.apply(tensor, name)\n\n\ndef _broadcast_function_factory(tensor):\n    return \'horovod_torch_broadcast_async_\' + tensor.type().replace(\'.\', \'_\')\n\n\ndef _broadcast_async(tensor, output, root_rank, name):\n    function = _check_function(_broadcast_function_factory, tensor)\n    try:\n        handle = getattr(mpi_lib, function)(\n            tensor, output, root_rank, name.encode() if name is not None else _NULL)\n    except RuntimeError as e:\n        raise HorovodInternalError(e)\n    _handle_map[handle] = (tensor, output)\n    return handle\n\n\ndef broadcast_async(tensor, root_rank, name=None):\n    """"""\n    A function that asynchronously broadcasts the input tensor on root rank to the same\n    input tensor on all other Horovod processes. The input tensor is not modified.\n\n    The broadcast operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The broadcast will not start until all processes\n    are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to broadcast.\n        root_rank: The rank to broadcast the value from.\n        name: A name of the broadcast operation.\n\n    Returns:\n        A handle to the broadcast operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    output = tensor.new(tensor.shape)\n    return _broadcast_async(tensor, output, root_rank, name)\n\n\nclass HorovodBroadcast(torch.autograd.Function):\n    """"""An autograd function that broadcasts a tensor.""""""\n\n    @staticmethod\n    def forward(ctx, tensor, root_rank, name):\n        ctx.root_rank = root_rank\n        handle = broadcast_async(tensor, root_rank, name)\n        return synchronize(handle)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        grad_reduced = allreduce(grad_output, average=False)\n        if rank() != ctx.root_rank:\n            grad_reduced *= 0\n        return grad_reduced, None, None\n\n\ndef broadcast(tensor, root_rank, name=None):\n    """"""\n    A function that broadcasts the input tensor on root rank to the same input tensor\n    on all other Horovod processes. The input tensor is not modified.\n\n    The broadcast operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The broadcast will not start until all processes\n    are ready to send and receive the tensor.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to broadcast.\n        root_rank: The rank to broadcast the value from.\n        name: A name of the broadcast operation.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, with the value broadcasted\n        from root rank.\n    """"""\n    return HorovodBroadcast.apply(tensor, root_rank, name)\n\n\ndef broadcast_async_(tensor, root_rank, name=None):\n    """"""\n    A function that asynchronously broadcasts the input tensor on root rank to the same\n    input tensor on all other Horovod processes. The operation is performed in-place.\n\n    The broadcast operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The broadcast will not start until all processes\n    are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to broadcast.\n        root_rank: The rank to broadcast the value from.\n        name: A name of the broadcast operation.\n\n    Returns:\n        A handle to the broadcast operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    return _broadcast_async(tensor, tensor, root_rank, name)\n\n\ndef broadcast_(tensor, root_rank, name=None):\n    """"""\n    A function that broadcasts the input tensor on root rank to the same input tensor\n    on all other Horovod processes. The operation is performed in-place.\n\n    The broadcast operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    Horovod processes for a given name. The broadcast will not start until all processes\n    are ready to send and receive the tensor.\n\n    Arguments:\n        tensor: A tensor to broadcast.\n        root_rank: The rank to broadcast the value from.\n        name: A name of the broadcast operation.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, with the value broadcasted\n        from root rank.\n    """"""\n    handle = broadcast_async_(tensor, root_rank, name)\n    return synchronize(handle)\n\n\ndef poll(handle):\n    """"""\n    Polls an allreduce, allgather or broadcast handle to determine whether underlying\n    asynchronous operation has completed. After `poll()` returns `True`, `synchronize()`\n    will return without blocking.\n\n    Arguments:\n        handle: A handle returned by an allreduce, allgather or broadcast asynchronous\n                operation.\n\n    Returns:\n        A flag indicating whether the operation has completed.\n    """"""\n    return mpi_lib.horovod_torch_poll(handle) != 0\n\n\ndef synchronize(handle):\n    """"""\n    Synchronizes an asynchronous allreduce, allgather or broadcast operation until\n    it\'s completed. Returns the result of the operation.\n\n    Arguments:\n        handle: A handle returned by an allreduce, allgather or broadcast asynchronous\n                operation.\n\n    Returns:\n        An output tensor of the operation.\n    """"""\n    if handle not in _handle_map:\n        return\n\n    try:\n        mpi_lib.horovod_torch_wait_and_clear(handle)\n        _, output = _handle_map.pop(handle)\n        return output\n    except RuntimeError as e:\n        raise HorovodInternalError(e)\n\n\ndef join(device=-1):\n    """"""A function that indicates that the rank finished processing data.\n\n    All ranks that did not call join() continue to process allreduce operations.\n    This function blocks Python thread until all ranks join.\n\n    Arguments:\n        device: An id of the device to create temprorary zero tensors (default -1, CPU)\n\n    Returns:\n        Id of the rank that joined last.\n    """"""\n    if not _v2_api:\n        raise NotImplementedError(""Join Op is not supported for PyTorch < 1.0"")\n\n    try:\n        return mpi_lib.horovod_torch_join(device)\n    except RuntimeError as e:\n        raise HorovodInternalError(e)\n'"
horovod/torch/optimizer.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright Microsoft\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport warnings\n\nfrom contextlib import contextmanager\n\nimport torch\n\nfrom horovod.torch.compression import Compression\nfrom horovod.torch.mpi_ops import allreduce_async_\nfrom horovod.torch.mpi_ops import synchronize\nfrom horovod.torch.mpi_ops import size\nfrom horovod.torch.mpi_ops import Average, Adasum\n\n\nclass _DistributedOptimizer(torch.optim.Optimizer):\n    def __init__(self, params, named_parameters, compression,\n                 backward_passes_per_step=1, op=Average):\n        super(self.__class__, self).__init__(params)\n        self._compression = compression\n\n        if named_parameters is not None:\n            named_parameters = list(named_parameters)\n        else:\n            named_parameters = [(\'allreduce.noname.%s\' % i, v)\n                                for param_group in self.param_groups\n                                for i, v in enumerate(param_group[\'params\'])]\n        # make sure that named_parameters are tuples\n        if any([not isinstance(p, tuple) for p in named_parameters]):\n            raise ValueError(\'named_parameters should be a sequence of \'\n                             \'tuples (name, parameter), usually produced by \'\n                             \'model.named_parameters().\')\n\n        dups = _DistributedOptimizer.find_duplicates([k for k, _ in named_parameters])\n        if len(dups) > 0:\n            raise ValueError(\'Parameter names in named_parameters must be unique. \'\n                             \'Found duplicates: %s\' % \', \'.join(dups))\n\n        all_param_ids = {id(v)\n                         for param_group in self.param_groups\n                         for v in param_group[\'params\']}\n        named_param_ids = {id(v) for k, v in named_parameters}\n        unnamed_param_ids = all_param_ids - named_param_ids\n        if len(unnamed_param_ids):\n            raise ValueError(\'named_parameters was specified, but one or more model \'\n                             \'parameters were not named. Python object ids: \'\n                             \'%s\' % \', \'.join(str(id) for id in unnamed_param_ids))\n\n        self._parameter_names = {v: k for k, v in sorted(named_parameters)}\n        self.backward_passes_per_step = backward_passes_per_step\n        self._allreduce_delay = {v: self.backward_passes_per_step\n                                 for _, v in sorted(named_parameters)}\n        self.op = op\n        self._handles = {}\n        self._grad_accs = []\n        self._requires_update = set()\n        self._synchronized = False\n        self._should_synchronize = True\n        if size() > 1 or os.environ.get(\'HOROVOD_ELASTIC\') == \'1\':\n            self._register_hooks()\n\n    def load_state_dict(self, *args, **kwargs):\n        self._handles = {}\n        self._synchronized = False\n        self._should_synchronize = True\n        for p in self._allreduce_delay:\n            self._allreduce_delay[p] = self.backward_passes_per_step\n        super(self.__class__, self).load_state_dict(*args, **kwargs)\n\n    @staticmethod\n    def find_duplicates(lst):\n        seen = set()\n        dups = set()\n        for el in lst:\n            if el in seen:\n                dups.add(el)\n            seen.add(el)\n        return dups\n\n    def set_backward_passes_per_step(self, passes):\n        self.backward_passes_per_step = passes\n        for p in self._allreduce_delay:\n            self._allreduce_delay[p] = self.backward_passes_per_step\n\n    def _register_hooks(self):\n        for param_group in self.param_groups:\n            for p in param_group[\'params\']:\n                if p.requires_grad:\n                    p.grad = p.data.new(p.size()).zero_()\n                    self._requires_update.add(p)\n                    p_tmp = p.expand_as(p)\n                    grad_acc = p_tmp.grad_fn.next_functions[0][0]\n                    grad_acc.register_hook(self._make_hook(p))\n                    self._grad_accs.append(grad_acc)\n\n    def _allreduce_grad_async(self, p):\n        name = self._parameter_names.get(p)\n        tensor = p.grad\n        tensor_compressed, ctx = self._compression.compress(tensor)\n\n        handle = allreduce_async_(tensor_compressed, name=name, op=self.op)\n        return handle, ctx\n\n    def _make_hook(self, p):\n        def hook(*ignore):\n            if p in self._handles and self._handles[p][0] is not None:\n                if self._allreduce_delay[p] <= 0:\n                    raise AssertionError(\n                        ""Gradients were computed more than ""\n                        ""backward_passes_per_step times before call ""\n                        ""to step(). Increase backward_passes_per_step to ""\n                        ""accumulate gradients locally."")\n            assert not p.grad.requires_grad\n            assert self._allreduce_delay[p] > 0\n            handle, ctx = None, None\n            self._allreduce_delay[p] -= 1\n            if self._allreduce_delay[p] == 0:\n                handle, ctx = self._allreduce_grad_async(p)\n            self._handles[p] = (handle, ctx)\n        return hook\n\n    def synchronize(self):\n        missing_p = self._requires_update - set(self._handles.keys())\n        for p in missing_p:\n            handle, ctx = self._allreduce_grad_async(p)\n            self._handles[p] = (handle, ctx)\n\n        for p, value in self._handles.items():\n            handle, ctx = value\n            if handle is None:\n                handle, ctx = self._allreduce_grad_async(p)\n                self._handles[p] = (handle, ctx)\n        for p, (handle, _) in self._handles.items():\n            output = synchronize(handle)\n            self._allreduce_delay[p] = self.backward_passes_per_step\n            p.grad.set_(self._compression.decompress(output, ctx))\n        self._handles.clear()\n\n        self._synchronized = True\n\n    @contextmanager\n    def skip_synchronize(self):\n        """"""\n        A context manager used to specify that optimizer.step() should\n        not perform synchronization.\n\n        It\'s typically used in a following pattern:\n\n        .. code-block:: python\n\n            optimizer.synchronize()\n            with optimizer.skip_synchronize():\n                optimizer.step()\n        """"""\n        self._should_synchronize = False\n        try:\n            yield\n        finally:\n            self._should_synchronize = True\n\n    def step(self, closure=None):\n        if self._should_synchronize:\n            if self._synchronized:\n                warnings.warn(""optimizer.step() called without ""\n                              ""optimizer.skip_synchronize() context after ""\n                              ""optimizer.synchronize(). This can cause training ""\n                              ""slowdown. You may want to consider using ""\n                              ""optimizer.skip_synchronize() context if you use ""\n                              ""optimizer.synchronize() in your code."")\n            self.synchronize()\n        self._synchronized = False\n        return super(self.__class__, self).step(closure)\n\n    def zero_grad(self):\n        if self._handles:\n            raise AssertionError(""optimizer.zero_grad() was called after loss.backward() ""\n                                 ""but before optimizer.step() or optimizer.synchronize(). ""\n                                 ""This is prohibited as it can cause a race condition."")\n        return super(self.__class__, self).zero_grad()\n\n\nclass _DistributedAdasumOptimizer(torch.optim.Optimizer):\n    def __init__(self, params, named_parameters, compression,\n                 backward_passes_per_step=1):\n        super(self.__class__, self).__init__(params)\n\n        self._compression = compression\n\n        if named_parameters is not None:\n            named_parameters = list(named_parameters)\n        else:\n            named_parameters = [(\'allreduce.noname.%s\' % i, v)\n                                for param_group in self.param_groups\n                                for i, v in enumerate(param_group[\'params\'])]\n\n        # make sure that named_parameters are tuples\n        if any([not isinstance(p, tuple) for p in named_parameters]):\n            raise ValueError(\'named_parameters should be a sequence of \'\n                             \'tuples (name, parameter), usually produced by \'\n                             \'model.named_parameters().\')\n\n        dups = _DistributedOptimizer.find_duplicates([k for k, _ in named_parameters])\n        if len(dups) > 0:\n            raise ValueError(\'Parameter names in named_parameters must be unique. \'\n                             \'Found duplicates: %s\' % \', \'.join(dups))\n\n        all_param_ids = {id(v)\n                         for param_group in self.param_groups\n                         for v in param_group[\'params\']}\n        named_param_ids = {id(v) for k, v in named_parameters}\n        unnamed_param_ids = all_param_ids - named_param_ids\n        if len(unnamed_param_ids):\n            raise ValueError(\'named_parameters was specified, but one or more model \'\n                             \'parameters were not named. Python object ids: \'\n                             \'%s\' % \', \'.join(str(id) for id in unnamed_param_ids))\n\n        self._parameter_names = {v: k for k, v in sorted(named_parameters)}\n        self.backward_passes_per_step = backward_passes_per_step\n        self._allreduce_delay = {v: self.backward_passes_per_step\n                                 for _, v in sorted(named_parameters)}\n        self._handles = {}\n        self._grad_accs = []\n        self._requires_update = set()\n        self._synchronized = False\n        self._should_synchronize = True\n\n        self._starting_models = {\n            p : torch.zeros_like(p, requires_grad=False)\n            for _, p in named_parameters\n        }\n\n        self._register_hooks()\n\n    def set_backward_passes_per_step(self, passes):\n        self.backward_passes_per_step = passes\n        for p in self._allreduce_delay:\n            self._allreduce_delay[p] = self.backward_passes_per_step\n\n    def _register_hooks(self):\n        for param_group in self.param_groups:\n            for p in param_group[\'params\']:\n                if p.requires_grad:\n                    p.grad = p.data.new(p.size()).zero_()\n                    self._requires_update.add(p)\n                    p_tmp = p.expand_as(p)\n                    grad_acc = p_tmp.grad_fn.next_functions[0][0]\n                    grad_acc.register_hook(self._make_hook(p))\n                    self._grad_accs.append(grad_acc)\n\n    def _allreduce_grad_async(self, p):\n        # Delta optimizer implements this logic:\n        #  start = current.copy()\n        #  step() -> computes \'current - \\alpha.f(g)\' where f is\n        #            optimizer logic and g is the gradient\n        #  delta = current-start\n        #  allreduce_(delta)\n        #  start += delta\n        #  current = start\n        # In order to suppport this logic using function hook to improve performance,\n        # we do:\n        # delta = (start - \\alpha.f(g)) - start\n        #       = -\\alpha.f(g)\n        # set start to zero and step computes -\\alpha.f(g)\n        # where f is the underlying optimizer logic\n\n        name = self._parameter_names.get(p)\n        start = self._starting_models[p]\n\n        stashed_params = []\n        for group in self.param_groups:\n            stashed_params.append(group[\'params\'])\n            # only want to step on p\n            if any([p is v for v in group[\'params\']]):\n                group[\'params\'] = [p]\n            else:\n                group[\'params\'] = []\n\n        start.data.copy_(p)\n\n        super(self.__class__, self).step()\n\n        # compute delta = curr - start\n        p.data.sub_(start)\n\n        # allreduce as before\n        tensor_compressed, ctx = self._compression.compress(p)\n        handle = allreduce_async_(tensor_compressed.data, name=name, op=Adasum)\n\n        # reset stashed parameters\n        for stashed, group in zip(stashed_params, self.param_groups):\n            group[\'params\'] = stashed\n\n        return handle, ctx\n\n    def _make_hook(self, p):\n        def hook(*ignore):\n            if p in self._handles and self._handles[p][0] is not None:\n                if self._allreduce_delay[p] <= 0:\n                    raise AssertionError(\n                        ""Gradients were computed more than ""\n                        ""backward_passes_per_step times before call ""\n                        ""to step(). Increase backward_passes_per_step to ""\n                        ""accumulate gradients locally."")\n            assert not p.grad.requires_grad\n            assert self._allreduce_delay[p] > 0\n            handle, ctx = None, None\n            self._allreduce_delay[p] -= 1\n            if self._allreduce_delay[p] == 0:\n                handle, ctx = self._allreduce_grad_async(p)\n            self._handles[p] = (handle, ctx)\n        return hook\n\n    def synchronize(self):\n        pass\n\n    @contextmanager\n    def skip_synchronize(self):\n        raise AssertionError(""Skipping synchronization is not supported when using Adasum optimizer."")\n\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        missing_p = self._requires_update - set(self._handles.keys())\n        for p in missing_p:\n            handle, ctx = self._allreduce_grad_async(p)\n            self._handles[p] = (handle, ctx)\n\n        for p, (handle, ctx) in self._handles.items():\n            # This means step() is called before backward_passes_per_steps finished.\n            # We do a synchoronous allreduce here.\n            if not handle:\n                handle, ctx = self._allreduce_grad_async(p)\n                self._handles[p] = (handle, ctx)\n            delta = synchronize(handle)\n            delta = self._compression.decompress(delta, ctx)\n            start = self._starting_models[p]\n            start.data.add_(delta.data)\n            p.data.copy_(start)\n            self._allreduce_delay[p] = self.backward_passes_per_step\n        self._handles.clear()\n        return loss\n\n    def zero_grad(self):\n        if self._handles:\n            raise AssertionError(""optimizer.zero_grad() was called after loss.backward() ""\n                                 ""but before optimizer.step() or optimizer.synchronize(). ""\n                                 ""This is prohibited as it can cause a race condition."")\n        return super(self.__class__, self).zero_grad()\n\n\ndef DistributedOptimizer(optimizer, named_parameters=None,\n                         compression=Compression.none,\n                         backward_passes_per_step=1,\n                         op=Average):\n    """"""\n    An optimizer that wraps another torch.optim.Optimizer, using an allreduce to\n    combine gradient values before applying gradients to model weights.\n\n    Allreduce operations are executed after each gradient is computed by ``loss.backward()``\n    in parallel with each other. The ``step()`` method ensures that all allreduce operations are\n    finished before applying gradients to the model.\n\n    DistributedOptimizer exposes the ``synchronize()`` method, which forces allreduce operations\n    to finish before continuing the execution. It\'s useful in conjunction with gradient\n    clipping, or other operations that modify gradients in place before ``step()`` is executed.\n    Make sure to use ``optimizer.skip_synchronize()`` if you\'re calling ``synchronize()``\n    in your code.\n\n    Example of gradient clipping:\n\n    .. code-block:: python\n\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.synchronize()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n        with optimizer.skip_synchronize():\n            optimizer.step()\n\n    Arguments:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        named_parameters: A mapping between parameter names and values. Used for naming of\n                          allreduce operations. Typically just ``model.named_parameters()``.\n        compression: Compression algorithm used during allreduce to reduce the amount\n                     of data sent during the each parameter update step.  Defaults to\n                     not using compression.\n        backward_passes_per_step: Number of expected backward passes to perform\n                                  before calling step()/synchronize(). This\n                                  allows accumulating gradients over multiple\n                                  mini-batches before reducing and applying them.\n        op: The reduction operation to use when combining gradients across different ranks.\n    """"""\n    # We dynamically create a new class that inherits from the optimizer that was passed in.\n    # The goal is to override the `step()` method with an allreduce implementation.\n\n    if op != Adasum or size() == 1:\n        cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n                   dict(_DistributedOptimizer.__dict__))\n        return cls(optimizer.param_groups, named_parameters, compression, backward_passes_per_step, op)\n    else:\n        cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n                   dict(_DistributedAdasumOptimizer.__dict__))\n        return cls(optimizer.param_groups, named_parameters, compression, backward_passes_per_step)\n'"
horovod/torch/sync_batch_norm.py,0,"b'# Based on https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/_functions.py\n# Modifications copyright 2020 Maka Autonomous Robotic Systems\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.torch.mpi_ops import allgather_async, allreduce_async, Sum, size, synchronize\n\nfrom distutils.version import LooseVersion\n\nimport torch\nfrom torch.autograd.function import Function\nimport torch.nn.functional as F\nfrom torch.nn.modules.batchnorm import _BatchNorm\n\n\n# Backward compat for old PyTorch\nif not hasattr(torch.jit, \'unused\'):\n    torch.jit.unused = lambda x: x\n\n\n_SYNC_BN_V2 = (\n    LooseVersion(torch.__version__) >= LooseVersion(\'1.5.0\') and\n    LooseVersion(torch.__version__) <= LooseVersion(\'1.6.0\')\n)\n_SYNC_BN_V3 = LooseVersion(torch.__version__) >= LooseVersion(\'1.6.0\')\n\n\nclass SyncBatchNorm(_BatchNorm):\n    """"""Applies synchronous version of N-dimensional BatchNorm.\n\n    In this version, normalization parameters are synchronized across workers during forward pass.\n    This is very useful in situations where each GPU can fit a very small number of examples.\n\n    See https://pytorch.org/docs/stable/nn.html#batchnorm2d for more details about BatchNorm.\n\n    Arguments:\n        num_features: number of channels `C` from the shape `(N, C, ...)`\n        eps: a value added to the denominator for numerical stability. Default: 1e-5\n        momentum: the value used for the running_mean and running_var\n            computation. Can be set to `None` for cumulative moving average\n            (i.e. simple average). Default: 0.1\n        affine: a boolean value that when set to `True`, this module has\n            learnable affine parameters. Default: `True`\n        track_running_stats: a boolean value that when set to `True`, this\n            module tracks the running mean and variance, and when set to `False`,\n            this module does not track such statistics and always uses batch\n            statistics in both training and eval modes. Default: `True`\n    \n    .. note:: Only GPU input tensors are supported in the training mode.\n    """"""\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True):\n        super().__init__(num_features, eps, momentum, affine, track_running_stats)\n\n    def _check_input_dim(self, input):\n        if input.dim() < 2:\n            raise ValueError(\'expected at least 2D input (got {}D input)\'.format(input.dim()))\n\n    def _run_bn(self, input):\n        return F.batch_norm(\n            input, self.running_mean, self.running_var, self.weight, self.bias,\n            self.training or not self.track_running_stats, self.momentum, self.eps)\n\n    @torch.jit.unused\n    def _maybe_run_sync_bn(self, input):\n        if size() == 1:\n            return self._run_bn(input)\n        return _SyncBatchNorm.apply(\n            input, self.weight, self.bias, self.running_mean, self.running_var,\n            self.eps, self.momentum)\n\n    def forward(self, input):\n        # currently only GPU input is supported by underlying kernel from PyTorch\n        if not input.is_cuda:\n            raise ValueError(\'SyncBatchNorm expected input tensor to be on GPU\')\n\n        self._check_input_dim(input)\n\n        if self.training and self.track_running_stats:\n            self.num_batches_tracked = self.num_batches_tracked + 1\n\n        if not self.training and self.track_running_stats:\n            return self._run_bn(input)\n        else:\n            return self._maybe_run_sync_bn(input)\n\n\nclass _SyncBatchNorm(Function):\n    @staticmethod\n    def forward(self, input, weight, bias, running_mean, running_var, eps, momentum):\n        input = input.contiguous()\n\n        size = input.numel() // input.size(1)\n        count = torch.tensor([size])\n\n        # calculate mean/invstd for input.\n        mean, invstd = torch.batch_norm_stats(input, eps)\n\n        count_handle = allgather_async(count.unsqueeze(0), name=\'sync_batch_norm.count\')\n        mean_handle = allgather_async(mean.unsqueeze(0), name=\'sync_batch_norm.mean\')\n        invstd_handle = allgather_async(invstd.unsqueeze(0), name=\'sync_batch_norm.invstd\')\n\n        # wait on the async communication to finish\n        count_all = synchronize(count_handle)\n        mean_all = synchronize(mean_handle)\n        invstd_all = synchronize(invstd_handle)\n\n        if _SYNC_BN_V3:\n            counts_for_bngswc = count_all.view(-1).float().to(input.device)\n        else:\n            # backwards compatibility\n            counts_for_bngswc = count_all.view(-1).tolist()\n\n        # calculate global mean & invstd\n        mean, invstd = torch.batch_norm_gather_stats_with_counts(\n            input,\n            mean_all,\n            invstd_all,\n            running_mean,\n            running_var,\n            momentum,\n            eps,\n            counts_for_bngswc\n        )\n\n        self.save_for_backward(input, weight, mean, invstd, count_all)\n\n        # apply element-wise normalization\n        return torch.batch_norm_elemt(input, weight, bias, mean, invstd, eps)\n\n    @staticmethod\n    def backward(self, grad_output):\n        grad_output = grad_output.contiguous()\n        saved_input, weight, mean, invstd, count_all = self.saved_tensors\n        need_input_grad, need_weight_grad, need_bias_grad = self.needs_input_grad[0:3]\n\n        # calculate local stats as well as grad_weight / grad_bias\n        sum_dy, sum_dy_xmu, grad_weight, grad_bias = torch.batch_norm_backward_reduce(\n            grad_output,\n            saved_input,\n            mean,\n            invstd,\n            weight,\n            need_input_grad,\n            need_weight_grad,\n            need_bias_grad\n        )\n\n        if need_input_grad:\n            # synchronizing stats used to calculate input gradient.\n            sum_dy_handle = allreduce_async(sum_dy, op=Sum, name=\'sync_batch_norm.sum_dy\')\n            sum_dy_xmu_handle = allreduce_async(sum_dy_xmu, op=Sum, name=\'sync_batch_norm.sum_dy_xmu\')\n\n            # wait on the async communication to finish\n            sum_dy = synchronize(sum_dy_handle)\n            sum_dy_xmu = synchronize(sum_dy_xmu_handle)\n\n            if _SYNC_BN_V2 or _SYNC_BN_V3:\n                count_all_sum = count_all.sum()\n                mean_dy = sum_dy / count_all_sum\n                mean_dy_xmu = sum_dy_xmu / count_all_sum\n            else:\n                # before 1.5.0, sum_dy was sum of means from every worker, so we just \n                # need to divide it by number of workers\n                mean_dy = sum_dy / size()\n                mean_dy_xmu = sum_dy_xmu / size()\n\n            # backward pass for gradient calculation\n            grad_input = torch.batch_norm_backward_elemt(\n                grad_output,\n                saved_input,\n                mean,\n                invstd,\n                weight,\n                mean_dy,\n                mean_dy_xmu\n            )\n        else:\n            grad_input = None\n\n        # synchronizing of grad_weight / grad_bias is not needed as distributed\n        # training would handle all reduce.\n        if weight is None or not need_weight_grad:\n            grad_weight = None\n\n        if weight is None or not need_bias_grad:\n            grad_bias = None\n\n        return grad_input, grad_weight, grad_bias, None, None, None, None, None, None\n'"
test/data/run_safe_shell_exec.py,0,"b'""""""\nThe purpose of this file is to execute a safe_shell_exec command in an isolated Python interpreter that doesn\'t\nshare resources with the main unit testing interpreter.\n\nPython runs a global process called Semaphore Tracker that is used across processes spawned with the multiprocessing\nAPI. If a process spawned by multiprocessing is hard killed while holding semaphores, then they will not be properly\ncleaned up and will be effectively leaked.\n\nNote that this is only a problem at test time, as in practice the process that is hard-killed will not be the child of\nyet another process.\n""""""\nimport os\nimport sys\nimport time\n\nfrom horovod.run.common.util import safe_shell_exec\n\n\nclass FakeEvent(object):\n    def wait(self):\n        time.sleep(999)\n\n\ndef write(filename, value):\n    filename_tmp = filename + \'.tmp\'\n    with open(filename_tmp, \'w\') as f:\n        f.write(str(value))\n\n    # Atomic rename to prevent race conditions from reader\n    os.rename(filename_tmp, filename)\n\n\nif __name__ == \'__main__\':\n    logfile = sys.argv[1]\n    write(logfile, os.getpid())\n\n    cmd = \' \'.join([sys.executable] + sys.argv[2:])\n\n    # Mock out the event to avoid leaking semaphores\n    safe_shell_exec._create_event = lambda ctx: FakeEvent()\n\n    safe_shell_exec.execute(cmd)\n'"
test/data/sleep.py,0,"b""import os\nimport sys\nimport time\n\nduration = int(sys.argv[1])\nfilename = sys.argv[2]\nfilename_tmp = filename + '.tmp'\n\n\ndef write(s):\n    with open(filename_tmp, 'w') as f:\n        f.write(str(s))\n\n    # Atomic rename to prevent race conditions from reader\n    os.rename(filename_tmp, filename)\n\n\nwrite(os.getpid())\ntime.sleep(duration)\n"""
test/integration/elastic_common.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport contextlib\nimport json\nimport os\nimport sys\n\nimport mock\nimport pytest\n\nfrom horovod.run.common.util import config_parser\nfrom horovod.run.runner import parse_args, _run_elastic\n\nsys.path.append(os.path.join(os.path.dirname(__file__), os.pardir))\n\nfrom common import override_args, temppath\n\n\nDISCOVERY_SCRIPT_TEMPLATE = """"""#!/bin/bash\nepoch=0\nif [ -f {logfile} ]; then\n    epoch=$(< {logfile} wc -l | tr -d \'[:space:]\')\nfi\n""""""\n\n\ndef _get_discovery_lines(schedule_step, start, end):\n    epoch, hosts = schedule_step\n    hosts_str = os.linesep.join([\'echo ""{}""\'.format(host) for host in hosts])\n    if start and end:\n        return hosts_str + os.linesep\n    if start:\n        return \'if [ ""$epoch"" == ""{}"" ]; then\'.format(epoch) + os.linesep + hosts_str + os.linesep\n    elif not start and not end:\n        return \'elif [ ""$epoch"" == ""{}"" ]; then\'.format(epoch) + os.linesep + hosts_str + os.linesep\n    else:\n        return \'else\' + os.linesep + hosts_str + os.linesep + \'fi\' + os.linesep\n\n\n@contextlib.contextmanager\ndef _temp_discovery_script(logfile, discovery_schedule):\n    with temppath() as discovery_script:\n        with open(discovery_script, \'w\') as f:\n            f.write(DISCOVERY_SCRIPT_TEMPLATE.format(logfile=logfile) + os.linesep)\n            for i, schedule_step in enumerate(discovery_schedule):\n                f.write(_get_discovery_lines(schedule_step,\n                                             start=i == 0,\n                                             end=i == len(discovery_schedule) - 1))\n        os.chmod(discovery_script, 0o755)\n        yield discovery_script\n\n\nclass BaseElasticTests(object):\n    def __init__(self, training_script, *args, **kwargs):\n        self._training_script = training_script\n        super(BaseElasticTests, self).__init__(*args, **kwargs)\n\n    def _run(self, discovery_schedule, exit_schedule=None, np=2, min_np=2, max_np=4, hosts=None, exit_mode=\'exception\'):\n        with temppath() as logfile:\n            with _temp_discovery_script(logfile, discovery_schedule) as discovery_script:\n                command_args = [\'horovodrun\',\n                                \'-np\', str(np),\n                                \'--min-np\', str(min_np),\n                                \'--log-level\', \'DEBUG\']\n                if hosts is not None:\n                    command_args += [\'-H\', hosts]\n                else:\n                    command_args += [\'--host-discovery-script\', discovery_script,\n                                     \'--max-np\', str(max_np)]\n                command_args += [\'python\', self._training_script,\n                                 \'--logfile\', logfile,\n                                 \'--discovery-schedule\', json.dumps(discovery_schedule),\n                                 \'--exit-schedule\', json.dumps(exit_schedule or {}),\n                                 \'--exit-mode\', exit_mode]\n                print(\' \'.join(command_args))\n\n                with override_args(*command_args):\n                    args = parse_args()\n                    env = {}\n                    config_parser.set_env_from_args(env, args)\n                    _run_elastic(args)\n\n                    with open(logfile, \'r\') as f:\n                        lines = f.readlines()\n\n                    print(\'logfile:\')\n                    for line in lines:\n                        print(line)\n\n                    return [json.loads(line) for line in lines]\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.gloo_run._get_min_start_hosts\', return_value=1)\n    def test_hosts_added_and_removed(self, mock_get_min_start_hosts):\n        for slots, np, min_np, max_np in [(2, 2, 2, 4), (1, 1, 1, 2)]:\n            discovery_schedule = [\n                (0, [\'localhost:{}\'.format(slots)]),\n                (1, [\'localhost:{}\'.format(slots), \'127.0.0.1:{}\'.format(slots)]),\n                (None, [\'127.0.0.1:{}\'.format(slots)]),\n            ]\n\n            results = self._run(discovery_schedule, np=np, min_np=min_np, max_np=max_np)\n            for result in results:\n                print(result)\n\n            assert len(results) == 3\n\n            assert results[0][\'start_rank\'] == 0\n            assert results[0][\'size\'] == slots\n            assert results[0][\'hostname\'] == \'localhost\'\n\n            assert results[1][\'start_rank\'] == 0\n            assert results[1][\'size\'] == slots * 2\n            assert results[1][\'hostname\'] == \'localhost\'\n\n            assert results[2][\'start_rank\'] == slots\n            assert results[2][\'size\'] == slots\n            assert results[2][\'hostname\'] == \'127.0.0.1\'\n            assert results[2][\'rendezvous\'] == 3\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.gloo_run._get_min_start_hosts\', return_value=1)\n    def test_single_rank_failure(self, mock_get_min_start_hosts):\n        for exit_mode in [\'exception\', \'kill\']:\n            discovery_schedule = [\n                (None, [\'localhost:2\', \'127.0.0.1:2\']),\n            ]\n\n            exit_schedule = {\n                str((1, 0)): [0],\n            }\n\n            results = self._run(discovery_schedule, exit_schedule=exit_schedule, exit_mode=exit_mode)\n\n            assert len(results) == 3\n\n            assert results[0][\'start_rank\'] == 0\n            assert results[0][\'size\'] == 4\n            assert results[0][\'rendezvous\'] == 1\n\n            assert results[1][\'start_rank\'] == 2\n            assert results[1][\'size\'] == 2\n            assert results[1][\'rendezvous\'] == 2\n\n            assert results[2][\'start_rank\'] == 2\n            assert results[2][\'size\'] == 2\n            assert results[2][\'rendezvous\'] == 2\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.gloo_run._get_min_start_hosts\', return_value=1)\n    def test_fault_tolerance_without_scaling(self, mock_get_min_start_hosts):\n        for exit_mode in [\'exception\', \'kill\']:\n            discovery_schedule = [\n                (None, [\'localhost:2\', \'127.0.0.1:2\']),\n            ]\n\n            hosts = \'localhost:2,127.0.0.1:2\'\n\n            exit_schedule = {\n                str((1, 0)): [0],\n            }\n\n            results = self._run(discovery_schedule, hosts=hosts, exit_schedule=exit_schedule, exit_mode=exit_mode)\n\n            assert len(results) == 3\n\n            assert results[0][\'start_rank\'] == 0\n            assert results[0][\'size\'] == 4\n            assert results[0][\'rendezvous\'] == 1\n\n            assert results[1][\'start_rank\'] == 2\n            assert results[1][\'size\'] == 2\n            assert results[1][\'rendezvous\'] == 2\n\n            assert results[2][\'start_rank\'] == 2\n            assert results[2][\'size\'] == 2\n            assert results[2][\'rendezvous\'] == 2\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.gloo_run._get_min_start_hosts\', return_value=1)\n    def test_all_ranks_failure(self, mock_get_min_start_hosts):\n        discovery_schedule = [\n            (None, [\'localhost:2\', \'127.0.0.1:2\']),\n        ]\n\n        exit_schedule = {\n            str((1, 0)): [0, 1, 2, 3],\n        }\n\n        message = \'Horovod detected that one or more processes exited with non-zero status\'\n        with pytest.raises(RuntimeError, match=message):\n            self._run(discovery_schedule, exit_schedule=exit_schedule)\n\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.gloo_run._get_min_start_hosts\', return_value=1)\n    def test_all_hosts_blacklisted(self, mock_get_min_start_hosts):\n        discovery_schedule = [\n            (None, [\'localhost:2\', \'127.0.0.1:2\']),\n        ]\n\n        exit_schedule = {\n            str((1, 0)): [0, 2],\n        }\n\n        message = \'Horovod detected that one or more processes exited with non-zero status\'\n        with pytest.raises(RuntimeError, match=message):\n            self._run(discovery_schedule, exit_schedule=exit_schedule)\n\n    @mock.patch(\'horovod.run.elastic.driver.ELASTIC_TIMEOUT_SECS\', 1)\n    @mock.patch(\'horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS\', 0.01)\n    @mock.patch(\'horovod.run.gloo_run._get_min_start_hosts\', return_value=1)\n    def test_min_hosts_timeout(self, mock_get_min_start_hosts):\n        discovery_schedule = [\n            (None, [\'localhost:2\', \'127.0.0.1:2\']),\n        ]\n\n        exit_schedule = {\n            str((1, 0)): [0],\n        }\n\n        message = \'Horovod detected that one or more processes exited with non-zero status\'\n        with pytest.raises(RuntimeError, match=message):\n            self._run(discovery_schedule, exit_schedule=exit_schedule, np=4, min_np=4)\n'"
test/integration/test_elastic_tensorflow.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport unittest\nimport warnings\n\nfrom elastic_common import BaseElasticTests\n\n\nclass ElasticTensorFlowTests(BaseElasticTests, unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        training_script = os.path.join(os.path.dirname(__file__), \'data/elastic_tensorflow_main.py\')\n        super(ElasticTensorFlowTests, self).__init__(training_script, *args, **kwargs)\n        warnings.simplefilter(\'module\')\n'"
test/integration/test_elastic_tensorflow2.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport unittest\nimport warnings\n\nfrom elastic_common import BaseElasticTests\n\n\nclass ElasticTensorFlow2Tests(BaseElasticTests, unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        training_script = os.path.join(os.path.dirname(__file__), \'data/elastic_tensorflow2_main.py\')\n        super(ElasticTensorFlow2Tests, self).__init__(training_script, *args, **kwargs)\n        warnings.simplefilter(\'module\')\n'"
test/integration/test_elastic_torch.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport unittest\nimport warnings\n\nfrom elastic_common import BaseElasticTests\n\n\nclass ElasticTorchTests(BaseElasticTests, unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        training_script = os.path.join(os.path.dirname(__file__), \'data/elastic_torch_main.py\')\n        super(ElasticTorchTests, self).__init__(training_script, *args, **kwargs)\n        warnings.simplefilter(\'module\')\n'"
horovod/run/common/__init__.py,0,b''
horovod/run/driver/__init__.py,0,b''
horovod/run/driver/driver_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\nimport os\nimport sys\n\nfrom socket import AF_INET\nfrom psutil import net_if_addrs\n\nfrom horovod.run.common.service import driver_service\nfrom horovod.run.common.util import codec, safe_shell_exec\nfrom horovod.run.task import task_service\nfrom horovod.run.util import cache, lsf, network, threads\n\n\nclass HorovodRunDriverService(driver_service.BasicDriverService):\n    NAME = \'horovod driver service\'\n\n    def __init__(self, num_hosts, key, nics):\n        super(HorovodRunDriverService, self).__init__(num_hosts,\n                                                      HorovodRunDriverService.NAME,\n                                                      key, nics)\n\n\nclass HorovodRunDriverClient(driver_service.BasicDriverClient):\n    def __init__(self, driver_addresses, key, verbose, match_intf=False):\n        super(HorovodRunDriverClient, self).__init__(\n            HorovodRunDriverService.NAME,\n            driver_addresses,\n            key,\n            verbose,\n            match_intf=match_intf)\n\n\ndef _launch_task_servers(all_host_names, local_host_names, driver_addresses,\n                         settings):\n    """"""\n    Executes the task server and service client task for registration on the\n    hosts.\n    :param all_host_names: list of addresses. for example,\n        [\'worker-0\',\'worker-1\']\n        [\'10.11.11.11\', \'10.11.11.12\']\n    :type all_host_names: list(string)\n    :param local_host_names: names that are resolved to one of the addresses\n    of local hosts interfaces. For example,\n        set([\'localhost\', \'127.0.0.1\'])\n    :type local_host_names: set\n    :param driver_addresses: map of interfaces and their address and port for\n    the service. For example:\n        {\n            \'lo\': [(\'127.0.0.1\', 34588)],\n            \'docker0\': [(\'172.122.10.1\', 34588)],\n            \'eth0\': [(\'11.111.33.73\', 34588)]\n        }\n    :type driver_addresses: map\n    :param settings: the object that contains the setting for running horovod\n    :type settings: Horovod.run.common.util.settings.Settings\n    :return:\n    :rtype:\n    """"""\n\n    def _exec_command(command):\n        host_output = io.StringIO()\n        try:\n            exit_code = safe_shell_exec.execute(command,\n                                                stdout=host_output,\n                                                stderr=host_output)\n            if exit_code != 0:\n                print(\n                    \'Launching horovod task function was not \'\n                    \'successful:\\n{host_output}\'\n                    .format(host_output=host_output.getvalue()))\n                os._exit(exit_code)\n        finally:\n            host_output.close()\n        return exit_code\n\n    if settings.ssh_port:\n        ssh_port_arg = \'-p {ssh_port}\'.format(ssh_port=settings.ssh_port)\n    else:\n        ssh_port_arg = \'\'\n    args_list = []\n    for index in range(len(all_host_names)):\n        host_name = all_host_names[index]\n        if host_name in local_host_names:\n            command = \\\n                \'{python} -m horovod.run.task_fn {index} \' \\\n                \'{driver_addresses} {settings}\'\\\n                .format(python=sys.executable,\n                        index=codec.dumps_base64(index),\n                        driver_addresses=codec.dumps_base64(driver_addresses),\n                        settings=codec.dumps_base64(settings))\n        else:\n            command = \\\n                \'ssh -o StrictHostKeyChecking=no {host} {ssh_port_arg} \' \\\n                \'\\\'{python} -m horovod.run.task_fn {index} {driver_addresses}\' \\\n                \' {settings}\\\'\'\\\n                .format(host=host_name,\n                        ssh_port_arg=ssh_port_arg,\n                        python=sys.executable,\n                        index=codec.dumps_base64(index),\n                        driver_addresses=codec.dumps_base64(driver_addresses),\n                        settings=codec.dumps_base64(settings))\n        args_list.append([command])\n    # Each thread will use ssh command to launch the server on one task. If an\n    # error occurs in one thread, entire process will be terminated. Otherwise,\n    # threads will keep running and ssh session -- and the the task server --\n    # will be bound to the thread. In case, the horovod process dies, all\n    # the ssh sessions and all the task servers will die as well.\n    threads.execute_function_multithreaded(_exec_command,\n                                           args_list,\n                                           block_until_all_done=False)\n\n\n@cache.use_cache()\ndef _driver_fn(all_host_names, local_host_names, settings):\n    """"""\n    launches the service service, launches the task service on each worker and\n    have them register with the service service. Each worker probes all the\n    interfaces of the worker index + 1 (in a ring manner) and only keeps the\n    routed interfaces. Function returns the intersection of the set of all the\n    routed interfaces on all the workers.\n    :param all_host_names: list of addresses. for example,\n        [\'worker-0\',\'worker-1\']\n        [\'10.11.11.11\', \'10.11.11.12\']\n    :type all_host_names: list(string)\n    :param local_host_names: host names that resolve into a local addresses.\n    :type local_host_names: set\n    :param settings: the object that contains the setting for running horovod\n    :type settings: Horovod.run.common.util.settings.Settings\n    :return: example: [\'eth0\', \'eth1\']\n    :rtype: list[string]\n    """"""\n    # Launch a TCP server called service service on the host running horovod\n    driver = HorovodRunDriverService(\n        settings.num_hosts, settings.key, settings.nics)\n    if settings.verbose >= 2:\n        print(\'Launched horovod server.\')\n    # Have all the workers register themselves with the service service.\n    _launch_task_servers(all_host_names, local_host_names,\n                         driver.addresses(), settings)\n    if settings.verbose >= 2:\n        print(\'Attempted to launch horovod task servers.\')\n    try:\n        # wait for all the hosts to register with the service service.\n        if settings.verbose >= 2:\n            print(\'Waiting for the hosts to acknowledge.\')\n        driver.wait_for_initial_registration(settings.start_timeout)\n        tasks = [\n            task_service.HorovodRunTaskClient(\n                index,\n                driver.task_addresses_for_driver(index),\n                settings.key,\n                settings.verbose) for index in range(\n                settings.num_hosts)]\n        # Notify all the drivers that the initial registration is complete.\n        for task in tasks:\n            task.notify_initial_registration_complete()\n        if settings.verbose >= 2:\n            print(\'Notified all the hosts that the registration is complete.\')\n        # Each worker should probe the interfaces of the next worker in a ring\n        # manner and filter only the routed ones -- it should filter out\n        # interfaces that are not really connected to any external networks\n        # such as lo0 with address 127.0.0.1.\n        if settings.verbose >= 2:\n            print(\'Waiting for hosts to perform host-to-host interface checking.\')\n        driver.wait_for_task_to_task_address_updates(settings.start_timeout)\n        if settings.verbose >= 2:\n            print(\'Host-to-host interface checking successful.\')\n        # Determine a set of common interfaces for task-to-task communication.\n        nics = set(driver.task_addresses_for_tasks(0).keys())\n        for index in range(1, settings.num_hosts):\n            nics.intersection_update(\n                driver.task_addresses_for_tasks(index).keys())\n        if not nics:\n            raise Exception(\n                \'Unable to find a set of common task-to-task communication interfaces: %s\'\n                % [(index, driver.task_addresses_for_tasks(index))\n                   for index in range(settings.num_hosts)])\n        return nics\n    finally:\n        driver.shutdown()\n\n\ndef get_common_interfaces(settings, all_host_names, remote_host_names=None, fn_cache=None):\n    \'\'\'\n    Find the set of common and routed interfaces on all the hosts.\n    :param settings: the object that contains the setting for running horovod\n    :type settings: Horovod.run.common.util.settings.Settings\n    :param all_host_names: list of the host names\n    :type all_host_names: list(string)\n    :param remote_host_names: list of the remote host names.\n    :type remote_host_names: list(string)\n    :param fn_cache: Cache storing the results of checks performed by horovod\n    :type fn_cache: Horovod.run.util.cache.Cache\n    :return: List of common interfaces\n    \'\'\'\n    # Skipping interface discovery for LSF cluster as it slows down considerably the job start\n    if lsf.LSFUtils.using_lsf():\n        return None\n\n    if remote_host_names is None:\n        remote_host_names = network.filter_local_addresses(all_host_names)\n\n    if len(remote_host_names) > 0:\n        if settings.nics:\n            # If args.nics is provided, we will use those interfaces. All the workers\n            # must have at least one of those interfaces available.\n            nics = settings.nics\n        else:\n            # Find the set of common, routed interfaces on all the hosts (remote\n            # and local) and specify it in the args to be used by NCCL. It is\n            # expected that the following function will find at least one interface\n            # otherwise, it will raise an exception.\n            if settings.verbose >= 2:\n                print(\'Testing interfaces on all the hosts.\')\n\n            local_host_names = set(all_host_names) - set(remote_host_names)\n            nics = _driver_fn(all_host_names, local_host_names, settings, fn_cache=fn_cache)\n\n            if settings.verbose >= 2:\n                print(\'Interfaces on all the hosts were successfully checked.\')\n                print(\'Common interface found: \' + \' \'.join(nics))\n\n    else:\n        if settings.verbose >= 2:\n            print(\'All hosts are local, finding the interfaces \'\n                  \'with address 127.0.0.1\')\n        # If all the given hosts are local, find the interfaces with address\n        # 127.0.0.1\n        nics = set()\n        for iface, addrs in net_if_addrs().items():\n            if settings.nics and iface not in settings.nics:\n                continue\n            for addr in addrs:\n                if addr.family == AF_INET and addr.address == \'127.0.0.1\':\n                    nics.add(iface)\n                    break\n\n        if len(nics) == 0:\n            raise ValueError(\'No interface is found for address 127.0.0.1.\')\n\n        if settings.verbose >= 2:\n            print(\'Local interface found \' + \' \'.join(nics))\n    return nics\n'"
horovod/run/elastic/__init__.py,0,b''
horovod/run/elastic/discovery.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\nimport logging\nimport threading\n\nfrom collections import defaultdict\n\nfrom horovod.run.common.util import safe_shell_exec\n\n\nclass HostState(object):\n    def __init__(self):\n        self._event = threading.Event()\n\n        # TODO(travis): blacklisted hosts should have a timeout period that increases with each failure\n        self._blacklisted = False\n\n    def get_event(self):\n        if self._event.is_set():\n            event = threading.Event()\n            self._event = event\n        return self._event\n\n    def set_event(self):\n        self._event.set()\n\n    def blacklist(self):\n        self._blacklisted = True\n        self.set_event()\n\n    def is_blacklisted(self):\n        return self._blacklisted\n\n\nclass DiscoveredHosts(object):\n    def __init__(self, host_slots, host_assignment_order):\n        self._host_slots = host_slots\n        self._host_assignment_order = host_assignment_order\n\n    @property\n    def host_slots(self):\n        return self._host_slots\n\n    @property\n    def available_hosts(self):\n        return set(self._host_assignment_order)\n\n    @property\n    def host_assignment_order(self):\n        return self._host_assignment_order\n\n    def get_slots(self, host):\n        return self._host_slots.get(host, 0)\n\n    def count_available_slots(self):\n        # Use the host_assignment_order as it does not contain blacklisted hosts\n        return sum([self.get_slots(host) for host in self._host_assignment_order])\n\n    def update(self, hosts_state):\n        self._host_assignment_order = [host for host in self._host_assignment_order\n                                       if not hosts_state[host].is_blacklisted()]\n        return self\n\n\nclass HostManager(object):\n    def __init__(self, discovery):\n        self._current_hosts = DiscoveredHosts(host_slots={}, host_assignment_order=[])\n        self._hosts_state = defaultdict(HostState)\n        self._discovery = discovery\n\n    def update_available_hosts(self):\n        # TODO(travis): also check for hosts removed from the blacklist in the future\n        prev_host_slots = self._current_hosts.host_slots\n        prev_host_assignment_order = self._current_hosts.host_assignment_order\n        host_slots = self._discovery.find_available_hosts_and_slots()\n        if prev_host_slots != host_slots:\n            available_hosts = set([host for host in host_slots.keys() if not self._hosts_state[host].is_blacklisted()])\n            host_assignment_order = HostManager.order_available_hosts(available_hosts, prev_host_assignment_order)\n            self._current_hosts = DiscoveredHosts(host_slots=host_slots,\n                                                  host_assignment_order=host_assignment_order)\n            return True\n        return False\n\n    @property\n    def current_hosts(self):\n        return self._current_hosts.update(self._hosts_state)\n\n    def blacklist(self, host):\n        if not self._hosts_state[host].is_blacklisted():\n            logging.warning(\'blacklist failing host: {}\'.format(host))\n        self._hosts_state[host].blacklist()\n\n    def is_blacklisted(self, host):\n        return self._hosts_state[host].is_blacklisted()\n\n    def get_host_event(self, host):\n        return self._hosts_state[host].get_event()\n\n    @staticmethod\n    def order_available_hosts(available_hosts, prev_host_assignment_order):\n        # We need to ensure this list preserves relative order to ensure the oldest hosts are assigned lower ranks.\n        host_assignment_order = [host for host in prev_host_assignment_order if host in available_hosts]\n        known_hosts = set(host_assignment_order)\n        for host in available_hosts:\n            if host not in known_hosts:\n                host_assignment_order.append(host)\n        return host_assignment_order\n\n\nclass HostDiscovery(object):\n    def find_available_hosts_and_slots(self):\n        """"""Returns a dict mapping <hostname> -> <number of slots>.""""""\n        raise NotImplementedError()\n\n\nclass HostDiscoveryScript(HostDiscovery):\n    def __init__(self, discovery_script, slots):\n        self._discovery_script = discovery_script\n        self._default_slots = slots\n        super(HostDiscoveryScript, self).__init__()\n\n    def find_available_hosts_and_slots(self):\n        stdout = io.StringIO()\n        exit_code = safe_shell_exec.execute(self._discovery_script, stdout=stdout)\n        if exit_code != 0:\n            raise RuntimeError(\'Failed to execute discovery script: {}. Exit code: {}\'\n                               .format(self._discovery_script, exit_code))\n\n        host_slots = {}\n        lines = set(stdout.getvalue().strip().split(\'\\n\'))\n        for line in lines:\n            host = line\n            if \':\' in line:\n                host, slots = line.split(\':\')\n                host_slots[host] = int(slots)\n            else:\n                host_slots[host] = self._default_slots\n        return host_slots\n\n\nclass FixedHosts(HostDiscovery):\n    def __init__(self, host_slots):\n        super(FixedHosts, self).__init__()\n        self._host_slots = host_slots\n\n    def find_available_hosts_and_slots(self):\n        return self._host_slots\n\n    def set(self, host_slots):\n        self._host_slots = host_slots\n'"
horovod/run/elastic/driver.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport logging\nimport os\nimport queue\nimport threading\nimport time\n\nfrom collections import defaultdict\n\nfrom horovod.run.common.util import hosts, timeout\nfrom horovod.run.elastic.discovery import HostManager\nfrom horovod.run.elastic.registration import WorkerStateRegistry\nfrom horovod.run.elastic.worker import WorkerNotificationClient\n\n\nDISCOVER_HOSTS_FREQUENCY_SECS = 1.0\nELASTIC_TIMEOUT_SECS = 600\n\n\ndef _epoch_time_s():\n    return int(time.time())\n\n\nclass Results(object):\n    def __init__(self):\n        self._results = {}\n        self._worker_threads = queue.Queue()\n\n    def expect(self, worker_thread):\n        self._worker_threads.put(worker_thread)\n\n    def add_result(self, key, value):\n        if key in self._results:\n            return\n        self._results[key] = value\n\n    def get_results(self):\n        while not self._worker_threads.empty():\n            worker_thread = self._worker_threads.get()\n            worker_thread.join()\n        return self._results\n\n\nclass ElasticDriver(object):\n    def __init__(self, rendezvous, discovery, min_np, max_np, timeout=None, verbose=0):\n        self._rendezvous = rendezvous\n        self._host_manager = HostManager(discovery)\n        self._min_np = min_np\n        self._max_np = max_np\n        self._verbose = verbose\n\n        self._host_assignments = {}\n        self._rank_assignments = {}\n        self._world_size = 0\n\n        self._wait_hosts_cond = threading.Condition()\n        self._timeout = timeout or int(os.getenv(\'HOROVOD_ELASTIC_TIMEOUT\', ELASTIC_TIMEOUT_SECS))\n\n        self._create_worker_fn = None\n        self._worker_clients = {}\n\n        self._worker_registry = WorkerStateRegistry(self, self._host_manager)\n        self._results = Results()\n        self._shutdown = threading.Event()\n\n        self._discovery_thread = threading.Thread(target=self._discover_hosts)\n        self._discovery_thread.daemon = True\n        self._discovery_thread.start()\n\n    def start(self, np, create_worker_fn):\n        self._create_worker_fn = create_worker_fn\n        self._activate_workers(np)\n\n    def resume(self):\n        self._activate_workers(self._min_np)\n\n    def stop(self):\n        self._shutdown.set()\n        self._discovery_thread.join()\n\n    def finished(self):\n        return self._shutdown.is_set()\n\n    def get_results(self):\n        return self._results.get_results()\n\n    def register_worker_server(self, host, slot, addresses, secret_key):\n        self._worker_clients[(host, slot)] = WorkerNotificationClient(\n            addresses, secret_key, self._verbose)\n\n    def get_worker_client(self, slot_info):\n        return self._worker_clients.get((slot_info.hostname, slot_info.local_rank))\n\n    def record_ready(self, host, slot):\n        self._worker_registry.record_ready(host, slot)\n\n    def world_size(self):\n        return self._world_size\n\n    def local_size(self, host):\n        return len(self._host_assignments[host])\n\n    def get_slot_info(self, host, slot):\n        return self._host_assignments[host][slot] if self.has_rank_assignment(host, slot) \\\n            else hosts.INVALID_SLOT_INFO\n\n    def get_coordinator_info(self):\n        return self._rank_assignments.get(0)\n\n    def has_rank_assignment(self, host, slot):\n        if self._host_manager.is_blacklisted(host):\n            return False\n        return host in self._host_assignments and len(self._host_assignments[host]) > slot\n\n    @property\n    def host_assignments(self):\n        return self._host_assignments\n\n    def wait_for_available_slots(self, min_np, min_hosts=1):\n        extra_message = \' An elastic job also requires that at least two hosts \' \\\n                        \'are available to resolve compatible network interfaces. If you know which interfaces \' \\\n                        \'are compatible in your network, set `--nic` to skip this check.\' if min_hosts > 1 else \'\'\n\n        tmout = timeout.Timeout(\n            self._timeout,\n            message=\'Timed out waiting for {{activity}}. Please check that you have \'\n                    \'enough resources to run at least {min_np} Horovod processes.{extra_message}\'\n                    .format(min_np=min_np, extra_message=extra_message))\n\n        self._wait_hosts_cond.acquire()\n        try:\n            while True:\n                current_hosts = self._host_manager.current_hosts\n                if current_hosts.count_available_slots() >= min_np and len(current_hosts.available_hosts) >= min_hosts:\n                    return current_hosts\n                if self._shutdown.is_set():\n                    raise RuntimeError(\'Job has been shutdown, see above error messages for details.\')\n                self._wait_hosts_cond.wait(tmout.remaining())\n                tmout.check_time_out_for(\'minimum number of slots to become available\')\n        finally:\n            self._wait_hosts_cond.release()\n\n    def _activate_workers(self, min_np):\n        logging.info(\'wait for available slots: {}\'.format(min_np))\n        current_hosts = self.wait_for_available_slots(min_np)\n        pending_slots = self._update_host_assignments(current_hosts)\n        self._worker_registry.reset(self.world_size())\n        self._start_worker_processes(pending_slots)\n\n    def _discover_hosts(self):\n        first_update = True\n        while not self._shutdown.is_set():\n            self._wait_hosts_cond.acquire()\n            try:\n                if self._host_manager.update_available_hosts():\n                    self._notify_workers_host_changes(self._host_manager.current_hosts)\n                    self._wait_hosts_cond.notify_all()\n            except RuntimeError as e:\n                if first_update:\n                    # Misconfiguration, fail the job immediately\n                    self._shutdown.set()\n                    self._wait_hosts_cond.notify_all()\n                    raise\n                # Transient error, retry until timeout\n                logging.warning(str(e))\n            finally:\n                self._wait_hosts_cond.release()\n            first_update = False\n            self._shutdown.wait(DISCOVER_HOSTS_FREQUENCY_SECS)\n\n    def _notify_workers_host_changes(self, current_hosts):\n        next_host_assignments = {}\n        if current_hosts.count_available_slots() >= self._min_np:\n            # Assignments are required to be stable via contract\n            next_host_assignments, _ = self._get_host_assignments(current_hosts)\n\n        if next_host_assignments == self.host_assignments:\n            # Skip notifying workers when host changes would not result in changes of host assignments\n            logging.debug(\'no host assignment changes, skipping notifications\')\n            return\n\n        coordinator_slot_info = self.get_coordinator_info()\n        if not coordinator_slot_info:\n            logging.debug(\'no coordinator info, skipping notifications\')\n            return\n\n        coordinator_client = self.get_worker_client(coordinator_slot_info)\n        if not coordinator_client:\n            logging.debug(\'no coordinator client, skipping notifications\')\n            return\n\n        timestamp = _epoch_time_s()\n        try:\n            coordinator_client.notify_hosts_updated(timestamp)\n        except:\n            if self._verbose >= 2:\n                logging.exception(\'failed to notify {}[{}] of host updates\'\n                                  .format(coordinator_slot_info.hostname,\n                                          coordinator_slot_info.local_rank))\n\n    def _update_host_assignments(self, current_hosts):\n        # Determine the slots that are already filled so we do not respawn these processes\n        active_slots = set([(host, slot_info.local_rank)\n                            for host, slots in self._host_assignments.items()\n                            for slot_info in slots])\n\n        # Adjust the host assignments to account for added / removed hosts\n        host_assignments, host_assignments_list = self._get_host_assignments(current_hosts)\n\n        if len(self._host_assignments) > 0:\n            # Ensure that at least one previously active host is still assigned, otherwise there is no\n            # way to sync the state to the new workers\n            prev_hosts = self._host_assignments.keys()\n            next_hosts = host_assignments.keys()\n            if not prev_hosts & next_hosts:\n                raise RuntimeError(\'No hosts from previous set remaining, unable to broadcast state.\')\n\n        self._host_assignments = host_assignments\n        self._world_size = len(host_assignments_list)\n        self._rendezvous.httpd.init(host_assignments_list)\n\n        # Rank assignments map from world rank to slot info\n        rank_assignments = {}\n        for slot_info in host_assignments_list:\n            rank_assignments[slot_info.rank] = slot_info\n        self._rank_assignments = rank_assignments\n\n        # Get the newly assigned slots that need to be started\n        pending_slots = [slot_info\n                         for host, slots in self._host_assignments.items()\n                         for slot_info in slots\n                         if (host, slot_info.local_rank) not in active_slots]\n        return pending_slots\n\n    def _get_host_assignments(self, current_hosts):\n        # Adjust the host assignments to account for added / removed hosts\n        host_list = [hosts.HostInfo(host, current_hosts.get_slots(host))\n                     for host in current_hosts.host_assignment_order]\n        host_assignments_list = hosts.get_host_assignments(host_list, self._min_np, self._max_np)\n        host_assignments = defaultdict(list)\n        for slot_info in host_assignments_list:\n            host_assignments[slot_info.hostname].append(slot_info)\n        return host_assignments, host_assignments_list\n\n    def _start_worker_processes(self, pending_slots):\n        for slot_info in pending_slots:\n            logging.info(\'start worker process: {}[{}]\'.format(slot_info.hostname, slot_info.local_rank))\n            self._start_worker_process(slot_info)\n\n    def _start_worker_process(self, slot_info):\n        create_worker_fn = self._create_worker_fn\n        shutdown_event = self._shutdown\n        host_event = self._host_manager.get_host_event(slot_info.hostname)\n\n        def run_worker():\n            res = create_worker_fn(slot_info, [shutdown_event, host_event])\n            exit_code, timestamp = res\n            self._handle_worker_exit(slot_info, exit_code, timestamp)\n\n        thread = threading.Thread(target=run_worker)\n        thread.daemon = True\n        thread.start()\n        self._results.expect(thread)\n\n    def _handle_worker_exit(self, slot_info, exit_code, timestamp):\n        if not self.has_rank_assignment(slot_info.hostname, slot_info.local_rank):\n            # Ignore hosts that are not assigned a rank\n            logging.debug(\'host {} has been blacklisted, ignoring exit from local_rank={}\'\n                          .format(slot_info.hostname, slot_info.local_rank))\n            return\n\n        if exit_code == 0:\n            rendezvous_id = self._worker_registry.record_success(slot_info.hostname, slot_info.local_rank)\n        else:\n            rendezvous_id = self._worker_registry.record_failure(slot_info.hostname, slot_info.local_rank)\n\n        if self.finished() and self._worker_registry.last_rendezvous() == rendezvous_id:\n            logging.debug(\'adding results for {}[{}]: ({}, {})\'\n                          .format(slot_info.hostname, slot_info.local_rank, exit_code, timestamp))\n            name = \'{}[{}]\'.format(slot_info.hostname, slot_info.local_rank)\n            self._results.add_result(name, (exit_code, timestamp))\n\n'"
horovod/run/elastic/registration.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport logging\nimport threading\n\nfrom collections import defaultdict\n\nREADY = \'READY\'\nSUCCESS = \'SUCCESS\'\nFAILURE = \'FAILURE\'\n\n\nclass WorkerStateRegistry(object):\n    def __init__(self, driver, host_manager, verbose=False):\n        self._driver = driver\n        self._host_manager = host_manager\n        self._lock = threading.Lock()\n        self._states = {}\n        self._workers = defaultdict(set)\n        self._barrier = None\n        self._rendezvous_id = 0\n        self._verbose = verbose\n        self._size = 0\n\n    def get_recorded_slots(self):\n        return self._states.keys()\n\n    def get(self, state):\n        return self._workers[state]\n\n    def count(self, state):\n        return len(self._workers[state])\n\n    def reset(self, size):\n        with self._lock:\n            logging.info(\'reset workers: {}\'.format(size))\n            self._states.clear()\n            self._workers.clear()\n            self._barrier = threading.Barrier(parties=size, action=self._action)\n            self._rendezvous_id += 1\n            self._size = size\n\n    def size(self):\n        return self._size\n\n    def last_rendezvous(self):\n        return self._rendezvous_id\n\n    def record_ready(self, host, slot):\n        return self._record_state(host, slot, READY)\n\n    def record_success(self, host, slot):\n        return self._record_state(host, slot, SUCCESS)\n\n    def record_failure(self, host, slot):\n        return self._record_state(host, slot, FAILURE)\n\n    def _record_state(self, host, slot, state):\n        if self._driver.finished():\n            logging.info(\'driver finished, ignoring registration: {}[{}] = {}\'.format(host, slot, state))\n            return self._rendezvous_id\n\n        if self._host_manager.is_blacklisted(host):\n            logging.warning(\'host registers state %s but is already blacklisted, ignoring: %s\', state, host)\n            return self._rendezvous_id\n\n        key = (host, slot)\n        with self._lock:\n            if key in self._states:\n                if state == FAILURE:\n                    # Worker originally recorded itself as READY, but the worker failed while waiting at the barrier. As\n                    # such, we need to update the state to FAILURE, and we don\'t want two threads coming from the same\n                    # worker at the barrier.\n                    #\n                    # In order to ensure that the new failing thread can record results in cases of total job failure,\n                    # we also need to block this thread by waiting on the barrier. This requires us to reset the barrier,\n                    # as otherwise this worker will be double-counted (once for the READY thread and once for FAILURE),\n                    # which would cause the barrier to complete too early.\n                    logging.info(\'key exists, reset barrier: {}[{}] = {} -> {}\'\n                                 .format(host, slot, self._states[key], state))\n                    self._barrier.reset()\n                else:\n                    logging.error(\'key exists and new state %s not FAILURE, \'\n                                  \'ignoring (current state is %s)\', state, self._states[key])\n\n            if key not in self._states or state == FAILURE:\n                logging.info(\'record state: {}[{}] = {}\'.format(host, slot, state))\n                self._states[key] = state\n                self._workers[state].add(key)\n                rendezvous_id = self._rendezvous_id\n\n        rendezvous_id = self._wait(key, state, rendezvous_id)\n        return rendezvous_id\n\n    def _wait(self, key, state, rendezvous_id):\n        while True:\n            try:\n                self._barrier.wait()\n                return rendezvous_id\n            except threading.BrokenBarrierError:\n                if self._barrier.broken:\n                    # Timeout or other non-recoverable error, so exit\n                    raise\n\n                # Barrier has been reset\n                with self._lock:\n                    # Check to make sure the reset was not caused by a change of state for this key\n                    rendezvous_id = self._rendezvous_id\n                    saved_state = self._states.get(key, state)\n                    if saved_state != state:\n                        # This worker changed its state, so do not attempt to wait again to avoid double-counting\n                        raise RuntimeError(\'State {} overridden by {}\'.format(state, saved_state))\n\n    def _action(self):\n        self._on_workers_recorded()\n\n    def _on_workers_recorded(self):\n        logging.info(\'all {} workers recorded\'.format(self.size()))\n\n        # Check for success state, if any process succeeded, shutdown all other processes\n        if self.count(SUCCESS) > 0:\n            logging.info(\'success count == {} -> stop running\'.format(self.count(SUCCESS)))\n            self._driver.stop()\n            return\n\n        # Check that all processes failed, indicating that processing should stop\n        if self.count(FAILURE) == self._size:\n            logging.error(\'failure count == {} -> stop running\'.format(self._size))\n            self._driver.stop()\n            return\n\n        # Check for failures, and add them to the blacklisted hosts list\n        failures = self.get(FAILURE)\n        for host, slot in failures:\n            self._host_manager.blacklist(host)\n\n        # If every active host is blacklisted, then treat this as job failure\n        if all([self._host_manager.is_blacklisted(host) for host, slot in self.get_recorded_slots()]):\n            logging.error(\'blacklisted slots count == {} -> stop running\'.format(self._size))\n            self._driver.stop()\n            return\n\n        try:\n            self._driver.resume()\n        except Exception:\n            logging.exception(\'failed to activate new hosts -> stop running\')\n            self._driver.stop()\n'"
horovod/run/elastic/rendezvous.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport logging\n\nfrom horovod.run.common.util import codec\nfrom horovod.run.http.http_server import RendezvousHandler\n\n# GET methods\nGET_RANK_AND_SIZE = \'rank_and_size\'\n\n# PUT methods\nPUT_WORKER_ADDRESSES = \'worker_addresses\'\n\n\ndef create_rendezvous_handler(driver):\n    class ElasticRendezvousHandler(RendezvousHandler):\n        def _get_value(self, scope, key):\n            if scope == GET_RANK_AND_SIZE:\n                host, local_rank = key.split(\':\')\n                return self._get_rank_and_size(host, int(local_rank))\n\n            return super(RendezvousHandler, self)._get_value(scope, key)\n\n        def _get_rank_and_size(self, host, local_rank):\n            logging.info(\'_get_rank_and_size: {} {}\'.format(host, local_rank))\n            driver.record_ready(host, local_rank)\n            slot_info = driver.get_slot_info(host, local_rank)\n            logging.info(\'rank and size: {} {}\'.format(slot_info.rank, slot_info.size))\n            return slot_info.to_response_string().encode(\'ascii\')\n\n        def _put_value(self, scope, key, value):\n            if scope == PUT_WORKER_ADDRESSES:\n                host, local_rank = key.split(\':\')\n                addresses, secret_key = codec.loads_base64(value)\n                self._put_worker_addresses(host, int(local_rank), addresses, secret_key)\n\n            super(RendezvousHandler, self)._put_value(scope, key, value)\n\n        def _put_worker_addresses(self, host, local_rank, addresses, secret_key):\n            driver.register_worker_server(host, local_rank, addresses, secret_key)\n\n    return ElasticRendezvousHandler\n'"
horovod/run/elastic/settings.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.run.common.util.settings import BaseSettings\n\n\nclass ElasticSettings(BaseSettings):\n    def __init__(self, discovery, min_np, max_np, elastic_timeout, **kwargs):\n        """"""\n        :param discovery: object used to detect and manage available hosts\n        :type discovery: horovod.run.elastic.discovery.HostDiscovery\n        :param min_np: minimum number of processes\n        :type min_np: int\n        :param max_np: maximum number of processes\n        :type max_np: int\n        :param elastic_timeout: timeout for elastic initialisation after re-scaling in seconds\n        :type elastic_timeout: int\n        """"""\n        super(ElasticSettings, self).__init__(elastic=True, **kwargs)\n        self.discovery = discovery\n        self.min_np = min_np\n        self.max_np = max_np\n        self.elastic_timeout = elastic_timeout\n'"
horovod/run/elastic/worker.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport threading\n\nfrom horovod.run.common.util import network, secret\nfrom horovod.run.elastic.rendezvous import PUT_WORKER_ADDRESSES\nfrom horovod.run.http.http_client import put_data_into_kvstore\n\n\nHOROVOD_GLOO_RENDEZVOUS_ADDR = \'HOROVOD_GLOO_RENDEZVOUS_ADDR\'\nHOROVOD_GLOO_RENDEZVOUS_PORT = \'HOROVOD_GLOO_RENDEZVOUS_PORT\'\nHOROVOD_GLOO_IFACE = \'HOROVOD_GLOO_IFACE\'\nHOROVOD_HOSTNAME = \'HOROVOD_HOSTNAME\'\nHOROVOD_LOCAL_RANK = \'HOROVOD_LOCAL_RANK\'\n\n\nclass HostsUpdatedRequest(object):\n    """"""Notifies worker that the set of available hosts/slots has changed.""""""\n    def __init__(self, timestamp):\n        self.timestamp = timestamp\n\n\nclass WorkerNotificationManager(object):\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._service = None\n        self._listeners = set()\n\n    def init(self, rendezvous_addr=None, rendezvous_port=None,\n             nic=None, hostname=None, local_rank=None):\n        with self._lock:\n            if self._service:\n                return\n\n            rendezvous_addr = rendezvous_addr or os.environ.get(HOROVOD_GLOO_RENDEZVOUS_ADDR)\n            if not rendezvous_addr:\n                return\n\n            rendezvous_port = rendezvous_port if rendezvous_port is not None else \\\n                int(os.environ.get(HOROVOD_GLOO_RENDEZVOUS_PORT))\n            nic = nic or os.environ.get(HOROVOD_GLOO_IFACE)\n            hostname = hostname or os.environ.get(HOROVOD_HOSTNAME)\n            local_rank = local_rank if local_rank is not None else \\\n                int(os.environ.get(HOROVOD_LOCAL_RANK))\n\n            secret_key = secret.make_secret_key()\n            self._service = WorkerNotificationService(secret_key, nic, self)\n\n            value = (self._service.addresses(), secret_key)\n            put_data_into_kvstore(rendezvous_addr,\n                                  rendezvous_port,\n                                  PUT_WORKER_ADDRESSES,\n                                  self._create_id(hostname, local_rank),\n                                  value)\n\n    def register_listener(self, listener):\n        self._listeners.add(listener)\n\n    def remove_listener(self, listener):\n        self._listeners.remove(listener)\n\n    def handle_hosts_updated(self, timestamp):\n        for listener in self._listeners:\n            listener.on_hosts_updated(timestamp)\n\n    def _create_id(self, hostname, local_rank):\n        return \'{}:{}\'.format(hostname, local_rank)\n\n\nclass WorkerNotificationService(network.BasicService):\n    NAME = \'worker notification service\'\n\n    def __init__(self, key, nic, manager):\n        super(WorkerNotificationService, self).__init__(WorkerNotificationService.NAME,\n                                                        key,\n                                                        nic)\n        self._manager = manager\n\n    def _handle(self, req, client_address):\n        if isinstance(req, HostsUpdatedRequest):\n            self._manager.handle_hosts_updated(req.timestamp)\n            return network.AckResponse()\n\n        return super(WorkerNotificationService, self)._handle(req, client_address)\n\n\nclass WorkerNotificationClient(network.BasicClient):\n    def __init__(self, addresses, key, verbose, match_intf=False):\n        super(WorkerNotificationClient, self).__init__(WorkerNotificationService.NAME,\n                                                       addresses,\n                                                       key,\n                                                       verbose,\n                                                       match_intf=match_intf)\n\n    def notify_hosts_updated(self, timestamp):\n        self._send(HostsUpdatedRequest(timestamp))\n'"
horovod/run/http/__init__.py,0,b''
horovod/run/http/http_client.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport sys\n\nfrom distutils.version import LooseVersion\n\nif LooseVersion(sys.version) < LooseVersion(\'3.0.0\'):\n    from urllib2 import urlopen\n    from urllib2 import Request\n    from urllib2 import HTTPError, URLError\nelse:\n    from urllib.request import urlopen\n    from urllib.request import Request\n    from urllib.error import HTTPError, URLError\n\nfrom horovod.run.common.util import codec\n\n\ndef read_data_from_kvstore(addr, port, scope, key):\n    try:\n        url = ""http://{addr}:{port}/{scope}/{key}"".format(\n            addr=addr, port=str(port), scope=scope, key=key\n        )\n        req = Request(url)\n        resp = urlopen(req)\n        # TODO: remove base64 encoding because base64 is not efficient\n        return codec.loads_base64(resp.read())\n    except (HTTPError, URLError) as e:\n        raise RuntimeError(""Read data from KVStore server failed."", e)\n\n\ndef put_data_into_kvstore(addr, port, scope, key, value):\n    try:\n        url = ""http://{addr}:{port}/{scope}/{key}"".format(\n            addr=addr, port=str(port), scope=scope, key=key\n        )\n        req = Request(url, data=codec.dumps_base64(value, to_ascii=False))\n        req.get_method = lambda: ""PUT""  # for urllib2 compatibility\n        urlopen(req)\n    except (HTTPError, URLError) as e:\n        raise RuntimeError(""Put data input KVStore server failed."", e)\n'"
horovod/run/http/http_server.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport collections\nimport logging\nimport socket\nimport socketserver\nimport threading\n\nfrom http.server import HTTPServer, SimpleHTTPRequestHandler\n\nfrom horovod.run.util.network import find_port\nfrom horovod.run.util.threads import in_thread\n\n# Timeout for reading from a single request\nSINGLE_REQUEST_TIMEOUT = 3\n\nBAD_REQUEST = 400\nTIMEOUT = 408\nOK = 200\n\n\nclass KVStoreHandler(SimpleHTTPRequestHandler):\n    # Set timeout\n    timeout = SINGLE_REQUEST_TIMEOUT\n\n    # Override GET handler\n    def do_GET(self):\n        paths = self.path.split(\'/\')\n        if len(paths) < 3:\n            logging.error(\n                \'KVStore ERROR: Invalid request path: {path}.\'.format(\n                    path=self.path))\n            self.send_status_code(BAD_REQUEST)\n            return\n\n        _, scope, key = paths\n        value = self._get_value(scope, key)\n\n        if value is None:\n            self.send_status_code(404)\n        else:\n            self.send_response(200)\n            self.send_header(""Content-Length"", str(len(value)))\n            self.end_headers()\n            self.wfile.write(value)\n\n    # Override PUT handler\n    def do_PUT(self):\n        paths = self.path.split(\'/\')\n        if len(paths) < 3:\n            logging.error(\n                \'KVStore ERROR: Invalid request path: {path}.\'.format(\n                    path=self.path))\n            self.send_status_code(BAD_REQUEST)\n            return\n\n        _, scope, key = paths\n\n        # Get body length\n        content_length = int(self.headers[\'Content-Length\'])\n        try:\n            value = self.rfile.read(content_length)\n        except socket.timeout:\n            if self.server.verbose:\n                logging.error(\n                    \'KVStore ERROR: Timeout when receiving {content_bytes} \'\n                    \'bytes, aborting this incomplete request.\' .format(\n                        content_bytes=content_length))\n\n            # If timeout, abort this request\n            self.send_status_code(TIMEOUT)\n            return\n\n        self._put_value(scope, key, value)\n        self.send_status_code(OK)\n\n    def send_status_code(self, status_code):\n        self.send_response(status_code)\n        self.send_header(""Content-Length"", 0)\n        self.end_headers()\n\n    # Override this function to prevent SimpleHTTPServer printing every\n    # request out.\n    def log_message(self, format, *args):\n        pass\n\n    def _get_value(self, scope, key):\n        with self.server.cache_lock:\n            return self.server.cache.get(scope, {}).get(key)\n\n    def _put_value(self, scope, key, value):\n        with self.server.cache_lock:\n            scope_dict = self.server.cache.setdefault(scope, {})\n            scope_dict[key] = value\n            if self.server.verbose:\n                logging.info(scope, self.server.cache[scope].keys())\n\n\nclass RendezvousHandler(KVStoreHandler):\n    # Override DELETE handler\n    def do_DELETE(self):\n        paths = self.path.split(\'/\')\n        if len(paths) < 3:\n            logging.error(\n                \'Rendezvous ERROR: Invalid request path: {path}.\'.format(\n                    path=self.path))\n            self.send_status_code(BAD_REQUEST)\n            return\n\n        _, scope, key = paths\n\n        with self.server.finished_list_lock:\n            self.server.finished_list[scope].append(key)\n            if self.server.scope_size[scope] == len(self.server.finished_list[scope]):\n                with self.server.cache_lock:\n                    self.server.cache.get(scope, {}).clear()\n\n        self.send_status_code(OK)\n\n\nclass RendezvousHTTPServer(socketserver.ThreadingMixIn, HTTPServer, object):\n    def __init__(self, addr, handler, verbose):\n        # This class has to inherit from object since HTTPServer is an old-style\n        # class that does not inherit from object.\n        super(RendezvousHTTPServer, self).__init__(addr, handler)\n\n        # Cache that provides the store\n        self.cache_lock = threading.Lock()\n        self.cache = {}\n\n        self.verbose = verbose\n\n        # Lists for finished rendezvous workers\n        self.finished_list_lock = threading.Lock()\n        self.finished_list = collections.defaultdict(list)\n\n        # Total size for scopes\n        self.scope_size = {}\n\n    def init(self, host_alloc_plan):\n        with self.cache_lock:\n            self.cache.clear()\n\n        with self.finished_list_lock:\n            self.finished_list.clear()\n\n        self.scope_size.clear()\n        self._extract_scope_size(host_alloc_plan)\n\n    def _extract_scope_size(self, host_alloc_plan):\n        for slot_info in host_alloc_plan:\n            self.scope_size[\'global_\'] = slot_info.size\n            cross_rank = slot_info.cross_rank\n            self.scope_size[\'local_\' + str(cross_rank)] = slot_info.local_size\n            local_rank = slot_info.local_rank\n            self.scope_size[\'cross_\' + str(local_rank)] = slot_info.cross_size\n\n    def should_continue(self):\n        return True\n\n\nclass RendezvousServer:\n    def __init__(self, verbose=0):\n        self.httpd = None\n        self.listen_thread = None\n        self.verbose = verbose\n\n    # Rendezvous function finds a available port, create http socket,\n    # and start listening loop to handle request\n    # self.httpd.init needs to be called after server start\n    def start_server(self, handler_cls=RendezvousHandler):\n        self.httpd, port = find_port(\n            lambda addr: RendezvousHTTPServer(\n                addr, handler_cls, self.verbose))\n        if self.verbose:\n            logging.info(\'Rendezvous INFO: HTTP rendezvous server started.\')\n\n        # start the listening loop\n        self.listen_thread = in_thread(target=self.httpd.serve_forever)\n\n        return port\n\n    def stop_server(self):\n        self.httpd.shutdown()\n        self.listen_thread.join()\n\n\nclass KVStoreHTTPServer(HTTPServer, object):\n    def __init__(self, addr, handler, verbose):\n        super(KVStoreHTTPServer, self).__init__(addr, handler)\n\n        # Cache that provides the store\n        self.cache_lock = threading.Lock()\n        self.cache = {}\n\n        self.verbose = verbose\n\n\nclass KVStoreServer:\n    def __init__(self, verbose):\n        self.httpd = None\n        self.listen_thread = None\n        self.verbose = verbose\n\n    # KVStore server finds a available port, create http socket,\n    # and start listening loop to handle request\n    def start_server(self):\n        self.httpd, port = find_port(\n            lambda addr: KVStoreHTTPServer(\n                addr, KVStoreHandler, self.verbose))\n\n        self.listen_thread = in_thread(target=self.httpd.serve_forever)\n\n        if self.verbose:\n            logging.info(\'KVStoreServer INFO: KVStore server started. Listen on port \' + str(port))\n\n        return port\n\n    def shutdown_server(self):\n        self.httpd.shutdown()\n\n        self.httpd.server_close()\n\n        if self.verbose:\n            logging.info(\'KVStoreServer INFO: KVStore server finishes.\')\n        # Because this thread is daemonized, no need to join.\n'"
horovod/run/task/__init__.py,0,b''
horovod/run/task/task_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.run.common.service import task_service\n\n\nclass TaskToTaskAddressCheckFinishedSignal(object):\n    def __init__(self, index):\n        self.index = index\n        """"""Task index.""""""\n\n\nclass TaskToTaskAddressCheckFinishedSignalResponse(object):\n    def __init__(self, index):\n        self.index = index\n        """"""Task index.""""""\n\n\nclass HorovodRunTaskService(task_service.BasicTaskService):\n    NAME_FORMAT = \'horovod task service #%d\'\n\n    def __init__(self, index, key, nics):\n        super(HorovodRunTaskService, self).__init__(\n            HorovodRunTaskService.NAME_FORMAT % index,\n            key, nics)\n        self.index = index\n        self._task_to_task_address_check_completed = False\n\n    def _handle(self, req, client_address):\n\n        if isinstance(req, TaskToTaskAddressCheckFinishedSignal):\n            self._wait_cond.acquire()\n            try:\n                self._task_to_task_address_check_completed = True\n            finally:\n                self._wait_cond.notify_all()\n                self._wait_cond.release()\n\n            return TaskToTaskAddressCheckFinishedSignalResponse(self.index)\n\n        return super(HorovodRunTaskService, self)._handle(req, client_address)\n\n    def wait_for_task_to_task_address_check_finish_signal(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while not self._task_to_task_address_check_completed:\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\'Task to task address check\')\n        finally:\n            self._wait_cond.release()\n\n\nclass HorovodRunTaskClient(task_service.BasicTaskClient):\n\n    def __init__(self, index, task_addresses, key, verbose, match_intf=False, attempts=3):\n        super(HorovodRunTaskClient, self).__init__(\n            HorovodRunTaskService.NAME_FORMAT % index,\n            task_addresses, key, verbose,\n            match_intf=match_intf,\n            attempts=attempts)\n        self.index = index\n\n    def task_to_task_address_check_completed(self):\n        resp = self._send(TaskToTaskAddressCheckFinishedSignal(self.index))\n        return resp.index\n'"
horovod/run/util/__init__.py,0,b''
horovod/run/util/cache.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport datetime\nimport errno\nimport os\nimport threading\nimport cloudpickle\n\n\nclass Cache(object):\n    """"""\n    Cache the function calls\n    """"""\n\n    def __init__(self, cache_folder, cache_staleness_threshold_in_minutes,\n                 parameters_hash):\n        # Protocol version 0 is the original ""human-readable"" protocol and is\n        # compatible with earlier python 2 and 3.\n        self._pickle_protocol = 0\n        self._cache_file = os.path.join(cache_folder, \'cache.bin\')\n        try:\n            # If folder exists, does not do anything.\n            os.makedirs(cache_folder)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n\n        if not os.path.isfile(self._cache_file) or \\\n                self._cache_file_is_corrupt_and_deleted():\n            self._dump({\'parameters_hash\': parameters_hash})\n\n        content = self._load(self._cache_file)\n\n        if content.get(\'parameters_hash\', None) == parameters_hash:\n            # If previous cache was for the same set of parameters, use it.\n            self._content = content\n        else:\n            self._content = {\'parameters_hash\': parameters_hash}\n\n        self._cache_staleness_threshold = \\\n            datetime.timedelta(minutes=cache_staleness_threshold_in_minutes)\n        self._lock = threading.Lock()\n\n    def get(self, key):\n        self._lock.acquire()\n        timestamp, val = self._content.get(key, (None, None))\n        self._lock.release()\n\n        if timestamp:\n            if timestamp >= datetime.datetime.now() - self._cache_staleness_threshold:\n                return val\n        else:\n            return None\n\n    def put(self, key, val):\n        self._lock.acquire()\n        self._content[key] = (datetime.datetime.now(), val)\n        try:\n            self._dump(self._content)\n        finally:\n            self._lock.release()\n\n    def _dump(self, content):\n        with open(self._cache_file, \'wb\') as cf:\n            cloudpickle.dump(content, cf, protocol=self._pickle_protocol)\n\n    def _load(self, cache_file):\n        with open(cache_file, \'rb\') as cf:\n            try:\n                content = cloudpickle.load(cf)\n            except Exception as e:\n                print(\n                    \'There is an error with reading cache file. You \'\n                    \'can delete the corrupt file: {cache_file}.\'.format(\n                        cache_file=cache_file))\n                raise\n        return content\n\n    def _cache_file_is_corrupt_and_deleted(self):\n        try:\n            _ = self._load(self._cache_file)\n            return False\n        except Exception as e:\n            os.remove(self._cache_file)\n            return True\n\n\ndef use_cache():\n    """"""\n    If used to decorate a function and if fn_cache is set, it will store the\n    output of the function if the output is not None. If a function output\n    is None, the execution result will not be cached.\n    :return:\n    """"""\n\n    def wrap(func):\n        def wrap_f(*args, **kwargs):\n            fn_cache = kwargs.pop(\'fn_cache\')\n            if fn_cache is None:\n                results = func(*args, **kwargs)\n            else:\n                cached_result = fn_cache.get(\n                    (func.__name__, tuple(args[0]), frozenset(kwargs.items())))\n                if cached_result is not None:\n                    return cached_result\n                results = func(*args, **kwargs)\n                if results is not None:\n                    fn_cache.put(\n                        (func.__name__, tuple(args[0]),\n                            frozenset(kwargs.items())),\n                        results)\n            return results\n\n        return wrap_f\n\n    return wrap\n'"
horovod/run/util/lsf.py,0,"b'# Copyright IBM Corp. 2020. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\nimport os\n\nimport yaml\n\nfrom horovod.common.util import _cache\nfrom horovod.run.common.util import safe_shell_exec\n\n\nclass LSFUtils:\n    """"""LSF Utilities""""""\n    _CSM_ALLOCATION_QUERY = ""/opt/ibm/csm/bin/csm_allocation_query""\n    _CSM_NODE_QUERY = ""/opt/ibm/csm/bin/csm_node_attributes_query""\n    _LSCPU_CMD = ""LANG=en_US.utf8 lscpu""\n    _THREAD_KEY= ""Thread(s) per core""\n    _csm_allocation_info = {}\n\n    @staticmethod\n    def using_lsf():\n        """"""Returns True if LSF was used to start the current process.""""""\n        return ""LSB_JOBID"" in os.environ\n\n    @staticmethod\n    def get_allocation_info():\n        """"""Returns and sets the static CSM allocation info.""""""\n        if not LSFUtils._csm_allocation_info:\n            lsf_allocation_id = os.environ[""CSM_ALLOCATION_ID""].strip()\n            output = io.StringIO()\n            exit_code = safe_shell_exec.execute(""{cmd} -a {allocation}"".format(\n                cmd=LSFUtils._CSM_ALLOCATION_QUERY, allocation=lsf_allocation_id),\n                stdout=output, stderr=output)\n            if exit_code != 0:\n                raise RuntimeError(\n                    ""{cmd} failed with exit code {exit_code}"".format(\n                        cmd=LSFUtils._CSM_ALLOCATION_QUERY, exit_code=exit_code))\n            LSFUtils._csm_allocation_info = yaml.safe_load(output.getvalue())\n            # Fetch the total number of cores and gpus for the first host\n            output = io.StringIO()\n            exit_code = safe_shell_exec.execute(""{cmd} -n {node}"".format(\n                cmd=LSFUtils._CSM_NODE_QUERY,\n                node=LSFUtils._csm_allocation_info[""compute_nodes""][0]),\n                stdout=output, stderr=output)\n            if exit_code != 0:\n                raise RuntimeError(\n                    ""{cmd} failed with exit code {exit_code}"".format(\n                        cmd=LSFUtils._CSM_NODE_QUERY, exit_code=exit_code))\n            node_output = yaml.safe_load(output.getvalue())\n            total_core_count = (int(node_output[""Record_1""][""discovered_cores""]) -\n                               int(node_output[""Record_1""][""discovered_sockets""]) * LSFUtils._csm_allocation_info[""isolated_cores""])\n            LSFUtils._csm_allocation_info[""compute_node_cores""]= total_core_count\n            LSFUtils._csm_allocation_info[""compute_node_gpus""] = int(node_output[""Record_1""][""discovered_gpus""])\n            # Sorting LSF hostnames\n            LSFUtils._csm_allocation_info[""compute_nodes""].sort()\n        return LSFUtils._csm_allocation_info\n\n    @staticmethod\n    def get_compute_hosts():\n        """"""Returns the list of LSF compute hosts.""""""\n        return LSFUtils.get_allocation_info()[""compute_nodes""]\n\n    @staticmethod\n    def get_num_cores():\n        """"""Returns the number of cores per node.""""""\n        return LSFUtils.get_allocation_info()[""compute_node_cores""]\n\n    @staticmethod\n    def get_num_gpus():\n        """"""Returns the number of gpus per node.""""""\n        return LSFUtils.get_allocation_info()[""compute_node_gpus""]\n\n    @staticmethod\n    @_cache\n    def get_num_processes():\n        """"""Returns the total number of processes.""""""\n        return len(LSFUtils.get_compute_hosts()) * LSFUtils.get_num_gpus()\n\n    @staticmethod\n    @_cache\n    def get_num_threads():\n        """"""Returns the number of hardware threads.""""""\n        lscpu_cmd = \'ssh -o StrictHostKeyChecking=no {host} {cmd}\'.format(\n            host=LSFUtils.get_compute_hosts()[0],\n            cmd=LSFUtils._LSCPU_CMD\n        )\n        output = io.StringIO()\n        exit_code = safe_shell_exec.execute(lscpu_cmd, stdout=output, stderr=output)\n        if exit_code != 0:\n            raise RuntimeError(""{cmd} failed with exit code {exit_code}"".format(\n                cmd=lscpu_cmd, exit_code=exit_code))\n        return int(yaml.safe_load(output.getvalue())[LSFUtils._THREAD_KEY])\n'"
horovod/run/util/network.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \'License\');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \'AS IS\' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport psutil\nimport random\nimport socket\n\nfrom socket import AF_INET\nfrom psutil import net_if_addrs\n\nfrom horovod.common.util import _cache\nfrom horovod.run.util import threads\n\n\n@_cache\ndef get_local_host_addresses():\n    local_addresses = set()\n    for intf_info_list in psutil.net_if_addrs().values():\n        for intf_info in intf_info_list:\n            if intf_info.family == socket.AF_INET:\n                local_addresses.add(intf_info.address)\n    return local_addresses\n\n\ndef get_local_intfs(nic=None):\n    common_intfs = set()\n    for iface, addrs in net_if_addrs().items():\n        if nic and iface != nic:\n            continue\n        for addr in addrs:\n            if addr.family == AF_INET and addr.address == \'127.0.0.1\':\n                common_intfs.add(iface)\n                break\n    return common_intfs\n\n\ndef resolve_host_address(host_name):\n    try:\n        return socket.gethostbyname(host_name)\n    except socket.gaierror:\n        return None\n\n\ndef filter_local_addresses(all_host_names):\n    local_addresses = get_local_host_addresses()\n\n    args_list = [[host] for host in all_host_names]\n    host_addresses = threads.execute_function_multithreaded(\n        resolve_host_address, args_list)\n\n    # host_addresses is a map\n    remote_host_names = []\n    for i in range(len(all_host_names)):\n        host_address = host_addresses[i]\n        host_name = all_host_names[i]\n\n        if not host_address or host_address not in local_addresses:\n            remote_host_names.append(host_name)\n\n    return remote_host_names\n\n\n# Given server factory, find a usable port\ndef find_port(server_factory):\n    min_port = 1024\n    max_port = 65536\n    num_ports = max_port - min_port\n    start_port = random.randrange(0, num_ports)\n    for port_offset in range(num_ports):\n        try:\n            port = min_port + (start_port + port_offset) % num_ports\n            addr = (\'\', port)\n            server = server_factory(addr)\n            return server, port\n        except Exception as e:\n            pass\n\n    raise Exception(\'Unable to find a port to bind to.\')\n\n\ndef get_driver_ip(nics):\n    """"""\n    :param nics: object return by `_driver_fn`\n    :return: driver ip. We make sure all workers can connect to this ip.\n    """"""\n    iface = list(nics)[0]\n    driver_ip = None\n    for addr in net_if_addrs()[iface]:\n        if addr.family == AF_INET:\n            driver_ip = addr.address\n\n    if not driver_ip:\n        raise RuntimeError(\n            \'Cannot find an IPv4 address of the common interface.\')\n\n    return driver_ip\n\n'"
horovod/run/util/threads.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport queue\nimport threading\n\n\ndef execute_function_multithreaded(fn,\n                                   args_list,\n                                   block_until_all_done=True,\n                                   max_concurrent_executions=1000):\n    """"""\n    Executes fn in multiple threads each with one set of the args in the\n    args_list.\n    :param fn: function to be executed\n    :type fn:\n    :param args_list:\n    :type args_list: list(list)\n    :param block_until_all_done: if is True, function will block until all the\n    threads are done and will return the results of each thread\'s execution.\n    :type block_until_all_done: bool\n    :param max_concurrent_executions:\n    :type max_concurrent_executions: int\n    :return:\n    If block_until_all_done is False, returns None. If block_until_all_done is\n    True, function returns the dict of results.\n        {\n            index: execution result of fn with args_list[index]\n        }\n    :rtype: dict\n    """"""\n    result_queue = queue.Queue()\n    worker_queue = queue.Queue()\n\n    for i, arg in enumerate(args_list):\n        arg.append(i)\n        worker_queue.put(arg)\n\n    def fn_execute():\n        while True:\n            try:\n                arg = worker_queue.get(block=False)\n            except queue.Empty:\n                return\n            exec_index = arg[-1]\n            res = fn(*arg[:-1])\n            result_queue.put((exec_index, res))\n\n    threads = []\n    number_of_threads = min(max_concurrent_executions, len(args_list))\n\n    for _ in range(number_of_threads):\n        thread = in_thread(target=fn_execute, daemon=not block_until_all_done)\n        threads.append(thread)\n\n    # Returns the results only if block_until_all_done is set.\n    results = None\n    if block_until_all_done:\n\n        # Because join() cannot be interrupted by signal, a single join()\n        # needs to be separated into join()s with timeout in a while loop.\n        have_alive_child = True\n        while have_alive_child:\n            have_alive_child = False\n            for t in threads:\n                t.join(0.1)\n                if t.is_alive():\n                    have_alive_child = True\n\n        results = {}\n        while not result_queue.empty():\n            item = result_queue.get()\n            results[item[0]] = item[1]\n\n        if len(results) != len(args_list):\n            raise RuntimeError(\n                \'Some threads for func {func} did not complete \'\n                \'successfully.\'.format(func=fn.__name__))\n    return results\n\n\ndef in_thread(target, args=(), name=None, daemon=True, silent=False):\n    """"""\n    Executes the given function in background.\n    :param target: function\n    :param args: function arguments\n    :param name: name of the thread\n    :param daemon: run as daemon thread, do not block until thread is doe\n    :param silent: swallows exceptions raised by target silently\n    :return background thread\n    """"""\n    if not isinstance(args, tuple):\n        raise ValueError(\'args must be a tuple, not {}, for a single argument use (arg,)\'\n                         .format(type(args)))\n\n    if silent:\n        def fn(*args):\n            try:\n                target(*args)\n            except:\n                pass\n    else:\n        fn = target\n\n    bg = threading.Thread(target=fn, args=args, name=name)\n    bg.daemon = daemon\n    bg.start()\n    return bg\n\n\ndef on_event(event, func, args=(), stop=None, check_interval_seconds=1.0, silent=False):\n    """"""\n    Executes the given function in a separate thread when event is set.\n    That threat can be stopped by setting the optional stop event.\n    The stop event is check regularly every check_interval_seconds.\n    Exceptions will silently be swallowed when silent is True.\n\n    :param event: event that triggers func\n    :type event: threading.Event\n    :param func: function to trigger\n    :param args: function arguments\n    :param stop: event to stop thread\n    :type stop: threading.Event\n    :param check_interval_seconds: interval in seconds to check the stop event\n    :type check_interval_seconds: float\n    :param silent: swallows exceptions raised by target silently\n    :return: thread\n    """"""\n    if not isinstance(args, tuple):\n        raise ValueError(\'args must be a tuple, not {}, for a single argument use (arg,)\'\n                         .format(type(args)))\n\n    if stop is None:\n        def fn():\n            event.wait()\n            func(*args)\n    else:\n        def fn():\n            while not event.is_set() and not stop.is_set():\n                event.wait(timeout=check_interval_seconds)\n            if not stop.is_set():\n                func(*args)\n\n    return in_thread(fn, silent=silent)\n'"
horovod/spark/common/__init__.py,0,b''
horovod/spark/common/_namedtuple_fix.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n# Workaround for https://issues.apache.org/jira/browse/SPARK-22674\n# This fix also requires the user to make this same change at the top of their\n# training script before importing pyspark (on serialization).\nimport collections\ncollections.namedtuple.__hijack = 1\n'"
horovod/spark/common/backend.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nimport os\n\nimport pyspark\n\nimport horovod.spark\n\n\ndef default_num_proc():\n    spark_context = pyspark.SparkContext._active_spark_context\n    return spark_context.defaultParallelism\n\n\nclass Backend(object):\n    """"""Interface for remote execution of the distributed training function.\n\n    A custom backend can be used in cases where the training environment running Horovod is different\n    from the Spark application running the HorovodEstimator.\n    """"""\n\n    def run(self, fn, args=(), kwargs={}, env=None):\n        """"""Executes the training `fn` and returns results from each worker in a list (ordered by ascending rank).\n\n        Args:\n            fn: Function to run.\n            args: Arguments to pass to `fn`.\n            kwargs: Keyword arguments to pass to `fn`.\n            env: Environment dictionary to use in Horovod run.  Defaults to `os.environ`.\n\n        Returns:\n            List of results returned by running `fn` on each rank.\n        """"""\n        raise NotImplementedError()\n\n    def num_processes(self):\n        """"""Returns the number of processes to use for training.""""""\n        raise NotImplementedError()\n\n\nclass SparkBackend(Backend):\n    """"""Uses `horovod.spark.run` to execute the distributed training `fn`.""""""\n\n    def __init__(self, num_proc=None, env=None, **kwargs):\n        """"""\n        Args:\n            num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.\n            env: Environment dictionary to use in Horovod run.  Defaults to `os.environ`.\n            **kwargs: Additional arguments passed to `horovod.spark.run` at training time.\n        """"""\n        self._num_proc = num_proc or default_num_proc()\n        self._env = env\n        self._kwargs = kwargs\n\n    def run(self, fn, args=(), kwargs={}, env=None):\n        full_env = self._env or os.environ.copy()\n        if env:\n            full_env.update(env)\n\n        if \'CUDA_VISIBLE_DEVICES\' in full_env:\n            # In TensorFlow 2.0, we set this before calling `run` in order to prevent TensorFlow\n            # from allocating memory on the GPU outside the training process.  Once we submit the\n            # function for execution, we want to ensure that TensorFLow has visibility into GPUs on\n            # the device so we can use them for training, which is why we need to unset this.\n            # See https://github.com/tensorflow/tensorflow/issues/33168\n            del full_env[\'CUDA_VISIBLE_DEVICES\']\n\n        return horovod.spark.run(fn, args=args, kwargs=kwargs,\n                                 num_proc=self._num_proc, env=full_env,\n                                 **self._kwargs)\n\n    def num_processes(self):\n        return self._num_proc\n'"
horovod/spark/common/cache.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport collections\nimport contextlib\nimport threading\n\n\nclass TrainingDataCache(object):\n    def __init__(self):\n        self.lock = threading.Lock()\n        self._reset()\n\n    def create_key(self, df, store, validation):\n        return df.__hash__(), store.get_train_data_path(), store.get_val_data_path(), validation\n\n    @contextlib.contextmanager\n    def use_key(self, key):\n        self._keys_in_use[key] += 1\n        try:\n            yield\n        finally:\n            self._keys_in_use[key] -= 1\n\n    def next_dataset_index(self, key):\n        """"""Finds the next available `dataset_idx` given a key.\n\n        Indices start a 0 and go up until the first unused index is found.\n\n        Will attempt to reuse earlier indices if they are no longer in use. This balances between\n        supporting multiple concurrent datasets being trained at once (multiple dataset indices),\n        and avoiding overuse of disk space (reclaiming unused datasets when no longer needed).\n\n        NOTE: this method is not thread-safe. You must wrap usage with `cache.lock` if using\n        in a multi-threaded setting (see `prepare_data`).\n        """"""\n        idx = 0\n        while True:\n            last_key = self._dataset_to_key.get(idx)\n            if self._keys_in_use[last_key] > 0:\n                # Paths are in use, try the next index\n                idx += 1\n                continue\n\n            self._dataset_to_key[idx] = key\n            self._key_to_dataset[key] = idx\n            return idx\n\n    def get_dataset(self, key):\n        return self._key_to_dataset[key]\n\n    def get_dataset_properties(self, dataset_idx):\n        return self._dataset_properties[dataset_idx]\n\n    def set_dataset_properties(self, dataset_idx, props):\n        self._dataset_properties[dataset_idx] = props\n\n    def is_cached(self, key, store):\n        """"""Returns true if the key is in the cache and its paths exist in the store already.""""""\n        if key not in self._key_to_dataset:\n            return False\n\n        dataset_idx = self._key_to_dataset[key]\n        _, _, _, validation = key\n        train_data_path = store.get_train_data_path(dataset_idx)\n        val_data_path = store.get_val_data_path(dataset_idx)\n\n        return self._keys_in_use[key] > 0 and \\\n            self._dataset_to_key.get(dataset_idx) == key and \\\n            store.is_parquet_dataset(train_data_path) and \\\n            (not validation or store.is_parquet_dataset(val_data_path))\n\n    def clear(self):\n        self._reset()\n\n    def _reset(self):\n        with self.lock:\n            self._keys_in_use = collections.Counter()\n            self._key_to_dataset = {}\n            self._dataset_to_key = {}\n            self._dataset_properties = {}\n'"
horovod/spark/common/constants.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nPETASTORM_HDFS_DRIVER = \'libhdfs\'\nMETRIC_PRINT_FREQUENCY = 1000  # to print metric every 1000 steps in verbose mode\n\nARRAY = \'array\'\nCUSTOM_SPARSE = \'custom_sparse_format\'\nNOCHANGE = \'nochange\'\n\nMIXED_SPARSE_DENSE_VECTOR = \'mixed_sparse_dense_vector\'\nSPARSE_VECTOR = \'sparse_vector\'\nDENSE_VECTOR = \'dense_vector\'\n\nTOTAL_BUFFER_MEMORY_CAP_GIB = 4\nBYTES_PER_GIB = 1073741824\n'"
horovod/spark/common/estimator.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nfrom pyspark.ml import Estimator, Model\n\nfrom horovod.spark.common import util\nfrom horovod.spark.common.backend import SparkBackend\nfrom horovod.spark.common.params import EstimatorParams, ModelParams\n\n\nclass HorovodEstimator(Estimator, EstimatorParams):\n    def fit(self, df, params=None):\n        """"""Fits the model to the DataFrame.\n\n        Args:\n            df: Input dataset, which is an instance of :py:class:`pyspark.sql.DataFrame`.\n            params: An optional param map that overrides embedded params.\n        Returns:\n            `HorovodModel` transformer wrapping the trained model.\n        """"""\n        return super(HorovodEstimator, self).fit(df, params)\n\n    def fit_on_parquet(self, params=None):\n        """"""Trains the model on a saved Parquet file at `store.get_train_path()`.\n\n        Args:\n            params: An optional param map that overrides embedded params.\n\n        Returns:\n            Trained HorovodModel transformer of the appropriate subclass wrapping the trained model.\n        """"""\n        if params:\n            return self.copy(params)._fit_on_parquet()\n        return self._fit_on_parquet()\n\n    def _fit_on_parquet(self):\n        backend = self._get_or_create_backend()\n        store = self.getStore()\n        label_columns = self.getLabelCols()\n        feature_columns = self.getFeatureCols()\n        sample_weight_col = self.getSampleWeightCol()\n\n        train_rows, val_rows, metadata, avg_row_size = \\\n            util.get_simple_meta_from_parquet(store,\n                                              label_columns=label_columns,\n                                              feature_columns=feature_columns,\n                                              sample_weight_col=sample_weight_col)\n\n        return self._fit_on_prepared_data(backend, train_rows, val_rows, metadata, avg_row_size)\n\n    def _fit(self, df):\n        backend = self._get_or_create_backend()\n        with util.prepare_data(backend.num_processes(),\n                               self.getStore(),\n                               df,\n                               label_columns=self.getLabelCols(),\n                               feature_columns=self.getFeatureCols(),\n                               validation=self.getValidation(),\n                               sample_weight_col=self.getSampleWeightCol(),\n                               compress_sparse=self.getCompressSparseCols(),\n                               partitions_per_process=self.getPartitionsPerProcess(),\n                               verbose=self.getVerbose()) as dataset_idx:\n            train_rows, val_rows, metadata, avg_row_size = util.get_dataset_properties(dataset_idx)\n            self._check_metadata_compatibility(metadata)\n            return self._fit_on_prepared_data(\n                backend, train_rows, val_rows, metadata, avg_row_size, dataset_idx)\n\n    def _get_or_create_backend(self):\n        backend = self.getBackend()\n        if backend is None:\n            backend = SparkBackend(self.getNumProc(), verbose=self.getVerbose())\n        elif self.getNumProc() is not None:\n            raise ValueError(\'At most one of parameters ""backend"" and ""num_proc"" may be specified\')\n        return backend\n\n    def _has_checkpoint(self, run_id):\n        store = self.getStore()\n        last_ckpt_path = store.get_checkpoint_path(run_id)\n        return last_ckpt_path is not None and store.exists(last_ckpt_path)\n\n\nclass HorovodModel(Model, ModelParams):\n    def transform(self, df, params=None):\n        """"""\n        Transforms the input dataset with prediction columns representing model predictions.\n\n        Prediction column names default to <label_column>__output. Override column names\n        by calling `transformer.setOutputCols(col_names)`.\n\n        Args:\n            df: Input dataset, which is an instance of :py:class:`pyspark.sql.DataFrame`.\n            params: An optional param map that overrides embedded params.\n\n        Returns:\n            Transformed dataset.\n        """"""\n        return super(HorovodModel, self).transform(df, params)\n'"
horovod/spark/common/params.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nfrom pyspark import keyword_only\nfrom pyspark.ml.param.shared import HasOutputCols, Param, Params, TypeConverters\n\nfrom horovod.spark.common import util\n\n\nclass EstimatorParams(Params):\n    num_proc = Param(Params._dummy(), \'num_proc\', \'number of processes\')\n    train_reader_num_workers = Param(Params._dummy(),\n                                     \'train_reader_num_workers\',\n                                     \'number of parallel worker processes to read train data\')\n    val_reader_num_workers = Param(Params._dummy(), \'val_reader_num_workers\',\n                                   \'number of parallel worker processes to read validation data\')\n    optimizer = Param(Params._dummy(), \'optimizer\', \'optimizer\')\n    model = Param(Params._dummy(), \'model\', \'model\')\n    backend = Param(Params._dummy(), \'backend\', \'backend\')\n    store = Param(Params._dummy(), \'store\', \'store\')\n    metrics = Param(Params._dummy(), \'metrics\', \'metrics\')\n    loss = Param(Params._dummy(), \'loss\', \'loss\')\n\n    gradient_compression = Param(Params._dummy(), \'gradient_compression\', \'Horovod gradient compression option\')\n    compress_sparse_cols = Param(Params._dummy(),\n                                 \'compress_sparse_cols\',\n                                 \'flag indicating whether SparseVector columns should be compressed. \'\n                                 \'requires additional compute time but saves intermediate disk space. \'\n                                 \'recommended to avoid unless using a lot of sparse data\',\n                                 typeConverter=TypeConverters.toBoolean)\n\n    loss_weights = Param(Params._dummy(), \'loss_weights\', \'loss weights\',\n                         typeConverter=TypeConverters.toListFloat)\n    sample_weight_col = Param(Params._dummy(), \'sample_weight_col\',\n                              \'name of the column containing sample weights\',\n                              typeConverter=TypeConverters.toString)\n    feature_cols = Param(Params._dummy(), ""feature_cols"", ""feature column names"",\n                         typeConverter=TypeConverters.toListString)\n    label_cols = Param(Params._dummy(), \'label_cols\', \'label column names\',\n                       typeConverter=TypeConverters.toListString)\n    validation = Param(Params._dummy(), \'validation\',\n                       \'one of: float validation split [0, 1), or string validation column name\',\n                       typeConverter=TypeConverters.toString)\n    callbacks = Param(Params._dummy(), \'callbacks\', \'callbacks\')\n    batch_size = Param(Params._dummy(), \'batch_size\', \'batch size\',\n                       typeConverter=TypeConverters.toInt)\n    epochs = Param(Params._dummy(), \'epochs\', \'epochs\', typeConverter=TypeConverters.toInt)\n    train_steps_per_epoch = Param(Params._dummy(), \'train_steps_per_epoch\',\n                                  \'number of training (batches) steps per epoch\',\n                                  typeConverter=TypeConverters.toInt)\n    validation_steps_per_epoch = Param(Params._dummy(), \'validation_steps_per_epoch\',\n                                       \'number of steps (batches) for validation per epoch\',\n                                       typeConverter=TypeConverters.toInt)\n\n    shuffle_buffer_size = Param(Params._dummy(),\n                                \'shuffle_buffer_size\',\n                                \'shuffling buffer size of data before training in number of samples\',\n                                typeConverter=TypeConverters.toInt)\n\n    verbose = Param(Params._dummy(), \'verbose\', \'verbose flag (0=silent, 1=enabled, other values used by frameworks)\',\n                    typeConverter=TypeConverters.toInt)\n\n    partitions_per_process = Param(Params._dummy(), \'partitions_per_process\',\n                                   \'partitions for parquet form of the DataFrame per process\',\n                                   typeConverter=TypeConverters.toInt)\n\n    run_id = Param(Params._dummy(), \'run_id\',\n                   \'unique ID for this run, if run already exists, \'\n                   \'then training will resume from last checkpoint in the store\',\n                   typeConverter=TypeConverters.toString)\n\n    transformation_fn = Param(Params._dummy(), \'transformation_fn\',\n                              \'functions that construct the transformation \'\n                              \'function that applies custom transformations to \'\n                              \'every batch before train and validation steps\')\n\n    def __init__(self):\n        super(EstimatorParams, self).__init__()\n\n        self._setDefault(\n            num_proc=None,\n            store=None,\n            backend=None,\n            model=None,\n            optimizer=None,\n            loss=None,\n            loss_weights=None,\n            sample_weight_col=None,\n            metrics=[],\n            feature_cols=None,\n            label_cols=None,\n            validation=None,\n            gradient_compression=None,\n            compress_sparse_cols=False,\n            batch_size=32,\n            epochs=1,\n            verbose=1,\n            callbacks=[],\n            shuffle_buffer_size=None,\n            partitions_per_process=10,\n            run_id=None,\n            train_steps_per_epoch=None,\n            validation_steps_per_epoch=None,\n            transformation_fn=None,\n            train_reader_num_workers=2,\n            val_reader_num_workers=2)\n\n    def _check_params(self, metadata):\n        model = self.getModel()\n        if not model:\n            raise ValueError(\'Model parameter is required\')\n\n        util.check_validation(self.getValidation())\n\n        feature_columns = self.getFeatureCols()\n        missing_features = [col for col in feature_columns if col not in metadata]\n        if missing_features:\n            raise ValueError(\'Feature columns {} not found in training DataFrame metadata\'\n                             .format(missing_features))\n\n        label_columns = self.getLabelCols()\n        missing_labels = [col for col in label_columns if col not in metadata]\n        if missing_labels:\n            raise ValueError(\'Label columns {} not found in training DataFrame metadata\'\n                             .format(missing_labels))\n\n    @keyword_only\n    def setParams(self, **kwargs):\n        return self._set(**kwargs)\n\n    def setNumProc(self, value):\n        return self._set(num_proc=value)\n\n    def getNumProc(self):\n        return self.getOrDefault(self.num_proc)\n\n    def setModel(self, value):\n        return self._set(model=value)\n\n    def getModel(self):\n        return self.getOrDefault(self.model)\n\n    def setBackend(self, value):\n        return self._set(backend=value)\n\n    def getBackend(self):\n        return self.getOrDefault(self.backend)\n\n    def setStore(self, value):\n        return self._set(store=value)\n\n    def getStore(self):\n        return self.getOrDefault(self.store)\n\n    def setLoss(self, value):\n        return self._set(loss=value)\n\n    def getLoss(self):\n        return self.getOrDefault(self.loss)\n\n    def setLossWeights(self, value):\n        return self._set(loss_weights=value)\n\n    def getLossWeights(self):\n        return self.getOrDefault(self.loss_weights)\n\n    def setSampleWeightCol(self, value):\n        return self._set(sample_weight_col=value)\n\n    def getSampleWeightCol(self):\n        return self.getOrDefault(self.sample_weight_col)\n\n    def setMetrics(self, value):\n        return self._set(metrics=value)\n\n    def getMetrics(self):\n        return self.getOrDefault(self.metrics)\n\n    def setFeatureCols(self, value):\n        return self._set(feature_cols=value)\n\n    def getFeatureCols(self):\n        return self.getOrDefault(self.feature_cols)\n\n    def setLabelCols(self, value):\n        return self._set(label_cols=value)\n\n    def getLabelCols(self):\n        return self.getOrDefault(self.label_cols)\n\n    def setValidation(self, value):\n        return self._set(validation=value)\n\n    def getValidation(self):\n        return self.getOrDefault(self.validation)\n\n    def setCallbacks(self, value):\n        return self._set(callbacks=value)\n\n    def getCallbacks(self):\n        return self.getOrDefault(self.callbacks)\n\n    def setBatchSize(self, value):\n        return self._set(batch_size=value)\n\n    def getBatchSize(self):\n        return self.getOrDefault(self.batch_size)\n\n    def setEpochs(self, value):\n        return self._set(epochs=value)\n\n    def getEpochs(self):\n        return self.getOrDefault(self.epochs)\n\n    def setTrainStepsPerEpoch(self, value):\n        return self._set(train_steps_per_epoch=value)\n\n    def getTrainStepsPerEpoch(self):\n        return self.getOrDefault(self.train_steps_per_epoch)\n\n    def setValidationStepsPerEpoch(self, value):\n        return self._set(validation_steps_per_epoch=value)\n\n    def getValidationStepsPerEpoch(self):\n        return self.getOrDefault(self.validation_steps_per_epoch)\n\n    def setVerbose(self, value):\n        return self._set(verbose=value)\n\n    def getVerbose(self):\n        return self.getOrDefault(self.verbose)\n\n    def setGradientCompression(self, value):\n        return self._set(gradient_compression=value)\n\n    def getGradientCompression(self):\n        return self.getOrDefault(self.gradient_compression)\n\n    def setCompressSparseCols(self, value):\n        return self._set(compress_sparse_cols=value)\n\n    def getCompressSparseCols(self):\n        return self.getOrDefault(self.compress_sparse_cols)\n\n    def setShufflingBufferSize(self, value):\n        return self._set(shuffle_buffer_size=value)\n\n    def getShufflingBufferSize(self):\n        return self.getOrDefault(self.shuffle_buffer_size)\n\n    def setOptimizer(self, value):\n        return self._set(optimizer=value)\n\n    def getOptimizer(self):\n        return self.getOrDefault(self.optimizer)\n\n    def setPartitionsPerProcess(self, value):\n        return self._set(partitions_per_process=value)\n\n    def getPartitionsPerProcess(self):\n        return self.getOrDefault(self.partitions_per_process)\n\n    def setRunId(self, value):\n        return self._set(run_id=value)\n\n    def getRunId(self):\n        return self.getOrDefault(self.run_id)\n\n    def setTransformationFn(self, value):\n        return self._set(transformation_fn=value)\n\n    def getTransformationFn(self):\n        return self.getOrDefault(self.transformation_fn)\n\n    def setTrainReaderNumWorker(self, value):\n        return self._set(train_reader_num_workers=value)\n\n    def getTrainReaderNumWorker(self):\n        return self.getOrDefault(self.train_reader_num_workers)\n\n    def setValReaderNumWorker(self, value):\n        return self._set(val_reader_num_workers=value)\n\n    def getValReaderNumWorker(self):\n        return self.getOrDefault(self.val_reader_num_workers)\n\n\nclass ModelParams(HasOutputCols):\n    history = Param(Params._dummy(), \'history\', \'history\')\n    model = Param(Params._dummy(), \'model\', \'model\')\n    feature_columns = Param(Params._dummy(), \'feature_columns\', \'feature columns\')\n    label_columns = Param(Params._dummy(), \'label_columns\', \'label columns\')\n    run_id = Param(Params._dummy(), \'run_id\',\n                   \'unique ID for the run that generated this model, if no ID was given by the \'\n                   \'user, defaults to current timestamp at the time of fit()\',\n                   typeConverter=TypeConverters.toString)\n    _metadata = Param(Params._dummy(), \'_metadata\',\n                      \'metadata contains the shape and type of input and output\')\n\n    def __init__(self):\n        super(ModelParams, self).__init__()\n\n    # Only for internal use\n    def _get_metadata(self):\n        return self.getOrDefault(self._metadata)\n\n    @keyword_only\n    def setParams(self, **kwargs):\n        return self._set(**kwargs)\n\n    def setHistory(self, value):\n        return self._set(history=value)\n\n    def getHistory(self):\n        return self.getOrDefault(self.history)\n\n    def setModel(self, value):\n        return self._set(model=value)\n\n    def getModel(self):\n        return self.getOrDefault(self.model)\n\n    def setFeatureColumns(self, value):\n        return self._set(feature_columns=value)\n\n    def getFeatureColumns(self):\n        return self.getOrDefault(self.feature_columns)\n\n    def setLabelColoumns(self, value):\n        return self._set(label_columns=value)\n\n    def getLabelColumns(self):\n        return self.getOrDefault(self.label_columns)\n\n    def setRunId(self, value):\n        return self._set(run_id=value)\n\n    def getRunId(self):\n        return self.getOrDefault(self.run_id)\n\n    # copied from https://github.com/apache/spark/tree/master/python/pyspark/ml/param/shared.py\n    # has been removed from pyspark.ml.param.HasOutputCol in pyspark 3.0.0\n    # added here to keep ModelParams API consistent between pyspark 2 and 3\n    # https://github.com/apache/spark/commit/b19fd487dfe307542d65391fd7b8410fa4992698#diff-3d1fb305acc7bab18e5d91f2b69018c7\n    # https://github.com/apache/spark/pull/26232\n    # https://issues.apache.org/jira/browse/SPARK-29093\n    def setOutputCols(self, value):\n        """"""\n        Sets the value of :py:attr:`outputCols`.\n        """"""\n        return self._set(outputCols=value)\n'"
horovod/spark/common/serialization.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport json\nimport os\nimport time\n\nfrom pyspark.ml.util import DefaultParamsWriter, DefaultParamsReader\n\n\nclass HorovodParamsWriter(DefaultParamsWriter):\n    @staticmethod\n    def saveMetadata(instance, path, sc, extraMetadata=None, paramMap=None,\n                     param_serializer_fn=None):\n        metadata_path = os.path.join(path, ""metadata"")\n        metadata_json = HorovodParamsWriter. \\\n            _get_metadata_to_save(instance,\n                                  sc,\n                                  extraMetadata,\n                                  paramMap,\n                                  param_serializer_fn)\n        sc.parallelize([metadata_json], 1).saveAsTextFile(metadata_path)\n\n    @staticmethod\n    def _get_metadata_to_save(instance, sc, extra_metadata=None, param_map=None,\n                              param_serializer_fn=None):\n        uid = instance.uid\n        cls = instance.__module__ + \'.\' + instance.__class__.__name__\n\n        # User-supplied param values\n        params = instance._paramMap\n        json_params = {}\n        if param_map is not None:\n            json_params = param_map\n        else:\n            for p, param_val in params.items():\n                # If param is not json serializable, convert it into serializable object\n                json_params[p.name] = param_serializer_fn(p.name, param_val)\n\n        # Default param values\n        json_default_params = {}\n        for p, param_val in instance._defaultParamMap.items():\n            json_default_params[p.name] = param_serializer_fn(p.name,\n                                                              param_val)\n\n        basic_metadata = {""class"": cls, ""timestamp"": int(round(time.time() * 1000)),\n                          ""sparkVersion"": sc.version, ""uid"": uid, ""paramMap"": json_params,\n                          ""defaultParamMap"": json_default_params}\n        if extra_metadata is not None:\n            basic_metadata.update(extra_metadata)\n        return json.dumps(basic_metadata, separators=[\',\', \':\'])\n\n\nclass HorovodParamsReader(DefaultParamsReader):\n    def load(self, path):\n        metadata = DefaultParamsReader.loadMetadata(path, self.sc)\n        metadata[\'paramMap\'] = self._deserialize_dict(metadata[\'paramMap\'])\n        metadata[\'defaultParamMap\'] = self._deserialize_dict(metadata[\'defaultParamMap\'])\n\n        py_type = DefaultParamsReader._DefaultParamsReader__get_class(metadata[\'class\'])\n        instance = py_type()\n        instance._resetUid(metadata[\'uid\'])\n        DefaultParamsReader.getAndSetParams(instance, metadata)\n        return instance\n'"
horovod/spark/common/store.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport contextlib\nimport errno\nimport os\nimport re\nimport shutil\nimport tempfile\n\nfrom distutils.version import LooseVersion\n\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\n\nclass Store(object):\n    """"""\n    Storage layer for intermediate files (materialized DataFrames) and training artifacts (checkpoints, logs).\n\n    Store provides an abstraction over a filesystem (e.g., local vs HDFS) or blob storage database. It provides the\n    basic semantics for reading and writing objects, and how to access objects with certain definitions.\n\n    The store exposes a generic interface that is not coupled to a specific DataFrame, model, or runtime. Every run\n    of an Estimator should result in a separate run directory containing checkpoints and logs, and every variation\n    in dataset should produce a separate intermediate data path.\n\n    In order to allow for caching but to prevent overuse of disk space on intermediate data, intermediate datasets\n    are named in a deterministic sequence. When a dataset is done being used for training, the intermediate files\n    can be reclaimed to free up disk space, but will not be automatically removed so that they can be reused as\n    needed. This is to support both parallel training processes using the same store on multiple DataFrames, as well\n    as iterative training using the same DataFrame on different model variations.\n    """"""\n    def __init__(self):\n        self._train_data_to_key = {}\n        self._val_data_to_key = {}\n\n    def is_parquet_dataset(self, path):\n        """"""Returns True if the path is the root of a Parquet dataset.""""""\n        raise NotImplementedError()\n\n    def get_parquet_dataset(self, path):\n        """"""Returns a :py:class:`pyarrow.parquet.ParquetDataset` from the path.""""""\n        raise NotImplementedError()\n\n    def get_train_data_path(self, idx=None):\n        """"""Returns the path to the training dataset.""""""\n        raise NotImplementedError()\n\n    def get_val_data_path(self, idx=None):\n        """"""Returns the path to the validation dataset.""""""\n        raise NotImplementedError()\n\n    def get_test_data_path(self, idx=None):\n        """"""Returns the path to the test dataset.""""""\n        raise NotImplementedError()\n\n    def saving_runs(self):\n        """"""Returns True if run output should be saved during training.""""""\n        raise NotImplementedError()\n\n    def get_runs_path(self):\n        """"""Returns the base path for all runs.""""""\n        raise NotImplementedError()\n\n    def get_run_path(self, run_id):\n        """"""Returns the path to the run with the given ID.""""""\n        raise NotImplementedError()\n\n    def get_checkpoint_path(self, run_id):\n        """"""Returns the path to the checkpoint file for the given run.""""""\n        raise NotImplementedError()\n\n    def get_logs_path(self, run_id):\n        """"""Returns the path to the log directory for the given run.""""""\n        raise NotImplementedError()\n\n    def get_checkpoint_filename(self):\n        """"""Returns the basename of the saved checkpoint file.""""""\n        raise NotImplementedError()\n\n    def get_logs_subdir(self):\n        """"""Returns the subdirectory name for the logs directory.""""""\n        raise NotImplementedError()\n\n    def exists(self, path):\n        """"""Returns True if the path exists in the store.""""""\n        raise NotImplementedError()\n\n    def read(self, path):\n        """"""Returns the contents of the path as bytes.""""""\n        raise NotImplementedError()\n\n    def get_local_output_dir_fn(self, run_id):\n        raise NotImplementedError()\n\n    def sync_fn(self, run_id):\n        """"""Returns a function that synchronises given path recursively into run path for `run_id`.""""""\n        raise NotImplementedError()\n\n    def to_remote(self, run_id, dataset_idx):\n        """"""Returns a view of the store that can execute in a remote environment without Horoovd deps.""""""\n        attrs = self._remote_attrs(run_id, dataset_idx)\n\n        class RemoteStore(object):\n            def __init__(self):\n                for name, attr in attrs.items():\n                    setattr(self, name, attr)\n\n        return RemoteStore()\n\n    def _remote_attrs(self, run_id, dataset_idx):\n        return {\n            \'train_data_path\': self.get_train_data_path(dataset_idx),\n            \'val_data_path\': self.get_val_data_path(dataset_idx),\n            \'test_data_path\': self.get_test_data_path(dataset_idx),\n            \'saving_runs\': self.saving_runs(),\n            \'runs_path\': self.get_runs_path(),\n            \'run_path\': self.get_run_path(run_id),\n            \'checkpoint_path\': self.get_checkpoint_path(run_id),\n            \'logs_path\': self.get_logs_path(run_id),\n            \'checkpoint_filename\': self.get_checkpoint_filename(),\n            \'logs_subdir\': self.get_logs_subdir(),\n            \'get_local_output_dir\': self.get_local_output_dir_fn(run_id),\n            \'sync\': self.sync_fn(run_id)\n        }\n\n    @staticmethod\n    def create(prefix_path, *args, **kwargs):\n        if HDFSStore.matches(prefix_path):\n            return HDFSStore(prefix_path, *args, **kwargs)\n        else:\n            return LocalStore(prefix_path, *args, **kwargs)\n\n\nclass FilesystemStore(Store):\n    """"""Abstract class for stores that use a filesystem for underlying storage.""""""\n\n    def __init__(self, prefix_path, train_path=None, val_path=None, test_path=None, runs_path=None, save_runs=True):\n        self.prefix_path = self.get_full_path(prefix_path)\n        self._train_path = self._get_full_path_or_default(train_path, \'intermediate_train_data\')\n        self._val_path = self._get_full_path_or_default(val_path, \'intermediate_val_data\')\n        self._test_path = self._get_full_path_or_default(test_path, \'intermediate_test_data\')\n        self._runs_path = self._get_full_path_or_default(runs_path, \'runs\')\n        self._save_runs = save_runs\n        super(FilesystemStore, self).__init__()\n\n    def exists(self, path):\n        return self.get_filesystem().exists(self.get_localized_path(path))\n\n    def read(self, path):\n        with self.get_filesystem().open(self.get_localized_path(path), \'rb\') as f:\n            return f.read()\n\n    def is_parquet_dataset(self, path):\n        try:\n            dataset = self.get_parquet_dataset(path)\n            return dataset is not None\n        except:\n            return False\n\n    def get_parquet_dataset(self, path):\n        return pq.ParquetDataset(self.get_localized_path(path), filesystem=self.get_filesystem())\n\n    def get_train_data_path(self, idx=None):\n        return \'{}.{}\'.format(self._train_path, idx) if idx is not None else self._train_path\n\n    def get_val_data_path(self, idx=None):\n        return \'{}.{}\'.format(self._val_path, idx) if idx is not None else self._val_path\n\n    def get_test_data_path(self, idx=None):\n        return \'{}.{}\'.format(self._test_path, idx) if idx is not None else self._test_path\n\n    def get_data_metadata_path(self, path):\n        localized_path = self.get_localized_path(path)\n        if localized_path.endswith(\'/\'):\n            localized_path = localized_path[:-1] # Remove the slash at the end if there is one\n        metadata_cache = localized_path+""_cached_metadata.pkl""\n        return metadata_cache\n\n    def saving_runs(self):\n        return self._save_runs\n\n    def get_runs_path(self):\n        return self._runs_path\n\n    def get_run_path(self, run_id):\n        return os.path.join(self.get_runs_path(), run_id)\n\n    def get_checkpoint_path(self, run_id):\n        return os.path.join(self.get_run_path(run_id), self.get_checkpoint_filename()) \\\n            if self._save_runs else None\n\n    def get_logs_path(self, run_id):\n        return os.path.join(self.get_run_path(run_id), self.get_logs_subdir()) \\\n            if self._save_runs else None\n\n    def get_checkpoint_filename(self):\n        return \'checkpoint.h5\'\n\n    def get_logs_subdir(self):\n        return \'logs\'\n\n    def get_full_path(self, path):\n        if not self.matches(path):\n            return self.path_prefix() + path\n        return path\n\n    def get_localized_path(self, path):\n        if self.matches(path):\n            return path[len(self.path_prefix()):]\n        return path\n\n    def get_full_path_fn(self):\n        prefix = self.path_prefix()\n\n        def get_path(path):\n            return prefix + path\n        return get_path\n\n    def _get_full_path_or_default(self, path, default_key):\n        if path is not None:\n            return self.get_full_path(path)\n        return self._get_path(default_key)\n\n    def _get_path(self, key):\n        return os.path.join(self.prefix_path, key)\n\n    def path_prefix(self):\n        raise NotImplementedError()\n\n    def get_filesystem(self):\n        raise NotImplementedError()\n\n    @classmethod\n    def matches(cls, path):\n        return path.startswith(cls.filesystem_prefix())\n\n    @classmethod\n    def filesystem_prefix(cls):\n        raise NotImplementedError()\n\n\nclass LocalStore(FilesystemStore):\n    """"""Uses the local filesystem as a store of intermediate data and training artifacts.""""""\n\n    FS_PREFIX = \'file://\'\n\n    def __init__(self, prefix_path, *args, **kwargs):\n        self._fs = pa.LocalFileSystem()\n        super(LocalStore, self).__init__(prefix_path, *args, **kwargs)\n\n    def path_prefix(self):\n        return self.FS_PREFIX\n\n    def get_filesystem(self):\n        return self._fs\n\n    def get_local_output_dir_fn(self, run_id):\n        run_path = self.get_localized_path(self.get_run_path(run_id))\n\n        @contextlib.contextmanager\n        def local_run_path():\n            if not os.path.exists(run_path):\n                try:\n                    os.makedirs(run_path, mode=0o755)\n                except OSError as e:\n                    # Race condition from workers on the same host: ignore\n                    if e.errno != errno.EEXIST:\n                        raise\n            yield run_path\n\n        return local_run_path\n\n    def sync_fn(self, run_id):\n        run_path = self.get_localized_path(self.get_run_path(run_id))\n\n        def fn(local_run_path):\n            # No-op for LocalStore since the `local_run_path` will be the same as the run path\n            assert run_path == local_run_path\n        return fn\n\n    @classmethod\n    def filesystem_prefix(cls):\n        return cls.FS_PREFIX\n\n\nclass HDFSStore(FilesystemStore):\n    """"""Uses HDFS as a store of intermediate data and training artifacts.\n\n    Initialized from a `prefix_path` that can take one of the following forms:\n\n    1. ""hdfs://namenode01:8020/user/test/horovod""\n    2. ""hdfs:///user/test/horovod""\n    3. ""/user/test/horovod""\n\n    The full path (including prefix, host, and port) will be used for all reads and writes to HDFS through Spark. If\n    host and port are not provided, they will be omitted. If prefix is not provided (case 3), it will be prefixed to\n    the full path regardless.\n\n    The localized path (without prefix, host, and port) will be used for interaction with PyArrow. Parsed host and port\n    information will be used to initialize PyArrow `HadoopFilesystem` if they are not provided through the `host` and\n    `port` arguments to this initializer. These parameters will default to `default` and `0` if neither the path URL\n    nor the arguments provide this information.\n    """"""\n\n    FS_PREFIX = \'hdfs://\'\n    URL_PATTERN = \'^(?:(.+://))?(?:([^/:]+))?(?:[:]([0-9]+))?(?:(.+))?$\'\n\n    def __init__(self, prefix_path,\n                 host=None, port=None, user=None, kerb_ticket=None,\n                 driver=\'libhdfs\', extra_conf=None, temp_dir=None, *args, **kwargs):\n        self._temp_dir = temp_dir\n\n        prefix, url_host, url_port, path, path_offset = self.parse_url(prefix_path)\n        self._check_url(prefix_path, prefix, path)\n        self._url_prefix = prefix_path[:path_offset] if prefix else self.FS_PREFIX\n\n        host = host or url_host or \'default\'\n        port = port or url_port or 0\n        self._hdfs_kwargs = dict(host=host,\n                                 port=port,\n                                 user=user,\n                                 kerb_ticket=kerb_ticket,\n                                 extra_conf=extra_conf)\n        if LooseVersion(pa.__version__) < LooseVersion(\'0.17.0\'):\n            self._hdfs_kwargs[\'driver\'] = driver\n        self._hdfs = self._get_filesystem_fn()()\n\n        super(HDFSStore, self).__init__(prefix_path, *args, **kwargs)\n\n    def parse_url(self, url):\n        match = re.search(self.URL_PATTERN, url)\n        prefix = match.group(1)\n        host = match.group(2)\n\n        port = match.group(3)\n        if port is not None:\n            port = int(port)\n\n        path = match.group(4)\n        path_offset = match.start(4)\n        return prefix, host, port, path, path_offset\n\n    def path_prefix(self):\n        return self._url_prefix\n\n    def get_filesystem(self):\n        return self._hdfs\n\n    def get_local_output_dir_fn(self, run_id):\n        temp_dir = self._temp_dir\n\n        @contextlib.contextmanager\n        def local_run_path():\n            dirpath = tempfile.mkdtemp(dir=temp_dir)\n            try:\n                yield dirpath\n            finally:\n                shutil.rmtree(dirpath)\n\n        return local_run_path\n\n    def sync_fn(self, run_id):\n        class SyncState(object):\n            def __init__(self):\n                self.fs = None\n                self.uploaded = {}\n\n        state = SyncState()\n        get_filesystem = self._get_filesystem_fn()\n        hdfs_root_path = self.get_run_path(run_id)\n\n        def fn(local_run_path):\n            if state.fs is None:\n                state.fs = get_filesystem()\n\n            hdfs = state.fs\n            uploaded = state.uploaded\n\n            # We need to swap this prefix from the local path with the absolute path, +1 due to\n            # including the trailing slash\n            prefix = len(local_run_path) + 1\n\n            for local_dir, dirs, files in os.walk(local_run_path):\n                hdfs_dir = os.path.join(hdfs_root_path, local_dir[prefix:])\n                for file in files:\n                    local_path = os.path.join(local_dir, file)\n                    modified_ts = int(os.path.getmtime(local_path))\n\n                    if local_path in uploaded:\n                        last_modified_ts = uploaded.get(local_path)\n                        if modified_ts <= last_modified_ts:\n                            continue\n\n                    hdfs_path = os.path.join(hdfs_dir, file)\n                    with open(local_path, \'rb\') as f:\n                        hdfs.upload(hdfs_path, f)\n                    uploaded[local_path] = modified_ts\n\n        return fn\n\n    def _get_filesystem_fn(self):\n        hdfs_kwargs = self._hdfs_kwargs\n\n        def fn():\n            return pa.hdfs.connect(**hdfs_kwargs)\n        return fn\n\n    def _check_url(self, url, prefix, path):\n        print(\'_check_url: {}\'.format(prefix))\n        if prefix is not None and prefix != self.FS_PREFIX:\n            raise ValueError(\'Mismatched HDFS namespace for URL: {}. Found {} but expected {}\'\n                             .format(url, prefix, self.FS_PREFIX))\n\n        if not path:\n            raise ValueError(\'Failed to parse path from URL: {}\'.format(url))\n\n    @classmethod\n    def filesystem_prefix(cls):\n        return cls.FS_PREFIX\n'"
horovod/spark/common/util.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nimport contextlib\n\nimport pyarrow as pa\nimport numpy as np\nimport pyspark.sql.functions as f\nfrom pyspark.ml.linalg import DenseVector, SparseVector, Vector, VectorUDT\nfrom pyspark.sql.types import ArrayType, BinaryType, BooleanType, FloatType, DoubleType, \\\n    IntegerType, LongType, NullType, StringType\ntry:\n    # Spark 3.0 moved to a pandas submodule\n    from pyspark.sql.pandas.types import from_arrow_type\nexcept ImportError:\n    from pyspark.sql.types import from_arrow_type\n\nfrom horovod.run.common.util import codec\nfrom horovod.spark.common import cache, constants\n\n_training_cache = cache.TrainingDataCache()\n\n\ndef data_type_to_str(dtype):\n    if dtype == VectorUDT or dtype == SparseVector or dtype == DenseVector:\n        return \'Vector\'\n    elif dtype == IntegerType:\n        return \'Int\'\n    elif dtype == StringType:\n        return \'String\'\n    elif dtype == FloatType:\n        return \'Float\'\n    elif dtype == BinaryType:\n        return \'Binary\'\n    elif dtype == DoubleType:\n        return \'Double\'\n    elif dtype == LongType:\n        return \'Long\'\n    elif dtype == BooleanType:\n        return \'Boolean\'\n    else:\n        raise ValueError(\'Unrecognized data type: {}\'.format(dtype))\n\n\ndef numpy_type_to_str(dtype):\n    if dtype == np.int32:\n        return \'Int\'\n    elif dtype == np.float32:\n        return \'Float\'\n    elif dtype == np.uint8:\n        return \'Binary\'\n    elif dtype == np.float64:\n        return \'Double\'\n    elif dtype == np.int64:\n        return \'Long\'\n    elif dtype == np.bool:\n        return \'Boolean\'\n    else:\n        raise ValueError(\'Cannot convert numpy data type to Spark string: {}\'.format(dtype))\n\n\ndef spark_scalar_to_python_type(dtype):\n    if dtype == IntegerType:\n        return int\n    elif dtype == StringType:\n        return str\n    elif dtype == FloatType:\n        return float\n    elif dtype == DoubleType:\n        return float\n    elif dtype == LongType:\n        return int\n    elif dtype == BooleanType:\n        return bool\n    elif dtype == BinaryType:\n        return bytes\n    else:\n        raise ValueError(\'cannot convert Spark data Type {} to native python type\'.format(dtype))\n\n\ndef pyarrow_to_spark_data_type(dtype):\n    # PySpark will interpret list types as Arrays, but for ML applications we want to default to\n    # treating these as DenseVectors.\n    if pa.types.is_list(dtype):\n        return DenseVector\n    return type(from_arrow_type(dtype))\n\n\ndef data_type_to_numpy(dtype):\n    if dtype == VectorUDT or dtype == SparseVector or dtype == DenseVector:\n        return np.float64\n    elif dtype == ArrayType:\n        return np.float64\n    elif dtype == IntegerType:\n        return np.int32\n    elif dtype == StringType:\n        return np.uint8\n    elif dtype == FloatType:\n        return np.float32\n    elif dtype == BinaryType:\n        return np.uint8\n    elif dtype == DoubleType:\n        return np.float64\n    elif dtype == LongType:\n        return np.int64\n    elif dtype == BooleanType:\n        return np.bool\n    else:\n        raise ValueError(\'Unrecognized data type: {}\'.format(dtype))\n\n\ndef check_shape_compatibility(metadata, feature_columns, label_columns,\n                              input_shapes=None, output_shapes=None):\n    # Check for model and input type incompatibility. Columns must have the same size\n    # (total number of elements) of the corresponding inputs.\n    feature_count = len(feature_columns)\n    if input_shapes is not None:\n        if feature_count != len(input_shapes):\n            raise ValueError(\'Feature column count {features} must equal \'\n                             \'model inputs count {inputs}\'\n                             .format(features=feature_count, inputs=len(input_shapes)))\n\n        for idx, col, input_shape in zip(range(feature_count), feature_columns, input_shapes):\n            col_size = metadata[col][\'shape\']\n            if col_size is None:\n                # When training directly on Parquet, we do not compute shape metadata\n                continue\n\n            input_size = abs(np.prod(input_shape))\n            if col_size != input_size:\n                raise ValueError(\n                    \'Feature column \\\'{col}\\\' with size {feature} must equal that of the \'\n                    \'model input at index {idx} with size {input}\'\n                    .format(col=col, feature=col_size, idx=idx, input=input_size))\n\n    if output_shapes is not None:\n        label_count = len(label_columns)\n        if label_count != len(output_shapes):\n            raise ValueError(\'Label column count {labels} must equal \'\n                             \'model outputs count {outputs}\'\n                             .format(labels=label_count, outputs=len(output_shapes)))\n\n        for idx, col, output_shape in zip(range(label_count), label_columns, output_shapes):\n            col_size = metadata[col][\'shape\']\n            if col_size is None:\n                # When training directly on Parquet, we do not compute shape metadata\n                continue\n\n            output_size = abs(np.prod(output_shape))\n            if col_size != output_size:\n                raise ValueError(\'Label column \\\'{col}\\\' with size {label} must equal that of the \'\n                                 \'model output at index {idx} with size {output}\'\n                                 .format(col=col, label=col_size, idx=idx, output=output_size))\n\n\ndef _get_col_info(df):\n    """"""\n    Infer the type and shape of all the columns.\n\n    NOTE: This function processes the entire DataFrame, and can therefore be very expensive to run.\n\n    TODO(travis): Only run this if user sets compress_sparse param, otherwise convert all to Array.\n    """"""\n\n    def get_meta(row):\n        row_dict = row.asDict()\n        row_schema = []\n        for col_name, data_col in row_dict.items():\n            dtype = type(data_col)\n            if isinstance(data_col, DenseVector):\n                # shape and size of dense vector are the same\n                shape = size = data_col.array.shape[0]\n            elif isinstance(data_col, SparseVector):\n                # shape is the total size of vector\n                shape = data_col.size\n                # size is the number of nonzero elements in the sparse vector\n                size = data_col.indices.shape[0]\n            elif isinstance(data_col, list):\n                shape = size = len(data_col)\n            else:\n                shape = size = 1\n            row_schema.append((col_name, ({dtype}, {shape}, {size})))\n        return row_schema\n\n    def merge(x, y):\n        x_dtypes, x_shapes, x_sizes = x\n        y_dtypes, y_shapes, y_sizes = y\n        dtypes = x_dtypes | y_dtypes\n        shapes = x_shapes | y_shapes\n        sizes = x_sizes | y_sizes\n        return dtypes, {min(shapes), max(shapes)}, {min(sizes), max(sizes)}\n\n    raw_col_info_list = df.rdd.flatMap(get_meta).reduceByKey(merge).collect()\n\n    all_col_types = {}\n    col_shapes = {}\n    col_max_sizes = {}\n\n    for col_info in raw_col_info_list:\n        col_name, col_meta = col_info\n        dtypes, shapes, sizes = col_meta\n\n        all_col_types[col_name] = dtypes\n        col_shapes[col_name] = shapes\n        col_max_sizes[col_name] = sizes\n\n    for col in df.schema.names:\n        # All rows in every column must have the same shape\n        shape_set = col_shapes[col]\n        if len(shape_set) != 1:\n            raise ValueError(\n                \'Column {col} does not have uniform shape. \'\n                \'shape set: {shapes_set}\'.format(col=col, shapes_set=shape_set))\n        col_shapes[col] = shape_set.pop()\n\n        # All rows in every column must have the same size unless they have SparseVectors\n        sizes = col_max_sizes[col]\n        if len(sizes) > 1 and not (SparseVector in all_col_types[col]):\n            raise ValueError(\n                \'Rows of column {col} have varying sizes. This is only allowed if datatype is \'\n                \'SparseVector or a mix of Sparse and DenseVector.\'.format(col=col))\n        col_max_sizes[col] = max(sizes)\n\n    return all_col_types, col_shapes, col_max_sizes\n\n\ndef _get_metadata(df):\n    """"""\n    Infer the type and shape of all the columns and determines if what intermediate format they\n    need to be converted to in case they are a vector.\n\n    Example return value:\n    {\n    \'col1\': {\n        \'dtype\': <type \'float\'>,\n        \'intermediate_format\': \'nochange\',\n        \'max_size\': 1,\n        \'shape\': 1\n        },\n     \'col2\': {\n        \'dtype\': <type \'float\'>,\n        \'intermediate_format\': \'nochange\',\n        \'max_size\': 1,\n        \'shape\': 1\n        },\n     \'col3\': {\n        \'dtype\': <class \'pyspark.ml.linalg.SparseVector\'>,\n        \'intermediate_format\': \'custom_sparse_format\',\n        \'max_size\': 37,\n        \'shape\': 56\n        }\n    }\n    """"""\n    all_col_types, col_shapes, col_max_sizes = _get_col_info(df)\n\n    metadata = dict()\n    for field in df.schema.fields:\n        col = field.name\n        col_types = all_col_types[col].copy()\n\n        if DenseVector in col_types:\n            # If a col has DenseVector type (whether it is mixed sparse and dense vector or just\n            # DenseVector), convert all of the values to dense vector\n            is_sparse_vector_only = False\n            spark_data_type = DenseVector\n            convert_to_target = constants.ARRAY\n        elif SparseVector in col_types:\n            # If a col has only sparse vectors, convert all the data into custom dense vectors\n            is_sparse_vector_only = True\n            spark_data_type = SparseVector\n            convert_to_target = constants.CUSTOM_SPARSE\n        else:\n            is_sparse_vector_only = False\n            spark_data_type = type(field.dataType)\n            convert_to_target = constants.NOCHANGE\n\n        # Explanation of the fields in metadata\n        #     dtype:\n        #\n        #     spark_data_type:\n        #         The spark data type from dataframe schema: type(field.dataType). If column has\n        #         mixed SparseVector and DenseVector we categorize it as DenseVector.\n        #\n        #     is_sparse_vector_only:\n        #         If all the rows in the column were sparse vectors.\n        #\n        #     shape:\n        #         Determines the shape of the data in the spark dataframe. It is useful for sparse\n        #         vectors.\n        #\n        #     intermediate_format:\n        #         Specifies if the column need to be converted to a different format so that\n        #         petastorm can read it. It can be one of ARRAY, CUSTOM_SPARSE, or NOCHANGE. It is\n        #         required because petastorm cannot read DenseVector and SparseVectors. We need to\n        #         identify these types and convert them to petastorm compatible type of array.\n\n        metadata[col] = {\'spark_data_type\': spark_data_type,\n                         \'is_sparse_vector_only\': is_sparse_vector_only,\n                         \'shape\': col_shapes[col],\n                         \'intermediate_format\': convert_to_target,\n                         \'max_size\': col_max_sizes[col]}\n\n    return metadata\n\n\ndef to_petastorm_fn(schema_cols, metadata):\n    ARRAY = constants.ARRAY\n    CUSTOM_SPARSE = constants.CUSTOM_SPARSE\n\n    # Convert Spark Vectors into arrays so Petastorm can read them\n    def to_petastorm(row):\n        import numpy as np\n        from pyspark import Row\n\n        converted = {}\n        for col in schema_cols:\n            col_data = row[col]\n            if isinstance(col_data, Vector):\n                intermediate_format = metadata[col][\'intermediate_format\'] if metadata else ARRAY\n                if intermediate_format == ARRAY:\n                    converted[col] = col_data.toArray().tolist()\n                elif intermediate_format == CUSTOM_SPARSE:\n                    # Currently petastorm does not support reading pyspark sparse vector. We put\n                    # the indices and values into one array. when consuming the data, we re-create\n                    # the vector from this format.\n                    size = len(col_data.indices)\n                    padding_zeros = 2 * (metadata[col][\'max_size\'] - len(col_data.indices))\n\n                    converted[col] = np.concatenate(\n                        (np.array([size]), col_data.indices, col_data.values,\n                         np.zeros(padding_zeros))).tolist()\n\n        if converted:\n            row = row.asDict().copy()\n            row.update(converted)\n        return Row(**row)\n\n    return to_petastorm\n\n\ndef _has_vector_column(df):\n    for field in df.schema.fields:\n        if isinstance(field.dataType, VectorUDT):\n            return True\n    return False\n\n\ndef _get_dataset_info(dataset, dataset_id, path):\n    total_rows = 0\n    total_byte_size = 0\n    for piece in dataset.pieces:\n        metadata = piece.get_metadata()\n        total_rows += metadata.num_rows\n        for row_group_index in range(metadata.num_row_groups):\n            row_group = metadata.row_group(row_group_index)\n            total_byte_size += row_group.total_byte_size\n\n    if total_rows == 0:\n        raise ValueError(\'No rows found in {} dataset: {}\'.format(dataset_id, path))\n\n    if total_byte_size == 0:\n        raise ValueError(\'No data found in {} dataset: {}\'.format(dataset_id, path))\n\n    if total_rows > total_byte_size:\n        raise ValueError(\'Found {} bytes in {} rows; {} dataset may be corrupted.\'\n                         .format(total_byte_size, total_rows, dataset_id))\n\n    return total_rows, total_byte_size\n\n\ndef _save_meta_to_fs(fs, path, schema, rows, total_byte_size):\n    with fs.open(path, \'wb\') as train_meta_file:\n        serialized_content = codec.dumps_base64(dict(schema=schema,\n                                                     rows=rows,\n                                                     total_byte_size=total_byte_size))\n        train_meta_file.write(serialized_content.encode(\'utf-8\'))\n\n\ndef _load_metadata_from_fs(fs, path):\n    with fs.open(path, \'rb\') as train_meta_file:\n        meta = train_meta_file.read()\n        meta = codec.loads_base64(meta.decode())\n        data_schema = meta[\'schema\']\n        rows = meta[\'rows\']\n        total_byte_size = meta[\'total_byte_size\']\n\n    return data_schema, rows, total_byte_size\n\n\ndef get_simple_meta_from_parquet(store, label_columns, feature_columns, sample_weight_col,\n                                 dataset_idx=None):\n    train_data_path = store.get_train_data_path(dataset_idx)\n    validation_data_path = store.get_val_data_path(dataset_idx)\n\n    if not store.exists(train_data_path):\n        raise ValueError(""{} path does not exist in the store"".format(train_data_path))\n\n    train_data_meta_path = store.get_data_metadata_path(train_data_path)\n    val_data_meta_path = store.get_data_metadata_path(validation_data_path)\n    fs = store.get_filesystem()\n\n    schema_cols = feature_columns + label_columns\n    if sample_weight_col:\n        schema_cols.append(sample_weight_col)\n\n    def make_metadata_dictionary(_train_data_schema):\n        _metadata = {}\n        for col in schema_cols:\n            col_schema = _train_data_schema.field_by_name(col)\n            col_info = {\n                \'spark_data_type\': pyarrow_to_spark_data_type(col_schema.type),\n                \'is_sparse_vector_only\': False,\n                \'shape\': None,  # Only used by SparseVector columns\n                \'intermediate_format\': constants.NOCHANGE,\n                \'max_size\': None  # Only used by SparseVector columns\n            }\n            _metadata[col] = col_info\n\n        _avg_row_size = train_data_total_byte_size / train_rows\n        return _metadata, _avg_row_size\n\n    # In the try block we try to read the data metadata from the cached metadata in the store. If\n    # anything goes wrong, we will ignore the cache and create the metadata from data.\n    try:\n        if store.exists(train_data_meta_path):\n            train_data_schema, train_rows, train_data_total_byte_size = \\\n                _load_metadata_from_fs(fs, train_data_meta_path)\n            metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n\n            val_rows = 0\n            if store.exists(validation_data_path) and store.exists(val_data_meta_path):\n                val_data_schema, val_rows, val_data_total_byte_size = _load_metadata_from_fs(fs,\n                                                                                             val_data_meta_path)\n\n            return train_rows, val_rows, metadata, avg_row_size\n    except Exception as ex:\n        print(ex)\n\n    train_data = store.get_parquet_dataset(train_data_path)\n    train_data_schema = train_data.schema.to_arrow_schema()\n    train_rows, train_data_total_byte_size = _get_dataset_info(train_data, \'training\',\n                                                               train_data_path)\n\n    # Write train metadata to filesystem\n    _save_meta_to_fs(fs, train_data_meta_path, train_data_schema, train_rows,\n                     train_data_total_byte_size)\n\n    val_rows = 0\n    if store.exists(validation_data_path):\n        val_data = store.get_parquet_dataset(validation_data_path)\n        val_data_schema = val_data.schema.to_arrow_schema()\n        val_rows, val_data_total_byte_size = _get_dataset_info(val_data, \'validation\',\n                                                               validation_data_path)\n\n        # Write validation metadata to filesystem\n        _save_meta_to_fs(fs, val_data_meta_path, val_data_schema, val_rows,\n                         val_data_total_byte_size)\n    metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n    return train_rows, val_rows, metadata, avg_row_size\n\n\ndef _train_val_split(df, validation):\n    train_df = df\n    val_df = None\n    validation_ratio = 0.0\n\n    if isinstance(validation, float) and validation > 0:\n        train_df, val_df = train_df.randomSplit([1.0 - validation, validation])\n        validation_ratio = validation\n    elif isinstance(validation, str):\n        dtype = [field.dataType for field in df.schema.fields if field.name == validation][0]\n        bool_dtype = isinstance(dtype, BooleanType)\n        val_df = train_df.filter(\n            f.col(validation) if bool_dtype else f.col(validation) > 0).drop(validation)\n        train_df = train_df.filter(\n            ~f.col(validation) if bool_dtype else f.col(validation) == 0).drop(validation)\n\n        # Approximate ratio of validation data to training data for proportionate scale\n        # of partitions\n        timeout_ms = 1000\n        confidence = 0.90\n        train_rows = train_df.rdd.countApprox(timeout=timeout_ms, confidence=confidence)\n        val_rows = val_df.rdd.countApprox(timeout=timeout_ms, confidence=confidence)\n        validation_ratio = val_rows / (val_rows + train_rows)\n    elif validation:\n        raise ValueError(\'Unrecognized validation type: {}\'.format(type(validation)))\n\n    return train_df, val_df, validation_ratio\n\n\ndef _get_or_create_dataset(key, store, df, feature_columns, label_columns,\n                           validation, sample_weight_col, compress_sparse,\n                           num_partitions, num_processes, verbose):\n    with _training_cache.lock:\n        if _training_cache.is_cached(key, store):\n            dataset_idx = _training_cache.get_dataset(key)\n            train_rows, val_rows, metadata, avg_row_size = _training_cache.get_dataset_properties(dataset_idx)\n            train_data_path = store.get_train_data_path(dataset_idx)\n            val_data_path = store.get_val_data_path(dataset_idx)\n            if verbose:\n                print(\'using cached dataframes for key: {}\'.format(key))\n                print(\'train_data_path={}\'.format(train_data_path))\n                print(\'train_rows={}\'.format(train_rows))\n                print(\'val_data_path={}\'.format(val_data_path))\n                print(\'val_rows={}\'.format(val_rows))\n        else:\n            dataset_idx = _training_cache.next_dataset_index(key)\n            train_data_path = store.get_train_data_path(dataset_idx)\n            val_data_path = store.get_val_data_path(dataset_idx)\n            if verbose:\n                print(\'writing dataframes\')\n                print(\'train_data_path={}\'.format(train_data_path))\n                print(\'val_data_path={}\'.format(val_data_path))\n\n            schema_cols = feature_columns + label_columns\n            if sample_weight_col:\n                schema_cols.append(sample_weight_col)\n            if isinstance(validation, str):\n                schema_cols.append(validation)\n            df = df[schema_cols]\n\n            metadata = None\n            if _has_vector_column(df):\n                if compress_sparse:\n                    metadata = _get_metadata(df)\n                to_petastorm = to_petastorm_fn(schema_cols, metadata)\n                df = df.rdd.map(to_petastorm).toDF()\n\n            train_df, val_df, validation_ratio = _train_val_split(df, validation)\n\n            train_partitions = max(int(num_partitions * (1.0 - validation_ratio)),\n                                   num_processes)\n            if verbose:\n                print(\'train_partitions={}\'.format(train_partitions))\n\n            train_df \\\n                .coalesce(train_partitions) \\\n                .write \\\n                .mode(\'overwrite\') \\\n                .parquet(train_data_path)\n\n            if val_df:\n                val_partitions = max(int(num_partitions * validation_ratio),\n                                     num_processes)\n                if verbose:\n                    print(\'val_partitions={}\'.format(val_partitions))\n\n                val_df \\\n                    .coalesce(val_partitions) \\\n                    .write \\\n                    .mode(\'overwrite\') \\\n                    .parquet(val_data_path)\n\n            train_rows, val_rows, pq_metadata, avg_row_size = get_simple_meta_from_parquet(\n                store, label_columns, feature_columns, sample_weight_col, dataset_idx)\n\n            if verbose:\n                print(\'train_rows={}\'.format(train_rows))\n            if val_df:\n                if val_rows == 0:\n                    raise ValueError(\n                        \'Validation DataFrame does not any samples with validation param {}\'\n                        .format(validation))\n                if verbose:\n                    print(\'val_rows={}\'.format(val_rows))\n\n            metadata = metadata or pq_metadata\n            _training_cache.set_dataset_properties(\n                dataset_idx, (train_rows, val_rows, metadata, avg_row_size))\n        return dataset_idx\n\n\ndef check_validation(validation, df=None):\n    if validation:\n        if isinstance(validation, float):\n            if validation < 0 or validation >= 1:\n                raise ValueError(\'Validation split {} must be in the range: [0, 1)\'\n                                 .format(validation))\n        elif isinstance(validation, str):\n            if df is not None and validation not in df.columns:\n                raise ValueError(\'Validation column {} does not exist in the DataFrame\'\n                                 .format(validation))\n        else:\n            raise ValueError(\'Param validation must be of type ""float"" or ""str"", found: {}\'\n                             .format(type(validation)))\n\n\n@contextlib.contextmanager\ndef prepare_data(num_processes, store, df, label_columns, feature_columns,\n                 validation=None, sample_weight_col=None, compress_sparse=False,\n                 partitions_per_process=10, verbose=0):\n    check_validation(validation, df=df)\n    if num_processes <= 0 or partitions_per_process <= 0:\n        raise ValueError(\'num_proc={} and partitions_per_process={} must both be > 0\'\n                         .format(num_processes, partitions_per_process))\n\n    if not label_columns:\n        raise ValueError(\'Parameter label_columns cannot be None or empty\')\n\n    num_partitions = num_processes * partitions_per_process\n    if verbose:\n        print(\'num_partitions={}\'.format(num_partitions))\n\n    for col in label_columns:\n        if col not in df.columns:\n            raise ValueError(\'Label column {} does not exist in the DataFrame\'.format(col))\n\n    if feature_columns is None:\n        feature_columns = [col for col in df.columns if col not in set(label_columns)]\n    else:\n        for col in feature_columns:\n            if col not in df.columns:\n                raise ValueError(\'Feature column {} does not exist in the DataFrame\'.format(col))\n\n    key = _training_cache.create_key(df, store, validation)\n    with _training_cache.use_key(key):\n        dataset_idx = _get_or_create_dataset(key, store, df, feature_columns, label_columns,\n                                             validation, sample_weight_col, compress_sparse,\n                                             num_partitions, num_processes, verbose)\n        yield dataset_idx\n\n\ndef get_dataset_properties(dataset_idx):\n    return _training_cache.get_dataset_properties(dataset_idx)\n\n\ndef clear_training_cache():\n    _training_cache.clear()\n\n\ndef to_list(var, length):\n    if var is None:\n        return None\n\n    if not isinstance(var, list):\n        var = [var]\n\n    # If var has only one element, pad it to match the given length.\n    if len(var) == 1:\n        var = [var[0] for _ in range(length)]\n    else:\n        if len(var) != length:\n            raise ValueError(""loss_constructors and loss functions must be a ""\n                             ""list with length that matches the length of ""\n                             ""label_cols"")\n\n    return var\n'"
horovod/spark/driver/__init__.py,0,b''
horovod/spark/driver/driver_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.run.common.service import driver_service\n\n\nclass TaskHostHashIndicesRequest(object):\n    """"""Request task indices for a given host hash.""""""\n    def __init__(self, host_hash):\n        self.host_hash = host_hash\n\n\nclass TaskHostHashIndicesResponse(object):\n    def __init__(self, indices):\n        self.indices = indices\n        """"""Task indices.""""""\n\n\nclass TaskIndexByRankRequest(object):\n    """"""Request task index by Horovod rank.""""""\n    def __init__(self, rank):\n        self.rank = rank\n\n\nclass TaskIndexByRankResponse(object):\n    def __init__(self, index):\n        self.index = index\n        """"""Task index.""""""\n\n\nclass CodeRequest(object):\n    """"""Request Python function to execute.""""""\n    pass\n\n\nclass CodeResponse(object):\n    def __init__(self, fn, args, kwargs):\n        self.fn = fn\n        """"""Function.""""""\n\n        self.args = args\n        """"""Function args.""""""\n\n        self.kwargs = kwargs\n        """"""Function kwargs.""""""\n\n\nclass SparkDriverService(driver_service.BasicDriverService):\n    NAME = \'driver service\'\n\n    def __init__(self, num_proc, fn, args, kwargs, key, nics):\n        super(SparkDriverService, self).__init__(num_proc,\n                                                 SparkDriverService.NAME,\n                                                 key, nics)\n\n        self._fn = fn\n        self._args = args\n        self._kwargs = kwargs\n        self._ranks_to_indices = None\n        self._spark_job_failed = False\n\n    def _handle(self, req, client_address):\n\n        if isinstance(req, TaskHostHashIndicesRequest):\n            return TaskHostHashIndicesResponse(self._task_host_hash_indices[req.host_hash])\n\n        if isinstance(req, TaskIndexByRankRequest):\n            return TaskIndexByRankResponse(self._ranks_to_indices[req.rank])\n\n        if isinstance(req, CodeRequest):\n            return CodeResponse(self._fn, self._args, self._kwargs)\n\n        return super(SparkDriverService, self)._handle(req, client_address)\n\n    def set_ranks_to_indices(self, ranks_to_indices):\n        self._ranks_to_indices = ranks_to_indices\n\n    def notify_spark_job_failed(self):\n        self._wait_cond.acquire()\n        try:\n            self._spark_job_failed = True\n        finally:\n            self._wait_cond.notify_all()\n            self._wait_cond.release()\n\n    def check_for_spark_job_failure(self):\n        if self._spark_job_failed:\n            raise Exception(\'Spark job has failed, see the error above.\')\n\n    def wait_for_initial_registration(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while len(self._all_task_addresses) < self._num_proc:\n                self.check_for_spark_job_failure()\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\'Spark tasks to start\')\n        finally:\n            self._wait_cond.release()\n\n    def wait_for_task_to_task_address_updates(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while len(self._task_addresses_for_tasks) < self._num_proc:\n                self.check_for_spark_job_failure()\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\'Spark tasks to update task-to-task addresses\')\n        finally:\n            self._wait_cond.release()\n\n\nclass SparkDriverClient(driver_service.BasicDriverClient):\n    def __init__(self, driver_addresses, key, verbose, match_intf=False):\n        super(SparkDriverClient, self).__init__(SparkDriverService.NAME,\n                                                driver_addresses,\n                                                key,\n                                                verbose,\n                                                match_intf=match_intf)\n\n    def task_host_hash_indices(self, host_hash):\n        resp = self._send(TaskHostHashIndicesRequest(host_hash))\n        return resp.indices\n\n    def task_index_by_rank(self, rank):\n        resp = self._send(TaskIndexByRankRequest(rank))\n        return resp.index\n\n    def code(self):\n        resp = self._send(CodeRequest())\n        return resp.fn, resp.args, resp.kwargs\n'"
horovod/spark/driver/job_id.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport threading\n\n\nLOCK = threading.Lock()\nJOB_ID = -1\n\n\ndef next_job_id():\n    global LOCK, JOB_ID\n    with LOCK:\n        JOB_ID += 1\n        return JOB_ID\n'"
horovod/spark/driver/mpirun_rsh.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport sys\n\nfrom horovod.run.common.util import codec, secret\nfrom horovod.spark.driver.rsh import rsh\n\n\nif __name__ == \'__main__\':\n    """"""\n    Method run by MPI to connect to a host hash and execute the given command.\n\n    The command is usually `orted` to setup the MPI cluster. That `orted` process\n    is then used to spin-up the actual remote process, the Horovod user\'s Python method.\n    The `orted` process will run on the lowest task index and all other tasks with the\n    same host hash are expected to no-op (see `horovod.spark._task_fn`)\n    and wait for the first task to terminate.\n\n    :param driver_addresses: all IP addresses of the driver, base64 encoded\n    :param settings: all settings, base64 encoded\n    :param host_hash: the host hash to connect to\n    :param command: the command and arguments to execute remotely\n    """"""\n    if len(sys.argv) < 5:\n        print(\'Usage: %s <service addresses> <settings> <host hash> \'\n              \'<command...>\' % sys.argv[0])\n        sys.exit(1)\n\n    addresses = codec.loads_base64(sys.argv[1])\n    key = codec.loads_base64(os.environ.get(secret.HOROVOD_SECRET_KEY))\n    settings = codec.loads_base64(sys.argv[2])\n    host_hash = sys.argv[3]\n    command = "" "".join(sys.argv[4:])\n    env = {}  # orted does not need any env vars, the target training code gets env from mpirun\n\n    # Since tasks with the same host hash have shared memory,\n    # we will run only one orted process on the first task.\n    rsh(addresses, key, host_hash, command, env, 0, settings.verbose)\n'"
horovod/spark/driver/rsh.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport threading\nimport traceback\n\nfrom horovod.run.util.threads import on_event\nfrom horovod.spark.task import task_service\nfrom horovod.spark.driver import driver_service\n\n\ndef rsh(driver_addresses, key, host_hash, command, env, local_rank, verbose,\n        background=True, events=None):\n    """"""\n    Method to run a command remotely given a host hash, local rank and driver addresses.\n\n    This method connects to the SparkDriverService running on the Spark driver,\n    retrieves all information required to connect to the task with given local rank\n    of that host hash and invoke the command there.\n\n    The method returns immediately after launching the command if background is True (default).\n    When background is set to False, this method waits for command termination and returns\n    command\'s result. If there is an exception while waiting for the result (i.e. connection reset)\n    it returns -1.\n\n    :param driver_addresses: driver\'s addresses\n    :param key: used for encryption of parameters passed across the hosts\n    :param host_hash: host hash to connect to\n    :param command: command and arguments to invoke\n    :param env: environment to use\n    :param local_rank: local rank on the host of task to run the command in\n    :param verbose: verbosity level\n    :param background: run command in background if True, returns command result otherwise\n    :param events: events to abort the command, only if background is True\n    """"""\n    if \':\' in host_hash:\n        raise Exception(\'Illegal host hash provided. Are you using Open MPI 4.0.0+?\')\n\n    driver_client = driver_service.SparkDriverClient(driver_addresses, key, verbose=verbose)\n    task_indices = driver_client.task_host_hash_indices(host_hash)\n    task_index = task_indices[local_rank]\n    task_addresses = driver_client.all_task_addresses(task_index)\n    task_client = task_service.SparkTaskClient(task_index, task_addresses, key, verbose=verbose)\n    task_client.run_command(command, env)\n\n    if not background:\n        stop = None\n        events = events or []\n        for event in events:\n            stop = threading.Event()\n            on_event(event, task_client.abort_command, stop=stop)\n\n        try:\n            return task_client.wait_for_command_exit_code()\n        except:\n            traceback.print_exc()\n            return -1\n        finally:\n            if stop is not None:\n                stop.set()\n'"
horovod/spark/keras/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.spark.keras.estimator import KerasEstimator\nfrom horovod.spark.keras.estimator import KerasModel\n'"
horovod/spark/keras/bare.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport json\nimport warnings\n\nimport numpy as np\nfrom keras import backend as K\nfrom keras import optimizers\n\n\ndef save_bare_keras_optimizer(optimizer, h5py_file):\n    def get_json_type(obj):\n        """"""Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        """"""\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, \'get_config\'):\n            return {\'class_name\': obj.__class__.__name__,\n                    \'config\': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return obj.tolist()\n            return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python \'type\'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError(\'Not JSON Serializable: %s\' % (obj,))\n\n    if isinstance(optimizer, optimizers.TFOptimizer):\n        warnings.warn(\n            \'TensorFlow optimizers do not \'\n            \'make it possible to access \'\n            \'optimizer attributes or optimizer state \'\n            \'after instantiation. \'\n            \'As a result, we cannot save the optimizer \'\n            \'as part of the model save file.\'\n            \'You will have to compile your model again \'\n            \'after loading it. \'\n            \'Prefer using a Keras optimizer instead \'\n            \'(see keras.io/optimizers).\')\n    else:\n        h5py_file[\'training_config\'] = json.dumps({\n            \'optimizer_config\': {\n                \'class_name\': optimizer.__class__.__name__,\n                \'config\': optimizer.get_config()\n            },\n        }, default=get_json_type).encode(\'utf8\')\n\n        symbolic_weights = getattr(optimizer, \'weights\')\n        if symbolic_weights:\n            optimizer_weights_group = h5py_file[\'optimizer_weights\']\n            weight_values = K.batch_get_value(symbolic_weights)\n            weight_names = []\n            for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n                if hasattr(w, \'name\') and w.name:\n                    name = str(w.name)\n                else:\n                    name = \'param_\' + str(i)\n\n                if name in weight_names:\n                    idx = 2\n                    unique_name = name + \'_1\'\n                    while unique_name in weight_names:\n                        unique_name = name + \'_\' + str(idx)\n                        idx += 1\n                    name = unique_name\n                weight_names.append(name.encode(\'utf8\'))\n            optimizer_weights_group[\'weight_names\'] = weight_names\n            for name, val in zip(weight_names, weight_values):\n                optimizer_weights_group[name] = val\n\n\ndef load_bare_keras_optimizer(h5py_file, custom_objects=None):\n    if not custom_objects:\n        custom_objects = {}\n\n    def convert_custom_objects(obj):\n        """"""Handles custom object lookup.\n\n        Arguments:\n            obj: object, dict, or list.\n\n        Returns:\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        """"""\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj\n\n    optimizer, optimizer_weight_values = None, None\n\n    # instantiate optimizer\n    training_config = h5py_file.get(\'training_config\')\n    training_config = json.loads(training_config[()].decode(\'utf-8\'))\n    optimizer_config = training_config[\'optimizer_config\']\n    optimizer = optimizers.deserialize(optimizer_config, custom_objects=custom_objects)\n\n    if \'optimizer_weights\' in h5py_file:\n        optimizer_weights_group = h5py_file[\'optimizer_weights\']\n        optimizer_weight_names = [\n            n.decode(\'utf8\')\n            for n in optimizer_weights_group.attrs[\'weight_names\']\n        ]\n        optimizer_weight_values = [optimizer_weights_group[n].value for n in\n                                   optimizer_weight_names]\n\n    if optimizer_weight_values:\n        optimizer.set_weights(optimizer_weight_values)\n    return optimizer\n'"
horovod/spark/keras/estimator.py,5,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nimport numbers\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom pyspark import keyword_only\nfrom pyspark.ml.util import MLWritable, MLReadable\nfrom pyspark.ml.param.shared import Param, Params\n\nfrom horovod.run.common.util import codec\n\nfrom horovod.spark.common import util\nfrom horovod.spark.common.estimator import HorovodEstimator, HorovodModel\nfrom horovod.spark.common.params import EstimatorParams\nfrom horovod.spark.common.serialization import HorovodParamsWriter, HorovodParamsReader\nfrom horovod.spark.keras import remote\nfrom horovod.spark.keras.util import \\\n    BARE_KERAS, TF_KERAS, \\\n    BareKerasUtil, TFKerasUtil, \\\n    is_instance_of_bare_keras_model, is_instance_of_bare_keras_optimizer\n\n\nclass KerasEstimatorParamsWriter(HorovodParamsWriter):\n    def saveImpl(self, path):\n        keras_utils = self.instance._get_keras_utils()\n        # Write the parameters\n        HorovodParamsWriter.saveMetadata(self.instance, path, self.sc,\n                                         param_serializer_fn=keras_utils.serialize_param_value)\n\n\nclass KerasEstimatorParamsWritable(MLWritable):\n    def write(self):\n        return KerasEstimatorParamsWriter(self)\n\n\nclass KerasEstimatorParamsReader(HorovodParamsReader):\n    def _deserialize_dict(self, dict):\n        def _param_deserializer_fn(name, param_val, keras_utils, custom_objects):\n            if param_val is None:\n                return param_val\n\n            if name == EstimatorParams.model.name:\n                def load_model_fn(x):\n                    with keras_utils.keras().utils.custom_object_scope(custom_objects):\n                        return keras_utils.keras().models.load_model(x, compile=True)\n\n                return keras_utils.deserialize_model(param_val,\n                                                     load_model_fn=load_model_fn)\n            elif name == KerasEstimator.optimizer.name:\n                opt_base64_encoded = codec.loads_base64(param_val)\n                return keras_utils.deserialize_optimizer(opt_base64_encoded)\n            else:\n                return codec.loads_base64(param_val)\n\n        # In order to deserialize the model, we need to deserialize the custom_objects param\n        # first.\n        keras_utils = None\n        if KerasEstimator._keras_pkg_type.name in dict:\n            keras_pkg_type = _param_deserializer_fn(KerasEstimator._keras_pkg_type.name,\n                                                    dict[KerasEstimator._keras_pkg_type.name],\n                                                    None, None)\n            if keras_pkg_type == BARE_KERAS:\n                keras_utils = BareKerasUtil\n            elif keras_pkg_type == TF_KERAS:\n                keras_utils = TFKerasUtil\n\n        custom_objects = {}\n        if KerasEstimator.custom_objects.name in dict:\n            custom_objects = _param_deserializer_fn(KerasEstimator.custom_objects.name,\n                                                    dict[KerasEstimator.custom_objects.name],\n                                                    None, None)\n\n        for key, val in dict.items():\n            dict[key] = _param_deserializer_fn(key, val, keras_utils, custom_objects)\n        return dict\n\n\nclass KerasEstimatorParamsReadable(MLReadable):\n    @classmethod\n    def read(cls):\n        """"""Returns a KerasEstimatorParamsReader instance for this class.""""""\n        return KerasEstimatorParamsReader(cls)\n\n\nclass KerasEstimator(HorovodEstimator, KerasEstimatorParamsReadable,\n                     KerasEstimatorParamsWritable):\n    """"""Spark Estimator for fitting Keras models to a DataFrame.\n\n    Supports standalone `keras` and `tf.keras`, and TensorFlow 1.X and 2.X.\n\n    Args:\n        num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.\n        model: Keras model to train.\n        backend: Optional Backend object for running distributed training function. Defaults to SparkBackend with\n                 `num_proc` worker processes. Cannot be specified if `num_proc` is also provided.\n        store: Store object that abstracts reading and writing of intermediate data and run results.\n        custom_objects: Optional dictionary mapping names (strings) to custom classes or functions to be considered\n                        during serialization/deserialization.\n        optimizer: Keras optimizer to be converted into a `hvd.DistributedOptimizer` for training.\n        loss: Keras loss or list of losses.\n        loss_weights: Optional list of float weight values to assign each loss.\n        sample_weight_col: Optional column indicating the weight of each sample.\n        gradient_compression: Gradient compression used by `hvd.DistributedOptimizer`.\n        metrics: Optional metrics to record.\n        feature_cols: Column names used as feature inputs to the model. Must be a list with each feature\n                      mapping to a sequential argument in the model\'s forward() function.\n        label_cols: Column names used as labels.  Must be a list with one label for each output of the model.\n        validation: Optional validation column name (string) where every row in the column is either 1/True or 0/False,\n                    or validation split (float) giving percent of data to be randomly selected for validation.\n        callbacks: Keras callbacks.\n        batch_size: Number of rows from the DataFrame per batch.\n        epochs: Number of epochs to train.\n        verbose: Verbosity level [0, 2] (default: 1).\n        shuffle_buffer_size: Optional size of in-memory shuffle buffer in rows. Allocating a larger buffer size\n                             increases randomness of shuffling at the cost of more host memory. Defaults to estimating\n                             with an assumption of 4GB of memory per host.\n        partitions_per_process: Number of Parquet partitions to assign per worker process from `num_proc` (default: 10).\n        run_id: Optional unique ID for this run for organization in the Store. Will be automatically assigned if not\n                provided.\n        train_steps_per_epoch: Number of steps to train each epoch. Useful for testing that model trains successfully.\n                               Defaults to training the entire dataset each epoch.\n        validation_steps_per_epoch: Number of validation steps to perform each epoch.\n        transformation_fn: Optional function that takes a row as its parameter\n                           and returns a modified row that is then fed into the\n                           train or validation step. This transformation is\n                           applied after batching. See Petastorm [TransformSpec](https://github.com/uber/petastorm/blob/master/petastorm/transform.py)\n                           for more details. Note that this fucntion constructs\n                           another function which should perform the\n                           transformation.\n        train_reader_num_workers: This parameter specifies the number of parallel processes that\n                               read the training data from data store and apply data\n                               transformations to it. Increasing this number\n                               will generally increase the reading rate but will also\n                               increase the memory footprint. More processes are\n                               particularly useful if the bandwidth to the data store is not\n                               high enough, or users need to apply transformation such as\n                               decompression or data augmentation on raw data.\n        val_reader_num_workers: Similar to the train_reader_num_workers.\n    """"""\n\n    custom_objects = Param(Params._dummy(), \'custom_objects\', \'custom objects\')\n    _keras_pkg_type = Param(Params._dummy(), \'_keras_pkg_type\', \'keras package type\')\n\n    @keyword_only\n    def __init__(self,\n                 num_proc=None,\n                 model=None,\n                 backend=None,\n                 store=None,\n                 custom_objects=None,\n                 optimizer=None,\n                 loss=None,\n                 loss_weights=None,\n                 sample_weight_col=None,\n                 gradient_compression=None,\n                 metrics=None,\n                 feature_cols=None,\n                 label_cols=None,\n                 validation=None,\n                 callbacks=None,\n                 batch_size=None,\n                 epochs=None,\n                 verbose=None,\n                 shuffle_buffer_size=None,\n                 partitions_per_process=None,\n                 run_id=None,\n                 train_steps_per_epoch=None,\n                 validation_steps_per_epoch=None,\n                 transformation_fn=None,\n                 train_reader_num_workers=None,\n                 val_reader_num_workers=None):\n\n        super(KerasEstimator, self).__init__()\n\n        self._setDefault(optimizer=None,\n                         custom_objects={},\n                         _keras_pkg_type=None)\n\n        kwargs = self._input_kwargs\n        self.setParams(**kwargs)\n\n    def _get_keras_utils(self):\n        # This function determines the keras package type of the Estimator based on the passed\n        # optimizer and model and updates _keras_pkg_type parameter.\n\n        model_type = None\n        model = self.getModel()\n        if model:\n            if isinstance(model, tf.keras.Model):\n                model_type = TF_KERAS\n            elif is_instance_of_bare_keras_model(model):\n                model_type = BARE_KERAS\n            else:\n                raise ValueError(\n                    ""model has to be an instance of tensorflow.keras.Model or keras.Model"")\n\n        optimizer_type = None\n        optimizer = self.getOptimizer()\n        if optimizer:\n            if isinstance(optimizer, str):\n                optimizer_type = None\n            elif isinstance(optimizer, tf.keras.optimizers.Optimizer):\n                optimizer_type = TF_KERAS\n            elif is_instance_of_bare_keras_optimizer(optimizer):\n                optimizer_type = BARE_KERAS\n            else:\n                raise ValueError(""invalid optimizer type"")\n\n        types = set([model_type, optimizer_type])\n        types.discard(None)\n\n        if len(types) > 1:\n            raise ValueError(\'mixed keras and tf.keras values for optimizers and model\')\n        elif len(types) == 1:\n            pkg_type = types.pop()\n            super(KerasEstimator, self)._set(_keras_pkg_type=pkg_type)\n\n            if pkg_type == TF_KERAS:\n                return TFKerasUtil\n            elif pkg_type == BARE_KERAS:\n                return BareKerasUtil\n            else:\n                raise ValueError(""invalid keras type"")\n\n    def setCustomObjects(self, value):\n        return self._set(custom_objects=value)\n\n    def getCustomObjects(self):\n        return self.getOrDefault(self.custom_objects)\n\n    def _check_metadata_compatibility(self, metadata):\n        input_shapes, output_shapes = self.get_model_shapes()\n        util.check_shape_compatibility(metadata,\n                                       self.getFeatureCols(),\n                                       self.getLabelCols(),\n                                       input_shapes=input_shapes,\n                                       output_shapes=output_shapes)\n\n    def get_model_shapes(self):\n        model = self.getModel()\n        input_shapes = [[dim if dim else -1 for dim in input.shape.as_list()]\n                        for input in model.inputs]\n        output_shapes = [[dim if dim else -1 for dim in output.shape.as_list()]\n                         for output in model.outputs]\n        return input_shapes, output_shapes\n\n    def _fit_on_prepared_data(self, backend, train_rows, val_rows, metadata, avg_row_size, dataset_idx=None):\n        self._check_params(metadata)\n        keras_utils = self._get_keras_utils()\n\n        run_id = self.getRunId()\n        if run_id is None:\n            run_id = \'keras_\' + str(int(time.time()))\n\n        if self._has_checkpoint(run_id):\n            serialized_model = self._load_model_from_checkpoint(run_id)\n        else:\n            serialized_model = self._compile_model(keras_utils)\n\n        # Workaround:\n        # https://stackoverflow.com/questions/50583056/is-there-any-way-to-set-java-opts-for-tensorflow-process/50615570\n        env = {\'LIBHDFS_OPTS\': \'-Xms2048m -Xmx2048m\'}\n\n        trainer = remote.RemoteTrainer(self, metadata, keras_utils, run_id, dataset_idx)\n        handle = backend.run(trainer,\n                             args=(serialized_model, train_rows, val_rows, avg_row_size),\n                             env=env)\n        return self._create_model(handle, run_id, metadata)\n\n    def _load_model_from_checkpoint(self, run_id):\n        store = self.getStore()\n        last_ckpt_path = store.get_checkpoint_path(run_id)\n\n        if self.getVerbose():\n            print(\'Resuming training from last checkpoint: {}\'.format(last_ckpt_path))\n\n        model_bytes = store.read(last_ckpt_path)\n        return codec.dumps_base64(model_bytes)\n\n    def _compile_model(self, keras_utils):\n        # Compile the model with all the parameters\n        model = self.getModel()\n\n        loss = self.getLoss()\n        loss_weights = self.getLossWeights()\n\n        if not loss:\n            raise ValueError(\'Loss parameter is required for the model to compile\')\n\n        optimizer = self.getOptimizer()\n        if not optimizer:\n            optimizer = model.optimizer\n\n        if not optimizer:\n            raise ValueError(\'Optimizer must be provided either as a parameter or as part of a \'\n                             \'compiled model\')\n\n        metrics = self.getMetrics()\n        gradient_compression = self.getGradientCompression()\n        optimizer_weight_values = optimizer.get_weights()\n\n        dist_optimizer_args = dict(optimizer=optimizer)\n        if gradient_compression:\n            dist_optimizer_args[\'compression\'] = gradient_compression\n\n        # Horovod: wrap optimizer with DistributedOptimizer.\n        dist_optimizer = keras_utils.get_horovod().DistributedOptimizer(**dist_optimizer_args)\n        model.compile(optimizer=dist_optimizer,\n                      loss=loss,\n                      loss_weights=loss_weights,\n                      metrics=metrics)\n\n        if optimizer_weight_values:\n            model.optimizer.set_weights(optimizer_weight_values)\n\n        return keras_utils.serialize_model(model)\n\n    def _create_model(self, run_results, run_id, metadata):\n        keras_utils = self._get_keras_utils()\n        keras_module = keras_utils.keras()\n        floatx = keras_module.backend.floatx()\n\n        custom_objects = self.getCustomObjects()\n\n        history, serialized_model, hvd_size = run_results[0]\n\n        def load_model_fn(x):\n            with keras_module.utils.custom_object_scope(custom_objects):\n                return keras_module.models.load_model(x)\n\n        model = keras_utils.deserialize_model(serialized_model, load_model_fn=load_model_fn)\n\n        # Here, learning rate is scaled down with the number of horovod workers.\n        # This is important the retraining of the model. User may retrain the model with\n        # different number of workers and we need the raw learning rate to adjust with the\n        # new number of workers.\n        scaled_lr = keras_module.backend.get_value(model.optimizer.lr)\n        keras_module.backend.set_value(model.optimizer.lr, scaled_lr / hvd_size)\n\n        return self.get_model_class()(**self._get_model_kwargs(\n            model, history, run_id, metadata, floatx))\n\n    def get_model_class(self):\n        return KerasModel\n\n    def _get_model_kwargs(self, model, history, run_id, metadata, floatx):\n        return dict(history=history,\n                    model=model,\n                    feature_columns=self.getFeatureCols(),\n                    label_columns=self.getLabelCols(),\n                    custom_objects=self.getCustomObjects(),\n                    run_id=run_id,\n                    _metadata=metadata,\n                    _floatx=floatx)\n\n\nclass KerasModel(HorovodModel, KerasEstimatorParamsReadable,\n                 KerasEstimatorParamsWritable):\n    """"""Spark Transformer wrapping a Keras model, used for making predictions on a DataFrame.\n\n    Retrieve the underlying Keras model by calling `keras_model.getModel()`.\n\n    Args:\n        history: List of metrics, one entry per epoch during training.\n        model: Trained Keras model.\n        feature_columns: List of feature column names.\n        label_columns: List of label column names.\n        custom_objects: Keras custom objects.\n        run_id: ID of the run used to train the model.\n    """"""\n\n    custom_objects = Param(Params._dummy(), \'custom_objects\', \'custom objects\')\n\n    # Setting _keras_pkg_type parameter helps us determine the type of keras package during\n    # deserializing the transformer\n    _keras_pkg_type = Param(Params._dummy(), \'_keras_pkg_type\', \'keras package type\')\n\n    _floatx = Param(Params._dummy(), \'_floatx\', \'keras default float type\')\n\n    @keyword_only\n    def __init__(self,\n                 history=None,\n                 model=None,\n                 feature_columns=None,\n                 label_columns=None,\n                 custom_objects=None,\n                 run_id=None,\n                 _metadata=None,\n                 _floatx=None):\n\n        super(KerasModel, self).__init__()\n\n        if label_columns:\n            self.setOutputCols([col + \'__output\' for col in label_columns])\n\n        self._setDefault(custom_objects={})\n\n        kwargs = self._input_kwargs\n        self.setParams(**kwargs)\n\n    def setCustomObjects(self, value):\n        return self._set(custom_objects=value)\n\n    def getCustomObjects(self):\n        return self.getOrDefault(self.custom_objects)\n\n    def _get_keras_utils(self, model=None):\n        # infer keras package from model\n        model = self.getModel()\n        if model:\n            if isinstance(model, tf.keras.Model):\n                pkg_type = TF_KERAS\n            elif is_instance_of_bare_keras_model(model):\n                pkg_type = BARE_KERAS\n            else:\n                raise ValueError(\n                    ""model has to be an instance of tensorflow.keras.Model or keras.Model"")\n\n            super(KerasModel, self)._set(_keras_pkg_type=pkg_type)\n\n            if pkg_type == TF_KERAS:\n                return TFKerasUtil\n            elif pkg_type == BARE_KERAS:\n                return BareKerasUtil\n            else:\n                raise ValueError(""invalid keras type"")\n\n        raise ValueError(""model is not set"")\n\n    def _get_floatx(self):\n        return self.getOrDefault(self._floatx)\n\n    # To run locally on OS X, need export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n    def _transform(self, df):\n        keras_utils = self._get_keras_utils()\n        floatx = self._get_floatx()\n        serialized_model = keras_utils.serialize_model(self.getModel())\n\n        label_cols = self.getLabelColumns()\n        output_cols = self.getOutputCols()\n        feature_cols = self.getFeatureColumns()\n        custom_objects = self.getCustomObjects()\n        metadata = self._get_metadata()\n\n        pin_cpu = remote._pin_cpu_fn()\n\n        def predict(rows):\n            import tensorflow as tf\n            from pyspark import Row\n            from pyspark.ml.linalg import DenseVector, SparseVector\n\n            k = keras_utils.keras()\n            k.backend.set_floatx(floatx)\n\n            # Do not use GPUs for prediction, use single CPU core per task.\n            pin_cpu(tf, k)\n\n            def load_model_fn(x):\n                with k.utils.custom_object_scope(custom_objects):\n                    return k.models.load_model(x)\n\n            model = keras_utils.deserialize_model(serialized_model,\n                                                  load_model_fn=load_model_fn)\n\n            input_shapes = [[dim if dim else -1 for dim in input.shape.as_list()]\n                            for input in model.inputs]\n\n            def to_array(item):\n                if type(item) in [DenseVector or SparseVector]:\n                    return item.toArray()\n                else:\n                    return np.array(item)\n\n            def to_numpy(item):\n                # Some versions of TensorFlow will return an EagerTensor\n                return item.numpy() if hasattr(item, \'numpy\') else item\n\n            # Perform predictions.\n            for row in rows:\n                fields = row.asDict().copy()\n                preds = model.predict_on_batch(\n                    [to_array(row[feature_cols[i]]).reshape(input_shapes[i])\n                     for i in range(len(feature_cols))])\n                preds = [to_numpy(item) for item in preds]\n\n                for label_col, output_col, pred, in zip(label_cols, output_cols, preds):\n                    meta = metadata[label_col]\n                    col_type = meta[\'spark_data_type\']\n                    # dtype for DenseVector and SparseVector is always np.float64\n                    if col_type == DenseVector:\n                        shape = np.prod(pred.shape)\n                        flattened_pred = pred.reshape(shape, )\n                        field = DenseVector(flattened_pred)\n                    elif col_type == SparseVector:\n                        shape = meta[\'shape\']\n                        flattened_pred = pred.reshape(shape, )\n                        nonzero_indices = flattened_pred.nonzero()[0]\n                        field = SparseVector(shape, nonzero_indices,\n                                             flattened_pred[nonzero_indices])\n                    else:\n                        # If the column is scalar type, int, float, etc.\n                        value = pred[0]\n                        python_type = util.spark_scalar_to_python_type(col_type)\n                        if issubclass(python_type, numbers.Integral):\n                            value = round(value)\n                        field = python_type(value)\n\n                    fields[output_col] = field\n\n                yield Row(**fields)\n\n        return df.rdd.mapPartitions(predict).toDF()\n'"
horovod/spark/keras/optimizer.py,1,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\n\nimport h5py\n\nfrom horovod.run.common.util import codec\n\n\ndef serialize_bare_keras_optimizer(x):\n    import keras\n    from horovod.spark.keras.bare import save_bare_keras_optimizer\n    return _serialize_keras_optimizer(x,\n                                      optimizer_class=keras.optimizers.Optimizer,\n                                      save_optimizer_fn=save_bare_keras_optimizer)\n\n\ndef deserialize_bare_keras_optimizer(x):\n    from horovod.spark.keras.bare import load_bare_keras_optimizer\n    return _deserialize_keras_optimizer(x,\n                                        load_keras_optimizer_fn=load_bare_keras_optimizer)\n\n\ndef serialize_tf_keras_optimizer(x):\n    import tensorflow as tf\n    from horovod.spark.keras.tensorflow import save_tf_keras_optimizer\n\n    return _serialize_keras_optimizer(x,\n                                      optimizer_class=tf.keras.optimizers.Optimizer,\n                                      save_optimizer_fn=save_tf_keras_optimizer)\n\n\ndef deserialize_tf_keras_optimizer(x):\n    from horovod.spark.keras.tensorflow import load_tf_keras_optimizer\n\n    return _deserialize_keras_optimizer(x,\n                                        load_keras_optimizer_fn=load_tf_keras_optimizer)\n\n\ndef _serialize_keras_optimizer(opt, optimizer_class, save_optimizer_fn):\n    if isinstance(opt, str):\n        return opt\n    elif isinstance(opt, optimizer_class):\n        bio = io.BytesIO()\n        with h5py.File(bio, \'w\') as f:\n            save_optimizer_fn(opt, f)\n        return codec.dumps_base64(bio.getvalue())\n    else:\n        raise \\\n            ValueError(\'Keras optimizer has to be an instance of str or keras.optimizers.Optimizer\')\n\n\ndef is_string(obj):\n    return isinstance(obj, str)\n\n\ndef _deserialize_keras_optimizer(serialized_opt, load_keras_optimizer_fn):\n    if is_string(serialized_opt):\n        return serialized_opt\n    bio = io.BytesIO(serialized_opt)\n    with h5py.File(bio, \'r\') as f:\n        return load_keras_optimizer_fn(f)\n'"
horovod/spark/keras/remote.py,11,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport contextlib\nimport io\nimport math\nimport os\n\nimport h5py\nimport tensorflow as tf\n\nfrom distutils.version import LooseVersion\n\nfrom horovod.spark.common import constants\nfrom horovod.run.common.util import codec\n\n\nPETASTORM_HDFS_DRIVER = constants.PETASTORM_HDFS_DRIVER\nTOTAL_BUFFER_MEMORY_CAP_GIB = constants.TOTAL_BUFFER_MEMORY_CAP_GIB\nBYTES_PER_GIB = constants.BYTES_PER_GIB\n\n\ndef RemoteTrainer(estimator, metadata, keras_utils, run_id, dataset_idx):\n    # Estimator parameters\n    label_columns = estimator.getLabelCols()\n    feature_columns = estimator.getFeatureCols()\n    user_callbacks = estimator.getCallbacks()\n    batch_size = estimator.getBatchSize()\n    epochs = estimator.getEpochs()\n    train_steps_per_epoch = estimator.getTrainStepsPerEpoch()\n    validation_steps_per_epoch = estimator.getValidationStepsPerEpoch()\n    sample_weight_col = estimator.getSampleWeightCol()\n    custom_objects = estimator.getCustomObjects()\n    should_validate = estimator.getValidation()\n    user_shuffle_buffer_size = estimator.getShufflingBufferSize()\n    user_verbose = estimator.getVerbose()\n\n    # Data reader parameters\n    train_reader_worker_count = estimator.getTrainReaderNumWorker()\n    val_reader_worker_count = estimator.getValReaderNumWorker()\n\n    # Model parameters\n    input_shapes, output_shapes = estimator.get_model_shapes()\n    output_names = estimator.getModel().output_names\n\n    # Keras implementation\n    keras_module = keras_utils.keras()\n    floatx = keras_module.backend.floatx()\n    get_horovod = keras_utils.horovod_fn()\n    get_keras = keras_utils.keras_fn()\n    make_dataset = keras_utils.make_dataset_fn(\n        feature_columns, label_columns, sample_weight_col, metadata,\n        input_shapes, output_shapes, output_names, batch_size)\n    fit = keras_utils.fit_fn(epochs)\n    transformation_fn = estimator.getTransformationFn()\n    transformation = transformation_fn if transformation_fn else None\n\n    # Utility functions\n    deserialize_keras_model = _deserialize_keras_model_fn()\n    calculate_shuffle_buffer_size = _calculate_shuffle_buffer_size_fn()\n    pin_gpu = _pin_gpu_fn()\n\n    # Storage\n    store = estimator.getStore()\n    remote_store = store.to_remote(run_id, dataset_idx)\n\n    def SyncCallback(root_path, sync_to_store_fn, keras):\n        class _SyncCallback(keras.callbacks.Callback):\n            def on_epoch_end(self, epoch, logs=None):\n                sync_to_store_fn(root_path)\n\n        return _SyncCallback()\n\n    @contextlib.contextmanager\n    def empty_batch_reader():\n        yield None\n\n    def train(serialized_model, train_rows, val_rows, avg_row_size):\n        from petastorm import TransformSpec, make_reader, make_batch_reader\n\n        k = get_keras()\n        k.backend.set_floatx(floatx)\n\n        hvd = get_horovod()\n        hvd.init()\n        pin_gpu(hvd, tf, k)\n\n        if not user_shuffle_buffer_size:\n            shuffle_buffer_size = calculate_shuffle_buffer_size(\n                hvd, avg_row_size, train_rows / hvd.size())\n        else:\n            shuffle_buffer_size = user_shuffle_buffer_size\n\n        # needs to be deserialized in the with scope\n        with k.utils.custom_object_scope(custom_objects):\n            model = deserialize_keras_model(\n                serialized_model, lambda x: hvd.load_model(x))\n\n        # Horovod: adjust learning rate based on number of processes.\n        k.backend.set_value(model.optimizer.lr,\n                            k.backend.get_value(model.optimizer.lr) * hvd.size())\n\n        # Verbose mode 1 will print a progress bar\n        verbose = user_verbose if hvd.rank() == 0 else 0\n\n        transform_spec = None\n        if transformation:\n            transform_spec = TransformSpec(transformation)\n\n        with remote_store.get_local_output_dir() as run_output_dir:\n            callbacks = [\n                # Horovod: broadcast initial variable states from rank 0 to all other processes.\n                # This is necessary to ensure consistent initialization of all workers when\n                # training is started with random weights or restored from a checkpoint.\n                hvd.callbacks.BroadcastGlobalVariablesCallback(root_rank=0),\n\n                # Horovod: average metrics among workers at the end of every epoch.\n                #\n                # Note: This callback must be in the list before the ReduceLROnPlateau,\n                # TensorBoard, or other metrics-based callbacks.\n                hvd.callbacks.MetricAverageCallback(),\n            ]\n            callbacks += user_callbacks\n\n            # Horovod: save checkpoints only on the first worker to prevent other workers from\n            # corrupting them.\n            if hvd.rank() == 0:\n                ckpt_file = os.path.join(run_output_dir, remote_store.checkpoint_filename)\n                logs_dir = os.path.join(run_output_dir, remote_store.logs_subdir)\n\n                callbacks.append(k.callbacks.ModelCheckpoint(ckpt_file))\n                if remote_store.saving_runs:\n                    callbacks.append(k.callbacks.TensorBoard(logs_dir))\n                    callbacks.append(SyncCallback(run_output_dir, remote_store.sync, k))\n\n            if train_steps_per_epoch is None:\n                steps_per_epoch = int(math.ceil(train_rows / batch_size / hvd.size()))\n            else:\n                steps_per_epoch = train_steps_per_epoch\n\n            if validation_steps_per_epoch is None:\n                # math.ceil because if val_rows is smaller than batch_size we still get the at least\n                # one step. float(val_rows) because val_rows/batch_size evaluates to zero before\n                # math.ceil\n                validation_steps = int(math.ceil(float(val_rows) / batch_size / hvd.size())) \\\n                    if should_validate else None\n            else:\n                validation_steps = validation_steps_per_epoch\n\n            schema_fields = feature_columns + label_columns\n            if sample_weight_col:\n                schema_fields.append(sample_weight_col)\n\n            # In general, make_batch_reader is faster than make_reader for reading the dataset.\n            # However, we found out that make_reader performs data transformations much faster than\n            # make_batch_reader with parallel worker processes. Therefore, the default reader\n            # we choose is make_batch_reader unless there are data transformations.\n            reader_factory_kwargs = dict()\n            if transform_spec:\n                reader_factory = make_reader\n                reader_factory_kwargs[\'pyarrow_serialize\'] = True\n                is_batch_reader = False\n            else:\n                reader_factory = make_batch_reader\n                is_batch_reader = True\n\n            # Petastorm: read data from the store with the correct shard for this rank\n            # setting num_epochs=None will cause an infinite iterator\n            # and enables ranks to perform training and validation with\n            # unequal number of samples\n            with reader_factory(remote_store.train_data_path,\n                                num_epochs=None,\n                                cur_shard=hvd.rank(),\n                                reader_pool_type=\'process\',\n                                workers_count=train_reader_worker_count,\n                                shard_count=hvd.size(),\n                                hdfs_driver=PETASTORM_HDFS_DRIVER,\n                                schema_fields=schema_fields,\n                                transform_spec=transform_spec,\n                                **reader_factory_kwargs) as train_reader:\n                with reader_factory(remote_store.val_data_path,\n                                    num_epochs=None,\n                                    cur_shard=hvd.rank(),\n                                    reader_pool_type=\'process\',\n                                    workers_count=val_reader_worker_count,\n                                    shard_count=hvd.size(),\n                                    hdfs_driver=PETASTORM_HDFS_DRIVER,\n                                    schema_fields=schema_fields,\n                                    transform_spec=transform_spec,\n                                    **reader_factory_kwargs) \\\n                    if should_validate else empty_batch_reader() as val_reader:\n\n                    train_data = make_dataset(train_reader, shuffle_buffer_size,\n                                              is_batch_reader, shuffle=True)\n                    val_data = make_dataset(val_reader, shuffle_buffer_size,\n                                            is_batch_reader, shuffle=False) \\\n                        if val_reader else None\n\n                    history = fit(model, train_data, val_data, steps_per_epoch,\n                                  validation_steps, callbacks, verbose)\n\n            # Dataset API usage currently displays a wall of errors upon termination.\n            # This global model registration ensures clean termination.\n            # Tracked in https://github.com/tensorflow/tensorflow/issues/24570\n            globals()[\'_DATASET_FINALIZATION_HACK\'] = model\n\n            if hvd.rank() == 0:\n                with open(ckpt_file, \'rb\') as f:\n                    return history.history, codec.dumps_base64(f.read()), hvd.size()\n    return train\n\n\ndef _deserialize_keras_model_fn():\n    def deserialize_keras_model(model_bytes, load_model_fn):\n        """"""Deserialize model from byte array encoded in base 64.""""""\n        model_bytes = codec.loads_base64(model_bytes)\n        bio = io.BytesIO(model_bytes)\n        with h5py.File(bio, \'r\') as f:\n            return load_model_fn(f)\n    return deserialize_keras_model\n\n\ndef _calculate_shuffle_buffer_size_fn():\n    def calculate_shuffle_buffer_size(hvd, avg_row_size, train_row_count_per_worker):\n        """"""\n        Determines the shuffling buffer size such that each worker gets at most 1GB for shuffling\n        buffer such that on a single machine, among all the workers on that machine, at most\n        memory_cap_gb GB are allocated for shuffling buffer. Also, it ensures that the buffer size\n        is identical among all the workers.\n\n        example 1:\n        memory_cap_gb = 4\n        machine1: 8 workers\n        machine2: 3 workers\n        shuffle_buffer_size = 0.5 GB\n\n        example 2:\n        memory_cap_gb = 4\n            machine1: 2 workers\n            machine2: 3 workers\n        shuffle_buffer_size = 1 GB\n\n        example 3:\n        memory_cap_gb = 4\n            machine1: 2 workers\n            machine2: 8 workers\n            machine3: 5 workers\n        shuffle_buffer_size = 0.5 GB\n        """"""\n        local_size = hvd.local_size()\n        local_sizes = hvd.allgather([local_size])\n        max_local_size = int(max(local_sizes))\n\n        if max_local_size > TOTAL_BUFFER_MEMORY_CAP_GIB:\n            shuffle_buffer_size = TOTAL_BUFFER_MEMORY_CAP_GIB * BYTES_PER_GIB / avg_row_size / max_local_size\n        else:\n            shuffle_buffer_size = BYTES_PER_GIB / avg_row_size\n\n        return int(min(shuffle_buffer_size, train_row_count_per_worker))\n\n    return calculate_shuffle_buffer_size\n\n\ndef _pin_gpu_fn():\n    # Horovod: pin GPU to be used to process local rank (one GPU per process)\n    return _pin_gpu_tensorflow2_fn() if LooseVersion(tf.__version__) >= LooseVersion(\'2.0.0\') \\\n        else _pin_gpu_tensorflow1_fn()\n\n\ndef _pin_gpu_tensorflow2_fn():\n    def fn(hvd, tf, keras):\n        gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        if gpus:\n            tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \'GPU\')\n    return fn\n\n\ndef _pin_gpu_tensorflow1_fn():\n    def fn(hvd, tf, keras):\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.gpu_options.visible_device_list = str(hvd.local_rank())\n        keras.backend.set_session(tf.Session(config=config))\n    return fn\n\n\ndef _pin_cpu_fn():\n    return _pin_cpu_tensorflow2_fn() if LooseVersion(tf.__version__) >= LooseVersion(\'2.0.0\') \\\n        else _pin_cpu_tensorflow1_fn()\n\n\ndef _pin_cpu_tensorflow2_fn():\n    def fn(tf, keras):\n        os.environ[\'CUDA_VISIBLE_DEVICES\'] = \'-1\'\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(1)\n    return fn\n\n\ndef _pin_cpu_tensorflow1_fn():\n    def fn(tf, keras):\n        config = tf.ConfigProto(device_count={\'GPU\': 0})\n        config.inter_op_parallelism_threads = 1\n        config.intra_op_parallelism_threads = 1\n        keras.backend.set_session(tf.Session(config=config))\n    return fn\n'"
horovod/spark/keras/tensorflow.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport json\n\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras import optimizers\nfrom tensorflow.python.platform import tf_logging as logging\nfrom tensorflow.python.util import serialization\n\n\ndef save_tf_keras_optimizer(optimizer, h5py_file):\n    if isinstance(optimizer, optimizers.TFOptimizer):\n        logging.warning(\n            \'TensorFlow optimizers do not \'\n            \'make it possible to access \'\n            \'optimizer attributes or optimizer state \'\n            \'after instantiation. \'\n            \'As a result, we cannot save the optimizer \'\n            \'as part of the model save file.\'\n            \'You will have to compile your model again after loading it. \'\n            \'Prefer using a Keras optimizer instead \'\n            \'(see keras.io/optimizers).\')\n    else:\n        h5py_file.attrs[\'training_config\'] = json.dumps(\n            {\n                \'optimizer_config\': {\n                    \'class_name\': optimizer.__class__.__name__,\n                    \'config\': optimizer.get_config()\n                }\n            },\n            default=serialization.get_json_type).encode(\'utf8\')\n\n        # Save optimizer weights.\n        symbolic_weights = getattr(optimizer, \'weights\')\n        if symbolic_weights:\n            optimizer_weights_group = h5py_file.create_group(\'optimizer_weights\')\n            weight_values = K.batch_get_value(symbolic_weights)\n            weight_names = []\n            for w, val in zip(symbolic_weights, weight_values):\n                name = str(w.name)\n                weight_names.append(name.encode(\'utf8\'))\n            optimizer_weights_group.attrs[\'weight_names\'] = weight_names\n            for name, val in zip(weight_names, weight_values):\n                param_dset = optimizer_weights_group.create_dataset(\n                    name, val.shape, dtype=val.dtype)\n                if not val.shape:\n                    # scalar\n                    param_dset[()] = val\n                else:\n                    param_dset[:] = val\n    h5py_file.flush()\n\n\ndef load_tf_keras_optimizer(h5py_file, custom_objects=None):\n    if not custom_objects:\n        custom_objects = {}\n\n    def convert_custom_objects(obj):\n        """"""Handles custom object lookup.\n\n        Arguments:\n            obj: object, dict, or list.\n\n        Returns:\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        """"""\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj\n\n    optimizer, optimizer_weight_values = None, None\n\n    # instantiate optimizer\n    training_config = h5py_file.attrs.get(\'training_config\')\n    training_config = json.loads(training_config.decode(\'utf-8\'))\n    optimizer_config = training_config[\'optimizer_config\']\n    optimizer = optimizers.deserialize(optimizer_config, custom_objects=custom_objects)\n\n    if \'optimizer_weights\' in h5py_file:\n        optimizer_weights_group = h5py_file[\'optimizer_weights\']\n        optimizer_weight_names = [\n            n.decode(\'utf8\')\n            for n in optimizer_weights_group.attrs[\'weight_names\']\n        ]\n        optimizer_weight_values = [optimizer_weights_group[n].value for n in\n                                   optimizer_weight_names]\n    if optimizer_weight_values:\n        optimizer.set_weights(optimizer_weight_values)\n    return optimizer\n'"
horovod/spark/keras/util.py,19,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\n\nimport h5py\nimport numpy as np\nimport tensorflow as tf\n\nfrom horovod.run.common.util import codec\n\nfrom horovod.spark.common import constants, params\nfrom horovod.spark.keras import optimizer, remote\n\n\nBARE_KERAS = \'keras\'\nTF_KERAS = \'tf_keras\'\n\n\nclass TFKerasUtil(object):\n    type = TF_KERAS\n\n    @staticmethod\n    def fit_fn(epochs):\n        def fn(model, train_data, val_data, steps_per_epoch, validation_steps, callbacks, verbose):\n            return model.fit(\n                train_data,\n                validation_data=val_data,\n                steps_per_epoch=steps_per_epoch,\n                validation_steps=validation_steps,\n                callbacks=callbacks,\n                verbose=verbose,\n                epochs=epochs)\n        return fn\n\n    @staticmethod\n    def make_dataset_fn(feature_columns, label_columns, sample_weight_col, metadata,\n                        input_shapes, output_shapes, output_names, batch_size):\n        # Check if any of the columns are only SparseVector\n        has_sparse_col = any(metadata[col][\'is_sparse_vector_only\']\n                             for col in label_columns + feature_columns)\n\n        reshape = TFKerasUtil._reshape_fn(\n            sample_weight_col, feature_columns, label_columns, metadata)\n        prep_data_tf_keras = TFKerasUtil._prep_data_fn(\n            has_sparse_col, sample_weight_col, feature_columns,\n            label_columns, input_shapes, output_shapes, output_names)\n\n        def fn(reader, shuffle_buffer_size, is_batch_reader, shuffle=False):\n            from petastorm.tf_utils import make_petastorm_dataset\n\n            dataset = make_petastorm_dataset(reader)\n            if is_batch_reader:\n                dataset = dataset.apply(tf.data.experimental.unbatch())\n\n            if shuffle:\n                dataset = dataset.shuffle(shuffle_buffer_size)\n\n            # Decompress sparse data if necessary\n            if has_sparse_col:\n                dataset = dataset.batch(1).map(reshape)\n\n            dataset = dataset.batch(batch_size).map(prep_data_tf_keras)\n            return dataset\n        return fn\n\n    @staticmethod\n    def get_horovod():\n        return TFKerasUtil.horovod_fn()()\n\n    @staticmethod\n    def horovod_fn():\n        def fn():\n            import horovod.tensorflow.keras as hvd\n            return hvd\n        return fn\n\n    @staticmethod\n    def keras():\n        return TFKerasUtil.keras_fn()()\n\n    @staticmethod\n    def keras_fn():\n        def fn():\n            import tensorflow.keras as tf_keras\n            return tf_keras\n        return fn\n\n    @staticmethod\n    def serialize_optimizer(*args, **kwargs):\n        return optimizer.serialize_tf_keras_optimizer(*args, **kwargs)\n\n    @staticmethod\n    def deserialize_optimizer(*args, **kwargs):\n        return optimizer.deserialize_tf_keras_optimizer(*args, **kwargs)\n\n    @staticmethod\n    def serialize_model(*args, **kwargs):\n        def serialize_keras_model(x):\n            return _serialize_keras_model(x, TFKerasUtil.keras().models.save_model)\n\n        return serialize_keras_model(*args, **kwargs)\n\n    @staticmethod\n    def deserialize_model(*args, **kwargs):\n        return _deserialize_keras_model(*args, **kwargs)\n\n    @staticmethod\n    def serialize_param_value(*args, **kwargs):\n        def _serialize_param(x, y):\n            return _serialize_param_value(x, y,\n                                          serialize_model_fn=TFKerasUtil.serialize_model,\n                                          serialize_opt_fn=TFKerasUtil.serialize_optimizer)\n\n        return _serialize_param(*args, **kwargs)\n\n    @staticmethod\n    def _reshape_fn(sample_weight_col, feature_columns, label_columns, metadata):\n        CUSTOM_SPARSE = constants.CUSTOM_SPARSE\n        custom_sparse_to_dense = _custom_sparse_to_dense_fn()\n\n        def reshape(row):\n            new_row = {}\n            if sample_weight_col:\n                new_row[sample_weight_col] = getattr(row, sample_weight_col)\n\n            for col in feature_columns + label_columns:\n                v = getattr(row, col)\n                intermediate_format = metadata[col][\'intermediate_format\']\n                if intermediate_format == CUSTOM_SPARSE:\n                    reshaped_v = tf.reshape(v, [metadata[col][\'max_size\'] * 2 + 1])\n                    v = custom_sparse_to_dense(reshaped_v, metadata[col][\'shape\'])\n\n                new_row[col] = v\n            return new_row\n\n        return reshape\n\n    @staticmethod\n    def _prep_data_fn(has_sparse_col, sample_weight_col, feature_columns, label_columns,\n                      input_shapes, output_shapes, output_names):\n        def _get_from_dict(row, col):\n            return row[col]\n\n        def _get_from_named_tuple(row, col):\n            return getattr(row, col)\n\n        if has_sparse_col:\n            get_col_from_row_fn = _get_from_dict\n        else:\n            get_col_from_row_fn = _get_from_named_tuple\n\n        num_inputs = len(feature_columns)\n        num_labels = len(label_columns)\n\n        def as_tuple(v):\n            return tuple(v) if len(v) > 1 else v[0]\n\n        def prep(row):\n            if sample_weight_col:\n                sample_weight = get_col_from_row_fn(row, sample_weight_col)\n                return (\n                    tuple(\n                        tf.reshape(get_col_from_row_fn(row, feature_columns[i]), input_shapes[i])\n                        for i\n                        in range(num_inputs)),\n                    as_tuple([\n                        tf.reshape(get_col_from_row_fn(row, label_columns[j]), output_shapes[j]) for\n                        j\n                        in range(num_labels)]),\n                    {name: tf.reshape(sample_weight, [-1]) for name in output_names}\n                )\n            else:\n                return (\n                    tuple(\n                        tf.reshape(get_col_from_row_fn(row, feature_columns[i]), input_shapes[i])\n                        for i\n                        in range(num_inputs)),\n                    as_tuple([\n                        tf.reshape(get_col_from_row_fn(row, label_columns[j]), output_shapes[j]) for\n                        j\n                        in range(num_labels)])\n                )\n\n        return prep\n\n\nclass BareKerasUtil(object):\n    type = BARE_KERAS\n\n    @staticmethod\n    def fit_fn(epochs):\n        def fn(model, train_data, val_data, steps_per_epoch, validation_steps, callbacks, verbose):\n            return model.fit_generator(\n                train_data,\n                validation_data=val_data,\n                steps_per_epoch=steps_per_epoch,\n                validation_steps=validation_steps,\n                callbacks=callbacks,\n                verbose=verbose,\n                epochs=epochs)\n\n        return fn\n\n    @staticmethod\n    def make_dataset_fn(feature_columns, label_columns, sample_weight_col, metadata,\n                        input_shapes, output_shapes, output_names, batch_size):\n        batch_generator = BareKerasUtil._batch_generator_fn(\n            feature_columns, label_columns, sample_weight_col,\n            input_shapes, output_shapes, batch_size, metadata)\n\n        def fn(reader, shuffle_buffer_size, shuffle=False):\n            return batch_generator(reader, shuffle_buffer_size)\n\n        return fn\n\n    @staticmethod\n    def get_horovod():\n        return BareKerasUtil.horovod_fn()()\n\n    @staticmethod\n    def horovod_fn():\n        def fn():\n            import horovod.keras as hvd\n            return hvd\n        return fn\n\n    @staticmethod\n    def keras():\n        return BareKerasUtil.keras_fn()()\n\n    @staticmethod\n    def keras_fn():\n        def fn():\n            import keras\n            return keras\n        return fn\n\n    @staticmethod\n    def serialize_optimizer(*args, **kwargs):\n        return optimizer.serialize_bare_keras_optimizer(*args, **kwargs)\n\n    @staticmethod\n    def deserialize_optimizer(*args, **kwargs):\n        return optimizer.deserialize_bare_keras_optimizer(*args, **kwargs)\n\n    @staticmethod\n    def serialize_model(*args, **kwargs):\n        def serialize_keras_model(x):\n            return _serialize_keras_model(x, BareKerasUtil.keras().models.save_model)\n\n        return serialize_keras_model(*args, **kwargs)\n\n    @staticmethod\n    def deserialize_model(*args, **kwargs):\n        return _deserialize_keras_model(*args, **kwargs)\n\n    @staticmethod\n    def serialize_param_value(*args, **kwargs):\n        def _serialize_param(x, y):\n            return _serialize_param_value(x, y,\n                                          serialize_model_fn=BareKerasUtil.serialize_model,\n                                          serialize_opt_fn=BareKerasUtil.serialize_optimizer)\n\n        return _serialize_param(*args, **kwargs)\n\n    @staticmethod\n    def _batch_generator_fn(feature_columns, label_columns, sample_weight_col,\n                            input_shapes, output_shapes, batch_size, metadata):\n        prepare_data_bare_keras = BareKerasUtil._prepare_data_fn(metadata)\n\n        cols = feature_columns + label_columns\n        if sample_weight_col:\n            cols.append(sample_weight_col)\n\n        def batch_generator(reader, shuffle_buffer_size, shuffle=False):\n            while True:\n                num_rows_read_sofar = 0\n                data = None\n                while num_rows_read_sofar < shuffle_buffer_size:\n                    # Each call to next reads one row group at a time. reader is an infinite\n                    # generator and never ends\n                    row_group_data = next(reader)\n                    if not data:\n                        data = {col: getattr(row_group_data, col) for col in cols}\n                    else:\n                        for col in cols:\n                            data[col] = np.concatenate((data[col],\n                                                        getattr(row_group_data, col)))\n                    num_rows_read_sofar += row_group_data[0].shape[0]\n\n                # Create a permutation of len of data and use it to shuffle each numpy array\n                perm = np.random.permutation(num_rows_read_sofar) \\\n                    if shuffle else list(range(num_rows_read_sofar))\n\n                inputs = [prepare_data_bare_keras(data[col][perm], col, shape) for col, shape\n                          in zip(feature_columns, input_shapes)]\n                labels = [prepare_data_bare_keras(data[col][perm], col, shape) for col, shape\n                          in zip(label_columns, output_shapes)]\n\n                num_outputs = len(label_columns)\n                sample_weights = None\n                if sample_weight_col:\n                    sample_weights = data[sample_weight_col][perm]\n\n                batch_count = int(len(inputs[0]) / batch_size)\n                for i in range(0, batch_count):\n                    if sample_weight_col:\n                        # We use the same sample weight for all the outputs of the sample\n                        sample_weight = sample_weights[i * batch_size:(i + 1) * batch_size]\n                        sample_weight_for_batch = [sample_weight for i in range(num_outputs)]\n\n                        yield (\n                            [input[i * batch_size:(i + 1) * batch_size] for input in inputs],\n                            [label[i * batch_size:(i + 1) * batch_size] for label in labels],\n                            sample_weight_for_batch)\n                    else:\n                        yield (\n                            [input[i * batch_size:(i + 1) * batch_size] for input in inputs],\n                            [label[i * batch_size:(i + 1) * batch_size] for label in labels])\n\n        return batch_generator\n\n    @staticmethod\n    def _prepare_data_fn(metadata):\n        convert_custom_sparse_to_dense = BareKerasUtil._convert_custom_sparse_to_dense_fn()\n        CUSTOM_SPARSE = constants.CUSTOM_SPARSE\n\n        def prepare_data(rows, col, shape):\n            intermediate_format = metadata[col][\'intermediate_format\']\n            if intermediate_format != CUSTOM_SPARSE:\n                return rows.reshape(shape)\n\n            dense_rows = []\n            shape_1d = metadata[col][\'shape\']\n            for row in rows:\n                dense_row = convert_custom_sparse_to_dense(row, shape_1d)\n                dense_rows.append(dense_row)\n            return np.array(dense_rows).reshape(shape)\n        return prepare_data\n\n    @staticmethod\n    def _convert_custom_sparse_to_dense_fn():\n        def convert_custom_sparse_to_dense(row, shape):\n            size = int(row[0])\n            dense_row = np.zeros(shape)\n            dense_row[row[1:size + 1].astype(int)] = row[size + 1:2 * size + 1]\n            return dense_row\n        return convert_custom_sparse_to_dense\n\n\ndef is_instance_of_bare_keras_optimizer(opt):\n    import keras\n    return isinstance(opt, keras.optimizers.Optimizer)\n\n\ndef is_instance_of_bare_keras_model(model):\n    import keras\n    return isinstance(model, keras.models.Model)\n\n\ndef _serialize_keras_model(model, save_model_fn):\n    """"""Serialize model into byte array encoded into base 64.""""""\n    bio = io.BytesIO()\n    with h5py.File(bio, \'w\') as f:\n        save_model_fn(model, f)\n    return codec.dumps_base64(bio.getvalue())\n\n\ndef _deserialize_keras_model(model_bytes, load_model_fn):\n    deserialize_keras_model = remote._deserialize_keras_model_fn()\n    return deserialize_keras_model(model_bytes, load_model_fn)\n\n\ndef _serialize_param_value(param_name, param_val, serialize_model_fn, serialize_opt_fn):\n    if param_val is None:\n        return param_val\n\n    if param_name in [params.EstimatorParams.backend.name, params.EstimatorParams.store.name]:\n        # We do not serialize backend and store. These params have to be regenerated for each\n        # run of the pipeline\n        return None\n    elif param_name == params.EstimatorParams.model.name:\n        return serialize_model_fn(param_val)\n    if param_name == params.EstimatorParams.optimizer.name:\n        return serialize_opt_fn(param_val)\n    else:\n        return codec.dumps_base64(param_val)\n\n\ndef _custom_sparse_to_dense_fn():\n    # TODO(fardin): ask petastorm team about codecs for sparse and dense vectors and see if that is\n    # a better solution\n    def custom_sparse_to_dense(custom_sparse_vec, dense_shape):\n        # original sparse vector:   v = {1:2.0, 3:.4.5, 5:7.1}\n        # custom sparse vector:     v = [3, 1, 3, 5, 2.0, 4.5, 7.1]\n        # dense vector:             v = [0, 2.0, 0, 4.5, 0, 7.1]\n\n        # Get the first element from custom_sparse_vec. This element is the size of\n        # non-zero elements in the original sparse vector.\n        sparse_vector_size = tf.cast(tf.gather(custom_sparse_vec, 0, axis=0), tf.int32)\n        sparse_vector_size = tf.reshape(sparse_vector_size, [1])\n\n        # get the first sparse_vector_size elements of the custom_sparse_vec which are the\n        # indices\n        indices_1d = tf.cast(\n            tf.slice(custom_sparse_vec, begin=tf.constant([1]), size=sparse_vector_size),\n            tf.int64)\n        indices_reshaped = tf.reshape(indices_1d,\n                                      tf.concat([sparse_vector_size, tf.constant([1])], 0))\n        # have to pad the indices to match the expected format by the SparseTensor\n        indices = tf.pad(indices_reshaped, [[0, 0], [1, 0]], ""CONSTANT"")\n\n        # get the second sparse_vector_size elements of the custom_sparse_vec which are\n        # the values\n        begin_index = sparse_vector_size + tf.constant(1)\n        values = tf.slice(custom_sparse_vec, begin=begin_index, size=sparse_vector_size)\n\n        # construct a sparse vector with the indices and values\n        dense_shape = [1, dense_shape]\n        sparse_tensor = tf.sparse.SparseTensor(indices=indices, values=values,\n                                               dense_shape=dense_shape)\n        # convert the sparse vector into a dense vector\n        return tf.sparse.to_dense(sparse_tensor)\n\n    return custom_sparse_to_dense\n'"
horovod/spark/task/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport time\n\nfrom horovod.run.util.threads import in_thread\nfrom horovod.spark.task import task_info, task_service\nfrom horovod.spark.task.task_info import get_available_devices\nfrom horovod.spark.driver import driver_service\nfrom horovod.run.common.util import codec, secret\n\n\ndef _parent_process_monitor(initial_ppid):\n    try:\n        while True:\n            if initial_ppid != os.getppid():\n                # Parent process died, terminate\n                os._exit(1)\n            time.sleep(1)\n    except:\n        # Avoids an error message during Python interpreter shutdown.\n        pass\n\n\ndef task_exec(driver_addresses, settings, rank_env):\n    # Die if parent process terminates\n    in_thread(target=_parent_process_monitor, args=(os.getppid(),))\n\n    key = codec.loads_base64(os.environ[secret.HOROVOD_SECRET_KEY])\n    rank = int(os.environ[rank_env])\n    driver_client = driver_service.SparkDriverClient(driver_addresses, key,\n                                                     verbose=settings.verbose)\n    task_index = driver_client.task_index_by_rank(rank)\n    task_addresses = driver_client.all_task_addresses(task_index)\n    task_client = task_service.SparkTaskClient(task_index, task_addresses, key,\n                                               verbose=settings.verbose)\n    task_info.set_resources(task_client.resources())\n\n    fn, args, kwargs = driver_client.code()\n    result = fn(*args, **kwargs)\n    task_client.register_code_result(result)\n'"
horovod/spark/task/gloo_exec_fn.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport sys\n\nfrom horovod.spark.task import task_exec\nfrom horovod.run.common.util import codec\n\n\ndef main(driver_addresses, settings):\n    task_exec(driver_addresses, settings, \'HOROVOD_RANK\')\n\n\nif __name__ == \'__main__\':\n    if len(sys.argv) != 3:\n        print(\'Usage: %s <driver addresses> <settings>\' % sys.argv[0])\n        sys.exit(1)\n    main(codec.loads_base64(sys.argv[1]), codec.loads_base64(sys.argv[2]))\n'"
horovod/spark/task/mpirun_exec_fn.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport sys\n\nfrom horovod.spark.task import task_exec\nfrom horovod.run.common.util import codec\n\n\ndef main(driver_addresses, settings):\n    # prepend HOROVOD_SPARK_PYTHONPATH to PYTHONPATH\n    if \'HOROVOD_SPARK_PYTHONPATH\' in os.environ:\n        ppath = os.environ[\'HOROVOD_SPARK_PYTHONPATH\']\n\n        # add injected HOROVOD_SPARK_PYTHONPATH to sys.path\n        for p in reversed(ppath.split(os.pathsep)):\n            sys.path.insert(1, p)  # don\'t put it in front which is usually .\n\n        if \'PYTHONPATH\' in os.environ:\n            ppath = os.pathsep.join([ppath, os.environ[\'PYTHONPATH\']])\n        os.environ[\'PYTHONPATH\'] = ppath\n\n    # change current working dir to where the Spark worker runs\n    # because orted runs this script where mpirun was executed\n    # this env var is injected by the Spark task service\n    work_dir = os.environ.get(\'HOROVOD_SPARK_WORK_DIR\')\n    if work_dir:\n        if settings.verbose >= 2:\n            print(""Changing cwd from {} to {}"".format(os.getcwd(), work_dir))\n        os.chdir(work_dir)\n\n    task_exec(driver_addresses, settings, \'OMPI_COMM_WORLD_RANK\')\n\n\nif __name__ == \'__main__\':\n    if len(sys.argv) != 3:\n        print(\'Usage: %s <driver addresses> <settings>\' % sys.argv[0])\n        sys.exit(1)\n    main(codec.loads_base64(sys.argv[1]), codec.loads_base64(sys.argv[2]))\n'"
horovod/spark/task/task_info.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\nclass TaskInfo(object):\n    def __init__(self):\n        self.resources = dict()\n\n\n_info = TaskInfo()\n\n\ndef get_available_devices():\n    if \'gpu\' not in _info.resources:\n        return []\n    return _info.resources[\'gpu\'].addresses\n\n\ndef set_resources(resources):\n    _info.resources = resources\n'"
horovod/spark/task/task_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom distutils.version import LooseVersion\n\nimport os\nimport pyspark\n\nfrom horovod.run.common.util import codec, secret\nfrom horovod.run.common.service import task_service\n\n\nclass ResourcesRequest(object):\n    """"""Request Spark resources info for this task.""""""\n\n\nclass ResourcesResponse(object):\n    def __init__(self, resources):\n        self.resources = resources\n        """"""Dictionary containing resource info.""""""\n\n\nclass GetTaskToTaskAddressesRequest(object):\n    def __init__(self, task_index, all_task_addresses):\n        self.task_index = task_index\n        """"""Task index of other task service.""""""\n\n        self.all_task_addresses = all_task_addresses\n        """"""Map of interface to list of (ip, port) pairs of other task service.""""""\n\n\nclass GetTaskToTaskAddressesResponse(object):\n    def __init__(self, task_addresses_for_task):\n        self.task_addresses_for_task = task_addresses_for_task\n        """"""Map of interface to list of (ip, port) pairs.""""""\n\n\nclass SparkTaskService(task_service.BasicTaskService):\n    NAME_FORMAT = \'task service #%d\'\n\n    @staticmethod\n    def _get_command_env(key):\n        # on a Spark cluster we need our train function to see the Spark worker environment\n        # this includes PYTHONPATH, HADOOP_TOKEN_FILE_LOCATION and _HOROVOD_SECRET_KEY\n        env = os.environ.copy()\n\n        # we inject the secret key here\n        env[secret.HOROVOD_SECRET_KEY] = codec.dumps_base64(key)\n\n        # we also need to provide the current working dir to mpirun_exec_fn.py\n        env[\'HOROVOD_SPARK_WORK_DIR\'] = os.getcwd()\n\n        return env\n\n    def __init__(self, index, key, nics, verbose=0):\n        super(SparkTaskService, self).__init__(SparkTaskService.NAME_FORMAT % index,\n                                               key, nics,\n                                               SparkTaskService._get_command_env(key),\n                                               verbose)\n\n        self._key = key\n\n    def _handle(self, req, client_address):\n        if isinstance(req, ResourcesRequest):\n            return ResourcesResponse(self._get_resources())\n\n        if isinstance(req, GetTaskToTaskAddressesRequest):\n            next_task_index = req.task_index\n            next_task_addresses = req.all_task_addresses\n            # We request interface matching to weed out all the NAT\'ed interfaces.\n            next_task_client = \\\n                SparkTaskClient(next_task_index, next_task_addresses,\n                                self._key, self._verbose,\n                                match_intf=True)\n            return GetTaskToTaskAddressesResponse(next_task_client.addresses())\n\n        return super(SparkTaskService, self)._handle(req, client_address)\n\n    def _get_resources(self):\n        if LooseVersion(pyspark.__version__) >= LooseVersion(\'3.0.0\'):\n            from pyspark import TaskContext\n            return TaskContext.get().resources()\n        return dict()\n\n\nclass SparkTaskClient(task_service.BasicTaskClient):\n\n    def __init__(self, index, task_addresses, key, verbose, match_intf=False):\n        super(SparkTaskClient, self).__init__(SparkTaskService.NAME_FORMAT % index,\n                                              task_addresses, key, verbose,\n                                              match_intf=match_intf)\n\n    def resources(self):\n        resp = self._send(ResourcesRequest())\n        return resp.resources\n\n    def get_task_addresses_for_task(self, task_index, all_task_addresses):\n        resp = self._send(GetTaskToTaskAddressesRequest(task_index, all_task_addresses))\n        return resp.task_addresses_for_task\n'"
horovod/spark/torch/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom horovod.spark.torch.estimator import TorchEstimator\nfrom horovod.spark.torch.estimator import TorchModel\n'"
horovod/spark/torch/estimator.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport horovod.spark.common._namedtuple_fix\n\nimport copy\nimport io\nimport numbers\nimport time\n\nfrom pyspark import keyword_only\nfrom pyspark.ml.param.shared import Param, Params\nfrom pyspark.ml.util import MLWritable, MLReadable\n\nfrom horovod.run.common.util import codec\nfrom horovod.spark.common import util\nfrom horovod.spark.common.estimator import HorovodEstimator, HorovodModel\nfrom horovod.spark.common.params import EstimatorParams\nfrom horovod.spark.common.serialization import \\\n    HorovodParamsWriter, HorovodParamsReader\nfrom horovod.spark.torch import remote\nfrom horovod.spark.torch.util import deserialize_fn, serialize_fn, \\\n    save_into_bio\n\nimport numpy as np\nimport torch\nimport torch.utils.data\n\n\ndef _torch_param_serialize(param_name, param_val):\n    if param_name in [EstimatorParams.backend.name, EstimatorParams.store.name]:\n        # We do not serialize backend and store. These params have to be regenerated for each\n        # run of the pipeline\n        return None\n\n    if param_val is None:\n        return None\n\n    return codec.dumps_base64(param_val)\n\n\nclass TorchEstimatorParamsWriter(HorovodParamsWriter):\n    def saveImpl(self, path):\n        # Write the parameters\n        HorovodParamsWriter.saveMetadata(self.instance, path, self.sc,\n                                         param_serializer_fn=_torch_param_serialize)\n\n\nclass TorchEstimatorParamsWritable(MLWritable):\n    def write(self):\n        return TorchEstimatorParamsWriter(self)\n\n\nclass TorchEstimatorParamsReader(HorovodParamsReader):\n    def _deserialize_dict(self, dict_values):\n        deserialized_dict = dict()\n        for key, val in dict_values.items():\n            if val is None:\n                deserialized_dict[key] = None\n            else:\n                deserialized_dict[key] = codec.loads_base64(val)\n        return deserialized_dict\n\n\nclass TorchEstimatorParamsReadable(MLReadable):\n    @classmethod\n    def read(cls):\n        """"""Returns a DefaultParamsReader instance for this class.""""""\n        return TorchEstimatorParamsReader(cls)\n\n\nclass TorchEstimator(HorovodEstimator, TorchEstimatorParamsWritable,\n                     TorchEstimatorParamsReadable):\n    """"""Spark Estimator for fitting PyTorch models to a DataFrame.\n\n    Args:\n        num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.\n        model: PyTorch model to train.\n        backend: Optional Backend object for running distributed training function. Defaults to SparkBackend with\n                 `num_proc` worker processes. Cannot be specified if `num_proc` is also provided.\n        store: Store object that abstracts reading and writing of intermediate data and run results.\n        optimizer: PyTorch optimizer to be converted into a `hvd.DistributedOptimizer` for training.\n        loss: PyTorch loss or list of losses.\n        loss_constructors: Optional functions that generate losses.\n        metrics: Optional metrics to record.\n        loss_weights: Optional list of float weight values to assign each loss.\n        sample_weight_col: Optional column indicating the weight of each sample.\n        gradient_compression: Gradient compression used by `hvd.DistributedOptimizer`.\n        feature_cols: Column names used as feature inputs to the model. Must be a list with each feature\n                      mapping to a sequential argument in the model\'s forward() function.\n        input_shapes: List of shapes for each input tensor to the model.\n        validation: Optional validation column name (string) where every row in the column is either 1/True or 0/False,\n                    or validation split (float) giving percent of data to be randomly selected for validation.\n        label_cols: Column names used as labels.  Must be a list with one label for each output of the model.\n        batch_size: Number of rows from the DataFrame per batch.\n        epochs: Number of epochs to train.\n        verbose: Verbosity level [0, 2] (default: 1).\n        shuffle_buffer_size: Optional size of in-memory shuffle buffer in rows. Allocating a larger buffer size\n                             increases randomness of shuffling at the cost of more host memory. Defaults to estimating\n                             with an assumption of 4GB of memory per host.\n        partitions_per_process: Number of Parquet partitions to assign per worker process from `num_proc` (default: 10).\n        run_id: Optional unique ID for this run for organization in the Store. Will be automatically assigned if not\n                provided.\n        train_minibatch_fn: Optional custom function to execute within the training loop. Defaults to standard\n                            gradient descent process.\n        train_steps_per_epoch: Number of steps to train each epoch. Useful for testing that model trains successfully.\n                               Defaults to training the entire dataset each epoch.\n        validation_steps_per_epoch: Number of validation steps to perform each epoch.\n        transformation_fn: Optional function that takes a row as its parameter\n                           and returns a modified row that is then fed into the\n                           train or validation step. This transformation is\n                           applied after batching. See Petastorm [TransformSpec](https://github.com/uber/petastorm/blob/master/petastorm/transform.py)\n                           for more details. Note that this fucntion constructs\n                           another function which should perform the\n                           transformation.\n        train_reader_num_workers: This parameter specifies the number of parallel processes that\n                               read the training data from data store and apply data\n                               transformations to it. Increasing this number\n                               will generally increase the reading rate but will also\n                               increase the memory footprint. More processes are\n                               particularly useful if the bandwidth to the data store is not\n                               high enough, or users need to apply transformation such as\n                               decompression or data augmentation on raw data.\n        val_reader_num_workers: Similar to the train_reader_num_workers.\n    """"""\n\n    input_shapes = Param(Params._dummy(), \'input_shapes\', \'input layer shapes\')\n    loss_constructors = Param(Params._dummy(), \'loss_constructors\',\n                              \'functions that construct the loss\')\n    train_minibatch_fn = Param(Params._dummy(), \'train_minibatch_fn\',\n                               \'functions that construct the minibatch train function for torch\')\n\n    @keyword_only\n    def __init__(self,\n                 num_proc=None,\n                 model=None,\n                 backend=None,\n                 store=None,\n                 optimizer=None,\n                 loss=None,\n                 loss_constructors=None,\n                 metrics=None,\n                 loss_weights=None,\n                 sample_weight_col=None,\n                 gradient_compression=None,\n                 feature_cols=None,\n                 input_shapes=None,\n                 validation=None,\n                 label_cols=None,\n                 callbacks=None,\n                 batch_size=None,\n                 epochs=None,\n                 verbose=1,\n                 shuffle_buffer_size=None,\n                 partitions_per_process=None,\n                 run_id=None,\n                 train_minibatch_fn=None,\n                 train_steps_per_epoch=None,\n                 validation_steps_per_epoch=None,\n                 transformation_fn=None,\n                 train_reader_num_workers=None,\n                 val_reader_num_workers=None):\n        super(TorchEstimator, self).__init__()\n        self._setDefault(loss_constructors=None,\n                         input_shapes=None,\n                         train_minibatch_fn=None,\n                         transformation_fn=None)\n\n        kwargs = self._input_kwargs\n\n        if EstimatorParams.loss.name in kwargs and TorchEstimator.loss_constructors.name in kwargs:\n            raise ValueError(""only one of loss_constructors and loss parameters can be specified."")\n\n        self.setParams(**kwargs)\n\n    def setTrainMinibatchFn(self, value):\n        return self._set(train_minibatch_fn=value)\n\n    def getTrainMinibatchFn(self):\n        return self.getOrDefault(self.train_minibatch_fn)\n\n    def setInputShapes(self, value):\n        return self._set(input_shapes=value)\n\n    def getInputShapes(self):\n        return self.getOrDefault(self.input_shapes)\n\n    def setLossConstructors(self, value):\n        return self._set(loss_constructors=value)\n\n    def getLossConstructors(self):\n        return self.getOrDefault(self.loss_constructors)\n\n    def _get_optimizer(self):\n        return self.getOrDefault(self.optimizer)\n\n    # Overwrites Model\'s getOptimizer method\n    def getOptimizer(self):\n        model = self.getModel()\n        if model:\n            optimizer = self._get_optimizer()\n            optimizer_cls = optimizer.__class__\n            optimizer_state = optimizer.state_dict()\n            optimzer = optimizer_cls(model.parameters(), lr=1)\n            optimzer.load_state_dict(optimizer_state)\n            return optimzer\n        else:\n            return self._get_optimizer()\n\n    def _check_metadata_compatibility(self, metadata):\n        util.check_shape_compatibility(metadata,\n                                       self.getFeatureCols(),\n                                       self.getLabelCols(),\n                                       input_shapes=self.getInputShapes())\n\n    def _fit_on_prepared_data(self, backend, train_rows, val_rows, metadata, avg_row_size, dataset_idx=None):\n        self._check_params(metadata)\n\n        run_id = self.getRunId()\n        if run_id is None:\n            run_id = \'pytorch_\' + str(int(time.time()))\n\n        last_checkpoint_state = None\n        if self._has_checkpoint(run_id):\n            last_checkpoint_state = self._load_checkpoint(run_id)\n\n        # Model parameters\n        model_pre_train = self.getModel()\n        model_state = model_pre_train.state_dict()\n        serialized_model = serialize_fn()(model_pre_train)\n\n        # Optimizer parameters\n        optimizer = self._get_optimizer()\n        optimizer_cls = optimizer.__class__\n        optimizer_state = optimizer.state_dict()\n\n        # Combine model and optimizer state\n        model_opt_state = {\'model\': model_state, \'optimizer\': optimizer_state} \\\n            if last_checkpoint_state is None else last_checkpoint_state\n        model_opt_state_serialized = save_into_bio(model_opt_state, torch.save)\n\n        trainer = remote.RemoteTrainer(self, metadata, last_checkpoint_state, run_id, dataset_idx)\n        handle = backend.run(trainer,\n                             args=(serialized_model, optimizer_cls, model_opt_state_serialized,\n                                   train_rows, val_rows, avg_row_size),\n                             env={})\n        return self._create_model(handle, run_id, metadata)\n\n    def _load_checkpoint(self, run_id):\n        store = self.getStore()\n        last_ckpt_path = store.get_checkpoint_path(run_id)\n\n        if self.getVerbose():\n            print(\'Resuming training from last checkpoint: {}\'.format(last_ckpt_path))\n\n        ckpt_file = io.BytesIO(store.read(last_ckpt_path))\n        return torch.load(ckpt_file)\n\n    def _create_model(self, run_results, run_id, metadata):\n        history, serialized_checkpoint = run_results[0]\n        serialized_checkpoint.seek(0)\n        best_checkpoint = torch.load(serialized_checkpoint, map_location=torch.device(\'cpu\'))\n\n        model = copy.deepcopy(self.getModel())\n        optimizer = copy.deepcopy(self.getOptimizer())\n\n        model.load_state_dict(best_checkpoint[\'model\'])\n        optimizer.load_state_dict(best_checkpoint[\'optimizer\'])\n\n        return self.get_model_class()(**self._get_model_kwargs(\n            model, history, optimizer, run_id, metadata))\n\n    def get_model_class(self):\n        return TorchModel\n\n    def _get_model_kwargs(self, model, history, optimizer, run_id, metadata):\n        return dict(history=history,\n                    model=model,\n                    optimizer=optimizer,\n                    feature_columns=self.getFeatureCols(),\n                    input_shapes=self.getInputShapes(),\n                    label_columns=self.getLabelCols(),\n                    run_id=run_id,\n                    _metadata=metadata,\n                    loss=self.getLoss(),\n                    loss_constructors=self.getLossConstructors())\n\n\nclass TorchModel(HorovodModel, TorchEstimatorParamsWritable, TorchEstimatorParamsReadable):\n    """"""Spark Transformer wrapping a PyTorch model, used for making predictions on a DataFrame.\n\n    Retrieve the underlying PyTorch model by calling `torch_model.getModel()`.\n\n    Args:\n        history: List of metrics, one entry per epoch during training.\n        model: Trained PyTorch model.\n        feature_columns: List of feature column names.\n        label_columns: List of label column names.\n        optimizer: PyTorch optimizer used during training, containing updated state.\n        run_id: ID of the run used to train the model.\n        loss: PyTorch loss(es).\n        loss_constructors: PyTorch loss constructors.\n    """"""\n\n    optimizer = Param(Params._dummy(), \'optimizer\', \'optimizer\')\n    input_shapes = Param(Params._dummy(), \'input_shapes\', \'input layer shapes\')\n    loss = Param(Params._dummy(), \'loss\', \'loss\')\n    loss_constructors = Param(Params._dummy(), \'loss_constructors\',\n                              \'functions that construct the loss\')\n\n    @keyword_only\n    def __init__(self,\n                 history=None,\n                 model=None,\n                 feature_columns=None,\n                 input_shapes=None,\n                 label_columns=None,\n                 optimizer=None,\n                 run_id=None,\n                 _metadata=None,\n                 loss=None,\n                 loss_constructors=None):\n        super(TorchModel, self).__init__()\n\n        if label_columns:\n            self.setOutputCols([col + \'__output\' for col in label_columns])\n\n        self._setDefault(optimizer=None,\n                         loss=None,\n                         loss_constructors=None,\n                         input_shapes=None)\n\n        kwargs = self._input_kwargs\n        self.setParams(**kwargs)\n\n    def setLoss(self, value):\n        return self._set(loss=value)\n\n    def getLoss(self):\n        return self.getOrDefault(self.loss)\n\n    def setLossConstructors(self, value):\n        return self._set(loss_constructors=value)\n\n    def getLossConstructors(self):\n        return self.getOrDefault(self.loss_constructors)\n\n    def setInputShapes(self, value):\n        return self._set(input_shapes=value)\n\n    def getInputShapes(self):\n        return self.getOrDefault(self.input_shapes)\n\n    def setOptimizer(self, value):\n        return self._set(optimizer=value)\n\n    def _get_optimizer(self):\n        return self.getOrDefault(self.optimizer)\n\n    def getOptimizer(self):\n        model = self.getModel()\n        if model:\n            _optimizer = self._get_optimizer()\n            optimizer_cls = _optimizer.__class__\n            optimizer_state = _optimizer.state_dict()\n            optimzer = optimizer_cls(model.parameters(), lr=1)\n            optimzer.load_state_dict(optimizer_state)\n            return optimzer\n        else:\n            return self._get_optimizer()\n\n    # To run locally on OS X, need export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n    def _transform(self, df):\n        model_pre_predict = self.getModel()\n        model_pre_predict.eval()\n\n        deserialize = deserialize_fn()\n        serialize = serialize_fn()\n        serialized_model = serialize(model_pre_predict)\n\n        input_shapes = self.getInputShapes()\n        label_cols = self.getLabelColumns()\n        output_cols = self.getOutputCols()\n        feature_cols = self.getFeatureColumns()\n        metadata = self._get_metadata()\n\n        def predict(rows):\n            from pyspark import Row\n            from pyspark.ml.linalg import DenseVector, SparseVector\n\n            model = deserialize(serialized_model)\n            # Perform predictions.\n            for row in rows:\n                fields = row.asDict().copy()\n\n                # Note: if the col is SparseVector, torch.tensor(col) correctly converts it to a\n                # dense torch tensor.\n                data = [torch.tensor([row[col]]).reshape(shape) for\n                        col, shape in zip(feature_cols, input_shapes)]\n\n                with torch.no_grad():\n                    preds = model(*data)\n\n                if not isinstance(preds, list) and not isinstance(preds, tuple):\n                    preds = [preds]\n\n                for label_col, output_col, pred in zip(label_cols, output_cols, preds):\n                    meta = metadata[label_col]\n                    col_type = meta[\'spark_data_type\']\n                    # dtype for dense and spark tensor is always np.float64\n                    if col_type == DenseVector:\n                        shape = np.prod(pred.shape)\n                        flattened_pred = pred.reshape(shape, )\n                        field = DenseVector(flattened_pred)\n                    elif col_type == SparseVector:\n                        shape = meta[\'shape\']\n                        flattened_pred = pred.reshape(shape, )\n                        nonzero_indices = flattened_pred.nonzero()[0]\n                        field = SparseVector(shape, nonzero_indices,\n                                             flattened_pred[nonzero_indices])\n                    elif pred.shape.numel() == 1:\n                        # If the column is scalar type, int, float, etc.\n                        value = pred.item()\n                        python_type = util.spark_scalar_to_python_type(col_type)\n                        if issubclass(python_type, numbers.Integral):\n                            value = round(value)\n                        field = python_type(value)\n                    else:\n                        field = DenseVector(pred.reshape(-1))\n\n                    fields[output_col] = field\n\n                yield Row(**fields)\n\n        return df.rdd.mapPartitions(predict).toDF()\n'"
horovod/spark/torch/remote.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport contextlib\nimport io\nimport math\nimport os\n\nimport torch\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom horovod.spark.common import constants\nfrom horovod.spark.common.util import to_list\nfrom horovod.spark.torch.util import deserialize_fn\n\nPETASTORM_HDFS_DRIVER = constants.PETASTORM_HDFS_DRIVER\nMETRIC_PRINT_FREQUENCY = constants.METRIC_PRINT_FREQUENCY\nTOTAL_BUFFER_MEMORY_CAP_GIB = constants.TOTAL_BUFFER_MEMORY_CAP_GIB\nBYTES_PER_GIB = constants.BYTES_PER_GIB\nCUSTOM_SPARSE = constants.CUSTOM_SPARSE\n\n\ndef RemoteTrainer(estimator, metadata, last_checkpoint_state, run_id, dataset_idx):\n    # Estimator parameters\n    gradient_compression = estimator.getGradientCompression()\n    input_shapes = estimator.getInputShapes()\n    feature_columns = estimator.getFeatureCols()\n    label_columns = estimator.getLabelCols()\n    num_labels = len(label_columns)\n    should_validate = estimator.getValidation()\n    batch_size = estimator.getBatchSize()\n    epochs = estimator.getEpochs()\n    train_steps_per_epoch = estimator.getTrainStepsPerEpoch()\n    validation_steps_per_epoch = estimator.getValidationStepsPerEpoch()\n    sample_weight_col = estimator.getSampleWeightCol()\n    metric_fn_groups = estimator.getMetrics()\n    user_shuffle_buffer_size = estimator.getShufflingBufferSize()\n    user_verbose = estimator.getVerbose()\n    train_minibatch_fn = estimator.getTrainMinibatchFn()\n    train_minibatch = train_minibatch_fn if train_minibatch_fn else _train_minibatch_fn()\n    loss_fns_pre_train = to_list(estimator.getLoss(), num_labels)\n    loss_constructors = to_list(estimator.getLossConstructors(), num_labels)\n    transformation_fn = estimator.getTransformationFn()\n    transformation = transformation_fn if transformation_fn else None\n\n    # If loss weight is not provided, use equal loss for all the labels\n    loss_weights = estimator.getLossWeights()\n    if not loss_weights:\n        loss_weights = [float(1) / num_labels for _ in range(num_labels)]\n    else:\n        if not isinstance(loss_weights, list) or \\\n                len(loss_weights) != len(label_columns):\n            raise ValueError(\'loss_weights needs to be a list with the same \'\n                             \'length as the label_columns.\')\n\n    # Data reader parameters\n    train_reader_worker_count = estimator.getTrainReaderNumWorker()\n    val_reader_worker_count = estimator.getValReaderNumWorker()\n\n    # Utility functions\n    deserialize = deserialize_fn()\n    get_optimizer_with_unscaled_lr = _get_optimizer_with_unscaled_lr_fn()\n    calculate_shuffle_buffer_size = _calculate_shuffle_buffer_size_fn()\n    construct_metric_value_holders = _construct_metric_value_holders_fn()\n    metric_cls = _metric_cls()\n    prepare_np_data = _prepare_np_data_fn()\n    get_metric_avgs = _get_metric_avgs_fn()\n    update_metrics = _update_metrics_fn(metric_fn_groups)\n    write_metrics_summary = _write_metrics_summary_fn()\n    calculate_loss = _calculate_loss_fn()\n\n    # Storage\n    store = estimator.getStore()\n    remote_store = store.to_remote(run_id, dataset_idx)\n\n    @contextlib.contextmanager\n    def empty_batch_reader():\n        yield None\n\n    def train(serialized_model, optimizer_cls, model_opt_state_serialized,\n              train_rows, val_rows, avg_row_size):\n        from petastorm import TransformSpec, make_reader, make_batch_reader\n        from petastorm.pytorch import BatchedDataLoader\n        import torch\n        import horovod.torch as hvd\n\n        # Deserializing objects\n        model_opt_state = torch.load(model_opt_state_serialized)\n        model = deserialize(serialized_model)\n\n        if loss_fns_pre_train:\n            loss_fns = loss_fns_pre_train\n        if loss_constructors:\n            local_vars = locals()\n            loss_fns = [loss_constructor(**local_vars) for loss_constructor in loss_constructors]\n\n        # Horovod: initialize library.\n        hvd.init()\n\n        if not user_shuffle_buffer_size:\n            shuffle_buffer_size = \\\n                calculate_shuffle_buffer_size(hvd, avg_row_size, train_rows / hvd.size())\n        else:\n            shuffle_buffer_size = user_shuffle_buffer_size\n\n        cuda_available = torch.cuda.is_available()\n        if cuda_available:\n            # Horovod: pin GPU to local rank.\n            torch.cuda.set_device(hvd.local_rank())\n            # Move model to GPU.\n            model.cuda()\n\n        # Optimizer object needs to be re-instantiated. Internally, it uses memory addresses of\n        # objects as their identity and therefore it cannot be serialized and then\n        # deserialized. The deserialized optimizer object stores the names of the parameters\n        # with their old memory addresses but in reality those are different than the\n        # reconstructed deserialized object and that creates problem.\n        # Learning rate is a required parameters in SGD optimizer. It will be overridden with\n        # load_state_dict.\n        optimizer = optimizer_cls(model.parameters(), lr=1)\n        optimizer_state = model_opt_state[\'optimizer\']\n\n        if last_checkpoint_state is not None:\n            model.load_state_dict(last_checkpoint_state[\'model\'])\n            optimizer.load_state_dict(last_checkpoint_state[\'optimizer\'])\n        else:\n            # scale the learning rate with the number of horovod workers\n            for i in range(len(optimizer_state[\'param_groups\'])):\n                optimizer_state[\'param_groups\'][i][\'lr\'] = \\\n                    optimizer_state[\'param_groups\'][i][\'lr\'] * hvd.size()\n\n            optimizer.load_state_dict(optimizer_state)\n\n        # Horovod: broadcast parameters & optimizer state.\n        hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n\n        for group in optimizer.param_groups:\n            for p in group[\'params\']:\n                if id(p) not in optimizer.state_dict()[\'state\']:\n                    p.grad = p.data.new(p.size()).zero_()\n        optimizer.step()\n        hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n        dist_optimizer_args = dict(optimizer=optimizer,\n                                   named_parameters=model.named_parameters())\n        if gradient_compression:\n            # Pass the compression arg only if it is specified by the user.\n            dist_optimizer_args[\'compression\'] = gradient_compression\n        # Horovod: wrap optimizer with DistributedOptimizer.\n        optimizer = hvd.DistributedOptimizer(**dist_optimizer_args)\n\n        # This function takes the current optimizer and constructs a new optimizer with the\n        # same state except with learning rate scaled down with the number of horovod workers.\n        # This is important the retraining of the model. User may retrain the model with\n        # different number of workers and we need the raw learning rate to adjust with the\n        # new number of workers.\n\n        transform_spec = None\n        if transformation:\n            transform_spec = TransformSpec(transformation)\n\n        schema_fields = feature_columns + label_columns\n        if sample_weight_col:\n            schema_fields.append(sample_weight_col)\n\n        if train_steps_per_epoch is None:\n            steps_per_epoch = int(math.ceil(float(train_rows) / batch_size / hvd.size()))\n        else:\n            steps_per_epoch = train_steps_per_epoch\n\n        with remote_store.get_local_output_dir() as run_output_dir:\n            logs_dir = os.path.join(run_output_dir, remote_store.logs_subdir)\n            log_writer = SummaryWriter(logs_dir) if hvd.rank() == 0 else None\n            ckpt_file = os.path.join(run_output_dir, remote_store.checkpoint_filename)\n\n            def save_checkpoint():\n                model.cpu()\n                optimizer_with_scaled_down_lr = \\\n                    get_optimizer_with_unscaled_lr(hvd, optimizer, optimizer_cls, model)\n                state = {\n                    \'model\': model.state_dict(),\n                    \'optimizer\': optimizer_with_scaled_down_lr.state_dict(),\n                }\n                torch.save(state, ckpt_file)\n                if cuda_available:\n                    model.cuda()\n\n            # In general, make_batch_reader is faster than make_reader for reading the dataset.\n            # However, we found out that make_reader performs data transformations much faster than\n            # make_batch_reader with parallel worker processes. Therefore, the default reader\n            # we choose is make_batch_reader unless there are data transformations.\n            reader_factory = None\n            reader_factory_kwargs = dict()\n            if transform_spec:\n                reader_factory = make_reader\n                reader_factory_kwargs[\'pyarrow_serialize\'] = True\n            else:\n                reader_factory = make_batch_reader\n\n            # Petastorm: read data from the store with the correct shard for this rank\n            # setting num_epochs=None will cause an infinite iterator\n            # and enables ranks to perform training and validation with\n            # unequal number of samples\n            with reader_factory(remote_store.train_data_path,\n                                num_epochs=None,\n                                cur_shard=hvd.rank(),\n                                reader_pool_type=\'process\',\n                                workers_count=train_reader_worker_count,\n                                shard_count=hvd.size(),\n                                hdfs_driver=PETASTORM_HDFS_DRIVER,\n                                schema_fields=schema_fields,\n                                transform_spec=transform_spec,\n                                **reader_factory_kwargs) as train_reader:\n                with reader_factory(remote_store.val_data_path,\n                                    num_epochs=None,\n                                    cur_shard=hvd.rank(),\n                                    reader_pool_type=\'process\',\n                                    workers_count=val_reader_worker_count,\n                                    shard_count=hvd.size(),\n                                    hdfs_driver=PETASTORM_HDFS_DRIVER,\n                                    schema_fields=schema_fields,\n                                    transform_spec=transform_spec,\n                                    **reader_factory_kwargs) \\\n                    if should_validate else empty_batch_reader() as val_reader:\n\n                    train_loader = BatchedDataLoader(train_reader,\n                                                     batch_size=batch_size,\n                                                     shuffling_queue_capacity=shuffle_buffer_size)\n                    train_loader_iter = iter(train_loader)\n\n                    def prepare_batch(row):\n                        inputs = [\n                            prepare_np_data(\n                                row[col].float(), col, metadata).reshape(shape)\n                            for col, shape in zip(feature_columns, input_shapes)]\n                        labels = [\n                            prepare_np_data(\n                                row[col].float(), col, metadata)\n                            for col in label_columns]\n\n                        sample_weights = row.get(sample_weight_col, None)\n                        if sample_weights is not None:\n                            sample_weights = sample_weights.float()\n                        if cuda_available:\n                            inputs = [input.cuda() for input in inputs]\n                            labels = [label.cuda() for label in labels]\n                            if sample_weights:\n                                sample_weights = sample_weights.cuda()\n                        return inputs, labels, sample_weights\n\n                    def transform_outputs(outputs, labels):\n                        if type(outputs) != tuple and type(outputs) != list:\n                            outputs = [outputs]\n\n                        # reshape labels to match the output shape of the model\n                        if hasattr(outputs[0], \'shape\'):\n                            labels = [label.reshape(output.shape)\n                                      if output.shape.numel() == label.shape.numel() else label\n                                      for label, output in zip(labels, outputs)]\n                        return outputs, labels\n\n                    def aggregate_metrics(stage, epoch, loss, metric_value_groups):\n                        all_metric_groups_values = get_metric_avgs(metric_value_groups)\n                        if remote_store.saving_runs:\n                            write_metrics_summary(\n                                stage, epoch, loss, all_metric_groups_values, log_writer)\n                        return {\n                            loss.name: loss.avg.item(),\n                            \'all_metrics\': all_metric_groups_values\n                        }\n\n                    def loss_fn(outputs, labels, sample_weights):\n                        loss = calculate_loss(outputs, labels, loss_weights, loss_fns, sample_weights)\n                        return loss\n\n                    def print_metrics(batch_idx, loss, metric_value_groups, phase):\n                        if user_verbose > 0 and hvd.rank() == 0 and \\\n                                batch_idx % METRIC_PRINT_FREQUENCY == 0:\n                            print(""epoch:\\t{epoch}\\tstep\\t{batch_idx}:\\t{metrics}"".\n                                  format(epoch=epoch,\n                                         batch_idx=batch_idx,\n                                         metrics=aggregate_metrics(phase, epoch, loss,\n                                                                   metric_value_groups)))\n\n                    def _train(epoch):\n                        model.train()\n                        train_loss = metric_cls(\'loss\', hvd)\n                        metric_value_groups = construct_metric_value_holders(\n                            metric_cls, metric_fn_groups, label_columns, hvd)\n\n                        # iterate on one epoch\n                        for batch_idx in range(steps_per_epoch):\n                            row = next(train_loader_iter)\n                            inputs, labels, sample_weights = prepare_batch(row)\n                            outputs, loss = train_minibatch(model, optimizer, transform_outputs,\n                                                            loss_fn, inputs, labels, sample_weights)\n                            update_metrics(metric_value_groups, outputs, labels)\n                            train_loss.update(loss)\n                            print_metrics(batch_idx, train_loss, metric_value_groups, \'train\')\n\n                        return aggregate_metrics(\'train\', epoch, train_loss, metric_value_groups)\n\n                    if should_validate:\n                        val_loader = BatchedDataLoader(val_reader, batch_size=batch_size)\n                        val_loader_iter = iter(val_loader)\n                        if validation_steps_per_epoch is None:\n                            validation_steps = int(math.ceil(float(val_rows) / batch_size / hvd.size()))\n                        else:\n                            validation_steps = validation_steps_per_epoch\n\n                        def _validate(epoch):\n                            model.eval()\n                            val_loss = metric_cls(\'loss\', hvd)\n\n                            metric_value_groups = construct_metric_value_holders(\n                                metric_cls, metric_fn_groups, label_columns, hvd)\n\n                            # iterate on one epoch\n                            for batch_idx in range(validation_steps):\n                                row = next(val_loader_iter)\n                                inputs, labels, sample_weights = prepare_batch(row)\n\n                                outputs = model(*inputs)\n                                outputs, labels = transform_outputs(outputs, labels)\n\n                                loss = calculate_loss(\n                                    outputs, labels, loss_weights, loss_fns, sample_weights)\n                                val_loss.update(loss)\n                                update_metrics(metric_value_groups, outputs, labels)\n                                print_metrics(batch_idx, val_loss, metric_value_groups, \'val\')\n                            return aggregate_metrics(\'val\', epoch, val_loss, metric_value_groups)\n\n                    history = []\n                    for epoch in range(epochs):\n                        epoch_metrics = {\n                            \'epoch\': epoch,\n                            \'train\': _train(epoch)\n                        }\n\n                        if should_validate:\n                            epoch_metrics[\'validation\'] = _validate(epoch)\n\n                        if user_verbose > 0:\n                            print(epoch_metrics)\n\n                        history.append(epoch_metrics)\n                        if hvd.rank() == 0:\n                            # Save model after every epoch\n                            save_checkpoint()\n                            if remote_store.saving_runs:\n                                remote_store.sync(run_output_dir)\n\n            if hvd.rank() == 0:\n                best_checkpoint = torch.load(ckpt_file)\n                serialized_checkpoint = io.BytesIO()\n                torch.save(best_checkpoint, serialized_checkpoint)\n                serialized_checkpoint.seek(0)\n                return history, serialized_checkpoint\n\n    return train\n\n\ndef _train_minibatch_fn():\n    def train_minibatch(model, optimizer, transform_outputs, loss_fn, inputs, labels, sample_weights):\n        optimizer.zero_grad()\n        outputs = model(*inputs)\n        outputs, labels = transform_outputs(outputs, labels)\n        loss = loss_fn(outputs, labels, sample_weights)\n        loss.backward()\n        optimizer.step()\n        return outputs, loss\n    return train_minibatch\n\n\ndef _get_optimizer_with_unscaled_lr_fn():\n    def get_optimizer_with_unscaled_lr(hvd, current_optimizer, optimizer_cls, model):\n        optimizer_state = current_optimizer.state_dict()\n        # scale down the learning rate with the number of horovod workers\n        for i in range(len(optimizer_state[\'param_groups\'])):\n            optimizer_state[\'param_groups\'][i][\'lr\'] = \\\n                optimizer_state[\'param_groups\'][i][\'lr\'] / hvd.size()\n        optimizer = optimizer_cls(model.parameters(), lr=1)\n        optimizer.load_state_dict(optimizer_state)\n        return optimizer\n\n    return get_optimizer_with_unscaled_lr\n\n\ndef _calculate_shuffle_buffer_size_fn():\n    def calculate_shuffle_buffer_size(hvd, avg_row_size, train_row_count_per_worker):\n        """"""\n        Determines the shuffling buffer size such that each worker gets at most 1GB for shuffling\n        buffer such that on a single machine, among all the workers on that machine, at most\n        memory_cap_gb GB are allocated for shuffling buffer. Also, it ensures that the buffer size\n        is identical among all the workers.\n\n        example 1:\n        memory_cap_gb = 4\n        machine1: 8 workers\n        machine2: 3 workers\n        shuffle_buffer_size = 0.5 GB\n\n        example 2:\n        memory_cap_gb = 4\n            machine1: 2 workers\n            machine2: 3 workers\n        shuffle_buffer_size = 1 GB\n\n        example 3:\n        memory_cap_gb = 4\n            machine1: 2 workers\n            machine2: 8 workers\n            machine3: 5 workers\n        shuffle_buffer_size = 0.5 GB\n        """"""\n        local_size = hvd.local_size()\n        local_sizes = hvd.allgather(torch.tensor([local_size]))\n        max_local_size = torch.max(local_sizes).item()\n\n        if max_local_size > TOTAL_BUFFER_MEMORY_CAP_GIB:\n            shuffle_buffer_size = TOTAL_BUFFER_MEMORY_CAP_GIB * BYTES_PER_GIB / avg_row_size / max_local_size\n        else:\n            shuffle_buffer_size = BYTES_PER_GIB / avg_row_size\n        return int(min(shuffle_buffer_size, train_row_count_per_worker))\n\n    return calculate_shuffle_buffer_size\n\n\ndef _construct_metric_value_holders_fn():\n    def construct_metric_value_holders(metric_class, metric_fn_groups, label_columns, hvd):\n        metric_values = []\n        for group_number, metric_group in enumerate(metric_fn_groups):\n            metric_group_val = []\n            for label_col in label_columns:\n                metric_group_val.append(\n                    metric_class(\'group_\' + str(group_number) + \'_\' + label_col, hvd))\n\n            metric_values.append(metric_group_val)\n        return metric_values\n    return construct_metric_value_holders\n\n\ndef _metric_cls():\n    # Horovod: average metrics from distributed training.\n    class Metric(object):\n        def __init__(self, name, hvd):\n            self.name = name\n            self.sum = torch.tensor(0.)\n            self.n = torch.tensor(0.)\n            self.hvd = hvd\n\n        def update(self, val):\n            self.sum += self.hvd.allreduce(val.detach().cpu(), name=self.name)\n            self.n += 1\n\n        @property\n        def avg(self):\n            return self.sum / self.n\n\n    return Metric\n\n\ndef _prepare_np_data_fn():\n    def prepare_np_data(rows, col_name, metadata):\n        intermediate_format = metadata[col_name][\'intermediate_format\']\n        if intermediate_format != CUSTOM_SPARSE:\n            return rows\n\n        shape = metadata[col_name][\'shape\']\n        num_rows = rows.shape[0]\n        dense_rows = torch.zeros([num_rows, shape])\n        for r in range(num_rows):\n            size = rows[r][0].long()\n            dense_rows[r][rows[r][1:size + 1].long()] = \\\n                rows[r][size + 1:2 * size + 1]\n        return dense_rows\n\n    return prepare_np_data\n\n\ndef _get_metric_avgs_fn():\n    def get_metric_avgs(metric_value_groups):\n        all_metric_groups_values = []\n        for metric_value_group in metric_value_groups:\n            metric_avgs = {}\n            for metric in metric_value_group:\n                metric_avgs[metric.name] = metric.avg.item()\n            all_metric_groups_values.append(metric_avgs)\n        return all_metric_groups_values\n\n    return get_metric_avgs\n\n\ndef _update_metrics_fn(metric_fn_groups):\n    def update_metrics(metric_value_groups, outputs, labels):\n        """"""\n        metric_value_groups is a list of metric functions. For example, for a model with 3\n        outputs, we can define these two metric groups\n        [\n            [metric_fn1],\n            [metric_fn21,metric_fn22,metric_fn23],\n        ]\n\n        In this example, first metric group provides only one metric function. This\n        function will be used to calculate the metric on all of the model outputs. Second\n        metric groups, however, defines one metric function per output.\n        """"""\n\n        num_outputs = len(outputs)\n        for metric_fn_group, metric_value_group in zip(metric_fn_groups, metric_value_groups):\n            if len(metric_fn_group) == 1:\n                _metric_fn_group = [metric_fn_group[0] for _ in range(num_outputs)]\n            else:\n                _metric_fn_group = metric_fn_group\n\n            for metric_val, metric_fn, output_group, label_group in \\\n                    zip(metric_value_group, _metric_fn_group, outputs, labels):\n                metric_val.update(metric_fn(output_group, label_group))\n\n        return metric_value_groups\n\n    return update_metrics\n\n\ndef _write_metrics_summary_fn():\n    def write_metrics_summary(stage, epoch, loss_metric, metric_value_groups, log_writer):\n        if not log_writer:\n            return\n\n        log_writer.add_scalar(\'{}/{}\'.format(stage, loss_metric.name),\n                              loss_metric.avg.item(), epoch)\n\n        for idx, metric_value_group in enumerate(metric_value_groups):\n            for metric in metric_value_group:\n                log_writer.add_scalar(\'{}/{}:{}\'.format(stage, metric.name, idx),\n                                      metric.avg.item(), epoch)\n\n    return write_metrics_summary\n\n\ndef _calculate_loss_fn():\n    def calculate_loss(outputs, labels, loss_weights, loss_fns, sample_weights=None):\n        if sample_weights is not None:\n            # when reduction=\'none\', loss function returns the value of all the losses\n            # from all the samples. We multiply each sample\'s weight to its loss and\n            # then take the mean of the weight adjusted losses from all the samples in the\n            # batch. Note that this approach is not ""weighted average"" because the sum of\n            # the sample weights in each batch does not necessarily add up to one. If we add\n            # the weights and divide the sum to the sum of weights, the impact of two\n            # samples with identical weights but in different batches will not be equal on\n            # the calculated gradients.\n            losses = []\n            for output, label, loss_fn, loss_weight in zip(outputs, labels,\n                                                           loss_fns, loss_weights):\n                weight_adjusted_sample_losses = \\\n                    loss_fn(output, label, reduction=\'none\').flatten() * sample_weights\n                output_loss = weight_adjusted_sample_losses.mean()\n                losses.append(output_loss * loss_weight)\n        else:\n            losses = [loss_fn(output, label) * loss_weight for\n                      output, label, loss_fn, loss_weight in\n                      zip(outputs, labels, loss_fns, loss_weights)]\n\n        loss = sum(losses)\n        return loss\n\n    return calculate_loss\n'"
horovod/spark/torch/util.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\nimport platform\nimport sys\n\nfrom horovod.run.common.util import codec\n\n\ndef is_module_available(module_name):\n    _is_module_available = is_module_available_fn()\n    return _is_module_available(module_name)\n\n\ndef is_module_available_fn():\n    def _is_module_available(module_name):\n        if sys.version_info <= (3, 3):\n            # python 3.0 to 3.3\n            import pkgutil\n            torch_loader = pkgutil.find_loader(module_name)\n        elif sys.version_info >= (3, 4):\n            # python 3.4 and above\n            import importlib\n            torch_loader = importlib.util.find_spec(module_name)\n        else:\n            raise RuntimeError(\'Unsupported version of Python: {}\'.format(platform.python_version()))\n\n        return torch_loader is not None\n\n    return _is_module_available\n\n\ndef serialize_fn():\n    is_module_available = is_module_available_fn()\n\n    def _serialize(model):\n        """"""Serialize model into byte array encoded into base 64.""""""\n        if is_module_available(\'torch\'):\n            import torch\n            sys.modules[""torch._C._nn""] = torch.nn.functional\n\n        serialized_obj = codec.dumps_base64(model)\n        return serialized_obj\n\n    return _serialize\n\n\ndef deserialize_fn():\n    is_module_available = is_module_available_fn()\n\n    def _deserialize(model_bytes_base64):\n        """"""Deserialize model from byte array encoded in base 64.""""""\n        if is_module_available(\'torch\'):\n            import torch\n            sys.modules[""torch._C._nn""] = torch.nn.functional\n\n        obj = codec.loads_base64(model_bytes_base64)\n        return obj\n\n    return _deserialize\n\n\ndef save_into_bio_fn():\n    def save_into_bio(obj, save_obj_fn):\n        """"""Serialize object into byte array encoded into base 64.""""""\n        bio = io.BytesIO()\n        save_obj_fn(obj, bio)\n        bio.seek(0)\n        return bio\n\n    return save_into_bio\n\n\ndef save_into_bio(obj, save_obj_fn):\n    _save_into_bio = save_into_bio_fn()\n    return _save_into_bio(obj, save_obj_fn)\n'"
horovod/tensorflow/keras/__init__.py,4,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport inspect\n\nimport tensorflow as tf\n\nfrom distutils.version import LooseVersion\nif LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):\n    from tensorflow import keras\n    from tensorflow.python.keras import backend as K\nelse:\n    from tensorflow.contrib import keras\n    from tensorflow.contrib.keras import backend as K\n\nfrom horovod.tensorflow import init\nfrom horovod.tensorflow import shutdown\nfrom horovod.tensorflow import size\nfrom horovod.tensorflow import local_size\nfrom horovod.tensorflow import rank\nfrom horovod.tensorflow import local_rank\nfrom horovod.tensorflow import mpi_threads_supported, mpi_enabled, mpi_built\nfrom horovod.tensorflow import gloo_enabled, gloo_built\nfrom horovod.tensorflow import nccl_built, ddl_built, ccl_built\nfrom horovod.tensorflow import Compression\n\nimport horovod._keras as _impl\nfrom horovod.tensorflow.keras import callbacks, elastic\n\n\ntry:\n    # In later versions of TensorFlow, optimizers are spread across multiple modules. This set is used to distinguish\n    # stock optimizers that come with tf.keras from custom optimizers that may need to be wrapped specially.\n    _OPTIMIZER_MODULES = set([obj.__module__ for name, obj in inspect.getmembers(tf.keras.optimizers)\n                              if isinstance(obj, type(tf.keras.optimizers.Optimizer))])\nexcept:\n    _OPTIMIZER_MODULES = set()\n\n\ndef DistributedOptimizer(optimizer, name=None,\n                         device_dense=\'\', device_sparse=\'\',\n                         compression=Compression.none,\n                         sparse_as_dense=False):\n    """"""\n    An optimizer that wraps another keras.optimizers.Optimizer, using an allreduce to\n    average gradient values before applying gradients to model weights.\n\n    Args:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        name: Optional name prefix for the operations created when applying\n              gradients. Defaults to ""Distributed"" followed by the provided\n              optimizer type.\n        device_dense: Device to be used for dense tensors. Uses GPU by default\n                      if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        device_sparse: Device to be used for sparse tensors. Uses GPU by default\n                       if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n        sparse_as_dense: Treat all sparse gradients as dense tensors.  This can\n                         help improve performance and memory utilization if\n                         the original sparse gradient has high density.\n                         Defaults to false.    """"""\n    return _impl.create_distributed_optimizer(keras, optimizer, name,\n                                              device_dense, device_sparse, compression,\n                                              sparse_as_dense)\n\n\ndef broadcast_global_variables(root_rank):\n    """"""Broadcasts all global variables from root rank to all other processes.\n\n    Arguments:\n        root_rank: Rank of the process from which global variables will be broadcasted\n                   to all other processes.\n    """"""\n    return _impl.broadcast_global_variables(K, root_rank)\n\n\ndef allreduce(value, name=None, average=True):\n    """"""\n    Perform an allreduce on a tensor-compatible value.\n\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        name: Optional name for the constants created by this operation.\n        average: If True, computes the average over all ranks.\n                 Otherwise, computes the sum over all ranks.\n    """"""\n    return _impl.allreduce(K, value, name, average)\n\n\ndef allgather(value, name=None):\n    """"""\n    Perform an allgather on a tensor-compatible value.\n\n    The concatenation is done on the first dimension, so the input values on the\n    different processes must have the same rank and shape, except for the first\n    dimension, which is allowed to be different.\n\n    Arguments:\n        value: A tensor-compatible value to gather.\n        name: Optional name prefix for the constants created by this operation.\n    """"""\n    return _impl.allgather(K, value, name)\n\n\ndef broadcast(value, root_rank, name=None):\n    """"""\n    Perform a broadcast on a tensor-compatible value.\n\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        root_rank: Rank of the process from which global variables will be\n                   broadcasted to all other processes.\n        name: Optional name for the constants created by this operation.\n    """"""\n    return _impl.broadcast(K, value, root_rank, name)\n\n\ndef load_model(filepath, custom_optimizers=None, custom_objects=None, compression=Compression.none):\n    """"""\n    Loads a saved Keras model with a Horovod DistributedOptimizer.\n\n    The DistributedOptimizer will wrap the underlying optimizer used to train\n    the saved model, so that the optimizer state (params and weights) will\n    be picked up for retraining.\n\n    By default, all optimizers in the module `keras.optimizers` will be loaded\n    and wrapped without needing to specify any `custom_optimizers` or\n    `custom_objects`.\n\n    Arguments:\n        filepath: One of the following:\n            - string, path to the saved model, or\n            - h5py.File object from which to load the model\n        custom_optimizers: Optional list of Optimizer subclasses to support\n            during loading.\n        custom_objects: Optional dictionary mapping names (strings) to custom\n            classes or functions to be considered during deserialization.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n\n    Returns:\n        A Keras model instance.\n\n    Raises:\n        ImportError: If h5py is not available.\n        ValueError: In case of an invalid savefile.\n    """"""\n    def wrap_optimizer(cls):\n        return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)\n    return _impl.load_model(keras, wrap_optimizer, _OPTIMIZER_MODULES, filepath, custom_optimizers, custom_objects)\n\n'"
horovod/tensorflow/keras/callbacks.py,1,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\n\nfrom distutils.version import LooseVersion\nif LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):\n    from tensorflow import keras\n    from tensorflow.python.keras import backend as K\nelse:\n    from tensorflow.contrib import keras\n    from tensorflow.contrib.keras import backend as K\n\nfrom horovod._keras import callbacks as _impl\n\n\nclass BroadcastGlobalVariablesCallback(_impl.BroadcastGlobalVariablesCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will broadcast all global variables from root rank\n    to all other processes during initialization.\n\n    This is necessary to ensure consistent initialization of all workers when\n    training is started with random weights or restored from a checkpoint.\n    """"""\n\n    def __init__(self, root_rank, device=\'\'):\n        """"""\n        Construct a new BroadcastGlobalVariablesCallback that will broadcast all\n        global variables from root rank to all other processes during initialization.\n\n        Args:\n            root_rank: Rank that will send data, other ranks will receive data.\n            device: Device to be used for broadcasting. Uses GPU by default\n                    if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        """"""\n        super(BroadcastGlobalVariablesCallback, self).__init__(K, root_rank, device)\n\n\nclass MetricAverageCallback(_impl.MetricAverageCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will average metrics across all processes at the\n    end of the epoch. Useful in conjuction with ReduceLROnPlateau,\n    TensorBoard and other metrics-based callbacks.\n\n    Note: This callback must be added to the callback list before the\n    ReduceLROnPlateau, TensorBoard or other metrics-based callbacks.\n    """"""\n\n    def __init__(self, device=\'\'):\n        """"""\n        Construct a new MetricAverageCallback that will average metrics\n        across all processes at the end of the epoch.\n\n        Args:\n            device: Device to be used for allreduce. Uses GPU by default\n                    if Horovod was build with HOROVOD_GPU_OPERATIONS.\n        """"""\n        super(MetricAverageCallback, self).__init__(K, device)\n\n\nclass LearningRateScheduleCallback(_impl.LearningRateScheduleCallbackImpl, keras.callbacks.Callback):\n    """"""\n    LearningRateScheduleCallback sets learning rate between epochs `start_epoch` and\n    `end_epoch` to be `initial_lr * multiplier`.  `multiplier` can be a constant or\n    a function `f(epoch) = lr\'`.\n\n    If `multiplier` is a function and `staircase=True`, learning rate adjustment will\n    happen at the beginning of each epoch and the epoch passed to the `multiplier`\n    function will be an integer.\n\n    If `multiplier` is a function and `staircase=False`, learning rate adjustment will\n    happen at the beginning of each batch and the epoch passed to the `multiplier`\n    function will be a floating number: `epoch\' = epoch + batch / steps_per_epoch`.\n    This functionality is useful for smooth learning rate adjustment schedulers, such\n    as `LearningRateWarmupCallback`.\n\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n    """"""\n\n    def __init__(self, multiplier, start_epoch=0, end_epoch=None, staircase=True,\n                 momentum_correction=True, steps_per_epoch=None, initial_lr=None):\n        """"""\n        Construct a new LearningRateScheduleCallback.\n\n        Args:\n            multiplier: A constant multiplier or a function `f(epoch) = lr\'`\n            start_epoch: The first epoch this adjustment will be applied to. Defaults to 0.\n            end_epoch: The epoch this adjustment will stop applying (exclusive end).\n                       Defaults to None.\n            staircase: Whether to adjust learning rate at the start of epoch (`staircase=True`)\n                       or at the start of every batch (`staircase=False`).\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in v0.21.0.\n\n        """"""\n        super(LearningRateScheduleCallback, self).__init__(K, multiplier, start_epoch, end_epoch,\n                                                           staircase, momentum_correction, steps_per_epoch,\n                                                           initial_lr)\n\n\nclass LearningRateWarmupCallback(_impl.LearningRateWarmupCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Implements gradual learning rate warmup:\n\n        `lr = initial_lr / hvd.size()` ---> `lr = initial_lr`\n\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n\n    This technique was described in the paper ""Accurate, Large Minibatch SGD: Training\n    ImageNet in 1 Hour"". See https://arxiv.org/pdf/1706.02677.pdf for details.\n\n    Math recap:\n\n    .. math::\n\n        epoch &= full\\\\_epochs + \\\\frac{batch}{steps\\\\_per\\\\_epoch}\n\n        lr\'(epoch) &= \\\\frac{lr}{size} * (\\\\frac{size - 1}{warmup} * epoch + 1)\n\n        lr\'(epoch = 0) &= \\\\frac{lr}{size}\n\n        lr\'(epoch = warmup) &= lr\n    """"""\n\n    def __init__(self, warmup_epochs=5, momentum_correction=True, steps_per_epoch=None,\n                 verbose=0, initial_lr=None):\n        """"""\n        Construct a new LearningRateWarmupCallback that will gradually warm up the learning rate.\n\n        Args:\n            warmup_epochs: The number of epochs of the warmup phase. Defaults to 5.\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            verbose: verbosity mode, 0 or 1.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in v0.21.0.\n        """"""\n        super(LearningRateWarmupCallback, self).__init__(K, warmup_epochs, momentum_correction,\n                                                         steps_per_epoch, verbose, initial_lr)\n'"
horovod/tensorflow/keras/elastic.py,8,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\n\nfrom horovod._keras import elastic as _impl\nfrom horovod.tensorflow.elastic import TensorFlowKerasState\n\n\nclass KerasState(TensorFlowKerasState):\n    """"""State representation of a `tf.keras` model and optimizer.\n\n    Args:\n        model: Keras model.\n        optimizer: Optional optimizer, can be compiled into model instead.\n        kwargs: Additional properties to sync, will be exposed as attributes of the object.\n    """"""\n    def __init__(self, model, optimizer=None, **kwargs):\n        super(KerasState, self).__init__(model, optimizer=optimizer, backend=tf.keras.backend, **kwargs)\n\n\nclass CommitStateCallback(_impl.CommitStateCallbackImpl, tf.keras.callbacks.Callback):\n    """"""\n    Keras Callback that will commit the `state` object every `batches_per_commit`\n    batches at the end of each batch.\n    """"""\n\n    def __init__(self, state, batches_per_commit=1):\n        """"""\n        Constructs a new CommitStateCallback.\n\n        Args:\n            state: `horovod.common.elastic.State` object to be committed.\n            batches_per_commit: Number of batches to complete between each commit (default: 1).\n        """"""\n        super(CommitStateCallback, self).__init__(tf.keras.backend, state, batches_per_commit)\n\n\nclass UpdateBatchStateCallback(_impl.UpdateBatchStateCallbackImpl, tf.keras.callbacks.Callback):\n    """"""\n    Keras Callback that will update the value of `state.batch` with the current batch number at\n    the end of each batch. Batch will reset to 0 at the end of each epoch.\n\n    If `steps_per_epoch` is set, then this callback will also ensure that the number of steps\n    in the first epoch following a reset is shortened by the number of batches already processed.\n    """"""\n\n    def __init__(self, state):\n        """"""\n        Constructs a new UpdateBatchStateCallback.\n\n        Args:\n            state: `horovod.common.elastic.State` object to be updated.\n        """"""\n        super(UpdateBatchStateCallback, self).__init__(tf.keras.backend, state)\n\n\nclass UpdateEpochStateCallback(_impl.UpdateEpochStateCallbackImpl, tf.keras.callbacks.Callback):\n    """"""\n    Keras Callback that will update the value of `state.epoch` with the current epoch number at\n    the end of each epoch.\n    """"""\n\n    def __init__(self, state):\n        """"""\n        Constructs a new UpdateEpochStateCallback.\n\n        Args:\n            state: `horovod.common.elastic.State` object to be updated.\n        """"""\n        super(UpdateEpochStateCallback, self).__init__(tf.keras.backend, state)\n'"
horovod/torch/mpi_lib/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom torch.utils.ffi import _wrap_function\nfrom horovod.common.util import get_ext_suffix as _get_ext_suffix\nfrom ._mpi_lib import ffi as _ffi\nimport os as _os\n\n# Make sure to preserve this code to load library with RTLD_GLOBAL,\n# otherwise it will get unloaded.\n_lib = _ffi.dlopen(_os.path.join(_os.path.dirname(__file__),\n                                \'_mpi_lib\' + _get_ext_suffix()),\n                   _ffi.RTLD_GLOBAL)\n\n__all__ = []\ndef _import_symbols(locals):\n    for symbol in dir(_lib):\n        fn = getattr(_lib, symbol)\n        if callable(fn):\n            locals[symbol] = _wrap_function(fn, _ffi)\n        else:\n            locals[symbol] = fn\n        __all__.append(symbol)\n\n_import_symbols(locals())\n'"
horovod/torch/mpi_lib_impl/__init__.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom torch.utils.ffi import _wrap_function\nfrom horovod.common.util import get_ext_suffix as _get_ext_suffix\nfrom ._mpi_lib_impl import ffi as _ffi\nimport os as _os\n\n# Make sure to preserve this code to load library with RTLD_GLOBAL,\n# otherwise it will get unloaded.\n_lib = _ffi.dlopen(_os.path.join(_os.path.dirname(__file__),\n                                \'_mpi_lib_impl\' + _get_ext_suffix()),\n                   _ffi.RTLD_GLOBAL)\n\n__all__ = []\ndef _import_symbols(locals):\n    for symbol in dir(_lib):\n        fn = getattr(_lib, symbol)\n        if callable(fn):\n            locals[symbol] = _wrap_function(fn, _ffi)\n        else:\n            locals[symbol] = fn\n        __all__.append(symbol)\n\n_import_symbols(locals())\n'"
test/integration/data/elastic_tensorflow2_main.py,8,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport json\nimport os\nimport psutil\nimport time\n\nimport tensorflow as tf\n\nimport horovod.tensorflow as hvd\n\nparser = argparse.ArgumentParser(description=\'TensorFlow 2 Elastic Test\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\nparser.add_argument(\'--batches-per-epoch\', type=int, default=10,\n                    help=\'number of batches per epoch\')\nparser.add_argument(\'--batches-per-commit\', type=int, default=1,\n                    help=\'number of batches per commit of the elastic state object\')\nparser.add_argument(\'--epochs\', type=int, default=3,\n                    help=\'number of epochs\')\nparser.add_argument(\'--logfile\', default=\'/tmp/logfile.txt\',\n                    help=\'log file to record results (one line per epoch)\')\nparser.add_argument(\'--discovery-schedule\', default=\'[]\',\n                    help=\'JSON string specifying schedule of host updates each epoch\')\nparser.add_argument(\'--exit-schedule\',\n                    help=\'JSON string mapping from (epoch, batch) to list of ranks to exit at that time\')\nparser.add_argument(\'--exit-mode\', default=\'exception\',\n                    help=\'means used to cause a worker to exit [exception | kill]\')\n\nargs = parser.parse_args()\n\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n\nhvd.init()\n\nbatch_size = 32\ndata = tf.random.uniform([batch_size, 2])\nindices = tf.random.uniform([batch_size], minval=0, maxval=2, dtype=tf.int64)\ntarget = tf.one_hot(indices, 2)\n\nlr = 0.001\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(2, activation=\'softmax\')])\noptimizer = tf.optimizers.SGD(lr * hvd.size())\n\nhostname = os.environ.get(\'HOROVOD_HOSTNAME\')\nstart_rank = int(os.environ.get(\'HOROVOD_RANK\', 0))\n\ndiscovery_schedule = json.loads(args.discovery_schedule)\nepoch_to_hosts = {epoch: hosts for epoch, hosts in discovery_schedule if epoch is not None}\ndefault_hosts = discovery_schedule[-1][1] if len(discovery_schedule) > 0 else []\n\nexit_schedule = json.loads(args.exit_schedule) if args.exit_schedule else {}\n\n\ndef check_exit(epoch, batch):\n    key = str((epoch, batch))\n    if key in exit_schedule:\n        ranks_to_exit = exit_schedule[key]\n        if start_rank in ranks_to_exit:\n            if args.exit_mode == \'exception\':\n                raise RuntimeError(\'check_rank and exit epoch={} batch={} start_rank={} rank={}\'\n                                   .format(epoch, batch, start_rank, hvd.rank()))\n            else:\n                psutil.Process(os.getpid()).kill()\n\n\ndef log_state(state):\n    state_dict = {\n        \'epoch\': state.epoch,\n        \'batch\': state.batch,\n        \'commits\': state.commits,\n        \'hostname\': hostname,\n        \'start_rank\': start_rank,\n        \'rank\': hvd.rank(),\n        \'size\': hvd.size(),\n        \'rendezvous\': state.rendezvous}\n    with open(args.logfile, \'a\') as f:\n        f.write(json.dumps(state_dict) + os.linesep)\n\n\n@tf.function\ndef step(allreduce=True):\n    # Horovod: use DistributedGradientTape\n    with tf.GradientTape() as tape:\n        probs = model(data, training=True)\n        loss = tf.losses.categorical_crossentropy(target, probs)\n\n    # Horovod: add Horovod Distributed GradientTape.\n    if allreduce:\n        tape = hvd.DistributedGradientTape(tape)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n\nstep(allreduce=False)\n\n\n@hvd.elastic.run\ndef train(state):\n    state.rendezvous += 1\n    while state.epoch < args.epochs:\n        print(\'epoch {} batch {}\'.format(state.epoch, state.batch))\n\n        while state.batch < args.batches_per_epoch:\n            check_exit(state.epoch, state.batch)\n            step()\n\n            state.batch += 1\n            if state.batch % args.batches_per_commit == 0:\n                state.commits += 1\n                state.commit()\n\n        if hvd.rank() == 0:\n            log_state(state)\n\n            current_hosts = epoch_to_hosts.get(state.epoch, default_hosts)\n            next_hosts = epoch_to_hosts.get(state.epoch + 1, default_hosts)\n            if current_hosts != next_hosts:\n                print(\'host changes: {} -> {}\'.format(current_hosts, next_hosts))\n                start = int(time.time())\n                while state._host_messages.empty():\n                    if int(time.time()) - start > 3:\n                        raise TimeoutError(\'Timed out waiting for notifications from driver.\')\n                    time.sleep(0.1)\n\n        state.epoch += 1\n        state.batch = 0\n        state.commits += 1\n        state.commit()\n\n\ndef on_state_reset():\n    optimizer.lr.assign(lr * hvd.size())\n\n\nstate = hvd.elastic.TensorFlowKerasState(model, optimizer, batch=0, epoch=0, commits=0, rendezvous=0)\nstate.register_reset_callbacks([on_state_reset])\ntrain(state)\n'"
test/integration/data/elastic_tensorflow_main.py,10,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport json\nimport os\nimport psutil\nimport time\n\nimport tensorflow as tf\n\nimport horovod.tensorflow as hvd\n\nparser = argparse.ArgumentParser(description=\'TensorFlow Elastic Test\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\nparser.add_argument(\'--batches-per-epoch\', type=int, default=10,\n                    help=\'number of batches per epoch\')\nparser.add_argument(\'--batches-per-commit\', type=int, default=1,\n                    help=\'number of batches per commit of the elastic state object\')\nparser.add_argument(\'--epochs\', type=int, default=3,\n                    help=\'number of epochs\')\nparser.add_argument(\'--logfile\', default=\'/tmp/logfile.txt\',\n                    help=\'log file to record results (one line per epoch)\')\nparser.add_argument(\'--discovery-schedule\', default=\'[]\',\n                    help=\'JSON string specifying schedule of host updates each epoch\')\nparser.add_argument(\'--exit-schedule\',\n                    help=\'JSON string mapping from (epoch, batch) to list of ranks to exit at that time\')\nparser.add_argument(\'--exit-mode\', default=\'exception\',\n                    help=\'means used to cause a worker to exit [exception | kill]\')\n\nargs = parser.parse_args()\n\nconfig = tf.ConfigProto()\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\nconfig.gpu_options.allow_growth = False\nconfig.gpu_options.visible_device_list = \'\'\n\nhvd.init()\n\nbase_lr = 0.01\nlr = tf.Variable(base_lr * hvd.size())\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(2, activation=\'softmax\')])\noptimizer = tf.train.GradientDescentOptimizer(lr)\noptimizer = hvd.DistributedOptimizer(optimizer)\n\nbatch_size = 32\ndata = tf.random_uniform([batch_size, 2])\ntarget = tf.random_uniform([batch_size, 1], minval=0, maxval=2, dtype=tf.int64)\n\nprobs = tf.layers.dense(data, 2, activation=None)\nloss = tf.losses.sparse_softmax_cross_entropy(target, probs)\n\nhostname = os.environ.get(\'HOROVOD_HOSTNAME\')\nstart_rank = int(os.environ.get(\'HOROVOD_RANK\', 0))\n\ndiscovery_schedule = json.loads(args.discovery_schedule)\nepoch_to_hosts = {epoch: hosts for epoch, hosts in discovery_schedule if epoch is not None}\ndefault_hosts = discovery_schedule[-1][1] if len(discovery_schedule) > 0 else []\n\nexit_schedule = json.loads(args.exit_schedule) if args.exit_schedule else {}\n\n\ndef check_exit(epoch, batch):\n    key = str((epoch, batch))\n    if key in exit_schedule:\n        ranks_to_exit = exit_schedule[key]\n        if start_rank in ranks_to_exit:\n            if args.exit_mode == \'exception\':\n                raise RuntimeError(\'check_rank and exit epoch={} batch={} start_rank={} rank={}\'\n                                   .format(epoch, batch, start_rank, hvd.rank()))\n            else:\n                psutil.Process(os.getpid()).kill()\n\n\ndef log_state(state):\n    state_dict = {\n        \'epoch\': state.epoch,\n        \'batch\': state.batch,\n        \'commits\': state.commits,\n        \'hostname\': hostname,\n        \'start_rank\': start_rank,\n        \'rank\': hvd.rank(),\n        \'size\': hvd.size(),\n        \'rendezvous\': state.rendezvous}\n    with open(args.logfile, \'a\') as f:\n        f.write(json.dumps(state_dict) + os.linesep)\n\n\n@hvd.elastic.run\ndef train(state, step):\n    state.rendezvous += 1\n    while state.epoch < args.epochs:\n        print(\'epoch {} batch {}\'.format(state.epoch, state.batch))\n\n        while state.batch < args.batches_per_epoch:\n            check_exit(state.epoch, state.batch)\n            step()\n\n            state.batch += 1\n            if state.batch % args.batches_per_commit == 0:\n                state.commits += 1\n                state.commit()\n\n        if hvd.rank() == 0:\n            log_state(state)\n\n            current_hosts = epoch_to_hosts.get(state.epoch, default_hosts)\n            next_hosts = epoch_to_hosts.get(state.epoch + 1, default_hosts)\n            if current_hosts != next_hosts:\n                print(\'host changes: {} -> {}\'.format(current_hosts, next_hosts))\n                start = int(time.time())\n                while state._host_messages.empty():\n                    if int(time.time()) - start > 3:\n                        raise TimeoutError(\'Timed out waiting for notifications from driver.\')\n                    time.sleep(0.1)\n\n        state.epoch += 1\n        state.batch = 0\n        state.commits += 1\n        state.commit()\n\n\nwith tf.Session(config=config) as session:\n    session.run(tf.global_variables_initializer())\n\n    def on_state_reset():\n        lr.load(base_lr * hvd.size(), session)\n\n    state = hvd.elastic.TensorFlowState(session=session, batch=0, epoch=0, commits=0, rendezvous=0)\n    state.register_reset_callbacks([on_state_reset])\n\n    train_opt = optimizer.minimize(loss)\n    train(state, lambda: session.run(train_opt))\n'"
test/integration/data/elastic_torch_main.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport argparse\nimport json\nimport os\nimport psutil\nimport time\n\nimport torch\nimport torch.nn.functional as F\n\nimport horovod.torch as hvd\n\nparser = argparse.ArgumentParser(description=\'PyTorch Elastic Test\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\nparser.add_argument(\'--batches-per-epoch\', type=int, default=10,\n                    help=\'number of batches per epoch\')\nparser.add_argument(\'--batches-per-commit\', type=int, default=1,\n                    help=\'number of batches per commit of the elastic state object\')\nparser.add_argument(\'--epochs\', type=int, default=3,\n                    help=\'number of epochs\')\nparser.add_argument(\'--logfile\', default=\'/tmp/logfile.txt\',\n                    help=\'log file to record results (one line per epoch)\')\nparser.add_argument(\'--discovery-schedule\', default=\'[]\',\n                    help=\'JSON string specifying schedule of host updates each epoch\')\nparser.add_argument(\'--exit-schedule\',\n                    help=\'JSON string mapping from (epoch, batch) to list of ranks to exit at that time\')\nparser.add_argument(\'--exit-mode\', default=\'exception\',\n                    help=\'means used to cause a worker to exit [exception | kill]\')\n\nargs = parser.parse_args()\n\nhvd.init()\n\nbatch_size = 32\ndata = torch.randn(batch_size, 2)\ntarget = torch.LongTensor(batch_size).random_() % 2\n\nlr = 0.001\nmodel = torch.nn.Sequential(torch.nn.Linear(2, 2))\noptimizer = torch.optim.SGD(model.parameters(), lr=lr * hvd.size())\noptimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\n\nhostname = os.environ.get(\'HOROVOD_HOSTNAME\')\nstart_rank = int(os.environ.get(\'HOROVOD_RANK\', 0))\n\ndiscovery_schedule = json.loads(args.discovery_schedule)\nepoch_to_hosts = {epoch: hosts for epoch, hosts in discovery_schedule if epoch is not None}\ndefault_hosts = discovery_schedule[-1][1] if len(discovery_schedule) > 0 else []\n\nexit_schedule = json.loads(args.exit_schedule) if args.exit_schedule else {}\n\n\ndef check_exit(epoch, batch):\n    key = str((epoch, batch))\n    if key in exit_schedule:\n        ranks_to_exit = exit_schedule[key]\n        if start_rank in ranks_to_exit:\n            if args.exit_mode == \'exception\':\n                raise RuntimeError(\'check_rank and exit epoch={} batch={} start_rank={} rank={}\'\n                                   .format(epoch, batch, start_rank, hvd.rank()))\n            else:\n                psutil.Process(os.getpid()).kill()\n\n\ndef log_state(state):\n    state_dict = {\n        \'epoch\': state.epoch,\n        \'batch\': state.batch,\n        \'commits\': state.commits,\n        \'hostname\': hostname,\n        \'start_rank\': start_rank,\n        \'rank\': hvd.rank(),\n        \'size\': hvd.size(),\n        \'rendezvous\': state.rendezvous}\n    with open(args.logfile, \'a\') as f:\n        f.write(json.dumps(state_dict) + os.linesep)\n\n\n@hvd.elastic.run\ndef train(state):\n    state.rendezvous += 1\n    while state.epoch < args.epochs:\n        print(\'epoch {} batch {}\'.format(state.epoch, state.batch))\n\n        while state.batch < args.batches_per_epoch:\n            check_exit(state.epoch, state.batch)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.cross_entropy(output, target)\n            loss.backward()\n            optimizer.step()\n\n            state.batch += 1\n            if state.batch % args.batches_per_commit == 0:\n                state.commits += 1\n                state.commit()\n\n        if hvd.rank() == 0:\n            log_state(state)\n\n            current_hosts = epoch_to_hosts.get(state.epoch, default_hosts)\n            next_hosts = epoch_to_hosts.get(state.epoch + 1, default_hosts)\n            if current_hosts != next_hosts:\n                print(\'host changes: {} -> {}\'.format(current_hosts, next_hosts))\n                start = int(time.time())\n                while state._host_messages.empty():\n                    if int(time.time()) - start > 3:\n                        raise TimeoutError(\'Timed out waiting for notifications from driver.\')\n                    time.sleep(0.1)\n\n        state.epoch += 1\n        state.batch = 0\n        state.commits += 1\n        state.commit()\n\n\ndef on_state_reset():\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr * hvd.size()\n\n\nstate = hvd.elastic.TorchState(model, optimizer, batch=0, epoch=0, commits=0, rendezvous=0)\nstate.register_reset_callbacks([on_state_reset])\ntrain(state)\n'"
horovod/run/common/service/__init__.py,0,b''
horovod/run/common/service/driver_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport threading\n\nfrom horovod.run.common.util import network\n\n\nclass RegisterTaskToTaskAddressesRequest(object):\n    def __init__(self, index, task_addresses):\n        self.index = index\n        """"""Task index.""""""\n\n        self.task_addresses = task_addresses\n        """"""Map of interface to list of (ip, port) pairs.""""""\n\n\nclass AllTaskAddressesRequest(object):\n    """"""Request all task addresses for a given index.""""""\n\n    def __init__(self, index):\n        self.index = index\n\n\nclass AllTaskAddressesResponse(object):\n    def __init__(self, all_task_addresses):\n        self.all_task_addresses = all_task_addresses\n        """"""Map of interface to list of (ip, port) pairs.""""""\n\n\nclass BasicDriverService(network.BasicService):\n    def __init__(self, num_proc, name, key, nics):\n        super(BasicDriverService, self).__init__(name, key, nics)\n        self._num_proc = num_proc\n        self._all_task_addresses = {}\n        self._task_addresses_for_driver = {}\n        self._task_addresses_for_tasks = {}\n        self._task_host_hash_indices = {}\n        self._wait_cond = threading.Condition()\n\n    def _handle(self, req, client_address):\n        if isinstance(req, RegisterTaskRequest):\n            self._wait_cond.acquire()\n            try:\n                assert 0 <= req.index < self._num_proc\n                self._all_task_addresses[req.index] = req.task_addresses\n                # Just use source address for service for fast probing.\n                self._task_addresses_for_driver[req.index] = \\\n                    self._filter_by_ip(req.task_addresses, client_address[0])\n                if not self._task_addresses_for_driver[req.index]:\n                    # No match is possible if one of the servers is behind NAT.\n                    # We don\'t throw exception here, but will allow the following\n                    # code fail with NoValidAddressesFound.\n                    print(\'ERROR: Task {index} declared addresses {task_addresses}, \'\n                          \'but has connected from a different address {source}. \'\n                          \'This is not supported. Is the server behind NAT?\'\n                          \'\'.format(index=req.index, task_addresses=req.task_addresses,\n                                    source=client_address[0]))\n                # Make host hash -> indices map.\n                if req.host_hash not in self._task_host_hash_indices:\n                    self._task_host_hash_indices[req.host_hash] = []\n                self._task_host_hash_indices[req.host_hash].append(req.index)\n                self._task_host_hash_indices[req.host_hash].sort()\n            finally:\n                self._wait_cond.notify_all()\n                self._wait_cond.release()\n            return network.AckResponse()\n\n        if isinstance(req, RegisterTaskToTaskAddressesRequest):\n            self.register_task_to_task_addresses(req.index, req.task_addresses)\n            return network.AckResponse()\n\n        if isinstance(req, AllTaskAddressesRequest):\n            return AllTaskAddressesResponse(self._all_task_addresses[req.index])\n\n        return super(BasicDriverService, self)._handle(req, client_address)\n\n    def _filter_by_ip(self, addresses, target_ip):\n        for intf, intf_addresses in addresses.items():\n            for ip, port in intf_addresses:\n                if ip == target_ip:\n                    return {intf: [(ip, port)]}\n        return {}\n\n    def all_task_addresses(self, index):\n        return self._all_task_addresses[index].copy()\n\n    def task_addresses_for_driver(self, index):\n        return self._task_addresses_for_driver[index].copy()\n\n    def task_addresses_for_tasks(self, index):\n        return self._task_addresses_for_tasks[index].copy()\n\n    def register_task_to_task_addresses(self, index, task_addresses):\n        self._wait_cond.acquire()\n        try:\n            assert 0 <= index < self._num_proc\n            self._task_addresses_for_tasks[index] = task_addresses\n        finally:\n            self._wait_cond.notify_all()\n            self._wait_cond.release()\n\n    def task_host_hash_indices(self):\n        return self._task_host_hash_indices.copy()\n\n    def wait_for_initial_registration(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while len(self._all_task_addresses) < self._num_proc:\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\'tasks to start\')\n        finally:\n            self._wait_cond.release()\n\n    def wait_for_task_to_task_address_updates(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while len(self._task_addresses_for_tasks) < self._num_proc:\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\n                    \'tasks to update task-to-task addresses\')\n        finally:\n            self._wait_cond.release()\n\n\nclass RegisterTaskRequest(object):\n    def __init__(self, index, task_addresses, host_hash):\n        self.index = index\n        """"""Task index.""""""\n\n        self.task_addresses = task_addresses\n        """"""Map of interface to list of (ip, port) pairs.""""""\n\n        self.host_hash = host_hash\n        """"""\n        Hash of the host that helps to determine which tasks\n        have shared memory access to each other.\n        """"""\n\n\nclass BasicDriverClient(network.BasicClient):\n    def __init__(self, name, driver_addresses, key, verbose, match_intf=False):\n        super(BasicDriverClient, self).__init__(name,\n                                                driver_addresses,\n                                                key,\n                                                verbose,\n                                                match_intf=match_intf)\n\n    def register_task(self, index, task_addresses, host_hash):\n        self._send(RegisterTaskRequest(index, task_addresses, host_hash))\n\n    def all_task_addresses(self, index):\n        resp = self._send(AllTaskAddressesRequest(index))\n        return resp.all_task_addresses\n\n    def register_task_to_task_addresses(self, index, task_addresses):\n        self._send(RegisterTaskToTaskAddressesRequest(index, task_addresses))\n'"
horovod/run/common/service/task_service.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport threading\n\nfrom horovod.run.common.util import network\nfrom horovod.run.common.util import safe_shell_exec\nfrom horovod.run.util.threads import in_thread\n\n\nclass RunCommandRequest(object):\n    def __init__(self, command, env):\n        self.command = command\n        """"""Command to run.""""""\n        self.env = env\n        """"""Environment to use.""""""\n\n\nclass CommandExitCodeRequest(object):\n    """"""Get command result""""""\n    pass\n\n\nclass CommandExitCodeResponse(object):\n    def __init__(self, terminated, exit_code):\n        self.terminated = terminated\n        """"""Yes/no""""""\n        self.exit_code = exit_code\n        """"""Exit code returned from command if terminated, None otherwise""""""\n\n\nclass AbortCommandRequest(object):\n    """"""Aborts the command currently running.""""""\n    pass\n\n\nclass WaitForCommandExitCodeRequest(object):\n    """"""Wait for command exit code. Blocks until command terminated or connection closed.""""""\n\n    def __init__(self, delay):\n        """"""\n        :param delay: delay in seconds\n        :type delay: float\n        """"""\n        self.delay = delay\n        """"""Delay in seconds between termination checks.""""""\n\n\nclass WaitForCommandExitCodeResponse(object):\n    def __init__(self, exit_code):\n        self.exit_code = exit_code\n        """"""Exit code returned from command, None if connection closed.""""""\n\n\nclass NotifyInitialRegistrationCompleteRequest(object):\n    """"""Notification that initial task registration has completed.""""""\n    pass\n\n\nclass RegisterCodeResultRequest(object):\n    """"""Register code execution results with task.""""""\n\n    def __init__(self, result):\n        self.result = result\n\n\nclass BasicTaskService(network.BasicService):\n    def __init__(self, name, key, nics, command_env=None, verbose=0):\n        super(BasicTaskService, self).__init__(name, key, nics)\n        self._initial_registration_complete = False\n        self._wait_cond = threading.Condition()\n        self._command_env = command_env\n        self._command_abort = None\n        self._command_exit_code = None\n        self._verbose = verbose\n\n        self._command_thread = None\n        self._fn_result = None\n\n    def _run_command(self, command, env, event):\n        self._command_exit_code = safe_shell_exec.execute(command, env=env, events=[event])\n\n    def _add_envs(self, env, extra_env):\n        """"""\n        Adds extra_env to env.\n\n        :param env: dict representing environment variables\n        :param extra_env: additional variables to be added to env\n        """"""\n        for key, value in extra_env.items():\n            if value is None:\n                if key in env:\n                    del env[key]\n            else:\n                env[key] = value\n\n    def _handle(self, req, client_address):\n        if isinstance(req, RunCommandRequest):\n            self._wait_cond.acquire()\n            try:\n                if self._command_thread is None:\n                    # we add req.env to _command_env and make this available to the executed command\n                    if self._command_env:\n                        env = self._command_env.copy()\n                        self._add_envs(env, req.env)\n                        req.env = env\n\n                    if self._verbose >= 2:\n                        print(""Task service executes command: {}"".format(req.command))\n                        for key, value in req.env.items():\n                            if \'SECRET\' in key:\n                                value = \'*\' * len(value)\n                            print(""Task service env: {} = {}"".format(key, value))\n\n                    # We only permit executing exactly one command, so this is idempotent.\n                    self._command_abort = threading.Event()\n                    self._command_thread = in_thread(\n                        target=self._run_command,\n                        args=(req.command, req.env, self._command_abort)\n                    )\n            finally:\n                self._wait_cond.notify_all()\n                self._wait_cond.release()\n            return network.AckResponse()\n\n        if isinstance(req, AbortCommandRequest):\n            self._wait_cond.acquire()\n            try:\n                if self._command_thread is not None:\n                    self._command_abort.set()\n            finally:\n                self._wait_cond.notify_all()\n                self._wait_cond.release()\n            return network.AckResponse()\n\n        if isinstance(req, NotifyInitialRegistrationCompleteRequest):\n            self._wait_cond.acquire()\n            try:\n                self._initial_registration_complete = True\n            finally:\n                self._wait_cond.notify_all()\n                self._wait_cond.release()\n            return network.AckResponse()\n\n        if isinstance(req, CommandExitCodeRequest):\n            self._wait_cond.acquire()\n            try:\n                terminated = (self._command_thread is not None and\n                              not self._command_thread.is_alive())\n                return CommandExitCodeResponse(terminated,\n                                               self._command_exit_code if terminated else None)\n            finally:\n                self._wait_cond.release()\n\n        if isinstance(req, WaitForCommandExitCodeRequest):\n            self._wait_cond.acquire()\n            try:\n                while self._command_thread is None or self._command_thread.is_alive():\n                    self._wait_cond.wait(req.delay if req.delay >= 1.0 else 1.0)\n                return WaitForCommandExitCodeResponse(self._command_exit_code)\n            finally:\n                self._wait_cond.release()\n\n        if isinstance(req, RegisterCodeResultRequest):\n            self._fn_result = req.result\n            return network.AckResponse()\n\n        return super(BasicTaskService, self)._handle(req, client_address)\n\n    def fn_result(self):\n        return self._fn_result\n\n    def wait_for_initial_registration(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while not self._initial_registration_complete:\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\'tasks to start\')\n        finally:\n            self._wait_cond.release()\n\n    def wait_for_command_start(self, timeout):\n        self._wait_cond.acquire()\n        try:\n            while self._command_thread is None:\n                self._wait_cond.wait(timeout.remaining())\n                timeout.check_time_out_for(\'command to run\')\n        finally:\n            self._wait_cond.release()\n\n    def wait_for_command_termination(self):\n        self._command_thread.join()\n\n\nclass BasicTaskClient(network.BasicClient):\n    def __init__(self, service_name, task_addresses, key, verbose,\n                 match_intf=False, attempts=3):\n        super(BasicTaskClient, self).__init__(service_name,\n                                              task_addresses, key, verbose,\n                                              match_intf=match_intf,\n                                              attempts=attempts)\n\n    def run_command(self, command, env):\n        self._send(RunCommandRequest(command, env))\n\n    def abort_command(self):\n        self._send(AbortCommandRequest())\n\n    def notify_initial_registration_complete(self):\n        self._send(NotifyInitialRegistrationCompleteRequest())\n\n    def command_terminated(self):\n        terminated, _ = self.command_result()\n        return terminated\n\n    def command_result(self):\n        """"""\n        Returns the command\'s result if terminated, or None.\n        :return: terminated flag and result tuple\n        """"""\n        resp = self._send(CommandExitCodeRequest())\n        return resp.terminated, resp.exit_code\n\n    def register_code_result(self, result):\n        self._send(RegisterCodeResultRequest(result))\n\n    def wait_for_command_termination(self, delay=1.0):\n        """"""\n        Wait for command termination. Blocks until command terminated or connection closed.\n\n        :param delay: delay in seconds\n        :type delay: float\n        """"""\n        self.wait_for_command_exit_code(delay)\n\n    def wait_for_command_exit_code(self, delay=1.0):\n        """"""\n        Wait for command termination and retrieve exit code.\n        Blocks until command terminated or connection closed.\n\n        :param delay: delay in seconds\n        :type delay: float\n        """"""\n        try:\n            resp = self._send(WaitForCommandExitCodeRequest(delay))\n            return resp.exit_code\n        except:\n            pass\n'"
horovod/run/common/util/__init__.py,0,b''
horovod/run/common/util/codec.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport base64\nimport cloudpickle\n\n\ndef loads_base64(encoded):\n    decoded = base64.b64decode(encoded)\n    return cloudpickle.loads(decoded)\n\n\ndef dumps_base64(obj, to_ascii=True):\n    serialized = cloudpickle.dumps(obj)\n    encoded = base64.b64encode(serialized)\n    return encoded.decode(\'ascii\') if to_ascii else encoded\n'"
horovod/run/common/util/config_parser.py,0,"b""# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an 'AS IS' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport logging\n\n# Parameter knobs\nHOROVOD_FUSION_THRESHOLD = 'HOROVOD_FUSION_THRESHOLD'\nHOROVOD_CYCLE_TIME = 'HOROVOD_CYCLE_TIME'\nHOROVOD_CACHE_CAPACITY = 'HOROVOD_CACHE_CAPACITY'\nHOROVOD_HIERARCHICAL_ALLREDUCE = 'HOROVOD_HIERARCHICAL_ALLREDUCE'\nHOROVOD_HIERARCHICAL_ALLGATHER = 'HOROVOD_HIERARCHICAL_ALLGATHER'\n\n# Autotune knobs\nHOROVOD_AUTOTUNE = 'HOROVOD_AUTOTUNE'\nHOROVOD_AUTOTUNE_LOG = 'HOROVOD_AUTOTUNE_LOG'\nHOROVOD_AUTOTUNE_WARMUP_SAMPLES = 'HOROVOD_AUTOTUNE_WARMUP_SAMPLES'\nHOROVOD_AUTOTUNE_STEPS_PER_SAMPLE = 'HOROVOD_AUTOTUNE_STEPS_PER_SAMPLE'\nHOROVOD_AUTOTUNE_BAYES_OPT_MAX_SAMPLES = 'HOROVOD_AUTOTUNE_BAYES_OPT_MAX_SAMPLES'\nHOROVOD_AUTOTUNE_GAUSSIAN_PROCESS_NOISE = 'HOROVOD_AUTOTUNE_GAUSSIAN_PROCESS_NOISE'\n\n# Timeline knobs\nHOROVOD_TIMELINE = 'HOROVOD_TIMELINE'\nHOROVOD_TIMELINE_MARK_CYCLES = 'HOROVOD_TIMELINE_MARK_CYCLES'\n\n# Stall check knobs\nHOROVOD_STALL_CHECK_DISABLE = 'HOROVOD_STALL_CHECK_DISABLE'\nHOROVOD_STALL_CHECK_TIME_SECONDS = 'HOROVOD_STALL_CHECK_TIME_SECONDS'\nHOROVOD_STALL_SHUTDOWN_TIME_SECONDS = 'HOROVOD_STALL_SHUTDOWN_TIME_SECONDS'\n\n# Library options knobs\nHOROVOD_MPI_THREADS_DISABLE = 'HOROVOD_MPI_THREADS_DISABLE'\nHOROVOD_NUM_NCCL_STREAMS = 'HOROVOD_NUM_NCCL_STREAMS'\nNCCL_IB_DISABLE = 'NCCL_IB_DISABLE'\nHOROVOD_CCL_BGT_AFFINITY = 'HOROVOD_CCL_BGT_AFFINITY'\nHOROVOD_GLOO_TIMEOUT_SECONDS = 'HOROVOD_GLOO_TIMEOUT_SECONDS'\n\n# Logging knobs\nHOROVOD_LOG_LEVEL = 'HOROVOD_LOG_LEVEL'\nHOROVOD_LOG_HIDE_TIME = 'HOROVOD_LOG_HIDE_TIME'\nLOG_LEVELS = ['TRACE', 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'FATAL']\n\n\ndef _set_arg_from_config(args, arg_base_name, override_args, config, arg_prefix=''):\n    arg_name = arg_prefix + arg_base_name\n    if arg_name in override_args:\n        return\n\n    value = config.get(arg_base_name)\n    if value is not None:\n        setattr(args, arg_name, value)\n\n\ndef set_args_from_config(args, config, override_args):\n    # Controller\n    controller = config.get('controller')\n    if controller and not args.use_gloo and not args.use_mpi:\n        if controller.lower() == 'gloo':\n            args.use_gloo = True\n        elif controller.lower() == 'mpi':\n            args.use_mpi = True\n        else:\n            raise ValueError('No such controller supported: {}'.format(controller))\n\n    # Params\n    params = config.get('params')\n    if params:\n        _set_arg_from_config(args, 'fusion_threshold_mb', override_args, params)\n        _set_arg_from_config(args, 'cycle_time_ms', override_args, params)\n        _set_arg_from_config(args, 'cache_capacity', override_args, params)\n        _set_arg_from_config(args, 'hierarchical_allreduce', override_args, params)\n        _set_arg_from_config(args, 'hierarchical_allgather', override_args, params)\n\n    # Autotune\n    autotune = config.get('autotune')\n    if autotune:\n        args.autotune = autotune.get('enabled', False) if 'autotune' not in override_args else args.autotune\n        _set_arg_from_config(args, 'log_file', override_args, autotune, arg_prefix='autotune_')\n        _set_arg_from_config(args, 'warmup_samples', override_args, autotune, arg_prefix='autotune_')\n        _set_arg_from_config(args, 'steps_per_sample', override_args, autotune, arg_prefix='autotune_')\n        _set_arg_from_config(args, 'bayes_opt_max_samples', override_args, autotune, arg_prefix='autotune_')\n        _set_arg_from_config(args, 'gaussian_process_noise', override_args, autotune, arg_prefix='autotune_')\n\n    # Timeline\n    timeline = config.get('timeline')\n    if timeline:\n        _set_arg_from_config(args, 'filename', override_args, timeline, arg_prefix='timeline_')\n        _set_arg_from_config(args, 'mark_cycles', override_args, timeline, arg_prefix='timeline_')\n\n    # Stall Check\n    stall_check = config.get('stall_check')\n    if stall_check:\n        args.no_stall_check = not stall_check.get('enabled', True) \\\n            if 'no_stall_check' not in override_args else args.no_stall_check\n        _set_arg_from_config(args, 'warning_time_seconds', override_args, stall_check, arg_prefix='stall_check_')\n        _set_arg_from_config(args, 'shutdown_time_seconds', override_args, stall_check, arg_prefix='stall_check_')\n\n    # Library Options\n    library_options = config.get('library_options')\n    if library_options:\n        _set_arg_from_config(args, 'mpi_threads_disable', override_args, library_options)\n        _set_arg_from_config(args, 'num_nccl_streams', override_args, library_options)\n        _set_arg_from_config(args, 'ccl_bgt_affinity', override_args, library_options)\n        _set_arg_from_config(args, 'gloo_timeout_seconds', override_args, library_options)\n\n    # Logging\n    logging = config.get('logging')\n    if logging:\n        _set_arg_from_config(args, 'level', override_args, logging, arg_prefix='log_')\n        _set_arg_from_config(args, 'hide_timestamp', override_args, logging, arg_prefix='log_')\n\n\ndef _validate_arg_nonnegative(args, arg_name):\n    value = getattr(args, arg_name)\n    if value is not None and value < 0:\n        raise ValueError('{}={} must be >= 0'.format(arg_name, value))\n\n\ndef validate_config_args(args):\n    _validate_arg_nonnegative(args, 'fusion_threshold_mb')\n    _validate_arg_nonnegative(args, 'cycle_time_ms')\n    _validate_arg_nonnegative(args, 'cache_capacity')\n    _validate_arg_nonnegative(args, 'autotune_warmup_samples')\n    _validate_arg_nonnegative(args, 'autotune_steps_per_sample')\n    _validate_arg_nonnegative(args, 'autotune_bayes_opt_max_samples')\n\n    noise = args.autotune_gaussian_process_noise\n    if noise is not None and (noise < 0 or noise > 1):\n        raise ValueError('{}={} must be in [0, 1]'.format('autotune_gaussian_process_noise',\n                                                          args.autotune_gaussian_process_noise))\n\n    _validate_arg_nonnegative(args, 'stall_check_warning_time_seconds')\n    _validate_arg_nonnegative(args, 'stall_check_shutdown_time_seconds')\n    _validate_arg_nonnegative(args, 'num_nccl_streams')\n    _validate_arg_nonnegative(args, 'ccl_bgt_affinity')\n    _validate_arg_nonnegative(args, 'gloo_timeout_seconds')\n\n\ndef _add_arg_to_env(env, env_key, arg_value, transform_fn=None):\n    if arg_value is not None:\n        value = arg_value\n        if transform_fn:\n            value = transform_fn(value)\n        env[env_key] = str(value)\n\n\ndef set_env_from_args(env, args):\n    def identity(value):\n        return 1 if value else 0\n\n    # Params\n    _add_arg_to_env(env, HOROVOD_FUSION_THRESHOLD, args.fusion_threshold_mb, lambda v: v * 1024 * 1024)\n    _add_arg_to_env(env, HOROVOD_CYCLE_TIME, args.cycle_time_ms)\n    _add_arg_to_env(env, HOROVOD_CACHE_CAPACITY, args.cache_capacity)\n    _add_arg_to_env(env, HOROVOD_HIERARCHICAL_ALLREDUCE, args.hierarchical_allreduce, identity)\n    _add_arg_to_env(env, HOROVOD_HIERARCHICAL_ALLGATHER, args.hierarchical_allgather, identity)\n\n    # Autotune\n    if args.autotune:\n        _add_arg_to_env(env, HOROVOD_AUTOTUNE, args.autotune, identity)\n        _add_arg_to_env(env, HOROVOD_AUTOTUNE_LOG, args.autotune_log_file)\n        _add_arg_to_env(env, HOROVOD_AUTOTUNE_WARMUP_SAMPLES, args.autotune_warmup_samples)\n        _add_arg_to_env(env, HOROVOD_AUTOTUNE_STEPS_PER_SAMPLE, args.autotune_steps_per_sample)\n        _add_arg_to_env(env, HOROVOD_AUTOTUNE_BAYES_OPT_MAX_SAMPLES, args.autotune_bayes_opt_max_samples)\n        _add_arg_to_env(env, HOROVOD_AUTOTUNE_GAUSSIAN_PROCESS_NOISE, args.autotune_gaussian_process_noise)\n\n    # Timeline\n    if args.timeline_filename:\n        _add_arg_to_env(env, HOROVOD_TIMELINE, args.timeline_filename)\n        _add_arg_to_env(env, HOROVOD_TIMELINE_MARK_CYCLES, args.timeline_mark_cycles, identity)\n\n    # Stall Check\n    _add_arg_to_env(env, HOROVOD_STALL_CHECK_DISABLE, args.no_stall_check, identity)\n    _add_arg_to_env(env, HOROVOD_STALL_CHECK_TIME_SECONDS, args.stall_check_warning_time_seconds)\n    _add_arg_to_env(env, HOROVOD_STALL_SHUTDOWN_TIME_SECONDS, args.stall_check_shutdown_time_seconds)\n\n    # Library Options\n    _add_arg_to_env(env, HOROVOD_MPI_THREADS_DISABLE, args.mpi_threads_disable, identity)\n    _add_arg_to_env(env, HOROVOD_NUM_NCCL_STREAMS, args.num_nccl_streams)\n    _add_arg_to_env(env, NCCL_IB_DISABLE, 1 if args.tcp_flag else None)\n    _add_arg_to_env(env, HOROVOD_CCL_BGT_AFFINITY, args.ccl_bgt_affinity)\n    _add_arg_to_env(env, HOROVOD_GLOO_TIMEOUT_SECONDS, args.gloo_timeout_seconds)\n\n    # Logging\n    _add_arg_to_env(env, HOROVOD_LOG_LEVEL, args.log_level)\n    _add_arg_to_env(env, HOROVOD_LOG_HIDE_TIME, args.log_hide_timestamp, identity)\n\n    return env\n"""
horovod/run/common/util/env.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport re\nimport os\n\nfrom horovod.run.common.util import secret\n\nLOG_LEVEL_STR = [\'FATAL\', \'ERROR\', \'WARNING\', \'INFO\', \'DEBUG\', \'TRACE\']\n\n# List of regular expressions to ignore environment variables by.\nIGNORE_REGEXES = {\'BASH_FUNC_.*\', \'OLDPWD\', secret.HOROVOD_SECRET_KEY}\n\n\ndef is_exportable(v):\n    return not any(re.match(r, v) for r in IGNORE_REGEXES)\n\n\ndef get_env_rank_and_size():\n    rank_env = [\'HOROVOD_RANK\', \'OMPI_COMM_WORLD_RANK\', \'PMI_RANK\']\n    size_env = [\'HOROVOD_SIZE\', \'OMPI_COMM_WORLD_SIZE\', \'PMI_SIZE\']\n\n    for rank_var, size_var in zip(rank_env, size_env):\n        rank = os.environ.get(rank_var)\n        size = os.environ.get(size_var)\n        if rank is not None and size is not None:\n            return int(rank), int(size)\n        elif rank is not None or size is not None:\n            raise RuntimeError(\n                \'Could not determine process rank and size: only one of {} and {} \'\n                \'found in environment\'.format(rank_var, size_var))\n\n    # Default to rank zero and size one if there are no environment variables\n    return 0, 1\n\n'"
horovod/run/common/util/host_hash.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport hashlib\nimport os\nimport socket\n\nNAMESPACE_PATH = \'/proc/self/ns\'\n\n\ndef _namespaces():\n    hash = \'\'\n    if os.path.exists(NAMESPACE_PATH):\n        for file in os.listdir(NAMESPACE_PATH):\n            if hash != \'\':\n                hash += \' \'\n            hash += os.readlink(os.path.join(NAMESPACE_PATH, file))\n    return hash\n\n\ndef _hash(string):\n    return hashlib.md5(string.encode(\'ascii\')).hexdigest()\n\n\ndef host_hash():\n    """"""\n    Computes a hash that represents this host, a unit of processing power that shares memory.\n\n    The hash contains the part of the hostname, e.g. `host` for hostname `host.example.com`,\n    plus a hash derived from the full hostname and further information about this machine.\n\n    This considers environment variable CONTAINER_ID which is present when running Spark via YARN.\n    A YARN container does not share memory with other containers on the same host,\n    so it must be considered a `host` in the sense of the `host_hash`.\n    """"""\n    hostname = socket.gethostname()\n    host = hostname.split(\'.\')[0]\n    ns = _namespaces()\n    host_info = \'{hostname}-{ns}\'.format(hostname=hostname, ns=ns)\n\n    # when running in YARN containers we need to consider a container a host\n    # otherwise we might violate resource allocation if we run all tasks of a host in one container\n    # see [issues 1497](https://github.com/horovod/horovod/issues/1497) for details\n    container = os.environ.get(""CONTAINER_ID"")\n    if container is not None:\n        host_info = \'{host_info}-{container}\'.format(host_info=host_info, container=container)\n\n    return \'{host}-{hash}\'.format(host=host, hash=_hash(host_info))\n'"
horovod/run/common/util/hosts.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport collections\n\n\nclass HostInfo:\n    def __init__(self, hostname, slots):\n        self.hostname = hostname\n        self.slots = slots\n\n    @staticmethod\n    def from_string(host_string):\n        hostname, slots = host_string.strip().split(\':\')\n        return HostInfo(hostname, int(slots))\n\n\nclass SlotInfo:\n    def __init__(self, hostname, rank, local_rank, cross_rank, size=None, local_size=None, cross_size=None):\n        self.hostname = hostname\n        self.rank = rank\n        self.size = size\n        self.local_rank = local_rank\n        self.local_size = local_size\n        self.cross_rank = cross_rank\n        self.cross_size = cross_size\n\n    def to_response_string(self):\n        return \',\'.join(str(v) for v in [self.rank, self.size,\n                                         self.local_rank, self.local_size,\n                                         self.cross_rank, self.cross_size])\n\n    def __eq__(self, other):\n        if isinstance(other, SlotInfo):\n            return self.hostname == other.hostname and \\\n                   self.rank == other.rank and self.size == other.size and \\\n                   self.local_rank == other.local_rank and self.local_size == other.local_size and \\\n                   self.cross_rank == other.cross_rank and self.cross_size == other.cross_size\n        return False\n\n\nINVALID_SLOT_INFO = SlotInfo(hostname=\'\',\n                             rank=-1, local_rank=-1, cross_rank=-1,\n                             size=-1, local_size=-1, cross_size=-1)\n\n\ndef parse_hosts(hosts_string):\n    """"""Parse a string of comma-separated hostname:slots mappings into a list of HostItem objects.\n\n    :param hosts_string: list of addresses and number of processes on each host.\n        For example:\n            - \'worker-0:2,worker-1:2\'\n            - \'10.11.11.11:4,10.11.11.12:4\'\n    :return: a list of HostInfo objects describing host to slot mappings\n    :rtype: list[HostInfo]\n    """"""\n    return [HostInfo.from_string(host_string) for host_string in hosts_string.split(\',\')]\n\n\ndef get_host_assignments(hosts, min_np, max_np=None):\n    """"""Assign hosts with process capacities (slots) to ranks in the Horovod process.\n\n    This function will try to allocate as many as possible processes on the same host to leverage\n    local network.\n\n    :param hosts: list of HostInfo objects describing host and slot capacity\n    :type hosts: list[HostInfo]\n    :param np: total number of processes to be allocated\n    :type np: int\n    :return: a list of the allocation of process on hosts in a AllocInfo object.\n            Members in the object include: hostname, rank, local_rank, cross_rank,\n            total_size, local_size, cross_size\n    :rtype: list[SlotInfo]\n    """"""\n    rank = 0\n    alloc_list = []\n\n    # key: local_rank; value: cross_size for this local_rank\n    local_sizes = collections.defaultdict(int)\n    # key: cross_rank; value: local_size for this cross_rank\n    cross_sizes = collections.defaultdict(int)\n\n    # allocate processes into slots\n    for host_idx, host_info in enumerate(hosts):\n        for local_rank in range(host_info.slots):\n            if rank == max_np:\n                break\n            cross_rank = host_idx\n            alloc_list.append(\n                SlotInfo(\n                    host_info.hostname,\n                    rank,\n                    local_rank,\n                    cross_rank))\n            cross_sizes[local_rank] += 1\n            local_sizes[cross_rank] += 1\n            rank += 1\n\n    if rank < min_np:\n        raise ValueError(\'Requested more processes ({}) than there are available slots ({})\'\n                         .format(min_np, rank))\n\n    # Fill in the local_size and cross_size because we can only know these number after\n    # allocation is done.\n    for alloc_item in alloc_list:\n        alloc_item.local_size = local_sizes[alloc_item.cross_rank]\n        alloc_item.cross_size = cross_sizes[alloc_item.local_rank]\n        alloc_item.size = rank\n    return alloc_list\n'"
horovod/run/common/util/network.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport psutil\nimport queue\nimport socket\nimport socketserver\nimport struct\n\nimport cloudpickle\n\nfrom horovod.run.util.threads import in_thread\nfrom horovod.run.common.util import secret\nfrom horovod.run.util.network import find_port\n\n\nclass PingRequest(object):\n    pass\n\n\nclass NoValidAddressesFound(Exception):\n    pass\n\n\nclass PingResponse(object):\n    def __init__(self, service_name, source_address):\n        self.service_name = service_name\n        """"""Service name that responded to this ping.""""""\n        self.source_address = source_address\n        """"""Source IP address that was visible to the service.""""""\n\n\nclass AckResponse(object):\n    """"""Used for situations when the response does not carry any data.""""""\n    pass\n\n\nclass Wire(object):\n    """"""\n    Used for serialization/deserialization of objects over the wire.\n\n    We use HMAC to protect services from unauthorized use. The key used for\n    the HMAC digest is distributed by Open MPI and Spark.\n\n    The objects are serialized using cloudpickle. Serialized objects become\n    the body of the message.\n\n    Structure of the message is as follows:\n    - HMAC digest of the body (32 bytes)\n    - length of the body (4 bytes)\n    - body\n    """"""\n    def __init__(self, key):\n        self._key = key\n\n    def write(self, obj, wfile):\n        message = cloudpickle.dumps(obj)\n        digest = secret.compute_digest(self._key, message)\n        wfile.write(digest)\n        # Pack message length into 4-byte integer.\n        wfile.write(struct.pack(\'i\', len(message)))\n        wfile.write(message)\n        wfile.flush()\n\n    def read(self, rfile):\n        digest = rfile.read(secret.DIGEST_LENGTH)\n        # Unpack message length into 4-byte integer.\n        message_len = struct.unpack(\'i\', rfile.read(4))[0]\n        message = rfile.read(message_len)\n        if not secret.check_digest(self._key, message, digest):\n            raise Exception(\'Security error: digest did not match the message.\')\n        return cloudpickle.loads(message)\n\n\nclass BasicService(object):\n    def __init__(self, service_name, key, nics):\n        self._service_name = service_name\n        self._wire = Wire(key)\n        self._nics = nics\n        self._server, _ = find_port(\n            lambda addr: socketserver.ThreadingTCPServer(\n                addr, self._make_handler()))\n        self._server._block_on_close = True\n        self._port = self._server.socket.getsockname()[1]\n        self._addresses = self._get_local_addresses()\n        self._thread = in_thread(target=self._server.serve_forever)\n\n    def _make_handler(self):\n        server = self\n\n        class _Handler(socketserver.StreamRequestHandler):\n            def handle(self):\n                try:\n                    req = server._wire.read(self.rfile)\n                    resp = server._handle(req, self.client_address)\n                    if not resp:\n                        raise Exception(\'Handler did not return a response.\')\n                    server._wire.write(resp, self.wfile)\n                except EOFError:\n                    # Happens when client is abruptly terminated, don\'t want to pollute the logs.\n                    pass\n\n        return _Handler\n\n    def _handle(self, req, client_address):\n        if isinstance(req, PingRequest):\n            return PingResponse(self._service_name, client_address[0])\n\n        raise NotImplementedError(req)\n\n    def _get_local_addresses(self):\n        result = {}\n        for intf, intf_addresses in psutil.net_if_addrs().items():\n            if self._nics and intf not in self._nics:\n                continue\n            for addr in intf_addresses:\n                if addr.family == socket.AF_INET:\n                    if intf not in result:\n                        result[intf] = []\n                    result[intf].append((addr.address, self._port))\n        if not result and self._nics:\n            raise NoValidAddressesFound(\n                \'No available network interface found matching user provided interface: {}\'.format(self._nics))\n        return result\n\n    def addresses(self):\n        return self._addresses.copy()\n\n    def shutdown(self):\n        self._server.shutdown()\n        self._server.server_close()\n        self._thread.join()\n\n    def get_port(self):\n        return self._port\n\n\nclass BasicClient(object):\n    def __init__(self, service_name, addresses, key, verbose, match_intf=False,\n                 probe_timeout=20, attempts=3):\n        # Note: because of retry logic, ALL RPC calls are REQUIRED to be idempotent.\n        self._verbose = verbose\n        self._service_name = service_name\n        self._wire = Wire(key)\n        self._match_intf = match_intf\n        self._probe_timeout = probe_timeout\n        self._attempts = attempts\n        self._addresses = self._probe(addresses)\n        if not self._addresses:\n            raise NoValidAddressesFound(\n                \'Horovod was unable to connect to {service_name} on any \'\n                \'of the following addresses: {addresses}.\\n\\n\'\n                \'One possible cause of this problem is that \'\n                \'horovod currently requires every host to have at \'\n                \'least one routable network interface with the same \'\n                \'name across all of the hosts. \'\n                \'You can run \\""ifconfig -a\\"" \'\n                \'on every host and check for the common \'\n                \'routable interface. \'\n                \'To fix the problem, you can rename interfaces on \'\n                \'Linux.\'.format(service_name=service_name, addresses=addresses))\n\n    def _probe(self, addresses):\n        result_queue = queue.Queue()\n        threads = []\n        for intf, intf_addresses in addresses.items():\n            for addr in intf_addresses:\n                thread = in_thread(target=self._probe_one, args=(intf, addr, result_queue))\n                threads.append(thread)\n        for t in threads:\n            t.join()\n\n        result = {}\n        while not result_queue.empty():\n            intf, addr = result_queue.get()\n            if intf not in result:\n                result[intf] = []\n            result[intf].append(addr)\n        return result\n\n    def _probe_one(self, intf, addr, result_queue):\n        for iter in range(self._attempts):\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(self._probe_timeout)\n            try:\n                sock.connect(addr)\n                rfile = sock.makefile(\'rb\')\n                wfile = sock.makefile(\'wb\')\n                try:\n                    self._wire.write(PingRequest(), wfile)\n                    resp = self._wire.read(rfile)\n                    if resp.service_name != self._service_name:\n                        return\n                    if self._match_intf:\n                        # Interface name of destination and source must match\n                        # since `match_intf` is requested.\n                        client_intf_addrs = [x.address\n                                             for x in psutil.net_if_addrs().get(intf, [])\n                                             if x.family == socket.AF_INET]\n                        if resp.source_address not in client_intf_addrs:\n                            if self._verbose >= 2:\n                                # Need to find the local interface name whose\n                                # address was visible to the target host\'s server.\n                                resp_intf = \'\'\n                                for key in psutil.net_if_addrs().keys():\n                                    key_intf_addrs = [x.address\n                                                      for x in psutil.net_if_addrs().get(key, [])]\n                                    if resp.source_address in key_intf_addrs:\n                                        resp_intf = key\n                                        break\n                                print(\'WARNING: Expected to connect the host \'\n                                      \'{addr} using interface \'\n                                      \'{intf}, but reached it on interface \'\n                                      \'{resp_intf}.\'.format(\n                                    addr=str(addr[0])+\':\'+str(addr[1]),\n                                    intf=intf,\n                                    resp_intf=resp_intf))\n                            return\n                    result_queue.put((intf, addr))\n                    return\n                finally:\n                    rfile.close()\n                    wfile.close()\n            except:\n                pass\n            finally:\n                sock.close()\n\n    def _send_one(self, addr, req):\n        for iter in range(self._attempts):\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            try:\n                sock.connect(addr)\n                rfile = sock.makefile(\'rb\')\n                wfile = sock.makefile(\'wb\')\n                try:\n                    self._wire.write(req, wfile)\n                    resp = self._wire.read(rfile)\n                    return resp\n                finally:\n                    rfile.close()\n                    wfile.close()\n            except:\n                if iter == self._attempts - 1:\n                    # Raise exception on the last retry.\n                    raise\n            finally:\n                sock.close()\n\n    def _send(self, req):\n        # Since all the addresses were vetted, use the first one.\n        addr = list(self._addresses.values())[0][0]\n        return self._send_one(addr, req)\n\n    def addresses(self):\n        return self._addresses\n'"
horovod/run/common/util/safe_shell_exec.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport multiprocessing\nimport os\nimport psutil\nimport re\nimport signal\nimport subprocess\nimport sys\nimport threading\nimport time\n\nfrom horovod.run.util.threads import in_thread, on_event\n\nGRACEFUL_TERMINATION_TIME_S = 5\n\n\ndef terminate_executor_shell_and_children(pid):\n    # If the shell already ends, no need to terminate its child.\n    try:\n        p = psutil.Process(pid)\n    except psutil.NoSuchProcess:\n        return\n\n    # Terminate children gracefully.\n    for child in p.children():\n        try:\n            child.terminate()\n        except psutil.NoSuchProcess:\n            pass\n\n    # Wait for graceful termination.\n    gone, alive = psutil.wait_procs(p.children(), timeout=GRACEFUL_TERMINATION_TIME_S)\n\n    # Freeze the process to prevent it from spawning any new children.\n    try:\n        p.send_signal(signal.SIGSTOP)\n    except psutil.NoSuchProcess:\n        pass\n\n    # Kill children recursively.\n    for child in alive:\n        try:\n            for grandchild in child.children(recursive=True):\n                try:\n                    grandchild.kill()\n                except psutil.NoSuchProcess:\n                    pass\n            child.kill()\n        except psutil.NoSuchProcess:\n            pass\n\n    # Kill shell itself.\n    try:\n        p.terminate()\n    except psutil.NoSuchProcess:\n        pass\n\n    try:\n        p.wait(timeout=GRACEFUL_TERMINATION_TIME_S)\n    except psutil.TimeoutExpired:\n        try:\n            p.kill()\n        except psutil.NoSuchProcess:\n            pass\n\n\ndef forward_stream(src_stream, dst_stream, prefix, index):\n    def prepend_context(line, rank, prefix):\n        localtime = time.asctime(time.localtime(time.time()))\n        return \'{time}[{rank}]<{prefix}>:{line}\'.format(\n            time=localtime,\n            rank=str(rank),\n            prefix=prefix,\n            line=line\n        )\n\n    def write(text):\n        if index is not None:\n            text = prepend_context(text, index, prefix)\n        dst_stream.write(text)\n        dst_stream.flush()\n\n    line_buffer = \'\'\n    while True:\n        text = os.read(src_stream.fileno(), 1000)\n        if text is None:\n            break\n\n        if not isinstance(text, str):\n            text = text.decode(\'utf-8\')\n\n        if not text:\n            break\n\n        for line in re.split(\'([\\r\\n])\', text):\n            line_buffer += line\n            if line == \'\\r\' or line == \'\\n\':\n                write(line_buffer)\n                line_buffer = \'\'\n\n    # flush the line buffer if it is not empty\n    if len(line_buffer):\n        write(line_buffer)\n\n    src_stream.close()\n\n\ndef _exec_middleman(command, env, exit_event, stdout, stderr, rw):\n    stdout_r, stdout_w = stdout\n    stderr_r, stderr_w = stderr\n    r, w = rw\n\n    # Close unused file descriptors to enforce PIPE behavior.\n    stdout_r.close()\n    stderr_r.close()\n    w.close()\n    os.setsid()\n\n    executor_shell = subprocess.Popen(command, shell=True, env=env,\n                                      stdout=stdout_w, stderr=stderr_w)\n\n    on_event(exit_event, terminate_executor_shell_and_children, args=(executor_shell.pid,))\n\n    def kill_executor_children_if_parent_dies():\n        # This read blocks until the pipe is closed on the other side\n        # due to parent process termination (for any reason, including -9).\n        os.read(r.fileno(), 1)\n        terminate_executor_shell_and_children(executor_shell.pid)\n\n    in_thread(kill_executor_children_if_parent_dies)\n\n    exit_code = executor_shell.wait()\n    if exit_code < 0:\n        # See: https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html\n        exit_code = 128 + abs(exit_code)\n\n    sys.exit(exit_code)\n\n\ndef _create_event(ctx):\n    # We need to expose this method for internal testing purposes, so we can mock it out to avoid\n    # leaking semaphores.\n    return ctx.Event()\n\n\ndef execute(command, env=None, stdout=None, stderr=None, index=None, events=None):\n    ctx = multiprocessing.get_context(\'spawn\')\n\n    # When this event is set, signal to middleman to terminate its children and exit.\n    exit_event = _create_event(ctx)\n\n    # Make a pipe for the subprocess stdout/stderr.\n    (stdout_r, stdout_w) = ctx.Pipe()\n    (stderr_r, stderr_w) = ctx.Pipe()\n\n    # This Pipe is how we ensure that the executed process is properly terminated (not orphaned) if\n    # the parent process is hard killed (-9). If the parent (this process) is killed for any reason,\n    # this Pipe will be closed, which can be detected by the middleman. When the middleman sees the\n    # closed Pipe, it will issue a SIGTERM to the subprocess executing the command. The assumption\n    # here is that users will be inclined to hard kill this process, not the middleman.\n    (r, w) = ctx.Pipe()\n\n    middleman = ctx.Process(target=_exec_middleman, args=(command, env, exit_event,\n                                                          (stdout_r, stdout_w),\n                                                          (stderr_r, stderr_w),\n                                                          (r, w)))\n    middleman.start()\n\n    # Close unused file descriptors to enforce PIPE behavior.\n    r.close()\n    stdout_w.close()\n    stderr_w.close()\n\n    # Redirect command stdout & stderr to provided streams or sys.stdout/sys.stderr.\n    # This is useful for Jupyter Notebook that uses custom sys.stdout/sys.stderr or\n    # for redirecting to a file on disk.\n    if stdout is None:\n        stdout = sys.stdout\n    if stderr is None:\n        stderr = sys.stderr\n\n    stdout_fwd = in_thread(target=forward_stream, args=(stdout_r, stdout, \'stdout\', index))\n    stderr_fwd = in_thread(target=forward_stream, args=(stderr_r, stderr, \'stderr\', index))\n\n    # TODO: Currently this requires explicitly declaration of the events and signal handler to set\n    #  the event (gloo_run.py:_launch_jobs()). Need to figure out a generalized way to hide this behind\n    #  interfaces.\n    stop = threading.Event()\n    events = events or []\n    for event in events:\n        on_event(event, exit_event.set, stop=stop, silent=True)\n\n    try:\n        middleman.join()\n    except:\n        # interrupted, send middleman TERM signal which will terminate children\n        exit_event.set()\n        while True:\n            try:\n                middleman.join()\n                break\n            except:\n                # interrupted, wait for middleman to finish\n                pass\n    finally:\n        stop.set()\n\n    stdout_fwd.join()\n    stderr_fwd.join()\n\n    return middleman.exitcode\n'"
horovod/run/common/util/secret.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport hashlib\nimport hmac\nimport os\n\n\nSECRET_LENGTH = 32  # bytes\nDIGEST_LENGTH = 32  # bytes\nHOROVOD_SECRET_KEY = \'_HOROVOD_SECRET_KEY\'\n\n\ndef make_secret_key():\n    return os.urandom(SECRET_LENGTH)\n\n\ndef compute_digest(key, message):\n    return hmac.new(key, message, hashlib.sha256).digest()\n\n\ndef check_digest(key, message, digest):\n    computed_digest = compute_digest(key, message)\n    return hmac.compare_digest(computed_digest, digest)\n'"
horovod/run/common/util/settings.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\nclass BaseSettings(object):\n    def __init__(self, num_proc=None, verbose=0, ssh_port=None, extra_mpi_args=None, tcp_flag=None,\n                 binding_args=None, key=None, start_timeout=None, output_filename=None,\n                 run_func_mode=None, nics=None, elastic=False):\n        """"""\n        :param num_proc: number of horovod processes (-np)\n        :type num_proc: int\n        :param verbose: level of verbosity\n        :type verbose: int\n        :param ssh_port: SSH port on all the hosts\n        :type ssh_port: int\n        :param extra_mpi_args: Extra MPI arguments to pass to mpirun\n        :type extra_mpi_args: string\n        :param tcp_flag: TCP only communication flag\n        :type tcp_flag: boolean\n        :param binding_args: Process binding arguments\n        :type binding_args: string\n        :param key: used for encryption of parameters passed across the hosts\n        :type key: str\n        :param start_timeout: has to finish all the checks before this timeout runs out.\n        :type start_timeout: horovod.run.common.util.timeout.Timeout\n        :param output_filename: optional filename to redirect stdout / stderr by process\n        :type output_filename: string\n        :param run_func_mode: whether it is run function mode\n        :type run_func_mode: boolean\n        :param nics: specify the NICs to be used for tcp network communication.\n        :type nics: string\n        :param elastic: enable elastic auto-scaling and fault tolerance mode\n        :type elastic: boolean\n        """"""\n        self.num_proc = num_proc\n        self.verbose = verbose\n        self.ssh_port = ssh_port\n        self.extra_mpi_args = extra_mpi_args\n        self.tcp_flag = tcp_flag\n        self.binding_args = binding_args\n        self.key = key\n        self.start_timeout = start_timeout\n        self.output_filename = output_filename\n        self.run_func_mode = run_func_mode\n        self.nics = nics\n        self.elastic = elastic\n\n\nclass Settings(BaseSettings):\n    def __init__(self, num_hosts=None, hosts=None, **kwargs):\n        """"""\n        :param num_hosts: number of horovod hosts\n        :type num_hosts: int\n        :param hosts: string, comma-delimited, of hostname[s] with slots number[s]\n        :type hosts: string\n        """"""\n        super(Settings, self).__init__(**kwargs)\n        self.num_hosts = num_hosts\n        self.hosts = hosts\n'"
horovod/run/common/util/timeout.py,0,"b'# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport time\n\n\nclass Timeout(object):\n    def __init__(self, timeout, message):\n        self._timeout_at = time.time() + timeout\n        self._message = message\n\n    def remaining(self):\n        return max(0, self._timeout_at - time.time())\n\n    def timed_out(self):\n        return time.time() > self._timeout_at\n\n    def check_time_out_for(self, activity):\n        if self.timed_out():\n            raise Exception(self._message.format(activity=activity))\n'"
horovod/run/common/util/tiny_shell_exec.py,0,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport io\nimport sys\nimport traceback\n\nfrom horovod.run.common.util import safe_shell_exec\n\n\ndef execute(command, env=None):\n    """"""\n    Executes the command and returns stdout and stderr as a string, together with the exit code.\n    :param command: command to execute\n    :param env: environment variables to use\n    :return: (output, exit code) or None on failure\n    """"""\n    output = io.StringIO()\n    try:\n        exit_code = safe_shell_exec.execute(command, env=env, stdout=output, stderr=output)\n        output_msg = output.getvalue()\n    except Exception:\n        print(traceback.format_exc(), file=sys.stderr)\n        return None\n    finally:\n        output.close()\n\n    return output_msg, exit_code\n'"
