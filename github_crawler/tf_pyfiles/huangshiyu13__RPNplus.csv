file_path,api_count,code
NMS.py,0,"b'import numpy as np\r\n\r\n#  Felzenszwalb et al.\r\ndef non_max_suppression_slow(boxes, overlapThresh):\r\n  # if there are no boxes, return an empty list\r\n  if len(boxes) == 0:\r\n    return boxes\r\n\r\n  # initialize the list of picked indexes\r\n  pick = []\r\n\r\n  # grab the coordinates of the bounding boxes\r\n  x1 = boxes[:,0]\r\n  y1 = boxes[:,1]\r\n  xw = boxes[:,2]\r\n  yh = boxes[:,3]\r\n  x2 = x1 + xw\r\n  y2 = y1 + yh\r\n\r\n  # compute the area of the bounding boxes and sort the bounding\r\n  # boxes by the bottom-right y-coordinate of the bounding box\r\n  area = xw * yh\r\n  idxs = np.argsort(boxes[:,4])\r\n\r\n  # keep looping while some indexes still remain in the indexes\r\n  # list\r\n  while len(idxs) > 0:\r\n    # grab the last index in the indexes list, add the index\r\n    # value to the list of picked indexes, then initialize\r\n    # the suppression list (i.e. indexes that will be deleted)\r\n    # using the last index\r\n    last = len(idxs) - 1\r\n    i = idxs[last]\r\n    pick.append(i)\r\n    suppress = [last]\r\n\r\n    # loop over all indexes in the indexes list\r\n    for pos in xrange(0, last):\r\n      # grab the current index\r\n      j = idxs[pos]\r\n\r\n      # find the largest (x, y) coordinates for the start of\r\n      # the bounding box and the smallest (x, y) coordinates\r\n      # for the end of the bounding box\r\n      xx1 = max(x1[i], x1[j])\r\n      yy1 = max(y1[i], y1[j])\r\n      xx2 = min(x2[i], x2[j])\r\n      yy2 = min(y2[i], y2[j])\r\n\r\n      # compute the width and height of the bounding box\r\n      w = max(0, xx2 - xx1)\r\n      h = max(0, yy2 - yy1)\r\n\r\n      # compute the ratio of overlap between the computed\r\n      # bounding box and the bounding box in the area list\r\n      overlap = float(w * h) / min(area[j], area[i])\r\n\r\n      # if there is sufficient overlap, suppress the\r\n      # current bounding box\r\n      if overlap > overlapThresh:\r\n        suppress.append(pos)\r\n\r\n    # delete all indexes from the index list that are in the\r\n    # suppression list\r\n    idxs = np.delete(idxs, suppress)\r\n\r\n  # return only the bounding boxes that were picked\r\n  return boxes[pick]\r\n\r\ndef non_max_suppression_fast(boxes, overlapThresh):\r\n  # if there are no boxes, return an empty list\r\n  if len(boxes) == 0:\r\n    return boxes\r\n \r\n  # initialize the list of picked indexes \r\n  pick = []\r\n \r\n  # grab the coordinates of the bounding boxes\r\n  x1 = boxes[:,0]\r\n  y1 = boxes[:,1]\r\n  xw = boxes[:,2]\r\n  yh = boxes[:,3]\r\n  x2 = x1 + xw\r\n  y2 = y1 + yh\r\n \r\n  # compute the area of the bounding boxes and sort the bounding\r\n  # boxes by the bottom-right y-coordinate of the bounding box\r\n  area = xw * yh\r\n  idxs = np.argsort(boxes[:,4])\r\n \r\n  # keep looping while some indexes still remain in the indexes\r\n  # list\r\n  while len(idxs) > 0:\r\n    # grab the last index in the indexes list and add the\r\n    # index value to the list of picked indexes\r\n    last = len(idxs) - 1\r\n    i = idxs[last]\r\n    pick.append(i)\r\n \r\n    # find the largest (x, y) coordinates for the start of\r\n    # the bounding box and the smallest (x, y) coordinates\r\n    # for the end of the bounding box\r\n    xx1 = np.maximum(x1[i], x1[idxs[:last]])\r\n    yy1 = np.maximum(y1[i], y1[idxs[:last]])\r\n    xx2 = np.minimum(x2[i], x2[idxs[:last]])\r\n    yy2 = np.minimum(y2[i], y2[idxs[:last]])\r\n \r\n    # compute the width and height of the bounding box\r\n    w = np.maximum(0, xx2 - xx1)\r\n    h = np.maximum(0, yy2 - yy1)\r\n \r\n    # compute the ratio of overlap\r\n    overlap = (w * h) / np.minimum(area[idxs[:last]], area[i])\r\n \r\n    # delete all indexes from the index list that have\r\n    idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\r\n  return boxes[pick]\r\n\r\ndef filter_bbox(bbox):\r\n  xrng = [0.1, 959.9]\r\n  yrng = [0.1, 719.9]\r\n  #bbox[:, :4] = bbox[:, :4] / 1.5\r\n  x1 = bbox[:, 0]\r\n  y1 = bbox[:, 1]\r\n  x2 = bbox[:, 0] + bbox[:, 2]\r\n  y2 = bbox[:, 1] + bbox[:, 3]\r\n  keep = np.where((x1 > xrng[0]) & (x2 < xrng[1]) & (y1 > yrng[0]) & (y2 < yrng[1]))[0]\r\n  return bbox[keep, :]'"
_init_paths.py,0,"b""import os.path as osp\r\nimport sys\r\n\r\ndef add_path(path):\r\n    if path not in sys.path:\r\n        sys.path.insert(0, path)\r\n\r\nthis_dir = osp.dirname(__file__)\r\n\r\n# Add caffe to PYTHONPATH\r\npath1 = osp.join(this_dir, '..','image_pylib')\r\nadd_path(path1)\r\n\r\n"""
data_engine.py,0,"b'\nfrom sklearn.utils.extmath import cartesian\nimport numpy as np\nfrom PIL import Image\n\nimport NMS\nimport os\n\nwandhG = [[100.0, 100.0], [300.0, 300.0], [500.0, 500.0],\n          [200.0, 100.0], [370.0, 185.0], [440.0, 220.0],\n          [100.0, 200.0], [185.0, 370.0], [220.0, 440.0]]\n\ndef getAllFiles(dirName, houzhui):\n    results = []\n\n    for file in os.listdir(dirName):\n        file_path = os.path.join(dirName, file)\n        if os.path.isfile(file_path) and os.path.splitext(file_path)[1] == houzhui:\n            results.append([file_path,os.path.splitext(file)[0]])\n\n    return results\n\nclass RPN_Test(object):\n    def __init__(self):\n\n        self.image_height = 720\n        self.image_width = 960\n\n        self.convmap_height = int(np.ceil(self.image_height / 16.))\n        self.convmap_width = int(np.ceil(self.image_width / 16.))\n\n        self.anchor_size = 9\n\n        self.bbox_normalize_scale = 5\n        self.wandh = wandhG\n        self.proposal_prepare()\n\n    def rpn_nms(self, prob, bbox_pred):\n        prob = prob[:, 0]\n        bbox_pred /= self.bbox_normalize_scale\n        anchors = self.proposals.copy()\n        anchors[:, 2] -= anchors[:, 0]\n        anchors[:, 3] -= anchors[:, 1]\n        anchors[:, 0] = bbox_pred[:, 0] * anchors[:, 2] + anchors[:, 0]\n        anchors[:, 1] = bbox_pred[:, 1] * anchors[:, 3] + anchors[:, 1]\n        anchors[:, 2] = np.exp(bbox_pred[:, 2]) * anchors[:, 2]\n        anchors[:, 3] = np.exp(bbox_pred[:, 3]) * anchors[:, 3]\n        bbox = np.zeros([anchors.shape[0], 5])\n        \n        bbox[:, :4] = anchors\n        bbox[:, 4] = prob\n        bbox = NMS.filter_bbox(bbox)\n        bbox = NMS.non_max_suppression_fast(bbox, 0.7)\n\n        keep_prob = np.sort(bbox[:, 4])[max(-50, -1 * bbox.shape[0])]\n        \n        index = np.where(bbox[:, 4] >= keep_prob)[0]\n        bbox = bbox[index]\n        return bbox\n\n    def proposal_prepare(self):\n        \n        anchors = self.generate_anchors()\n        proposals = np.zeros([self.anchor_size * self.convmap_width * self.convmap_height, 4])\n\n        for i in range(self.convmap_height):\n            h = i * 16 + 8\n            for j in range(self.convmap_width):\n                w = j * 16 + 8\n                for k in range(self.anchor_size):\n                    index = i * self.convmap_width * self.anchor_size + j * self.anchor_size + k\n                    anchor = anchors[k, :]\n                    proposals[index, :] = anchor + np.array([w, h, w, h])\n\n        \n        self.proposals = proposals\n\n    def generate_anchors(self):\n        anchors = np.zeros([self.anchor_size, 4])\n\n        for i in range(self.anchor_size):\n            anchor_width = self.wandh[i][0]\n            anchor_height = self.wandh[i][1]\n            anchors[i, :] = np.array(\n                [-0.5 * anchor_width, -0.5 * anchor_height, 0.5 * anchor_width, 0.5 * anchor_height])\n        return anchors\n\nclass My_Caltech_Test(object):\n    def __init__(self ,original):\n        self.original = original;\n        self.image_height = 720\n        self.image_width = 960\n\n        self.convmap_height = int(np.ceil(self.image_height / 16.))\n        self.convmap_width = int(np.ceil(self.image_width / 16.))\n\n        self.anchor_size = 9\n        self.img_resize = 1.5\n        self.bbox_normalize_scale = 5\n        self.wandh = wandhG\n\n        self.aspect_ratio = 0.41\n        self.image_resize_factor = 1.5\n        self.anchor_min_height = 40 * self.image_resize_factor\n        self.anchor_factor = 1.3\n\n        self.proposal_prepare()\n\n    def rpn_nms(self, prob, bbox_pred):\n        prob = prob[:, 0]\n        bbox_pred /= self.bbox_normalize_scale\n        \n        anchors = self.proposals.copy()\n        anchors[:, 2] -= anchors[:, 0]\n        anchors[:, 3] -= anchors[:, 1]\n        anchors[:, 0] = bbox_pred[:, 0] * anchors[:, 2] + anchors[:, 0]\n        anchors[:, 1] = bbox_pred[:, 1] * anchors[:, 3] + anchors[:, 1]\n        anchors[:, 2] = np.exp(bbox_pred[:, 2]) * anchors[:, 2]\n        anchors[:, 3] = np.exp(bbox_pred[:, 3]) * anchors[:, 3]\n        bbox = np.zeros([anchors.shape[0], 5])\n        \n        bbox[:, :4] = anchors\n        bbox[:, 4] = prob\n        bbox = NMS.filter_bbox(bbox)\n        bbox = NMS.non_max_suppression_fast(bbox, 0.7)\n\n        keep_prob = np.sort(bbox[:, 4])[max(-50, -1 * bbox.shape[0])]\n        \n        index = np.where(bbox[:, 4] >= keep_prob)[0]\n        bbox = bbox[index]\n\n        bbox[:, :4] = bbox[:, :4] / self.img_resize\n\n        return bbox\n    \n    def proposal_prepare(self):\n       \n        anchors = self.generate_anchors()\n        proposals = np.zeros([self.anchor_size * self.convmap_width * self.convmap_height, 4])\n\n        for i in range(self.convmap_height):\n            h = i * 16 + 8\n            for j in range(self.convmap_width):\n                w = j * 16 + 8\n                for k in range(self.anchor_size):\n                    index = i * self.convmap_width * self.anchor_size + j * self.anchor_size + k\n                    anchor = anchors[k, :]\n                    proposals[index, :] = anchor + np.array([w, h, w, h])\n\n        \n        self.proposals = proposals\n\n    def generate_anchors(self):\n        if self.original:\n            anchors = np.zeros([self.anchor_size, 4])\n            anchor_height = self.anchor_min_height\n            for i in range(self.anchor_size):\n                anchor_width = anchor_height * self.aspect_ratio\n                anchors[i, :] = np.array(\n                    [-0.5 * anchor_width, -0.5 * anchor_height, 0.5 * anchor_width, 0.5 * anchor_height])\n                anchor_height *= self.anchor_factor\n            return anchors\n        else:\n            anchors = np.zeros([self.anchor_size, 4])\n\n            for i in range(self.anchor_size):\n                anchor_width = self.wandh[i][0]\n                anchor_height = self.wandh[i][1]\n                anchors[i, :] = np.array(\n                    [-0.5 * anchor_width, -0.5 * anchor_height, 0.5 * anchor_width, 0.5 * anchor_height])\n            return anchors\n\n    def open(self,imgPath):\n        im = Image.open(imgPath)\n        return im.resize( ( int(im.width*self.img_resize), int(im.height*self.img_resize) ), Image.ANTIALIAS)\n\nclass CNNData(object):\n    def __init__(self, batch_size=128, imageLoadDir=\'\' , anoLoadDir=\'\',original = False):\n        self.batch_size = batch_size\n        if anoLoadDir == \'\':\n            self.useList = True\n        else:\n            self.useList = False\n\n        if self.useList:\n            self.listName = imageLoadDir\n        else:\n            self.imageLoadDir = imageLoadDir\n            self.anoLoadDir = anoLoadDir\n\n\n        self.aspect_ratio = 0.41\n        self.image_resize_factor = 1.5\n        self.image_height = 720\n        self.image_width = 960\n\n        self.convmap_height = int(np.ceil(self.image_height / 16.))\n        self.convmap_width = int(np.ceil(self.image_width / 16.))\n\n        self.anchor_min_height = 40 * self.image_resize_factor\n        self.anchor_factor = 1.3\n        self.anchor_size = 9\n\n        self.fg_thresh = 0.5\n        self.bg_thresh = 0.2\n\n        self.bbox_normalize_scale = 5\n        self.wandh = wandhG\n\n        self.original = original\n\n        self.load_data()\n\n    def load_data(self):\n        \n        print (\'Load Training Data\')\n\n        self.imdb_train = self.load_image()\n        self.imdb_train = self.proposal_prepare(self.imdb_train)\n        print (\'Done\')\n\n        self.inds = self.generate_minibatch()\n        print (\'Total Batches:\', self.inds.shape[0])\n\n        self.idx = 0\n\n    def load_test_data(self, testDataPath):\n        \n        print (\'Load Testing Data\')\n\n        print (\'Done\')\n\n    def prepare_data(self):\n        if self.idx == self.inds.shape[0]:\n            self.inds = self.generate_minibatch()\n            self.idx = 0\n\n        ind = self.inds[self.idx]\n        im_train = self.imdb_train[ind]\n        self.idx += 1\n\n        im = Image.open(im_train[\'name\'])\n        pix = np.array(im.getdata()).reshape(1, self.image_height, self.image_width, 3).astype(np.float32)\n\n        roi_anchor = im_train[\'roi_anchor\']\n\n        anchors_size = roi_anchor.shape[0]\n\n        labels = np.hstack([np.zeros([anchors_size, 1]), np.ones([anchors_size, 1])])\n        fg_idx = np.where(roi_anchor[:, 0] == 1)[0]\n        \n        bg_idx = np.where(roi_anchor[:, 0] == -1)[0]\n        labels[fg_idx, 0] = 1\n        labels[fg_idx, 1] = 0\n        bbox_targets = roi_anchor[:, 1:5] * self.bbox_normalize_scale\n\n        \n        fg_num = min(fg_idx.shape[0], self.batch_size / 6)\n        np.random.shuffle(fg_idx)\n        fg_idx = fg_idx[:fg_num]\n        bg_num = min(self.batch_size - fg_num, 5 * fg_num)\n        np.random.shuffle(bg_idx)\n        bg_idx = bg_idx[:bg_num]\n\n        labels_weight = np.zeros(anchors_size)\n        bbox_loss_weight = np.zeros(anchors_size)\n        labels_weight[fg_idx] = 1\n        labels_weight[bg_idx] = 1\n        bbox_loss_weight[fg_idx] = 1\n\n        return pix, labels, labels_weight, bbox_targets, bbox_loss_weight\n\n    def get_testdata_size(self):\n        return len(self.imdb_test)\n\n    def prepare_test_data(self, idx):\n        assert (idx >= 0)\n        assert (idx < len(self.imdb_test))\n        im_test = self.imdb_test[idx]\n        im = Image.open(self.path + \'test/images_resize/\' + im_test[\'name\'] + \'.jpg\')\n        pix = np.array(im.getdata()).reshape(1, self.image_height, self.image_width, 3).astype(np.float32)\n        return pix\n\n    def post_process(self, idx, prob, bbox_pred):\n        prob = prob[:, 0]\n        bbox_pred /= self.bbox_normalize_scale\n        keep_prob = np.sort(prob)[-1000]\n        index = np.where(prob >= keep_prob)[0]\n        anchors = self.proposals.copy()\n        anchors[:, 2] -= anchors[:, 0]\n        anchors[:, 3] -= anchors[:, 1]\n        anchors[:, 0] = bbox_pred[:, 0] * anchors[:, 2] + anchors[:, 0]\n        anchors[:, 1] = bbox_pred[:, 1] * anchors[:, 3] + anchors[:, 1]\n        anchors[:, 2] = np.exp(bbox_pred[:, 2]) * anchors[:, 2]\n        anchors[:, 3] = np.exp(bbox_pred[:, 3]) * anchors[:, 3]\n        self.imdb_test[idx][\'bbox\'] = anchors[index, :]\n        self.imdb_test[idx][\'prob\'] = prob[index]\n\n    def save_test(self, iter, save_dir):\n        n = len(self.imdb_test)\n        f = open(save_dir + \'RPN_\' + str(iter) + \'.txt\', \'w\')\n        for i in range(n):\n            im_test = self.imdb_test[i]\n            bbox_num = im_test[\'prob\'].shape[0]\n            for j in range(bbox_num):\n                f.write(str(i + 1) + \' \')\n                for k in range(4):\n                    f.write(str(im_test[\'bbox\'][j, k]) + \' \')\n                f.write(str(im_test[\'prob\'][j]) + \'\\n\')\n        f.close()\n\n    def getImgAndAnoFromList(self, listName):\n        res = []\n        f = open(listName, ""r"")\n        lines = f.readlines()\n        for line in lines:\n            line = line.strip(\'\\n\')\n            ss = line.split(\' \')\n            if len(ss) == 2:\n                res.append(ss)\n        return res\n\n    def load_image(self,flip = 0):\n        imdb = []\n        if self.useList:\n            self.files = self.getImgAndAnoFromList(self.listName)\n            for fileNow in self.files:\n                roi = self.load_roi(fileNow[1])\n                iminfo = {\'name\': fileNow[0], \'image\': None, \'roi\': roi}\n                imdb.append(iminfo)\n                if flip:\n                    roi_f = self.flip_roi(roi)\n                    iminfo = {\'name\': fileNow[0] + \'_flip\', \'image\': None, \'roi\': roi_f}\n                    imdb.append(iminfo)\n        else:\n            self.files = getAllFiles(self.imageLoadDir, \'.jpg\')\n            for fileNow in self.files:\n                roi = self.load_roi(self.anoLoadDir + \'/\' + fileNow[1] + \'.txt\')\n                iminfo = {\'name\': fileNow[0], \'image\': None, \'roi\': roi}\n                imdb.append(iminfo)\n                if flip:\n                    roi_f = self.flip_roi(roi)\n                    iminfo = {\'name\': fileNow[0] + \'_flip\', \'image\': None, \'roi\': roi_f}\n                    imdb.append(iminfo)\n\n        return imdb\n\n    def load_roi(self, path):\n        f = open(path)\n        bbs = f.readlines()[1:]\n        roi = np.zeros([len(bbs), 5])\n        for iter_, bb in zip(range(len(bbs)), bbs):\n            bb = bb.replace(\'\\n\', \'\').split(\' \')\n            bbtype = bb[0]\n            bba = np.array([float(bb[i]) for i in range(1, 5)])\n            occ = float(bb[5])\n            bbv = np.array([float(bb[i]) for i in range(6, 10)])\n            ignore = int(bb[10])\n\n            ignore = ignore or (bbtype != \'person\')\n            ignore = ignore or (bba[3] < 40)\n\n           \n\n            roi[iter_, :4] = bba\n            roi[iter_, 4] = ignore\n        return roi\n\n    def flip_roi(self, roi):\n        roi_f = np.zeros(roi.shape)\n        for i in range(roi_f.shape[0]):\n            roi_f[i, :] = roi[i, :]\n            roi_f[i, 0] = self.image_width - roi[i, 0] - roi[i, 2]\n        return roi_f\n\n    def generate_anchors(self):\n        if self.original:\n            anchors = np.zeros([self.anchor_size, 4])\n            anchor_height = self.anchor_min_height\n            for i in range(self.anchor_size):\n                anchor_width = anchor_height * self.aspect_ratio\n                anchors[i, :] = np.array(\n                    [-0.5 * anchor_width, -0.5 * anchor_height, 0.5 * anchor_width, 0.5 * anchor_height])\n                anchor_height *= self.anchor_factor\n            return anchors\n        else:\n            anchors = np.zeros([self.anchor_size, 4])\n\n            for i in range(self.anchor_size):\n                anchor_width = self.wandh[i][0]\n                anchor_height = self.wandh[i][1]\n                anchors[i, :] = np.array(\n                    [-0.5 * anchor_width, -0.5 * anchor_height, 0.5 * anchor_width, 0.5 * anchor_height])\n            return anchors\n\n    def proposal_prepare(self, imdb):\n      \n        anchors = self.generate_anchors()\n        proposals = np.zeros([self.anchor_size * self.convmap_width * self.convmap_height, 4])\n\n        for i in range(self.convmap_height):\n            h = i * 16 + 8\n            for j in range(self.convmap_width):\n                w = j * 16 + 8\n                for k in range(self.anchor_size):\n                    index = i * self.convmap_width * self.anchor_size + j * self.anchor_size + k\n                    anchor = anchors[k, :]\n                    proposals[index, :] = anchor + np.array([w, h, w, h])\n\n        # ignore cross-boundary anchors\n        self.proposals = proposals\n        proposals_keep = np.where(\n            (proposals[:, 0] > -5) & (proposals[:, 1] > -5) & (proposals[:, 2] < self.image_width + 5) & (\n                proposals[:, 3] < self.image_height + 5))[0]\n        self.proposals_mask = np.zeros(proposals.shape[0])\n        self.proposals_mask[proposals_keep] = 1\n\n        area = (proposals[:, 2] - proposals[:, 0]) * (proposals[:, 3] - proposals[:, 1])\n        proposals = np.hstack([proposals, area.reshape([area.shape[0], 1])])\n       \n        n = len(imdb)\n        foreground_anchor_size = np.zeros(n)\n        for i in range(n):\n            imdb[i][\'roi_anchor\'], foreground_anchor_size[i] = compute_target(imdb[i][\'roi\'], proposals, self.fg_thresh,\n                                                                              self.bg_thresh)\n            imdb[i][\'fgsize\']= foreground_anchor_size[i]\n            if i % 500 == 0:\n                print(\'Compute Target: %d/%d\' % (i, n))\n        print(\'Compute Target: %d/%d\' % (n, n))\n        self.fg_anchors_per_image = foreground_anchor_size\n\n        return imdb\n\n    def generate_minibatch(self):\n        keep = np.where(self.fg_anchors_per_image >= 10)[0]\n        np.random.shuffle(keep)\n        return keep\n\ndef compute_target(roi_t, proposals, fg_thresh, bg_thresh):\n    roi = roi_t.copy()\n    roi[:, 2] += roi[:, 0]\n    roi[:, 3] += roi[:, 1]\n    proposal_size = proposals.shape[0]\n    roi_anchor = np.zeros([proposal_size, 5])\n\n    if roi.shape[0] == 0:\n        return roi_anchor, 0\n\n    overlap = compute_overlap(roi, proposals)\n    overlap_max = np.max(overlap, axis=1)\n    overlap_max_idx = np.argmax(overlap, axis=1)\n\n    for i in range(proposal_size):\n        if overlap_max[i] >= fg_thresh:\n            if roi[overlap_max_idx[i], 4] == 0:\n                roi_anchor[i, 0] = 1\n                roi_anchor[i, 1:5] = compute_regression(roi[overlap_max_idx[i], :4], proposals[i, :])\n        if overlap_max[i] <= bg_thresh:\n            roi_anchor[i, 0] = -1\n\n    foreground = np.sum(roi_anchor[:, 0] == 1)\n    return roi_anchor, foreground\n\ndef compute_overlap(mat1, mat2):\n    s1 = mat1.shape[0]\n    s2 = mat2.shape[0]\n    area1 = (mat1[:, 2] - mat1[:, 0]) * (mat1[:, 3] - mat1[:, 1])\n    if mat2.shape[1] == 5:\n        area2 = mat2[:, 4]\n    else:\n        area2 = (mat2[:, 2] - mat2[:, 0]) * (mat2[:, 3] - mat2[:, 1])\n\n    x1 = cartesian([mat1[:, 0], mat2[:, 0]])\n\n    x1 = np.amax(x1, axis=1)\n    x2 = cartesian([mat1[:, 2], mat2[:, 2]])\n    x2 = np.amin(x2, axis=1)\n    com_zero = np.zeros(x2.shape[0])\n    w = x2 - x1\n    w = w - 1\n\n    w = np.maximum(com_zero, w)\n\n    y1 = cartesian([mat1[:, 1], mat2[:, 1]])\n    y1 = np.amax(y1, axis=1)\n    y2 = cartesian([mat1[:, 3], mat2[:, 3]])\n    y2 = np.amin(y2, axis=1)\n    h = y2 - y1\n    h = h - 1\n    h = np.maximum(com_zero, h)\n\n    oo = w * h\n\n    aa = cartesian([area1[:], area2[:]])\n    aa = np.sum(aa, axis=1)\n\n    ooo = oo / (aa - oo)\n\n    overlap = np.transpose(ooo.reshape(s1, s2), (1, 0))\n\n    return overlap\n\ndef compute_regression(mat1, mat2):\n    target = np.zeros(4)\n    w1 = mat1[2] - mat1[0]\n    h1 = mat1[3] - mat1[1]\n    w2 = mat2[2] - mat2[0]\n    h2 = mat2[3] - mat2[1]\n\n    target[0] = (mat1[0] - mat2[0]) / w2\n    target[1] = (mat1[1] - mat2[1]) / h2\n    target[2] = np.log(w1 / w2)\n    target[3] = np.log(h1 / h2)\n\n    return target\n'"
demo.py,32,"b'import _init_paths\nimport inspect\nimport os\nimport shutil\nimport time\nimport sys\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom image_pylib import IMGLIB\nfrom datetime import datetime  \nimport data_engine\n\nVGG_MEAN = [103.939, 116.779, 123.68]\n\nimage_height = 720\nimage_width = 960\nfeature_height = int(np.ceil(image_height / 16.))\nfeature_width = int(np.ceil(image_width / 16.))\n\n\nclass RPN:\n    def __init__(self, vgg16_npy_path=None, rpn_npy_path=None):\n        if vgg16_npy_path is None:\n            path = inspect.getfile(Vgg16)\n            path = os.path.abspath(os.path.join(path, os.pardir))\n            path = os.path.join(path, \'vgg16.npy\')\n            vgg16_npy_path = path\n            print (path)\n        if rpn_npy_path is None:\n            exit()\n\n        self.vgg16_params = np.load(vgg16_npy_path, encoding=\'latin1\').item()\n        self.rpn_params = np.load(rpn_npy_path, encoding=\'latin1\').item()\n        print(\'npy file loaded\')\n\n    def build(self, rgb):\n     \n        start_time = time.time()\n        print(\'build model started\')\n\n        # Convert RGB to BGR\n        red, green, blue = tf.split(rgb,3, 3)\n        assert red.get_shape().as_list()[1:] == [image_height, image_width, 1]\n        assert green.get_shape().as_list()[1:] == [image_height, image_width, 1]\n        assert blue.get_shape().as_list()[1:] == [image_height, image_width, 1]\n        bgr = tf.concat( [\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ],3)\n        assert bgr.get_shape().as_list()[1:] == [image_height, image_width, 3]\n        # Conv layer 1\n        self.conv1_1 = self.conv_layer_const(bgr, \'conv1_1\')\n        self.conv1_2 = self.conv_layer_const(self.conv1_1, \'conv1_2\')\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n        # Conv layer 2\n        self.conv2_1 = self.conv_layer_const(self.pool1, \'conv2_1\')\n        self.conv2_2 = self.conv_layer_const(self.conv2_1, \'conv2_2\')\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n\n\n        # Conv layer 3\n        self.conv3_1 = self.conv_layer(self.pool2, \'conv3_1\')\n        self.conv3_2 = self.conv_layer(self.conv3_1, \'conv3_2\')\n        self.conv3_3 = self.conv_layer(self.conv3_2, \'conv3_3\')\n        self.pool3 = self.max_pool(self.conv3_3, \'pool3\')\n        # Conv layer 4\n        self.conv4_1 = self.conv_layer(self.pool3, \'conv4_1\')\n        self.conv4_2 = self.conv_layer(self.conv4_1, \'conv4_2\')\n        self.conv4_3 = self.conv_layer(self.conv4_2, \'conv4_3\')\n        self.pool4 = self.max_pool(self.conv4_3, \'pool4\')\n        # Conv layer 5\n        self.conv5_1 = self.conv_layer(self.pool4, \'conv5_1\')\n        self.conv5_2 = self.conv_layer(self.conv5_1, \'conv5_2\')\n        self.conv5_3 = self.conv_layer(self.conv5_2, \'conv5_3\')\n\n        # RPN_TEST_6(>=7)\n        normalization_factor = tf.sqrt(tf.reduce_mean(tf.square(self.conv5_3)))\n        self.gamma3 = tf.constant(self.rpn_params[\'gamma3:0\'], dtype=tf.float32, name=\'gamma3\')\n        self.gamma4 = tf.constant(self.rpn_params[\'gamma4:0\'], dtype=tf.float32, name=\'gamma4\')\n        # Pooling to the same size\n        self.pool3_p = tf.nn.max_pool(self.pool3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\',\n                                      name=\'pool3_proposal\')\n        # L2 Normalization\n        self.pool3_p = self.pool3_p / (\n            tf.sqrt(tf.reduce_mean(tf.square(self.pool3_p))) / normalization_factor) * self.gamma3\n        self.pool4_p = self.pool4 / (\n            tf.sqrt(tf.reduce_mean(tf.square(self.pool4))) / normalization_factor) * self.gamma4\n        # Proposal Convolution\n\n        self.conv_proposal_3 = self.conv_layer(self.pool3_p, \'conv_proposal_3\', use_relu=0)\n        self.relu_proposal_3 = tf.nn.relu(self.conv_proposal_3)\n        self.conv_proposal_4 = self.conv_layer(self.pool4_p, \'conv_proposal_4\', use_relu=0)\n        self.relu_proposal_4 = tf.nn.relu(self.conv_proposal_4)\n        self.conv_proposal_5 = self.conv_layer(self.conv5_3, \'conv_proposal_5\', use_relu=0)\n        self.relu_proposal_5 = tf.nn.relu(self.conv_proposal_5)\n        # Concatrate\n        self.relu_proposal_all = tf.concat([self.relu_proposal_3, self.relu_proposal_4, self.relu_proposal_5],3)\n        # RPN_TEST_6(>=7)\n\n        self.conv_cls_score = self.conv_layer(self.relu_proposal_all, \'conv_cls_score\', use_relu=0)\n        self.conv_bbox_pred = self.conv_layer(self.relu_proposal_all, \'conv_bbox_pred\', use_relu=0)\n\n        assert self.conv_cls_score.get_shape().as_list()[1:] == [feature_height, feature_width, 18]\n        assert self.conv_bbox_pred.get_shape().as_list()[1:] == [feature_height, feature_width, 36]\n\n        self.cls_score = tf.reshape(self.conv_cls_score, [-1, 2])\n        self.bbox_pred = tf.reshape(self.conv_bbox_pred, [-1, 4])\n\n        self.prob = tf.nn.softmax(self.cls_score, name=""prob"")\n\n        self.data_dict = None\n        print(\'build model finished: %ds\' % (time.time() - start_time))\n\n    def avg_pool(self, bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def conv_layer(self, bottom, name, use_relu=1):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter(name)\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n            if use_relu == 1:\n                relu = tf.nn.relu(bias)\n                return relu\n            else:\n                return bias\n\n    def conv_layer_const(self, bottom, name):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter_const(name)\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias_const(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def get_conv_filter(self, name):\n        return tf.constant(self.rpn_params[name][0], name=\'filter\')\n\n    def get_bias(self, name):\n        return tf.constant(self.rpn_params[name][1], name=\'biases\')\n\n    def get_conv_filter_const(self, name):\n        return tf.constant(self.vgg16_params[name][0], name=\'filter\')\n\n    def get_bias_const(self, name):\n        return tf.constant(self.vgg16_params[name][1], name=\'biases\')\n\n\ndef checkFile(fileName):\n    if os.path.isfile(fileName):\n        return True\n    else:\n        print (fileName, \'is not found!\')\n        exit()\n\n\ndef checkDir(fileName, creat=False):\n    if os.path.isdir(fileName):\n        if creat:\n            shutil.rmtree(fileName)\n            os.mkdir(fileName)\n    else:\n        if creat:\n            os.mkdir(fileName)\n        else:\n            print (fileName, \'is not found!\')\n            exit()\n\n\nif __name__ == \'__main__\':\n    if len(sys.argv) < 2:\n        print (\'please input GPU index\')\n        exit()\n    #gpuNow = \'/gpu:\'+sys.argv[1]\n\n\n    modelPath = \'./models/model.npy\'\n\n    vggModelPath = \'./models/vgg16.npy\'\n\n    imageDir = \'./images/\'\n    resultsDir= \'./results/\'\n    checkDir(imageDir,False)\n    checkDir(resultsDir,True)\n    checkFile(vggModelPath)\n    checkFile(modelPath)\n\n\n    image_height = 720\n    image_width = 960\n\n    testDeal = data_engine.RPN_Test()\n\n\n\n    \n    sess = tf.Session()  \n    image = tf.placeholder(tf.float32, [1, image_height, image_width, 3])\n\n    cnn = RPN(vggModelPath, modelPath)\n    with tf.name_scope(\'content_rpn\'):\n        cnn.build(image)\n\n    imglib = IMGLIB()\n\n    imageNames = data_engine.getAllFiles(imageDir, \'.jpg\')\n    startTime = time.time()\n    for imageName in imageNames:\n        print (imageName[0])\n        im = Image.open(imageName[0])\n        pix = np.array(im.getdata()).reshape(1, image_height, image_width, 3).astype(np.float32)\n        \n        start_ = datetime.utcnow()  \n        [test_prob, test_bbox_pred] = sess.run([cnn.prob, cnn.bbox_pred], feed_dict={image: pix})\n        \n        end_ = datetime.utcnow()  \n        c = (end_ - start_)  \n        print (\'%s uses %d milliseconds\' % (imageName[0] , c.microseconds/1000  ) )\n\n        bbox = testDeal.rpn_nms(test_prob, test_bbox_pred)\n        imglib.read_img(imageName[0])\n        imglib.setBBXs(bbox, \'person\')\n        imglib.drawBox(0.99)\n        imglib.save_img(resultsDir+\'/\'+imageName[1]+\'.jpg\')\n    print (\'total use time : %ds\' % (time.time() - startTime))\n'"
train.py,59,"b'import inspect\nimport os\nimport time\nimport  sys\nimport numpy as np\nimport tensorflow as tf\nimport shutil\nimport data_engine\n\nVGG_MEAN = [103.939, 116.779, 123.68]\n\nimage_height = 720\nimage_width = 960\nfeature_height = int(np.ceil(image_height / 16.))\nfeature_width = int(np.ceil(image_width / 16.))\n\n\nclass RPN:\n    def __init__(self, vgg16_npy_path=None):\n        if vgg16_npy_path is None:\n            path = inspect.getfile(Vgg16)\n            path = os.path.abspath(os.path.join(path, os.pardir))\n            path = os.path.join(path, \'vgg16.npy\')\n            vgg16_npy_path = path\n            print path\n\n        self.data_dict = np.load(vgg16_npy_path, encoding=\'latin1\').item()\n        print(\'npy file loaded\')\n\n    def build(self, rgb, label, label_weight, bbox_target, bbox_loss_weight, learning_rate):\n       \n        start_time = time.time()\n        print(\'build model started\')\n\n        # Convert RGB to BGR\n        red, green, blue = tf.split(rgb, 3, 3)\n        assert red.get_shape().as_list()[1:] == [image_height, image_width, 1]\n        assert green.get_shape().as_list()[1:] == [image_height, image_width, 1]\n        assert blue.get_shape().as_list()[1:] == [image_height, image_width, 1]\n        bgr = tf.concat([\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ],3)\n        assert bgr.get_shape().as_list()[1:] == [image_height, image_width, 3]\n        # Conv layer 1\n        self.conv1_1 = self.conv_layer_const(bgr, \'conv1_1\')\n        self.conv1_2 = self.conv_layer_const(self.conv1_1, \'conv1_2\')\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n        # Conv layer 2\n        self.conv2_1 = self.conv_layer_const(self.pool1, \'conv2_1\')\n        self.conv2_2 = self.conv_layer_const(self.conv2_1, \'conv2_2\')\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n        # Conv layer 3\n        self.conv3_1, conv3_1_wd = self.conv_layer(self.pool2, \'conv3_1\')\n        self.conv3_2, conv3_2_wd = self.conv_layer(self.conv3_1, \'conv3_2\')\n        self.conv3_3, conv3_3_wd = self.conv_layer(self.conv3_2, \'conv3_3\')\n        self.weight_dacay = conv3_1_wd + conv3_2_wd + conv3_3_wd\n        self.pool3 = self.max_pool(self.conv3_3, \'pool3\')\n        # Conv layer 4\n        self.conv4_1, conv4_1_wd = self.conv_layer(self.pool3, \'conv4_1\')\n        self.conv4_2, conv4_2_wd = self.conv_layer(self.conv4_1, \'conv4_2\')\n        self.conv4_3, conv4_3_wd = self.conv_layer(self.conv4_2, \'conv4_3\')\n        self.weight_dacay += conv4_1_wd + conv4_2_wd + conv4_3_wd\n        self.pool4 = self.max_pool(self.conv4_3, \'pool4\')\n        # Conv layer 5\n        self.conv5_1, conv5_1_wd = self.conv_layer(self.pool4, \'conv5_1\')\n        self.conv5_2, conv5_2_wd = self.conv_layer(self.conv5_1, \'conv5_2\')\n        self.conv5_3, conv5_3_wd = self.conv_layer(self.conv5_2, \'conv5_3\')\n        self.weight_dacay += conv5_1_wd + conv5_2_wd + conv5_3_wd\n\n        # RPN_TEST_6(>=7)\n        normalization_factor = tf.sqrt(tf.reduce_mean(tf.square(self.conv5_3)))\n        self.gamma3 = tf.Variable(np.sqrt(2), dtype=tf.float32, name=\'gamma3\')\n        self.gamma4 = tf.Variable(1.0, dtype=tf.float32, name=\'gamma4\')\n        # Pooling to the same size\n        self.pool3_p = tf.nn.max_pool(self.pool3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\',\n                                      name=\'pool3_proposal\')\n        # L2 Normalization\n        self.pool3_p = self.pool3_p / (\n            tf.sqrt(tf.reduce_mean(tf.square(self.pool3_p))) / normalization_factor) * self.gamma3\n        self.pool4_p = self.pool4 / (\n            tf.sqrt(tf.reduce_mean(tf.square(self.pool4))) / normalization_factor) * self.gamma4\n        # Proposal Convolution\n        self.conv_proposal_3, conv_proposal_3_wd = self.conv_layer_new(self.pool3_p, \'conv_proposal_3\',\n                                                                       kernel_size=[5, 2], out_channel=256, stddev=0.01)\n        self.relu_proposal_3 = tf.nn.relu(self.conv_proposal_3)\n        self.conv_proposal_4, conv_proposal_4_wd = self.conv_layer_new(self.pool4_p, \'conv_proposal_4\',\n                                                                       kernel_size=[5, 2], out_channel=512, stddev=0.01)\n        self.relu_proposal_4 = tf.nn.relu(self.conv_proposal_4)\n        self.conv_proposal_5, conv_proposal_5_wd = self.conv_layer_new(self.conv5_3, \'conv_proposal_5\',\n                                                                       kernel_size=[5, 2], out_channel=512, stddev=0.01)\n        self.relu_proposal_5 = tf.nn.relu(self.conv_proposal_5)\n        self.weight_dacay += conv_proposal_3_wd + conv_proposal_4_wd + conv_proposal_5_wd\n        # Concatrate\n        self.relu_proposal_all = tf.concat( [self.relu_proposal_3, self.relu_proposal_4, self.relu_proposal_5],3)\n        # RPN_TEST_6(>=7)\n\n        self.conv_cls_score, conv_cls_wd = self.conv_layer_new(self.relu_proposal_all, \'conv_cls_score\',\n                                                               kernel_size=[1, 1], out_channel=18, stddev=0.01)\n        self.conv_bbox_pred, conv_bbox_wd = self.conv_layer_new(self.relu_proposal_all, \'conv_bbox_pred\',\n                                                                kernel_size=[1, 1], out_channel=36, stddev=0.01)\n        self.weight_dacay += conv_cls_wd + conv_bbox_wd\n\n        assert self.conv_cls_score.get_shape().as_list()[1:] == [feature_height, feature_width, 18]\n        assert self.conv_bbox_pred.get_shape().as_list()[1:] == [feature_height, feature_width, 36]\n\n        self.cls_score = tf.reshape(self.conv_cls_score, [-1, 2])\n        self.bbox_pred = tf.reshape(self.conv_bbox_pred, [-1, 4])\n\n        self.prob = tf.nn.softmax(self.cls_score, name=""prob"")\n        self.cross_entropy = tf.reduce_sum(\n            tf.nn.softmax_cross_entropy_with_logits(labels=label,\n                                                    logits=self.cls_score) * label_weight) / tf.reduce_sum(label_weight)\n\n        bbox_error = tf.abs(self.bbox_pred - bbox_target)\n        bbox_loss = 0.5 * bbox_error * bbox_error * tf.cast(bbox_error < 1, tf.float32) + (bbox_error - 0.5) * tf.cast(\n            bbox_error >= 1, tf.float32)\n        self.bb_loss = tf.reduce_sum(\n            tf.reduce_sum(bbox_loss, reduction_indices=[1]) * bbox_loss_weight) / tf.reduce_sum(bbox_loss_weight)\n\n        self.loss = self.cross_entropy + 0.0005 * self.weight_dacay + 0.5 * self.bb_loss\n\n        self.train_step = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(self.loss)\n\n        self.data_dict = None\n        print(\'build model finished: %ds\' % (time.time() - start_time))\n\n    def avg_pool(self, bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def conv_layer(self, bottom, name):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter(name)\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            weight_dacay = tf.nn.l2_loss(filt, name=\'weight_dacay\')\n            return relu, weight_dacay\n\n    def conv_layer_const(self, bottom, name):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter_const(name)\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias_const(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def conv_layer_new(self, bottom, name, kernel_size=[3, 3], out_channel=512, stddev=0.01):\n        with tf.variable_scope(name):\n            shape = bottom.get_shape().as_list()[-1]\n            filt = tf.Variable(\n                tf.random_normal([kernel_size[0], kernel_size[1], shape, out_channel], mean=0.0, stddev=stddev),\n                name=\'filter\')\n            conv_biases = tf.Variable(tf.zeros([out_channel]), name=\'biases\')\n\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            weight_dacay = tf.nn.l2_loss(filt, name=\'weight_dacay\')\n            return bias, weight_dacay\n\n    def get_conv_filter(self, name):\n        return tf.Variable(self.data_dict[name][0], name=\'filter\')\n\n    def get_bias(self, name):\n        return tf.Variable(self.data_dict[name][1], name=\'biases\')\n\n    def get_conv_filter_const(self, name):\n        return tf.constant(self.data_dict[name][0], name=\'filter\')\n\n    def get_bias_const(self, name):\n        return tf.constant(self.data_dict[name][1], name=\'biases\')\n\n    def save(self, save_dir, step=None):\n        params = {}\n        for var in tf.trainable_variables():\n            param_name = var.name.split(\'/\')\n            if param_name[1] in params.keys():\n                params[param_name[1]].append(sess.run(var))\n            else:\n                params[param_name[1]] = [sess.run(var)]\n\n        if step == None:\n            step = 100000\n        np.save(save_dir + \'params_\' + str(step) + \'.npy\', params)\n\n\ndef checkFile(fileName):\n    if os.path.isfile(fileName):\n        return True\n    else:\n        print fileName, \'is not found!\'\n        exit()\n\n\ndef checkDir(fileName, creat=False):\n    if os.path.isdir(fileName):\n        if creat:\n            shutil.rmtree(fileName)\n            os.mkdir(fileName)\n    else:\n        if creat:\n            os.mkdir(fileName)\n        else:\n            print fileName, \'is not found!\'\n            exit()\n\n\nif __name__ == \'__main__\':\n    if len(sys.argv) < 2:\n        print \'please input GPU index\'\n        exit()\n\n    gpuNow = \'/gpu:\'+sys.argv[1]\n    print_time = 100\n    step = 10000\n    batch_size = 256\n    saveTime = 2000\n\n    modelSaveDir = \'./models/\'\n    vggModelPath = \'./models/vgg16.npy\'\n\n    imageLoadDir = \'./yourImagePath/\'\n    anoLoadDir = \'./yourAnnotationPath/\'\n\n    checkDir(modelSaveDir, False)\n    checkDir(imageLoadDir, False)\n    checkDir(anoLoadDir, False)\n\n    with tf.device(gpuNow):\n        sess = tf.Session() \n        image = tf.placeholder(tf.float32, [1, image_height, image_width, 3])\n        label = tf.placeholder(tf.float32, [None, 2])\n        label_weight = tf.placeholder(tf.float32, [None])\n        bbox_target = tf.placeholder(tf.float32, [None, 4])\n        bbox_loss_weight = tf.placeholder(tf.float32, [None])\n        learning_rate = tf.placeholder(tf.float32)\n\n        cnn = RPN(vggModelPath)\n        with tf.name_scope(\'content_rpn\'):\n            cnn.build(image, label, label_weight, bbox_target, bbox_loss_weight, learning_rate)\n\n        sess.run(tf.initialize_all_variables())\n        for var in tf.trainable_variables():\n            print var.name, var.get_shape().as_list(), sess.run(tf.nn.l2_loss(var))\n\n        \n        cnnData = data_engine.CNNData(batch_size, imageLoadDir, anoLoadDir)\n        print \'Training Begin\'\n    \n        train_loss = []\n        train_cross_entropy = []\n        train_bbox_loss = []\n        start_time = time.time()\n\n        for i in xrange(1, step + 1):\n            batch = cnnData.prepare_data()\n            if i <= 7000:\n                l_r = 0.001\n            else:\n                if i <= 9000:\n                    l_r = 0.0001\n                else:\n                    l_r = 0.00001\n            (_, train_loss_iter, train_cross_entropy_iter, train_bbox_loss_iter, cls, bbox) = sess.run(\n                [cnn.train_step, cnn.loss, cnn.cross_entropy, cnn.bb_loss, cnn.cls_score, cnn.bbox_pred],\n                feed_dict={image: batch[0], label: batch[1], label_weight: batch[2], bbox_target: batch[3],\n                           bbox_loss_weight: batch[4], learning_rate: l_r})\n\n            train_loss.append(train_loss_iter)\n          \n\n            if i % print_time == 0:\n              \n                print \' step :\', i, \'time :\', time.time() - start_time, \'loss :\', np.mean(\n                    train_loss), \'l_r :\', l_r\n                train_loss = []\n\n            if i% saveTime == 0:\n                cnn.save(modelSaveDir, i)\n'"
