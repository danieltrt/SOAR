file_path,api_count,code
Chapter3/adadelta.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xbaadadelta\nepsilon = 1e-2\ngamma = 0.9\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\nfig = plt.figure(1, figsize=(12, 8))\nfig.suptitle(\' method: adadelta \xce\xb5=%.4f, \xce\xb3=%.2f\'%(epsilon,gamma), fontsize=15)\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\nax = fig.add_subplot(2, 2, 1, projection=\'3d\')\nax.set_top_view()\nax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\nplt.subplot(2,2,2)\nta = np.linspace(-20, 20, 100)\ntb = np.linspace(-20, 20, 100)\nplt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\nC = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\nplt.clabel(C,inline=True)\nplt.xlabel(\'a\')\nplt.ylabel(\'b\')\n\nplt.ion() # iteration on\n\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nn = np.array([0,0])\ntheta = np.array([0,0]).astype(np.float32) # \xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1a,b\xe8\xbf\xad\xe4\xbb\xa3\xe7\x9a\x84\xe6\x9b\xb4\xe6\x96\xb0\xe5\x80\xbc\n\napple = np.array([0,0]).astype(np.float32)\npear = np.array([0,0]).astype(np.float32)\n# \xe8\xbf\xad\xe4\xbb\xa3\nfor step in range(1,201):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    all_d = np.array([0,0]).astype(np.float32)\n    for i in range(0,len(x)):\n        y_p = a*x[i] + b\n        loss = loss + (y[i] - y_p)*(y[i] - y_p)/2\n        all_da = all_da + da(y[i],y_p,x[i])\n        all_db = all_db + db(y[i],y_p)\n    #loss_ = calc_loss(a = a,b=b,x=np.array(x),y=np.array(y))\n    all_d = np.array([all_da,all_db])\n    loss = loss/len(x)\n\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    ax.scatter(a, b, loss, color=\'black\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    plt.subplot(2,2,2)\n    plt.scatter(a,b,s=5,color=\'blue\')\n    plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    plt.subplot(2, 2, 3)\n    plt.plot(x, y)\n    plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n    plt.subplot(2,2,4)\n    plt.plot(all_step,all_loss,color=\'orange\')\n    plt.xlabel(""step"")\n    plt.ylabel(""loss"")\n\n    # print(\'a = %.3f,b = %.3f\' % (a,b))\n    last_a = a\n    last_b = b\n\n    #-- \xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\n    apple = gamma*apple + (1-gamma)*(all_d**2) # apple with all_d of this step\n    rms_apple = np.sqrt(apple + epsilon)\n\n    pear = gamma*pear + (1-gamma)*(theta**2) # pear with theta of last step\n    rms_pear = np.sqrt(pear + epsilon)\n\n    theta = -(rms_pear/rms_apple)*all_d\n    [a,b] = [a,b] + theta\n\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss,""rms_pear: "",rms_pear,"" rms_apple"",rms_apple)\n        plt.show()\n        plt.pause(0.01)\nplt.show()\nplt.pause(99999999999)\n'"
Chapter3/adagrad.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xbaadagrad\nrate = 0.2 # learning rate\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\nfig = plt.figure(1, figsize=(12, 8))\nfig.suptitle(\'learning rate: %.2f method: adagrad\'%(rate), fontsize=15)\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\nax = fig.add_subplot(2, 2, 1, projection=\'3d\')\nax.set_top_view()\nax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\nplt.subplot(2,2,2)\nta = np.linspace(-20, 20, 100)\ntb = np.linspace(-20, 20, 100)\nplt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\nC = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\nplt.clabel(C,inline=True)\nplt.xlabel(\'a\')\nplt.ylabel(\'b\')\n\nplt.ion() # iteration on\n\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nn = np.array([0,0])\nepsilon = 1e-8\nfor step in range(1,500):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    for i in range(0,len(x)):\n        y_p = a*x[i] + b\n        loss = loss + (y[i] - y_p)*(y[i] - y_p)/2\n        all_da = all_da + da(y[i],y_p,x[i])\n        all_db = all_db + db(y[i],y_p)\n    #loss_ = calc_loss(a = a,b=b,x=np.array(x),y=np.array(y))\n    loss = loss/len(x)\n\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    ax.scatter(a, b, loss, color=\'black\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    plt.subplot(2,2,2)\n    plt.scatter(a,b,s=5,color=\'blue\')\n    plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    plt.subplot(2, 2, 3)\n    plt.plot(x, y)\n    plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n    plt.subplot(2,2,4)\n    plt.plot(all_step,all_loss,color=\'orange\')\n    plt.xlabel(""step"")\n    plt.ylabel(""loss"")\n\n    # print(\'a = %.3f,b = %.3f\' % (a,b))\n    last_a = a\n    last_b = b\n\n    #-- \xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\n    n[0] = n[0]+np.square(all_da)\n    n[1] = n[1]+np.square(all_db)\n    rate_new = rate/(np.sqrt(n + epsilon))\n    print(\'rate_new a:\',rate_new[0],\' b:\',rate_new[1])\n    a = a - (rate/(np.sqrt(n[0] + epsilon)))*all_da\n    b = b - (rate/(np.sqrt(n[1] + epsilon)))*all_db\n\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss)\n        plt.show()\n        plt.pause(0.01)\nplt.show()\nplt.pause(99999999999)\n'"
Chapter3/adam.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xbaadam\n# \xe8\xaf\xa5\xe7\xbb\x84\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb8\x80\xe8\x88\xac\xe6\x9d\xa5\xe8\xaf\xb4\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa7\xa3\xe5\x86\xb3\xe5\xa4\xa7\xe5\xa4\x9a\xe6\x95\xb0\xe9\x97\xae\xe9\xa2\x98\n# \xe6\xb3\xa8\xef\xbc\x9aadam\xe7\xae\x97\xe6\xb3\x95\xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\xa7\xe8\xa7\x84\xe6\xa8\xa1\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x94\xe7\x94\xa8\xe6\x95\x88\xe6\x9e\x9c\xe4\xbc\x9a\xe6\x9b\xb4\xe5\xa5\xbd\xef\xbc\x8c\xe6\x95\x85\xe5\x9c\xa8\xe5\xbd\x93\xe5\x89\x8d\xe5\xb0\x8f\xe8\xa7\x84\xe6\xa8\xa1\xe7\x9a\x84\xe7\xae\x80\xe5\x8d\x95\xe5\x87\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xbc\x98\xe5\x8c\x96\xe9\x97\xae\xe9\xa2\x98\xe4\xb8\x8a\xe6\x94\xb6\xe6\x95\x9b\xe9\x80\x9f\xe5\xba\xa6\xe5\xb9\xb6\xe4\xb8\x8d\xe5\xbf\xab\nrate = 0.001\nbeta1 = 0.9\nbeta2 = 0.999\nepsilon = 1e-8\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\nfig = plt.figure(1, figsize=(12, 8))\nfig.suptitle(\' method: adam \xce\xb5=%.4f, learning rate=%.2f, beta1=%.2f, beta2=%.3f\'%(epsilon,rate,beta1,beta2), fontsize=15)\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\nax = fig.add_subplot(2, 2, 1, projection=\'3d\')\nax.set_top_view()\nax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\nplt.subplot(2,2,2)\nta = np.linspace(-20, 20, 100)\ntb = np.linspace(-20, 20, 100)\nplt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\nC = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\nplt.clabel(C,inline=True)\nplt.xlabel(\'a\')\nplt.ylabel(\'b\')\n\nplt.ion() # iteration on\n\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nm = 0.0\nv = 0.0\ntheta = np.array([0,0]).astype(np.float32)\nfor step in range(1,500):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    for i in range(0,len(x)):\n        y_p = a*x[i] + b\n        loss = loss + (y[i] - y_p)*(y[i] - y_p)/2\n        all_da = all_da + da(y[i],y_p,x[i])\n        all_db = all_db + db(y[i],y_p)\n    loss = loss/len(x)\n    all_d = np.array([all_da,all_db]).astype(np.float32)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    ax.scatter(a, b, loss, color=\'black\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    plt.subplot(2,2,2)\n    plt.scatter(a,b,s=5,color=\'blue\')\n    plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    plt.subplot(2, 2, 3)\n    plt.plot(x, y)\n    plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n    plt.subplot(2,2,4)\n    plt.plot(all_step,all_loss,color=\'orange\')\n    plt.xlabel(""step"")\n    plt.ylabel(""loss"")\n\n\n    # print(\'a = %.3f,b = %.3f\' % (a,b))\n    last_a = a\n    last_b = b\n\n    m = beta1*m + (1-beta1)*all_d\n    v = beta2*v + (1-beta2)*(all_d**2)\n\n    m_ = m/(1 - beta1)\n    v_ = v/(1 - beta2)\n\n\n    theta = -(rate/(np.sqrt(v_) + epsilon))*m_\n\n\n    [a,b] = [a,b] + theta\n\n\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss)\n        plt.show()\n        plt.pause(0.01)\nplt.show()\nplt.pause(99999999999)\n'"
Chapter3/gradientDescent.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nap = argparse.ArgumentParser()\nap.add_argument(""-e"", ""--epochs"", type=float, default=100,\n\thelp=""# of epochs"")\nap.add_argument(""-a"", ""--alpha"", type=float, default=0.01,\n\thelp=""learning rate"")\nap.add_argument(""-b"", ""--batch-size"", type=int, default=32,\n    help=""size of SGD mini-batches"")\nap.add_argument(""-ep"", ""--epsilon"", type=float, default=0.01\n    help=""epsilon value"")\nap.add_argument(""-g"", ""--gamma"", type=float, default=0.9,\n    help=""gamma value"")\n\nargs = vars(ap.parse_args())\n\n'"
Chapter3/gradientSGD.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.datasets.samples_generator import make_blobs\n\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84gradient descent\nrate = 0.2 # learning rate\n\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\n\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\n\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\nfig = plt.figure(1, figsize=(12, 8))\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\nax = fig.add_subplot(2, 2, 1, projection=\'3d\')\nax.set_top_view()\nax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\nplt.subplot(2,2,2)\nta = np.linspace(-20, 20, 100)\ntb = np.linspace(-20, 20, 100)\nplt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\nC = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\nplt.clabel(C,inline=True)\nplt.xlabel(\'a\')\nplt.ylabel(\'b\')\n\nplt.ion() # iteration on\n\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\n\nfor step in range(1,10):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    for i in range(0,len(x)):\n        y_p = a*x[i] + b\n        loss = loss + (y[i] - y_p)*(y[i] - y_p)/2\n        all_da = all_da + da(y[i],y_p,x[i])\n        all_db = all_db + db(y[i],y_p)\n    #loss_ = calc_loss(a = a,b=b,x=np.array(x),y=np.array(y))\n    loss = loss/len(x)\n\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    ax.scatter(a, b, loss, color=\'black\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    plt.subplot(2,2,2)\n    plt.scatter(a,b,s=5,color=\'blue\')\n    plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    plt.subplot(2, 2, 3)\n    plt.plot(x, y)\n    plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n    plt.subplot(2,2,4)\n    plt.plot(all_step,all_loss,color=\'orange\')\n    plt.xlabel(""step"")\n    plt.ylabel(""loss"")\n\n\n    # print(\'a = %.3f,b = %.3f\' % (a,b))\n    last_a = a\n    last_b = b\n    a = a - rate*all_da\n    b = b - rate*all_db\n\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss)\n        plt.show()\n        plt.pause(0.01)\nplt.show()\nplt.pause(99999999999)\n'"
Chapter3/imagePreprocessing.py,34,"b""#--*--coding:tf-8\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\nimage_raw_data = tf.gfile.FastGFile('images/1.jpg', 'rb').read()\n\n\n# \xe4\xbd\xbf\xe7\x94\xa8pyplot\xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe5\x83\x8f\ndef show(img_data):\n    plt.imshow(img_data.eval())\n    plt.show()\n\n\nwith tf.Session() as sess:\n    # \xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xa7\xa3\xe7\xa0\x81\xe6\x88\x90\xe5\xa4\x9a\xe7\xbb\xb4\xe7\x9f\xa9\xe9\x98\xb5\n    img_data = tf.image.decode_jpeg(image_raw_data)\n    print(img_data.eval())\n    show(img_data)\n\n    # \xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe7\xbc\x96\xe7\xa0\x81\xe6\x88\x90\xe5\x9b\xbe\xe5\x83\x8f\xe5\xb9\xb6\xe5\xad\x98\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\n    encoded_image = tf.image.encode_jpeg(img_data)\n    with tf.gfile.GFile('images/output.jpg', 'wb') as f:\n        f.write(encoded_image.eval())\n\n    # \xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xb1\xbb\xe5\x9e\x8b\xe8\xbd\xac\xe4\xb8\xba\xe5\xae\x9e\xe6\x95\xb0\xe7\xb1\xbb\xe5\x9e\x8b\xef\xbc\x8c\xe4\xbe\xbf\xe4\xba\x8e\xe5\xaf\xb9\xe5\x9b\xbe\xe5\x83\x8f\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xa4\x84\xe7\x90\x86\n    img_data = tf.image.convert_image_dtype(img_data, dtype=tf.float32)\n\n    # \xe7\x94\xa8resize_images\xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\n    # \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe5\x83\x8f\n    # \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f[new_height,new_width]\xef\xbc\x8c\xe8\xb7\x9f\xe6\x97\xa7\xe7\x89\x88\xe6\x9c\xac\xe5\x88\x86\xe4\xb8\xba\xe4\xb8\xa4\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8d\xe4\xb8\x80\xe6\xa0\xb7\n    # method\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x99\xe5\x87\xba\xe4\xba\x86\xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\xe7\x9a\x84\xe7\xae\x97\xe6\xb3\x95\n    resized = tf.image.resize_images(img_data, [300, 300], method=0)\n    print(resized.get_shape())  # \xe5\x9b\xbe\xe5\x83\x8f\xe6\xb7\xb1\xe5\xba\xa6\xe6\xb2\xa1\xe6\x9c\x89\xe6\x98\xbe\xe5\xbc\x8f\xe6\x8c\x87\xe5\xae\x9a\xe5\x88\x99\xe4\xb8\xba\xe9\x97\xae\xe5\x8f\xb7\n    show(resized)\n\n    # \xe7\x94\xa8resize_image_with_crop_or_pad\xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\n    # \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe5\x83\x8f\n    # \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x92\x8c\xe7\xac\xac\xe4\xb8\x89\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e\xe5\x8e\x9f\xe5\x9b\xbe\xe5\x88\x99\xe5\xa1\xab\xe5\x85\x85\xef\xbc\x8c\xe5\xb0\x8f\xe4\xba\x8e\xe5\x88\x99\xe8\xa3\x81\xe5\x89\xaa\xe5\xb1\x85\xe4\xb8\xad\xe9\x83\xa8\xe5\x88\x86\n    croped = tf.image.resize_image_with_crop_or_pad(img_data, 200, 200)\n    show(croped)\n    padded = tf.image.resize_image_with_crop_or_pad(img_data, 500, 600)\n    show(padded)\n\n    # \xe7\x94\xa8central_crop\xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\n    # \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe5\x83\x8f\n    # \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\xba\xe8\xb0\x83\xe6\x95\xb4\xe6\xaf\x94\xe4\xbe\x8b\xef\xbc\x8c\xe6\x98\xaf(0,1]\xe7\x9a\x84\xe5\xae\x9e\xe6\x95\xb0\n    central_cropped = tf.image.central_crop(img_data, 0.5)\n    show(central_cropped)\n\n    # \xe5\x9b\xbe\xe5\x83\x8f\xe7\xbf\xbb\xe8\xbd\xac\n    flipped = tf.image.flip_up_down(img_data)  # \xe4\xb8\x8a\xe4\xb8\x8b\n    show(flipped)\n    flipped = tf.image.flip_left_right(img_data)  # \xe5\xb7\xa6\xe5\x8f\xb3\n    show(flipped)\n    transposed = tf.image.transpose_image(img_data)  # \xe5\xaf\xb9\xe8\xa7\x92\xe7\xba\xbf\n    show(transposed)\n\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe7\xbf\xbb\xe8\xbd\xac\xe5\x9b\xbe\xe5\x83\x8f\n    flipped = tf.image.random_flip_up_down(img_data)  # \xe9\x9a\x8f\xe6\x9c\xba\xe4\xb8\x8a\xe4\xb8\x8b\n    show(flipped)\n    flipped = tf.image.random_flip_left_right(img_data)  # \xe9\x9a\x8f\xe6\x9c\xba\xe5\xb7\xa6\xe5\x8f\xb3\n    show(flipped)\n\n    # \xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe4\xba\xae\xe5\xba\xa6\n    adjusted = tf.image.adjust_brightness(img_data, 0.5)  # \xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe4\xba\xae\xe5\xba\xa6+0.5\n    show(adjusted)\n    adjusted = tf.image.random_brightness(\n        img_data, max_delta=0.5)  # \xe5\x9c\xa8[-0.5,0.5]\xe8\x8c\x83\xe5\x9b\xb4\xe5\x86\x85\xe9\x9a\x8f\xe6\x9c\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe4\xba\xae\xe5\xba\xa6\n    show(adjusted)\n\n    # \xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\xba\xa6\n    adjusted = tf.image.adjust_contrast(img_data, -5)  # \xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\xba\xa6-5\n    show(adjusted)\n    adjusted = tf.image.adjust_contrast(img_data, 5)  # \xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\xba\xa6+5\n    show(adjusted)\n    adjusted = tf.image.random_contrast(img_data, lower=-5, upper=5)  # \xe9\x9a\x8f\xe6\x9c\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\xaf\xb9\xe6\xaf\x94\xe5\xba\xa6\n\n    # \xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe9\xa5\xb1\xe5\x92\x8c\xe5\xba\xa6\n    adjusted = tf.image.adjust_saturation(img_data, -5)  # \xe5\xb0\x86\xe9\xa5\xb1\xe5\x92\x8c\xe5\xba\xa6-5\n    show(adjusted)\n    adjusted = tf.image.adjust_saturation(img_data, 5)  # \xe5\xb0\x86\xe9\xa5\xb1\xe5\x92\x8c\xe5\xba\xa6+5\n    show(adjusted)\n    adjusted = tf.image.random_saturation(image, lower=-5, uppper=5)  # \xe9\x9a\x8f\xe6\x9c\xba\xe8\xb0\x83\xe6\x95\xb4\xe9\xa5\xb1\xe5\x92\x8c\xe5\xba\xa6\n    show(adjusted)\n\n    # \xe8\xb0\x83\xe6\x95\xb4\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe8\x89\xb2\xe7\x9b\xb8\n    adjusted = tf.image.adjust_hue(img_data, 0.5)  # \xe5\xb0\x86\xe8\x89\xb2\xe7\x9b\xb8+0.5\n    show(adjusted)\n    adjusted = tf.image.random_hue(img_data, max_delta=0.5)  # \xe9\x9a\x8f\xe6\x9c\xba\xe8\xb0\x83\xe6\x95\xb4\xe8\x89\xb2\xe7\x9b\xb8\n    show(adjusted)\n\n    # \xe7\x94\xa8draw_bounding_boxes\xe5\x8a\xa0\xe5\x85\xa5\xe6\xa0\x87\xe6\xb3\xa8\xe6\xa1\x86\n    # \xe8\xa6\x81\xe6\xb1\x82\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9f\xa9\xe9\x98\xb5\xe7\xb1\xbb\xe5\x9e\x8b\xe4\xb8\xba\xe5\xae\x9e\xe6\x95\xb0\n    # \xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaabatch\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe5\xa4\x9a\xe5\xbc\xa0\xe5\x9b\xbe\xe5\x83\x8f\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe9\x9c\x80\xe8\xa6\x81\xe5\x8a\xa0\xe4\xb8\x80\xe7\xbb\xb4\n    batched = tf.expand_dims(img_data, 0)\n    boxes = tf.constant([[[0.05, 0.05, 0.9, 0.7], [0.35, 0.47, 0.5,\n                                                   0.56]]])  # \xe4\xbb\xa3\xe8\xa1\xa8\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xbd\x8d\xe7\xbd\xae\n    result = tf.image.draw_bounding_boxes(batched, boxes)\n    show(result)\n\n    # \xe7\x94\xa8sample_distorted_bounding_box\xe9\x9a\x8f\xe6\x9c\xba\xe6\x88\xaa\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\n    boxes = tf.constant([[[0.05, 0.05, 0.9, 0.7], [0.35, 0.47, 0.5, 0.56]]])\n    begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(\n        tf.shape(img_data), bounding_boxes=boxes)  # \xe9\x80\x9a\xe8\xbf\x87\xe6\xa0\x87\xe6\xb3\xa8\xe6\xa1\x86\xe5\x91\x8a\xe8\xaf\x89\xe7\xae\x97\xe6\xb3\x95\xe6\x9c\x89\xe4\xbf\xa1\xe6\x81\xaf\xe9\x87\x8f\xe7\x9a\x84\xe9\x83\xa8\xe5\x88\x86\n    batched = tf.expand_dims(img_data, 0)\n    image_with_box = tf.image.draw_bounding_boxes(batched, bbox_for_draw)\n    distorted_image = tf.slice(img_data, begin, size)\n    show(distorted_image)\n"""
Chapter3/learningrate.py,8,"b'import tensorflow as tf\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nx_data = np.random.rand(50).astype(np.float32)\ny_data = x_data * 0.1 + 0.3;\n\nWeights = tf.Variable(tf.random_uniform([1],-1.0,1.0))\nbiases = tf.Variable(tf.zeros([1]))\n\ny = Weights*x_data + biases\n\nloss=tf.reduce_mean(tf.square(y-y_data))\n\nglobal_step = tf.Variable(0)\n\nlearning_rate = tf.train.exponential_decay(0.1,global_step,100,0.96,staircase=True)\nlearning_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n\ninit = tf.global_variables_initializer()\n###\n\nsess = tf.Session()\nsess.run(init)\n\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n\nplt.ion()\nplt.show()\n\n\nfor step in range(300):\n    sess.run(learning_step)\n    if step % 20 == 0:\n        y_value=sess.run(y)\n        ax.scatter(x_data,y_data)\n        ax.scatter(x_data,y_value)\n        plt.pause(1)\n'"
Chapter3/minibatchSGD.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport random\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xbaminibatch SGD\nrate = 0.2 # learning rate\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n\n\ndef shuffle_data(x,y):\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1x\xef\xbc\x8cy\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe4\xbf\x9d\xe6\x8c\x81x\xe5\x92\x8cy\xe4\xb8\x80\xe4\xb8\x80\xe5\xaf\xb9\xe5\xba\x94\n    seed = random.random()\n    random.seed(seed)\n    random.shuffle(x)\n    random.seed(seed)\n    random.shuffle(y)\n\ndef get_batch_data(x,y,batch=3):\n    shuffle_data(x,y)\n    x_new = x[0:batch]\n    y_new = y[0:batch]\n    return [x_new,y_new]\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\nfig = plt.figure(1, figsize=(12, 8))\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\nax = fig.add_subplot(2, 2, 1, projection=\'3d\')\nax.set_top_view()\nax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\nplt.subplot(2,2,2)\nta = np.linspace(-20, 20, 100)\ntb = np.linspace(-20, 20, 100)\nplt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\nC = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\nplt.clabel(C,inline=True)\nplt.xlabel(\'a\')\nplt.ylabel(\'b\')\n\nplt.ion() # iteration on\n\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nfor step in range(1,300):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    shuffle_data(x,y)\n    [x_new,y_new] = get_batch_data(x,y,batch=4)\n    for i in range(0,len(x_new)):\n        y_p = a*x_new[i] + b\n        loss = loss + (y_new[i] - y_p)*(y_new[i] - y_p)/2\n        all_da = all_da + da(y_new[i],y_p,x_new[i])\n        all_db = all_db + db(y_new[i],y_p)\n    #loss_ = calc_loss(a = a,b=b,x=np.array(x),y=np.array(y))\n    loss = loss/len(x_new)\n\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    ax.scatter(a, b, loss, color=\'black\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    plt.subplot(2,2,2)\n    plt.scatter(a,b,s=5,color=\'blue\')\n    plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    plt.subplot(2, 2, 3)\n    plt.plot(x, y)\n    plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n    plt.subplot(2,2,4)\n    plt.plot(all_step,all_loss,color=\'orange\')\n    plt.xlabel(""step"")\n    plt.ylabel(""loss"")\n\n\n    # print(\'a = %.3f,b = %.3f\' % (a,b))\n    last_a = a\n    last_b = b\n    a = a - rate*all_da\n    b = b - rate*all_db\n\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss)\n        plt.show()\n        plt.pause(0.01)\nplt.show()\nplt.pause(99999999999)\n'"
Chapter3/momentumSGD.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport random\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xbaminibatch SGD\nrate = 0.1 # learning rate\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n\n\ndef shuffle_data(x,y):\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1x\xef\xbc\x8cy\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe4\xbf\x9d\xe6\x8c\x81x\xe5\x92\x8cy\xe4\xb8\x80\xe4\xb8\x80\xe5\xaf\xb9\xe5\xba\x94\n    seed = random.random()\n    random.seed(seed)\n    random.shuffle(x)\n    random.seed(seed)\n    random.shuffle(y)\n\ndef get_batch_data(x,y,batch=3):\n    shuffle_data(x,y)\n    x_new = x[0:batch]\n    y_new = y[0:batch]\n    return [x_new,y_new]\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\n#fig = plt.figure(1, figsize=(12, 8))\n#fig.suptitle(\'learning rate: %.2f method:momentum SGD\'%(rate), fontsize=15)\n#\n## \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\n#ax = fig.add_subplot(2, 2, 1, projection=\'3d\')\n#ax.set_top_view()\n#ax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n#\n## \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\n#plt.subplot(2,2,2)\n#ta = np.linspace(-20, 20, 100)\n#tb = np.linspace(-20, 20, 100)\n#plt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\n#C = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\n#plt.clabel(C,inline=True)\n#plt.xlabel(\'a\')\n#plt.ylabel(\'b\')\n#\n#plt.ion() # iteration on\n#\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nva = 0\nvb = 0\ngamma = 0.9\nfor step in range(1,104):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    shuffle_data(x,y)\n    [x_new,y_new] = get_batch_data(x,y,batch=4)\n    for i in range(0,len(x_new)):\n        y_p = a*x_new[i] + b\n        loss = loss + (y_new[i] - y_p)*(y_new[i] - y_p)/2\n        all_da = all_da + da(y_new[i],y_p,x_new[i])\n        all_db = all_db + db(y_new[i],y_p)\n    #loss_ = calc_loss(a = a,b=b,x=np.array(x),y=np.array(y))\n    loss = loss/len(x_new)\n\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    #ax.scatter(a, b, loss, color=\'black\')\n    ## \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    #plt.subplot(2,2,2)\n    #plt.scatter(a,b,s=5,color=\'blue\')\n    #plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    ## \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    #plt.subplot(2, 2, 3)\n    #plt.plot(x, y)\n    #plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    #plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n#    plt.subplot(2,2,4)\n#    plt.plot(all_step,all_loss,color=\'orange\')\n#    plt.xlabel(""step"")\n#    plt.ylabel(""loss"")\n#\n\n    # print(\'a = %.3f,b = %.3f\' % (a,b))\n    last_a = a\n    last_b = b\n\n    va = gamma*va + rate*all_da\n    vb = gamma*vb + rate*all_db\n    a = a - va\n    b = b - vb\n\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss)\n        #plt.show()\n        #plt.pause(0.01)\n#plt.show()\n#plt.pause(99999999999)\n'"
Chapter3/nestrovemomentumSGD.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba momentum with Nesterov\nrate = 0.01 # learning rate\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\nfig = plt.figure(1, figsize=(12, 8))\nfig.suptitle(\'learning rate: %.2f method: Nesterov momentum\'%(rate), fontsize=15)\n\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\nax = fig.add_subplot(2, 2, 1, projection=\'3d\')\nax.set_top_view()\nax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\nplt.subplot(2,2,2)\nta = np.linspace(-20, 20, 100)\ntb = np.linspace(-20, 20, 100)\nplt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\nC = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\nplt.clabel(C,inline=True)\nplt.xlabel(\'a\')\nplt.ylabel(\'b\')\n\nplt.ion() # iteration on\n\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nva = 0\nvb = 0\ngamma = 0.9\nfor step in range(1,100):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    a_ahead = a - gamma*va\n    b_ahead = b - gamma*vb\n    #-- \xe6\xb1\x82loss\n    for i in range(0,len(x)):\n        y_p = a_ahead*x[i] + b_ahead\n        loss = loss + (y[i] - y_p)*(y[i] - y_p)/2\n        all_da = all_da + da(y[i],y_p,x[i])\n        all_db = all_db + db(y[i],y_p)\n    loss = loss/len(x)\n### \xe7\xbb\x98\xe5\x9b\xbe\xe5\x8c\xba\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    ax.scatter(a, b, loss, color=\'black\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n    plt.subplot(2,2,2)\n    plt.scatter(a,b,s=5,color=\'blue\')\n    plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n    plt.subplot(2, 2, 3)\n    plt.plot(x, y)\n    plt.plot(x, y, \'o\')\n    x_ = np.linspace(0, 1, 2)\n    y_draw = a * x_ + b\n    #plt.plot(x_, y_draw)\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n    all_loss.append(loss)\n    all_step.append(step)\n    plt.subplot(2,2,4)\n    plt.plot(all_step,all_loss,color=\'orange\')\n    plt.xlabel(""step"")\n    plt.ylabel(""loss"")\n\n    last_a = a\n    last_b = b\n###\n    #-- \xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\n    print(\'a = %.3f,b = %.3f\' % (a,b))\n\n    va = gamma * va+ rate*all_da\n    vb = gamma * vb+ rate*all_db\n    a = a - va\n    b = b - vb\n    #--\n    if step%1 == 0:\n        print(""step: "", step, "" loss: "", loss)\n        plt.show()\n        plt.pause(0.01)\nplt.show()\nplt.pause(99999999999)\n'"
Chapter3/sgd.py,0,"b'#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport random\n# \xe6\x9c\xac\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\xba\xbf\xe5\xbd\xa2\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84 SGD\nrate = 0.2 # learning rate\ndef da(y,y_p,x):\n    return (y-y_p)*(-x)\n\ndef db(y,y_p):\n    return (y-y_p)*(-1)\ndef calc_loss(a,b,x,y):\n    tmp = y - (a * x + b)\n    tmp = tmp ** 2  # \xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe5\x86\x85\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xb9\xb3\xe6\x96\xb9\n    SSE = sum(tmp) / (2 * len(x))\n    return SSE\ndef draw_hill(x,y):\n    a = np.linspace(-20,20,100)\n    print(a)\n    b = np.linspace(-20,20,100)\n    x = np.array(x)\n    y = np.array(y)\n\n    allSSE = np.zeros(shape=(len(a),len(b)))\n    for ai in range(0,len(a)):\n        for bi in range(0,len(b)):\n            a0 = a[ai]\n            b0 = b[bi]\n            SSE = calc_loss(a=a0,b=b0,x=x,y=y)\n            allSSE[ai][bi] = SSE\n\n    a,b = np.meshgrid(a, b)\n\n    return [a,b,allSSE]\n\ndef shuffle_data(x,y):\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1x\xef\xbc\x8cy\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe4\xbf\x9d\xe6\x8c\x81x\xe5\x92\x8cy\xe4\xb8\x80\xe4\xb8\x80\xe5\xaf\xb9\xe5\xba\x94\n    seed = random.random()\n    random.seed(seed)\n    random.shuffle(x)\n    random.seed(seed)\n    random.shuffle(y)\n#  \xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = [30\t,35,37,\t59,\t70,\t76,\t88,\t100]\ny = [1100,\t1423,\t1377,\t1800,\t2304,\t2588,\t3495,\t4839]\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\nx_max = max(x)\nx_min = min(x)\ny_max = max(y)\ny_min = min(y)\n\nfor i in range(0,len(x)):\n    x[i] = (x[i] - x_min)/(x_max - x_min)\n    y[i] = (y[i] - y_min)/(y_max - y_min)\n\n[ha,hb,hallSSE] = draw_hill(x,y)\nhallSSE = hallSSE.T# \xe9\x87\x8d\xe8\xa6\x81\xef\xbc\x8c\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84losses\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbd\xac\xe7\xbd\xae\xe3\x80\x82\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe8\x87\xb3\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe9\xa1\xba\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x8c\xe8\x80\x8c\xe7\xbb\x98\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5\xe5\xb7\xa6\xe4\xb8\x8b\xe8\xa7\x92\xe4\xb8\xba\xe5\x8e\x9f\xe7\x82\xb9\xe3\x80\x82\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96a,b\xe5\x80\xbc\na = 10.0\nb = -20.0\n#fig = plt.figure(1, figsize=(12, 8))\n#\n## \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe7\x9a\x84\xe6\x9b\xb2\xe9\x9d\xa2\n#ax = fig.add_subplot(2, 2, 1, projection=\'3d\')\n#ax.set_top_view()\n#ax.plot_surface(ha, hb, hallSSE, rstride=2, cstride=2, cmap=\'rainbow\')\n#\n## \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe7\x9a\x84\xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf\xe5\x9b\xbe\n#plt.subplot(2,2,2)\n#ta = np.linspace(-20, 20, 100)\n#tb = np.linspace(-20, 20, 100)\n#plt.contourf(ha,hb,hallSSE,15,alpha=0.5,cmap=plt.cm.hot)\n#C = plt.contour(ha,hb,hallSSE,15,colors=\'black\')\n#plt.clabel(C,inline=True)\n#plt.xlabel(\'a\')\n#plt.ylabel(\'b\')\n#\n#plt.ion() # iteration on\n#\nall_loss = []\nall_step = []\nlast_a = a\nlast_b = b\nstep = 1\nwhile step in range(0,100):\n    loss = 0\n    all_da = 0\n    all_db = 0\n    shuffle_data(x,y)\n    for i in range(0,len(x)):\n        y_p = a*x[i] + b\n        loss = (y[i] - y_p)*(y[i] - y_p)/2\n        all_da = da(y[i],y_p,x[i])\n        all_db = db(y[i],y_p)\n    #loss_ = calc_loss(a = a,b=b,x=np.array(x),y=np.array(y))\n    #loss = loss/len(x)\n\n        # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe1\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n#        ax.scatter(a, b, loss, color=\'black\')\n#        # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe2\xe4\xb8\xad\xe7\x9a\x84loss\xe7\x82\xb9\n#        plt.subplot(2, 2, 2)\n#        plt.scatter(a,b,s=5,color=\'blue\')\n#        plt.plot([last_a,a],[last_b,b],color=\'aqua\')\n#        # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe3\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9b\xb4\xe7\xba\xbf\n#        plt.subplot(2, 2, 3)\n#        plt.plot(x, y)\n#        plt.plot(x, y, \'o\')\n#        x_ = np.linspace(0, 1, 2)\n#        y_draw = a * x_ + b\n#        plt.plot(x_, y_draw)\n#        # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe4\xe7\x9a\x84loss\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9b\xb2\xe7\xba\xbf\n#        all_loss.append(loss)\n#        all_step.append(step)\n#        plt.subplot(2,2,4)\n#        plt.plot(all_step,all_loss,color=\'orange\')\n#        plt.xlabel(""step"")\n#        plt.ylabel(""loss"")\n\n        last_a = a\n        last_b = b\n\n        # \xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\n        a = a - rate*all_da\n        b = b - rate*all_db\n\n        if step%1 == 0:\n            print(""step: "", step, "" loss: "", loss)\n            plt.show()\n            plt.pause(0.01)\n        step = step + 1\n#plt.show()\n#plt.pause(99999999999)\n'"
Chapter3/tfrecordCmp.py,18,"b'#--*--coding--*--:utf-8\nimport os\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe8\xb7\xaf\xe5\xbe\x84\nroot = ""./ADE20K/images/training/""\n\ndef get_filenames(path):\n    filenames = []\n    for root, dirs, files in os.walk(path):\n        for f in files:\n            if "".jpg"" in f:\n                filenames.append(os.path.join(root, f))\n    return filenames\n\ndef convert_to_tfrecord():\n    writer = tf.python_io.TFRecordWriter(""./training.tfrecords"")\n    filenames = get_filenames(root)\n    for name in filenames:\n        img = Image.open(name)\n        if img.mode == ""RGB"":\n            img = img.resize((256, 256), Image.NEAREST)\n            img_raw = img.tobytes()\n            example = tf.train.Example(features=tf.train.Features(feature={\n                      ""img_raw"":tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n            }))\n            writer.write(example.SerializeToString())\n    writer.close()\n\ndef read_img(filenames, num_epochs, shuffle=True):\n    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=True)\n\n    reader = tf.WholeFileReader()\n    key, value = reader.read(filename_queue)\n    img = tf.image.decode_jpeg(value, channels=3)\n    img = tf.image.resize_images(img, size=(256, 256), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n    return img\n\ndef read_tfrecord(filenames, num_epochs, shuffle=True):\n    filename_queue = tf.train.string_input_producer([filenames], num_epochs=num_epochs, shuffle=True)\n\n    reader = tf.TFRecordReader()\n    _, serialized_example = reader.read(filename_queue)\n    features = tf.parse_single_example(serialized_example, features={\n               ""img_raw"": tf.FixedLenFeature([], tf.string),\n    })\n    img = tf.decode_raw(features[""img_raw""], tf.uint8)\n    img =  tf.reshape(img, [256, 256, 3])\n\n    return img\n\nif __name__ == \'__main__\':\n    #create_tfrecord_start_time = time.time()\n    #convert_to_tfrecord()\n    #create_tfrecord_duration = time.time() - create_tfrecord_start_time\n    #print(""Create TFrecord Duration:  %.3f"" % (create_tfrecord_duration))\n\n    with tf.Session() as sess:\n        min_after_dequeue = 1000\n        capacity = min_after_dequeue + 3*4\n\n        img = read_img(get_filenames(root), 1, True)\n        # img = read_tfrecord(""training.tfrecords"", 1, True)\n        img_batch = tf.train.shuffle_batch([img], batch_size=4, num_threads=8,\n                                           capacity=capacity,\n                                           min_after_dequeue=min_after_dequeue)\n\n\n        init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n        sess.run(init)\n        # sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n        # print(sess.run(img))\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        i = 0\n        read_tfrecord_start_time = time.time()\n        try:\n            while not coord.should_stop():\n                imgs = sess.run([img_batch])\n                for img in imgs:\n                    print(img.shape)\n        except Exception, e:\n            coord.request_stop(e)\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n        read_tfrecord_duration = time.time() - read_tfrecord_start_time\n        print(""Read TFrecord Duration:   %.3f"" % read_tfrecord_duration)\n'"
Chapter3/tfrecordConvert.py,17,"b'#--*--coding--*--:utf-8\nimport os\nimport tensorflow as tf\nfrom PIL import Image\n\ncwd = os.getcwd()\n\ndef create_record():\n    \'\'\'\n    \xe6\xad\xa4\xe5\xa4\x84\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9b\xae\xe5\xbd\x95\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a\n    0 -- img1.jpg\n         img2.jpg\n         img3.jpg\n         ...\n    1 -- img1.jpg\n         img2.jpg\n         ...\n    2 -- ...\n    ...\n    \'\'\'\n    writer = tf.python_io.TFRecordWriter(""train.tfrecords"")\n    for index, name in enumerate(num_classes):\n        class_path = cwd + name + ""/""\n        for img_name in os.listdir(class_path):\n            img_path = class_path + img_name\n                img = Image.open(img_path)\n                img = img.resize((224, 224))\n            img_raw = img.tobytes() #\xe5\xb0\x86\xe5\x9b\xbe\xe7\x89\x87\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe5\x8e\x9f\xe7\x94\x9fbytes\n            example = tf.train.Example(features=tf.train.Features(feature={\n                ""label"": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n                \'img_raw\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n            }))\n            writer.write(example.SerializeToString())\n    writer.close()\n\ndef read_and_decode(filename):\n    filename_queue = tf.train.string_input_producer([filename])\n\n    reader = tf.TFRecordReader()\n    _, serialized_example = reader.read(filename_queue)\n    features = tf.parse_single_example(serialized_example,\n                                       features={\n                                           \'label\': tf.FixedLenFeature([], tf.int64),\n                                           \'img_raw\' : tf.FixedLenFeature([], tf.string),\n                                       })\n\n    img = tf.decode_raw(features[\'img_raw\'], tf.uint8)\n    img = tf.reshape(img, [224, 224, 3])\n    img = tf.cast(img, tf.float32) * (1. / 255) - 0.5\n    label = tf.cast(features[\'label\'], tf.int32)\n\n    return img, label\n\nif __name__ == \'__main__\':\n    img, label = read_and_decode(""train.tfrecords"")\n\n    img_batch, label_batch = tf.train.shuffle_batch([img, label],\n                                                    batch_size=30, capacity=2000,\n                                                    min_after_dequeue=1000)\n    #\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84op\n    init = tf.initialize_all_variables()\n\n    with tf.Session() as sess:\n        sess.run(init)\n\t#\xe5\x90\xaf\xe5\x8a\xa8\xe9\x98\x9f\xe5\x88\x97\n        threads = tf.train.start_queue_runners(sess=sess)\n        for i in range(3):\n            val, l= sess.run([img_batch, label_batch])\n            #l = to_categorical(l, 12)\n            print(val.shape, l)\n'"
Chapter5/denoisingAe.py,0,"b""##coding:utf-8\nfrom keras.layers import Input, Convolution2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import TensorBoard\n\n(x_train, _), (x_test, _) = mnist.load_data()\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\nx_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\nnoise_factor = 0.5\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\nprint(x_train.shape)\nprint(x_test.shape)\n\ninput_img = Input(shape=(28, 28, 1))\n\nx = Convolution2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Convolution2D(32, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\nx = Convolution2D(32, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(32, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Convolution2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(inputs=input_img, outputs=decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n# \xe6\x89\x93\xe5\xbc\x80\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\x88\xe7\xab\xaf\xe5\xb9\xb6\xe5\x90\xaf\xe5\x8a\xa8TensorBoard\xef\xbc\x8c\xe7\xbb\x88\xe7\xab\xaf\xe4\xb8\xad\xe8\xbe\x93\xe5\x85\xa5 tensorboard --logdir=/autoencoder\nautoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=256,\n                shuffle=True, validation_data=(x_test_noisy, x_test),\n                callbacks=[TensorBoard(log_dir='autoencoder', write_graph=False)])\n\ndecoded_imgs = autoencoder.predict(x_test_noisy)\n\nn = 10\nplt.figure(figsize=(30, 6))\nfor i in range(n):\n    ax = plt.subplot(3, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    ax = plt.subplot(3, n, i + 1 + n)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    ax = plt.subplot(3, n, i + 1 + 2*n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n"""
Chapter5/input_data.py,0,"b'#coding:utf-8\n# input_data.py\n#!/usr/bin/env python\n\n""""""Functions for downloading and reading MNIST data.""""""\nimport gzip\nimport os\nfrom six.moves.urllib.request import urlretrieve\nimport numpy\nSOURCE_URL = \'http://yann.lecun.com/exdb/mnist/\'\n\n\ndef maybe_download(filename, work_directory):\n    """"""Download the data from Yann\'s website, unless it\'s already here.""""""\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    return filepath\n\n\ndef _read32(bytestream):\n    dt = numpy.dtype(numpy.uint32).newbyteorder(\'>\')\n    return numpy.frombuffer(bytestream.read(4), dtype=dt)\n\n\ndef extract_images(filename):\n    """"""Extract the images into a 4D uint8 numpy array [index, y, x, depth].""""""\n    print(\'Extracting\', filename)\n    with gzip.open(filename) as bytestream:\n        magic = _read32(bytestream) #\xe8\xaf\xbb\xe5\x8f\x96\xe5\x89\x8d\xe5\x9b\x9b\xe4\xb8\xaa\xe5\xad\x97\xe8\x8a\x82\xe6\x89\x80\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84magic number\n        if magic != 2051: #\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84magic number = 2051\n            raise ValueError(\n                \'Invalid magic number %d in MNIST image file: %s\' %\n                (magic, filename))\n        num_images = _read32(bytestream) #\xe8\xaf\xbb\xe5\x8f\x96\xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa54\xe4\xb8\xaa\xe5\xad\x97\xe8\x8a\x82\xe4\xbd\x9c\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe7\x9b\xae.[60000] for train,[10000] for test\n        #\xe6\xaf\x8f\xe4\xb8\x80\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe5\x8c\x85\xe5\x90\xab28X28\xe4\xb8\xaa\xe5\x83\x8f\xe7\xb4\xa0\xe7\x82\xb9,\xe5\x8d\xb3rows=[28],cols=[28]\n        rows = _read32(bytestream) \n        cols = _read32(bytestream)\n        buf = bytestream.read(rows * cols * num_images)\n        data = numpy.frombuffer(buf, dtype=numpy.uint8)  #\xe5\xb0\x86buf\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba1\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\n        data = data.reshape(num_images, rows, cols, 1)  #\xe6\x94\xb9\xe5\x8f\x98\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe7\x8a\xb6:(60000, 28, 28, 1)for train, (10000, 28, 28, 1)for test\n        return data\n\n\ndef dense_to_one_hot(labels_dense, num_classes=10):\n    """"""Convert class labels from scalars to one-hot vectors.""""""\n    num_labels = labels_dense.shape[0]\n    index_offset = numpy.arange(num_labels) * num_classes\n    labels_one_hot = numpy.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\n\ndef extract_labels(filename, one_hot=False):\n    """"""Extract the labels into a 1D uint8 numpy array [index].""""""\n    print(\'Extracting\', filename)\n    with gzip.open(filename) as bytestream:\n        magic = _read32(bytestream) #\xe8\xaf\xbb\xe5\x8f\x96\xe5\x89\x8d\xe5\x9b\x9b\xe4\xb8\xaa\xe5\xad\x97\xe8\x8a\x82\xe6\x89\x80\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84magic number\n        if magic != 2049: #label\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84magic number = 2049\n            raise ValueError(\n                \'Invalid magic number %d in MNIST label file: %s\' %\n                (magic, filename))\n        num_items = _read32(bytestream)  #\xe8\xaf\xbb\xe5\x8f\x96\xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa54\xe4\xb8\xaa\xe5\xad\x97\xe8\x8a\x82\xe4\xbd\x9c\xe4\xb8\xbalabel\xe6\x95\xb0\xe7\x9b\xae.[60000] for train,[10000] for test\n        buf = bytestream.read(num_items) \n        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n        if one_hot:\n            return dense_to_one_hot(labels) #\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xbaone_hot\xe5\xbd\xa2\xe5\xbc\x8f,\xe5\x8d\xb3\xe6\xaf\x8f\xe4\xb8\xaalabel\xe7\x94\xb1\xe4\xb8\x80\xe4\xb8\xaa10\xe7\xbb\xb4\xe5\x90\x91\xe9\x87\x8f\xe8\xa1\xa8\xe7\xa4\xba,label\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xe4\xb8\xba1,\xe5\x85\xb6\xe4\xbd\x99\xe4\xb8\xba0\n        return labels\n\n\nclass DataSet(object):\n    def __init__(self, images, labels, fake_data=False):\n        if fake_data:\n            self._num_examples = 10000\n        else:\n            assert images.shape[0] == labels.shape[0], (\n                ""images.shape: %s labels.shape: %s"" % (images.shape,\n                                                       labels.shape))\n            self._num_examples = images.shape[0]\n            # Convert shape from [num examples, rows, columns, depth]\n            # to [num examples, rows*columns] (assuming depth == 1)\n            assert images.shape[3] == 1\n            images = images.reshape(images.shape[0],\n                                    images.shape[1] * images.shape[2]) #\xe6\x8a\x8a28*28\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\xe5\xb1\x95\xe5\xbc\x80\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa28x28 = 784\xe7\xbb\xb4\xe5\x90\x91\xe9\x87\x8f\n            # Convert from [0, 255] -> [0.0, 1.0].\n            images = images.astype(numpy.float32)\n            images = numpy.multiply(images, 1.0 / 255.0) #\xe5\xb0\x86\xe5\x83\x8f\xe7\xb4\xa0\xe5\x80\xbc\xe8\xbd\xac\xe5\x8c\x96\xe5\x88\xb0[0.0, 1.0]\n        self._images = images\n        self._labels = labels\n        self._epochs_completed = 0\n        self._index_in_epoch = 0\n\n    @property\n    def images(self):\n        return self._images\n\n    @property\n    def labels(self):\n        return self._labels\n\n    @property\n    def num_examples(self):\n        return self._num_examples\n\n    @property\n    def epochs_completed(self):\n        return self._epochs_completed\n\n    def next_batch(self, batch_size, fake_data=False):\n        """"""Return the next `batch_size` examples from this data set.""""""\n        if fake_data:\n            fake_image = [1.0 for _ in xrange(784)]\n            fake_label = 0\n            return [fake_image for _ in xrange(batch_size)], [\n                fake_label for _ in xrange(batch_size)]\n        start = self._index_in_epoch\n        self._index_in_epoch += batch_size\n        if self._index_in_epoch > self._num_examples:\n            # Finished epoch\n            self._epochs_completed += 1\n            # Shuffle the data\n            perm = numpy.arange(self._num_examples)\n            numpy.random.shuffle(perm)\n            self._images = self._images[perm]\n            self._labels = self._labels[perm]\n            # Start next epoch\n            start = 0\n            self._index_in_epoch = batch_size\n            assert batch_size <= self._num_examples\n        end = self._index_in_epoch\n        return self._images[start:end], self._labels[start:end]\n\n\ndef read_data_sets(train_dir, fake_data=False, one_hot=False):\n    class DataSets(object):\n        pass\n    data_sets = DataSets()\n    if fake_data:\n        data_sets.train = DataSet([], [], fake_data=True)\n        data_sets.validation = DataSet([], [], fake_data=True)\n        data_sets.test = DataSet([], [], fake_data=True)\n        return data_sets\n    TRAIN_IMAGES = \'train-images-idx3-ubyte.gz\'  #\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n    TRAIN_LABELS = \'train-labels-idx1-ubyte.gz\'  #\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86label\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n    TEST_IMAGES = \'t10k-images-idx3-ubyte.gz\'    #\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n    TEST_LABELS = \'t10k-labels-idx1-ubyte.gz\'    #\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86label\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n    VALIDATION_SIZE = 5000\n    local_file = maybe_download(TRAIN_IMAGES, train_dir)  #\xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f,\xe8\xbf\x94\xe5\x9b\x9e\xe5\x9b\xbe\xe5\x83\x8f\xe6\x96\x87\xe4\xbb\xb6\xe6\x89\x80\xe5\x9c\xa8\xe7\x9b\xae\xe5\xbd\x95\n    train_images = extract_images(local_file)\n    local_file = maybe_download(TRAIN_LABELS, train_dir)  #\xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe7\x9a\x84label\n    train_labels = extract_labels(local_file, one_hot=one_hot)\n    local_file = maybe_download(TEST_IMAGES, train_dir)   #\xe4\xb8\x8b\xe8\xbd\xbd\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f,\xe8\xbf\x94\xe5\x9b\x9e\xe5\x9b\xbe\xe5\x83\x8f\xe6\x96\x87\xe4\xbb\xb6\xe6\x89\x80\xe5\x9c\xa8\xe7\x9b\xae\xe5\xbd\x95\n    test_images = extract_images(local_file)\n    local_file = maybe_download(TEST_LABELS, train_dir)   #\xe4\xb8\x8b\xe8\xbd\xbd\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe7\x9a\x84label\n    test_labels = extract_labels(local_file, one_hot=one_hot)\n    #\xe5\x8f\x96\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe4\xb8\xad\xe7\x9a\x84\xe5\x89\x8d5000\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe4\xbd\x9c\xe4\xb8\xba\xe9\xaa\x8c\xe8\xaf\x81\xe9\x9b\x86\n    validation_images = train_images[:VALIDATION_SIZE]\n    validation_labels = train_labels[:VALIDATION_SIZE]\n    train_images = train_images[VALIDATION_SIZE:]\n    train_labels = train_labels[VALIDATION_SIZE:]\n    data_sets.train = DataSet(train_images, train_labels)\n    data_sets.validation = DataSet(validation_images, validation_labels)\n    data_sets.test = DataSet(test_images, test_labels)\n    return data_sets\n'"
Chapter6/datagenerator.py,6,"b'import tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework.ops import convert_to_tensor\nfrom tensorflow.contrib.data import Dataset\n\nVGG_MEAN = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32)\n\n\n# \xe6\x8a\x8a\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe4\xb8\x89\xe7\xbb\xb4\xe7\x9f\xa9\xe9\x98\xb5\nclass ImageDataGenerator(object):\n    def __init__(self, images, labels, batch_size, num_classes, shuffle=True):\n\n        self.img_paths = images\n        self.labels = labels\n        self.num_classes = num_classes\n        self.data_size = len(self.labels)\n        self.pointer = 0\n\n        if shuffle:\n            self._shuffle_lists()\n\n        self.img_paths = convert_to_tensor(self.img_paths, dtype=dtypes.string)\n        self.labels = convert_to_tensor(self.labels, dtype=dtypes.int32)\n        data = Dataset.from_tensor_slices((self.img_paths, self.labels))\n        data = data.map(self._parse_function_train, num_threads=8,\n                        output_buffer_size=100 * batch_size)\n\n        data = data.batch(batch_size)\n\n        self.data = data\n\n    # \xe6\x89\x93\xe4\xb9\xb1\xe5\x9b\xbe\xe7\x89\x87\xe9\xa1\xba\xe5\xba\x8f\n    def _shuffle_lists(self):\n        path = self.img_paths\n        labels = self.labels\n        permutation = np.random.permutation(self.data_size)\n        self.img_paths = []\n        self.labels = []\n        for i in permutation:\n            self.img_paths.append(path[i])\n            self.labels.append(labels[i])\n\n    # \xe6\x8a\x8a\xe5\x9b\xbe\xe7\x89\x87\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x89\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x8a\x8a\xe6\xa0\x87\xe7\xad\xbe\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe5\x90\x91\xe9\x87\x8f\n    def _parse_function_train(self, filename, label):\n        one_hot = tf.one_hot(label, self.num_classes)\n        img_string = tf.read_file(filename)\n        img_decoded = tf.image.decode_png(img_string, channels=3)\n        img_resized = tf.image.resize_images(img_decoded, [227, 227])\n        img_centered = tf.subtract(img_resized, VGG_MEAN)\n        img_bgr = img_centered[:, :, ::-1]\n        return img_bgr, one_hot\n'"
Chapter3/flower/predict.py,6,"b'#-*-:coding:utf-8\nfrom skimage import io,transform\nimport tensorflow as tf\nimport numpy as np\n\n\npath1 = ""./data/flower_photos/daisy/5547758_eea9edfd54_n.jpg""\npath2 = ""./data/flower_photos/dandelion/7355522_b66e5d3078_m.jpg""\npath3 = ""./data/flower_photos/roses/394990940_7af082cf8d_n.jpg""\npath4 = ""./data/flower_photos/sunflowers/6953297_8576bf4ea3.jpg""\npath5 = ""./data/flower_photos/tulips/10791227_7168491604.jpg""\n\nflower_dict = {0:\'dasiy\',1:\'dandelion\',2:\'roses\',3:\'sunflowers\',4:\'tulips\'}\n\nw=100\nh=100\nc=3\n\ndef read_one_image(path):\n    img = io.imread(path)\n    img = transform.resize(img,(w,h))\n    return np.asarray(img)\n\nwith tf.Session() as sess:\n    data = []\n    data1 = read_one_image(path1)\n    data2 = read_one_image(path2)\n    data3 = read_one_image(path3)\n    data4 = read_one_image(path4)\n    data5 = read_one_image(path5)\n    data.append(data1)\n    data.append(data2)\n    data.append(data3)\n    data.append(data4)\n    data.append(data5)\n\n    saver = tf.train.import_meta_graph(\'./model/model.ckpt.meta\')\n    saver.restore(sess,tf.train.latest_checkpoint(\'./model/\'))\n\n    graph = tf.get_default_graph()\n    x = graph.get_tensor_by_name(""x:0"")\n    feed_dict = {x:data}\n\n    logits = graph.get_tensor_by_name(""logits_eval:0"")\n\n    classification_result = sess.run(logits,feed_dict)\n\n    #\xe6\x89\x93\xe5\x8d\xb0\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9f\xa9\xe9\x98\xb5\n    print(classification_result)\n    #\xe6\x89\x93\xe5\x8d\xb0\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9f\xa9\xe9\x98\xb5\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\n    print(tf.argmax(classification_result,1).eval())\n    #\xe6\xa0\xb9\xe6\x8d\xae\xe7\xb4\xa2\xe5\xbc\x95\xe9\x80\x9a\xe8\xbf\x87\xe5\xad\x97\xe5\x85\xb8\xe5\xaf\xb9\xe5\xba\x94\xe8\x8a\xb1\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\n    output = []\n    output = tf.argmax(classification_result,1).eval()\n    for i in range(len(output)):\n        print(""\xe7\xac\xac"",i+1,""\xe6\x9c\xb5\xe8\x8a\xb1\xe9\xa2\x84\xe6\xb5\x8b:""+flower_dict[output[i]])\n'"
Chapter3/flower/train.py,61,"b'#-*-:coding:utf-8\nfrom skimage import io,transform\nimport glob\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport time\n\n#\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x9c\xb0\xe5\x9d\x80\npath=\'./data/flower_photos/\'\n#\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbf\x9d\xe5\xad\x98\xe5\x9c\xb0\xe5\x9d\x80\nmodel_path=\'./model/model.ckpt\'\n\n#\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87resize\xe6\x88\x90100*100\nw=100\nh=100\nc=3\n\n#\xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\ndef read_img(path):\n    cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)]\n    imgs=[]\n    labels=[]\n    for idx,folder in enumerate(cate):\n        for im in glob.glob(folder+\'/*.jpg\'):\n            print(\'reading the images:%s\'%(im))\n            img=io.imread(im)\n            img=transform.resize(img,(w,h))\n            imgs.append(img)\n            labels.append(idx)\n    return np.asarray(imgs,np.float32),np.asarray(labels,np.int32)\ndata,label=read_img(path)\n\n\n#\xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\nnum_example=data.shape[0]\narr=np.arange(num_example)\nnp.random.shuffle(arr)\ndata=data[arr]\nlabel=label[arr]\n\n\n#\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe9\x9b\x86\nratio=0.8\ns=np.int(num_example*ratio)\nx_train=data[:s]\ny_train=label[:s]\nx_val=data[s:]\ny_val=label[s:]\n\n#-----------------\xe6\x9e\x84\xe5\xbb\xba\xe7\xbd\x91\xe7\xbb\x9c----------------------\n#\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\nx=tf.placeholder(tf.float32,shape=[None,w,h,c],name=\'x\')\ny_=tf.placeholder(tf.int32,shape=[None,],name=\'y_\')\n\ndef inference(input_tensor, train, regularizer):\n    with tf.variable_scope(\'layer1-conv1\'):\n        conv1_weights = tf.get_variable(""weight"",[5,5,3,32],initializer=tf.truncated_normal_initializer(stddev=0.1))\n        conv1_biases = tf.get_variable(""bias"", [32], initializer=tf.constant_initializer(0.0))\n        conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding=\'SAME\')\n        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n\n    with tf.name_scope(""layer2-pool1""):\n        pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding=""VALID"")\n\n    with tf.variable_scope(""layer3-conv2""):\n        conv2_weights = tf.get_variable(""weight"",[5,5,32,64],initializer=tf.truncated_normal_initializer(stddev=0.1))\n        conv2_biases = tf.get_variable(""bias"", [64], initializer=tf.constant_initializer(0.0))\n        conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding=\'SAME\')\n        relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n\n    with tf.name_scope(""layer4-pool2""):\n        pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'VALID\')\n\n    with tf.variable_scope(""layer5-conv3""):\n        conv3_weights = tf.get_variable(""weight"",[3,3,64,128],initializer=tf.truncated_normal_initializer(stddev=0.1))\n        conv3_biases = tf.get_variable(""bias"", [128], initializer=tf.constant_initializer(0.0))\n        conv3 = tf.nn.conv2d(pool2, conv3_weights, strides=[1, 1, 1, 1], padding=\'SAME\')\n        relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))\n\n    with tf.name_scope(""layer6-pool3""):\n        pool3 = tf.nn.max_pool(relu3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'VALID\')\n\n    with tf.variable_scope(""layer7-conv4""):\n        conv4_weights = tf.get_variable(""weight"",[3,3,128,128],initializer=tf.truncated_normal_initializer(stddev=0.1))\n        conv4_biases = tf.get_variable(""bias"", [128], initializer=tf.constant_initializer(0.0))\n        conv4 = tf.nn.conv2d(pool3, conv4_weights, strides=[1, 1, 1, 1], padding=\'SAME\')\n        relu4 = tf.nn.relu(tf.nn.bias_add(conv4, conv4_biases))\n\n    with tf.name_scope(""layer8-pool4""):\n        pool4 = tf.nn.max_pool(relu4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'VALID\')\n        nodes = 6*6*128\n        reshaped = tf.reshape(pool4,[-1,nodes])\n\n    with tf.variable_scope(\'layer9-fc1\'):\n        fc1_weights = tf.get_variable(""weight"", [nodes, 1024],\n                                      initializer=tf.truncated_normal_initializer(stddev=0.1))\n        if regularizer != None: tf.add_to_collection(\'losses\', regularizer(fc1_weights))\n        fc1_biases = tf.get_variable(""bias"", [1024], initializer=tf.constant_initializer(0.1))\n\n        fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases)\n        if train: fc1 = tf.nn.dropout(fc1, 0.5)\n\n    with tf.variable_scope(\'layer10-fc2\'):\n        fc2_weights = tf.get_variable(""weight"", [1024, 512],\n                                      initializer=tf.truncated_normal_initializer(stddev=0.1))\n        if regularizer != None: tf.add_to_collection(\'losses\', regularizer(fc2_weights))\n        fc2_biases = tf.get_variable(""bias"", [512], initializer=tf.constant_initializer(0.1))\n\n        fc2 = tf.nn.relu(tf.matmul(fc1, fc2_weights) + fc2_biases)\n        if train: fc2 = tf.nn.dropout(fc2, 0.5)\n\n    with tf.variable_scope(\'layer11-fc3\'):\n        fc3_weights = tf.get_variable(""weight"", [512, 5],\n                                      initializer=tf.truncated_normal_initializer(stddev=0.1))\n        if regularizer != None: tf.add_to_collection(\'losses\', regularizer(fc3_weights))\n        fc3_biases = tf.get_variable(""bias"", [5], initializer=tf.constant_initializer(0.1))\n        logit = tf.matmul(fc2, fc3_weights) + fc3_biases\n\n    return logit\n\n#---------------------------\xe7\xbd\x91\xe7\xbb\x9c\xe7\xbb\x93\xe6\x9d\x9f---------------------------\nregularizer = tf.contrib.layers.l2_regularizer(0.0001)\nlogits = inference(x,False,regularizer)\n\n#(\xe5\xb0\x8f\xe5\xa4\x84\xe7\x90\x86)\xe5\xb0\x86logits\xe4\xb9\x98\xe4\xbb\xa51\xe8\xb5\x8b\xe5\x80\xbc\xe7\xbb\x99logits_eval\xef\xbc\x8c\xe5\xae\x9a\xe4\xb9\x89name\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe5\x9c\xa8\xe5\x90\x8e\xe7\xbb\xad\xe8\xb0\x83\xe7\x94\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x97\xb6\xe9\x80\x9a\xe8\xbf\x87tensor\xe5\x90\x8d\xe5\xad\x97\xe8\xb0\x83\xe7\x94\xa8\xe8\xbe\x93\xe5\x87\xbatensor\nb = tf.constant(value=1,dtype=tf.float32)\nlogits_eval = tf.multiply(logits,b,name=\'logits_eval\') \n\nloss=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_)\ntrain_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\ncorrect_prediction = tf.equal(tf.cast(tf.argmax(logits,1),tf.int32), y_)    \nacc= tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n\n#\xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe4\xb8\xaa\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe6\x8c\x89\xe6\x89\xb9\xe6\xac\xa1\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\ndef minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):\n    assert len(inputs) == len(targets)\n    if shuffle:\n        indices = np.arange(len(inputs))\n        np.random.shuffle(indices)\n    for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):\n        if shuffle:\n            excerpt = indices[start_idx:start_idx + batch_size]\n        else:\n            excerpt = slice(start_idx, start_idx + batch_size)\n        yield inputs[excerpt], targets[excerpt]\n\n\n#\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\x8f\xaf\xe5\xb0\x86n_epoch\xe8\xae\xbe\xe7\xbd\xae\xe6\x9b\xb4\xe5\xa4\xa7\xe4\xb8\x80\xe4\xba\x9b\n\nn_epoch=1 \nbatch_size=64\nsaver=tf.train.Saver()\nsess=tf.Session()  \nsess.run(tf.global_variables_initializer())\nfor epoch in range(n_epoch):\n    start_time = time.time()\n\n    #training\n    train_loss, train_acc, n_batch = 0, 0, 0\n    for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True):\n        _,err,ac=sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a})\n        train_loss += err; train_acc += ac; n_batch += 1\n    print(""   train loss: %f"" % (np.sum(train_loss)/ n_batch))\n    print(""   train acc: %f"" % (np.sum(train_acc)/ n_batch))\n\n    #validation\n    val_loss, val_acc, n_batch = 0, 0, 0\n    for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False):\n        err, ac = sess.run([loss,acc], feed_dict={x: x_val_a, y_: y_val_a})\n        val_loss += err; val_acc += ac; n_batch += 1\n    print(""   validation loss: %f"" % (np.sum(val_loss)/ n_batch))\n    print(""   validation acc: %f"" % (np.sum(val_acc)/ n_batch))\nsaver.save(sess,model_path)\nsess.close()\n'"
Chapter3/sgd/gradient_descent.py,0,"b'# USAGE\n# python gradient_descent.py\n\n# import the necessary packages\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets.samples_generator import make_blobs\nimport numpy as np\nimport argparse\n\ndef sigmoid_activation(x):\n\t# compute and return the sigmoid activation value for a\n\t# given input value\n\treturn 1.0 / (1 + np.exp(-x))\n\n# construct the argument parse and parse the arguments\nap = argparse.ArgumentParser()\nap.add_argument(""-e"", ""--epochs"", type=float, default=100,\n\thelp=""# of epochs"")\nap.add_argument(""-a"", ""--alpha"", type=float, default=0.01,\n\thelp=""learning rate"")\nargs = vars(ap.parse_args())\n\n# generate a 2-class classification problem with 250 data points,\n# where each data point is a 2D feature vector\n(X, y) = make_blobs(n_samples=250, n_features=2, centers=2,\n\tcluster_std=1.05, random_state=20)\n\n# insert a column of 1\'s as the first entry in the feature\n# vector -- this is a little trick that allows us to treat\n# the bias as a trainable parameter *within* the weight matrix\n# rather than an entirely separate variable\nX = np.c_[np.ones((X.shape[0])), X]\n\n# initialize our weight matrix such it has the same number of\n# columns as our input features\nprint(""[INFO] starting training..."")\nW = np.random.uniform(size=(X.shape[1],))\n\n# initialize a list to store the loss value for each epoch\nlossHistory = []\n\n# loop over the desired number of epochs\nfor epoch in np.arange(0, args[""epochs""]):\n\t# take the dot product between our features `X` and the\n\t# weight matrix `W`, then pass this value through the\n\t# sigmoid activation function, thereby giving us our\n\t# predictions on the dataset\n\tpreds = sigmoid_activation(X.dot(W))\n\n\t# now that we have our predictions, we need to determine\n\t# our `error`, which is the difference between our predictions\n\t# and the true values\n\terror = preds - y\n\n\t# given our `error`, we can compute the total loss value as\n\t# the sum of squared loss -- ideally, our loss should\n\t# decrease as we continue training\n\tloss = np.sum(error ** 2)\n\tlossHistory.append(loss)\n\tprint(""[INFO] epoch #{}, loss={:.7f}"".format(epoch + 1, loss))\n\n\t# the gradient update is therefore the dot product between\n\t# the transpose of `X` and our error, scaled by the total\n\t# number of data points in `X`\n\tgradient = X.T.dot(error) / X.shape[0]\n\n\t# in the update stage, all we need to do is nudge our weight\n\t# matrix in the opposite direction of the gradient (hence the\n\t# term ""gradient descent"" by taking a small step towards a\n\t# set of ""more optimal"" parameters\n\tW += -args[""alpha""] * gradient\n\n# to demonstrate how to use our weight matrix as a classifier,\n# let\'s look over our a sample of training examples\nfor i in np.random.choice(250, 10):\n\t# compute the prediction by taking the dot product of the\n\t# current feature vector with the weight matrix W, then\n\t# passing it through the sigmoid activation function\n\tactivation = sigmoid_activation(X[i].dot(W))\n\n\t# the sigmoid function is defined over the range y=[0, 1],\n\t# so we can use 0.5 as our threshold -- if `activation` is\n\t# below 0.5, it\'s class `0`; otherwise it\'s class `1`\n\tlabel = 0 if activation < 0.5 else 1\n\n\t# show our output classification\n\tprint(""activation={:.4f}; predicted_label={}, true_label={}"".format(\n\t\tactivation, label, y[i]))\n\n# compute the line of best fit by setting the sigmoid function\n# to 0 and solving for X2 in terms of X1\nY = (-W[0] - (W[1] * X)) / W[2]\n\n# plot the original data along with our line of best fit\nplt.figure()\nplt.scatter(X[:, 1], X[:, 2], marker=""o"", c=y)\nplt.plot(X, Y, ""r-"")\n\n# construct a figure that plots the loss over time\nfig = plt.figure()\nplt.plot(np.arange(0, args[""epochs""]), lossHistory)\nfig.suptitle(""Training Loss"")\nplt.xlabel(""Epoch #"")\nplt.ylabel(""Loss"")\nplt.show()\n'"
Chapter3/sgd/sgd.py,0,"b'# USAGE\n# python gradient_descent.py\n\n# import the necessary packages\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets.samples_generator import make_blobs\nimport numpy as np\nimport argparse\n\ndef sigmoid_activation(x):\n\treturn 1.0 / (1 + np.exp(-x))\n\ndef next_training_batch(X, y, batchSize):\n    for i in np.arange(0, X.shape[0], batchSize):\n        yield (X[i:i + batchSize], y[i:i + batchSize])\n\nap = argparse.ArgumentParser()\nap.add_argument(""-e"", ""--epochs"", type=float, default=100,\n\thelp=""# of epochs"")\nap.add_argument(""-a"", ""--alpha"", type=float, default=0.01,\n\thelp=""learning rate"")\nap.add_argument(""-b"", ""--batch-size"", type=int, default=32,\n    help=""size of SGD mini-batches"")\nargs = vars(ap.parse_args())\n\n(X, y) = make_blobs(n_samples=250, n_features=2, centers=2,\n    cluster_std=1.05, random_state=20)\nX = np.c_[np.ones((X.shape[0])), X]\n\nprint(""[INFO] starting training..."")\nW = np.random.uniform(size=(X.shape[1],))\n\nlossHistory = []\n\n\nfor epoch in np.arange(0, args[""epochs""]):\n    epochLoss = []\n \n    for (batchX, batchY) in next_training_batch(X, y, args[""batch_size""]):\n\n        preds = sigmoid_activation(batchX.dot(W))\n \n\n        error = preds - batchY\n \n\n        loss = np.sum(error ** 2)\n        epochLoss.append(loss)\n \n\n        gradient = batchX.T.dot(error) / batchX.shape[0]\n \n\n        W += -args[""alpha""] * gradient\n \n\n    lossHistory.append(np.average(epochLoss))\n    print(""[INFO] epoch #{}, loss={:.7f}"".format(epoch + 1, loss))\n\nfor i in np.random.choice(250, 10):\n\tactivation = sigmoid_activation(X[i].dot(W))\n\n\tlabel = 0 if activation < 0.5 else 1\n\n\t# show our output classification\n\tprint(""activation={:.4f}; predicted_label={}, true_label={}"".format(\n\t\tactivation, label, y[i]))\n\nY = (-W[0] - (W[1] * X)) / W[2]\nplt.figure()\nplt.scatter(X[:, 1], X[:, 2], marker=""o"", c=y)\nplt.plot(X, Y, ""r-"")\n\nfig = plt.figure()\nplt.plot(np.arange(0, args[""epochs""]), lossHistory)\nfig.suptitle(""Training Loss"")\nplt.xlabel(""Epoch #"")\nplt.ylabel(""Loss"")\nplt.show()\n'"
Chapter5/ae/autoencoder_train.py,0,"b'#-*- coding:utf-8 -*-\r\nimport numpy as np\r\nfrom base import nn,autoencoder\r\n# \xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef sigmod(x):\r\n    return 1.0 / (1.0 + np.exp(-x))\r\n\r\n#\xe5\x89\x8d\xe9\xa6\x88\xe5\x87\xbd\xe6\x95\xb0\r\ndef nnff(nn,x,y):\r\n    layers = nn.layers\r\n    numbers = x.shape[0]\r\n    # \xe8\xb5\x8b\xe4\xba\x88\xe5\x88\x9d\xe5\x80\xbc\r\n    nn.values[0] = x\r\n    for i in range(1,layers):\r\n        nn.values[i] = sigmod(np.dot(nn.values[i-1],nn.W[i-1])+nn.B[i-1])\r\n    # \xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\x8e\xe5\xae\x9e\xe9\x99\x85\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    nn.error = y - nn.values[layers-1]\r\n    nn.loss = 1.0/2.0*(nn.error**2).sum()/numbers\r\n    return nn     \r\n#BP\xe5\x87\xbd\xe6\x95\xb0\r\ndef nnbp(nn):\r\n    layers = nn.layers;\r\n    #\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96delta\r\n    \r\n    deltas = list();\r\n    for i in range(layers):\r\n        deltas.append(0)\r\n    \r\n    #\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84delta\xe4\xb8\xba\r\n    deltas[layers-1] = -nn.error*nn.values[layers-1]*(1-nn.values[layers-1])\r\n    #\xe5\x85\xb6\xe4\xbb\x96\xe5\xb1\x82\xe7\x9a\x84delta\xe4\xb8\xba\r\n    for j in range(1,layers-1)[::-1]:#\xe5\x80\x92\xe8\xbf\x87\xe6\x9d\xa5\r\n        deltas[j] = np.dot(deltas[j+1],nn.W[j].T)*nn.values[j]*(1-nn.values[j])\r\n    #\xe6\x9b\xb4\xe6\x96\xb0W\xe5\x80\xbc\r\n    for k in range(layers-1):\r\n        nn.W[k] -= nn.u*np.dot(nn.values[k].T,deltas[k+1])/(deltas[k+1].shape[0])\r\n        nn.B[k] -= nn.u*deltas[k+1]/(deltas[k+1].shape[0])\r\n    return nn\r\n#\xe5\xaf\xb9\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\r\ndef nntrain(nn,x,y,iterations):\r\n    for i in range(iterations):\r\n        nnff(nn,x,y)\r\n        nnbp(nn)\r\n    return nn\r\n#\xe5\xbb\xba\xe7\xab\x8bautoencoder\xe6\xa1\x86\xe6\x9e\xb6\r\ndef aebuilder(nodes):\r\n    layers = len(nodes)\r\n    ae = autoencoder()\r\n    for i in range(layers-1):\r\n        ae.add_one(nn([nodes[i],nodes[i+1],nodes[i]]))\r\n    \r\n    return ae\r\n        \r\n#\xe8\xae\xad\xe7\xbb\x83autoencoder\r\ndef aetrain(ae,x,interations):\r\n    elayers = len(ae.encoders)\r\n    for i in range(elayers):\r\n        #\xe5\x8d\x95\xe5\xb1\x82\xe8\xae\xad\xe7\xbb\x83\r\n        ae.encoders[i] = nntrain(ae.encoders[i],x,x,interations)\r\n        #\xe5\x8d\x95\xe5\xb1\x82\xe8\xae\xad\xe7\xbb\x83\xe5\x90\x8e\xef\xbc\x8c\xe8\x8e\xb7\xe5\x8f\x96\xe8\xaf\xa5\xe5\xb1\x82\xe4\xb8\xad\xe9\x97\xb4\xe5\xb1\x82\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe4\xbd\x9c\xe4\xb8\xba\xe4\xb8\x8b\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        nntemp = nnff(ae.encoders[i],x,x)\r\n        x = nntemp.values[1]   \r\n    return ae     \r\n        \r\n#def predict(nn,x):\r\n    \r\n        \r\n'"
Chapter5/ae/base.py,0,"b""#-*- coding:utf-8 -*-\r\n'''\r\nCreated on 2016\xef\xbf\xbd\xef\xbf\xbd5\xef\xbf\xbd\xef\xbf\xbd16\xef\xbf\xbd\xef\xbf\xbd\r\n\r\n@author: Administrator\r\n'''\r\nimport numpy as np\r\n#import pandas as pd\r\n\r\n#\xe5\x88\x9b\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\xb1\xbb\r\n# nodes\xe4\xb8\xba1*n\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe8\xa1\xa8\xe7\xa4\xba\xe6\xaf\x8f\xe4\xb8\x80\xe5\xb1\x82\xe6\x9c\x89\xe5\xa4\x9a\xe5\xb0\x91\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\r\nclass nn():\r\n    def __init__(self,nodes):\r\n        self.layers = len(nodes)\r\n        self.nodes = nodes;\r\n        # \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\r\n        self.u = 1.0;\r\n        # \xe6\x9d\x83\xe5\x80\xbc\r\n        self.W = list();\r\n        # \xe5\x81\x8f\xe5\xb7\xae\xe5\x80\xbc\r\n        self.B = list()\r\n        # \xe5\xb1\x82\xe5\x80\xbc\r\n        self.values = list();\r\n        # \xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error = 0;\r\n        # \xe6\x8d\x9f\xe5\xa4\xb1\r\n        self.loss = 0;\r\n\r\n        for i in range(self.layers-1):\r\n            # \xe6\x9d\x83\xe5\x80\xbc\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xef\xbc\x8c\xe6\x9d\x83\xe9\x87\x8d\xe8\x8c\x83\xe5\x9b\xb4-0.5~0.5\r\n            self.W.append(np.random.random((self.nodes[i],self.nodes[i+1])) - 0.5)   \r\n            # B\xe5\x80\xbc\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n            self.B.append(0)\r\n            # P\xe5\x80\xbc\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n#            self.P.append(0)\r\n        \r\n        for j in range(self.layers):\r\n            # values\xe5\x80\xbc\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n            self.values.append(0)\r\n            \r\n            \r\n#\xe5\x88\x9b\xe5\xbb\xbaautoencoder\xe7\xb1\xbb\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe6\x88\x90\xe6\x98\xaf\xe5\xa4\x9a\xe4\xb8\xaa\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe5\xa0\x86\xe5\x8f\xa0\xe8\x80\x8c\xe6\x9d\xa5\r\nclass autoencoder():\r\n    def __init__(self):\r\n        self.encoders = list()\r\n    def add_one(self,nn):\r\n        self.encoders.append(nn)\r\n    """
Chapter5/ae/test.py,0,"b'#-*- coding:utf-8 -*-\r\nimport autoencoder_train\r\nfrom base import autoencoder,nn\r\nimport numpy as np\r\n\r\nx = np.array([[0,0,1,0,0],\r\n            [0,1,1,0,1],\r\n            [1,0,0,0,1],\r\n            [1,1,1,0,0],\r\n            [0,1,0,1,0],\r\n            [0,1,1,1,1],\r\n            [0,1,0,0,1],\r\n            [0,1,1,0,1],\r\n            [1,1,1,1,0],\r\n            [0,0,0,1,0]])\r\ny = np.array([[0],\r\n            [1],\r\n            [0],\r\n            [1],\r\n            [0],\r\n            [1],\r\n            [0],\r\n            [1],\r\n            [1],\r\n            [0]])\r\n#################################\r\n# step1 \xe5\xbb\xba\xe7\xab\x8bautoencoder\r\n#\xe5\xbc\x84\xe4\xb8\xa4\xe5\xb1\x82autoencoder\r\nnodes=[5,3,2]\r\n#\xe5\xbb\xba\xe7\xab\x8bauto\xe6\xa1\x86\xe6\x9e\xb6\r\nae = autoencoder_train.aebuilder(nodes)\r\n#\xe8\xae\xbe\xe7\xbd\xae\xe9\x83\xa8\xe5\x88\x86\xe5\x8f\x82\xe6\x95\xb0\r\n#\xe8\xae\xad\xe7\xbb\x83\r\nae = autoencoder_train.aetrain(ae, x, 6000)\r\n##############################\r\n# step2 \xe5\xbe\xae\xe8\xb0\x83\r\n#\xe5\xbb\xba\xe7\xab\x8b\xe5\xae\x8c\xe5\x85\xa8\xe4\xbd\x93\xe7\x9a\x84autoencoder\r\nnodescomplete = np.array([5,3,2,1])\r\naecomplete = nn(nodescomplete)\r\nfor i in range(len(nodescomplete)-2):\r\n    aecomplete.W[i] = ae.encoders[i].W[0]\r\n    \r\naecomplete = autoencoder_train.nntrain(aecomplete, x, y, 6000)\r\nprint aecomplete.values[3]\r\n'"
Chapter7/ssd/ssd_300_vgg.py,19,"b'from collections import namedtuple\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom ssd_layers import conv2d, max_pool2d, l2norm, dropout, \\\n    pad2d, ssd_multibox_layer\nfrom ssd_anchors import ssd_anchors_all_layers\n\n# SSD parameters\nSSDParams = namedtuple(\'SSDParameters\', [\'img_shape\',  # the input image size: 300x300\n                                         \'num_classes\',  # number of classes: 20+1\n                                         \'no_annotation_label\',\n                                         \'feat_layers\', # list of names of layer for detection\n                                         \'feat_shapes\', # list of feature map sizes of layer for detection\n                                         \'anchor_size_bounds\', # the down and upper bounds of anchor sizes\n                                         \'anchor_sizes\',   # list of anchor sizes of layer for detection\n                                         \'anchor_ratios\',  # list of rations used in layer for detection\n                                         \'anchor_steps\',   # list of cell size (pixel size) of layer for detection\n                                         \'anchor_offset\',  # the center point offset\n                                         \'normalizations\', # list of normalizations of layer for detection\n                                         \'prior_scaling\'   #\n                                         ])\nclass SSD(object):\n    """"""SSD net 300""""""\n    def __init__(self, is_training=True):\n        self.is_training = is_training\n        self.threshold = 0.5  # class score threshold\n        self.ssd_params = SSDParams(img_shape=(300, 300),\n                                    num_classes=21,\n                                    no_annotation_label=21,\n                                    feat_layers=[""block4"", ""block7"", ""block8"", ""block9"", ""block10"", ""block11""],\n                                    feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)],\n                                    anchor_size_bounds=[0.15, 0.90],  # diff from the original paper\n                                    anchor_sizes=[(21., 45.),\n                                                  (45., 99.),\n                                                  (99., 153.),\n                                                  (153., 207.),\n                                                  (207., 261.),\n                                                  (261., 315.)],\n                                    anchor_ratios=[[2, .5],\n                                                   [2, .5, 3, 1. / 3],\n                                                   [2, .5, 3, 1. / 3],\n                                                   [2, .5, 3, 1. / 3],\n                                                   [2, .5],\n                                                   [2, .5]],\n                                    anchor_steps=[8, 16, 32, 64, 100, 300],\n                                    anchor_offset=0.5,\n                                    normalizations=[20, -1, -1, -1, -1, -1],\n                                    prior_scaling=[0.1, 0.1, 0.2, 0.2]\n                                    )\n\n        predictions, logits, locations = self._built_net()\n        #self._update_feat_shapes_from_net()\n        classes, scores, bboxes = self._bboxes_select(predictions, locations)\n        self._classes = classes\n        self._scores = scores\n        self._bboxes = bboxes\n\n    def _built_net(self):\n        """"""Construct the SSD net""""""\n        self.end_points = {}  # record the detection layers output\n        self._images = tf.placeholder(tf.float32, shape=[None, self.ssd_params.img_shape[0],\n                                                        self.ssd_params.img_shape[1], 3])\n        with tf.variable_scope(""ssd_300_vgg""):\n            # original vgg layers\n            # block 1\n            net = conv2d(self._images, 64, 3, scope=""conv1_1"")\n            net = conv2d(net, 64, 3, scope=""conv1_2"")\n            self.end_points[""block1""] = net\n            net = max_pool2d(net, 2, scope=""pool1"")\n            # block 2\n            net = conv2d(net, 128, 3, scope=""conv2_1"")\n            net = conv2d(net, 128, 3, scope=""conv2_2"")\n            self.end_points[""block2""] = net\n            net = max_pool2d(net, 2, scope=""pool2"")\n            # block 3\n            net = conv2d(net, 256, 3, scope=""conv3_1"")\n            net = conv2d(net, 256, 3, scope=""conv3_2"")\n            net = conv2d(net, 256, 3, scope=""conv3_3"")\n            self.end_points[""block3""] = net\n            net = max_pool2d(net, 2, scope=""pool3"")\n            # block 4\n            net = conv2d(net, 512, 3, scope=""conv4_1"")\n            net = conv2d(net, 512, 3, scope=""conv4_2"")\n            net = conv2d(net, 512, 3, scope=""conv4_3"")\n            self.end_points[""block4""] = net\n            net = max_pool2d(net, 2, scope=""pool4"")\n            # block 5\n            net = conv2d(net, 512, 3, scope=""conv5_1"")\n            net = conv2d(net, 512, 3, scope=""conv5_2"")\n            net = conv2d(net, 512, 3, scope=""conv5_3"")\n            self.end_points[""block5""] = net\n            print(net)\n            net = max_pool2d(net, 3, stride=1, scope=""pool5"")\n            print(net)\n\n            # additional SSD layers\n            # block 6: use dilate conv\n            net = conv2d(net, 1024, 3, dilation_rate=6, scope=""conv6"")\n            self.end_points[""block6""] = net\n            #net = dropout(net, is_training=self.is_training)\n            # block 7\n            net = conv2d(net, 1024, 1, scope=""conv7"")\n            self.end_points[""block7""] = net\n            # block 8\n            net = conv2d(net, 256, 1, scope=""conv8_1x1"")\n            net = conv2d(pad2d(net, 1), 512, 3, stride=2, scope=""conv8_3x3"",\n                         padding=""valid"")\n            self.end_points[""block8""] = net\n            # block 9\n            net = conv2d(net, 128, 1, scope=""conv9_1x1"")\n            net = conv2d(pad2d(net, 1), 256, 3, stride=2, scope=""conv9_3x3"",\n                         padding=""valid"")\n            self.end_points[""block9""] = net\n            # block 10\n            net = conv2d(net, 128, 1, scope=""conv10_1x1"")\n            net = conv2d(net, 256, 3, scope=""conv10_3x3"", padding=""valid"")\n            self.end_points[""block10""] = net\n            # block 11\n            net = conv2d(net, 128, 1, scope=""conv11_1x1"")\n            net = conv2d(net, 256, 3, scope=""conv11_3x3"", padding=""valid"")\n            self.end_points[""block11""] = net\n\n            # class and location predictions\n            predictions = []\n            logits = []\n            locations = []\n            for i, layer in enumerate(self.ssd_params.feat_layers):\n                cls, loc = ssd_multibox_layer(self.end_points[layer], self.ssd_params.num_classes,\n                                              self.ssd_params.anchor_sizes[i],\n                                              self.ssd_params.anchor_ratios[i],\n                                              self.ssd_params.normalizations[i], scope=layer+""_box"")\n                predictions.append(tf.nn.softmax(cls))\n                logits.append(cls)\n                locations.append(loc)\n            return predictions, logits, locations\n\n    def _update_feat_shapes_from_net(self, predictions):\n        """""" Obtain the feature shapes from the prediction layers""""""\n        new_feat_shapes = []\n        for l in predictions:\n            new_feat_shapes.append(l.get_shape().as_list()[1:])\n        self.ssd_params._replace(feat_shapes=new_feat_shapes)\n\n    def anchors(self):\n        """"""Get sSD anchors""""""\n        return ssd_anchors_all_layers(self.ssd_params.img_shape,\n                                      self.ssd_params.feat_shapes,\n                                      self.ssd_params.anchor_sizes,\n                                      self.ssd_params.anchor_ratios,\n                                      self.ssd_params.anchor_steps,\n                                      self.ssd_params.anchor_offset,\n                                      np.float32)\n\n    def _bboxes_decode_layer(self, feat_locations, anchor_bboxes, prior_scaling):\n        """"""\n        Decode the feat location of one layer\n        params:\n         feat_locations: 5D Tensor, [batch_size, size, size, n_anchors, 4]\n         anchor_bboxes: list of Tensors(y, x, w, h)\n                        shape: [size,size,1], [size, size,1], [n_anchors], [n_anchors]\n         prior_scaling: list of 4 floats\n        """"""\n        yref, xref, href, wref = anchor_bboxes\n        print(yref)\n        # Compute center, height and width\n        cx = feat_locations[:, :, :, :, 0] * wref * prior_scaling[0] + xref\n        cy = feat_locations[:, :, :, :, 1] * href * prior_scaling[1] + yref\n        w = wref * tf.exp(feat_locations[:, :, :, :, 2] * prior_scaling[2])\n        h = href * tf.exp(feat_locations[:, :, :, :, 3] * prior_scaling[3])\n        # compute boxes coordinates (ymin, xmin, ymax,,xmax)\n        bboxes = tf.stack([cy - h / 2., cx - w / 2.,\n                           cy + h / 2., cx + w / 2.], axis=-1)\n        # shape [batch_size, size, size, n_anchors, 4]\n        return bboxes\n\n    def _bboxes_select_layer(self, feat_predictions, feat_locations, anchor_bboxes,\n                             prior_scaling):\n        """"""Select boxes from the feat layer, only for bacth_size=1""""""\n        n_bboxes = np.product(feat_predictions.get_shape().as_list()[1:-1])\n        # decode the location\n        bboxes = self._bboxes_decode_layer(feat_locations, anchor_bboxes, prior_scaling)\n        bboxes = tf.reshape(bboxes, [n_bboxes, 4])\n        predictions = tf.reshape(feat_predictions, [n_bboxes, self.ssd_params.num_classes])\n        # remove the background predictions\n        sub_predictions = predictions[:, 1:]\n        # choose the max score class\n        classes = tf.argmax(sub_predictions, axis=1) + 1  # class labels\n        scores = tf.reduce_max(sub_predictions, axis=1)   # max_class scores\n        # Boxes selection: use threshold\n        filter_mask = scores > self.threshold\n        classes = tf.boolean_mask(classes, filter_mask)\n        scores = tf.boolean_mask(scores, filter_mask)\n        bboxes = tf.boolean_mask(bboxes, filter_mask)\n        return classes, scores, bboxes\n\n    def _bboxes_select(self, predictions, locations):\n        """"""Select all bboxes predictions, only for bacth_size=1""""""\n        anchor_bboxes_list = self.anchors()\n        classes_list = []\n        scores_list = []\n        bboxes_list = []\n        # select bboxes for each feat layer\n        for n in range(len(predictions)):\n            anchor_bboxes = list(map(tf.convert_to_tensor, anchor_bboxes_list[n]))\n            classes, scores, bboxes = self._bboxes_select_layer(predictions[n],\n                            locations[n], anchor_bboxes, self.ssd_params.prior_scaling)\n            classes_list.append(classes)\n            scores_list.append(scores)\n            bboxes_list.append(bboxes)\n        # combine all feat layers\n        classes = tf.concat(classes_list, axis=0)\n        scores = tf.concat(scores_list, axis=0)\n        bboxes = tf.concat(bboxes_list, axis=0)\n        return classes, scores, bboxes\n\n    def images(self):\n        return self._images\n\n    def detections(self):\n        return self._classes, self._scores, self._bboxes\n\n\nif __name__ == ""__main__"":\n    ssd = SSD()\n    sess = tf.Session()\n    saver_ = tf.train.Saver()\n    saver_.restore(sess, ""../SSD-Tensorflow-master/ssd_checkpoints/ssd_vgg_300_weights.ckpt"")\n'"
Chapter7/ssd/ssd_anchors.py,19,"b'from collections import namedtuple\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom ssd_layers import conv2d, max_pool2d, l2norm, dropout, \\\n    pad2d, ssd_multibox_layer\nfrom ssd_anchors import ssd_anchors_all_layers\n\n# SSD parameters\nSSDParams = namedtuple(\'SSDParameters\', [\'img_shape\',  # the input image size: 300x300\n                                         \'num_classes\',  # number of classes: 20+1\n                                         \'no_annotation_label\',\n                                         \'feat_layers\', # list of names of layer for detection\n                                         \'feat_shapes\', # list of feature map sizes of layer for detection\n                                         \'anchor_size_bounds\', # the down and upper bounds of anchor sizes\n                                         \'anchor_sizes\',   # list of anchor sizes of layer for detection\n                                         \'anchor_ratios\',  # list of rations used in layer for detection\n                                         \'anchor_steps\',   # list of cell size (pixel size) of layer for detection\n                                         \'anchor_offset\',  # the center point offset\n                                         \'normalizations\', # list of normalizations of layer for detection\n                                         \'prior_scaling\'   #\n                                         ])\nclass SSD(object):\n    """"""SSD net 300""""""\n    def __init__(self, is_training=True):\n        self.is_training = is_training\n        self.threshold = 0.5  # class score threshold\n        self.ssd_params = SSDParams(img_shape=(300, 300),\n                                    num_classes=21,\n                                    no_annotation_label=21,\n                                    feat_layers=[""block4"", ""block7"", ""block8"", ""block9"", ""block10"", ""block11""],\n                                    feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)],\n                                    anchor_size_bounds=[0.15, 0.90],  # diff from the original paper\n                                    anchor_sizes=[(21., 45.),\n                                                  (45., 99.),\n                                                  (99., 153.),\n                                                  (153., 207.),\n                                                  (207., 261.),\n                                                  (261., 315.)],\n                                    anchor_ratios=[[2, .5],\n                                                   [2, .5, 3, 1. / 3],\n                                                   [2, .5, 3, 1. / 3],\n                                                   [2, .5, 3, 1. / 3],\n                                                   [2, .5],\n                                                   [2, .5]],\n                                    anchor_steps=[8, 16, 32, 64, 100, 300],\n                                    anchor_offset=0.5,\n                                    normalizations=[20, -1, -1, -1, -1, -1],\n                                    prior_scaling=[0.1, 0.1, 0.2, 0.2]\n                                    )\n\n        predictions, logits, locations = self._built_net()\n        #self._update_feat_shapes_from_net()\n        classes, scores, bboxes = self._bboxes_select(predictions, locations)\n        self._classes = classes\n        self._scores = scores\n        self._bboxes = bboxes\n\n    def _built_net(self):\n        """"""Construct the SSD net""""""\n        self.end_points = {}  # record the detection layers output\n        self._images = tf.placeholder(tf.float32, shape=[None, self.ssd_params.img_shape[0],\n                                                        self.ssd_params.img_shape[1], 3])\n        with tf.variable_scope(""ssd_300_vgg""):\n            # original vgg layers\n            # block 1\n            net = conv2d(self._images, 64, 3, scope=""conv1_1"")\n            net = conv2d(net, 64, 3, scope=""conv1_2"")\n            self.end_points[""block1""] = net\n            net = max_pool2d(net, 2, scope=""pool1"")\n            # block 2\n            net = conv2d(net, 128, 3, scope=""conv2_1"")\n            net = conv2d(net, 128, 3, scope=""conv2_2"")\n            self.end_points[""block2""] = net\n            net = max_pool2d(net, 2, scope=""pool2"")\n            # block 3\n            net = conv2d(net, 256, 3, scope=""conv3_1"")\n            net = conv2d(net, 256, 3, scope=""conv3_2"")\n            net = conv2d(net, 256, 3, scope=""conv3_3"")\n            self.end_points[""block3""] = net\n            net = max_pool2d(net, 2, scope=""pool3"")\n            # block 4\n            net = conv2d(net, 512, 3, scope=""conv4_1"")\n            net = conv2d(net, 512, 3, scope=""conv4_2"")\n            net = conv2d(net, 512, 3, scope=""conv4_3"")\n            self.end_points[""block4""] = net\n            net = max_pool2d(net, 2, scope=""pool4"")\n            # block 5\n            net = conv2d(net, 512, 3, scope=""conv5_1"")\n            net = conv2d(net, 512, 3, scope=""conv5_2"")\n            net = conv2d(net, 512, 3, scope=""conv5_3"")\n            self.end_points[""block5""] = net\n            print(net)\n            net = max_pool2d(net, 3, stride=1, scope=""pool5"")\n            print(net)\n\n            # additional SSD layers\n            # block 6: use dilate conv\n            net = conv2d(net, 1024, 3, dilation_rate=6, scope=""conv6"")\n            self.end_points[""block6""] = net\n            #net = dropout(net, is_training=self.is_training)\n            # block 7\n            net = conv2d(net, 1024, 1, scope=""conv7"")\n            self.end_points[""block7""] = net\n            # block 8\n            net = conv2d(net, 256, 1, scope=""conv8_1x1"")\n            net = conv2d(pad2d(net, 1), 512, 3, stride=2, scope=""conv8_3x3"",\n                         padding=""valid"")\n            self.end_points[""block8""] = net\n            # block 9\n            net = conv2d(net, 128, 1, scope=""conv9_1x1"")\n            net = conv2d(pad2d(net, 1), 256, 3, stride=2, scope=""conv9_3x3"",\n                         padding=""valid"")\n            self.end_points[""block9""] = net\n            # block 10\n            net = conv2d(net, 128, 1, scope=""conv10_1x1"")\n            net = conv2d(net, 256, 3, scope=""conv10_3x3"", padding=""valid"")\n            self.end_points[""block10""] = net\n            # block 11\n            net = conv2d(net, 128, 1, scope=""conv11_1x1"")\n            net = conv2d(net, 256, 3, scope=""conv11_3x3"", padding=""valid"")\n            self.end_points[""block11""] = net\n\n            # class and location predictions\n            predictions = []\n            logits = []\n            locations = []\n            for i, layer in enumerate(self.ssd_params.feat_layers):\n                cls, loc = ssd_multibox_layer(self.end_points[layer], self.ssd_params.num_classes,\n                                              self.ssd_params.anchor_sizes[i],\n                                              self.ssd_params.anchor_ratios[i],\n                                              self.ssd_params.normalizations[i], scope=layer+""_box"")\n                predictions.append(tf.nn.softmax(cls))\n                logits.append(cls)\n                locations.append(loc)\n            return predictions, logits, locations\n\n    def _update_feat_shapes_from_net(self, predictions):\n        """""" Obtain the feature shapes from the prediction layers""""""\n        new_feat_shapes = []\n        for l in predictions:\n            new_feat_shapes.append(l.get_shape().as_list()[1:])\n        self.ssd_params._replace(feat_shapes=new_feat_shapes)\n\n    def anchors(self):\n        """"""Get sSD anchors""""""\n        return ssd_anchors_all_layers(self.ssd_params.img_shape,\n                                      self.ssd_params.feat_shapes,\n                                      self.ssd_params.anchor_sizes,\n                                      self.ssd_params.anchor_ratios,\n                                      self.ssd_params.anchor_steps,\n                                      self.ssd_params.anchor_offset,\n                                      np.float32)\n\n    def _bboxes_decode_layer(self, feat_locations, anchor_bboxes, prior_scaling):\n        """"""\n        Decode the feat location of one layer\n        params:\n         feat_locations: 5D Tensor, [batch_size, size, size, n_anchors, 4]\n         anchor_bboxes: list of Tensors(y, x, w, h)\n                        shape: [size,size,1], [size, size,1], [n_anchors], [n_anchors]\n         prior_scaling: list of 4 floats\n        """"""\n        yref, xref, href, wref = anchor_bboxes\n        print(yref)\n        # Compute center, height and width\n        cx = feat_locations[:, :, :, :, 0] * wref * prior_scaling[0] + xref\n        cy = feat_locations[:, :, :, :, 1] * href * prior_scaling[1] + yref\n        w = wref * tf.exp(feat_locations[:, :, :, :, 2] * prior_scaling[2])\n        h = href * tf.exp(feat_locations[:, :, :, :, 3] * prior_scaling[3])\n        # compute boxes coordinates (ymin, xmin, ymax,,xmax)\n        bboxes = tf.stack([cy - h / 2., cx - w / 2.,\n                           cssd_anchors_all_layersy + h / 2., cx + w / 2.], axis=-1)\n        # shape [batch_size, size, size, n_anchors, 4]\n        return bboxes\n\n    def _bboxes_select_layer(self, feat_predictions, feat_locations, anchor_bboxes,\n                             prior_scaling):\n        """"""Select boxes from the feat layer, only for bacth_size=1""""""\n        n_bboxes = np.product(feat_predictions.get_shape().as_list()[1:-1])\n        # decode the location\n        bboxes = self._bboxes_decode_layer(feat_locations, anchor_bboxes, prior_scaling)\n        bboxes = tf.reshape(bboxes, [n_bboxes, 4])\n        predictions = tf.reshape(feat_predictions, [n_bboxes, self.ssd_params.num_classes])\n        # remove the background predictions\n        sub_predictions = predictions[:, 1:]\n        # choose the max score class\n        classes = tf.argmax(sub_predictions, axis=1) + 1  # class labels\n        scores = tf.reduce_max(sub_predictions, axis=1)   # max_class scores\n        # Boxes selection: use threshold\n        filter_mask = scores > self.threshold\n        classes = tf.boolean_mask(classes, filter_mask)\n        scores = tf.boolean_mask(scores, filter_mask)\n        bboxes = tf.boolean_mask(bboxes, filter_mask)\n        return classes, scores, bboxes\n\n    def _bboxes_select(self, predictions, locations):\n        """"""Select all bboxes predictions, only for bacth_size=1""""""\n        anchor_bboxes_list = self.anchors()\n        classes_list = []\n        scores_list = []\n        bboxes_list = []\n        # select bboxes for each feat layer\n        for n in range(len(predictions)):\n            anchor_bboxes = list(map(tf.convert_to_tensor, anchor_bboxes_list[n]))\n            classes, scores, bboxes = self._bboxes_select_layer(predictions[n],\n                            locations[n], anchor_bboxes, self.ssd_params.prior_scaling)\n            classes_list.append(classes)\n            scores_list.append(scores)\n            bboxes_list.append(bboxes)\n        # combine all feat layers\n        classes = tf.concat(classes_list, axis=0)\n        scores = tf.concat(scores_list, axis=0)\n        bboxes = tf.concat(bboxes_list, axis=0)\n        return classes, scores, bboxes\n\n    def images(self):\n        return self._images\n\n    def detections(self):\n        return self._classes, self._scores, self._bboxes\n\n\nif __name__ == ""__main__"":\n    ssd = SSD()\n    sess = tf.Session()\n    saver_ = tf.train.Saver()\n    saver_.restore(sess, ""../SSD-Tensorflow-master/ssd_checkpoints/ssd_vgg_300_weights.ckpt"")\n'"
Chapter7/ssd/ssd_demo.py,3,"b""import cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.image as mpimg\n\nfrom ssd_300_vgg import SSD\nfrom utils import preprocess_image, process_bboxes\nfrom visualization import plt_bboxes\n\n\nssd_net = SSD()\nclasses, scores, bboxes = ssd_net.detections()\nimages = ssd_net.images()\n\nsess = tf.Session()\n# Restore SSD model.\nckpt_filename = './ssd_checkpoints/ssd_vgg_300_weights.ckpt'\nsess.run(tf.global_variables_initializer())\nsaver = tf.train.Saver()\nsaver.restore(sess, ckpt_filename)\n\nimg = cv2.imread('./demo/dog.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_prepocessed = preprocess_image(img)\nrclasses, rscores, rbboxes = sess.run([classes, scores, bboxes],\n                                      feed_dict={images: img_prepocessed})\nrclasses, rscores, rbboxes = process_bboxes(rclasses, rscores, rbboxes)\n\nplt_bboxes(img, rclasses, rscores, rbboxes)\n"""
Chapter7/ssd/ssd_layers.py,12,"b'import tensorflow as tf\n\n# Conv2d: for stride = 1\ndef conv2d(x, filters, kernel_size, stride=1, padding=""same"",\n           dilation_rate=1, activation=tf.nn.relu, scope=""conv2d""):\n    kernel_sizes = [kernel_size] * 2\n    strides = [stride] * 2\n    dilation_rate = [dilation_rate] * 2\n    return tf.layers.conv2d(x, filters, kernel_sizes, strides=strides,\n                            dilation_rate=dilation_rate, padding=padding,\n                            name=scope, activation=activation)\n\n# max pool2d: default pool_size = stride\ndef max_pool2d(x, pool_size, stride=None, scope=""max_pool2d""):\n    pool_sizes = [pool_size] * 2\n    strides = [pool_size] * 2 if stride is None else [stride] * 2\n    return tf.layers.max_pooling2d(x, pool_sizes, strides, name=scope, padding=""same"")\n\n# pad2d: for conv2d with stride > 1\ndef pad2d(x, pad):\n    return tf.pad(x, paddings=[[0, 0], [pad, pad], [pad, pad], [0, 0]])\n\n# dropout\ndef dropout(x, rate=0.5, is_training=True):\n    return tf.layers.dropout(x, rate=rate, training=is_training)\n\n# l2norm (not bacth norm, spatial normalization)\ndef l2norm(x, scale, trainable=True, scope=""L2Normalization""):\n    n_channels = x.get_shape().as_list()[-1]\n    l2_norm = tf.nn.l2_normalize(x, [3], epsilon=1e-12)\n    with tf.variable_scope(scope):\n        gamma = tf.get_variable(""gamma"", shape=[n_channels, ], dtype=tf.float32,\n                                initializer=tf.constant_initializer(scale),\n                                trainable=trainable)\n        return l2_norm * gamma\n\n\n# multibox layer: get class and location predicitions from detection layer\ndef ssd_multibox_layer(x, num_classes, sizes, ratios, normalization=-1, scope=""multibox""):\n    pre_shape = x.get_shape().as_list()[1:-1]\n    pre_shape = [-1] + pre_shape\n    with tf.variable_scope(scope):\n        # l2 norm\n        if normalization > 0:\n            x = l2norm(x, normalization)\n            print(x)\n        # numbers of anchors\n        n_anchors = len(sizes) + len(ratios)\n        # location predictions\n        loc_pred = conv2d(x, n_anchors*4, 3, activation=None, scope=""conv_loc"")\n        loc_pred = tf.reshape(loc_pred, pre_shape + [n_anchors, 4])\n        # class prediction\n        cls_pred = conv2d(x, n_anchors*num_classes, 3, activation=None, scope=""conv_cls"")\n        cls_pred = tf.reshape(cls_pred, pre_shape + [n_anchors, num_classes])\n        return cls_pred, loc_pred\n'"
Chapter7/ssd/utils.py,0,"b'import cv2\nimport numpy as np\n\n\n############## preprocess image ##################\n# whiten the image\ndef whiten_image(image, means=(123., 117., 104.)):\n    """"""Subtracts the given means from each image channel""""""\n    if image.ndim != 3:\n        raise ValueError(\'Input must be of size [height, width, C>0]\')\n    num_channels = image.shape[-1]\n    if len(means) != num_channels:\n        raise ValueError(\'len(means) must match the number of channels\')\n\n    mean = np.array(means, dtype=image.dtype)\n    image = image - mean\n    return image\n\ndef resize_image(image, size=(300, 300)):\n    return cv2.resize(image, size)\n\ndef preprocess_image(image):\n    """"""Preprocess a image to inference""""""\n    image_cp = np.copy(image).astype(np.float32)\n    # whiten the image\n    image_whitened = whiten_image(image_cp)\n    # resize the image\n    image_resized = resize_image(image_whitened)\n    # expand the batch_size dim\n    image_expanded = np.expand_dims(image_resized, axis=0)\n    return image_expanded\n\n############## process bboxes ##################\ndef bboxes_clip(bbox_ref, bboxes):\n    """"""Clip bounding boxes with respect to reference bbox.\n    """"""\n    bboxes = np.copy(bboxes)\n    bboxes = np.transpose(bboxes)\n    bbox_ref = np.transpose(bbox_ref)\n    bboxes[0] = np.maximum(bboxes[0], bbox_ref[0])\n    bboxes[1] = np.maximum(bboxes[1], bbox_ref[1])\n    bboxes[2] = np.minimum(bboxes[2], bbox_ref[2])\n    bboxes[3] = np.minimum(bboxes[3], bbox_ref[3])\n    bboxes = np.transpose(bboxes)\n    return bboxes\n\ndef bboxes_sort(classes, scores, bboxes, top_k=400):\n    """"""Sort bounding boxes by decreasing order and keep only the top_k\n    """"""\n    # if priority_inside:\n    #     inside = (bboxes[:, 0] > margin) & (bboxes[:, 1] > margin) & \\\n    #         (bboxes[:, 2] < 1-margin) & (bboxes[:, 3] < 1-margin)\n    #     idxes = np.argsort(-scores)\n    #     inside = inside[idxes]\n    #     idxes = np.concatenate([idxes[inside], idxes[~inside]])\n    idxes = np.argsort(-scores)\n    classes = classes[idxes][:top_k]\n    scores = scores[idxes][:top_k]\n    bboxes = bboxes[idxes][:top_k]\n    return classes, scores, bboxes\n\ndef bboxes_iou(bboxes1, bboxes2):\n    """"""Computing iou between bboxes1 and bboxes2.\n    Note: bboxes1 and bboxes2 can be multi-dimensional, but should broacastable.\n    """"""\n    bboxes1 = np.transpose(bboxes1)\n    bboxes2 = np.transpose(bboxes2)\n    # Intersection bbox and volume.\n    int_ymin = np.maximum(bboxes1[0], bboxes2[0])\n    int_xmin = np.maximum(bboxes1[1], bboxes2[1])\n    int_ymax = np.minimum(bboxes1[2], bboxes2[2])\n    int_xmax = np.minimum(bboxes1[3], bboxes2[3])\n\n    int_h = np.maximum(int_ymax - int_ymin, 0.)\n    int_w = np.maximum(int_xmax - int_xmin, 0.)\n    int_vol = int_h * int_w\n    # Union volume.\n    vol1 = (bboxes1[2] - bboxes1[0]) * (bboxes1[3] - bboxes1[1])\n    vol2 = (bboxes2[2] - bboxes2[0]) * (bboxes2[3] - bboxes2[1])\n    iou = int_vol / (vol1 + vol2 - int_vol)\n    return iou\n\ndef bboxes_nms(classes, scores, bboxes, nms_threshold=0.5):\n    """"""Apply non-maximum selection to bounding boxes.\n    """"""\n    keep_bboxes = np.ones(scores.shape, dtype=np.bool)\n    for i in range(scores.size-1):\n        if keep_bboxes[i]:\n            # Computer overlap with bboxes which are following.\n            overlap = bboxes_iou(bboxes[i], bboxes[(i+1):])\n            # Overlap threshold for keeping + checking part of the same class\n            keep_overlap = np.logical_or(overlap < nms_threshold, classes[(i+1):] != classes[i])\n            keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):], keep_overlap)\n\n    idxes = np.where(keep_bboxes)\n    return classes[idxes], scores[idxes], bboxes[idxes]\n\ndef bboxes_resize(bbox_ref, bboxes):\n    """"""Resize bounding boxes based on a reference bounding box,\n    assuming that the latter is [0, 0, 1, 1] after transform.\n    """"""\n    bboxes = np.copy(bboxes)\n    # Translate.\n    bboxes[:, 0] -= bbox_ref[0]\n    bboxes[:, 1] -= bbox_ref[1]\n    bboxes[:, 2] -= bbox_ref[0]\n    bboxes[:, 3] -= bbox_ref[1]\n    # Resize.\n    resize = [bbox_ref[2] - bbox_ref[0], bbox_ref[3] - bbox_ref[1]]\n    bboxes[:, 0] /= resize[0]\n    bboxes[:, 1] /= resize[1]\n    bboxes[:, 2] /= resize[0]\n    bboxes[:, 3] /= resize[1]\n    return bboxes\n\ndef process_bboxes(rclasses, rscores, rbboxes, rbbox_img = (0.0, 0.0, 1.0, 1.0),\n                   top_k=400, nms_threshold=0.5):\n    """"""Process the bboxes including sort and nms""""""\n    rbboxes = bboxes_clip(rbbox_img, rbboxes)\n    rclasses, rscores, rbboxes = bboxes_sort(rclasses, rscores, rbboxes, top_k)\n    rclasses, rscores, rbboxes = bboxes_nms(rclasses, rscores, rbboxes, nms_threshold)\n    rbboxes = bboxes_resize(rbbox_img, rbboxes)\n    return rclasses, rscores, rbboxes\n'"
Chapter7/ssd/visualization.py,0,"b'import cv2\nimport random\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.cm as mpcm\n\n\n# class names\nCLASSES = [""aeroplane"", ""bicycle"", ""bird"", ""boat"", ""bottle"",\n                        ""bus"", ""car"", ""cat"", ""chair"", ""cow"", ""diningtable"",\n                        ""dog"", ""horse"", ""motorbike"", ""person"", ""pottedplant"",\n                        ""sheep"", ""sofa"", ""train"",""tvmonitor""]\n# =========================================================================== #\n# Some colormaps.\n# =========================================================================== #\ndef colors_subselect(colors, num_classes=21):\n    dt = len(colors) // num_classes\n    sub_colors = []\n    for i in range(num_classes):\n        color = colors[i*dt]\n        if isinstance(color[0], float):\n            sub_colors.append([int(c * 255) for c in color])\n        else:\n            sub_colors.append([c for c in color])\n    return sub_colors\n\ncolors_plasma = colors_subselect(mpcm.plasma.colors, num_classes=21)\ncolors_tableau = [(255, 255, 255), (31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),\n                  (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),\n                  (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),\n                  (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),\n                  (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]\n\n\n# =========================================================================== #\n# OpenCV drawing.\n# =========================================================================== #\ndef draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n    """"""Draw a collection of lines on an image.\n    """"""\n    for line in lines:\n        for x1, y1, x2, y2 in line:\n            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n\n\ndef draw_rectangle(img, p1, p2, color=[255, 0, 0], thickness=2):\n    cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n\n\ndef draw_bbox(img, bbox, shape, label, color=[255, 0, 0], thickness=2):\n    p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n    p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n    cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n    p1 = (p1[0]+15, p1[1])\n    cv2.putText(img, str(label), p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n\n\ndef bboxes_draw_on_img(img, classes, scores, bboxes, colors, thickness=2):\n    shape = img.shape\n    for i in range(bboxes.shape[0]):\n        bbox = bboxes[i]\n        color = colors[classes[i]]\n        # Draw bounding box...\n        p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n        p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n        cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n        # Draw text...\n        s = \'%s/%.3f\' % (classes[i], scores[i])\n        p1 = (p1[0]-5, p1[1])\n        cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.4, color, 1)\n\n\n# =========================================================================== #\n# Matplotlib show...\n# =========================================================================== #\ndef plt_bboxes(img, classes, scores, bboxes, figsize=(10,10), linewidth=1.5, show_class_name=True):\n    """"""Visualize bounding boxes. Largely inspired by SSD-MXNET!\n    """"""\n    fig = plt.figure(figsize=figsize)\n    plt.imshow(img)\n    height = img.shape[0]\n    width = img.shape[1]\n    colors = dict()\n    for i in range(classes.shape[0]):\n        cls_id = int(classes[i])\n        if cls_id >= 0:\n            score = scores[i]\n            if cls_id not in colors:\n                colors[cls_id] = (random.random(), random.random(), random.random())\n            ymin = int(bboxes[i, 0] * height)\n            xmin = int(bboxes[i, 1] * width)\n            ymax = int(bboxes[i, 2] * height)\n            xmax = int(bboxes[i, 3] * width)\n            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n                                 ymax - ymin, fill=False,\n                                 edgecolor=colors[cls_id],\n                                 linewidth=linewidth)\n            plt.gca().add_patch(rect)\n            class_name = CLASSES[cls_id-1] if show_class_name else str(cls_id)\n            plt.gca().text(xmin, ymin - 2,\n                           \'{:s} | {:.3f}\'.format(class_name, score),\n                           bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n                           fontsize=12, color=\'white\')\n    plt.show()\n'"
