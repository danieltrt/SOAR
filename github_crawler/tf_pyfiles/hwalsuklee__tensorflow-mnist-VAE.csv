file_path,api_count,code
mnist_data.py,4,"b'# Some code was borrowed from https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/models/image/mnist/convolutional.py\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gzip\nimport os\n\nimport numpy\nfrom scipy import ndimage\n\nfrom six.moves import urllib\n\nimport tensorflow as tf\n\nSOURCE_URL = \'http://yann.lecun.com/exdb/mnist/\'\nDATA_DIRECTORY = ""data""\n\n# Params for MNIST\nIMAGE_SIZE = 28\nNUM_CHANNELS = 1\nPIXEL_DEPTH = 255\nNUM_LABELS = 10\nVALIDATION_SIZE = 5000  # Size of the validation set.\n\n# Download MNIST data\ndef maybe_download(filename):\n    """"""Download the data from Yann\'s website, unless it\'s already here.""""""\n    if not tf.gfile.Exists(DATA_DIRECTORY):\n        tf.gfile.MakeDirs(DATA_DIRECTORY)\n    filepath = os.path.join(DATA_DIRECTORY, filename)\n    if not tf.gfile.Exists(filepath):\n        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n        with tf.gfile.GFile(filepath) as f:\n            size = f.size()\n        print(\'Successfully downloaded\', filename, size, \'bytes.\')\n    return filepath\n\n# Extract the images\ndef extract_data(filename, num_images, norm_shift=False, norm_scale=True):\n    """"""Extract the images into a 4D tensor [image index, y, x, channels].\n    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n    """"""\n    print(\'Extracting\', filename)\n    with gzip.open(filename) as bytestream:\n        bytestream.read(16)\n        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n        if norm_shift:\n            data = data - (PIXEL_DEPTH / 2.0)\n        if norm_scale:\n            data = data / PIXEL_DEPTH\n        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n        data = numpy.reshape(data, [num_images, -1])\n    return data\n\n# Extract the labels\ndef extract_labels(filename, num_images):\n    """"""Extract the labels into a vector of int64 label IDs.""""""\n    print(\'Extracting\', filename)\n    with gzip.open(filename) as bytestream:\n        bytestream.read(8)\n        buf = bytestream.read(1 * num_images)\n        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n        num_labels_data = len(labels)\n        one_hot_encoding = numpy.zeros((num_labels_data,NUM_LABELS))\n        one_hot_encoding[numpy.arange(num_labels_data),labels] = 1\n        one_hot_encoding = numpy.reshape(one_hot_encoding, [-1, NUM_LABELS])\n    return one_hot_encoding\n\n# Augment training data\ndef expend_training_data(images, labels):\n\n    expanded_images = []\n    expanded_labels = []\n\n    j = 0 # counter\n    for x, y in zip(images, labels):\n        j = j+1\n        if j%100==0:\n            print (\'expanding data : %03d / %03d\' % (j,numpy.size(images,0)))\n\n        # register original data\n        expanded_images.append(x)\n        expanded_labels.append(y)\n\n        # get a value for the background\n        # zero is the expected value, but median() is used to estimate background\'s value\n        bg_value = numpy.median(x) # this is regarded as background\'s value\n        image = numpy.reshape(x, (-1, 28))\n\n        for i in range(4):\n            # rotate the image with random degree\n            angle = numpy.random.randint(-15,15,1)\n            new_img = ndimage.rotate(image,angle,reshape=False, cval=bg_value)\n\n            # shift the image with random distance\n            shift = numpy.random.randint(-2, 2, 2)\n            new_img_ = ndimage.shift(new_img,shift, cval=bg_value)\n\n            # register new training data\n            expanded_images.append(numpy.reshape(new_img_, 784))\n            expanded_labels.append(y)\n\n    # images and labels are concatenated for random-shuffle at each epoch\n    # notice that pair of image and label should not be broken\n    expanded_train_total_data = numpy.concatenate((expanded_images, expanded_labels), axis=1)\n    numpy.random.shuffle(expanded_train_total_data)\n\n    return expanded_train_total_data\n\n# Prepare MNISt data\ndef prepare_MNIST_data(use_norm_shift=False, use_norm_scale=True, use_data_augmentation=False):\n    # Get the data.\n    train_data_filename = maybe_download(\'train-images-idx3-ubyte.gz\')\n    train_labels_filename = maybe_download(\'train-labels-idx1-ubyte.gz\')\n    test_data_filename = maybe_download(\'t10k-images-idx3-ubyte.gz\')\n    test_labels_filename = maybe_download(\'t10k-labels-idx1-ubyte.gz\')\n\n    # Extract it into numpy arrays.\n    train_data = extract_data(train_data_filename, 60000, use_norm_shift, use_norm_scale)\n    train_labels = extract_labels(train_labels_filename, 60000)\n    test_data = extract_data(test_data_filename, 10000, use_norm_shift, use_norm_scale)\n    test_labels = extract_labels(test_labels_filename, 10000)\n\n    # Generate a validation set.\n    validation_data = train_data[:VALIDATION_SIZE, :]\n    validation_labels = train_labels[:VALIDATION_SIZE,:]\n    train_data = train_data[VALIDATION_SIZE:, :]\n    train_labels = train_labels[VALIDATION_SIZE:,:]\n\n    # Concatenate train_data & train_labels for random shuffle\n    if use_data_augmentation:\n        train_total_data = expend_training_data(train_data, train_labels)\n    else:\n        train_total_data = numpy.concatenate((train_data, train_labels), axis=1)\n\n    train_size = train_total_data.shape[0]\n\n    return train_total_data, train_size, validation_data, validation_labels, test_data, test_labels\n'"
plot_utils.py,0,"b'import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imsave\nfrom scipy.misc import imresize\n\nclass Plot_Reproduce_Performance():\n    def __init__(self, DIR, n_img_x=8, n_img_y=8, img_w=28, img_h=28, resize_factor=1.0):\n        self.DIR = DIR\n\n        assert n_img_x > 0 and n_img_y > 0\n\n        self.n_img_x = n_img_x\n        self.n_img_y = n_img_y\n        self.n_tot_imgs = n_img_x * n_img_y\n\n        assert img_w > 0 and img_h > 0\n\n        self.img_w = img_w\n        self.img_h = img_h\n\n        assert resize_factor > 0\n\n        self.resize_factor = resize_factor\n\n    def save_images(self, images, name=\'result.jpg\'):\n        images = images.reshape(self.n_img_x*self.n_img_y, self.img_h, self.img_w)\n        imsave(self.DIR + ""/""+name, self._merge(images, [self.n_img_y, self.n_img_x]))\n\n    def _merge(self, images, size):\n        h, w = images.shape[1], images.shape[2]\n\n        h_ = int(h * self.resize_factor)\n        w_ = int(w * self.resize_factor)\n\n        img = np.zeros((h_ * size[0], w_ * size[1]))\n\n        for idx, image in enumerate(images):\n            i = int(idx % size[1])\n            j = int(idx / size[1])\n\n            image_ = imresize(image, size=(w_,h_), interp=\'bicubic\')\n\n            img[j*h_:j*h_+h_, i*w_:i*w_+w_] = image_\n\n        return img\n\nclass Plot_Manifold_Learning_Result():\n    def __init__(self, DIR, n_img_x=20, n_img_y=20, img_w=28, img_h=28, resize_factor=1.0, z_range=4):\n        self.DIR = DIR\n\n        assert n_img_x > 0 and n_img_y > 0\n\n        self.n_img_x = n_img_x\n        self.n_img_y = n_img_y\n        self.n_tot_imgs = n_img_x * n_img_y\n\n        assert img_w > 0 and img_h > 0\n\n        self.img_w = img_w\n        self.img_h = img_h\n\n        assert resize_factor > 0\n\n        self.resize_factor = resize_factor\n\n        assert z_range > 0\n        self.z_range = z_range\n\n        self._set_latent_vectors()\n\n    def _set_latent_vectors(self):\n\n        # z1 = np.linspace(-self.z_range, self.z_range, self.n_img_y)\n        # z2 = np.linspace(-self.z_range, self.z_range, self.n_img_x)\n        #\n        # z = np.array(np.meshgrid(z1, z2))\n        # z = z.reshape([-1, 2])\n\n        # borrowed from https://github.com/fastforwardlabs/vae-tf/blob/master/plot.py\n        z = np.rollaxis(np.mgrid[self.z_range:-self.z_range:self.n_img_y * 1j, self.z_range:-self.z_range:self.n_img_x * 1j], 0, 3)\n        # z1 = np.rollaxis(np.mgrid[1:-1:self.n_img_y * 1j, 1:-1:self.n_img_x * 1j], 0, 3)\n        # z = z1**2\n        # z[z1<0] *= -1\n        #\n        # z = z*self.z_range\n\n        self.z = z.reshape([-1, 2])\n\n    def save_images(self, images, name=\'result.jpg\'):\n        images = images.reshape(self.n_img_x*self.n_img_y, self.img_h, self.img_w)\n        imsave(self.DIR + ""/""+name, self._merge(images, [self.n_img_y, self.n_img_x]))\n\n    def _merge(self, images, size):\n        h, w = images.shape[1], images.shape[2]\n\n        h_ = int(h * self.resize_factor)\n        w_ = int(w * self.resize_factor)\n\n        img = np.zeros((h_ * size[0], w_ * size[1]))\n\n        for idx, image in enumerate(images):\n            i = int(idx % size[1])\n            j = int(idx / size[1])\n\n            image_ = imresize(image, size=(w_, h_), interp=\'bicubic\')\n\n            img[j * h_:j * h_ + h_, i * w_:i * w_ + w_] = image_\n\n        return img\n\n    # borrowed from https://github.com/ykwon0407/variational_autoencoder/blob/master/variational_bayes.ipynb\n    def save_scattered_image(self, z, id, name=\'scattered_image.jpg\'):\n        N = 10\n        plt.figure(figsize=(8, 6))\n        plt.scatter(z[:, 0], z[:, 1], c=np.argmax(id, 1), marker=\'o\', edgecolor=\'none\', cmap=discrete_cmap(N, \'jet\'))\n        plt.colorbar(ticks=range(N))\n        axes = plt.gca()\n        axes.set_xlim([-self.z_range-2, self.z_range+2])\n        axes.set_ylim([-self.z_range-2, self.z_range+2])\n        plt.grid(True)\n        plt.savefig(self.DIR + ""/"" + name)\n\n# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\ndef discrete_cmap(N, base_cmap=None):\n    """"""Create an N-bin discrete colormap from the specified input map""""""\n\n    # Note that if base_cmap is a string or None, you can simply do\n    #    return plt.cm.get_cmap(base_cmap, N)\n    # The following works for string, None, or a colormap instance:\n\n    base = plt.cm.get_cmap(base_cmap)\n    color_list = base(np.linspace(0, 1, N))\n    cmap_name = base.name + str(N)\n    return base.from_list(cmap_name, color_list, N)'"
run_main.py,7,"b'import tensorflow as tf\nimport numpy as np\nimport mnist_data\nimport os\nimport vae\nimport plot_utils\nimport glob\n\nimport argparse\n\nIMAGE_SIZE_MNIST = 28\n\n""""""parsing and configuration""""""\ndef parse_args():\n    desc = ""Tensorflow implementation of \'Variational AutoEncoder (VAE)\'""\n    parser = argparse.ArgumentParser(description=desc)\n\n    parser.add_argument(\'--results_path\', type=str, default=\'results\',\n                        help=\'File path of output images\')\n\n    parser.add_argument(\'--add_noise\', type=bool, default=False, help=\'Boolean for adding salt & pepper noise to input image\')\n\n    parser.add_argument(\'--dim_z\', type=int, default=\'20\', help=\'Dimension of latent vector\', required = True)\n\n    parser.add_argument(\'--n_hidden\', type=int, default=500, help=\'Number of hidden units in MLP\')\n\n    parser.add_argument(\'--learn_rate\', type=float, default=1e-3, help=\'Learning rate for Adam optimizer\')\n\n    parser.add_argument(\'--num_epochs\', type=int, default=20, help=\'The number of epochs to run\')\n\n    parser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size\')\n\n    parser.add_argument(\'--PRR\', type=bool, default=True,\n                        help=\'Boolean for plot-reproduce-result\')\n\n    parser.add_argument(\'--PRR_n_img_x\', type=int, default=10,\n                        help=\'Number of images along x-axis\')\n\n    parser.add_argument(\'--PRR_n_img_y\', type=int, default=10,\n                        help=\'Number of images along y-axis\')\n\n    parser.add_argument(\'--PRR_resize_factor\', type=float, default=1.0,\n                        help=\'Resize factor for each displayed image\')\n\n    parser.add_argument(\'--PMLR\', type=bool, default=False,\n                        help=\'Boolean for plot-manifold-learning-result\')\n\n    parser.add_argument(\'--PMLR_n_img_x\', type=int, default=20,\n                        help=\'Number of images along x-axis\')\n\n    parser.add_argument(\'--PMLR_n_img_y\', type=int, default=20,\n                        help=\'Number of images along y-axis\')\n\n    parser.add_argument(\'--PMLR_resize_factor\', type=float, default=1.0,\n                        help=\'Resize factor for each displayed image\')\n\n    parser.add_argument(\'--PMLR_z_range\', type=float, default=2.0,\n                        help=\'Range for unifomly distributed latent vector\')\n\n    parser.add_argument(\'--PMLR_n_samples\', type=int, default=5000,\n                        help=\'Number of samples in order to get distribution of labeled data\')\n\n    return check_args(parser.parse_args())\n\n""""""checking arguments""""""\ndef check_args(args):\n\n    # --results_path\n    try:\n        os.mkdir(args.results_path)\n    except(FileExistsError):\n        pass\n    # delete all existing files\n    files = glob.glob(args.results_path+\'/*\')\n    for f in files:\n        os.remove(f)\n\n    # --add_noise\n    try:\n        assert args.add_noise == True or args.add_noise == False\n    except:\n        print(\'add_noise must be boolean type\')\n        return None\n\n    # --dim-z\n    try:\n        assert args.dim_z > 0\n    except:\n        print(\'dim_z must be positive integer\')\n        return None\n\n    # --n_hidden\n    try:\n        assert args.n_hidden >= 1\n    except:\n        print(\'number of hidden units must be larger than one\')\n\n    # --learn_rate\n    try:\n        assert args.learn_rate > 0\n    except:\n        print(\'learning rate must be positive\')\n\n    # --num_epochs\n    try:\n        assert args.num_epochs >= 1\n    except:\n        print(\'number of epochs must be larger than or equal to one\')\n\n    # --batch_size\n    try:\n        assert args.batch_size >= 1\n    except:\n        print(\'batch size must be larger than or equal to one\')\n\n    # --PRR\n    try:\n        assert args.PRR == True or args.PRR == False\n    except:\n        print(\'PRR must be boolean type\')\n        return None\n\n    if args.PRR == True:\n        # --PRR_n_img_x, --PRR_n_img_y\n        try:\n            assert args.PRR_n_img_x >= 1 and args.PRR_n_img_y >= 1\n        except:\n            print(\'PRR : number of images along each axis must be larger than or equal to one\')\n\n        # --PRR_resize_factor\n        try:\n            assert args.PRR_resize_factor > 0\n        except:\n            print(\'PRR : resize factor for each displayed image must be positive\')\n\n    # --PMLR\n    try:\n        assert args.PMLR == True or args.PMLR == False\n    except:\n        print(\'PMLR must be boolean type\')\n        return None\n\n    if args.PMLR == True:\n        try:\n            assert args.dim_z == 2\n        except:\n            print(\'PMLR : dim_z must be two\')\n\n        # --PMLR_n_img_x, --PMLR_n_img_y\n        try:\n            assert args.PMLR_n_img_x >= 1 and args.PMLR_n_img_y >= 1\n        except:\n            print(\'PMLR : number of images along each axis must be larger than or equal to one\')\n\n        # --PMLR_resize_factor\n        try:\n            assert args.PMLR_resize_factor > 0\n        except:\n            print(\'PMLR : resize factor for each displayed image must be positive\')\n\n        # --PMLR_z_range\n        try:\n            assert args.PMLR_z_range > 0\n        except:\n            print(\'PMLR : range for unifomly distributed latent vector must be positive\')\n\n        # --PMLR_n_samples\n        try:\n            assert args.PMLR_n_samples > 100\n        except:\n            print(\'PMLR : Number of samples in order to get distribution of labeled data must be large enough\')\n\n    return args\n\n""""""main function""""""\ndef main(args):\n\n    """""" parameters """"""\n    RESULTS_DIR = args.results_path\n\n    # network architecture\n    ADD_NOISE = args.add_noise\n\n    n_hidden = args.n_hidden\n    dim_img = IMAGE_SIZE_MNIST**2  # number of pixels for a MNIST image\n    dim_z = args.dim_z\n\n    # train\n    n_epochs = args.num_epochs\n    batch_size = args.batch_size\n    learn_rate = args.learn_rate\n\n    # Plot\n    PRR = args.PRR                              # Plot Reproduce Result\n    PRR_n_img_x = args.PRR_n_img_x              # number of images along x-axis in a canvas\n    PRR_n_img_y = args.PRR_n_img_y              # number of images along y-axis in a canvas\n    PRR_resize_factor = args.PRR_resize_factor  # resize factor for each image in a canvas\n\n    PMLR = args.PMLR                            # Plot Manifold Learning Result\n    PMLR_n_img_x = args.PMLR_n_img_x            # number of images along x-axis in a canvas\n    PMLR_n_img_y = args.PMLR_n_img_y            # number of images along y-axis in a canvas\n    PMLR_resize_factor = args.PMLR_resize_factor# resize factor for each image in a canvas\n    PMLR_z_range = args.PMLR_z_range            # range for random latent vector\n    PMLR_n_samples = args.PMLR_n_samples        # number of labeled samples to plot a map from input data space to the latent space\n\n    """""" prepare MNIST data """"""\n\n    train_total_data, train_size, _, _, test_data, test_labels = mnist_data.prepare_MNIST_data()\n    n_samples = train_size\n\n    """""" build graph """"""\n\n    # input placeholders\n    # In denoising-autoencoder, x_hat == x + noise, otherwise x_hat == x\n    x_hat = tf.placeholder(tf.float32, shape=[None, dim_img], name=\'input_img\')\n    x = tf.placeholder(tf.float32, shape=[None, dim_img], name=\'target_img\')\n\n    # dropout\n    keep_prob = tf.placeholder(tf.float32, name=\'keep_prob\')\n\n    # input for PMLR\n    z_in = tf.placeholder(tf.float32, shape=[None, dim_z], name=\'latent_variable\')\n\n    # network architecture\n    y, z, loss, neg_marginal_likelihood, KL_divergence = vae.autoencoder(x_hat, x, dim_img, dim_z, n_hidden, keep_prob)\n\n    # optimization\n    train_op = tf.train.AdamOptimizer(learn_rate).minimize(loss)\n\n    """""" training """"""\n\n    # Plot for reproduce performance\n    if PRR:\n        PRR = plot_utils.Plot_Reproduce_Performance(RESULTS_DIR, PRR_n_img_x, PRR_n_img_y, IMAGE_SIZE_MNIST, IMAGE_SIZE_MNIST, PRR_resize_factor)\n\n        x_PRR = test_data[0:PRR.n_tot_imgs, :]\n\n        x_PRR_img = x_PRR.reshape(PRR.n_tot_imgs, IMAGE_SIZE_MNIST, IMAGE_SIZE_MNIST)\n        PRR.save_images(x_PRR_img, name=\'input.jpg\')\n\n        if ADD_NOISE:\n            x_PRR = x_PRR * np.random.randint(2, size=x_PRR.shape)\n            x_PRR += np.random.randint(2, size=x_PRR.shape)\n\n            x_PRR_img = x_PRR.reshape(PRR.n_tot_imgs, IMAGE_SIZE_MNIST, IMAGE_SIZE_MNIST)\n            PRR.save_images(x_PRR_img, name=\'input_noise.jpg\')\n\n    # Plot for manifold learning result\n    if PMLR and dim_z == 2:\n\n        PMLR = plot_utils.Plot_Manifold_Learning_Result(RESULTS_DIR, PMLR_n_img_x, PMLR_n_img_y, IMAGE_SIZE_MNIST, IMAGE_SIZE_MNIST, PMLR_resize_factor, PMLR_z_range)\n\n        x_PMLR = test_data[0:PMLR_n_samples, :]\n        id_PMLR = test_labels[0:PMLR_n_samples, :]\n\n        if ADD_NOISE:\n            x_PMLR = x_PMLR * np.random.randint(2, size=x_PMLR.shape)\n            x_PMLR += np.random.randint(2, size=x_PMLR.shape)\n\n        decoded = vae.decoder(z_in, dim_img, n_hidden)\n\n    # train\n    total_batch = int(n_samples / batch_size)\n    min_tot_loss = 1e99\n\n    with tf.Session() as sess:\n\n        sess.run(tf.global_variables_initializer(), feed_dict={keep_prob : 0.9})\n\n        for epoch in range(n_epochs):\n\n            # Random shuffling\n            np.random.shuffle(train_total_data)\n            train_data_ = train_total_data[:, :-mnist_data.NUM_LABELS]\n\n            # Loop over all batches\n            for i in range(total_batch):\n                # Compute the offset of the current minibatch in the data.\n                offset = (i * batch_size) % (n_samples)\n                batch_xs_input = train_data_[offset:(offset + batch_size), :]\n\n                batch_xs_target = batch_xs_input\n\n                # add salt & pepper noise\n                if ADD_NOISE:\n                    batch_xs_input = batch_xs_input * np.random.randint(2, size=batch_xs_input.shape)\n                    batch_xs_input += np.random.randint(2, size=batch_xs_input.shape)\n\n                _, tot_loss, loss_likelihood, loss_divergence = sess.run(\n                    (train_op, loss, neg_marginal_likelihood, KL_divergence),\n                    feed_dict={x_hat: batch_xs_input, x: batch_xs_target, keep_prob : 0.9})\n\n            # print cost every epoch\n            print(""epoch %d: L_tot %03.2f L_likelihood %03.2f L_divergence %03.2f"" % (epoch, tot_loss, loss_likelihood, loss_divergence))\n\n            # if minimum loss is updated or final epoch, plot results\n            if min_tot_loss > tot_loss or epoch+1 == n_epochs:\n                min_tot_loss = tot_loss\n                # Plot for reproduce performance\n                if PRR:\n                    y_PRR = sess.run(y, feed_dict={x_hat: x_PRR, keep_prob : 1})\n                    y_PRR_img = y_PRR.reshape(PRR.n_tot_imgs, IMAGE_SIZE_MNIST, IMAGE_SIZE_MNIST)\n                    PRR.save_images(y_PRR_img, name=""/PRR_epoch_%02d"" %(epoch) + "".jpg"")\n\n                # Plot for manifold learning result\n                if PMLR and dim_z == 2:\n                    y_PMLR = sess.run(decoded, feed_dict={z_in: PMLR.z, keep_prob : 1})\n                    y_PMLR_img = y_PMLR.reshape(PMLR.n_tot_imgs, IMAGE_SIZE_MNIST, IMAGE_SIZE_MNIST)\n                    PMLR.save_images(y_PMLR_img, name=""/PMLR_epoch_%02d"" % (epoch) + "".jpg"")\n\n                    # plot distribution of labeled images\n                    z_PMLR = sess.run(z, feed_dict={x_hat: x_PMLR, keep_prob : 1})\n                    PMLR.save_scattered_image(z_PMLR,id_PMLR, name=""/PMLR_map_epoch_%02d"" % (epoch) + "".jpg"")\n\nif __name__ == \'__main__\':\n\n    # parse arguments\n    args = parse_args()\n    if args is None:\n        exit()\n\n    # main\n    main(args)'"
vae.py,39,"b'import tensorflow as tf\n\n# Gaussian MLP as encoder\ndef gaussian_MLP_encoder(x, n_hidden, n_output, keep_prob):\n    with tf.variable_scope(""gaussian_MLP_encoder""):\n        # initializers\n        w_init = tf.contrib.layers.variance_scaling_initializer()\n        b_init = tf.constant_initializer(0.)\n\n        # 1st hidden layer\n        w0 = tf.get_variable(\'w0\', [x.get_shape()[1], n_hidden], initializer=w_init)\n        b0 = tf.get_variable(\'b0\', [n_hidden], initializer=b_init)\n        h0 = tf.matmul(x, w0) + b0\n        h0 = tf.nn.elu(h0)\n        h0 = tf.nn.dropout(h0, keep_prob)\n\n        # 2nd hidden layer\n        w1 = tf.get_variable(\'w1\', [h0.get_shape()[1], n_hidden], initializer=w_init)\n        b1 = tf.get_variable(\'b1\', [n_hidden], initializer=b_init)\n        h1 = tf.matmul(h0, w1) + b1\n        h1 = tf.nn.tanh(h1)\n        h1 = tf.nn.dropout(h1, keep_prob)\n\n        # output layer\n        # borrowed from https: // github.com / altosaar / vae / blob / master / vae.py\n        wo = tf.get_variable(\'wo\', [h1.get_shape()[1], n_output * 2], initializer=w_init)\n        bo = tf.get_variable(\'bo\', [n_output * 2], initializer=b_init)\n        gaussian_params = tf.matmul(h1, wo) + bo\n\n        # The mean parameter is unconstrained\n        mean = gaussian_params[:, :n_output]\n        # The standard deviation must be positive. Parametrize with a softplus and\n        # add a small epsilon for numerical stability\n        stddev = 1e-6 + tf.nn.softplus(gaussian_params[:, n_output:])\n\n    return mean, stddev\n\n# Bernoulli MLP as decoder\ndef bernoulli_MLP_decoder(z, n_hidden, n_output, keep_prob, reuse=False):\n\n    with tf.variable_scope(""bernoulli_MLP_decoder"", reuse=reuse):\n        # initializers\n        w_init = tf.contrib.layers.variance_scaling_initializer()\n        b_init = tf.constant_initializer(0.)\n\n        # 1st hidden layer\n        w0 = tf.get_variable(\'w0\', [z.get_shape()[1], n_hidden], initializer=w_init)\n        b0 = tf.get_variable(\'b0\', [n_hidden], initializer=b_init)\n        h0 = tf.matmul(z, w0) + b0\n        h0 = tf.nn.tanh(h0)\n        h0 = tf.nn.dropout(h0, keep_prob)\n\n        # 2nd hidden layer\n        w1 = tf.get_variable(\'w1\', [h0.get_shape()[1], n_hidden], initializer=w_init)\n        b1 = tf.get_variable(\'b1\', [n_hidden], initializer=b_init)\n        h1 = tf.matmul(h0, w1) + b1\n        h1 = tf.nn.elu(h1)\n        h1 = tf.nn.dropout(h1, keep_prob)\n\n        # output layer-mean\n        wo = tf.get_variable(\'wo\', [h1.get_shape()[1], n_output], initializer=w_init)\n        bo = tf.get_variable(\'bo\', [n_output], initializer=b_init)\n        y = tf.sigmoid(tf.matmul(h1, wo) + bo)\n\n    return y\n\n# Gateway\ndef autoencoder(x_hat, x, dim_img, dim_z, n_hidden, keep_prob):\n\n    # encoding\n    mu, sigma = gaussian_MLP_encoder(x_hat, n_hidden, dim_z, keep_prob)\n\n    # sampling by re-parameterization technique\n    z = mu + sigma * tf.random_normal(tf.shape(mu), 0, 1, dtype=tf.float32)\n\n    # decoding\n    y = bernoulli_MLP_decoder(z, n_hidden, dim_img, keep_prob)\n    y = tf.clip_by_value(y, 1e-8, 1 - 1e-8)\n\n    # loss\n    marginal_likelihood = tf.reduce_sum(x * tf.log(y) + (1 - x) * tf.log(1 - y), 1)\n    KL_divergence = 0.5 * tf.reduce_sum(tf.square(mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1, 1)\n\n    marginal_likelihood = tf.reduce_mean(marginal_likelihood)\n    KL_divergence = tf.reduce_mean(KL_divergence)\n\n    ELBO = marginal_likelihood - KL_divergence\n\n    loss = -ELBO\n\n    return y, z, loss, -marginal_likelihood, KL_divergence\n\ndef decoder(z, dim_img, n_hidden):\n\n    y = bernoulli_MLP_decoder(z, n_hidden, dim_img, 1.0, reuse=True)\n\n    return y'"
