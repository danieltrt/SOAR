file_path,api_count,code
mkdocs/autogen.py,0,"b'# Heavily borrowed from the Auto-Keras project:\n# https://github.com/jhfjhfj1/autokeras/blob/master/mkdocs/autogen.py\n\nimport ast\nimport os\nimport re\n\n\ndef delete_space(parts, start, end):\n    if start > end or end >= len(parts):\n        return None\n    count = 0\n    while count < len(parts[start]):\n        if parts[start][count] == \' \':\n            count += 1\n        else:\n            break\n    return \'\\n\'.join(y for y in [x[count:] for x in parts[start : end + 1] if len(x) > count])\n\n\ndef change_args_to_dict(string):\n    if string is None:\n        return None\n    ans = []\n    strings = string.split(\'\\n\')\n    ind = 1\n    start = 0\n    while ind <= len(strings):\n        if ind < len(strings) and strings[ind].startswith("" ""):\n            ind += 1\n        else:\n            if start < ind:\n                ans.append(\'\\n\'.join(strings[start:ind]))\n            start = ind\n            ind += 1\n    d = {}\n    for line in ans:\n        if "":"" in line and len(line) > 0:\n            lines = line.split("":"")\n            d[lines[0]] = lines[1].strip()\n    return d\n\n\ndef remove_next_line(comments):\n    for x in comments:\n        if comments[x] is not None and \'\\n\' in comments[x]:\n            comments[x] = \' \'.join(comments[x].split(\'\\n\'))\n    return comments\n\n\ndef skip_space_line(parts, ind):\n    while ind < len(parts):\n        if re.match(r\'^\\s*$\', parts[ind]):\n            ind += 1\n        else:\n            break\n    return ind\n\n\n# check if comment is None or len(comment) == 0 return {}\ndef parse_func_string(comment):\n    if comment is None or len(comment) == 0:\n        return {}\n    comments = {}\n    paras = (\'Args\', \'Attributes\', \'Returns\', \'Raises\')\n    comment_parts = [\n        \'short_description\',\n        \'long_description\',\n        \'Args\',\n        \'Attributes\',\n        \'Returns\',\n        \'Raises\',\n    ]\n    for x in comment_parts:\n        comments[x] = None\n\n    parts = re.split(r\'\\n\', comment)\n    ind = 1\n    while ind < len(parts):\n        if re.match(r\'^\\s*$\', parts[ind]):\n            break\n        else:\n            ind += 1\n\n    comments[\'short_description\'] = \'\\n\'.join(\n        [\'\\n\'.join(re.split(\'\\n\\s+\', x.strip())) for x in parts[0:ind]]\n    ).strip(\':\\n\\t \')\n    ind = skip_space_line(parts, ind)\n\n    start = ind\n    while ind < len(parts):\n        if parts[ind].strip().startswith(paras):\n            break\n        else:\n            ind += 1\n    long_description = \'\\n\'.join(\n        [\'\\n\'.join(re.split(\'\\n\\s+\', x.strip())) for x in parts[start:ind]]\n    ).strip(\':\\n\\t \')\n    comments[\'long_description\'] = long_description\n\n    ind = skip_space_line(paras, ind)\n    while ind < len(parts):\n        if parts[ind].strip().startswith(paras):\n            start = ind\n            start_with = parts[ind].strip()\n            ind += 1\n            while ind < len(parts):\n                if parts[ind].strip().startswith(paras):\n                    break\n                else:\n                    ind += 1\n            part = delete_space(parts, start + 1, ind - 1)\n            if start_with.startswith(paras[0]):\n                comments[paras[0]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[1]):\n                comments[paras[1]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[2]):\n                comments[paras[2]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[3]):\n                comments[paras[3]] = part\n            ind = skip_space_line(parts, ind)\n        else:\n            ind += 1\n\n    remove_next_line(comments)\n    return comments\n\n\ndef md_parse_line_break(comment):\n    comment = comment.replace(\'  \', \'\\n\\n\')\n    return comment.replace(\' - \', \'\\n\\n- \')\n\n\ndef to_md(comment_dict):\n    doc = \'\'\n    if \'short_description\' in comment_dict:\n        doc += comment_dict[\'short_description\']\n        doc += \'\\n\\n\'\n\n    if \'long_description\' in comment_dict:\n        doc += md_parse_line_break(comment_dict[\'long_description\'])\n        doc += \'\\n\'\n\n    if \'Args\' in comment_dict and comment_dict[\'Args\'] is not None:\n        doc += \'##### Args\\n\'\n        for arg, des in comment_dict[\'Args\'].items():\n            doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n\n    if \'Attributes\' in comment_dict and comment_dict[\'Attributes\'] is not None:\n        doc += \'##### Attributes\\n\'\n        for arg, des in comment_dict[\'Attributes\'].items():\n            doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n\n    if \'Returns\' in comment_dict and comment_dict[\'Returns\'] is not None:\n        doc += \'##### Returns\\n\'\n        if isinstance(comment_dict[\'Returns\'], str):\n            doc += comment_dict[\'Returns\']\n            doc += \'\\n\'\n        else:\n            for arg, des in comment_dict[\'Returns\'].items():\n                doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n    return doc\n\n\ndef parse_func_args(function):\n    args = [a.arg for a in function.args.args if a.arg != \'self\']\n    kwargs = []\n    if function.args.kwarg:\n        kwargs = [\'**\' + function.args.kwarg.arg]\n\n    return \'(\' + \', \'.join(args + kwargs) + \')\'\n\n\ndef get_func_comments(function_definitions):\n    doc = \'\'\n    for f in function_definitions:\n        temp_str = to_md(parse_func_string(ast.get_docstring(f)))\n        doc += \'\'.join(\n            [\n                \'### \',\n                f.name.replace(\'_\', \'\\\\_\'),\n                \'\\n\',\n                \'```python\',\n                \'\\n\',\n                \'def \',\n                f.name,\n                parse_func_args(f),\n                \'\\n\',\n                \'```\',\n                \'\\n\',\n                temp_str,\n                \'\\n\',\n            ]\n        )\n\n    return doc\n\n\ndef get_comments_str(file_name):\n    with open(file_name) as fd:\n        file_contents = fd.read()\n    module = ast.parse(file_contents)\n\n    function_definitions = [node for node in module.body if isinstance(node, ast.FunctionDef)]\n\n    doc = get_func_comments(function_definitions)\n\n    class_definitions = [node for node in module.body if isinstance(node, ast.ClassDef)]\n    for class_def in class_definitions:\n        temp_str = to_md(parse_func_string(ast.get_docstring(class_def)))\n\n        # excludes private methods (start with \'_\')\n        method_definitions = [\n            node\n            for node in class_def.body\n            if isinstance(node, ast.FunctionDef) and (node.name[0] != \'_\' or node.name[:2] == \'__\')\n        ]\n\n        temp_str += get_func_comments(method_definitions)\n        doc += \'## class \' + class_def.name + \'\\n\' + temp_str\n    return doc\n\n\ndef extract_comments(directory):\n    for parent, dir_names, file_names in os.walk(directory):\n        for file_name in file_names:\n            if os.path.splitext(file_name)[1] == \'.py\' and file_name != \'__init__.py\':\n                # with open\n                doc = get_comments_str(os.path.join(parent, file_name))\n                directory = os.path.join(\'docs\', parent.replace(\'../src/\', \'\'))\n                if not os.path.exists(directory):\n                    os.makedirs(directory)\n\n                output_file = open(os.path.join(directory, file_name[:-3] + \'.md\'), \'w\')\n                output_file.write(doc)\n                output_file.close()\n\n\nextract_comments(\'../src/\')'"
contrib/tf_serving/save_tfs_model.py,0,"b""import tensorflow.keras.backend as K\nimport argparse\nfrom tensorflow.keras.applications.mobilenet import DepthwiseConv2D, relu6\nfrom tensorflow.keras.utils.generic_utils import CustomObjectScope\nfrom tensorflow.python.saved_model import builder as saved_model_builder\nfrom tensorflow.python.saved_model import tag_constants\nfrom tensorflow.python.saved_model.signature_def_utils_impl import \\\n    predict_signature_def\n\nfrom src.handlers.model_builder import Nima\n\n\ndef main(base_model_name, weights_file, export_path):\n    # Load model and weights\n    nima = Nima(base_model_name, weights=None)\n    nima.build()\n    nima.nima_model.load_weights(weights_file)\n\n    # Tell keras that this will be used for making predictions\n    K.set_learning_phase(0)\n\n    # CustomObject required by MobileNet\n    with CustomObjectScope({'relu6': relu6, 'DepthwiseConv2D': DepthwiseConv2D}):\n        builder = saved_model_builder.SavedModelBuilder(export_path)\n        signature = predict_signature_def(\n            inputs={'input_image': nima.nima_model.input},\n            outputs={'quality_prediction': nima.nima_model.output}\n        )\n\n        builder.add_meta_graph_and_variables(\n            sess=K.get_session(),\n            tags=[tag_constants.SERVING],\n            signature_def_map={'image_quality': signature}\n        )\n        builder.save()\n\n    print(f'TF model exported to: {export_path}')\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-b', '--base-model-name', help='CNN base model name', required=True)\n    parser.add_argument('-w', '--weights-file', help='path of weights file', required=True)\n    parser.add_argument('-ep', '--export-path', help='path to save the tfs model', required=True)\n\n    args = parser.parse_args()\n\n    main(**args.__dict__)\n"""
contrib/tf_serving/tfs_sample_client.py,1,"b""import json\nimport argparse\nimport tensorflow.keras as keras\nimport numpy as np\nimport tensorflow as tf\nfrom src.utils import utils\nimport grpc\nfrom tensorflow_serving.apis import predict_pb2, prediction_service_pb2_grpc\n\nTFS_HOST = 'localhost'\nTFS_PORT = 8500\n\n\ndef normalize_labels(labels):\n    labels_np = np.array(labels)\n    return labels_np / labels_np.sum()\n\n\ndef calc_mean_score(score_dist):\n    score_dist = normalize_labels(score_dist)\n    return (score_dist * np.arange(1, 11)).sum()\n\n\ndef get_image_quality_predictions(image_path, model_name):\n    # Load and preprocess image\n    image = utils.load_image(image_path, target_size=(224, 224))\n    image = keras.applications.mobilenet.preprocess_input(image)\n\n    # Run through model\n    target = f'{TFS_HOST}:{TFS_PORT}'\n    channel = grpc.insecure_channel(target)\n    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n    request = predict_pb2.PredictRequest()\n    request.model_spec.name = model_name\n    request.model_spec.signature_name = 'image_quality'\n\n    request.inputs['input_image'].CopyFrom(\n        tf.contrib.util.make_tensor_proto(np.expand_dims(image, 0))\n    )\n\n    response = stub.Predict(request, 10.0)\n    result = round(calc_mean_score(response.outputs['quality_prediction'].float_val), 2)\n\n    print(json.dumps({'mean_score_prediction': np.round(result, 3)}, indent=2))\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-ip', '--image-path', help='Path to image file.', required=True)\n    parser.add_argument(\n        '-mn', '--model-name', help='mobilenet_aesthetic or mobilenet_technical', required=True\n    )\n    args = parser.parse_args()\n    get_image_quality_predictions(**args.__dict__)\n"""
data/TID2013/get_labels.py,0,"b""\nimport argparse\nimport numpy as np\nimport pandas as pd\nfrom src.utils.utils import save_json\nfrom maxentropy.skmaxent import MinDivergenceModel\n\n\n# the maximised distribution must satisfy the mean for each sample\ndef get_features():\n    def f0(x):\n        return x\n\n    return [f0]\n\n\ndef get_max_entropy_distribution(mean):\n    SAMPLESPACE = np.arange(10)\n    features = get_features()\n\n    model = MinDivergenceModel(features, samplespace=SAMPLESPACE, algorithm='CG')\n\n    # set the desired feature expectations and fit the model\n    X = np.array([[mean]])\n    model.fit(X)\n\n    return model.probdist()\n\n\ndef get_dataframe(mean_raw_file):\n    df = pd.read_csv(mean_raw_file, header=None, sep=' ')\n    df.columns = ['mos', 'id']\n    return df\n\n\ndef parse_raw_data(df):\n    samples = []\n    for i, row in df.iterrows():\n        max_entropy_dist = get_max_entropy_distribution(row['mos'])\n        samples.append({'image_id': row['id'].split('.')[0], 'label': max_entropy_dist.tolist()})\n\n    return samples\n\n\ndef main(target_file, source_file_mean):\n    df = get_dataframe(source_file_mean)\n    samples = parse_raw_data(df)\n    save_json(samples, target_file)\n    print('Done! Saved JSON at {}'.format(target_file))\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-sfm', '--source-file-mean', help='file path of raw mos_with_names file', required=True)\n    parser.add_argument('-tf', '--target-file', help='file path of json labels file to be saved', required=True)\n\n    args = parser.parse_args()\n    main(**args.__dict__)\n"""
src/evaluater/predict.py,0,"b""\nimport os\nimport glob\nimport json\nimport argparse\nfrom utils.utils import calc_mean_score, save_json\nfrom handlers.model_builder import Nima\nfrom handlers.data_generator import TestDataGenerator\n\n\ndef image_file_to_json(img_path):\n    img_dir = os.path.dirname(img_path)\n    img_id = os.path.basename(img_path).split('.')[0]\n\n    return img_dir, [{'image_id': img_id}]\n\n\ndef image_dir_to_json(img_dir, img_type='jpg'):\n    img_paths = glob.glob(os.path.join(img_dir, '*.'+img_type))\n\n    samples = []\n    for img_path in img_paths:\n        img_id = os.path.basename(img_path).split('.')[0]\n        samples.append({'image_id': img_id})\n\n    return samples\n\n\ndef predict(model, data_generator):\n    return model.predict_generator(data_generator, workers=8, use_multiprocessing=True, verbose=1)\n\n\ndef main(base_model_name, weights_file, image_source, predictions_file, img_format='jpg'):\n    # load samples\n    if os.path.isfile(image_source):\n        image_dir, samples = image_file_to_json(image_source)\n    else:\n        image_dir = image_source\n        samples = image_dir_to_json(image_dir, img_type='jpg')\n\n    # build model and load weights\n    nima = Nima(base_model_name, weights=None)\n    nima.build()\n    nima.nima_model.load_weights(weights_file)\n\n    # initialize data generator\n    data_generator = TestDataGenerator(samples, image_dir, 64, 10, nima.preprocessing_function(),\n                                       img_format=img_format)\n\n    # get predictions\n    predictions = predict(nima.nima_model, data_generator)\n\n    # calc mean scores and add to samples\n    for i, sample in enumerate(samples):\n        sample['mean_score_prediction'] = calc_mean_score(predictions[i])\n\n    print(json.dumps(samples, indent=2))\n\n    if predictions_file is not None:\n        save_json(samples, predictions_file)\n\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-b', '--base-model-name', help='CNN base model name', required=True)\n    parser.add_argument('-w', '--weights-file', help='path of weights file', required=True)\n    parser.add_argument('-is', '--image-source', help='image directory or file', required=True)\n    parser.add_argument('-pf', '--predictions-file', help='file with predictions', required=False, default=None)\n\n    args = parser.parse_args()\n\n    main(**args.__dict__)\n"""
src/handlers/config_loader.py,0,b'\nfrom utils.utils import load_json\n\n\ndef load_config(config_file):\n    config = load_json(config_file)\n    return config\n'
src/handlers/data_generator.py,2,"b""\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom utils import utils\n\n\nclass TrainDataGenerator(tf.keras.utils.Sequence):\n    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n                 img_load_dims=(256, 256), img_crop_dims=(224, 224), shuffle=True):\n        self.samples = samples\n        self.img_dir = img_dir\n        self.batch_size = batch_size\n        self.n_classes = n_classes\n        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n        self.img_load_dims = img_load_dims  # dimensions that images get resized into when loaded\n        self.img_crop_dims = img_crop_dims  # dimensions that images get randomly cropped to\n        self.shuffle = shuffle\n        self.img_format = img_format\n        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n\n    def __len__(self):\n        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n\n    def __getitem__(self, index):\n        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n        X, y = self.__data_generator(batch_samples)\n        return X, y\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.samples))\n        if self.shuffle is True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generator(self, batch_samples):\n        # initialize images and labels tensors for faster processing\n        X = np.empty((len(batch_samples), *self.img_crop_dims, 3))\n        y = np.empty((len(batch_samples), self.n_classes))\n\n        for i, sample in enumerate(batch_samples):\n            # load and randomly augment image\n            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n            img = utils.load_image(img_file, self.img_load_dims)\n            if img is not None:\n                img = utils.random_crop(img, self.img_crop_dims)\n                img = utils.random_horizontal_flip(img)\n                X[i, ] = img\n\n            # normalize labels\n            y[i, ] = utils.normalize_labels(sample['label'])\n\n        # apply basenet specific preprocessing\n        # input is 4D numpy array of RGB values within [0, 255]\n        X = self.basenet_preprocess(X)\n\n        return X, y\n\n\nclass TestDataGenerator(tf.keras.utils.Sequence):\n    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n                 img_load_dims=(224, 224)):\n        self.samples = samples\n        self.img_dir = img_dir\n        self.batch_size = batch_size\n        self.n_classes = n_classes\n        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n        self.img_load_dims = img_load_dims  # dimensions that images get resized into when loaded\n        self.img_format = img_format\n        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n\n    def __len__(self):\n        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n\n    def __getitem__(self, index):\n        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n        X, y = self.__data_generator(batch_samples)\n        return X, y\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.samples))\n\n    def __data_generator(self, batch_samples):\n        # initialize images and labels tensors for faster processing\n        X = np.empty((len(batch_samples), *self.img_load_dims, 3))\n        y = np.empty((len(batch_samples), self.n_classes))\n\n        for i, sample in enumerate(batch_samples):\n            # load and randomly augment image\n            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n            img = utils.load_image(img_file, self.img_load_dims)\n            if img is not None:\n                X[i, ] = img\n\n            # normalize labels\n            if sample.get('label') is not None:\n                y[i, ] = utils.normalize_labels(sample['label'])\n\n        # apply basenet specific preprocessing\n        # input is 4D numpy array of RGB values within [0, 255]\n        X = self.basenet_preprocess(X)\n\n        return X, y\n"""
src/handlers/model_builder.py,0,"b""\nimport importlib\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom utils.losses import earth_movers_distance\n\n\nclass Nima:\n    def __init__(self, base_model_name, n_classes=10, learning_rate=0.001, dropout_rate=0, loss=earth_movers_distance,\n                 decay=0, weights='imagenet'):\n        self.n_classes = n_classes\n        self.base_model_name = base_model_name\n        self.learning_rate = learning_rate\n        self.dropout_rate = dropout_rate\n        self.loss = loss\n        self.decay = decay\n        self.weights = weights\n        self._get_base_module()\n\n    def _get_base_module(self):\n        # import Keras base model module\n        if self.base_model_name == 'InceptionV3':\n            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_v3')\n        elif self.base_model_name == 'InceptionResNetV2':\n            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_resnet_v2')\n        else:\n            self.base_module = importlib.import_module('tensorflow.keras.applications.'+self.base_model_name.lower())\n\n    def build(self):\n        # get base model class\n        BaseCnn = getattr(self.base_module, self.base_model_name)\n\n        # load pre-trained model\n        self.base_model = BaseCnn(input_shape=(224, 224, 3), weights=self.weights, include_top=False, pooling='avg')\n\n        # add dropout and dense layer\n        x = Dropout(self.dropout_rate)(self.base_model.output)\n        x = Dense(units=self.n_classes, activation='softmax')(x)\n\n        self.nima_model = Model(self.base_model.inputs, x)\n\n    def compile(self):\n        self.nima_model.compile(optimizer=Adam(lr=self.learning_rate, decay=self.decay), loss=self.loss)\n\n    def preprocessing_function(self):\n        return self.base_module.preprocess_input\n"""
src/handlers/samples_loader.py,0,b'\nfrom utils.utils import load_json\n\n\ndef load_samples(samples_file):\n    return load_json(samples_file)\n'
src/tests/test_augmentation_utils.py,0,"b""\nimport unittest\nimport numpy as np\nfrom utils import utils\nfrom unittest.mock import patch\n\n\nclass TestUtils(unittest.TestCase):\n\n    @patch('numpy.random.randint')\n    def test_random_crop(self, mock_np_random_randint):\n        mock_np_random_randint.return_value = 1\n\n        test_img = np.expand_dims(np.array([[0, 255], [0, 255]]), axis=2)\n        crop_dims = (1, 1)\n        cropped_img = utils.random_crop(test_img, crop_dims)\n        self.assertEqual([255], cropped_img)\n\n    @patch('numpy.random.random')\n    def test_random_flip(self, mock_np_random_randint):\n        mock_np_random_randint.return_value = 0\n        temp = np.array([[0, 255], [0, 255]])\n        test_img = np.dstack((temp, temp, temp))\n\n        temp = np.array([[255, 0], [255, 0]])\n        expected = np.dstack((temp, temp, temp))\n\n        flipped_img = utils.random_horizontal_flip(test_img)\n        np.testing.assert_array_equal(expected, flipped_img)\n\n    def test_normalize_label(self):\n        labels = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n        normed_label = utils.normalize_labels(labels)\n        np.testing.assert_array_equal(np.array([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1]), normed_label)\n"""
src/tests/test_data_generator.py,0,"b""\nimport os\nimport unittest\nimport numpy as np\nfrom handlers.data_generator import TrainDataGenerator, TestDataGenerator\n\n\nIMG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'test_images')\nN_CLASSES = 10\nBATCH_SIZE = 2\nBASENET_PREPROCESS = lambda x: x\nIMG_FORMAT = 'jpg'\nTEST_SAMPLES = [\n    {\n        'image_id': '42039',\n        'label': [0, 5, 10, 28, 54, 31, 12, 3, 3, 2]\n    },\n    {\n        'image_id': '42040',\n        'label': [0, 5, 10, 28, 54, 31, 12, 3, 3, 2]\n    },\n    {\n        'image_id': '42041',\n        'label': [0, 5, 10, 28, 54, 31, 12, 3, 3, 2]\n    },\n    {\n        'image_id': '42042',\n        'label': [0, 5, 10, 28, 54, 31, 12, 3, 3, 2]\n    },\n    {\n        'image_id': '42044',\n        'label': [0, 5, 10, 28, 54, 31, 12, 3, 3, 2]\n    },\n]\n\n\nclass TestTrainDataGenerator(unittest.TestCase):\n\n    def test_train_data_generator(self):\n        dg = TrainDataGenerator(TEST_SAMPLES, IMG_DIR, BATCH_SIZE, N_CLASSES, BASENET_PREPROCESS, img_format=IMG_FORMAT,\n                                shuffle=False)\n        X, y = dg.__getitem__(0)\n\n        # test image dimensions\n        expected = (BATCH_SIZE, 224, 224, 3)\n        self.assertEqual(X.shape, expected)\n\n        # test label dimensions\n        expected = (BATCH_SIZE, 10)\n        self.assertEqual(y.shape, expected)\n\n        # test that label is probability distribution\n        expected = np.array([1, 1])\n        np.testing.assert_array_almost_equal(np.sum(y, axis=1), expected)\n\n        # test that last batch has 1 sample only\n        X, y = dg.__getitem__(2)\n        expected = 1\n        self.assertEqual(X.shape[0], expected)\n\n        # test number of batches\n        expected = 3\n        self.assertEqual(dg.__len__(), expected)\n\n    def test_test_data_generator(self):\n        dg = TestDataGenerator(TEST_SAMPLES, IMG_DIR, BATCH_SIZE, N_CLASSES, BASENET_PREPROCESS, img_format=IMG_FORMAT)\n        X, y = dg.__getitem__(0)\n\n        # test image dimensions\n        expected = (BATCH_SIZE, 224, 224, 3)\n        self.assertEqual(X.shape, expected)\n\n        # test label dimensions\n        expected = (BATCH_SIZE, 10)\n        self.assertEqual(y.shape, expected)\n\n        # test that label is probability distribution\n        expected = np.array([1, 1])\n        np.testing.assert_array_almost_equal(np.sum(y, axis=1), expected)\n\n        # test that last batch has 1 sample only\n        X, y = dg.__getitem__(2)\n        expected = 1\n        self.assertEqual(X.shape[0], expected)\n\n        # test number of batches\n        expected = 3\n        self.assertEqual(dg.__len__(), expected)\n"""
src/trainer/train.py,0,"b""import os\nimport argparse\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\nfrom sklearn.model_selection import train_test_split\nfrom handlers.data_generator import TrainDataGenerator, TestDataGenerator\nfrom handlers.model_builder import Nima\nfrom handlers.samples_loader import load_samples\nfrom handlers.config_loader import load_config\nfrom utils.utils import ensure_dir_exists\n\n\ndef train(\n    base_model_name,\n    n_classes,\n    samples,\n    image_dir,\n    batch_size,\n    epochs_train_dense,\n    epochs_train_all,\n    learning_rate_dense,\n    learning_rate_all,\n    dropout_rate,\n    job_dir,\n    img_format='jpg',\n    existing_weights=None,\n    multiprocessing_data_load=False,\n    num_workers_data_load=2,\n    decay_dense=0,\n    decay_all=0,\n    **kwargs\n):\n\n    # build NIMA model and load existing weights if they were provided in config\n    nima = Nima(\n        base_model_name, n_classes, learning_rate_dense, dropout_rate, decay=decay_dense\n    )\n    nima.build()\n\n    if existing_weights is not None:\n        nima.nima_model.load_weights(existing_weights)\n\n    # split samples in train and validation set, and initialize data generators\n    samples_train, samples_test = train_test_split(\n        samples, test_size=0.05, shuffle=True, random_state=10207\n    )\n\n    training_generator = TrainDataGenerator(\n        samples_train,\n        image_dir,\n        batch_size,\n        n_classes,\n        nima.preprocessing_function(),\n        img_format=img_format,\n    )\n\n    validation_generator = TestDataGenerator(\n        samples_test,\n        image_dir,\n        batch_size,\n        n_classes,\n        nima.preprocessing_function(),\n        img_format=img_format,\n    )\n\n    # initialize callbacks TensorBoard and ModelCheckpoint\n    tensorboard = TensorBoard(\n        log_dir=os.path.join(job_dir, 'logs'), update_freq='batch'\n    )\n\n    model_save_name = (\n        'weights_' + base_model_name.lower() + '_{epoch:02d}_{val_loss:.3f}.hdf5'\n    )\n    model_file_path = os.path.join(job_dir, 'weights', model_save_name)\n    model_checkpointer = ModelCheckpoint(\n        filepath=model_file_path,\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=True,\n        save_weights_only=True,\n    )\n\n    # start training only dense layers\n    for layer in nima.base_model.layers:\n        layer.trainable = False\n\n    nima.compile()\n    nima.nima_model.summary()\n\n    nima.nima_model.fit_generator(\n        generator=training_generator,\n        validation_data=validation_generator,\n        epochs=epochs_train_dense,\n        verbose=1,\n        use_multiprocessing=multiprocessing_data_load,\n        workers=num_workers_data_load,\n        max_queue_size=30,\n        callbacks=[tensorboard, model_checkpointer],\n    )\n\n    # start training all layers\n    for layer in nima.base_model.layers:\n        layer.trainable = True\n\n    nima.learning_rate = learning_rate_all\n    nima.decay = decay_all\n    nima.compile()\n    nima.nima_model.summary()\n\n    nima.nima_model.fit_generator(\n        generator=training_generator,\n        validation_data=validation_generator,\n        epochs=epochs_train_dense + epochs_train_all,\n        initial_epoch=epochs_train_dense,\n        verbose=1,\n        use_multiprocessing=multiprocessing_data_load,\n        workers=num_workers_data_load,\n        max_queue_size=30,\n        callbacks=[tensorboard, model_checkpointer],\n    )\n\n    K.clear_session()\n\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '-j',\n        '--job-dir',\n        help='train job directory with samples and config file',\n        required=True,\n    )\n    parser.add_argument(\n        '-i', '--image-dir', help='directory with image files', required=True\n    )\n\n    args = parser.parse_args()\n\n    image_dir = args.__dict__['image_dir']\n    job_dir = args.__dict__['job_dir']\n\n    ensure_dir_exists(os.path.join(job_dir, 'weights'))\n    ensure_dir_exists(os.path.join(job_dir, 'logs'))\n\n    config_file = os.path.join(job_dir, 'config.json')\n    config = load_config(config_file)\n\n    samples_file = os.path.join(job_dir, 'samples.json')\n    samples = load_samples(samples_file)\n\n    train(samples=samples, job_dir=job_dir, image_dir=image_dir, **config)\n"""
src/utils/losses.py,0,"b'\nfrom tensorflow.keras import backend as K\n\n\ndef earth_movers_distance(y_true, y_pred):\n    cdf_true = K.cumsum(y_true, axis=-1)\n    cdf_pred = K.cumsum(y_pred, axis=-1)\n    emd = K.sqrt(K.mean(K.square(cdf_true - cdf_pred), axis=-1))\n    return K.mean(emd)\n'"
src/utils/utils.py,1,"b""\nimport os\nimport json\nimport tensorflow as tf\nimport numpy as np\n\n\ndef load_json(file_path):\n    with open(file_path, 'r') as f:\n        return json.load(f)\n\n\ndef save_json(data, target_file):\n    with open(target_file, 'w') as f:\n        json.dump(data, f, indent=2, sort_keys=True)\n\n\ndef random_crop(img, crop_dims):\n    h, w = img.shape[0], img.shape[1]\n    ch, cw = crop_dims[0], crop_dims[1]\n    assert h >= ch, 'image height is less than crop height'\n    assert w >= cw, 'image width is less than crop width'\n    x = np.random.randint(0, w - cw + 1)\n    y = np.random.randint(0, h - ch + 1)\n    return img[y:(y+ch), x:(x+cw), :]\n\n\ndef random_horizontal_flip(img):\n    assert len(img.shape) == 3, 'input tensor must have 3 dimensions (height, width, channels)'\n    assert img.shape[2] == 3, 'image not in channels last format'\n    if np.random.random() < 0.5:\n        img = img.swapaxes(1, 0)\n        img = img[::-1, ...]\n        img = img.swapaxes(0, 1)\n    return img\n\n\ndef load_image(img_file, target_size):\n    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n\n\ndef normalize_labels(labels):\n    labels_np = np.array(labels)\n    return labels_np / labels_np.sum()\n\n\ndef calc_mean_score(score_dist):\n    score_dist = normalize_labels(score_dist)\n    return (score_dist*np.arange(1, 11)).sum()\n\n\ndef ensure_dir_exists(dir):\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n"""
