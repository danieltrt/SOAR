file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\n\nlong_description = '''\nISR (Image Super-Resolution) is a library to upscale and improve the quality of low resolution images.\n\nRead the documentation at: https://idealo.github.io/image-super-resolution/\n\nISR is compatible with Python 3.6 and is distributed under the Apache 2.0 license.\n'''\n\nsetup(\n    name='ISR',\n    version='2.2.0',\n    author='Francesco Cardinale',\n    author_email='testadicardi@gmail.com',\n    description='Image Super Resolution',\n    long_description=long_description,\n    license='Apache 2.0',\n    install_requires=['imageio', 'numpy', 'tensorflow==2.0.1', 'tqdm', 'pyaml'],\n    extras_require={\n        'tests': ['pytest==4.3.0', 'pytest-cov==2.6.1'],\n        'docs': ['mkdocs==1.0.4', 'mkdocs-material==4.0.2'],\n        'gpu': ['tensorflow-gpu==2.0.0'],\n        'dev': ['bumpversion==0.5.3'],\n    },\n    classifiers=[\n        'Development Status :: 4 - Beta',\n        'Intended Audience :: Developers',\n        'Intended Audience :: Education',\n        'Intended Audience :: Science/Research',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.6',\n        'Topic :: Software Development :: Libraries',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n    ],\n    packages=find_packages(exclude=('tests',)),\n)\n"""
ISR/__init__.py,0,"b""from . import assistant\n\n__version__ = '2.2.0'\n"""
ISR/assistant.py,0,"b""import os\nfrom importlib import import_module\n\nimport numpy as np\n\nfrom ISR.utils.utils import setup, parse_args\nfrom ISR.utils.logger import get_logger\n\n\ndef _get_module(generator):\n    return import_module('ISR.models.' + generator)\n\n\ndef run(config_file, default=False, training=False, prediction=False):\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n    logger = get_logger(__name__)\n    session_type, generator, conf, dataset = setup(config_file, default, training, prediction)\n    \n    lr_patch_size = conf['session'][session_type]['patch_size']\n    scale = conf['generators'][generator]['x']\n    \n    module = _get_module(generator)\n    gen = module.make_model(conf['generators'][generator], lr_patch_size)\n    if session_type == 'prediction':\n        from ISR.predict.predictor import Predictor\n        \n        pr_h = Predictor(input_dir=conf['test_sets'][dataset])\n        pr_h.get_predictions(gen, conf['weights_paths']['generator'])\n    \n    elif session_type == 'training':\n        from ISR.train.trainer import Trainer\n        \n        hr_patch_size = lr_patch_size * scale\n        if conf['default']['feature_extractor']:\n            from ISR.models.cut_vgg19 import Cut_VGG19\n            \n            out_layers = conf['feature_extractor']['vgg19']['layers_to_extract']\n            f_ext = Cut_VGG19(patch_size=hr_patch_size, layers_to_extract=out_layers)\n        else:\n            f_ext = None\n        \n        if conf['default']['discriminator']:\n            from ISR.models.discriminator import Discriminator\n            \n            discr = Discriminator(patch_size=hr_patch_size, kernel_size=3)\n        else:\n            discr = None\n        \n        trainer = Trainer(\n            generator=gen,\n            discriminator=discr,\n            feature_extractor=f_ext,\n            lr_train_dir=conf['training_sets'][dataset]['lr_train_dir'],\n            hr_train_dir=conf['training_sets'][dataset]['hr_train_dir'],\n            lr_valid_dir=conf['training_sets'][dataset]['lr_valid_dir'],\n            hr_valid_dir=conf['training_sets'][dataset]['hr_valid_dir'],\n            learning_rate=conf['session'][session_type]['learning_rate'],\n            loss_weights=conf['loss_weights'],\n            losses=conf['losses'],\n            dataname=conf['training_sets'][dataset]['data_name'],\n            log_dirs=conf['log_dirs'],\n            weights_generator=conf['weights_paths']['generator'],\n            weights_discriminator=conf['weights_paths']['discriminator'],\n            n_validation=conf['session'][session_type]['n_validation_samples'],\n            flatness=conf['session'][session_type]['flatness'],\n            fallback_save_every_n_epochs=conf['session'][session_type][\n                'fallback_save_every_n_epochs'\n            ],\n            adam_optimizer=conf['session'][session_type]['adam_optimizer'],\n            metrics=conf['session'][session_type]['metrics'],\n        )\n        trainer.train(\n            epochs=conf['session'][session_type]['epochs'],\n            steps_per_epoch=conf['session'][session_type]['steps_per_epoch'],\n            batch_size=conf['session'][session_type]['batch_size'],\n            monitored_metrics=conf['session'][session_type]['monitored_metrics'],\n        )\n    \n    else:\n        logger.error('Invalid choice.')\n\n\nif __name__ == '__main__':\n    args = parse_args()\n    np.random.seed(1000)\n    run(\n        config_file=args['config_file'],\n        default=args['default'],\n        training=args['training'],\n        prediction=args['prediction'],\n    )\n"""
mkdocs/autogen.py,0,"b'# Heavily borrowed from the Auto-Keras project:\n# https://github.com/jhfjhfj1/autokeras/blob/master/mkdocs/autogen.py\n\nimport ast\nimport os\nimport re\n\n\ndef delete_space(parts, start, end):\n    if start > end or end >= len(parts):\n        return None\n    count = 0\n    while count < len(parts[start]):\n        if parts[start][count] == \' \':\n            count += 1\n        else:\n            break\n    return \'\\n\'.join(y for y in [x[count:] for x in parts[start: end + 1] if len(x) > count])\n\n\ndef change_args_to_dict(string):\n    if string is None:\n        return None\n    ans = []\n    strings = string.split(\'\\n\')\n    ind = 1\n    start = 0\n    while ind <= len(strings):\n        if ind < len(strings) and strings[ind].startswith("" ""):\n            ind += 1\n        else:\n            if start < ind:\n                ans.append(\'\\n\'.join(strings[start:ind]))\n            start = ind\n            ind += 1\n    d = {}\n    for line in ans:\n        if "":"" in line and len(line) > 0:\n            lines = line.split("":"")\n            d[lines[0]] = lines[1].strip()\n    return d\n\n\ndef remove_next_line(comments):\n    for x in comments:\n        if comments[x] is not None and \'\\n\' in comments[x]:\n            comments[x] = \' \'.join(comments[x].split(\'\\n\'))\n    return comments\n\n\ndef skip_space_line(parts, ind):\n    while ind < len(parts):\n        if re.match(r\'^\\s*$\', parts[ind]):\n            ind += 1\n        else:\n            break\n    return ind\n\n\n# check if comment is None or len(comment) == 0 return {}\ndef parse_func_string(comment):\n    if comment is None or len(comment) == 0:\n        return {}\n    comments = {}\n    paras = (\'Args\', \'Attributes\', \'Methods\', \'Returns\', \'Raises\')\n    comment_parts = [\n        \'short_description\',\n        \'long_description\',\n        \'Args\',\n        \'Attributes\',\n        \'Methods\',\n        \'Returns\',\n        \'Raises\',\n    ]\n    for x in comment_parts:\n        comments[x] = None\n    \n    parts = re.split(r\'\\n\', comment)\n    ind = 1\n    while ind < len(parts):\n        if re.match(r\'^\\s*$\', parts[ind]):\n            break\n        else:\n            ind += 1\n    \n    comments[\'short_description\'] = \'\\n\'.join(\n        [\'\\n\'.join(re.split(\'\\n\\s+\', x.strip())) for x in parts[0:ind]]\n    ).strip(\':\\n\\t \')\n    ind = skip_space_line(parts, ind)\n    \n    start = ind\n    while ind < len(parts):\n        if parts[ind].strip().startswith(paras):\n            break\n        else:\n            ind += 1\n    long_description = \'\\n\'.join(\n        [\'\\n\'.join(re.split(\'\\n\\s+\', x.strip())) for x in parts[start:ind]]\n    ).strip(\':\\n\\t \')\n    comments[\'long_description\'] = long_description\n    \n    ind = skip_space_line(paras, ind)\n    while ind < len(parts):\n        if parts[ind].strip().startswith(paras):\n            start = ind\n            start_with = parts[ind].strip()\n            ind += 1\n            while ind < len(parts):\n                if parts[ind].strip().startswith(paras):\n                    break\n                else:\n                    ind += 1\n            part = delete_space(parts, start + 1, ind - 1)\n            if start_with.startswith(paras[0]):\n                comments[paras[0]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[1]):\n                comments[paras[1]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[2]):\n                comments[paras[2]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[3]):\n                comments[paras[3]] = change_args_to_dict(part)\n            elif start_with.startswith(paras[4]):\n                comments[paras[4]] = part\n            ind = skip_space_line(parts, ind)\n        else:\n            ind += 1\n    \n    remove_next_line(comments)\n    return comments\n\n\ndef md_parse_line_break(comment):\n    comment = comment.replace(\'  \', \'\\n\\n\')\n    return comment.replace(\' - \', \'\\n\\n- \')\n\n\ndef to_md(comment_dict):\n    doc = \'\'\n    if \'short_description\' in comment_dict:\n        doc += comment_dict[\'short_description\']\n        doc += \'\\n\\n\'\n    \n    if \'long_description\' in comment_dict:\n        doc += md_parse_line_break(comment_dict[\'long_description\'])\n        doc += \'\\n\'\n    \n    if \'Args\' in comment_dict and comment_dict[\'Args\'] is not None:\n        doc += \'##### Args\\n\'\n        for arg, des in comment_dict[\'Args\'].items():\n            doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n    \n    if \'Attributes\' in comment_dict and comment_dict[\'Attributes\'] is not None:\n        doc += \'##### Attributes\\n\'\n        for arg, des in comment_dict[\'Attributes\'].items():\n            doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n    \n    if \'Methods\' in comment_dict and comment_dict[\'Methods\'] is not None:\n        doc += \'##### Methods\\n\'\n        for arg, des in comment_dict[\'Methods\'].items():\n            doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n    \n    if \'Returns\' in comment_dict and comment_dict[\'Returns\'] is not None:\n        doc += \'##### Returns\\n\'\n        if isinstance(comment_dict[\'Returns\'], str):\n            doc += comment_dict[\'Returns\']\n            doc += \'\\n\'\n        else:\n            for arg, des in comment_dict[\'Returns\'].items():\n                doc += \'* **\' + arg + \'**: \' + des + \'\\n\\n\'\n    return doc\n\n\ndef parse_func_args(function):\n    args = [a.arg for a in function.args.args if a.arg != \'self\']\n    kwargs = []\n    if function.args.kwarg:\n        kwargs = [\'**\' + function.args.kwarg.arg]\n    \n    return \'(\' + \', \'.join(args + kwargs) + \')\'\n\n\ndef get_func_comments(function_definitions):\n    doc = \'\'\n    for f in function_definitions:\n        temp_str = to_md(parse_func_string(ast.get_docstring(f)))\n        doc += \'\'.join(\n            [\n                \'### \',\n                f.name.replace(\'_\', \'\\\\_\'),\n                \'\\n\',\n                \'```python\',\n                \'\\n\',\n                \'def \',\n                f.name,\n                parse_func_args(f),\n                \'\\n\',\n                \'```\',\n                \'\\n\',\n                temp_str,\n                \'\\n\',\n            ]\n        )\n    \n    return doc\n\n\ndef get_comments_str(file_name):\n    with open(file_name) as fd:\n        file_contents = fd.read()\n    module = ast.parse(file_contents)\n    \n    function_definitions = [node for node in module.body if\n                            isinstance(node, ast.FunctionDef) and (node.name[0] != \'_\' or node.name[:2] == \'__\')]\n    \n    doc = get_func_comments(function_definitions)\n    \n    class_definitions = [node for node in module.body if isinstance(node, ast.ClassDef)]\n    for class_def in class_definitions:\n        temp_str = to_md(parse_func_string(ast.get_docstring(class_def)))\n        \n        # excludes private methods (start with \'_\')\n        method_definitions = [\n            node\n            for node in class_def.body\n            if isinstance(node, ast.FunctionDef) and (node.name[0] != \'_\' or node.name[:2] == \'__\')\n        ]\n        \n        temp_str += get_func_comments(method_definitions)\n        doc += \'## class \' + class_def.name + \'\\n\' + temp_str\n    return doc\n\n\ndef extract_comments(directory):\n    for parent, dir_names, file_names in os.walk(directory):\n        for file_name in file_names:\n            if os.path.splitext(file_name)[1] == \'.py\' and file_name != \'__init__.py\':\n                # with open\n                doc = get_comments_str(os.path.join(parent, file_name))\n                directory_out = os.path.join(\'docs\', parent.replace(directory, \'\'))\n                if not os.path.exists(directory_out):\n                    os.makedirs(directory_out)\n                \n                output_file = open(os.path.join(directory_out, file_name[:-3] + \'.md\'), \'w\')\n                output_file.write(doc)\n                output_file.close()\n\n\nextract_comments(\'../ISR/\')\n'"
ISR/models/__init__.py,0,b'from .cut_vgg19 import Cut_VGG19\nfrom .discriminator import Discriminator\nfrom .rdn import RDN\nfrom .rrdn import RRDN\n'
ISR/models/cut_vgg19.py,0,"b'from tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\n\nfrom ISR.utils.logger import get_logger\n\n\nclass Cut_VGG19:\n    """"""\n    Class object that fetches keras\' VGG19 model trained on the imagenet dataset\n    and declares <layers_to_extract> as output layers. Used as feature extractor\n    for the perceptual loss function.\n\n    Args:\n        layers_to_extract: list of layers to be declared as output layers.\n        patch_size: integer, defines the size of the input (patch_size x patch_size).\n\n    Attributes:\n        loss_model: multi-output vgg architecture with <layers_to_extract> as output layers.\n    """"""\n    \n    def __init__(self, patch_size, layers_to_extract):\n        self.patch_size = patch_size\n        self.input_shape = (patch_size,) * 2 + (3,)\n        self.layers_to_extract = layers_to_extract\n        self.logger = get_logger(__name__)\n        \n        if len(self.layers_to_extract) > 0:\n            self._cut_vgg()\n        else:\n            self.logger.error(\'Invalid VGG instantiation: extracted layer must be > 0\')\n            raise ValueError(\'Invalid VGG instantiation: extracted layer must be > 0\')\n    \n    def _cut_vgg(self):\n        """"""\n        Loads pre-trained VGG, declares as output the intermediate\n        layers selected by self.layers_to_extract.\n        """"""\n        \n        vgg = VGG19(weights=\'imagenet\', include_top=False, input_shape=self.input_shape)\n        vgg.trainable = False\n        outputs = [vgg.layers[i].output for i in self.layers_to_extract]\n        self.model = Model([vgg.input], outputs)\n        self.model._name = \'feature_extractor\'\n        self.name = \'vgg19\'  # used in weights naming\n'"
ISR/models/discriminator.py,0,"b'from tensorflow.keras.layers import Input, Activation, Dense, Conv2D, BatchNormalization, \\\n    LeakyReLU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n\nclass Discriminator:\n    """"""\n    Implementation of the discriminator network for the adversarial\n    component of the perceptual loss.\n\n    Args:\n        patch_size: integer, determines input size as (patch_size, patch_size, 3).\n        kernel_size: size of the kernel in the conv blocks.\n\n    Attributes:\n        model: Keras model.\n        name: name used to identify what discriminator is used during GANs training.\n        model._name: identifies this network as the discriminator network\n            in the compound model built by the trainer class.\n        block_param: dictionary, determines the number of filters and the strides for each\n            conv block.\n\n    """"""\n    \n    def __init__(self, patch_size, kernel_size=3):\n        self.patch_size = patch_size\n        self.kernel_size = kernel_size\n        self.block_param = {}\n        self.block_param[\'filters\'] = (64, 128, 128, 256, 256, 512, 512)\n        self.block_param[\'strides\'] = (2, 1, 2, 1, 1, 1, 1)\n        self.block_num = len(self.block_param[\'filters\'])\n        self.model = self._build_disciminator()\n        optimizer = Adam(0.0002, 0.5)\n        self.model.compile(loss=\'binary_crossentropy\', optimizer=optimizer, metrics=[\'accuracy\'])\n        self.model._name = \'discriminator\'\n        self.name = \'srgan-large\'\n    \n    def _conv_block(self, input, filters, strides, batch_norm=True, count=None):\n        """""" Convolutional layer + Leaky ReLU + conditional BN. """"""\n        \n        x = Conv2D(\n            filters,\n            kernel_size=self.kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=\'Conv_{}\'.format(count),\n        )(input)\n        x = LeakyReLU(alpha=0.2)(x)\n        if batch_norm:\n            x = BatchNormalization(momentum=0.8)(x)\n        return x\n    \n    def _build_disciminator(self):\n        """""" Puts the discriminator\'s layers together. """"""\n        \n        HR = Input(shape=(self.patch_size, self.patch_size, 3))\n        x = self._conv_block(HR, filters=64, strides=1, batch_norm=False, count=1)\n        for i in range(self.block_num):\n            x = self._conv_block(\n                x,\n                filters=self.block_param[\'filters\'][i],\n                strides=self.block_param[\'strides\'][i],\n                count=i + 2,\n            )\n        x = Dense(self.block_param[\'filters\'][-1] * 2, name=\'Dense_1024\')(x)\n        x = LeakyReLU(alpha=0.2)(x)\n        # x = Flatten()(x)\n        x = Dense(1, name=\'Dense_last\')(x)\n        HR_v_SR = Activation(\'sigmoid\')(x)\n        \n        discriminator = Model(inputs=HR, outputs=HR_v_SR)\n        return discriminator\n'"
ISR/models/imagemodel.py,0,"b'import numpy as np\n\nfrom ISR.utils.image_processing import (\n    process_array,\n    process_output,\n    split_image_into_overlapping_patches,\n    stich_together,\n)\n\n\nclass ImageModel:\n    """"""ISR models parent class.\n\n    Contains functions that are common across the super-scaling models.\n    """"""\n    \n    def predict(self, input_image_array, by_patch_of_size=None, batch_size=10, padding_size=2):\n        """"""\n        Processes the image array into a suitable format\n        and transforms the network output in a suitable image format.\n\n        Args:\n            input_image_array: input image array.\n            by_patch_of_size: for large image inference. Splits the image into\n                patches of the given size.\n            padding_size: for large image inference. Padding between the patches.\n                Increase the value if there is seamlines.\n            batch_size: for large image inferce. Number of patches processed at a time.\n                Keep low and increase by_patch_of_size instead.\n        Returns:\n            sr_img: image output.\n        """"""\n        \n        if by_patch_of_size:\n            lr_img = process_array(input_image_array, expand=False)\n            patches, p_shape = split_image_into_overlapping_patches(\n                lr_img, patch_size=by_patch_of_size, padding_size=padding_size\n            )\n            # return patches\n            for i in range(0, len(patches), batch_size):\n                batch = self.model.predict(patches[i: i + batch_size])\n                if i == 0:\n                    collect = batch\n                else:\n                    collect = np.append(collect, batch, axis=0)\n            \n            scale = self.scale\n            padded_size_scaled = tuple(np.multiply(p_shape[0:2], scale)) + (3,)\n            scaled_image_shape = tuple(np.multiply(input_image_array.shape[0:2], scale)) + (3,)\n            sr_img = stich_together(\n                collect,\n                padded_image_shape=padded_size_scaled,\n                target_shape=scaled_image_shape,\n                padding_size=padding_size * scale,\n            )\n        \n        else:\n            lr_img = process_array(input_image_array)\n            sr_img = self.model.predict(lr_img)[0]\n        \n        sr_img = process_output(sr_img)\n        return sr_img\n'"
ISR/models/rdn.py,2,"b'import tensorflow as tf\nfrom tensorflow.keras.initializers import RandomUniform\nfrom tensorflow.keras.layers import concatenate, Input, Activation, Add, Conv2D, Lambda, UpSampling2D\nfrom tensorflow.keras.models import Model\n\nfrom ISR.models.imagemodel import ImageModel\n\nWEIGHTS_URLS = {\n    \'psnr-large\': {\n        \'arch_params\': {\'C\': 6, \'D\': 20, \'G\': 64, \'G0\': 64, \'x\': 2},\n        \'url\': \'https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C6-D20-G64-G064-x2/PSNR-driven/rdn-C6-D20-G64-G064-x2_PSNR_epoch086.hdf5\',\n        \'name\': \'rdn-C6-D20-G64-G064-x2_PSNR_epoch086.hdf5\'\n    },\n    \'psnr-small\': {\n        \'arch_params\': {\'C\': 3, \'D\': 10, \'G\': 64, \'G0\': 64, \'x\': 2},\n        \'url\': \'https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C3-D10-G64-G064-x2/PSNR-driven/rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5\',\n        \'name\': \'rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5\',\n    },\n    \'noise-cancel\': {\n        \'arch_params\': {\'C\': 6, \'D\': 20, \'G\': 64, \'G0\': 64, \'x\': 2},\n        \'url\': \'https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C6-D20-G64-G064-x2/ArtefactCancelling/rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5\',\n        \'name\': \'rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5\',\n    }\n}\n\n\ndef make_model(arch_params, patch_size):\n    """""" Returns the model.\n\n    Used to select the model.\n    """"""\n    \n    return RDN(arch_params, patch_size)\n\n\ndef get_network(weights):\n    if weights in WEIGHTS_URLS.keys():\n        arch_params = WEIGHTS_URLS[weights][\'arch_params\']\n        url = WEIGHTS_URLS[weights][\'url\']\n        name = WEIGHTS_URLS[weights][\'name\']\n    else:\n        raise ValueError(\'Available RDN network weights: {}\'.format(list(WEIGHTS_URLS.keys())))\n    c_dim = 3\n    kernel_size = 3\n    upscaling = \'ups\'\n    return arch_params, c_dim, kernel_size, upscaling, url, name\n\n\nclass RDN(ImageModel):\n    """"""Implementation of the Residual Dense Network for image super-scaling.\n\n    The network is the one described in https://arxiv.org/abs/1802.08797 (Zhang et al. 2018).\n\n    Args:\n        arch_params: dictionary, contains the network parameters C, D, G, G0, x.\n        patch_size: integer or None, determines the input size. Only needed at\n            training time, for prediction is set to None.\n        c_dim: integer, number of channels of the input image.\n        kernel_size: integer, common kernel size for convolutions.\n        upscaling: string, \'ups\' or \'shuffle\', determines which implementation\n            of the upscaling layer to use.\n        init_extreme_val: extreme values for the RandomUniform initializer.\n        weights: string, if not empty, download and load pre-trained weights.\n            Overrides other parameters.\n\n    Attributes:\n        C: integer, number of conv layer inside each residual dense blocks (RDB).\n        D: integer, number of RDBs.\n        G: integer, number of convolution output filters inside the RDBs.\n        G0: integer, number of output filters of each RDB.\n        x: integer, the scaling factor.\n        model: Keras model of the RDN.\n        name: name used to identify what upscaling network is used during training.\n        model._name: identifies this network as the generator network\n            in the compound model built by the trainer class.\n    """"""\n    \n    def __init__(\n            self,\n            arch_params={},\n            patch_size=None,\n            c_dim=3,\n            kernel_size=3,\n            upscaling=\'ups\',\n            init_extreme_val=0.05,\n            weights=\'\'\n    ):\n        if weights:\n            arch_params, c_dim, kernel_size, upscaling, url, fname = get_network(weights)\n        \n        self.params = arch_params\n        self.C = self.params[\'C\']\n        self.D = self.params[\'D\']\n        self.G = self.params[\'G\']\n        self.G0 = self.params[\'G0\']\n        self.scale = self.params[\'x\']\n        self.patch_size = patch_size\n        self.c_dim = c_dim\n        self.kernel_size = kernel_size\n        self.upscaling = upscaling\n        self.initializer = RandomUniform(\n            minval=-init_extreme_val, maxval=init_extreme_val, seed=None\n        )\n        self.model = self._build_rdn()\n        self.model._name = \'generator\'\n        self.name = \'rdn\'\n        if weights:\n            weights_path = tf.keras.utils.get_file(fname=fname, origin=url)\n            self.model.load_weights(weights_path)\n    \n    def _upsampling_block(self, input_layer):\n        """""" Upsampling block for old weights. """"""\n        \n        x = Conv2D(\n            self.c_dim * self.scale ** 2,\n            kernel_size=3,\n            padding=\'same\',\n            name=\'UPN3\',\n            kernel_initializer=self.initializer,\n        )(input_layer)\n        return UpSampling2D(size=self.scale, name=\'UPsample\')(x)\n    \n    def _pixel_shuffle(self, input_layer):\n        """""" PixelShuffle implementation of the upscaling layer. """"""\n        \n        x = Conv2D(\n            self.c_dim * self.scale ** 2,\n            kernel_size=3,\n            padding=\'same\',\n            name=\'UPN3\',\n            kernel_initializer=self.initializer,\n        )(input_layer)\n        return Lambda(\n            lambda x: tf.nn.depth_to_space(x, block_size=self.scale, data_format=\'NHWC\'),\n            name=\'PixelShuffle\',\n        )(x)\n    \n    def _UPN(self, input_layer):\n        """""" Upscaling layers. With old weights use _upsampling_block instead of _pixel_shuffle. """"""\n        \n        x = Conv2D(\n            64,\n            kernel_size=5,\n            strides=1,\n            padding=\'same\',\n            name=\'UPN1\',\n            kernel_initializer=self.initializer,\n        )(input_layer)\n        x = Activation(\'relu\', name=\'UPN1_Relu\')(x)\n        x = Conv2D(\n            32, kernel_size=3, padding=\'same\', name=\'UPN2\', kernel_initializer=self.initializer\n        )(x)\n        x = Activation(\'relu\', name=\'UPN2_Relu\')(x)\n        if self.upscaling == \'shuffle\':\n            return self._pixel_shuffle(x)\n        elif self.upscaling == \'ups\':\n            return self._upsampling_block(x)\n        else:\n            raise ValueError(\'Invalid choice of upscaling layer.\')\n    \n    def _RDBs(self, input_layer):\n        """"""RDBs blocks.\n\n        Args:\n            input_layer: input layer to the RDB blocks (e.g. the second convolutional layer F_0).\n\n        Returns:\n            concatenation of RDBs output feature maps with G0 feature maps.\n        """"""\n        rdb_concat = list()\n        rdb_in = input_layer\n        for d in range(1, self.D + 1):\n            x = rdb_in\n            for c in range(1, self.C + 1):\n                F_dc = Conv2D(\n                    self.G,\n                    kernel_size=self.kernel_size,\n                    padding=\'same\',\n                    kernel_initializer=self.initializer,\n                    name=\'F_%d_%d\' % (d, c),\n                )(x)\n                F_dc = Activation(\'relu\', name=\'F_%d_%d_Relu\' % (d, c))(F_dc)\n                # concatenate input and output of ConvRelu block\n                # x = [input_layer,F_11(input_layer),F_12([input_layer,F_11(input_layer)]), F_13..]\n                x = concatenate([x, F_dc], axis=3, name=\'RDB_Concat_%d_%d\' % (d, c))\n            # 1x1 convolution (Local Feature Fusion)\n            x = Conv2D(\n                self.G0, kernel_size=1, kernel_initializer=self.initializer, name=\'LFF_%d\' % (d)\n            )(x)\n            # Local Residual Learning F_{i,LF} + F_{i-1}\n            rdb_in = Add(name=\'LRL_%d\' % (d))([x, rdb_in])\n            rdb_concat.append(rdb_in)\n        \n        assert len(rdb_concat) == self.D\n        \n        return concatenate(rdb_concat, axis=3, name=\'LRLs_Concat\')\n    \n    def _build_rdn(self):\n        LR_input = Input(shape=(self.patch_size, self.patch_size, 3), name=\'LR\')\n        F_m1 = Conv2D(\n            self.G0,\n            kernel_size=self.kernel_size,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'F_m1\',\n        )(LR_input)\n        F_0 = Conv2D(\n            self.G0,\n            kernel_size=self.kernel_size,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'F_0\',\n        )(F_m1)\n        FD = self._RDBs(F_0)\n        # Global Feature Fusion\n        # 1x1 Conv of concat RDB layers -> G0 feature maps\n        GFF1 = Conv2D(\n            self.G0,\n            kernel_size=1,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'GFF_1\',\n        )(FD)\n        GFF2 = Conv2D(\n            self.G0,\n            kernel_size=self.kernel_size,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'GFF_2\',\n        )(GFF1)\n        # Global Residual Learning for Dense Features\n        FDF = Add(name=\'FDF\')([GFF2, F_m1])\n        # Upscaling\n        FU = self._UPN(FDF)\n        # Compose SR image\n        SR = Conv2D(\n            self.c_dim,\n            kernel_size=self.kernel_size,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'SR\',\n        )(FU)\n        \n        return Model(inputs=LR_input, outputs=SR)\n'"
ISR/models/rrdn.py,2,"b'import tensorflow as tf\nfrom tensorflow.keras.initializers import RandomUniform\nfrom tensorflow.keras.layers import concatenate, Input, Activation, Add, Conv2D, Lambda\nfrom tensorflow.keras.models import Model\n\nfrom ISR.models.imagemodel import ImageModel\n\nWEIGHTS_URLS = {\n    \'gans\': {\n        \'arch_params\': {\'C\': 4, \'D\': 3, \'G\': 32, \'G0\': 32, \'x\': 4, \'T\': 10},\n        \'url\': \'https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rrdn-C4-D3-G32-G032-T10-x4-GANS/rrdn-C4-D3-G32-G032-T10-x4_epoch299.hdf5\',\n        \'name\': \'rrdn-C4-D3-G32-G032-T10-x4_epoch299.hdf5\',\n    },\n}\n\n\ndef make_model(arch_params, patch_size):\n    """""" Returns the model.\n\n    Used to select the model.\n    """"""\n    \n    return RRDN(arch_params, patch_size)\n\n\ndef get_network(weights):\n    if weights in WEIGHTS_URLS.keys():\n        arch_params = WEIGHTS_URLS[weights][\'arch_params\']\n        url = WEIGHTS_URLS[weights][\'url\']\n        name = WEIGHTS_URLS[weights][\'name\']\n    else:\n        raise ValueError(\'Available RRDN network weights: {}\'.format(list(WEIGHTS_URLS.keys())))\n    c_dim = 3\n    kernel_size = 3\n    return arch_params, c_dim, kernel_size, url, name\n\n\nclass RRDN(ImageModel):\n    """"""Implementation of the Residual in Residual Dense Network for image super-scaling.\n\n    The network is the one described in https://arxiv.org/abs/1809.00219 (Wang et al. 2018).\n\n    Args:\n        arch_params: dictionary, contains the network parameters C, D, G, G0, T, x.\n        patch_size: integer or None, determines the input size. Only needed at\n            training time, for prediction is set to None.\n        beta: float <= 1, scaling parameter for the residual connections.\n        c_dim: integer, number of channels of the input image.\n        kernel_size: integer, common kernel size for convolutions.\n        upscaling: string, \'ups\' or \'shuffle\', determines which implementation\n            of the upscaling layer to use.\n        init_val: extreme values for the RandomUniform initializer.\n        weights: string, if not empty, download and load pre-trained weights.\n            Overrides other parameters.\n\n    Attributes:\n        C: integer, number of conv layer inside each residual dense blocks (RDB).\n        D: integer, number of RDBs inside each Residual in Residual Dense Block (RRDB).\n        T: integer, number or RRDBs.\n        G: integer, number of convolution output filters inside the RDBs.\n        G0: integer, number of output filters of each RDB.\n        x: integer, the scaling factor.\n        model: Keras model of the RRDN.\n        name: name used to identify what upscaling network is used during training.\n        model._name: identifies this network as the generator network\n            in the compound model built by the trainer class.\n    """"""\n    \n    def __init__(\n            self, arch_params={}, patch_size=None, beta=0.2, c_dim=3, kernel_size=3, init_val=0.05, weights=\'\'\n    ):\n        if weights:\n            arch_params, c_dim, kernel_size, url, fname = get_network(weights)\n        \n        self.params = arch_params\n        self.beta = beta\n        self.c_dim = c_dim\n        self.C = self.params[\'C\']\n        self.D = self.params[\'D\']\n        self.G = self.params[\'G\']\n        self.G0 = self.params[\'G0\']\n        self.T = self.params[\'T\']\n        self.scale = self.params[\'x\']\n        self.initializer = RandomUniform(minval=-init_val, maxval=init_val, seed=None)\n        self.kernel_size = kernel_size\n        self.patch_size = patch_size\n        self.model = self._build_rdn()\n        self.model._name = \'generator\'\n        self.name = \'rrdn\'\n        if weights:\n            weights_path = tf.keras.utils.get_file(fname=fname, origin=url)\n            self.model.load_weights(weights_path)\n    \n    def _dense_block(self, input_layer, d, t):\n        """"""\n        Implementation of the (Residual) Dense Block as in the paper\n        Residual Dense Network for Image Super-Resolution (Zhang et al. 2018).\n\n        Residuals are incorporated in the RRDB.\n        d is an integer only used for naming. (d-th block)\n        """"""\n        \n        x = input_layer\n        for c in range(1, self.C + 1):\n            F_dc = Conv2D(\n                self.G,\n                kernel_size=self.kernel_size,\n                padding=\'same\',\n                kernel_initializer=self.initializer,\n                name=\'F_%d_%d_%d\' % (t, d, c),\n            )(x)\n            F_dc = Activation(\'relu\', name=\'F_%d_%d_%d_Relu\' % (t, d, c))(F_dc)\n            x = concatenate([x, F_dc], axis=3, name=\'RDB_Concat_%d_%d_%d\' % (t, d, c))\n        \n        # DIFFERENCE: in RDN a kernel size of 1 instead of 3 is used here\n        x = Conv2D(\n            self.G0,\n            kernel_size=3,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'LFF_%d_%d\' % (t, d),\n        )(x)\n        return x\n    \n    def _RRDB(self, input_layer, t):\n        """"""Residual in Residual Dense Block.\n\n        t is integer, for naming of RRDB.\n        beta is scalar.\n        """"""\n        \n        # SUGGESTION: MAKE BETA LEARNABLE\n        x = input_layer\n        \n        for d in range(1, self.D + 1):\n            LFF = self._dense_block(x, d, t)\n            LFF_beta = Lambda(lambda x: x * self.beta)(LFF)\n            x = Add(name=\'LRL_%d_%d\' % (t, d))([x, LFF_beta])\n        x = Lambda(lambda x: x * self.beta)(x)\n        x = Add(name=\'RRDB_%d_out\' % (t))([input_layer, x])\n        return x\n    \n    def _pixel_shuffle(self, input_layer):\n        """""" PixelShuffle implementation of the upscaling part. """"""\n        \n        x = Conv2D(\n            self.c_dim * self.scale ** 2,\n            kernel_size=3,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'PreShuffle\',\n        )(input_layer)\n        return Lambda(\n            lambda x: tf.nn.depth_to_space(x, block_size=self.scale, data_format=\'NHWC\'),\n            name=\'PixelShuffle\',\n        )(x)\n    \n    def _build_rdn(self):\n        LR_input = Input(shape=(self.patch_size, self.patch_size, 3), name=\'LR_input\')\n        pre_blocks = Conv2D(\n            self.G0,\n            kernel_size=self.kernel_size,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'Pre_blocks_conv\',\n        )(LR_input)\n        # DIFFERENCE: in RDN an extra convolution is present here\n        for t in range(1, self.T + 1):\n            if t == 1:\n                x = self._RRDB(pre_blocks, t)\n            else:\n                x = self._RRDB(x, t)\n        # DIFFERENCE: in RDN a conv with kernel size of 1 after a concat operation is used here\n        post_blocks = Conv2D(\n            self.G0,\n            kernel_size=3,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'post_blocks_conv\',\n        )(x)\n        # Global Residual Learning\n        GRL = Add(name=\'GRL\')([post_blocks, pre_blocks])\n        # Upscaling\n        PS = self._pixel_shuffle(GRL)\n        # Compose SR image\n        SR = Conv2D(\n            self.c_dim,\n            kernel_size=self.kernel_size,\n            padding=\'same\',\n            kernel_initializer=self.initializer,\n            name=\'SR\',\n        )(PS)\n        return Model(inputs=LR_input, outputs=SR)\n'"
ISR/predict/__init__.py,0,b'from .predictor import Predictor\n'
ISR/predict/predictor.py,0,"b'from time import time\n\nimport imageio\nimport yaml\nimport numpy as np\nfrom pathlib import Path\n\nfrom ISR.utils.logger import get_logger\nfrom ISR.utils.utils import get_timestamp\n\n\nclass Predictor:\n    """"""The predictor class handles prediction, given an input model.\n\n    Loads the images in the input directory, executes training given a model\n    and saves the results in the output directory.\n    Can receive a path for the weights or can let the user browse through the\n    weights directory for the desired weights.\n\n    Args:\n        input_dir: string, path to the input directory.\n        output_dir: string, path to the output directory.\n        verbose: bool.\n\n    Attributes:\n        extensions: list of accepted image extensions.\n        img_ls: list of image files in input_dir.\n\n    Methods:\n        get_predictions: given a model and a string containing the weights\' path,\n            runs the predictions on the images contained in the input directory and\n            stores the results in the output directory.\n    """"""\n\n    def __init__(self, input_dir, output_dir=\'./data/output\', verbose=True):\n\n        self.input_dir = Path(input_dir)\n        self.data_name = self.input_dir.name\n        self.output_dir = Path(output_dir) / self.data_name\n        self.logger = get_logger(__name__)\n        if not verbose:\n            self.logger.setLevel(40)\n        self.extensions = (\'.jpeg\', \'.jpg\', \'.png\')  # file extensions that are admitted\n        self.img_ls = [f for f in self.input_dir.iterdir() if f.suffix in self.extensions]\n        if len(self.img_ls) < 1:\n            self.logger.error(\'No valid image files found (check config file).\')\n            raise ValueError(\'No valid image files found (check config file).\')\n        # Create results folder\n        if not self.output_dir.exists():\n            self.logger.info(\'Creating output directory:\\n{}\'.format(self.output_dir))\n            self.output_dir.mkdir(parents=True)\n\n    def _load_weights(self):\n        """""" Invokes the model\'s load weights function if any weights are provided. """"""\n        if self.weights_path is not None:\n            self.logger.info(\'Loaded weights from \\n > {}\'.format(self.weights_path))\n            # loading by name automatically excludes the vgg layers\n            self.model.model.load_weights(str(self.weights_path))\n        else:\n            self.logger.error(\'Error: Weights path not specified (check config file).\')\n            raise ValueError(\'Weights path not specified (check config file).\')\n\n        session_config_path = self.weights_path.parent / \'session_config.yml\'\n        if session_config_path.exists():\n            conf = yaml.load(session_config_path.read_text(), Loader=yaml.FullLoader)\n        else:\n            self.logger.warning(\'Could not find weights training configuration\')\n            conf = {}\n        conf.update({\'pre-trained-weights\': self.weights_path.name})\n        return conf\n\n    def _make_basename(self):\n        """""" Combines generators\'s name and its architecture\'s parameters. """"""\n\n        params = [self.model.name]\n        for param in np.sort(list(self.model.params.keys())):\n            params.append(\'{g}{p}\'.format(g=param, p=self.model.params[param]))\n        return \'-\'.join(params)\n\n    def get_predictions(self, model, weights_path):\n        """""" Runs the prediction. """"""\n\n        self.model = model\n        self.weights_path = Path(weights_path)\n        weights_conf = self._load_weights()\n        out_folder = self.output_dir / self._make_basename() / get_timestamp()\n        self.logger.info(\'Results in:\\n > {}\'.format(out_folder))\n        if out_folder.exists():\n            self.logger.warning(\'Directory exists, might overwrite files\')\n        else:\n            out_folder.mkdir(parents=True)\n        if weights_conf:\n            yaml.dump(weights_conf, (out_folder / \'weights_config.yml\').open(\'w\'))\n        # Predict and store\n        for img_path in self.img_ls:\n            output_path = out_folder / img_path.name\n            self.logger.info(\'Processing file\\n > {}\'.format(img_path))\n            start = time()\n            sr_img = self._forward_pass(img_path)\n            end = time()\n            self.logger.info(\'Elapsed time: {}s\'.format(end - start))\n            self.logger.info(\'Result in: {}\'.format(output_path))\n            imageio.imwrite(output_path, sr_img)\n\n    def _forward_pass(self, file_path):\n        lr_img = imageio.imread(file_path)\n        if lr_img.shape[2] == 3:\n            sr_img = self.model.predict(lr_img)\n            return sr_img\n        else:\n            self.logger.error(\'{} is not an image with 3 channels.\'.format(file_path))\n'"
ISR/train/__init__.py,0,b'from .trainer import Trainer\n'
ISR/train/trainer.py,0,"b'from time import time\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras import backend as K\n\nfrom ISR.utils.datahandler import DataHandler\nfrom ISR.utils.train_helper import TrainerHelper\nfrom ISR.utils.metrics import PSNR\nfrom ISR.utils.metrics import PSNR_Y\nfrom ISR.utils.logger import get_logger\nfrom ISR.utils.utils import check_parameter_keys\n\n\nclass Trainer:\n    """"""Class object to setup and carry the training.\n\n    Takes as input a generator that produces SR images.\n    Conditionally, also a discriminator network and a feature extractor\n        to build the components of the perceptual loss.\n    Compiles the model(s) and trains in a GANS fashion if a discriminator is provided, otherwise\n    carries a regular ISR training.\n\n    Args:\n        generator: Keras model, the super-scaling, or generator, network.\n        discriminator: Keras model, the discriminator network for the adversarial\n            component of the perceptual loss.\n        feature_extractor: Keras model, feature extractor network for the deep features\n            component of perceptual loss function.\n        lr_train_dir: path to the directory containing the Low-Res images for training.\n        hr_train_dir: path to the directory containing the High-Res images for training.\n        lr_valid_dir: path to the directory containing the Low-Res images for validation.\n        hr_valid_dir: path to the directory containing the High-Res images for validation.\n        learning_rate: float.\n        loss_weights: dictionary, use to weigh the components of the loss function.\n            Contains \'generator\' for the generator loss component, and can contain \'discriminator\' and \'feature_extractor\'\n            for the discriminator and deep features components respectively.\n        logs_dir: path to the directory where the tensorboard logs are saved.\n        weights_dir: path to the directory where the weights are saved.\n        dataname: string, used to identify what dataset is used for the training session.\n        weights_generator: path to the pre-trained generator\'s weights, for transfer learning.\n        weights_discriminator: path to the pre-trained discriminator\'s weights, for transfer learning.\n        n_validation:integer, number of validation samples used at training from the validation set.\n        flatness: dictionary. Determines determines the \'flatness\' threshold level for the training patches.\n            See the TrainerHelper class for more details.\n        lr_decay_frequency: integer, every how many epochs the learning rate is reduced.\n        lr_decay_factor: 0 < float <1, learning rate reduction multiplicative factor.\n\n    Methods:\n        train: combines the networks and triggers training with the specified settings.\n\n    """"""\n\n    def __init__(\n            self,\n            generator,\n            discriminator,\n            feature_extractor,\n            lr_train_dir,\n            hr_train_dir,\n            lr_valid_dir,\n            hr_valid_dir,\n            loss_weights={\'generator\': 1.0, \'discriminator\': 0.003, \'feature_extractor\': 1 / 12},\n            log_dirs={\'logs\': \'logs\', \'weights\': \'weights\'},\n            fallback_save_every_n_epochs=2,\n            dataname=None,\n            weights_generator=None,\n            weights_discriminator=None,\n            n_validation=None,\n            flatness={\'min\': 0.0, \'increase_frequency\': None, \'increase\': 0.0, \'max\': 0.0},\n            learning_rate={\'initial_value\': 0.0004, \'decay_frequency\': 100, \'decay_factor\': 0.5},\n            adam_optimizer={\'beta1\': 0.9, \'beta2\': 0.999, \'epsilon\': None},\n            losses={\n                \'generator\': \'mae\',\n                \'discriminator\': \'binary_crossentropy\',\n                \'feature_extractor\': \'mse\',\n            },\n            metrics={\'generator\': \'PSNR_Y\'},\n    ):\n        self.generator = generator\n        self.discriminator = discriminator\n        self.feature_extractor = feature_extractor\n        self.scale = generator.scale\n        self.lr_patch_size = generator.patch_size\n        self.learning_rate = learning_rate\n        self.loss_weights = loss_weights\n        self.weights_generator = weights_generator\n        self.weights_discriminator = weights_discriminator\n        self.adam_optimizer = adam_optimizer\n        self.dataname = dataname\n        self.flatness = flatness\n        self.n_validation = n_validation\n        self.losses = losses\n        self.log_dirs = log_dirs\n        self.metrics = metrics\n        if self.metrics[\'generator\'] == \'PSNR_Y\':\n            self.metrics[\'generator\'] = PSNR_Y\n        elif self.metrics[\'generator\'] == \'PSNR\':\n            self.metrics[\'generator\'] = PSNR\n        self._parameters_sanity_check()\n        self.model = self._combine_networks()\n\n        self.settings = {}\n        self.settings[\'training_parameters\'] = locals()\n        self.settings[\'training_parameters\'][\'lr_patch_size\'] = self.lr_patch_size\n        self.settings = self.update_training_config(self.settings)\n\n        self.logger = get_logger(__name__)\n\n        self.helper = TrainerHelper(\n            generator=self.generator,\n            weights_dir=log_dirs[\'weights\'],\n            logs_dir=log_dirs[\'logs\'],\n            lr_train_dir=lr_train_dir,\n            feature_extractor=self.feature_extractor,\n            discriminator=self.discriminator,\n            dataname=dataname,\n            weights_generator=self.weights_generator,\n            weights_discriminator=self.weights_discriminator,\n            fallback_save_every_n_epochs=fallback_save_every_n_epochs,\n        )\n\n        self.train_dh = DataHandler(\n            lr_dir=lr_train_dir,\n            hr_dir=hr_train_dir,\n            patch_size=self.lr_patch_size,\n            scale=self.scale,\n            n_validation_samples=None,\n        )\n        self.valid_dh = DataHandler(\n            lr_dir=lr_valid_dir,\n            hr_dir=hr_valid_dir,\n            patch_size=self.lr_patch_size,\n            scale=self.scale,\n            n_validation_samples=n_validation,\n        )\n\n    def _parameters_sanity_check(self):\n        """""" Parameteres sanity check. """"""\n\n        if self.discriminator:\n            assert self.lr_patch_size * self.scale == self.discriminator.patch_size\n            self.adam_optimizer\n        if self.feature_extractor:\n            assert self.lr_patch_size * self.scale == self.feature_extractor.patch_size\n\n        check_parameter_keys(\n            self.learning_rate,\n            needed_keys=[\'initial_value\'],\n            optional_keys=[\'decay_factor\', \'decay_frequency\'],\n            default_value=None,\n        )\n        check_parameter_keys(\n            self.flatness,\n            needed_keys=[],\n            optional_keys=[\'min\', \'increase_frequency\', \'increase\', \'max\'],\n            default_value=0.0,\n        )\n        check_parameter_keys(\n            self.adam_optimizer,\n            needed_keys=[\'beta1\', \'beta2\'],\n            optional_keys=[\'epsilon\'],\n            default_value=None,\n        )\n        check_parameter_keys(self.log_dirs, needed_keys=[\'logs\', \'weights\'])\n\n    def _combine_networks(self):\n        """"""\n        Constructs the combined model which contains the generator network,\n        as well as discriminator and geature extractor, if any are defined.\n        """"""\n\n        lr = Input(shape=(self.lr_patch_size,) * 2 + (3,))\n        sr = self.generator.model(lr)\n        outputs = [sr]\n        losses = [self.losses[\'generator\']]\n        loss_weights = [self.loss_weights[\'generator\']]\n\n        if self.discriminator:\n            self.discriminator.model.trainable = False\n            validity = self.discriminator.model(sr)\n            outputs.append(validity)\n            losses.append(self.losses[\'discriminator\'])\n            loss_weights.append(self.loss_weights[\'discriminator\'])\n        if self.feature_extractor:\n            self.feature_extractor.model.trainable = False\n            sr_feats = self.feature_extractor.model(sr)\n            outputs.extend([*sr_feats])\n            losses.extend([self.losses[\'feature_extractor\']] * len(sr_feats))\n            loss_weights.extend(\n                [self.loss_weights[\'feature_extractor\'] / len(sr_feats)] * len(sr_feats)\n            )\n        combined = Model(inputs=lr, outputs=outputs)\n        # https://stackoverflow.com/questions/42327543/adam-optimizer-goes-haywire-after-200k-batches-training-loss-grows\n        optimizer = Adam(\n            beta_1=self.adam_optimizer[\'beta1\'],\n            beta_2=self.adam_optimizer[\'beta2\'],\n            lr=self.learning_rate[\'initial_value\'],\n            epsilon=self.adam_optimizer[\'epsilon\'],\n        )\n        combined.compile(\n            loss=losses, loss_weights=loss_weights, optimizer=optimizer, metrics=self.metrics\n        )\n        return combined\n\n    def _lr_scheduler(self, epoch):\n        """""" Scheduler for the learning rate updates. """"""\n\n        n_decays = epoch // self.learning_rate[\'decay_frequency\']\n        lr = self.learning_rate[\'initial_value\'] * (self.learning_rate[\'decay_factor\'] ** n_decays)\n        # no lr below minimum control 10e-7\n        return max(1e-7, lr)\n\n    def _flatness_scheduler(self, epoch):\n        if self.flatness[\'increase\']:\n            n_increases = epoch // self.flatness[\'increase_frequency\']\n        else:\n            return self.flatness[\'min\']\n\n        f = self.flatness[\'min\'] + n_increases * self.flatness[\'increase\']\n\n        return min(self.flatness[\'max\'], f)\n\n    def _load_weights(self):\n        """"""\n        Loads the pretrained weights from the given path, if any is provided.\n        If a discriminator is defined, does the same.\n        """"""\n\n        if self.weights_generator:\n            self.model.get_layer(\'generator\').load_weights(str(self.weights_generator))\n\n        if self.discriminator:\n            if self.weights_discriminator:\n                self.model.get_layer(\'discriminator\').load_weights(str(self.weights_discriminator))\n                self.discriminator.model.load_weights(str(self.weights_discriminator))\n\n    def _format_losses(self, prefix, losses, model_metrics):\n        """""" Creates a dictionary for tensorboard tracking. """"""\n\n        return dict(zip([prefix + m for m in model_metrics], losses))\n\n    def update_training_config(self, settings):\n        """""" Summarizes training setting. """"""\n\n        _ = settings[\'training_parameters\'].pop(\'weights_generator\')\n        _ = settings[\'training_parameters\'].pop(\'self\')\n        _ = settings[\'training_parameters\'].pop(\'generator\')\n        _ = settings[\'training_parameters\'].pop(\'discriminator\')\n        _ = settings[\'training_parameters\'].pop(\'feature_extractor\')\n        settings[\'generator\'] = {}\n        settings[\'generator\'][\'name\'] = self.generator.name\n        settings[\'generator\'][\'parameters\'] = self.generator.params\n        settings[\'generator\'][\'weights_generator\'] = self.weights_generator\n\n        _ = settings[\'training_parameters\'].pop(\'weights_discriminator\')\n        if self.discriminator:\n            settings[\'discriminator\'] = {}\n            settings[\'discriminator\'][\'name\'] = self.discriminator.name\n            settings[\'discriminator\'][\'weights_discriminator\'] = self.weights_discriminator\n        else:\n            settings[\'discriminator\'] = None\n\n        if self.discriminator:\n            settings[\'feature_extractor\'] = {}\n            settings[\'feature_extractor\'][\'name\'] = self.feature_extractor.name\n            settings[\'feature_extractor\'][\'layers\'] = self.feature_extractor.layers_to_extract\n        else:\n            settings[\'feature_extractor\'] = None\n\n        return settings\n\n    def train(self, epochs, steps_per_epoch, batch_size, monitored_metrics):\n        """"""\n        Carries on the training for the given number of epochs.\n        Sends the losses to Tensorboard.\n\n        Args:\n            epochs: how many epochs to train for.\n            steps_per_epoch: how many batches epoch.\n            batch_size: amount of images per batch.\n            monitored_metrics: dictionary, the keys are the metrics that are monitored for the weights\n                saving logic. The values are the mode that trigger the weights saving (\'min\' vs \'max\').\n        """"""\n\n        self.settings[\'training_parameters\'][\'steps_per_epoch\'] = steps_per_epoch\n        self.settings[\'training_parameters\'][\'batch_size\'] = batch_size\n        starting_epoch = self.helper.initialize_training(\n            self\n        )  # load_weights, creates folders, creates basename\n\n        self.tensorboard = TensorBoard(log_dir=str(self.helper.callback_paths[\'logs\']))\n        self.tensorboard.set_model(self.model)\n\n        # validation data\n        validation_set = self.valid_dh.get_validation_set(batch_size)\n        y_validation = [validation_set[\'hr\']]\n        if self.discriminator:\n            discr_out_shape = list(self.discriminator.model.outputs[0].shape)[1:4]\n            valid = np.ones([batch_size] + discr_out_shape)\n            fake = np.zeros([batch_size] + discr_out_shape)\n            validation_valid = np.ones([len(validation_set[\'hr\'])] + discr_out_shape)\n            y_validation.append(validation_valid)\n        if self.feature_extractor:\n            validation_feats = self.feature_extractor.model.predict(validation_set[\'hr\'])\n            y_validation.extend([*validation_feats])\n\n        for epoch in range(starting_epoch, epochs):\n            self.logger.info(\'Epoch {e}/{tot_eps}\'.format(e=epoch, tot_eps=epochs))\n            K.set_value(self.model.optimizer.lr, self._lr_scheduler(epoch=epoch))\n            self.logger.info(\'Current learning rate: {}\'.format(K.eval(self.model.optimizer.lr)))\n\n            flatness = self._flatness_scheduler(epoch)\n            if flatness:\n                self.logger.info(\'Current flatness treshold: {}\'.format(flatness))\n\n            epoch_start = time()\n            for step in tqdm(range(steps_per_epoch)):\n                batch = self.train_dh.get_batch(batch_size, flatness=flatness)\n                y_train = [batch[\'hr\']]\n                training_losses = {}\n\n                ## Discriminator training\n                if self.discriminator:\n                    sr = self.generator.model.predict(batch[\'lr\'])\n                    d_loss_real = self.discriminator.model.train_on_batch(batch[\'hr\'], valid)\n                    d_loss_fake = self.discriminator.model.train_on_batch(sr, fake)\n                    d_loss_fake = self._format_losses(\n                        \'train_d_fake_\', d_loss_fake, self.discriminator.model.metrics_names\n                    )\n                    d_loss_real = self._format_losses(\n                        \'train_d_real_\', d_loss_real, self.discriminator.model.metrics_names\n                    )\n                    training_losses.update(d_loss_real)\n                    training_losses.update(d_loss_fake)\n                    y_train.append(valid)\n\n                ## Generator training\n                if self.feature_extractor:\n                    hr_feats = self.feature_extractor.model.predict(batch[\'hr\'])\n                    y_train.extend([*hr_feats])\n\n                model_losses = self.model.train_on_batch(batch[\'lr\'], y_train)\n                model_losses = self._format_losses(\'train_\', model_losses, self.model.metrics_names)\n                training_losses.update(model_losses)\n\n                self.tensorboard.on_epoch_end(epoch * steps_per_epoch + step, training_losses)\n                self.logger.debug(\'Losses at step {s}:\\n {l}\'.format(s=step, l=training_losses))\n\n            elapsed_time = time() - epoch_start\n            self.logger.info(\'Epoch {} took {:10.1f}s\'.format(epoch, elapsed_time))\n\n            validation_losses = self.model.evaluate(\n                validation_set[\'lr\'], y_validation, batch_size=batch_size\n            )\n            validation_losses = self._format_losses(\n                \'val_\', validation_losses, self.model.metrics_names\n            )\n\n            if epoch == starting_epoch:\n                remove_metrics = []\n                for metric in monitored_metrics:\n                    if (metric not in training_losses) and (metric not in validation_losses):\n                        msg = \' \'.join([metric, \'is NOT among the model metrics, removing it.\'])\n                        self.logger.error(msg)\n                        remove_metrics.append(metric)\n                for metric in remove_metrics:\n                    _ = monitored_metrics.pop(metric)\n\n            # should average train metrics\n            end_losses = {}\n            end_losses.update(validation_losses)\n            end_losses.update(training_losses)\n\n            self.helper.on_epoch_end(\n                epoch=epoch,\n                losses=end_losses,\n                generator=self.model.get_layer(\'generator\'),\n                discriminator=self.discriminator,\n                metrics=monitored_metrics,\n            )\n            self.tensorboard.on_epoch_end(epoch, validation_losses)\n        self.tensorboard.on_train_end(None)\n'"
ISR/utils/__init__.py,0,b''
ISR/utils/datahandler.py,0,"b'import os\n\nimport imageio\nimport numpy as np\n\nfrom ISR.utils.logger import get_logger\n\n\nclass DataHandler:\n    """"""\n    DataHandler generate augmented batches used for training or validation.\n\n    Args:\n        lr_dir: directory containing the Low Res images.\n        hr_dir: directory containing the High Res images.\n        patch_size: integer, size of the patches extracted from LR images.\n        scale: integer, upscaling factor.\n        n_validation_samples: integer, size of the validation set. Only provided if the\n            DataHandler is used to generate validation sets.\n    """"""\n    \n    def __init__(self, lr_dir, hr_dir, patch_size, scale, n_validation_samples=None):\n        self.folders = {\'hr\': hr_dir, \'lr\': lr_dir}  # image folders\n        self.extensions = (\'.png\', \'.jpeg\', \'.jpg\')  # admissible extension\n        self.img_list = {}  # list of file names\n        self.n_validation_samples = n_validation_samples\n        self.patch_size = patch_size\n        self.scale = scale\n        self.patch_size = {\'lr\': patch_size, \'hr\': patch_size * self.scale}\n        self.logger = get_logger(__name__)\n        self._make_img_list()\n        self._check_dataset()\n    \n    def _make_img_list(self):\n        """""" Creates a dictionary of lists of the acceptable images contained in lr_dir and hr_dir. """"""\n        \n        for res in [\'hr\', \'lr\']:\n            file_names = os.listdir(self.folders[res])\n            file_names = [file for file in file_names if file.endswith(self.extensions)]\n            self.img_list[res] = np.sort(file_names)\n        \n        if self.n_validation_samples:\n            samples = np.random.choice(\n                range(len(self.img_list[\'hr\'])), self.n_validation_samples, replace=False\n            )\n            for res in [\'hr\', \'lr\']:\n                self.img_list[res] = self.img_list[res][samples]\n    \n    def _check_dataset(self):\n        """""" Sanity check for dataset. """"""\n        \n        # the order of these asserts is important for testing\n        assert len(self.img_list[\'hr\']) == self.img_list[\'hr\'].shape[0], \'UnevenDatasets\'\n        assert self._matching_datasets(), \'Input/LabelsMismatch\'\n    \n    def _matching_datasets(self):\n        """""" Rough file name matching between lr and hr directories. """"""\n        # LR_name.png = HR_name+x+scale.png\n        # or\n        # LR_name.png = HR_name.png\n        LR_name_root = [x.split(\'.\')[0].rsplit(\'x\', 1)[0] for x in self.img_list[\'lr\']]\n        HR_name_root = [x.split(\'.\')[0] for x in self.img_list[\'hr\']]\n        return np.all(HR_name_root == LR_name_root)\n    \n    def _not_flat(self, patch, flatness):\n        """"""\n        Determines whether the patch is complex, or not-flat enough.\n        Threshold set by flatness.\n        """"""\n        \n        if max(np.std(patch, axis=0).mean(), np.std(patch, axis=1).mean()) < flatness:\n            return False\n        else:\n            return True\n    \n    def _crop_imgs(self, imgs, batch_size, flatness):\n        """"""\n        Get random top left corners coordinates in LR space, multiply by scale to\n        get HR coordinates.\n        Gets batch_size + n possible coordinates.\n        Accepts the batch only if the standard deviation of pixel intensities is above a given threshold, OR\n        no patches can be further discarded (n have been discarded already).\n        Square crops of size patch_size are taken from the selected\n        top left corners.\n        """"""\n        \n        slices = {}\n        crops = {}\n        crops[\'lr\'] = []\n        crops[\'hr\'] = []\n        accepted_slices = {}\n        accepted_slices[\'lr\'] = []\n        top_left = {\'x\': {}, \'y\': {}}\n        n = 50 * batch_size\n        for i, axis in enumerate([\'x\', \'y\']):\n            top_left[axis][\'lr\'] = np.random.randint(\n                0, imgs[\'lr\'].shape[i] - self.patch_size[\'lr\'] + 1, batch_size + n\n            )\n            top_left[axis][\'hr\'] = top_left[axis][\'lr\'] * self.scale\n        for res in [\'lr\', \'hr\']:\n            slices[res] = np.array(\n                [\n                    {\'x\': (x, x + self.patch_size[res]), \'y\': (y, y + self.patch_size[res])}\n                    for x, y in zip(top_left[\'x\'][res], top_left[\'y\'][res])\n                ]\n            )\n        \n        for slice_index, s in enumerate(slices[\'lr\']):\n            candidate_crop = imgs[\'lr\'][s[\'x\'][0]: s[\'x\'][1], s[\'y\'][0]: s[\'y\'][1], slice(None)]\n            if self._not_flat(candidate_crop, flatness) or n == 0:\n                crops[\'lr\'].append(candidate_crop)\n                accepted_slices[\'lr\'].append(slice_index)\n            else:\n                n -= 1\n            if len(crops[\'lr\']) == batch_size:\n                break\n        \n        accepted_slices[\'hr\'] = slices[\'hr\'][accepted_slices[\'lr\']]\n        \n        for s in accepted_slices[\'hr\']:\n            candidate_crop = imgs[\'hr\'][s[\'x\'][0]: s[\'x\'][1], s[\'y\'][0]: s[\'y\'][1], slice(None)]\n            crops[\'hr\'].append(candidate_crop)\n        \n        crops[\'lr\'] = np.array(crops[\'lr\'])\n        crops[\'hr\'] = np.array(crops[\'hr\'])\n        return crops\n    \n    def _apply_transform(self, img, transform_selection):\n        """""" Rotates and flips input image according to transform_selection. """"""\n        \n        rotate = {\n            0: lambda x: x,\n            1: lambda x: np.rot90(x, k=1, axes=(1, 0)),  # rotate right\n            2: lambda x: np.rot90(x, k=1, axes=(0, 1)),  # rotate left\n        }\n        \n        flip = {\n            0: lambda x: x,\n            1: lambda x: np.flip(x, 0),  # flip along horizontal axis\n            2: lambda x: np.flip(x, 1),  # flip along vertical axis\n        }\n        \n        rot_direction = transform_selection[0]\n        flip_axis = transform_selection[1]\n        \n        img = rotate[rot_direction](img)\n        img = flip[flip_axis](img)\n        \n        return img\n    \n    def _transform_batch(self, batch, transforms):\n        """""" Transforms each individual image of the batch independently. """"""\n        \n        t_batch = np.array(\n            [self._apply_transform(img, transforms[i]) for i, img in enumerate(batch)]\n        )\n        return t_batch\n    \n    def get_batch(self, batch_size, idx=None, flatness=0.0):\n        """"""\n        Returns a dictionary with keys (\'lr\', \'hr\') containing training batches\n        of Low Res and High Res image patches.\n\n        Args:\n            batch_size: integer.\n            flatness: float in [0,1], is the patch ""flatness"" threshold.\n                Determines what level of detail the patches need to meet. 0 means any patch is accepted.\n        """"""\n        \n        if not idx:\n            # randomly select one image. idx is given at validation time.\n            idx = np.random.choice(range(len(self.img_list[\'hr\'])))\n        img = {}\n        for res in [\'lr\', \'hr\']:\n            img_path = os.path.join(self.folders[res], self.img_list[res][idx])\n            img[res] = imageio.imread(img_path) / 255.0\n        batch = self._crop_imgs(img, batch_size, flatness)\n        transforms = np.random.randint(0, 3, (batch_size, 2))\n        batch[\'lr\'] = self._transform_batch(batch[\'lr\'], transforms)\n        batch[\'hr\'] = self._transform_batch(batch[\'hr\'], transforms)\n        \n        return batch\n    \n    def get_validation_batches(self, batch_size):\n        """""" Returns a batch for each image in the validation set. """"""\n        \n        if self.n_validation_samples:\n            batches = []\n            for idx in range(self.n_validation_samples):\n                batches.append(self.get_batch(batch_size, idx, flatness=0.0))\n            return batches\n        else:\n            self.logger.error(\n                \'No validation set size specified. (not operating in a validation set?)\'\n            )\n            raise ValueError(\n                \'No validation set size specified. (not operating in a validation set?)\'\n            )\n    \n    def get_validation_set(self, batch_size):\n        """"""\n        Returns a batch for each image in the validation set.\n        Flattens and splits them to feed it to Keras\'s model.evaluate.\n        """"""\n        \n        if self.n_validation_samples:\n            batches = self.get_validation_batches(batch_size)\n            valid_set = {\'lr\': [], \'hr\': []}\n            for batch in batches:\n                for res in (\'lr\', \'hr\'):\n                    valid_set[res].extend(batch[res])\n            for res in (\'lr\', \'hr\'):\n                valid_set[res] = np.array(valid_set[res])\n            return valid_set\n        else:\n            self.logger.error(\n                \'No validation set size specified. (not operating in a validation set?)\'\n            )\n            raise ValueError(\n                \'No validation set size specified. (not operating in a validation set?)\'\n            )\n'"
ISR/utils/image_processing.py,0,"b'import numpy as np\n\n\ndef process_array(image_array, expand=True):\n    """""" Process a 3-dimensional array into a scaled, 4 dimensional batch of size 1. """"""\n    \n    image_batch = image_array / 255.0\n    if expand:\n        image_batch = np.expand_dims(image_batch, axis=0)\n    return image_batch\n\n\ndef process_output(output_tensor):\n    """""" Transforms the 4-dimensional output tensor into a suitable image format. """"""\n    \n    sr_img = output_tensor.clip(0, 1) * 255\n    sr_img = np.uint8(sr_img)\n    return sr_img\n\n\ndef pad_patch(image_patch, padding_size, channel_last=True):\n    """""" Pads image_patch with with padding_size edge values. """"""\n    \n    if channel_last:\n        return np.pad(\n            image_patch,\n            ((padding_size, padding_size), (padding_size, padding_size), (0, 0)),\n            \'edge\',\n        )\n    else:\n        return np.pad(\n            image_patch,\n            ((0, 0), (padding_size, padding_size), (padding_size, padding_size)),\n            \'edge\',\n        )\n\n\ndef unpad_patches(image_patches, padding_size):\n    return image_patches[:, padding_size:-padding_size, padding_size:-padding_size, :]\n\n\ndef split_image_into_overlapping_patches(image_array, patch_size, padding_size=2):\n    """""" Splits the image into partially overlapping patches.\n\n    The patches overlap by padding_size pixels.\n\n    Pads the image twice:\n        - first to have a size multiple of the patch size,\n        - then to have equal padding at the borders.\n\n    Args:\n        image_array: numpy array of the input image.\n        patch_size: size of the patches from the original image (without padding).\n        padding_size: size of the overlapping area.\n    """"""\n    \n    xmax, ymax, _ = image_array.shape\n    x_remainder = xmax % patch_size\n    y_remainder = ymax % patch_size\n    \n    # modulo here is to avoid extending of patch_size instead of 0\n    x_extend = (patch_size - x_remainder) % patch_size\n    y_extend = (patch_size - y_remainder) % patch_size\n    \n    # make sure the image is divisible into regular patches\n    extended_image = np.pad(image_array, ((0, x_extend), (0, y_extend), (0, 0)), \'edge\')\n    \n    # add padding around the image to simplify computations\n    padded_image = pad_patch(extended_image, padding_size, channel_last=True)\n    \n    xmax, ymax, _ = padded_image.shape\n    patches = []\n    \n    x_lefts = range(padding_size, xmax - padding_size, patch_size)\n    y_tops = range(padding_size, ymax - padding_size, patch_size)\n    \n    for x in x_lefts:\n        for y in y_tops:\n            x_left = x - padding_size\n            y_top = y - padding_size\n            x_right = x + patch_size + padding_size\n            y_bottom = y + patch_size + padding_size\n            patch = padded_image[x_left:x_right, y_top:y_bottom, :]\n            patches.append(patch)\n    \n    return np.array(patches), padded_image.shape\n\n\ndef stich_together(patches, padded_image_shape, target_shape, padding_size=4):\n    """""" Reconstruct the image from overlapping patches.\n\n    After scaling, shapes and padding should be scaled too.\n\n    Args:\n        patches: patches obtained with split_image_into_overlapping_patches\n        padded_image_shape: shape of the padded image contructed in split_image_into_overlapping_patches\n        target_shape: shape of the final image\n        padding_size: size of the overlapping area.\n    """"""\n    \n    xmax, ymax, _ = padded_image_shape\n    patches = unpad_patches(patches, padding_size)\n    patch_size = patches.shape[1]\n    n_patches_per_row = ymax // patch_size\n    \n    complete_image = np.zeros((xmax, ymax, 3))\n    \n    row = -1\n    col = 0\n    for i in range(len(patches)):\n        if i % n_patches_per_row == 0:\n            row += 1\n            col = 0\n        complete_image[\n        row * patch_size: (row + 1) * patch_size, col * patch_size: (col + 1) * patch_size, :\n        ] = patches[i]\n        col += 1\n    return complete_image[0: target_shape[0], 0: target_shape[1], :]\n'"
ISR/utils/logger.py,0,"b'import logging\nimport os\n\n\ndef get_logger(name, job_dir=\'.\'):\n    """""" Returns logger that prints on stdout at INFO level and on file at DEBUG level. """"""\n    \n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    if not logger.handlers:\n        # stream handler ensures that logging events are passed to stdout\n        ch = logging.StreamHandler()\n        ch.setLevel(logging.INFO)\n        ch_formatter = logging.Formatter(\'%(message)s\')\n        ch.setFormatter(ch_formatter)\n        logger.addHandler(ch)\n        \n        # file handler ensures that logging events are passed to log file\n        if not os.path.exists(job_dir):\n            os.makedirs(job_dir)\n        \n        fh = logging.FileHandler(filename=os.path.join(job_dir, \'log_file\'))\n        fh.setLevel(logging.DEBUG)\n        fh_formatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\n        fh.setFormatter(fh_formatter)\n        logger.addHandler(fh)\n    \n    return logger\n'"
ISR/utils/metrics.py,0,"b'import tensorflow.keras.backend as K\n\n\ndef PSNR(y_true, y_pred, MAXp=1):\n    """"""\n    Evaluates the PSNR value:\n        PSNR = 20 * log10(MAXp) - 10 * log10(MSE).\n\n    Args:\n        y_true: ground truth.\n        y_pred: predicted value.\n        MAXp: maximum value of the pixel range (default=1).\n    """"""\n    return -10.0 * K.log(K.mean(K.square(y_pred - y_true))) / K.log(10.0)\n\n\ndef RGB_to_Y(image):\n    """""" Image has values from 0 to 1. """"""\n    \n    R = image[:, :, :, 0]\n    G = image[:, :, :, 1]\n    B = image[:, :, :, 2]\n    \n    Y = 16 + (65.738 * R) + 129.057 * G + 25.064 * B\n    return Y / 255.0\n\n\ndef PSNR_Y(y_true, y_pred, MAXp=1):\n    """"""\n    Evaluates the PSNR value on the Y channel:\n        PSNR = 20 * log10(MAXp) - 10 * log10(MSE).\n\n    Args:\n        y_true: ground truth.\n        y_pred: predicted value.\n        MAXp: maximum value of the pixel range (default=1).\n    """"""\n    y_true = RGB_to_Y(y_true)\n    y_pred = RGB_to_Y(y_pred)\n    return -10.0 * K.log(K.mean(K.square(y_pred - y_true))) / K.log(10.0)\n'"
ISR/utils/train_helper.py,0,"b'import yaml\nimport numpy as np\nfrom pathlib import Path\n\nfrom ISR.utils.logger import get_logger\nfrom ISR.utils.utils import get_timestamp\n\n\nclass TrainerHelper:\n    """"""Collection of useful functions to manage training sessions.\n\n    Args:\n        generator: Keras model, the super-scaling, or generator, network.\n        logs_dir: path to the directory where the tensorboard logs are saved.\n        weights_dir: path to the directory where the weights are saved.\n        lr_train_dir: path to the directory containing the Low-Res images.\n        feature_extractor: Keras model, feature extractor network for the deep features\n            component of perceptual loss function.\n        discriminator: Keras model, the discriminator network for the adversarial\n            component of the perceptual loss.\n        dataname: string, used to identify what dataset is used for the training session.\n        weights_dictionarycontains the paths, if any to the\n            pre-trained generator\'s and to the pre-trained discriminator\'s weights,\n            for transfer learning.\n        fallback_save_every_n_epochs: integer, determines after how many epochs that did not trigger\n            weights saving the weights are despite no metric improvement.\n        max_n_best_weights: maximum amount of weights that are best on some metric that are kept.\n        max_n_other_weights: maximum amount of non-best weights that are kept.\n\n\n    Methods:\n        print_training_setting: see docstring.\n        on_epoch_end: see docstring.\n        epoch_n_from_weights_name: see docstring.\n        initialize_training: see docstring.\n\n    """"""\n    \n    def __init__(\n            self,\n            generator,\n            weights_dir,\n            logs_dir,\n            lr_train_dir,\n            feature_extractor=None,\n            discriminator=None,\n            dataname=None,\n            weights_generator=None,\n            weights_discriminator=None,\n            fallback_save_every_n_epochs=2,\n            max_n_other_weights=5,\n            max_n_best_weights=5,\n    ):\n        self.generator = generator\n        self.dirs = {\'logs\': Path(logs_dir), \'weights\': Path(weights_dir)}\n        self.feature_extractor = feature_extractor\n        self.discriminator = discriminator\n        self.dataname = dataname\n        \n        if weights_generator:\n            self.pretrained_generator_weights = Path(weights_generator)\n        else:\n            self.pretrained_generator_weights = None\n        \n        if weights_discriminator:\n            self.pretrained_discriminator_weights = Path(weights_discriminator)\n        else:\n            self.pretrained_discriminator_weights = None\n        \n        self.fallback_save_every_n_epochs = fallback_save_every_n_epochs\n        self.lr_dir = Path(lr_train_dir)\n        self.basename = self._make_basename()\n        self.session_id = self.get_session_id(basename=None)\n        self.session_config_name = \'session_config.yml\'\n        self.callback_paths = self._make_callback_paths()\n        self.weights_name = self._weights_name(self.callback_paths)\n        self.best_metrics = {}\n        self.since_last_epoch = 0\n        self.max_n_other_weights = max_n_other_weights\n        self.max_n_best_weights = max_n_best_weights\n        self.logger = get_logger(__name__)\n    \n    def _make_basename(self):\n        """""" Combines generators\'s name and its architecture\'s parameters. """"""\n        \n        gen_name = self.generator.name\n        params = [gen_name]\n        for param in np.sort(list(self.generator.params.keys())):\n            params.append(\'{g}{p}\'.format(g=param, p=self.generator.params[param]))\n        return \'-\'.join(params)\n    \n    def get_session_id(self, basename):\n        """""" Returns unique session identifier. """"""\n        \n        time_stamp = get_timestamp()\n        \n        if basename:\n            session_id = \'{b}_{ts}\'.format(b=basename, ts=time_stamp)\n        else:\n            session_id = time_stamp\n        return session_id\n    \n    def _get_previous_conf(self):\n        """""" Checks if a session_config.yml is available in the pretrained weights folder. """"""\n        \n        if self.pretrained_generator_weights:\n            session_config_path = (\n                    self.pretrained_generator_weights.parent / self.session_config_name\n            )\n            if session_config_path.exists():\n                return yaml.load(session_config_path.read_text(), Loader=yaml.FullLoader)\n            else:\n                self.logger.warning(\'Could not find previous configuration\')\n                return {}\n        \n        return {}\n    \n    def update_config(self, training_settings):\n        """"""\n        Adds to the existing settings (if any) the current settings dictionary\n        under the session_id key.\n        """"""\n        \n        session_settings = self._get_previous_conf()\n        session_settings.update({self.session_id: training_settings})\n        \n        return session_settings\n    \n    def _make_callback_paths(self):\n        """""" Creates the paths used for managing logs and weights storage. """"""\n        \n        callback_paths = {}\n        callback_paths[\'weights\'] = self.dirs[\'weights\'] / self.basename / self.session_id\n        callback_paths[\'logs\'] = self.dirs[\'logs\'] / self.basename / self.session_id\n        return callback_paths\n    \n    def _weights_name(self, callback_paths):\n        """""" Builds the string used to name the weights of the training session. """"""\n        \n        w_name = {\n            \'generator\': callback_paths[\'weights\']\n                         / (self.basename + \'{metric}_epoch{epoch:03d}.hdf5\')\n        }\n        if self.discriminator:\n            w_name.update(\n                {\n                    \'discriminator\': callback_paths[\'weights\']\n                                     / (self.discriminator.name + \'{metric}_epoch{epoch:03d}.hdf5\')\n                }\n            )\n        return w_name\n    \n    def print_training_setting(self, settings):\n        """""" Does what it says. """"""\n        \n        self.logger.info(\'\\nTraining details:\')\n        for k in settings[self.session_id]:\n            if isinstance(settings[self.session_id][k], dict):\n                self.logger.info(\'  {}: \'.format(k))\n                for kk in settings[self.session_id][k]:\n                    self.logger.info(\n                        \'    {key}: {value}\'.format(\n                            key=kk, value=str(settings[self.session_id][k][kk])\n                        )\n                    )\n            else:\n                self.logger.info(\n                    \'  {key}: {value}\'.format(key=k, value=str(settings[self.session_id][k]))\n                )\n    \n    def _save_weights(self, epoch, generator, discriminator=None, metric=None, best=False):\n        """""" Saves the weights of the non-None models. """"""\n        \n        if best:\n            gen_path = self.weights_name[\'generator\'].with_name(\n                (self.weights_name[\'generator\'].name).format(\n                    metric=\'_best-\' + metric, epoch=epoch + 1\n                )\n            )\n        else:\n            gen_path = self.weights_name[\'generator\'].with_name(\n                (self.weights_name[\'generator\'].name).format(metric=\'\', epoch=epoch + 1)\n            )\n        # CANT SAVE MODEL DUE TO TF LAYER INSIDE LAMBDA (PIXELSHUFFLE)\n        generator.save_weights(gen_path.as_posix())\n        if discriminator:\n            if best:\n                discr_path = self.weights_name[\'discriminator\'].with_name(\n                    (self.weights_name[\'discriminator\'].name).format(\n                        metric=\'_best-\' + metric, epoch=epoch + 1\n                    )\n                )\n            else:\n                discr_path = self.weights_name[\'discriminator\'].with_name(\n                    (self.weights_name[\'discriminator\'].name).format(metric=\'\', epoch=epoch + 1)\n                )\n            discriminator.model.save_weights(discr_path.as_posix())\n        try:\n            self._remove_old_weights(self.max_n_other_weights, max_best=self.max_n_best_weights)\n        except Exception as e:\n            self.logger.warning(\'Could not remove weights: {}\'.format(e))\n    \n    def _remove_old_weights(self, max_n_weights, max_best=5):\n        """"""\n        Scans the weights folder and removes all but:\n            - the max_best newest \'best\' weights.\n            - max_n_weights most recent \'others\' weights.\n        """"""\n        \n        w_list = {}\n        w_list[\'all\'] = [w for w in self.callback_paths[\'weights\'].iterdir() if \'.hdf5\' in w.name]\n        w_list[\'best\'] = [w for w in w_list[\'all\'] if \'best\' in w.name]\n        w_list[\'others\'] = [w for w in w_list[\'all\'] if w not in w_list[\'best\']]\n        # remove older best\n        epochs_set = {}\n        epochs_set[\'best\'] = list(\n            set([self.epoch_n_from_weights_name(w.name) for w in w_list[\'best\']])\n        )\n        epochs_set[\'others\'] = list(\n            set([self.epoch_n_from_weights_name(w.name) for w in w_list[\'others\']])\n        )\n        keep_max = {\'best\': max_best, \'others\': max_n_weights}\n        for type in [\'others\', \'best\']:\n            if len(epochs_set[type]) > keep_max[type]:\n                epoch_list = np.sort(epochs_set[type])[::-1]\n                epoch_list = epoch_list[0: keep_max[type]]\n                for w in w_list[type]:\n                    if self.epoch_n_from_weights_name(w.name) not in epoch_list:\n                        w.unlink()\n    \n    def on_epoch_end(self, epoch, losses, generator, discriminator=None, metrics={}):\n        """"""\n        Manages the operations that are taken at the end of each epoch:\n        metric checks, weight saves, logging.\n        """"""\n        \n        self.logger.info(losses)\n        monitor_op = {\'max\': np.greater, \'min\': np.less}\n        extreme = {\'max\': -np.Inf, \'min\': np.Inf}\n        for metric in metrics:\n            if metric in losses.keys():\n                if metric not in self.best_metrics.keys():\n                    self.best_metrics[metric] = extreme[metrics[metric]]\n                \n                if monitor_op[metrics[metric]](losses[metric], self.best_metrics[metric]):\n                    self.logger.info(\n                        \'{} improved from {:10.5f} to {:10.5f}\'.format(\n                            metric, self.best_metrics[metric], losses[metric]\n                        )\n                    )\n                    self.logger.info(\'Saving weights\')\n                    self.best_metrics[metric] = losses[metric]\n                    self._save_weights(epoch, generator, discriminator, metric=metric, best=True)\n                    self.since_last_epoch = 0\n                    return True\n                else:\n                    self.logger.info(\'{} did not improve.\'.format(metric))\n                    if self.since_last_epoch >= self.fallback_save_every_n_epochs:\n                        self.logger.info(\'Saving weights anyways.\')\n                        self._save_weights(epoch, generator, discriminator, best=False)\n                        self.since_last_epoch = 0\n                        return True\n            \n            else:\n                self.logger.warning(\'{} is not monitored, cannot save weights.\'.format(metric))\n        self.since_last_epoch += 1\n        return False\n    \n    def epoch_n_from_weights_name(self, w_name):\n        """"""\n        Extracts the last epoch number from the standardized weights name.\n        Only works if the weights contain \'epoch\' followed by 3 integers, for example:\n            some-architectureepoch023suffix.hdf5\n        """"""\n        try:\n            starting_epoch = int(w_name.split(\'epoch\')[1][0:3])\n        except Exception as e:\n            self.logger.warning(\n                \'Could not retrieve starting epoch from the weights name: \\n{}\'.format(w_name)\n            )\n            self.logger.error(e)\n            starting_epoch = 0\n        return starting_epoch\n    \n    def initialize_training(self, object):\n        """"""Function that is exectured prior to training.\n\n        Wraps up most of the functions of this class:\n        load the weights if any are given, generaters names for session and weights,\n        creates directories and prints the training session.\n        """"""\n        \n        object.weights_generator = self.pretrained_generator_weights\n        object.weights_discriminator = self.pretrained_discriminator_weights\n        object._load_weights()\n        w_name = object.weights_generator\n        if w_name:\n            last_epoch = self.epoch_n_from_weights_name(w_name.name)\n        else:\n            last_epoch = 0\n        \n        self.callback_paths = self._make_callback_paths()\n        self.callback_paths[\'weights\'].mkdir(parents=True)\n        self.callback_paths[\'logs\'].mkdir(parents=True)\n        object.settings[\'training_parameters\'][\'starting_epoch\'] = last_epoch\n        self.settings = self.update_config(object.settings)\n        self.print_training_setting(self.settings)\n        yaml.dump(\n            self.settings, (self.callback_paths[\'weights\'] / self.session_config_name).open(\'w\')\n        )\n        return last_epoch\n'"
ISR/utils/utils.py,0,"b'import os\nimport argparse\nfrom datetime import datetime\n\nimport numpy as np\nimport yaml\n\nfrom ISR.utils.logger import get_logger\n\nlogger = get_logger(__name__)\n\n\ndef _get_parser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--prediction\', action=\'store_true\', dest=\'prediction\')\n    parser.add_argument(\'--training\', action=\'store_true\', dest=\'training\')\n    parser.add_argument(\'--summary\', action=\'store_true\', dest=\'summary\')\n    parser.add_argument(\'--default\', action=\'store_true\', dest=\'default\')\n    parser.add_argument(\'--config\', action=\'store\', dest=\'config_file\')\n    return parser\n\n\ndef parse_args():\n    """""" Parse CLI arguments. """"""\n    \n    parser = _get_parser()\n    args = vars(parser.parse_args())\n    if args[\'prediction\'] and args[\'training\']:\n        logger.error(\'Select only prediction OR training.\')\n        raise ValueError(\'Select only prediction OR training.\')\n    return args\n\n\ndef get_timestamp():\n    ts = datetime.now()\n    time_stamp = \'{y}-{m:02d}-{d:02d}_{h:02d}{mm:02d}\'.format(\n        y=ts.year, m=ts.month, d=ts.day, h=ts.hour, mm=ts.minute\n    )\n    return time_stamp\n\n\ndef check_parameter_keys(parameter, needed_keys, optional_keys=None, default_value=None):\n    if needed_keys:\n        for key in needed_keys:\n            if key not in parameter:\n                logger.error(\'{p} is missing key {k}\'.format(p=parameter, k=key))\n                raise\n    if optional_keys:\n        for key in optional_keys:\n            if key not in parameter:\n                logger.info(\'Setting {k} in {p} to {d}\'.format(k=key, p=parameter, d=default_value))\n                parameter[key] = default_value\n\n\ndef get_config_from_weights(w_path, arch_params, name):\n    """"""\n    Extracts architecture parameters from the file name of the weights.\n    Only works with standardized weights name.\n    """"""\n    \n    w_path = os.path.basename(w_path)\n    parts = w_path.split(name)[1]\n    parts = parts.split(\'_\')[0]\n    parts = parts.split(\'-\')\n    new_param = {}\n    for param in arch_params:\n        param_part = [x for x in parts if param in x]\n        param_value = int(param_part[0].split(param)[1])\n        new_param[param] = param_value\n    return new_param\n\n\ndef select_option(options, message=\'\', val=None):\n    """""" CLI selection given options. """"""\n    \n    while val not in options:\n        val = input(message)\n        if val not in options:\n            logger.error(\'Invalid choice.\')\n    return val\n\n\ndef select_multiple_options(options, message=\'\', val=None):\n    """""" CLI multiple selection given options. """"""\n    \n    n_options = len(options)\n    valid_selections = False\n    selected_options = []\n    while not valid_selections:\n        for i, opt in enumerate(np.sort(options)):\n            logger.info(\'{}: {}\'.format(i, opt))\n        val = input(message + \' (space separated selection)\\n\')\n        vals = val.split(\' \')\n        valid_selections = True\n        for v in vals:\n            if int(v) not in list(range(n_options)):\n                logger.error(\'Invalid choice.\')\n                valid_selections = False\n            else:\n                selected_options.append(options[int(v)])\n    \n    return selected_options\n\n\ndef select_bool(message=\'\'):\n    """""" CLI bool selection. """"""\n    \n    options = [\'y\', \'n\']\n    message = message + \' (\' + \'/\'.join(options) + \') \'\n    val = None\n    while val not in options:\n        val = input(message)\n        if val not in options:\n            logger.error(\'Input y (yes) or n (no).\')\n    if val == \'y\':\n        return True\n    elif val == \'n\':\n        return False\n\n\ndef select_positive_float(message=\'\'):\n    """""" CLI non-negative float selection. """"""\n    \n    value = -1\n    while value < 0:\n        value = float(input(message))\n        if value < 0:\n            logger.error(\'Invalid choice.\')\n    return value\n\n\ndef select_positive_integer(message=\'\', value=-1):\n    """""" CLI non-negative integer selection. """"""\n    \n    while value < 0:\n        value = int(input(message))\n        if value < 0:\n            logger.error(\'Invalid choice.\')\n    return value\n\n\ndef browse_weights(weights_dir, model=\'generator\'):\n    """""" Weights selection from cl. """"""\n    \n    exit = False\n    while exit is False:\n        weights = np.sort(os.listdir(weights_dir))[::-1]\n        print_sel = dict(zip(np.arange(len(weights)), weights))\n        for k in print_sel.keys():\n            logger_message = \'{item_n}: {item} \\n\'.format(item_n=k, item=print_sel[k])\n            logger.info(logger_message)\n        \n        sel = select_positive_integer(\'>>> Select folder or weights for {}\\n\'.format(model))\n        if weights[sel].endswith(\'hdf5\'):\n            weights_path = os.path.join(weights_dir, weights[sel])\n            exit = True\n        else:\n            weights_dir = os.path.join(weights_dir, weights[sel])\n    return weights_path\n\n\ndef setup(config_file=\'config.yml\', default=False, training=False, prediction=False):\n    """"""CLI interface to set up the training or prediction session.\n\n    Takes as input the configuration file path (minus the \'.py\' extension)\n    and arguments parse from CLI.\n    """"""\n    \n    conf = yaml.load(open(config_file, \'r\'), Loader=yaml.FullLoader)\n    \n    if training:\n        session_type = \'training\'\n    elif prediction:\n        session_type = \'prediction\'\n    else:\n        message = \'(t)raining or (p)rediction? (t/p) \'\n        session_type = {\'t\': \'training\', \'p\': \'prediction\'}[select_option([\'t\', \'p\'], message)]\n    if default:\n        all_default = \'y\'\n    else:\n        all_default = select_bool(\'Default options for everything?\')\n    \n    if all_default:\n        generator = conf[\'default\'][\'generator\']\n        if session_type == \'prediction\':\n            dataset = conf[\'default\'][\'test_set\']\n            conf[\'generators\'][generator] = get_config_from_weights(\n                conf[\'weights_paths\'][\'generator\'], conf[\'generators\'][generator], generator\n            )\n        elif session_type == \'training\':\n            dataset = conf[\'default\'][\'training_set\']\n        \n        return session_type, generator, conf, dataset\n    \n    logger.info(\'Select SR (generator) network\')\n    generators = {}\n    for i, gen in enumerate(conf[\'generators\']):\n        generators[str(i)] = gen\n        logger.info(\'{}: {}\'.format(i, gen))\n    generator = generators[select_option(generators)]\n    \n    load_weights = input(\'Load pretrained weights for {}? ([y]/n/d) \'.format(generator))\n    if load_weights == \'n\':\n        default = select_bool(\'Load default parameters for {}?\'.format(generator))\n        if not default:\n            for param in conf[\'generators\'][generator]:\n                value = select_positive_integer(message=\'{}:\'.format(param))\n                conf[\'generators\'][generator][param] = value\n        else:\n            logger.info(\'Default {} parameters.\'.format(generator))\n    elif (load_weights == \'d\') and (conf[\'weights_paths\'][\'generator\']):\n        logger.info(\'Loading default weights for {}\'.format(generator))\n        logger.info(conf[\'weights_paths\'][\'generator\'])\n        conf[\'generators\'][generator] = get_config_from_weights(\n            conf[\'weights_paths\'][\'generator\'], conf[\'generators\'][generator], generator\n        )\n    else:\n        conf[\'weights_paths\'][\'generator\'] = browse_weights(conf[\'dirs\'][\'weights\'], generator)\n        conf[\'generators\'][\'generator\'] = get_config_from_weights(\n            conf[\'weights_paths\'][\'generator\'], conf[\'generators\'][generator], generator\n        )\n    logger.info(\'{} parameters:\'.format(generator))\n    logger.info(conf[\'generators\'][generator])\n    \n    if session_type == \'training\':\n        default_loss_weights = select_bool(\'Use default weights for loss components?\')\n        if not default_loss_weights:\n            conf[\'loss_weights\'][\'generator\'] = select_positive_float(\n                \'Input coefficient for pixel-wise generator loss component \'\n            )\n        use_discr = select_bool(\'Use an Adversarial Network?\')\n        if use_discr:\n            conf[\'default\'][\'discriminator\'] = True\n            discr_w = select_bool(\'Use pretrained discriminator weights?\')\n            if discr_w:\n                conf[\'weights_paths\'][\'discriminator\'] = browse_weights(\n                    conf[\'dirs\'][\'weights\'], \'discriminator\'\n                )\n            if not default_loss_weights:\n                conf[\'loss_weights\'][\'discriminator\'] = select_positive_float(\n                    \'Input coefficient for Adversarial loss component \'\n                )\n        \n        use_feature_extractor = select_bool(\'Use feature extractor?\')\n        if use_feature_extractor:\n            conf[\'default\'][\'feature_extractor\'] = True\n            if not default_loss_weights:\n                conf[\'loss_weights\'][\'feature_extractor\'] = select_positive_float(\n                    \'Input coefficient for conv features loss component \'\n                )\n        default_metrics = select_bool(\'Monitor default metrics?\')\n        if not default_metrics:\n            suggested_list = suggest_metrics(use_discr, use_feature_extractor)\n            selected_metrics = select_multiple_options(\n                list(suggested_list.keys()), message=\'Select metrics to monitor.\'\n            )\n            \n            conf[\'session\'][\'training\'][\'monitored_metrics\'] = {}\n            for metric in selected_metrics:\n                conf[\'session\'][\'training\'][\'monitored_metrics\'][metric] = suggested_list[metric]\n            print(conf[\'session\'][\'training\'][\'monitored_metrics\'])\n    \n    dataset = select_dataset(session_type, conf)\n    \n    return session_type, generator, conf, dataset\n\n\ndef suggest_metrics(discriminator=False, feature_extractor=False, loss_weights={}):\n    suggested_metrics = {}\n    if not discriminator and not feature_extractor:\n        suggested_metrics[\'val_loss\'] = \'min\'\n        suggested_metrics[\'train_loss\'] = \'min\'\n        suggested_metrics[\'val_PSNR\'] = \'max\'\n        suggested_metrics[\'train_PSNR\'] = \'max\'\n    if feature_extractor or discriminator:\n        suggested_metrics[\'val_generator_loss\'] = \'min\'\n        suggested_metrics[\'train_generator_loss\'] = \'min\'\n        suggested_metrics[\'val_generator_PSNR\'] = \'max\'\n        suggested_metrics[\'train_generator_PSNR\'] = \'max\'\n    if feature_extractor:\n        suggested_metrics[\'val_feature_extractor_loss\'] = \'min\'\n        suggested_metrics[\'train_feature_extractor_loss\'] = \'min\'\n    return suggested_metrics\n\n\ndef select_dataset(session_type, conf):\n    """""" CLI snippet for selection the dataset for training. """"""\n    \n    if session_type == \'training\':\n        logger.info(\'Select training set\')\n        datasets = {}\n        for i, data in enumerate(conf[\'training_sets\']):\n            datasets[str(i)] = data\n            logger.info(\'{}: {}\'.format(i, data))\n        dataset = datasets[select_option(datasets)]\n        \n        return dataset\n    else:\n        logger.info(\'Select test set\')\n        datasets = {}\n        for i, data in enumerate(conf[\'test_sets\']):\n            datasets[str(i)] = data\n            logger.info(\'{}: {}\'.format(i, data))\n        dataset = datasets[select_option(datasets)]\n        \n        return dataset\n'"
tests/assistant/test_assistant.py,0,"b""import logging\nimport os\nimport unittest\n\nimport yaml\nfrom unittest.mock import patch\n\nfrom ISR import assistant\n\n\nclass Object:\n    def __init__(self, *args, **kwargs):\n        self.scale = 0\n        self.patch_size = 0\n        pass\n    \n    def make_model(self, *args, **kwargs):\n        return self\n    \n    def train(self, *args, **kwargs):\n        return True\n    \n    def get_predictions(self, *args, **kwargs):\n        return True\n\n\nclass RunFunctionTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        logging.disable(logging.CRITICAL)\n        conf = yaml.load(open(os.path.join('tests', 'data', 'config.yml'), 'r'))\n        conf['default'] = {\n            'feature_extractor': False,\n            'discriminator': False,\n            'generator': 'rdn',\n            'training_set': 'test',\n            'test_set': 'test',\n        }\n        conf['session'] = {}\n        conf['session']['training'] = {}\n        conf['session']['training']['patch_size'] = 0\n        conf['session']['training']['epochs'] = 0\n        conf['session']['training']['steps_per_epoch'] = 0\n        conf['session']['training']['batch_size'] = 0\n        conf['session']['prediction'] = {}\n        conf['session']['prediction']['patch_size'] = 5\n        conf['generators'] = {}\n        conf['generators']['rdn'] = {}\n        conf['generators']['rdn']['x'] = 0\n        conf['training_sets'] = {}\n        conf['training_sets']['test'] = {}\n        conf['training_sets']['test']['lr_train_dir'] = None\n        conf['training_sets']['test']['hr_train_dir'] = None\n        conf['training_sets']['test']['lr_valid_dir'] = None\n        conf['training_sets']['test']['hr_valid_dir'] = None\n        conf['loss_weights'] = None\n        conf['training_sets']['test']['data_name'] = None\n        conf['log_dirs'] = {}\n        conf['log_dirs']['logs'] = None\n        conf['log_dirs']['weights'] = None\n        conf['weights_paths'] = {}\n        conf['weights_paths']['generator'] = 'a/path/rdn-C1-D6-G1-G02-x0-weights.hdf5'\n        conf['weights_paths']['discriminator'] = 'a/path/rdn-weights.hdf5'\n        conf['session']['training']['n_validation_samples'] = None\n        conf['session']['training']['metrics'] = None\n        conf['session']['training']['learning_rate'] = {}\n        conf['session']['training']['adam_optimizer'] = None\n        conf['session']['training']['flatness'] = None\n        conf['session']['training']['fallback_save_every_n_epochs'] = None\n        conf['session']['training']['monitored_metrics'] = None\n        conf['losses'] = None\n        cls.conf = conf\n    \n    @classmethod\n    def tearDownClass(cls):\n        pass\n    \n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    @patch('ISR.assistant._get_module', return_value=Object())\n    @patch('ISR.train.trainer.Trainer', return_value=Object())\n    def test_run_arguments_trainer(self, trainer, _get_module):\n        with patch('yaml.load', return_value=self.conf):\n            assistant.run(\n                config_file='tests/data/config.yml', training=True, prediction=False, default=True\n            )\n            trainer.assert_called_once()\n    \n    @patch('ISR.assistant._get_module', return_value=Object())\n    @patch('ISR.predict.predictor.Predictor', return_value=Object())\n    def test_run_arguments_predictor(self, predictor, _get_module):\n        with patch('yaml.load', return_value=self.conf):\n            assistant.run(\n                config_file='tests/data/config.yml', training=False, prediction=True, default=True\n            )\n            predictor.assert_called_once()\n"""
tests/models/test_models.py,0,"b""import os\nimport unittest\n\nimport yaml\nimport numpy as np\nfrom tensorflow.keras.optimizers import Adam\n\nfrom ISR.models.rrdn import RRDN\nfrom ISR.models.rdn import RDN\nfrom ISR.models.discriminator import Discriminator\nfrom ISR.models.cut_vgg19 import Cut_VGG19\n\n\nclass ModelsClassTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.setup = yaml.load(open(os.path.join('tests', 'data', 'config.yml'), 'r'))\n        cls.weights_path = {\n            'generator': os.path.join(cls.setup['weights_dir'], 'test_gen_weights.hdf5'),\n            'discriminator': os.path.join(cls.setup['weights_dir'], 'test_dis_weights.hdf5'),\n        }\n        cls.hr_shape = (cls.setup['patch_size'] * 2,) * 2 + (3,)\n        \n        cls.RRDN = RRDN(arch_params=cls.setup['rrdn'], patch_size=cls.setup['patch_size'])\n        cls.RRDN.model.compile(optimizer=Adam(), loss=['mse'])\n        cls.RDN = RDN(arch_params=cls.setup['rdn'], patch_size=cls.setup['patch_size'])\n        cls.RDN.model.compile(optimizer=Adam(), loss=['mse'])\n        cls.f_ext = Cut_VGG19(patch_size=cls.setup['patch_size'] * 2, layers_to_extract=[1, 2])\n        cls.f_ext.model.compile(optimizer=Adam(), loss=['mse', 'mse'])\n        cls.discr = Discriminator(patch_size=cls.setup['patch_size'] * 2)\n        cls.discr.model.compile(optimizer=Adam(), loss=['mse'])\n    \n    @classmethod\n    def tearDownClass(cls):\n        pass\n    \n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    def test_SR_output_shapes(self):\n        self.assertTrue(self.RRDN.model.output_shape[1:4] == self.hr_shape)\n        self.assertTrue(self.RDN.model.output_shape[1:4] == self.hr_shape)\n    \n    def test_that_the_trainable_layers_change(self):\n        \n        x = np.random.random((1, self.setup['patch_size'], self.setup['patch_size'], 3))\n        y = np.random.random((1, self.setup['patch_size'] * 2, self.setup['patch_size'] * 2, 3))\n        \n        before_step = []\n        for layer in self.RRDN.model.layers:\n            if len(layer.trainable_weights) > 0:\n                before_step.append(layer.get_weights()[0])\n        \n        self.RRDN.model.train_on_batch(x, y)\n        \n        i = 0\n        for layer in self.RRDN.model.layers:\n            if len(layer.trainable_weights) > 0:\n                self.assertFalse(np.all(before_step[i] == layer.get_weights()[0]))\n                i += 1\n        \n        before_step = []\n        for layer in self.RDN.model.layers:\n            if len(layer.trainable_weights) > 0:\n                before_step.append(layer.get_weights()[0])\n        \n        self.RDN.model.train_on_batch(x, y)\n        \n        i = 0\n        for layer in self.RDN.model.layers:\n            if len(layer.trainable_weights) > 0:\n                self.assertFalse(np.all(before_step[i] == layer.get_weights()[0]))\n                i += 1\n        \n        discr_out_shape = list(self.discr.model.outputs[0].shape)[1:4]\n        valid = np.ones([1] + discr_out_shape)\n        \n        before_step = []\n        for layer in self.discr.model.layers:\n            if len(layer.trainable_weights) > 0:\n                before_step.append(layer.get_weights()[0])\n        \n        self.discr.model.train_on_batch(y, valid)\n        \n        i = 0\n        for layer in self.discr.model.layers:\n            if len(layer.trainable_weights) > 0:\n                self.assertFalse(np.all(before_step[i] == layer.get_weights()[0]))\n                i += 1\n    \n    def test_that_feature_extractor_is_not_trainable(self):\n        y = np.random.random((1, self.setup['patch_size'] * 2, self.setup['patch_size'] * 2, 3))\n        f_ext_out_shape = list(self.f_ext.model.outputs[0].shape[1:4])\n        f_ext_out_shape1 = list(self.f_ext.model.outputs[1].shape[1:4])\n        feats = [np.random.random([1] + f_ext_out_shape), np.random.random([1] + f_ext_out_shape1)]\n        w_before = []\n        for layer in self.f_ext.model.layers:\n            if layer.trainable:\n                w_before.append(layer.get_weights()[0])\n        self.f_ext.model.train_on_batch(y, [*feats])\n        for i, layer in enumerate(self.f_ext.model.layers):\n            if layer.trainable:\n                self.assertFalse(w_before[i] == layer.get_weights()[0])\n"""
tests/predict/test_predict.py,0,"b""import logging\nimport unittest\nimport shutil\nfrom copy import copy\n\nimport yaml\nimport numpy as np\nfrom pathlib import Path\nfrom unittest.mock import patch, Mock\n\nfrom ISR.models.rdn import RDN\nfrom ISR.predict.predictor import Predictor\n\n\nclass PredictorClassTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        logging.disable(logging.CRITICAL)\n        cls.setup = yaml.load(Path('tests/data/config.yml').read_text(), Loader=yaml.FullLoader)\n        cls.RDN = RDN(arch_params=cls.setup['rdn'], patch_size=cls.setup['patch_size'])\n        \n        cls.temp_data = Path('tests/temporary_test_data')\n        cls.valid_files = cls.temp_data / 'valid_files'\n        cls.valid_files.mkdir(parents=True, exist_ok=True)\n        for item in ['data2.gif', 'data1.png', 'data0.jpeg']:\n            (cls.valid_files / item).touch()\n        \n        cls.invalid_files = cls.temp_data / 'invalid_files'\n        cls.invalid_files.mkdir(parents=True, exist_ok=True)\n        for item in ['data2.gif', 'data.data', 'data02']:\n            (cls.invalid_files / item).touch()\n        \n        def nullifier(*args):\n            pass\n        \n        cls.out_dir = cls.temp_data / 'out_dir'\n        cls.predictor = Predictor(input_dir=str(cls.valid_files), output_dir=str(cls.out_dir))\n        cls.predictor.logger = Mock(return_value=True)\n    \n    @classmethod\n    def tearDownClass(cls):\n        shutil.rmtree(cls.temp_data)\n        pass\n    \n    def setUp(self):\n        self.pred = copy(self.predictor)\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    def test__load_weights_with_no_weights(self):\n        self.pred.weights_path = None\n        try:\n            self.pred._load_weights()\n        except:\n            self.assertTrue(True)\n        else:\n            self.assertTrue(False)\n    \n    def test__load_weights_with_valid_weights(self):\n        def raise_path(path):\n            raise ValueError(path)\n        \n        self.pred.model = self.RDN\n        self.pred.model.model.load_weights = Mock(side_effect=raise_path)\n        self.pred.weights_path = 'a/path'\n        try:\n            self.pred._load_weights()\n        except ValueError as e:\n            self.assertTrue(str(e) == 'a/path')\n        else:\n            self.assertTrue(False)\n    \n    def test__make_basename(self):\n        self.pred.model = self.RDN\n        made_name = self.pred._make_basename()\n        self.assertTrue(made_name == 'rdn-C3-D10-G64-G064-x2')\n    \n    def test__forward_pass_pixel_range_and_type(self):\n        def valid_sr_output(*args):\n            sr = np.random.random((1, 20, 20, 3))\n            sr[0, 0, 0, 0] = 0.5\n            return sr\n        \n        self.pred.model = self.RDN\n        self.pred.model.model.predict = Mock(side_effect=valid_sr_output)\n        with patch('imageio.imread', return_value=np.random.random((10, 10, 3))):\n            sr = self.pred._forward_pass('file_path')\n        self.assertTrue(type(sr[0, 0, 0]) is np.uint8)\n        self.assertTrue(np.all(sr >= 0.0))\n        self.assertTrue(np.all(sr <= 255.0))\n        self.assertTrue(np.any(sr > 1.0))\n        self.assertTrue(sr.shape == (20, 20, 3))\n    \n    def test__forward_pass_4_channela(self):\n        def valid_sr_output(*args):\n            sr = np.random.random((1, 20, 20, 3))\n            sr[0, 0, 0, 0] = 0.5\n            return sr\n        \n        self.pred.model = self.RDN\n        self.pred.model.model.predict = Mock(side_effect=valid_sr_output)\n        with patch('imageio.imread', return_value=np.random.random((10, 10, 4))):\n            sr = self.pred._forward_pass('file_path')\n        self.assertTrue(sr is None)\n    \n    def test__forward_pass_1_channel(self):\n        def valid_sr_output(*args):\n            sr = np.random.random((1, 20, 20, 3))\n            sr[0, 0, 0, 0] = 0.5\n            return sr\n        \n        self.pred.model = self.RDN\n        self.pred.model.model.predict = Mock(side_effect=valid_sr_output)\n        with patch('imageio.imread', return_value=np.random.random((10, 10, 1))):\n            sr = self.pred._forward_pass('file_path')\n        self.assertTrue(sr is None)\n    \n    def test_get_predictions(self):\n        self.pred._load_weights = Mock(return_value={})\n        self.pred._forward_pass = Mock(return_value=True)\n        with patch('imageio.imwrite', return_value=True):\n            self.pred.get_predictions(self.RDN, 'a/path/arch-weights_session1_session2.hdf5')\n        pass\n    \n    def test_output_folder_and_dataname(self):\n        self.assertTrue(self.pred.data_name == 'valid_files')\n        self.assertTrue(\n            self.pred.output_dir == Path('tests/temporary_test_data/out_dir/valid_files')\n        )\n    \n    def test_valid_extensions(self):\n        self.assertTrue(\n            np.array_equal(\n                np.sort(self.pred.img_ls),\n                np.sort([self.valid_files / 'data0.jpeg', self.valid_files / 'data1.png']),\n            )\n        )\n    \n    def test_no_valid_images(self):\n        try:\n            predictor = Predictor(input_dir=str(self.invalid_files), output_dir=str(self.out_dir))\n        except ValueError as e:\n            self.assertTrue('image' in str(e))\n        else:\n            self.assertTrue(False)\n"""
tests/train/test_trainer.py,0,"b""import logging\nimport os\nimport shutil\nimport unittest\nfrom copy import copy\n\nfrom pathlib import Path\nimport yaml\nimport numpy as np\nfrom unittest.mock import patch, Mock\n\nfrom ISR.models.cut_vgg19 import Cut_VGG19\nfrom ISR.models.discriminator import Discriminator\nfrom ISR.models.rrdn import RRDN\nfrom ISR.train.trainer import Trainer\n\n\nclass TrainerClassTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.setup = yaml.load(open(os.path.join('tests', 'data', 'config.yml'), 'r'))\n        cls.RRDN = RRDN(arch_params=cls.setup['rrdn'], patch_size=cls.setup['patch_size'])\n        cls.f_ext = Cut_VGG19(patch_size=cls.setup['patch_size'] * 2, layers_to_extract=[1, 2])\n        cls.discr = Discriminator(patch_size=cls.setup['patch_size'] * 2)\n        cls.weights_path = {\n            'generator': os.path.join(cls.setup['weights_dir'], 'test_gen_weights.hdf5'),\n            'discriminator': os.path.join(cls.setup['weights_dir'], 'test_dis_weights.hdf5'),\n        }\n        cls.temp_data = Path('tests/temporary_test_data')\n        \n        cls.not_matching_hr = cls.temp_data / 'not_matching_hr'\n        cls.not_matching_hr.mkdir(parents=True)\n        for item in ['data2.gif', 'data1.png', 'data0.jpeg']:\n            (cls.not_matching_hr / item).touch()\n        \n        cls.not_matching_lr = cls.temp_data / 'not_matching_lr'\n        cls.not_matching_lr.mkdir(parents=True)\n        for item in ['data1.png']:\n            (cls.not_matching_lr / item).touch()\n        \n        cls.matching_hr = cls.temp_data / 'matching_hr'\n        cls.matching_hr.mkdir(parents=True)\n        for item in ['data2.gif', 'data1.png', 'data0.jpeg']:\n            (cls.matching_hr / item).touch()\n        \n        cls.matching_lr = cls.temp_data / 'matching_lr'\n        cls.matching_lr.mkdir(parents=True)\n        for item in ['data1.png', 'data0.jpeg']:\n            (cls.matching_lr / item).touch()\n        \n        with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n            cls.trainer = Trainer(\n                generator=cls.RRDN,\n                discriminator=cls.discr,\n                feature_extractor=cls.f_ext,\n                lr_train_dir=str(cls.matching_lr),\n                hr_train_dir=str(cls.matching_hr),\n                lr_valid_dir=str(cls.matching_lr),\n                hr_valid_dir=str(cls.matching_hr),\n                learning_rate={'initial_value': 0.0004, 'decay_factor': 0.5, 'decay_frequency': 5},\n                log_dirs={\n                    'logs': './tests/temporary_test_data/logs',\n                    'weights': './tests/temporary_test_data/weights',\n                },\n                dataname='TEST',\n                weights_generator=None,\n                weights_discriminator=None,\n                n_validation=2,\n                flatness={'min': 0.01, 'max': 0.3, 'increase': 0.01, 'increase_frequency': 5},\n                adam_optimizer={'beta1': 0.9, 'beta2': 0.999, 'epsilon': None},\n                losses={'generator': 'mae', 'discriminator': 'mse', 'feature_extractor': 'mse'},\n                loss_weights={'generator': 1.0, 'discriminator': 1.0, 'feature_extractor': 0.5},\n            )\n    \n    @classmethod\n    def tearDownClass(cls):\n        shutil.rmtree(cls.temp_data)\n        pass\n    \n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    def test__combine_networks_sanity(self):\n        mockd_trainer = copy(self.trainer)\n        combined = mockd_trainer._combine_networks()\n        self.assertTrue(len(combined.layers) == 4)\n        self.assertTrue(len(combined.loss_weights) == 4)\n        self.assertTrue(np.all(np.array(combined.loss_weights) == [1.0, 1.0, 0.25, 0.25]))\n        mockd_trainer.discriminator = None\n        combined = mockd_trainer._combine_networks()\n        self.assertTrue(len(combined.layers) == 3)\n        self.assertTrue(len(combined.loss_weights) == 3)\n        self.assertTrue(np.all(np.array(combined.loss_weights) == [1.0, 0.25, 0.25]))\n        mockd_trainer.feature_extractor = None\n        combined = mockd_trainer._combine_networks()\n        self.assertTrue(len(combined.layers) == 2)\n        self.assertTrue(len(combined.loss_weights) == 1)\n        self.assertTrue(np.all(np.array(combined.loss_weights) == [1.0]))\n        try:\n            mockd_trainer.generator = None\n            combined = mockd_trainer._combine_networks()\n        except:\n            self.assertTrue(True)\n        else:\n            self.assertTrue(False)\n    \n    def test__lr_scheduler(self):\n        lr = self.trainer._lr_scheduler(epoch=10)\n        expected_lr = 0.0004 * (0.5) ** 2\n        self.assertTrue(lr == expected_lr)\n    \n    def test__flatness_scheduler(self):\n        # test with arguments values\n        f = self.trainer._flatness_scheduler(epoch=10)\n        expected_flatness = 0.03\n        self.assertTrue(f == expected_flatness)\n        \n        # test with specified values\n        self.trainer.flatness['increase'] = 0.1\n        self.trainer.flatness['increase_frequency'] = 2\n        self.trainer.flatness['min'] = 0.1\n        self.trainer.flatness['max'] = 1.0\n        f = self.trainer._flatness_scheduler(epoch=10)\n        expected_flatness = 0.6\n        self.assertTrue(f == expected_flatness)\n        \n        # test max\n        self.trainer.flatness['increase'] = 1.0\n        self.trainer.flatness['increase_frequency'] = 1\n        self.trainer.flatness['min'] = 0.1\n        self.trainer.flatness['max'] = 1.0\n        f = self.trainer._flatness_scheduler(epoch=10)\n        expected_flatness = 1.0\n        self.assertTrue(f == expected_flatness)\n    \n    def test_that_discriminator_and_f_extr_are_not_trainable_in_combined_model(self):\n        combined = self.trainer._combine_networks()\n        self.assertTrue(combined.get_layer('discriminator').trainable == False)\n        self.assertTrue(combined.get_layer('feature_extractor').trainable == False)\n    \n    def test_that_discriminator_is_trainable_outside_of_combined(self):\n        combined = self.trainer._combine_networks()\n        y = np.random.random((1, self.setup['patch_size'] * 2, self.setup['patch_size'] * 2, 3))\n        discr_out_shape = list(self.discr.model.outputs[0].shape)[1:4]\n        valid = np.ones([1] + discr_out_shape)\n        \n        before_step = []\n        for layer in self.trainer.discriminator.model.layers:\n            if len(layer.trainable_weights) > 0:\n                before_step.append(layer.get_weights()[0])\n        \n        self.trainer.discriminator.model.train_on_batch(y, valid)\n        \n        i = 0\n        for layer in self.trainer.discriminator.model.layers:\n            if len(layer.trainable_weights) > 0:\n                self.assertFalse(np.all(before_step[i] == layer.get_weights()[0]))\n                i += 1\n    \n    def test_that_feature_extractor_is_not_trainable_outside_of_combined(self):\n        mockd_trainer = copy(self.trainer)\n        y = np.random.random((1, self.setup['patch_size'] * 2, self.setup['patch_size'] * 2, 3))\n        f_ext_out_shape = list(mockd_trainer.feature_extractor.model.outputs[0].shape[1:4])\n        f_ext_out_shape1 = list(mockd_trainer.feature_extractor.model.outputs[1].shape[1:4])\n        feats = [np.random.random([1] + f_ext_out_shape), np.random.random([1] + f_ext_out_shape1)]\n        # should not have optimizer\n        try:\n            mockd_trainer.feature_extractor.model.train_on_batch(y, [*feats])\n        except:\n            self.assertTrue(True)\n        else:\n            self.assertTrue(False)\n    \n    def test__load_weights(self):\n        def check_gen_path(path):\n            self.assertTrue(path == 'gen')\n        \n        def check_discr_path(path):\n            self.assertTrue(path == 'discr')\n        \n        mockd_trainer = copy(self.trainer)\n        \n        mockd_trainer.pretrained_weights_path = {'generator': 'gen', 'discriminator': 'discr'}\n        mockd_trainer.discriminator.model.load_weights = Mock(side_effect=check_discr_path)\n        mockd_trainer.model.get_layer('generator').load_weights = Mock(side_effect=check_gen_path)\n        mockd_trainer._load_weights()\n    \n    def test_train(self):\n        def nullifier(*args):\n            pass\n        \n        mockd_trainer = copy(self.trainer)\n        mockd_trainer.logger = Mock(side_effect=nullifier)\n        mockd_trainer.valid_dh.get_validation_set = Mock(return_value={'lr': [], 'hr': []})\n        mockd_trainer.train_dh.get_batch = Mock(return_value={'lr': [], 'hr': []})\n        mockd_trainer.feature_extractor.model.predict = Mock(return_value=[])\n        mockd_trainer.generator.model.predict = Mock(return_value=[])\n        mockd_trainer.discriminator.model.train_on_batch = Mock(return_value=[])\n        mockd_trainer.model.train_on_batch = Mock(return_value=[])\n        mockd_trainer.model.evaluate = Mock(return_value=[])\n        mockd_trainer.tensorboard = Mock(side_effect=nullifier)\n        mockd_trainer.helper.on_epoch_end = Mock(return_value=True)\n        \n        logging.disable(logging.CRITICAL)\n        mockd_trainer.train(epochs=1, steps_per_epoch=1, batch_size=1, monitored_metrics={})\n"""
tests/utils/test_datahandler.py,0,"b""import unittest\n\nimport numpy as np\nfrom unittest.mock import patch\n\nfrom ISR.utils.datahandler import DataHandler\n\n\nclass DataHandlerTest(unittest.TestCase):\n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    def fake_folders(self, kind):\n        if kind['matching'] == False:\n            if kind['res'] == 'hr':\n                return ['data2.gif', 'data1.png', 'data0.jpeg']\n            elif kind['res'] == 'lr':\n                return ['data1.png']\n            else:\n                raise\n        if kind['matching'] == True:\n            if kind['res'] == 'hr':\n                return ['data2.gif', 'data1.png', 'data0.jpeg']\n            elif kind['res'] == 'lr':\n                return ['data1.png', 'data0.jpeg']\n            else:\n                raise\n    \n    def path_giver(self, d, b):\n        if d['res'] == 'hr':\n            return 'hr'\n        else:\n            return 'lr'\n    \n    def image_getter(self, res):\n        if res == 'hr':\n            return np.random.random((20, 20, 3))\n        else:\n            return np.random.random((10, 10, 3))\n    \n    def test__make_img_list_non_validation(self):\n        with patch('os.listdir', side_effect=self.fake_folders):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir={'res': 'lr', 'matching': False},\n                    hr_dir={'res': 'hr', 'matching': False},\n                    patch_size=0,\n                    scale=0,\n                    n_validation_samples=None,\n                )\n        \n        expected_ls = {'hr': ['data0.jpeg', 'data1.png'], 'lr': ['data1.png']}\n        self.assertTrue(np.all(DH.img_list['hr'] == expected_ls['hr']))\n        self.assertTrue(np.all(DH.img_list['lr'] == expected_ls['lr']))\n    \n    def test__make_img_list_validation(self):\n        with patch('os.listdir', side_effect=self.fake_folders):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                with patch('numpy.random.choice', return_value=np.array([0])):\n                    DH = DataHandler(\n                        lr_dir={'res': 'lr', 'matching': False},\n                        hr_dir={'res': 'hr', 'matching': False},\n                        patch_size=0,\n                        scale=0,\n                        n_validation_samples=10,\n                    )\n        \n        expected_ls = {'hr': ['data0.jpeg'], 'lr': ['data1.png']}\n        self.assertTrue(np.all(DH.img_list['hr'] == expected_ls['hr']))\n        self.assertTrue(np.all(DH.img_list['lr'] == expected_ls['lr']))\n    \n    def test__check_dataset_with_mismatching_data(self):\n        try:\n            with patch('os.listdir', side_effect=self.fake_folders):\n                \n                DH = DataHandler(\n                    lr_dir={'res': 'lr', 'matching': False},\n                    hr_dir={'res': 'hr', 'matching': False},\n                    patch_size=0,\n                    scale=0,\n                    n_validation_samples=None,\n                )\n        except:\n            self.assertTrue(True)\n        else:\n            self.assertTrue(False)\n    \n    def test__check_dataset_with_matching_data(self):\n        with patch('os.listdir', side_effect=self.fake_folders):\n            DH = DataHandler(\n                lr_dir={'res': 'lr', 'matching': True},\n                hr_dir={'res': 'hr', 'matching': True},\n                patch_size=0,\n                scale=0,\n                n_validation_samples=None,\n            )\n    \n    def test__not_flat_with_flat_patch(self):\n        lr_patch = np.zeros((5, 5, 3))\n        with patch('ISR.utils.datahandler.DataHandler._make_img_list', return_value=True):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir=None, hr_dir=None, patch_size=0, scale=0, n_validation_samples=None\n                )\n        self.assertFalse(DH._not_flat(lr_patch, flatness=0.1))\n    \n    def test__not_flat_with_non_flat_patch(self):\n        lr_patch = np.random.random((5, 5, 3))\n        with patch('ISR.utils.datahandler.DataHandler._make_img_list', return_value=True):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir=None, hr_dir=None, patch_size=0, scale=0, n_validation_samples=None\n                )\n        self.assertTrue(DH._not_flat(lr_patch, flatness=0.00001))\n    \n    def test__crop_imgs_crops_shapes(self):\n        with patch('ISR.utils.datahandler.DataHandler._make_img_list', return_value=True):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir=None, hr_dir=None, patch_size=3, scale=2, n_validation_samples=None\n                )\n        imgs = {'hr': np.random.random((20, 20, 3)), 'lr': np.random.random((10, 10, 3))}\n        crops = DH._crop_imgs(imgs, batch_size=2, flatness=0)\n        self.assertTrue(crops['hr'].shape == (2, 6, 6, 3))\n        self.assertTrue(crops['lr'].shape == (2, 3, 3, 3))\n    \n    def test__apply_transorm(self):\n        I = np.ones((2, 2))\n        A = I * 0\n        B = I * 1\n        C = I * 2\n        D = I * 3\n        image = np.block([[A, B], [C, D]])\n        with patch('ISR.utils.datahandler.DataHandler._make_img_list', return_value=True):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir=None, hr_dir=None, patch_size=3, scale=2, n_validation_samples=None\n                )\n        transf = [[1, 0], [0, 1], [2, 0], [0, 2], [1, 1], [0, 0]]\n        self.assertTrue(np.all(np.block([[C, A], [D, B]]) == DH._apply_transform(image, transf[0])))\n        self.assertTrue(np.all(np.block([[C, D], [A, B]]) == DH._apply_transform(image, transf[1])))\n        self.assertTrue(np.all(np.block([[B, D], [A, C]]) == DH._apply_transform(image, transf[2])))\n        self.assertTrue(np.all(np.block([[B, A], [D, C]]) == DH._apply_transform(image, transf[3])))\n        self.assertTrue(np.all(np.block([[D, B], [C, A]]) == DH._apply_transform(image, transf[4])))\n        self.assertTrue(np.all(image == DH._apply_transform(image, transf[5])))\n    \n    def test__transform_batch(self):\n        with patch('ISR.utils.datahandler.DataHandler._make_img_list', return_value=True):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir=None, hr_dir=None, patch_size=3, scale=2, n_validation_samples=None\n                )\n        I = np.ones((2, 2))\n        A = I * 0\n        B = I * 1\n        C = I * 2\n        D = I * 3\n        image = np.block([[A, B], [C, D]])\n        t_image_1 = np.block([[D, B], [C, A]])\n        t_image_2 = np.block([[B, D], [A, C]])\n        batch = np.array([image, image])\n        expected = np.array([t_image_1, t_image_2])\n        self.assertTrue(np.all(DH._transform_batch(batch, [[1, 1], [2, 0]]) == expected))\n    \n    def test_get_batch_shape_and_diversity(self):\n        patch_size = 3\n        with patch('os.listdir', side_effect=self.fake_folders):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir={'res': 'lr', 'matching': True},\n                    hr_dir={'res': 'hr', 'matching': True},\n                    patch_size=patch_size,\n                    scale=2,\n                    n_validation_samples=None,\n                )\n        \n        with patch('imageio.imread', side_effect=self.image_getter):\n            with patch('os.path.join', side_effect=self.path_giver):\n                batch = DH.get_batch(batch_size=5)\n        \n        self.assertTrue(type(batch) is dict)\n        self.assertTrue(batch['hr'].shape == (5, patch_size * 2, patch_size * 2, 3))\n        self.assertTrue(batch['lr'].shape == (5, patch_size, patch_size, 3))\n        \n        self.assertTrue(\n            np.any(\n                [\n                    batch['lr'][0] != batch['lr'][1],\n                    batch['lr'][1] != batch['lr'][2],\n                    batch['lr'][2] != batch['lr'][3],\n                    batch['lr'][3] != batch['lr'][4],\n                ]\n            )\n        )\n    \n    def test_get_validation_batches_invalid_number_of_samples(self):\n        patch_size = 3\n        with patch('os.listdir', side_effect=self.fake_folders):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir={'res': 'lr', 'matching': True},\n                    hr_dir={'res': 'hr', 'matching': True},\n                    patch_size=patch_size,\n                    scale=2,\n                    n_validation_samples=None,\n                )\n        \n        with patch('imageio.imread', side_effect=self.image_getter):\n            with patch('os.path.join', side_effect=self.path_giver):\n                try:\n                    with patch('raise', None):\n                        batch = DH.get_validation_batches(batch_size=5)\n                except:\n                    self.assertTrue(True)\n                else:\n                    self.assertTrue(False)\n    \n    def test_get_validation_batches_requesting_more_than_available(self):\n        patch_size = 3\n        with patch('os.listdir', side_effect=self.fake_folders):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                try:\n                    DH = DataHandler(\n                        lr_dir={'res': 'lr', 'matching': True},\n                        hr_dir={'res': 'hr', 'matching': True},\n                        patch_size=patch_size,\n                        scale=2,\n                        n_validation_samples=10,\n                    )\n                except:\n                    self.assertTrue(True)\n                else:\n                    self.assertTrue(False)\n    \n    def test_get_validation_batches_valid_request(self):\n        patch_size = 3\n        with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n            with patch('os.listdir', side_effect=self.fake_folders):\n                DH = DataHandler(\n                    lr_dir={'res': 'lr', 'matching': True},\n                    hr_dir={'res': 'hr', 'matching': True},\n                    patch_size=patch_size,\n                    scale=2,\n                    n_validation_samples=2,\n                )\n        \n        with patch('imageio.imread', side_effect=self.image_getter):\n            with patch('os.path.join', side_effect=self.path_giver):\n                batch = DH.get_validation_batches(batch_size=12)\n        \n        self.assertTrue(len(batch) == 2)\n        self.assertTrue(type(batch) is list)\n        self.assertTrue(type(batch[0]) is dict)\n        self.assertTrue(batch[0]['hr'].shape == (12, patch_size * 2, patch_size * 2, 3))\n        self.assertTrue(batch[0]['lr'].shape == (12, patch_size, patch_size, 3))\n        self.assertTrue(batch[1]['hr'].shape == (12, patch_size * 2, patch_size * 2, 3))\n        self.assertTrue(batch[1]['lr'].shape == (12, patch_size, patch_size, 3))\n    \n    def test_validation_set(self):\n        patch_size = 3\n        with patch('os.listdir', side_effect=self.fake_folders):\n            with patch('ISR.utils.datahandler.DataHandler._check_dataset', return_value=True):\n                DH = DataHandler(\n                    lr_dir={'res': 'lr', 'matching': True},\n                    hr_dir={'res': 'hr', 'matching': True},\n                    patch_size=patch_size,\n                    scale=2,\n                    n_validation_samples=2,\n                )\n        \n        with patch('imageio.imread', side_effect=self.image_getter):\n            with patch('os.path.join', side_effect=self.path_giver):\n                batch = DH.get_validation_set(batch_size=12)\n        \n        self.assertTrue(type(batch) is dict)\n        self.assertTrue(len(batch) == 2)\n        self.assertTrue(batch['hr'].shape == (24, patch_size * 2, patch_size * 2, 3))\n        self.assertTrue(batch['lr'].shape == (24, patch_size, patch_size, 3))\n"""
tests/utils/test_metrics.py,0,"b'import unittest\n\nimport numpy as np\nimport tensorflow.keras.backend as K\n\nfrom ISR.utils.metrics import PSNR\n\n\nclass MetricsClassTest(unittest.TestCase):\n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    def test_PSNR_sanity(self):\n        A = K.ones((10, 10, 3))\n        B = K.zeros((10, 10, 3))\n        self.assertEqual(K.get_value(PSNR(A, A)), np.inf)\n        self.assertEqual(K.get_value(PSNR(A, B)), 0)\n'"
tests/utils/test_trainer_helper.py,0,"b""import unittest\nimport shutil\n\nimport yaml\nfrom pathlib import Path\nfrom unittest.mock import patch\n\nfrom ISR.utils.train_helper import TrainerHelper\nfrom ISR.models.rrdn import RRDN\nfrom ISR.models.discriminator import Discriminator\nfrom ISR.models.cut_vgg19 import Cut_VGG19\n\n\nclass UtilsClassTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.setup = yaml.load(Path('./tests/data/config.yml').read_text())\n        cls.RRDN = RRDN(arch_params=cls.setup['rrdn'], patch_size=cls.setup['patch_size'])\n        cls.f_ext = Cut_VGG19(patch_size=cls.setup['patch_size'], layers_to_extract=[1, 2])\n        cls.discr = Discriminator(patch_size=cls.setup['patch_size'])\n        cls.weights_path = {\n            'generator': Path(cls.setup['weights_dir']) / 'test_gen_weights.hdf5',\n            'discriminator': Path(cls.setup['weights_dir']) / 'test_dis_weights.hdf5',\n        }\n        cls.TH = TrainerHelper(\n            generator=cls.RRDN,\n            weights_dir=cls.setup['weights_dir'],\n            logs_dir=cls.setup['log_dir'],\n            lr_train_dir=cls.setup['lr_input'],\n            feature_extractor=cls.f_ext,\n            discriminator=cls.discr,\n            dataname='TEST',\n            weights_generator='',\n            weights_discriminator='',\n            fallback_save_every_n_epochs=2,\n        )\n        cls.TH.session_id = '0000'\n        cls.TH.logger.setLevel(50)\n    \n    @classmethod\n    def tearDownClass(cls):\n        pass\n    \n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        if Path('./tests/temporary_test_data').exists():\n            shutil.rmtree('./tests/temporary_test_data')\n        if Path('./log_file').exists():\n            Path('./log_file').unlink()\n        pass\n    \n    def test__make_basename(self):\n        generator_name = self.TH.generator.name + '-C2-D3-G20-G020-T2-x2'\n        generated_name = self.TH._make_basename()\n        assert generator_name == generated_name, 'Generated name: {}, expected: {}'.format(\n            generated_name, generator_name\n        )\n    \n    def test_basename_without_pretrained_weights(self):\n        basename = 'rrdn-C2-D3-G20-G020-T2-x2'\n        made_basename = self.TH._make_basename()\n        assert basename == made_basename, 'Generated name: {}, expected: {}'.format(\n            made_basename, basename\n        )\n    \n    def test_basename_with_pretrained_weights(self):\n        basename = 'rrdn-C2-D3-G20-G020-T2-x2'\n        self.TH.pretrained_weights_path = self.weights_path\n        made_basename = self.TH._make_basename()\n        self.TH.pretrained_weights_path = {}\n        assert basename == made_basename, 'Generated name: {}, expected: {}'.format(\n            made_basename, basename\n        )\n    \n    def test_callback_paths_creation(self):\n        # reset session_id\n        self.TH.callback_paths = self.TH._make_callback_paths()\n        self.assertTrue(\n            self.TH.callback_paths['weights']\n            == Path('tests/temporary_test_data/weights/rrdn-C2-D3-G20-G020-T2-x2/0000')\n        )\n        self.assertTrue(\n            self.TH.callback_paths['logs']\n            == Path('tests/temporary_test_data/logs/rrdn-C2-D3-G20-G020-T2-x2/0000')\n        )\n    \n    def test_weights_naming(self):\n        w_names = {\n            'generator': Path(\n                'tests/temporary_test_data/weights/rrdn-C2-D3-G20-G020-T2-x2/0000/rrdn-C2-D3-G20-G020-T2-x2{metric}_epoch{epoch:03d}.hdf5'\n            ),\n            'discriminator': Path(\n                'tests/temporary_test_data/weights/rrdn-C2-D3-G20-G020-T2-x2/0000/srgan-large{metric}_epoch{epoch:03d}.hdf5'\n            ),\n        }\n        cb_paths = self.TH._make_callback_paths()\n        generated_names = self.TH._weights_name(cb_paths)\n        assert (\n                w_names['generator'] == generated_names['generator']\n        ), 'Generated names: {}, expected: {}'.format(\n            generated_names['generator'], w_names['generator']\n        )\n        assert (\n                w_names['discriminator'] == generated_names['discriminator']\n        ), 'Generated names: {}, expected: {}'.format(\n            generated_names['discriminator'], w_names['discriminator']\n        )\n    \n    def test_mock_training_setting_printer(self):\n        with patch(\n                'ISR.utils.train_helper.TrainerHelper.print_training_setting', return_value=True\n        ):\n            self.assertTrue(self.TH.print_training_setting())\n    \n    def test_weights_saving(self):\n        \n        self.TH.callback_paths = self.TH._make_callback_paths()\n        self.TH.weights_name = self.TH._weights_name(self.TH.callback_paths)\n        Path('tests/temporary_test_data/weights/rrdn-C2-D3-G20-G020-T2-x2/0000/').mkdir(\n            parents=True\n        )\n        self.TH._save_weights(1, self.TH.generator.model, self.TH.discriminator, best=False)\n        \n        assert Path(\n            './tests/temporary_test_data/weights/rrdn-C2-D3-G20-G020-T2-x2/0000/rrdn-C2-D3-G20-G020-T2-x2_epoch002.hdf5'\n        ).exists()\n        assert Path(\n            './tests/temporary_test_data/weights/rrdn-C2-D3-G20-G020-T2-x2/0000/srgan-large_epoch002.hdf5'\n        ).exists()\n    \n    def test_mock_epoch_end(self):\n        with patch('ISR.utils.train_helper.TrainerHelper.on_epoch_end', return_value=True):\n            self.assertTrue(self.TH.on_epoch_end())\n    \n    def test_epoch_number_from_weights_names(self):\n        w_names = {\n            'generator': 'test_gen_weights_TEST-vgg19-1-2-srgan-large-e003.hdf5',\n            'discriminator': 'txxxxxxxxepoch003xxxxxhdf5',\n            'discriminator2': 'test_discr_weights_TEST-vgg19-1-2-srgan-large-epoch03.hdf5',\n        }\n        e_n = self.TH.epoch_n_from_weights_name(w_names['generator'])\n        assert e_n == 0\n        e_n = self.TH.epoch_n_from_weights_name(w_names['discriminator'])\n        assert e_n == 3\n        e_n = self.TH.epoch_n_from_weights_name(w_names['discriminator2'])\n        assert e_n == 0\n    \n    def test_mock_initalize_training(self):\n        with patch('ISR.utils.train_helper.TrainerHelper.initialize_training', return_value=True):\n            self.assertTrue(self.TH.initialize_training())\n"""
tests/utils/test_utils.py,0,"b""import logging\nimport os\nimport unittest\n\nimport yaml\nfrom unittest.mock import patch\n\nfrom ISR.utils import utils\n\nlogger = utils.get_logger(__name__)\n\n\nclass UtilsClassTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        \n        logging.disable(logging.CRITICAL)\n    \n    @classmethod\n    def tearDownClass(cls):\n        pass\n    \n    def setUp(self):\n        pass\n    \n    def tearDown(self):\n        pass\n    \n    def test_check_parameter_keys(self):\n        par = {'a': 0}\n        utils.check_parameter_keys(parameter=par, needed_keys=['a'])\n        utils.check_parameter_keys(\n            parameter=par, needed_keys=None, optional_keys=['b'], default_value=-1\n        )\n        self.assertTrue(par['b'] == -1)\n        try:\n            utils.check_parameter_keys(parameter=par, needed_keys=['c'])\n        except:\n            self.assertTrue(True)\n        else:\n            self.assertTrue(False)\n        \n        def check_parameter_keys(parameter, needed_keys, optional_keys=None, default_value=None):\n            if needed_keys:\n                for key in needed_keys:\n                    if key not in parameter:\n                        logger.error('{p} is missing key {k}'.format(p=parameter, k=key))\n                        raise\n            if optional_keys:\n                for key in optional_keys:\n                    if key not in parameter:\n                        logger.info(\n                            'Setting {k} in {p} to {d}'.format(k=key, p=parameter, d=default_value)\n                        )\n                        parameter[key] = default_value\n    \n    def test_config_from_weights_valid(self):\n        weights = os.path.join('a', 'path', 'to', 'rdn-C3-D1-G7-G05-x2')\n        arch_params = {'C': None, 'D': None, 'G': None, 'G0': None, 'x': None}\n        expected_params = {'C': 3, 'D': 1, 'G': 7, 'G0': 5, 'x': 2}\n        name = 'rdn'\n        generated_param = utils.get_config_from_weights(\n            w_path=weights, arch_params=arch_params, name=name\n        )\n        for p in expected_params:\n            self.assertTrue(generated_param[p] == expected_params[p])\n    \n    def test_config_from_weights_invalid(self):\n        weights = os.path.join('a', 'path', 'to', 'rrdn-C3-D1-G7-G05-x2')\n        arch_params = {'C': None, 'D': None, 'G': None, 'G0': None, 'x': None, 'T': None}\n        name = 'rdn'\n        try:\n            generated_param = utils.get_config_from_weights(\n                w_path=weights, arch_params=arch_params, name=name\n            )\n        except:\n            self.assertTrue(True)\n        else:\n            self.assertFalse(True)\n    \n    def test_setup_default_training(self):\n        base_conf = {}\n        base_conf['default'] = {\n            'generator': 'rrdn',\n            'feature_extractor': False,\n            'discriminator': False,\n            'training_set': 'div2k-x4',\n            'test_set': 'dummy',\n        }\n        training = True\n        prediction = False\n        default = True\n        \n        with patch('yaml.load', return_value=base_conf) as import_module:\n            session_type, generator, conf, dataset = utils.setup(\n                'tests/data/config.yml', default, training, prediction\n            )\n        self.assertTrue(session_type == 'training')\n        self.assertTrue(generator == 'rrdn')\n        self.assertTrue(conf == base_conf)\n        self.assertTrue(dataset == 'div2k-x4')\n    \n    def test_setup_default_prediction(self):\n        base_conf = {}\n        base_conf['default'] = {\n            'generator': 'rdn',\n            'feature_extractor': False,\n            'discriminator': False,\n            'training_set': 'div2k-x4',\n            'test_set': 'dummy',\n        }\n        base_conf['generators'] = {'rdn': {'C': None, 'D': None, 'G': None, 'G0': None, 'x': None}}\n        base_conf['weights_paths'] = {\n            'generator': os.path.join('a', 'path', 'to', 'rdn-C3-D1-G7-G05-x2')\n        }\n        training = False\n        prediction = True\n        default = True\n        \n        with patch('yaml.load', return_value=base_conf):\n            session_type, generator, conf, dataset = utils.setup(\n                'tests/data/config.yml', default, training, prediction\n            )\n        self.assertTrue(session_type == 'prediction')\n        self.assertTrue(generator == 'rdn')\n        self.assertTrue(conf == base_conf)\n        self.assertTrue(dataset == 'dummy')\n    \n    def test__get_parser(self):\n        parser = utils._get_parser()\n        cl_args = parser.parse_args(['--training'])\n        namespace = cl_args._get_kwargs()\n        self.assertTrue(('training', True) in namespace)\n        self.assertTrue(('prediction', False) in namespace)\n        self.assertTrue(('default', False) in namespace)\n        pass\n    \n    @patch('builtins.input', return_value='1')\n    def test_select_option(self, input):\n        self.assertEqual(utils.select_option(['0', '1'], ''), '1')\n        self.assertNotEqual(utils.select_option(['0', '1'], ''), '0')\n    \n    @patch('builtins.input', return_value='2 0')\n    def test_select_multiple_options(self, input):\n        self.assertEqual(utils.select_multiple_options(['0', '1', '3'], ''), ['3', '0'])\n        self.assertNotEqual(utils.select_multiple_options(['0', '1', '3'], ''), ['0', '3'])\n    \n    @patch('builtins.input', return_value='1')\n    def test_select_positive_integer(self, input):\n        self.assertEqual(utils.select_positive_integer(''), 1)\n        self.assertNotEqual(utils.select_positive_integer(''), 0)\n    \n    @patch('builtins.input', return_value='1.3')\n    def test_select_positive_float(self, input):\n        self.assertEqual(utils.select_positive_float(''), 1.3)\n        self.assertNotEqual(utils.select_positive_float(''), 0)\n    \n    @patch('builtins.input', return_value='y')\n    def test_select_bool_true(self, input):\n        self.assertEqual(utils.select_bool(''), True)\n        self.assertNotEqual(utils.select_bool(''), False)\n    \n    @patch('builtins.input', return_value='n')\n    def test_select_bool_false(self, input):\n        self.assertEqual(utils.select_bool(''), False)\n        self.assertNotEqual(utils.select_bool(''), True)\n    \n    @patch('builtins.input', return_value='0')\n    def test_browse_weights(self, sel_pos):\n        def folder_weights_select(inp):\n            if inp == '':\n                return ['folder']\n            if inp == 'folder':\n                return ['1.hdf5']\n        \n        with patch('os.listdir', side_effect=folder_weights_select):\n            weights = utils.browse_weights('')\n        self.assertEqual(weights, 'folder/1.hdf5')\n    \n    @patch('builtins.input', return_value='0')\n    def test_select_dataset(self, sel_opt):\n        conf = yaml.load(open(os.path.join('tests', 'data', 'config.yml'), 'r'))\n        conf['test_sets'] = {'test_test_set': {}}\n        conf['training_sets'] = {'test_train_set': {}}\n        \n        tr_data = utils.select_dataset('training', conf)\n        pr_data = utils.select_dataset('prediction', conf)\n        \n        self.assertEqual(tr_data, 'test_train_set')\n        self.assertEqual(pr_data, 'test_test_set')\n    \n    def test_suggest_metrics(self):\n        metrics = utils.suggest_metrics(\n            discriminator=False, feature_extractor=False, loss_weights={}\n        )\n        self.assertTrue('val_loss' in metrics)\n        self.assertFalse('val_generator_loss' in metrics)\n        metrics = utils.suggest_metrics(\n            discriminator=True, feature_extractor=False, loss_weights={}\n        )\n        self.assertTrue('val_generator_loss' in metrics)\n        self.assertFalse('val_feature_extractor_loss' in metrics)\n        self.assertFalse('val_loss' in metrics)\n        metrics = utils.suggest_metrics(discriminator=True, feature_extractor=True, loss_weights={})\n        self.assertTrue('val_feature_extractor_loss' in metrics)\n        self.assertTrue('val_generator_loss' in metrics)\n        self.assertFalse('val_loss' in metrics)\n        metrics = utils.suggest_metrics(\n            discriminator=False, feature_extractor=True, loss_weights={}\n        )\n        self.assertTrue('val_feature_extractor_loss' in metrics)\n        self.assertTrue('val_generator_loss' in metrics)\n        self.assertFalse('val_loss' in metrics)\n"""
