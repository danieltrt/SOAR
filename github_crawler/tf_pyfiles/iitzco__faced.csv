file_path,api_count,code
setup.py,0,"b'from setuptools import setup\n\n\ndef readme():\n    with open(\'README.md\') as f:\n        return f.read()\n\nwith open(\'requirements.txt\') as f:\n    required = f.read().splitlines()\n\nsetup(name=\'faced\',\n      version=\'0.1\',\n      description=\'Face detection using deep learning\',\n      long_description=readme(),\n      classifiers=[\n        \'Development Status :: 3 - Alpha\',\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python :: 3\',\n        \'Topic :: Text Processing :: Linguistic\',\n      ],\n      keywords=\'face detection deep learning cnn neural network\',\n      url=\'http://github.com/iitzco/faced\',\n      author=\'Ivan Itzcovich\',\n      author_email=\'i.itzcovich@gmail.com\',\n      license=\'MIT\',\n      packages=[\'faced\'],\n      scripts=[""bin/faced""],\n      install_requires=required,\n      python_requires=\'>3.4\',\n      include_package_data=True,\n      zip_safe=False)\n'"
faced/__init__.py,0,b'from faced.detector import FaceDetector\n'
faced/const.py,0,"b'import os\n\nMODELS_PATH = os.path.join(os.path.dirname(__file__), ""models"")\n\nYOLO_SIZE = 288\nYOLO_TARGET = 9\n\nCORRECTOR_SIZE = 50\n'"
faced/detector.py,27,"b'import tensorflow as tf\nimport cv2\nimport numpy as np\nimport os\n\nfrom faced.const import YOLO_TARGET, YOLO_SIZE, CORRECTOR_SIZE, MODELS_PATH\nfrom faced.utils import iou\n\n\nclass FaceDetector(object):\n\n    def __init__(self):\n        self.load_model(os.path.join(MODELS_PATH, ""face_yolo.pb""))\n        self.load_aux_vars()\n\n        self.face_corrector = FaceCorrector()\n\n    def load_aux_vars(self):\n        cols = np.zeros(shape=[1, YOLO_TARGET])\n        for i in range(1, YOLO_TARGET):\n            cols = np.concatenate((cols, np.full((1, YOLO_TARGET), i)), axis=0)\n\n        self.cols = cols\n        self.rows = cols.T\n\n    def load_model(self, yolo_model, from_pb=True):\n        graph = tf.Graph()\n        with graph.as_default():\n            self.sess = tf.Session()\n\n            if from_pb:\n                with tf.gfile.GFile(yolo_model, ""rb"") as f:\n                    graph_def = tf.GraphDef()\n                    graph_def.ParseFromString(f.read())\n                    tf.import_graph_def(graph_def, name="""") # If not, name is appended in op name\n\n            else:\n                ckpt_path = tf.train.latest_checkpoint(yolo_model)\n                saver = tf.train.import_meta_graph(\'{}.meta\'.format(ckpt_path))\n                saver.restore(self.sess, ckpt_path)\n\n            self.img = tf.get_default_graph().get_tensor_by_name(""img:0"")\n            self.training = tf.get_default_graph().get_tensor_by_name(""training:0"")\n            self.prob = tf.get_default_graph().get_tensor_by_name(""prob:0"")\n            self.x_center = tf.get_default_graph().get_tensor_by_name(""x_center:0"")\n            self.y_center = tf.get_default_graph().get_tensor_by_name(""y_center:0"")\n            self.w = tf.get_default_graph().get_tensor_by_name(""w:0"")\n            self.h = tf.get_default_graph().get_tensor_by_name(""h:0"")\n\n    # Receives RGB numpy array\n    def predict(self, frame, thresh=0.85):\n        input_img = cv2.resize(frame, (YOLO_SIZE, YOLO_SIZE)) / 255.\n        input_img = np.expand_dims(input_img, axis=0)\n\n        pred = self.sess.run([self.prob, self.x_center, self.y_center, self.w, self.h], feed_dict={self.training: False, self.img: input_img})\n\n        bboxes = self._absolute_bboxes(pred, frame, thresh)\n        bboxes = self._correct(frame, bboxes)\n        bboxes = self._nonmax_supression(bboxes)\n\n        return bboxes\n\n    def _absolute_bboxes(self, pred, frame, thresh):\n        img_h, img_w, _ = frame.shape\n        p, x, y, w, h = pred\n\n        mask = p > thresh\n\n        x += self.cols\n        y += self.rows\n\n        p, x, y, w, h = p[mask], x[mask], y[mask], w[mask], h[mask]\n\n        ret = []\n\n        for j in range(x.shape[0]):\n            xc, yc = int((x[j]/YOLO_TARGET)*img_w), int((y[j]/YOLO_TARGET)*img_h)\n            wi, he = int(w[j]*img_w), int(h[j]*img_h)\n            ret.append((xc, yc, wi, he, p[j]))\n\n        return ret\n\n    def _nonmax_supression(self, bboxes, thresh=0.2):\n        SUPPRESSED = 1\n        NON_SUPPRESSED = 2\n\n        N = len(bboxes)\n        status = [None] * N\n        for i in range(N):\n            if status[i] is not None:\n                continue\n\n            curr_max_p = bboxes[i][-1]\n            curr_max_index = i\n\n            for j in range(i+1, N):\n                if status[j] is not None:\n                    continue\n\n                metric = iou(bboxes[i], bboxes[j])\n                if metric > thresh:\n                    if bboxes[j][-1] > curr_max_p:\n                        status[curr_max_index] = SUPPRESSED\n                        curr_max_p = bboxes[j][-1]\n                        curr_max_index = j\n                    else:\n                        status[j] = SUPPRESSED\n\n            status[curr_max_index] = NON_SUPPRESSED\n\n        return [bboxes[i] for i in range(N) if status[i] == NON_SUPPRESSED]\n\n    def _correct(self, frame, bboxes):\n        N = len(bboxes)\n        ret = []\n\n        img_h, img_w, _ = frame.shape\n        for i in range(N):\n            x, y, w, h, p = bboxes[i]\n\n            MARGIN = 0.5\n            # Add margin\n            xmin = int(max(0, x - w/2 - MARGIN*w))\n            xmax = int(min(img_w, x + w/2 + MARGIN*w))\n            ymin = int(max(0, y - h/2 - MARGIN*h))\n            ymax = int(min(img_h, y + h/2 + MARGIN*h))\n\n            face = frame[ymin:ymax, xmin:xmax, :]\n            x, y, w, h = self.face_corrector.predict(face)\n\n            ret.append((x + xmin, y + ymin, w, h, p))\n\n        return ret\n\n\nclass FaceCorrector(object):\n\n    def __init__(self):\n        self.load_model(os.path.join(MODELS_PATH, ""face_corrector.pb""))\n\n    def load_model(self, corrector_model, from_pb=True):\n        self.graph = tf.Graph()\n        with self.graph.as_default():\n            self.sess = tf.Session()\n            if from_pb:\n                with tf.gfile.GFile(corrector_model, ""rb"") as f:\n                    graph_def = tf.GraphDef()\n                    graph_def.ParseFromString(f.read())\n                    tf.import_graph_def(graph_def, name="""") # If not, name is appended in op name\n\n            else:\n                ckpt_path = tf.train.latest_checkpoint(corrector_model)\n                saver = tf.train.import_meta_graph(\'{}.meta\'.format(ckpt_path))\n                saver.restore(self.sess, ckpt_path)\n\n            self.img = tf.get_default_graph().get_tensor_by_name(""img:0"")\n            self.training = tf.get_default_graph().get_tensor_by_name(""training:0"")\n            self.x = tf.get_default_graph().get_tensor_by_name(""X:0"")\n            self.y = tf.get_default_graph().get_tensor_by_name(""Y:0"")\n            self.w = tf.get_default_graph().get_tensor_by_name(""W:0"")\n            self.h = tf.get_default_graph().get_tensor_by_name(""H:0"")\n\n    def predict(self, frame):\n        # Preprocess\n        input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        input_img = cv2.resize(input_img, (CORRECTOR_SIZE, CORRECTOR_SIZE)) / 255.\n        input_img = np.reshape(input_img, [1, CORRECTOR_SIZE, CORRECTOR_SIZE, 3])\n\n        x, y, w, h = self.sess.run([self.x, self.y, self.w, self.h], feed_dict={self.training: False, self.img: input_img})\n\n        img_h, img_w, _ = frame.shape\n\n        x = int(x*img_w)\n        w = int(w*img_w)\n\n        y = int(y*img_h)\n        h = int(h*img_h)\n\n        return x, y, w, h\n'"
faced/utils.py,0,"b'import cv2\n\ndef iou(bbox1, bbox2):\n    # determine the (x, y)-coordinates of the intersection rectangle\n    boxA = bbox1[0] - bbox1[2]/2, bbox1[1] - bbox1[3]/2, bbox1[0] + bbox1[2]/2, bbox1[1] + bbox1[3]/2\n    boxB = bbox2[0] - bbox2[2]/2, bbox2[1] - bbox2[3]/2, bbox2[0] + bbox2[2]/2, bbox2[1] + bbox2[3]/2\n\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n\n    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n\n    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n\n    ret = interArea / float(boxAArea + boxBArea - interArea)\n\n    return ret\n\n\ndef annotate_image(frame, bboxes):\n    ret = frame[:]\n\n    img_h, img_w, _ = frame.shape\n\n    for x, y, w, h, p in bboxes:\n        cv2.rectangle(ret, (int(x - w/2), int(y - h/2)), (int(x + w/2), int(y + h/2)), (0, 255, 0), 3)\n\n    return ret\n'"
