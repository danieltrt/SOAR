file_path,api_count,code
gan.py,13,"b'\'\'\'TensorFlow implementation of http://arxiv.org/pdf/1511.06434.pdf\'\'\'\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\n\nimport numpy as np\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib import losses\nfrom tensorflow.contrib.framework import arg_scope\nimport tensorflow as tf\n\nfrom utils import discriminator, decoder\nfrom generator import Generator\n\ndef concat_elu(inputs):\n    return tf.nn.elu(tf.concat(3, [-inputs, inputs]))\n\nclass GAN(Generator):\n\n    def __init__(self, hidden_size, batch_size, learning_rate):\n        self.input_tensor = tf.placeholder(tf.float32, [None, 28 * 28])\n\n        with arg_scope([layers.conv2d, layers.conv2d_transpose],\n                       activation_fn=concat_elu,\n                       normalizer_fn=layers.batch_norm,\n                       normalizer_params={\'scale\': True}):\n            with tf.variable_scope(""model""):\n                D1 = discriminator(self.input_tensor)  # positive examples\n                D_params_num = len(tf.trainable_variables())\n                G = decoder(tf.random_normal([batch_size, hidden_size]))\n                self.sampled_tensor = G\n\n            with tf.variable_scope(""model"", reuse=True):\n                D2 = discriminator(G)  # generated examples\n\n        D_loss = self.__get_discrinator_loss(D1, D2)\n        G_loss = self.__get_generator_loss(D2)\n\n        params = tf.trainable_variables()\n        D_params = params[:D_params_num]\n        G_params = params[D_params_num:]\n        #    train_discrimator = optimizer.minimize(loss=D_loss, var_list=D_params)\n        # train_generator = optimizer.minimize(loss=G_loss, var_list=G_params)\n        global_step = tf.contrib.framework.get_or_create_global_step()\n        self.train_discrimator = layers.optimize_loss(\n            D_loss, global_step, learning_rate / 10, \'Adam\', variables=D_params, update_ops=[])\n        self.train_generator = layers.optimize_loss(\n            G_loss, global_step, learning_rate, \'Adam\', variables=G_params, update_ops=[])\n\n        self.sess = tf.Session()\n        self.sess.run(tf.global_variables_initializer())\n\n    def __get_discrinator_loss(self, D1, D2):\n        \'\'\'Loss for the discriminator network\n\n        Args:\n            D1: logits computed with a discriminator networks from real images\n            D2: logits computed with a discriminator networks from generated images\n\n        Returns:\n            Cross entropy loss, positive samples have implicit labels 1, negative 0s\n        \'\'\'\n        return (losses.sigmoid_cross_entropy(D1, tf.ones(tf.shape(D1))) +\n                losses.sigmoid_cross_entropy(D2, tf.zeros(tf.shape(D1))))\n\n    def __get_generator_loss(self, D2):\n        \'\'\'Loss for the genetor. Maximize probability of generating images that\n        discrimator cannot differentiate.\n\n        Returns:\n            see the paper\n        \'\'\'\n        return losses.sigmoid_cross_entropy(D2, tf.ones(tf.shape(D2)))\n\n    def update_params(self, inputs):\n        d_loss_value = self.sess.run(self.train_discrimator, {\n            self.input_tensor: inputs})\n\n        g_loss_value = self.sess.run(self.train_generator)\n\n        return g_loss_value\n'"
generator.py,0,"b""import os\nfrom scipy.misc import imsave\n\nclass Generator(object):\n\n    def update_params(self, input_tensor):\n        '''Update parameters of the network\n\n        Args:\n            input_tensor: a batch of flattened images\n\n        Returns:\n            Current loss value\n        '''\n        raise NotImplementedError()\n\n    def generate_and_save_images(self, num_samples, directory):\n        '''Generates the images using the model and saves them in the directory\n\n        Args:\n            num_samples: number of samples to generate\n            directory: a directory to save the images\n        '''\n        imgs = self.sess.run(self.sampled_tensor)\n        for k in range(imgs.shape[0]):\n            imgs_folder = os.path.join(directory, 'imgs')\n            if not os.path.exists(imgs_folder):\n                os.makedirs(imgs_folder)\n\n            imsave(os.path.join(imgs_folder, '%d.png') % k,\n                   imgs[k].reshape(28, 28))\n"""
main-draw.py,66,"b'\'\'\'TensorFlow implementation of http://arxiv.org/pdf/1502.04623v2.pdf\n\nDISCLAIMER\nWork in progress. This code requires massive refactoring.\n\'\'\'\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\nimport os\n\nimport numpy as np\nimport prettytensor as pt\nimport scipy.misc\nimport tensorflow as tf\nfrom scipy.misc import imsave\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom progressbar import ETA, Bar, Percentage, ProgressBar\n\nflags = tf.flags\nlogging = tf.logging\n\nflags.DEFINE_integer(""batch_size"", 8, ""batch size"")\nflags.DEFINE_integer(""updates_per_epoch"", 1000, ""number of updates per epoch"")\nflags.DEFINE_integer(""max_epoch"", 100, ""max epoch"")\nflags.DEFINE_float(""learning_rate"", 1e-3, ""learning rate"")\nflags.DEFINE_string(""working_directory"", """", """")\nflags.DEFINE_integer(""rnn_size"", 128, ""size of the hidden VAE unit"")\nflags.DEFINE_integer(""rnn_len"", 16, ""size of the hidden VAE unit"")\nflags.DEFINE_integer(""hidden_size"", 10, ""size of the hidden VAE unit"")\nflags.DEFINE_integer(""N"", 5, ""crop size"")\n\nFLAGS = flags.FLAGS\n\n\n# inspired by https://github.com/jbornschein/draw\n# TODO: better names for N, A, B\ndef filterbank_matrices(g_x, g_y, delta, sigma, N, A, B):\n    \'\'\' Computer filter bank matrices. All inputs are in batches.\n\n    Args:\n        g_x, g_y: grid centers, relative to the center of the image\n        delta: strides\n        sigma: isotropic variance\n        N: grid dimension\n        A, B: input image dimensions, width and height\n    Returns:\n        F_x, F_y: filter banks matrices [batch, N, A] and [batch, N, B]\n    \'\'\'\n\n    rng = tf.reshape(tf.cast(tf.range(N), tf.float32), [1, -1])\n\n    # eq 19\n    mu_x = g_x + (rng - N / 2 - 0.5) * delta\n\n    # eq 20\n    mu_y = g_y + (rng - N / 2 - 0.5) * delta\n\n    a = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n    b = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n\n    # reshape for broadcasting\n    mu_x = tf.reshape(mu_x, [-1, N, 1])\n    mu_y = tf.reshape(mu_y, [-1, N, 1])\n    sigma = tf.reshape(sigma, [-1, 1, 1])\n\n    F_x = tf.exp(-tf.square((a - mu_x) / sigma))\n    F_y = tf.exp(-tf.square((b - mu_y) / sigma))\n\n    # transform in a convenient form for further use\n    return F_x, F_y\n\n\ndef apply_filters(image, F_x, F_y, gamma, N, A, B, forward=True, epsilon=1e-9):\n    \'\'\'Apply a batch of filter banks to a batch of images.\n\n    Args:\n        image: image, [batch, w, h, c]\n        F_x, F_y: filter banks matrices [batch, N, A] and [batch, N, B]\n    Returns:\n        filtered image\n    \'\'\'\n\n    F_x = F_x / tf.maximum(tf.reduce_sum(F_x, 2, keep_dims=True), epsilon)\n    F_y = F_y / tf.maximum(tf.reduce_sum(F_y, 2, keep_dims=True), epsilon)\n    if forward:\n        F_y = tf.reshape(F_y, [-1, N, B, 1, 1])\n        image = tf.reshape(image, [-1, 1, B, A, 1])\n        image = tf.tile(image, [1, N, 1, 1, 1])\n        image = tf.reduce_sum(F_y * image, 2)\n\n        image = tf.reshape(image, [-1, N, A, 1, 1])\n        F_x = tf.transpose(F_x, [0, 2, 1])\n        F_x = tf.reshape(F_x, [-1, 1, A, N, 1])\n        F_x = tf.tile(F_x, [1, N, 1, 1, 1])\n\n        image = tf.reduce_sum(image * F_x, 2)\n\n        return image * tf.reshape(gamma, [-1, 1, 1, 1])\n    else:\n        F_y = tf.transpose(F_y, [0, 2, 1])\n        F_y = tf.reshape(F_y, [-1, B, N, 1, 1])\n        image = tf.reshape(image, [-1, 1, N, N, 1])\n        image = tf.tile(image, [1, B, 1, 1, 1])\n        image = tf.reduce_sum(F_y * image, 2)\n\n        image = tf.reshape(image, [-1, B, N, 1, 1])\n        F_x = tf.reshape(F_x, [-1, 1, N, A, 1])\n        F_x = tf.tile(F_x, [1, B, 1, 1, 1])\n        image = tf.reduce_sum(image * F_x, 2)\n\n        return image * tf.reshape(1.0 / gamma, [-1, 1, 1, 1])\n\n\ndef transform_params(input_tensor, N, A, B):\n    \'\'\'Transformes a raw NN output into a set of parameters\n        See the paper.\n    Args:\n        input_tensor:\n        N:\n        A:\n        B:\n    \'\'\'\n    g_x, g_y, log_sigma_sqr, log_delta, log_gamma = tf.split(1, 5, input_tensor)\n    g_x = (A + 1) / 2 * (g_x + 1)\n    g_y = (B + 1) / 2 * (g_y + 1)\n    sigma = tf.exp(log_sigma_sqr / 2.0)\n    delta = (max(A, B) - 1) / (N - 1) * tf.exp(log_delta)\n    gamma = tf.exp(log_gamma)\n    return g_x, g_y, delta, sigma, gamma\n\n\ndef get_vae_cost(mean, stddev, epsilon=1e-8):\n    \'\'\'VAE loss\n        See the paper\n\n    Args:\n        mean:\n        stddev:\n        epsilon:\n    \'\'\'\n    return tf.reduce_sum(0.5 * (tf.square(mean) + tf.square(stddev) -\n                                2.0 * tf.log(stddev + epsilon) - 1.0))\n\n\ndef get_reconstruction_cost(output_tensor, target_tensor, epsilon=1e-8):\n    \'\'\'Reconstruction loss\n\n    Cross entropy reconstruction loss\n\n    Args:\n        output_tensor: tensor produces by decoder\n        target_tensor: the target tensor that we want to reconstruct\n        epsilon:\n    \'\'\'\n    return tf.reduce_sum(-target_tensor * tf.log(output_tensor + epsilon) -\n                         (1.0 - target_tensor) * tf.log(1.0 - output_tensor + epsilon))\n\nif __name__ == ""__main__"":\n    data_directory = os.path.join(FLAGS.working_directory, ""MNIST"")\n    if not os.path.exists(data_directory):\n        os.makedirs(data_directory)\n    mnist = input_data.read_data_sets(data_directory, one_hot=True)\n\n    input_tensor = tf.placeholder(tf.float32, [FLAGS.batch_size, 28 * 28])\n    output_tensor = tf.zeros([FLAGS.batch_size, 28 * 28], tf.float32)\n    sampled_tensor = tf.zeros([FLAGS.batch_size, 28 * 28], tf.float32)\n\n    # TODO: Remove magic number\n    encoder_state = (pt.wrap(tf.zeros([FLAGS.batch_size, FLAGS.rnn_size], tf.float32)),)\n    decoder_state = (pt.wrap(tf.zeros([FLAGS.batch_size, FLAGS.rnn_size], tf.float32)),)\n\n    sampled_state = (pt.wrap(tf.zeros([FLAGS.batch_size, FLAGS.rnn_size], tf.float32)),)\n\n    sampled_tensors = []\n    glimpse_tensors = []\n    write_tensors = []\n    params_tensors = []\n\n    loss = 0.0\n    with tf.variable_scope(""model""):\n        with pt.defaults_scope(activation_fn=tf.nn.elu,\n                               batch_normalize=True,\n                               learned_moments_update_rate=0.1,\n                               variance_epsilon=0.001,\n                               scale_after_normalization=True):\n            # Encoder RNN (Eq. 5)\n            encoder_template = (pt.template(\'input\').\n                                gru_cell(num_units=FLAGS.rnn_size, state=pt.UnboundVariable(\'state\')))\n\n            # Projection of encoder RNN output (Eq. 1-2)\n            encoder_proj_template = (pt.template(\'input\').\n                                     fully_connected(FLAGS.hidden_size * 2, activation_fn=None))\n\n            # Params of read from decoder RNN output (Eq. 21)\n            decoder_read_params_template = (pt.template(\'input\').\n                                            fully_connected(5, activation_fn=None))\n\n            # Decoder RNN (Eq. 7)\n            decoder_template = (pt.template(\'input\').\n                                gru_cell(num_units=FLAGS.rnn_size, state=pt.UnboundVariable(\'state\')))\n\n            # Projection of decoder RNN output (Eq. 18)\n            decoder_proj_template = (pt.template(\'input\').\n                                     fully_connected(FLAGS.N * FLAGS.N, activation_fn=None))\n\n            # Projection of decoder RNN output (Eq. 18)\n            decoder_write_params_template = (pt.template(\'input\').\n                                             fully_connected(5, activation_fn=None))\n\n            for _ in range(FLAGS.rnn_len):\n                epsilon = tf.random_normal([FLAGS.batch_size, FLAGS.hidden_size])\n\n                # For unknown reason combination of batch normalization and phases within\n                # templates doesn\'t work. Hopefully, the workaround below works as\n                # intended.\n                with pt.defaults_scope(phase=pt.Phase.train):\n                    attention_params = decoder_read_params_template.construct(\n                        input=decoder_state[0].tensor)\n                    g_x, g_y, delta, sigma, gamma = transform_params(\n                        attention_params, FLAGS.N, 28, 28)\n                    F_x, F_y = filterbank_matrices(\n                        g_x, g_y, delta, sigma, FLAGS.N, 28, 28)\n                    image_tensor = tf.reshape(input_tensor, [FLAGS.batch_size, 28, 28, 1])\n                    image_glipse = apply_filters(image_tensor, F_x, F_y, gamma, FLAGS.N, 28, 28)\n\n                    image_hat_tensor = tf.reshape(\n                        input_tensor - tf.nn.sigmoid(output_tensor), [FLAGS.batch_size, 28, 28, 1])\n                    image_hat_glipse = apply_filters(\n                        image_hat_tensor, F_x, F_y, gamma, FLAGS.N, 28, 28)\n\n                    encoder_input_tensor = pt.wrap(\n                        tf.concat(1, [tf.reshape(image_glipse, [FLAGS.batch_size, -1]), tf.reshape(image_hat_glipse, [FLAGS.batch_size, -1]), decoder_state[0].tensor]))\n\n                    encoded_tensor, encoder_state = encoder_template.construct(\n                        input=encoder_input_tensor, state=encoder_state[0].tensor)\n\n                    hidden_tensor = encoder_proj_template.construct(input=encoded_tensor)\n                    mean = hidden_tensor[:, :FLAGS.hidden_size]\n                    stddev = tf.sqrt(tf.exp(hidden_tensor[:, FLAGS.hidden_size:]))\n                    input_sample = mean + epsilon * stddev\n\n                    decoder_output_tensor, decoder_state = decoder_template.construct(\n                        input=input_sample, state=decoder_state[0].tensor)\n\n                    attention_params = decoder_write_params_template.construct(\n                        input=decoder_state[0].tensor)\n                    g_x, g_y, delta, sigma, gamma = transform_params(\n                        attention_params, FLAGS.N, 28, 28)\n                    F_x, F_y = filterbank_matrices(\n                        g_x, g_y, delta, sigma, FLAGS.N, 28, 28)\n\n                    decoder_output_image_tensor = decoder_proj_template.construct(\n                        input=decoder_output_tensor)\n\n                    image_tensor = tf.reshape(decoder_output_image_tensor, [\n                                              FLAGS.batch_size, FLAGS.N, FLAGS.N, 1])\n                    image_glipse = apply_filters(\n                        image_tensor, F_x, F_y, gamma, FLAGS.N, 28, 28, False)\n\n                    output_tensor = output_tensor + \\\n                        tf.reshape(image_glipse, [FLAGS.batch_size, -1])\n\n                    vae_loss = get_vae_cost(mean, stddev)\n\n                    loss = loss + vae_loss\n\n                with pt.defaults_scope(phase=pt.Phase.test):\n                    decoder_output_tensor, sampled_state = decoder_template.construct(\n                        input=epsilon, state=sampled_state[0].tensor)\n\n                    attention_params = decoder_write_params_template.construct(\n                        input=sampled_state[0].tensor)\n\n                    params_tensors.append(attention_params)\n\n                    g_x, g_y, delta, sigma, gamma = transform_params(\n                        attention_params, FLAGS.N, 28, 28)\n                    F_x, F_y = filterbank_matrices(\n                        g_x, g_y, delta, sigma, FLAGS.N, 28, 28)\n\n                    decoder_output_image_tensor = decoder_proj_template.construct(\n                        input=decoder_output_tensor)\n\n                    image_tensor = tf.reshape(decoder_output_image_tensor, [\n                                              FLAGS.batch_size, FLAGS.N, FLAGS.N, 1])\n\n                    glimpse_tensors.append(tf.nn.sigmoid(\n                        tf.reshape(1.0 / gamma, [-1, 1, 1, 1]) * image_tensor))\n\n                    image_glipse = apply_filters(\n                        image_tensor, F_x, F_y, gamma, FLAGS.N, 28, 28, False)\n\n                    write_tensors.append(tf.nn.sigmoid(image_glipse))\n\n                    sampled_tensor = sampled_tensor + \\\n                        tf.reshape(image_glipse, [FLAGS.batch_size, -1])\n\n                    sampled_tensors.append(tf.nn.sigmoid(sampled_tensor))\n\n    rec_loss = get_reconstruction_cost(tf.nn.sigmoid(output_tensor), input_tensor)\n    loss = loss + rec_loss\n\n    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate, beta1=0.5)\n    train = pt.apply_optimizer(optimizer, losses=[loss])\n\n    init = tf.initialize_all_variables()\n\n    with tf.Session() as sess:\n        sess.run(init)\n\n        for epoch in range(FLAGS.max_epoch):\n            training_loss = 0.0\n\n            widgets = [""epoch #%d|"" % epoch, Percentage(), Bar(), ETA()]\n            pbar = ProgressBar(max_value = FLAGS.updates_per_epoch, widgets=widgets)\n            pbar.start()\n            for i in range(FLAGS.updates_per_epoch):\n                pbar.update(i)\n                x, _ = mnist.train.next_batch(FLAGS.batch_size)\n                _, loss_value = sess.run([train, loss], {input_tensor: x})\n                training_loss += loss_value\n\n            training_loss = training_loss / \\\n                (FLAGS.updates_per_epoch * 28 * 28 * FLAGS.batch_size)\n\n            print(""Loss %f"" % training_loss)\n\n            results = sess.run(sampled_tensors + write_tensors + glimpse_tensors + params_tensors)\n\n            imgs = []\n            write_imgs = []\n            glimpse_imgs = []\n            img_params = []\n\n            for i in range(len(results) // 4):\n                imgs.append(results[i])\n                write_imgs.append(results[i + len(results) // 4])\n                glimpse_imgs.append(results[i + len(results) // 4 * 2])\n                img_params.append(results[i + len(results) // 4 * 3])\n\n            for k in range(FLAGS.batch_size):\n                imgs_folder = os.path.join(FLAGS.working_directory, \'imgs\')\n                if not os.path.exists(imgs_folder):\n                    os.makedirs(imgs_folder)\n                for i in range(len(imgs)):\n                    imsave(os.path.join(imgs_folder, \'%d_%d.png\') % (k, i),\n                           imgs[i][k].reshape(28, 28))\n\n                    imsave(os.path.join(imgs_folder, \'%d_%d_w.png\') % (k, i),\n                           write_imgs[i][k].reshape(28, 28))\n\n                    imsave(os.path.join(imgs_folder, \'%d_%d_g.png\') % (k, i),\n                           glimpse_imgs[i][k].reshape(FLAGS.N, FLAGS.N))\n'"
main.py,2,"b'\'\'\'TensorFlow implementation of http://arxiv.org/pdf/1312.6114v10.pdf\'\'\'\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\nimport os\n\nimport numpy as np\nimport scipy.misc\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib import losses\nfrom tensorflow.contrib.framework import arg_scope\nfrom scipy.misc import imsave\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom progressbar import ETA, Bar, Percentage, ProgressBar\n\nfrom vae import VAE\nfrom gan import GAN\n\nflags = tf.flags\nlogging = tf.logging\n\nflags.DEFINE_integer(""batch_size"", 128, ""batch size"")\nflags.DEFINE_integer(""updates_per_epoch"", 1000, ""number of updates per epoch"")\nflags.DEFINE_integer(""max_epoch"", 100, ""max epoch"")\nflags.DEFINE_float(""learning_rate"", 1e-2, ""learning rate"")\nflags.DEFINE_string(""working_directory"", """", """")\nflags.DEFINE_integer(""hidden_size"", 128, ""size of the hidden VAE unit"")\nflags.DEFINE_string(""model"", ""gan"", ""gan or vae"")\n\nFLAGS = flags.FLAGS\n\nif __name__ == ""__main__"":\n    data_directory = os.path.join(FLAGS.working_directory, ""MNIST"")\n    if not os.path.exists(data_directory):\n        os.makedirs(data_directory)\n    mnist = input_data.read_data_sets(data_directory, one_hot=True)\n\n    assert FLAGS.model in [\'vae\', \'gan\']\n    if FLAGS.model == \'vae\':\n        model = VAE(FLAGS.hidden_size, FLAGS.batch_size, FLAGS.learning_rate)\n    elif FLAGS.model == \'gan\':\n        model = GAN(FLAGS.hidden_size, FLAGS.batch_size, FLAGS.learning_rate)\n\n    for epoch in range(FLAGS.max_epoch):\n        training_loss = 0.0\n\n        pbar = ProgressBar()\n        for i in pbar(range(FLAGS.updates_per_epoch)):\n            images, _ = mnist.train.next_batch(FLAGS.batch_size)\n            loss_value = model.update_params(images)\n            training_loss += loss_value\n\n        training_loss = training_loss / \\\n            (FLAGS.updates_per_epoch * FLAGS.batch_size)\n\n        print(""Loss %f"" % training_loss)\n\n        model.generate_and_save_images(\n            FLAGS.batch_size, FLAGS.working_directory)\n'"
utils.py,4,"b""import tensorflow as tf\nfrom tensorflow.contrib import layers\n\n\ndef encoder(input_tensor, output_size):\n    '''Create encoder network.\n\n    Args:\n        input_tensor: a batch of flattened images [batch_size, 28*28]\n\n    Returns:\n        A tensor that expresses the encoder network\n    '''\n    net = tf.reshape(input_tensor, [-1, 28, 28, 1])\n    net = layers.conv2d(net, 32, 5, stride=2)\n    net = layers.conv2d(net, 64, 5, stride=2)\n    net = layers.conv2d(net, 128, 5, stride=2, padding='VALID')\n    net = layers.dropout(net, keep_prob=0.9)\n    net = layers.flatten(net)\n    return layers.fully_connected(net, output_size, activation_fn=None)\n\n\ndef discriminator(input_tensor):\n    '''Create a network that discriminates between images from a dataset and\n    generated ones.\n\n    Args:\n        input: a batch of real images [batch, height, width, channels]\n    Returns:\n        A tensor that represents the network\n    '''\n\n    return encoder(input_tensor, 1)\n\n\ndef decoder(input_tensor):\n    '''Create decoder network.\n\n        If input tensor is provided then decodes it, otherwise samples from\n        a sampled vector.\n    Args:\n        input_tensor: a batch of vectors to decode\n\n    Returns:\n        A tensor that expresses the decoder network\n    '''\n\n    net = tf.expand_dims(input_tensor, 1)\n    net = tf.expand_dims(net, 1)\n    net = layers.conv2d_transpose(net, 128, 3, padding='VALID')\n    net = layers.conv2d_transpose(net, 64, 5, padding='VALID')\n    net = layers.conv2d_transpose(net, 32, 5, stride=2)\n    net = layers.conv2d_transpose(\n        net, 1, 5, stride=2, activation_fn=tf.nn.sigmoid)\n    net = layers.flatten(net)\n    return net\n"""
vae.py,15,"b'\'\'\'TensorFlow implementation of http://arxiv.org/pdf/1312.6114v10.pdf\'\'\'\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib import losses\nfrom tensorflow.contrib.framework import arg_scope\n\nfrom utils import encoder, decoder\nfrom generator import Generator\n\n\nclass VAE(Generator):\n\n    def __init__(self, hidden_size, batch_size, learning_rate):\n        self.input_tensor = tf.placeholder(\n            tf.float32, [None, 28 * 28])\n\n        with arg_scope([layers.conv2d, layers.conv2d_transpose],\n                       activation_fn=tf.nn.elu,\n                       normalizer_fn=layers.batch_norm,\n                       normalizer_params={\'scale\': True}):\n            with tf.variable_scope(""model"") as scope:\n                encoded = encoder(self.input_tensor, hidden_size * 2)\n\n                mean = encoded[:, :hidden_size]\n                stddev = tf.sqrt(tf.exp(encoded[:, hidden_size:]))\n\n                epsilon = tf.random_normal([tf.shape(mean)[0], hidden_size])\n                input_sample = mean + epsilon * stddev\n\n                output_tensor = decoder(input_sample)\n\n            with tf.variable_scope(""model"", reuse=True) as scope:\n                self.sampled_tensor = decoder(tf.random_normal(\n                    [batch_size, hidden_size]))\n\n        vae_loss = self.__get_vae_cost(mean, stddev)\n        rec_loss = self.__get_reconstruction_cost(\n            output_tensor, self.input_tensor)\n\n        loss = vae_loss + rec_loss\n        self.train = layers.optimize_loss(loss, tf.contrib.framework.get_or_create_global_step(\n        ), learning_rate=learning_rate, optimizer=\'Adam\', update_ops=[])\n\n        self.sess = tf.Session()\n        self.sess.run(tf.global_variables_initializer())\n\n    def __get_vae_cost(self, mean, stddev, epsilon=1e-8):\n        \'\'\'VAE loss\n            See the paper\n\n        Args:\n            mean:\n            stddev:\n            epsilon:\n        \'\'\'\n        return tf.reduce_sum(0.5 * (tf.square(mean) + tf.square(stddev) -\n                                    2.0 * tf.log(stddev + epsilon) - 1.0))\n\n    def __get_reconstruction_cost(self, output_tensor, target_tensor, epsilon=1e-8):\n        \'\'\'Reconstruction loss\n\n        Cross entropy reconstruction loss\n\n        Args:\n            output_tensor: tensor produces by decoder\n            target_tensor: the target tensor that we want to reconstruct\n            epsilon:\n        \'\'\'\n        return tf.reduce_sum(-target_tensor * tf.log(output_tensor + epsilon) -\n                             (1.0 - target_tensor) * tf.log(1.0 - output_tensor + epsilon))\n\n    def update_params(self, input_tensor):\n        \'\'\'Update parameters of the network\n\n        Args:\n            input_tensor: a batch of flattened images [batch_size, 28*28]\n\n        Returns:\n            Current loss value\n        \'\'\'\n        return self.sess.run(self.train, {self.input_tensor: input_tensor})\n'"
