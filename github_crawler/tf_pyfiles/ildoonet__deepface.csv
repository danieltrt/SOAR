file_path,api_count,code
setup.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\nimport setuptools\n\n_VERSION = \'0.1.1\'\n\ncwd = os.path.dirname(os.path.abspath(__file__))\nsubprocess.check_output([""bash"", ""deepface/detectors/dlib/download.sh""], cwd=cwd)\nsubprocess.check_output([""bash"", ""deepface/detectors/ssd/download.sh""], cwd=cwd)\nsubprocess.check_output([""bash"", ""deepface/recognizers/vggface/download.sh""], cwd=cwd)\nsubprocess.check_output([""bash"", ""deepface/recognizers/vggface2_resnet/download.sh""], cwd=cwd)\n\n# \'opencv-python >= 3.3.1\'\nREQUIRED_PACKAGES = [\n    \'tensorflow >= 1.7.0\',\n    \'dill >= 0.2.7.1\',\n    \'dlib==19.12.0\',\n    \'h5py >= 2.8.0\',\n    \'matplotlib >= 2.2.2\',\n    \'numpy >= 1.14.3\',\n    \'pyyaml >= 3.0.0\',\n    \'scikit-learn >= 0.18.1\',\n    \'scikit-image >= 0.13.1\',\n    \'scipy >= 1.1.0\',\n    \'tqdm >= 4.23.4\',\n]\n\nDEPENDENCY_LINKS = [\n]\n\nsetuptools.setup(\n    name=\'deepface\',\n    version=_VERSION,\n    description=\n    \'Deep Learning Models for Face Detection/Recognition/Alignments, implemented in Tensorflow\',\n    install_requires=REQUIRED_PACKAGES,\n    dependency_links=DEPENDENCY_LINKS,\n    url=\'https://github.com/ildoonet/deepface\',\n    license=\'Apache License 2.0\',\n    package_dir={},\n    packages=setuptools.find_packages(exclude=[\'tests\']),\n    package_data={\'deepface\': [\'detectors/dlib/shape_predictor_68_face_landmarks.dat\',\n                               \'detectors/ssd/graph_inception_v2_fddb.pb\',\n                               \'detectors/ssd/graph_mobilenet_v2_fddb_180627.pb\',\n                               \'detectors/ssd/graph_mobilenet_v2_all_180627.pb\',\n                               \'confs/basic.yaml\',\n                               \'recognizers/vggface/weight.mat\',\n                               \'recognizers/vggface/db_blackpink.pkl\',\n                               \'recognizers/vggface2_resnet/db_blackpink.pkl\',\n                               \'recognizers/vggface2_resnet/labels.npy\',\n                               \'recognizers/vggface2_resnet/weight.h5\']\n                  },\n)\n'"
test_scripts.py,0,"b'import os\nimport cv2\n\nfrom deepface.detectors.detector_ssd import FaceDetectorSSDMobilenetV2\n\n\ndef test_ssd():\n    face_detector = FaceDetectorSSDMobilenetV2()\n    image = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            ""samples/blackpink/blackpink4.jpg"")\n    print(""image path is: "" + image)\n    test_image = cv2.imread(image, cv2.IMREAD_COLOR)\n    faces = face_detector.detect(test_image)\n\n    for face in faces:\n      cv2.rectangle(test_image,(int(face.x),int(face.y)),(int(face.x + face.w), int(face.y + face.h)), (0,255,0),3)\n\n    window_name = ""image""\n    cv2.namedWindow(window_name, cv2.WND_PROP_AUTOSIZE)\n    cv2.startWindowThread()\n\n    cv2.imshow(\'image\', test_image)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n    cv2.waitKey(1)\n    print(""done showing face annotated image!"")\n\n    for face in faces:\n      print(face.face_landmark)\n\n    print(""done"")\n\n\ndef test_ssd_webcam():\n    cap = cv2.VideoCapture(0)\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*\'MP4V\')\n    out = cv2.VideoWriter(\'ssd_output.mp4\', fourcc, 60.0, (640, 480))\n\n    face_detector = FaceDetectorSSDMobilenetV2()\n    while(True):\n        ret, frame = cap.read()\n\n        test_image = frame\n        faces = face_detector.detect(test_image)\n\n        for face in faces:\n          cv2.rectangle(test_image,(int(face.x),int(face.y)),(int(face.x + face.w), int(face.y + face.h)), (0,255,0),3)\n\n        window_name = ""image""\n        cv2.namedWindow(window_name, cv2.WND_PROP_AUTOSIZE)\n        cv2.startWindowThread()\n\n        out.write(test_image)\n        cv2.imshow(window_name, test_image)\n\n        if cv2.waitKey(5) & 0xFF == ord(\'q\'):\n            break\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\n\nif __name__ == ""__main__"":\n    test_ssd_webcam()\n'"
bin/face.py,0,"b'from __future__ import absolute_import\n\nimport logging\nimport os\nimport pickle\nimport sys\nfrom glob import glob\n\nimport cv2\nimport numpy as np\n\nimport fire\nfrom sklearn.metrics import roc_curve\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(base_dir)\nfrom deepface.confs.conf import DeepFaceConfs\nfrom deepface.detectors.detector_dlib import FaceDetectorDlib\nfrom deepface.detectors.detector_ssd import FaceDetectorSSDMobilenetV2, FaceDetectorSSDInceptionV2\nfrom deepface.recognizers.recognizer_vgg import FaceRecognizerVGG\nfrom deepface.recognizers.recognizer_resnet import FaceRecognizerResnet\nfrom deepface.utils.common import get_roi, feat_distance_l2, feat_distance_cosine\nfrom deepface.utils.visualization import draw_bboxs\n\nlogger = logging.getLogger(\'DeepFace\')\nlogger.setLevel(logging.INFO if int(os.environ.get(\'DEBUG\', 0)) == 0 else logging.DEBUG)\nch = logging.StreamHandler(sys.stdout)\nch.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s\')\nch.setFormatter(formatter)\nlogger.handlers = []\nlogger.addHandler(ch)\n\n\nclass DeepFace:\n    def __init__(self):\n        self.detector = None\n        self.recognizer = None\n\n    def set_detector(self, detector):\n        if self.detector is not None and self.detector.name() == detector:\n            return\n        logger.debug(\'set_detector old=%s new=%s\' % (self.detector, detector))\n        if detector == FaceDetectorDlib.NAME:\n            self.detector = FaceDetectorDlib()\n        elif detector == \'detector_ssd_inception_v2\':\n            self.detector = FaceDetectorSSDInceptionV2()\n        elif detector == \'detector_ssd_mobilenet_v2\':\n            self.detector = FaceDetectorSSDMobilenetV2()\n\n    def set_recognizer(self, recognizer):\n        if self.recognizer is not None and self.recognizer.name() == recognizer:\n            return\n        logger.debug(\'set_recognizer old=%s new=%s\' % (self.recognizer, recognizer))\n        if recognizer == FaceRecognizerVGG.NAME:\n            self.recognizer = FaceRecognizerVGG()\n        elif recognizer == FaceRecognizerResnet.NAME:\n            self.recognizer = FaceRecognizerResnet()\n\n    def blackpink(self, visualize=True):\n        imgs = [\'./samples/blackpink/blackpink%d.jpg\' % (i + 1) for i in range(7)]\n        for img in imgs:\n            self.run(image=img, visualize=visualize)\n\n    def recognizer_test_run(self, detector=FaceDetectorDlib.NAME, recognizer=FaceRecognizerResnet.NAME, image=\'./samples/ajb.jpg\', visualize=False):\n        self.set_detector(detector)\n        self.set_recognizer(recognizer)\n\n        if isinstance(image, str):\n            logger.debug(\'read image, path=%s\' % image)\n            npimg = cv2.imread(image, cv2.IMREAD_COLOR)\n        elif isinstance(image, np.ndarray):\n            npimg = image\n        else:\n            logger.error(\'Argument image should be str or ndarray. image=%s\' % str(image))\n            sys.exit(-1)\n\n        if npimg is None:\n            logger.error(\'image can not be read, path=%s\' % image)\n            sys.exit(-1)\n\n        if recognizer:\n            logger.debug(\'run face recognition+\')\n            result = self.recognizer.detect([npimg[...,::-1]])\n            logger.debug(\'run face recognition-\')\n        return\n\n    def run_recognizer(self, npimg, faces, recognizer=FaceRecognizerResnet.NAME):\n        self.set_recognizer(recognizer)\n        rois = []\n        for face in faces:\n            # roi = npimg[face.y:face.y+face.h, face.x:face.x+face.w, :]\n            roi = get_roi(npimg, face, roi_mode=recognizer)\n            if int(os.environ.get(\'DEBUG_SHOW\', 0)) == 1:\n                cv2.imshow(\'roi\', roi)\n                cv2.waitKey(0)\n            rois.append(roi)\n            face.face_roi = roi\n\n        if len(rois) > 0:\n            logger.debug(\'run face recognition+\')\n            result = self.recognizer.detect(rois=rois, faces=faces)\n            logger.debug(\'run face recognition-\')\n            for face_idx, face in enumerate(faces):\n                face.face_feature = result[\'feature\'][face_idx]\n                logger.debug(\'candidates: %s\' % str(result[\'name\'][face_idx]))\n                if result[\'name\'][face_idx]:\n                    name, score = result[\'name\'][face_idx][0]\n                    # if score < self.recognizer.get_threshold():\n                    #     continue\n                    face.face_name = name\n                    face.face_score = score\n        return faces\n\n    def run(self, detector=\'detector_ssd_mobilenet_v2\', recognizer=FaceRecognizerResnet.NAME, image=\'./samples/blackpink/blackpink1.jpg\',\n            visualize=False):\n        self.set_detector(detector)\n        self.set_recognizer(recognizer)\n\n        if image is None:\n            return []\n        elif isinstance(image, str):\n            logger.debug(\'read image, path=%s\' % image)\n            npimg = cv2.imread(image, cv2.IMREAD_COLOR)\n        elif isinstance(image, np.ndarray):\n            npimg = image\n        else:\n            logger.error(\'Argument image should be str or ndarray. image=%s\' % str(image))\n            sys.exit(-1)\n\n        if npimg is None:\n            logger.error(\'image can not be read, path=%s\' % image)\n            sys.exit(-1)\n\n        logger.debug(\'run face detection+ %dx%d\' % (npimg.shape[1], npimg.shape[0]))\n        faces = self.detector.detect(npimg)\n\n        logger.debug(\'run face detection- %s\' % len(faces))\n\n        if recognizer:\n            faces = self.run_recognizer(npimg, faces, recognizer)\n\n        img = draw_bboxs(np.copy(npimg), faces)\n        cv2.imwrite(\'result.jpg\', img)\n        if visualize and visualize not in [\'false\', \'False\']:\n            cv2.imshow(\'DeepFace\', img)\n            cv2.waitKey(0)\n\n        return faces\n\n    def save_and_run(self, path, image, visualize=True):\n        """"""\n        :param visualize:\n        :param path: samples/faces\n        :param image_path: samples/blackpink1.jpg\n        :return:\n        """"""\n        self.save_features_path(path)\n        self.run(image=image, visualize=visualize)\n\n    def save_features_path(self, path=""./samples/blackpink/faces/""):\n        """"""\n\n        :param path: folder contain images(""./samples/faces/"")\n        :return:\n        """"""\n        name_paths = [(os.path.basename(img_path)[:-4], img_path)\n                      for img_path in glob(os.path.join(path, ""*.jpg""))]\n\n        features = {}\n        for name, path in tqdm(name_paths):\n            logger.debug(""finding faces for %s:"" % path)\n            faces = self.run(image=path)\n            features[name] = faces[0].face_feature\n\n        import pickle\n        with open(\'db.pkl\', \'wb\') as f:\n            pickle.dump(features, f, protocol=2)\n\n    def test_lfw(self, set=\'test\', model=\'ssdm_resnet\', visualize=True):\n        if set is \'train\':\n            pairfile = \'pairsDevTrain.txt\'\n        else:\n            pairfile = \'pairsDevTest.txt\'\n        lfw_path = DeepFaceConfs.get()[\'dataset\'][\'lfw\']\n        path = os.path.join(lfw_path, pairfile)\n        with open(path, \'r\') as f:\n            lines = f.readlines()[1:]\n\n        pairs = []\n        for line in lines:\n            elms = line.split()\n            if len(elms) == 3:\n                pairs.append((elms[0], int(elms[1]), elms[0], int(elms[2])))\n            elif len(elms) == 4:\n                pairs.append((elms[0], int(elms[1]), elms[2], int(elms[3])))\n            else:\n                logger.warning(\'line should have 3 or 4 elements, line=%s\' % line)\n\n        detec = FaceDetectorDlib.NAME\n        if model == \'baseline\':\n            recog = FaceRecognizerVGG.NAME\n            just_name = \'vgg\'\n        elif model == \'baseline_resnet\':\n            recog = FaceRecognizerResnet.NAME\n            just_name = \'resnet\'\n        elif model == \'ssdm_resnet\':\n            recog = FaceRecognizerResnet.NAME\n            just_name = \'resnet\'\n            detec = \'detector_ssd_mobilenet_v2\'\n        else:\n            raise Exception(\'invalid model name=%s\' % model)\n\n        logger.info(\'pair length=%d\' % len(pairs))\n        test_result = []  # score, label(1=same)\n        for name1, idx1, name2, idx2 in tqdm(pairs):\n            img1_path = os.path.join(lfw_path, name1, \'%s_%04d.jpg\' % (name1, idx1))\n            img2_path = os.path.join(lfw_path, name2, \'%s_%04d.jpg\' % (name2, idx2))\n            img1 = cv2.imread(img1_path, cv2.IMREAD_COLOR)\n            img2 = cv2.imread(img2_path, cv2.IMREAD_COLOR)\n\n            if img1 is None:\n                logger.warning(\'image not read, path=%s\' % img1_path)\n            if img2 is None:\n                logger.warning(\'image not read, path=%s\' % img2_path)\n\n            result1 = self.run(image=img1, detector=detec, recognizer=recog, visualize=False)\n            result2 = self.run(image=img2, detector=detec, recognizer=recog, visualize=False)\n\n            if len(result1) == 0:\n                logger.warning(\'face not detected, name=%s(%d)! %s(%d)\' % (name1, idx1, name2, idx2))\n                test_result.append((0.0, name1 == name2))\n                continue\n            if len(result2) == 0:\n                logger.warning(\'face not detected, name=%s(%d) %s(%d)!\' % (name1, idx1, name2, idx2))\n                test_result.append((0.0, name1 == name2))\n                continue\n\n            feat1 = result1[0].face_feature\n            feat2 = result2[0].face_feature\n            similarity = feat_distance_cosine(feat1, feat2)\n            test_result.append((similarity, name1 == name2))\n\n        # calculate accuracy TODO\n        accuracy = sum([label == (score > DeepFaceConfs.get()[\'recognizer\'][just_name][\'score_th\']) for score, label in test_result]) / float(len(test_result))\n        logger.info(\'accuracy=%.8f\' % accuracy)\n\n        # ROC Curve, AUC\n        tps = []\n        fps = []\n        accuracy0 = []\n        accuracy1 = []\n        acc_th = []\n\n        for th in range(0, 100, 5):\n            th = th / 100.0\n            tp = 0\n            tn = 0\n            fp = 0\n            fn = 0\n            for score, label in test_result:\n                if score >= th and label == 1:\n                    tp += 1\n                elif score >= th and label == 0:\n                    fp += 1\n                elif score < th and label == 0:\n                    tn += 1\n                elif score < th and label == 1:\n                    fn += 1\n            tpr = tp / (tp + fn + 1e-12)\n            fpr = fp / (fp + tn + 1e-12)\n            tps.append(tpr)\n            fps.append(fpr)\n            accuracy0.append(tn / (tn + fp + 1e-12))\n            accuracy1.append(tp / (tp + fn + 1e-12))\n            acc_th.append(th)\n\n        fpr, tpr, thresh = roc_curve([x[1] for x in test_result], [x[0] for x in test_result])\n        fnr = 1 - tpr\n        eer = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n        logger.info(\'1-eer=%.4f\' % (1.0 - eer))\n\n        with open(\'./etc/test_lfw.pkl\', \'rb\') as f:\n            results = pickle.load(f)\n\n        if visualize in [True, \'True\', \'true\', 1, \'1\']:\n            fig = plt.figure()\n            a = fig.add_subplot(1, 2, 1)\n            plt.title(\'Experiment on LFW\')\n            plt.plot(fpr, tpr, label=\'%s(%.4f)\' % (model, 1 - eer))  # TODO : label\n\n            for model_name in results:\n                if model_name == model:\n                    continue\n                fpr_prev = results[model_name][\'fpr\']\n                tpr_prev = results[model_name][\'tpr\']\n                eer_prev = results[model_name][\'eer\']\n                plt.plot(fpr_prev, tpr_prev, label=\'%s(%.4f)\' % (model_name, 1 - eer_prev))\n\n            plt.xlim([0.0, 1.0])\n            plt.ylim([0.0, 1.05])\n            plt.xlabel(\'False Positive Rate\')\n            plt.ylabel(\'True Positive Rate\')\n            a.legend()\n            a.set_title(\'Receiver operating characteristic\')\n\n            a = fig.add_subplot(1, 2, 2)\n            plt.plot(accuracy0, acc_th, label=\'Accuracy_diff\')\n            plt.plot(accuracy1, acc_th, label=\'Accuracy_same\')\n            plt.xlim([0.0, 1.0])\n            plt.ylim([0.0, 1.05])\n            a.legend()\n            a.set_title(\'%s : TP, TN\' % model)\n\n            fig.savefig(\'./etc/roc.png\', dpi=300)\n            plt.show()\n            plt.draw()\n\n        with open(\'./etc/test_lfw.pkl\', \'wb\') as f:\n            results[model] = {\n                \'fpr\': fpr,\n                \'tpr\': tpr,\n                \'acc_th\': acc_th,\n                \'accuracy0\': accuracy0,\n                \'accuracy1\': accuracy1,\n                \'eer\': eer\n            }\n            pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n\n        return 1.0 - eer\n\n\nif __name__ == \'__main__\':\n    fire.Fire(DeepFace)\n'"
bin/generate_bench_result.py,0,"b'import os\nimport sys\nfrom glob import glob\n\nimport cv2\nimport fire\nimport numpy as np\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(base_dir)\nfrom deepface import get_detector, get_recognizer, save_features\nfrom deepface.utils.visualization import draw_bboxs\nfrom deepface.utils.common import tag_faces\n\n\ndef show_with_face(npimg, faces, visualize=False):\n    if visualize:\n        img = draw_bboxs(np.copy(npimg), faces)\n        cv2.imshow(\'DeepFace\', img)\n        cv2.waitKey(0)\n\n\nclass DeepFace:\n    def __init__(self):\n        pass\n\n    def run(self,\n            folder_path=None,\n            detector_method=\'dlib\',\n            visualize=True):\n\n        # detect\n        detector = get_detector(name=\'ssd_mobilenet_v2\')\n\n        print(os.path.join(folder_path, ""*.jpg""))\n        for img_path in glob(os.path.join(folder_path, ""*.jpg"")):\n            npimg = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            faces = detector.detect(npimg=npimg)\n\n            print(""![face](%s)"" % img_path)\n            for face in faces:\n                print(face, face.score, face.face_landmark)\n\n            show_with_face(npimg, faces, visualize=visualize)\n\n    def generate_fddb_ret(self,\n                          detector_method=\'ssd_mobilenet_v2\',\n                          output_fddb_ret_txt=\'fddb_ret.txt\',\n                          img_list_path=""/data/public/rw/datasets/faces/fddb/filePath.txt""):\n\n        detector = get_detector(name=detector_method)\n\n        with open(img_list_path, ""r"") as fr:\n            img_list = [img_path.strip() for img_path in fr]\n\n        base_dir = ""/data/public/rw/datasets/faces/fddb/originalPics""\n\n        with open(output_fddb_ret_txt, ""w"") as fw:\n            for img_path in img_list:\n                real_img_path = os.path.join(base_dir, img_path+"".jpg"")\n                print(real_img_path+ ""\\n\\n\\n"")\n\n                npimg = cv2.imread(real_img_path, cv2.IMREAD_COLOR)\n                faces = detector.detect(npimg=npimg)\n\n                fw.write(img_path + ""\\n"")\n                fw.write(""%d\\n"" % len(faces))\n                for face in faces:\n                    fw.write(""%d %d %d %d %f\\n"" % (face.x, face.y, face.w, face.h, face.score))\n\n\nif __name__ == \'__main__\':\n    fire.Fire(DeepFace)\n'"
bin/hyperopt_main.py,0,"b""import hyperopt\nfrom hyperopt import hp, fmin, tpe\nfrom hyperopt.mongoexp import MongoTrials\n\nimport hyperopt_optimizer\n\n\nif __name__ == '__main__':\n    exp_key = 'deepface15'\n    print('---- %s ----' % exp_key)\n    space = hp.choice('parameters', [\n        {\n            'crop_y_ratio': hp.uniform('crop_y_ratio', 0.3, 0.7),\n            'size_ratio': hp.uniform('size_ratio', 1.0, 3.0),\n        }\n    ])\n    trials = MongoTrials('mongo://hyper-mongo.devel.kakao.com:10247/curtis_db/jobs', exp_key=exp_key)\n    best = fmin(hyperopt_optimizer.objective, space, trials=trials, algo=tpe.suggest, max_evals=100, verbose=1)\n    print(trials.best_trial['result'])\n    print(hyperopt.space_eval(space, best))\n"""
bin/hyperopt_optimizer.py,0,"b""import os\nimport sys\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(base_dir)\n\nfrom deepface.confs.conf import DeepFaceConfs\nfrom face import DeepFace\nfrom hyperopt import STATUS_OK\n\n\ndef objective(args):\n    if 'crop_y_ratio' in args.keys():\n        print('---------- crop_y_ratio set', args['crop_y_ratio'])\n        DeepFaceConfs.get()['roi']['crop_y_ratio'] = args['crop_y_ratio']\n    if 'size_ratio' in args.keys():\n        print('---------- size_ratio set', args['size_ratio'])\n        DeepFaceConfs.get()['roi']['size_ratio'] = args['size_ratio']\n\n    t = DeepFace()\n    try:\n        score = t.test_lfw(visualize=False)\n    except Exception as e:\n        print('--------- error...')\n        print(e)\n        return 100\n    print('---------- score=', score)\n\n    return -score\n"""
bin/run_example.py,0,"b""import os\nimport sys\n\nimport cv2\nimport fire\nimport numpy as np\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(base_dir)\nfrom deepface import get_detector, get_recognizer, save_features\nfrom deepface.utils.visualization import draw_bboxs\nfrom deepface.utils.common import tag_faces\n\n\ndef show_with_face(npimg, faces, visualize=False):\n    if visualize:\n        img = draw_bboxs(np.copy(npimg), faces)\n        cv2.imshow('DeepFace', img)\n        cv2.waitKey(0)\n\n\nclass DeepFace:\n    def __init__(self):\n        pass\n\n    def run(self, source_path=None,\n            db_path=None,\n            img_path=None,\n            method='vgg',\n            visualize=True):\n        if source_path:\n            save_features(img_folder_path=source_path,\n                          output_path=db_path,\n                          method=method)\n\n        npimg = cv2.imread(img_path, cv2.IMREAD_COLOR)\n\n        # detect\n        detector = get_detector()\n        faces = detector.detect(npimg=npimg)\n\n        # recognize\n        recognizer = get_recognizer(name=method, db=db_path)\n        result = recognizer.detect(faces=faces, npimg=npimg)\n        tagged_faces = tag_faces(faces=faces, result=result, threshold=recognizer.get_threshold())\n\n        show_with_face(npimg, tagged_faces, visualize=visualize)\n\n\nif __name__ == '__main__':\n    fire.Fire(DeepFace)\n"""
deepface/__init__.py,0,"b'# -*- coding: utf-8 -*-\n""""""deepface\n""""""\nfrom __future__ import absolute_import\n\nfrom . import confs\nfrom . import detectors\nfrom . import recognizers\nfrom . import utils\n\nfrom .shortcuts import \\\n    get_detector, \\\n    get_recognizer, \\\n    save_features\n'"
deepface/shortcuts.py,0,"b'import os\nfrom glob import glob\n\nimport cv2\nfrom tqdm import tqdm\n\nfrom deepface.confs.conf import DeepFaceConfs\nfrom deepface.detectors.detector_dlib import FaceDetectorDlib\nfrom deepface.detectors.detector_ssd import FaceDetectorSSDInceptionV2, FaceDetectorSSDMobilenetV2\nfrom deepface.recognizers.recognizer_vgg import FaceRecognizerVGG\nfrom deepface.recognizers.recognizer_resnet import FaceRecognizerResnet\n\n\ndef get_detector(name=\'ssd_mobilenet_v2\'):\n    """"""\n\n    :type name: str\n    :param name: \n    :return:\n    """"""\n\n    if name == \'dlib\':\n        return FaceDetectorDlib()\n    elif name == \'ssd_inception_v2\':\n        return FaceDetectorSSDInceptionV2()\n    elif name == \'ssd_mobilenet_v2\':\n        return FaceDetectorSSDMobilenetV2()\n\n    return None\n\n\ndef get_recognizer(name=\'vgg\', db=None):\n    """"""\n\n    :param db:\n    :param name:\n    :return:\n    """"""\n    if name == \'vgg\':\n        return FaceRecognizerVGG(custom_db=db)\n    elif name == \'vgg2\':\n        return FaceRecognizerResnet(custom_db=db)\n\n    return None\n\n\ndef save_features(img_folder_path, output_path=None, method=""vgg""):\n    """"""\n\n    :param path: folder contain images(""./samples/faces/"")\n    :return:\n    """"""\n    name_paths = [(os.path.basename(img_path)[:-4], img_path)\n                  for img_path in glob(os.path.join(img_folder_path, ""*.jpg""))]\n\n    detector = get_detector()\n    recognizer = get_recognizer(name=method)\n\n    features = {}\n    for name, path in tqdm(name_paths):\n        npimg = cv2.imread(path, cv2.IMREAD_COLOR)\n        faces = detector.detect(npimg)\n        _, feats = recognizer.extract_features(npimg=npimg, faces=faces)\n        features[name] = feats[0]\n\n    import pickle\n    if not output_path:\n        output_path = os.path.join(""recognizers/vggface"", os.path.basename(img_folder_path) + "".pkl"")\n    with open(output_path, \'wb\') as f:\n        pickle.dump(features, f, pickle.HIGHEST_PROTOCOL)\n'"
deepface/confs/__init__.py,0,b''
deepface/confs/conf.py,0,"b'import os\nimport yaml\n\n\nclass DeepFaceConfs:\n    __instance = None\n\n    @staticmethod\n    def get():\n        """""" Static access method. """"""\n        if DeepFaceConfs.__instance is None:\n            DeepFaceConfs()\n        return DeepFaceConfs.__instance\n\n    def __init__(self):\n        if DeepFaceConfs.__instance is not None:\n            raise Exception(""This class is a singleton!"")\n        else:\n            DeepFaceConfs.__instance = self\n\n        dir_path = os.path.dirname(os.path.realpath(__file__))\n\n        with open(os.path.join(dir_path, \'basic.yaml\'), \'r\') as f:\n            self.conf = yaml.load(f)\n\n    def __getitem__(self, key):\n        return self.conf[key]\n'"
deepface/detectors/__init__.py,0,b''
deepface/detectors/detector_base.py,0,"b'import abc\n\n\nclass FaceDetector(object):\n    def __init__(self):\n        pass\n\n    def __str__(self):\n        return self.name()\n\n    @abc.abstractmethod\n    def name(self):\n        return \'detector\'\n\n    @abc.abstractmethod\n    def detect(self, npimg):\n        """"""\n\n        :param npimg:\n        :return: list of BoundingBox\n        """"""\n        pass\n'"
deepface/detectors/detector_dlib.py,0,"b'import os\n\nimport dlib\nimport numpy as np\n\nfrom deepface.confs.conf import DeepFaceConfs\nfrom deepface.utils.bbox import BoundingBox\n\nfrom .detector_base import FaceDetector\n\n\nclass FaceDetectorDlib(FaceDetector):\n    """"""\n    reference : https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/\n    """"""\n    NAME = \'detector_dlib\'\n\n    def __init__(self):\n        super(FaceDetectorDlib, self).__init__()\n        self.detector = dlib.get_frontal_face_detector()\n        predictor_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            DeepFaceConfs.get()[\'detector\'][\'dlib\'][\'landmark_detector\']\n        )\n        self.predictor = dlib.shape_predictor(predictor_path)\n        self.upsample_scale = DeepFaceConfs.get()[\'detector\'][\'dlib\'][\'scale\']\n\n    def name(self):\n        return FaceDetectorDlib.NAME\n\n    def detect(self, npimg):\n        dets, scores, idx = self.detector.run(npimg, self.upsample_scale, -1)\n        faces = []\n        for det, score in zip(dets, scores):\n            if score < DeepFaceConfs.get()[\'detector\'][\'dlib\'][\'score_th\']:\n                continue\n\n            x = max(det.left(), 0)\n            y = max(det.top(), 0)\n            w = min(det.right() - det.left(), npimg.shape[1] - x)\n            h = min(det.bottom() - det.top(), npimg.shape[0] - y)\n\n            if w <= 1 or h <= 1:\n                continue\n\n            bbox = BoundingBox(x, y, w, h, score)\n\n            # find landmark\n            bbox.face_landmark = self.detect_landmark(npimg, det)\n\n            faces.append(bbox)\n\n        faces = sorted(faces, key=lambda x: x.score, reverse=True)\n        return faces\n\n    def detect_landmark(self, npimg, det):\n        shape = self.predictor(npimg, det)\n        coords = np.zeros((68, 2), dtype=np.int)\n\n        # loop over the 68 facial landmarks and convert them\n        # to a 2-tuple of (x, y)-coordinates\n        for i in range(0, 68):\n            coords[i] = (shape.part(i).x, shape.part(i).y)\n        return coords\n'"
deepface/detectors/detector_ssd.py,6,"b'import os\nimport sys\n\nimport dlib\nimport tensorflow as tf\nimport numpy as np\nimport cv2\n\nfrom .detector_base import FaceDetector\nfrom deepface.confs.conf import DeepFaceConfs\nfrom deepface.utils.bbox import BoundingBox\n\n\nclass FaceDetectorSSD(FaceDetector):\n    NAME = \'detector_ssd\'\n\n    def __init__(self, specific_model):\n        super(FaceDetectorSSD, self).__init__()\n        self.specific_model = specific_model\n        graph_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            DeepFaceConfs.get()[\'detector\'][self.specific_model][\'frozen_graph\']\n        )\n        self.detector = self._load_graph(graph_path)\n\n        self.tensor_image = self.detector.get_tensor_by_name(\'prefix/image_tensor:0\')\n        self.tensor_boxes = self.detector.get_tensor_by_name(\'prefix/detection_boxes:0\')\n        self.tensor_score = self.detector.get_tensor_by_name(\'prefix/detection_scores:0\')\n        self.tensor_class = self.detector.get_tensor_by_name(\'prefix/detection_classes:0\')\n\n        predictor_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            DeepFaceConfs.get()[\'detector\'][\'dlib\'][\'landmark_detector\']\n        )\n        self.predictor = dlib.shape_predictor(predictor_path)\n\n        config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n        self.session = tf.Session(graph=self.detector, config=config)\n\n    def _load_graph(self, graph_path):\n        # We load the protobuf file from the disk and parse it to retrieve the\n        # unserialized graph_def\n        with tf.gfile.GFile(graph_path, ""rb"") as f:\n            graph_def = tf.GraphDef()\n            graph_def.ParseFromString(f.read())\n\n        # Then, we import the graph_def into a new Graph and return it\n        with tf.Graph().as_default() as graph:\n            # The name var will prefix every op/nodes in your graph\n            # Since we load everything in a new graph, this is not needed\n            tf.import_graph_def(graph_def, name=""prefix"")\n        return graph\n\n    def name(self):\n        return \'detector_%s\' % self.specific_model\n\n    def detect(self, npimg, resize=(480, 640)):\n        """"""\n\n        :param npimg:\n        :param resize: False or tuple\n        :return:\n        """"""\n        height, width = npimg.shape[:2]\n        if not resize:\n            infer_img = npimg\n        else:\n            infer_img = cv2.resize(npimg, resize, cv2.INTER_AREA)   # TODO : Resize or not?\n\n        dets, scores, classes = self.session.run([self.tensor_boxes, self.tensor_score, self.tensor_class], feed_dict={\n            self.tensor_image: [infer_img]\n        })\n        dets, scores = dets[0], scores[0]\n\n        faces = []\n        for det, score in zip(dets, scores):\n            if score < DeepFaceConfs.get()[\'detector\'][self.specific_model][\'score_th\']:\n                continue\n\n            y = int(max(det[0], 0) * height)\n            x = int(max(det[1], 0) * width)\n            h = int((det[2] - det[0]) * height)\n            w = int((det[3] - det[1]) * width)\n\n            if w <= 1 or h <= 1:\n                continue\n\n            bbox = BoundingBox(x, y, w, h, score)\n\n            # find landmark\n            rect = dlib.rectangle(left=x, top=y, right=x + w, bottom=y + h)\n            shape = self.predictor(npimg, rect)\n            coords = np.zeros((68, 2), dtype=np.int)\n\n            # loop over the 68 facial landmarks and convert them\n            # to a 2-tuple of (x, y)-coordinates\n            for i in range(0, 68):\n                coords[i] = (shape.part(i).x, shape.part(i).y)\n            bbox.face_landmark = coords\n\n            faces.append(bbox)\n\n        faces = sorted(faces, key=lambda x: x.score, reverse=True)\n\n        return faces\n\n\nclass FaceDetectorSSDInceptionV2(FaceDetectorSSD):\n    def __init__(self):\n        super(FaceDetectorSSDInceptionV2, self).__init__(\'ssd_inception_v2\')\n\n\nclass FaceDetectorSSDMobilenetV2(FaceDetectorSSD):\n    def __init__(self):\n        super(FaceDetectorSSDMobilenetV2, self).__init__(\'ssd_mobilenet_v2\')\n'"
deepface/recognizers/__init__.py,0,b''
deepface/recognizers/recognizer_base.py,0,"b""import abc\n\n\nclass FaceRecognizer(object):\n    def __str__(self):\n        return self.name()\n\n    @abc.abstractmethod\n    def name(self):\n        return 'recognizer'\n\n    @abc.abstractmethod\n    def extract_features(self, npimg, rois, faces):\n        pass\n\n    @abc.abstractmethod\n    def detect(self, rois):\n        pass\n\n    @abc.abstractmethod\n    def get_threshold(self):\n        pass\n"""
deepface/recognizers/recognizer_resnet.py,53,"b""import logging\nimport os\nimport h5py\n\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport pickle\n\nfrom ..confs.conf import DeepFaceConfs\nfrom ..recognizers.recognizer_base import FaceRecognizer\nfrom ..utils.common import grouper, rotate_dot, faces_to_rois\n\n\ndef conv_block(input_tensor, filters, stage, block, strides=(2, 2), bias=False):\n    layer_name = 'conv' + str(stage) + '_' + str(block)\n    l = tf.layers.conv2d(input_tensor, filters[0], 1, strides=strides, use_bias=bias, name=layer_name + '_1x1_reduce')\n    l = tf.layers.batch_normalization(l, axis=3, name=layer_name + '_1x1_reduce/bn')\n    l = tf.nn.relu(l)\n\n    l = tf.layers.conv2d(l, filters[1], 3, padding='SAME', use_bias=bias, name=layer_name + '_3x3')\n    l = tf.layers.batch_normalization(l, axis=3, name=layer_name + '_3x3/bn')\n    l = tf.nn.relu(l)\n\n    l = tf.layers.conv2d(l, filters[2], 1, name=layer_name + '_1x1_increase')\n    l = tf.layers.batch_normalization(l, axis=3, name=layer_name + '_1x1_increase/bn')\n\n    m = tf.layers.conv2d(input_tensor, filters[2], 1, strides=strides, use_bias=bias, name=layer_name + '_1x1_proj')\n    m = tf.layers.batch_normalization(m, axis=3, name=layer_name + '_1x1_proj/bn')\n\n    l = tf.add(l, m)\n    l = tf.nn.relu(l)\n    return l\n\n\ndef identity_block(input_tensor, filters, stage, block, bias=False, last_relu=True):\n    layer_name = 'conv' + str(stage) + '_' + str(block)\n    l = tf.layers.conv2d(input_tensor, filters[0], 1, use_bias=bias, name=layer_name + '_1x1_reduce')\n    l = tf.layers.batch_normalization(l, axis=3, name=layer_name + '_1x1_reduce/bn')\n    l = tf.nn.relu(l)\n\n    l = tf.layers.conv2d(l, filters[1], 3, padding='SAME', use_bias=bias, name=layer_name + '_3x3')\n    l = tf.layers.batch_normalization(l, name=layer_name + '_3x3/bn')\n    l = tf.nn.relu(l)\n\n    l = tf.layers.conv2d(l, filters[2], 1, use_bias=bias, name=layer_name + '_1x1_increase')\n    l = tf.layers.batch_normalization(l, name=layer_name + '_1x1_increase/bn')\n\n    l = tf.add(l, input_tensor)\n    if last_relu:\n        l = tf.nn.relu(l)\n    return l\n\n\ndef get_layer_type(layer):\n    layer_type = ''\n    if layer.find('bn') > 0:\n        layer_type = 'BatchNormalization'\n    elif layer[0:4] == 'conv':\n        layer_type = 'Conv2D'\n    elif layer[0:4] == 'clas':\n        layer_type = 'Classifier'\n    return layer_type\n\n\nclass FaceRecognizerResnet(FaceRecognizer):\n    NAME = 'recognizer_resnet'\n\n    def __init__(self, custom_db=None):\n        self.batch_size = 4\n        dir_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'vggface2_resnet')\n        filename = 'rcmalli_vggface_labels_v2.npy'\n        filepath = os.path.join(dir_path, filename)\n\n        if not os.path.exists(filepath):\n            raise FileNotFoundError('Label file not found, path=%s' % filepath)\n\n        self.class_names = np.load(filepath)\n        self.input_node = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='image')\n        current = self.input_node\n        network = {}\n\n        with tf.variable_scope('vgg2', reuse=tf.AUTO_REUSE) as scope:\n            # Building the cnn architecture:\n            # First block:\n            l = tf.layers.conv2d(current, 64, (7, 7), strides=(2, 2), padding='SAME', use_bias=False, name='conv1/7x7_s2')\n            l = tf.layers.batch_normalization(l, axis=3, name='conv1/7x7_s2/bn')\n            l = tf.nn.relu(l)\n            l = tf.layers.max_pooling2d(l, 3, 2)\n\n            # Second block:\n            l = conv_block(l, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n            l = identity_block(l, [64, 64, 256], stage=2, block=2)\n            l = identity_block(l, [64, 64, 256], stage=2, block=3)\n\n            # Third block:\n            l = conv_block(l, [128, 128, 512], stage=3, block=1)\n            l = identity_block(l, [128, 128, 512], stage=3, block=2)\n            l = identity_block(l, [128, 128, 512], stage=3, block=3)\n            l = identity_block(l, [128, 128, 512], stage=3, block=4)\n\n            # Fourth block:\n            l = conv_block(l, [256, 256, 1024], stage=4, block=1)\n            l = identity_block(l, [256, 256, 1024], stage=4, block=2)\n            l = identity_block(l, [256, 256, 1024], stage=4, block=3)\n            l = identity_block(l, [256, 256, 1024], stage=4, block=4)\n            l = identity_block(l, [256, 256, 1024], stage=4, block=5)\n            l = identity_block(l, [256, 256, 1024], stage=4, block=6)\n\n            # Fifth block:\n            l = conv_block(l, [512, 512, 2048], stage=5, block=1)\n            l = identity_block(l, [512, 512, 2048], stage=5, block=2)\n            l = identity_block(l, [512, 512, 2048], stage=5, block=3, last_relu=False)\n\n            # Final stage:\n            l = tf.layers.average_pooling2d(l, 7, 1)\n            l = tf.layers.flatten(l)\n            network['feat'] = l\n            l = tf.nn.relu(l)\n            output = tf.layers.dense(l, 8631, activation=tf.nn.softmax, name='classifier')  # 8631 classes\n            network['out'] = output\n\n        # Load weights:\n        filename = 'rcmalli_vggface_tf_resnet50.h5'\n        filepath = os.path.join(dir_path, filename)\n\n        if not os.path.exists(filepath):\n            raise FileNotFoundError('Weight file not found, path=%s' % filepath)\n\n        # Assign weights:\n        assign_list = []\n        with h5py.File(filepath, mode='r') as f:\n            layers = f.attrs['layer_names']\n            for layer in layers:\n                g = f[layer]\n\n                if isinstance(layer, bytes):\n                    layer = layer.decode('utf-8')\n                layer_type = get_layer_type(layer)\n                if layer_type == 'Conv2D':\n                    with tf.variable_scope('vgg2', reuse=tf.AUTO_REUSE) as scope:\n                        conv = tf.get_variable(layer + '/kernel')\n                        w = np.asarray(g[layer + '/kernel:0'])\n                        assign_op = conv.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n\n                elif layer_type == 'BatchNormalization':\n                    with tf.variable_scope('vgg2', reuse=tf.AUTO_REUSE) as scope:\n                        beta = tf.get_variable(layer + '/beta')\n                        gamma = tf.get_variable(layer + '/gamma')\n                        mean = tf.get_variable(layer + '/moving_mean')\n                        var = tf.get_variable(layer + '/moving_variance')\n                        w = np.asarray(g[layer + '/beta:0'])\n                        assign_op = beta.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n                        w = np.asarray(g[layer + '/gamma:0'])\n                        assign_op = gamma.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n                        w = np.asarray(g[layer + '/moving_mean:0'])\n                        assign_op = mean.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n                        w = np.asarray(g[layer + '/moving_variance:0'])\n                        assign_op = var.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n\n                elif layer_type == 'Classifier':\n                    with tf.variable_scope('vgg2', reuse=tf.AUTO_REUSE):\n                        bias = tf.get_variable(layer + '/bias')\n                        kernel = tf.get_variable(layer + '/kernel')\n                        w = np.asarray(g[layer + '/bias:0'])\n                        assign_op = bias.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n                        w = np.asarray(g[layer + '/kernel:0'])\n                        assign_op = kernel.assign(tf.constant(w))\n                        assign_list.append(assign_op)\n\n        # Create session:\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        init = tf.global_variables_initializer()\n\n        config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n        self.persistent_sess = tf.Session(config=config)\n\n        # Warm-up:\n        self.persistent_sess.run(init, feed_dict={\n            self.input_node: np.zeros((self.batch_size, 224, 224, 3), dtype=np.uint8)\n        })\n        self.persistent_sess.run([assign_list, update_ops], feed_dict={\n            self.input_node: np.zeros((self.batch_size, 224, 224, 3), dtype=np.uint8)\n        })\n\n        self.network = network\n        self.db = None\n\n        if custom_db:\n            db_path = custom_db\n        else:\n            db_path = DeepFaceConfs.get()['recognizer']['resnet'].get('db', '')\n            db_path = os.path.join(dir_path, db_path)\n        try:\n            with open(db_path, 'rb') as f:\n                u = pickle._Unpickler(f)\n                u.encoding = 'latin1'\n                self.db = u.load()\n        except Exception as e:\n            logging.warning('db file not loaded, %s, err=%s' % (db_path, str(e)))\n\n    def name(self):\n        return FaceRecognizerResnet.NAME\n\n    def get_new_rois(self, rois):\n        new_rois = []\n        for roi in rois:\n            if roi.shape[0] != 224 or roi.shape[1] != 224:\n                new_roi = cv2.resize(roi, (224, 224), interpolation=cv2.INTER_AREA)\n                new_rois.append(new_roi)\n            else:\n                new_rois.append(roi)\n        return new_rois\n\n    def extract_features(self, npimg=None, rois=None, faces=None):\n        if not rois and faces:\n            rois = faces_to_rois(npimg=npimg,\n                                 faces=faces,\n                                 roi_mode=FaceRecognizerResnet.NAME)\n\n        if rois:\n            new_rois = self.get_new_rois(rois=rois)\n            for face, roi in zip(faces, new_rois):\n                face.face_roi = roi\n        else:\n            return np.array([]), np.array([])\n\n        probs = []\n        feats = []\n        for roi_chunk in grouper(new_rois, self.batch_size, fillvalue=np.zeros((224, 224, 3), dtype=np.uint8)):\n            prob, feat = self.persistent_sess.run([self.network['out'], self.network['feat']],\n                                                  feed_dict={self.input_node: roi_chunk})\n            feat = [np.squeeze(x) for x in feat]\n            probs.append(prob)\n            feats.append(feat)\n        probs = np.vstack(probs)[:len(rois)]\n        feats = np.vstack(feats)[:len(rois)]\n\n        return probs, feats\n\n    def detect(self, rois=None, npimg=None, faces=None):\n        probs, feats = self.extract_features(npimg=npimg,\n                                             rois=rois,\n                                             faces=faces)\n\n        if self.db is None:\n            names = [[(str(self.class_names[idx].encode('utf8')), prop[idx]) for idx in\n                      prop.argsort()[-5:][::-1]] for prop in probs]\n        else:\n            names = []\n            for feat in feats:\n                scores = []\n                for db_name, db_feature in self.db.items():\n                    similarity = np.dot(feat / np.linalg.norm(feat, 2), db_feature / np.linalg.norm(db_feature, 2))\n                    scores.append((db_name, similarity))\n                scores.sort(key=lambda x: x[1], reverse=True)\n                names.append(scores)\n\n        return {\n            'output': probs,\n            'feature': feats,\n            'name': names\n        }\n\n    def get_threshold(self):\n        return DeepFaceConfs.get()['recognizer']['resnet']['score_th']\n"""
deepface/recognizers/recognizer_vgg.py,10,"b""import abc\nimport os\nimport sys\n\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom scipy.io import loadmat\nimport pickle\n\nfrom deepface.confs.conf import DeepFaceConfs\nfrom .recognizer_base import FaceRecognizer\nfrom deepface.utils.common import grouper, faces_to_rois, feat_distance_cosine\n\n\nclass FaceRecognizerVGG(FaceRecognizer):\n    NAME = 'recognizer_vgg'\n\n    def __init__(self, custom_db=None):\n        self.batch_size = 4\n        dir_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'vggface')\n        filename = 'weight.mat'\n        filepath = os.path.join(dir_path, filename)\n\n        if not os.path.exists(filepath):\n            raise FileNotFoundError('Weight file not found, path=%s' % filepath)\n\n        data = loadmat(filepath)\n\n        # read meta info\n        meta = data['meta']\n        classes = meta['classes']\n        normalization = meta['normalization']\n\n        self.average_image = np.squeeze(normalization[0][0]['averageImage'][0][0][0][0]).reshape(1, 1, 1, 3)\n        self.input_hw = tuple(np.squeeze(normalization[0][0]['imageSize'][0][0])[:2])\n        self.input_node = tf.placeholder(tf.float32, shape=(None, self.input_hw[0], self.input_hw[1], 3), name='image')\n        self.class_names = [str(x[0][0]) for x in classes[0][0]['description'][0][0]]\n\n        input_norm = tf.subtract(self.input_node, self.average_image, name='normalized_image')\n\n        # read layer info\n        layers = data['layers']\n        current = input_norm\n        network = {}\n        for layer in layers[0]:\n            name = layer[0]['name'][0][0]\n            layer_type = layer[0]['type'][0][0]\n            if layer_type == 'conv':\n                if name[:2] == 'fc':\n                    padding = 'VALID'\n                else:\n                    padding = 'SAME'\n                stride = layer[0]['stride'][0][0]\n                kernel, bias = layer[0]['weights'][0][0]\n                # kernel = np.transpose(kernel, (1, 0, 2, 3))\n                bias = np.squeeze(bias).reshape(-1)\n                conv = tf.nn.conv2d(current, tf.constant(kernel), strides=(1, stride[0], stride[0], 1), padding=padding)\n                current = tf.nn.bias_add(conv, bias)\n            elif layer_type == 'relu':\n                current = tf.nn.relu(current)\n            elif layer_type == 'pool':\n                stride = layer[0]['stride'][0][0]\n                pool = layer[0]['pool'][0][0]\n                current = tf.nn.max_pool(current, ksize=(1, pool[0], pool[1], 1), strides=(1, stride[0], stride[0], 1),\n                                         padding='SAME')\n            elif layer_type == 'softmax':\n                current = tf.nn.softmax(tf.reshape(current, [-1, len(self.class_names)]))\n\n            network[name] = current\n        self.network = network\n\n        self.graph = tf.get_default_graph()\n        config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n        self.persistent_sess = tf.Session(graph=self.graph, config=config)\n        self.db = None\n\n        if custom_db:\n            db_path = custom_db\n        else:\n            db_path = DeepFaceConfs.get()['recognizer']['vgg'].get('db', '')\n            db_path = os.path.join(dir_path, db_path)\n        with open(db_path, 'rb') as f:\n            self.db = pickle.load(f)\n\n        # warm-up\n        self.persistent_sess.run([self.network['prob'], self.network['fc7']], feed_dict={\n            self.input_node: np.zeros((self.batch_size, 224, 224, 3), dtype=np.uint8)\n        })\n\n    def name(self):\n        return FaceRecognizerVGG.NAME\n\n    def get_new_rois(self, rois):\n        new_rois = []\n        for roi in rois:\n            if roi.shape[0] != self.input_hw[0] or roi.shape[1] != self.input_hw[1]:\n                new_roi = cv2.resize(roi, self.input_hw, interpolation=cv2.INTER_AREA)\n                # new_roi = cv2.cvtColor(new_roi, cv2.COLOR_BGR2RGB)\n                new_rois.append(new_roi)\n            else:\n                # roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n                new_rois.append(roi)\n        return new_rois\n\n    def extract_features(self, rois=None, npimg=None, faces=None):\n        probs = []\n        feats = []\n\n        if not rois and faces:\n            rois = faces_to_rois(npimg=npimg,\n                                 faces=faces)\n\n        new_rois = []\n        if len(rois) > 0:\n            new_rois = self.get_new_rois(rois=rois)\n\n        for roi_chunk in grouper(new_rois, self.batch_size,\n                                 fillvalue=np.zeros((self.input_hw[0], self.input_hw[1], 3), dtype=np.uint8)):\n            prob, feat = self.persistent_sess.run([self.network['prob'], self.network['fc7']], feed_dict={\n                self.input_node: roi_chunk\n            })\n            feat = [np.squeeze(x) for x in feat]\n            probs.append(prob)\n            feats.append(feat)\n        probs = np.vstack(probs)[:len(rois)]\n        feats = np.vstack(feats)[:len(rois)]\n\n        return probs, feats\n\n    def detect(self, npimg, rois=None, faces=None):\n        probs, feats = self.extract_features(npimg=npimg,\n                                             rois=rois,\n                                             faces=faces)\n\n        if self.db is None:\n            names = [[(self.class_names[idx], prop[idx]) for idx in\n                      prop.argsort()[-DeepFaceConfs.get()['recognizer']['topk']:][::-1]] for prop in probs]\n        else:\n            # TODO\n            names = []\n            for feat in feats:\n                scores = []\n                for db_name, db_feature in self.db.items():\n                    similarity = feat_distance_cosine(feat, db_feature)\n                    scores.append((db_name, similarity))\n                scores.sort(key=lambda x: x[1], reverse=True)\n                names.append(scores)\n\n        return {\n            'output': probs,\n            'feature': feats,\n            'name': names\n        }\n\n    def get_threshold(self):\n        return DeepFaceConfs.get()['recognizer']['vgg']['score_th']\n"""
deepface/utils/__init__.py,0,b''
deepface/utils/bbox.py,0,"b""class BoundingBox:\n    __slots__ = ['x', 'y', 'w', 'h', 'score', 'face_name', 'face_score', 'face_feature', 'face_landmark', 'face_roi']\n\n    def __init__(self, x=0, y=0, w=0, h=0, score=0.0):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.score = score\n\n        self.face_name = ''\n        self.face_score = 0.0\n        self.face_feature = None\n        self.face_landmark = None\n        self.face_roi = None\n\n    def __repr__(self):\n        return '%.2f %.2f %.2f %.2f score=%.2f name=%s' % (self.x, self.y, self.w, self.h, self.score, self.face_name)\n"""
deepface/utils/colors.py,0,"b'# coding=utf-8\n""""""\nProvide RGB color constants and a colors dictionary with\nelements formatted: colors[colorname] = CONSTANT\n\nReference : https://www.webucator.com/blog/2015/03/python-color-constants-module/\n""""""\n\nfrom collections import namedtuple, OrderedDict\n\nColor = namedtuple(\'RGB\',\'red, green, blue\')\ncolors = {} #dict of colors\n\n\nclass RGB(Color):\n    def hex_format(self):\n        \'\'\'Returns color in hex format\'\'\'\n        return \'#{:02X}{:02X}{:02X}\'.format(self.red,self.green,self.blue)\n\n    def tuple(self):\n        return (self.red, self.green, self.blue)\n\n    def tuple_one(self):\n        return (self.red/255.0, self.green/255.0, self.blue/255.0)\n\n#Color Contants\nALICEBLUE = RGB(240, 248, 255)\nANTIQUEWHITE = RGB(250, 235, 215)\nANTIQUEWHITE1 = RGB(255, 239, 219)\nANTIQUEWHITE2 = RGB(238, 223, 204)\nANTIQUEWHITE3 = RGB(205, 192, 176)\nANTIQUEWHITE4 = RGB(139, 131, 120)\nAQUA = RGB(0, 255, 255)\nAQUAMARINE1 = RGB(127, 255, 212)\nAQUAMARINE2 = RGB(118, 238, 198)\nAQUAMARINE3 = RGB(102, 205, 170)\nAQUAMARINE4 = RGB(69, 139, 116)\nAZURE1 = RGB(240, 255, 255)\nAZURE2 = RGB(224, 238, 238)\nAZURE3 = RGB(193, 205, 205)\nAZURE4 = RGB(131, 139, 139)\nBANANA = RGB(227, 207, 87)\nBEIGE = RGB(245, 245, 220)\nBISQUE1 = RGB(255, 228, 196)\nBISQUE2 = RGB(238, 213, 183)\nBISQUE3 = RGB(205, 183, 158)\nBISQUE4 = RGB(139, 125, 107)\nBLACK = RGB(0, 0, 0)\nBLANCHEDALMOND = RGB(255, 235, 205)\nBLUE = RGB(0, 0, 255)\nBLUE2 = RGB(0, 0, 238)\nBLUE3 = RGB(0, 0, 205)\nBLUE4 = RGB(0, 0, 139)\nBLUEVIOLET = RGB(138, 43, 226)\nBRICK = RGB(156, 102, 31)\nBROWN = RGB(165, 42, 42)\nBROWN1 = RGB(255, 64, 64)\nBROWN2 = RGB(238, 59, 59)\nBROWN3 = RGB(205, 51, 51)\nBROWN4 = RGB(139, 35, 35)\nBURLYWOOD = RGB(222, 184, 135)\nBURLYWOOD1 = RGB(255, 211, 155)\nBURLYWOOD2 = RGB(238, 197, 145)\nBURLYWOOD3 = RGB(205, 170, 125)\nBURLYWOOD4 = RGB(139, 115, 85)\nBURNTSIENNA = RGB(138, 54, 15)\nBURNTUMBER = RGB(138, 51, 36)\nCADETBLUE = RGB(95, 158, 160)\nCADETBLUE1 = RGB(152, 245, 255)\nCADETBLUE2 = RGB(142, 229, 238)\nCADETBLUE3 = RGB(122, 197, 205)\nCADETBLUE4 = RGB(83, 134, 139)\nCADMIUMORANGE = RGB(255, 97, 3)\nCADMIUMYELLOW = RGB(255, 153, 18)\nCARROT = RGB(237, 145, 33)\nCHARTREUSE1 = RGB(127, 255, 0)\nCHARTREUSE2 = RGB(118, 238, 0)\nCHARTREUSE3 = RGB(102, 205, 0)\nCHARTREUSE4 = RGB(69, 139, 0)\nCHOCOLATE = RGB(210, 105, 30)\nCHOCOLATE1 = RGB(255, 127, 36)\nCHOCOLATE2 = RGB(238, 118, 33)\nCHOCOLATE3 = RGB(205, 102, 29)\nCHOCOLATE4 = RGB(139, 69, 19)\nCOBALT = RGB(61, 89, 171)\nCOBALTGREEN = RGB(61, 145, 64)\nCOLDGREY = RGB(128, 138, 135)\nCORAL = RGB(255, 127, 80)\nCORAL1 = RGB(255, 114, 86)\nCORAL2 = RGB(238, 106, 80)\nCORAL3 = RGB(205, 91, 69)\nCORAL4 = RGB(139, 62, 47)\nCORNFLOWERBLUE = RGB(100, 149, 237)\nCORNSILK1 = RGB(255, 248, 220)\nCORNSILK2 = RGB(238, 232, 205)\nCORNSILK3 = RGB(205, 200, 177)\nCORNSILK4 = RGB(139, 136, 120)\nCRIMSON = RGB(220, 20, 60)\nCYAN2 = RGB(0, 238, 238)\nCYAN3 = RGB(0, 205, 205)\nCYAN4 = RGB(0, 139, 139)\nDARKGOLDENROD = RGB(184, 134, 11)\nDARKGOLDENROD1 = RGB(255, 185, 15)\nDARKGOLDENROD2 = RGB(238, 173, 14)\nDARKGOLDENROD3 = RGB(205, 149, 12)\nDARKGOLDENROD4 = RGB(139, 101, 8)\nDARKGRAY = RGB(169, 169, 169)\nDARKGREEN = RGB(0, 100, 0)\nDARKKHAKI = RGB(189, 183, 107)\nDARKOLIVEGREEN = RGB(85, 107, 47)\nDARKOLIVEGREEN1 = RGB(202, 255, 112)\nDARKOLIVEGREEN2 = RGB(188, 238, 104)\nDARKOLIVEGREEN3 = RGB(162, 205, 90)\nDARKOLIVEGREEN4 = RGB(110, 139, 61)\nDARKORANGE = RGB(255, 140, 0)\nDARKORANGE1 = RGB(255, 127, 0)\nDARKORANGE2 = RGB(238, 118, 0)\nDARKORANGE3 = RGB(205, 102, 0)\nDARKORANGE4 = RGB(139, 69, 0)\nDARKORCHID = RGB(153, 50, 204)\nDARKORCHID1 = RGB(191, 62, 255)\nDARKORCHID2 = RGB(178, 58, 238)\nDARKORCHID3 = RGB(154, 50, 205)\nDARKORCHID4 = RGB(104, 34, 139)\nDARKSALMON = RGB(233, 150, 122)\nDARKSEAGREEN = RGB(143, 188, 143)\nDARKSEAGREEN1 = RGB(193, 255, 193)\nDARKSEAGREEN2 = RGB(180, 238, 180)\nDARKSEAGREEN3 = RGB(155, 205, 155)\nDARKSEAGREEN4 = RGB(105, 139, 105)\nDARKSLATEBLUE = RGB(72, 61, 139)\nDARKSLATEGRAY = RGB(47, 79, 79)\nDARKSLATEGRAY1 = RGB(151, 255, 255)\nDARKSLATEGRAY2 = RGB(141, 238, 238)\nDARKSLATEGRAY3 = RGB(121, 205, 205)\nDARKSLATEGRAY4 = RGB(82, 139, 139)\nDARKTURQUOISE = RGB(0, 206, 209)\nDARKVIOLET = RGB(148, 0, 211)\nDEEPPINK1 = RGB(255, 20, 147)\nDEEPPINK2 = RGB(238, 18, 137)\nDEEPPINK3 = RGB(205, 16, 118)\nDEEPPINK4 = RGB(139, 10, 80)\nDEEPSKYBLUE1 = RGB(0, 191, 255)\nDEEPSKYBLUE2 = RGB(0, 178, 238)\nDEEPSKYBLUE3 = RGB(0, 154, 205)\nDEEPSKYBLUE4 = RGB(0, 104, 139)\nDIMGRAY = RGB(105, 105, 105)\nDIMGRAY = RGB(105, 105, 105)\nDODGERBLUE1 = RGB(30, 144, 255)\nDODGERBLUE2 = RGB(28, 134, 238)\nDODGERBLUE3 = RGB(24, 116, 205)\nDODGERBLUE4 = RGB(16, 78, 139)\nEGGSHELL = RGB(252, 230, 201)\nEMERALDGREEN = RGB(0, 201, 87)\nFIREBRICK = RGB(178, 34, 34)\nFIREBRICK1 = RGB(255, 48, 48)\nFIREBRICK2 = RGB(238, 44, 44)\nFIREBRICK3 = RGB(205, 38, 38)\nFIREBRICK4 = RGB(139, 26, 26)\nFLESH = RGB(255, 125, 64)\nFLORALWHITE = RGB(255, 250, 240)\nFORESTGREEN = RGB(34, 139, 34)\nGAINSBORO = RGB(220, 220, 220)\nGHOSTWHITE = RGB(248, 248, 255)\nGOLD1 = RGB(255, 215, 0)\nGOLD2 = RGB(238, 201, 0)\nGOLD3 = RGB(205, 173, 0)\nGOLD4 = RGB(139, 117, 0)\nGOLDENROD = RGB(218, 165, 32)\nGOLDENROD1 = RGB(255, 193, 37)\nGOLDENROD2 = RGB(238, 180, 34)\nGOLDENROD3 = RGB(205, 155, 29)\nGOLDENROD4 = RGB(139, 105, 20)\nGRAY = RGB(128, 128, 128)\nGRAY1 = RGB(3, 3, 3)\nGRAY10 = RGB(26, 26, 26)\nGRAY11 = RGB(28, 28, 28)\nGRAY12 = RGB(31, 31, 31)\nGRAY13 = RGB(33, 33, 33)\nGRAY14 = RGB(36, 36, 36)\nGRAY15 = RGB(38, 38, 38)\nGRAY16 = RGB(41, 41, 41)\nGRAY17 = RGB(43, 43, 43)\nGRAY18 = RGB(46, 46, 46)\nGRAY19 = RGB(48, 48, 48)\nGRAY2 = RGB(5, 5, 5)\nGRAY20 = RGB(51, 51, 51)\nGRAY21 = RGB(54, 54, 54)\nGRAY22 = RGB(56, 56, 56)\nGRAY23 = RGB(59, 59, 59)\nGRAY24 = RGB(61, 61, 61)\nGRAY25 = RGB(64, 64, 64)\nGRAY26 = RGB(66, 66, 66)\nGRAY27 = RGB(69, 69, 69)\nGRAY28 = RGB(71, 71, 71)\nGRAY29 = RGB(74, 74, 74)\nGRAY3 = RGB(8, 8, 8)\nGRAY30 = RGB(77, 77, 77)\nGRAY31 = RGB(79, 79, 79)\nGRAY32 = RGB(82, 82, 82)\nGRAY33 = RGB(84, 84, 84)\nGRAY34 = RGB(87, 87, 87)\nGRAY35 = RGB(89, 89, 89)\nGRAY36 = RGB(92, 92, 92)\nGRAY37 = RGB(94, 94, 94)\nGRAY38 = RGB(97, 97, 97)\nGRAY39 = RGB(99, 99, 99)\nGRAY4 = RGB(10, 10, 10)\nGRAY40 = RGB(102, 102, 102)\nGRAY42 = RGB(107, 107, 107)\nGRAY43 = RGB(110, 110, 110)\nGRAY44 = RGB(112, 112, 112)\nGRAY45 = RGB(115, 115, 115)\nGRAY46 = RGB(117, 117, 117)\nGRAY47 = RGB(120, 120, 120)\nGRAY48 = RGB(122, 122, 122)\nGRAY49 = RGB(125, 125, 125)\nGRAY5 = RGB(13, 13, 13)\nGRAY50 = RGB(127, 127, 127)\nGRAY51 = RGB(130, 130, 130)\nGRAY52 = RGB(133, 133, 133)\nGRAY53 = RGB(135, 135, 135)\nGRAY54 = RGB(138, 138, 138)\nGRAY55 = RGB(140, 140, 140)\nGRAY56 = RGB(143, 143, 143)\nGRAY57 = RGB(145, 145, 145)\nGRAY58 = RGB(148, 148, 148)\nGRAY59 = RGB(150, 150, 150)\nGRAY6 = RGB(15, 15, 15)\nGRAY60 = RGB(153, 153, 153)\nGRAY61 = RGB(156, 156, 156)\nGRAY62 = RGB(158, 158, 158)\nGRAY63 = RGB(161, 161, 161)\nGRAY64 = RGB(163, 163, 163)\nGRAY65 = RGB(166, 166, 166)\nGRAY66 = RGB(168, 168, 168)\nGRAY67 = RGB(171, 171, 171)\nGRAY68 = RGB(173, 173, 173)\nGRAY69 = RGB(176, 176, 176)\nGRAY7 = RGB(18, 18, 18)\nGRAY70 = RGB(179, 179, 179)\nGRAY71 = RGB(181, 181, 181)\nGRAY72 = RGB(184, 184, 184)\nGRAY73 = RGB(186, 186, 186)\nGRAY74 = RGB(189, 189, 189)\nGRAY75 = RGB(191, 191, 191)\nGRAY76 = RGB(194, 194, 194)\nGRAY77 = RGB(196, 196, 196)\nGRAY78 = RGB(199, 199, 199)\nGRAY79 = RGB(201, 201, 201)\nGRAY8 = RGB(20, 20, 20)\nGRAY80 = RGB(204, 204, 204)\nGRAY81 = RGB(207, 207, 207)\nGRAY82 = RGB(209, 209, 209)\nGRAY83 = RGB(212, 212, 212)\nGRAY84 = RGB(214, 214, 214)\nGRAY85 = RGB(217, 217, 217)\nGRAY86 = RGB(219, 219, 219)\nGRAY87 = RGB(222, 222, 222)\nGRAY88 = RGB(224, 224, 224)\nGRAY89 = RGB(227, 227, 227)\nGRAY9 = RGB(23, 23, 23)\nGRAY90 = RGB(229, 229, 229)\nGRAY91 = RGB(232, 232, 232)\nGRAY92 = RGB(235, 235, 235)\nGRAY93 = RGB(237, 237, 237)\nGRAY94 = RGB(240, 240, 240)\nGRAY95 = RGB(242, 242, 242)\nGRAY97 = RGB(247, 247, 247)\nGRAY98 = RGB(250, 250, 250)\nGRAY99 = RGB(252, 252, 252)\nGREEN = RGB(0, 128, 0)\nGREEN1 = RGB(0, 255, 0)\nGREEN2 = RGB(0, 238, 0)\nGREEN3 = RGB(0, 205, 0)\nGREEN4 = RGB(0, 139, 0)\nGREENYELLOW = RGB(173, 255, 47)\nHONEYDEW1 = RGB(240, 255, 240)\nHONEYDEW2 = RGB(224, 238, 224)\nHONEYDEW3 = RGB(193, 205, 193)\nHONEYDEW4 = RGB(131, 139, 131)\nHOTPINK = RGB(255, 105, 180)\nHOTPINK1 = RGB(255, 110, 180)\nHOTPINK2 = RGB(238, 106, 167)\nHOTPINK3 = RGB(205, 96, 144)\nHOTPINK4 = RGB(139, 58, 98)\nINDIANRED = RGB(176, 23, 31)\nINDIANRED = RGB(205, 92, 92)\nINDIANRED1 = RGB(255, 106, 106)\nINDIANRED2 = RGB(238, 99, 99)\nINDIANRED3 = RGB(205, 85, 85)\nINDIANRED4 = RGB(139, 58, 58)\nINDIGO = RGB(75, 0, 130)\nIVORY1 = RGB(255, 255, 240)\nIVORY2 = RGB(238, 238, 224)\nIVORY3 = RGB(205, 205, 193)\nIVORY4 = RGB(139, 139, 131)\nIVORYBLACK = RGB(41, 36, 33)\nKHAKI = RGB(240, 230, 140)\nKHAKI1 = RGB(255, 246, 143)\nKHAKI2 = RGB(238, 230, 133)\nKHAKI3 = RGB(205, 198, 115)\nKHAKI4 = RGB(139, 134, 78)\nLAVENDER = RGB(230, 230, 250)\nLAVENDERBLUSH1 = RGB(255, 240, 245)\nLAVENDERBLUSH2 = RGB(238, 224, 229)\nLAVENDERBLUSH3 = RGB(205, 193, 197)\nLAVENDERBLUSH4 = RGB(139, 131, 134)\nLAWNGREEN = RGB(124, 252, 0)\nLEMONCHIFFON1 = RGB(255, 250, 205)\nLEMONCHIFFON2 = RGB(238, 233, 191)\nLEMONCHIFFON3 = RGB(205, 201, 165)\nLEMONCHIFFON4 = RGB(139, 137, 112)\nLIGHTBLUE = RGB(173, 216, 230)\nLIGHTBLUE1 = RGB(191, 239, 255)\nLIGHTBLUE2 = RGB(178, 223, 238)\nLIGHTBLUE3 = RGB(154, 192, 205)\nLIGHTBLUE4 = RGB(104, 131, 139)\nLIGHTCORAL = RGB(240, 128, 128)\nLIGHTCYAN1 = RGB(224, 255, 255)\nLIGHTCYAN2 = RGB(209, 238, 238)\nLIGHTCYAN3 = RGB(180, 205, 205)\nLIGHTCYAN4 = RGB(122, 139, 139)\nLIGHTGOLDENROD1 = RGB(255, 236, 139)\nLIGHTGOLDENROD2 = RGB(238, 220, 130)\nLIGHTGOLDENROD3 = RGB(205, 190, 112)\nLIGHTGOLDENROD4 = RGB(139, 129, 76)\nLIGHTGOLDENRODYELLOW = RGB(250, 250, 210)\nLIGHTGREY = RGB(211, 211, 211)\nLIGHTPINK = RGB(255, 182, 193)\nLIGHTPINK1 = RGB(255, 174, 185)\nLIGHTPINK2 = RGB(238, 162, 173)\nLIGHTPINK3 = RGB(205, 140, 149)\nLIGHTPINK4 = RGB(139, 95, 101)\nLIGHTSALMON1 = RGB(255, 160, 122)\nLIGHTSALMON2 = RGB(238, 149, 114)\nLIGHTSALMON3 = RGB(205, 129, 98)\nLIGHTSALMON4 = RGB(139, 87, 66)\nLIGHTSEAGREEN = RGB(32, 178, 170)\nLIGHTSKYBLUE = RGB(135, 206, 250)\nLIGHTSKYBLUE1 = RGB(176, 226, 255)\nLIGHTSKYBLUE2 = RGB(164, 211, 238)\nLIGHTSKYBLUE3 = RGB(141, 182, 205)\nLIGHTSKYBLUE4 = RGB(96, 123, 139)\nLIGHTSLATEBLUE = RGB(132, 112, 255)\nLIGHTSLATEGRAY = RGB(119, 136, 153)\nLIGHTSTEELBLUE = RGB(176, 196, 222)\nLIGHTSTEELBLUE1 = RGB(202, 225, 255)\nLIGHTSTEELBLUE2 = RGB(188, 210, 238)\nLIGHTSTEELBLUE3 = RGB(162, 181, 205)\nLIGHTSTEELBLUE4 = RGB(110, 123, 139)\nLIGHTYELLOW1 = RGB(255, 255, 224)\nLIGHTYELLOW2 = RGB(238, 238, 209)\nLIGHTYELLOW3 = RGB(205, 205, 180)\nLIGHTYELLOW4 = RGB(139, 139, 122)\nLIMEGREEN = RGB(50, 205, 50)\nLINEN = RGB(250, 240, 230)\nMAGENTA = RGB(255, 0, 255)\nMAGENTA2 = RGB(238, 0, 238)\nMAGENTA3 = RGB(205, 0, 205)\nMAGENTA4 = RGB(139, 0, 139)\nMANGANESEBLUE = RGB(3, 168, 158)\nMAROON = RGB(128, 0, 0)\nMAROON1 = RGB(255, 52, 179)\nMAROON2 = RGB(238, 48, 167)\nMAROON3 = RGB(205, 41, 144)\nMAROON4 = RGB(139, 28, 98)\nMEDIUMORCHID = RGB(186, 85, 211)\nMEDIUMORCHID1 = RGB(224, 102, 255)\nMEDIUMORCHID2 = RGB(209, 95, 238)\nMEDIUMORCHID3 = RGB(180, 82, 205)\nMEDIUMORCHID4 = RGB(122, 55, 139)\nMEDIUMPURPLE = RGB(147, 112, 219)\nMEDIUMPURPLE1 = RGB(171, 130, 255)\nMEDIUMPURPLE2 = RGB(159, 121, 238)\nMEDIUMPURPLE3 = RGB(137, 104, 205)\nMEDIUMPURPLE4 = RGB(93, 71, 139)\nMEDIUMSEAGREEN = RGB(60, 179, 113)\nMEDIUMSLATEBLUE = RGB(123, 104, 238)\nMEDIUMSPRINGGREEN = RGB(0, 250, 154)\nMEDIUMTURQUOISE = RGB(72, 209, 204)\nMEDIUMVIOLETRED = RGB(199, 21, 133)\nMELON = RGB(227, 168, 105)\nMIDNIGHTBLUE = RGB(25, 25, 112)\nMINT = RGB(189, 252, 201)\nMINTCREAM = RGB(245, 255, 250)\nMISTYROSE1 = RGB(255, 228, 225)\nMISTYROSE2 = RGB(238, 213, 210)\nMISTYROSE3 = RGB(205, 183, 181)\nMISTYROSE4 = RGB(139, 125, 123)\nMOCCASIN = RGB(255, 228, 181)\nNAVAJOWHITE1 = RGB(255, 222, 173)\nNAVAJOWHITE2 = RGB(238, 207, 161)\nNAVAJOWHITE3 = RGB(205, 179, 139)\nNAVAJOWHITE4 = RGB(139, 121, 94)\nNAVY = RGB(0, 0, 128)\nOLDLACE = RGB(253, 245, 230)\nOLIVE = RGB(128, 128, 0)\nOLIVEDRAB = RGB(107, 142, 35)\nOLIVEDRAB1 = RGB(192, 255, 62)\nOLIVEDRAB2 = RGB(179, 238, 58)\nOLIVEDRAB3 = RGB(154, 205, 50)\nOLIVEDRAB4 = RGB(105, 139, 34)\nORANGE = RGB(255, 128, 0)\nORANGE1 = RGB(255, 165, 0)\nORANGE2 = RGB(238, 154, 0)\nORANGE3 = RGB(205, 133, 0)\nORANGE4 = RGB(139, 90, 0)\nORANGERED1 = RGB(255, 69, 0)\nORANGERED2 = RGB(238, 64, 0)\nORANGERED3 = RGB(205, 55, 0)\nORANGERED4 = RGB(139, 37, 0)\nORCHID = RGB(218, 112, 214)\nORCHID1 = RGB(255, 131, 250)\nORCHID2 = RGB(238, 122, 233)\nORCHID3 = RGB(205, 105, 201)\nORCHID4 = RGB(139, 71, 137)\nPALEGOLDENROD = RGB(238, 232, 170)\nPALEGREEN = RGB(152, 251, 152)\nPALEGREEN1 = RGB(154, 255, 154)\nPALEGREEN2 = RGB(144, 238, 144)\nPALEGREEN3 = RGB(124, 205, 124)\nPALEGREEN4 = RGB(84, 139, 84)\nPALETURQUOISE1 = RGB(187, 255, 255)\nPALETURQUOISE2 = RGB(174, 238, 238)\nPALETURQUOISE3 = RGB(150, 205, 205)\nPALETURQUOISE4 = RGB(102, 139, 139)\nPALEVIOLETRED = RGB(219, 112, 147)\nPALEVIOLETRED1 = RGB(255, 130, 171)\nPALEVIOLETRED2 = RGB(238, 121, 159)\nPALEVIOLETRED3 = RGB(205, 104, 137)\nPALEVIOLETRED4 = RGB(139, 71, 93)\nPAPAYAWHIP = RGB(255, 239, 213)\nPEACHPUFF1 = RGB(255, 218, 185)\nPEACHPUFF2 = RGB(238, 203, 173)\nPEACHPUFF3 = RGB(205, 175, 149)\nPEACHPUFF4 = RGB(139, 119, 101)\nPEACOCK = RGB(51, 161, 201)\nPINK = RGB(255, 192, 203)\nPINK1 = RGB(255, 181, 197)\nPINK2 = RGB(238, 169, 184)\nPINK3 = RGB(205, 145, 158)\nPINK4 = RGB(139, 99, 108)\nPLUM = RGB(221, 160, 221)\nPLUM1 = RGB(255, 187, 255)\nPLUM2 = RGB(238, 174, 238)\nPLUM3 = RGB(205, 150, 205)\nPLUM4 = RGB(139, 102, 139)\nPOWDERBLUE = RGB(176, 224, 230)\nPURPLE = RGB(128, 0, 128)\nPURPLE1 = RGB(155, 48, 255)\nPURPLE2 = RGB(145, 44, 238)\nPURPLE3 = RGB(125, 38, 205)\nPURPLE4 = RGB(85, 26, 139)\nRASPBERRY = RGB(135, 38, 87)\nRAWSIENNA = RGB(199, 97, 20)\nRED1 = RGB(255, 0, 0)\nRED2 = RGB(238, 0, 0)\nRED3 = RGB(205, 0, 0)\nRED4 = RGB(139, 0, 0)\nROSYBROWN = RGB(188, 143, 143)\nROSYBROWN1 = RGB(255, 193, 193)\nROSYBROWN2 = RGB(238, 180, 180)\nROSYBROWN3 = RGB(205, 155, 155)\nROSYBROWN4 = RGB(139, 105, 105)\nROYALBLUE = RGB(65, 105, 225)\nROYALBLUE1 = RGB(72, 118, 255)\nROYALBLUE2 = RGB(67, 110, 238)\nROYALBLUE3 = RGB(58, 95, 205)\nROYALBLUE4 = RGB(39, 64, 139)\nSALMON = RGB(250, 128, 114)\nSALMON1 = RGB(255, 140, 105)\nSALMON2 = RGB(238, 130, 98)\nSALMON3 = RGB(205, 112, 84)\nSALMON4 = RGB(139, 76, 57)\nSANDYBROWN = RGB(244, 164, 96)\nSAPGREEN = RGB(48, 128, 20)\nSEAGREEN1 = RGB(84, 255, 159)\nSEAGREEN2 = RGB(78, 238, 148)\nSEAGREEN3 = RGB(67, 205, 128)\nSEAGREEN4 = RGB(46, 139, 87)\nSEASHELL1 = RGB(255, 245, 238)\nSEASHELL2 = RGB(238, 229, 222)\nSEASHELL3 = RGB(205, 197, 191)\nSEASHELL4 = RGB(139, 134, 130)\nSEPIA = RGB(94, 38, 18)\nSGIBEET = RGB(142, 56, 142)\nSGIBRIGHTGRAY = RGB(197, 193, 170)\nSGICHARTREUSE = RGB(113, 198, 113)\nSGIDARKGRAY = RGB(85, 85, 85)\nSGIGRAY12 = RGB(30, 30, 30)\nSGIGRAY16 = RGB(40, 40, 40)\nSGIGRAY32 = RGB(81, 81, 81)\nSGIGRAY36 = RGB(91, 91, 91)\nSGIGRAY52 = RGB(132, 132, 132)\nSGIGRAY56 = RGB(142, 142, 142)\nSGIGRAY72 = RGB(183, 183, 183)\nSGIGRAY76 = RGB(193, 193, 193)\nSGIGRAY92 = RGB(234, 234, 234)\nSGIGRAY96 = RGB(244, 244, 244)\nSGILIGHTBLUE = RGB(125, 158, 192)\nSGILIGHTGRAY = RGB(170, 170, 170)\nSGIOLIVEDRAB = RGB(142, 142, 56)\nSGISALMON = RGB(198, 113, 113)\nSGISLATEBLUE = RGB(113, 113, 198)\nSGITEAL = RGB(56, 142, 142)\nSIENNA = RGB(160, 82, 45)\nSIENNA1 = RGB(255, 130, 71)\nSIENNA2 = RGB(238, 121, 66)\nSIENNA3 = RGB(205, 104, 57)\nSIENNA4 = RGB(139, 71, 38)\nSILVER = RGB(192, 192, 192)\nSKYBLUE = RGB(135, 206, 235)\nSKYBLUE1 = RGB(135, 206, 255)\nSKYBLUE2 = RGB(126, 192, 238)\nSKYBLUE3 = RGB(108, 166, 205)\nSKYBLUE4 = RGB(74, 112, 139)\nSLATEBLUE = RGB(106, 90, 205)\nSLATEBLUE1 = RGB(131, 111, 255)\nSLATEBLUE2 = RGB(122, 103, 238)\nSLATEBLUE3 = RGB(105, 89, 205)\nSLATEBLUE4 = RGB(71, 60, 139)\nSLATEGRAY = RGB(112, 128, 144)\nSLATEGRAY1 = RGB(198, 226, 255)\nSLATEGRAY2 = RGB(185, 211, 238)\nSLATEGRAY3 = RGB(159, 182, 205)\nSLATEGRAY4 = RGB(108, 123, 139)\nSNOW1 = RGB(255, 250, 250)\nSNOW2 = RGB(238, 233, 233)\nSNOW3 = RGB(205, 201, 201)\nSNOW4 = RGB(139, 137, 137)\nSPRINGGREEN = RGB(0, 255, 127)\nSPRINGGREEN1 = RGB(0, 238, 118)\nSPRINGGREEN2 = RGB(0, 205, 102)\nSPRINGGREEN3 = RGB(0, 139, 69)\nSTEELBLUE = RGB(70, 130, 180)\nSTEELBLUE1 = RGB(99, 184, 255)\nSTEELBLUE2 = RGB(92, 172, 238)\nSTEELBLUE3 = RGB(79, 148, 205)\nSTEELBLUE4 = RGB(54, 100, 139)\nTAN = RGB(210, 180, 140)\nTAN1 = RGB(255, 165, 79)\nTAN2 = RGB(238, 154, 73)\nTAN3 = RGB(205, 133, 63)\nTAN4 = RGB(139, 90, 43)\nTEAL = RGB(0, 128, 128)\nTHISTLE = RGB(216, 191, 216)\nTHISTLE1 = RGB(255, 225, 255)\nTHISTLE2 = RGB(238, 210, 238)\nTHISTLE3 = RGB(205, 181, 205)\nTHISTLE4 = RGB(139, 123, 139)\nTOMATO1 = RGB(255, 99, 71)\nTOMATO2 = RGB(238, 92, 66)\nTOMATO3 = RGB(205, 79, 57)\nTOMATO4 = RGB(139, 54, 38)\nTURQUOISE = RGB(64, 224, 208)\nTURQUOISE1 = RGB(0, 245, 255)\nTURQUOISE2 = RGB(0, 229, 238)\nTURQUOISE3 = RGB(0, 197, 205)\nTURQUOISE4 = RGB(0, 134, 139)\nTURQUOISEBLUE = RGB(0, 199, 140)\nVIOLET = RGB(238, 130, 238)\nVIOLETRED = RGB(208, 32, 144)\nVIOLETRED1 = RGB(255, 62, 150)\nVIOLETRED2 = RGB(238, 58, 140)\nVIOLETRED3 = RGB(205, 50, 120)\nVIOLETRED4 = RGB(139, 34, 82)\nWARMGREY = RGB(128, 128, 105)\nWHEAT = RGB(245, 222, 179)\nWHEAT1 = RGB(255, 231, 186)\nWHEAT2 = RGB(238, 216, 174)\nWHEAT3 = RGB(205, 186, 150)\nWHEAT4 = RGB(139, 126, 102)\nWHITE = RGB(255, 255, 255)\nWHITESMOKE = RGB(245, 245, 245)\nWHITESMOKE = RGB(245, 245, 245)\nYELLOW1 = RGB(255, 255, 0)\nYELLOW2 = RGB(238, 238, 0)\nYELLOW3 = RGB(205, 205, 0)\nYELLOW4 = RGB(139, 139, 0)\n\n#Add colors to colors dictionary\ncolors[\'aliceblue\'] = ALICEBLUE\ncolors[\'antiquewhite\'] = ANTIQUEWHITE\ncolors[\'antiquewhite1\'] = ANTIQUEWHITE1\ncolors[\'antiquewhite2\'] = ANTIQUEWHITE2\ncolors[\'antiquewhite3\'] = ANTIQUEWHITE3\ncolors[\'antiquewhite4\'] = ANTIQUEWHITE4\ncolors[\'aqua\'] = AQUA\ncolors[\'aquamarine1\'] = AQUAMARINE1\ncolors[\'aquamarine2\'] = AQUAMARINE2\ncolors[\'aquamarine3\'] = AQUAMARINE3\ncolors[\'aquamarine4\'] = AQUAMARINE4\ncolors[\'azure1\'] = AZURE1\ncolors[\'azure2\'] = AZURE2\ncolors[\'azure3\'] = AZURE3\ncolors[\'azure4\'] = AZURE4\ncolors[\'banana\'] = BANANA\ncolors[\'beige\'] = BEIGE\ncolors[\'bisque1\'] = BISQUE1\ncolors[\'bisque2\'] = BISQUE2\ncolors[\'bisque3\'] = BISQUE3\ncolors[\'bisque4\'] = BISQUE4\ncolors[\'black\'] = BLACK\ncolors[\'blanchedalmond\'] = BLANCHEDALMOND\ncolors[\'blue\'] = BLUE\ncolors[\'blue2\'] = BLUE2\ncolors[\'blue3\'] = BLUE3\ncolors[\'blue4\'] = BLUE4\ncolors[\'blueviolet\'] = BLUEVIOLET\ncolors[\'brick\'] = BRICK\ncolors[\'brown\'] = BROWN\ncolors[\'brown1\'] = BROWN1\ncolors[\'brown2\'] = BROWN2\ncolors[\'brown3\'] = BROWN3\ncolors[\'brown4\'] = BROWN4\ncolors[\'burlywood\'] = BURLYWOOD\ncolors[\'burlywood1\'] = BURLYWOOD1\ncolors[\'burlywood2\'] = BURLYWOOD2\ncolors[\'burlywood3\'] = BURLYWOOD3\ncolors[\'burlywood4\'] = BURLYWOOD4\ncolors[\'burntsienna\'] = BURNTSIENNA\ncolors[\'burntumber\'] = BURNTUMBER\ncolors[\'cadetblue\'] = CADETBLUE\ncolors[\'cadetblue1\'] = CADETBLUE1\ncolors[\'cadetblue2\'] = CADETBLUE2\ncolors[\'cadetblue3\'] = CADETBLUE3\ncolors[\'cadetblue4\'] = CADETBLUE4\ncolors[\'cadmiumorange\'] = CADMIUMORANGE\ncolors[\'cadmiumyellow\'] = CADMIUMYELLOW\ncolors[\'carrot\'] = CARROT\ncolors[\'chartreuse1\'] = CHARTREUSE1\ncolors[\'chartreuse2\'] = CHARTREUSE2\ncolors[\'chartreuse3\'] = CHARTREUSE3\ncolors[\'chartreuse4\'] = CHARTREUSE4\ncolors[\'chocolate\'] = CHOCOLATE\ncolors[\'chocolate1\'] = CHOCOLATE1\ncolors[\'chocolate2\'] = CHOCOLATE2\ncolors[\'chocolate3\'] = CHOCOLATE3\ncolors[\'chocolate4\'] = CHOCOLATE4\ncolors[\'cobalt\'] = COBALT\ncolors[\'cobaltgreen\'] = COBALTGREEN\ncolors[\'coldgrey\'] = COLDGREY\ncolors[\'coral\'] = CORAL\ncolors[\'coral1\'] = CORAL1\ncolors[\'coral2\'] = CORAL2\ncolors[\'coral3\'] = CORAL3\ncolors[\'coral4\'] = CORAL4\ncolors[\'cornflowerblue\'] = CORNFLOWERBLUE\ncolors[\'cornsilk1\'] = CORNSILK1\ncolors[\'cornsilk2\'] = CORNSILK2\ncolors[\'cornsilk3\'] = CORNSILK3\ncolors[\'cornsilk4\'] = CORNSILK4\ncolors[\'crimson\'] = CRIMSON\ncolors[\'cyan2\'] = CYAN2\ncolors[\'cyan3\'] = CYAN3\ncolors[\'cyan4\'] = CYAN4\ncolors[\'darkgoldenrod\'] = DARKGOLDENROD\ncolors[\'darkgoldenrod1\'] = DARKGOLDENROD1\ncolors[\'darkgoldenrod2\'] = DARKGOLDENROD2\ncolors[\'darkgoldenrod3\'] = DARKGOLDENROD3\ncolors[\'darkgoldenrod4\'] = DARKGOLDENROD4\ncolors[\'darkgray\'] = DARKGRAY\ncolors[\'darkgreen\'] = DARKGREEN\ncolors[\'darkkhaki\'] = DARKKHAKI\ncolors[\'darkolivegreen\'] = DARKOLIVEGREEN\ncolors[\'darkolivegreen1\'] = DARKOLIVEGREEN1\ncolors[\'darkolivegreen2\'] = DARKOLIVEGREEN2\ncolors[\'darkolivegreen3\'] = DARKOLIVEGREEN3\ncolors[\'darkolivegreen4\'] = DARKOLIVEGREEN4\ncolors[\'darkorange\'] = DARKORANGE\ncolors[\'darkorange1\'] = DARKORANGE1\ncolors[\'darkorange2\'] = DARKORANGE2\ncolors[\'darkorange3\'] = DARKORANGE3\ncolors[\'darkorange4\'] = DARKORANGE4\ncolors[\'darkorchid\'] = DARKORCHID\ncolors[\'darkorchid1\'] = DARKORCHID1\ncolors[\'darkorchid2\'] = DARKORCHID2\ncolors[\'darkorchid3\'] = DARKORCHID3\ncolors[\'darkorchid4\'] = DARKORCHID4\ncolors[\'darksalmon\'] = DARKSALMON\ncolors[\'darkseagreen\'] = DARKSEAGREEN\ncolors[\'darkseagreen1\'] = DARKSEAGREEN1\ncolors[\'darkseagreen2\'] = DARKSEAGREEN2\ncolors[\'darkseagreen3\'] = DARKSEAGREEN3\ncolors[\'darkseagreen4\'] = DARKSEAGREEN4\ncolors[\'darkslateblue\'] = DARKSLATEBLUE\ncolors[\'darkslategray\'] = DARKSLATEGRAY\ncolors[\'darkslategray1\'] = DARKSLATEGRAY1\ncolors[\'darkslategray2\'] = DARKSLATEGRAY2\ncolors[\'darkslategray3\'] = DARKSLATEGRAY3\ncolors[\'darkslategray4\'] = DARKSLATEGRAY4\ncolors[\'darkturquoise\'] = DARKTURQUOISE\ncolors[\'darkviolet\'] = DARKVIOLET\ncolors[\'deeppink1\'] = DEEPPINK1\ncolors[\'deeppink2\'] = DEEPPINK2\ncolors[\'deeppink3\'] = DEEPPINK3\ncolors[\'deeppink4\'] = DEEPPINK4\ncolors[\'deepskyblue1\'] = DEEPSKYBLUE1\ncolors[\'deepskyblue2\'] = DEEPSKYBLUE2\ncolors[\'deepskyblue3\'] = DEEPSKYBLUE3\ncolors[\'deepskyblue4\'] = DEEPSKYBLUE4\ncolors[\'dimgray\'] = DIMGRAY\ncolors[\'dimgray\'] = DIMGRAY\ncolors[\'dodgerblue1\'] = DODGERBLUE1\ncolors[\'dodgerblue2\'] = DODGERBLUE2\ncolors[\'dodgerblue3\'] = DODGERBLUE3\ncolors[\'dodgerblue4\'] = DODGERBLUE4\ncolors[\'eggshell\'] = EGGSHELL\ncolors[\'emeraldgreen\'] = EMERALDGREEN\ncolors[\'firebrick\'] = FIREBRICK\ncolors[\'firebrick1\'] = FIREBRICK1\ncolors[\'firebrick2\'] = FIREBRICK2\ncolors[\'firebrick3\'] = FIREBRICK3\ncolors[\'firebrick4\'] = FIREBRICK4\ncolors[\'flesh\'] = FLESH\ncolors[\'floralwhite\'] = FLORALWHITE\ncolors[\'forestgreen\'] = FORESTGREEN\ncolors[\'gainsboro\'] = GAINSBORO\ncolors[\'ghostwhite\'] = GHOSTWHITE\ncolors[\'gold1\'] = GOLD1\ncolors[\'gold2\'] = GOLD2\ncolors[\'gold3\'] = GOLD3\ncolors[\'gold4\'] = GOLD4\ncolors[\'goldenrod\'] = GOLDENROD\ncolors[\'goldenrod1\'] = GOLDENROD1\ncolors[\'goldenrod2\'] = GOLDENROD2\ncolors[\'goldenrod3\'] = GOLDENROD3\ncolors[\'goldenrod4\'] = GOLDENROD4\ncolors[\'gray\'] = GRAY\ncolors[\'gray1\'] = GRAY1\ncolors[\'gray10\'] = GRAY10\ncolors[\'gray11\'] = GRAY11\ncolors[\'gray12\'] = GRAY12\ncolors[\'gray13\'] = GRAY13\ncolors[\'gray14\'] = GRAY14\ncolors[\'gray15\'] = GRAY15\ncolors[\'gray16\'] = GRAY16\ncolors[\'gray17\'] = GRAY17\ncolors[\'gray18\'] = GRAY18\ncolors[\'gray19\'] = GRAY19\ncolors[\'gray2\'] = GRAY2\ncolors[\'gray20\'] = GRAY20\ncolors[\'gray21\'] = GRAY21\ncolors[\'gray22\'] = GRAY22\ncolors[\'gray23\'] = GRAY23\ncolors[\'gray24\'] = GRAY24\ncolors[\'gray25\'] = GRAY25\ncolors[\'gray26\'] = GRAY26\ncolors[\'gray27\'] = GRAY27\ncolors[\'gray28\'] = GRAY28\ncolors[\'gray29\'] = GRAY29\ncolors[\'gray3\'] = GRAY3\ncolors[\'gray30\'] = GRAY30\ncolors[\'gray31\'] = GRAY31\ncolors[\'gray32\'] = GRAY32\ncolors[\'gray33\'] = GRAY33\ncolors[\'gray34\'] = GRAY34\ncolors[\'gray35\'] = GRAY35\ncolors[\'gray36\'] = GRAY36\ncolors[\'gray37\'] = GRAY37\ncolors[\'gray38\'] = GRAY38\ncolors[\'gray39\'] = GRAY39\ncolors[\'gray4\'] = GRAY4\ncolors[\'gray40\'] = GRAY40\ncolors[\'gray42\'] = GRAY42\ncolors[\'gray43\'] = GRAY43\ncolors[\'gray44\'] = GRAY44\ncolors[\'gray45\'] = GRAY45\ncolors[\'gray46\'] = GRAY46\ncolors[\'gray47\'] = GRAY47\ncolors[\'gray48\'] = GRAY48\ncolors[\'gray49\'] = GRAY49\ncolors[\'gray5\'] = GRAY5\ncolors[\'gray50\'] = GRAY50\ncolors[\'gray51\'] = GRAY51\ncolors[\'gray52\'] = GRAY52\ncolors[\'gray53\'] = GRAY53\ncolors[\'gray54\'] = GRAY54\ncolors[\'gray55\'] = GRAY55\ncolors[\'gray56\'] = GRAY56\ncolors[\'gray57\'] = GRAY57\ncolors[\'gray58\'] = GRAY58\ncolors[\'gray59\'] = GRAY59\ncolors[\'gray6\'] = GRAY6\ncolors[\'gray60\'] = GRAY60\ncolors[\'gray61\'] = GRAY61\ncolors[\'gray62\'] = GRAY62\ncolors[\'gray63\'] = GRAY63\ncolors[\'gray64\'] = GRAY64\ncolors[\'gray65\'] = GRAY65\ncolors[\'gray66\'] = GRAY66\ncolors[\'gray67\'] = GRAY67\ncolors[\'gray68\'] = GRAY68\ncolors[\'gray69\'] = GRAY69\ncolors[\'gray7\'] = GRAY7\ncolors[\'gray70\'] = GRAY70\ncolors[\'gray71\'] = GRAY71\ncolors[\'gray72\'] = GRAY72\ncolors[\'gray73\'] = GRAY73\ncolors[\'gray74\'] = GRAY74\ncolors[\'gray75\'] = GRAY75\ncolors[\'gray76\'] = GRAY76\ncolors[\'gray77\'] = GRAY77\ncolors[\'gray78\'] = GRAY78\ncolors[\'gray79\'] = GRAY79\ncolors[\'gray8\'] = GRAY8\ncolors[\'gray80\'] = GRAY80\ncolors[\'gray81\'] = GRAY81\ncolors[\'gray82\'] = GRAY82\ncolors[\'gray83\'] = GRAY83\ncolors[\'gray84\'] = GRAY84\ncolors[\'gray85\'] = GRAY85\ncolors[\'gray86\'] = GRAY86\ncolors[\'gray87\'] = GRAY87\ncolors[\'gray88\'] = GRAY88\ncolors[\'gray89\'] = GRAY89\ncolors[\'gray9\'] = GRAY9\ncolors[\'gray90\'] = GRAY90\ncolors[\'gray91\'] = GRAY91\ncolors[\'gray92\'] = GRAY92\ncolors[\'gray93\'] = GRAY93\ncolors[\'gray94\'] = GRAY94\ncolors[\'gray95\'] = GRAY95\ncolors[\'gray97\'] = GRAY97\ncolors[\'gray98\'] = GRAY98\ncolors[\'gray99\'] = GRAY99\ncolors[\'green\'] = GREEN\ncolors[\'green1\'] = GREEN1\ncolors[\'green2\'] = GREEN2\ncolors[\'green3\'] = GREEN3\ncolors[\'green4\'] = GREEN4\ncolors[\'greenyellow\'] = GREENYELLOW\ncolors[\'honeydew1\'] = HONEYDEW1\ncolors[\'honeydew2\'] = HONEYDEW2\ncolors[\'honeydew3\'] = HONEYDEW3\ncolors[\'honeydew4\'] = HONEYDEW4\ncolors[\'hotpink\'] = HOTPINK\ncolors[\'hotpink1\'] = HOTPINK1\ncolors[\'hotpink2\'] = HOTPINK2\ncolors[\'hotpink3\'] = HOTPINK3\ncolors[\'hotpink4\'] = HOTPINK4\ncolors[\'indianred\'] = INDIANRED\ncolors[\'indianred\'] = INDIANRED\ncolors[\'indianred1\'] = INDIANRED1\ncolors[\'indianred2\'] = INDIANRED2\ncolors[\'indianred3\'] = INDIANRED3\ncolors[\'indianred4\'] = INDIANRED4\ncolors[\'indigo\'] = INDIGO\ncolors[\'ivory1\'] = IVORY1\ncolors[\'ivory2\'] = IVORY2\ncolors[\'ivory3\'] = IVORY3\ncolors[\'ivory4\'] = IVORY4\ncolors[\'ivoryblack\'] = IVORYBLACK\ncolors[\'khaki\'] = KHAKI\ncolors[\'khaki1\'] = KHAKI1\ncolors[\'khaki2\'] = KHAKI2\ncolors[\'khaki3\'] = KHAKI3\ncolors[\'khaki4\'] = KHAKI4\ncolors[\'lavender\'] = LAVENDER\ncolors[\'lavenderblush1\'] = LAVENDERBLUSH1\ncolors[\'lavenderblush2\'] = LAVENDERBLUSH2\ncolors[\'lavenderblush3\'] = LAVENDERBLUSH3\ncolors[\'lavenderblush4\'] = LAVENDERBLUSH4\ncolors[\'lawngreen\'] = LAWNGREEN\ncolors[\'lemonchiffon1\'] = LEMONCHIFFON1\ncolors[\'lemonchiffon2\'] = LEMONCHIFFON2\ncolors[\'lemonchiffon3\'] = LEMONCHIFFON3\ncolors[\'lemonchiffon4\'] = LEMONCHIFFON4\ncolors[\'lightblue\'] = LIGHTBLUE\ncolors[\'lightblue1\'] = LIGHTBLUE1\ncolors[\'lightblue2\'] = LIGHTBLUE2\ncolors[\'lightblue3\'] = LIGHTBLUE3\ncolors[\'lightblue4\'] = LIGHTBLUE4\ncolors[\'lightcoral\'] = LIGHTCORAL\ncolors[\'lightcyan1\'] = LIGHTCYAN1\ncolors[\'lightcyan2\'] = LIGHTCYAN2\ncolors[\'lightcyan3\'] = LIGHTCYAN3\ncolors[\'lightcyan4\'] = LIGHTCYAN4\ncolors[\'lightgoldenrod1\'] = LIGHTGOLDENROD1\ncolors[\'lightgoldenrod2\'] = LIGHTGOLDENROD2\ncolors[\'lightgoldenrod3\'] = LIGHTGOLDENROD3\ncolors[\'lightgoldenrod4\'] = LIGHTGOLDENROD4\ncolors[\'lightgoldenrodyellow\'] = LIGHTGOLDENRODYELLOW\ncolors[\'lightgrey\'] = LIGHTGREY\ncolors[\'lightpink\'] = LIGHTPINK\ncolors[\'lightpink1\'] = LIGHTPINK1\ncolors[\'lightpink2\'] = LIGHTPINK2\ncolors[\'lightpink3\'] = LIGHTPINK3\ncolors[\'lightpink4\'] = LIGHTPINK4\ncolors[\'lightsalmon1\'] = LIGHTSALMON1\ncolors[\'lightsalmon2\'] = LIGHTSALMON2\ncolors[\'lightsalmon3\'] = LIGHTSALMON3\ncolors[\'lightsalmon4\'] = LIGHTSALMON4\ncolors[\'lightseagreen\'] = LIGHTSEAGREEN\ncolors[\'lightskyblue\'] = LIGHTSKYBLUE\ncolors[\'lightskyblue1\'] = LIGHTSKYBLUE1\ncolors[\'lightskyblue2\'] = LIGHTSKYBLUE2\ncolors[\'lightskyblue3\'] = LIGHTSKYBLUE3\ncolors[\'lightskyblue4\'] = LIGHTSKYBLUE4\ncolors[\'lightslateblue\'] = LIGHTSLATEBLUE\ncolors[\'lightslategray\'] = LIGHTSLATEGRAY\ncolors[\'lightsteelblue\'] = LIGHTSTEELBLUE\ncolors[\'lightsteelblue1\'] = LIGHTSTEELBLUE1\ncolors[\'lightsteelblue2\'] = LIGHTSTEELBLUE2\ncolors[\'lightsteelblue3\'] = LIGHTSTEELBLUE3\ncolors[\'lightsteelblue4\'] = LIGHTSTEELBLUE4\ncolors[\'lightyellow1\'] = LIGHTYELLOW1\ncolors[\'lightyellow2\'] = LIGHTYELLOW2\ncolors[\'lightyellow3\'] = LIGHTYELLOW3\ncolors[\'lightyellow4\'] = LIGHTYELLOW4\ncolors[\'limegreen\'] = LIMEGREEN\ncolors[\'linen\'] = LINEN\ncolors[\'magenta\'] = MAGENTA\ncolors[\'magenta2\'] = MAGENTA2\ncolors[\'magenta3\'] = MAGENTA3\ncolors[\'magenta4\'] = MAGENTA4\ncolors[\'manganeseblue\'] = MANGANESEBLUE\ncolors[\'maroon\'] = MAROON\ncolors[\'maroon1\'] = MAROON1\ncolors[\'maroon2\'] = MAROON2\ncolors[\'maroon3\'] = MAROON3\ncolors[\'maroon4\'] = MAROON4\ncolors[\'mediumorchid\'] = MEDIUMORCHID\ncolors[\'mediumorchid1\'] = MEDIUMORCHID1\ncolors[\'mediumorchid2\'] = MEDIUMORCHID2\ncolors[\'mediumorchid3\'] = MEDIUMORCHID3\ncolors[\'mediumorchid4\'] = MEDIUMORCHID4\ncolors[\'mediumpurple\'] = MEDIUMPURPLE\ncolors[\'mediumpurple1\'] = MEDIUMPURPLE1\ncolors[\'mediumpurple2\'] = MEDIUMPURPLE2\ncolors[\'mediumpurple3\'] = MEDIUMPURPLE3\ncolors[\'mediumpurple4\'] = MEDIUMPURPLE4\ncolors[\'mediumseagreen\'] = MEDIUMSEAGREEN\ncolors[\'mediumslateblue\'] = MEDIUMSLATEBLUE\ncolors[\'mediumspringgreen\'] = MEDIUMSPRINGGREEN\ncolors[\'mediumturquoise\'] = MEDIUMTURQUOISE\ncolors[\'mediumvioletred\'] = MEDIUMVIOLETRED\ncolors[\'melon\'] = MELON\ncolors[\'midnightblue\'] = MIDNIGHTBLUE\ncolors[\'mint\'] = MINT\ncolors[\'mintcream\'] = MINTCREAM\ncolors[\'mistyrose1\'] = MISTYROSE1\ncolors[\'mistyrose2\'] = MISTYROSE2\ncolors[\'mistyrose3\'] = MISTYROSE3\ncolors[\'mistyrose4\'] = MISTYROSE4\ncolors[\'moccasin\'] = MOCCASIN\ncolors[\'navajowhite1\'] = NAVAJOWHITE1\ncolors[\'navajowhite2\'] = NAVAJOWHITE2\ncolors[\'navajowhite3\'] = NAVAJOWHITE3\ncolors[\'navajowhite4\'] = NAVAJOWHITE4\ncolors[\'navy\'] = NAVY\ncolors[\'oldlace\'] = OLDLACE\ncolors[\'olive\'] = OLIVE\ncolors[\'olivedrab\'] = OLIVEDRAB\ncolors[\'olivedrab1\'] = OLIVEDRAB1\ncolors[\'olivedrab2\'] = OLIVEDRAB2\ncolors[\'olivedrab3\'] = OLIVEDRAB3\ncolors[\'olivedrab4\'] = OLIVEDRAB4\ncolors[\'orange\'] = ORANGE\ncolors[\'orange1\'] = ORANGE1\ncolors[\'orange2\'] = ORANGE2\ncolors[\'orange3\'] = ORANGE3\ncolors[\'orange4\'] = ORANGE4\ncolors[\'orangered1\'] = ORANGERED1\ncolors[\'orangered2\'] = ORANGERED2\ncolors[\'orangered3\'] = ORANGERED3\ncolors[\'orangered4\'] = ORANGERED4\ncolors[\'orchid\'] = ORCHID\ncolors[\'orchid1\'] = ORCHID1\ncolors[\'orchid2\'] = ORCHID2\ncolors[\'orchid3\'] = ORCHID3\ncolors[\'orchid4\'] = ORCHID4\ncolors[\'palegoldenrod\'] = PALEGOLDENROD\ncolors[\'palegreen\'] = PALEGREEN\ncolors[\'palegreen1\'] = PALEGREEN1\ncolors[\'palegreen2\'] = PALEGREEN2\ncolors[\'palegreen3\'] = PALEGREEN3\ncolors[\'palegreen4\'] = PALEGREEN4\ncolors[\'paleturquoise1\'] = PALETURQUOISE1\ncolors[\'paleturquoise2\'] = PALETURQUOISE2\ncolors[\'paleturquoise3\'] = PALETURQUOISE3\ncolors[\'paleturquoise4\'] = PALETURQUOISE4\ncolors[\'palevioletred\'] = PALEVIOLETRED\ncolors[\'palevioletred1\'] = PALEVIOLETRED1\ncolors[\'palevioletred2\'] = PALEVIOLETRED2\ncolors[\'palevioletred3\'] = PALEVIOLETRED3\ncolors[\'palevioletred4\'] = PALEVIOLETRED4\ncolors[\'papayawhip\'] = PAPAYAWHIP\ncolors[\'peachpuff1\'] = PEACHPUFF1\ncolors[\'peachpuff2\'] = PEACHPUFF2\ncolors[\'peachpuff3\'] = PEACHPUFF3\ncolors[\'peachpuff4\'] = PEACHPUFF4\ncolors[\'peacock\'] = PEACOCK\ncolors[\'pink\'] = PINK\ncolors[\'pink1\'] = PINK1\ncolors[\'pink2\'] = PINK2\ncolors[\'pink3\'] = PINK3\ncolors[\'pink4\'] = PINK4\ncolors[\'plum\'] = PLUM\ncolors[\'plum1\'] = PLUM1\ncolors[\'plum2\'] = PLUM2\ncolors[\'plum3\'] = PLUM3\ncolors[\'plum4\'] = PLUM4\ncolors[\'powderblue\'] = POWDERBLUE\ncolors[\'purple\'] = PURPLE\ncolors[\'purple1\'] = PURPLE1\ncolors[\'purple2\'] = PURPLE2\ncolors[\'purple3\'] = PURPLE3\ncolors[\'purple4\'] = PURPLE4\ncolors[\'raspberry\'] = RASPBERRY\ncolors[\'rawsienna\'] = RAWSIENNA\ncolors[\'red1\'] = RED1\ncolors[\'red2\'] = RED2\ncolors[\'red3\'] = RED3\ncolors[\'red4\'] = RED4\ncolors[\'rosybrown\'] = ROSYBROWN\ncolors[\'rosybrown1\'] = ROSYBROWN1\ncolors[\'rosybrown2\'] = ROSYBROWN2\ncolors[\'rosybrown3\'] = ROSYBROWN3\ncolors[\'rosybrown4\'] = ROSYBROWN4\ncolors[\'royalblue\'] = ROYALBLUE\ncolors[\'royalblue1\'] = ROYALBLUE1\ncolors[\'royalblue2\'] = ROYALBLUE2\ncolors[\'royalblue3\'] = ROYALBLUE3\ncolors[\'royalblue4\'] = ROYALBLUE4\ncolors[\'salmon\'] = SALMON\ncolors[\'salmon1\'] = SALMON1\ncolors[\'salmon2\'] = SALMON2\ncolors[\'salmon3\'] = SALMON3\ncolors[\'salmon4\'] = SALMON4\ncolors[\'sandybrown\'] = SANDYBROWN\ncolors[\'sapgreen\'] = SAPGREEN\ncolors[\'seagreen1\'] = SEAGREEN1\ncolors[\'seagreen2\'] = SEAGREEN2\ncolors[\'seagreen3\'] = SEAGREEN3\ncolors[\'seagreen4\'] = SEAGREEN4\ncolors[\'seashell1\'] = SEASHELL1\ncolors[\'seashell2\'] = SEASHELL2\ncolors[\'seashell3\'] = SEASHELL3\ncolors[\'seashell4\'] = SEASHELL4\ncolors[\'sepia\'] = SEPIA\ncolors[\'sgibeet\'] = SGIBEET\ncolors[\'sgibrightgray\'] = SGIBRIGHTGRAY\ncolors[\'sgichartreuse\'] = SGICHARTREUSE\ncolors[\'sgidarkgray\'] = SGIDARKGRAY\ncolors[\'sgigray12\'] = SGIGRAY12\ncolors[\'sgigray16\'] = SGIGRAY16\ncolors[\'sgigray32\'] = SGIGRAY32\ncolors[\'sgigray36\'] = SGIGRAY36\ncolors[\'sgigray52\'] = SGIGRAY52\ncolors[\'sgigray56\'] = SGIGRAY56\ncolors[\'sgigray72\'] = SGIGRAY72\ncolors[\'sgigray76\'] = SGIGRAY76\ncolors[\'sgigray92\'] = SGIGRAY92\ncolors[\'sgigray96\'] = SGIGRAY96\ncolors[\'sgilightblue\'] = SGILIGHTBLUE\ncolors[\'sgilightgray\'] = SGILIGHTGRAY\ncolors[\'sgiolivedrab\'] = SGIOLIVEDRAB\ncolors[\'sgisalmon\'] = SGISALMON\ncolors[\'sgislateblue\'] = SGISLATEBLUE\ncolors[\'sgiteal\'] = SGITEAL\ncolors[\'sienna\'] = SIENNA\ncolors[\'sienna1\'] = SIENNA1\ncolors[\'sienna2\'] = SIENNA2\ncolors[\'sienna3\'] = SIENNA3\ncolors[\'sienna4\'] = SIENNA4\ncolors[\'silver\'] = SILVER\ncolors[\'skyblue\'] = SKYBLUE\ncolors[\'skyblue1\'] = SKYBLUE1\ncolors[\'skyblue2\'] = SKYBLUE2\ncolors[\'skyblue3\'] = SKYBLUE3\ncolors[\'skyblue4\'] = SKYBLUE4\ncolors[\'slateblue\'] = SLATEBLUE\ncolors[\'slateblue1\'] = SLATEBLUE1\ncolors[\'slateblue2\'] = SLATEBLUE2\ncolors[\'slateblue3\'] = SLATEBLUE3\ncolors[\'slateblue4\'] = SLATEBLUE4\ncolors[\'slategray\'] = SLATEGRAY\ncolors[\'slategray1\'] = SLATEGRAY1\ncolors[\'slategray2\'] = SLATEGRAY2\ncolors[\'slategray3\'] = SLATEGRAY3\ncolors[\'slategray4\'] = SLATEGRAY4\ncolors[\'snow1\'] = SNOW1\ncolors[\'snow2\'] = SNOW2\ncolors[\'snow3\'] = SNOW3\ncolors[\'snow4\'] = SNOW4\ncolors[\'springgreen\'] = SPRINGGREEN\ncolors[\'springgreen1\'] = SPRINGGREEN1\ncolors[\'springgreen2\'] = SPRINGGREEN2\ncolors[\'springgreen3\'] = SPRINGGREEN3\ncolors[\'steelblue\'] = STEELBLUE\ncolors[\'steelblue1\'] = STEELBLUE1\ncolors[\'steelblue2\'] = STEELBLUE2\ncolors[\'steelblue3\'] = STEELBLUE3\ncolors[\'steelblue4\'] = STEELBLUE4\ncolors[\'tan\'] = TAN\ncolors[\'tan1\'] = TAN1\ncolors[\'tan2\'] = TAN2\ncolors[\'tan3\'] = TAN3\ncolors[\'tan4\'] = TAN4\ncolors[\'teal\'] = TEAL\ncolors[\'thistle\'] = THISTLE\ncolors[\'thistle1\'] = THISTLE1\ncolors[\'thistle2\'] = THISTLE2\ncolors[\'thistle3\'] = THISTLE3\ncolors[\'thistle4\'] = THISTLE4\ncolors[\'tomato1\'] = TOMATO1\ncolors[\'tomato2\'] = TOMATO2\ncolors[\'tomato3\'] = TOMATO3\ncolors[\'tomato4\'] = TOMATO4\ncolors[\'turquoise\'] = TURQUOISE\ncolors[\'turquoise1\'] = TURQUOISE1\ncolors[\'turquoise2\'] = TURQUOISE2\ncolors[\'turquoise3\'] = TURQUOISE3\ncolors[\'turquoise4\'] = TURQUOISE4\ncolors[\'turquoiseblue\'] = TURQUOISEBLUE\ncolors[\'violet\'] = VIOLET\ncolors[\'violetred\'] = VIOLETRED\ncolors[\'violetred1\'] = VIOLETRED1\ncolors[\'violetred2\'] = VIOLETRED2\ncolors[\'violetred3\'] = VIOLETRED3\ncolors[\'violetred4\'] = VIOLETRED4\ncolors[\'warmgrey\'] = WARMGREY\ncolors[\'wheat\'] = WHEAT\ncolors[\'wheat1\'] = WHEAT1\ncolors[\'wheat2\'] = WHEAT2\ncolors[\'wheat3\'] = WHEAT3\ncolors[\'wheat4\'] = WHEAT4\ncolors[\'white\'] = WHITE\ncolors[\'whitesmoke\'] = WHITESMOKE\ncolors[\'whitesmoke\'] = WHITESMOKE\ncolors[\'yellow1\'] = YELLOW1\ncolors[\'yellow2\'] = YELLOW2\ncolors[\'yellow3\'] = YELLOW3\ncolors[\'yellow4\'] = YELLOW4\n\ncolors = OrderedDict(sorted(colors.items(), key=lambda t: t[0]))\ncolor_names = list(colors.keys())\n\n\ndef get_random_color(idx):\n    color_name = color_names[(30 + idx * 7) % len(color_names)]\n    return colors[color_name]\n'"
deepface/utils/common.py,0,"b'# -*- coding: utf-8 -*-\nimport math\n\nimport cv2\nimport numpy as np\n\ntry:\n    from itertools import zip_longest\nexcept:\n    from itertools import izip_longest as zip_longest\n\nfrom deepface.confs.conf import DeepFaceConfs\n\n\ndef grouper(iterable, n, fillvalue=None):\n    args = [iter(iterable)] * n\n    return zip_longest(*args, fillvalue=fillvalue)\n\n\ndef rotate_dot(point, mat):\n    px, py = point\n\n    qx = mat[0][0] * px + mat[0][1] * py + mat[0][2]\n    qy = mat[1][0] * px + mat[1][1] * py + mat[1][2]\n    return int(qx), int(qy)\n\n\ndef roundint(v):\n    return int(round(v))\n\n\ndef tag_faces(faces, result, threshold):\n    for face_idx, face in enumerate(faces):\n        face.face_feature = result[\'feature\'][face_idx]\n        name, score = result[\'name\'][face_idx][0]\n        if score < threshold:\n            continue\n        face.face_name = name\n        face.face_score = score\n\n    return faces\n\n\ndef faces_to_rois(npimg, faces, roi_mode=\'recognizer_vgg\'):\n    rois = []\n    for face in faces:\n        roi = get_roi(npimg, face, roi_mode=roi_mode)\n        rois.append(roi)\n    return rois\n\n\ndef get_roi(img, face, roi_mode):\n    """"""\n    :return: target_size \xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 Cropped & Aligned Face Image\n    """"""\n    rpy, node_point = landmark_to_pose(face.face_landmark, img.shape)\n    roll = rpy[0]\n    if abs(roll) > math.pi / 2.0:\n        roll = 0.0  # TODO ?\n\n    height, width = img.shape[:2]\n\n    new_w, new_h = (abs(math.sin(roll) * height) + abs(math.cos(roll) * width),\n                    abs(math.sin(roll) * width) + abs(math.cos(roll) * height))\n    new_w = roundint(new_w)\n    new_h = roundint(new_h)\n    mat = cv2.getRotationMatrix2D((height / 2, width / 2), -1 * roll * 180.0 / math.pi, 1.0)\n    (tx, ty) = (roundint((new_w - width) / 2), roundint((new_h - height) / 2))\n    mat[0, 2] += tx\n    mat[1, 2] += ty\n    dst = cv2.warpAffine(img, mat, dsize=(new_w + tx * 2, new_h + ty * 2))\n\n    aligned_points = []\n    if face.face_landmark is not None:\n        for x, y in face.face_landmark:\n            new_x, new_y = rotate_dot((x, y), mat)\n            aligned_points.append((new_x, new_y))\n\n        min_x = min(aligned_points, key=lambda x: x[0])[0]\n        max_x = max(aligned_points, key=lambda x: x[0])[0]\n        min_y = min(aligned_points, key=lambda x: x[1])[1]\n        max_y = max(aligned_points, key=lambda x: x[1])[1]\n\n        aligned_w = max_x - min_x\n        aligned_h = max_y - min_y\n        crop_y_ratio = float(DeepFaceConfs.get()[\'roi\'][roi_mode][\'crop_y_ratio\'])\n        center_point = ((min_x + max_x) / 2, min_y * crop_y_ratio + max_y * (1.0 - crop_y_ratio))\n        image_size = int(\n            max(aligned_w, aligned_h) * DeepFaceConfs.get()[\'roi\'][roi_mode][\'size_ratio\'])  # TODO : Parameter tuning?\n    else:\n        min_x, min_y = rotate_dot((face.x, face.y), mat)\n        max_x, max_y = rotate_dot((face.x + face.w, face.y + face.h), mat)\n\n        aligned_w = max_x - min_x\n        aligned_h = max_y - min_y\n        center_point = ((min_x + max_x) / 2, (min_y + max_y) / 2)\n        image_size = int(max(aligned_w, aligned_h) * DeepFaceConfs.get()[\'roi\'][roi_mode][\'size_ratio\'])\n\n    crop_x1 = roundint(center_point[0] - image_size / 2)\n    crop_y1 = roundint(center_point[1] - image_size / 2)\n    crop_x2 = roundint(center_point[0] + image_size / 2)\n    crop_y2 = roundint(center_point[1] + image_size / 2)\n\n    cropped = dst[max(0, crop_y1):min(new_h, crop_y2), max(0, crop_x1):min(new_w, crop_x2)]\n    pasted = np.zeros((image_size, image_size, 3), np.uint8)\n\n    start_x = 0 if crop_x1 > 0 else -crop_x1\n    start_y = 0 if crop_y1 > 0 else -crop_y1\n    crop_w = min(cropped.shape[1], pasted.shape[1] - start_x)\n    crop_h = min(cropped.shape[0], pasted.shape[0] - start_y)\n    try:\n        pasted[start_y:start_y + crop_h, start_x:start_x + crop_w] = cropped[:crop_h, :crop_w]  # TODO\n    except:\n        print(crop_y_ratio, (1.0 - crop_y_ratio), roll, pasted.shape, cropped.shape, \'min\', min_x, max_x, min_y, max_y,\n              \'imgsize\', image_size, start_x, start_y, crop_w, crop_h)\n        print(center_point)\n        # crop_y_ratio set 0.3667256819925064\n        # 0.0 (128, 128, 3) (249, 128, 3) min 76 166 101 193 imgsize 128 0 129 128 -1\n        # (121.0, -65.31315823528763)\n\n    return pasted\n\n\ndef landmark_to_pose(landmark, image_shape):\n    image_points = np.array([\n        landmark[33],  # (359, 391),  # Nose tip\n        landmark[8],  # (399, 561),  # Chin\n        landmark[36],  # (337, 297),  # Left eye left corner\n        landmark[45],  # (513, 301),  # Right eye right corne\n        landmark[48],  # (345, 465),  # Left Mouth corner\n        landmark[54],  # (453, 469)  # Right mouth corner\n    ], dtype=\'double\')\n\n    model_points = np.array([\n        (0.0, 0.0, 0.0),  # Nose tip\n        (0.0, -330.0, -65.0),  # Chin\n        (-225.0, 170.0, -135.0),  # Left eye left corner\n        (225.0, 170.0, -135.0),  # Right eye right corne\n        (-150.0, -150.0, -125.0),  # Left Mouth corner\n        (150.0, -150.0, -125.0)  # Right mouth corner\n    ])\n\n    center = (image_shape[1] / 2, image_shape[0] / 2)\n    focal_length = center[0] / np.tan(60 / 2 * np.pi / 180)\n    camera_matrix = np.array(\n        [[focal_length, 0, center[0]],\n         [0, focal_length, center[1]],\n         [0, 0, 1]], dtype=""double""\n    )\n\n    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n    success, rotation_vector, translation_vector = cv2.solvePnP(model_points, image_points, camera_matrix,\n                                                                dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n\n    rotation, jacobian = cv2.Rodrigues(rotation_vector)\n    translation = np.array(translation_vector).reshape(-1, 1).T[0]\n\n    permutation_marker_to_ros = np.array((\n        (0.0, 0.0, 1.0, 0.0),\n        (1.0, 0.0, 0.0, 0.0),\n        (0.0, 1.0, 0.0, 0.0),\n        (0.0, 0.0, 0.0, 1.0)\n    ), dtype=np.float64)\n    permutation_camera_to_ros = np.array((\n        (0.0, 0.0, 1.0, 0.0),\n        (-1.0, 0.0, 0.0, 0.0),\n        (0.0, -1.0, 0.0, 0.0),\n        (0.0, 0.0, 0.0, 1.0)\n    ), dtype=np.float64)\n\n    relation_cv = np.concatenate((\n        np.concatenate((rotation, translation.reshape(3, 1)), axis=1),\n        np.array((0.0, 0.0, 0.0, 1.0)).reshape(1, 4)\n    ), axis=0)\n    relation = permutation_camera_to_ros.dot(relation_cv)\n    relation = relation.dot(np.linalg.inv(permutation_marker_to_ros))\n\n    if success:\n        nose_end_point2D, jacobian = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector,\n                                                       translation_vector, camera_matrix, dist_coeffs)\n        return rotationMatrixToEulerAngles(relation), nose_end_point2D\n    else:\n        return None, None\n\n\ndef rotationMatrixToEulerAngles(R):\n    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n\n    singular = sy < 1e-6\n\n    if not singular:\n        x = math.atan2(R[2, 1], R[2, 2])\n        y = math.atan2(-R[2, 0], sy)\n        z = math.atan2(R[1, 0], R[0, 0])\n    else:\n        x = math.atan2(-R[1, 2], R[1, 1])\n        y = math.atan2(-R[2, 0], sy)\n        z = 0\n\n    return np.array([x, y, z])\n\n\ndef feat_distance_cosine(feat1, feat2):\n    similarity = np.dot(feat1 / np.linalg.norm(feat1, 2), feat2 / np.linalg.norm(feat2, 2))\n    return similarity\n\n\ndef feat_distance_l2(feat1, feat2):\n    feat1_norm = feat1 / np.linalg.norm(feat1, 2)\n    feat2_norm = feat2 / np.linalg.norm(feat2, 2)\n    similarity = 1.0 - np.linalg.norm(feat1_norm - feat2_norm, 2) / 2.0\n    return similarity\n'"
deepface/utils/visualization.py,0,"b'import cv2\n\nfrom .colors import get_random_color\n\ndef draw_bbox(npimg, bbox, color=(0, 255, 0)):\n    cv2.rectangle(npimg, (bbox.x, bbox.y), (bbox.x + bbox.w, bbox.y + bbox.h), color, 2)\n\n    if bbox.face_landmark is not None:\n        for (x, y) in bbox.face_landmark:\n            cv2.circle(npimg, (x, y), 1, color, -1)\n\n    if bbox.score > 0.0:\n        cv2.putText(npimg, ""%s %.2f"" % ((\'%s(%.2f):\' % (bbox.face_name, bbox.face_score)) if bbox.face_name else \'\', bbox.score), (bbox.x, bbox.y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), thickness=2)\n        cv2.putText(npimg, ""%s %.2f"" % ((\'%s(%.2f):\' % (bbox.face_name, bbox.face_score)) if bbox.face_name else \'\', bbox.score), (bbox.x - 1, bbox.y - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness=1)\n\n\ndef draw_bboxs(npimg, bboxs):\n    for i, bbox in enumerate(bboxs):\n        draw_bbox(npimg, bbox, color=get_random_color(i).tuple())\n    return npimg\n'"
