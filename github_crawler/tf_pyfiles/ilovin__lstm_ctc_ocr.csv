file_path,api_count,code
lib/__init__.py,0,b'#import fast_rcnn\n'
lstm/__init__.py,0,"b""import sys\nsys.path.insert(0, '..')"""
lstm/test_net.py,0,"b'import sys\nimport os\nimport collections\nimport argparse\nimport pprint\nimport numpy as np\nimport pdb\nimport sys\nimport os.path\n\nthis_dir = os.path.dirname(__file__)\nsys.path.insert(0, this_dir + \'/..\')\n\nfrom lib.lstm.test import test_net\nfrom lib.lstm.config import cfg, cfg_from_file, cfg_from_list, get_output_dir, get_log_dir\nfrom lib.networks.factory import get_network\nfrom easydict import EasyDict as edict\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'Test a FCN network\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    parser.add_argument(\'--network\', dest=\'network_name\',\n                        help=\'name of the network\',\n                        default=None, type=str)\n    parser.add_argument(\'--cfg\', dest=\'cfg_file\',\n                        help=\'optional config file\',\n                        default=None, type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'restore or not\',\n                        default=1, type=int)\n\n    if len(sys.argv) == 1:\n        parser.print_help()\n\n    args = parser.parse_args()\n    return args\n\nif __name__ == \'__main__\':\n    args = parse_args()\n\n    print(\'Called with args:\')\n    print(args)\n\n    if args.cfg_file is not None:\n        cfg_from_file(args.cfg_file)\n\n    os.environ[""CUDA_VISIBLE_DEVICES""] = str(cfg.GPU_ID)\n\n    print(\'Using config:\')\n    pprint.pprint(cfg)\n\n    output_network_name=args.network_name.split(\'_\')[-1]\n    imgdb = edict({\'path\':\'./data/train.tfrecords\',\'name\':\'lstm_\'+output_network_name,\n                   \'val_path\':\'./data/val.tfrecords\' })\n\n    output_dir = get_output_dir(imgdb, None)\n    log_dir = get_log_dir(imgdb)\n    print((\'Output will be saved to `{:s}`\'.format(output_dir)))\n    print((\'Logs will be saved to `{:s}`\'.format(log_dir)))\n\n    device_name = \'/gpu:{:d}\'.format(args.gpu_id)\n    print(device_name)\n\n    network = get_network(args.network_name)\n    print((\'Use network `{:s}` in training\'.format(args.network_name)))\n\n    test_net(network, imgdb,\n              testDir= \'./data/val/\', #\'data/demo\'\n              output_dir=output_dir,\n              log_dir=log_dir,\n              restore=bool(int(args.restore)))\n'"
lstm/train_net.py,0,"b'import argparse\nimport pprint\nimport numpy as np\nimport pdb\nimport sys\nimport os.path\n\nthis_dir = os.path.dirname(__file__)\nsys.path.insert(0, this_dir + \'/..\')\n\nfrom lib.lstm.train import train_net\nfrom lib.lstm.config import cfg, cfg_from_file, cfg_from_list, get_output_dir, get_log_dir\nfrom lib.networks.factory import get_network\nfrom easydict import EasyDict as edict\nimport matplotlib\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'Train a lstm network\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    parser.add_argument(\'--iters\', dest=\'max_iters\',\n                        help=\'number of iterations to train\',\n                        default=1000000, type=int)\n    parser.add_argument(\'--cfg\', dest=\'cfg_file\',\n                        help=\'optional config file\',\n                        default=None, type=str)\n    parser.add_argument(\'--pre_train\', dest=\'pre_train\',\n                        help=\'pre trained model\',\n                        default=None, type=str)\n    parser.add_argument(\'--rand\', dest=\'randomize\',\n                        help=\'randomize (do not use a fixed seed)\',\n                        action=\'store_true\')\n    parser.add_argument(\'--network\', dest=\'network_name\',\n                        help=\'name of the network\',\n                        default=None, type=str)\n    parser.add_argument(\'--set\', dest=\'set_cfgs\',\n                        help=\'set config keys\', default=None,\n                        nargs=argparse.REMAINDER)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'restore or not\',\n                        default=0, type=int)\n\n    if len(sys.argv) == 1:\n        parser.print_help()\n\n    args = parser.parse_args()\n    return args\n\n# os.environ[""CUDA_VISIBLE_DEVICES""] = \'0\'\nif __name__ == \'__main__\':\n    args = parse_args()\n    print(\'Called with args:\')\n    print(args)\n    if args.cfg_file is not None:\n        cfg_from_file(args.cfg_file)\n    if args.set_cfgs is not None:\n        cfg_from_list(args.set_cfgs)\n    os.environ[""CUDA_VISIBLE_DEVICES""] = str(cfg.GPU_ID)\n\n    print(\'Using config:\')\n    pprint.pprint(cfg)\n\n    if not args.randomize:\n        # fix the random seeds (numpy and caffe) for reproducibility\n        np.random.seed(cfg.RNG_SEED)\n\n    # imgdb = edict({\'path\':\'data/lstm_voc/pascal_augmented_train.tfrecords\',\'name\':\'pascal_augmentted\'})\n    output_network_name=args.network_name.split(\'_\')[-1]\n    imgdb = edict({\'path\':\'./data/train_4_6.tfrecords\',\'name\':\'lstm_\'+output_network_name,\n                   \'val_path\':\'./data/val.tfrecords\' })\n\n    output_dir = get_output_dir(imgdb, None)\n    log_dir = get_log_dir(imgdb)\n    print((\'Output will be saved to `{:s}`\'.format(output_dir)))\n    print((\'Logs will be saved to `{:s}`\'.format(log_dir)))\n\n    device_name = \'/gpu:{:d}\'.format(args.gpu_id)\n    print(device_name)\n\n    network = get_network(args.network_name)\n    print((\'Use network `{:s}` in training\'.format(args.network_name)))\n\n    train_net(network, imgdb,\n              pre_train=args.pre_train,\n              output_dir=output_dir,\n              log_dir=log_dir,\n              max_iters=args.max_iters,\n              restore=bool(int(args.restore)))\n'"
lib/lstm/__init__.py,0,b'# --------------------------------------------------------\n# Fast R-CNN\n# Copyright (c) 2015 Microsoft\n# Licensed under The MIT License [see LICENSE for details]\n# Written by Ross Girshick\n# --------------------------------------------------------\n\nfrom . import config\nfrom . import train\n'
lib/lstm/config.py,0,"b'import os\nimport os.path as osp\nimport numpy as np\nfrom time import strftime, localtime\nfrom easydict import EasyDict as edict\n\n__C = edict()\n# Consumers can get config by:\n#   from fast_rcnn_config import cfg\ncfg = __C\n\n# Default GPU device id\n__C.GPU_ID = 1\n__C.GPU_USAGE = 0.9\n__C.OFFSET_TIME_STEP = -1\n# region proposal network (RPN) or not\n__C.POOL_SCALE = 4\n__C.IMG_SHAPE = [32,100]\n__C.IMG_HEIGHT = 32\n__C.MAX_CHAR_LEN = 6\n__C.BLANK_TOKEN=0\n__C.CHARSET = \'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\'\n__C.NCLASSES = len(__C.CHARSET)+2\n__C.MIN_LEN = 4\n__C.MAX_LEN = 6\n__C.FONT = \'fonts/Ubuntu-M.ttf\'\n__C.NCHANNELS = 1\n__C.NUM_FEATURES= __C.IMG_HEIGHT *__C.NCHANNELS\n#__C.TIME_STEP = __C.IMG_SHAPE[0]//__C.POOL_SCALE\n\n__C.NET_NAME = \'lstm\'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.SOLVER = \'Adam\'\n#__C.TRAIN.SOLVER = \'Momentum\'\n# __C.TRAIN.SOLVER = \'RMS\'\n# learning rate\n__C.TRAIN.TXT = \'annotation_train.txt\'\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.01\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.NUM_EPOCHS = 2000\n\n__C.TRAIN.NUM_HID = 512\n__C.TRAIN.NUM_LAYERS = 2\n__C.TRAIN.BATCH_SIZE = 64\n\n# Iterations between snapshots\n__C.TRAIN.SNAPSHOT_ITERS = 5000\n__C.TRAIN.SNAPSHOT_PREFIX = \'lstm\'\n__C.TRAIN.SNAPSHOT_INFIX = \'\'\n\n__C.VAL = edict()\n__C.VAL.TXT = \'annotation_val.txt\'\n__C.VAL.VAL_STEP = 1000\n__C.VAL.NUM_EPOCHS = 1000\n__C.VAL.BATCH_SIZE = 128\n__C.VAL.PRINT_NUM = 5\n\n__C.RNG_SEED = 3\n\n__C.ROOT_DIR = osp.abspath(osp.join(osp.dirname(__file__), \'..\', \'..\'))\n__C.TEST = edict()\n__C.EXP_DIR = \'default\'\n__C.LOG_DIR = \'default\'\n\n__C.SPACE_INDEX = 0\n__C.SPACE_TOKEN = \'\'\ndef get_encode_decode_dict():\n    encode_maps = {}\n    decode_maps = {}\n    for i, char in enumerate(__C.CHARSET, 1):\n        encode_maps[char] = i\n        decode_maps[i] = char\n    encode_maps[__C.SPACE_TOKEN] = __C.SPACE_INDEX\n    decode_maps[__C.SPACE_INDEX] = __C.SPACE_TOKEN\n    return encode_maps,decode_maps\n\n\ndef get_output_dir(imdb, weights_filename):\n    outdir = osp.abspath(osp.join(__C.ROOT_DIR, \'output\', __C.EXP_DIR))\n    if weights_filename is not None:\n        outdir = osp.join(outdir, weights_filename)\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n    return outdir\n\ndef get_log_dir(imdb):\n    log_dir = osp.abspath(\\\n        osp.join(__C.ROOT_DIR, \'logs\', __C.LOG_DIR, imdb.name, strftime(""%Y-%m-%d-%H-%M-%S"", localtime())))\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    return log_dir\n\ndef _merge_a_into_b(a, b):\n    if type(a) is not edict:\n        return\n\n    for k, v in a.items():\n        # a must specify keys that are in b\n        if k not in b:\n            raise KeyError(\'{} is not a valid config key\'.format(k))\n\n        # the types must match, too\n        old_type = type(b[k])\n        if old_type is not type(v):\n            if isinstance(b[k], np.ndarray):\n                v = np.array(v, dtype=b[k].dtype)\n            else:\n                raise ValueError((\'Type mismatch ({} vs. {}) \'\n                                \'for config key: {}\').format(type(b[k]),\n                                                            type(v), k))\n\n        # recursively merge dicts\n        if type(v) is edict:\n            try:\n                _merge_a_into_b(a[k], b[k])\n            except:\n                print((\'Error under config key: {}\'.format(k)))\n                raise\n        else:\n            b[k] = v\n\ndef cfg_from_file(filename):\n    """"""Load a config file and merge it into the default options.""""""\n    import yaml\n    with open(filename, \'r\') as f:\n        yaml_cfg = edict(yaml.load(f))\n\n    _merge_a_into_b(yaml_cfg, __C)\n\ndef cfg_from_list(cfg_list):\n    """"""Set config keys via list (e.g., from command line).""""""\n    from ast import literal_eval\n    assert len(cfg_list) % 2 == 0\n    for k, v in zip(cfg_list[0::2], cfg_list[1::2]):\n        key_list = k.split(\'.\')\n        d = __C\n        for subkey in key_list[:-1]:\n            assert subkey in d\n            d = d[subkey]\n        subkey = key_list[-1]\n        assert subkey in d\n        try:\n            value = literal_eval(v)\n        except:\n            # handle the case when v is a string literal\n            value = v\n        assert type(value) == type(d[subkey]), \\\n            \'type {} does not match original type {}\'.format(\n            type(value), type(d[subkey]))\n        d[subkey] = value\n'"
lib/lstm/test.py,13,"b""import sys,math\nimport os,shutil\nimport collections\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport cv2\nfrom lib.lstm.utils.timer import Timer\nfrom ..lstm.config import cfg,get_encode_decode_dict\n\nclass SolverWrapper(object):\n    def __init__(self, sess, network, imgdb, output_dir, logdir, pretrained_model=None):\n        self.net = network\n        self.imgdb = imgdb\n        self.output_dir = output_dir\n        self.pretrained_model = pretrained_model\n        print('done')\n\n        # For checkpoint\n        self.saver = tf.train.Saver(max_to_keep=100)\n        self.writer = tf.summary.FileWriter(logdir=logdir,\n                                             graph=tf.get_default_graph(),\n                                             flush_secs=5)\n\n\n\n    def test_model(self,sess,testDir=None,restore = True):\n        logits = self.net.get_output('logits')\n        time_step_batch = self.net.get_output('time_step_len')\n        decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, time_step_batch, merge_repeated=True)\n        dense_decoded = tf.cast(tf.sparse_tensor_to_dense(decoded[0], default_value=0), tf.int32)\n\n        img_size = cfg.IMG_SHAPE\n        global_step = tf.Variable(0, trainable=False)\n        # intialize variables\n        local_vars_init_op = tf.local_variables_initializer()\n        global_vars_init_op = tf.global_variables_initializer()\n\n        combined_op = tf.group(local_vars_init_op, global_vars_init_op)\n        sess.run(combined_op)\n        # resuming a trainer\n        if restore:\n            try:\n                ckpt = tf.train.get_checkpoint_state(self.output_dir)\n                print('Restoring from {}...'.format(ckpt.model_checkpoint_path), end=' ')\n                self.saver.restore(sess, tf.train.latest_checkpoint(self.output_dir))\n                stem = os.path.splitext(os.path.basename(ckpt.model_checkpoint_path))[0]\n                restore_iter = int(stem.split('_')[-1])\n                sess.run(global_step.assign(restore_iter))\n                print('done')\n            except:\n                raise Exception('Check your pretrained {:s}'.format(ckpt.model_checkpoint_path))\n\n        timer = Timer()\n\n        total = correct = 0\n        for file in os.listdir(testDir):\n            timer.tic()\n            total+=1\n\n            if cfg.NCHANNELS == 1: img = cv2.imread(os.path.join(testDir,file),0)\n            else : img = cv2.imread(os.path.join(testDir,file),1)\n            print(file,end=' ')\n            #img = cv2.resize(img,tuple(img_size))\n            w = img.shape[1]\n            width = math.ceil(img.shape[1] / cfg.POOL_SCALE) * cfg.POOL_SCALE\n            img = cv2.copyMakeBorder(img, 0, 0, 0, width - w, cv2.BORDER_CONSTANT, value=0).astype(np.float32) / 255.\n\n            img = img.swapaxes(0,1)\n            img = np.reshape(img, [1,width,cfg.NUM_FEATURES])\n            #img = np.expand_dims(img,axis=0)\n            feed_dict = {\n                self.net.data: img,\n                self.net.time_step_len: [img.shape[1]//cfg.POOL_SCALE],\n                self.net.keep_prob: 1.0\n            }\n            res = sess.run(fetches=dense_decoded[0], feed_dict=feed_dict)\n            def decodeRes(nums,ignore= 0):\n                encode_maps,decode_maps = get_encode_decode_dict()\n                res = [decode_maps[i] for i in nums if i!=ignore]\n                return res\n            org = file.split('.')[0].split('_')[1]\n            res = ''.join(decodeRes(res))\n            if org==res:correct+=1\n            _diff_time = timer.toc(average=False)\n            print('cost time: {:.3f},\\n    res: {}'.format(_diff_time,res))\n            #visualize_segmentation_adaptive(np.array(output),cls_dict)\n        print('total acc:{}/{}={:.4f}'.format(correct,total,correct/total))\n\n\ndef test_net(network, imgdb, testDir, output_dir, log_dir, pretrained_model=None,restore=True):\n\n    config = tf.ConfigProto(allow_soft_placement=True)\n    config.gpu_options.allocator_type = 'BFC'\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.4\n    with tf.Session(config=config) as sess:\n        sw = SolverWrapper(sess, network, imgdb, output_dir, logdir= log_dir, pretrained_model=pretrained_model)\n        print('Solving...')\n        sw.test_model(sess, testDir=testDir, restore=restore)\n        print('done solving')\n\n"""
lib/lstm/train.py,22,"b'import numpy as np\nimport os,re\nimport tensorflow as tf\nfrom ..lstm.config import cfg\nfrom lib.lstm.utils.timer import Timer\nfrom lib.lstm.utils.training import accuracy_calculation\nfrom lib.lstm.utils.tf_records import read_tfrecord_and_decode_into_image_annotation_pair_tensors\nfrom lib.lstm.utils.gen import get_batch\n\nclass SolverWrapper(object):\n    def __init__(self, sess, network, imgdb, pre_train,output_dir, logdir):\n        """"""Initialize the SolverWrapper.""""""\n        self.net = network\n        self.imgdb = imgdb\n        self.pre_train=pre_train\n        self.output_dir = output_dir\n        print(\'done\')\n        self.saver = tf.train.Saver(max_to_keep=100)\n        self.writer = tf.summary.FileWriter(logdir=logdir,\n                                             graph=tf.get_default_graph(),\n                                             flush_secs=5)\n\n    def snapshot(self, sess, iter):\n        net = self.net\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n        infix = (\'_\' + cfg.TRAIN.SNAPSHOT_INFIX\n                 if cfg.TRAIN.SNAPSHOT_INFIX != \'\' else \'\')\n        \n        filename = (cfg.TRAIN.SNAPSHOT_PREFIX + \'_ctc\' + infix +\n                        \'_iter_{:d}\'.format(iter + 1) + \'.ckpt\')\n        \n        #filename = (cfg.TRAIN.SNAPSHOT_PREFIX + infix +\n         #           \'_iter_{:d}\'.format(iter+1) + \'.ckpt\')\n        filename = os.path.join(self.output_dir, filename)\n        self.saver.save(sess, filename)\n        print(\'Wrote snapshot to: {:s}\'.format(filename))\n\n    def get_data(self,path,batch_size,num_epochs):\n        filename_queue = tf.train.string_input_producer([path], num_epochs=num_epochs)\n        image,label,label_len,time_step= read_tfrecord_and_decode_into_image_annotation_pair_tensors(filename_queue)\n        image_batch, label_batch, label_len_batch,time_step_batch = tf.train.shuffle_batch([image,label,label_len,time_step],\n                                                                                           batch_size=batch_size,\n                                                                                           capacity=9600,\n                                                                                           num_threads=4,\n                                                                                           min_after_dequeue=6400)\n        return image_batch, label_batch, label_len_batch,time_step_batch\n\n    def restoreLabel(self,label_vec,label_len):\n        labels = []\n        for l_len in label_len:\n            labels.append(label_vec[:l_len])\n            label_vec = label_vec[l_len:]\n        return labels\n\n    def mergeLabel(self,labels,ignore = 0):\n        label_lst = []\n        for l in labels:\n            while l[-1] == ignore: l = l[:-1]\n            label_lst.extend(l)\n        return np.array(label_lst)\n\n    def train_model(self, sess, max_iters, restore=False):\n        train_gen = get_batch(num_workers=12,batch_size=cfg.TRAIN.BATCH_SIZE,vis=False)\n        val_gen = get_batch(num_workers=1,batch_size=cfg.VAL.BATCH_SIZE,vis=False)\n\n        loss, dense_decoded = self.net.build_loss()\n\n        tf.summary.scalar(\'loss\', loss)\n        summary_op = tf.summary.merge_all()\n\n        # optimizer\n        lr = tf.Variable(cfg.TRAIN.LEARNING_RATE, trainable=False)\n        if cfg.TRAIN.SOLVER == \'Adam\': opt = tf.train.AdamOptimizer(lr)\n        elif cfg.TRAIN.SOLVER == \'RMS\': opt = tf.train.RMSPropOptimizer(lr)\n        else: opt = tf.train.MomentumOptimizer(lr, cfg.TRAIN.MOMENTUM)\n\n        global_step = tf.Variable(0, trainable=False)\n        with_clip = True\n        if with_clip:\n            tvars = tf.trainable_variables()\n            grads, norm = tf.clip_by_global_norm(tf.gradients(loss, tvars), 10.0)\n            train_op = opt.apply_gradients(list(zip(grads, tvars)), global_step=global_step)\n        else:\n            train_op = opt.minimize(loss, global_step=global_step)\n\n        # intialize variables\n        local_vars_init_op = tf.local_variables_initializer()\n        global_vars_init_op = tf.global_variables_initializer()\n\n        combined_op = tf.group(local_vars_init_op, global_vars_init_op)\n        sess.run(combined_op)\n        restore_iter = 1\n\n        # resuming a trainer\n        if restore:\n            try:\n                ckpt = tf.train.get_checkpoint_state(self.output_dir)\n                print(\'Restoring from {}...\'.format(ckpt.model_checkpoint_path), end=\' \')\n                self.saver.restore(sess, tf.train.latest_checkpoint(self.output_dir))\n                stem = os.path.splitext(os.path.basename(ckpt.model_checkpoint_path))[0]\n                restore_iter = int(stem.split(\'_\')[-1])\n                sess.run(global_step.assign(restore_iter))\n                print(\'done\')\n            except:\n                raise Exception(\'Check your pretrained {:s}\'.format(ckpt.model_checkpoint_path))\n\n        timer = Timer()\n        loss_min = 0.015\n        first_val = True\n        for iter in range(restore_iter, max_iters):\n            timer.tic()\n            # learning rate\n            if iter != 0 and iter % cfg.TRAIN.STEPSIZE == 0:\n                sess.run(tf.assign(lr, lr.eval() * cfg.TRAIN.GAMMA))\n\n            # get one batch\n            img_Batch,label_Batch, label_len_Batch,time_step_Batch = next(train_gen)\n            img_Batch = np.array(img_Batch)\n            # Subtract the mean pixel value from each pixel\n            feed_dict = {\n                self.net.data:          np.array(img_Batch),\n                self.net.labels:        np.array(label_Batch),\n                self.net.time_step_len: np.array(time_step_Batch),\n                self.net.labels_len:    np.array(label_len_Batch),\n                self.net.keep_prob:     0.5\n            }\n\n            fetch_list = [loss,summary_op,train_op]\n            ctc_loss,summary_str, _ =  sess.run(fetches=fetch_list, feed_dict=feed_dict)\n\n            self.writer.add_summary(summary=summary_str, global_step=global_step.eval())\n            _diff_time = timer.toc(average=False)\n\n            if (iter) % (cfg.TRAIN.DISPLAY) == 0:\n                print(\'iter: %d / %d, total loss: %.7f, lr: %.7f\'%\\\n                        (iter, max_iters, ctc_loss ,lr.eval()),end=\' \')\n                print(\'speed: {:.3f}s / iter\'.format(_diff_time))\n            if (iter+1) % cfg.TRAIN.SNAPSHOT_ITERS == 0 or ctc_loss<loss_min:\n                if(ctc_loss<loss_min):\n                    print(\'loss: \',ctc_loss,end=\' \')\n                    self.snapshot(sess, 1)\n                    loss_min = ctc_loss\n                else: self.snapshot(sess, iter)\n            if (iter+1) % cfg.VAL.VAL_STEP == 0 or loss_min==ctc_loss:\n                if first_val:\n                    val_img_Batch,val_label_Batch, val_label_len_Batch,val_time_step_Batch = next(val_gen)\n                    org = self.restoreLabel(val_label_Batch,val_label_len_Batch)\n                    first_val=False\n\n                feed_dict = {\n                    self.net.data :          np.array(val_img_Batch),\n                    self.net.labels :         np.array(val_label_Batch),\n                    self.net.time_step_len : np.array(val_time_step_Batch),\n                    self.net.labels_len :     np.array(val_label_len_Batch),\n                    self.net.keep_prob:      1.0\n                }\n\n                # fetch_list = [dense_decoded]\n                res =  sess.run(fetches=dense_decoded, feed_dict=feed_dict)\n                acc = accuracy_calculation(org,res,ignore_value=0)\n                print(\'accuracy: {:.5f}\'.format(acc))\n\n\ndef train_net(network, imgdb, pre_train,output_dir, log_dir, max_iters=40000, restore=False):\n    config = tf.ConfigProto(allow_soft_placement=True)\n    config.gpu_options.per_process_gpu_memory_fraction = cfg.GPU_USAGE\n    config.gpu_options.allocator_type = \'BFC\'\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sw = SolverWrapper(sess, network, imgdb, pre_train,output_dir, logdir= log_dir)\n        print(\'Solving...\')\n        sw.train_model(sess, max_iters, restore=restore)\n        print(\'done solving\')\n'"
lib/networks/LSTM_test.py,3,"b""import tensorflow as tf\nfrom .network import Network\nfrom ..lstm.config import cfg\n\n\nclass LSTM_test(Network):\n    def __init__(self, trainable=True):\n        self.inputs = []\n\n        self.data = tf.placeholder(tf.float32, shape=[None, None, cfg.NUM_FEATURES], name='data')\n        self.time_step_len = tf.placeholder(tf.int32,[None], name='time_step_len')\n\n        self.keep_prob = tf.placeholder(tf.float32)\n        self.layers = dict({'data': self.data, 'time_step_len':self.time_step_len})\n        self.trainable = trainable\n        self.setup()\n\n    def setup(self):\n        (self.feed('data')\n         .conv_single(3, 3, 64 ,1, 1, name='conv1',c_i=cfg.NCHANNELS)\n         .max_pool(2, 2, 2, 2, padding='VALID', name='pool1')\n         .conv_single(3, 3, 128 ,1, 1, name='conv2')\n         .max_pool(2, 2, 2, 2, padding='VALID', name='pool2')\n         .conv_single(3, 3, 256 ,1, 1, name='conv3_1')\n         .conv_single(3, 3, 256 ,1, 1, name='conv3_2')\n         .max_pool(1, 2, 1, 2, padding='VALID', name='pool2')\n         .conv_single(3, 3, 512 ,1, 1, name='conv4_1', bn=True)\n         .conv_single(3, 3, 512 ,1, 1, name='conv4_2', bn=True)\n         .max_pool(1, 2, 1, 2, padding='VALID', name='pool3')\n         .conv_single(2, 2, 512 ,1, 1, padding = 'VALID', name='conv5', relu=False)\n         #.dropout(keep_prob = self.keep_prob, name = 'dropout_layer')\n         .reshape_squeeze_layer(d = 512 , name='reshaped_layer'))\n        (self.feed('reshaped_layer','time_step_len')\n         .bi_lstm(cfg.TRAIN.NUM_HID,cfg.TRAIN.NUM_LAYERS,name='logits'))\n\n"""
lib/networks/LSTM_train.py,5,"b""import tensorflow as tf\nfrom .network import Network\nfrom ..lstm.config import cfg\n\n\nclass LSTM_train(Network):\n    def __init__(self, trainable=True):\n        self.inputs = []\n\n        self.data = tf.placeholder(tf.float32, shape=[None, None, cfg.NUM_FEATURES ], name='data') #N*t_s*features*channels\n        self.labels = tf.placeholder(tf.int32,[None],name='labels')\n        self.time_step_len = tf.placeholder(tf.int32,[None], name='time_step_len')\n        self.labels_len = tf.placeholder(tf.int32,[None],name='labels_len')\n\n        self.keep_prob = tf.placeholder(tf.float32)\n        self.layers = dict({'data': self.data,'labels':self.labels,\n                            'time_step_len':self.time_step_len,\n                            'labels_len':self.labels_len})\n        self.trainable = trainable\n        self.setup()\n\n    def setup(self):\n        (self.feed('data')\n         .conv_single(3, 3, 64 ,1, 1, name='conv1',c_i=cfg.NCHANNELS)\n         .max_pool(2, 2, 2, 2, padding='VALID', name='pool1')\n         .conv_single(3, 3, 128 ,1, 1, name='conv2')\n         .max_pool(2, 2, 2, 2, padding='VALID', name='pool2')\n         .conv_single(3, 3, 256 ,1, 1, name='conv3_1')\n         .conv_single(3, 3, 256 ,1, 1, name='conv3_2')\n         .max_pool(1, 2, 1, 2, padding='VALID', name='pool2')\n         .conv_single(3, 3, 512 ,1, 1, name='conv4_1', bn=True)\n         .conv_single(3, 3, 512 ,1, 1, name='conv4_2', bn=True)\n         .max_pool(1, 2, 1, 2, padding='VALID', name='pool3')\n         .conv_single(2, 2, 512 ,1, 1, padding = 'VALID', name='conv5', relu=False)\n         #.dropout(keep_prob = self.keep_prob, name = 'dropout_layer')\n         .reshape_squeeze_layer(d = 512 , name='reshaped_layer'))\n        (self.feed('reshaped_layer','time_step_len')\n         .bi_lstm(cfg.TRAIN.NUM_HID,cfg.TRAIN.NUM_LAYERS,name='logits'))\n         # .lstm(cfg.TRAIN.NUM_HID,cfg.TRAIN.NUM_LAYERS,name='logits',img_shape=[-1,cfg.IMG_SHAPE[0]//cfg.POOL_SCALE,cfg.NUM_FEATURES//cfg.POOL_SCALE]))\n         #.bi_lstm(cfg.TRAIN.NUM_HID,cfg.TRAIN.NUM_LAYERS,name='logits',img_shape=[-1,cfg.IMG_SHAPE[0]//cfg.POOL_SCALE,cfg.NUM_FEATURES//cfg.POOL_SCALE]))\n"""
lib/networks/__init__.py,0,b'from . import factory\n'
lib/networks/factory.py,0,"b'# --------------------------------------------------------\n# SubCNN_TF\n# Copyright (c) 2016 CVGL Stanford\n# Licensed under The MIT License [see LICENSE for details]\n# Written by Yu Xiang\n# --------------------------------------------------------\n\n""""""Factory method for easily getting imdbs by name.""""""\n\n__sets = {}\nfrom .LSTM_train import LSTM_train\nfrom .LSTM_test import LSTM_test\ndef get_network(name):\n    """"""Get a network by name.""""""\n    if name.split(\'_\')[0] == \'LSTM\':\n        if name.split(\'_\')[1] == \'train\':\n            return LSTM_train()\n        elif name.split(\'_\')[1] == \'test\':\n            return LSTM_test()\n        else:\n            raise KeyError(\'Unknown dataset: {}\'.format(name))\n\ndef list_networks():\n    """"""List all registered imdbs.""""""\n    return list(__sets.keys())\n\n'"
lib/networks/network.py,176,"b'import numpy as np\nimport tensorflow as tf\n\nfrom lib.lstm.config import cfg\nfrom lib.lstm.utils.training import *\nimport warpctc_tensorflow\n\nDEFAULT_PADDING = \'SAME\'\n\ndef incluude_original(dec):\n    """""" Meta decorator, which make the original function callable (via f._original() )""""""\n    def meta_decorator(f):\n        decorated = dec(f)\n        decorated._original = f\n        return decorated\n    return meta_decorator\n\n#@include_original\ndef layer(op):\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault(\'name\', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.inputs)==0:\n            raise RuntimeError(\'No input variables found for layer %s.\'%name)\n        elif len(self.inputs)==1:\n            layer_input = self.inputs[0]\n        else:\n            layer_input = list(self.inputs)\n        # Perform the operation and get the output.\n        layer_output = op(self, layer_input, *args, **kwargs)\n        # Add to layer LUT.\n        self.layers[name] = layer_output\n        # This output is now the input for the next layer.\n        self.feed(layer_output)\n        # Return self for chained calls.\n        return self\n    return layer_decorated\n\nclass Network(object):\n    def __init__(self, inputs, trainable=True):\n        self.inputs = []\n        self.layers = dict(inputs)\n        self.trainable = trainable\n        self.setup()\n\n    def setup(self):\n        raise NotImplementedError(\'Must be subclassed.\')\n\n    def load(self, data_path, session, ignore_missing=False):\n        data_dict = np.load(data_path,encoding=\'latin1\').item()\n        for key in data_dict:\n            with tf.variable_scope(key, reuse=True):\n                for subkey in data_dict[key]:\n                    try:\n                        var = tf.get_variable(subkey)\n                        session.run(var.assign(data_dict[key][subkey]))\n                        print(""assign pretrain model ""+subkey+ "" to ""+key)\n                    except ValueError:\n                        print(""ignore ""+key)\n                        if not ignore_missing:\n\n                            raise\n\n    def feed(self, *args):\n        assert len(args)!=0\n        self.inputs = []\n        for layer in args:\n            if isinstance(layer, str):\n                try:\n                    layer = self.layers[layer]\n                    print(layer)\n                except KeyError:\n                    print(list(self.layers.keys()))\n                    raise KeyError(\'Unknown layer name fed: %s\'%layer)\n            self.inputs.append(layer)\n        return self\n\n    def get_output(self, layer):\n        try:\n            layer = self.layers[layer]\n        except KeyError:\n            print(list(self.layers.keys()))\n            raise KeyError(\'Unknown layer name fed: %s\'%layer)\n        return layer\n\n    def get_unique_name(self, prefix):\n        id = sum(t.startswith(prefix) for t,_ in list(self.layers.items()))+1\n        return \'%s_%d\'%(prefix, id)\n\n    def make_var(self, name, shape, initializer=None, trainable=True, regularizer=None):\n        return tf.get_variable(name, shape, initializer=initializer, trainable=trainable, regularizer=regularizer)\n\n    def validate_padding(self, padding):\n        assert padding in (\'SAME\', \'VALID\')\n\n    @layer\n    def bi_lstm(self, input, num_hids, num_layers, name,img_shape = None ,trainable=True):\n        img,img_len = input[0],input[1]\n        #img = tf.squeeze(img,axis=3)\n        if img_shape:img =tf.reshape(img,shape = img_shape )\n        with tf.variable_scope(name) as scope:\n            #stack = tf.contrib.rnn.MultiRNNCell([cell,cell1] , state_is_tuple=True)\n            lstm_fw_cell = tf.contrib.rnn.LSTMCell(num_hids//2,state_is_tuple=True)\n            lstm_bw_cell = tf.contrib.rnn.LSTMCell(num_hids//2,state_is_tuple=True)\n\n            output,_ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell,lstm_bw_cell,img,img_len,dtype=tf.float32)\n            # output_bw_reverse = tf.reverse_sequence(output[1],img_len,seq_axis=1)\n            output = tf.concat(output,axis=2)\n\n            #stack_cell = tf.contrib.rnn.MultiRNNCell(\n            #    [tf.contrib.rnn.LSTMCell(num_hids, state_is_tuple=True) for _ in range(num_layers)],\n            #    state_is_tuple=True)\n            #lstm_out,last_state = tf.nn.dynamic_rnn(stack_cell,output,img_len,dtype=tf.float32)\n            lstm_out = output\n            shape = tf.shape(img)\n            batch_size, time_step = shape[0],shape[1]\n            lstm_out = tf.reshape(lstm_out,[-1,num_hids])\n            init_weights = tf.contrib.layers.variance_scaling_initializer(factor=0.01, mode=\'FAN_AVG\', uniform=False)\n            # init_weights = tf.contrib.layers.xavier_initializer()\n            # init_weights = tf.truncated_normal_initializer(stddev=0.1)\n            init_biases = tf.constant_initializer(0.0)\n            W = self.make_var(\'weights\', [num_hids, cfg.NCLASSES], init_weights, trainable, \\\n                              regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            b = self.make_var(\'biases\', [cfg.NCLASSES], init_biases, trainable)\n            logits = tf.matmul(lstm_out,W)+b\n            logits = tf.reshape(logits,[batch_size,-1,cfg.NCLASSES])\n            logits = tf.transpose(logits,(1,0,2))\n            return logits\n    @layer\n    def lstm(self, input, num_hids, num_layers, name,img_shape = None ,trainable=True):\n        img,img_len = input[0],input[1]\n        if img_shape:img =tf.reshape(img,shape = img_shape )\n        with tf.variable_scope(name) as scope:\n            stack_cell = tf.contrib.rnn.MultiRNNCell(\n                [tf.contrib.rnn.LSTMCell(num_hids, state_is_tuple=True) for _ in range(num_layers)],\n                state_is_tuple=True)\n            lstm_out,last_state = tf.nn.dynamic_rnn(stack_cell,img,img_len,dtype=tf.float32)\n            shape = tf.shape(img)\n            batch_size, time_step = shape[0],shape[1]\n            lstm_out = tf.reshape(lstm_out,[-1,num_hids])\n            # init_weights = tf.contrib.layers.variance_scaling_initializer(factor=0.001, mode=\'FAN_AVG\', uniform=False)\n            # init_weights = tf.contrib.layers.xavier_initializer()\n            init_weights = tf.truncated_normal_initializer(stddev=0.1)\n            init_biases = tf.constant_initializer(0.0)\n            W = self.make_var(\'weights\', [num_hids, cfg.NCLASSES], init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            b = self.make_var(\'biases\', [cfg.NCLASSES], init_biases, trainable)\n            logits = tf.matmul(lstm_out,W)+b\n            logits = tf.reshape(logits,[batch_size,-1,cfg.NCLASSES])\n            logits = tf.transpose(logits,(1,0,2))\n            return logits\n\n    @layer\n    def concat(self, input, axis, name):\n        with tf.variable_scope(name) as scope:\n            concat = tf.concat(values=input,axis=axis)\n        return concat\n\n    @layer\n    def conv_single(self, input, k_h, k_w, c_o, s_h, s_w, name, c_i=None, bn=False, biased=True,relu=True, padding=DEFAULT_PADDING, trainable=True):\n        """""" contribution by miraclebiu, and biased option""""""\n        self.validate_padding(padding)\n        if not c_i: c_i = input.get_shape()[-1]\n        if c_i==1: input = tf.expand_dims(input=input,axis=3)\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1,s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            init_weights = tf.contrib.layers.xavier_initializer()\n            init_biases = tf.constant_initializer(0.0)\n            kernel = self.make_var(\'weights\', [k_h, k_w, c_i, c_o], init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            if biased:\n                biases = self.make_var(\'biases\', [c_o], init_biases, trainable)\n                conv = convolve(input, kernel)\n                bias = tf.nn.bias_add(conv, biases)\n                if bn:\n                    bn_layer = tf.contrib.layers.batch_norm(bias, scale=True,\n                                                            center=True, is_training=True, scope=name)\n                else:bn_layer = bias\n                if relu:\n                    return tf.nn.relu(bn_layer)\n                else: return bn_layer\n            else:\n                conv = convolve(input, kernel)\n                if bn:\n                    bn_layer = tf.contrib.layers.batch_norm(conv, scale=True,\n                                                            center=True, is_training=True, scope=name)\n                else:bn_layer = conv\n                if relu:\n                    return tf.nn.relu(bn_layer)\n                return bn_layer\n\n    @layer\n    def conv(self, input, k_h, k_w, c_o, s_h, s_w, name, c_i=None, biased=True,relu=True, padding=DEFAULT_PADDING, trainable=True):\n        """""" contribution by miraclebiu, and biased option""""""\n        self.validate_padding(padding)\n        if not c_i: c_i = input.get_shape()[-1]\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            init_weights = tf.contrib.layers.xavier_initializer()\n            init_biases = tf.constant_initializer(0.0)\n            kernel = self.make_var(\'weights\', [k_h, k_w, c_i, c_o], init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            if biased:\n                biases = self.make_var(\'biases\', [c_o], init_biases, trainable)\n                conv = convolve(input, kernel)\n                if relu:\n                    bias = tf.nn.bias_add(conv, biases)\n\n                    return tf.nn.relu(bias)\n                return tf.nn.bias_add(conv, biases)\n            else:\n                conv = convolve(input, kernel)\n                if relu:\n                    return tf.nn.relu(conv)\n                return conv\n\n    @layer\n    def conv_zero(self, input, k_h, k_w, c_o, s_h, s_w, name, biased=True, relu=True, padding=DEFAULT_PADDING,\n             trainable=True):\n        """""" contribution by miraclebiu, and biased option""""""\n        self.validate_padding(padding)\n        c_i = input.get_shape()[-1]\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            init_weights = tf.constant_initializer(0.0)\n            init_biases = tf.constant_initializer(0.0)\n            kernel = self.make_var(\'weights\', [k_h, k_w, c_i, c_o], init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            if biased:\n                biases = self.make_var(\'biases\', [c_o], init_biases, trainable)\n                conv = convolve(input, kernel)\n                if relu:\n                    bias = tf.nn.bias_add(conv, biases)\n\n                    return tf.nn.relu(bias)\n                return tf.nn.bias_add(conv, biases)\n            else:\n                conv = convolve(input, kernel)\n                if relu:\n                    return tf.nn.relu(conv)\n                return conv\n\n    @layer\n    def conv_norm(self, input, k_h, k_w, c_o, s_h, s_w, name, biased=True,relu=True, padding=DEFAULT_PADDING, trainable=True):\n        """""" contribution by miraclebiu, and biased option""""""\n        self.validate_padding(padding)\n        c_i = input.get_shape()[-1]\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            init_weights = tf.contrib.layers.variance_scaling_initializer(factor=0.001, mode=\'FAN_AVG\', uniform=False)\n            # init_weights = tf.contrib.layers.xavier_initializer()\n            init_biases = tf.constant_initializer(0.0)\n            kernel = self.make_var(\'weights\', [k_h, k_w, c_i, c_o], init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            if biased:\n                biases = self.make_var(\'biases\', [c_o], init_biases, trainable)\n                conv = convolve(input, kernel)\n                if relu:\n                    bias = tf.nn.bias_add(conv, biases)\n                    temp_layer = tf.contrib.layers.batch_norm(bias, scale=True, center=True, is_training=True,\n                                                      scope=name)\n                    return tf.nn.relu(temp_layer)\n                return tf.nn.bias_add(conv, biases)\n            else:\n                conv = convolve(input, kernel)\n                if relu:\n                    return tf.nn.crelu(conv)\n                return conv\n\n    @layer\n    def conv_final(self, input, k_h, k_w, c_o, s_h, s_w, name, biased=True, relu=True, padding=DEFAULT_PADDING,\n                  trainable=True):\n        """""" contribution by miraclebiu, and biased option""""""\n        self.validate_padding(padding)\n        c_i = 128\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            init_weights = tf.contrib.layers.variance_scaling_initializer(factor=0.001, mode=\'FAN_AVG\', uniform=False)\n            # init_weights = tf.contrib.layers.xavier_initializer()\n            init_biases = tf.constant_initializer(0.0)\n            kernel = self.make_var(\'weights\', [k_h, k_w, c_i, c_o], init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            if biased:\n                biases = self.make_var(\'biases\', [c_o], init_biases, trainable)\n                conv = convolve(input, kernel)\n                if relu:\n                    bias = tf.nn.bias_add(conv, biases)\n                    temp_layer = tf.contrib.layers.batch_norm(bias, scale=True, center=True, is_training=True,\n                                                              scope=name)\n                    return tf.nn.relu(temp_layer)\n                return tf.nn.bias_add(conv, biases)\n            else:\n                conv = convolve(input, kernel)\n                if relu:\n                    return tf.nn.crelu(conv)\n                return conv\n\n    @layer\n    def upconv(self, input, shape, c_o, ksize=4, stride = 2, name = \'upconv\', biased=False, relu=True, padding=DEFAULT_PADDING,\n             trainable=True):\n        """""" up-conv""""""\n        self.validate_padding(padding)\n\n        c_in = input.get_shape()[3].value\n        in_shape = tf.shape(input)\n        if shape is None:\n            h = ((in_shape[1] ) * stride)\n            w = ((in_shape[2] ) * stride)\n            new_shape = [in_shape[0], h, w, c_o]\n        else:\n            new_shape = [in_shape[0], shape[1], shape[2], c_o]\n        output_shape = tf.stack(new_shape)\n\n        filter_shape = [ksize, ksize, c_o, c_in]\n\n        with tf.variable_scope(name) as scope:\n            # init_weights = tf.contrib.layers.xavier_initializer()\n            init_weights = tf.contrib.layers.variance_scaling_initializer(factor=0.001, mode=\'FAN_AVG\', uniform=False)\n            filters = self.make_var(\'weights\', filter_shape, init_weights, trainable, \\\n                                   regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            deconv = tf.nn.conv2d_transpose(input, filters, output_shape,\n                                            strides=[1, stride, stride, 1], padding=DEFAULT_PADDING, name=scope.name)\n            # coz de-conv losses shape info, use reshape to re-gain shape\n            deconv = tf.reshape(deconv, new_shape)\n\n            if biased:\n                init_biases = tf.constant_initializer(0.0)\n                biases = self.make_var(\'biases\', [c_o], init_biases, trainable)\n                if relu:\n                    bias = tf.nn.bias_add(deconv, biases)\n                    return tf.nn.relu(bias)\n                return tf.nn.bias_add(deconv, biases)\n            else:\n                if relu:\n                    return tf.nn.relu(deconv)\n                return deconv\n\n    @layer\n    def relu(self, input, name):\n        return tf.nn.relu(input, name=name)\n\n    @layer\n    def max_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.max_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def avg_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.avg_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def reshape_squeeze_layer(self, input, d, name):\n        #N,H,W,C-> N,H*W,C\n        input_shape = tf.shape(input)\n        return tf.reshape(input, \\\n                          [input_shape[0], \\\n                           input_shape[1]*input_shape[2], \\\n                           int(d)])\n\n    @layer\n    def reshape_layer(self, input, d, name):\n        input_shape = tf.shape(input)\n        if name == \'rpn_cls_prob_reshape\':\n            #\n            # transpose: (1, AxH, W, 2) -> (1, 2, AxH, W)\n            # reshape: (1, 2xA, H, W)\n            # transpose: -> (1, H, W, 2xA)\n             return tf.transpose(tf.reshape(tf.transpose(input,[0,3,1,2]),\n                                            [   input_shape[0],\n                                                int(d),\n                                                tf.cast(tf.cast(input_shape[1],tf.float32)/tf.cast(d,tf.float32)*tf.cast(input_shape[3],tf.float32),tf.int32),\n                                                input_shape[2]\n                                            ]),\n                                 [0,2,3,1],name=name)\n        else:\n             return tf.transpose(tf.reshape(tf.transpose(input,[0,3,1,2]),\n                                        [   input_shape[0],\n                                            int(d),\n                                            tf.cast(tf.cast(input_shape[1],tf.float32)*(tf.cast(input_shape[3],tf.float32)/tf.cast(d,tf.float32)),tf.int32),\n                                            input_shape[2]\n                                        ]),\n                                 [0,2,3,1],name=name)\n\n    @layer\n    def spatial_reshape_layer(self, input, d, name):\n        input_shape = tf.shape(input)\n        # transpose: (1, H, W, A x d) -> (1, H, WxA, d)\n        return tf.reshape(input,\\\n                               [input_shape[0],\\\n                                input_shape[1], \\\n                                -1,\\\n                                int(d)])\n\n\n    @layer\n    def lrn(self, input, radius, alpha, beta, name, bias=1.0):\n        return tf.nn.local_response_normalization(input,\n                                                  depth_radius=radius,\n                                                  alpha=alpha,\n                                                  beta=beta,\n                                                  bias=bias,\n                                                  name=name)\n\n\n    @layer\n    def fc(self, input, num_out, name, relu=True, trainable=True):\n        with tf.variable_scope(name) as scope:\n            # only use the first input\n            if isinstance(input, tuple):\n                input = input[0]\n\n            input_shape = input.get_shape()\n            if input_shape.ndims == 4:\n                dim = 1\n                for d in input_shape[1:].as_list():\n                    dim *= d\n                feed_in = tf.reshape(tf.transpose(input,[0,3,1,2]), [-1, dim])\n            else:\n                feed_in, dim = (input, int(input_shape[-1]))\n\n            if name == \'bbox_pred\':\n                init_weights = tf.truncated_normal_initializer(0.0, stddev=0.001)\n                init_biases = tf.constant_initializer(0.0)\n            else:\n                init_weights = tf.truncated_normal_initializer(0.0, stddev=0.01)\n                init_biases = tf.constant_initializer(0.0)\n\n            weights = self.make_var(\'weights\', [dim, num_out], init_weights, trainable, \\\n                                    regularizer=self.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY))\n            biases = self.make_var(\'biases\', [num_out], init_biases, trainable)\n\n            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n            fc = op(feed_in, weights, biases, name=scope.name)\n            return fc\n\n    @layer\n    def softmax(self, input, name):\n        input_shape = tf.shape(input)\n        if name == \'rpn_cls_prob\':\n            return tf.reshape(tf.nn.softmax(tf.reshape(input,[-1,input_shape[3]])),[-1,input_shape[1],input_shape[2],input_shape[3]],name=name)\n        else:\n            return tf.nn.softmax(input,name=name)\n\n    @layer\n    def spatial_softmax(self, input, name):\n        input_shape = tf.shape(input)\n        # d = input.get_shape()[-1]\n        return tf.reshape(tf.nn.softmax(tf.reshape(input, [-1, input_shape[3]])),\n                          [-1, input_shape[1], input_shape[2], input_shape[3]], name=name)\n\n    @layer\n    def add(self,input,name):\n        """"""contribution by miraclebiu""""""\n        return tf.add(input[0],input[1], name=name)\n\n    @layer\n    def batch_normalization(self,input,name,relu=True, is_training=False):\n        """"""contribution by miraclebiu""""""\n        if relu:\n            temp_layer=tf.contrib.layers.batch_norm(input,scale=True,center=True,is_training=is_training,scope=name)\n            return tf.nn.relu(temp_layer)\n        else:\n            return tf.contrib.layers.batch_norm(input,scale=True,center=True,is_training=is_training,scope=name)\n\n    @layer\n    def negation(self, input, name):\n        """""" simply multiplies -1 to the tensor""""""\n        return tf.multiply(input, -1.0, name=name)\n\n    @layer\n    def bn_scale_combo(self, input, c_in, name, relu=True):\n        """""" PVA net BN -> Scale -> Relu""""""\n        with tf.variable_scope(name) as scope:\n            bn = self.batch_normalization._original(self, input, name=\'bn\', relu=False, is_training=False)\n            # alpha = tf.get_variable(\'bn_scale/alpha\', shape=[c_in, ], dtype=tf.float32,\n            #                     initializer=tf.constant_initializer(1.0), trainable=True,\n            #                     regularizer=self.l2_regularizer(0.00001))\n            # beta = tf.get_variable(\'bn_scale/beta\', shape=[c_in, ], dtype=tf.float32,\n            #                    initializer=tf.constant_initializer(0.0), trainable=True,\n            #                    regularizer=self.l2_regularizer(0.00001))\n            # bn = tf.add(tf.mul(bn, alpha), beta)\n            if relu:\n                bn = tf.nn.relu(bn, name=\'relu\')\n            return bn\n\n    @layer\n    def pva_negation_block(self, input, k_h, k_w, c_o, s_h, s_w, name, biased=True, padding=DEFAULT_PADDING, trainable=True,\n                           scale = True, negation = True):\n        """""" for PVA net, Conv -> BN -> Neg -> Concat -> Scale -> Relu""""""\n        with tf.variable_scope(name) as scope:\n            conv = self.conv._original(self, input, k_h, k_w, c_o, s_h, s_w, biased=biased, relu=False, name=\'conv\', padding=padding, trainable=trainable)\n            conv = self.batch_normalization._original(self, conv, name=\'bn\', relu=False, is_training=False)\n            c_in = c_o\n            if negation:\n                conv_neg = self.negation._original(self, conv, name=\'neg\')\n                conv = tf.concat(axis=3, values=[conv, conv_neg], name=\'concat\')\n                c_in += c_in\n            if scale:\n                # y = \\alpha * x + \\beta\n                alpha = tf.get_variable(\'scale/alpha\', shape=[c_in,], dtype=tf.float32,\n                                        initializer=tf.constant_initializer(1.0), trainable=True, regularizer=self.l2_regularizer(0.00001))\n                beta = tf.get_variable(\'scale/beta\', shape=[c_in, ], dtype=tf.float32,\n                                        initializer=tf.constant_initializer(0.0), trainable=True, regularizer=self.l2_regularizer(0.00001))\n                # conv = conv * alpha + beta\n                conv = tf.add(tf.multiply(conv, alpha), beta)\n            return tf.nn.relu(conv, name=\'relu\')\n\n    @layer\n    def pva_negation_block_v2(self, input, k_h, k_w, c_o, s_h, s_w, c_in, name, biased=True, padding=DEFAULT_PADDING, trainable=True,\n                           scale = True, negation = True):\n        """""" for PVA net, BN -> [Neg -> Concat ->] Scale -> Relu -> Conv""""""\n        with tf.variable_scope(name) as scope:\n            bn = self.batch_normalization._original(self, input, name=\'bn\', relu=False, is_training=False)\n            if negation:\n                bn_neg = self.negation._original(self, bn, name=\'neg\')\n                bn = tf.concat(axis=3, values=[bn, bn_neg], name=\'concat\')\n                c_in += c_in\n                # y = \\alpha * x + \\beta\n                alpha = tf.get_variable(\'scale/alpha\', shape=[c_in,], dtype=tf.float32,\n                                        initializer=tf.constant_initializer(1.0), trainable=True, regularizer=self.l2_regularizer(0.00004))\n                beta = tf.get_variable(\'scale/beta\', shape=[c_in, ], dtype=tf.float32,\n                                        initializer=tf.constant_initializer(0.0), trainable=True, regularizer=self.l2_regularizer(0.00004))\n                bn = tf.add(tf.multiply(bn, alpha), beta)\n            bn = tf.nn.relu(bn, name=\'relu\')\n            if name == \'conv3_1/1\': self.layers[\'conv3_1/1/relu\'] = bn\n\n            conv = self.conv._original(self, bn, k_h, k_w, c_o, s_h, s_w, biased=biased, relu=False, name=\'conv\', padding=padding,\n                         trainable=trainable)\n            return conv\n\n    @layer\n    def pva_inception_res_stack(self, input, c_in, name, block_start = False, type = \'a\'):\n\n        if type == \'a\':\n            (c_0, c_1, c_2, c_pool, c_out) = (64, 64, 24, 128, 256)\n        elif type == \'b\':\n            (c_0, c_1, c_2, c_pool, c_out) = (64, 96, 32, 128, 384)\n        else:\n            raise (\'Unexpected inception-res type\')\n        if block_start:\n            stride = 2\n        else:\n            stride = 1\n        with tf.variable_scope(name+\'/incep\') as scope:\n            bn = self.batch_normalization._original(self, input, name=\'bn\', relu=False, is_training=False)\n            bn_scale = self.scale._original(self, bn, c_in, name=\'bn_scale\')\n            ## 1 x 1\n\n            conv = self.conv._original(self, bn_scale, 1, 1, c_0, stride, stride, name=\'0/conv\', biased = False, relu=False)\n            conv_0 = self.bn_scale_combo._original(self, conv, c_in=c_0, name =\'0\', relu=True)\n\n            ## 3 x 3\n            bn_relu = tf.nn.relu(bn_scale, name=\'relu\')\n            if name == \'conv4_1\': tmp_c = c_1; c_1 = 48\n            conv = self.conv._original(self, bn_relu, 1, 1, c_1, stride, stride, name=\'1_reduce/conv\', biased = False, relu=False)\n            conv = self.bn_scale_combo._original(self, conv, c_in=c_1, name=\'1_reduce\', relu=True)\n            if name == \'conv4_1\': c_1 = tmp_c\n            conv = self.conv._original(self, conv, 3, 3, c_1 * 2, 1, 1, name=\'1_0/conv\', biased = False, relu=False)\n            conv_1 = self.bn_scale_combo._original(self, conv, c_in=c_1 * 2, name=\'1_0\', relu=True)\n\n            ## 5 x 5\n            conv = self.conv._original(self, bn_scale, 1, 1, c_2, stride, stride, name=\'2_reduce/conv\', biased = False, relu=False)\n            conv = self.bn_scale_combo._original(self, conv, c_in=c_2, name=\'2_reduce\', relu=True)\n            conv = self.conv._original(self, conv, 3, 3, c_2 * 2, 1, 1, name=\'2_0/conv\', biased = False, relu=False)\n            conv = self.bn_scale_combo._original(self, conv, c_in=c_2 * 2, name=\'2_0\', relu=True)\n            conv = self.conv._original(self, conv, 3, 3, c_2 * 2, 1, 1, name=\'2_1/conv\', biased = False, relu=False)\n            conv_2 = self.bn_scale_combo._original(self, conv, c_in=c_2 * 2, name=\'2_1\', relu=True)\n\n            ## pool\n            if block_start:\n                pool = self.max_pool._original(self, bn_scale, 3, 3, 2, 2, padding=DEFAULT_PADDING, name=\'pool\')\n                pool = self.conv._original(self, pool, 1, 1, c_pool, 1, 1, name=\'poolproj/conv\', biased = False, relu=False)\n                pool = self.bn_scale_combo._original(self, pool, c_in=c_pool, name=\'poolproj\', relu=True)\n\n        with tf.variable_scope(name) as scope:\n            if block_start:\n                concat = tf.concat(axis=3, values=[conv_0, conv_1, conv_2, pool], name=\'concat\')\n                proj = self.conv._original(self, input, 1, 1, c_out, 2, 2, name=\'proj\', biased=True,\n                                           relu=False)\n            else:\n                concat = tf.concat(axis=3, values=[conv_0, conv_1, conv_2], name=\'concat\')\n                proj = input\n\n            conv = self.conv._original(self, concat, 1, 1, c_out, 1, 1, name=\'out/conv\', relu=False)\n            if name == \'conv5_4\':\n                conv = self.bn_scale_combo._original(self, conv, c_in=c_out, name=\'out\', relu=False)\n            conv = self.add._original(self, [conv, proj], name=\'sum\')\n        return  conv\n\n    @layer\n    def pva_inception_res_block(self, input, name, name_prefix = \'conv4_\', type = \'a\'):\n        """"""build inception block""""""\n        node = input\n        if type == \'a\':\n            c_ins = (128, 256, 256, 256, 256, )\n        else:\n            c_ins = (256, 384, 384, 384, 384, )\n        for i in range(1, 5):\n            node = self.pva_inception_res_stack._original(self, node, c_in = c_ins[i-1],\n                                                          name = name_prefix + str(i), block_start=(i==1), type=type)\n        return node\n\n    @layer\n    def scale(self, input, c_in, name):\n        with tf.variable_scope(name) as scope:\n\n            alpha = tf.get_variable(\'alpha\', shape=[c_in, ], dtype=tf.float32,\n                                    initializer=tf.constant_initializer(1.0), trainable=True,\n                                    regularizer=self.l2_regularizer(0.00001))\n            beta = tf.get_variable(\'beta\', shape=[c_in, ], dtype=tf.float32,\n                                   initializer=tf.constant_initializer(0.0), trainable=True,\n                                   regularizer=self.l2_regularizer(0.00001))\n            return tf.add(tf.multiply(input, alpha), beta)\n\n\n    @layer\n    def dropout(self, input, keep_prob, name):\n        return tf.nn.dropout(input, keep_prob, name=name)\n\n    def l2_regularizer(self, weight_decay=0.0005, scope=None):\n        def regularizer(tensor):\n            with tf.name_scope(scope, default_name=\'l2_regularizer\', values=[tensor]):\n                l2_weight = tf.convert_to_tensor(weight_decay,\n                                       dtype=tensor.dtype.base_dtype,\n                                       name=\'weight_decay\')\n                return tf.multiply(l2_weight, tf.nn.l2_loss(tensor), name=\'value\')\n        return regularizer\n\n    def smooth_l1_dist(self, deltas, sigma2=9.0, name=\'smooth_l1_dist\'):\n        with tf.name_scope(name=name) as scope:\n            deltas_abs = tf.abs(deltas)\n            smoothL1_sign = tf.cast(tf.less(deltas_abs, 1.0/sigma2), tf.float32)\n            return tf.square(deltas) * 0.5 * sigma2 * smoothL1_sign + \\\n                        (deltas_abs - 0.5 / sigma2) * tf.abs(smoothL1_sign - 1)\n\n\n    def build_loss(self):\n        time_step_batch = self.get_output(\'time_step_len\')\n        logits_batch = self.get_output(\'logits\')\n        labels = self.get_output(\'labels\')\n        label_len = self.get_output(\'labels_len\')\n\n        ctc_loss = warpctc_tensorflow.ctc(activations=logits_batch,flat_labels=labels,\n                                               label_lengths=label_len,input_lengths=time_step_batch)\n        loss = tf.reduce_mean(ctc_loss)\n        decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits_batch, time_step_batch, merge_repeated=True)\n        dense_decoded = tf.cast(tf.sparse_tensor_to_dense(decoded[0], default_value=0), tf.int32)\n\n        # add regularizer\n        if cfg.TRAIN.WEIGHT_DECAY > 0:\n            regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n            loss = tf.add_n(regularization_losses) + loss\n\n        return loss,dense_decoded\n'"
lib/utils/convert_ckpt2npy.py,10,"b'import os\nimport tensorflow as tf\nimport numpy as np\nfrom easydict import EasyDict as edict\nfrom lib.networks.factory import get_network\nfrom lib.fcn.config import get_output_dir,cfg_from_file\n\nclass Convert(object):\n    def __init__(self, sess, network, model_dir,out_path,model):\n        self.net = network\n        self.model_dir = model_dir\n        self.out_path=out_path\n        self.model=model\n        self.saver = tf.train.Saver(max_to_keep=100)\n\n    def conver2npy(self,sess):\n        global_step = tf.Variable(0, trainable=False)\n        local_vars_init_op = tf.local_variables_initializer()\n        global_vars_init_op = tf.global_variables_initializer()\n        combined_op = tf.group(local_vars_init_op, global_vars_init_op)\n        sess.run(combined_op)\n\n        try:\n            self.saver.restore(sess, tf.train.latest_checkpoint(self.model_dir))\n            sess.run(global_step.assign(0))\n            dic=dict()\n            pri_keys=[\'conv1_1\',\'conv1_2\',\'conv2_1\',\'conv2_2\',\n                  \'conv3_1\',\'conv3_2\',\'conv3_3\',\n                  \'conv4_1\',\'conv4_2\',\'conv4_3\',\n                  \'conv5_1\',\'conv5_2\',\'conv5_3\']\n            if self.model==32:\n                keys=pri_keys+[\'fc6\',\'fc7\',\'fc8\']\n            elif self.model==16:\n                keys=pri_keys+[\'fc6\',\'fc7\',\'fc8\',\'pool4_fc\']\n            elif self.model==8:\n                keys=pri_keys+[\'fc6\',\'fc7\',\'fc8\',\'pool4_fc\',\'pool3_fc\']\n            for key in keys:\n                with tf.variable_scope(key, reuse=True):\n                    dic[key] = dict()\n                    for subkey in [\'weights\',\'biases\']:\n                        try:\n                            var = tf.get_variable(subkey)\n                            data=sess.run(var)\n                            dic[key][subkey]=data\n\n                            print(""save model "" + subkey + "" to "" + key)\n                        except ValueError:\n                            print(""fail to convert"")\n            np.save(self.out_path, dic)\n        except:\n            raise Exception(\'Check your model\')\n\n\ndef convert_ckpt2npy(network, model_dir,out_path,model):\n    config = tf.ConfigProto(allow_soft_placement=True)\n    config.gpu_options.allocator_type = \'BFC\'\n    with tf.Session(config=config) as sess:\n        ct = Convert(sess, network,model_dir,out_path,model)\n        ct.conver2npy(sess)\n        print(\'done converting\')\n\n\n\n\nif __name__ == \'__main__\':\n    os.environ[""CUDA_VISIBLE_DEVICES""] = \'0\'\n\n    #\xe4\xbf\xae\xe6\x94\xb9\xe6\xad\xa4\xe5\xa4\x84\n    output_network_name = \'32s\'\n\n    cfg_from_file(\'./fcn/fcn_nlpr.yml\')\n    imgdb = edict({\'path\': \'./data/train.tfrecords\', \'name\': \'FCN_\' + output_network_name})\n    model_dir = get_output_dir(imgdb, None)\n    network = get_network(\'VGGnet_\'+output_network_name)\n    out_path=\'./data/\'+output_network_name\n    convert_ckpt2npy(network,model_dir=model_dir,out_path=out_path,model=int(output_network_name[:-1]))\n'"
lib/utils/data_util.py,0,"b'\'\'\'\nthis file is modified from keras implemention of data process multi-threading,\nsee https://github.com/fchollet/keras/blob/master/keras/utils/data_utils.py\n\'\'\'\nimport time\nimport numpy as np\nimport threading\nimport multiprocessing\ntry:\n    import queue\nexcept ImportError:\n    import Queue as queue\n\n\nclass GeneratorEnqueuer():\n    """"""Builds a queue out of a data generator.\n\n    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n\n    # Arguments\n        generator: a generator function which endlessly yields data\n        use_multiprocessing: use multiprocessing if True, otherwise threading\n        wait_time: time to sleep in-between calls to `put()`\n        random_seed: Initial seed for workers,\n            will be incremented by one for each workers.\n    """"""\n\n    def __init__(self, generator,\n                 use_multiprocessing=False,\n                 wait_time=0.05,\n                 random_seed=None):\n        self.wait_time = wait_time\n        self._generator = generator\n        self._use_multiprocessing = use_multiprocessing\n        self._threads = []\n        self._stop_event = None\n        self.queue = None\n        self.random_seed = random_seed\n\n    def start(self, workers=1, max_queue_size=10):\n        """"""Kicks off threads which add data from the generator into the queue.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, threads could block on `put()`)\n        """"""\n\n        def data_generator_task():\n            while not self._stop_event.is_set():\n                try:\n                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n                        generator_output = next(self._generator)\n                        self.queue.put(generator_output)\n                    else:\n                        time.sleep(self.wait_time)\n                except Exception:\n                    self._stop_event.set()\n                    raise\n\n        try:\n            if self._use_multiprocessing:\n                self.queue = multiprocessing.Queue(maxsize=max_queue_size)\n                self._stop_event = multiprocessing.Event()\n            else:\n                self.queue = queue.Queue()\n                self._stop_event = threading.Event()\n\n            for _ in range(workers):\n                if self._use_multiprocessing:\n                    # Reset random seed else all children processes\n                    # share the same seed\n                    np.random.seed(self.random_seed)\n                    thread = multiprocessing.Process(target=data_generator_task)\n                    thread.daemon = True\n                    if self.random_seed is not None:\n                        self.random_seed += 1\n                else:\n                    thread = threading.Thread(target=data_generator_task)\n                self._threads.append(thread)\n                thread.start()\n        except:\n            self.stop()\n            raise\n\n    def is_running(self):\n        return self._stop_event is not None and not self._stop_event.is_set()\n\n    def stop(self, timeout=None):\n        """"""Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`.\n        """"""\n        if self.is_running():\n            self._stop_event.set()\n\n        for thread in self._threads:\n            if thread.is_alive():\n                if self._use_multiprocessing:\n                    thread.terminate()\n                else:\n                    thread.join(timeout)\n\n        if self._use_multiprocessing:\n            if self.queue is not None:\n                self.queue.close()\n\n        self._threads = []\n        self._stop_event = None\n        self.queue = None\n\n    def get(self):\n        """"""Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Returns\n            A generator\n        """"""\n        while self.is_running():\n            if not self.queue.empty():\n                inputs = self.queue.get()\n                if inputs is not None:\n                    yield inputs\n            else:\n                time.sleep(self.wait_time)'"
lib/utils/genImg.py,0,"b'import sys, random,os\nimport numpy as np\nfrom captcha.image import ImageCaptcha\nimport cv2\nfrom multiprocessing import Pool\n\ndef randRGB():\n        return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n#10+26+26\nchar_set=\'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\'\nimgDir = None\nnumProcess = 12 \ndef gen_rand():\n    buf = """"\n    max_len = random.randint(4,6)\n    for i in range(max_len):\n       buf += random.choice(char_set)\n    return buf\ndef generateImg(ind):\n    global imgDir\n    captcha=ImageCaptcha(fonts=[\'./fonts/Ubuntu-M.ttf\'])\n    theChars=gen_rand()\n    data=captcha.generate(theChars)\n    img_name= \'{:08d}\'.format(ind)+\'_\'+theChars+\'.png\'\n    img_path=imgDir+\'/\'+img_name\n    captcha.write(theChars,img_path)\n    print(img_path)\n\ndef run(num,path):\n    global imgDir\n    imgDir = path\n    if not os.path.exists(path):\n        os.makedirs(path)\n    with Pool(processes=numProcess) as pool:\n         pool.map(generateImg,range(num))\n\nif __name__==\'__main__\':\n    #run(64*2000,\'./data/train\')\n    run(500,\'./data/val\')\n'"
lib/lstm/utils/__init__.py,0,b''
lib/lstm/utils/gen.py,0,"b'# encoding:utf-8\n# encoding:utf-8\nimport glob\nimport csv\nimport cv2,math\nimport time\nimport os,random\nimport numpy as np\nimport scipy.optimize\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as Patches\n#from shapely.geometry import Polygon\nfrom lib.utils.data_util import GeneratorEnqueuer\nfrom lib.lstm.config import cfg,get_encode_decode_dict\nimport tensorflow as tf\nfrom captcha.image import ImageCaptcha\nimport cv2\nimport sys\n\n\ndef randRGB():\n    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\ndef gen_rand():\n    buf = """"\n    max_len = random.randint(cfg.MIN_LEN,cfg.MAX_LEN)\n    for i in range(max_len):\n        buf += random.choice(cfg.CHARSET)\n    return buf\n\ndef generateImg():\n    captcha=ImageCaptcha(fonts=[cfg.FONT])\n    if not os.path.exists(cfg.FONT):\n        print(\'cannot open the font\')\n    theChars=gen_rand()\n    data=captcha.generate_image(theChars)\n    return np.array(data),theChars\n\nencode_maps,decode_maps = get_encode_decode_dict()\n\ndef groupBatch(imgs,labels):\n    max_w = -sys.maxsize\n    time_steps = []\n    label_len = []\n    label_vec = []\n    img_batch = []\n    nh = cfg.IMG_HEIGHT\n    for i,img in enumerate(imgs):\n        if cfg.NCHANNELS==1: h,w = img.shape\n        else: h,w,_ = img.shape\n        nw = int(nh/h*w)\n        max_w = max(max_w,nw)\n        imgs[i] = cv2.resize(img,(nw,nh))\n        time_steps.append(nw//cfg.POOL_SCALE+cfg.OFFSET_TIME_STEP)\n        code = [encode_maps[c] for c in list(labels[i])]\n        label_vec.extend(code)\n        label_len.append(len(labels[i]))\n    max_w = math.ceil(max_w/cfg.POOL_SCALE)*cfg.POOL_SCALE\n    for img in imgs:\n        if cfg.NCHANNELS==1: h,w = img.shape\n        else: h,w,_ = img.shape\n        img = cv2.copyMakeBorder(img,0,0,0,max_w-w,cv2.BORDER_CONSTANT,value=0).astype(np.float32)/255.\n        img = img.swapaxes(0, 1)\n        img = np.reshape(img,[-1,cfg.NUM_FEATURES])\n        img_batch.append(img)\n    #img_batch = np.array(img_batch)\n    return img_batch,label_vec,label_len,time_steps\n\ndef generator(batch_size=32, vis=False):\n    images = []\n    labels = []\n    while True:\n        try:\n            im, label = generateImg()\n            #img_size = cfg.IMG_SHAPE  # 160,60\n            #im = cv2.resize(im,(img_size[0],img_size[1]))\n            if cfg.NCHANNELS == 1:\n                im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n                #im = np.expand_dims(im,axis=2)\n            # print(im.shape,\' \',label)\n            if vis:\n                fig, axs = plt.subplots(2, 1, figsize=(50, 30))\n                if cfg.NCHANNELS==1: axs[0].imshow(im[:, :])\n                else: axs[0].imshow(im[:, :,:])\n                axs[0].set_xticks([])\n                axs[0].set_yticks([])\n                axs[0].text(0, 0, label)\n\n                if cfg.NCHANNELS==1: pass#axs[1].imshow(im[:, :])\n                else:axs[1].imshow(im[:, :, ::-1])\n                axs[1].set_xticks([])\n                axs[1].set_yticks([])\n\n                plt.tight_layout()\n                plt.show()\n                plt.close()\n\n            images.append(im)\n            labels.append(label)\n\n            if len(images) == batch_size:\n                image_batch,label_vec,label_len,time_step = groupBatch(images,labels)\n                yield image_batch,label_vec,label_len,time_step\n                images = []\n                labels = []\n        except Exception as e:\n            print(e)\n            import traceback\n            traceback.print_exc()\n            continue\n\ndef get_batch(num_workers, **kwargs):\n    try:\n        enqueuer = GeneratorEnqueuer(generator(**kwargs), use_multiprocessing=True)\n        enqueuer.start(max_queue_size=24, workers=num_workers)\n        generator_output = None\n        while True:\n            while enqueuer.is_running():\n                if not enqueuer.queue.empty():\n                    generator_output = enqueuer.queue.get()\n                    break\n                else:\n                    time.sleep(0.01)\n            yield generator_output\n            generator_output = None\n    finally:\n        if enqueuer is not None:\n            enqueuer.stop()\n\nif __name__ == \'__main__\':\n    # gen = generator(batch_size=32, vis=False)\n    gen = get_batch(num_workers=24,batch_size=32,vis=False)\n    while True:\n        images, labels,label_len,time_step =  next(gen)\n        print(len(images),"" "",images[0].shape)\n'"
lib/lstm/utils/tf_records.py,48,"b'# Important: We are using PIL to read .png files later.\n# This was done on purpose to read indexed png files\n# in a special way -- only indexes and not map the indexes\n# to actual rgb values. This is specific to PASCAL VOC\n# dataset data. If you don\'t want thit type of behaviour\n# consider using skimage.io.imread()\nfrom PIL import Image\nimport numpy as np\nimport skimage.io as io\nimport tensorflow as tf\nimport os,re\nfrom lib.lstm.config import cfg,get_encode_decode_dict\n\ncharset = cfg.CHARSET\nencode_maps , decode_maps = get_encode_decode_dict()\n# Helper functions for defining tf types\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _int64_feature_list(values):\n    """"""Wrapper for inserting an int64 FeatureList into a SequenceExample proto,\n    e.g, sentence in list of ints\n    """"""\n    return tf.train.FeatureList(feature=[_int64_feature(v) for v in values])\n\ndef _bytes_feature_list(values):\n    """"""Wrapper for inserting a bytes FeatureList into a SequenceExample proto,\n    e.g, sentence in list of bytes\n    """"""\n    return tf.train.FeatureList(feature=[_bytes_feature(v) for v in values])\n\n\ndef write_image_annotation_pairs_to_tfrecord(img_path, tfrecords_filename):\n    """"""Writes given image/annotation pairs to the tfrecords file.\n    The function reads each image/annotation pair given img_path\n    of image and respective annotation and writes it to the tfrecord\n    file.\n    Parameters\n    ----------\n    img_path : img_path\n    tfrecords_filename : string\n        Tfrecords filename to write the image/annotation pairs\n    """"""\n    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n    maxLen = cfg.MAX_CHAR_LEN\n\n    for root,subfolder,fileList in os.walk(img_path):\n        for fname in fileList:\n            fname = os.path.join(root,fname)\n            img = np.array(Image.open(fname))\n            code = re.match(r\'.*\\/[0-9]+_(.*)(_1)?\\..*\', fname).group(1)\n            code = [cfg.SPACE_INDEX if code == cfg.SPACE_TOKEN else encode_maps[c] for c in list(code)]\n            aligned_code = code[:]\n            while len(aligned_code)<maxLen:aligned_code.append(0)\n            # Unomment this one when working with surgical data\n\n            # The reason to store image sizes was demonstrated\n            # in the previous example -- we have to know sizes\n            # of images to later read raw serialized string,\n            # convert to 1d array and convert to respective\n            # shape that image used to have.\n            height = img.shape[0]\n            width = img.shape[1]\n            time_step = cfg.IMG_SHAPE[0]#160\n\n            img_raw = img.tostring()\n\n            context = tf.train.Features(feature={\n                \'height\': _int64_feature(height),\n                \'width\': _int64_feature(width),\n                \'time_step\': _int64_feature(time_step),\n                \'label_len\': _int64_feature(len(code)),\n                \'image_raw\': _bytes_feature(img_raw)\n                })\n            featureLists = tf.train.FeatureLists(feature_list={\n                \'label\': _int64_feature_list(aligned_code)\n            })\n\n            sequence_example = tf.train.SequenceExample(\n                context=context,feature_lists =featureLists\n            )\n\n            writer.write(sequence_example.SerializeToString())\n            # writer.write(example.SerializeToString())\n\n        writer.close()\n        print(\'Done\')\n\n\ndef read_image_annotation_pairs_from_tfrecord(tfrecords_filename):\n    """"""Return image/annotation pairs from the tfrecords file.\n    The function reads the tfrecords file and returns image\n    and respective annotation matrices pairs.\n    Parameters\n    ----------\n    tfrecords_filename : string\n        filename of .tfrecords file to read from\n    \n    Returns\n    -------\n    image_annotation_pairs : array of tuples (img, annotation)\n        The image and annotation that were read from the file\n    """"""\n    \n    image_annotation_pairs = []\n\n    record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n\n    for string_record in record_iterator:\n\n        example = tf.train.Example()\n        example.ParseFromString(string_record)\n\n        height = int(example.features.feature[\'height\']\n                                     .int64_list\n                                     .value[0])\n\n        width = int(example.features.feature[\'width\']\n                                    .int64_list\n                                    .value[0])\n\n        img_string = (example.features.feature[\'image_raw\']\n                                      .bytes_list\n                                      .value[0])\n\n        annotation_string = (example.features.feature[\'mask_raw\']\n                                    .bytes_list\n                                    .value[0])\n\n        img_1d = np.fromstring(img_string, dtype=np.uint8)\n        img = img_1d.reshape((height, width, -1))\n\n        annotation_1d = np.fromstring(annotation_string, dtype=np.uint8)\n\n        # Annotations don\'t have depth (3rd dimension)\n        # TODO: check if it works for other datasets\n        annotation = annotation_1d.reshape((height, width))\n\n        image_annotation_pairs.append((img, annotation))\n    \n    return image_annotation_pairs\n\n\ndef read_tfrecord_and_decode_into_image_annotation_pair_tensors(tfrecord_filenames_queue):\n    """"""Return image/annotation tensors that are created by reading tfrecord file.\n    The function accepts tfrecord filenames queue as an input which is usually\n    can be created using tf.train.string_input_producer() where filename\n    is specified with desired number of epochs. This function takes queue\n    produced by aforemention tf.train.string_input_producer() and defines\n    tensors converted from raw binary representations into\n    reshaped image/annotation tensors.\n    Parameters\n    ----------\n    tfrecord_filenames_queue : tfrecord filename queue\n        String queue object from tf.train.string_input_producer()\n    \n    Returns\n    -------\n    image, annotation : tuple of tf.int32 (image, annotation)\n        Tuple of image/annotation tensors\n    """"""\n    \n    reader = tf.TFRecordReader()\n\n    _, serialized_example = reader.read(tfrecord_filenames_queue)\n\n    features,sequence_features = tf.parse_single_sequence_example( serialized_example,\n        context_features={\n            \'height\': tf.FixedLenFeature([], tf.int64),\n            \'width\': tf.FixedLenFeature([], tf.int64),\n            \'time_step\': tf.FixedLenFeature([], tf.int64),\n            \'label_len\': tf.FixedLenFeature([], tf.int64),\n            \'image_raw\': tf.FixedLenFeature([], tf.string), },\n        sequence_features={\n            \'label\': tf.FixedLenSequenceFeature([], tf.int64),})\n    \n    image = tf.decode_raw(features[\'image_raw\'], tf.uint8)\n\n    height = tf.cast(features[\'height\'], tf.int32)\n    width = tf.cast(features[\'width\'], tf.int32)\n    label_len = tf.cast(features[\'label_len\'], tf.int32)\n    label = tf.cast(sequence_features[\'label\'],tf.int32)\n    label = tf.reshape(label,[cfg.MAX_CHAR_LEN])\n    #image_shape = tf.pack([height, width, 3])\n    image_shape = tf.parallel_stack([height, width, 3])\n    image = tf.reshape(image,image_shape)\n\n    img_size = cfg.IMG_SHAPE #160,60\n    time_step = tf.constant(cfg.TIME_STEP,tf.int32)\n\n    if cfg.NCHANNELS==1: image = tf.image.rgb_to_grayscale(image)\n    image = tf.image.resize_images(image,size=(img_size[1],img_size[0]),method=tf.image.ResizeMethod.BILINEAR)\n    image = tf.transpose(image,perm=[1,0,2])\n    image = tf.cast(tf.reshape(image,[img_size[0],cfg.NUM_FEATURES]),dtype=tf.float32)/255.\n\n    # The last dimension was added because\n    # the tf.resize_image_with_crop_or_pad() accepts tensors\n    # that have depth. We need resize and crop later.\n    # TODO: See if it is necessary and probably remove third\n    # dimension\n    #annotation_shape = tf.pack([height, width, 1])\n    # image = tf.reshape(image, image_shape)\n\n    return image, label,label_len,time_step\n\ndef wrtie_test(img_path ,tfrecords_filename = None):\n    write_image_annotation_pairs_to_tfrecord(img_path=img_path,tfrecords_filename=tfrecords_filename)\ndef read_test(tfrecords_fiename=None):\n    config = tf.ConfigProto(allow_soft_placement=True)\n    config.gpu_options.allocator_type = \'BFC\'\n    with tf.Session(config=config) as sess:\n        filename_queue = tf.train.string_input_producer([tfrecords_fiename], num_epochs=1)\n        image,label,label_len,time_step= read_tfrecord_and_decode_into_image_annotation_pair_tensors(filename_queue)\n        image_batch, label_batch, label_len_batch,time_step_batch = tf.train.shuffle_batch([image,label,label_len,time_step],\n                                                                                           batch_size=2,\n                                                                                           capacity=500,\n                                                                                           num_threads=2,\n                                                                                           min_after_dequeue=100)\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.local_variables_initializer())\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        try:\n            while not coord.should_stop():\n                # get one batch\n                img_batch, l_batch, l_len_batch,t_s_batch = sess.run([image_batch, label_batch, label_len_batch,time_step_batch] )\n                label = []\n                for l in l_batch:\n                    while l[-1] == 0: l=l[:-1]\n                    label.extend(l)\n                print(l_batch)\n                # Subtract the mean pixel value from each pixel\n        except tf.errors.OutOfRangeError:\n            print(\'finish\')\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n\n\nif __name__==\'__main__\':\n    wrtie_test(img_path=\'/home/amax/Documents/code/lstm_train/lstm_ctc/data/train_4_6\',tfrecords_filename=\'./data/train_4_6.tfrecords\')\n    # wrtie_test(img_path=\'./data/val\',tfrecords_filename=\'./data/val.tfrecords\')\n    # read_test(tfrecords_fiename=\'./data/val.tfrecords\')\n'"
lib/lstm/utils/timer.py,0,"b'# --------------------------------------------------------\n# Fast R-CNN\n# Copyright (c) 2015 Microsoft\n# Licensed under The MIT License [see LICENSE for details]\n# Written by Ross Girshick\n# --------------------------------------------------------\n\nimport time\n\nclass Timer(object):\n    """"""A simple timer.""""""\n    def __init__(self):\n        self.total_time = 0.\n        self.calls = 0\n        self.start_time = 0.\n        self.diff = 0.\n        self.average_time = 0.\n\n    def tic(self):\n        # using time.time instead of time.clock because time time.clock\n        # does not normalize for multithreading\n        self.start_time = time.time()\n\n    def toc(self, average=True):\n        self.diff = time.time() - self.start_time\n        self.total_time += self.diff\n        self.calls += 1\n        self.average_time = self.total_time / self.calls\n        if average:\n            return self.average_time\n        else:\n            return self.diff\n'"
lib/lstm/utils/training.py,15,"b'import tensorflow as tf\nimport re\nfrom lib.lstm.config import cfg\nimport numpy as np\n\ndef get_label_and_len(fnames):\n    labels = []\n    lens = []\n    """"""\n    need to add regular expresiion for tensorflow\n    """"""\n    fnames = fnames.reshape([-1,1])\n    # for fname in fnames:\n    labels = np.array(labels,dtype=np.int32)\n    lens = np.array(lens,dtype=np.int32)\n    return labels\n\ndef get_label_and_len_from_fnames(fnames_tensor):\n    """"""\n    :param fnames_tensor: (batch_size) string\n    :return: (n) n: the number of label\n    """"""\n    labels,label_len = tf.py_func(get_label_and_len,[fnames_tensor],tf.int32)\n    return labels,label_len\n\ndef accuracy_calculation(original_seq,decoded_seq,ignore_value=0,isPrint = True):\n    if  len(original_seq)!=len(decoded_seq):\n        print(\'original lengths is different from the decoded_seq,please check again\')\n        return 0\n    count = 0\n    for i,origin_label in enumerate(original_seq):\n        decoded_label  = [j for j in decoded_seq[i] if j!=ignore_value]\n        org_label = [l for l in origin_label if l!=ignore_value]\n        if isPrint and i<cfg.VAL.PRINT_NUM:\n            print(\'seq{0:4d}: origin: {1} decoded:{2}\'.format(i,origin_label,decoded_label))\n        if org_label == decoded_label: count+=1\n    return count*1.0/len(original_seq)\n\ndef get_labels_from_annotation(annotation_tensor, class_labels):\n    """"""Returns tensor of size (width, height, num_classes) derived from annotation tensor.\n    The function returns tensor that is of a size (width, height, num_classes) which\n    is derived from annotation tensor with sizes (width, height) where value at\n    each position represents a class. The functions requires a list with class\n    values like [0, 1, 2 ,3] -- they are used to derive labels. Derived values will\n    be ordered in the same way as the class numbers were provided in the list. Last\n    value in the aforementioned list represents a value that indicate that the pixel\n    should be masked out. So, the size of num_classes := len(class_labels) - 1.\n    \n    Parameters\n    ----------\n    annotation_tensor : Tensor of size (width, height)\n        Tensor with class labels for each element\n    class_labels : list of ints\n        List that contains the numbers that represent classes. Last\n        value in the list should represent the number that was used\n        for masking out.\n        \n    Returns\n    -------\n    labels_2d_stacked : Tensor of size (width, height, num_classes).\n        Tensor with labels for each pixel.\n    """"""\n    \n    # Last value in the classes list should show\n    # which number was used in the annotation to mask out\n    # the ambigious regions or regions that should not be\n    # used for training.\n    # TODO: probably replace class_labels list with some custom object\n    valid_entries_class_labels = class_labels[:-1]\n    \n    # Stack the binary masks for each class\n    labels_2d = list(map(lambda x: tf.equal(annotation_tensor, x),\n                    valid_entries_class_labels))\n\n    # Perform the merging of all of the binary masks into one matrix\n    labels_2d_stacked = tf.stack(labels_2d, axis=2)\n    \n    # Convert tf.bool to tf.float\n    # Later on in the labels and logits will be used\n    # in tf.softmax_cross_entropy_with_logits() function\n    # where they have to be of the float type.\n    labels_2d_stacked_float = tf.to_float(labels_2d_stacked)\n    \n    return labels_2d_stacked_float\n\ndef get_labels_from_annotation_batch(annotation_batch_tensor, class_labels):\n    """"""Returns tensor of size (batch_size, width, height, num_classes) derived\n    from annotation batch tensor. The function returns tensor that is of a size\n    (batch_size, width, height, num_classes) which is derived from annotation tensor\n    with sizes (batch_size, width, height) where value at each position represents a class.\n    The functions requires a list with class values like [0, 1, 2 ,3] -- they are\n    used to derive labels. Derived values will be ordered in the same way as\n    the class numbers were provided in the list. Last value in the aforementioned\n    list represents a value that indicate that the pixel should be masked out.\n    So, the size of num_classes len(class_labels) - 1.\n    \n    Parameters\n    ----------\n    annotation_batch_tensor : Tensor of size (batch_size, width, height)\n        Tensor with class labels for each element\n    class_labels : list of ints\n        List that contains the numbers that represent classes. Last\n        value in the list should represent the number that was used\n        for masking out.\n        \n    Returns\n    -------\n    batch_labels : Tensor of size (batch_size, width, height, num_classes).\n        Tensor with labels for each batch.\n    """"""\n    \n    batch_labels = tf.map_fn(fn=lambda x: get_labels_from_annotation(annotation_tensor=x, class_labels=class_labels),\n                             elems=annotation_batch_tensor,\n                             dtype=tf.float32)\n    \n    return batch_labels\n\ndef get_valid_entries_indices_from_annotation_batch(annotation_batch_tensor, class_labels):\n    """"""Returns tensor of size (num_valid_eintries, 3).\n    Returns tensor that contains the indices of valid entries according\n    to the annotation tensor. This can be used to later on extract only\n    valid entries from logits tensor and labels tensor. This function is\n    supposed to work with a batch input like [b, w, h] -- where b is a\n    batch size, w, h -- are width and height sizes. So the output is\n    a tensor which contains indexes of valid entries. This function can\n    also work with a single annotation like [w, h] -- the output will\n    be (num_valid_eintries, 2).\n    \n    Parameters\n    ----------\n    annotation_batch_tensor : Tensor of size (batch_size, width, height)\n        Tensor with class labels for each batch\n    class_labels : list of ints\n        List that contains the numbers that represent classes. Last\n        value in the list should represent the number that was used\n        for masking out.\n        \n    Returns\n    -------\n    valid_labels_indices : Tensor of size (num_valid_eintries, 3).\n        Tensor with indices of valid entries\n    """"""\n    \n    # Last value in the classes list should show\n    # which number was used in the annotation to mask out\n    # the ambigious regions or regions that should not be\n    # used for training.\n    # TODO: probably replace class_labels list with some custom object\n    mask_out_class_label = class_labels[-1]\n    \n    # Get binary mask for the pixels that we want to\n    # use for training. We do this because some pixels\n    # are marked as ambigious and we don\'t want to use\n    # them for trainig to avoid confusing the model\n    valid_labels_mask = tf.not_equal(annotation_batch_tensor,\n                                        mask_out_class_label)\n    \n    valid_labels_indices = tf.where(valid_labels_mask)\n    \n    return tf.to_int32(valid_labels_indices)\n\nimport numpy as np\ndef sample(x):\n    input_shape=x.shape\n    x=x.reshape([-1,1])\n    num_fg = 500\n    fg_inds = np.where(x == 1)[0]\n    len_fg = len(fg_inds)\n    if len_fg > num_fg:\n        disable_inds = np.random.choice(fg_inds, size=(len_fg - num_fg), replace=False)\n        x[disable_inds] = 255\n        len_fg= 500\n\n    num_bg = 1000-len_fg\n    bg_inds = np.where(x == 0)[0]\n    len_bg = len(bg_inds)\n    if len_bg > num_bg:\n        disable_inds = np.random.choice(bg_inds, size=(len_bg - num_bg), replace=False)\n        x[disable_inds] = 255\n    x=x.reshape(input_shape)\n    return x\n\ndef get_valid_logits_and_labels(annotation_batch_tensor,\n                                logits_batch_tensor,\n                                class_labels):\n    """"""Returns two tensors of size (num_valid_entries, num_classes).\n    The function converts annotation batch tensor input of the size\n    (batch_size, height, width) into label tensor (batch_size, height,\n    width, num_classes) and then selects only valid entries, resulting\n    in tensor of the size (num_valid_entries, num_classes). The function\n    also returns the tensor with corresponding valid entries in the logits\n    tensor. Overall, two tensors of the same sizes are returned and later on\n    can be used as an input into tf.softmax_cross_entropy_with_logits() to\n    get the cross entropy error for each entry.\n    \n    Parameters\n    ----------\n    annotation_batch_tensor : Tensor of size (batch_size, width, height)\n        Tensor with class labels for each batch\n    logits_batch_tensor : Tensor of size (batch_size, width, height, num_classes)\n        Tensor with logits. Usually can be achived after inference of fcn network.\n    class_labels : list of ints\n        List that contains the numbers that represent classes. Last\n        value in the list should represent the number that was used\n        for masking out.\n        \n    Returns\n    -------\n    (valid_labels_batch_tensor, valid_logits_batch_tensor) : Two Tensors of size (num_valid_eintries, num_classes).\n        Tensors that represent valid labels and logits.\n    """"""\n\n    annotation_batch_tensor = tf.py_func(sample, [annotation_batch_tensor], tf.int32)\n    labels_batch_tensor = get_labels_from_annotation_batch(annotation_batch_tensor=annotation_batch_tensor,\n                                                           class_labels=class_labels)\n    \n    valid_batch_indices = get_valid_entries_indices_from_annotation_batch(annotation_batch_tensor=annotation_batch_tensor,\n                                                                          class_labels=class_labels)\n    \n    valid_labels_batch_tensor = tf.gather_nd(params=labels_batch_tensor, indices=valid_batch_indices)\n    \n    valid_logits_batch_tensor = tf.gather_nd(params=logits_batch_tensor, indices=valid_batch_indices)\n    \n    return valid_labels_batch_tensor, valid_logits_batch_tensor'"
