file_path,api_count,code
__init__.py,0,b''
benchmark.py,4,"b'import json\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nfrom predict import Predictor\n\n\nif __name__ == ""__main__"":\n    checkpoint = ""logs/semantic_backup_full_submit_dec_10/best_model_epoch_275.ckpt""\n    hyper_params = json.loads(open(""semantic.json"").read())\n    predictor = Predictor(\n        checkpoint_path=checkpoint, num_classes=9, hyper_params=hyper_params\n    )\n\n    batch_size = 64\n    # Init data\n    points_with_colors = np.random.randn(batch_size, hyper_params[""num_point""], 6)\n\n    # Warm up\n    pd_labels = predictor.predict(points_with_colors)\n\n    # Benchmark\n    s = time.time()\n\n    profiler = tf.profiler.Profiler(predictor.sess.graph)\n    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n    run_metadata = tf.RunMetadata()\n\n    _ = predictor.predict(\n        points_with_colors, run_options=run_options, run_metadata=run_metadata\n    )\n\n    profiler.add_step(0, run_metadata)\n\n    batch_time = time.time() - s\n    sample_time = batch_time / batch_size\n    print(\n        ""Batch size: {}, batch_time: {}, sample_time: {}"".format(\n            batch_size, batch_time, sample_time\n        )\n    )\n\n    option_builder = tf.profiler.ProfileOptionBuilder\n    opts = (\n        option_builder(option_builder.time_and_memory())\n        .with_step(-1)  # with -1, should compute the average of all registered steps.\n        .with_file_output(""tf-profile.txt"")\n        .select([""micros"", ""bytes"", ""occurrence""])\n        .order_by(""micros"")\n        .build()\n    )\n    # Profiling info about ops are saved in \'test-%s.txt\' % FLAGS.out\n    profiler.profile_operations(options=opts)\n\n    for batch_size in [2 ** n for n in range(8)]:\n        # Init data\n        points_with_colors = np.random.randn(batch_size, hyper_params[""num_point""], 6)\n\n        # Warm up\n        pd_labels = predictor.predict(points_with_colors)\n\n        # Benchmark\n        s = time.time()\n        _ = predictor.predict(points_with_colors)\n        batch_time = time.time() - s\n        sample_time = batch_time / batch_size\n        print(\n            ""Batch size: {}, batch_time: {}, sample_time: {}"".format(\n                batch_size, batch_time, sample_time\n            )\n        )\n'"
colorize.py,0,"b'import open3d\nimport os\nfrom util.point_cloud_util import load_labels, colorize_point_cloud\nimport time\nimport glob\n\n\ndef colorize(input_pcd_path, input_labels_path, output_pcd_path):\n    pcd = open3d.read_point_cloud(input_pcd_path)\n    print(""Point cloud loaded from"", input_pcd_path)\n\n    labels = load_labels(input_labels_path)\n    print(""Labels loaded from"", input_labels_path)\n\n    s = time.time()\n    colorize_point_cloud(pcd, labels)\n    print(""time colorize_point_cloud pd"", time.time() - s, flush=True)\n\n    open3d.write_point_cloud(output_pcd_path, pcd)\n    print(""Output written to"", output_pcd_path)\n\n\nif __name__ == ""__main__"":\n\n    # Dense folders\n    # gt_dir = ""dataset/semantic_raw""\n    # pd_dir = ""result/dense""\n    # colorized_pd_dir = ""result/dense_colorized""\n    # colorized_gt_dir = ""result/dense_colorized_gt""\n\n    # Sparse folders\n    gt_dir = ""result/sparse""\n    pd_dir = ""result/sparse""\n    colorized_pd_dir = ""result/sparse_colorized""\n    os.makedirs(colorized_pd_dir, exist_ok=True)\n\n    pd_labels_paths = glob.glob(os.path.join(pd_dir, ""*.labels""))\n    for pd_labels_path in pd_labels_paths:\n        print(""Processing"", pd_labels_path)\n        file_prefix = os.path.basename(os.path.splitext(pd_labels_path)[0])\n\n        # Input pcd\n        input_pcd_path = os.path.join(gt_dir, file_prefix + "".pcd"")\n\n        # Colorize by predicted labels\n        input_labels_path = os.path.join(pd_dir, file_prefix + "".labels"")\n        if os.path.isfile(input_labels_path):\n            output_pcd_path = os.path.join(colorized_pd_dir, file_prefix + "".pcd"")\n            colorize(input_pcd_path, input_labels_path, output_pcd_path)\n'"
downsample.py,0,"b'import open3d\nimport os\nimport numpy as np\nfrom util.point_cloud_util import load_labels, write_labels\nfrom dataset.semantic_dataset import all_file_prefixes\n\n\ndef down_sample(\n    dense_pcd_path, dense_label_path, sparse_pcd_path, sparse_label_path, voxel_size\n):\n    # Skip if done\n    if os.path.isfile(sparse_pcd_path) and (\n        not os.path.isfile(dense_label_path) or os.path.isfile(sparse_label_path)\n    ):\n        print(""Skipped:"", file_prefix)\n        return\n    else:\n        print(""Processing:"", file_prefix)\n\n    # Inputs\n    dense_pcd = open3d.read_point_cloud(dense_pcd_path)\n    try:\n        dense_labels = load_labels(dense_label_path)\n    except:\n        dense_labels = None\n\n    # Skip label 0, we use explicit frees to reduce memory usage\n    print(""Num points:"", np.asarray(dense_pcd.points).shape[0])\n    if dense_labels is not None:\n        non_zero_indexes = dense_labels != 0\n\n        dense_points = np.asarray(dense_pcd.points)[non_zero_indexes]\n        dense_pcd.points = open3d.Vector3dVector()\n        dense_pcd.points = open3d.Vector3dVector(dense_points)\n        del dense_points\n\n        dense_colors = np.asarray(dense_pcd.colors)[non_zero_indexes]\n        dense_pcd.colors = open3d.Vector3dVector()\n        dense_pcd.colors = open3d.Vector3dVector(dense_colors)\n        del dense_colors\n\n        dense_labels = dense_labels[non_zero_indexes]\n        print(""Num points after 0-skip:"", np.asarray(dense_pcd.points).shape[0])\n\n    # Downsample points\n    min_bound = dense_pcd.get_min_bound() - voxel_size * 0.5\n    max_bound = dense_pcd.get_max_bound() + voxel_size * 0.5\n\n    sparse_pcd, cubics_ids = open3d.voxel_down_sample_and_trace(\n        dense_pcd, voxel_size, min_bound, max_bound, False\n    )\n    print(""Num points after down sampling:"", np.asarray(sparse_pcd.points).shape[0])\n\n    open3d.write_point_cloud(sparse_pcd_path, sparse_pcd)\n    print(""Point cloud written to:"", sparse_pcd_path)\n\n    # Downsample labels\n    if dense_labels is not None:\n        sparse_labels = []\n        for cubic_ids in cubics_ids:\n            cubic_ids = cubic_ids[cubic_ids != -1]\n            cubic_labels = dense_labels[cubic_ids]\n            sparse_labels.append(np.bincount(cubic_labels).argmax())\n        sparse_labels = np.array(sparse_labels)\n\n        write_labels(sparse_label_path, sparse_labels)\n        print(""Labels written to:"", sparse_label_path)\n\n\nif __name__ == ""__main__"":\n    voxel_size = 0.05\n\n    # By default\n    # raw data: ""dataset/semantic_raw""\n    # downsampled data: ""dataset/semantic_downsampled""\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    dataset_dir = os.path.join(current_dir, ""dataset"")\n    raw_dir = os.path.join(dataset_dir, ""semantic_raw"")\n    downsampled_dir = os.path.join(dataset_dir, ""semantic_downsampled"")\n\n    # Create downsampled_dir\n    os.makedirs(downsampled_dir, exist_ok=True)\n\n    for file_prefix in all_file_prefixes:\n        # Paths\n        dense_pcd_path = os.path.join(raw_dir, file_prefix + "".pcd"")\n        dense_label_path = os.path.join(raw_dir, file_prefix + "".labels"")\n        sparse_pcd_path = os.path.join(downsampled_dir, file_prefix + "".pcd"")\n        sparse_label_path = os.path.join(downsampled_dir, file_prefix + "".labels"")\n\n        # Put down_sample in a function for garbage collection\n        down_sample(\n            dense_pcd_path,\n            dense_label_path,\n            sparse_pcd_path,\n            sparse_label_path,\n            voxel_size,\n        )\n'"
interpolate.py,5,"b'import argparse\nimport os\nimport numpy as np\nimport open3d\nimport time\nimport multiprocessing\nimport tensorflow as tf\n\nfrom util.metric import ConfusionMatrix\nfrom util.point_cloud_util import load_labels, write_labels\nfrom dataset.semantic_dataset import map_name_to_file_prefixes\nfrom pprint import pprint\nfrom tf_ops.tf_interpolate import interpolate_label_with_color\n\n\nclass Interpolator:\n    def __init__(self):\n        pl_sparse_points = tf.placeholder(tf.float32, (None, 3))\n        pl_sparse_labels = tf.placeholder(tf.int32, (None,))\n        pl_dense_points = tf.placeholder(tf.float32, (None, 3))\n        pl_knn = tf.placeholder(tf.int32, ())\n        dense_labels, dense_colors = interpolate_label_with_color(\n            pl_sparse_points, pl_sparse_labels, pl_dense_points, pl_knn\n        )\n        self.ops = {\n            ""pl_sparse_points"": pl_sparse_points,\n            ""pl_sparse_labels"": pl_sparse_labels,\n            ""pl_dense_points"": pl_dense_points,\n            ""pl_knn"": pl_knn,\n            ""dense_labels"": dense_labels,\n            ""dense_colors"": dense_colors,\n        }\n        self.sess = tf.Session()\n\n    def interpolate_labels(self, sparse_points, sparse_labels, dense_points, knn=3):\n        return self.sess.run(\n            [self.ops[""dense_labels""], self.ops[""dense_colors""]],\n            feed_dict={\n                self.ops[""pl_sparse_points""]: sparse_points,\n                self.ops[""pl_sparse_labels""]: sparse_labels,\n                self.ops[""pl_dense_points""]: dense_points,\n                self.ops[""pl_knn""]: knn,\n            },\n        )\n\n\nif __name__ == ""__main__"":\n    # Parser\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--set"", default=""validation"", help=""train, validation, test"")\n    flags = parser.parse_args()\n\n    # Directories\n    sparse_dir = ""result/sparse""\n    dense_dir = ""result/dense""\n    gt_dir = ""dataset/semantic_raw""\n    os.makedirs(dense_dir, exist_ok=True)\n\n    # Parameters\n    radius = 0.2\n    k = 20\n\n    # Global statistics\n    cm_global = ConfusionMatrix(9)\n    interpolator = Interpolator()\n\n    for file_prefix in map_name_to_file_prefixes[flags.set]:\n        print(""Interpolating:"", file_prefix, flush=True)\n\n        # Paths\n        sparse_points_path = os.path.join(sparse_dir, file_prefix + "".pcd"")\n        sparse_labels_path = os.path.join(sparse_dir, file_prefix + "".labels"")\n        dense_points_path = os.path.join(gt_dir, file_prefix + "".pcd"")\n        dense_labels_path = os.path.join(dense_dir, file_prefix + "".labels"")\n        dense_points_colored_path = os.path.join(\n            dense_dir, file_prefix + ""_colored.pcd""\n        )\n        dense_gt_labels_path = os.path.join(gt_dir, file_prefix + "".labels"")\n\n        # Sparse points\n        sparse_pcd = open3d.read_point_cloud(sparse_points_path)\n        sparse_points = np.asarray(sparse_pcd.points)\n        del sparse_pcd\n        print(""sparse_points loaded"", flush=True)\n\n        # Sparse labels\n        sparse_labels = load_labels(sparse_labels_path)\n        print(""sparse_labels loaded"", flush=True)\n\n        # Dense points\n        dense_pcd = open3d.read_point_cloud(dense_points_path)\n        dense_points = np.asarray(dense_pcd.points)\n        print(""dense_points loaded"", flush=True)\n\n        # Dense Ground-truth labels\n        try:\n            dense_gt_labels = load_labels(os.path.join(gt_dir, file_prefix + "".labels""))\n            print(""dense_gt_labels loaded"", flush=True)\n        except:\n            print(""dense_gt_labels not found, treat as test set"")\n            dense_gt_labels = None\n\n        # Assign labels\n        start = time.time()\n        dense_labels, dense_colors = interpolator.interpolate_labels(\n            sparse_points, sparse_labels, dense_points\n        )\n        print(""KNN interpolation time: "", time.time() - start, ""seconds"", flush=True)\n\n        # Write dense labels\n        write_labels(dense_labels_path, dense_labels)\n        print(""Dense labels written to:"", dense_labels_path, flush=True)\n\n        # Write dense point cloud with color\n        dense_pcd.colors = open3d.Vector3dVector(dense_colors)\n        open3d.write_point_cloud(dense_points_colored_path, dense_pcd)\n        print(""Dense pcd with color written to:"", dense_points_colored_path, flush=True)\n\n        # Eval\n        if dense_gt_labels is not None:\n            cm = ConfusionMatrix(9)\n            cm.increment_from_list(dense_gt_labels, dense_labels)\n            cm.print_metrics()\n            cm_global.increment_from_list(dense_gt_labels, dense_labels)\n\n    pprint(""Global results"")\n    cm_global.print_metrics()\n'"
kitti_predict.py,12,"b'import argparse\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nimport open3d\nimport time\n\nimport model\nfrom dataset.kitti_dataset import KittiDataset\nfrom tf_ops.tf_interpolate import interpolate_label_with_color\n\n\ndef interpolate_dense_labels(sparse_points, sparse_labels, dense_points, k=3):\n    sparse_pcd = open3d.PointCloud()\n    sparse_pcd.points = open3d.Vector3dVector(sparse_points)\n    sparse_pcd_tree = open3d.KDTreeFlann(sparse_pcd)\n\n    dense_labels = []\n    for dense_point in dense_points:\n        result_k, sparse_indexes, _ = sparse_pcd_tree.search_knn_vector_3d(\n            dense_point, k\n        )\n        knn_sparse_labels = sparse_labels[sparse_indexes]\n        dense_label = np.bincount(knn_sparse_labels).argmax()\n        dense_labels.append(dense_label)\n    return dense_labels\n\n\nclass PredictInterpolator:\n    def __init__(self, checkpoint_path, num_classes, hyper_params):\n        # Get ops from graph\n        with tf.device(""/gpu:0""):\n            # Placeholders\n            pl_sparse_points_centered_batched, _, _ = model.get_placeholders(\n                hyper_params[""num_point""], hyperparams=hyper_params\n            )\n            pl_is_training = tf.placeholder(tf.bool, shape=())\n\n            # Prediction\n            pred, _ = model.get_model(\n                pl_sparse_points_centered_batched,\n                pl_is_training,\n                num_classes,\n                hyperparams=hyper_params,\n            )\n            sparse_labels_batched = tf.argmax(pred, axis=2)\n            # (1, num_sparse_points) -> (num_sparse_points,)\n            sparse_labels = tf.reshape(sparse_labels_batched, [-1])\n            sparse_labels = tf.cast(sparse_labels, tf.int32)\n\n            # Saver\n            saver = tf.train.Saver()\n\n            # Graph for interpolating labels\n            # Assuming batch_size == 1 for simplicity\n            pl_sparse_points_batched = tf.placeholder(tf.float32, (None, None, 3))\n            sparse_points = tf.reshape(pl_sparse_points_batched, [-1, 3])\n            pl_dense_points = tf.placeholder(tf.float32, (None, 3))\n            pl_knn = tf.placeholder(tf.int32, ())\n            dense_labels, dense_colors = interpolate_label_with_color(\n                sparse_points, sparse_labels, pl_dense_points, pl_knn\n            )\n\n        self.ops = {\n            ""pl_sparse_points_centered_batched"": pl_sparse_points_centered_batched,\n            ""pl_sparse_points_batched"": pl_sparse_points_batched,\n            ""pl_dense_points"": pl_dense_points,\n            ""pl_is_training"": pl_is_training,\n            ""pl_knn"": pl_knn,\n            ""dense_labels"": dense_labels,\n            ""dense_colors"": dense_colors,\n        }\n\n        # Restore checkpoint to session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        self.sess = tf.Session(config=config)\n        saver.restore(self.sess, checkpoint_path)\n        print(""Model restored"")\n\n    def predict_and_interpolate(\n        self,\n        sparse_points_centered_batched,\n        sparse_points_batched,\n        dense_points,\n        run_metadata=None,\n        run_options=None,\n    ):\n        dense_labels_val, dense_colors_val = self.sess.run(\n            [self.ops[""dense_labels""], self.ops[""dense_colors""]],\n            feed_dict={\n                self.ops[\n                    ""pl_sparse_points_centered_batched""\n                ]: sparse_points_centered_batched,\n                self.ops[""pl_sparse_points_batched""]: sparse_points_batched,\n                self.ops[""pl_dense_points""]: dense_points,\n                self.ops[""pl_knn""]: 3,\n                self.ops[""pl_is_training""]: False,\n            },\n        )\n        return dense_labels_val, dense_colors_val\n\n\nif __name__ == ""__main__"":\n    np.random.seed(0)\n\n    # Parser\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        ""--num_samples"",\n        type=int,\n        default=8,\n        help=""# samples, each contains num_point points"",\n    )\n    parser.add_argument(""--ckpt"", default="""", help=""Checkpoint file"")\n    parser.add_argument(""--save"", action=""store_true"", default=False)\n    parser.add_argument(\n        ""--kitti_root"", default="""", help=""Checkpoint file"", required=True\n    )\n    flags = parser.parse_args()\n    hyper_params = json.loads(open(""semantic_no_color.json"").read())\n\n    # Create output dir\n    sparse_output_dir = os.path.join(""result"", ""sparse"")\n    dense_output_dir = os.path.join(""result"", ""dense"")\n    os.makedirs(sparse_output_dir, exist_ok=True)\n    os.makedirs(dense_output_dir, exist_ok=True)\n\n    # Dataset\n    dataset = KittiDataset(\n        num_points_per_sample=hyper_params[""num_point""],\n        base_dir=flags.kitti_root,\n        dates=[""2011_09_26""],\n        # drives=[""0095"", ""0001""],\n        drives=[""0095""],\n        box_size_x=hyper_params[""box_size_x""],\n        box_size_y=hyper_params[""box_size_y""],\n    )\n\n    # Model\n    max_batch_size = 128  # The more the better, limited by memory size\n    predictor = PredictInterpolator(\n        checkpoint_path=flags.ckpt,\n        num_classes=dataset.num_classes,\n        hyper_params=hyper_params,\n    )\n\n    # Init visualizer\n    dense_pcd = open3d.PointCloud()\n    vis = open3d.Visualizer()\n    vis.create_window()\n    vis.add_geometry(dense_pcd)\n    render_option = vis.get_render_option()\n    render_option.point_size = 0.05\n\n    to_reset_view_point = True\n    for kitti_file_data in dataset.list_file_data:\n        timer = {\n            ""load_data"": 0,\n            ""predict_interpolate"": 0,\n            ""visualize"": 0,\n            ""write_data"": 0,\n            ""total"": 0,\n        }\n\n        global_start_time = time.time()\n\n        # Predict for num_samples times\n        points_collector = []\n        pd_labels_collector = []\n\n        # Get data\n        start_time = time.time()\n        points_centered, points = kitti_file_data.get_batch_of_one_z_box_from_origin(\n            num_points_per_sample=hyper_params[""num_point""]\n        )\n        if len(points_centered) > max_batch_size:\n            raise NotImplementedError(""TODO: iterate batches if > max_batch_size"")\n        timer[""load_data""] += time.time() - start_time\n\n        # Predict and interpolate\n        start_time = time.time()\n        dense_points = kitti_file_data.points\n        dense_labels, dense_colors = predictor.predict_and_interpolate(\n            sparse_points_centered_batched=points_centered,  # (batch_size, num_sparse_points, 3)\n            sparse_points_batched=points,  # (batch_size, num_sparse_points, 3)\n            dense_points=dense_points,  # (num_dense_points, 3)\n        )\n        timer[""predict_interpolate""] += time.time() - start_time\n\n        # Visualize\n        start_time = time.time()\n        dense_pcd.points = open3d.Vector3dVector(dense_points)\n        dense_pcd.colors = open3d.Vector3dVector(dense_colors.astype(np.float64))\n        vis.update_geometry()\n        if to_reset_view_point:\n            vis.reset_view_point(True)\n            to_reset_view_point = False\n        vis.poll_events()\n        vis.update_renderer()\n        timer[""visualize""] += time.time() - start_time\n\n        # Save dense point cloud with predicted labels\n        if flags.save:\n            start_time = time.time()\n            file_prefix = os.path.basename(kitti_file_data.file_path_without_ext)\n\n            dense_pcd = open3d.PointCloud()\n            dense_pcd.points = open3d.Vector3dVector(dense_points.reshape((-1, 3)))\n            dense_pcd_path = os.path.join(dense_output_dir, file_prefix + "".pcd"")\n            open3d.write_point_cloud(dense_pcd_path, dense_pcd)\n            print(""Exported dense_pcd to {}"".format(dense_pcd_path))\n\n            dense_labels_path = os.path.join(dense_output_dir, file_prefix + "".labels"")\n            np.savetxt(dense_labels_path, dense_labels, fmt=""%d"")\n            print(""Exported dense_labels to {}"".format(dense_labels_path))\n            timer[""write_data""] += time.time() - start_time\n\n        timer[""total""] += time.time() - global_start_time\n\n        # Print timer\n        fmt_string = ""[{:5.2f} FPS] "" + "": {:.04f}, "".join(timer.keys()) + "": {:.04f}""\n        fmt_values = [1.0 / timer[""total""]] + list(timer.values())\n        print(fmt_string.format(*fmt_values))\n'"
kitti_visualize.py,0,"b'import pykitti\nimport open3d\nimport time\nimport argparse\n\nif __name__ == ""__main__"":\n    # Parser\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        ""--kitti_root"", default="""", help=""Checkpoint file"", required=True\n    )\n    flags = parser.parse_args()\n\n    basedir = flags.kitti_root\n    date = ""2011_09_26""\n    drive = ""0001""\n\n    pcd = open3d.PointCloud()\n    vis = open3d.Visualizer()\n    vis.create_window()\n    vis.add_geometry(pcd)\n\n    render_option = vis.get_render_option()\n    render_option.point_size = 0.01\n\n    data = pykitti.raw(basedir, date, drive)\n    to_reset_view_point = True\n    for points_with_intensity in data.velo:\n        points = points_with_intensity[:, :3]\n        pcd.points = open3d.Vector3dVector(points)\n\n        vis.update_geometry()\n        if to_reset_view_point:\n            vis.reset_view_point(True)\n            to_reset_view_point = False\n        vis.poll_events()\n        vis.update_renderer()\n        time.sleep(0.2)\n\n    vis.destroy_window()\n'"
model.py,9,"b'import os.path\nimport sys\n\nROOT_DIR = os.path.abspath(os.path.pardir)\nsys.path.append(ROOT_DIR)\n\nimport tensorflow as tf\nimport util.tf_util as tf_util\nfrom util.pointnet_util import pointnet_sa_module, pointnet_fp_module\n\n\ndef get_placeholders(num_point, hyperparams):\n    feature_size = 3 * int(hyperparams[""use_color""])\n    pointclouds_pl = tf.placeholder(\n        tf.float32, shape=(None, num_point, 3 + feature_size)\n    )\n    labels_pl = tf.placeholder(tf.int32, shape=(None, num_point))\n    smpws_pl = tf.placeholder(tf.float32, shape=(None, num_point))\n    return pointclouds_pl, labels_pl, smpws_pl\n\n\ndef get_model(point_cloud, is_training, num_class, hyperparams, bn_decay=None):\n    """""" Semantic segmentation PointNet, input is BxNx3, output Bxnum_class """"""\n    end_points = {}\n\n    if hyperparams[""use_color""]:\n        feature_size = 3 * int(hyperparams[""use_color""])\n        l0_xyz = tf.slice(point_cloud, [0, 0, 0], [-1, -1, 3])\n        l0_points = tf.slice(point_cloud, [0, 0, 3], [-1, -1, feature_size])\n    else:\n        l0_xyz = point_cloud\n        l0_points = None\n    end_points[""l0_xyz""] = l0_xyz\n\n    # Layer 1\n    l1_xyz, l1_points, l1_indices = pointnet_sa_module(\n        l0_xyz,\n        l0_points,\n        npoint=hyperparams[""l1_npoint""],\n        radius=hyperparams[""l1_radius""],\n        nsample=hyperparams[""l1_nsample""],\n        mlp=[32, 32, 64],\n        mlp2=None,\n        group_all=False,\n        is_training=is_training,\n        bn_decay=bn_decay,\n        scope=""layer1"",\n    )\n    l2_xyz, l2_points, l2_indices = pointnet_sa_module(\n        l1_xyz,\n        l1_points,\n        npoint=hyperparams[""l2_npoint""],\n        radius=hyperparams[""l2_radius""],\n        nsample=hyperparams[""l2_nsample""],\n        mlp=[64, 64, 128],\n        mlp2=None,\n        group_all=False,\n        is_training=is_training,\n        bn_decay=bn_decay,\n        scope=""layer2"",\n    )\n    l3_xyz, l3_points, l3_indices = pointnet_sa_module(\n        l2_xyz,\n        l2_points,\n        npoint=hyperparams[""l3_npoint""],\n        radius=hyperparams[""l3_radius""],\n        nsample=hyperparams[""l3_nsample""],\n        mlp=[128, 128, 256],\n        mlp2=None,\n        group_all=False,\n        is_training=is_training,\n        bn_decay=bn_decay,\n        scope=""layer3"",\n    )\n    l4_xyz, l4_points, l4_indices = pointnet_sa_module(\n        l3_xyz,\n        l3_points,\n        npoint=hyperparams[""l4_npoint""],\n        radius=hyperparams[""l4_radius""],\n        nsample=hyperparams[""l4_nsample""],\n        mlp=[256, 256, 512],\n        mlp2=None,\n        group_all=False,\n        is_training=is_training,\n        bn_decay=bn_decay,\n        scope=""layer4"",\n    )\n\n    # Feature Propagation layers\n    l3_points = pointnet_fp_module(\n        l3_xyz,\n        l4_xyz,\n        l3_points,\n        l4_points,\n        [256, 256],\n        is_training,\n        bn_decay,\n        scope=""fa_layer1"",\n    )\n    l2_points = pointnet_fp_module(\n        l2_xyz,\n        l3_xyz,\n        l2_points,\n        l3_points,\n        [256, 256],\n        is_training,\n        bn_decay,\n        scope=""fa_layer2"",\n    )\n    l1_points = pointnet_fp_module(\n        l1_xyz,\n        l2_xyz,\n        l1_points,\n        l2_points,\n        [256, 128],\n        is_training,\n        bn_decay,\n        scope=""fa_layer3"",\n    )\n    l0_points = pointnet_fp_module(\n        l0_xyz,\n        l1_xyz,\n        l0_points,\n        l1_points,\n        [128, 128, 128],\n        is_training,\n        bn_decay,\n        scope=""fa_layer4"",\n    )\n\n    # FC layers\n    net = tf_util.conv1d(\n        l0_points,\n        128,\n        1,\n        padding=""VALID"",\n        bn=True,\n        is_training=is_training,\n        scope=""fc1"",\n        bn_decay=bn_decay,\n    )\n    end_points[""feats""] = net\n    net = tf_util.dropout(net, keep_prob=0.5, is_training=is_training, scope=""dp1"")\n    net = tf_util.conv1d(\n        net, num_class, 1, padding=""VALID"", activation_fn=None, scope=""fc2""\n    )\n\n    return net, end_points\n\n\n# For get_loss I added the end_points parameter. Like in pointnet2_cls_ssg.py, it\'s not used in the function.\ndef get_loss(pred, label, smpw, end_points):\n    """""" pred: BxNxC, #one score per class per batch element (N is the nb of points)\n        label: BxN,  #one label per batch element\n\tsmpw: BxN """"""\n    classify_loss = tf.losses.sparse_softmax_cross_entropy(\n        labels=label, logits=pred, weights=smpw\n    )\n    tf.summary.scalar(""classify loss"", classify_loss)\n    tf.add_to_collection(""losses"", classify_loss)\n    return classify_loss\n'"
predict.py,12,"b'import argparse\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nimport open3d\nimport time\n\nimport model\nfrom dataset.semantic_dataset import SemanticDataset\nfrom util.metric import ConfusionMatrix\nfrom tf_ops.tf_interpolate import interpolate_label_with_color\n\n\nclass Predictor:\n    def __init__(self, checkpoint_path, num_classes, hyper_params):\n        # Get ops from graph\n        with tf.device(""/gpu:0""):\n            # Placeholder\n            pl_points, _, _ = model.get_placeholders(\n                hyper_params[""num_point""], hyperparams=hyper_params\n            )\n            pl_is_training = tf.placeholder(tf.bool, shape=())\n            print(""pl_points shape"", tf.shape(pl_points))\n\n            # Prediction\n            pred, _ = model.get_model(\n                pl_points, pl_is_training, num_classes, hyperparams=hyper_params\n            )\n\n            # Saver\n            saver = tf.train.Saver()\n\n            # Graph for interpolating labels\n            # Assuming batch_size == 1 for simplicity\n            pl_sparse_points = tf.placeholder(tf.float32, (None, 3))\n            pl_sparse_labels = tf.placeholder(tf.int32, (None,))\n            pl_dense_points = tf.placeholder(tf.float32, (None, 3))\n            pl_knn = tf.placeholder(tf.int32, ())\n            dense_labels, dense_colors = interpolate_label_with_color(\n                pl_sparse_points, pl_sparse_labels, pl_dense_points, pl_knn\n            )\n\n        self.ops = {\n            ""pl_points"": pl_points,\n            ""pl_is_training"": pl_is_training,\n            ""pred"": pred,\n            ""pl_sparse_points"": pl_sparse_points,\n            ""pl_sparse_labels"": pl_sparse_labels,\n            ""pl_dense_points"": pl_dense_points,\n            ""pl_knn"": pl_knn,\n            ""dense_labels"": dense_labels,\n            ""dense_colors"": dense_colors,\n        }\n\n        # Restore checkpoint to session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        self.sess = tf.Session(config=config)\n        saver.restore(self.sess, checkpoint_path)\n        print(""Model restored"")\n\n    def predict(self, batch_data, run_metadata=None, run_options=None):\n        """"""\n        Args:\n            batch_data: batch_size * num_point * 6(3)\n\n        Returns:\n            pred_labels: batch_size * num_point * 1\n        """"""\n        is_training = False\n        feed_dict = {\n            self.ops[""pl_points""]: batch_data,\n            self.ops[""pl_is_training""]: is_training,\n        }\n        if run_metadata is None:\n            run_metadata = tf.RunMetadata()\n        if run_options is None:\n            run_options = tf.RunOptions()\n\n        pred_val = self.sess.run(\n            [self.ops[""pred""]],\n            options=run_options,\n            run_metadata=run_metadata,\n            feed_dict=feed_dict,\n        )\n        pred_val = pred_val[0]  # batch_size * num_point * 1\n        pred_labels = np.argmax(pred_val, 2)  # batch_size * num_point * 1\n        return pred_labels\n\n    def interpolate_labels(self, sparse_points, sparse_labels, dense_points):\n        s = time.time()\n        dense_labels, dense_colors = self.sess.run(\n            self.ops[""sparse_indices""],\n            feed_dict={\n                self.ops[""pl_sparse_points""]: sparse_points,\n                self.ops[""pl_sparse_labels""]: sparse_labels,\n                self.ops[""pl_dense_points""]: dense_points,\n                self.ops[""pl_knn""]: 3,\n            },\n        )\n        print(""sess.run interpolate_labels time"", time.time() - s)\n        return dense_labels, dense_colors\n\n\nif __name__ == ""__main__"":\n    np.random.seed(0)\n\n    # Parser\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        ""--num_samples"",\n        type=int,\n        default=8,\n        help=""# samples, each contains num_point points_centered"",\n    )\n    parser.add_argument(""--ckpt"", default="""", help=""Checkpoint file"")\n    parser.add_argument(""--set"", default=""validation"", help=""train, validation, test"")\n    flags = parser.parse_args()\n    hyper_params = json.loads(open(""semantic.json"").read())\n\n    # Create output dir\n    output_dir = os.path.join(""result"", ""sparse"")\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Dataset\n    dataset = SemanticDataset(\n        num_points_per_sample=hyper_params[""num_point""],\n        split=flags.set,\n        box_size_x=hyper_params[""box_size_x""],\n        box_size_y=hyper_params[""box_size_y""],\n        use_color=hyper_params[""use_color""],\n        path=hyper_params[""data_path""],\n    )\n\n    # Model\n    batch_size = 64\n    predictor = Predictor(\n        checkpoint_path=flags.ckpt,\n        num_classes=dataset.num_classes,\n        hyper_params=hyper_params,\n    )\n\n    # Process each file\n    cm = ConfusionMatrix(9)\n\n    for semantic_file_data in dataset.list_file_data:\n        print(""Processing {}"".format(semantic_file_data))\n\n        # Predict for num_samples times\n        points_collector = []\n        pd_labels_collector = []\n\n        # If flags.num_samples < batch_size, will predict one batch\n        for batch_index in range(int(np.ceil(flags.num_samples / batch_size))):\n            current_batch_size = min(\n                batch_size, flags.num_samples - batch_index * batch_size\n            )\n\n            # Get data\n            points_centered, points, gt_labels, colors = semantic_file_data.sample_batch(\n                batch_size=current_batch_size,\n                num_points_per_sample=hyper_params[""num_point""],\n            )\n\n            # (bs, 8192, 3) concat (bs, 8192, 3) -> (bs, 8192, 6)\n            if hyper_params[""use_color""]:\n                points_centered_with_colors = np.concatenate(\n                    (points_centered, colors), axis=-1\n                )\n            else:\n                points_centered_with_colors = points_centered\n\n            # Predict\n            s = time.time()\n            pd_labels = predictor.predict(points_centered_with_colors)\n            print(\n                ""Batch size: {}, time: {}"".format(current_batch_size, time.time() - s)\n            )\n\n            # Save to collector for file output\n            points_collector.extend(points)\n            pd_labels_collector.extend(pd_labels)\n\n            # Increment confusion matrix\n            cm.increment_from_list(gt_labels.flatten(), pd_labels.flatten())\n\n        # Save sparse point cloud and predicted labels\n        file_prefix = os.path.basename(semantic_file_data.file_path_without_ext)\n\n        sparse_points = np.array(points_collector).reshape((-1, 3))\n        pcd = open3d.PointCloud()\n        pcd.points = open3d.Vector3dVector(sparse_points)\n        pcd_path = os.path.join(output_dir, file_prefix + "".pcd"")\n        open3d.write_point_cloud(pcd_path, pcd)\n        print(""Exported sparse pcd to {}"".format(pcd_path))\n\n        sparse_labels = np.array(pd_labels_collector).astype(int).flatten()\n        pd_labels_path = os.path.join(output_dir, file_prefix + "".labels"")\n        np.savetxt(pd_labels_path, sparse_labels, fmt=""%d"")\n        print(""Exported sparse labels to {}"".format(pd_labels_path))\n\n    cm.print_metrics()\n'"
preprocess.py,0,"b'import os\nimport subprocess\nimport shutil\nimport open3d\n\nfrom dataset.semantic_dataset import all_file_prefixes\n\n\ndef wc(file_name):\n    out = subprocess.Popen(\n        [""wc"", ""-l"", file_name], stdout=subprocess.PIPE, stderr=subprocess.STDOUT\n    ).communicate()[0]\n    return int(out.partition(b"" "")[0])\n\n\ndef prepend_line(file_name, line):\n    with open(file_name, ""r+"") as f:\n        content = f.read()\n        f.seek(0, 0)\n        f.write(line.rstrip(""\\r\\n"") + ""\\n"" + content)\n\n\ndef point_cloud_txt_to_pcd(raw_dir, file_prefix):\n    # File names\n    txt_file = os.path.join(raw_dir, file_prefix + "".txt"")\n    pts_file = os.path.join(raw_dir, file_prefix + "".pts"")\n    pcd_file = os.path.join(raw_dir, file_prefix + "".pcd"")\n\n    # Skip if already done\n    if os.path.isfile(pcd_file):\n        print(""pcd {} exists, skipped"".format(pcd_file))\n        return\n\n    # .txt to .pts\n    # We could just prepend the line count, however, there are some intensity value\n    # which are non-integers.\n    print(""[txt->pts]"")\n    print(""txt: {}"".format(txt_file))\n    print(""pts: {}"".format(pts_file))\n    with open(txt_file, ""r"") as txt_f, open(pts_file, ""w"") as pts_f:\n        for line in txt_f:\n            # x, y, z, i, r, g, b\n            tokens = line.split()\n            tokens[3] = str(int(float(tokens[3])))\n            line = "" "".join(tokens)\n            pts_f.write(line + ""\\n"")\n    prepend_line(pts_file, str(wc(txt_file)))\n\n    # .pts -> .pcd\n    print(""[pts->pcd]"")\n    print(""pts: {}"".format(pts_file))\n    print(""pcd: {}"".format(pcd_file))\n    point_cloud = open3d.read_point_cloud(pts_file)\n    open3d.write_point_cloud(pcd_file, point_cloud)\n    os.remove(pts_file)\n\n\nif __name__ == ""__main__"":\n    # By default\n    # raw data: ""dataset/semantic_raw""\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    dataset_dir = os.path.join(current_dir, ""dataset"")\n    raw_dir = os.path.join(dataset_dir, ""semantic_raw"")\n\n    for file_prefix in all_file_prefixes:\n        point_cloud_txt_to_pcd(raw_dir, file_prefix)\n'"
renamer.py,0,"b'""""""\nRename the prediction label files for submission\n""""""\n\nimport os\nimport glob\n\n\nconversion_dict = {\n    ""birdfountain_station1_xyz_intensity_rgb.labels"": ""birdfountain1.labels"",\n    ""castleblatten_station1_intensity_rgb.labels"": ""castleblatten1.labels"",\n    ""castleblatten_station5_xyz_intensity_rgb.labels"": ""castleblatten5.labels"",\n    ""marketplacefeldkirch_station1_intensity_rgb.labels"": ""marketsquarefeldkirch1.labels"",\n    ""marketplacefeldkirch_station4_intensity_rgb.labels"": ""marketsquarefeldkirch4.labels"",\n    ""marketplacefeldkirch_station7_intensity_rgb.labels"": ""marketsquarefeldkirch7.labels"",\n    ""sg27_station10_intensity_rgb.labels"": ""sg27_10.labels"",\n    ""sg27_station3_intensity_rgb.labels"": ""sg27_3.labels"",\n    ""sg27_station6_intensity_rgb.labels"": ""sg27_6.labels"",\n    ""sg27_station8_intensity_rgb.labels"": ""sg27_8.labels"",\n    ""sg28_station2_intensity_rgb.labels"": ""sg28_2.labels"",\n    ""sg28_station5_xyz_intensity_rgb.labels"": ""sg28_5.labels"",\n    ""stgallencathedral_station1_intensity_rgb.labels"": ""stgallencathedral1.labels"",\n    ""stgallencathedral_station3_intensity_rgb.labels"": ""stgallencathedral3.labels"",\n    ""stgallencathedral_station6_intensity_rgb.labels"": ""stgallencathedral6.labels"",\n}\n\n\nif __name__ == ""__main__"":\n    # for src_path in glob.glob(""result_archive/result_dec_03_full_trainset/dense/*""):\n    for src_path in glob.glob(""result/dense/*""):\n        dir_name = os.path.dirname(src_path)\n        src_name = os.path.basename(src_path)\n        dst_name = conversion_dict.get(src_name, None)\n        if dst_name is not None:\n            dst_path = os.path.join(dir_name, dst_name)\n            os.rename(src_path, dst_path)\n            print(""Moved {} to {}"".format(src_path, dst_path))\n        else:\n            print(""src_name not found in conversion_dict:"", src_name)\n'"
train.py,38,"b'import os\nimport sys\nimport json\nimport datetime\nimport numpy as np\nimport tensorflow as tf\nimport multiprocessing as mp\nimport argparse\nimport time\nfrom datetime import datetime\n\nimport util.metric as metric\nimport model\nfrom dataset.semantic_dataset import SemanticDataset\n\n# Two global arg collections\nparser = argparse.ArgumentParser()\nparser.add_argument(""--train_set"", default=""train"", help=""train, train_full"")\nparser.add_argument(""--config_file"", default=""semantic.json"", help=""config file path"")\n\nFLAGS = parser.parse_args()\nPARAMS = json.loads(open(FLAGS.config_file).read())\nos.makedirs(PARAMS[""logdir""], exist_ok=True)\n\n# Import dataset\nTRAIN_DATASET = SemanticDataset(\n    num_points_per_sample=PARAMS[""num_point""],\n    split=FLAGS.train_set,\n    box_size_x=PARAMS[""box_size_x""],\n    box_size_y=PARAMS[""box_size_y""],\n    use_color=PARAMS[""use_color""],\n    path=PARAMS[""data_path""],\n)\nVALIDATION_DATASET = SemanticDataset(\n    num_points_per_sample=PARAMS[""num_point""],\n    split=""validation"",\n    box_size_x=PARAMS[""box_size_x""],\n    box_size_y=PARAMS[""box_size_y""],\n    use_color=PARAMS[""use_color""],\n    path=PARAMS[""data_path""],\n)\nNUM_CLASSES = TRAIN_DATASET.num_classes\n\n# Start logging\nLOG_FOUT = open(os.path.join(PARAMS[""logdir""], ""log_train.txt""), ""w"")\nEPOCH_CNT = 0\n\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str + ""\\n"")\n    LOG_FOUT.flush()\n    print(out_str)\n\n\ndef update_progress(progress):\n    """"""\n    Displays or updates a console progress bar\n    Args:\n        progress: A float between 0 and 1. Any int will be converted to a float.\n                  A value under 0 represents a \'halt\'.\n                  A value at 1 or bigger represents 100%\n    """"""\n    barLength = 10  # Modify this to change the length of the progress bar\n    if isinstance(progress, int):\n        progress = round(float(progress), 2)\n    if not isinstance(progress, float):\n        progress = 0\n    if progress < 0:\n        progress = 0\n    if progress >= 1:\n        progress = 1\n    block = int(round(barLength * progress))\n    text = ""\\rProgress: [{}] {}%"".format(\n        ""#"" * block + ""-"" * (barLength - block), progress * 100\n    )\n    sys.stdout.write(text)\n    sys.stdout.flush()\n\n\ndef get_learning_rate(batch):\n    """"""Compute the learning rate for a given batch size and global parameters\n\n    Args:\n        batch (tf.Variable): the batch size\n\n    Returns:\n        scalar tf.Tensor: the decayed learning rate\n    """"""\n\n    learning_rate = tf.train.exponential_decay(\n        PARAMS[""learning_rate""],  # Base learning rate.\n        batch * PARAMS[""batch_size""],  # Current index into the dataset.\n        PARAMS[""decay_step""],  # Decay step.\n        PARAMS[""learning_rate_decay_rate""],  # Decay rate.\n        staircase=True,\n    )\n    learning_rate = tf.maximum(learning_rate, 0.00001)  # CLIP THE LEARNING RATE!\n    return learning_rate\n\n\ndef get_bn_decay(batch):\n    """"""Compute the batch normalisation exponential decay\n\n    Args:\n        batch (tf.Variable): the batch size\n\n    Returns:\n        scalar tf.Tensor: the batch norm decay\n    """"""\n\n    bn_momentum = tf.train.exponential_decay(\n        PARAMS[""bn_init_decay""],\n        batch * PARAMS[""batch_size""],\n        float(PARAMS[""decay_step""]),\n        PARAMS[""bn_decay_decay_rate""],\n        staircase=True,\n    )\n    bn_decay = tf.minimum(PARAMS[""bn_decay_clip""], 1 - bn_momentum)\n    return bn_decay\n\n\ndef get_batch(split):\n    np.random.seed()\n    if split == ""train"":\n        return TRAIN_DATASET.sample_batch_in_all_files(\n            PARAMS[""batch_size""], augment=True\n        )\n    else:\n        return VALIDATION_DATASET.sample_batch_in_all_files(\n            PARAMS[""batch_size""], augment=False\n        )\n\n\ndef fill_queues(\n    stack_train, stack_validation, num_train_batches, num_validation_batches\n):\n    """"""\n    Args:\n        stack_train: mp.Queue to be filled asynchronously\n        stack_validation: mp.Queue to be filled asynchronously\n        num_train_batches: total number of training batches\n        num_validation_batches: total number of validationation batches\n    """"""\n    pool = mp.Pool(processes=mp.cpu_count())\n    launched_train = 0\n    launched_validation = 0\n    results_train = []  # Temp buffer before filling the stack_train\n    results_validation = []  # Temp buffer before filling the stack_validation\n    # Launch as much as n\n    while True:\n        if stack_train.qsize() + launched_train < num_train_batches:\n            results_train.append(pool.apply_async(get_batch, args=(""train"",)))\n            launched_train += 1\n        elif stack_validation.qsize() + launched_validation < num_validation_batches:\n            results_validation.append(pool.apply_async(get_batch, args=(""validation"",)))\n            launched_validation += 1\n        for p in results_train:\n            if p.ready():\n                stack_train.put(p.get())\n                results_train.remove(p)\n                launched_train -= 1\n        for p in results_validation:\n            if p.ready():\n                stack_validation.put(p.get())\n                results_validation.remove(p)\n                launched_validation -= 1\n        # Stability\n        time.sleep(0.01)\n\n\ndef init_stacking():\n    """"""\n    Returns:\n        stacker: mp.Process object\n        stack_validation: mp.Queue, use stack_validation.get() to read a batch\n        stack_train: mp.Queue, use stack_train.get() to read a batch\n    """"""\n    with tf.device(""/cpu:0""):\n        # Queues that contain several batches in advance\n        num_train_batches = TRAIN_DATASET.get_num_batches(PARAMS[""batch_size""])\n        num_validation_batches = VALIDATION_DATASET.get_num_batches(\n            PARAMS[""batch_size""]\n        )\n        stack_train = mp.Queue(num_train_batches)\n        stack_validation = mp.Queue(num_validation_batches)\n        stacker = mp.Process(\n            target=fill_queues,\n            args=(\n                stack_train,\n                stack_validation,\n                num_train_batches,\n                num_validation_batches,\n            ),\n        )\n        stacker.start()\n        return stacker, stack_validation, stack_train\n\n\ndef train_one_epoch(sess, ops, train_writer, stack):\n    """"""Train one epoch\n\n    Args:\n        sess (tf.Session): the session to evaluate Tensors and ops\n        ops (dict of tf.Operation): contain multiple operation mapped with with strings\n        train_writer (tf.FileSaver): enable to log the training with TensorBoard\n        compute_class_iou (bool): it takes time to compute the iou per class, so you can\n                                  disable it here\n    """"""\n\n    is_training = True\n\n    num_batches = TRAIN_DATASET.get_num_batches(PARAMS[""batch_size""])\n\n    log_string(str(datetime.now()))\n    update_progress(0)\n    # Reset metrics\n    loss_sum = 0\n    confusion_matrix = metric.ConfusionMatrix(NUM_CLASSES)\n\n    # Train over num_batches batches\n    for batch_idx in range(num_batches):\n        # Refill more batches if empty\n        progress = float(batch_idx) / float(num_batches)\n        update_progress(round(progress, 2))\n        batch_data, batch_label, batch_weights = stack.get()\n\n        # Get predicted labels\n        feed_dict = {\n            ops[""pointclouds_pl""]: batch_data,\n            ops[""labels_pl""]: batch_label,\n            ops[""smpws_pl""]: batch_weights,\n            ops[""is_training_pl""]: is_training,\n        }\n        summary, step, _, loss_val, pred_val, _ = sess.run(\n            [\n                ops[""merged""],\n                ops[""step""],\n                ops[""train_op""],\n                ops[""loss""],\n                ops[""pred""],\n                ops[""update_iou""],\n            ],\n            feed_dict=feed_dict,\n        )\n        train_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 2)\n\n        # Update metrics\n        for i in range(len(pred_val)):\n            for j in range(len(pred_val[i])):\n                confusion_matrix.increment(batch_label[i][j], pred_val[i][j])\n        loss_sum += loss_val\n    update_progress(1)\n    log_string(""mean loss: %f"" % (loss_sum / float(num_batches)))\n    log_string(""Overall accuracy : %f"" % (confusion_matrix.get_accuracy()))\n    log_string(""Average IoU : %f"" % (confusion_matrix.get_mean_iou()))\n    iou_per_class = confusion_matrix.get_per_class_ious()\n    iou_per_class = [0] + iou_per_class  # label 0 is ignored\n    for i in range(1, NUM_CLASSES):\n        log_string(""IoU of %s : %f"" % (TRAIN_DATASET.labels_names[i], iou_per_class[i]))\n\n\ndef eval_one_epoch(sess, ops, validation_writer, stack):\n    """"""Evaluate one epoch\n\n    Args:\n        sess (tf.Session): the session to evaluate tensors and operations\n        ops (tf.Operation): the dict of operations\n        validation_writer (tf.summary.FileWriter): enable to log the evaluation on TensorBoard\n\n    Returns:\n        float: the overall accuracy computed on the validationation set\n    """"""\n\n    global EPOCH_CNT\n\n    is_training = False\n\n    num_batches = VALIDATION_DATASET.get_num_batches(PARAMS[""batch_size""])\n\n    # Reset metrics\n    loss_sum = 0\n    confusion_matrix = metric.ConfusionMatrix(NUM_CLASSES)\n\n    log_string(str(datetime.now()))\n\n    log_string(""---- EPOCH %03d EVALUATION ----"" % (EPOCH_CNT))\n\n    update_progress(0)\n\n    for batch_idx in range(num_batches):\n        progress = float(batch_idx) / float(num_batches)\n        update_progress(round(progress, 2))\n        batch_data, batch_label, batch_weights = stack.get()\n\n        feed_dict = {\n            ops[""pointclouds_pl""]: batch_data,\n            ops[""labels_pl""]: batch_label,\n            ops[""smpws_pl""]: batch_weights,\n            ops[""is_training_pl""]: is_training,\n        }\n        summary, step, loss_val, pred_val = sess.run(\n            [ops[""merged""], ops[""step""], ops[""loss""], ops[""pred""]], feed_dict=feed_dict\n        )\n\n        validation_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 2)  # BxN\n\n        # Update metrics\n        for i in range(len(pred_val)):\n            for j in range(len(pred_val[i])):\n                confusion_matrix.increment(batch_label[i][j], pred_val[i][j])\n        loss_sum += loss_val\n\n    update_progress(1)\n\n    iou_per_class = confusion_matrix.get_per_class_ious()\n\n    # Display metrics\n    log_string(""mean loss: %f"" % (loss_sum / float(num_batches)))\n    log_string(""Overall accuracy : %f"" % (confusion_matrix.get_accuracy()))\n    log_string(""Average IoU : %f"" % (confusion_matrix.get_mean_iou()))\n    iou_per_class = [0] + iou_per_class  # label 0 is ignored\n    for i in range(1, NUM_CLASSES):\n        log_string(\n            ""IoU of %s : %f"" % (VALIDATION_DATASET.labels_names[i], iou_per_class[i])\n        )\n\n    EPOCH_CNT += 5\n    return confusion_matrix.get_accuracy()\n\n\ndef train():\n    """"""Train the model on a single GPU\n    """"""\n    with tf.Graph().as_default():\n        stacker, stack_validation, stack_train = init_stacking()\n\n        with tf.device(""/gpu:"" + str(PARAMS[""gpu""])):\n            pointclouds_pl, labels_pl, smpws_pl = model.get_placeholders(\n                PARAMS[""num_point""], hyperparams=PARAMS\n            )\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n\n            # Note the global_step=batch parameter to minimize.\n            # That tells the optimizer to helpfully increment the \'batch\' parameter for\n            # you every time it trains.\n            batch = tf.Variable(0)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar(""bn_decay"", bn_decay)\n\n            print(""--- Get model and loss"")\n            # Get model and loss\n            pred, end_points = model.get_model(\n                pointclouds_pl,\n                is_training_pl,\n                NUM_CLASSES,\n                hyperparams=PARAMS,\n                bn_decay=bn_decay,\n            )\n            loss = model.get_loss(pred, labels_pl, smpws_pl, end_points)\n            tf.summary.scalar(""loss"", loss)\n\n            # Compute accuracy\n            correct = tf.equal(tf.argmax(pred, 2), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(\n                PARAMS[""batch_size""] * PARAMS[""num_point""]\n            )\n            tf.summary.scalar(""accuracy"", accuracy)\n\n            # Computer mean intersection over union\n            mean_intersection_over_union, update_iou_op = tf.metrics.mean_iou(\n                tf.to_int32(labels_pl), tf.to_int32(tf.argmax(pred, 2)), NUM_CLASSES\n            )\n            tf.summary.scalar(""mIoU"", tf.to_float(mean_intersection_over_union))\n\n            print(""--- Get training operator"")\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar(""learning_rate"", learning_rate)\n            if PARAMS[""optimizer""] == ""momentum"":\n                optimizer = tf.train.MomentumOptimizer(\n                    learning_rate, momentum=PARAMS[""momentum""]\n                )\n            else:\n                assert PARAMS[""optimizer""] == ""adam""\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            train_op = optimizer.minimize(loss, global_step=batch)\n\n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n\n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(\n            os.path.join(PARAMS[""logdir""], ""train""), sess.graph\n        )\n        validation_writer = tf.summary.FileWriter(\n            os.path.join(PARAMS[""logdir""], ""validation""), sess.graph\n        )\n\n        # Init variables\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.local_variables_initializer())  # important for mIoU\n\n        ops = {\n            ""pointclouds_pl"": pointclouds_pl,\n            ""labels_pl"": labels_pl,\n            ""smpws_pl"": smpws_pl,\n            ""is_training_pl"": is_training_pl,\n            ""pred"": pred,\n            ""loss"": loss,\n            ""train_op"": train_op,\n            ""merged"": merged,\n            ""step"": batch,\n            ""end_points"": end_points,\n            ""update_iou"": update_iou_op,\n        }\n\n        # Train for hyper_params[""max_epoch""] epochs\n        best_acc = 0\n        for epoch in range(PARAMS[""max_epoch""]):\n            print(""in epoch"", epoch)\n            print(""max_epoch"", PARAMS[""max_epoch""])\n\n            log_string(""**** EPOCH %03d ****"" % (epoch))\n            sys.stdout.flush()\n\n            # Train one epoch\n            train_one_epoch(sess, ops, train_writer, stack_train)\n\n            # Evaluate, save, and compute the accuracy\n            if epoch % 5 == 0:\n                acc = eval_one_epoch(sess, ops, validation_writer, stack_validation)\n\n            if acc > best_acc:\n                best_acc = acc\n                save_path = saver.save(\n                    sess,\n                    os.path.join(\n                        PARAMS[""logdir""], ""best_model_epoch_%03d.ckpt"" % (epoch)\n                    ),\n                )\n                log_string(""Model saved in file: %s"" % save_path)\n                print(""Model saved in file: %s"" % save_path)\n\n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(\n                    sess, os.path.join(PARAMS[""logdir""], ""model.ckpt"")\n                )\n                log_string(""Model saved in file: %s"" % save_path)\n                print(""Model saved in file: %s"" % save_path)\n\n        # Kill the process, close the file and exit\n        stacker.terminate()\n        LOG_FOUT.close()\n        sys.exit()\n\n\nif __name__ == ""__main__"":\n    train()\n'"
visualize.py,0,"b'import open3d\nimport argparse\nimport os\nfrom util.point_cloud_util import load_labels, colorize_point_cloud\nimport numpy as np\nfrom util.provider import rotate_point_cloud, rotate_feature_point_cloud\n\n\nif __name__ == ""__main__"":\n    # Parser\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--pcd_path"", default="""", type=str)\n    parser.add_argument(""--labels_path"", default="""", type=str)\n    flags = parser.parse_args()\n\n    # Load point cloud\n    if not os.path.isfile(flags.pcd_path):\n        raise ValueError(""pcd path not found at {}"".format(flags.pcd_path))\n    pcd = open3d.read_point_cloud(flags.pcd_path)\n\n    # pcd = open3d.crop_point_cloud(pcd, [-30, -10, -2], [30, 10, 100])\n    # batched_points = np.expand_dims(np.asarray(pcd.points), axis=0)\n    # batched_points = rotate_point_cloud(batched_points, rotation_axis=""y"")\n    # pcd.points = open3d.Vector3dVector(batched_points[0])\n\n    # Load labels and colorize pcd, if labels available\n    if flags.labels_path != """":\n        if not os.path.isfile(flags.pcd_path):\n            raise ValueError(""labels path not found at {}"".format(flags.labels_path))\n        labels = load_labels(flags.labels_path)\n        colorize_point_cloud(pcd, labels)\n\n    # points = np.asarray(pcd.points)\n    # colors = np.asarray(pcd.colors)\n    # points_with_colors = np.concatenate((points, colors), axis=1)\n    # points_with_colors = rotate_feature_point_cloud(points_with_colors)\n    # points = points_with_colors[:, :3]\n    # colors = points_with_colors[:, 3:]\n    # pcd.points = open3d.Vector3dVector(points)\n    # pcd.colors = open3d.Vector3dVector(colors)\n\n    open3d.draw_geometries([pcd])\n'"
dataset/__init__.py,0,b''
dataset/kitti_dataset.py,0,"b'import os\nimport open3d\nimport numpy as np\nfrom dataset.semantic_dataset import SemanticFileData, SemanticDataset\nimport pykitti\n\n\nclass KittiFileData(SemanticFileData):\n    def __init__(self, points, box_size_x, box_size_y):\n        self.box_size_x = box_size_x\n        self.box_size_y = box_size_y\n\n        # Crop the region of interest centered at origin\n        # TODO: This is a special treatment, since we only care about the origin now\n        min_z = -2\n        max_z = 5\n        min_x = -self.box_size_x / 2.0\n        max_x = -min_x\n        min_y = -self.box_size_y / 2.0\n        max_y = -min_y\n        pcd = open3d.PointCloud()\n        pcd.points = open3d.Vector3dVector(points)\n        region_pcd = open3d.crop_point_cloud(\n            pcd, [min_x, min_y, min_z], [max_x, max_y, max_z]\n        )\n        self.points = np.asarray(region_pcd.points)\n\n        # Load label. In pure test set, fill with zeros.\n        self.labels = np.zeros(len(self.points)).astype(bool)\n\n        # Load colors. If not use_color, fill with zeros.\n        self.colors = np.zeros_like(self.points)\n\n        # Sort according to x to speed up computation of boxes and z-boxes\n        sort_idx = np.argsort(self.points[:, 0])\n        self.points = self.points[sort_idx]\n        self.labels = self.labels[sort_idx]\n        self.colors = self.colors[sort_idx]\n\n    def get_batch_of_one_z_box_from_origin(self, num_points_per_sample):\n        # This point cloud has already been cropped near the origin\n        # extract_mask = self._extract_z_box(np.array([0, 0, 0]))\n        # points = self.points[extract_mask]\n\n        sample_mask = self._get_fix_sized_sample_mask(\n            self.points, num_points_per_sample\n        )\n        points = self.points[sample_mask]\n\n        centered_points = self._center_box(points)\n\n        batch_points = np.expand_dims(points, 0)\n        centered_batch_points = np.expand_dims(centered_points, 0)\n        return centered_batch_points, batch_points\n\n\nclass KittiDataset(SemanticDataset):\n    def __init__(\n        self, num_points_per_sample, base_dir, dates, drives, box_size_x, box_size_y\n    ):\n        """"""Create a dataset holder\n        num_points_per_sample (int): Defaults to 8192. The number of point per sample\n        split (str): Defaults to \'train\'. The selected part of the data (train, test,\n                     reduced...)\n        color (bool): Defaults to True. Whether to use colors or not\n        box_size_x (int): Defaults to 10. The size of the extracted cube.\n        box_size_y (int): Defaults to 10. The size of the extracted cube.\n        path (float): Defaults to \'dataset/semantic_data/\'.\n        """"""\n        # Dataset parameters\n        self.num_points_per_sample = num_points_per_sample\n        self.num_classes = 9\n        self.labels_names = [\n            ""unlabeled"",\n            ""man-made terrain"",\n            ""natural terrain"",\n            ""high vegetation"",\n            ""low vegetation"",\n            ""buildings"",\n            ""hard scape"",\n            ""scanning artifact"",\n            ""cars"",\n        ]\n        self.box_size_x = box_size_x\n        self.box_size_y = box_size_y\n\n        # Load files\n        self.list_file_data = []\n        for date in dates:\n            for drive in drives:\n                print(""Loading date: {}, drive: {}"".format(date, drive))\n                pykitti_data = pykitti.raw(base_dir, date, drive)\n                frame_idx = 0\n                for points_with_intensity in pykitti_data.velo:\n                    # Get points\n                    points = points_with_intensity[:, :3]\n                    # Init file data\n                    file_data = KittiFileData(\n                        points=points, box_size_x=box_size_x, box_size_y=box_size_y\n                    )\n                    # TODO: just for compatibility reason to include the name\n                    file_data.file_path_without_ext = os.path.join(\n                        date, drive, ""{:04d}"".format(frame_idx)\n                    )\n                    frame_idx += 1\n                    self.list_file_data.append(file_data)\n'"
dataset/semantic_dataset.py,0,"b'import os\nimport open3d\nimport numpy as np\nimport util.provider as provider\nfrom util.point_cloud_util import load_labels\n\ntrain_file_prefixes = [\n    ""bildstein_station1_xyz_intensity_rgb"",\n    ""bildstein_station3_xyz_intensity_rgb"",\n    ""bildstein_station5_xyz_intensity_rgb"",\n    ""domfountain_station1_xyz_intensity_rgb"",\n    ""domfountain_station2_xyz_intensity_rgb"",\n    ""domfountain_station3_xyz_intensity_rgb"",\n    ""neugasse_station1_xyz_intensity_rgb"",\n    ""sg27_station1_intensity_rgb"",\n    ""sg27_station2_intensity_rgb"",\n]\n\nvalidation_file_prefixes = [\n    ""sg27_station4_intensity_rgb"",\n    ""sg27_station5_intensity_rgb"",\n    ""sg27_station9_intensity_rgb"",\n    ""sg28_station4_intensity_rgb"",\n    ""untermaederbrunnen_station1_xyz_intensity_rgb"",\n    ""untermaederbrunnen_station3_xyz_intensity_rgb"",\n]\n\ntest_file_prefixes = [\n    ""birdfountain_station1_xyz_intensity_rgb"",\n    ""castleblatten_station1_intensity_rgb"",\n    ""castleblatten_station5_xyz_intensity_rgb"",\n    ""marketplacefeldkirch_station1_intensity_rgb"",\n    ""marketplacefeldkirch_station4_intensity_rgb"",\n    ""marketplacefeldkirch_station7_intensity_rgb"",\n    ""sg27_station10_intensity_rgb"",\n    ""sg27_station3_intensity_rgb"",\n    ""sg27_station6_intensity_rgb"",\n    ""sg27_station8_intensity_rgb"",\n    ""sg28_station2_intensity_rgb"",\n    ""sg28_station5_xyz_intensity_rgb"",\n    ""stgallencathedral_station1_intensity_rgb"",\n    ""stgallencathedral_station3_intensity_rgb"",\n    ""stgallencathedral_station6_intensity_rgb"",\n]\n\nall_file_prefixes = train_file_prefixes + validation_file_prefixes + test_file_prefixes\n\nmap_name_to_file_prefixes = {\n    ""train"": train_file_prefixes,\n    ""train_full"": train_file_prefixes + validation_file_prefixes,\n    ""validation"": validation_file_prefixes,\n    ""test"": test_file_prefixes,\n    ""all"": all_file_prefixes,\n}\n\n\nclass SemanticFileData:\n    def __init__(\n        self, file_path_without_ext, has_label, use_color, box_size_x, box_size_y\n    ):\n        """"""\n        Loads file data\n        """"""\n        self.file_path_without_ext = file_path_without_ext\n        self.box_size_x = box_size_x\n        self.box_size_y = box_size_y\n\n        # Load points\n        pcd = open3d.read_point_cloud(file_path_without_ext + "".pcd"")\n        self.points = np.asarray(pcd.points)\n\n        # Load label. In pure test set, fill with zeros.\n        if has_label:\n            self.labels = load_labels(file_path_without_ext + "".labels"")\n        else:\n            self.labels = np.zeros(len(self.points)).astype(bool)\n\n        # Load colors. If not use_color, fill with zeros.\n        if use_color:\n            self.colors = np.asarray(pcd.colors)\n        else:\n            self.colors = np.zeros_like(self.points)\n\n        # Sort according to x to speed up computation of boxes and z-boxes\n        sort_idx = np.argsort(self.points[:, 0])\n        self.points = self.points[sort_idx]\n        self.labels = self.labels[sort_idx]\n        self.colors = self.colors[sort_idx]\n\n    def _get_fix_sized_sample_mask(self, points, num_points_per_sample):\n        """"""\n        Get down-sample or up-sample mask to sample points to num_points_per_sample\n        """"""\n        # TODO: change this to numpy\'s build-in functions\n        # Shuffling or up-sampling if needed\n        if len(points) - num_points_per_sample > 0:\n            true_array = np.ones(num_points_per_sample, dtype=bool)\n            false_array = np.zeros(len(points) - num_points_per_sample, dtype=bool)\n            sample_mask = np.concatenate((true_array, false_array), axis=0)\n            np.random.shuffle(sample_mask)\n        else:\n            # Not enough points, recopy the data until there are enough points\n            sample_mask = np.arange(len(points))\n            while len(sample_mask) < num_points_per_sample:\n                sample_mask = np.concatenate((sample_mask, sample_mask), axis=0)\n            sample_mask = sample_mask[:num_points_per_sample]\n        return sample_mask\n\n    def _center_box(self, points):\n        # Shift the box so that z = 0 is the min and x = 0 and y = 0 is the box center\n        # E.g. if box_size_x == box_size_y == 10, then the new mins are (-5, -5, 0)\n        box_min = np.min(points, axis=0)\n        shift = np.array(\n            [\n                box_min[0] + self.box_size_x / 2,\n                box_min[1] + self.box_size_y / 2,\n                box_min[2],\n            ]\n        )\n        points_centered = points - shift\n        return points_centered\n\n    def _extract_z_box(self, center_point):\n        """"""\n        Crop along z axis (vertical) from the center_point.\n\n        Args:\n            center_point: only x and y coordinates will be used\n            points: points (n * 3)\n            scene_idx: scene index to get the min and max of the whole scene\n        """"""\n        # TODO TAKES LOT OF TIME !! THINK OF AN ALTERNATIVE !\n        scene_z_size = np.max(self.points, axis=0)[2] - np.min(self.points, axis=0)[2]\n        box_min = center_point - [\n            self.box_size_x / 2,\n            self.box_size_y / 2,\n            scene_z_size,\n        ]\n        box_max = center_point + [\n            self.box_size_x / 2,\n            self.box_size_y / 2,\n            scene_z_size,\n        ]\n\n        i_min = np.searchsorted(self.points[:, 0], box_min[0])\n        i_max = np.searchsorted(self.points[:, 0], box_max[0])\n        mask = (\n            np.sum(\n                (self.points[i_min:i_max, :] >= box_min)\n                * (self.points[i_min:i_max, :] <= box_max),\n                axis=1,\n            )\n            == 3\n        )\n        mask = np.hstack(\n            (\n                np.zeros(i_min, dtype=bool),\n                mask,\n                np.zeros(len(self.points) - i_max, dtype=bool),\n            )\n        )\n\n        # mask = np.sum((points>=box_min)*(points<=box_max),axis=1) == 3\n        assert np.sum(mask) != 0\n        return mask\n\n    def sample(self, num_points_per_sample):\n        points = self.points\n\n        # Pick a point, and crop a z-box around\n        center_point = points[np.random.randint(0, len(points))]\n        scene_extract_mask = self._extract_z_box(center_point)\n        points = points[scene_extract_mask]\n        labels = self.labels[scene_extract_mask]\n        colors = self.colors[scene_extract_mask]\n\n        sample_mask = self._get_fix_sized_sample_mask(points, num_points_per_sample)\n        points = points[sample_mask]\n        labels = labels[sample_mask]\n        colors = colors[sample_mask]\n\n        # Shift the points, such that min(z) == 0, and x = 0 and y = 0 is the center\n        # This canonical column is used for both training and inference\n        points_centered = self._center_box(points)\n\n        return points_centered, points, labels, colors\n\n    def sample_batch(self, batch_size, num_points_per_sample):\n        """"""\n        TODO: change this to stack instead of extend\n        """"""\n        batch_points_centered = []\n        batch_points_raw = []\n        batch_labels = []\n        batch_colors = []\n\n        for _ in range(batch_size):\n            points_centered, points_raw, gt_labels, colors = self.sample(\n                num_points_per_sample\n            )\n            batch_points_centered.append(points_centered)\n            batch_points_raw.append(points_raw)\n            batch_labels.append(gt_labels)\n            batch_colors.append(colors)\n\n        return (\n            np.array(batch_points_centered),\n            np.array(batch_points_raw),\n            np.array(batch_labels),\n            np.array(batch_colors),\n        )\n\n\nclass SemanticDataset:\n    def __init__(\n        self, num_points_per_sample, split, use_color, box_size_x, box_size_y, path\n    ):\n        """"""Create a dataset holder\n        num_points_per_sample (int): Defaults to 8192. The number of point per sample\n        split (str): Defaults to \'train\'. The selected part of the data (train, test,\n                     reduced...)\n        color (bool): Defaults to True. Whether to use colors or not\n        box_size_x (int): Defaults to 10. The size of the extracted cube.\n        box_size_y (int): Defaults to 10. The size of the extracted cube.\n        path (float): Defaults to \'dataset/semantic_data/\'.\n        """"""\n        # Dataset parameters\n        self.num_points_per_sample = num_points_per_sample\n        self.split = split\n        self.use_color = use_color\n        self.box_size_x = box_size_x\n        self.box_size_y = box_size_y\n        self.num_classes = 9\n        self.path = path\n        self.labels_names = [\n            ""unlabeled"",\n            ""man-made terrain"",\n            ""natural terrain"",\n            ""high vegetation"",\n            ""low vegetation"",\n            ""buildings"",\n            ""hard scape"",\n            ""scanning artifact"",\n            ""cars"",\n        ]\n\n        # Get file_prefixes\n        file_prefixes = map_name_to_file_prefixes[self.split]\n        print(""Dataset split:"", self.split)\n        print(""Loading file_prefixes:"", file_prefixes)\n\n        # Load files\n        self.list_file_data = []\n        for file_prefix in file_prefixes:\n            file_path_without_ext = os.path.join(self.path, file_prefix)\n            file_data = SemanticFileData(\n                file_path_without_ext=file_path_without_ext,\n                has_label=self.split != ""test"",\n                use_color=self.use_color,\n                box_size_x=self.box_size_x,\n                box_size_y=self.box_size_y,\n            )\n            self.list_file_data.append(file_data)\n\n        # Pre-compute the probability of picking a scene\n        self.num_scenes = len(self.list_file_data)\n        self.scene_probas = [\n            len(fd.points) / self.get_total_num_points() for fd in self.list_file_data\n        ]\n\n        # Pre-compute the points weights if it is a training set\n        if self.split == ""train"" or self.split == ""train_full"":\n            # First, compute the histogram of each labels\n            label_weights = np.zeros(9)\n            for labels in [fd.labels for fd in self.list_file_data]:\n                tmp, _ = np.histogram(labels, range(10))\n                label_weights += tmp\n\n            # Then, a heuristic gives the weights\n            # 1 / log(1.2 + probability of occurrence)\n            label_weights = label_weights.astype(np.float32)\n            label_weights = label_weights / np.sum(label_weights)\n            self.label_weights = 1 / np.log(1.2 + label_weights)\n        else:\n            self.label_weights = np.zeros(9)\n\n    def sample_batch_in_all_files(self, batch_size, augment=True):\n        batch_data = []\n        batch_label = []\n        batch_weights = []\n\n        for _ in range(batch_size):\n            points, labels, colors, weights = self.sample_in_all_files(is_training=True)\n            if self.use_color:\n                batch_data.append(np.hstack((points, colors)))\n            else:\n                batch_data.append(points)\n            batch_label.append(labels)\n            batch_weights.append(weights)\n\n        batch_data = np.array(batch_data)\n        batch_label = np.array(batch_label)\n        batch_weights = np.array(batch_weights)\n\n        if augment:\n            if self.use_color:\n                batch_data = provider.rotate_feature_point_cloud(batch_data, 3)\n            else:\n                batch_data = provider.rotate_point_cloud(batch_data)\n\n        return batch_data, batch_label, batch_weights\n\n    def sample_in_all_files(self, is_training):\n        """"""\n        Returns points and other info within a z - cropped box.\n        """"""\n        # Pick a scene, scenes with more points are more likely to be chosen\n        scene_index = np.random.choice(\n            np.arange(0, len(self.list_file_data)), p=self.scene_probas\n        )\n\n        # Sample from the selected scene\n        points_centered, points_raw, labels, colors = self.list_file_data[\n            scene_index\n        ].sample(num_points_per_sample=self.num_points_per_sample)\n\n        if is_training:\n            weights = self.label_weights[labels]\n            return points_centered, labels, colors, weights\n        else:\n            return scene_index, points_centered, points_raw, labels, colors\n\n    def get_total_num_points(self):\n        list_num_points = [len(fd.points) for fd in self.list_file_data]\n        return np.sum(list_num_points)\n\n    def get_num_batches(self, batch_size):\n        return int(\n            self.get_total_num_points() / (batch_size * self.num_points_per_sample)\n        )\n\n    def get_file_paths_without_ext(self):\n        return [file_data.file_path_without_ext for file_data in self.list_file_data]\n'"
tf_ops/__init__.py,0,b''
tf_ops/test_interpolate.py,4,"b'import numpy as np\nimport tensorflow as tf\nimport time\nfrom tf_interpolate import three_nn, three_interpolate\n\nif __name__ == ""__main__"":\n    np.random.seed(100)\n\n    target_points = np.random.random((64, 8192, 3)).astype(""float32"")\n    reference_points = np.random.random((64, 1024, 3)).astype(""float32"")\n\n    with tf.device(""/cpu:0""):\n        xyz1 = tf.constant(target_points)\n        xyz2 = tf.constant(reference_points)\n        dist, idx = three_nn(xyz1, xyz2)\n\n    with tf.Session("""") as sess:\n        # Warm up\n        dist, idx = sess.run(three_nn(xyz1, xyz2))\n\n        # Run\n        s = time.time()\n        dist, idx = sess.run(three_nn(xyz1, xyz2))\n        print(""Time: {}"".format(time.time() - s))\n        print(idx.shape, idx.dtype)\n        print(dist.shape, dist.dtype)\n        print(dist[:3, :3, :1].flatten())\n        print(idx[:3, :3, :1].flatten())\n\n        # Expected output\n        # (64, 8192, 3) int32\n        # (64, 8192, 3) float32\n        # [0.00175864 0.00671887 0.0034472  0.00337327 0.00191902 0.00075543\n        #  0.00169418 0.00473733 0.00381071]\n        # [137 856 116  76 915 199 117 659 786]\n'"
tf_ops/test_tf_ops.py,38,"b'import tensorflow as tf\nimport numpy as np\nimport time\nfrom tf_grouping import query_ball_point, group_point, knn_point\nfrom tf_interpolate import three_nn, three_interpolate\nfrom tf_sampling import prob_sample, farthest_point_sample, gather_point\n\n\nclass TestGrouping(tf.test.TestCase):\n    def test(self):\n        knn = True\n        np.random.seed(100)\n        pts = np.random.random((32, 512, 64)).astype(""float32"")\n        tmp1 = np.random.random((32, 512, 3)).astype(""float32"")\n        tmp2 = np.random.random((32, 128, 3)).astype(""float32"")\n        with tf.device(""/gpu:0""):\n            points = tf.constant(pts)\n            xyz1 = tf.constant(tmp1)\n            xyz2 = tf.constant(tmp2)\n            radius = 0.1\n            nsample = 64\n            if knn:\n                _, idx = knn_point(nsample, xyz1, xyz2)\n                grouped_points = group_point(points, idx)\n            else:\n                idx, _ = query_ball_point(radius, nsample, xyz1, xyz2)\n                grouped_points = group_point(points, idx)\n                # grouped_points_grad = tf.ones_like(grouped_points)\n                # points_grad = tf.gradients(grouped_points, points, grouped_points_grad)\n        with tf.Session("""") as sess:\n            now = time.time()\n            for _ in range(100):\n                ret = sess.run(grouped_points)\n            print(time.time() - now)\n            print(ret.shape, ret.dtype)\n            print(ret)\n\n    def test_grad(self):\n        with tf.device(""/gpu:0""):\n            points = tf.constant(np.random.random((1, 128, 16)).astype(""float32""))\n            print(points)\n            xyz1 = tf.constant(np.random.random((1, 128, 3)).astype(""float32""))\n            xyz2 = tf.constant(np.random.random((1, 8, 3)).astype(""float32""))\n            radius = 0.3\n            nsample = 32\n            idx, pts_cnt = query_ball_point(radius, nsample, xyz1, xyz2)\n            grouped_points = group_point(points, idx)\n            print(grouped_points)\n\n        with self.test_session():\n            print(""---- Going to compute gradient error"")\n            err = tf.test.compute_gradient_error(\n                points, (1, 128, 16), grouped_points, (1, 8, 32, 16)\n            )\n            print(err)\n            self.assertLess(err, 1e-4)\n\n\nclass TestInterpolate(tf.test.TestCase):\n    def test(self):\n        np.random.seed(100)\n        pts = np.random.random((32, 128, 64)).astype(""float32"")\n        tmp1 = np.random.random((32, 512, 3)).astype(""float32"")\n        tmp2 = np.random.random((32, 128, 3)).astype(""float32"")\n        with tf.device(""/cpu:0""):\n            points = tf.constant(pts)\n            xyz1 = tf.constant(tmp1)\n            xyz2 = tf.constant(tmp2)\n            dist, idx = three_nn(xyz1, xyz2)\n            weight = tf.ones_like(dist) / 3.0\n            interpolated_points = three_interpolate(points, idx, weight)\n        with tf.Session("""") as sess:\n            now = time.time()\n            for _ in range(100):\n                ret = sess.run(interpolated_points)\n            print(time.time() - now)\n            print(ret.shape, ret.dtype)\n            # print ret\n\n    def test_grad(self):\n        with self.test_session():\n            points = tf.constant(np.random.random((1, 8, 16)).astype(""float32""))\n            print(points)\n            xyz1 = tf.constant(np.random.random((1, 128, 3)).astype(""float32""))\n            xyz2 = tf.constant(np.random.random((1, 8, 3)).astype(""float32""))\n            dist, idx = three_nn(xyz1, xyz2)\n            weight = tf.ones_like(dist) / 3.0\n            interpolated_points = three_interpolate(points, idx, weight)\n            print(interpolated_points)\n            err = tf.test.compute_gradient_error(\n                points, (1, 8, 16), interpolated_points, (1, 128, 16)\n            )\n            print(err)\n            self.assertLess(err, 1e-4)\n\n\nclass TestSampling(tf.test.TestCase):\n    def test(self):\n        np.random.seed(100)\n        triangles = np.random.rand(1, 5, 3, 3).astype(""float32"")\n        with tf.device(""/gpu:0""):\n            inp = tf.constant(triangles)\n            tria = inp[:, :, 0, :]\n            trib = inp[:, :, 1, :]\n            tric = inp[:, :, 2, :]\n            areas = tf.sqrt(\n                tf.reduce_sum(tf.cross(trib - tria, tric - tria) ** 2, 2) + 1e-9\n            )\n            randomnumbers = tf.random_uniform((1, 8192))\n            triids = prob_sample(areas, randomnumbers)\n            tria_sample = gather_point(tria, triids)\n            trib_sample = gather_point(trib, triids)\n            tric_sample = gather_point(tric, triids)\n            us = tf.random_uniform((1, 8192))\n            vs = tf.random_uniform((1, 8192))\n            uplusv = 1 - tf.abs(us + vs - 1)\n            uminusv = us - vs\n            us = (uplusv + uminusv) * 0.5\n            vs = (uplusv - uminusv) * 0.5\n            pt_sample = (\n                tria_sample\n                + (trib_sample - tria_sample) * tf.expand_dims(us, -1)\n                + (tric_sample - tria_sample) * tf.expand_dims(vs, -1)\n            )\n            print(""pt_sample: "", pt_sample)\n            reduced_sample = gather_point(\n                pt_sample, farthest_point_sample(1024, pt_sample)\n            )\n            print(reduced_sample)\n        with tf.Session("""") as sess:\n            ret = sess.run(reduced_sample)\n        print(ret.shape, ret.dtype)\n        # pickle.dump(ret, open(""1.pkl"", ""wb""), -1)\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tf_ops/tf_grouping.py,8,"b'import tensorflow as tf\nfrom tensorflow.python.framework import ops\nimport sys\nimport os\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\ngrouping_module = tf.load_op_library(\n    os.path.join(BASE_DIR, ""build"", ""libtf_grouping.so"")\n)\n\n\ndef query_ball_point(radius, nsample, xyz1, xyz2):\n    """"""\n    Input:\n        radius: float32, ball search radius\n        nsample: int32, number of points selected in each ball region\n        xyz1: (batch_size, ndataset, 3) float32 array, input points\n        xyz2: (batch_size, npoint, 3) float32 array, query points\n    Output:\n        idx: (batch_size, npoint, nsample) int32 array, indices to input points\n        pts_cnt: (batch_size, npoint) int32 array, number of unique points in each local region\n    """"""\n    # return grouping_module.query_ball_point(radius, nsample, xyz1, xyz2)\n    return grouping_module.query_ball_point(xyz1, xyz2, radius, nsample)\n\n\nops.NoGradient(""QueryBallPoint"")\n\n\ndef select_top_k(k, dist):\n    """"""\n    Input:\n        k: int32, number of k SMALLEST elements selected\n        dist: (b,m,n) float32 array, distance matrix, m query points, n dataset points\n    Output:\n        idx: (b,m,n) int32 array, first k in n are indices to the top k\n        dist_out: (b,m,n) float32 array, first k in n are the top k\n    """"""\n    return grouping_module.selection_sort(dist, k)\n\n\nops.NoGradient(""SelectionSort"")\n\n\ndef group_point(points, idx):\n    """"""\n    Input:\n        points: (batch_size, ndataset, channel) float32 array, points to sample from\n        idx: (batch_size, npoint, nsample) int32 array, indices to points\n    Output:\n        out: (batch_size, npoint, nsample, channel) float32 array, values sampled from points\n    """"""\n    return grouping_module.group_point(points, idx)\n\n\n@tf.RegisterGradient(""GroupPoint"")\ndef _group_point_grad(op, grad_out):\n    points = op.inputs[0]\n    idx = op.inputs[1]\n    return [grouping_module.group_point_grad(points, idx, grad_out), None]\n\n\ndef knn_point(k, xyz1, xyz2):\n    """"""\n    Input:\n        k: int32, number of k in k-nn search\n        xyz1: (batch_size, ndataset, c) float32 array, input points\n        xyz2: (batch_size, npoint, c) float32 array, query points\n    Output:\n        val: (batch_size, npoint, k) float32 array, L2 distances\n        idx: (batch_size, npoint, k) int32 array, indices to input points\n    """"""\n    b = xyz1.get_shape()[0].value\n    n = xyz1.get_shape()[1].value\n    c = xyz1.get_shape()[2].value\n    m = xyz2.get_shape()[1].value\n    print(b, n, c, m)\n    print(xyz1, (b, 1, n, c))\n    xyz1 = tf.tile(tf.reshape(xyz1, (b, 1, n, c)), [1, m, 1, 1])\n    xyz2 = tf.tile(tf.reshape(xyz2, (b, m, 1, c)), [1, 1, n, 1])\n    dist = tf.reduce_sum((xyz1 - xyz2) ** 2, -1)\n    print(dist, k)\n    outi, out = select_top_k(k, dist)\n    idx = tf.slice(outi, [0, 0, 0], [-1, -1, k])\n    val = tf.slice(out, [0, 0, 0], [-1, -1, k])\n    print(idx, val)\n    # val, idx = tf.nn.top_k(-dist, k=k) # ONLY SUPPORT CPU\n    return val, idx\n'"
tf_ops/tf_interpolate.py,2,"b'import tensorflow as tf\nfrom tensorflow.python.framework import ops\nimport sys\nimport os\n\nBASE_DIR = os.path.dirname(__file__)\nsys.path.append(BASE_DIR)\ninterpolate_module = tf.load_op_library(\n    os.path.join(BASE_DIR, ""build"", ""libtf_interpolate.so"")\n)\n\n\ndef three_nn(xyz1, xyz2):\n    """"""\n    Input:\n        xyz1: (b,n,3) float32 array, unknown points\n        xyz2: (b,m,3) float32 array, known points\n    Output:\n        dist: (b,n,3) float32 array, distances to known points\n        idx: (b,n,3) int32 array, indices to known points\n    """"""\n    return interpolate_module.three_nn(xyz1, xyz2)\n\n\nops.NoGradient(""ThreeNN"")\n\n\ndef interpolate_label_with_color(sparse_points, sparse_labels, dense_points, knn):\n    """"""\n    Input:\n        sparse_points: (num_sparse_points, 3) float32 array, points\n                      with known labels\n        sparse_labels: (num_sparse_points, 3) float32 array, labels of\n                      sparse_points\n        dense_points: (num_dense_points, 3) float32 array, points\n                      with unknown labels\n        knn: int, use k-NN for label interpolation\n    Output:\n        dense_labels:  (num_dense_points,) int32 array, indices\n        dense_colors:  (num_dense_points, 3) uint8 array, colors for dense_labels\n    """"""\n    return interpolate_module.interpolate_label_with_color(\n        sparse_points, sparse_labels, dense_points, knn\n    )\n\n\nops.NoGradient(""InterpolateLabelWithColor"")\n\n\ndef three_interpolate(points, idx, weight):\n    """"""\n    Input:\n        points: (b,m,c) float32 array, known points\n        idx: (b,n,3) int32 array, indices to known points\n        weight: (b,n,3) float32 array, weights on known points\n    Output:\n        out: (b,n,c) float32 array, interpolated point values\n    """"""\n    return interpolate_module.three_interpolate(points, idx, weight)\n\n\n@tf.RegisterGradient(""ThreeInterpolate"")\ndef _three_interpolate_grad(op, grad_out):\n    points = op.inputs[0]\n    idx = op.inputs[1]\n    weight = op.inputs[2]\n    return [\n        interpolate_module.three_interpolate_grad(points, idx, weight, grad_out),\n        None,\n        None,\n    ]\n'"
tf_ops/tf_sampling.py,6,"b'"""""" Furthest point sampling\nOriginal author: Haoqiang Fan\nModified by Charles R. Qi\nAll Rights Reserved. 2017.\n""""""\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nimport sys\nimport os\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsampling_module = tf.load_op_library(\n    os.path.join(BASE_DIR, ""build"", ""libtf_sampling.so"")\n)\n\n\ndef prob_sample(inp, inpr):\n    """"""\ninput:\n    batch_size * ncategory float32\n    batch_size * npoints   float32\nreturns:\n    batch_size * npoints   int32\n    """"""\n    return sampling_module.prob_sample(inp, inpr)\n\n\nops.NoGradient(""ProbSample"")\n\n\n# TF1.0 API requires set shape in C++\n# @tf.RegisterShape(\'ProbSample\')\n# def _prob_sample_shape(op):\n#    shape1=op.inputs[0].get_shape().with_rank(2)\n#    shape2=op.inputs[1].get_shape().with_rank(2)\n#    return [tf.TensorShape([shape2.dims[0],shape2.dims[1]])]\ndef gather_point(inp, idx):\n    """"""\ninput:\n    batch_size * ndataset * 3   float32\n    batch_size * npoints        int32\nreturns:\n    batch_size * npoints * 3    float32\n    """"""\n    return sampling_module.gather_point(inp, idx)\n\n\n# @tf.RegisterShape(\'GatherPoint\')\n# def _gather_point_shape(op):\n#    shape1=op.inputs[0].get_shape().with_rank(3)\n#    shape2=op.inputs[1].get_shape().with_rank(2)\n#    return [tf.TensorShape([shape1.dims[0],shape2.dims[1],shape1.dims[2]])]\n@tf.RegisterGradient(""GatherPoint"")\ndef _gather_point_grad(op, out_g):\n    inp = op.inputs[0]\n    idx = op.inputs[1]\n    return [sampling_module.gather_point_grad(inp, idx, out_g), None]\n\n\ndef farthest_point_sample(npoint, inp):\n    """"""\ninput:\n    int32\n    batch_size * ndataset * 3   float32\nreturns:\n    batch_size * npoint         int32\n    """"""\n    return sampling_module.farthest_point_sample(inp, npoint)\n\n\nops.NoGradient(""FarthestPointSample"")\n'"
util/__init__.py,0,b''
util/metric.py,0,"b'from __future__ import print_function\nimport numpy as np\nfrom pprint import pprint\nfrom sklearn.metrics import confusion_matrix as skl_get_confusion_matrix\n\n\nclass ConfusionMatrix:\n    def __init__(self, num_classes):\n        """"""\n        label must be {0, 1, 2, ..., num_classes - 1}\n        """"""\n        self.num_classes = num_classes\n        self.confusion_matrix = np.zeros(\n            (self.num_classes, self.num_classes), dtype=np.int64\n        )\n        self.valid_labels = set(range(self.num_classes))\n\n    def increment(self, gt_label, pd_label):\n        if gt_label not in self.valid_labels:\n            raise ValueError(""Invalid value for gt_label"")\n        if pd_label not in self.valid_labels:\n            raise ValueError(""Invalid value for pd_label"")\n        self.confusion_matrix[gt_label][pd_label] += 1\n\n    def increment_from_list(self, gt_labels, pd_labels):\n        increment_cm = skl_get_confusion_matrix(\n            gt_labels, pd_labels, labels=list(range(self.num_classes))\n        )\n        np.testing.assert_array_equal(self.confusion_matrix.shape, increment_cm.shape)\n        self.confusion_matrix += increment_cm\n\n    def get_per_class_ious(self):\n        """"""\n        Warning: Semantic3D assumes label 0 is not used.\n        I.e. 1. if gt == 0, this data point is simply ignored\n             2. it\'s always true that pd != 0\n\n        |        | 0 (pd)      | 1 (pd)      | 2 (pd)      | 3 (pd)      |\n        |--------|-------------|-------------|-------------|-------------|\n        | 0 (gt) | (must be) 0 | (ignored) 1 | (ignored) 2 | (ignored) 3 |\n        | 1 (gt) | (must be) 0 | 4           | 5           | 6           |\n        | 2 (gt) | (must be) 0 | 7           | 8           | 9           |\n        | 3 (gt) | (must be) 0 | 10          | 11          | 12          |\n\n        Returns a list of num_classes - 1 elements\n        """"""\n\n        # Check that pd != 0\n        if any(self.confusion_matrix[:, 0] != 0):\n            print(""[Warn] Contains prediction of label 0:"", self.confusion_matrix[:, 0])\n\n        # Ignore gt == 0\n        valid_confusion_matrix = self.confusion_matrix[1:, 1:]\n        ious = []\n        for c in range(len(valid_confusion_matrix)):\n            intersection = valid_confusion_matrix[c, c]\n            union = (\n                np.sum(valid_confusion_matrix[c, :])\n                + np.sum(valid_confusion_matrix[:, c])\n                - intersection\n            )\n            if union == 0:\n                union = 1\n            ious.append(float(intersection) / union)\n        return ious\n\n    def get_mean_iou(self):\n        """"""\n        Warning: Semantic3D assumes label 0 is not used.\n        E.g. 1. if gt == 0, this data point is simply ignored\n             2. assert that pd != 0\n        """"""\n        per_class_ious = self.get_per_class_ious()\n        return np.sum(per_class_ious) / len(per_class_ious)\n\n    def get_accuracy(self):\n        """"""\n        Warning: Semantic3D assumes label 0 is not used.\n        E.g. 1. if gt == 0, this data point is simply ignored\n             2. assert that pd != 0\n        """"""\n        valid_confusion_matrix = self.confusion_matrix[1:, 1:]\n        return np.trace(valid_confusion_matrix) / np.sum(valid_confusion_matrix)\n\n    def print_metrics(self, labels=None):\n        # 1. Confusion matrix\n        print(""Confusion matrix:"")\n\n        # Fill default labels: [""0"", ""1"", ""2"", ...]\n        if labels == None:\n            labels = [str(val) for val in range(self.num_classes)]\n        elif len(labels) != self.num_classes:\n            raise ValueError(""len(labels) != self.num_classes"")\n\n        # Formatting helpers\n        column_width = max([len(x) for x in labels] + [7])\n        empty_cell = "" "" * column_width\n\n        # Print header\n        print(""    "" + empty_cell, end="" "")\n        for label in labels:\n            print(""%{0}s"".format(column_width) % label, end="" "")\n        print()\n\n        # Print rows\n        for i, label in enumerate(labels):\n            print(""    %{0}s"".format(column_width) % label, end="" "")\n            for j in range(len(labels)):\n                cell = ""%{0}.0f"".format(column_width) % self.confusion_matrix[i, j]\n                print(cell, end="" "")\n            print()\n\n        # 2. IoU per class\n        print(""IoU per class:"")\n        pprint(self.get_per_class_ious())\n\n        # 3. Mean IoU\n        # Warning: excluding class 0\n        print(""mIoU (ignoring label 0):"")\n        print(self.get_mean_iou())\n\n        # 4. Overall accuracy\n        print(""Overall accuracy"")\n        print(self.get_accuracy())\n\n\nif __name__ == ""__main__"":\n    # Test data\n    # |        | 0 (pd)      | 1 (pd)      | 2 (pd)      | 3 (pd)      |\n    # |--------|-------------|-------------|-------------|-------------|\n    # | 0 (gt) | (must be) 0 | (ignored) 1 | (ignored) 2 | (ignored) 3 |\n    # | 1 (gt) | (must be) 0 | 4           | 5           | 6           |\n    # | 2 (gt) | (must be) 0 | 7           | 8           | 9           |\n    # | 3 (gt) | (must be) 0 | 10          | 11          | 12          |\n    ref_confusion_matrix = np.array(\n        [[0, 1, 2, 3], [0, 4, 5, 6], [0, 7, 8, 9], [0, 10, 11, 12]]\n    )\n\n    # Build CM\n    cm = ConfusionMatrix(num_classes=4)\n    for gt in range(4):\n        for pd in range(4):\n            for _ in range(ref_confusion_matrix[gt, pd]):\n                cm.increment(gt, pd)\n\n    # Check confusion matrix\n    np.testing.assert_allclose(ref_confusion_matrix, cm.confusion_matrix)\n    print(cm.confusion_matrix)\n\n    # Check IoU\n    ref_per_class_ious = np.array(\n        [\n            4.0 / (4 + 7 + 10 + 5 + 6),\n            8.0 / (5 + 8 + 11 + 7 + 9),\n            12.0 / (6 + 9 + 12 + 10 + 11),\n        ]\n    )\n    np.testing.assert_allclose(cm.get_per_class_ious(), ref_per_class_ious)\n    print(cm.get_per_class_ious())\n\n    ref_mean_iou = np.mean(ref_per_class_ious)\n    assert cm.get_mean_iou() == ref_mean_iou\n    print(cm.get_mean_iou())\n\n    # Check accuracy\n    ref_accuracy = float(4 + 8 + 12) / ((4 + 12) * 9 / 2)\n    assert cm.get_accuracy() == ref_accuracy\n    print(cm.get_accuracy())\n'"
util/point_cloud_util.py,0,"b'import numpy as np\nimport open3d\n\n\ndef _label_to_colors(labels):\n    map_label_to_color = {\n        0: [255, 255, 255],  # white\n        1: [0, 0, 255],  # blue\n        2: [128, 0, 0],  # maroon\n        3: [255, 0, 255],  # fuchisia\n        4: [0, 128, 0],  # green\n        5: [255, 0, 0],  # red\n        6: [128, 0, 128],  # purple\n        7: [0, 0, 128],  # navy\n        8: [128, 128, 0],  # olive\n    }\n    return np.array([map_label_to_color[label] for label in labels]).astype(np.int32)\n\n\ndef _label_to_colors_one_hot(labels):\n    map_label_to_color = np.array(\n        [\n            [255, 255, 255],\n            [0, 0, 255],\n            [128, 0, 0],\n            [255, 0, 255],\n            [0, 128, 0],\n            [255, 0, 0],\n            [128, 0, 128],\n            [0, 0, 128],\n            [128, 128, 0],\n        ]\n    )\n    num_labels = len(labels)\n    labels_one_hot = np.zeros((num_labels, 9))\n    labels_one_hot[np.arange(num_labels), labels] = 1\n    return np.dot(labels_one_hot, map_label_to_color).astype(np.int32)\n\n\ndef colorize_point_cloud(point_cloud, labels):\n    if len(point_cloud.points) != len(labels):\n        raise ValueError(""len(point_cloud.points) != len(labels)"")\n    if len(labels) < 1e6:\n        print(""_label_to_colors_one_hot used"")\n        colors = _label_to_colors_one_hot(labels)\n    else:\n        colors = _label_to_colors(labels)\n    # np.testing.assert_equal(colors, colors_v2)\n    point_cloud.colors = open3d.Vector3dVector()  # Clear it to save memory\n    point_cloud.colors = open3d.Vector3dVector(colors)\n\n\ndef load_labels(label_path):\n    # Assuming each line is a valid int\n    with open(label_path, ""r"") as f:\n        labels = [int(line) for line in f]\n    return np.array(labels, dtype=np.int32)\n\n\ndef write_labels(label_path, labels):\n    with open(label_path, ""w"") as f:\n        for label in labels:\n            f.write(""%d\\n"" % label)\n'"
util/pointnet_util.py,39,"b'# PointNet++ Layers\n# Author: Charles R. Qi\n# Date: November 2017\n\nimport os\nimport sys\nimport numpy as np\nimport tensorflow as tf\nfrom tf_ops.tf_interpolate import three_nn, three_interpolate\nfrom tf_ops.tf_grouping import query_ball_point, group_point, knn_point\nfrom tf_ops.tf_sampling import farthest_point_sample, gather_point\nfrom util import tf_util\n\nROOT_DIR = os.path.abspath(os.path.pardir)\nsys.path.append(ROOT_DIR)\n\n\ndef sample_and_group(npoint, radius, nsample, xyz, points, knn=False, use_xyz=True):\n    """"""\n    Input:\n        npoint: int32\n        radius: float32\n        nsample: int32\n        xyz: (batch_size, ndataset, 3) TF tensor\n        points: (batch_size, ndataset, channel) TF tensor, if None will just use xyz as points\n        knn: bool, if True use kNN instead of radius search\n        use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n    Output:\n        new_xyz: (batch_size, npoint, 3) TF tensor\n        new_points: (batch_size, npoint, nsample, 3+channel) TF tensor\n        idx: (batch_size, npoint, nsample) TF tensor, indices of local points as in ndataset points\n        grouped_xyz: (batch_size, npoint, nsample, 3) TF tensor, normalized point XYZs\n            (subtracted by seed point XYZ) in local regions\n    """"""\n\n    new_xyz = gather_point(\n        xyz, farthest_point_sample(npoint, xyz)\n    )  # (batch_size, npoint, 3)\n    if knn:\n        _, idx = knn_point(nsample, xyz, new_xyz)\n    else:\n        idx, pts_cnt = query_ball_point(radius, nsample, xyz, new_xyz)\n    grouped_xyz = group_point(xyz, idx)  # (batch_size, npoint, nsample, 3)\n    grouped_xyz -= tf.tile(\n        tf.expand_dims(new_xyz, 2), [1, 1, nsample, 1]\n    )  # translation normalization\n    if points is not None:\n        grouped_points = group_point(\n            points, idx\n        )  # (batch_size, npoint, nsample, channel)\n        if use_xyz:\n            new_points = tf.concat(\n                [grouped_xyz, grouped_points], axis=-1\n            )  # (batch_size, npoint, nample, 3+channel)\n        else:\n            new_points = grouped_points\n    else:\n        new_points = grouped_xyz\n\n    return new_xyz, new_points, idx, grouped_xyz\n\n\ndef sample_and_group_all(xyz, points, use_xyz=True):\n    """"""\n    Inputs:\n        xyz: (batch_size, ndataset, 3) TF tensor\n        points: (batch_size, ndataset, channel) TF tensor, if None will just use xyz as points\n        use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n    Outputs:\n        new_xyz: (batch_size, 1, 3) as (0,0,0)\n        new_points: (batch_size, 1, ndataset, 3+channel) TF tensor\n    Note:\n        Equivalent to sample_and_group with npoint=1, radius=inf, use (0,0,0) as the centroid\n    """"""\n    batch_size = xyz.get_shape()[0].value\n    nsample = xyz.get_shape()[1].value\n    new_xyz = tf.constant(\n        np.tile(np.array([0, 0, 0]).reshape((1, 1, 3)), (batch_size, 1, 1)),\n        dtype=tf.float32,\n    )  # (batch_size, 1, 3)\n    idx = tf.constant(\n        np.tile(np.array(range(nsample)).reshape((1, 1, nsample)), (batch_size, 1, 1))\n    )\n    grouped_xyz = tf.reshape(\n        xyz, (batch_size, 1, nsample, 3)\n    )  # (batch_size, npoint=1, nsample, 3)\n    if points is not None:\n        if use_xyz:\n            new_points = tf.concat([xyz, points], axis=2)  # (batch_size, 16, 259)\n        else:\n            new_points = points\n        new_points = tf.expand_dims(new_points, 1)  # (batch_size, 1, 16, 259)\n    else:\n        new_points = grouped_xyz\n    return new_xyz, new_points, idx, grouped_xyz\n\n\ndef pointnet_sa_module(\n    xyz,\n    points,\n    npoint,\n    radius,\n    nsample,\n    mlp,\n    mlp2,\n    group_all,\n    is_training,\n    bn_decay,\n    scope,\n    bn=True,\n    pooling=""max"",\n    knn=False,\n    use_xyz=True,\n    use_nchw=False,\n):\n    """""" PointNet Set Abstraction (SA) Module\n        Input:\n            xyz: (batch_size, ndataset, 3) TF tensor\n            points: (batch_size, ndataset, channel) TF tensor\n            npoint: int32 -- #points sampled in farthest point sampling\n            radius: float32 -- search radius in local region\n            nsample: int32 -- how many points in each local region\n            mlp: list of int32 -- output size for MLP on each point\n            mlp2: list of int32 -- output size for MLP on each region\n            group_all: bool -- group all points into one PC if set true, OVERRIDE\n                npoint, radius and nsample settings\n            use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n            use_nchw: bool, if True, use NCHW data format for conv2d, which is usually faster than NHWC format\n        Return:\n            new_xyz: (batch_size, npoint, 3) TF tensor\n            new_points: (batch_size, npoint, mlp[-1] or mlp2[-1]) TF tensor\n            idx: (batch_size, npoint, nsample) int32 -- indices for local regions\n    """"""\n    data_format = ""NCHW"" if use_nchw else ""NHWC""\n    with tf.variable_scope(scope) as sc:\n        # Sample and Grouping\n        if group_all:\n            nsample = xyz.get_shape()[1].value\n            new_xyz, new_points, idx, grouped_xyz = sample_and_group_all(\n                xyz, points, use_xyz\n            )\n        else:\n            new_xyz, new_points, idx, grouped_xyz = sample_and_group(\n                npoint, radius, nsample, xyz, points, knn, use_xyz\n            )\n\n        # Point Feature Embedding\n        if use_nchw:\n            new_points = tf.transpose(new_points, [0, 3, 1, 2])\n        for i, num_out_channel in enumerate(mlp):\n            new_points = tf_util.conv2d(\n                new_points,\n                num_out_channel,\n                [1, 1],\n                padding=""VALID"",\n                stride=[1, 1],\n                bn=bn,\n                is_training=is_training,\n                scope=""conv%d"" % (i),\n                bn_decay=bn_decay,\n                data_format=data_format,\n            )\n        if use_nchw:\n            new_points = tf.transpose(new_points, [0, 2, 3, 1])\n\n        # Pooling in Local Regions\n        if pooling == ""max"":\n            new_points = tf.reduce_max(\n                new_points, axis=[2], keepdims=True, name=""maxpool""\n            )\n        elif pooling == ""avg"":\n            new_points = tf.reduce_mean(\n                new_points, axis=[2], keepdims=True, name=""avgpool""\n            )\n        elif pooling == ""weighted_avg"":\n            with tf.variable_scope(""weighted_avg""):\n                dists = tf.norm(grouped_xyz, axis=-1, ord=2, keepdims=True)\n                exp_dists = tf.exp(-dists * 5)\n                weights = exp_dists / tf.reduce_sum(\n                    exp_dists, axis=2, keepdims=True\n                )  # (batch_size, npoint, nsample, 1)\n                new_points *= weights  # (batch_size, npoint, nsample, mlp[-1])\n                new_points = tf.reduce_sum(new_points, axis=2, keepdims=True)\n        elif pooling == ""max_and_avg"":\n            max_points = tf.reduce_max(\n                new_points, axis=[2], keepdims=True, name=""maxpool""\n            )\n            avg_points = tf.reduce_mean(\n                new_points, axis=[2], keepdims=True, name=""avgpool""\n            )\n            new_points = tf.concat([avg_points, max_points], axis=-1)\n\n        # [Optional] Further Processing\n        if mlp2 is not None:\n            if use_nchw:\n                new_points = tf.transpose(new_points, [0, 3, 1, 2])\n            for i, num_out_channel in enumerate(mlp2):\n                new_points = tf_util.conv2d(\n                    new_points,\n                    num_out_channel,\n                    [1, 1],\n                    padding=""VALID"",\n                    stride=[1, 1],\n                    bn=bn,\n                    is_training=is_training,\n                    scope=""conv_post_%d"" % (i),\n                    bn_decay=bn_decay,\n                    data_format=data_format,\n                )\n            if use_nchw:\n                new_points = tf.transpose(new_points, [0, 2, 3, 1])\n\n        new_points = tf.squeeze(\n            new_points, [2]\n        )  # (batch_size, num_points_per_sample, mlp2[-1])\n        return new_xyz, new_points, idx\n\n\ndef pointnet_sa_module_msg(\n    xyz,\n    points,\n    npoint,\n    radius_list,\n    nsample_list,\n    mlp_list,\n    is_training,\n    bn_decay,\n    scope,\n    bn=True,\n    use_xyz=True,\n    use_nchw=False,\n):\n    """""" PointNet Set Abstraction (SA) module with Multi-Scale Grouping (MSG)\n        Input:\n            xyz: (batch_size, ndataset, 3) TF tensor\n            points: (batch_size, ndataset, channel) TF tensor\n            npoint: int32 -- #points sampled in farthest point sampling\n            radius: list of float32 -- search radius in local region\n            nsample: list of int32 -- how many points in each local region\n            mlp: list of list of int32 -- output size for MLP on each point\n            use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n            use_nchw: bool, if True, use NCHW data format for conv2d, which is usually faster than NHWC format\n        Return:\n            new_xyz: (batch_size, npoint, 3) TF tensor\n            new_points: (batch_size, npoint, \\sum_k{mlp[k][-1]}) TF tensor\n    """"""\n    data_format = ""NCHW"" if use_nchw else ""NHWC""\n    with tf.variable_scope(scope) as sc:\n        new_xyz = gather_point(xyz, farthest_point_sample(npoint, xyz))\n        new_points_list = []\n        for i in range(len(radius_list)):\n            radius = radius_list[i]\n            nsample = nsample_list[i]\n            idx, pts_cnt = query_ball_point(radius, nsample, xyz, new_xyz)\n            grouped_xyz = group_point(xyz, idx)\n            grouped_xyz -= tf.tile(tf.expand_dims(new_xyz, 2), [1, 1, nsample, 1])\n            if points is not None:\n                grouped_points = group_point(points, idx)\n                if use_xyz:\n                    grouped_points = tf.concat([grouped_points, grouped_xyz], axis=-1)\n            else:\n                grouped_points = grouped_xyz\n            if use_nchw:\n                grouped_points = tf.transpose(grouped_points, [0, 3, 1, 2])\n            for j, num_out_channel in enumerate(mlp_list[i]):\n                grouped_points = tf_util.conv2d(\n                    grouped_points,\n                    num_out_channel,\n                    [1, 1],\n                    padding=""VALID"",\n                    stride=[1, 1],\n                    bn=bn,\n                    is_training=is_training,\n                    scope=""conv%d_%d"" % (i, j),\n                    bn_decay=bn_decay,\n                )\n            if use_nchw:\n                grouped_points = tf.transpose(grouped_points, [0, 2, 3, 1])\n            new_points = tf.reduce_max(grouped_points, axis=[2])\n            new_points_list.append(new_points)\n        new_points_concat = tf.concat(new_points_list, axis=-1)\n        return new_xyz, new_points_concat\n\n\ndef pointnet_fp_module(\n    xyz1, xyz2, points1, points2, mlp, is_training, bn_decay, scope, bn=True\n):\n    """""" PointNet Feature Propogation (FP) Module\n        Input:\n            xyz1: (batch_size, ndataset1, 3) TF tensor\n            xyz2: (batch_size, ndataset2, 3) TF tensor, sparser than xyz1\n            points1: (batch_size, ndataset1, nchannel1) TF tensor\n            points2: (batch_size, ndataset2, nchannel2) TF tensor\n            mlp: list of int32 -- output size for MLP on each point\n        Return:\n            new_points: (batch_size, ndataset1, mlp[-1]) TF tensor\n    """"""\n    with tf.variable_scope(scope) as sc:\n        dist, idx = three_nn(xyz1, xyz2)\n        dist = tf.maximum(dist, 1e-10)\n        norm = tf.reduce_sum((1.0 / dist), axis=2, keepdims=True)\n        norm = tf.tile(norm, [1, 1, 3])\n        weight = (1.0 / dist) / norm\n        interpolated_points = three_interpolate(points2, idx, weight)\n\n        if points1 is not None:\n            new_points1 = tf.concat(\n                axis=2, values=[interpolated_points, points1]\n            )  # B,ndataset1,nchannel1+nchannel2\n        else:\n            new_points1 = interpolated_points\n        new_points1 = tf.expand_dims(new_points1, 2)\n        for i, num_out_channel in enumerate(mlp):\n            new_points1 = tf_util.conv2d(\n                new_points1,\n                num_out_channel,\n                [1, 1],\n                padding=""VALID"",\n                stride=[1, 1],\n                bn=bn,\n                is_training=is_training,\n                scope=""conv_%d"" % (i),\n                bn_decay=bn_decay,\n            )\n        new_points1 = tf.squeeze(new_points1, [2])  # B,ndataset1,mlp[-1]\n        return new_points1\n'"
util/provider.py,0,"b'"""""" import os\nimport sys """"""\nimport numpy as np\n\n"""""" BASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR) """"""\n\n\ndef shuffle_data(data, labels):\n    """""" Shuffle data and labels.\n        Input:\n          data: B,N,... numpy array\n          label: B,... numpy array\n        Return:\n          shuffled data, label and shuffle indices\n    """"""\n    idx = np.arange(len(labels))\n    np.random.shuffle(idx)\n    return data[idx, ...], labels[idx], idx\n\n\ndef shuffle_points(batch_data):\n    """""" Shuffle orders of points in each point cloud -- changes FPS behavior.\n        Use the same shuffling idx for the entire batch.\n        Input:\n            BxNxC array\n        Output:\n            BxNxC array\n    """"""\n    idx = np.arange(batch_data.shape[1])\n    np.random.shuffle(idx)\n    return batch_data[:, idx, :]\n\n\ndef rotate_point_cloud(batch_data, rotation_axis=""z""):\n    """""" Randomly rotate the point clouds to augument the dataset\n        rotation is per shape based along up direction\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    if np.ndim(batch_data) != 3:\n        raise ValueError(""np.ndim(batch_data) != 3, must be (b, n, 3)"")\n    if batch_data.shape[2] != 3:\n        raise ValueError(""batch_data.shape[2] != 3, must be (x, y, z)"")\n\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        if rotation_axis == ""x"":\n            rotation_matrix = np.array(\n                [[1, 0, 0], [0, cosval, sinval], [0, -sinval, cosval]]\n            )\n        elif rotation_axis == ""y"":\n            rotation_matrix = np.array(\n                [[cosval, 0, sinval], [0, 1, 0], [-sinval, 0, cosval]]\n            )\n        elif rotation_axis == ""z"":\n            rotation_matrix = np.array(\n                [[cosval, sinval, 0], [-sinval, cosval, 0], [0, 0, 1]]\n            )\n        else:\n            raise ValueError(""Wrong rotation axis"")\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_feature_point_cloud(batch_data, feature_size=3, rotation_axis=""z""):\n    """""" Randomly rotate the point clouds to augument the dataset\n        rotation is per shape based along up direction\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    rotated_data[:, :, 3 : 3 + feature_size] = batch_data[:, :, 3 : 3 + feature_size]\n    for k in range(batch_data.shape[0]):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        if rotation_axis == ""x"":\n            rotation_matrix = np.array(\n                [[1, 0, 0], [0, cosval, sinval], [0, -sinval, cosval]]\n            )\n        elif rotation_axis == ""y"":\n            rotation_matrix = np.array(\n                [[cosval, 0, sinval], [0, 1, 0], [-sinval, 0, cosval]]\n            )\n        elif rotation_axis == ""z"":\n            rotation_matrix = np.array(\n                [[cosval, sinval, 0], [-sinval, cosval, 0], [0, 0, 1]]\n            )\n        else:\n            raise ValueError(""Wrong rotation axis"")\n        shape_pc = batch_data[k, :, 0:3]\n        rotated_data[k, :, 0:3] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_point_cloud_with_normal(batch_xyz_normal):\n    """""" Randomly rotate XYZ, normal point cloud.\n        Input:\n            batch_xyz_normal: B,N,6, first three channels are XYZ, last 3 all normal\n        Output:\n            B,N,6, rotated XYZ, normal point cloud\n    """"""\n    for k in range(batch_xyz_normal.shape[0]):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array(\n            [[cosval, 0, sinval], [0, 1, 0], [-sinval, 0, cosval]]\n        )\n        shape_pc = batch_xyz_normal[k, :, 0:3]\n        shape_normal = batch_xyz_normal[k, :, 3:6]\n        batch_xyz_normal[k, :, 0:3] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n        batch_xyz_normal[k, :, 3:6] = np.dot(\n            shape_normal.reshape((-1, 3)), rotation_matrix\n        )\n    return batch_xyz_normal\n\n\ndef rotate_perturbation_point_cloud_with_normal(\n    batch_data, angle_sigma=0.06, angle_clip=0.18\n):\n    """""" Randomly perturb the point clouds by small rotations\n        Input:\n          BxNx6 array, original batch of point clouds and point normals\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        angles = np.clip(angle_sigma * np.random.randn(3), -angle_clip, angle_clip)\n        Rx = np.array(\n            [\n                [1, 0, 0],\n                [0, np.cos(angles[0]), -np.sin(angles[0])],\n                [0, np.sin(angles[0]), np.cos(angles[0])],\n            ]\n        )\n        Ry = np.array(\n            [\n                [np.cos(angles[1]), 0, np.sin(angles[1])],\n                [0, 1, 0],\n                [-np.sin(angles[1]), 0, np.cos(angles[1])],\n            ]\n        )\n        Rz = np.array(\n            [\n                [np.cos(angles[2]), -np.sin(angles[2]), 0],\n                [np.sin(angles[2]), np.cos(angles[2]), 0],\n                [0, 0, 1],\n            ]\n        )\n        R = np.dot(Rz, np.dot(Ry, Rx))\n        shape_pc = batch_data[k, :, 0:3]\n        shape_normal = batch_data[k, :, 3:6]\n        rotated_data[k, :, 0:3] = np.dot(shape_pc.reshape((-1, 3)), R)\n        rotated_data[k, :, 3:6] = np.dot(shape_normal.reshape((-1, 3)), R)\n    return rotated_data\n\n\ndef rotate_point_cloud_by_angle(batch_data, rotation_angle):\n    """""" Rotate the point cloud along up direction with certain angle.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        # rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array(\n            [[cosval, 0, sinval], [0, 1, 0], [-sinval, 0, cosval]]\n        )\n        shape_pc = batch_data[k, :, 0:3]\n        rotated_data[k, :, 0:3] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_point_cloud_by_angle_with_normal(batch_data, rotation_angle):\n    """""" Rotate the point cloud along up direction with certain angle.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        # rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array(\n            [[cosval, 0, sinval], [0, 1, 0], [-sinval, 0, cosval]]\n        )\n        shape_pc = batch_data[k, ...]\n        shape_normal = batch_data[k, :, 3:6]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n        rotated_data[k, :, 3:6] = np.dot(shape_normal.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_perturbation_point_cloud(batch_data, angle_sigma=0.06, angle_clip=0.18):\n    """""" Randomly perturb the point clouds by small rotations\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        angles = np.clip(angle_sigma * np.random.randn(3), -angle_clip, angle_clip)\n        Rx = np.array(\n            [\n                [1, 0, 0],\n                [0, np.cos(angles[0]), -np.sin(angles[0])],\n                [0, np.sin(angles[0]), np.cos(angles[0])],\n            ]\n        )\n        Ry = np.array(\n            [\n                [np.cos(angles[1]), 0, np.sin(angles[1])],\n                [0, 1, 0],\n                [-np.sin(angles[1]), 0, np.cos(angles[1])],\n            ]\n        )\n        Rz = np.array(\n            [\n                [np.cos(angles[2]), -np.sin(angles[2]), 0],\n                [np.sin(angles[2]), np.cos(angles[2]), 0],\n                [0, 0, 1],\n            ]\n        )\n        R = np.dot(Rz, np.dot(Ry, Rx))\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), R)\n    return rotated_data\n\n\ndef jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n    """""" Randomly jitter points. jittering is per point.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, jittered batch of point clouds\n    """"""\n    B, N, C = batch_data.shape\n    assert clip > 0\n    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1 * clip, clip)\n    jittered_data += batch_data\n    return jittered_data\n\n\ndef shift_point_cloud(batch_data, shift_range=0.1):\n    """""" Randomly shift point cloud. Shift is per point cloud.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, shifted batch of point clouds\n    """"""\n    B, N, C = batch_data.shape\n    shifts = np.random.uniform(-shift_range, shift_range, (B, 3))\n    for batch_index in range(B):\n        batch_data[batch_index, :, :] += shifts[batch_index, :]\n    return batch_data\n\n\ndef random_scale_point_cloud(batch_data, scale_low=0.8, scale_high=1.25):\n    """""" Randomly scale the point cloud. Scale is per point cloud.\n        Input:\n            BxNx3 array, original batch of point clouds\n        Return:\n            BxNx3 array, scaled batch of point clouds\n    """"""\n    B, N, C = batch_data.shape\n    scales = np.random.uniform(scale_low, scale_high, B)\n    for batch_index in range(B):\n        batch_data[batch_index, :, :] *= scales[batch_index]\n    return batch_data\n\n\ndef random_point_dropout(batch_pc, max_dropout_ratio=0.875):\n    """""" batch_pc: BxNx3 """"""\n    for b in range(batch_pc.shape[0]):\n        dropout_ratio = np.random.random() * max_dropout_ratio  # 0~0.875\n        drop_idx = np.where(np.random.random((batch_pc.shape[1])) <= dropout_ratio)[0]\n        if len(drop_idx) > 0:\n            batch_pc[b, drop_idx, :] = batch_pc[b, 0, :]  # set to the first point\n    return batch_pc\n\n\ndef getDataFiles(list_filename):\n    return [line.rstrip() for line in open(list_filename)]\n\n\ndef load_h5(h5_filename):\n    import h5py\n\n    f = h5py.File(h5_filename)\n    data = f[""data""][:]\n    label = f[""label""][:]\n    return (data, label)\n\n\ndef loadDataFile(filename):\n    return load_h5(filename)\n'"
util/tf_util.py,63,"b'"""""" Wrapper functions for TensorFlow layers.\n\nAuthor: Charles R. Qi\nDate: November 2017\n""""""\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef _variable_on_cpu(name, shape, initializer, use_fp16=False):\n    """"""Helper to create a Variable stored on CPU memory.\n  Args:\n    name: name of the variable\n    shape: list of ints\n    initializer: initializer for Variable\n  Returns:\n    Variable Tensor\n  """"""\n    with tf.device(""/cpu:0""):\n        dtype = tf.float16 if use_fp16 else tf.float32\n        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n    return var\n\n\ndef _variable_with_weight_decay(name, shape, stddev, wd, use_xavier=True):\n    """"""Helper to create an initialized Variable with weight decay.\n\n  Note that the Variable is initialized with a truncated normal distribution.\n  A weight decay is added only if one is specified.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    stddev: standard deviation of a truncated Gaussian\n    wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n    use_xavier: bool, whether to use xavier initializer\n\n  Returns:\n    Variable Tensor\n  """"""\n    if use_xavier:\n        initializer = tf.contrib.layers.xavier_initializer()\n    else:\n        initializer = tf.truncated_normal_initializer(stddev=stddev)\n    var = _variable_on_cpu(name, shape, initializer)\n    if wd is not None:\n        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=""weight_loss"")\n        tf.add_to_collection(""losses"", weight_decay)\n    return var\n\n\ndef conv1d(\n    inputs,\n    num_output_channels,\n    kernel_size,\n    scope,\n    stride=1,\n    padding=""SAME"",\n    data_format=""NHWC"",\n    use_xavier=True,\n    stddev=1e-3,\n    weight_decay=None,\n    activation_fn=tf.nn.relu,\n    bn=False,\n    bn_decay=None,\n    is_training=None,\n):\n    """""" 1D convolution with non-linear operation.\n\n  Args:\n    inputs: 3-D tensor variable BxLxC\n    num_output_channels: int\n    kernel_size: int\n    scope: string\n    stride: int\n    padding: \'SAME\' or \'VALID\'\n    data_format: \'NHWC\' or \'NCHW\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        assert data_format == ""NHWC"" or data_format == ""NCHW""\n        if data_format == ""NHWC"":\n            num_in_channels = inputs.get_shape()[-1].value\n        else:\n            num_in_channels = inputs.get_shape()[1].value\n        kernel_shape = [kernel_size, num_in_channels, num_output_channels]\n        kernel = _variable_with_weight_decay(\n            ""weights"",\n            shape=kernel_shape,\n            use_xavier=use_xavier,\n            stddev=stddev,\n            wd=weight_decay,\n        )\n        data_format_1d = ""NWC"" if data_format == ""NHWC"" else ""NCW""\n        outputs = tf.nn.conv1d(\n            inputs, kernel, stride=stride, padding=padding, data_format=data_format_1d\n        )\n        biases = _variable_on_cpu(\n            ""biases"", [num_output_channels], tf.constant_initializer(0.0)\n        )\n        outputs = tf.nn.bias_add(outputs, biases, data_format=data_format)\n\n        if bn:\n            outputs = batch_norm_for_conv1d(\n                outputs,\n                is_training,\n                bn_decay=bn_decay,\n                scope=""bn"",\n                data_format=data_format,\n            )\n\n        if activation_fn is not None:\n            outputs = activation_fn(outputs)\n        return outputs\n\n\ndef conv2d(\n    inputs,\n    num_output_channels,\n    kernel_size,\n    scope,\n    stride=[1, 1],\n    padding=""SAME"",\n    data_format=""NHWC"",\n    use_xavier=True,\n    stddev=1e-3,\n    weight_decay=None,\n    activation_fn=tf.nn.relu,\n    bn=False,\n    bn_decay=None,\n    is_training=None,\n):\n    """""" 2D convolution with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    data_format: \'NHWC\' or \'NCHW\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_h, kernel_w = kernel_size\n        assert data_format == ""NHWC"" or data_format == ""NCHW""\n        if data_format == ""NHWC"":\n            num_in_channels = inputs.get_shape()[-1].value\n        elif data_format == ""NCHW"":\n            num_in_channels = inputs.get_shape()[1].value\n        kernel_shape = [kernel_h, kernel_w, num_in_channels, num_output_channels]\n        kernel = _variable_with_weight_decay(\n            ""weights"",\n            shape=kernel_shape,\n            use_xavier=use_xavier,\n            stddev=stddev,\n            wd=weight_decay,\n        )\n        stride_h, stride_w = stride\n        outputs = tf.nn.conv2d(\n            inputs,\n            kernel,\n            [1, stride_h, stride_w, 1],\n            padding=padding,\n            data_format=data_format,\n        )\n        biases = _variable_on_cpu(\n            ""biases"", [num_output_channels], tf.constant_initializer(0.0)\n        )\n        outputs = tf.nn.bias_add(outputs, biases, data_format=data_format)\n\n        if bn:\n            outputs = batch_norm_for_conv2d(\n                outputs,\n                is_training,\n                bn_decay=bn_decay,\n                scope=""bn"",\n                data_format=data_format,\n            )\n\n        if activation_fn is not None:\n            outputs = activation_fn(outputs)\n        return outputs\n\n\ndef conv2d_transpose(\n    inputs,\n    num_output_channels,\n    kernel_size,\n    scope,\n    stride=[1, 1],\n    padding=""SAME"",\n    use_xavier=True,\n    stddev=1e-3,\n    weight_decay=None,\n    activation_fn=tf.nn.relu,\n    bn=False,\n    bn_decay=None,\n    is_training=None,\n):\n    """""" 2D convolution transpose with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n\n  Note: conv2d(conv2d_transpose(a, num_out, ksize, stride), a.shape[-1], ksize, stride) == a\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_h, kernel_w = kernel_size\n        num_in_channels = inputs.get_shape()[-1].value\n        kernel_shape = [\n            kernel_h,\n            kernel_w,\n            num_output_channels,\n            num_in_channels,\n        ]  # reversed to conv2d\n        kernel = _variable_with_weight_decay(\n            ""weights"",\n            shape=kernel_shape,\n            use_xavier=use_xavier,\n            stddev=stddev,\n            wd=weight_decay,\n        )\n        stride_h, stride_w = stride\n\n        # from slim.convolution2d_transpose\n        def get_deconv_dim(dim_size, stride_size, kernel_size, padding):\n            dim_size *= stride_size\n\n            if padding == ""VALID"" and dim_size is not None:\n                dim_size += max(kernel_size - stride_size, 0)\n            return dim_size\n\n        # caculate output shape\n        batch_size = inputs.get_shape()[0].value\n        height = inputs.get_shape()[1].value\n        width = inputs.get_shape()[2].value\n        out_height = get_deconv_dim(height, stride_h, kernel_h, padding)\n        out_width = get_deconv_dim(width, stride_w, kernel_w, padding)\n        output_shape = [batch_size, out_height, out_width, num_output_channels]\n\n        outputs = tf.nn.conv2d_transpose(\n            inputs, kernel, output_shape, [1, stride_h, stride_w, 1], padding=padding\n        )\n        biases = _variable_on_cpu(\n            ""biases"", [num_output_channels], tf.constant_initializer(0.0)\n        )\n        outputs = tf.nn.bias_add(outputs, biases)\n\n        if bn:\n            outputs = batch_norm_for_conv2d(\n                outputs, is_training, bn_decay=bn_decay, scope=""bn""\n            )\n\n        if activation_fn is not None:\n            outputs = activation_fn(outputs)\n        return outputs\n\n\ndef conv3d(\n    inputs,\n    num_output_channels,\n    kernel_size,\n    scope,\n    stride=[1, 1, 1],\n    padding=""SAME"",\n    use_xavier=True,\n    stddev=1e-3,\n    weight_decay=None,\n    activation_fn=tf.nn.relu,\n    bn=False,\n    bn_decay=None,\n    is_training=None,\n):\n    """""" 3D convolution with non-linear operation.\n\n  Args:\n    inputs: 5-D tensor variable BxDxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 3 ints\n    scope: string\n    stride: a list of 3 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_d, kernel_h, kernel_w = kernel_size\n        num_in_channels = inputs.get_shape()[-1].value\n        kernel_shape = [\n            kernel_d,\n            kernel_h,\n            kernel_w,\n            num_in_channels,\n            num_output_channels,\n        ]\n        kernel = _variable_with_weight_decay(\n            ""weights"",\n            shape=kernel_shape,\n            use_xavier=use_xavier,\n            stddev=stddev,\n            wd=weight_decay,\n        )\n        stride_d, stride_h, stride_w = stride\n        outputs = tf.nn.conv3d(\n            inputs, kernel, [1, stride_d, stride_h, stride_w, 1], padding=padding\n        )\n        biases = _variable_on_cpu(\n            ""biases"", [num_output_channels], tf.constant_initializer(0.0)\n        )\n        outputs = tf.nn.bias_add(outputs, biases)\n\n        if bn:\n            outputs = batch_norm_for_conv3d(\n                outputs, is_training, bn_decay=bn_decay, scope=""bn""\n            )\n\n        if activation_fn is not None:\n            outputs = activation_fn(outputs)\n        return outputs\n\n\ndef fully_connected(\n    inputs,\n    num_outputs,\n    scope,\n    use_xavier=True,\n    stddev=1e-3,\n    weight_decay=None,\n    activation_fn=tf.nn.relu,\n    bn=False,\n    bn_decay=None,\n    is_training=None,\n):\n    """""" Fully connected layer with non-linear operation.\n\n  Args:\n    inputs: 2-D tensor BxN\n    num_outputs: int\n\n  Returns:\n    Variable tensor of size B x num_outputs.\n  """"""\n    with tf.variable_scope(scope) as sc:\n        num_input_units = inputs.get_shape()[-1].value\n        weights = _variable_with_weight_decay(\n            ""weights"",\n            shape=[num_input_units, num_outputs],\n            use_xavier=use_xavier,\n            stddev=stddev,\n            wd=weight_decay,\n        )\n        outputs = tf.matmul(inputs, weights)\n        biases = _variable_on_cpu(""biases"", [num_outputs], tf.constant_initializer(0.0))\n        outputs = tf.nn.bias_add(outputs, biases)\n\n        if bn:\n            outputs = batch_norm_for_fc(outputs, is_training, bn_decay, ""bn"")\n\n        if activation_fn is not None:\n            outputs = activation_fn(outputs)\n        return outputs\n\n\ndef max_pool2d(inputs, kernel_size, scope, stride=[2, 2], padding=""VALID""):\n    """""" 2D max pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_h, kernel_w = kernel_size\n        stride_h, stride_w = stride\n        outputs = tf.nn.max_pool(\n            inputs,\n            ksize=[1, kernel_h, kernel_w, 1],\n            strides=[1, stride_h, stride_w, 1],\n            padding=padding,\n            name=sc.name,\n        )\n        return outputs\n\n\ndef avg_pool2d(inputs, kernel_size, scope, stride=[2, 2], padding=""VALID""):\n    """""" 2D avg pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_h, kernel_w = kernel_size\n        stride_h, stride_w = stride\n        outputs = tf.nn.avg_pool(\n            inputs,\n            ksize=[1, kernel_h, kernel_w, 1],\n            strides=[1, stride_h, stride_w, 1],\n            padding=padding,\n            name=sc.name,\n        )\n        return outputs\n\n\ndef max_pool3d(inputs, kernel_size, scope, stride=[2, 2, 2], padding=""VALID""):\n    """""" 3D max pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_d, kernel_h, kernel_w = kernel_size\n        stride_d, stride_h, stride_w = stride\n        outputs = tf.nn.max_pool3d(\n            inputs,\n            ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n            strides=[1, stride_d, stride_h, stride_w, 1],\n            padding=padding,\n            name=sc.name,\n        )\n        return outputs\n\n\ndef avg_pool3d(inputs, kernel_size, scope, stride=[2, 2, 2], padding=""VALID""):\n    """""" 3D avg pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n\n  Returns:\n    Variable tensor\n  """"""\n    with tf.variable_scope(scope) as sc:\n        kernel_d, kernel_h, kernel_w = kernel_size\n        stride_d, stride_h, stride_w = stride\n        outputs = tf.nn.avg_pool3d(\n            inputs,\n            ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n            strides=[1, stride_d, stride_h, stride_w, 1],\n            padding=padding,\n            name=sc.name,\n        )\n        return outputs\n\n\ndef batch_norm_template_unused(inputs, is_training, scope, moments_dims, bn_decay):\n    """""" NOTE: this is older version of the util func. it is deprecated.\n  Batch normalization on convolutional maps and beyond...\n  Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n\n  Args:\n      inputs:        Tensor, k-D input ... x C could be BC or BHWC or BDHWC\n      is_training:   boolean tf.Varialbe, true indicates training phase\n      scope:         string, variable scope\n      moments_dims:  a list of ints, indicating dimensions for moments calculation\n      bn_decay:      float or float tensor variable, controling moving average weight\n  Return:\n      normed:        batch-normalized maps\n  """"""\n    with tf.variable_scope(scope) as sc:\n        num_channels = inputs.get_shape()[-1].value\n        beta = _variable_on_cpu(\n            name=""beta"", shape=[num_channels], initializer=tf.constant_initializer(0)\n        )\n        gamma = _variable_on_cpu(\n            name=""gamma"", shape=[num_channels], initializer=tf.constant_initializer(1.0)\n        )\n        batch_mean, batch_var = tf.nn.moments(inputs, moments_dims, name=""moments"")\n        decay = bn_decay if bn_decay is not None else 0.9\n        ema = tf.train.ExponentialMovingAverage(decay=decay)\n        # Operator that maintains moving averages of variables.\n        # Need to set reuse=False, otherwise if reuse, will see moments_1/mean/ExponentialMovingAverage/ does not exist\n        # https://github.com/shekkizh/WassersteinGAN.tensorflow/issues/3\n        with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n            ema_apply_op = tf.cond(\n                is_training,\n                lambda: ema.apply([batch_mean, batch_var]),\n                lambda: tf.no_op(),\n            )\n\n        # Update moving average and return current batch\'s avg and var.\n        def mean_var_with_update():\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n\n        # ema.average returns the Variable holding the average of var.\n        mean, var = tf.cond(\n            is_training,\n            mean_var_with_update,\n            lambda: (ema.average(batch_mean), ema.average(batch_var)),\n        )\n        normed = tf.nn.batch_normalization(inputs, mean, var, beta, gamma, 1e-3)\n    return normed\n\n\ndef batch_norm_template(\n    inputs, is_training, scope, moments_dims_unused, bn_decay, data_format=""NHWC""\n):\n    """""" Batch normalization on convolutional maps and beyond...\n  Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n\n  Args:\n      inputs:        Tensor, k-D input ... x C could be BC or BHWC or BDHWC\n      is_training:   boolean tf.Varialbe, true indicates training phase\n      scope:         string, variable scope\n      moments_dims:  a list of ints, indicating dimensions for moments calculation\n      bn_decay:      float or float tensor variable, controling moving average weight\n      data_format:   \'NHWC\' or \'NCHW\'\n  Return:\n      normed:        batch-normalized maps\n  """"""\n    bn_decay = bn_decay if bn_decay is not None else 0.9\n    return tf.contrib.layers.batch_norm(\n        inputs,\n        center=True,\n        scale=True,\n        is_training=is_training,\n        decay=bn_decay,\n        updates_collections=None,\n        scope=scope,\n        data_format=data_format,\n    )\n\n\ndef batch_norm_for_fc(inputs, is_training, bn_decay, scope):\n    """""" Batch normalization on FC data.\n\n  Args:\n      inputs:      Tensor, 2D BxC input\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n    return batch_norm_template(inputs, is_training, scope, [0], bn_decay)\n\n\ndef batch_norm_for_conv1d(inputs, is_training, bn_decay, scope, data_format):\n    """""" Batch normalization on 1D convolutional maps.\n\n  Args:\n      inputs:      Tensor, 3D BLC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n      data_format: \'NHWC\' or \'NCHW\'\n  Return:\n      normed:      batch-normalized maps\n  """"""\n    return batch_norm_template(\n        inputs, is_training, scope, [0, 1], bn_decay, data_format\n    )\n\n\ndef batch_norm_for_conv2d(inputs, is_training, bn_decay, scope, data_format):\n    """""" Batch normalization on 2D convolutional maps.\n\n  Args:\n      inputs:      Tensor, 4D BHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n      data_format: \'NHWC\' or \'NCHW\'\n  Return:\n      normed:      batch-normalized maps\n  """"""\n    return batch_norm_template(\n        inputs, is_training, scope, [0, 1, 2], bn_decay, data_format\n    )\n\n\ndef batch_norm_for_conv3d(inputs, is_training, bn_decay, scope):\n    """""" Batch normalization on 3D convolutional maps.\n\n  Args:\n      inputs:      Tensor, 5D BDHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n    return batch_norm_template(inputs, is_training, scope, [0, 1, 2, 3], bn_decay)\n\n\ndef dropout(inputs, is_training, scope, keep_prob=0.5, noise_shape=None):\n    """""" Dropout layer.\n\n  Args:\n    inputs: tensor\n    is_training: boolean tf.Variable\n    scope: string\n    keep_prob: float in [0,1]\n    noise_shape: list of ints\n\n  Returns:\n    tensor variable\n  """"""\n    with tf.variable_scope(scope) as sc:\n        outputs = tf.cond(\n            is_training,\n            lambda: tf.nn.dropout(inputs, keep_prob, noise_shape),\n            lambda: inputs,\n        )\n        return outputs\n'"
