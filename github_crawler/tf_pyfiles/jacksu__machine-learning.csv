file_path,api_count,code
src/ml/np.py,0,"b""#encoding=utf8\nimport numpy as np\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\na = np.array([2, 0, 1, 5, 8, 3])\nprint(u'\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae:', a)\n\n#\xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe5\xa4\xa7\xe3\x80\x81\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xe5\x8f\x8a\xe5\xbd\xa2\xe7\x8a\xb6\nprint(u'\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc:', a.min())\nprint(u'\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc:', a.max())\nprint(u'\xe5\xbd\xa2\xe7\x8a\xb6', a.shape)\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x87\xe7\x89\x87\nprint(u'\xe5\x88\x87\xe7\x89\x87\xe6\x93\x8d\xe4\xbd\x9c:')\n# [:-2]\xe5\x90\x8e\xe9\x9d\xa2\xe4\xb8\xa4\xe4\xb8\xaa\xe4\xb8\xa4\xe4\xb8\xaa\xe5\x80\xbc\xe4\xb8\x8d\xe5\x8f\x96\nprint(a[:-2])\n#[-2:]\xe8\xa1\xa8\xe7\xa4\xba\xe5\x90\x8e\xe5\xbe\x80\xe5\x89\x8d\xe6\x95\xb0\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x8c\xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe5\xad\x97\xe8\x87\xb3\xe7\xbb\x93\xe5\xb0\xbe\nprint(a[-2:])\n#[:1]\xe8\xa1\xa8\xe7\xa4\xba\xe4\xbb\x8e\xe5\xa4\xb4\xe5\xbc\x80\xe5\xa7\x8b\xe8\x8e\xb7\xe5\x8f\x96\xef\xbc\x8c\xe8\x8e\xb7\xe5\x8f\x961\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\nprint(a[:1])\nprint(np.sum(a))\n\n# \xe6\x8e\x92\xe5\xba\x8f\nprint(type(a))\nprint(a.dtype)\na.sort()\nprint(u'\xe6\x8e\x92\xe5\xba\x8f\xe5\x90\x8e:', a)\n\n\n#\xe4\xba\x8c\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\xe6\x93\x8d\xe4\xbd\x9c\n\n\nc = np.array([[1, 2, 3, 4], [4, 5, 6, 7], [7, 8, 9, 10]])\n\n# \xe8\x8e\xb7\xe5\x8f\x96\xe5\x80\xbc\nprint(u'\xe5\xbd\xa2\xe7\x8a\xb6:', c.shape)\nprint(u'\xe8\x8e\xb7\xe5\x8f\x96\xe5\x80\xbc:', c[1][0])\nprint(u'\xe8\x8e\xb7\xe5\x8f\x96\xe6\x9f\x90\xe8\xa1\x8c:')\nprint(c[1][:])\nprint(u'\xe8\x8e\xb7\xe5\x8f\x96\xe6\x9f\x90\xe8\xa1\x8c\xe5\xb9\xb6\xe5\x88\x87\xe7\x89\x87:')\nprint(c[0][:-1])\nprint(c[0][-1:])\n\n#\xe8\x8e\xb7\xe5\x8f\x96\xe5\x85\xb7\xe4\xbd\x93\xe6\x9f\x90\xe5\x88\x97\xe5\x80\xbc\nprint(u'\xe8\x8e\xb7\xe5\x8f\x96\xe7\xac\xac3\xe5\x88\x97:')\n#np.newaxis\xe5\xa2\x9e\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe6\x96\xb0\xe7\xbb\xb4\xe5\xba\xa6\nprint(c[:,np.newaxis, 2])\n\n\n#\xe5\x87\xbd\xe6\x95\xb0\n#sin\nprint(np.sin(np.pi/6))\nprint(np.sin(np.pi/2))\nprint(np.tan(np.pi/2))\n\nprint(np.arange(0,4))\n\nprint(np.random.random_integers(0,5,6))\n"""
src/ml/pd.py,0,"b'#encoding=utf8\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ns = pd.Series([1,3,5,np.nan,6,8])\nprint(s)\ndates = pd.date_range(\'20130101\', periods=6)\nprint(dates)\n#\xe5\x88\x9b\xe5\xbb\xbaDataFrame\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list(\'ABCD\'))\nprint(df)\n#\xe9\x80\x9a\xe8\xbf\x87\xe5\xad\x97\xe5\x85\xb8\xe5\x88\x9b\xe5\xbb\xbaDataFrame\nf2 = pd.DataFrame({ \'A\' : 1.,\n                    \'B\' : pd.Timestamp(\'20130102\'),\n                    \'C\' : pd.Series(1,index=list(range(4)),dtype=\'float32\'),\n                    \'D\' : np.array([3] * 4,dtype=\'int32\'),\n                    \'E\' : pd.Categorical([""test"",""train"",""test"",""train""]),\n                    \'F\' : \'foo\' })\nprint(f2)\n\n#\xe6\x8e\xa2\xe7\xb4\xa2\xe6\x95\xb0\xe6\x8d\xae\n\nprint(""\xe5\x89\x8d\xe4\xba\x94\xe8\xa1\x8c\xef\xbc\x9a"",df.head())\nprint(""\xe5\x90\x8e\xe4\xb8\x89\xe8\xa1\x8c\xef\xbc\x9a"",df.tail(3))\nprint(""index: "",df.index)\nprint(""columns: "",df.columns)\nprint(""values: "",df.values)\nprint(""describe: "",df.describe())\nprint(""\xe8\xbd\xac\xe7\xbd\xae\xef\xbc\x9a"",df.T)\nprint(""\xe6\x8c\x89\xe7\x85\xa7axis\xe6\x8e\x92\xe5\x88\x97\xef\xbc\x9a"",df.sort_index(axis=0, ascending=False))\nprint(""\xe6\x8c\x89\xe7\x85\xa7\xe6\x9f\x90\xe5\x88\x97\xe6\x8e\x92\xe5\xba\x8f\xef\xbc\x9a"",df.sort_values(by=\'B\'))\nprint(""\xe5\x88\xa0\xe9\x99\xa4nan\xef\xbc\x9a"",s.dropna(how=\'any\'))\nprint(""\xe5\xa1\xab\xe5\x85\x85nan\xe5\x80\xbc\xef\xbc\x9a"",s.fillna(0))\n'"
src/ml/plt.py,0,"b'\n# coding: utf-8\n\n# In[1]:\n\n\nimport pandas as pd\ntweets = pd.read_csv(""tweets.csv"")\ntweets.head()\n\n\n# In[3]:\n\n\ndef get_candidate(row):\n        candidates = []\n        text = row[""text""].lower()\n        if ""clinton"" in text or ""hillary"" in text:\n            candidates.append(""clinton"")\n        if ""trump"" in text or ""donald"" in text:\n            candidates.append(""trump"")\n        if ""sanders"" in text or ""bernie"" in text:\n            candidates.append(""sanders"")\n        return "","".join(candidates)\n    \ntweets[""candidate""] = tweets.apply(get_candidate,axis=1)\ntweets.head()\n\n\n# In[14]:\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\ncounts = tweets[""candidate""].value_counts()\nplt.bar(range(len(counts)), counts)\nplt.show()\n\n\n# In[16]:\n\n\n#\xe7\x94\xa8\xe6\x88\xb7\xe5\xb9\xb4\xe9\xbe\x84\xe7\xbb\x9f\xe8\xae\xa1\nfrom datetime import datetime\n    \ntweets[""created""] = pd.to_datetime(tweets[""created""])\ntweets[""user_created""] = pd.to_datetime(tweets[""user_created""])\n    \ntweets[""user_age""] = tweets[""user_created""].apply(lambda x: (datetime.now() - x).total_seconds() / 3600 / 24 / 365)\nplt.hist(tweets[""user_age""])\nplt.title(""Tweets mentioning candidates"")\nplt.xlabel(""Twitter account age in years"")\nplt.ylabel(""# of tweets"")\nplt.show()\n\n\n# In[23]:\n\n\ncl_tweets = tweets[""user_age""][tweets[""candidate""] == ""clinton""]\nsa_tweets = tweets[""user_age""][tweets[""candidate""] == ""sanders""]\ntr_tweets = tweets[""user_age""][tweets[""candidate""] == ""trump""]\nplt.hist([\n        cl_tweets, \n        sa_tweets, \n        tr_tweets\n        ],\n    stacked=True, \n    label=[""clinton"", ""sanders"", ""trump""]\n)\nplt.legend()\nplt.title(""Tweets mentioning each candidate"")\nplt.xlabel(""Twitter account age in years"")\nplt.ylabel(""# of tweets"")\nplt.annotate(\'More Trump tweets\', xy=(2, 35000), xytext=(3, 35000),\n                arrowprops=dict(facecolor=\'black\'))\nplt.show()\n\n\n# In[24]:\n\n\nimport matplotlib.colors as colors\n    \ntweets[""red""] = tweets[""user_bg_color""].apply(lambda x: colors.hex2color(\'#{0}\'.format(x))[0])\ntweets[""blue""] = tweets[""user_bg_color""].apply(lambda x: colors.hex2color(\'#{0}\'.format(x))[2])\nfig, axes = plt.subplots(nrows=2, ncols=2)\nax0, ax1, ax2, ax3 = axes.flat\n    \nax0.hist(tweets[""red""])\nax0.set_title(\'Red in backgrounds\')\n    \nax1.hist(tweets[""red""][tweets[""candidate""] == ""trump""].values)\nax1.set_title(\'Red in Trump tweeters\')\n    \nax2.hist(tweets[""blue""])\nax2.set_title(\'Blue in backgrounds\')\n    \nax3.hist(tweets[""blue""][tweets[""candidate""] == ""trump""].values)\nax3.set_title(\'Blue in Trump tweeters\')\n    \nplt.tight_layout()\nplt.show()\n\n\n# In[26]:\n\n\ngr = tweets.groupby(""candidate"").agg([np.mean, np.std])\n    \nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(7, 7))\nax0, ax1 = axes.flat\n    \nstd = gr[""polarity""][""std""].iloc[1:]\nmean = gr[""polarity""][""mean""].iloc[1:]\nax0.bar(range(len(std)), std)\nax0.set_xticklabels(std.index, rotation=30)\nax0.set_title(\'Standard deviation of tweet sentiment\')\n    \nax1.bar(range(len(mean)), mean)\nax1.set_xticklabels(mean.index, rotation=45)\nax1.set_title(\'Mean tweet sentiment\')\n    \nplt.tight_layout()\nplt.show()\n'"
src/ml/recommend.py,0,"b""import numpy as np\nimport pandas  as pd\n\nheader = ['user_id', 'item_id', 'rating', 'timestamp']\ndf = pd.read_csv('ml-100k/u.data', sep='\\t', names=header)\nn_users = df.user_id.unique().shape[0]\nn_items = df.item_id.unique().shape[0]\nprint('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))\n#\xe4\xbd\xa0\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe5\x89\xb2\xe6\x88\x90\xe6\xb5\x8b\xe8\xaf\x95\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x82Cross_validation.train_test_split\n#\xe6\xa0\xb9\xe6\x8d\xae\xe6\xb5\x8b\xe8\xaf\x95\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xef\xbc\x88test_size\xef\xbc\x89\xef\xbc\x8c\xe6\x9c\xac\xe4\xbe\x8b\xe4\xb8\xad\xe6\x98\xaf0.25\xef\xbc\x8c\xe6\x9d\xa5\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe6\xb7\xb7\xe6\xb4\x97\xe5\xb9\xb6\xe5\x88\x86\xe5\x89\xb2\xe6\x88\x90\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\nfrom sklearn import model_selection  as ms\ntrain_data, test_data = ms.train_test_split(df, test_size=0.25)\n#Create two user-item matrices, one for training and another for testing\ntrain_data_matrix = np.zeros((n_users, n_items))\nfor line in train_data.itertuples():\n    train_data_matrix[line[1]-1, line[2]-1] = line[3] \ntest_data_matrix = np.zeros((n_users, n_items))\nfor line in test_data.itertuples():\n    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n    \nfrom sklearn.metrics.pairwise import pairwise_distances\nuser_similarity = pairwise_distances(train_data_matrix, metric='cosine')\nitem_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\nprint(user_similarity)\n\ndef predict(ratings, similarity, type='user'):\n    #ratings.mean(axis=1) \xe6\x8c\x89\xe8\xa1\x8c\xe6\xb1\x82\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc\n    if type == 'user':\n        mean_user_rating = ratings.mean(axis=1)\n        #You use np.newaxis so that mean_user_rating has same format as ratings\n        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n    elif type == 'item':\n        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])     \n    return pred\n    \nitem_prediction = predict(train_data_matrix, item_similarity, type='item')\nuser_prediction = predict(train_data_matrix, user_similarity, type='user')\n"""
src/ml/sci.py,0,"b'\n# coding: utf-8\n\n# In[2]:\n\n\nimport numpy as np\nfrom scipy import linalg\narr = np.array([[1, 2],[3, 4]])\n##\xe7\x9f\xa9\xe9\x98\xb5\xe8\xa1\x8c\xe5\x88\x97\xe5\xbc\x8f\nprint(""\xe7\x9f\xa9\xe9\x98\xb5\xe8\xa1\x8c\xe5\x88\x97\xe5\xbc\x8f\xef\xbc\x9a"",linalg.det(arr))\nprint(""\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe9\x80\x86\xef\xbc\x9a"",linalg.inv(arr))\n\n\n# In[5]:\n\n\n#\xe5\xa5\x87\xe5\xbc\x82\xe5\x80\xbc\xe5\x88\x86\xe8\xa7\xa3\narr = np.arange(9).reshape((3, 3)) + np.diag([1, 0, 1])\nuarr, spec, vharr = linalg.svd(arr)\nprint(spec)\nsarr = np.diag(spec)\nsvd_mat = uarr.dot(sarr).dot(vharr)\nprint(svd_mat)\nnp.allclose(arr,svd_mat)\n\n\n# In[10]:\n\n\n##\xe5\x82\x85\xe9\x87\x8c\xe5\x8f\xb6\xe5\x8f\x98\xe6\x8d\xa2\n##\xe4\xbc\x98\xe5\x8c\x96\nfrom scipy import optimize\ndef f(x):\n    return x**2 + 10*np.sin(x)\nimport matplotlib.pyplot as plt\nx = np.arange(-10, 10, 0.1)\nplt.plot(x, f(x)) \nplt.show() \n##bfgs\xe4\xbe\x9d\xe8\xb5\x96\xe4\xba\x8e\xe5\x88\x9d\xe5\xa7\x8b\xe7\x82\xb9\xef\xbc\x8c\xe6\x9c\x89\xe5\x8f\xaf\xe8\x83\xbd\xe5\xbe\x97\xe5\x88\xb0\xe5\xb1\x80\xe9\x83\xa8\xe6\x9c\x80\xe5\xb0\x8f\noptimize.fmin_bfgs(f, 0)\n\n\n# In[12]:\n\n\noptimize.fmin_bfgs(f, 3)\n\n\n# In[13]:\n\n\n##\xe5\x85\xa8\xe5\xb1\x80\xe6\x9c\x80\xe4\xbc\x98\noptimize.basinhopping(f, 0)\n\n\n# In[15]:\n\n\n#\xe8\xae\xa1\xe7\xae\x97\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe6\xa0\xb9\n#1 \xe5\x8f\xaa\xe6\xb1\x82\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaa\nroot = optimize.fsolve(f, 1)\nroot\n\n\n# In[16]:\n\n\n##\xe6\x9b\xb2\xe7\xba\xbf\xe6\x8b\x9f\xe5\x90\x88\nxdata = np.linspace(-10, 10, num=20)\nydata = f(xdata) + np.random.randn(xdata.size)\n#\xe5\x81\x87\xe8\xae\xbe\xe6\xbb\xa1\xe8\xb6\xb3\xe5\x87\xbd\xe6\x95\xb0f2\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe6\xb1\x82a\xe3\x80\x81b\ndef f2(x, a, b):\n     return a*x**2 + b*np.sin(x)\nguess = [2, 2]\nparams, params_covariance = optimize.curve_fit(f2, xdata, ydata, guess)\nparams\n\n\n# In[27]:\n\n\n#\xe7\xbb\x9f\xe8\xae\xa1\na = np.random.normal(size=1000)\nbins = np.arange(-4, 5)\nprint(bins)\nhistogram = np.histogram(a, bins=bins, normed=True)[0]\nprint(histogram)\nbins = 0.5*(bins[1:] + bins[:-1])\nprint(bins)\nfrom scipy import stats\n#pdf\xe6\xa6\x82\xe7\x8e\x87\xe5\xaf\x86\xe5\xba\xa6\xe5\x87\xbd\xe6\x95\xb0probability density function\nb = stats.norm.pdf(bins)\nprint(""pdf:"",b)\nplt.plot(bins, histogram)\nplt.plot(bins, b)\nplt.show()\nloc, std = stats.norm.fit(a)\nprint(""loc:""+str(loc)+""std:""+str(std))\n#\xe4\xb8\xad\xe4\xbd\x8d\xe6\x95\xb0\nnp.median(a)\n\n\n# In[28]:\n\n\n#50\xe7\x99\xbe\xe5\x88\x86\xe4\xbd\x8d\nstats.scoreatpercentile(a, 50)\n\n\n# In[29]:\n\n\n#t\xe6\xa3\x80\xe9\xaa\x8c\na = np.random.normal(0, 1, size=100)\nb = np.random.normal(1, 1, size=10)\nstats.ttest_ind(a, b)\n\n\n# In[ ]:\n'"
src/ml/wordcloudtest.py,0,"b'#encoding=utf8\nfrom pyecharts import WordCloud\nfrom snownlp import SnowNLP\nimport jieba\n\n##\xe8\xaf\x8d\xe4\xba\x91\n\nfilename = ""wdqbs.txt""\nwith open(filename) as f:\n mytext = f.read()\n#print mytext\n\ns= SnowNLP(unicode(mytext,\'utf8\'))\nfor word in s.keywords(10):\n    print word.encode(\'utf8\')\n\nseg_list = jieba.cut(mytext)\n\npunct = set(u\'\'\':!),.:;?]}\xc2\xa2\'""\xe3\x80\x81\xe3\x80\x82\xe3\x80\x89\xe3\x80\x8b\xe3\x80\x8d\xe3\x80\x8f\xe3\x80\x91\xe3\x80\x95\xe3\x80\x97\xe3\x80\x9e\xef\xb8\xb0\xef\xb8\xb1\xef\xb8\xb3\xef\xb9\x90\xef\xbd\xa4\xef\xb9\x92\n\xef\xb9\x94\xef\xb9\x95\xef\xb9\x96\xef\xb9\x97\xef\xb9\x9a\xef\xb9\x9c\xef\xb9\x9e\xef\xbc\x81\xef\xbc\x89\xef\xbc\x8c\xef\xbc\x8e\xef\xbc\x9a\xef\xbc\x9b\xef\xbc\x9f\xef\xbd\x9c\xef\xbd\x9d\xef\xb8\xb4\xef\xb8\xb6\xef\xb8\xb8\xef\xb8\xba\xef\xb8\xbc\xef\xb8\xbe\xef\xb9\x80\xef\xb9\x82\xef\xb9\x84\xef\xb9\x8f\xef\xbd\xa4\xef\xbd\x9e\xef\xbf\xa0\n\xe3\x80\x85\xe2\x80\x96\xe2\x80\xa2\xc2\xb7\xcb\x87\xcb\x89\xe2\x80\x95--\xe2\x80\xb2\xe2\x80\x99\xe2\x80\x9d([{\xc2\xa3\xc2\xa5\'""\xe2\x80\xb5\xe3\x80\x88\xe3\x80\x8a\xe3\x80\x8c\xe3\x80\x8e\xe3\x80\x90\xe3\x80\x94\xe3\x80\x96\xef\xbc\x88\xef\xbc\xbb\xef\xbd\x9b\xef\xbf\xa1\xef\xbf\xa5\xe3\x80\x9d\xef\xb8\xb5\xef\xb8\xb7\xef\xb8\xb9\xef\xb8\xbb\n\xef\xb8\xbd\xef\xb8\xbf\xef\xb9\x81\xef\xb9\x83\xef\xb9\x99\xef\xb9\x9b\xef\xb9\x9d\xef\xbc\x88\xef\xbd\x9b\xe2\x80\x9c\xe2\x80\x98-\xe2\x80\x94_\xe2\x80\xa6\'\'\')\n# \xe5\xaf\xb9str/unicode\nfilterpunt = lambda s: \'\'.join(filter(lambda x: x not in punct, s))\n# \xe5\xaf\xb9list\nfilterpuntl = lambda l: list(filter(lambda x: x not in punct, l))\n\ndict={}\nfor word in filterpuntl(seg_list):\n    if word in dict:\n        dict[word]=int(dict[word])+1\n    else:\n        dict[word]=1\nname=[]\nfor word in dict.keys():\n    name.append(word.encode(\'utf8\'))\nprint name\nvalue = dict.values()\nprint value\nwordcloud = WordCloud(width=1300, height=620)\nwordcloud.add("""", name, value, word_size_range=[20, 100])\nwordcloud.show_config()\nwordcloud.render()\n'"
