file_path,api_count,code
input_3Dimage.py,2,"b""# A script to load images and make batch.\n# Dependency: 'nibabel' to load MRI (NIFTI) images\n# Reference: http://blog.naver.com/kjpark79/220783765651\n\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport nibabel as nib\n\nFLAGS = tf.app.flags.FLAGS\nFLAGS.width = 256\nFLAGS.height = 256\nFLAGS.depth = 40 # 3\nbatch_index = 0\nfilenames = []\n\n# user selection\nFLAGS.data_dir = '/home/ikbeom/Desktop/DL/MNIST_simpleCNN/data'\nFLAGS.num_class = 4\n\ndef get_filenames(data_set):\ni    global filenames\n    labels = []\n\n    with open(FLAGS.data_dir + '/labels.txt') as f:\n        for line in f:\n            inner_list = [elt.strip() for elt in line.split(',')]\n            labels += inner_list\n\n    for i, label in enumerate(labels):\n        list = os.listdir(FLAGS.data_dir  + '/' + data_set + '/' + label)\n        for filename in list:\n            filenames.append([label + '/' + filename, i])\n\n    random.shuffle(filenames)\n\n\ndef get_data_MRI(sess, data_set, batch_size):\n    global batch_index, filenames\n\n    if len(filenames) == 0: get_filenames(data_set) \n    max = len(filenames)\n\n    begin = batch_index\n    end = batch_index + batch_size\n\n    if end >= max:\n        end = max\n        batch_index = 0\n\n    x_data = np.array([], np.float32)\n    y_data = np.zeros((batch_size, FLAGS.num_class)) # zero-filled list for 'one hot encoding'\n    index = 0\n\n    for i in range(begin, end):\n        \n        imagePath = FLAGS.data_dir + '/' + data_set + '/' + filenames[i][0]\n        FA_org = nib.load(imagePath)\n        FA_data = FA_org.get_data()  # 256x256x40; numpy.ndarray\n        \n        # TensorShape([Dimension(256), Dimension(256), Dimension(40)])                       \n        resized_image = tf.image.resize_images(images=FA_data, size=(FLAGS.width,FLAGS.height), method=1)\n\n        image = sess.run(resized_image)  # (256,256,40)\n        x_data = np.append(x_data, np.asarray(image, dtype='float32')) # (image.data, dtype='float32')\n        y_data[index][filenames[i][1]] = 1  # assign 1 to corresponding column (one hot encoding)\n        index += 1\n\n    batch_index += batch_size  # update index for the next batch\n    x_data_ = x_data.reshape(batch_size, FLAGS.height * FLAGS.width * FLAGS.depth)\n\n    return x_data_, y_data\n"""
simpleCNN_MRI.py,23,"b'# A simple CNN to predict certain characteristics of the human subject from MRI images.\n# 3d convolution is used in each layer.\n# Reference: https://www.tensorflow.org/get_started/mnist/pros, http://blog.naver.com/kjpark79/220783765651\n# Adjust needed for your dataset e.g., max pooling, convolution parameters, training_step, batch size, etc\n\nwidth = 256\nheight = 256\ndepth = 40\nnLabel = 4\n\n# Start TensorFlow InteractiveSession\nimport input_3Dimage\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\n# Placeholders (MNIST image:28x28pixels=784, label=10)\nx = tf.placeholder(tf.float32, shape=[None, width*height*depth]) # [None, 28*28]\ny_ = tf.placeholder(tf.float32, shape=[None, nLabel])  # [None, 10]\n\n## Weight Initialization\n# Create lots of weights and biases & Initialize with a small positive number as we will use ReLU\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n\n## Convolution and Pooling\n# Convolution here: stride=1, zero-padded -> output size = input size\ndef conv3d(x, W):\n  return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding=\'SAME\') # conv2d, [1, 1, 1, 1]\n\n# Pooling: max pooling over 2x2 blocks\ndef max_pool_2x2(x):  # tf.nn.max_pool. ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]\n  return tf.nn.max_pool3d(x, ksize=[1, 4, 4, 4, 1], strides=[1, 4, 4, 4, 1], padding=\'SAME\')\n\n\n## First Convolutional Layer\n# Conv then Max-pooling. 1st layer will have 32 features for each 5x5 patch. (1 feature -> 32 features)\nW_conv1 = weight_variable([5, 5, 5, 1, 32])  # shape of weight tensor = [5,5,1,32]\nb_conv1 = bias_variable([32])  # bias vector for each output channel. = [32]\n\n# Reshape \'x\' to a 4D tensor (2nd dim=image width, 3rd dim=image height, 4th dim=nColorChannel)\nx_image = tf.reshape(x, [-1,width,height,depth,1]) # [-1,28,28,1]\nprint(x_image.get_shape) # (?, 256, 256, 40, 1)  # -> output image: 28x28 x1\n\n# x_image * weight tensor + bias -> apply ReLU -> apply max-pool\nh_conv1 = tf.nn.relu(conv3d(x_image, W_conv1) + b_conv1)  # conv2d, ReLU(x_image * weight + bias)\nprint(h_conv1.get_shape) # (?, 256, 256, 40, 32)  # -> output image: 28x28 x32\nh_pool1 = max_pool_2x2(h_conv1)  # apply max-pool \nprint(h_pool1.get_shape) # (?, 128, 128, 20, 32)  # -> output image: 14x14 x32\n\n\n## Second Convolutional Layer\n# Conv then Max-pooling. 2nd layer will have 64 features for each 5x5 patch. (32 features -> 64 features)\nW_conv2 = weight_variable([5, 5, 5, 32, 64]) # [5, 5, 32, 64]\nb_conv2 = bias_variable([64]) # [64]\n\nh_conv2 = tf.nn.relu(conv3d(h_pool1, W_conv2) + b_conv2)  # conv2d, .ReLU(x_image * weight + bias)\nprint(h_conv2.get_shape) # (?, 128, 128, 20, 64)  # -> output image: 14x14 x64\nh_pool2 = max_pool_2x2(h_conv2)  # apply max-pool \nprint(h_pool2.get_shape) # (?, 64, 64, 10, 64)    # -> output image: 7x7 x64\n\n\n## Densely Connected Layer (or fully-connected layer)\n# fully-connected layer with 1024 neurons to process on the entire image\nW_fc1 = weight_variable([16*16*3*64, 1024])  # [7*7*64, 1024]\nb_fc1 = bias_variable([1024]) # [1024]]\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 16*16*3*64])  # -> output image: [-1, 7*7*64] = 3136\nprint(h_pool2_flat.get_shape)  # (?, 2621440)\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  # ReLU(h_pool2_flat x weight + bias)\nprint(h_fc1.get_shape) # (?, 1024)  # -> output: 1024\n\n## Dropout (to reduce overfitting; useful when training very large neural network)\n# We will turn on dropout during training & turn off during testing\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\nprint(h_fc1_drop.get_shape)  # -> output: 1024\n\n## Readout Layer\nW_fc2 = weight_variable([1024, nLabel]) # [1024, 10]\nb_fc2 = bias_variable([nLabel]) # [10]\n\ny_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\nprint(y_conv.get_shape)  # -> output: 10\n\n## Train and Evaluate the Model\n# set up for optimization (optimizer:ADAM)\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\ntrain_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)  # 1e-4\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nsess.run(tf.global_variables_initializer())\n\n# Include keep_prob in feed_dict to control dropout rate.\nfor i in range(100):\n    batch = get_data_MRI(sess,\'train\',20)\n    # Logging every 100th iteration in the training process.\n    if i%5 == 0:\n        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n        print(""step %d, training accuracy %g""%(i, train_accuracy))\n    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\n# Evaulate our accuracy on the test data\ntestset = get_data_MRI(sess,\'test\',30)\nprint(""test accuracy %g""%accuracy.eval(feed_dict={x: testset[0], y_: teseset[1], keep_prob: 1.0}))\n'"
