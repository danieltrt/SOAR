file_path,api_count,code
clients/python/dd_bench.py,0,"b'""""""\nDeepDetect benchmark tool\n\nLicence:\nCopyright (c) 2017 Emmanuel Benazera\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n""""""\n\n""""""\nThis is a benchmark for image services with DeepDetect.\n\nInstructions:\n- wget https://deepdetect.com/stuff/bench.tar.gz\n- untar bench.tar.gz onto the machine where your DeepDetect server runs\n- remotely benchmark your server with (adapt options as needed):\n  \n  python dd_bench.py --host yourhost --port 8080 --sname faces --img-width 300 --img-height 300 --gpu --remote-bench-data-dir /server/path/to/bench/ --max-batch-size 64\n""""""\n\nimport time\nimport sys\nimport argparse\nimport csv\nfrom dd_client import DD\n\nparser = argparse.ArgumentParser(description=\'DeepDetect benchmark tool\')\nparser.add_argument(\'--host\',help=\'server host\',default=\'localhost\')\nparser.add_argument(\'--port\',help=\'server port\',type=int,default=8080)\nparser.add_argument(\'--sname\',help=\'service name\')\nparser.add_argument(\'--img-width\',help=\'image width\',type=int,default=224)\nparser.add_argument(\'--img-height\',help=\'image height\',type=int,default=224)\nparser.add_argument(\'--gpu\',help=\'whether to bench GPU\',action=\'store_true\')\nparser.add_argument(\'--gpuid\',help=\'gpu id to use\',type=int,default=0)\nparser.add_argument(\'--cpu\',help=\'whether to bench CPU\',action=\'store_true\')\nparser.add_argument(\'--remote-bench-data-dir\',help=\'when bench data directory, when available remotely on the server\')\nparser.add_argument(\'--max-batch-size\',help=\'max batch size to be tested\',type=int,default=256)\nparser.add_argument(\'--max-workspace-size\',help=\'max workspace size for tensort bench\',type=int,default=1024)\nparser.add_argument(\'--list-bench-files\',help=\'file holding the list of bench files\',default=\'list_bench_files.txt\')\nparser.add_argument(\'--npasses\',help=\'number of passes for every batch size\',type=int,default=5)\nparser.add_argument(\'--detection\',help=\'whether benching a detection model\',action=\'store_true\')\nparser.add_argument(\'--segmentation\',help=\'whether benching a segmentation model\',action=\'store_true\')\nparser.add_argument(\'--search\',help=\'whether benching a similarity search service\',action=\'store_true\')\nparser.add_argument(\'--search-multibox\',help=\'whether benching a multibox similarity search service\',action=\'store_true\')\nparser.add_argument(\'--create\',help=\'model\\\'s folder name to create a service\')\nparser.add_argument(\'--nclasses\',help=\'number of classes for service creation\',type=int,default=1000)\nparser.add_argument(\'--auto-kill\',help=\'auto kill the service after benchmarking\',action=\'store_true\')\nparser.add_argument(\'--csv-output\',help=\'CSV file output\')\nparser.add_argument(\'--mllib\', help=\'mllib to bench, ie [tensorrt|ncnn|caffe]\', default=\'caffe\')\nparser.add_argument(\'--datatype\', help=\'datatype for tensorrt [fp16|fp32]\', default=\'fp32\')\nparser.add_argument(\'--recreate\', help=\'recreate service between every batchsize, useful for batch_size dependent precompiling backends (ie tensorRT)\', action=\'store_true\', default=False)\nparser.add_argument(\'--dla\', help=\'use dla\', action=\'store_true\', default = False)\nparser.add_argument(\'--gpu-resize\',help=\'image resizing on gpu\', action=\'store_true\', default = False)\nparser.add_argument(\'--image-interp\',help=\'image interpolation method (nearest, linear, cubic, ...)\')\nargs = parser.parse_args()\n\nhost = args.host\nport = args.port\ndd = DD(host,port)\ndd.set_return_format(dd.RETURN_PYTHON)\nautokill = args.auto_kill\n\n\ndef service_create(bs):\n  # Create a service\n  if args.create:\n    description = \'image classification service\'\n    mllib = args.mllib\n    model = {\'repository\':args.create}\n    parameters_input = {\'connector\':\'image\',\'width\':args.img_width,\'height\':args.img_height}\n    if args.segmentation:\n      parameters_input[\'segmentation\'] = True\n    if args.dla:\n        parameters_mllib = {\'nclasses\':args.nclasses,\'datatype\':args.datatype,\'readEngine\':True,\'writeEngine\':True,\'maxBatchSize\':bs,\'dla\':0, \'maxWorkspaceSize\':args.max_workspace_size}\n    else:    \n        parameters_mllib = {\'nclasses\':args.nclasses,\'datatype\':args.datatype,\'readEngine\':True,\'writeEngine\':True,\'maxBatchSize\':bs,\'maxWorkspaceSize\':args.max_workspace_size}\n    parameters_output = {}\n    dd.put_service(args.sname,model,description,mllib,\n                   parameters_input,parameters_mllib,parameters_output)\n  else:\n    pass\n\nout_csv = None\ncsv_writer = None\nif args.csv_output:\n  out_csv = open(args.csv_output,\'w+\')\n  csv_writer = csv.writer(out_csv)\n  csv_writer.writerow([\'batch_size\',\'mean processing time\',\'mean time per img\'])\n  \nlist_bench_files = []\nwith open(args.list_bench_files) as f:\n    for l in f:\n        list_bench_files.append(args.remote_bench_data_dir + \'/\' + l.rstrip())\ninit_batch_size = 1\nbatch_sizes = []\nl = init_batch_size\nwhile l <= args.max_batch_size:\n    batch_sizes.append(l)\n    if l < 32:\n        l = l * 2\n    else:\n        l += 16\n\nparameters_input = {}\nif not args.image_interp == \'\':\n  parameters_input[\'interp\'] = args.image_interp\nif args.gpu_resize:\n  parameters_input[\'cuda\'] = args.gpu_resize\nparameters_mllib = {\'gpu\':args.gpu,\'gpuid\':args.gpuid}\nparameters_output = {}\nif args.detection:\n    parameters_output[\'confidence_threshold\'] = 0.1\n    if args.search or args.search_multibox:\n      parameters_output[\'search\'] = True\n      parameters_output[\'rois\'] = \'rois\'\n      parameters_output[\'bbox\'] = False\n    else:\n      parameters_output[\'bbox\'] = True\n    if args.search_multibox:\n      parameters_output[\'multibox_rois\'] = True\nelif args.segmentation:\n  parameters_input[\'segmentation\'] = True\nelif args.search:\n  parameters_output[\'search\'] = True\n      \n# First call to load model\ndata = list_bench_files[:1]\nif not args.recreate:\n  if not args.mllib == ""tensorrt"" or args.recreate:\n    service_create(1)\n  else:\n    service_create(args.max_batch_size)\n  classif = dd.post_predict(args.sname,data,parameters_input,parameters_mllib,parameters_output)\n\nfor b in batch_sizes:\n    data = list_bench_files[:b]\n    #print data\n    fail = False\n    if args.recreate:\n      service_create(b)\n      for i in range(5):\n        classif = dd.post_predict(args.sname,data,parameters_input,parameters_mllib,parameters_output)\n    mean_ptime = 0\n    mean_ptime_per_img = 0\n    for i in range(0,args.npasses+1):\n        #print \'testing batch size =\',len(data)\n        classif = dd.post_predict(args.sname,data,parameters_input,parameters_mllib,parameters_output)\n        if classif[\'status\'][\'code\'] == 200:\n            if i == 0:\n                continue # skipping first pass so that the batch resize does not affect timing\n            ptime = classif[\'head\'][\'time\']\n            ptime_per_img = ptime/b\n            mean_ptime += ptime\n            mean_ptime_per_img += ptime_per_img\n            print \'pass\',i,\' batch size =\',b,\' / processing time =\',ptime, \' / time per image = \', ptime_per_img\n        else:\n            print classif[\'status\']\n            # reload model\n            data =list_bench_files[:1]\n            classif = dd.post_predict(args.sname,data,parameters_input,parameters_mllib,parameters_output)\n            fail = True\n            break\n    mean_processing_time = mean_ptime/args.npasses\n    mean_time_per_img = mean_ptime_per_img/args.npasses\n    print \'>>> batch size =\',b,\' / mean processing time =\',mean_ptime/args.npasses, \' / mean time per image =\',mean_ptime_per_img/args.npasses, \' / fps = \', 1000/(mean_ptime_per_img/args.npasses) , \' / fail =\',fail\n    if args.csv_output:\n      csv_writer.writerow([b,mean_processing_time,mean_time_per_img])\n    #break\n    if args.recreate:\n      dd.delete_service(args.sname)\n\n    \nif autokill:\n  dd.delete_service(args.sname)\n  \n'"
clients/python/dd_client.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nDeepDetect Python client\n\nLicence:\nCopyright (c) 2015 Emmanuel Benazera, Evgeny BAZAROV <baz.evgenii@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n""""""\n\nimport base64\nimport os\nimport re\nimport warnings\n\nimport requests\n\nDD_TIMEOUT = 2000  # seconds, for long blocking training calls, as needed\n\nAPI_METHODS_URL = {\n    ""0.1"": {\n        ""info"": ""/info"",\n        ""services"": ""/services"",\n        ""train"": ""/train"",\n        ""predict"": ""/predict"",\n        ""chain"": ""/chain""\n    }\n}\n\ndef _convert_base64(filename):  # return type: Optional[str]\n    if os.path.isfile(filename):\n        with open(filename, \'rb\') as fh:\n            data = fh.read()\n            x = base64.encodebytes(data)\n            return x.decode(\'ascii\').replace(\'\\n\', \'\')\n    if re.match(\'^http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|\'\n                \'[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+$\', filename):\n        result = requests.get(filename)\n        if result.status_code != 200:\n            warnings.warn(""{} returned status {}"".format(filename, status))\n            return\n        x = base64.encodebytes(result.content)\n        return x.decode(\'ascii\').replace(\'\\n\', \'\')\n    warnings.warn(""Unable to understand file type:""\n                  "" file not found or url not valid"", RuntimeWarning)\n\n\nclass DD(object):\n    """"""HTTP requests to the DeepDetect server\n    """"""\n\n    # return types\n    RETURN_PYTHON = 0\n    RETURN_JSON = 1\n    RETURN_NONE = 2\n\n    __HTTP = 0\n    __HTTPS = 1\n\n    def __init__(self, host=""localhost"", port=8080, proto=0, path=\'\', apiversion=""0.1""):\n        """""" DD class constructor\n        Parameters:\n        host -- the DeepDetect server host\n        port -- the DeepDetect server port\n        proto -- user http (0,default) or https connection\n        """"""\n        self.apiversion = apiversion\n        self.__urls = API_METHODS_URL[apiversion]\n        self.__host = host\n        self.__port = port\n        self.__path = path\n        self.__proto = proto\n        self.__returntype = self.RETURN_PYTHON\n        if proto == self.__HTTP:\n            self.__ddurl = \'http://%s:%d\' % (host, port)\n        else:\n            self.__ddurl = \'https://%s:%d\' % (host, port)\n        if path:\n            self.__ddurl += path\n            \n    def set_return_format(self, f):\n        assert f == self.RETURN_PYTHON or f == self.RETURN_JSON or f == self.RETURN_NONE\n        self.__returntype = f\n\n    def __return_data(self, r):\n        if self.__returntype == self.RETURN_PYTHON:\n            return r.json()\n        elif self.__returntype == self.RETURN_JSON:\n            return r.text\n        else:\n            return None\n\n    def get(self, method, json=None, params=None):\n        """"""GET to DeepDetect server """"""\n        url = self.__ddurl + method\n        r = requests.get(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def put(self, method, json=None, params=None):\n        """"""PUT request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.put(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def post(self, method, json=None, params=None):\n        """"""POST request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.post(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def delete(self, method, json=None, params=None):\n        """"""DELETE request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.delete(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    # API methods\n    def info(self):\n        """"""Info on the DeepDetect server""""""\n        return self.get(self.__urls[""info""])\n\n    # API services\n    def put_service(self, sname, model, description, mllib, parameters_input, parameters_mllib, parameters_output, mltype=\'supervised\'):\n        """"""\n        Create a service\n        Parameters:\n        sname -- service name as a resource\n        model -- dict with model location and optional templates\n        description -- string describing the service\n        mllib -- ML library name, e.g. caffe\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        data = {""description"": description,\n                ""mllib"": mllib,\n                ""type"": mltype,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""model"": model}\n        return self.put(self.__urls[""services""] + \'/%s\' % sname, json=data)\n\n    def get_service(self, sname):\n        """"""\n        Get information about a service\n        Parameters:\n        sname -- service name as a resource\n        """"""\n        return self.get(self.__urls[""services""] + \'/%s\' % sname)\n\n    def delete_service(self, sname, clear=None):\n        """"""\n        Delete a service\n        Parameters:\n        sname -- service name as a resource\n        clear -- \'full\',\'lib\' or \'mem\', optionally clears model repository data\n        """"""\n        lurl = \'/%s\' % sname\n        if clear:\n            lurl += \'?clear=\' + clear\n        return self.delete(self.__urls[""services""] + lurl)\n\n    # API train\n    def post_train(self, sname, data, parameters_input, parameters_mllib, parameters_output, async=True):\n        """"""\n        Creates a training job\n        Parameters:\n        sname -- service name as a resource\n        async -- whether to run the job as non-blocking\n        data -- array of input data / dataset for training\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        data = {""service"": sname,\n                ""async"": async,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""data"": data}\n        return self.post(self.__urls[""train""], json=data)\n\n    def get_train(self, sname, job=1, timeout=0, measure_hist=False):\n        """"""\n        Get information on a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        timeout -- timeout before obtaining the job status\n        measure_hist -- whether to return the full measure history (e.g. for plotting)\n        """"""\n        params = {""service"": sname,\n                  ""job"": str(job),\n                  ""timeout"": str(timeout)}\n        if measure_hist:\n            params[""parameters.output.measure_hist""] = measure_hist\n        return self.get(self.__urls[""train""], params=params)\n\n    def delete_train(self, sname, job=1):\n        """"""\n        Kills a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        """"""\n        params = {""service"": sname,\n                  ""job"": str(job)}\n        return self.delete(self.__urls[""train""], params=params)\n\n    # API predict\n    def post_predict(self, sname, data, parameters_input, parameters_mllib,\n                     parameters_output, use_base64=False, index_uris=[]):\n        """"""\n        Makes prediction from data and model\n        Parameters:\n        sname -- service name as a resource\n        data -- array of data URI to predict from\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n\n        if use_base64:\n            data = [_convert_base64(d) for d in data]\n\n        data = {""service"": sname,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""data"": data}\n        if index_uris:\n            data[""index_uris""] = index_uris\n        return self.post(self.__urls[""predict""], json=data)\n\n    # API chain\n    def make_call(self, sname, data, parameters_input, parameters_mllib,\n                  parameters_output, use_base64=False, index_uris = []):\n        """"""\n        Creates a dictionary that holds the JSON call,\n        to be added to an array and processed by \n        a post_chain API call. This basically eases the making\n        of chain calls from Python.\n        Parameters are the same as for a post_predict call\n        """"""\n        \n        if use_base64:\n            data = [_convert_base64(d) for d in data]\n\n        call = {""service"": sname,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output}}\n        if data:\n            call[""data""] = data\n        if index_uris:\n            call[""index_uris""] = index_uris\n        \n        return call\n\n    def make_action(self, action_type, parameters=[]):\n        """"""\n        Creates a dictionary that holds a JSON chain action.\n        Parameters:\n        action_type -- ""crop"" or ""filter"" for now\n        parameters -- action parameters\n        """"""\n        action = {""action"": {""type"":action_type}}\n        if parameters:\n            action[""action""][""parameters""] = parameters\n        return action\n\n    def post_chain(self, cname, calls):\n        """"""\n        Makes a chained prediction\n        Parameters:\n        cname -- chain execution name\n        calls -- array of calls and actions, use make_call and make_action\n        """"""\n\n        chain = {""chain"": { ""calls"": calls } }\n        return self.post(self.__urls[""chain""] + \'/%s\' % cname, json=chain)\n    \n# test\nif __name__ == \'__main__\':\n    dd = DD()\n    dd.set_return_format(dd.RETURN_PYTHON)\n    inf = dd.info()\n    print(inf)\n'"
demo/gpt2/dd_client.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nDeepDetect Python client\n\nLicence:\nCopyright (c) 2015 Emmanuel Benazera, Evgeny BAZAROV <baz.evgenii@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n""""""\n\nimport base64\nimport os\nimport re\nimport warnings\n\nimport requests\n\nDD_TIMEOUT = 2000  # seconds, for long blocking training calls, as needed\n\nAPI_METHODS_URL = {\n    ""0.1"": {\n        ""info"": ""/info"",\n        ""services"": ""/services"",\n        ""train"": ""/train"",\n        ""predict"": ""/predict"",\n        ""chain"": ""/chain""\n    }\n}\n\ndef _convert_base64(filename):  # return type: Optional[str]\n    if os.path.isfile(filename):\n        with open(filename, \'rb\') as fh:\n            data = fh.read()\n            x = base64.encodebytes(data)\n            return x.decode(\'ascii\').replace(\'\\n\', \'\')\n    if re.match(\'^http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|\'\n                \'[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+$\', filename):\n        result = requests.get(filename)\n        if result.status_code != 200:\n            warnings.warn(""{} returned status {}"".format(filename, status))\n            return\n        x = base64.encodebytes(result.content)\n        return x.decode(\'ascii\').replace(\'\\n\', \'\')\n    warnings.warn(""Unable to understand file type:""\n                  "" file not found or url not valid"", RuntimeWarning)\n\n\nclass DD(object):\n    """"""HTTP requests to the DeepDetect server\n    """"""\n\n    # return types\n    RETURN_PYTHON = 0\n    RETURN_JSON = 1\n    RETURN_NONE = 2\n\n    __HTTP = 0\n    __HTTPS = 1\n\n    def __init__(self, host=""localhost"", port=8080, proto=0, path=\'\', apiversion=""0.1""):\n        """""" DD class constructor\n        Parameters:\n        host -- the DeepDetect server host\n        port -- the DeepDetect server port\n        proto -- user http (0,default) or https connection\n        """"""\n        self.apiversion = apiversion\n        self.__urls = API_METHODS_URL[apiversion]\n        self.__host = host\n        self.__port = port\n        self.__path = path\n        self.__proto = proto\n        self.__returntype = self.RETURN_PYTHON\n        if proto == self.__HTTP:\n            self.__ddurl = \'http://%s:%d\' % (host, port)\n        else:\n            self.__ddurl = \'https://%s:%d\' % (host, port)\n        if path:\n            self.__ddurl += path\n            \n    def set_return_format(self, f):\n        assert f == self.RETURN_PYTHON or f == self.RETURN_JSON or f == self.RETURN_NONE\n        self.__returntype = f\n\n    def __return_data(self, r):\n        if self.__returntype == self.RETURN_PYTHON:\n            return r.json()\n        elif self.__returntype == self.RETURN_JSON:\n            return r.text\n        else:\n            return None\n\n    def get(self, method, json=None, params=None):\n        """"""GET to DeepDetect server """"""\n        url = self.__ddurl + method\n        r = requests.get(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def put(self, method, json=None, params=None):\n        """"""PUT request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.put(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def post(self, method, json=None, params=None):\n        """"""POST request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.post(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def delete(self, method, json=None, params=None):\n        """"""DELETE request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.delete(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    # API methods\n    def info(self):\n        """"""Info on the DeepDetect server""""""\n        return self.get(self.__urls[""info""])\n\n    # API services\n    def put_service(self, sname, model, description, mllib, parameters_input, parameters_mllib, parameters_output, mltype=\'supervised\'):\n        """"""\n        Create a service\n        Parameters:\n        sname -- service name as a resource\n        model -- dict with model location and optional templates\n        description -- string describing the service\n        mllib -- ML library name, e.g. caffe\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        data = {""description"": description,\n                ""mllib"": mllib,\n                ""type"": mltype,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""model"": model}\n        return self.put(self.__urls[""services""] + \'/%s\' % sname, json=data)\n\n    def get_service(self, sname):\n        """"""\n        Get information about a service\n        Parameters:\n        sname -- service name as a resource\n        """"""\n        return self.get(self.__urls[""services""] + \'/%s\' % sname)\n\n    def delete_service(self, sname, clear=None):\n        """"""\n        Delete a service\n        Parameters:\n        sname -- service name as a resource\n        clear -- \'full\',\'lib\' or \'mem\', optionally clears model repository data\n        """"""\n        lurl = \'/%s\' % sname\n        if clear:\n            lurl += \'?clear=\' + clear\n        return self.delete(self.__urls[""services""] + lurl)\n\n    # API train\n    def post_train(self, sname, data, parameters_input, parameters_mllib, parameters_output, async=True):\n        """"""\n        Creates a training job\n        Parameters:\n        sname -- service name as a resource\n        async -- whether to run the job as non-blocking\n        data -- array of input data / dataset for training\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        data = {""service"": sname,\n                ""async"": async,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""data"": data}\n        return self.post(self.__urls[""train""], json=data)\n\n    def get_train(self, sname, job=1, timeout=0, measure_hist=False):\n        """"""\n        Get information on a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        timeout -- timeout before obtaining the job status\n        measure_hist -- whether to return the full measure history (e.g. for plotting)\n        """"""\n        params = {""service"": sname,\n                  ""job"": str(job),\n                  ""timeout"": str(timeout)}\n        if measure_hist:\n            params[""parameters.output.measure_hist""] = measure_hist\n        return self.get(self.__urls[""train""], params=params)\n\n    def delete_train(self, sname, job=1):\n        """"""\n        Kills a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        """"""\n        params = {""service"": sname,\n                  ""job"": str(job)}\n        return self.delete(self.__urls[""train""], params=params)\n\n    # API predict\n    def post_predict(self, sname, data, parameters_input, parameters_mllib,\n                     parameters_output, use_base64=False, index_uris=[]):\n        """"""\n        Makes prediction from data and model\n        Parameters:\n        sname -- service name as a resource\n        data -- array of data URI to predict from\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n\n        if use_base64:\n            data = [_convert_base64(d) for d in data]\n\n        data = {""service"": sname,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""data"": data}\n        if index_uris:\n            data[""index_uris""] = index_uris\n        return self.post(self.__urls[""predict""], json=data)\n\n    # API chain\n    def make_call(self, sname, data, parameters_input, parameters_mllib,\n                  parameters_output, use_base64=False, index_uris = []):\n        """"""\n        Creates a dictionary that holds the JSON call,\n        to be added to an array and processed by \n        a post_chain API call. This basically eases the making\n        of chain calls from Python.\n        Parameters are the same as for a post_predict call\n        """"""\n        \n        if use_base64:\n            data = [_convert_base64(d) for d in data]\n\n        call = {""service"": sname,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output}}\n        if data:\n            call[""data""] = data\n        if index_uris:\n            call[""index_uris""] = index_uris\n        \n        return call\n\n    def make_action(self, action_type, parameters=[]):\n        """"""\n        Creates a dictionary that holds a JSON chain action.\n        Parameters:\n        action_type -- ""crop"" or ""filter"" for now\n        parameters -- action parameters\n        """"""\n        action = {""action"": {""type"":action_type}}\n        if parameters:\n            action[""action""][""parameters""] = parameters\n        return action\n\n    def post_chain(self, cname, calls):\n        """"""\n        Makes a chained prediction\n        Parameters:\n        cname -- chain execution name\n        calls -- array of calls and actions, use make_call and make_action\n        """"""\n\n        chain = {""chain"": { ""calls"": calls } }\n        return self.post(self.__urls[""chain""] + \'/%s\' % cname, json=chain)\n    \n# test\nif __name__ == \'__main__\':\n    dd = DD()\n    dd.set_return_format(dd.RETURN_PYTHON)\n    inf = dd.info()\n    print(inf)\n'"
demo/gpt2/run_gpt2.py,0,"b'import random\nimport sys\nimport argparse\nfrom dd_client import DD\n\nparser = argparse.ArgumentParser(description=""Use DeepDetect and GPT-2 to generate text"")\nparser.add_argument(""-r"", ""--repository"", required=True, help=""Model repository"")\nparser.add_argument(""--host"", type=str, default=""localhost"")\nparser.add_argument(""--port"", type=int, default=8080)\nparser.add_argument(""--cpu"", action=\'store_true\', help=""Force model to run on CPU"")\nparser.add_argument(""--input-size"", type=int, default=512)\nparser.add_argument(""--topk"", type=int, default=5, help=""How many top predictions should be considered to chose the next token."")\nparser.add_argument(""--temperature"", type=float, default=1, help=""Temperature of the predictions. The higher, the \'randomer\'."")\n\nargs = parser.parse_args()\n\n# dd global variables\nsname = \'gpt-2\'\ndescription = \'Inference with GPT-2\'\nmllib = \'torch\'\n\ndd = DD(args.host, args.port)\ndd.set_return_format(dd.RETURN_PYTHON)\n\n# setting up the ML service\nmodel = {\'repository\':args.repository}\nparameters_input = {\n    \'connector\':\'txt\',\n    \'ordered_words\': True,\n    \'wordpiece_tokens\': True,\n    \'punctuation_tokens\': True,\n    \'lower_case\': False,\n    \'width\': args.input_size\n}\nparameters_mllib = {\'template\':\'gpt2\', \'gpu\':True}\nparameters_output = {}\ndd.put_service(sname,model,description,mllib,\n               parameters_input,parameters_mllib,parameters_output)\n\n# generating text\nprompt = input(""Enter beggining of sentence >>> "")\n\nfor i in range(0, 256):\n    data = [prompt]\n    parameters_input = {\'word_start\': ""\xc4\xa0"", \'suffix_start\': """"}\n    parameters_mllib = {}\n    parameters_output = {\'best\':args.topk}\n    result = dd.post_predict(sname, data, parameters_input,parameters_mllib,parameters_output)\n\n    # Select result from the returned tokens\n    word_probs = list()\n    total_probs = 0\n\n    for cls in result[\'body\'][\'predictions\'][0][\'classes\']:\n        word = cls[\'cat\'].replace(""\xc4\xa0"", "" "")\n        # dede does not support \\n character well, so we don\'t select tokens containing a new line\n        if \'\xc4\x8a\' in word:\n            continue\n\n        prob = pow(cls[\'prob\'], args.temperature)\n        total_probs += prob\n        word_probs.append((word, prob))\n    \n    selector = random.uniform(0, total_probs)\n    total_probs = 0\n\n    for word, prob in word_probs:\n        total_probs += prob\n        if total_probs > selector:\n            selected_word = word\n            break\n\n    print(selected_word, sep=\'\', end=\'\')\n    sys.stdout.flush()\n    prompt += selected_word\n'"
demo/imgsearch/dd_client.py,0,"b'""""""\nDeepDetect Python client\n\nLicence:\nCopyright (c) 2015 Emmanuel Benazera\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n""""""\n\ntry:\n    import urllib.request as urllib2\nexcept ImportError:\n    import urllib2\n\ntry:\n    import http.client as httplib\nexcept ImportError:\n    import httplib\n\n\nimport os.path\nimport json\nimport uuid\nimport datetime\n\n\nVERBOSE=False\nDD_TIMEOUT = 2000 # seconds, for long blocking training alls, as needed\n\ndef LOG(msg):\n    """"""Output a log message.""""""\n    # XXX: may want to use python log manager classes instead of this stupid print\n    if VERBOSE:\n        msg = str(datetime.datetime.now()) + \' \' + msg\n        print (msg)\n\n### Exception classes :\n\nclass DDCommunicationError(Exception):\n    def __init__(self, url, http_method,  headers, body, response=None):\n        self.msg = """"""DeepDetect Communication Error""""""\n        self.http_method = http_method\n        self.req_headers = headers\n        self.req_body = body\n        self.url = url\n        self.res_headers = None\n        if response is not None:\n            self.res_headers = response.get_info()\n            \n    def __str__(self):\n        msg = ""%s %s\\n""%(str(self.http_method),str(self.url))\n        for h,v in self.req_headers.iteritems():\n            msg += ""%s:%s\\n""%(h,v)\n        msg += ""\\n""\n        if self.req_body is not None:\n            msg += str(self.req_body)[:100]\n        msg += ""\\n""\n        msg += ""--\\n""\n        msg += str(self.res_headers)\n        msg += ""\\n""\n        return msg\n\nclass DDDataError(Exception):\n    def __init__(self, url, http_method,  headers, body, data=None):\n        self.msg = ""DeepDetect Data Error""\n        self.http_method = http_method\n        self.req_headers = headers\n        self.req_body = body\n        self.url = url\n        self.data = data\n\n    def __str__(self):\n        msg = ""%s %s\\n""%(str(self.http_method),str(self.url))\n        if self.data is not None:\n            msg += str(self.data)[:100]\n        msg += ""\\n""\n        for h,v in self.req_headers.iteritems():\n            msg += ""%s:%s\\n""%(h,v)\n        msg += ""\\n""\n        if self.req_body is not None:\n            msg += str(self.req_body)\n        msg += ""\\n""\n        msg += ""--\\n""\n        msg += str(self.data)\n        msg += ""\\n""\n        return msg\n\nAPI_METHODS_URL = {\n    ""0.1"" : {\n        ""info"":""/info"",\n        ""services"":""/services"",\n        ""train"":""/train"",\n        ""predict"":""/predict""\n    }\n}\n\nclass DD(object):\n    """"""HTTP requests to the DeepDetect server\n\n    """"""\n\n    # return types\n    RETURN_PYTHON=0\n    RETURN_JSON=1\n    RETURN_NONE=2\n\n    __HTTP=0\n    __HTTPS=1\n\n    def __init__(self,host=""localhost"",port=8080,proto=0,apiversion=""0.1""):\n        """""" DD class constructor\n        Parameters:\n        host -- the DeepDetect server host\n        port -- the DeepDetect server port\n        proto -- user http (0,default) or https connection\n        """"""\n        self.apiversion = apiversion\n        self.__urls = API_METHODS_URL[apiversion]\n        self.__host = host\n        self.__port = port\n        self.__proto = proto\n        self.__returntype=self.RETURN_PYTHON\n        if proto == self.__HTTP:\n            self.__ddurl=\'http://%s:%d\'%(host,port)\n        else:\n            self.__ddurl=\'https://%s:%d\'%(host,port)\n\n\n    def set_return_format(self,f):\n        assert f == self.RETURN_PYTHON or f == self.RETURN_JSON or f == self.RETURN_NONE\n        self.__returntype = f\n\n    def __return_format(self,js):\n        if self.__returntype == self.RETURN_PYTHON:\n            return json.loads(js.decode(\'utf-8\'))\n        elif self.__returntype == self.RETURN_JSON:\n            return js\n        else:\n            return None\n\n    def get(self,method,args=None):\n        """""" GET to DeepDetect server """"""\n        u = self.__ddurl\n        u += method\n        headers = {}\n        if args is not None:\n            sep = ""?""\n            for arg,argv in args.iteritems():\n                u += sep\n                sep = ""&""\n                u += urllib2.quote(arg)\n                u += \'=\'\n                if argv is not None:\n                    u += urllib2.quote(argv)\n                    \n        LOG(""GET %s""%u)\n        response = None\n        try:\n            req = urllib2.Request(u)\n            response = urllib2.urlopen(req, timeout=DD_TIMEOUT)\n            jsonresponse=response.read()\n        except:\n            raise DDCommunicationError(u,""GET"",headers,None,response)\n        LOG(jsonresponse)\n        try:\n            return self.__return_format(jsonresponse)\n        except:\n            raise DDDataError(u,""GET"",headers,None,jsonresponse)\n\n    def put(self, method, body):\n        """"""PUT request to DeepDetect server""""""\n\n        LOG(""PUT %s\\n%s""%(method,body))\n        r = None\n        u = """"\n        headers = {}\n        try:\n            u = self.__ddurl + method\n            if self.__proto == self.__HTTP:\n            #    u = ""http://%s:%s%s""%(self.__host,self.__port,method)\n                c=httplib.HTTPConnection(self.__host,self.__port, timeout=DD_TIMEOUT)\n            else:\n            #    u = ""https://%s:%s%s""%(self.__host,self.__port,method)\n                c=httplib.HTTPSConnection(self.__host,self.__port, timeout=DD_TIMEOUT)\n            c.request(\'PUT\',method,body,headers)\n            r = c.getresponse()\n            data = r.read()\n        except:\n            raise DDCommunicationError(u,""PUT"",headers,body,r)\n        LOG(data)\n        try:\n            return self.__return_format(data)\n        except:\n            raise DDDataError(u,""PUT"",headers,body,data)\n\n    def post(self,method,body):\n        """"""POST request to DeepDetect server""""""\n        \n        r = None\n        u = """"\n        headers = {}\n        try:\n            u = self.__ddurl + method\n            if self.__proto == self.__HTTP:\n                LOG(""curl -X POST \'http://%s:%s%s\' -d \'%s\'""%(self.__host,\n                                                             self.__port,\n                                                             method,\n                                                             body))\n                c=httplib.HTTPConnection(self.__host,self.__port,timeout=DD_TIMEOUT)\n            else:\n                LOG(""curl -k -X POST \'https://%s:%s%s\' -d \'%s\'""%(self.__host,\n                                                                 self.__port,\n                                                                 method,\n                                                                 body))\n                c=httplib.HTTPSConnection(self.__host,self.__port, timeout=DD_TIMEOUT)\n            c.request(\'POST\',method,body,headers)\n            r = c.getresponse()\n            data = r.read()\n            \n        except:\n            raise DDCommunicationError(u,""POST"",headers,body,r)\n\n        # LOG(data)\n        try:\n            return self.__return_format(data)\n        except:\n            import traceback\n            print (traceback.format_exc())\n\n            raise DDDataError(u,""POST"",headers,body,data)\n        \n    def delete(self, method):\n        """"""DELETE request to DeepDetect server""""""\n\n        LOG(""DELETE %s""%(method))\n        r = None\n        u = """"\n        body = """"\n        headers = {}\n        try:\n            u = self.__ddurl + method\n            if self.__proto == self.__HTTP:\n                c=httplib.HTTPConnection(self.__host,self.__port, timeout=DD_TIMEOUT)\n            else:\n                c=httplib.HTTPSConnection(self.__host,self.__port, timeout=DD_TIMEOUT)\n            c.request(\'DELETE\',method,body,headers)\n            r = c.getresponse()\n            data = r.read()\n        except:\n            raise DDCommunicationError(u,""DELETE"",headers,None,r)\n\n        LOG(data)\n        try:\n            return self.__return_format(data)\n        except:\n            raise DDDataError(u,""DELETE"",headers,None,data)\n\n\n    # API methods\n\n    def info(self):\n        """"""Info on the DeepDetect server""""""\n        return self.get(self.__urls[""info""])\n\n\n    # - PUT services\n    # - GET services\n    # - DELETE services\n    def put_service(self,sname,model,description,mllib,parameters_input,parameters_mllib,parameters_output,mltype=\'supervised\'):\n        """"""\n        Create a service\n        Parameters:\n        sname -- service name as a resource\n        model -- dict with model location and optional templates\n        description -- string describing the service\n        mllib -- ML library name, e.g. caffe\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        body={""description"":description,""mllib"":mllib,""type"":mltype,\n              ""parameters"":{""input"":parameters_input,""mllib"":parameters_mllib,""output"":parameters_output},\n              ""model"":model}\n        return self.put(self.__urls[""services""] + \'/%s\'%sname,json.dumps(body))\n\n    def get_service(self,sname):\n        """"""\n        Get information about a service\n        Parameters:\n        sname -- service name as a resource\n        """"""\n        return self.get(self.__urls[""services""] + \'/%s\'%sname)\n\n    def delete_service(self,sname,clear=None):\n        """"""\n        Delete a service\n        Parameters:\n        sname -- service name as a resource\n        clear -- \'full\',\'lib\' or \'mem\', optionally clears model repository data\n        """"""\n        qs = self.__urls[""services""] + \'/%s\'%sname\n        if clear:\n            qs += \'?clear=\' + clear\n        return self.delete(qs)\n\n\n    # PUT/POST /train\n    # GET /train\n    # DELETE /train\n\n    def post_train(self,sname,data,parameters_input,parameters_mllib,parameters_output,async=True):\n        """"""\n        Creates a training job\n        Parameters:\n        sname -- service name as a resource\n        async -- whether to run the job as non-blocking\n        data -- array of input data / dataset for training\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        body={""service"":sname,""async"":async,\n              ""parameters"":{""input"":parameters_input,""mllib"":parameters_mllib,""output"":parameters_output},\n              ""data"":data}\n        return self.post(self.__urls[""train""],json.dumps(body))\n\n    def get_train(self,sname,job=1,timeout=0,measure_hist=False):\n        """"""\n        Get information on a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        timeout -- timeout before obtaining the job status\n        measure_hist -- whether to return the full measure history (e.g. for plotting)\n        """"""\n        qs=self.__urls[""train""] + ""?service="" + sname + ""&job="" + str(job) + ""&timeout="" + str(timeout)\n        if measure_hist:\n            qs += ""&parameters.output.measure_hist=true""\n        return self.get(qs)\n\n    def delete_train(self,sname,job=1):\n        """"""\n        Kills a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        """"""\n        qs=self.__urls[""train""] + ""?service="" + sname + ""&job="" + str(job)\n        return self.delete(qs)\n\n\n    # POST /predict\n\n    def post_predict(self,sname,data,parameters_input,parameters_mllib,parameters_output):\n        """"""\n        Makes prediction from data and model\n        Parameters:\n        sname -- service name as a resource\n        data -- array of data URI to predict from\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        body={""service"":sname,\n              ""parameters"":{""input"":parameters_input,""mllib"":parameters_mllib,""output"":parameters_output},\n              ""data"":data}\n        return self.post(self.__urls[""predict""],json.dumps(body))\n    \n# test\nif __name__ == \'__main__\':\n    dd = DD()\n    dd.set_return_format(dd.RETURN_PYTHON)\n    inf = dd.info()\n    print (inf)\n'"
demo/imgsearch/imgsearch.py,0,"b'import os, sys, argparse\nfrom os import listdir\nfrom os.path import isfile, join\nfrom os import walk\nfrom dd_client import DD\nfrom annoy import AnnoyIndex\nimport shelve\nimport cv2\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--index"",help=""repository of images to be indexed"")\nparser.add_argument(""--index-batch-size"",type=int,help=""size of image batch when indexing"",default=1)\nparser.add_argument(""--search"",help=""image input file for similarity search"")\nparser.add_argument(""--search-size"",help=""number of nearest neighbors"",type=int,default=10)\nargs = parser.parse_args()\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\ndef image_resize(imgfile,width):\n    imgquery = cv2.imread(imgfile)\n    r = width / imgquery.shape[1]\n    dim = (int(width), int(imgquery.shape[0] * r))\n    small = cv2.resize(imgquery,dim)\n    return small\n\nhost = \'localhost\'\nsname = \'imgserv\'\ndescription = \'image classification\'\nmllib = \'caffe\'\nmltype = \'unsupervised\'\nextract_layer = \'loss3/classifier\'\n#extract_layer = \'pool5/7x7_s1\'\nnclasses = 1000\nlayer_size = 1000 # default output code size\nwidth = height = 224\nbinarized = False\ndd = DD(host)\ndd.set_return_format(dd.RETURN_PYTHON)\nntrees = 100\nmetric = \'angular\'  # or \'euclidean\'\n\n# creating ML service\nmodel_repo = os.getcwd() + \'/model\'\nmodel = {\'repository\':model_repo,\'templates\':\'../templates/caffe/\'}\nparameters_input = {\'connector\':\'image\',\'width\':width,\'height\':height}\n\n# Only indexing needs the template.\nif args.index:\n    parameters_mllib = {\'nclasses\':nclasses,\'template\':\'googlenet\'}\nelse:\n    parameters_mllib = {\'nclasses\':nclasses}\n\nparameters_output = {}\ndd.put_service(sname,model,description,mllib,\n               parameters_input,parameters_mllib,parameters_output,mltype)\n\n# reset call params\nparameters_input = {}\nparameters_mllib = {\'gpu\':True,\'extract_layer\':extract_layer}\nparameters_output = {\'binarized\':binarized}\n\nif args.index:\n    try:\n        os.remove(\'names.bin\')\n    except:\n        pass\n    s = shelve.open(\'names.bin\')\n        \n    # list files in image repository\n    c = 0\n    onlyfiles = []\n    for (dirpath, dirnames, filenames) in walk(args.index):\n        nfilenames = []\n        for f in filenames:\n            nfilenames.append(dirpath + \'/\' + f)\n        onlyfiles.extend(nfilenames)\n    for x in batch(onlyfiles,args.index_batch_size):\n        sys.stdout.write(\'\\r\'+str(c)+\'/\'+str(len(onlyfiles)))\n        sys.stdout.flush()\n        classif = dd.post_predict(sname,x,parameters_input,parameters_mllib,parameters_output)\n        for p in classif[\'body\'][\'predictions\']:\n            if c == 0:\n                layer_size = len(p[\'vals\'])\n                s[\'layer_size\'] = layer_size\n                t = AnnoyIndex(layer_size,metric) # prepare index\n            t.add_item(c,p[\'vals\'])\n            s[str(c)] = p[\'uri\']\n            c = c + 1\n        #if c >= 10000:\n        #    break\n    print \'building index...\\n\'\n    print \'layer_size=\',layer_size\n    t.build(ntrees)\n    t.save(\'index.ann\')\n    s.close()\n\nif args.search:\n    s = shelve.open(\'names.bin\')\n    u = AnnoyIndex(s[\'layer_size\'],metric)\n    u.load(\'index.ann\')\n    data = [args.search]\n    classif = dd.post_predict(sname,data,parameters_input,parameters_mllib,parameters_output)\n    near = u.get_nns_by_vector(classif[\'body\'][\'predictions\'][0][\'vals\'],args.search_size,include_distances=True)\n    print near\n    near_names = []\n    for n in near[0]:\n        near_names.append(s[str(n)])\n    print near_names\n    cv2.imshow(\'query\',image_resize(args.search,224.0))\n    cv2.waitKey(0)\n    for n in near_names:\n        cv2.imshow(\'res\',image_resize(n,224.0))\n        cv2.waitKey(0)\n    \ndd.delete_service(sname,clear=\'\')\n'"
demo/imgsearch/imgsearch_dd.py,0,"b'import os, sys, argparse\nfrom os import listdir\nfrom os.path import isfile, join\nfrom os import walk\nfrom dd_client import DD\nimport cv2\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--index"",help=""repository of images to be indexed"")\nparser.add_argument(""--index-batch-size"",type=int,help=""size of image batch when indexing"",default=1)\nparser.add_argument(""--search"",help=""image input file for similarity search"")\nparser.add_argument(""--search-size"",help=""number of nearest neighbors"",type=int,default=10)\nargs = parser.parse_args()\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\ndef image_resize(imgfile,width):\n    imgquery = cv2.imread(imgfile)\n    r = width / imgquery.shape[1]\n    dim = (int(width), int(imgquery.shape[0] * r))\n    small = cv2.resize(imgquery,dim)\n    return small\n\nhost = \'localhost\'\nsname = \'imgserv\'\ndescription = \'image classification\'\nmllib = \'caffe\'\nmltype = \'unsupervised\'\nextract_layer = \'loss3/classifier\'\n#extract_layer = \'pool5/7x7_s1\'\nnclasses = 1000\nwidth = height = 224\nbinarized = False\ndd = DD(host)\ndd.set_return_format(dd.RETURN_PYTHON)\n\n# creating ML service\nmodel_repo = os.getcwd() + \'/model\'\nmodel = {\'repository\':model_repo,\'templates\':\'../templates/caffe/\'}\nparameters_input = {\'connector\':\'image\',\'width\':width,\'height\':height}\n\n# Only indexing needs the template.\nif args.index:\n    parameters_mllib = {\'nclasses\':nclasses,\'template\':\'googlenet\'}\nelse:\n    parameters_mllib = {\'nclasses\':nclasses}\n\nparameters_output = {}\ntry:\n    dd.put_service(sname,model,description,mllib,\n                   parameters_input,parameters_mllib,parameters_output,mltype)\nexcept:\n    pass\n\n# reset call params\nparameters_input = {}\nparameters_mllib = {\'gpu\':True,\'extract_layer\':extract_layer}\nparameters_output = {\'binarized\':binarized}\n\nif args.index:\n    parameters_output[\'index\'] = True\n    \n    # list files in image repository\n    c = 0\n    onlyfiles = []\n    for (dirpath, dirnames, filenames) in walk(args.index):\n        nfilenames = []\n        for f in filenames:\n            nfilenames.append(dirpath + \'/\' + f)\n        onlyfiles.extend(nfilenames)\n    for x in batch(onlyfiles,args.index_batch_size):\n        sys.stdout.write(\'\\r\'+str(c)+\'/\'+str(len(onlyfiles)))\n        sys.stdout.flush()\n        classif = dd.post_predict(sname,x,parameters_input,parameters_mllib,parameters_output)\n        for p in classif[\'body\'][\'predictions\']:\n            c = c + 1\n        if c >= 100:\n            break\n\n    # one last dumb predict call to build the index\n    print \'building index...\\n\'\n    parameters_output[\'index\'] = False\n    parameters_output[\'build_index\']=True\n    classif = dd.post_predict(sname,[nfilenames[0]],parameters_input,parameters_mllib,parameters_output)\n\nif args.search:\n    parameters_output[\'search\'] = True\n    parameters_output[\'search_nn\'] = args.search_size\n    data = [args.search]\n    classif = dd.post_predict(sname,data,parameters_input,parameters_mllib,parameters_output)\n    print classif\n    near_names = []\n    for nn in classif[\'body\'][\'predictions\'][0][\'nns\']:\n        near_names.append(nn[\'uri\'])\n    print near_names\n    print len(near_names)\n    cv2.imshow(\'query\',image_resize(args.search,224.0))\n    cv2.waitKey(0)\n    for n in near_names:\n        cv2.imshow(\'res\',image_resize(n,224.0))\n        cv2.waitKey(0)\n    \ndd.delete_service(sname,clear=\'\')\n'"
demo/objdetect/dd_client.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nDeepDetect Python client\n\nLicence:\nCopyright (c) 2015 Emmanuel Benazera, Evgeny BAZAROV <baz.evgenii@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n""""""\n\nimport base64\nimport os\nimport re\nimport warnings\n\nimport requests\n\nDD_TIMEOUT = 2000  # seconds, for long blocking training calls, as needed\n\nAPI_METHODS_URL = {\n    ""0.1"": {\n        ""info"": ""/info"",\n        ""services"": ""/services"",\n        ""train"": ""/train"",\n        ""predict"": ""/predict"",\n        ""chain"": ""/chain""\n    }\n}\n\ndef _convert_base64(filename):  # return type: Optional[str]\n    if os.path.isfile(filename):\n        with open(filename, \'rb\') as fh:\n            data = fh.read()\n            x = base64.encodebytes(data)\n            return x.decode(\'ascii\').replace(\'\\n\', \'\')\n    if re.match(\'^http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|\'\n                \'[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+$\', filename):\n        result = requests.get(filename)\n        if result.status_code != 200:\n            warnings.warn(""{} returned status {}"".format(filename, status))\n            return\n        x = base64.encodebytes(result.content)\n        return x.decode(\'ascii\').replace(\'\\n\', \'\')\n    warnings.warn(""Unable to understand file type:""\n                  "" file not found or url not valid"", RuntimeWarning)\n\n\nclass DD(object):\n    """"""HTTP requests to the DeepDetect server\n    """"""\n\n    # return types\n    RETURN_PYTHON = 0\n    RETURN_JSON = 1\n    RETURN_NONE = 2\n\n    __HTTP = 0\n    __HTTPS = 1\n\n    def __init__(self, host=""localhost"", port=8080, proto=0, path=\'\', apiversion=""0.1""):\n        """""" DD class constructor\n        Parameters:\n        host -- the DeepDetect server host\n        port -- the DeepDetect server port\n        proto -- user http (0,default) or https connection\n        """"""\n        self.apiversion = apiversion\n        self.__urls = API_METHODS_URL[apiversion]\n        self.__host = host\n        self.__port = port\n        self.__path = path\n        self.__proto = proto\n        self.__returntype = self.RETURN_PYTHON\n        if proto == self.__HTTP:\n            self.__ddurl = \'http://%s:%d\' % (host, port)\n        else:\n            self.__ddurl = \'https://%s:%d\' % (host, port)\n        if path:\n            self.__ddurl += path\n            \n    def set_return_format(self, f):\n        assert f == self.RETURN_PYTHON or f == self.RETURN_JSON or f == self.RETURN_NONE\n        self.__returntype = f\n\n    def __return_data(self, r):\n        if self.__returntype == self.RETURN_PYTHON:\n            return r.json()\n        elif self.__returntype == self.RETURN_JSON:\n            return r.text\n        else:\n            return None\n\n    def get(self, method, json=None, params=None):\n        """"""GET to DeepDetect server """"""\n        url = self.__ddurl + method\n        r = requests.get(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def put(self, method, json=None, params=None):\n        """"""PUT request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.put(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def post(self, method, json=None, params=None):\n        """"""POST request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.post(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    def delete(self, method, json=None, params=None):\n        """"""DELETE request to DeepDetect server""""""\n        url = self.__ddurl + method\n        r = requests.delete(url=url, json=json, params=params, timeout=DD_TIMEOUT)\n        r.raise_for_status()\n        return self.__return_data(r)\n\n    # API methods\n    def info(self):\n        """"""Info on the DeepDetect server""""""\n        return self.get(self.__urls[""info""])\n\n    # API services\n    def put_service(self, sname, model, description, mllib, parameters_input, parameters_mllib, parameters_output, mltype=\'supervised\'):\n        """"""\n        Create a service\n        Parameters:\n        sname -- service name as a resource\n        model -- dict with model location and optional templates\n        description -- string describing the service\n        mllib -- ML library name, e.g. caffe\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        data = {""description"": description,\n                ""mllib"": mllib,\n                ""type"": mltype,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""model"": model}\n        return self.put(self.__urls[""services""] + \'/%s\' % sname, json=data)\n\n    def get_service(self, sname):\n        """"""\n        Get information about a service\n        Parameters:\n        sname -- service name as a resource\n        """"""\n        return self.get(self.__urls[""services""] + \'/%s\' % sname)\n\n    def delete_service(self, sname, clear=None):\n        """"""\n        Delete a service\n        Parameters:\n        sname -- service name as a resource\n        clear -- \'full\',\'lib\' or \'mem\', optionally clears model repository data\n        """"""\n        lurl = \'/%s\' % sname\n        if clear:\n            lurl += \'?clear=\' + clear\n        return self.delete(self.__urls[""services""] + lurl)\n\n    # API train\n    def post_train(self, sname, data, parameters_input, parameters_mllib, parameters_output, async=True):\n        """"""\n        Creates a training job\n        Parameters:\n        sname -- service name as a resource\n        async -- whether to run the job as non-blocking\n        data -- array of input data / dataset for training\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n        data = {""service"": sname,\n                ""async"": async,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""data"": data}\n        return self.post(self.__urls[""train""], json=data)\n\n    def get_train(self, sname, job=1, timeout=0, measure_hist=False):\n        """"""\n        Get information on a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        timeout -- timeout before obtaining the job status\n        measure_hist -- whether to return the full measure history (e.g. for plotting)\n        """"""\n        params = {""service"": sname,\n                  ""job"": str(job),\n                  ""timeout"": str(timeout)}\n        if measure_hist:\n            params[""parameters.output.measure_hist""] = measure_hist\n        return self.get(self.__urls[""train""], params=params)\n\n    def delete_train(self, sname, job=1):\n        """"""\n        Kills a non-blocking training job\n        Parameters:\n        sname -- service name as a resource\n        job -- job number on the service\n        """"""\n        params = {""service"": sname,\n                  ""job"": str(job)}\n        return self.delete(self.__urls[""train""], params=params)\n\n    # API predict\n    def post_predict(self, sname, data, parameters_input, parameters_mllib,\n                     parameters_output, use_base64=False, index_uris=[]):\n        """"""\n        Makes prediction from data and model\n        Parameters:\n        sname -- service name as a resource\n        data -- array of data URI to predict from\n        parameters_input -- dict of input parameters\n        parameters_mllib -- dict ML library parameters\n        parameters_output -- dict of output parameters\n        """"""\n\n        if use_base64:\n            data = [_convert_base64(d) for d in data]\n\n        data = {""service"": sname,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output},\n                ""data"": data}\n        if index_uris:\n            data[""index_uris""] = index_uris\n        return self.post(self.__urls[""predict""], json=data)\n\n    # API chain\n    def make_call(self, sname, data, parameters_input, parameters_mllib,\n                  parameters_output, use_base64=False, index_uris = []):\n        """"""\n        Creates a dictionary that holds the JSON call,\n        to be added to an array and processed by \n        a post_chain API call. This basically eases the making\n        of chain calls from Python.\n        Parameters are the same as for a post_predict call\n        """"""\n        \n        if use_base64:\n            data = [_convert_base64(d) for d in data]\n\n        call = {""service"": sname,\n                ""parameters"": {""input"": parameters_input,\n                               ""mllib"": parameters_mllib,\n                               ""output"": parameters_output}}\n        if data:\n            call[""data""] = data\n        if index_uris:\n            call[""index_uris""] = index_uris\n        \n        return call\n\n    def make_action(self, action_type, parameters=[]):\n        """"""\n        Creates a dictionary that holds a JSON chain action.\n        Parameters:\n        action_type -- ""crop"" or ""filter"" for now\n        parameters -- action parameters\n        """"""\n        action = {""action"": {""type"":action_type}}\n        if parameters:\n            action[""action""][""parameters""] = parameters\n        return action\n\n    def post_chain(self, cname, calls):\n        """"""\n        Makes a chained prediction\n        Parameters:\n        cname -- chain execution name\n        calls -- array of calls and actions, use make_call and make_action\n        """"""\n\n        chain = {""chain"": { ""calls"": calls } }\n        return self.post(self.__urls[""chain""] + \'/%s\' % cname, json=chain)\n    \n# test\nif __name__ == \'__main__\':\n    dd = DD()\n    dd.set_return_format(dd.RETURN_PYTHON)\n    inf = dd.info()\n    print(inf)\n'"
demo/objdetect/objdetect.py,0,"b'import os, sys, argparse\nfrom dd_client import DD\nimport cv2\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--image"",help=""path to image"")\nparser.add_argument(""--confidence-threshold"",help=""keep detections with confidence above threshold"",type=float,default=0.1)\nargs = parser.parse_args()\n\nhost = \'localhost\'\nsname = \'imgserv\'\ndescription = \'image classification\'\nmllib = \'caffe\'\nmltype = \'supervised\'\nnclasses = 21\nwidth = height = 300\ndd = DD(host)\ndd.set_return_format(dd.RETURN_PYTHON)\n\n# creating ML service\nmodel_repo = os.getcwd() + \'/model\'\nmodel = {\'repository\':model_repo}\nparameters_input = {\'connector\':\'image\',\'width\':width,\'height\':height}\nparameters_mllib = {\'nclasses\':nclasses}\nparameters_output = {}\ndd.put_service(sname,model,description,mllib,\n               parameters_input,parameters_mllib,parameters_output,mltype)\n\n# prediction call\nparameters_input = {}\nparameters_mllib = {\'gpu\':True}\nparameters_output = {\'bbox\':True, \'confidence_threshold\': args.confidence_threshold}\ndata = [args.image]\ndetect = dd.post_predict(sname,data,parameters_input,parameters_mllib,parameters_output)\nprint detect\nif detect[\'status\'][\'code\'] != 200:\n    print \'error\',detect[\'status\'][\'code\']\n    sys.exit()\npredictions = detect[\'body\'][\'predictions\']\nfor p in predictions:\n    img = cv2.imread(p[\'uri\'])\n    for c in p[\'classes\']:\n        cat = c[\'cat\']\n        bbox = c[\'bbox\']\n        cv2.rectangle(img,(int(bbox[\'xmin\']),int(bbox[\'ymax\'])),(int(bbox[\'xmax\']),int(bbox[\'ymin\'])),(255,0,0),2)\n        cv2.putText(img,cat,(int(bbox[\'xmin\']),int(bbox[\'ymax\'])),cv2.FONT_HERSHEY_PLAIN,1,255)\n    cv2.imshow(\'img\',img)\n    k = cv2.waitKey(0)\n'"
demo/objsearch/objsearch.py,0,"b'import os, sys, argparse\nfrom os import listdir\nfrom os.path import isfile, join\nfrom os import walk\nfrom dd_client import DD\nfrom annoy import AnnoyIndex\nimport shelve\nimport cv2\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--index"",help=""repository of images to be indexed"")\nparser.add_argument(""--index-batch-size"",type=int,help=""size of image batch when indexing"",default=1)\nparser.add_argument(""--search"",help=""image input file for similarity search"")\nparser.add_argument(""--search-size"",help=""number of nearest neighbors"",type=int,default=10)\nparser.add_argument(""--confidence-threshold"",help=""confidence threshold on bounding boxes"",type=float,default=0.01)\nparser.add_argument(""--nclasses"",help=""number of classes in the model"",type=int,default=21)\nparser.add_argument(""--model-dir"",help=""model directory"",default=""model"")\nargs = parser.parse_args()\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\ndef image_resize(imgfile,width):\n    imgquery = cv2.imread(imgfile)\n    r = width / imgquery.shape[1]\n    dim = (int(width), int(imgquery.shape[0] * r))\n    small = cv2.resize(imgquery,dim)\n    return small\n\nhost = \'localhost\'\nsname = \'imageserv\'\ndescription = \'image classification\'\nmllib = \'caffe\'\nmltype = \'supervised\'\nextract_layer = \'rois\'\nnclasses = args.nclasses\nlayer_size = 512 # auto anyways\nwidth = height = 300\ndd = DD(host)\ndd.set_return_format(dd.RETURN_PYTHON)\nntrees = 1000\nmetric = \'angular\'  # or \'euclidean\'\n\n# creating ML service\nmodel_repo = os.getcwd() + \'/\' + args.model_dir\nmodel = {\'repository\':model_repo,\'templates\':\'../templates/caffe/\'}\nparameters_input = {\'connector\':\'image\',\'width\':width,\'height\':height}\nparameters_mllib = {\'nclasses\':nclasses}\nparameters_output = {}\ntry:\n    dd.put_service(sname,model,description,mllib,\n                   parameters_input,parameters_mllib,parameters_output,mltype)\nexcept:\n    pass\n\n# reset call params\nparameters_input = {}\nparameters_mllib = {\'gpu\':True}\nparameters_output = {\'rois\':\'rois\',\'confidence_threshold\':args.confidence_threshold,\'best\':1}\n\nif args.index:\n    try:\n        os.remove(\'data.bin\')\n    except:\n        pass\n    s = shelve.open(\'data.bin\')\n\n    # list files in image repository\n    c = 0\n    d = 1\n    onlyfiles = []\n    for (dirpath, dirnames, filenames) in walk(args.index):\n        nfilenames = []\n        for f in filenames:\n            nfilenames.append(dirpath + \'/\' + f)\n        onlyfiles.extend(nfilenames)\n    for x in batch(onlyfiles,args.index_batch_size):\n        classif = dd.post_predict(sname,x,parameters_input,parameters_mllib,parameters_output)\n        \n        for p in classif[\'body\'][\'predictions\']:\n            uri =  p[\'uri\']\n            rois = p[\'rois\']\n            sys.stdout.write(\'\\rIndexing image \'+str(d)+\'/\'+str(len(onlyfiles)) + \' : \' + str(len(rois)) + \' rois  total:\' + str(c) + \'   \')\n            sys.stdout.flush()\n\n            for roi in rois:\n                bbox = roi[\'bbox\']\n                cat = roi[\'cat\']\n                prob = roi[\'prob\']\n                vals = roi[\'vals\']\n                if c == 0:\n                    layer_size = len(vals)\n                    s[\'layer_size\'] = layer_size\n                    t = AnnoyIndex(layer_size,metric) # prepare index\n                t.add_item(c,vals)\n                s[str(c)] = {\'uri\':uri, \'bbox\' : bbox, \'cat\' : cat, \'prob\' : prob}\n                c = c + 1\n            d = d + 1\n        #if c >= 10000:\n        #    break\n    print \'building index...\\n\'\n    print \'layer_size=\',layer_size\n    t.build(ntrees)\n    t.save(\'index.ann\')\n    s.close()\n\nif args.search:\n    s = shelve.open(\'data.bin\')\n    u = AnnoyIndex(s[\'layer_size\'],metric)\n    u.load(\'index.ann\')\n    data = [args.search]\n    classif = dd.post_predict(sname,data,parameters_input,parameters_mllib,parameters_output)\n    # search for every roi\n    res = classif[\'body\'][\'predictions\'][0][\'rois\']\n    print(\'number of ROI in query: \' + str(len(res)))\n    for roi in res:\n        near = u.get_nns_by_vector(roi[\'vals\'],args.search_size,include_distances=True)\n        near_data = []\n        near_distance = []\n        for n in near[1]:\n            near_distance.append(n)\n        print(\'distances: \')\n        print(near_distance)\n        for n in near[0]:\n            near_data.append(s[str(n)])\n        # print query bbox\n        img = cv2.imread(args.search)\n        bbox = roi[\'bbox\']\n        cat = roi[\'cat\']\n        cv2.rectangle(img, (int(bbox[\'xmin\']),int(bbox[\'ymax\'])),(int(bbox[\'xmax\']),int(bbox[\'ymin\'])),(255,0,0),2)\n\n        cv2.putText(img,cat,(int(bbox[\'xmin\']),int(bbox[\'ymax\'])),cv2.FONT_HERSHEY_PLAIN,1,255)\n        cv2.imshow(\'query\',img)\n        cv2.waitKey(0)\n        for n in near_data:\n            resimg = cv2.imread(n[\'uri\'])\n            bbox = n[\'bbox\']\n            cat = n[\'cat\']\n            cv2.rectangle(resimg, (int(bbox[\'xmin\']),int(bbox[\'ymax\'])),(int(bbox[\'xmax\']),int(bbox[\'ymin\'])),(255,0,0),2)\n\n            cv2.putText(resimg,cat,(int(bbox[\'xmin\']),int(bbox[\'ymax\'])),cv2.FONT_HERSHEY_PLAIN,1,255)\n            cv2.imshow(\'res\',resimg)\n            cv2.waitKey(0)\n\ndd.delete_service(sname,clear=\'\')\n'"
demo/objsearch/objsearch_dd.py,0,"b'import os, sys, argparse\nfrom os import listdir\nfrom os.path import isfile, join\nfrom os import walk\nfrom dd_client import DD\nfrom annoy import AnnoyIndex\nimport shelve\nimport cv2\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--index"",help=""repository of images to be indexed"")\nparser.add_argument(""--index-batch-size"",type=int,help=""size of image batch when indexing"",default=1)\nparser.add_argument(""--search"",help=""image input file for similarity search"")\nparser.add_argument(""--search-size"",help=""number of nearest neighbors"",type=int,default=10)\nparser.add_argument(""--confidence-threshold"",help=""confidence threshold on bounding boxes"",type=float,default=0.01)\nparser.add_argument(""--nclasses"",help=""number of classes in the model"",type=int,default=21)\nparser.add_argument(""--model-dir"",help=""model directory"",default=""model"")\nargs = parser.parse_args()\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\ndef image_resize(imgfile,width):\n    imgquery = cv2.imread(imgfile)\n    r = width / imgquery.shape[1]\n    dim = (int(width), int(imgquery.shape[0] * r))\n    small = cv2.resize(imgquery,dim)\n    return small\n\nhost = \'localhost\'\nport = 8200\nsname = \'imageserv\'\ndescription = \'image classification\'\nmllib = \'caffe\'\nmltype = \'supervised\'\nextract_layer = \'rois\'\nnclasses = args.nclasses\nwidth = height = 300\ndd = DD(host,port)\ndd.set_return_format(dd.RETURN_PYTHON)\nntrees = 1000\nmetric = \'angular\'  # or \'euclidean\'\n\n# creating ML service\nmodel_repo = os.getcwd() + \'/\' + args.model_dir\nmodel = {\'repository\':model_repo,\'templates\':\'../templates/caffe/\'}\nparameters_input = {\'connector\':\'image\',\'width\':width,\'height\':height}\nparameters_mllib = {\'nclasses\':nclasses}\nparameters_output = {}\ntry:\n    dd.put_service(sname,model,description,mllib,\n                   parameters_input,parameters_mllib,parameters_output,mltype)\nexcept:\n    pass\n\n# reset call params\nparameters_input = {}\nparameters_mllib = {\'gpu\':True}\nparameters_output = {\'rois\':\'rois\',\'confidence_threshold\':args.confidence_threshold,\'best\':1}\n\nif args.index:\n    parameters_output[\'index\'] = True\n    \n    # list files in image repository\n    c = 0\n    d = 0\n    onlyfiles = []\n    for (dirpath, dirnames, filenames) in walk(args.index):\n        nfilenames = []\n        for f in filenames:\n            nfilenames.append(dirpath + \'/\' + f)\n        onlyfiles.extend(nfilenames)\n    for x in batch(onlyfiles,args.index_batch_size):\n        classif = dd.post_predict(sname,x,parameters_input,parameters_mllib,parameters_output)\n        \n        for p in classif[\'body\'][\'predictions\']:\n            c = c + 1\n            uri =  p[\'uri\']\n            rois = p[\'rois\']\n            sys.stdout.write(\'\\rIndexing image \'+str(c)+\'/\'+str(len(onlyfiles)) + \' : \' + str(len(rois)) + \' rois  total:\' + str(d) + \'   \')\n            sys.stdout.flush()\n            d += len(rois)\n        if c >= 100:\n            break\n\n    # one last dumb predict call to build the index\n    print \'building index...\\n\'\n    parameters_output[\'index\'] = False\n    parameters_output[\'build_index\']=True\n    classif = dd.post_predict(sname,[nfilenames[0]],parameters_input,parameters_mllib,parameters_output)\n        \nif args.search:\n    parameters_output[\'search\'] = True\n    parameters_output[\'search_nn\'] = args.search_size\n    data = [args.search]\n    classif = dd.post_predict(sname,data,parameters_input,parameters_mllib,parameters_output)\n    # search for every roi\n    res = classif[\'body\'][\'predictions\'][0][\'rois\']\n    print(\'number of ROI in query: \' + str(len(res)))\n    for roi in res:\n    #    near = u.get_nns_by_vector(roi[\'vals\'],args.search_size,include_distances=True)\n        near = roi[\'nns\']\n        print(near)\n\n        # print query bbox\n        img = cv2.imread(args.search)\n        bbox = roi[\'bbox\']\n        cat = roi[\'cat\']\n        cv2.rectangle(img, (int(bbox[\'xmin\']),int(bbox[\'ymax\'])),(int(bbox[\'xmax\']),int(bbox[\'ymin\'])),(255,0,0),2)\n        cv2.putText(img,cat,(int(bbox[\'xmin\']),int(bbox[\'ymax\'])),cv2.FONT_HERSHEY_PLAIN,1,255)\n        cv2.imshow(\'query\',img)\n        cv2.waitKey(0)\n        for n in near:\n            resimg = cv2.imread(n[\'uri\'])\n            bbox = n[\'bbox\']\n            cat = n[\'cat\']\n            cv2.rectangle(resimg, (int(bbox[\'xmin\']),int(bbox[\'ymax\'])),(int(bbox[\'xmax\']),int(bbox[\'ymin\'])),(255,0,0),2)\n\n            cv2.putText(resimg,cat,(int(bbox[\'xmin\']),int(bbox[\'ymax\'])),cv2.FONT_HERSHEY_PLAIN,1,255)\n            cv2.imshow(\'res\',resimg)\n            cv2.waitKey(0)\n\ndd.delete_service(sname,clear=\'\')\n'"
demo/segmentation/segment.py,0,"b'import os, sys, argparse\nimport numpy as np\nfrom dd_client import DD\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\n\nrandom.seed(134124)\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--image"",help=""path to image"")\nparser.add_argument(""--nclasses"",help=""number of classes"",type=int,default=150)\nparser.add_argument(""--width"",help=""image width"",type=int,default=480)\nparser.add_argument(""--height"",help=""image height"",type=int,default=480)\nparser.add_argument(""--model-dir"",help=""model directory"")\nargs = parser.parse_args();\n\nhost = \'localhost\'\nport = 8080\nsname = \'segserv\'\ndescription = \'image segmentation\'\nmllib = \'caffe\'\nmltype = \'unsupervised\'\nnclasses = args.nclasses\nwidth = args.width\nheight = args.height\ndd = DD(host,port)\ndd.set_return_format(dd.RETURN_PYTHON)\n\ndef random_color():\n    \'\'\' generate rgb using a list comprehension \'\'\'\n    r, g, b = [random.randint(0,255) for i in range(3)]\n    return [r, g, b]\n\n# creating ML service\nmodel_repo = args.model_dir\nif not model_repo:\n    model_repo = os.getcwd() + \'/model/\'\nmodel = {\'repository\':model_repo}\nparameters_input = {\'connector\':\'image\',\'width\':width,\'height\':height}\nparameters_mllib = {\'nclasses\':nclasses}\nparameters_output = {}\ntry:\n    servput = dd.put_service(sname,model,description,mllib,\n                             parameters_input,parameters_mllib,parameters_output,mltype)\nexcept: # most likely the service already exists\n    pass\n\n# prediction call\nparameters_input = {\'segmentation\':True}\nparameters_mllib = {\'gpu\':True,\'gpuid\':0}\nparameters_output = {}\ndata = [args.image]\ndetect = dd.post_predict(sname,data,parameters_input,parameters_mllib,parameters_output)\n\npixels = np.array((map(int,detect[\'body\'][\'predictions\'][0][\'vals\'])))\nimgsize = detect[\'body\'][\'predictions\'][0][\'imgsize\']\n\n# visual output\nlabel_colours = []\nfor c in range(nclasses):\n    label_colours.append(random_color())\nlabel_colours = np.array(label_colours)\n\nr = pixels.copy()\ng = pixels.copy()\nb = pixels.copy()\nfor l in range(0,nclasses):\n    r[pixels==l] = label_colours[l,0]\n    g[pixels==l] = label_colours[l,1]\n    b[pixels==l] = label_colours[l,2]\n\nr = np.reshape(r,(imgsize[\'height\'],imgsize[\'width\']))\ng = np.reshape(g,(imgsize[\'height\'],imgsize[\'width\']))\nb = np.reshape(b,(imgsize[\'height\'],imgsize[\'width\']))\nrgb = np.zeros((imgsize[\'height\'],imgsize[\'width\'],3))\nrgb[:,:,0] = r/255.0\nrgb[:,:,1] = g/255.0\nrgb[:,:,2] = b/255.0\n\nplt.figure()\nplt.imshow(rgb,vmin=0,vmax=1)\nplt.show()\n'"
demo/segmentation/view_annot.py,0,"b'import os, sys, argparse\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\n\nrandom.seed(134124)\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--image"",help=""path to image"")\nparser.add_argument(""--nclasses"",help=""number of classes"",type=int,default=150)\nparser.add_argument(""--width"",help=""image width"",type=int,default=480)\nparser.add_argument(""--height"",help=""image height"",type=int,default=480)\nargs = parser.parse_args();\n\ndef random_color():\n    \'\'\' generate rgb using a list comprehension \'\'\'\n    r, g, b = [random.randint(0,255) for i in range(3)]\n    return [r, g, b]\n\nnclasses = args.nclasses\nlabel_colours = []\nfor c in range(nclasses):\n    label_colours.append(random_color())\nlabel_colours = np.array(label_colours)\n\nheight = args.height\nwidth = args.width\n\npixels = cv2.imread(args.image,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n\nr = pixels.copy()\ng = pixels.copy()\nb = pixels.copy()\nfor l in range(0,nclasses):\n    r[pixels==l] = label_colours[l,0]\n    g[pixels==l] = label_colours[l,1]\n    b[pixels==l] = label_colours[l,2]\n\nr = np.reshape(r,(height,width))\ng = np.reshape(g,(height,width))\nb = np.reshape(b,(height,width))\nrgb = np.zeros((height,width,3))\nrgb[:,:,0] = r/255.0\nrgb[:,:,1] = g/255.0\nrgb[:,:,2] = b/255.0\n\nplt.figure()\nplt.imshow(rgb,vmin=0,vmax=1)\nplt.show()\n'"
demo/tsne/demo_tsne.py,0,"b'from dd_client import DD\nimport matplotlib\nimport numpy as np\nimport time\n\nimport matplotlib.pyplot as plt\nimport pylab\n\nmodel_repo = ""/tmp""\nhost = \'localhost\'\nport = 8080\nsname = \'test\'\ndescription = \'clustering\'\nmllib = \'tsne\'\ndd = DD(host)\ndd.set_return_format(dd.RETURN_PYTHON)\n\ntraining_repo = \'https://deepdetect.com/dd/datasets/mnist_csv/mnist_test.csv\'\n\n# service creation\nmodel = {\'repository\':model_repo}\nparameters_input = {\'connector\':\'csv\'}\nparameters_mllib = {}\nparameters_output = {}\ndd.put_service(sname,model,description,mllib,\n               parameters_input,parameters_mllib,parameters_output,\'unsupervised\')\n\n# training\ntrain_data = [training_repo]\nparameters_input = {\'id\':\'\',\'separator\':\',\',\'label\':\'label\'}\nparameters_mllib = {\'iterations\':500}\nparameters_output = {}\npredout = dd.post_train(sname,train_data,parameters_input,parameters_mllib,parameters_output,async=True)\n\ntime.sleep(1)\ntrain_status = \'\'\nwhile True:\n    train_status = dd.get_train(sname,job=1,timeout=3)\n    if train_status[\'head\'][\'status\'] == \'running\':\n        print train_status[\'body\'][\'measure\']\n    else:\n        print train_status\n        predout = train_status\n        break\n\npredictions = predout[\'body\'][\'predictions\']\nN = len(predictions)\npoints = np.empty((N,2),dtype=np.float)\ni = 0\nfor p in predictions:\n    points[i,0] = p[\'vals\'][0]\n    points[i,1] = p[\'vals\'][1]\n    i = i + 1\n        \npylab.xlim([-30,30])\npylab.ylim([-30,30])\n\nplt.ioff()\ncolors = np.random.rand(N)\nplt.scatter(points[:,0],points[:,1],colors)\npylab.show()\n'"
demo/tsne/demo_tsne_txt.py,0,"b'from dd_client import DD\nimport matplotlib\nimport numpy as np\nimport time\nimport argparse\nimport sys\n\nimport matplotlib.pyplot as plt\nimport pylab\n\nmodel_repo = ""/tmp""\nhost = \'localhost\'\nport = 8080\nsname = \'test\'\ndescription = \'clustering\'\nmllib = \'tsne\'\ndd = DD(host)\ndd.set_return_format(dd.RETURN_PYTHON)\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--txtdir"",help=""directory containing text files"")\nparser.add_argument(""--perplexity"",help=""TSNE perplexity"",type=int,default=30)\nargs = parser.parse_args()\n\ntraining_repo = args.txtdir\n\n# service creation\nmodel = {\'repository\':model_repo}\nparameters_input = {\'connector\':\'txt\'}\nparameters_mllib = {}\nparameters_output = {}\ntry:\n    creat = dd.put_service(sname,model,description,mllib,\n                           parameters_input,parameters_mllib,parameters_output,\'unsupervised\')\nexcept:\n    pass\n\n# training\ntrain_data = [training_repo]\nparameters_input = {\'min_count\':10,\'min_word_length\':5}\nparameters_mllib = {\'iterations\':500,\'perplexity\':args.perplexity}\nparameters_output = {}\npredout = dd.post_train(sname,train_data,parameters_input,parameters_mllib,parameters_output,async=True)\n\ntime.sleep(1)\ntrain_status = \'\'\nwhile True:\n    train_status = dd.get_train(sname,job=1,timeout=3)\n    if train_status[\'head\'][\'status\'] == \'running\':\n        print train_status[\'body\'][\'measure\']\n    else:\n        print train_status\n        predout = train_status\n        break\n\npredictions = predout[\'body\'][\'predictions\']\nN = len(predictions)\npoints = np.empty((N,2),dtype=np.float)\ni = 0\nfor p in predictions:\n    points[i,0] = p[\'vals\'][0]\n    points[i,1] = p[\'vals\'][1]\n    i = i + 1\n        \npylab.xlim([-30,30])\npylab.ylim([-30,30])\n\nplt.ioff()\ncolors = np.random.rand(N)\nplt.scatter(points[:,0],points[:,1],colors)\npylab.show()\n\ndd.delete_service(sname,clear=\'\')\n'"
tools/torch/trace_pytorch_transformers.py,0,"b'#!/usr/bin/python3\nimport sys\nimport os\nimport argparse\nimport logging\n\nimport torch\nimport torch.nn as nn\nimport transformers as M\n\nparser = argparse.ArgumentParser(description=""Trace NLP models from pytorch-transformers"")\nparser.add_argument(\'models\', type=str, nargs=\'*\', help=""Models to trace."")\nparser.add_argument(\'--print-models\', action=\'store_true\', help=""Print all the available models names and exit"")\nparser.add_argument(\'-a\', ""--all"", action=\'store_true\', help=""Export all available models"")\nparser.add_argument(\'-v\', ""--verbose"", action=\'store_true\', help=""Set logging level to INFO"")\nparser.add_argument(\'-o\', ""--output-dir"", default=""."", type=str, help=""Output directory for traced models"")\nparser.add_argument(\'-p\', ""--not-pretrained"", dest=""pretrained"", action=\'store_false\',\n                    help=""Whether the exported models should not be pretrained"")\nparser.add_argument(\'-t\', \'--template\', default="""", type=str, help=""Template name of the model, as specified by pytorch-transformers"")\nparser.add_argument(\'--cpu\', action=\'store_true\', help=""Force models to be exported for CPU device"")\nparser.add_argument(\'--gpuid\', type=int, help=""If cuda, trace model on given gpu."")\nparser.add_argument(\'--input-size\', type=int, default=512, help=""Length of the input sequence"")\nparser.add_argument(\'--vocab\', action=\'store_true\', help=""Export the vocab.dat file along with the model."")\nparser.add_argument(\'--train\', action=\'store_true\', help=""Prepare model for training"")\nparser.add_argument(\'--num-labels\', type=int, default=2, help=""For sequence classification only: number of classes"")\n\nargs = parser.parse_args()\n\nif args.verbose:\n    logging.basicConfig(level=logging.INFO)\n\nlogging.info(""pytorch version %s, from %s"" % (torch.__version__, torch.__file__))\nlogging.info(""pytorch-transformers version %s, from %s"" % (M.__version__, M.__file__))\n\nmodel_classes = {\n    ""bert"": M.BertForMaskedLM,\n    ""bert_classif"": M.BertForSequenceClassification,\n    ""roberta"": M.RobertaForMaskedLM,\n    ""gpt2"": M.GPT2LMHeadModel,\n}\n\ndef get_model_type(mname):\n    for key in default_templates:\n        if mname == key or mname.startswith(key + ""_""):\n            return key\n    return """"\n    \n\ndefault_templates = {\n    ""bert"": ""bert-base-uncased"",\n    ""roberta"":""roberta-base"",\n    ""gpt2"": ""gpt2"",\n}\n\ntokenizers = {\n    ""bert"": M.BertTokenizer,\n    ""roberta"": M.RobertaTokenizer,\n    ""gpt2"": M.GPT2Tokenizer,\n}\n\nif args.all:\n    args.models = model_classes.keys()\n\nif args.print_models:\n    print(""*** Available models ***"")\n    for key in model_classes:\n        print(key)\n    sys.exit(0)\nelif not args.models:\n    sys.stderr.write(""Please specify at least one model to be exported\\n"")\n    sys.exit(-1)\n\ndevice = \'cuda\' if torch.cuda.is_available() and not args.cpu else \'cpu\'\nif device == \'cuda\' and args.gpuid:\n    device += \':\' + str(args.gpuid)\nlogging.info(""Device: %s"", device)\n\nif args.input_size > 512 or args.input_size <= 0:\n    logging.error(""This input size is not supported: %d"", args.input_size)\n    sys.exit(-1)\n\nlogging.info(""Input size: %d"", args.input_size)\n\n# Example inputs\ninput_ids = torch.ones((1, args.input_size), dtype=torch.long, device=device)\natt_mask = torch.ones_like(input_ids)\ntoken_type_ids = torch.zeros_like(input_ids)\nposition_ids = torch.arange(args.input_size, dtype=torch.long, device=device).unsqueeze(0)\n\nfor mname in args.models:\n    if mname not in model_classes:\n        logging.warn(""model %s is unknown and will not be exported"", mname)\n        continue\n\n    model_type = get_model_type(mname)\n\n    # Find appropriate template\n    if args.template:\n        mtemplate = args.template\n    else:\n        mtemplate = default_templates[model_type]\n\n    # Additionnal parameters\n    kvargs = dict()\n    if mname in [""bert_classif""]:\n        kvargs[""num_labels""] = args.num_labels\n    if model_type in [""bert"", ""roberta""]:\n        kvargs[""output_hidden_states""] = True\n\n    # Create the model\n    mclass = model_classes[mname]\n    logging.info(""Model class: %s"", mclass.__name__)\n    logging.info(""Use template \'%s\'"", mtemplate)\n    model = mclass.from_pretrained(mtemplate, torchscript=True, **kvargs)\n\n    if not args.pretrained:\n        logging.info(""Create model from scratch with the same config as the pretrained one"")\n        model = mclass(model.config)\n\n    model.to(device)\n    if not args.train:\n        model.eval()\n    else:\n        model.train()\n\n    # Trace the model with the correct inputs\n    if mname in [""bert"", ""roberta"", ""bert_classif""]:\n        traced_model = torch.jit.trace(model, (input_ids, token_type_ids, att_mask))\n    elif mname in [""distilbert""]:\n        traced_model = torch.jit.trace(model, (input_ids, att_mask))\n    elif mname in [""gpt2""]:\n        # change order of positional arguments\n        def real_forward(self, i, p):\n            return self.p_forward(input_ids=i, position_ids=p)\n        setattr(mclass, \'p_forward\', mclass.forward)\n        setattr(mclass, \'forward\', real_forward)\n\n        traced_model = torch.jit.trace(model, (input_ids, position_ids))\n    else:\n        raise ValueError(""there is no method to trace this model: %s"" % mname)\n    \n    filename = os.path.join(args.output_dir, mname + \n        (""-"" + mtemplate if args.template in mclass.pretrained_model_archive_map else """") +\n        (""-pretrained"" if args.pretrained else """") + "".pt"")\n    logging.info(""Saving to %s"", filename)\n    traced_model.save(filename)\n\n    # Export vocab.dat\n    if args.vocab:\n        tokenizer = tokenizers[model_type].from_pretrained(mtemplate)\n        filename = os.path.join(args.output_dir, ""vocab.dat"")\n        \n        with open(filename, \'w\') as f:\n            for i in range(len(tokenizer)):\n                word = tokenizer.convert_ids_to_tokens([i])[0]\n                f.write(word + ""\\t"" + str(i) + ""\\n"")\n\n        logging.info(""Vocabulary saved to %s"", filename)\n\nlogging.info(""Done"")\n'"
tools/torch/trace_torchvision.py,0,"b'#!/usr/bin/python3\n""""""\nDeepDetect\nCopyright (c) 2019 Jolibrain\nAuthor: Louis Jean <ljean@etud.insa-toulouse.fr>\n\nThis file is part of deepdetect.\n\ndeepdetect is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\ndeepdetect is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Lesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License\nalong with deepdetect.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport torch\nimport torchvision.models as M\n\nimport sys\nimport os\nimport argparse\nimport logging\n\nparser = argparse.ArgumentParser(description=""Trace image processing models from torchvision"")\nparser.add_argument(\'models\', type=str, nargs=\'*\', help=""Models to trace."")\nparser.add_argument(\'--print-models\', action=\'store_true\', help=""Print all the available models names and exit"")\nparser.add_argument(\'-a\', ""--all"", action=\'store_true\', help=""Export all available models"")\nparser.add_argument(\'-v\', ""--verbose"", action=\'store_true\', help=""Set logging level to INFO"")\nparser.add_argument(\'-o\', ""--output-dir"", default=""."", type=str, help=""Output directory for traced models"")\nparser.add_argument(\'-p\', ""--not-pretrained"", dest=""pretrained"", action=\'store_false\', \n                    help=""Whether the exported models should not be pretrained"")\nparser.add_argument(\'--cpu\', action=\'store_true\', help=""Force models to be exported for CPU device"")\n\nargs = parser.parse_args()\n\nif args.verbose:\n    logging.basicConfig(level=logging.INFO)\n\nmodel_classes = {\n    ""alexnet"": M.alexnet,\n    ""vgg11"": M.vgg11,\n    ""vgg11_bn"": M.vgg11_bn,\n    ""vgg13"": M.vgg13,\n    ""vgg13_bn"": M.vgg13_bn,\n    ""vgg16"": M.vgg16,\n    ""vgg16_bn"": M.vgg16_bn,\n    ""vgg19"": M.vgg19,\n    ""vgg19_bn"": M.vgg19_bn,\n    ""resnet18"": M.resnet18,\n    ""resnet34"": M.resnet34,\n    ""resnet50"": M.resnet50,\n    ""resnet101"": M.resnet101,\n    ""resnet152"": M.resnet152,\n    ""squeezenet1_0"": M.squeezenet1_0,\n    ""squeezenet1_1"": M.squeezenet1_1,\n    ""densenet121"": M.densenet121,\n    ""densenet169"": M.densenet169,\n    ""densenet161"": M.densenet161,\n    ""densenet201"": M.densenet201,\n    ""googlenet"": M.googlenet,\n    ""shufflenet_v2_x0_5"": M.shufflenet_v2_x0_5,\n    ""shufflenet_v2_x1_0"": M.shufflenet_v2_x1_0,\n    ""shufflenet_v2_x1_5"": M.shufflenet_v2_x1_5,\n    ""shufflenet_v2_x2_0"": M.shufflenet_v2_x1_0,\n    ""mobilenet_v2"": M.mobilenet_v2,\n    ""resnext50_32x4d"": M.resnext50_32x4d,\n    ""resnext101_32x8d"": M.resnext101_32x8d,\n}\nif args.all:\n    args.models = model_classes.keys()\n\nif args.print_models:\n    print(""*** Available models ***"")\n    for key in model_classes:\n        print(key)\n    sys.exit(0)\nelif not args.models:\n    sys.stderr.write(""Please specify at least one model to be exported\\n"")\n    sys.exit(-1)\n\ndevice = \'cuda\' if torch.cuda.is_available() and not args.cpu else \'cpu\'\nlogging.info(""Device: %s"", device)\n\n# An instance of your model.\nfor mname in args.models:\n    if mname not in model_classes:\n        logging.warn(""model %s is unknown and will not be exported"", mname)\n        continue\n\n    logging.info(""Exporting model %s %s"", mname, ""(pretrained)"" if args.pretrained else """")\n    model = model_classes[mname](pretrained=args.pretrained, progress=args.verbose)\n    model.eval()\n\n    example = torch.rand(1, 3, 224, 224)\n    traced_script_module = torch.jit.trace(model, example)\n\n    filename = os.path.join(args.output_dir, mname + (""-pretrained"" if args.pretrained else """") + "".pt"")\n    logging.info(""Saving to %s"", filename)\n    traced_script_module.save(filename)\n\nlogging.info(""Done"")'"
datasets/imagenet/scripts/build_dataset.py,0,"b""import os, argparse\n\ndef convert_imageset(convert_imageset,images,prefix,vt='train',resize=256):\n    cmd = convert_imageset + ' --resize_height=' + str(resize) + ' --resize_width=' + str(resize) + ' --shuffle ' + images + '/' + vt + '/ ' + images + '/' + vt + '.txt ' + prefix + '_' + vt + '_lmdb'\n    print cmd\n    os.system(cmd)\n\ndef compute_image_mean(image_mean,prefix,vt='train'):\n    cmd = image_mean + ' ' + prefix + '_' + vt + '_lmdb ' + prefix + '_mean.binaryproto'\n    print cmd\n    os.system(cmd)\n\nparser = argparse.ArgumentParser(description='Imagenet dataset builder')\nparser.add_argument('--convert_imageset',type=str,default='build/tools/convert_imageset',help='location of the convert_imageset exe')\nparser.add_argument('--image_mean',type=str,default='build/tools/compute_image_mean',help='location of the compute_image_mean exe')\nparser.add_argument('--images',type=str,default='.',help='location of the dataset of images')\nparser.add_argument('--prefix',type=str,default='img_dataset',help='dataset prefix name')\nparser.add_argument('--repo',type=str,default='',help='locatation of the dataset of lmdb databases output repositories')\nargs = parser.parse_args()\n\nconvert_imageset(args.convert_imageset,args.images,args.prefix,'train',256)\nconvert_imageset(args.convert_imageset,args.images,args.prefix,'val',256)\ncompute_image_mean(args.image_mean,args.prefix,'train')\n"""
datasets/imagenet/scripts/imagenet.py,0,"b'import os, argparse, glob, sys, subprocess\nfrom collections import defaultdict\n\ndef sizeof_fmt(num):\n    for x in [\'bytes\',\'KB\',\'MB\',\'GB\']:\n        if num < 1024.0 and num > -1024.0:\n            return ""%3.1f%s"" % (num, x)\n        num /= 1024.0\n    return ""%3.1f%s"" % (num, \'TB\')\n\nclass Synset:\n    \'A representation of a category, aka synset\'\n    _name = \'\'\n    _desc = \'\'\n    _syn = \'\'\n    _loc = \'\'\n    _img_count = 0 # number of images in synset\n    _imgs = []\n    _size = 0\n    _parent = \'\'\n    _children = []\n\n    def __init__(self, loc):\n        self._loc = loc\n        self._syn = os.path.basename(os.path.normpath(loc))\n\n    def print_synset(self):\n        print \'----------------------\'\n        print self._syn\n        print self._name\n        print self._desc\n        print self._img_count, ""images""\n        print sizeof_fmt(self._size)\n        print \'----------------------\'\n\ndef load_words(wordsfile):\n    words = {}\n    with open(wordsfile) as f:\n        words = dict(x.rstrip().split(None, 1) for x in f)\n    return words\n\ndef load_descs(descfile):\n    descs = {}\n    with open(descfile) as f:\n        descs = dict(x.rstrip().split(None,1) for x in f)\n    return descs\n\ndef load_treemap(treemapfile):\n    tdict = defaultdict(list)\n    with open(treemapfile) as f:\n        for line in f:\n            ls = line.rstrip().split(\' \')\n            tdict[ls[0]].append(ls[1])\n    return tdict\n\ndef read_synsets(alldirs,synsets,descs,search,lsynsets):\n    synsetsobj = {}\n    for d in alldirs:\n        s = Synset(d)\n        if lsynsets:\n            if not s._syn in lsynsets:\n                continue\n        s._name = synsets[s._syn]\n        if search:\n            if not search in s._name:\n                continue\n        s._desc = descs[s._syn]\n        s._imgs = glob.glob(d + ""/*"")\n        s._img_count = len(s._imgs)\n        s._size = sum(os.path.getsize(f) for f in s._imgs if os.path.isfile(f))\n        synsetsobj[s._syn] = s\n    return synsetsobj\n\ndef find_treemap(lsyn,tmap):\n    # - iterate lsyn\n    # - for each key get the subsynets\n    # - if no subsynets add to temporary lsyn\n    # - otherwise remove key from lsyn (if fact only if no image, so we leave it for now)\n    # - merge lsyn with temporary lsyn\n    clsyn = lsyn\n    tlsyn = []\n    for key in lsyn:\n        ls = tmap[key]\n        if ls:\n            #tlsyn.remove(key)\n            for l in ls:\n                #tlsyn.append(l)\n                ttlsyn = []\n                ttlsyn.append(l)\n                ttlsyn = find_treemap(ttlsyn,tmap)\n                #print \'ttlsyn=\',ttlsyn\n                tlsyn = tlsyn + ttlsyn\n                #print \'tlsyn=\',tlsyn\n    lsyn = clsyn + tlsyn\n    return lsyn\n\ndef write_dict(files,ffile):\n    f = open(ffile,\'w\')\n    for key in files:\n        line = str(key) + \' \' + str(files[key]) + \'\\n\'\n        f.write(line)\n\nparser = argparse.ArgumentParser(description=\'Imagenet processing tools\')\nparser.add_argument(\'repository\',type=str,help=\'location of the imagenet repository\')\nparser.add_argument(\'--list\',dest=\'list\',action=\'store_true\',help=\'list repository, read-only\')\nparser.add_argument(\'--dataset\',dest=\'dataset\',type=str,help=\'location of a dataset to be created based on search terms (--search) or list (--synsets) of synsets\')\nparser.add_argument(\'--trainperc\',dest=\'trainperc\',type=float,help=\'% of the dataset to be used as training set\')\nparser.add_argument(\'--search\',dest=\'search\',type=str,default=\'\',help=\'search for synsets whose name contains the search term\')\nparser.add_argument(\'--synsets\',dest=\'synsets\',type=str,help=\'list of synsets, possibly in a file, to be looked up\')\nparser.add_argument(\'--subsynsets\',dest=\'subsynsets\',type=str,default=\'none\',help=\'use treemaps to retrieve synsets that are part of a higher level synset\')\nargs = parser.parse_args()\n\nallsynsets = load_words(\'words.txt\')\nalldescs = load_descs(\'gloss.txt\')\nalldirs = glob.glob(args.repository + ""/n*"")\n\nprint ""Found"", len(alldirs), ""image repositories as synsets""\n\nlsynsets = {}\nif args.synsets:\n    if not \'.\' in args.synsets: # not a file\n        l = args.synsets.split(\',\')\n        for e in l:\n            lsynsets[e] = 1\n    else:\n        with open(args.synsets) as f:\n            lsynsets = dict(x.rstrip().split(None,1) for x in f)\n\nif not args.subsynsets == \'none\' and not args.subsynsets == \'\':\n    lsynsets[args.subsynsets] = 1\nallsynsetsobj = read_synsets(alldirs,allsynsets,alldescs,args.search,lsynsets)\nprint ""Found"", len(allsynsetsobj), ""relevant synsets""\n\nif not args.subsynsets == \'none\':\n    treemap = load_treemap(\'wordnet.is_a.txt\')\n    lsyn = []\n    for key,value in allsynsetsobj.items():\n        for l in treemap[key]:\n            lsyn.append(l)\n    lsyn = find_treemap(lsyn,treemap)\n    #print len(lsyn)\n    subsynsetsobj = read_synsets(alldirs,allsynsets,alldescs,\'\',lsyn)\n    allsynsetsobj = dict(allsynsetsobj,**subsynsetsobj)\n\nif args.list:\n    totalsize = 0\n    for key,value in allsynsetsobj.items():\n        value.print_synset()\n        totalsize = totalsize + value._size\n    print ""Found"", len(allsynsetsobj), ""relevant synsets""\n    print ""Number of images:"",sum(allsynsetsobj[o]._img_count for o in allsynsetsobj)\n    print ""Total size: ""+ sizeof_fmt(totalsize)\n\nelif args.dataset:\n    try:\n        os.mkdir(args.dataset)\n    except:\n        pass\n    if not args.trainperc:\n        for key,value in allsynsetsobj.items():\n            os.symlink(value._loc,args.dataset + ""/"" + value._syn)\n    else:\n        print ""Processing dataset"", args.dataset\n        trainrep = \'train\'\n        valrep = \'val\'\n        trainpath = args.dataset + ""/"" + trainrep\n        valpath = args.dataset + ""/"" + valrep\n        trainfile = args.dataset + \'/train.txt\'\n        valfile = args.dataset + \'/val.txt\'\n        correspfile = args.dataset + \'/corresp.txt\'\n        tfiles = {}\n        vfiles = {}\n        corresp = {}\n        try:\n            os.mkdir(trainpath)\n            os.mkdir(valpath)\n        except:\n            pass\n        cl = 0\n        gifconverts = 0\n        for key,value in allsynsetsobj.items():\n            thresh = int(len(value._imgs)*args.trainperc/100.0)\n            train_list = value._imgs[0:thresh]\n            val_list = value._imgs[thresh:int(len(value._imgs))]\n            lpath = trainpath + ""/"" + value._syn\n            if not cl in corresp:\n                corresp[cl] = key + \' \' + value._name\n            try:\n                os.mkdir(lpath)\n            except:\n                pass\n            for f in train_list:\n                fname = os.path.basename(os.path.normpath(f))\n                if "".gif"" in fname:\n                    fname = fname + "".jpg""\n                    convcmd = f + \' \' + trainpath + \'/\' + value._syn + \'/\' + fname\n                    os.system(""/usr/bin/convert "" + convcmd)\n                    gifconverts += 1\n                else:\n                    os.symlink(f,trainpath + ""/"" + value._syn + ""/"" + fname)\n                tfiles[value._syn + \'/\' + os.path.basename(fname)] = cl\n            for f in val_list:\n                fname = os.path.basename(os.path.normpath(f))\n                if "".gif"" in fname:\n                    fname = fname + "".jpg""\n                    convcmd = f + \' \' + valpath + \'/\' + os.path.basename(fname)\n                    os.system(""/usr/bin/convert "" + convcmd)\n                    gifconverts += 1\n                else:\n                    os.symlink(f,valpath + ""/"" + os.path.basename(fname))\n                vfiles[os.path.basename(fname)] = cl\n            cl += 1\n        write_dict(corresp,correspfile)\n        write_dict(tfiles,trainfile)\n        write_dict(vfiles,valfile)\n        print ""converted "" + str(gifconverts) + "" gif files""\n'"
examples/all/sinus/gen.py,0,"b'#generates a simple sinus in csvTS form for testing timeserie predicions\nimport numpy as np\nimport os\n\nnp.random.seed(2)\n\nT = 20\nL = 1000\nN = 100\n\nx = np.empty((N, L), \'int64\')\nx[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\ndata = np.sin(x / 1.0 / T).astype(\'float64\')\n\ninput = data[3:, :-1]\ntarget = data[3:, 1:]  # target is sinus as timestep + 1 wrt input\ntest_input = data[:3, :-1]\ntest_target = data[:3, 1:]\n\nif os.path.exists(""./train""):\n    for f in os.listdir(""train""):\n        os.remove(""train/""+f)\n    os.rmdir(""train"")\nif os.path.exists(""./test""):\n    for f in os.listdir(""test""):\n        os.remove(""test/""+f)\n    os.rmdir(""test"")\n\nif os.path.exists(""./predict""):\n    for f in os.listdir(""predict""):\n        os.remove(""predict/""+f)\n    os.rmdir(""predict"")\n\n\nos.mkdir(""train"")\nos.mkdir(""test"")\nos.mkdir(""predict"")\n\nfor i in range(N-3):\n    csvdat = np.empty((L-1,2), \'float64\')\n    csvdat[:,0] = input[i,:]\n    csvdat[:,1] = target[i,:]\n    filename = ""train/seq_"" + str(i) + "".csv""\n    np.savetxt(filename, csvdat, delimiter="","")\n    with open(filename, \'r+\') as f:\n        content = f.read()\n        f.seek(0,0)\n        f.write(""input,output\\n"" + content)\n\nfor i in range(2):\n    csvdat = np.empty((L-1,2), \'float64\')\n    csvdat[:,0] = test_input[i,:]\n    csvdat[:,1] = test_target[i,:]\n    filename = ""test/seq_"" + str(i) + "".csv""\n    np.savetxt(filename, csvdat, delimiter="","")\n    with open(filename, \'r+\') as f:\n        content = f.read()\n        f.seek(0,0)\n        f.write(""input,output\\n"" + content)\n\ncsvdat = np.empty((L-1,2), \'float64\')\ncsvdat[:,0] = test_input[2,:]\ncsvdat[:,1] = test_target[2,:]\nfilename = ""predict/seq_"" + str(2) + "".csv""\nnp.savetxt(filename, csvdat,  delimiter="","")\nwith open(filename, \'r+\') as f:\n    content = f.read()\n    f.seek(0,0)\n    f.write(""input,output\\n"" + content)\n'"
examples/caffe2/detectron/convert_pkl_to_pb.py,0,"b'#!/usr/bin/env python\n\nimport cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)\n\nimport os\nimport sys\nimport copy\nimport numpy\nimport argparse\nfrom caffe2.python import core\nfrom caffe2.proto import caffe2_pb2\nfrom detectron.core.config import cfg\nfrom detectron.core.config import merge_cfg_from_file\nfrom detectron.core.config import merge_cfg_from_list\nfrom detectron.core.config import assert_and_infer_cfg\nimport detectron.core.test_engine as infer_engine\nimport detectron.utils.c2 as c2_utils\nimport detectron.utils.io as io_utils\nimport detectron.utils.model_convert_utils as mutils\nimport detectron.datasets.dummy_datasets as dummy_datasets\nimport tools.convert_pkl_to_pb as convert_tools\n\n#############################################################\n# Supposed to be used for ""seg-every-thing models"" training #\n# Set for compatibility but currenlty ignored               #\nfrom detectron.utils.collections import AttrDict\ncfg.MRCNN.BBOX2MASK = AttrDict()\ncfg.MRCNN.BBOX2MASK.BBOX2MASK_ON = False\ncfg.MRCNN.BBOX2MASK.TYPE = b\'\'\ncfg.MRCNN.BBOX2MASK.USE_PRETRAINED_EMBED = False\ncfg.MRCNN.BBOX2MASK.PRETRAINED_EMBED_NAME = b\'\'\ncfg.MRCNN.BBOX2MASK.PRETRAINED_EMBED_DIM = -1\ncfg.MRCNN.BBOX2MASK.STOP_DET_W_GRAD = True\ncfg.MRCNN.BBOX2MASK.INCLUDE_CLS_SCORE = True\ncfg.MRCNN.BBOX2MASK.INCLUDE_BBOX_PRED = False\ncfg.MRCNN.BBOX2MASK.USE_LEAKYRELU = True\ncfg.MRCNN.JOINT_FCN_MLP_HEAD = False\ncfg.MRCNN.MLP_MASK_BRANCH_TYPE = b\'\'\ncfg.TRAIN.TRAIN_MASK_HEAD_ONLY = False\ncfg.TRAIN.MRCNN_FILTER_LABELS = False\ncfg.TRAIN.MRCNN_LABELS_TO_KEEP = ()\n#############################################################\n\n# Hardcoded values\nclass Constants:\n\n    ### Defined by Detectron\n\n    # In Detectron/tools/convert_pkl_to_pb.py\n    nms_outputs = [\'score_nms\', \'bbox_nms\', \'class_nms\'] # (see add_bbox_ops)\n    im_info = \'im_info\' # (see _prepare_blobs)\n    # In Detectron/detectron/core/test.py # (see im_detect_mask)\n    mask_rois = \'mask_rois\'\n    mask_pred = \'mask_fcn_probs\'\n    # In Detectron/detectron/modeling/FPN.py (see add_multilevel_roi_blobs)\n    idx_restore_suffix = \'_idx_restore_int32\'\n    @staticmethod\n    def fpn_level_suffix(level): return \'_fpn\' + str(level)\n\n    ### Defined by Learning to Segment Every Thing\n\n    # In seg_every_thing/lib/modeling/mask_rcnn_heads.py (see bbox2mask_weight_transfer)\n    mask_w = \'mask_fcn_logits_w\'\n    mask_w_flat = \'mask_fcn_logits_w_flat\'\n    mask_w_flat_inputs = (mask_w_flat + \'_w\', mask_w_flat + \'_b\')\n    mask_w_size = 3002\n\n    ### Defined by Deepdetect\n\n    # In deepdetect/src/backends/caffe2/nettools/internal.h\n    batch_splits_suffix = \'_batch_splits\'\n    # In deepdetect/src/backends/caffe2/nettools/devices_and_operators.cc\n    nms_outputs.append(\n        nms_outputs[0] + batch_splits_suffix\n    ) # (see ensure_box_nms_is_batchable)\n\n    ### Can be set to anything\n\n    main_output = \'masks\'\n\ndef add_custom_op(net, name, inputs, outputs, **args):\n    op = net.op.add()\n    op.type = name\n    op.input[:] = inputs\n    op.output[:] = outputs\n    for k,v in args.items():\n        arg = op.arg.add()\n        arg.name = k\n        if isinstance(v, int):\n            arg.i = v\n        elif isinstance(v, float):\n            arg.f = v\n        elif type(v) in (list, tuple, numpy.ndarray):\n            assert len(v)\n            if type(v[0]) in (int, numpy.int32):\n                arg.ints[:] = v\n            elif type(v[0]) in (float, numpy.float32):\n                arg.floats[:] = v\n            else:\n                raise RuntimeError(\'Unknown type : {}\'.format(type(v[0])))\n        else:\n            raise RuntimeError(\'Unknown type : {}\'.format(type(v)))\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--wts\', required=True, help=\'weights model file\')\n    parser.add_argument(\'--cfg\', required=True, help=\'cfg model file\')\n    parser.add_argument(\'--out_dir\', required=True, help=\'output directory\')\n    parser.add_argument(\'--mask_dir\', type=str, help=\'mask extension directory\')\n    parser.add_argument(\'--corresp\', default=None, choices=[\'coco\', \'vg3k\'],\n                        help=\'generate a corresp.txt file containing the classes \'\n                        \'(81 for the COCO dataset, 3002 for Visual Genome 3K)\')\n    parser.add_argument(\'--net_name\', default=\'detectron\',\n                        type=str, help=\'optional name for the net\')\n    parser.add_argument(\'--fuse_af\', default=1, type=int, help=\'1 to fuse_af\')\n    parser.add_argument(\'--device\', choices=[\'cpu\', \'gpu\'], default=\'cpu\',\n                        type=str, help=\'Device to run the model on\')\n    parser.add_argument(\'--net_execution_type\', choices=[\'simple\', \'dag\'], default=\'simple\',\n                        type=str, help=\'caffe2 net execution type\')\n    parser.add_argument(\'--use_nnpack\', default=1, type=int, help=\'Use nnpack for conv\')\n    parser.add_argument(\'opts\', nargs=argparse.REMAINDER,\n                        help=\'See detectron/core/config.py for all options\')\n    args = parser.parse_args()\n    assert not args.device == \'gpu\' and args.use_nnpack\n    for key in {\'cfg\', \'wts\', \'out_dir\'}:\n        setattr(args, key, os.path.abspath(getattr(args, key)))\n    args.opts.extend([\'TRAIN.WEIGHTS\', args.wts, \'TEST.WEIGHTS\', args.wts, \'NUM_GPUS\', 1])\n    return args\n\ndef save_model(net, init_net, path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    with open(os.path.join(path, \'predict_net.pb\'), \'wb\') as f:\n        f.write(net.SerializeToString())\n    with open(os.path.join(path, \'init_net.pb\'), \'wb\') as f:\n        f.write(init_net.SerializeToString())\n\ndef convert_main_net(args, main_net, blobs):\n    net = core.Net(\'\')\n    net.Proto().op.extend(copy.deepcopy(main_net.op))\n    net.Proto().external_input.extend(copy.deepcopy(main_net.external_input))\n    net.Proto().external_output.extend(copy.deepcopy(main_net.external_output))\n    net.Proto().type = args.net_execution_type\n    net.Proto().num_workers = 1 if args.net_execution_type == \'simple\' else 4\n    convert_tools.convert_net(args, net.Proto(), blobs)\n    convert_tools.add_bbox_ops(args, net, blobs)\n    if args.fuse_af:\n        print (\'Fusing affine channel...\')\n        net, blobs = mutils.fuse_net_affine(net, blobs)\n    if args.use_nnpack:\n        mutils.update_mobile_engines(net.Proto())\n    empty_blobs = [\'data\', \'im_info\']\n    init_net = convert_tools.gen_init_net(net, blobs, empty_blobs)\n    if args.device == \'gpu\':\n        [net, init_net] = convert_tools.convert_model_gpu(args, net, init_net)\n    net.Proto().name = args.net_name\n    init_net.Proto().name = args.net_name + \'_init\'\n    save_model(net.Proto(), init_net.Proto(), args.out_dir)\n\ndef convert_mask_net(args, mask_net):\n\n    # Initialization net\n    init_net = caffe2_pb2.NetDef()\n    net = caffe2_pb2.NetDef()\n    blobs = io_utils.load_object(args.wts)[\'blobs\']\n    externals = set(c2_utils.UnscopeName(inp) for inp in mask_net.external_input)\n    for name in set(blobs.keys()).intersection(externals):\n        blob = blobs[name]\n        add_custom_op(init_net, \'GivenTensorFill\', [], [name],\n                      values = blob.flatten(),\n                      shape = blob.shape)\n\n    # Pre-process the ROIs\n    add_custom_op(net, \'BBoxToRoi\',\n                [Constants.nms_outputs[1], Constants.im_info, Constants.nms_outputs[3]],\n                [Constants.mask_rois])\n    # Group the ROIs based on their FPN level\n    if cfg.FPN.MULTILEVEL_ROIS:\n        outputs = [Constants.mask_rois + Constants.idx_restore_suffix]\n        for level in range(cfg.FPN.ROI_MIN_LEVEL, cfg.FPN.ROI_MAX_LEVEL + 1):\n            outputs.append(Constants.mask_rois + Constants.fpn_level_suffix(level))\n        add_custom_op(net, \'MultiLevelRoi\', [Constants.mask_rois], outputs,\n                    min_level = cfg.FPN.ROI_MIN_LEVEL,\n                    canon_scale = cfg.FPN.ROI_CANONICAL_SCALE,\n                    canon_level = cfg.FPN.ROI_CANONICAL_LEVEL)\n\n    # Generate the masks\n    net.op.extend(mask_net.op)\n\n    # Post-process the masks\n    add_custom_op(net, \'SegmentMask\',\n                  Constants.nms_outputs[1:-1] + [Constants.mask_pred, Constants.im_info],\n                  [Constants.main_output, Constants.im_info],\n                  thresh_bin = cfg.MRCNN.THRESH_BINARIZE)\n\n    net.name = args.net_name + \'_mask\'\n    init_net.name = args.net_name + \'_mask_init\'\n    save_model(net, init_net, args.mask_dir)\n\ndef create_corresp_file(args, dataset):\n    classes = dataset.classes\n    corresp = \'\\n\'.join(\'{} {}\'.format(i, classes[i]) for i, _ in enumerate(classes))\n    with open(args.out_dir + \'/corresp.txt\', \'w\') as f:\n        f.write(corresp)\n\ndef main():\n    args = parse_args()\n    merge_cfg_from_file(args.cfg)\n    merge_cfg_from_list(args.opts)\n    assert_and_infer_cfg()\n    model, blobs = convert_tools.load_model(args)\n\n    convert_main_net(args, model.net.Proto(), blobs)\n    if args.mask_dir:\n        convert_mask_net(args, model.mask_net.Proto())\n    if args.corresp:\n        classes = getattr(dummy_datasets, \'get_{}_dataset\'.format(args.corresp))().classes\n        corresp = \'\\n\'.join(\'{} {}\'.format(i, classes[i]) for i, _ in enumerate(classes))\n        with open(args.out_dir + \'/corresp.txt\', \'w\') as f:\n            f.write(corresp)\n    return 0\n\nif __name__ == \'__main__\':\n    exit(main())\n'"
examples/caffe2/detectron/plot_masks.py,0,"b'#!/usr/bin/env python\n\nimport os\nimport json\nimport argparse\nimport requests\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\n\ndef pred_to_fig(pred, alpha=0.9, color_min=0.3, color_max=0.7):\n    name = os.path.split(pred[\'uri\'])[-1]\n    print(\'Applying masks on ""{}""\'.format(name))\n    img = np.array(Image.open(pred[\'uri\']).convert(\'RGBA\'))\n    fig, ax = plt.subplots(1)\n    ax.set_title(name)\n    ax.imshow(img)\n    for item in pred[\'classes\']:\n\n        #Fetch\n        xmin = int(item[\'bbox\'][\'xmin\'])\n        ymin = int(item[\'bbox\'][\'ymin\'])\n        width = item[\'mask\'][\'width\']\n        height = item[\'mask\'][\'height\']\n\n        #Set to a random color\n        mask = np.array(item[\'mask\'][\'data\']).astype(float) * 255\n        mask = np.stack((mask.reshape(height, width),) * 4, -1)\n        mask[...,-1] *= alpha\n        mask[...,:-1] *= np.random.uniform(color_min, color_max, 3)\n\n        #Plot\n        buff = np.zeros(img.shape, dtype=\'uint8\')\n        buff[ymin:ymin+height, xmin:xmin+width] = mask\n        ax.imshow(buff)\n        ax.text(xmin, ymin, \'{} {:.2f}\'.format(item[\'cat\'], item[\'prob\']))\n\n    plt.figure(fig.number)\n\ndef preds_to_pdf(data, path):\n    with PdfPages(path) as pdf:\n        for pred in data[\'body\'][\'predictions\']:\n            pred_to_fig(pred)\n            pdf.savefig()\n\ndef get_preds(host, port, service, thresh, images):\n    url = \'http://{}:{}/predict\'.format(host, port)\n    print(\'Posting on ""{}""\'.format(url))\n    return requests.post(url, json = {\n        \'service\': service,\n        \'parameters\': {\n            \'output\': {\n                \'mask\': True,\n                \'best\': 1,\n                \'confidence_threshold\': thresh\n            }\n        },\n        \'data\': images\n    }).json()\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--host\', default=\'localhost\', type=str)\n    parser.add_argument(\'--port\', default=8080, type=int)\n    parser.add_argument(\'--threshold\', default=0.8, type=float)\n    parser.add_argument(\'--pdf\', required=True, type=str)\n    parser.add_argument(\'--service\', required=True, type=str)\n    parser.add_argument(\'image\', type=str, nargs=\'+\')\n    return parser.parse_args()\n\ndef main():\n    args = get_args()\n    preds = get_preds(args.host, args.port, args.service, args.threshold, args.image)\n    preds_to_pdf(preds, args.pdf)\n    return 0\n\nif __name__ == \'__main__\':\n    exit(main())\n'"
