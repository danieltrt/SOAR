file_path,api_count,code
gan-script-fast.py,60,"b'""""""\nThis is a straightforward Python implementation of a generative adversarial network.\nThe code is derived from the O\'Reilly interactive tutorial on GANs\n(https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners).\n\nThe tutorial\'s code trades efficiency for clarity in explaining how GANs function;\nthis script refactors a few things to improve performance, especially on GPU machines.\nIn particular, it uses a TensorFlow operation to generate random z values and pass them\nto the generator; this way, more computations are contained entirely within the\nTensorFlow graph.\n\nA version of this model with explanatory notes is also available on GitHub\nat https://github.com/jonbruner/generative-adversarial-networks.\n\nThis script requires TensorFlow and its dependencies in order to run. Please see\nthe readme for guidance on installing TensorFlow.\n\nThis script won\'t print summary statistics in the terminal during training;\ntrack progress and see sample images in TensorBoard.\n""""""\n\nimport tensorflow as tf\nimport datetime\n\n# Load MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""MNIST_data/"")\n\n# Define the discriminator network\ndef discriminator(images, reuse_variables=None):\n    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n        # First convolutional and pool layers\n        # This finds 32 different 5 x 5 pixel features\n        d_w1 = tf.get_variable(\'d_w1\', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b1 = tf.get_variable(\'d_b1\', [32], initializer=tf.constant_initializer(0))\n        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding=\'SAME\')\n        d1 = d1 + d_b1\n        d1 = tf.nn.relu(d1)\n        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n        # Second convolutional and pool layers\n        # This finds 64 different 5 x 5 pixel features\n        d_w2 = tf.get_variable(\'d_w2\', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b2 = tf.get_variable(\'d_b2\', [64], initializer=tf.constant_initializer(0))\n        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding=\'SAME\')\n        d2 = d2 + d_b2\n        d2 = tf.nn.relu(d2)\n        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n        # First fully connected layer\n        d_w3 = tf.get_variable(\'d_w3\', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b3 = tf.get_variable(\'d_b3\', [1024], initializer=tf.constant_initializer(0))\n        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n        d3 = tf.matmul(d3, d_w3)\n        d3 = d3 + d_b3\n        d3 = tf.nn.relu(d3)\n\n        # Second fully connected layer\n        d_w4 = tf.get_variable(\'d_w4\', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b4 = tf.get_variable(\'d_b4\', [1], initializer=tf.constant_initializer(0))\n        d4 = tf.matmul(d3, d_w4) + d_b4\n\n        # d4 contains unscaled values\n        return d4\n\n# Define the generator network\ndef generator(batch_size, z_dim):\n    z = tf.random_normal([batch_size, z_dim], mean=0, stddev=1, name=\'z\')\n    g_w1 = tf.get_variable(\'g_w1\', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b1 = tf.get_variable(\'g_b1\', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g1 = tf.matmul(z, g_w1) + g_b1\n    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope=\'g_b1\')\n    g1 = tf.nn.relu(g1)\n\n    # Generate 50 features\n    g_w2 = tf.get_variable(\'g_w2\', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b2 = tf.get_variable(\'g_b2\', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding=\'SAME\')\n    g2 = g2 + g_b2\n    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope=\'g_b2\')\n    g2 = tf.nn.relu(g2)\n    g2 = tf.image.resize_images(g2, [56, 56])\n\n    # Generate 25 features\n    g_w3 = tf.get_variable(\'g_w3\', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b3 = tf.get_variable(\'g_b3\', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding=\'SAME\')\n    g3 = g3 + g_b3\n    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope=\'g_b3\')\n    g3 = tf.nn.relu(g3)\n    g3 = tf.image.resize_images(g3, [56, 56])\n\n    # Final convolution with one output channel\n    g_w4 = tf.get_variable(\'g_w4\', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b4 = tf.get_variable(\'g_b4\', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding=\'SAME\')\n    g4 = g4 + g_b4\n    g4 = tf.sigmoid(g4)\n\n    # Dimensions of g4: batch_size x 28 x 28 x 1\n    return g4\n\nz_dimensions = 100\nbatch_size = 50\n\nx_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name=\'x_placeholder\')\n# x_placeholder is for feeding input images to the discriminator\n\nGz = generator(batch_size, z_dimensions)\n# Gz holds the generated images\n\nDx = discriminator(x_placeholder)\n# Dx will hold discriminator prediction probabilities\n# for the real MNIST images\n\nDg = discriminator(Gz, reuse_variables=True)\n# Dg will hold discriminator prediction probabilities for generated images\n\n# Define losses\nd_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\nd_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\ng_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))\n\n# Define variable lists\ntvars = tf.trainable_variables()\nd_vars = [var for var in tvars if \'d_\' in var.name]\ng_vars = [var for var in tvars if \'g_\' in var.name]\n\n# Define the optimizers\n# Train the discriminator\nd_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\nd_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n\n# Train the generator\ng_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)\n\n# From this point forward, reuse variables\ntf.get_variable_scope().reuse_variables()\n\nsess = tf.Session()\n\n# Send summary statistics to TensorBoard\ntf.summary.scalar(\'Generator_loss\', g_loss)\ntf.summary.scalar(\'Discriminator_loss_real\', d_loss_real)\ntf.summary.scalar(\'Discriminator_loss_fake\', d_loss_fake)\n\nimages_for_tensorboard = generator(batch_size, z_dimensions)\ntf.summary.image(\'Generated_images\', images_for_tensorboard, 5)\nmerged = tf.summary.merge_all()\nlogdir = ""tensorboard/"" + datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"") + ""/""\nwriter = tf.summary.FileWriter(logdir, sess.graph)\n\nsess.run(tf.global_variables_initializer())\n\n# Pre-train discriminator\nfor i in range(300):\n    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n    _, __ = sess.run([d_trainer_real, d_trainer_fake],\n                                           {x_placeholder: real_image_batch})\n\n# Train generator and discriminator together\nfor i in range(100000):\n    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n\n    # Train discriminator on both real and fake images\n    _, __ = sess.run([d_trainer_real, d_trainer_fake],\n                                           {x_placeholder: real_image_batch})\n\n    # Train generator\n    _ = sess.run(g_trainer)\n\n    if i % 10 == 0:\n        # Update TensorBoard with summary statistics\n        summary = sess.run(merged, {x_placeholder: real_image_batch})\n        writer.add_summary(summary, i)\n\n# Optionally, uncomment the following lines to update the checkpoint files attached to the tutorial.\n# saver = tf.train.Saver()\n# saver.save(sess, \'pretrained-model/pretrained_gan.ckpt\')\n'"
gan-script.py,60,"b'""""""\nThis is a straightforward Python implementation of a generative adversarial network.\nThe code is drawn directly from the O\'Reilly interactive tutorial on GANs\n(https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners).\n\nA version of this model with explanatory notes is also available on GitHub\nat https://github.com/jonbruner/generative-adversarial-networks.\n\nThis script requires TensorFlow and its dependencies in order to run. Please see\nthe readme for guidance on installing TensorFlow.\n\nThis script won\'t print summary statistics in the terminal during training;\ntrack progress and see sample images in TensorBoard.\n""""""\n\nimport tensorflow as tf\nimport numpy as np\nimport datetime\n\n# Load MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""MNIST_data/"")\n\n# Define the discriminator network\ndef discriminator(images, reuse_variables=None):\n    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n        # First convolutional and pool layers\n        # This finds 32 different 5 x 5 pixel features\n        d_w1 = tf.get_variable(\'d_w1\', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b1 = tf.get_variable(\'d_b1\', [32], initializer=tf.constant_initializer(0))\n        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding=\'SAME\')\n        d1 = d1 + d_b1\n        d1 = tf.nn.relu(d1)\n        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n        # Second convolutional and pool layers\n        # This finds 64 different 5 x 5 pixel features\n        d_w2 = tf.get_variable(\'d_w2\', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b2 = tf.get_variable(\'d_b2\', [64], initializer=tf.constant_initializer(0))\n        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding=\'SAME\')\n        d2 = d2 + d_b2\n        d2 = tf.nn.relu(d2)\n        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n        # First fully connected layer\n        d_w3 = tf.get_variable(\'d_w3\', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b3 = tf.get_variable(\'d_b3\', [1024], initializer=tf.constant_initializer(0))\n        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n        d3 = tf.matmul(d3, d_w3)\n        d3 = d3 + d_b3\n        d3 = tf.nn.relu(d3)\n\n        # Second fully connected layer\n        d_w4 = tf.get_variable(\'d_w4\', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n        d_b4 = tf.get_variable(\'d_b4\', [1], initializer=tf.constant_initializer(0))\n        d4 = tf.matmul(d3, d_w4) + d_b4\n\n        # d4 contains unscaled values\n        return d4\n\n# Define the generator network\ndef generator(z, batch_size, z_dim):\n    g_w1 = tf.get_variable(\'g_w1\', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b1 = tf.get_variable(\'g_b1\', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g1 = tf.matmul(z, g_w1) + g_b1\n    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope=\'g_b1\')\n    g1 = tf.nn.relu(g1)\n\n    # Generate 50 features\n    g_w2 = tf.get_variable(\'g_w2\', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b2 = tf.get_variable(\'g_b2\', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding=\'SAME\')\n    g2 = g2 + g_b2\n    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope=\'g_b2\')\n    g2 = tf.nn.relu(g2)\n    g2 = tf.image.resize_images(g2, [56, 56])\n\n    # Generate 25 features\n    g_w3 = tf.get_variable(\'g_w3\', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b3 = tf.get_variable(\'g_b3\', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding=\'SAME\')\n    g3 = g3 + g_b3\n    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope=\'g_b3\')\n    g3 = tf.nn.relu(g3)\n    g3 = tf.image.resize_images(g3, [56, 56])\n\n    # Final convolution with one output channel\n    g_w4 = tf.get_variable(\'g_w4\', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g_b4 = tf.get_variable(\'g_b4\', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding=\'SAME\')\n    g4 = g4 + g_b4\n    g4 = tf.sigmoid(g4)\n\n    # Dimensions of g4: batch_size x 28 x 28 x 1\n    return g4\n\nz_dimensions = 100\nbatch_size = 50\nz_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name=\'z_placeholder\')\n# z_placeholder is for feeding input noise to the generator\n\nx_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name=\'x_placeholder\')\n# x_placeholder is for feeding input images to the discriminator\n\nGz = generator(z_placeholder, batch_size, z_dimensions)\n# Gz holds the generated images\n\nDx = discriminator(x_placeholder)\n# Dx will hold discriminator prediction probabilities\n# for the real MNIST images\n\nDg = discriminator(Gz, reuse_variables=True)\n# Dg will hold discriminator prediction probabilities for generated images\n\n# Define losses\nd_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\nd_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\ng_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))\n\n# Define variable lists\ntvars = tf.trainable_variables()\nd_vars = [var for var in tvars if \'d_\' in var.name]\ng_vars = [var for var in tvars if \'g_\' in var.name]\n\n# Define the optimizers\n# Train the discriminator\nd_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\nd_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n\n# Train the generator\ng_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)\n\n# From this point forward, reuse variables\ntf.get_variable_scope().reuse_variables()\n\nsess = tf.Session()\n\n# Send summary statistics to TensorBoard\ntf.summary.scalar(\'Generator_loss\', g_loss)\ntf.summary.scalar(\'Discriminator_loss_real\', d_loss_real)\ntf.summary.scalar(\'Discriminator_loss_fake\', d_loss_fake)\n\nimages_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\ntf.summary.image(\'Generated_images\', images_for_tensorboard, 5)\nmerged = tf.summary.merge_all()\nlogdir = ""tensorboard/"" + datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"") + ""/""\nwriter = tf.summary.FileWriter(logdir, sess.graph)\n\nsess.run(tf.global_variables_initializer())\n\n# Pre-train discriminator\nfor i in range(300):\n    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n\n# Train generator and discriminator together\nfor i in range(100000):\n    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n\n    # Train discriminator on both real and fake images\n    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n\n    # Train generator\n    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n    _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n\n    if i % 10 == 0:\n        # Update TensorBoard with summary statistics\n        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n        summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n        writer.add_summary(summary, i)\n\n# Optionally, uncomment the following lines to update the checkpoint files attached to the tutorial.\n# saver = tf.train.Saver()\n# saver.save(sess, \'pretrained-model/pretrained_gan.ckpt\')\n'"
