file_path,api_count,code
setup.py,0,"b""from setuptools import setup\nfrom setuptools import find_packages\n\nlong_description = '''\nKeras is a high-level neural networks API,\nwritten in Python and capable of running on top of\nTensorFlow, CNTK, or Theano.\n\nUse Keras if you need a deep learning library that:\n\n- Allows for easy and fast prototyping\n  (through user friendliness, modularity, and extensibility).\n- Supports both convolutional networks and recurrent networks,\n  as well as combinations of the two.\n- Runs seamlessly on CPU and GPU.\n\nRead the documentation at: https://keras.io/\n\nFor a detailed overview of what makes Keras special, see:\nhttps://keras.io/why-use-keras/\n\nKeras is compatible with Python 2.7-3.6\nand is distributed under the MIT license.\n'''\n\nsetup(name='Keras',\n      version='2.3.1',\n      description='Deep Learning for humans',\n      long_description=long_description,\n      author='Francois Chollet',\n      author_email='francois.chollet@gmail.com',\n      url='https://github.com/keras-team/keras',\n      download_url='https://github.com/keras-team/keras/tarball/2.3.0',\n      license='MIT',\n      install_requires=['numpy>=1.9.1',\n                        'scipy>=0.14',\n                        'six>=1.9.0',\n                        'pyyaml',\n                        'h5py',\n                        'keras_applications>=1.0.6',\n                        'keras_preprocessing>=1.0.5'],\n      extras_require={\n          'visualize': ['pydot>=1.2.4'],\n          'tests': ['pytest',\n                    'pytest-pep8',\n                    'pytest-xdist',\n                    'flaky',\n                    'pytest-cov',\n                    'pandas',\n                    'requests',\n                    'markdown'],\n      },\n      classifiers=[\n          'Development Status :: 5 - Production/Stable',\n          'Intended Audience :: Developers',\n          'Intended Audience :: Education',\n          'Intended Audience :: Science/Research',\n          'License :: OSI Approved :: MIT License',\n          'Programming Language :: Python :: 2',\n          'Programming Language :: Python :: 2.7',\n          'Programming Language :: Python :: 3',\n          'Programming Language :: Python :: 3.6',\n          'Topic :: Software Development :: Libraries',\n          'Topic :: Software Development :: Libraries :: Python Modules'\n      ],\n      packages=find_packages())\n"""
update_api.py,0,"b""import pyux\nimport keras\nimport json\n\n\nimport keras.backend.tensorflow_backend\nimport keras.backend.theano_backend\nimport keras.backend.cntk_backend\nimport keras.backend.numpy_backend\nimport keras.utils.test_utils\n\nsign = pyux.sign(keras)\n\nwith open('api.json', 'w') as f:\n    json.dump(sign, f)\n"""
docs/__init__.py,0,b''
docs/autogen.py,0,"b'# -*- coding: utf-8 -*-\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport re\nimport inspect\nimport os\nimport shutil\nimport six\n\ntry:\n    import pathlib\nexcept ImportError:\n    import pathlib2 as pathlib\n\nimport keras\nfrom keras import backend as K\nfrom keras.backend import numpy_backend\n\nfrom docs.structure import EXCLUDE\nfrom docs.structure import PAGES\nfrom docs.structure import template_np_implementation\nfrom docs.structure import template_hidden_np_implementation\n\nimport sys\nif sys.version[0] == \'2\':\n    reload(sys)\n    sys.setdefaultencoding(\'utf8\')\n\nkeras_dir = pathlib.Path(__file__).resolve().parents[1]\n\n\ndef get_function_signature(function, method=True):\n    wrapped = getattr(function, \'_original_function\', None)\n    if wrapped is None:\n        signature = inspect.getfullargspec(function)\n    else:\n        signature = inspect.getfullargspec(wrapped)\n    defaults = signature.defaults\n    if method:\n        args = signature.args[1:]\n    else:\n        args = signature.args\n    if defaults:\n        kwargs = zip(args[-len(defaults):], defaults)\n        args = args[:-len(defaults)]\n    else:\n        kwargs = []\n    st = \'%s.%s(\' % (clean_module_name(function.__module__), function.__name__)\n\n    for a in args:\n        st += str(a) + \', \'\n    for a, v in kwargs:\n        if isinstance(v, str):\n            v = \'\\\'\' + v + \'\\\'\'\n        st += str(a) + \'=\' + str(v) + \', \'\n    if kwargs or args:\n        signature = st[:-2] + \')\'\n    else:\n        signature = st + \')\'\n    return post_process_signature(signature)\n\n\ndef get_class_signature(cls):\n    try:\n        class_signature = get_function_signature(cls.__init__)\n        class_signature = class_signature.replace(\'__init__\', cls.__name__)\n    except (TypeError, AttributeError):\n        # in case the class inherits from object and does not\n        # define __init__\n        class_signature = ""{clean_module_name}.{cls_name}()"".format(\n            clean_module_name=cls.__module__,\n            cls_name=cls.__name__\n        )\n    return post_process_signature(class_signature)\n\n\ndef post_process_signature(signature):\n    parts = re.split(r\'\\.(?!\\d)\', signature)\n    if len(parts) >= 4:\n        if parts[1] == \'layers\':\n            signature = \'keras.layers.\' + \'.\'.join(parts[3:])\n        if parts[1] == \'utils\':\n            signature = \'keras.utils.\' + \'.\'.join(parts[3:])\n        if parts[1] == \'backend\':\n            signature = \'keras.backend.\' + \'.\'.join(parts[3:])\n        if parts[1] == \'callbacks\':\n            signature = \'keras.callbacks.\' + \'.\'.join(parts[3:])\n    return signature\n\n\ndef clean_module_name(name):\n    if name.startswith(\'keras_applications\'):\n        name = name.replace(\'keras_applications\', \'keras.applications\')\n    if name.startswith(\'keras_preprocessing\'):\n        name = name.replace(\'keras_preprocessing\', \'keras.preprocessing\')\n    return name\n\n\ndef class_to_source_link(cls):\n    module_name = clean_module_name(cls.__module__)\n    path = module_name.replace(\'.\', \'/\')\n    path += \'.py\'\n    line = inspect.getsourcelines(cls)[-1]\n    link = (\'https://github.com/keras-team/\'\n            \'keras/blob/master/\' + path + \'#L\' + str(line))\n    return \'[[source]](\' + link + \')\'\n\n\ndef code_snippet(snippet):\n    result = \'```python\\n\'\n    result += snippet.encode(\'unicode_escape\').decode(\'utf8\') + \'\\n\'\n    result += \'```\\n\'\n    return result\n\n\ndef count_leading_spaces(s):\n    ws = re.search(r\'\\S\', s)\n    if ws:\n        return ws.start()\n    else:\n        return 0\n\n\ndef process_list_block(docstring, starting_point, section_end,\n                       leading_spaces, marker):\n    ending_point = docstring.find(\'\\n\\n\', starting_point)\n    block = docstring[starting_point:\n                      (ending_point - 1 if ending_point > -1\n                       else section_end)]\n    # Place marker for later reinjection.\n    docstring_slice = docstring[\n        starting_point:section_end].replace(block, marker)\n    docstring = (docstring[:starting_point] +\n                 docstring_slice +\n                 docstring[section_end:])\n    lines = block.split(\'\\n\')\n    # Remove the computed number of leading white spaces from each line.\n    lines = [re.sub(\'^\' + \' \' * leading_spaces, \'\', line) for line in lines]\n    # Usually lines have at least 4 additional leading spaces.\n    # These have to be removed, but first the list roots have to be detected.\n    top_level_regex = r\'^    ([^\\s\\\\\\(]+):(.*)\'\n    top_level_replacement = r\'- __\\1__:\\2\'\n    lines = [re.sub(top_level_regex, top_level_replacement, line)\n             for line in lines]\n    # All the other lines get simply the 4 leading space (if present) removed\n    lines = [re.sub(r\'^    \', \'\', line) for line in lines]\n    # Fix text lines after lists\n    indent = 0\n    text_block = False\n    for i in range(len(lines)):\n        line = lines[i]\n        spaces = re.search(r\'\\S\', line)\n        if spaces:\n            # If it is a list element\n            if line[spaces.start()] == \'-\':\n                indent = spaces.start() + 1\n                if text_block:\n                    text_block = False\n                    lines[i] = \'\\n\' + line\n            elif spaces.start() < indent:\n                text_block = True\n                indent = spaces.start()\n                lines[i] = \'\\n\' + line\n        else:\n            text_block = False\n            indent = 0\n    block = \'\\n\'.join(lines)\n    return docstring, block\n\n\ndef process_docstring(docstring):\n    # First, extract code blocks and process them.\n    code_blocks = []\n    if \'```\' in docstring:\n        tmp = docstring[:]\n        while \'```\' in tmp:\n            tmp = tmp[tmp.find(\'```\'):]\n            index = tmp[3:].find(\'```\') + 6\n            snippet = tmp[:index]\n            # Place marker in docstring for later reinjection.\n            docstring = docstring.replace(\n                snippet, \'$CODE_BLOCK_%d\' % len(code_blocks))\n            snippet_lines = snippet.split(\'\\n\')\n            # Remove leading spaces.\n            num_leading_spaces = snippet_lines[-1].find(\'`\')\n            snippet_lines = ([snippet_lines[0]] +\n                             [line[num_leading_spaces:]\n                             for line in snippet_lines[1:]])\n            # Most code snippets have 3 or 4 more leading spaces\n            # on inner lines, but not all. Remove them.\n            inner_lines = snippet_lines[1:-1]\n            leading_spaces = None\n            for line in inner_lines:\n                if not line or line[0] == \'\\n\':\n                    continue\n                spaces = count_leading_spaces(line)\n                if leading_spaces is None:\n                    leading_spaces = spaces\n                if spaces < leading_spaces:\n                    leading_spaces = spaces\n            if leading_spaces:\n                snippet_lines = ([snippet_lines[0]] +\n                                 [line[leading_spaces:]\n                                  for line in snippet_lines[1:-1]] +\n                                 [snippet_lines[-1]])\n            snippet = \'\\n\'.join(snippet_lines)\n            code_blocks.append(snippet)\n            tmp = tmp[index:]\n\n    # Format docstring lists.\n    section_regex = r\'\\n( +)# (.*)\\n\'\n    section_idx = re.search(section_regex, docstring)\n    shift = 0\n    sections = {}\n    while section_idx and section_idx.group(2):\n        anchor = section_idx.group(2)\n        leading_spaces = len(section_idx.group(1))\n        shift += section_idx.end()\n        next_section_idx = re.search(section_regex, docstring[shift:])\n        if next_section_idx is None:\n            section_end = -1\n        else:\n            section_end = shift + next_section_idx.start()\n        marker = \'$\' + anchor.replace(\' \', \'_\') + \'$\'\n        docstring, content = process_list_block(docstring,\n                                                shift,\n                                                section_end,\n                                                leading_spaces,\n                                                marker)\n        sections[marker] = content\n        # `docstring` has changed, so we can\'t use `next_section_idx` anymore\n        # we have to recompute it\n        section_idx = re.search(section_regex, docstring[shift:])\n\n    # Format docstring section titles.\n    docstring = re.sub(r\'\\n(\\s+)# (.*)\\n\',\n                       r\'\\n\\1__\\2__\\n\\n\',\n                       docstring)\n\n    # Strip all remaining leading spaces.\n    lines = docstring.split(\'\\n\')\n    docstring = \'\\n\'.join([line.lstrip(\' \') for line in lines])\n\n    # Reinject list blocks.\n    for marker, content in sections.items():\n        docstring = docstring.replace(marker, content)\n\n    # Reinject code blocks.\n    for i, code_block in enumerate(code_blocks):\n        docstring = docstring.replace(\n            \'$CODE_BLOCK_%d\' % i, code_block)\n    return docstring\n\n\ndef add_np_implementation(function, docstring):\n    np_implementation = getattr(numpy_backend, function.__name__)\n    code = inspect.getsource(np_implementation)\n    code_lines = code.split(\'\\n\')\n    for i in range(len(code_lines)):\n        if code_lines[i]:\n            # if there is something on the line, add 8 spaces.\n            code_lines[i] = \'        \' + code_lines[i]\n    code = \'\\n\'.join(code_lines[:-1])\n\n    if len(code_lines) < 10:\n        section = template_np_implementation.replace(\'{{code}}\', code)\n    else:\n        section = template_hidden_np_implementation.replace(\'{{code}}\', code)\n    return docstring.replace(\'{{np_implementation}}\', section)\n\n\ndef read_file(path):\n    with open(path, encoding=\'utf-8\') as f:\n        return f.read()\n\n\ndef collect_class_methods(cls, methods):\n    if isinstance(methods, (list, tuple)):\n        return [getattr(cls, m) if isinstance(m, str) else m for m in methods]\n    methods = []\n    for _, method in inspect.getmembers(cls, predicate=inspect.isroutine):\n        if method.__name__[0] == \'_\' or method.__name__ in EXCLUDE:\n            continue\n        methods.append(method)\n    return methods\n\n\ndef render_function(function, method=True):\n    subblocks = []\n    signature = get_function_signature(function, method=method)\n    if method:\n        signature = signature.replace(\n            clean_module_name(function.__module__) + \'.\', \'\')\n    subblocks.append(\'### \' + function.__name__ + \'\\n\')\n    subblocks.append(code_snippet(signature))\n    docstring = function.__doc__\n    if docstring:\n        if (\'backend\' in signature and\n                \'{{np_implementation}}\' in docstring):\n            docstring = add_np_implementation(function, docstring)\n        subblocks.append(process_docstring(docstring))\n    return \'\\n\\n\'.join(subblocks)\n\n\ndef read_page_data(page_data, type):\n    assert type in [\'classes\', \'functions\', \'methods\']\n    data = page_data.get(type, [])\n    for module in page_data.get(\'all_module_{}\'.format(type), []):\n        module_data = []\n        for name in dir(module):\n            if name[0] == \'_\' or name in EXCLUDE:\n                continue\n            module_member = getattr(module, name)\n            if (inspect.isclass(module_member) and type == \'classes\' or\n               inspect.isfunction(module_member) and type == \'functions\'):\n                instance = module_member\n                if module.__name__ in instance.__module__:\n                    if instance not in module_data:\n                        module_data.append(instance)\n        module_data.sort(key=lambda x: id(x))\n        data += module_data\n    return data\n\n\ndef get_module_docstring(filepath):\n    """"""Extract the module docstring.\n\n    Also finds the line at which the docstring ends.\n    """"""\n    co = compile(open(filepath, encoding=\'utf-8\').read(), filepath, \'exec\')\n    if co.co_consts and isinstance(co.co_consts[0], six.string_types):\n        docstring = co.co_consts[0]\n    else:\n        print(\'Could not get the docstring from \' + filepath)\n        docstring = \'\'\n    return docstring, co.co_firstlineno\n\n\ndef copy_examples(examples_dir, destination_dir):\n    """"""Copy the examples directory in the documentation.\n\n    Prettify files by extracting the docstrings written in Markdown.\n    """"""\n    pathlib.Path(destination_dir).mkdir(exist_ok=True)\n    for file in os.listdir(examples_dir):\n        if not file.endswith(\'.py\'):\n            continue\n        module_path = os.path.join(examples_dir, file)\n        docstring, starting_line = get_module_docstring(module_path)\n        destination_file = os.path.join(destination_dir, file[:-2] + \'md\')\n        with open(destination_file, \'w+\', encoding=\'utf-8\') as f_out, \\\n                open(os.path.join(examples_dir, file),\n                     \'r+\', encoding=\'utf-8\') as f_in:\n\n            f_out.write(docstring + \'\\n\\n\')\n\n            # skip docstring\n            for _ in range(starting_line):\n                next(f_in)\n\n            f_out.write(\'```python\\n\')\n            # next line might be empty.\n            line = next(f_in)\n            if line != \'\\n\':\n                f_out.write(line)\n\n            # copy the rest of the file.\n            for line in f_in:\n                f_out.write(line)\n            f_out.write(\'```\')\n\n\ndef generate(sources_dir):\n    """"""Generates the markdown files for the documentation.\n\n    # Arguments\n        sources_dir: Where to put the markdown files.\n    """"""\n    template_dir = os.path.join(str(keras_dir), \'docs\', \'templates\')\n\n    if K.backend() != \'tensorflow\':\n        raise RuntimeError(\'The documentation must be built \'\n                           \'with the TensorFlow backend because this \'\n                           \'is the only backend with docstrings.\')\n\n    print(\'Cleaning up existing sources directory.\')\n    if os.path.exists(sources_dir):\n        shutil.rmtree(sources_dir)\n\n    print(\'Populating sources directory with templates.\')\n    shutil.copytree(template_dir, sources_dir)\n\n    readme = read_file(os.path.join(str(keras_dir), \'README.md\'))\n    index = read_file(os.path.join(template_dir, \'index.md\'))\n    index = index.replace(\'{{autogenerated}}\', readme[readme.find(\'##\'):])\n    with open(os.path.join(sources_dir, \'index.md\'), \'w\', encoding=\'utf-8\') as f:\n        f.write(index)\n\n    print(\'Generating docs for Keras %s.\' % keras.__version__)\n    for page_data in PAGES:\n        classes = read_page_data(page_data, \'classes\')\n\n        blocks = []\n        for element in classes:\n            if not isinstance(element, (list, tuple)):\n                element = (element, [])\n            cls = element[0]\n            subblocks = []\n            signature = get_class_signature(cls)\n            subblocks.append(\'<span style=""float:right;"">\' +\n                             class_to_source_link(cls) + \'</span>\')\n            if element[1]:\n                subblocks.append(\'## \' + cls.__name__ + \' class\\n\')\n            else:\n                subblocks.append(\'### \' + cls.__name__ + \'\\n\')\n            subblocks.append(code_snippet(signature))\n            docstring = cls.__doc__\n            if docstring:\n                subblocks.append(process_docstring(docstring))\n            methods = collect_class_methods(cls, element[1])\n            if methods:\n                subblocks.append(\'\\n---\')\n                subblocks.append(\'## \' + cls.__name__ + \' methods\\n\')\n                subblocks.append(\'\\n---\\n\'.join(\n                    [render_function(method, method=True)\n                     for method in methods]))\n            blocks.append(\'\\n\'.join(subblocks))\n\n        methods = read_page_data(page_data, \'methods\')\n\n        for method in methods:\n            blocks.append(render_function(method, method=True))\n\n        functions = read_page_data(page_data, \'functions\')\n\n        for function in functions:\n            blocks.append(render_function(function, method=False))\n\n        if not blocks:\n            raise RuntimeError(\'Found no content for page \' +\n                               page_data[\'page\'])\n\n        mkdown = \'\\n----\\n\\n\'.join(blocks)\n        # Save module page.\n        # Either insert content into existing page,\n        # or create page otherwise.\n        page_name = page_data[\'page\']\n        path = os.path.join(sources_dir, page_name)\n        if os.path.exists(path):\n            template = read_file(path)\n            if \'{{autogenerated}}\' not in template:\n                raise RuntimeError(\'Template found for \' + path +\n                                   \' but missing {{autogenerated}}\'\n                                   \' tag.\')\n            mkdown = template.replace(\'{{autogenerated}}\', mkdown)\n            print(\'...inserting autogenerated content into template:\', path)\n        else:\n            print(\'...creating new page with autogenerated content:\', path)\n        subdir = os.path.dirname(path)\n        if not os.path.exists(subdir):\n            os.makedirs(subdir)\n        with open(path, \'w\', encoding=\'utf-8\') as f:\n            f.write(mkdown)\n\n    shutil.copyfile(os.path.join(str(keras_dir), \'CONTRIBUTING.md\'),\n                    os.path.join(str(sources_dir), \'contributing.md\'))\n    copy_examples(os.path.join(str(keras_dir), \'examples\'),\n                  os.path.join(str(sources_dir), \'examples\'))\n\n\nif __name__ == \'__main__\':\n    generate(os.path.join(str(keras_dir), \'docs\', \'sources\'))\n'"
docs/structure.py,0,"b'# -*- coding: utf-8 -*-\r\n\'\'\'\r\nGeneral documentation architecture:\r\n\r\nHome\r\nIndex\r\n\r\n- Getting started\r\n    Getting started with the sequential model\r\n    Getting started with the functional api\r\n    FAQ\r\n\r\n- Models\r\n    About Keras models\r\n        explain when one should use Sequential or functional API\r\n        explain compilation step\r\n        explain weight saving, weight loading\r\n        explain serialization, deserialization\r\n    Sequential\r\n    Model (functional API)\r\n\r\n- Layers\r\n    About Keras layers\r\n        explain common layer functions: get_weights, set_weights, get_config\r\n        explain input_shape\r\n        explain usage on non-Keras tensors\r\n    Core Layers\r\n    Convolutional Layers\r\n    Pooling Layers\r\n    Locally-connected Layers\r\n    Recurrent Layers\r\n    Embedding Layers\r\n    Merge Layers\r\n    Advanced Activations Layers\r\n    Normalization Layers\r\n    Noise Layers\r\n    Layer Wrappers\r\n    Writing your own Keras layers\r\n\r\n- Preprocessing\r\n    Sequence Preprocessing\r\n    Text Preprocessing\r\n    Image Preprocessing\r\n\r\nLosses\r\nMetrics\r\nOptimizers\r\nActivations\r\nCallbacks\r\nDatasets\r\nApplications\r\nBackend\r\nInitializers\r\nRegularizers\r\nConstraints\r\nVisualization\r\nScikit-learn API\r\nUtils\r\nContributing\r\n\r\n\'\'\'\r\nfrom keras import utils\r\nfrom keras import layers\r\nfrom keras.layers import advanced_activations\r\nfrom keras.layers import noise\r\nfrom keras.layers import wrappers\r\nfrom keras import initializers\r\nfrom keras import optimizers\r\nfrom keras import callbacks\r\nfrom keras import models\r\nfrom keras import losses\r\nfrom keras import metrics\r\nfrom keras import backend\r\nfrom keras import constraints\r\nfrom keras import activations\r\nfrom keras import preprocessing\r\n\r\n\r\nEXCLUDE = {\r\n    \'Optimizer\',\r\n    \'TFOptimizer\',\r\n    \'Wrapper\',\r\n    \'get_session\',\r\n    \'set_session\',\r\n    \'CallbackList\',\r\n    \'serialize\',\r\n    \'deserialize\',\r\n    \'get\',\r\n    \'set_image_dim_ordering\',\r\n    \'normalize_data_format\',\r\n    \'image_dim_ordering\',\r\n    \'get_variable_shape\',\r\n    \'Constraint\'\r\n}\r\n\r\n# For each class to document, it is possible to:\r\n# 1) Document only the class: [classA, classB, ...]\r\n# 2) Document all its methods: [classA, (classB, ""*"")]\r\n# 3) Choose which methods to document (methods listed as strings):\r\n# [classA, (classB, [""method1"", ""method2"", ...]), ...]\r\n# 4) Choose which methods to document (methods listed as qualified names):\r\n# [classA, (classB, [module.classB.method1, module.classB.method2, ...]), ...]\r\nPAGES = [\r\n    {\r\n        \'page\': \'models/sequential.md\',\r\n        \'methods\': [\r\n            models.Sequential.compile,\r\n            models.Sequential.fit,\r\n            models.Sequential.evaluate,\r\n            models.Sequential.predict,\r\n            models.Sequential.train_on_batch,\r\n            models.Sequential.test_on_batch,\r\n            models.Sequential.predict_on_batch,\r\n            models.Sequential.fit_generator,\r\n            models.Sequential.evaluate_generator,\r\n            models.Sequential.predict_generator,\r\n            models.Sequential.get_layer,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'models/model.md\',\r\n        \'methods\': [\r\n            models.Model.compile,\r\n            models.Model.fit,\r\n            models.Model.evaluate,\r\n            models.Model.predict,\r\n            models.Model.train_on_batch,\r\n            models.Model.test_on_batch,\r\n            models.Model.predict_on_batch,\r\n            models.Model.fit_generator,\r\n            models.Model.evaluate_generator,\r\n            models.Model.predict_generator,\r\n            models.Model.get_layer,\r\n        ]\r\n    },\r\n    {\r\n        \'page\': \'layers/core.md\',\r\n        \'classes\': [\r\n            layers.Dense,\r\n            layers.Activation,\r\n            layers.Dropout,\r\n            layers.Flatten,\r\n            layers.Input,\r\n            layers.Reshape,\r\n            layers.Permute,\r\n            layers.RepeatVector,\r\n            layers.Lambda,\r\n            layers.ActivityRegularization,\r\n            layers.Masking,\r\n            layers.SpatialDropout1D,\r\n            layers.SpatialDropout2D,\r\n            layers.SpatialDropout3D,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/convolutional.md\',\r\n        \'classes\': [\r\n            layers.Conv1D,\r\n            layers.Conv2D,\r\n            layers.SeparableConv1D,\r\n            layers.SeparableConv2D,\r\n            layers.DepthwiseConv2D,\r\n            layers.Conv2DTranspose,\r\n            layers.Conv3D,\r\n            layers.Conv3DTranspose,\r\n            layers.Cropping1D,\r\n            layers.Cropping2D,\r\n            layers.Cropping3D,\r\n            layers.UpSampling1D,\r\n            layers.UpSampling2D,\r\n            layers.UpSampling3D,\r\n            layers.ZeroPadding1D,\r\n            layers.ZeroPadding2D,\r\n            layers.ZeroPadding3D,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/pooling.md\',\r\n        \'classes\': [\r\n            layers.MaxPooling1D,\r\n            layers.MaxPooling2D,\r\n            layers.MaxPooling3D,\r\n            layers.AveragePooling1D,\r\n            layers.AveragePooling2D,\r\n            layers.AveragePooling3D,\r\n            layers.GlobalMaxPooling1D,\r\n            layers.GlobalAveragePooling1D,\r\n            layers.GlobalMaxPooling2D,\r\n            layers.GlobalAveragePooling2D,\r\n            layers.GlobalMaxPooling3D,\r\n            layers.GlobalAveragePooling3D,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/local.md\',\r\n        \'classes\': [\r\n            layers.LocallyConnected1D,\r\n            layers.LocallyConnected2D,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/recurrent.md\',\r\n        \'classes\': [\r\n            layers.RNN,\r\n            layers.SimpleRNN,\r\n            layers.GRU,\r\n            layers.LSTM,\r\n            layers.ConvLSTM2D,\r\n            layers.ConvLSTM2DCell,\r\n            layers.SimpleRNNCell,\r\n            layers.GRUCell,\r\n            layers.LSTMCell,\r\n            layers.CuDNNGRU,\r\n            layers.CuDNNLSTM,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/embeddings.md\',\r\n        \'classes\': [\r\n            layers.Embedding,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/normalization.md\',\r\n        \'classes\': [\r\n            layers.BatchNormalization,\r\n        ],\r\n    },\r\n    {\r\n        \'page\': \'layers/advanced-activations.md\',\r\n        \'all_module_classes\': [advanced_activations],\r\n    },\r\n    {\r\n        \'page\': \'layers/noise.md\',\r\n        \'all_module_classes\': [noise],\r\n    },\r\n    {\r\n        \'page\': \'layers/merge.md\',\r\n        \'classes\': [\r\n            layers.Add,\r\n            layers.Subtract,\r\n            layers.Multiply,\r\n            layers.Average,\r\n            layers.Maximum,\r\n            layers.Minimum,\r\n            layers.Concatenate,\r\n            layers.Dot,\r\n        ],\r\n        \'functions\': [\r\n            layers.add,\r\n            layers.subtract,\r\n            layers.multiply,\r\n            layers.average,\r\n            layers.maximum,\r\n            layers.minimum,\r\n            layers.concatenate,\r\n            layers.dot,\r\n        ]\r\n    },\r\n    {\r\n        \'page\': \'preprocessing/sequence.md\',\r\n        \'functions\': [\r\n            preprocessing.sequence.pad_sequences,\r\n            preprocessing.sequence.skipgrams,\r\n            preprocessing.sequence.make_sampling_table,\r\n        ],\r\n        \'classes\': [\r\n            preprocessing.sequence.TimeseriesGenerator,\r\n        ]\r\n    },\r\n    {\r\n        \'page\': \'preprocessing/image.md\',\r\n        \'classes\': [\r\n            (preprocessing.image.ImageDataGenerator, \'*\')\r\n        ]\r\n    },\r\n    {\r\n        \'page\': \'preprocessing/text.md\',\r\n        \'functions\': [\r\n            preprocessing.text.hashing_trick,\r\n            preprocessing.text.one_hot,\r\n            preprocessing.text.text_to_word_sequence,\r\n        ],\r\n        \'classes\': [\r\n            preprocessing.text.Tokenizer,\r\n        ]\r\n    },\r\n    {\r\n        \'page\': \'layers/wrappers.md\',\r\n        \'all_module_classes\': [wrappers],\r\n    },\r\n    {\r\n        \'page\': \'metrics.md\',\r\n        \'all_module_functions\': [metrics],\r\n    },\r\n    {\r\n        \'page\': \'losses.md\',\r\n        \'all_module_functions\': [losses],\r\n    },\r\n    {\r\n        \'page\': \'initializers.md\',\r\n        \'all_module_functions\': [initializers],\r\n        \'all_module_classes\': [initializers],\r\n    },\r\n    {\r\n        \'page\': \'optimizers.md\',\r\n        \'all_module_classes\': [optimizers],\r\n    },\r\n    {\r\n        \'page\': \'callbacks.md\',\r\n        \'all_module_classes\': [callbacks],\r\n    },\r\n    {\r\n        \'page\': \'activations.md\',\r\n        \'all_module_functions\': [activations],\r\n    },\r\n    {\r\n        \'page\': \'backend.md\',\r\n        \'all_module_functions\': [backend],\r\n    },\r\n    {\r\n        \'page\': \'constraints.md\',\r\n        \'all_module_classes\': [constraints],\r\n    },\r\n    {\r\n        \'page\': \'utils.md\',\r\n        \'functions\': [utils.to_categorical,\r\n                      utils.normalize,\r\n                      utils.get_file,\r\n                      utils.print_summary,\r\n                      utils.plot_model,\r\n                      utils.multi_gpu_model],\r\n        \'classes\': [utils.CustomObjectScope,\r\n                    utils.HDF5Matrix,\r\n                    utils.Sequence],\r\n    },\r\n]\r\n\r\nROOT = \'http://keras.io/\'\r\n\r\ntemplate_np_implementation = """"""# Numpy implementation\r\n\r\n    ```python\r\n{{code}}\r\n    ```\r\n""""""\r\n\r\ntemplate_hidden_np_implementation = """"""# Numpy implementation\r\n\r\n    <details>\r\n    <summary>Show the Numpy implementation</summary>\r\n\r\n    ```python\r\n{{code}}\r\n    ```\r\n\r\n    </details>\r\n""""""\r\n'"
examples/addition_rnn.py,0,"b'# -*- coding: utf-8 -*-\n\'\'\'\n# An implementation of sequence to sequence learning for performing addition\n\nInput: ""535+61""\nOutput: ""596""\nPadding is handled by using a repeated sentinel character (space)\n\nInput may optionally be reversed, shown to increase performance in many tasks in:\n""Learning to Execute""\nhttp://arxiv.org/abs/1410.4615\nand\n""Sequence to Sequence Learning with Neural Networks""\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\nTheoretically it introduces shorter term dependencies between source and target.\n\nTwo digits reversed:\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n\nThree digits reversed:\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n\nFour digits reversed:\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n\nFive digits reversed:\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n\'\'\'  # noqa\n\nfrom __future__ import print_function\nfrom keras.models import Sequential\nfrom keras import layers\nimport numpy as np\nfrom six.moves import range\n\n\nclass CharacterTable(object):\n    """"""Given a set of characters:\n    + Encode them to a one-hot integer representation\n    + Decode the one-hot or integer representation to their character output\n    + Decode a vector of probabilities to their character output\n    """"""\n    def __init__(self, chars):\n        """"""Initialize character table.\n\n        # Arguments\n            chars: Characters that can appear in the input.\n        """"""\n        self.chars = sorted(set(chars))\n        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n\n    def encode(self, C, num_rows):\n        """"""One-hot encode given string C.\n\n        # Arguments\n            C: string, to be encoded.\n            num_rows: Number of rows in the returned one-hot encoding. This is\n                used to keep the # of rows for each data the same.\n        """"""\n        x = np.zeros((num_rows, len(self.chars)))\n        for i, c in enumerate(C):\n            x[i, self.char_indices[c]] = 1\n        return x\n\n    def decode(self, x, calc_argmax=True):\n        """"""Decode the given vector or 2D array to their character output.\n\n        # Arguments\n            x: A vector or a 2D array of probabilities or one-hot representations;\n                or a vector of character indices (used with `calc_argmax=False`).\n            calc_argmax: Whether to find the character index with maximum\n                probability, defaults to `True`.\n        """"""\n        if calc_argmax:\n            x = x.argmax(axis=-1)\n        return \'\'.join(self.indices_char[x] for x in x)\n\n\nclass colors:\n    ok = \'\\033[92m\'\n    fail = \'\\033[91m\'\n    close = \'\\033[0m\'\n\n# Parameters for the model and dataset.\nTRAINING_SIZE = 50000\nDIGITS = 3\nREVERSE = True\n\n# Maximum length of input is \'int + int\' (e.g., \'345+678\'). Maximum length of\n# int is DIGITS.\nMAXLEN = DIGITS + 1 + DIGITS\n\n# All the numbers, plus sign and space for padding.\nchars = \'0123456789+ \'\nctable = CharacterTable(chars)\n\nquestions = []\nexpected = []\nseen = set()\nprint(\'Generating data...\')\nwhile len(questions) < TRAINING_SIZE:\n    f = lambda: int(\'\'.join(np.random.choice(list(\'0123456789\'))\n                    for i in range(np.random.randint(1, DIGITS + 1))))\n    a, b = f(), f()\n    # Skip any addition questions we\'ve already seen\n    # Also skip any such that x+Y == Y+x (hence the sorting).\n    key = tuple(sorted((a, b)))\n    if key in seen:\n        continue\n    seen.add(key)\n    # Pad the data with spaces such that it is always MAXLEN.\n    q = \'{}+{}\'.format(a, b)\n    query = q + \' \' * (MAXLEN - len(q))\n    ans = str(a + b)\n    # Answers can be of maximum size DIGITS + 1.\n    ans += \' \' * (DIGITS + 1 - len(ans))\n    if REVERSE:\n        # Reverse the query, e.g., \'12+345  \' becomes \'  543+21\'. (Note the\n        # space used for padding.)\n        query = query[::-1]\n    questions.append(query)\n    expected.append(ans)\nprint(\'Total addition questions:\', len(questions))\n\nprint(\'Vectorization...\')\nx = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\ny = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(questions):\n    x[i] = ctable.encode(sentence, MAXLEN)\nfor i, sentence in enumerate(expected):\n    y[i] = ctable.encode(sentence, DIGITS + 1)\n\n# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n# digits.\nindices = np.arange(len(y))\nnp.random.shuffle(indices)\nx = x[indices]\ny = y[indices]\n\n# Explicitly set apart 10% for validation data that we never train over.\nsplit_at = len(x) - len(x) // 10\n(x_train, x_val) = x[:split_at], x[split_at:]\n(y_train, y_val) = y[:split_at], y[split_at:]\n\nprint(\'Training Data:\')\nprint(x_train.shape)\nprint(y_train.shape)\n\nprint(\'Validation Data:\')\nprint(x_val.shape)\nprint(y_val.shape)\n\n# Try replacing GRU, or SimpleRNN.\nRNN = layers.LSTM\nHIDDEN_SIZE = 128\nBATCH_SIZE = 128\nLAYERS = 1\n\nprint(\'Build model...\')\nmodel = Sequential()\n# ""Encode"" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n# Note: In a situation where your input sequences have a variable length,\n# use input_shape=(None, num_feature).\nmodel.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n# As the decoder RNN\'s input, repeatedly provide with the last output of\n# RNN for each time step. Repeat \'DIGITS + 1\' times as that\'s the maximum\n# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\nmodel.add(layers.RepeatVector(DIGITS + 1))\n# The decoder RNN could be multiple layers stacked or a single layer.\nfor _ in range(LAYERS):\n    # By setting return_sequences to True, return not only the last output but\n    # all the outputs so far in the form of (num_samples, timesteps,\n    # output_dim). This is necessary as TimeDistributed in the below expects\n    # the first dimension to be the timesteps.\n    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n\n# Apply a dense layer to the every temporal slice of an input. For each of step\n# of the output sequence, decide which character should be chosen.\nmodel.add(layers.TimeDistributed(layers.Dense(len(chars), activation=\'softmax\')))\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\nmodel.summary()\n\n# Train the model each generation and show predictions against the validation\n# dataset.\nfor iteration in range(1, 200):\n    print()\n    print(\'-\' * 50)\n    print(\'Iteration\', iteration)\n    model.fit(x_train, y_train,\n              batch_size=BATCH_SIZE,\n              epochs=1,\n              validation_data=(x_val, y_val))\n    # Select 10 samples from the validation set at random so we can visualize\n    # errors.\n    for i in range(10):\n        ind = np.random.randint(0, len(x_val))\n        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n        preds = model.predict_classes(rowx, verbose=0)\n        q = ctable.decode(rowx[0])\n        correct = ctable.decode(rowy[0])\n        guess = ctable.decode(preds[0], calc_argmax=False)\n        print(\'Q\', q[::-1] if REVERSE else q, end=\' \')\n        print(\'T\', correct, end=\' \')\n        if correct == guess:\n            print(colors.ok + \'\xe2\x98\x91\' + colors.close, end=\' \')\n        else:\n            print(colors.fail + \'\xe2\x98\x92\' + colors.close, end=\' \')\n        print(guess)\n'"
examples/antirectifier.py,0,"b""'''\n#This example demonstrates how to write custom layers for Keras.\n\nWe build a custom activation layer called 'Antirectifier',\nwhich modifies the shape of the tensor that passes through it.\nWe need to specify two methods: `compute_output_shape` and `call`.\n\nNote that the same result can also be achieved via a Lambda layer.\n\nBecause our custom layer is written with primitives from the Keras\nbackend (`K`), our code can run both on TensorFlow and Theano.\n'''\n\nfrom __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.datasets import mnist\nfrom keras import backend as K\n\n\nclass Antirectifier(layers.Layer):\n    '''This is the combination of a sample-wise\n    L2 normalization with the concatenation of the\n    positive part of the input with the negative part\n    of the input. The result is a tensor of samples that are\n    twice as large as the input samples.\n\n    It can be used in place of a ReLU.\n\n    # Input shape\n        2D tensor of shape (samples, n)\n\n    # Output shape\n        2D tensor of shape (samples, 2*n)\n\n    # Theoretical justification\n        When applying ReLU, assuming that the distribution\n        of the previous output is approximately centered around 0.,\n        you are discarding half of your input. This is inefficient.\n\n        Antirectifier allows to return all-positive outputs like ReLU,\n        without discarding any data.\n\n        Tests on MNIST show that Antirectifier allows to train networks\n        with twice less parameters yet with comparable\n        classification accuracy as an equivalent ReLU-based network.\n    '''\n\n    def compute_output_shape(self, input_shape):\n        shape = list(input_shape)\n        assert len(shape) == 2  # only valid for 2D tensors\n        shape[-1] *= 2\n        return tuple(shape)\n\n    def call(self, inputs):\n        inputs -= K.mean(inputs, axis=1, keepdims=True)\n        inputs = K.l2_normalize(inputs, axis=1)\n        pos = K.relu(inputs)\n        neg = K.relu(-inputs)\n        return K.concatenate([pos, neg], axis=1)\n\n# global parameters\nbatch_size = 128\nnum_classes = 10\nepochs = 40\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n# build the model\nmodel = Sequential()\nmodel.add(layers.Dense(256, input_shape=(784,)))\nmodel.add(Antirectifier())\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(256))\nmodel.add(Antirectifier())\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(num_classes))\nmodel.add(layers.Activation('softmax'))\n\n# compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# train the model\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n# next, compare with an equivalent network\n# with2x bigger Dense layers and ReLU\n"""
examples/babi_memnn.py,0,"b'\'\'\'\n#Trains a memory network on the bAbI dataset.\n\nReferences:\n\n- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n  [""Towards AI-Complete Question Answering:\n  A Set of Prerequisite Toy Tasks""](http://arxiv.org/abs/1502.05698)\n\n- Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n  [""End-To-End Memory Networks""](http://arxiv.org/abs/1503.08895)\n\nReaches 98.6% accuracy on task \'single_supporting_fact_10k\' after 120 epochs.\nTime per epoch: 3s on CPU (core i7).\n\'\'\'\nfrom __future__ import print_function\n\nfrom keras.models import Sequential, Model\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Input, Activation, Dense, Permute, Dropout\nfrom keras.layers import add, dot, concatenate\nfrom keras.layers import LSTM\nfrom keras.utils.data_utils import get_file\nfrom keras.preprocessing.sequence import pad_sequences\nfrom functools import reduce\nimport tarfile\nimport numpy as np\nimport re\n\n\ndef tokenize(sent):\n    \'\'\'Return the tokens of a sentence including punctuation.\n\n    >>> tokenize(\'Bob dropped the apple. Where is the apple?\')\n    [\'Bob\', \'dropped\', \'the\', \'apple\', \'.\', \'Where\', \'is\', \'the\', \'apple\', \'?\']\n    \'\'\'\n    return [x.strip() for x in re.split(r\'(\\W+)?\', sent) if x.strip()]\n\n\ndef parse_stories(lines, only_supporting=False):\n    \'\'\'Parse stories provided in the bAbi tasks format\n\n    If only_supporting is true, only the sentences\n    that support the answer are kept.\n    \'\'\'\n    data = []\n    story = []\n    for line in lines:\n        line = line.decode(\'utf-8\').strip()\n        nid, line = line.split(\' \', 1)\n        nid = int(nid)\n        if nid == 1:\n            story = []\n        if \'\\t\' in line:\n            q, a, supporting = line.split(\'\\t\')\n            q = tokenize(q)\n            if only_supporting:\n                # Only select the related substory\n                supporting = map(int, supporting.split())\n                substory = [story[i - 1] for i in supporting]\n            else:\n                # Provide all the substories\n                substory = [x for x in story if x]\n            data.append((substory, q, a))\n            story.append(\'\')\n        else:\n            sent = tokenize(line)\n            story.append(sent)\n    return data\n\n\ndef get_stories(f, only_supporting=False, max_length=None):\n    \'\'\'Given a file name, read the file,\n    retrieve the stories,\n    and then convert the sentences into a single story.\n\n    If max_length is supplied,\n    any stories longer than max_length tokens will be discarded.\n    \'\'\'\n    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n    flatten = lambda data: reduce(lambda x, y: x + y, data)\n    data = [(flatten(story), q, answer) for story, q, answer in data\n            if not max_length or len(flatten(story)) < max_length]\n    return data\n\n\ndef vectorize_stories(data):\n    inputs, queries, answers = [], [], []\n    for story, query, answer in data:\n        inputs.append([word_idx[w] for w in story])\n        queries.append([word_idx[w] for w in query])\n        answers.append(word_idx[answer])\n    return (pad_sequences(inputs, maxlen=story_maxlen),\n            pad_sequences(queries, maxlen=query_maxlen),\n            np.array(answers))\n\ntry:\n    path = get_file(\'babi-tasks-v1-2.tar.gz\',\n                    origin=\'https://s3.amazonaws.com/text-datasets/\'\n                           \'babi_tasks_1-20_v1-2.tar.gz\')\nexcept:\n    print(\'Error downloading dataset, please download it manually:\\n\'\n          \'$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2\'\n          \'.tar.gz\\n\'\n          \'$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz\')\n    raise\n\n\nchallenges = {\n    # QA1 with 10,000 samples\n    \'single_supporting_fact_10k\': \'tasks_1-20_v1-2/en-10k/qa1_\'\n                                  \'single-supporting-fact_{}.txt\',\n    # QA2 with 10,000 samples\n    \'two_supporting_facts_10k\': \'tasks_1-20_v1-2/en-10k/qa2_\'\n                                \'two-supporting-facts_{}.txt\',\n}\nchallenge_type = \'single_supporting_fact_10k\'\nchallenge = challenges[challenge_type]\n\nprint(\'Extracting stories for the challenge:\', challenge_type)\nwith tarfile.open(path) as tar:\n    train_stories = get_stories(tar.extractfile(challenge.format(\'train\')))\n    test_stories = get_stories(tar.extractfile(challenge.format(\'test\')))\n\nvocab = set()\nfor story, q, answer in train_stories + test_stories:\n    vocab |= set(story + q + [answer])\nvocab = sorted(vocab)\n\n# Reserve 0 for masking via pad_sequences\nvocab_size = len(vocab) + 1\nstory_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\nquery_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n\nprint(\'-\')\nprint(\'Vocab size:\', vocab_size, \'unique words\')\nprint(\'Story max length:\', story_maxlen, \'words\')\nprint(\'Query max length:\', query_maxlen, \'words\')\nprint(\'Number of training stories:\', len(train_stories))\nprint(\'Number of test stories:\', len(test_stories))\nprint(\'-\')\nprint(\'Here\\\'s what a ""story"" tuple looks like (input, query, answer):\')\nprint(train_stories[0])\nprint(\'-\')\nprint(\'Vectorizing the word sequences...\')\n\nword_idx = dict((c, i + 1) for i, c in enumerate(vocab))\ninputs_train, queries_train, answers_train = vectorize_stories(train_stories)\ninputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n\nprint(\'-\')\nprint(\'inputs: integer tensor of shape (samples, max_length)\')\nprint(\'inputs_train shape:\', inputs_train.shape)\nprint(\'inputs_test shape:\', inputs_test.shape)\nprint(\'-\')\nprint(\'queries: integer tensor of shape (samples, max_length)\')\nprint(\'queries_train shape:\', queries_train.shape)\nprint(\'queries_test shape:\', queries_test.shape)\nprint(\'-\')\nprint(\'answers: binary (1 or 0) tensor of shape (samples, vocab_size)\')\nprint(\'answers_train shape:\', answers_train.shape)\nprint(\'answers_test shape:\', answers_test.shape)\nprint(\'-\')\nprint(\'Compiling...\')\n\n# placeholders\ninput_sequence = Input((story_maxlen,))\nquestion = Input((query_maxlen,))\n\n# encoders\n# embed the input sequence into a sequence of vectors\ninput_encoder_m = Sequential()\ninput_encoder_m.add(Embedding(input_dim=vocab_size,\n                              output_dim=64))\ninput_encoder_m.add(Dropout(0.3))\n# output: (samples, story_maxlen, embedding_dim)\n\n# embed the input into a sequence of vectors of size query_maxlen\ninput_encoder_c = Sequential()\ninput_encoder_c.add(Embedding(input_dim=vocab_size,\n                              output_dim=query_maxlen))\ninput_encoder_c.add(Dropout(0.3))\n# output: (samples, story_maxlen, query_maxlen)\n\n# embed the question into a sequence of vectors\nquestion_encoder = Sequential()\nquestion_encoder.add(Embedding(input_dim=vocab_size,\n                               output_dim=64,\n                               input_length=query_maxlen))\nquestion_encoder.add(Dropout(0.3))\n# output: (samples, query_maxlen, embedding_dim)\n\n# encode input sequence and questions (which are indices)\n# to sequences of dense vectors\ninput_encoded_m = input_encoder_m(input_sequence)\ninput_encoded_c = input_encoder_c(input_sequence)\nquestion_encoded = question_encoder(question)\n\n# compute a \'match\' between the first input vector sequence\n# and the question vector sequence\n# shape: `(samples, story_maxlen, query_maxlen)`\nmatch = dot([input_encoded_m, question_encoded], axes=(2, 2))\nmatch = Activation(\'softmax\')(match)\n\n# add the match matrix with the second input vector sequence\nresponse = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\nresponse = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n\n# concatenate the match matrix with the question vector sequence\nanswer = concatenate([response, question_encoded])\n\n# the original paper uses a matrix multiplication for this reduction step.\n# we choose to use a RNN instead.\nanswer = LSTM(32)(answer)  # (samples, 32)\n\n# one regularization layer -- more would probably be needed.\nanswer = Dropout(0.3)(answer)\nanswer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n# we output a probability distribution over the vocabulary\nanswer = Activation(\'softmax\')(answer)\n\n# build the final model\nmodel = Model([input_sequence, question], answer)\nmodel.compile(optimizer=\'rmsprop\', loss=\'sparse_categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\n# train\nmodel.fit([inputs_train, queries_train], answers_train,\n          batch_size=32,\n          epochs=120,\n          validation_data=([inputs_test, queries_test], answers_test))\n'"
examples/babi_rnn.py,0,"b'\'\'\'\n# Trains two recurrent neural networks based upon a story and a question.\n\nThe resulting merged vector is then queried to answer a range of bAbI tasks.\n\nThe results are comparable to those for an LSTM model provided in Weston et al.:\n""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks""\nhttp://arxiv.org/abs/1502.05698\n\nTask Number                  | FB LSTM Baseline | Keras QA\n---                          | ---              | ---\nQA1 - Single Supporting Fact | 50               | 52.1\nQA2 - Two Supporting Facts   | 20               | 37.0\nQA3 - Three Supporting Facts | 20               | 20.5\nQA4 - Two Arg. Relations     | 61               | 62.9\nQA5 - Three Arg. Relations   | 70               | 61.9\nQA6 - yes/No Questions       | 48               | 50.7\nQA7 - Counting               | 49               | 78.9\nQA8 - Lists/Sets             | 45               | 77.2\nQA9 - Simple Negation        | 64               | 64.0\nQA10 - Indefinite Knowledge  | 44               | 47.7\nQA11 - Basic Coreference     | 72               | 74.9\nQA12 - Conjunction           | 74               | 76.4\nQA13 - Compound Coreference  | 94               | 94.4\nQA14 - Time Reasoning        | 27               | 34.8\nQA15 - Basic Deduction       | 21               | 32.4\nQA16 - Basic Induction       | 23               | 50.6\nQA17 - Positional Reasoning  | 51               | 49.1\nQA18 - Size Reasoning        | 52               | 90.8\nQA19 - Path Finding          | 8                | 9.0\nQA20 - Agent\'s Motivations   | 91               | 90.7\n\nFor the resources related to the bAbI project, refer to:\nhttps://research.facebook.com/researchers/1543934539189348\n\n### Notes\n\n- With default word, sentence, and query vector sizes, the GRU model achieves:\n  - 52.1% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n  - 37.0% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\nIn comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\n\n- The task does not traditionally parse the question separately. This likely\nimproves accuracy and is a good example of merging two RNNs.\n\n- The word vector embeddings are not shared between the story and question RNNs.\n\n- See how the accuracy changes given 10,000 training samples (en-10k) instead\nof only 1000. 1000 was used in order to be comparable to the original paper.\n\n- Experiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\n\n- The length and noise (i.e. \'useless\' story components) impact the ability of\nLSTMs / GRUs to provide the correct answer. Given only the supporting facts,\nthese RNNs can achieve 100% accuracy on many tasks. Memory networks and neural\nnetworks that use attentional processes can efficiently search through this\nnoise to find the relevant statements, improving performance substantially.\nThis becomes especially obvious on QA2 and QA3, both far longer than QA1.\n\'\'\'\n\nfrom __future__ import print_function\nfrom functools import reduce\nimport re\nimport tarfile\n\nimport numpy as np\n\nfrom keras.utils.data_utils import get_file\nfrom keras.layers.embeddings import Embedding\nfrom keras import layers\nfrom keras.layers import recurrent\nfrom keras.models import Model\nfrom keras.preprocessing.sequence import pad_sequences\n\n\ndef tokenize(sent):\n    \'\'\'Return the tokens of a sentence including punctuation.\n\n    >>> tokenize(\'Bob dropped the apple. Where is the apple?\')\n    [\'Bob\', \'dropped\', \'the\', \'apple\', \'.\', \'Where\', \'is\', \'the\', \'apple\', \'?\']\n    \'\'\'\n    return [x.strip() for x in re.split(r\'(\\W+)\', sent) if x.strip()]\n\n\ndef parse_stories(lines, only_supporting=False):\n    \'\'\'Parse stories provided in the bAbi tasks format\n\n    If only_supporting is true,\n    only the sentences that support the answer are kept.\n    \'\'\'\n    data = []\n    story = []\n    for line in lines:\n        line = line.decode(\'utf-8\').strip()\n        nid, line = line.split(\' \', 1)\n        nid = int(nid)\n        if nid == 1:\n            story = []\n        if \'\\t\' in line:\n            q, a, supporting = line.split(\'\\t\')\n            q = tokenize(q)\n            if only_supporting:\n                # Only select the related substory\n                supporting = map(int, supporting.split())\n                substory = [story[i - 1] for i in supporting]\n            else:\n                # Provide all the substories\n                substory = [x for x in story if x]\n            data.append((substory, q, a))\n            story.append(\'\')\n        else:\n            sent = tokenize(line)\n            story.append(sent)\n    return data\n\n\ndef get_stories(f, only_supporting=False, max_length=None):\n    \'\'\'Given a file name, read the file, retrieve the stories,\n    and then convert the sentences into a single story.\n\n    If max_length is supplied,\n    any stories longer than max_length tokens will be discarded.\n    \'\'\'\n    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n    flatten = lambda data: reduce(lambda x, y: x + y, data)\n    data = [(flatten(story), q, answer) for story, q, answer in data\n            if not max_length or len(flatten(story)) < max_length]\n    return data\n\n\ndef vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n    xs = []\n    xqs = []\n    ys = []\n    for story, query, answer in data:\n        x = [word_idx[w] for w in story]\n        xq = [word_idx[w] for w in query]\n        # let\'s not forget that index 0 is reserved\n        y = np.zeros(len(word_idx) + 1)\n        y[word_idx[answer]] = 1\n        xs.append(x)\n        xqs.append(xq)\n        ys.append(y)\n    return (pad_sequences(xs, maxlen=story_maxlen),\n            pad_sequences(xqs, maxlen=query_maxlen), np.array(ys))\n\nRNN = recurrent.LSTM\nEMBED_HIDDEN_SIZE = 50\nSENT_HIDDEN_SIZE = 100\nQUERY_HIDDEN_SIZE = 100\nBATCH_SIZE = 32\nEPOCHS = 20\nprint(\'RNN / Embed / Sent / Query = {}, {}, {}, {}\'.format(RNN,\n                                                           EMBED_HIDDEN_SIZE,\n                                                           SENT_HIDDEN_SIZE,\n                                                           QUERY_HIDDEN_SIZE))\n\ntry:\n    path = get_file(\'babi-tasks-v1-2.tar.gz\',\n                    origin=\'https://s3.amazonaws.com/text-datasets/\'\n                           \'babi_tasks_1-20_v1-2.tar.gz\')\nexcept:\n    print(\'Error downloading dataset, please download it manually:\\n\'\n          \'$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2\'\n          \'.tar.gz\\n\'\n          \'$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz\')\n    raise\n\n# Default QA1 with 1000 samples\n# challenge = \'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt\'\n# QA1 with 10,000 samples\n# challenge = \'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt\'\n# QA2 with 1000 samples\nchallenge = \'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt\'\n# QA2 with 10,000 samples\n# challenge = \'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt\'\nwith tarfile.open(path) as tar:\n    train = get_stories(tar.extractfile(challenge.format(\'train\')))\n    test = get_stories(tar.extractfile(challenge.format(\'test\')))\n\nvocab = set()\nfor story, q, answer in train + test:\n    vocab |= set(story + q + [answer])\nvocab = sorted(vocab)\n\n# Reserve 0 for masking via pad_sequences\nvocab_size = len(vocab) + 1\nword_idx = dict((c, i + 1) for i, c in enumerate(vocab))\nstory_maxlen = max(map(len, (x for x, _, _ in train + test)))\nquery_maxlen = max(map(len, (x for _, x, _ in train + test)))\n\nx, xq, y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\ntx, txq, ty = vectorize_stories(test, word_idx, story_maxlen, query_maxlen)\n\nprint(\'vocab = {}\'.format(vocab))\nprint(\'x.shape = {}\'.format(x.shape))\nprint(\'xq.shape = {}\'.format(xq.shape))\nprint(\'y.shape = {}\'.format(y.shape))\nprint(\'story_maxlen, query_maxlen = {}, {}\'.format(story_maxlen, query_maxlen))\n\nprint(\'Build model...\')\n\nsentence = layers.Input(shape=(story_maxlen,), dtype=\'int32\')\nencoded_sentence = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\nencoded_sentence = RNN(SENT_HIDDEN_SIZE)(encoded_sentence)\n\nquestion = layers.Input(shape=(query_maxlen,), dtype=\'int32\')\nencoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\nencoded_question = RNN(QUERY_HIDDEN_SIZE)(encoded_question)\n\nmerged = layers.concatenate([encoded_sentence, encoded_question])\npreds = layers.Dense(vocab_size, activation=\'softmax\')(merged)\n\nmodel = Model([sentence, question], preds)\nmodel.compile(optimizer=\'adam\',\n              loss=\'categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\nprint(\'Training\')\nmodel.fit([x, xq], y,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_split=0.05)\n\nprint(\'Evaluation\')\nloss, acc = model.evaluate([tx, txq], ty,\n                           batch_size=BATCH_SIZE)\nprint(\'Test loss / test accuracy = {:.4f} / {:.4f}\'.format(loss, acc))\n'"
examples/cifar10_cnn.py,0,"b'\'\'\'\n#Train a simple deep CNN on the CIFAR10 small images dataset.\n\nIt gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n(it\'s still underfitting at that point, though).\n\'\'\'\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport os\n\nbatch_size = 32\nnum_classes = 10\nepochs = 100\ndata_augmentation = True\nnum_predictions = 20\nsave_dir = os.path.join(os.getcwd(), \'saved_models\')\nmodel_name = \'keras_cifar10_trained_model.h5\'\n\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\'same\',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation(\'relu\'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation(\'relu\'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding=\'same\'))\nmodel.add(Activation(\'relu\'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\'relu\'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation(\'softmax\'))\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n\n# Let\'s train the model using RMSprop\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=opt,\n              metrics=[\'accuracy\'])\n\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\n\nif not data_augmentation:\n    print(\'Not using data augmentation.\')\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True)\nelse:\n    print(\'Using real-time data augmentation.\')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        # randomly shift images horizontally (fraction of total width)\n        width_shift_range=0.1,\n        # randomly shift images vertically (fraction of total height)\n        height_shift_range=0.1,\n        shear_range=0.,  # set range for random shear\n        zoom_range=0.,  # set range for random zoom\n        channel_shift_range=0.,  # set range for random channel shifts\n        # set mode for filling points outside the input boundaries\n        fill_mode=\'nearest\',\n        cval=0.,  # value used for fill_mode = ""constant""\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,  # randomly flip images\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either ""channels_first"" or ""channels_last""\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(datagen.flow(x_train, y_train,\n                                     batch_size=batch_size),\n                        epochs=epochs,\n                        validation_data=(x_test, y_test),\n                        workers=4)\n\n# Save model and weights\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint(\'Saved trained model at %s \' % model_path)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy:\', scores[1])\n'"
examples/cifar10_resnet.py,0,"b'""""""\n#Trains a ResNet on the CIFAR10 dataset.\n\nResNet v1:\n[Deep Residual Learning for Image Recognition\n](https://arxiv.org/pdf/1512.03385.pdf)\n\nResNet v2:\n[Identity Mappings in Deep Residual Networks\n](https://arxiv.org/pdf/1603.05027.pdf)\n\n\nModel|n|200-epoch accuracy|Original paper accuracy |sec/epoch GTX1080Ti\n:------------|--:|-------:|-----------------------:|---:\nResNet20   v1|  3| 92.16 %|                 91.25 %|35\nResNet32   v1|  5| 92.46 %|                 92.49 %|50\nResNet44   v1|  7| 92.50 %|                 92.83 %|70\nResNet56   v1|  9| 92.71 %|                 93.03 %|90\nResNet110  v1| 18| 92.65 %|            93.39+-.16 %|165\nResNet164  v1| 27|     - %|                 94.07 %|  -\nResNet1001 v1|N/A|     - %|                 92.39 %|  -\n\n&nbsp;\n\nModel|n|200-epoch accuracy|Original paper accuracy |sec/epoch GTX1080Ti\n:------------|--:|-------:|-----------------------:|---:\nResNet20   v2|  2|     - %|                     - %|---\nResNet32   v2|N/A| NA    %|            NA         %| NA\nResNet44   v2|N/A| NA    %|            NA         %| NA\nResNet56   v2|  6| 93.01 %|            NA         %|100\nResNet110  v2| 12| 93.15 %|            93.63      %|180\nResNet164  v2| 18|     - %|            94.54      %|  -\nResNet1001 v2|111|     - %|            95.08+-.14 %|  -\n""""""\n\nfrom __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nimport numpy as np\nimport os\n\n# Training parameters\nbatch_size = 32  # orig paper trained all networks with batch_size=128\nepochs = 200\ndata_augmentation = True\nnum_classes = 10\n\n# Subtracting pixel mean improves accuracy\nsubtract_pixel_mean = True\n\n# Model parameter\n# ----------------------------------------------------------------------------\n#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n# ----------------------------------------------------------------------------\n# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n# ---------------------------------------------------------------------------\nn = 3\n\n# Model version\n# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\nversion = 1\n\n# Computed depth from supplied model parameter n\nif version == 1:\n    depth = n * 6 + 2\nelif version == 2:\n    depth = n * 9 + 2\n\n# Model name, depth and version\nmodel_type = \'ResNet%dv%d\' % (depth, version)\n\n# Load the CIFAR10 data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Input image dimensions.\ninput_shape = x_train.shape[1:]\n\n# Normalize data.\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# If subtract pixel mean is enabled\nif subtract_pixel_mean:\n    x_train_mean = np.mean(x_train, axis=0)\n    x_train -= x_train_mean\n    x_test -= x_train_mean\n\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\nprint(\'y_train shape:\', y_train.shape)\n\n# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n\ndef lr_schedule(epoch):\n    """"""Learning Rate Schedule\n\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n\n    # Arguments\n        epoch (int): The number of epochs\n\n    # Returns\n        lr (float32): learning rate\n    """"""\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print(\'Learning rate: \', lr)\n    return lr\n\n\ndef resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation=\'relu\',\n                 batch_normalization=True,\n                 conv_first=True):\n    """"""2D Convolution-Batch Normalization-Activation stack builder\n\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n\n    # Returns\n        x (tensor): tensor as input to the next layer\n    """"""\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding=\'same\',\n                  kernel_initializer=\'he_normal\',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x\n\n\ndef resnet_v1(input_shape, depth, num_classes=10):\n    """"""ResNet Version 1 Model builder [a]\n\n    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n    Last ReLU is after the shortcut connection.\n    At the beginning of each stage, the feature map size is halved (downsampled)\n    by a convolutional layer with strides=2, while the number of filters is\n    doubled. Within each stage, the layers have the same number filters and the\n    same number of filters.\n    Features maps sizes:\n    stage 0: 32x32, 16\n    stage 1: 16x16, 32\n    stage 2:  8x8,  64\n    The Number of parameters is approx the same as Table 6 of [a]:\n    ResNet20 0.27M\n    ResNet32 0.46M\n    ResNet44 0.66M\n    ResNet56 0.85M\n    ResNet110 1.7M\n\n    # Arguments\n        input_shape (tensor): shape of input image tensor\n        depth (int): number of core convolutional layers\n        num_classes (int): number of classes (CIFAR10 has 10)\n\n    # Returns\n        model (Model): Keras model instance\n    """"""\n    if (depth - 2) % 6 != 0:\n        raise ValueError(\'depth should be 6n+2 (eg 20, 32, 44 in [a])\')\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation(\'relu\')(x)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation=\'softmax\',\n                    kernel_initializer=\'he_normal\')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n\ndef resnet_v2(input_shape, depth, num_classes=10):\n    """"""ResNet Version 2 Model builder [b]\n\n    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n    bottleneck layer\n    First shortcut connection per layer is 1 x 1 Conv2D.\n    Second and onwards shortcut connection is identity.\n    At the beginning of each stage, the feature map size is halved (downsampled)\n    by a convolutional layer with strides=2, while the number of filter maps is\n    doubled. Within each stage, the layers have the same number filters and the\n    same filter map sizes.\n    Features maps sizes:\n    conv1  : 32x32,  16\n    stage 0: 32x32,  64\n    stage 1: 16x16, 128\n    stage 2:  8x8,  256\n\n    # Arguments\n        input_shape (tensor): shape of input image tensor\n        depth (int): number of core convolutional layers\n        num_classes (int): number of classes (CIFAR10 has 10)\n\n    # Returns\n        model (Model): Keras model instance\n    """"""\n    if (depth - 2) % 9 != 0:\n        raise ValueError(\'depth should be 9n+2 (eg 56 or 110 in [b])\')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) / 9)\n\n    inputs = Input(shape=input_shape)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x = resnet_layer(inputs=inputs,\n                     num_filters=num_filters_in,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = \'relu\'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n\n        num_filters_in = num_filters_out\n\n    # Add classifier on top.\n    # v2 has BN-ReLU before Pooling\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation=\'softmax\',\n                    kernel_initializer=\'he_normal\')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n\nif version == 2:\n    model = resnet_v2(input_shape=input_shape, depth=depth)\nelse:\n    model = resnet_v1(input_shape=input_shape, depth=depth)\n\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=Adam(learning_rate=lr_schedule(0)),\n              metrics=[\'accuracy\'])\nmodel.summary()\nprint(model_type)\n\n# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), \'saved_models\')\nmodel_name = \'cifar10_%s_model.{epoch:03d}.h5\' % model_type\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)\n\n# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor=\'val_acc\',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]\n\n# Run training, with or without data augmentation.\nif not data_augmentation:\n    print(\'Not using data augmentation.\')\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=callbacks)\nelse:\n    print(\'Using real-time data augmentation.\')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        # set input mean to 0 over the dataset\n        featurewise_center=False,\n        # set each sample mean to 0\n        samplewise_center=False,\n        # divide inputs by std of dataset\n        featurewise_std_normalization=False,\n        # divide each input by its std\n        samplewise_std_normalization=False,\n        # apply ZCA whitening\n        zca_whitening=False,\n        # epsilon for ZCA whitening\n        zca_epsilon=1e-06,\n        # randomly rotate images in the range (deg 0 to 180)\n        rotation_range=0,\n        # randomly shift images horizontally\n        width_shift_range=0.1,\n        # randomly shift images vertically\n        height_shift_range=0.1,\n        # set range for random shear\n        shear_range=0.,\n        # set range for random zoom\n        zoom_range=0.,\n        # set range for random channel shifts\n        channel_shift_range=0.,\n        # set mode for filling points outside the input boundaries\n        fill_mode=\'nearest\',\n        # value used for fill_mode = ""constant""\n        cval=0.,\n        # randomly flip images\n        horizontal_flip=True,\n        # randomly flip images\n        vertical_flip=False,\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either ""channels_first"" or ""channels_last""\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    # Compute quantities required for featurewise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                        validation_data=(x_test, y_test),\n                        epochs=epochs, verbose=1, workers=4,\n                        callbacks=callbacks)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy:\', scores[1])\n'"
examples/class_activation_maps.py,0,"b""# -*- coding: utf-8 -*-\r\n\r\nimport numpy as np\r\nimport argparse\r\nimport cv2\r\nimport matplotlib.pyplot as plt\r\n\r\nfrom keras.models import Model\r\n\r\nimport keras.applications.resnet50 as resnet\r\nfrom keras.layers import UpSampling2D, Conv2D\r\n\r\n# Set an appropriate image file\r\nparser = argparse.ArgumentParser(description='Class activation maps with Keras.')\r\nparser.add_argument('input_image', metavar='base', type=str,\r\n                    help='Path to the image to use.')\r\nargs = parser.parse_args()\r\ninput_image = args.input_image\r\n\r\n\r\n################################################################\r\n# The following parameters can be changed to other models\r\n# that use global average pooling.\r\n# e.g.) InceptionResnetV2 / NASNetLarge\r\nNETWORK_INPUT_SIZE = 224\r\nMODEL_CLASS = resnet.ResNet50\r\nPREPROCESS_FN = resnet.preprocess_input\r\nLAST_CONV_LAYER = 'activation_49'\r\nPRED_LAYER = 'fc1000'\r\n################################################################\r\n\r\n# number of imagenet classes\r\nN_CLASSES = 1000\r\n\r\n\r\ndef load_img(fname, input_size, preprocess_fn):\r\n    original_img = cv2.imread(fname)[:, :, ::-1]\r\n    original_size = (original_img.shape[1], original_img.shape[0])\r\n    img = cv2.resize(original_img, (input_size, input_size))\r\n    imgs = np.expand_dims(preprocess_fn(img), axis=0)\r\n    return imgs, original_img, original_size\r\n\r\n\r\ndef get_cam_model(model_class,\r\n                  input_size=224,\r\n                  last_conv_layer='activation_49',\r\n                  pred_layer='fc1000'):\r\n    model = model_class(input_shape=(input_size, input_size, 3))\r\n\r\n    final_params = model.get_layer(pred_layer).get_weights()\r\n    final_params = (final_params[0].reshape(\r\n        1, 1, -1, N_CLASSES), final_params[1])\r\n\r\n    last_conv_output = model.get_layer(last_conv_layer).output\r\n    x = UpSampling2D(size=(32, 32), interpolation='bilinear')(\r\n        last_conv_output)\r\n    x = Conv2D(filters=N_CLASSES, kernel_size=(\r\n        1, 1), name='predictions_2')(x)\r\n\r\n    cam_model = Model(inputs=model.input,\r\n                      outputs=[model.output, x])\r\n    cam_model.get_layer('predictions_2').set_weights(final_params)\r\n    return cam_model\r\n\r\n\r\ndef postprocess(preds, cams, top_k=1):\r\n    idxes = np.argsort(preds[0])[-top_k:]\r\n    class_activation_map = np.zeros_like(cams[0, :, :, 0])\r\n    for i in idxes:\r\n        class_activation_map += cams[0, :, :, i]\r\n    return class_activation_map\r\n\r\n\r\n# 1. load image\r\nimgs, original_img, original_size = load_img(input_image,\r\n                                             input_size=NETWORK_INPUT_SIZE,\r\n                                             preprocess_fn=resnet.preprocess_input)\r\n\r\n# 2. prediction\r\nmodel = get_cam_model(resnet.ResNet50,\r\n                      NETWORK_INPUT_SIZE,\r\n                      LAST_CONV_LAYER,\r\n                      PRED_LAYER)\r\npreds, cams = model.predict(imgs)\r\n\r\n# 4. post processing\r\nclass_activation_map = postprocess(preds, cams)\r\n\r\n# 5. plot image+cam to original size\r\nplt.imshow(original_img, alpha=0.5)\r\nplt.imshow(cv2.resize(class_activation_map,\r\n                      original_size), cmap='jet', alpha=0.5)\r\nplt.show()\r\n"""
examples/cnn_seq2seq.py,0,"b'\'\'\'# Sequence-to-sequence example in Keras (character-level).\n\nThis script demonstrates how to implement a basic character-level CNN\nsequence-to-sequence model. We apply it to translating\nshort English sentences into short French sentences,\ncharacter-by-character. Note that it is fairly unusual to\ndo character-level machine translation, as word-level\nmodels are much more common in this domain. This example\nis for demonstration purposes only.\n\n**Summary of the algorithm**\n\n- We start with input sequences from a domain (e.g. English sentences)\n    and corresponding target sequences from another domain\n    (e.g. French sentences).\n- An encoder CNN encodes the input character sequence.\n- A decoder CNN is trained to turn the target sequences into\n    the same sequence but offset by one timestep in the future,\n    a training process called ""teacher forcing"" in this context.\n    It uses the output from the encoder.\n    Effectively, the decoder learns to generate `targets[t+1...]`\n    given `targets[...t]`, conditioned on the input sequence.\n- In inference mode, when we want to decode unknown input sequences, we:\n    - Encode the input sequence.\n    - Start with a target sequence of size 1\n        (just the start-of-sequence character)\n    - Feed the input sequence and 1-char target sequence\n        to the decoder to produce predictions for the next character\n    - Sample the next character using these predictions\n        (we simply use argmax).\n    - Append the sampled character to the target sequence\n    - Repeat until we hit the character limit.\n\n**Data download**\n\n[English to French sentence pairs.\n](http://www.manythings.org/anki/fra-eng.zip)\n\n[Lots of neat sentence pairs datasets.\n](http://www.manythings.org/anki/)\n\n**References**\n\n- lstm_seq2seq.py\n- https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html\n\'\'\'\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom keras.layers import Input, Convolution1D, Dot, Dense, Activation, Concatenate\nfrom keras.models import Model\n\nbatch_size = 64  # Batch size for training.\nepochs = 100  # Number of epochs to train for.\nnum_samples = 10000  # Number of samples to train on.\n# Path to the data txt file on disk.\ndata_path = \'fra-eng/fra.txt\'\n\n# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, \'r\', encoding=\'utf-8\') as f:\n    lines = f.read().split(\'\\n\')\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text = line.split(\'\\t\')\n    # We use ""tab"" as the ""start sequence"" character\n    # for the targets, and ""\\n"" as ""end sequence"" character.\n    target_text = \'\\t\' + target_text + \'\\n\'\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint(\'Number of samples:\', len(input_texts))\nprint(\'Number of unique input tokens:\', num_encoder_tokens)\nprint(\'Number of unique output tokens:\', num_decoder_tokens)\nprint(\'Max sequence length for inputs:\', max_encoder_seq_length)\nprint(\'Max sequence length for outputs:\', max_decoder_seq_length)\n\ninput_token_index = dict(\n    [(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict(\n    [(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n    dtype=\'float32\')\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\'float32\')\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\'float32\')\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token_index[char]] = 1.\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n\n# Define an input sequence and process it.\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\n# Encoder\nx_encoder = Convolution1D(256, kernel_size=3, activation=\'relu\',\n                          padding=\'causal\')(encoder_inputs)\nx_encoder = Convolution1D(256, kernel_size=3, activation=\'relu\',\n                          padding=\'causal\', dilation_rate=2)(x_encoder)\nx_encoder = Convolution1D(256, kernel_size=3, activation=\'relu\',\n                          padding=\'causal\', dilation_rate=4)(x_encoder)\n\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\n# Decoder\nx_decoder = Convolution1D(256, kernel_size=3, activation=\'relu\',\n                          padding=\'causal\')(decoder_inputs)\nx_decoder = Convolution1D(256, kernel_size=3, activation=\'relu\',\n                          padding=\'causal\', dilation_rate=2)(x_decoder)\nx_decoder = Convolution1D(256, kernel_size=3, activation=\'relu\',\n                          padding=\'causal\', dilation_rate=4)(x_decoder)\n# Attention\nattention = Dot(axes=[2, 2])([x_decoder, x_encoder])\nattention = Activation(\'softmax\')(attention)\n\ncontext = Dot(axes=[2, 1])([attention, x_encoder])\ndecoder_combined_context = Concatenate(axis=-1)([context, x_decoder])\n\ndecoder_outputs = Convolution1D(64, kernel_size=3, activation=\'relu\',\n                                padding=\'causal\')(decoder_combined_context)\ndecoder_outputs = Convolution1D(64, kernel_size=3, activation=\'relu\',\n                                padding=\'causal\')(decoder_outputs)\n# Output\ndecoder_dense = Dense(num_decoder_tokens, activation=\'softmax\')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.summary()\n\n# Run training\nmodel.compile(optimizer=\'adam\', loss=\'categorical_crossentropy\')\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.2)\n# Save model\nmodel.save(\'cnn_s2s.h5\')\n\n# Next: inference mode (sampling).\n\n# Define sampling models\nreverse_input_char_index = dict(\n    (i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict(\n    (i, char) for char, i in target_token_index.items())\n\nnb_examples = 100\nin_encoder = encoder_input_data[:nb_examples]\nin_decoder = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\'float32\')\n\nin_decoder[:, 0, target_token_index[""\\t""]] = 1\n\npredict = np.zeros(\n    (len(input_texts), max_decoder_seq_length),\n    dtype=\'float32\')\n\nfor i in range(max_decoder_seq_length - 1):\n    predict = model.predict([in_encoder, in_decoder])\n    predict = predict.argmax(axis=-1)\n    predict_ = predict[:, i].ravel().tolist()\n    for j, x in enumerate(predict_):\n        in_decoder[j, i + 1, x] = 1\n\nfor seq_index in range(nb_examples):\n    # Take one sequence (part of the training set)\n    # for trying out decoding.\n    output_seq = predict[seq_index, :].ravel().tolist()\n    decoded = []\n    for x in output_seq:\n        if reverse_target_char_index[x] == ""\\n"":\n            break\n        else:\n            decoded.append(reverse_target_char_index[x])\n    decoded_sentence = """".join(decoded)\n    print(\'-\')\n    print(\'Input sentence:\', input_texts[seq_index])\n    print(\'Decoded sentence:\', decoded_sentence)\n'"
examples/conv_filter_visualization.py,0,"b'""""""\n#Visualization of the filters of VGG16, via gradient ascent in input space.\n\nThis script can run on CPU in a few minutes.\n\nResults example: ![Visualization](http://i.imgur.com/4nj4KjN.jpg)\n""""""\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nfrom PIL import Image as pil_image\nfrom keras.preprocessing.image import save_img\nfrom keras import layers\nfrom keras.applications import vgg16\nfrom keras import backend as K\n\n\ndef normalize(x):\n    """"""utility function to normalize a tensor.\n\n    # Arguments\n        x: An input tensor.\n\n    # Returns\n        The normalized input tensor.\n    """"""\n    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n\n\ndef deprocess_image(x):\n    """"""utility function to convert a float array into a valid uint8 image.\n\n    # Arguments\n        x: A numpy-array representing the generated image.\n\n    # Returns\n        A processed numpy-array, which could be used in e.g. imshow.\n    """"""\n    # normalize tensor: center on 0., ensure std is 0.25\n    x -= x.mean()\n    x /= (x.std() + K.epsilon())\n    x *= 0.25\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    if K.image_data_format() == \'channels_first\':\n        x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype(\'uint8\')\n    return x\n\n\ndef process_image(x, former):\n    """"""utility function to convert a valid uint8 image back into a float array.\n       Reverses `deprocess_image`.\n\n    # Arguments\n        x: A numpy-array, which could be used in e.g. imshow.\n        former: The former numpy-array.\n                Need to determine the former mean and variance.\n\n    # Returns\n        A processed numpy-array representing the generated image.\n    """"""\n    if K.image_data_format() == \'channels_first\':\n        x = x.transpose((2, 0, 1))\n    return (x / 255 - 0.5) * 4 * former.std() + former.mean()\n\n\ndef visualize_layer(model,\n                    layer_name,\n                    step=1.,\n                    epochs=15,\n                    upscaling_steps=9,\n                    upscaling_factor=1.2,\n                    output_dim=(412, 412),\n                    filter_range=(0, None)):\n    """"""Visualizes the most relevant filters of one conv-layer in a certain model.\n\n    # Arguments\n        model: The model containing layer_name.\n        layer_name: The name of the layer to be visualized.\n                    Has to be a part of model.\n        step: step size for gradient ascent.\n        epochs: Number of iterations for gradient ascent.\n        upscaling_steps: Number of upscaling steps.\n                         Starting image is in this case (80, 80).\n        upscaling_factor: Factor to which to slowly upgrade\n                          the image towards output_dim.\n        output_dim: [img_width, img_height] The output image dimensions.\n        filter_range: Tupel[lower, upper]\n                      Determines the to be computed filter numbers.\n                      If the second value is `None`,\n                      the last filter will be inferred as the upper boundary.\n    """"""\n\n    def _generate_filter_image(input_img,\n                               layer_output,\n                               filter_index):\n        """"""Generates image for one particular filter.\n\n        # Arguments\n            input_img: The input-image Tensor.\n            layer_output: The output-image Tensor.\n            filter_index: The to be processed filter number.\n                          Assumed to be valid.\n\n        #Returns\n            Either None if no image could be generated.\n            or a tuple of the image (array) itself and the last loss.\n        """"""\n        s_time = time.time()\n\n        # we build a loss function that maximizes the activation\n        # of the nth filter of the layer considered\n        if K.image_data_format() == \'channels_first\':\n            loss = K.mean(layer_output[:, filter_index, :, :])\n        else:\n            loss = K.mean(layer_output[:, :, :, filter_index])\n\n        # we compute the gradient of the input picture wrt this loss\n        grads = K.gradients(loss, input_img)[0]\n\n        # normalization trick: we normalize the gradient\n        grads = normalize(grads)\n\n        # this function returns the loss and grads given the input picture\n        iterate = K.function([input_img], [loss, grads])\n\n        # we start from a gray image with some random noise\n        intermediate_dim = tuple(\n            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n        if K.image_data_format() == \'channels_first\':\n            input_img_data = np.random.random(\n                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n        else:\n            input_img_data = np.random.random(\n                (1, intermediate_dim[0], intermediate_dim[1], 3))\n        input_img_data = (input_img_data - 0.5) * 20 + 128\n\n        # Slowly upscaling towards the original size prevents\n        # a dominating high-frequency of the to visualized structure\n        # as it would occur if we directly compute the 412d-image.\n        # Behaves as a better starting point for each following dimension\n        # and therefore avoids poor local minima\n        for up in reversed(range(upscaling_steps)):\n            # we run gradient ascent for e.g. 20 steps\n            for _ in range(epochs):\n                loss_value, grads_value = iterate([input_img_data])\n                input_img_data += grads_value * step\n\n                # some filters get stuck to 0, we can skip them\n                if loss_value <= K.epsilon():\n                    return None\n\n            # Calculate upscaled dimension\n            intermediate_dim = tuple(\n                int(x / (upscaling_factor ** up)) for x in output_dim)\n            # Upscale\n            img = deprocess_image(input_img_data[0])\n            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n                                                           pil_image.BICUBIC))\n            input_img_data = np.expand_dims(\n                process_image(img, input_img_data[0]), 0)\n\n        # decode the resulting input image\n        img = deprocess_image(input_img_data[0])\n        e_time = time.time()\n        print(\'Costs of filter {:3}: {:5.0f} ( {:4.2f}s )\'.format(filter_index,\n                                                                  loss_value,\n                                                                  e_time - s_time))\n        return img, loss_value\n\n    def _draw_filters(filters, n=None):\n        """"""Draw the best filters in a nxn grid.\n\n        # Arguments\n            filters: A List of generated images and their corresponding losses\n                     for each processed filter.\n            n: dimension of the grid.\n               If none, the largest possible square will be used\n        """"""\n        if n is None:\n            n = int(np.floor(np.sqrt(len(filters))))\n\n        # the filters that have the highest loss are assumed to be better-looking.\n        # we will only keep the top n*n filters.\n        filters.sort(key=lambda x: x[1], reverse=True)\n        filters = filters[:n * n]\n\n        # build a black picture with enough space for\n        # e.g. our 8 x 8 filters of size 412 x 412, with a 5px margin in between\n        MARGIN = 5\n        width = n * output_dim[0] + (n - 1) * MARGIN\n        height = n * output_dim[1] + (n - 1) * MARGIN\n        stitched_filters = np.zeros((width, height, 3), dtype=\'uint8\')\n\n        # fill the picture with our saved filters\n        for i in range(n):\n            for j in range(n):\n                img, _ = filters[i * n + j]\n                width_margin = (output_dim[0] + MARGIN) * i\n                height_margin = (output_dim[1] + MARGIN) * j\n                stitched_filters[\n                    width_margin: width_margin + output_dim[0],\n                    height_margin: height_margin + output_dim[1], :] = img\n\n        # save the result to disk\n        save_img(\'vgg_{0:}_{1:}x{1:}.png\'.format(layer_name, n), stitched_filters)\n\n    # this is the placeholder for the input images\n    assert len(model.inputs) == 1\n    input_img = model.inputs[0]\n\n    # get the symbolic outputs of each ""key"" layer (we gave them unique names).\n    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n\n    output_layer = layer_dict[layer_name]\n    assert isinstance(output_layer, layers.Conv2D)\n\n    # Compute to be processed filter range\n    filter_lower = filter_range[0]\n    filter_upper = (filter_range[1]\n                    if filter_range[1] is not None\n                    else len(output_layer.get_weights()[1]))\n    assert(filter_lower >= 0\n           and filter_upper <= len(output_layer.get_weights()[1])\n           and filter_upper > filter_lower)\n    print(\'Compute filters {:} to {:}\'.format(filter_lower, filter_upper))\n\n    # iterate through each filter and generate its corresponding image\n    processed_filters = []\n    for f in range(filter_lower, filter_upper):\n        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n\n        if img_loss is not None:\n            processed_filters.append(img_loss)\n\n    print(\'{} filter processed.\'.format(len(processed_filters)))\n    # Finally draw and store the best filters to disk\n    _draw_filters(processed_filters)\n\n\nif __name__ == \'__main__\':\n    # the name of the layer we want to visualize\n    # (see model definition at keras/applications/vgg16.py)\n    LAYER_NAME = \'block5_conv1\'\n\n    # build the VGG16 network with ImageNet weights\n    vgg = vgg16.VGG16(weights=\'imagenet\', include_top=False)\n    print(\'Model loaded.\')\n    vgg.summary()\n\n    # example function call\n    visualize_layer(vgg, LAYER_NAME)\n'"
examples/conv_lstm.py,0,"b'""""""\n#This script demonstrates the use of a convolutional LSTM network.\n\nThis network is used to predict the next frame of an artificially\ngenerated movie which contains moving squares.\n""""""\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv3D\nfrom keras.layers.convolutional_recurrent import ConvLSTM2D\nfrom keras.layers.normalization import BatchNormalization\nimport numpy as np\nimport pylab as plt\n\n# We create a layer which take as input movies of shape\n# (n_frames, width, height, channels) and returns a movie\n# of identical shape.\n\nseq = Sequential()\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   input_shape=(None, 40, 40, 1),\n                   padding=\'same\', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   padding=\'same\', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   padding=\'same\', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   padding=\'same\', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n               activation=\'sigmoid\',\n               padding=\'same\', data_format=\'channels_last\'))\nseq.compile(loss=\'binary_crossentropy\', optimizer=\'adadelta\')\n\n\n# Artificial data generation:\n# Generate movies with 3 to 7 moving squares inside.\n# The squares are of shape 1x1 or 2x2 pixels,\n# which move linearly over time.\n# For convenience we first create movies with bigger width and height (80x80)\n# and at the end we select a 40x40 window.\n\ndef generate_movies(n_samples=1200, n_frames=15):\n    row = 80\n    col = 80\n    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n                              dtype=np.float)\n\n    for i in range(n_samples):\n        # Add 3 to 7 moving squares\n        n = np.random.randint(3, 8)\n\n        for j in range(n):\n            # Initial position\n            xstart = np.random.randint(20, 60)\n            ystart = np.random.randint(20, 60)\n            # Direction of motion\n            directionx = np.random.randint(0, 3) - 1\n            directiony = np.random.randint(0, 3) - 1\n\n            # Size of the square\n            w = np.random.randint(2, 4)\n\n            for t in range(n_frames):\n                x_shift = xstart + directionx * t\n                y_shift = ystart + directiony * t\n                noisy_movies[i, t, x_shift - w: x_shift + w,\n                             y_shift - w: y_shift + w, 0] += 1\n\n                # Make it more robust by adding noise.\n                # The idea is that if during inference,\n                # the value of the pixel is not exactly one,\n                # we need to train the network to be robust and still\n                # consider it as a pixel belonging to a square.\n                if np.random.randint(0, 2):\n                    noise_f = (-1)**np.random.randint(0, 2)\n                    noisy_movies[i, t,\n                                 x_shift - w - 1: x_shift + w + 1,\n                                 y_shift - w - 1: y_shift + w + 1,\n                                 0] += noise_f * 0.1\n\n                # Shift the ground truth by 1\n                x_shift = xstart + directionx * (t + 1)\n                y_shift = ystart + directiony * (t + 1)\n                shifted_movies[i, t, x_shift - w: x_shift + w,\n                               y_shift - w: y_shift + w, 0] += 1\n\n    # Cut to a 40x40 window\n    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n    noisy_movies[noisy_movies >= 1] = 1\n    shifted_movies[shifted_movies >= 1] = 1\n    return noisy_movies, shifted_movies\n\n# Train the network\nnoisy_movies, shifted_movies = generate_movies(n_samples=1200)\nseq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n        epochs=300, validation_split=0.05)\n\n# Testing the network on one movie\n# feed it with the first 7 positions and then\n# predict the new positions\nwhich = 1004\ntrack = noisy_movies[which][:7, ::, ::, ::]\n\nfor j in range(16):\n    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n    new = new_pos[::, -1, ::, ::, ::]\n    track = np.concatenate((track, new), axis=0)\n\n\n# And then compare the predictions\n# to the ground truth\ntrack2 = noisy_movies[which][::, ::, ::, ::]\nfor i in range(15):\n    fig = plt.figure(figsize=(10, 5))\n\n    ax = fig.add_subplot(121)\n\n    if i >= 7:\n        ax.text(1, 3, \'Predictions !\', fontsize=20, color=\'w\')\n    else:\n        ax.text(1, 3, \'Initial trajectory\', fontsize=20)\n\n    toplot = track[i, ::, ::, 0]\n\n    plt.imshow(toplot)\n    ax = fig.add_subplot(122)\n    plt.text(1, 3, \'Ground truth\', fontsize=20)\n\n    toplot = track2[i, ::, ::, 0]\n    if i >= 2:\n        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n\n    plt.imshow(toplot)\n    plt.savefig(\'%i_animate.png\' % (i + 1))\n'"
examples/deep_dream.py,0,"b'\'\'\'\n#Deep Dreaming in Keras.\n\nRun the script with:\n```python\npython deep_dream.py path_to_your_base_image.jpg prefix_for_results\n```\ne.g.:\n```python\npython deep_dream.py img/mypic.jpg results/dream\n```\n\'\'\'\nfrom __future__ import print_function\n\nfrom keras.preprocessing.image import load_img, save_img, img_to_array\nimport numpy as np\nimport scipy\nimport argparse\n\nfrom keras.applications import inception_v3\nfrom keras import backend as K\n\nparser = argparse.ArgumentParser(description=\'Deep Dreams with Keras.\')\nparser.add_argument(\'base_image_path\', metavar=\'base\', type=str,\n                    help=\'Path to the image to transform.\')\nparser.add_argument(\'result_prefix\', metavar=\'res_prefix\', type=str,\n                    help=\'Prefix for the saved results.\')\n\nargs = parser.parse_args()\nbase_image_path = args.base_image_path\nresult_prefix = args.result_prefix\n\n# These are the names of the layers\n# for which we try to maximize activation,\n# as well as their weight in the final loss\n# we try to maximize.\n# You can tweak these setting to obtain new visual effects.\nsettings = {\n    \'features\': {\n        \'mixed2\': 0.2,\n        \'mixed3\': 0.5,\n        \'mixed4\': 2.,\n        \'mixed5\': 1.5,\n    },\n}\n\n\ndef preprocess_image(image_path):\n    # Util function to open, resize and format pictures\n    # into appropriate tensors.\n    img = load_img(image_path)\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = inception_v3.preprocess_input(img)\n    return img\n\n\ndef deprocess_image(x):\n    # Util function to convert a tensor into a valid image.\n    if K.image_data_format() == \'channels_first\':\n        x = x.reshape((3, x.shape[2], x.shape[3]))\n        x = x.transpose((1, 2, 0))\n    else:\n        x = x.reshape((x.shape[1], x.shape[2], 3))\n    x /= 2.\n    x += 0.5\n    x *= 255.\n    x = np.clip(x, 0, 255).astype(\'uint8\')\n    return x\n\nK.set_learning_phase(0)\n\n# Build the InceptionV3 network with our placeholder.\n# The model will be loaded with pre-trained ImageNet weights.\nmodel = inception_v3.InceptionV3(weights=\'imagenet\',\n                                 include_top=False)\ndream = model.input\nprint(\'Model loaded.\')\n\n# Get the symbolic outputs of each ""key"" layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n\n# Define the loss.\nloss = K.variable(0.)\nfor layer_name in settings[\'features\']:\n    # Add the L2 norm of the features of a layer to the loss.\n    if layer_name not in layer_dict:\n        raise ValueError(\'Layer \' + layer_name + \' not found in model.\')\n    coeff = settings[\'features\'][layer_name]\n    x = layer_dict[layer_name].output\n    # We avoid border artifacts by only involving non-border pixels in the loss.\n    scaling = K.prod(K.cast(K.shape(x), \'float32\'))\n    if K.image_data_format() == \'channels_first\':\n        loss = loss + coeff * K.sum(K.square(x[:, :, 2: -2, 2: -2])) / scaling\n    else:\n        loss = loss + coeff * K.sum(K.square(x[:, 2: -2, 2: -2, :])) / scaling\n\n# Compute the gradients of the dream wrt the loss.\ngrads = K.gradients(loss, dream)[0]\n# Normalize gradients.\ngrads /= K.maximum(K.mean(K.abs(grads)), K.epsilon())\n\n# Set up function to retrieve the value\n# of the loss and gradients given an input image.\noutputs = [loss, grads]\nfetch_loss_and_grads = K.function([dream], outputs)\n\n\ndef eval_loss_and_grads(x):\n    outs = fetch_loss_and_grads([x])\n    loss_value = outs[0]\n    grad_values = outs[1]\n    return loss_value, grad_values\n\n\ndef resize_img(img, size):\n    img = np.copy(img)\n    if K.image_data_format() == \'channels_first\':\n        factors = (1, 1,\n                   float(size[0]) / img.shape[2],\n                   float(size[1]) / img.shape[3])\n    else:\n        factors = (1,\n                   float(size[0]) / img.shape[1],\n                   float(size[1]) / img.shape[2],\n                   1)\n    return scipy.ndimage.zoom(img, factors, order=1)\n\n\ndef gradient_ascent(x, iterations, step, max_loss=None):\n    for i in range(iterations):\n        loss_value, grad_values = eval_loss_and_grads(x)\n        if max_loss is not None and loss_value > max_loss:\n            break\n        print(\'..Loss value at\', i, \':\', loss_value)\n        x += step * grad_values\n    return x\n\n\n""""""Process:\n\n- Load the original image.\n- Define a number of processing scales (i.e. image shapes),\n    from smallest to largest.\n- Resize the original image to the smallest scale.\n- For every scale, starting with the smallest (i.e. current one):\n    - Run gradient ascent\n    - Upscale image to the next scale\n    - Reinject the detail that was lost at upscaling time\n- Stop when we are back to the original size.\n\nTo obtain the detail lost during upscaling, we simply\ntake the original image, shrink it down, upscale it,\nand compare the result to the (resized) original image.\n""""""\n\n\n# Playing with these hyperparameters will also allow you to achieve new effects\nstep = 0.01  # Gradient ascent step size\nnum_octave = 3  # Number of scales at which to run gradient ascent\noctave_scale = 1.4  # Size ratio between scales\niterations = 20  # Number of ascent steps per scale\nmax_loss = 10.\n\nimg = preprocess_image(base_image_path)\nif K.image_data_format() == \'channels_first\':\n    original_shape = img.shape[2:]\nelse:\n    original_shape = img.shape[1:3]\nsuccessive_shapes = [original_shape]\nfor i in range(1, num_octave):\n    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n    successive_shapes.append(shape)\nsuccessive_shapes = successive_shapes[::-1]\noriginal_img = np.copy(img)\nshrunk_original_img = resize_img(img, successive_shapes[0])\n\nfor shape in successive_shapes:\n    print(\'Processing image shape\', shape)\n    img = resize_img(img, shape)\n    img = gradient_ascent(img,\n                          iterations=iterations,\n                          step=step,\n                          max_loss=max_loss)\n    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n    same_size_original = resize_img(original_img, shape)\n    lost_detail = same_size_original - upscaled_shrunk_original_img\n\n    img += lost_detail\n    shrunk_original_img = resize_img(original_img, shape)\n\nsave_img(result_prefix + \'.png\', deprocess_image(np.copy(img)))\n'"
examples/image_ocr.py,0,"b'# -*- coding: utf-8 -*-\n\'\'\'\n# Optical character recognition\nThis example uses a convolutional stack followed by a recurrent stack\nand a CTC logloss function to perform optical character recognition\nof generated text images. I have no evidence of whether it actually\nlearns general shapes of text, or just is able to recognize all\nthe different fonts thrown at it...the purpose is more to demonstrate CTC\ninside of Keras.  Note that the font list may need to be updated\nfor the particular OS in use.\n\nThis starts off with 4 letter words.  For the first 12 epochs, the\ndifficulty is gradually increased using the TextImageGenerator class\nwhich is both a generator class for test/train data and a Keras\ncallback class. After 20 epochs, longer sequences are thrown at it\nby recompiling the model to handle a wider image and rebuilding\nthe word list to include two words separated by a space.\n\nThe table below shows normalized edit distance values. Theano uses\na slightly different CTC implementation, hence the different results.\n\nEpoch |   TF   |   TH\n-----:|-------:|-------:\n    10|  0.027 | 0.064\n    15|  0.038 | 0.035\n    20|  0.043 | 0.045\n    25|  0.014 | 0.019\n\n# Additional dependencies\n\nThis requires ```cairo``` and ```editdistance``` packages:\n\nFirst, install the Cairo library: https://cairographics.org/\n\nThen install Python dependencies:\n\n```python\npip install cairocffi\npip install editdistance\n```\n\nCreated by Mike Henry\nhttps://github.com/mbhenry/\n\'\'\'\nimport os\nimport itertools\nimport codecs\nimport re\nimport datetime\nimport cairocffi as cairo\nimport editdistance\nimport numpy as np\nfrom scipy import ndimage\nimport pylab\nfrom keras import backend as K\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import Input, Dense, Activation\nfrom keras.layers import Reshape, Lambda\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model\nfrom keras.layers.recurrent import GRU\nfrom keras.optimizers import SGD\nfrom keras.utils.data_utils import get_file\nfrom keras.preprocessing import image\nimport keras.callbacks\n\n\nOUTPUT_DIR = \'image_ocr\'\n\n# character classes and matching regex filter\nregex = r\'^[a-z ]+$\'\nalphabet = u\'abcdefghijklmnopqrstuvwxyz \'\n\nnp.random.seed(55)\n\n\n# this creates larger ""blotches"" of noise which look\n# more realistic than just adding gaussian noise\n# assumes greyscale with pixels ranging from 0 to 1\n\ndef speckle(img):\n    severity = np.random.uniform(0, 0.6)\n    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n    img_speck = (img + blur)\n    img_speck[img_speck > 1] = 1\n    img_speck[img_speck <= 0] = 0\n    return img_speck\n\n\n# paints the string in a random location the bounding box\n# also uses a random font, a slight random rotation,\n# and a random amount of speckle noise\n\ndef paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n    with cairo.Context(surface) as context:\n        context.set_source_rgb(1, 1, 1)  # White\n        context.paint()\n        # this font list works in CentOS 7\n        if multi_fonts:\n            fonts = [\n                \'Century Schoolbook\', \'Courier\', \'STIX\',\n                \'URW Chancery L\', \'FreeMono\']\n            context.select_font_face(\n                np.random.choice(fonts),\n                cairo.FONT_SLANT_NORMAL,\n                np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n        else:\n            context.select_font_face(\'Courier\',\n                                     cairo.FONT_SLANT_NORMAL,\n                                     cairo.FONT_WEIGHT_BOLD)\n        context.set_font_size(25)\n        box = context.text_extents(text)\n        border_w_h = (4, 4)\n        if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n            raise IOError((\'Could not fit string into image.\'\n                           \'Max char count is too large for given image width.\'))\n\n        # teach the RNN translational invariance by\n        # fitting text box randomly on canvas, with some room to rotate\n        max_shift_x = w - box[2] - border_w_h[0]\n        max_shift_y = h - box[3] - border_w_h[1]\n        top_left_x = np.random.randint(0, int(max_shift_x))\n        if ud:\n            top_left_y = np.random.randint(0, int(max_shift_y))\n        else:\n            top_left_y = h // 2\n        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n        context.set_source_rgb(0, 0, 0)\n        context.show_text(text)\n\n    buf = surface.get_data()\n    a = np.frombuffer(buf, np.uint8)\n    a.shape = (h, w, 4)\n    a = a[:, :, 0]  # grab single channel\n    a = a.astype(np.float32) / 255\n    a = np.expand_dims(a, 0)\n    if rotate:\n        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n    a = speckle(a)\n\n    return a\n\n\ndef shuffle_mats_or_lists(matrix_list, stop_ind=None):\n    ret = []\n    assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n    len_val = len(matrix_list[0])\n    if stop_ind is None:\n        stop_ind = len_val\n    assert stop_ind <= len_val\n\n    a = list(range(stop_ind))\n    np.random.shuffle(a)\n    a += list(range(stop_ind, len_val))\n    for mat in matrix_list:\n        if isinstance(mat, np.ndarray):\n            ret.append(mat[a])\n        elif isinstance(mat, list):\n            ret.append([mat[i] for i in a])\n        else:\n            raise TypeError(\'`shuffle_mats_or_lists` only supports \'\n                            \'numpy.array and list objects.\')\n    return ret\n\n\n# Translation of characters to unique integer values\ndef text_to_labels(text):\n    ret = []\n    for char in text:\n        ret.append(alphabet.find(char))\n    return ret\n\n\n# Reverse translation of numerical classes back to characters\ndef labels_to_text(labels):\n    ret = []\n    for c in labels:\n        if c == len(alphabet):  # CTC Blank\n            ret.append("""")\n        else:\n            ret.append(alphabet[c])\n    return """".join(ret)\n\n\n# only a-z and space..probably not to difficult\n# to expand to uppercase and symbols\n\ndef is_valid_str(in_str):\n    search = re.compile(regex, re.UNICODE).search\n    return bool(search(in_str))\n\n\n# Uses generator functions to supply train/test with\n# data. Image renderings and text are created on the fly\n# each time with random perturbations\n\nclass TextImageGenerator(keras.callbacks.Callback):\n\n    def __init__(self, monogram_file, bigram_file, minibatch_size,\n                 img_w, img_h, downsample_factor, val_split,\n                 absolute_max_string_len=16):\n\n        self.minibatch_size = minibatch_size\n        self.img_w = img_w\n        self.img_h = img_h\n        self.monogram_file = monogram_file\n        self.bigram_file = bigram_file\n        self.downsample_factor = downsample_factor\n        self.val_split = val_split\n        self.blank_label = self.get_output_size() - 1\n        self.absolute_max_string_len = absolute_max_string_len\n\n    def get_output_size(self):\n        return len(alphabet) + 1\n\n    # num_words can be independent of the epoch size due to the use of generators\n    # as max_string_len grows, num_words can grow\n    def build_word_list(self, num_words, max_string_len=None, mono_fraction=0.5):\n        assert max_string_len <= self.absolute_max_string_len\n        assert num_words % self.minibatch_size == 0\n        assert (self.val_split * num_words) % self.minibatch_size == 0\n        self.num_words = num_words\n        self.string_list = [\'\'] * self.num_words\n        tmp_string_list = []\n        self.max_string_len = max_string_len\n        self.Y_data = np.ones([self.num_words, self.absolute_max_string_len]) * -1\n        self.X_text = []\n        self.Y_len = [0] * self.num_words\n\n        def _is_length_of_word_valid(word):\n            return (max_string_len == -1 or\n                    max_string_len is None or\n                    len(word) <= max_string_len)\n\n        # monogram file is sorted by frequency in english speech\n        with codecs.open(self.monogram_file, mode=\'r\', encoding=\'utf-8\') as f:\n            for line in f:\n                if len(tmp_string_list) == int(self.num_words * mono_fraction):\n                    break\n                word = line.rstrip()\n                if _is_length_of_word_valid(word):\n                    tmp_string_list.append(word)\n\n        # bigram file contains common word pairings in english speech\n        with codecs.open(self.bigram_file, mode=\'r\', encoding=\'utf-8\') as f:\n            lines = f.readlines()\n            for line in lines:\n                if len(tmp_string_list) == self.num_words:\n                    break\n                columns = line.lower().split()\n                word = columns[0] + \' \' + columns[1]\n                if is_valid_str(word) and _is_length_of_word_valid(word):\n                    tmp_string_list.append(word)\n        if len(tmp_string_list) != self.num_words:\n            raise IOError(\'Could not pull enough words\'\n                          \'from supplied monogram and bigram files.\')\n        # interlace to mix up the easy and hard words\n        self.string_list[::2] = tmp_string_list[:self.num_words // 2]\n        self.string_list[1::2] = tmp_string_list[self.num_words // 2:]\n\n        for i, word in enumerate(self.string_list):\n            self.Y_len[i] = len(word)\n            self.Y_data[i, 0:len(word)] = text_to_labels(word)\n            self.X_text.append(word)\n        self.Y_len = np.expand_dims(np.array(self.Y_len), 1)\n\n        self.cur_val_index = self.val_split\n        self.cur_train_index = 0\n\n    # each time an image is requested from train/val/test, a new random\n    # painting of the text is performed\n    def get_batch(self, index, size, train):\n        # width and height are backwards from typical Keras convention\n        # because width is the time dimension when it gets fed into the RNN\n        if K.image_data_format() == \'channels_first\':\n            X_data = np.ones([size, 1, self.img_w, self.img_h])\n        else:\n            X_data = np.ones([size, self.img_w, self.img_h, 1])\n\n        labels = np.ones([size, self.absolute_max_string_len])\n        input_length = np.zeros([size, 1])\n        label_length = np.zeros([size, 1])\n        source_str = []\n        for i in range(size):\n            # Mix in some blank inputs.  This seems to be important for\n            # achieving translational invariance\n            if train and i > size - 4:\n                if K.image_data_format() == \'channels_first\':\n                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(\'\')[0, :, :].T\n                else:\n                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(\'\',)[0, :, :].T\n                labels[i, 0] = self.blank_label\n                input_length[i] = self.img_w // self.downsample_factor - 2\n                label_length[i] = 1\n                source_str.append(\'\')\n            else:\n                if K.image_data_format() == \'channels_first\':\n                    X_data[i, 0, 0:self.img_w, :] = (\n                        self.paint_func(self.X_text[index + i])[0, :, :].T)\n                else:\n                    X_data[i, 0:self.img_w, :, 0] = (\n                        self.paint_func(self.X_text[index + i])[0, :, :].T)\n                labels[i, :] = self.Y_data[index + i]\n                input_length[i] = self.img_w // self.downsample_factor - 2\n                label_length[i] = self.Y_len[index + i]\n                source_str.append(self.X_text[index + i])\n        inputs = {\'the_input\': X_data,\n                  \'the_labels\': labels,\n                  \'input_length\': input_length,\n                  \'label_length\': label_length,\n                  \'source_str\': source_str  # used for visualization only\n                  }\n        outputs = {\'ctc\': np.zeros([size])}  # dummy data for dummy loss function\n        return (inputs, outputs)\n\n    def next_train(self):\n        while 1:\n            ret = self.get_batch(self.cur_train_index,\n                                 self.minibatch_size, train=True)\n            self.cur_train_index += self.minibatch_size\n            if self.cur_train_index >= self.val_split:\n                self.cur_train_index = self.cur_train_index % 32\n                (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists(\n                    [self.X_text, self.Y_data, self.Y_len], self.val_split)\n            yield ret\n\n    def next_val(self):\n        while 1:\n            ret = self.get_batch(self.cur_val_index,\n                                 self.minibatch_size, train=False)\n            self.cur_val_index += self.minibatch_size\n            if self.cur_val_index >= self.num_words:\n                self.cur_val_index = self.val_split + self.cur_val_index % 32\n            yield ret\n\n    def on_train_begin(self, logs={}):\n        self.build_word_list(16000, 4, 1)\n        self.paint_func = lambda text: paint_text(\n            text, self.img_w, self.img_h,\n            rotate=False, ud=False, multi_fonts=False)\n\n    def on_epoch_begin(self, epoch, logs={}):\n        # rebind the paint function to implement curriculum learning\n        if 3 <= epoch < 6:\n            self.paint_func = lambda text: paint_text(\n                text, self.img_w, self.img_h,\n                rotate=False, ud=True, multi_fonts=False)\n        elif 6 <= epoch < 9:\n            self.paint_func = lambda text: paint_text(\n                text, self.img_w, self.img_h,\n                rotate=False, ud=True, multi_fonts=True)\n        elif epoch >= 9:\n            self.paint_func = lambda text: paint_text(\n                text, self.img_w, self.img_h,\n                rotate=True, ud=True, multi_fonts=True)\n        if epoch >= 21 and self.max_string_len < 12:\n            self.build_word_list(32000, 12, 0.5)\n\n\n# the actual loss calc occurs here despite it not being\n# an internal Keras loss function\n\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage:\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n# For a real OCR application, this should be beam search with a dictionary\n# and language model.  For this example, best path is sufficient.\n\ndef decode_batch(test_func, word_batch):\n    out = test_func([word_batch])[0]\n    ret = []\n    for j in range(out.shape[0]):\n        out_best = list(np.argmax(out[j, 2:], 1))\n        out_best = [k for k, g in itertools.groupby(out_best)]\n        outstr = labels_to_text(out_best)\n        ret.append(outstr)\n    return ret\n\n\nclass VizCallback(keras.callbacks.Callback):\n\n    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n        self.test_func = test_func\n        self.output_dir = os.path.join(\n            OUTPUT_DIR, run_name)\n        self.text_img_gen = text_img_gen\n        self.num_display_words = num_display_words\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n\n    def show_edit_distance(self, num):\n        num_left = num\n        mean_norm_ed = 0.0\n        mean_ed = 0.0\n        while num_left > 0:\n            word_batch = next(self.text_img_gen)[0]\n            num_proc = min(word_batch[\'the_input\'].shape[0], num_left)\n            decoded_res = decode_batch(self.test_func,\n                                       word_batch[\'the_input\'][0:num_proc])\n            for j in range(num_proc):\n                edit_dist = editdistance.eval(decoded_res[j],\n                                              word_batch[\'source_str\'][j])\n                mean_ed += float(edit_dist)\n                mean_norm_ed += float(edit_dist) / len(word_batch[\'source_str\'][j])\n            num_left -= num_proc\n        mean_norm_ed = mean_norm_ed / num\n        mean_ed = mean_ed / num\n        print(\'\\nOut of %d samples:  Mean edit distance:\'\n              \'%.3f Mean normalized edit distance: %0.3f\'\n              % (num, mean_ed, mean_norm_ed))\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.model.save_weights(\n            os.path.join(self.output_dir, \'weights%02d.h5\' % (epoch)))\n        self.show_edit_distance(256)\n        word_batch = next(self.text_img_gen)[0]\n        res = decode_batch(self.test_func,\n                           word_batch[\'the_input\'][0:self.num_display_words])\n        if word_batch[\'the_input\'][0].shape[0] < 256:\n            cols = 2\n        else:\n            cols = 1\n        for i in range(self.num_display_words):\n            pylab.subplot(self.num_display_words // cols, cols, i + 1)\n            if K.image_data_format() == \'channels_first\':\n                the_input = word_batch[\'the_input\'][i, 0, :, :]\n            else:\n                the_input = word_batch[\'the_input\'][i, :, :, 0]\n            pylab.imshow(the_input.T, cmap=\'Greys_r\')\n            pylab.xlabel(\n                \'Truth = \\\'%s\\\'\\nDecoded = \\\'%s\\\'\' %\n                (word_batch[\'source_str\'][i], res[i]))\n        fig = pylab.gcf()\n        fig.set_size_inches(10, 13)\n        pylab.savefig(os.path.join(self.output_dir, \'e%02d.png\' % (epoch)))\n        pylab.close()\n\n\ndef train(run_name, start_epoch, stop_epoch, img_w):\n    # Input Parameters\n    img_h = 64\n    words_per_epoch = 16000\n    val_split = 0.2\n    val_words = int(words_per_epoch * (val_split))\n\n    # Network parameters\n    conv_filters = 16\n    kernel_size = (3, 3)\n    pool_size = 2\n    time_dense_size = 32\n    rnn_size = 512\n    minibatch_size = 32\n\n    if K.image_data_format() == \'channels_first\':\n        input_shape = (1, img_w, img_h)\n    else:\n        input_shape = (img_w, img_h, 1)\n\n    fdir = os.path.dirname(\n        get_file(\'wordlists.tgz\',\n                 origin=\'http://www.mythic-ai.com/datasets/wordlists.tgz\',\n                 untar=True))\n\n    img_gen = TextImageGenerator(\n        monogram_file=os.path.join(fdir, \'wordlist_mono_clean.txt\'),\n        bigram_file=os.path.join(fdir, \'wordlist_bi_clean.txt\'),\n        minibatch_size=minibatch_size,\n        img_w=img_w,\n        img_h=img_h,\n        downsample_factor=(pool_size ** 2),\n        val_split=words_per_epoch - val_words)\n    act = \'relu\'\n    input_data = Input(name=\'the_input\', shape=input_shape, dtype=\'float32\')\n    inner = Conv2D(conv_filters, kernel_size, padding=\'same\',\n                   activation=act, kernel_initializer=\'he_normal\',\n                   name=\'conv1\')(input_data)\n    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name=\'max1\')(inner)\n    inner = Conv2D(conv_filters, kernel_size, padding=\'same\',\n                   activation=act, kernel_initializer=\'he_normal\',\n                   name=\'conv2\')(inner)\n    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name=\'max2\')(inner)\n\n    conv_to_rnn_dims = (img_w // (pool_size ** 2),\n                        (img_h // (pool_size ** 2)) * conv_filters)\n    inner = Reshape(target_shape=conv_to_rnn_dims, name=\'reshape\')(inner)\n\n    # cuts down input size going into RNN:\n    inner = Dense(time_dense_size, activation=act, name=\'dense1\')(inner)\n\n    # Two layers of bidirectional GRUs\n    # GRU seems to work as well, if not better than LSTM:\n    gru_1 = GRU(rnn_size, return_sequences=True,\n                kernel_initializer=\'he_normal\', name=\'gru1\')(inner)\n    gru_1b = GRU(rnn_size, return_sequences=True,\n                 go_backwards=True, kernel_initializer=\'he_normal\',\n                 name=\'gru1_b\')(inner)\n    gru1_merged = add([gru_1, gru_1b])\n    gru_2 = GRU(rnn_size, return_sequences=True,\n                kernel_initializer=\'he_normal\', name=\'gru2\')(gru1_merged)\n    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n                 kernel_initializer=\'he_normal\', name=\'gru2_b\')(gru1_merged)\n\n    # transforms RNN output to character activations:\n    inner = Dense(img_gen.get_output_size(), kernel_initializer=\'he_normal\',\n                  name=\'dense2\')(concatenate([gru_2, gru_2b]))\n    y_pred = Activation(\'softmax\', name=\'softmax\')(inner)\n    Model(inputs=input_data, outputs=y_pred).summary()\n\n    labels = Input(name=\'the_labels\',\n                   shape=[img_gen.absolute_max_string_len], dtype=\'float32\')\n    input_length = Input(name=\'input_length\', shape=[1], dtype=\'int64\')\n    label_length = Input(name=\'label_length\', shape=[1], dtype=\'int64\')\n    # Keras doesn\'t currently support loss funcs with extra parameters\n    # so CTC loss is implemented in a lambda layer\n    loss_out = Lambda(\n        ctc_lambda_func, output_shape=(1,),\n        name=\'ctc\')([y_pred, labels, input_length, label_length])\n\n    # clipnorm seems to speeds up convergence\n    sgd = SGD(learning_rate=0.02,\n              decay=1e-6,\n              momentum=0.9,\n              nesterov=True)\n\n    model = Model(inputs=[input_data, labels, input_length, label_length],\n                  outputs=loss_out)\n\n    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n    model.compile(loss={\'ctc\': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n    if start_epoch > 0:\n        weight_file = os.path.join(\n            OUTPUT_DIR,\n            os.path.join(run_name, \'weights%02d.h5\' % (start_epoch - 1)))\n        model.load_weights(weight_file)\n    # captures output of softmax so we can decode the output during visualization\n    test_func = K.function([input_data], [y_pred])\n\n    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n\n    model.fit_generator(\n        generator=img_gen.next_train(),\n        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,\n        epochs=stop_epoch,\n        validation_data=img_gen.next_val(),\n        validation_steps=val_words // minibatch_size,\n        callbacks=[viz_cb, img_gen],\n        initial_epoch=start_epoch)\n\n\nif __name__ == \'__main__\':\n    run_name = datetime.datetime.now().strftime(\'%Y:%m:%d:%H:%M:%S\')\n    train(run_name, 0, 20, 128)\n    # increase to wider images and start at epoch 20.\n    # The learned weights are reloaded\n    train(run_name, 20, 25, 512)\n'"
examples/imdb_bidirectional_lstm.py,0,"b""'''\n#Trains a Bidirectional LSTM on the IMDB sentiment classification task.\n\nOutput after 4 epochs on CPU: ~0.8146\nTime per epoch on CPU (Core i7): ~150s.\n'''\n\nfrom __future__ import print_function\nimport numpy as np\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\nfrom keras.datasets import imdb\n\n\nmax_features = 20000\n# cut texts after this number of words\n# (among top max_features most common words)\nmaxlen = 100\nbatch_size = 32\n\nprint('Loading data...')\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(x_train), 'train sequences')\nprint(len(x_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128, input_length=maxlen))\nmodel.add(Bidirectional(LSTM(64)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# try using different optimizers and different optimizer configs\nmodel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n\nprint('Train...')\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=4,\n          validation_data=[x_test, y_test])\n"""
examples/imdb_cnn.py,0,"b""'''\n#This example demonstrates the use of Convolution1D for text classification.\n\nGets to 0.89 test accuracy after 2 epochs. </br>\n90s/epoch on Intel i5 2.4Ghz CPU. </br>\n10s/epoch on Tesla K40 GPU.\n'''\nfrom __future__ import print_function\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import Conv1D, GlobalMaxPooling1D\nfrom keras.datasets import imdb\n\n# set parameters:\nmax_features = 5000\nmaxlen = 400\nbatch_size = 32\nembedding_dims = 50\nfilters = 250\nkernel_size = 3\nhidden_dims = 250\nepochs = 2\n\nprint('Loading data...')\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(x_train), 'train sequences')\nprint(len(x_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n\nprint('Build model...')\nmodel = Sequential()\n\n# we start off with an efficient embedding layer which maps\n# our vocab indices into embedding_dims dimensions\nmodel.add(Embedding(max_features,\n                    embedding_dims,\n                    input_length=maxlen))\nmodel.add(Dropout(0.2))\n\n# we add a Convolution1D, which will learn filters\n# word group filters of size filter_length:\nmodel.add(Conv1D(filters,\n                 kernel_size,\n                 padding='valid',\n                 activation='relu',\n                 strides=1))\n# we use max pooling:\nmodel.add(GlobalMaxPooling1D())\n\n# We add a vanilla hidden layer:\nmodel.add(Dense(hidden_dims))\nmodel.add(Dropout(0.2))\nmodel.add(Activation('relu'))\n\n# We project onto a single unit output layer, and squash it with a sigmoid:\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(x_test, y_test))\n"""
examples/imdb_cnn_lstm.py,0,"b""'''\n#Train a recurrent convolutional network on the IMDB sentiment classification task.\n\nGets to 0.8498 test accuracy after 2 epochs. 41 s/epoch on K520 GPU.\n'''\nfrom __future__ import print_function\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\nfrom keras.layers import Conv1D, MaxPooling1D\nfrom keras.datasets import imdb\n\n# Embedding\nmax_features = 20000\nmaxlen = 100\nembedding_size = 128\n\n# Convolution\nkernel_size = 5\nfilters = 64\npool_size = 4\n\n# LSTM\nlstm_output_size = 70\n\n# Training\nbatch_size = 30\nepochs = 2\n\n'''\nNote:\nbatch_size is highly sensitive.\nOnly 2 epochs are needed as the dataset is very small.\n'''\n\nprint('Loading data...')\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(x_train), 'train sequences')\nprint(len(x_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n\nprint('Build model...')\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, embedding_size, input_length=maxlen))\nmodel.add(Dropout(0.25))\nmodel.add(Conv1D(filters,\n                 kernel_size,\n                 padding='valid',\n                 activation='relu',\n                 strides=1))\nmodel.add(MaxPooling1D(pool_size=pool_size))\nmodel.add(LSTM(lstm_output_size))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nprint('Train...')\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n"""
examples/imdb_fasttext.py,0,"b'\'\'\'\n#This example demonstrates the use of fasttext for text classification\n\nBased on Joulin et al\'s paper:\n\n[Bags of Tricks for Efficient Text Classification\n](https://arxiv.org/abs/1607.01759)\n\nResults on IMDB datasets with uni and bi-gram embeddings:\n\nEmbedding|Accuracy, 5 epochs|Speed (s/epoch)|Hardware\n:--------|-----------------:|----:|:-------\nUni-gram |            0.8813|    8|i7 CPU\nBi-gram  |            0.9056|    2|GTx 980M GPU\n\n\'\'\'\n\nfrom __future__ import print_function\nimport numpy as np\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Embedding\nfrom keras.layers import GlobalAveragePooling1D\nfrom keras.datasets import imdb\n\n\ndef create_ngram_set(input_list, ngram_value=2):\n    """"""\n    Extract a set of n-grams from a list of integers.\n\n    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n    {(4, 9), (4, 1), (1, 4), (9, 4)}\n\n    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n    """"""\n    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n\n\ndef add_ngram(sequences, token_indice, ngram_range=2):\n    """"""\n    Augment the input list of list (sequences) by appending n-grams values.\n\n    Example: adding bi-gram\n    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n    >>> add_ngram(sequences, token_indice, ngram_range=2)\n    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n\n    Example: adding tri-gram\n    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n    >>> add_ngram(sequences, token_indice, ngram_range=3)\n    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n    """"""\n    new_sequences = []\n    for input_list in sequences:\n        new_list = input_list[:]\n        for ngram_value in range(2, ngram_range + 1):\n            for i in range(len(new_list) - ngram_value + 1):\n                ngram = tuple(new_list[i:i + ngram_value])\n                if ngram in token_indice:\n                    new_list.append(token_indice[ngram])\n        new_sequences.append(new_list)\n\n    return new_sequences\n\n# Set parameters:\n# ngram_range = 2 will add bi-grams features\nngram_range = 1\nmax_features = 20000\nmaxlen = 400\nbatch_size = 32\nembedding_dims = 50\nepochs = 5\n\nprint(\'Loading data...\')\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(x_train), \'train sequences\')\nprint(len(x_test), \'test sequences\')\nprint(\'Average train sequence length: {}\'.format(\n    np.mean(list(map(len, x_train)), dtype=int)))\nprint(\'Average test sequence length: {}\'.format(\n    np.mean(list(map(len, x_test)), dtype=int)))\n\nif ngram_range > 1:\n    print(\'Adding {}-gram features\'.format(ngram_range))\n    # Create set of unique n-gram from the training set.\n    ngram_set = set()\n    for input_list in x_train:\n        for i in range(2, ngram_range + 1):\n            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n            ngram_set.update(set_of_ngram)\n\n    # Dictionary mapping n-gram token to a unique integer.\n    # Integer values are greater than max_features in order\n    # to avoid collision with existing features.\n    start_index = max_features + 1\n    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n    indice_token = {token_indice[k]: k for k in token_indice}\n\n    # max_features is the highest integer that could be found in the dataset.\n    max_features = np.max(list(indice_token.keys())) + 1\n\n    # Augmenting x_train and x_test with n-grams features\n    x_train = add_ngram(x_train, token_indice, ngram_range)\n    x_test = add_ngram(x_test, token_indice, ngram_range)\n    print(\'Average train sequence length: {}\'.format(\n        np.mean(list(map(len, x_train)), dtype=int)))\n    print(\'Average test sequence length: {}\'.format(\n        np.mean(list(map(len, x_test)), dtype=int)))\n\nprint(\'Pad sequences (samples x time)\')\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint(\'x_train shape:\', x_train.shape)\nprint(\'x_test shape:\', x_test.shape)\n\nprint(\'Build model...\')\nmodel = Sequential()\n\n# we start off with an efficient embedding layer which maps\n# our vocab indices into embedding_dims dimensions\nmodel.add(Embedding(max_features,\n                    embedding_dims,\n                    input_length=maxlen))\n\n# we add a GlobalAveragePooling1D, which will average the embeddings\n# of all words in the document\nmodel.add(GlobalAveragePooling1D())\n\n# We project onto a single unit output layer, and squash it with a sigmoid:\nmodel.add(Dense(1, activation=\'sigmoid\'))\n\nmodel.compile(loss=\'binary_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(x_test, y_test))\n'"
examples/imdb_lstm.py,0,"b""'''\n#Trains an LSTM model on the IMDB sentiment classification task.\n\nThe dataset is actually too small for LSTM to be of any advantage\ncompared to simpler, much faster methods such as TF-IDF + LogReg.\n\n**Notes**\n\n- RNNs are tricky. Choice of batch size is important,\nchoice of loss and optimizer is critical, etc.\nSome configurations won't converge.\n\n- LSTM loss decrease patterns during training can be quite different\nfrom what you see with CNNs/MLPs/etc.\n\n'''\nfrom __future__ import print_function\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding\nfrom keras.layers import LSTM\nfrom keras.datasets import imdb\n\nmax_features = 20000\n# cut texts after this number of words (among top max_features most common words)\nmaxlen = 80\nbatch_size = 32\n\nprint('Loading data...')\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(x_train), 'train sequences')\nprint(len(x_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n\nprint('Build model...')\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# try using different optimizers and different optimizer configs\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nprint('Train...')\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=15,\n          validation_data=(x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test,\n                            batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n"""
examples/lstm_seq2seq.py,0,"b'\'\'\'\n#Sequence to sequence example in Keras (character-level).\n\nThis script demonstrates how to implement a basic character-level\nsequence-to-sequence model. We apply it to translating\nshort English sentences into short French sentences,\ncharacter-by-character. Note that it is fairly unusual to\ndo character-level machine translation, as word-level\nmodels are more common in this domain.\n\n**Summary of the algorithm**\n\n- We start with input sequences from a domain (e.g. English sentences)\n    and corresponding target sequences from another domain\n    (e.g. French sentences).\n- An encoder LSTM turns input sequences to 2 state vectors\n    (we keep the last LSTM state and discard the outputs).\n- A decoder LSTM is trained to turn the target sequences into\n    the same sequence but offset by one timestep in the future,\n    a training process called ""teacher forcing"" in this context.\n    It uses as initial state the state vectors from the encoder.\n    Effectively, the decoder learns to generate `targets[t+1...]`\n    given `targets[...t]`, conditioned on the input sequence.\n- In inference mode, when we want to decode unknown input sequences, we:\n    - Encode the input sequence into state vectors\n    - Start with a target sequence of size 1\n        (just the start-of-sequence character)\n    - Feed the state vectors and 1-char target sequence\n        to the decoder to produce predictions for the next character\n    - Sample the next character using these predictions\n        (we simply use argmax).\n    - Append the sampled character to the target sequence\n    - Repeat until we generate the end-of-sequence character or we\n        hit the character limit.\n\n**Data download**\n\n[English to French sentence pairs.\n](http://www.manythings.org/anki/fra-eng.zip)\n\n[Lots of neat sentence pairs datasets.\n](http://www.manythings.org/anki/)\n\n**References**\n\n- [Sequence to Sequence Learning with Neural Networks\n   ](https://arxiv.org/abs/1409.3215)\n- [Learning Phrase Representations using\n    RNN Encoder-Decoder for Statistical Machine Translation\n    ](https://arxiv.org/abs/1406.1078)\n\'\'\'\nfrom __future__ import print_function\n\nfrom keras.models import Model\nfrom keras.layers import Input, LSTM, Dense\nimport numpy as np\n\nbatch_size = 64  # Batch size for training.\nepochs = 100  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = 10000  # Number of samples to train on.\n# Path to the data txt file on disk.\ndata_path = \'fra-eng/fra.txt\'\n\n# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, \'r\', encoding=\'utf-8\') as f:\n    lines = f.read().split(\'\\n\')\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text, _ = line.split(\'\\t\')\n    # We use ""tab"" as the ""start sequence"" character\n    # for the targets, and ""\\n"" as ""end sequence"" character.\n    target_text = \'\\t\' + target_text + \'\\n\'\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint(\'Number of samples:\', len(input_texts))\nprint(\'Number of unique input tokens:\', num_encoder_tokens)\nprint(\'Number of unique output tokens:\', num_decoder_tokens)\nprint(\'Max sequence length for inputs:\', max_encoder_seq_length)\nprint(\'Max sequence length for outputs:\', max_decoder_seq_length)\n\ninput_token_index = dict(\n    [(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict(\n    [(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n    dtype=\'float32\')\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\'float32\')\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\'float32\')\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.\n    encoder_input_data[i, t + 1:, input_token_index[\' \']] = 1.\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token_index[char]] = 1.\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n    decoder_input_data[i, t + 1:, target_token_index[\' \']] = 1.\n    decoder_target_data[i, t:, target_token_index[\' \']] = 1.\n# Define an input sequence and process it.\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nencoder = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don\'t use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation=\'softmax\')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n# Run training\nmodel.compile(optimizer=\'rmsprop\', loss=\'categorical_crossentropy\',\n              metrics=[\'accuracy\'])\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.2)\n# Save model\nmodel.save(\'s2s.h5\')\n\n# Next: inference mode (sampling).\n# Here\'s the drill:\n# 1) encode input and retrieve initial decoder state\n# 2) run one step of decoder with this initial state\n# and a ""start of sequence"" token as target.\n# Output will be the next target token\n# 3) Repeat with the current target token and current states\n\n# Define sampling models\nencoder_model = Model(encoder_inputs, encoder_states)\n\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_outputs, state_h, state_c = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs] + decoder_states)\n\n# Reverse-lookup token index to decode sequences back to\n# something readable.\nreverse_input_char_index = dict(\n    (i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict(\n    (i, char) for char, i in target_token_index.items())\n\n\ndef decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0, target_token_index[\'\\t\']] = 1.\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = \'\'\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict(\n            [target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == \'\\n\' or\n           len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence\n\n\nfor seq_index in range(100):\n    # Take one sequence (part of the training set)\n    # for trying out decoding.\n    input_seq = encoder_input_data[seq_index: seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print(\'-\')\n    print(\'Input sentence:\', input_texts[seq_index])\n    print(\'Decoded sentence:\', decoded_sentence)\n'"
examples/lstm_seq2seq_restore.py,0,"b'\'\'\'\n#Restore a character-level sequence to sequence model from to generate predictions.\n\nThis script loads the ```s2s.h5``` model saved by [lstm_seq2seq.py\n](/examples/lstm_seq2seq/) and generates sequences from it. It assumes\nthat no changes have been made (for example: ```latent_dim``` is unchanged,\nand the input data and model architecture are unchanged).\n\nSee [lstm_seq2seq.py](/examples/lstm_seq2seq/) for more details on the\nmodel architecture and how it is trained.\n\'\'\'\nfrom __future__ import print_function\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nimport numpy as np\n\nbatch_size = 64  # Batch size for training.\nepochs = 100  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = 10000  # Number of samples to train on.\n# Path to the data txt file on disk.\ndata_path = \'fra-eng/fra.txt\'\n\n# Vectorize the data.  We use the same approach as the training script.\n# NOTE: the data must be identical, in order for the character -> integer\n# mappings to be consistent.\n# We omit encoding target_texts since they are not needed.\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, \'r\', encoding=\'utf-8\') as f:\n    lines = f.read().split(\'\\n\')\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text, _ = line.split(\'\\t\')\n    # We use ""tab"" as the ""start sequence"" character\n    # for the targets, and ""\\n"" as ""end sequence"" character.\n    target_text = \'\\t\' + target_text + \'\\n\'\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint(\'Number of samples:\', len(input_texts))\nprint(\'Number of unique input tokens:\', num_encoder_tokens)\nprint(\'Number of unique output tokens:\', num_decoder_tokens)\nprint(\'Max sequence length for inputs:\', max_encoder_seq_length)\nprint(\'Max sequence length for outputs:\', max_decoder_seq_length)\n\ninput_token_index = dict(\n    [(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict(\n    [(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n    dtype=\'float32\')\n\nfor i, input_text in enumerate(input_texts):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.\n\n# Restore the model and construct the encoder and decoder.\nmodel = load_model(\'s2s.h5\')\n\nencoder_inputs = model.input[0]   # input_1\nencoder_outputs, state_h_enc, state_c_enc = model.layers[2].output   # lstm_1\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = Model(encoder_inputs, encoder_states)\n\ndecoder_inputs = model.input[1]   # input_2\ndecoder_state_input_h = Input(shape=(latent_dim,), name=\'input_3\')\ndecoder_state_input_c = Input(shape=(latent_dim,), name=\'input_4\')\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_lstm = model.layers[3]\ndecoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_h_dec, state_c_dec]\ndecoder_dense = model.layers[4]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs] + decoder_states)\n\n# Reverse-lookup token index to decode sequences back to\n# something readable.\nreverse_input_char_index = dict(\n    (i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict(\n    (i, char) for char, i in target_token_index.items())\n\n\n# Decodes an input sequence.  Future work should support beam search.\ndef decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0, target_token_index[\'\\t\']] = 1.\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = \'\'\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict(\n            [target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == \'\\n\' or\n           len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence\n\n\nfor seq_index in range(100):\n    # Take one sequence (part of the training set)\n    # for trying out decoding.\n    input_seq = encoder_input_data[seq_index: seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print(\'-\')\n    print(\'Input sentence:\', input_texts[seq_index])\n    print(\'Decoded sentence:\', decoded_sentence)\n'"
examples/lstm_stateful.py,0,"b'\'\'\'\n#How to use a stateful LSTM model, stateful vs stateless LSTM performance comparison\n\n[More documentation about the Keras LSTM model](/layers/recurrent/#lstm)\n\nThe models are trained on an input/output pair, where\nthe input is a generated uniformly distributed\nrandom sequence of length = `input_len`,\nand the output is a moving average of the input with window length = `tsteps`.\nBoth `input_len` and `tsteps` are defined in the ""editable parameters""\nsection.\n\nA larger `tsteps` value means that the LSTM will need more memory\nto figure out the input-output relationship.\nThis memory length is controlled by the `lahead` variable (more details below).\n\nThe rest of the parameters are:\n\n- `input_len`: the length of the generated input sequence\n- `lahead`: the input sequence length that the LSTM\n  is trained on for each output point\n- `batch_size`, `epochs`: same parameters as in the `model.fit(...)`\n  function\n\nWhen `lahead > 1`, the model input is preprocessed to a ""rolling window view""\nof the data, with the window length = `lahead`.\nThis is similar to sklearn\'s `view_as_windows`\nwith `window_shape` [being a single number.](\nhttp://scikit-image.org/docs/0.10.x/api/skimage.util.html#view-as-windows)\n\nWhen `lahead < tsteps`, only the stateful LSTM converges because its\nstatefulness allows it to see beyond the capability that lahead\ngave it to fit the n-point average. The stateless LSTM does not have\nthis capability, and hence is limited by its `lahead` parameter,\nwhich is not sufficient to see the n-point average.\n\nWhen `lahead >= tsteps`, both the stateful and stateless LSTM converge.\n\'\'\'\nfrom __future__ import print_function\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# ----------------------------------------------------------\n# EDITABLE PARAMETERS\n# Read the documentation in the script head for more details\n# ----------------------------------------------------------\n\n# length of input\ninput_len = 1000\n\n# The window length of the moving average used to generate\n# the output from the input in the input/output pair used\n# to train the LSTM\n# e.g. if tsteps=2 and input=[1, 2, 3, 4, 5],\n#      then output=[1.5, 2.5, 3.5, 4.5]\ntsteps = 2\n\n# The input sequence length that the LSTM is trained on for each output point\nlahead = 1\n\n# training parameters passed to ""model.fit(...)""\nbatch_size = 1\nepochs = 10\n\n# ------------\n# MAIN PROGRAM\n# ------------\n\nprint(""*"" * 33)\nif lahead >= tsteps:\n    print(""STATELESS LSTM WILL ALSO CONVERGE"")\nelse:\n    print(""STATELESS LSTM WILL NOT CONVERGE"")\nprint(""*"" * 33)\n\nnp.random.seed(1986)\n\nprint(\'Generating Data...\')\n\n\ndef gen_uniform_amp(amp=1, xn=10000):\n    """"""Generates uniform random data between\n    -amp and +amp\n    and of length xn\n\n    # Arguments\n        amp: maximum/minimum range of uniform data\n        xn: length of series\n    """"""\n    data_input = np.random.uniform(-1 * amp, +1 * amp, xn)\n    data_input = pd.DataFrame(data_input)\n    return data_input\n\n# Since the output is a moving average of the input,\n# the first few points of output will be NaN\n# and will be dropped from the generated data\n# before training the LSTM.\n# Also, when lahead > 1,\n# the preprocessing step later of ""rolling window view""\n# will also cause some points to be lost.\n# For aesthetic reasons,\n# in order to maintain generated data length = input_len after pre-processing,\n# add a few points to account for the values that will be lost.\nto_drop = max(tsteps - 1, lahead - 1)\ndata_input = gen_uniform_amp(amp=0.1, xn=input_len + to_drop)\n\n# set the target to be a N-point average of the input\nexpected_output = data_input.rolling(window=tsteps, center=False).mean()\n\n# when lahead > 1, need to convert the input to ""rolling window view""\n# https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html\nif lahead > 1:\n    data_input = np.repeat(data_input.values, repeats=lahead, axis=1)\n    data_input = pd.DataFrame(data_input)\n    for i, c in enumerate(data_input.columns):\n        data_input[c] = data_input[c].shift(i)\n\n# drop the nan\nexpected_output = expected_output[to_drop:]\ndata_input = data_input[to_drop:]\n\nprint(\'Input shape:\', data_input.shape)\nprint(\'Output shape:\', expected_output.shape)\nprint(\'Input head: \')\nprint(data_input.head())\nprint(\'Output head: \')\nprint(expected_output.head())\nprint(\'Input tail: \')\nprint(data_input.tail())\nprint(\'Output tail: \')\nprint(expected_output.tail())\n\nprint(\'Plotting input and expected output\')\nplt.plot(data_input[0][:10], \'.\')\nplt.plot(expected_output[0][:10], \'-\')\nplt.legend([\'Input\', \'Expected output\'])\nplt.title(\'Input\')\nplt.show()\n\n\ndef create_model(stateful):\n    model = Sequential()\n    model.add(LSTM(20,\n              input_shape=(lahead, 1),\n              batch_size=batch_size,\n              stateful=stateful))\n    model.add(Dense(1))\n    model.compile(loss=\'mse\', optimizer=\'adam\')\n    return model\n\nprint(\'Creating Stateful Model...\')\nmodel_stateful = create_model(stateful=True)\n\n\n# split train/test data\ndef split_data(x, y, ratio=0.8):\n    to_train = int(input_len * ratio)\n    # tweak to match with batch_size\n    to_train -= to_train % batch_size\n\n    x_train = x[:to_train]\n    y_train = y[:to_train]\n    x_test = x[to_train:]\n    y_test = y[to_train:]\n\n    # tweak to match with batch_size\n    to_drop = x.shape[0] % batch_size\n    if to_drop > 0:\n        x_test = x_test[:-1 * to_drop]\n        y_test = y_test[:-1 * to_drop]\n\n    # some reshaping\n    reshape_3 = lambda x: x.values.reshape((x.shape[0], x.shape[1], 1))\n    x_train = reshape_3(x_train)\n    x_test = reshape_3(x_test)\n\n    reshape_2 = lambda x: x.values.reshape((x.shape[0], 1))\n    y_train = reshape_2(y_train)\n    y_test = reshape_2(y_test)\n\n    return (x_train, y_train), (x_test, y_test)\n\n\n(x_train, y_train), (x_test, y_test) = split_data(data_input, expected_output)\nprint(\'x_train.shape: \', x_train.shape)\nprint(\'y_train.shape: \', y_train.shape)\nprint(\'x_test.shape: \', x_test.shape)\nprint(\'y_test.shape: \', y_test.shape)\n\nprint(\'Training\')\nfor i in range(epochs):\n    print(\'Epoch\', i + 1, \'/\', epochs)\n    # Note that the last state for sample i in a batch will\n    # be used as initial state for sample i in the next batch.\n    # Thus we are simultaneously training on batch_size series with\n    # lower resolution than the original series contained in data_input.\n    # Each of these series are offset by one step and can be\n    # extracted with data_input[i::batch_size].\n    model_stateful.fit(x_train,\n                       y_train,\n                       batch_size=batch_size,\n                       epochs=1,\n                       verbose=1,\n                       validation_data=(x_test, y_test),\n                       shuffle=False)\n    model_stateful.reset_states()\n\nprint(\'Predicting\')\npredicted_stateful = model_stateful.predict(x_test, batch_size=batch_size)\n\nprint(\'Creating Stateless Model...\')\nmodel_stateless = create_model(stateful=False)\n\nprint(\'Training\')\nmodel_stateless.fit(x_train,\n                    y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(x_test, y_test),\n                    shuffle=False)\n\nprint(\'Predicting\')\npredicted_stateless = model_stateless.predict(x_test, batch_size=batch_size)\n\n# ----------------------------\n\nprint(\'Plotting Results\')\nplt.subplot(3, 1, 1)\nplt.plot(y_test)\nplt.title(\'Expected\')\nplt.subplot(3, 1, 2)\n# drop the first ""tsteps-1"" because it is not possible to predict them\n# since the ""previous"" timesteps to use do not exist\nplt.plot((y_test - predicted_stateful).flatten()[tsteps - 1:])\nplt.title(\'Stateful: Expected - Predicted\')\nplt.subplot(3, 1, 3)\nplt.plot((y_test - predicted_stateless).flatten())\nplt.title(\'Stateless: Expected - Predicted\')\nplt.show()\n'"
examples/lstm_text_generation.py,0,"b'\'\'\'\n#Example script to generate text from Nietzsche\'s writings.\n\nAt least 20 epochs are required before the generated text\nstarts sounding coherent.\n\nIt is recommended to run this script on GPU, as recurrent\nnetworks are quite computationally intensive.\n\nIf you try this script on new data, make sure your corpus\nhas at least ~100k characters. ~1M is better.\n\'\'\'\n\nfrom __future__ import print_function\nfrom keras.callbacks import LambdaCallback\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop\nfrom keras.utils.data_utils import get_file\nimport numpy as np\nimport random\nimport sys\nimport io\n\npath = get_file(\n    \'nietzsche.txt\',\n    origin=\'https://s3.amazonaws.com/text-datasets/nietzsche.txt\')\nwith io.open(path, encoding=\'utf-8\') as f:\n    text = f.read().lower()\nprint(\'corpus length:\', len(text))\n\nchars = sorted(list(set(text)))\nprint(\'total chars:\', len(chars))\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))\n\n# cut the text in semi-redundant sequences of maxlen characters\nmaxlen = 40\nstep = 3\nsentences = []\nnext_chars = []\nfor i in range(0, len(text) - maxlen, step):\n    sentences.append(text[i: i + maxlen])\n    next_chars.append(text[i + maxlen])\nprint(\'nb sequences:\', len(sentences))\n\nprint(\'Vectorization...\')\nx = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\ny = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        x[i, t, char_indices[char]] = 1\n    y[i, char_indices[next_chars[i]]] = 1\n\n\n# build the model: a single LSTM\nprint(\'Build model...\')\nmodel = Sequential()\nmodel.add(LSTM(128, input_shape=(maxlen, len(chars))))\nmodel.add(Dense(len(chars), activation=\'softmax\'))\n\noptimizer = RMSprop(learning_rate=0.01)\nmodel.compile(loss=\'categorical_crossentropy\', optimizer=optimizer)\n\n\ndef sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype(\'float64\')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\n\ndef on_epoch_end(epoch, _):\n    # Function invoked at end of each epoch. Prints generated text.\n    print()\n    print(\'----- Generating text after Epoch: %d\' % epoch)\n\n    start_index = random.randint(0, len(text) - maxlen - 1)\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\n        print(\'----- diversity:\', diversity)\n\n        generated = \'\'\n        sentence = text[start_index: start_index + maxlen]\n        generated += sentence\n        print(\'----- Generating with seed: ""\' + sentence + \'""\')\n        sys.stdout.write(generated)\n\n        for i in range(400):\n            x_pred = np.zeros((1, maxlen, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] = 1.\n\n            preds = model.predict(x_pred, verbose=0)[0]\n            next_index = sample(preds, diversity)\n            next_char = indices_char[next_index]\n\n            sentence = sentence[1:] + next_char\n\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()\n\nprint_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n\nmodel.fit(x, y,\n          batch_size=128,\n          epochs=60,\n          callbacks=[print_callback])\n'"
examples/mnist_acgan.py,0,"b'# -*- coding: utf-8 -*-\n""""""\n#Train an Auxiliary Classifier GAN (ACGAN) on the MNIST dataset.\n\n[More details on Auxiliary Classifier GANs.](https://arxiv.org/abs/1610.09585)\n\nYou should start to see reasonable images after ~5 epochs, and good images\nby ~15 epochs. You should use a GPU, as the convolution-heavy operations are\nvery slow on the CPU. Prefer the TensorFlow backend if you plan on iterating,\nas the compilation time can be a blocker using Theano.\n\nTimings:\n\nHardware           | Backend | Time / Epoch\n:------------------|:--------|------------:\n CPU               | TF      | 3 hrs\n Titan X (maxwell) | TF      | 4 min\n Titan X (maxwell) | TH      | 7 min\n\nConsult [Auxiliary Classifier Generative Adversarial Networks in Keras\n](https://github.com/lukedeo/keras-acgan) for more information and example output.\n""""""\nfrom __future__ import print_function\n\nfrom collections import defaultdict\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\nfrom PIL import Image\n\nfrom six.moves import range\n\nfrom keras.datasets import mnist\nfrom keras import layers\nfrom keras.layers import Input, Dense, Reshape, Flatten, Embedding, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2DTranspose, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom keras.utils.generic_utils import Progbar\nimport numpy as np\n\nnp.random.seed(1337)\nnum_classes = 10\n\n\ndef build_generator(latent_size):\n    # we will map a pair of (z, L), where z is a latent vector and L is a\n    # label drawn from P_c, to image space (..., 28, 28, 1)\n    cnn = Sequential()\n\n    cnn.add(Dense(3 * 3 * 384, input_dim=latent_size, activation=\'relu\'))\n    cnn.add(Reshape((3, 3, 384)))\n\n    # upsample to (7, 7, ...)\n    cnn.add(Conv2DTranspose(192, 5, strides=1, padding=\'valid\',\n                            activation=\'relu\',\n                            kernel_initializer=\'glorot_normal\'))\n    cnn.add(BatchNormalization())\n\n    # upsample to (14, 14, ...)\n    cnn.add(Conv2DTranspose(96, 5, strides=2, padding=\'same\',\n                            activation=\'relu\',\n                            kernel_initializer=\'glorot_normal\'))\n    cnn.add(BatchNormalization())\n\n    # upsample to (28, 28, ...)\n    cnn.add(Conv2DTranspose(1, 5, strides=2, padding=\'same\',\n                            activation=\'tanh\',\n                            kernel_initializer=\'glorot_normal\'))\n\n    # this is the z space commonly referred to in GAN papers\n    latent = Input(shape=(latent_size, ))\n\n    # this will be our label\n    image_class = Input(shape=(1,), dtype=\'int32\')\n\n    cls = Embedding(num_classes, latent_size,\n                    embeddings_initializer=\'glorot_normal\')(image_class)\n\n    # hadamard product between z-space and a class conditional embedding\n    h = layers.multiply([latent, cls])\n\n    fake_image = cnn(h)\n\n    return Model([latent, image_class], fake_image)\n\n\ndef build_discriminator():\n    # build a relatively standard conv net, with LeakyReLUs as suggested in\n    # the reference paper\n    cnn = Sequential()\n\n    cnn.add(Conv2D(32, 3, padding=\'same\', strides=2,\n                   input_shape=(28, 28, 1)))\n    cnn.add(LeakyReLU(0.2))\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Conv2D(64, 3, padding=\'same\', strides=1))\n    cnn.add(LeakyReLU(0.2))\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Conv2D(128, 3, padding=\'same\', strides=2))\n    cnn.add(LeakyReLU(0.2))\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Conv2D(256, 3, padding=\'same\', strides=1))\n    cnn.add(LeakyReLU(0.2))\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Flatten())\n\n    image = Input(shape=(28, 28, 1))\n\n    features = cnn(image)\n\n    # first output (name=generation) is whether or not the discriminator\n    # thinks the image that is being shown is fake, and the second output\n    # (name=auxiliary) is the class that the discriminator thinks the image\n    # belongs to.\n    fake = Dense(1, activation=\'sigmoid\', name=\'generation\')(features)\n    aux = Dense(num_classes, activation=\'softmax\', name=\'auxiliary\')(features)\n\n    return Model(image, [fake, aux])\n\n\nif __name__ == \'__main__\':\n    # batch and latent size taken from the paper\n    epochs = 100\n    batch_size = 100\n    latent_size = 100\n\n    # Adam parameters suggested in https://arxiv.org/abs/1511.06434\n    adam_lr = 0.0002\n    adam_beta_1 = 0.5\n\n    # build the discriminator\n    print(\'Discriminator model:\')\n    discriminator = build_discriminator()\n    discriminator.compile(\n        optimizer=Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n        loss=[\'binary_crossentropy\', \'sparse_categorical_crossentropy\']\n    )\n    discriminator.summary()\n\n    # build the generator\n    generator = build_generator(latent_size)\n\n    latent = Input(shape=(latent_size, ))\n    image_class = Input(shape=(1,), dtype=\'int32\')\n\n    # get a fake image\n    fake = generator([latent, image_class])\n\n    # we only want to be able to train generation for the combined model\n    discriminator.trainable = False\n    fake, aux = discriminator(fake)\n    combined = Model([latent, image_class], [fake, aux])\n\n    print(\'Combined model:\')\n    combined.compile(\n        optimizer=Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n        loss=[\'binary_crossentropy\', \'sparse_categorical_crossentropy\']\n    )\n    combined.summary()\n\n    # get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n    # range [-1, 1]\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n    x_train = np.expand_dims(x_train, axis=-1)\n\n    x_test = (x_test.astype(np.float32) - 127.5) / 127.5\n    x_test = np.expand_dims(x_test, axis=-1)\n\n    num_train, num_test = x_train.shape[0], x_test.shape[0]\n\n    train_history = defaultdict(list)\n    test_history = defaultdict(list)\n\n    for epoch in range(1, epochs + 1):\n        print(\'Epoch {}/{}\'.format(epoch, epochs))\n\n        num_batches = int(np.ceil(x_train.shape[0] / float(batch_size)))\n        progress_bar = Progbar(target=num_batches)\n\n        epoch_gen_loss = []\n        epoch_disc_loss = []\n\n        for index in range(num_batches):\n            # get a batch of real images\n            image_batch = x_train[index * batch_size:(index + 1) * batch_size]\n            label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n\n            # generate a new batch of noise\n            noise = np.random.uniform(-1, 1, (len(image_batch), latent_size))\n\n            # sample some labels from p_c\n            sampled_labels = np.random.randint(0, num_classes, len(image_batch))\n\n            # generate a batch of fake images, using the generated labels as a\n            # conditioner. We reshape the sampled labels to be\n            # (len(image_batch), 1) so that we can feed them into the embedding\n            # layer as a length one sequence\n            generated_images = generator.predict(\n                [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n\n            x = np.concatenate((image_batch, generated_images))\n\n            # use one-sided soft real/fake labels\n            # Salimans et al., 2016\n            # https://arxiv.org/pdf/1606.03498.pdf (Section 3.4)\n            soft_zero, soft_one = 0, 0.95\n            y = np.array(\n                [soft_one] * len(image_batch) + [soft_zero] * len(image_batch))\n            aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n\n            # we don\'t want the discriminator to also maximize the classification\n            # accuracy of the auxiliary classifier on generated images, so we\n            # don\'t train discriminator to produce class labels for generated\n            # images (see https://openreview.net/forum?id=rJXTf9Bxg).\n            # To preserve sum of sample weights for the auxiliary classifier,\n            # we assign sample weight of 2 to the real images.\n            disc_sample_weight = [np.ones(2 * len(image_batch)),\n                                  np.concatenate((np.ones(len(image_batch)) * 2,\n                                                  np.zeros(len(image_batch))))]\n\n            # see if the discriminator can figure itself out...\n            epoch_disc_loss.append(discriminator.train_on_batch(\n                x, [y, aux_y], sample_weight=disc_sample_weight))\n\n            # make new noise. we generate 2 * batch size here such that we have\n            # the generator optimize over an identical number of images as the\n            # discriminator\n            noise = np.random.uniform(-1, 1, (2 * len(image_batch), latent_size))\n            sampled_labels = np.random.randint(0, num_classes, 2 * len(image_batch))\n\n            # we want to train the generator to trick the discriminator\n            # For the generator, we want all the {fake, not-fake} labels to say\n            # not-fake\n            trick = np.ones(2 * len(image_batch)) * soft_one\n\n            epoch_gen_loss.append(combined.train_on_batch(\n                [noise, sampled_labels.reshape((-1, 1))],\n                [trick, sampled_labels]))\n\n            progress_bar.update(index + 1)\n\n        print(\'Testing for epoch {}:\'.format(epoch))\n\n        # evaluate the testing loss here\n\n        # generate a new batch of noise\n        noise = np.random.uniform(-1, 1, (num_test, latent_size))\n\n        # sample some labels from p_c and generate images from them\n        sampled_labels = np.random.randint(0, num_classes, num_test)\n        generated_images = generator.predict(\n            [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n\n        x = np.concatenate((x_test, generated_images))\n        y = np.array([1] * num_test + [0] * num_test)\n        aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n\n        # see if the discriminator can figure itself out...\n        discriminator_test_loss = discriminator.evaluate(\n            x, [y, aux_y], verbose=False)\n\n        discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n\n        # make new noise\n        noise = np.random.uniform(-1, 1, (2 * num_test, latent_size))\n        sampled_labels = np.random.randint(0, num_classes, 2 * num_test)\n\n        trick = np.ones(2 * num_test)\n\n        generator_test_loss = combined.evaluate(\n            [noise, sampled_labels.reshape((-1, 1))],\n            [trick, sampled_labels], verbose=False)\n\n        generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n\n        # generate an epoch report on performance\n        train_history[\'generator\'].append(generator_train_loss)\n        train_history[\'discriminator\'].append(discriminator_train_loss)\n\n        test_history[\'generator\'].append(generator_test_loss)\n        test_history[\'discriminator\'].append(discriminator_test_loss)\n\n        print(\'{0:<22s} | {1:4s} | {2:15s} | {3:5s}\'.format(\n            \'component\', *discriminator.metrics_names))\n        print(\'-\' * 65)\n\n        ROW_FMT = \'{0:<22s} | {1:<4.2f} | {2:<15.4f} | {3:<5.4f}\'\n        print(ROW_FMT.format(\'generator (train)\',\n                             *train_history[\'generator\'][-1]))\n        print(ROW_FMT.format(\'generator (test)\',\n                             *test_history[\'generator\'][-1]))\n        print(ROW_FMT.format(\'discriminator (train)\',\n                             *train_history[\'discriminator\'][-1]))\n        print(ROW_FMT.format(\'discriminator (test)\',\n                             *test_history[\'discriminator\'][-1]))\n\n        # save weights every epoch\n        generator.save_weights(\n            \'params_generator_epoch_{0:03d}.hdf5\'.format(epoch), True)\n        discriminator.save_weights(\n            \'params_discriminator_epoch_{0:03d}.hdf5\'.format(epoch), True)\n\n        # generate some digits to display\n        num_rows = 40\n        noise = np.tile(np.random.uniform(-1, 1, (num_rows, latent_size)),\n                        (num_classes, 1))\n\n        sampled_labels = np.array([\n            [i] * num_rows for i in range(num_classes)\n        ]).reshape(-1, 1)\n\n        # get a batch to display\n        generated_images = generator.predict(\n            [noise, sampled_labels], verbose=0)\n\n        # prepare real images sorted by class label\n        real_labels = y_train[(epoch - 1) * num_rows * num_classes:\n                              epoch * num_rows * num_classes]\n        indices = np.argsort(real_labels, axis=0)\n        real_images = x_train[(epoch - 1) * num_rows * num_classes:\n                              epoch * num_rows * num_classes][indices]\n\n        # display generated images, white separator, real images\n        img = np.concatenate(\n            (generated_images,\n             np.repeat(np.ones_like(x_train[:1]), num_rows, axis=0),\n             real_images))\n\n        # arrange them into a grid\n        img = (np.concatenate([r.reshape(-1, 28)\n                               for r in np.split(img, 2 * num_classes + 1)\n                               ], axis=-1) * 127.5 + 127.5).astype(np.uint8)\n\n        Image.fromarray(img).save(\n            \'plot_epoch_{0:03d}_generated.png\'.format(epoch))\n\n    with open(\'acgan-history.pkl\', \'wb\') as f:\n        pickle.dump({\'train\': train_history, \'test\': test_history}, f)\n'"
examples/mnist_cnn.py,0,"b""'''Trains a simple convnet on the MNIST dataset.\n\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n'''\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
examples/mnist_denoising_autoencoder.py,0,"b""'''Trains a denoising autoencoder on MNIST dataset.\n\nDenoising is one of the classic applications of autoencoders.\nThe denoising process removes unwanted noise that corrupted the\ntrue signal.\n\nNoise + Data ---> Denoising Autoencoder ---> Data\n\nGiven a training dataset of corrupted data as input and\ntrue signal as output, a denoising autoencoder can recover the\nhidden structure to generate clean data.\n\nThis example has modular design. The encoder, decoder and autoencoder\nare 3 models that share weights. For example, after training the\nautoencoder, the encoder can be used to  generate latent vectors\nof input data for low-dim visualization like PCA or TSNE.\n'''\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport keras\nfrom keras.layers import Activation, Dense, Input\nfrom keras.layers import Conv2D, Flatten\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nnp.random.seed(1337)\n\n# MNIST dataset\n(x_train, _), (x_test, _) = mnist.load_data()\n\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1])\nx_test = np.reshape(x_test, [-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# Generate corrupted MNIST images by adding noise with normal dist\n# centered at 0.5 and std=0.5\nnoise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\nx_train_noisy = x_train + noise\nnoise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\nx_test_noisy = x_test + noise\n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n# Network parameters\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\nlatent_dim = 16\n# Encoder/Decoder number of CNN layers and filters per layer\nlayer_filters = [32, 64]\n\n# Build the Autoencoder Model\n# First build the Encoder Model\ninputs = Input(shape=input_shape, name='encoder_input')\nx = inputs\n# Stack of Conv2D blocks\n# Notes:\n# 1) Use Batch Normalization before ReLU on deep networks\n# 2) Use MaxPooling2D as alternative to strides>1\n# - faster but not as good as strides>1\nfor filters in layer_filters:\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               strides=2,\n               activation='relu',\n               padding='same')(x)\n\n# Shape info needed to build Decoder Model\nshape = K.int_shape(x)\n\n# Generate the latent vector\nx = Flatten()(x)\nlatent = Dense(latent_dim, name='latent_vector')(x)\n\n# Instantiate Encoder Model\nencoder = Model(inputs, latent, name='encoder')\nencoder.summary()\n\n# Build the Decoder Model\nlatent_inputs = Input(shape=(latent_dim,), name='decoder_input')\nx = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\n\n# Stack of Transposed Conv2D blocks\n# Notes:\n# 1) Use Batch Normalization before ReLU on deep networks\n# 2) Use UpSampling2D as alternative to strides>1\n# - faster but not as good as strides>1\nfor filters in layer_filters[::-1]:\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        strides=2,\n                        activation='relu',\n                        padding='same')(x)\n\nx = Conv2DTranspose(filters=1,\n                    kernel_size=kernel_size,\n                    padding='same')(x)\n\noutputs = Activation('sigmoid', name='decoder_output')(x)\n\n# Instantiate Decoder Model\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\n\n# Autoencoder = Encoder + Decoder\n# Instantiate Autoencoder Model\nautoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\nautoencoder.summary()\n\nautoencoder.compile(loss='mse', optimizer='adam')\n\n# Train the autoencoder\nautoencoder.fit(x_train_noisy,\n                x_train,\n                validation_data=(x_test_noisy, x_test),\n                epochs=30,\n                batch_size=batch_size)\n\n# Predict the Autoencoder output from corrupted test images\nx_decoded = autoencoder.predict(x_test_noisy)\n\n# Display the 1st 8 corrupted and denoised images\nrows, cols = 10, 30\nnum = rows * cols\nimgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\nimgs = imgs.reshape((rows * 3, cols, image_size, image_size))\nimgs = np.vstack(np.split(imgs, rows, axis=1))\nimgs = imgs.reshape((rows * 3, -1, image_size, image_size))\nimgs = np.vstack([np.hstack(i) for i in imgs])\nimgs = (imgs * 255).astype(np.uint8)\nplt.figure()\nplt.axis('off')\nplt.title('Original images: top rows, '\n          'Corrupted Input: middle rows, '\n          'Denoised Input:  third rows')\nplt.imshow(imgs, interpolation='none', cmap='gray')\nImage.fromarray(imgs).save('corrupted_and_denoised.png')\nplt.show()\n"""
examples/mnist_hierarchical_rnn.py,0,"b'""""""Example of using Hierarchical RNN (HRNN) to classify MNIST digits.\n\nHRNNs can learn across multiple levels\nof temporal hierarchy over a complex sequence.\nUsually, the first recurrent layer of an HRNN\nencodes a sentence (e.g. of word vectors)\ninto a  sentence vector.\nThe second recurrent layer then encodes a sequence of\nsuch vectors (encoded by the first layer) into a document vector.\nThis document vector is considered to preserve both\nthe word-level and sentence-level structure of the context.\n\n# References\n\n- [A Hierarchical Neural Autoencoder for Paragraphs and Documents]\n    (https://arxiv.org/abs/1506.01057)\n    Encodes paragraphs and documents with HRNN.\n    Results have shown that HRNN outperforms standard\n    RNNs and may play some role in more sophisticated generation tasks like\n    summarization or question answering.\n- [Hierarchical recurrent neural network for skeleton based action recognition]\n    (http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298714)\n    Achieved state-of-the-art results on\n    skeleton based action recognition with 3 levels\n    of bidirectional HRNN combined with fully connected layers.\n\nIn the below MNIST example the first LSTM layer first encodes every\ncolumn of pixels of shape (28, 1) to a column vector of shape (128,).\nThe second LSTM layer encodes then these 28 column vectors of shape (28, 128)\nto a image vector representing the whole image.\nA final Dense layer is added for prediction.\n\nAfter 5 epochs: train acc: 0.9858, val acc: 0.9864\n""""""\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, TimeDistributed\nfrom keras.layers import LSTM\n\n# Training parameters.\nbatch_size = 32\nnum_classes = 10\nepochs = 5\n\n# Embedding dimensions.\nrow_hidden = 128\ncol_hidden = 128\n\n# The data, split between train and test sets.\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Reshapes data to 4D for Hierarchical RNN.\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# Converts class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nrow, col, pixel = x_train.shape[1:]\n\n# 4D input.\nx = Input(shape=(row, col, pixel))\n\n# Encodes a row of pixels using TimeDistributed Wrapper.\nencoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n\n# Encodes columns of encoded rows.\nencoded_columns = LSTM(col_hidden)(encoded_rows)\n\n# Final predictions and model.\nprediction = Dense(num_classes, activation=\'softmax\')(encoded_columns)\nmodel = Model(x, prediction)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'rmsprop\',\n              metrics=[\'accuracy\'])\n\n# Training.\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n# Evaluation.\nscores = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy:\', scores[1])\n'"
examples/mnist_irnn.py,0,"b'\'\'\'This is a reproduction of the IRNN experiment\nwith pixel-by-pixel sequential MNIST in\n""A Simple Way to Initialize Recurrent Networks of Rectified Linear Units""\nby Quoc V. Le, Navdeep Jaitly, Geoffrey E. Hinton\n\narxiv:1504.00941v2 [cs.NE] 7 Apr 2015\nhttp://arxiv.org/pdf/1504.00941v2.pdf\n\nOptimizer is replaced with RMSprop which yields more stable and steady\nimprovement.\n\nReaches 0.93 train/test accuracy after 900 epochs\n(which roughly corresponds to 1687500 steps in the original paper.)\n\'\'\'\n\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import SimpleRNN\nfrom keras import initializers\nfrom keras.optimizers import RMSprop\n\nbatch_size = 32\nnum_classes = 10\nepochs = 200\nhidden_units = 100\n\nlearning_rate = 1e-6\nclip_norm = 1.0\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(x_train.shape[0], -1, 1)\nx_test = x_test.reshape(x_test.shape[0], -1, 1)\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nprint(\'Evaluate IRNN...\')\nmodel = Sequential()\nmodel.add(SimpleRNN(hidden_units,\n                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n                    recurrent_initializer=initializers.Identity(gain=1.0),\n                    activation=\'relu\',\n                    input_shape=x_train.shape[1:]))\nmodel.add(Dense(num_classes))\nmodel.add(Activation(\'softmax\'))\nrmsprop = RMSprop(learning_rate=learning_rate)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=rmsprop,\n              metrics=[\'accuracy\'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\nscores = model.evaluate(x_test, y_test, verbose=0)\nprint(\'IRNN test score:\', scores[0])\nprint(\'IRNN test accuracy:\', scores[1])\n'"
examples/mnist_mlp.py,0,"b""'''Trains a simple deep NN on the MNIST dataset.\n\nGets to 98.40% test accuracy after 20 epochs\n(there is *a lot* of margin for parameter tuning).\n2 seconds per epoch on a K520 GPU.\n'''\n\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop\n\nbatch_size = 128\nnum_classes = 10\nepochs = 20\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(784,)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(),\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
examples/mnist_net2net.py,0,"b""'''This is an implementation of Net2Net experiment with MNIST in\n'Net2Net: Accelerating Learning via Knowledge Transfer'\nby Tianqi Chen, Ian Goodfellow, and Jonathon Shlens\n\narXiv:1511.05641v4 [cs.LG] 23 Apr 2016\nhttp://arxiv.org/abs/1511.05641\n\n# Notes\n\n- What:\n  + Net2Net is a group of methods to transfer knowledge from a teacher neural\n    net to a student net,so that the student net can be trained faster than\n    from scratch.\n  + The paper discussed two specific methods of Net2Net, i.e. Net2WiderNet\n    and Net2DeeperNet.\n  + Net2WiderNet replaces a model with an equivalent wider model that has\n    more units in each hidden layer.\n  + Net2DeeperNet replaces a model with an equivalent deeper model.\n  + Both are based on the idea of 'function-preserving transformations of\n    neural nets'.\n- Why:\n  + Enable fast exploration of multiple neural nets in experimentation and\n    design process,by creating a series of wider and deeper models with\n    transferable knowledge.\n  + Enable 'lifelong learning system' by gradually adjusting model complexity\n    to data availability,and reusing transferable knowledge.\n\n# Experiments\n\n- Teacher model: a basic CNN model trained on MNIST for 3 epochs.\n- Net2WiderNet experiment:\n  + Student model has a wider Conv2D layer and a wider FC layer.\n  + Comparison of 'random-padding' vs 'net2wider' weight initialization.\n  + With both methods, after 1 epoch, student model should perform as well as\n    teacher model, but 'net2wider' is slightly better.\n- Net2DeeperNet experiment:\n  + Student model has an extra Conv2D layer and an extra FC layer.\n  + Comparison of 'random-init' vs 'net2deeper' weight initialization.\n  + After 1 epoch, performance of 'net2deeper' is better than 'random-init'.\n- Hyper-parameters:\n  + SGD with momentum=0.9 is used for training teacher and student models.\n  + Learning rate adjustment: it's suggested to reduce learning rate\n    to 1/10 for student model.\n  + Addition of noise in 'net2wider' is used to break weight symmetry\n    and thus enable full capacity of student models. It is optional\n    when a Dropout layer is used.\n\n# Results\n\n- Tested with TF backend and 'channels_last' image_data_format.\n- Running on GPU GeForce GTX Titan X Maxwell\n- Performance Comparisons - validation loss values during first 3 epochs:\n\nTeacher model ...\n(0) teacher_model:             0.0537   0.0354   0.0356\n\nExperiment of Net2WiderNet ...\n(1) wider_random_pad:          0.0320   0.0317   0.0289\n(2) wider_net2wider:           0.0271   0.0274   0.0270\n\nExperiment of Net2DeeperNet ...\n(3) deeper_random_init:        0.0682   0.0506   0.0468\n(4) deeper_net2deeper:         0.0292   0.0294   0.0286\n'''\n\nfrom __future__ import print_function\nimport numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.optimizers import SGD\nfrom keras.datasets import mnist\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (1, 28, 28)  # image shape\nelse:\n    input_shape = (28, 28, 1)  # image shape\nnum_classes = 10  # number of classes\nepochs = 3\n\n\n# load and pre-process data\ndef preprocess_input(x):\n    return x.astype('float32').reshape((-1,) + input_shape) / 255\n\n\ndef preprocess_output(y):\n    return keras.utils.to_categorical(y)\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = map(preprocess_input, [x_train, x_test])\ny_train, y_test = map(preprocess_output, [y_train, y_test])\nprint('Loading MNIST data...')\nprint('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\nprint('x_test shape:', x_test.shape, 'y_test shape', y_test.shape)\n\n\n# knowledge transfer algorithms\ndef wider2net_conv2d(teacher_w1, teacher_b1, teacher_w2, new_width, init):\n    '''Get initial weights for a wider conv2d layer with a bigger filters,\n    by 'random-padding' or 'net2wider'.\n\n    # Arguments\n        teacher_w1: `weight` of conv2d layer to become wider,\n          of shape (filters1, num_channel1, kh1, kw1)\n        teacher_b1: `bias` of conv2d layer to become wider,\n          of shape (filters1, )\n        teacher_w2: `weight` of next connected conv2d layer,\n          of shape (filters2, num_channel2, kh2, kw2)\n        new_width: new `filters` for the wider conv2d layer\n        init: initialization algorithm for new weights,\n          either 'random-pad' or 'net2wider'\n    '''\n    assert teacher_w1.shape[0] == teacher_w2.shape[1], (\n        'successive layers from teacher model should have compatible shapes')\n    assert teacher_w1.shape[3] == teacher_b1.shape[0], (\n        'weight and bias from same layer should have compatible shapes')\n    assert new_width > teacher_w1.shape[3], (\n        'new width (filters) should be bigger than the existing one')\n\n    n = new_width - teacher_w1.shape[3]\n    if init == 'random-pad':\n        new_w1 = np.random.normal(0, 0.1, size=teacher_w1.shape[:3] + (n,))\n        new_b1 = np.ones(n) * 0.1\n        new_w2 = np.random.normal(\n            0, 0.1,\n            size=teacher_w2.shape[:2] + (n, teacher_w2.shape[3]))\n    elif init == 'net2wider':\n        index = np.random.randint(teacher_w1.shape[3], size=n)\n        factors = np.bincount(index)[index] + 1.\n        new_w1 = teacher_w1[:, :, :, index]\n        new_b1 = teacher_b1[index]\n        new_w2 = teacher_w2[:, :, index, :] / factors.reshape((1, 1, -1, 1))\n    else:\n        raise ValueError('Unsupported weight initializer: %s' % init)\n\n    student_w1 = np.concatenate((teacher_w1, new_w1), axis=3)\n    if init == 'random-pad':\n        student_w2 = np.concatenate((teacher_w2, new_w2), axis=2)\n    elif init == 'net2wider':\n        # add small noise to break symmetry, so that student model will have\n        # full capacity later\n        noise = np.random.normal(0, 5e-2 * new_w2.std(), size=new_w2.shape)\n        student_w2 = np.concatenate((teacher_w2, new_w2 + noise), axis=2)\n        student_w2[:, :, index, :] = new_w2\n    student_b1 = np.concatenate((teacher_b1, new_b1), axis=0)\n\n    return student_w1, student_b1, student_w2\n\n\ndef wider2net_fc(teacher_w1, teacher_b1, teacher_w2, new_width, init):\n    '''Get initial weights for a wider fully connected (dense) layer\n       with a bigger nout, by 'random-padding' or 'net2wider'.\n\n    # Arguments\n        teacher_w1: `weight` of fc layer to become wider,\n          of shape (nin1, nout1)\n        teacher_b1: `bias` of fc layer to become wider,\n          of shape (nout1, )\n        teacher_w2: `weight` of next connected fc layer,\n          of shape (nin2, nout2)\n        new_width: new `nout` for the wider fc layer\n        init: initialization algorithm for new weights,\n          either 'random-pad' or 'net2wider'\n    '''\n    assert teacher_w1.shape[1] == teacher_w2.shape[0], (\n        'successive layers from teacher model should have compatible shapes')\n    assert teacher_w1.shape[1] == teacher_b1.shape[0], (\n        'weight and bias from same layer should have compatible shapes')\n    assert new_width > teacher_w1.shape[1], (\n        'new width (nout) should be bigger than the existing one')\n\n    n = new_width - teacher_w1.shape[1]\n    if init == 'random-pad':\n        new_w1 = np.random.normal(0, 0.1, size=(teacher_w1.shape[0], n))\n        new_b1 = np.ones(n) * 0.1\n        new_w2 = np.random.normal(0, 0.1, size=(n, teacher_w2.shape[1]))\n    elif init == 'net2wider':\n        index = np.random.randint(teacher_w1.shape[1], size=n)\n        factors = np.bincount(index)[index] + 1.\n        new_w1 = teacher_w1[:, index]\n        new_b1 = teacher_b1[index]\n        new_w2 = teacher_w2[index, :] / factors[:, np.newaxis]\n    else:\n        raise ValueError('Unsupported weight initializer: %s' % init)\n\n    student_w1 = np.concatenate((teacher_w1, new_w1), axis=1)\n    if init == 'random-pad':\n        student_w2 = np.concatenate((teacher_w2, new_w2), axis=0)\n    elif init == 'net2wider':\n        # add small noise to break symmetry, so that student model will have\n        # full capacity later\n        noise = np.random.normal(0, 5e-2 * new_w2.std(), size=new_w2.shape)\n        student_w2 = np.concatenate((teacher_w2, new_w2 + noise), axis=0)\n        student_w2[index, :] = new_w2\n    student_b1 = np.concatenate((teacher_b1, new_b1), axis=0)\n\n    return student_w1, student_b1, student_w2\n\n\ndef deeper2net_conv2d(teacher_w):\n    '''Get initial weights for a deeper conv2d layer by net2deeper'.\n\n    # Arguments\n        teacher_w: `weight` of previous conv2d layer,\n          of shape (kh, kw, num_channel, filters)\n    '''\n    kh, kw, num_channel, filters = teacher_w.shape\n    student_w = np.zeros_like(teacher_w)\n    for i in range(filters):\n        student_w[(kh - 1) // 2, (kw - 1) // 2, i, i] = 1.\n    student_b = np.zeros(filters)\n    return student_w, student_b\n\n\ndef copy_weights(teacher_model, student_model, layer_names):\n    '''Copy weights from teacher_model to student_model,\n     for layers with names listed in layer_names\n    '''\n    for name in layer_names:\n        weights = teacher_model.get_layer(name=name).get_weights()\n        student_model.get_layer(name=name).set_weights(weights)\n\n\n# methods to construct teacher_model and student_models\ndef make_teacher_model(x_train, y_train,\n                       x_test, y_test,\n                       epochs):\n    '''Train and benchmark performance of a simple CNN.\n    (0) Teacher model\n    '''\n    model = Sequential()\n    model.add(Conv2D(64, 3, input_shape=input_shape,\n                     padding='same', name='conv1'))\n    model.add(MaxPooling2D(2, name='pool1'))\n    model.add(Conv2D(64, 3, padding='same', name='conv2'))\n    model.add(MaxPooling2D(2, name='pool2'))\n    model.add(Flatten(name='flatten'))\n    model.add(Dense(64, activation='relu', name='fc1'))\n    model.add(Dense(num_classes, activation='softmax', name='fc2'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=SGD(learning_rate=0.01, momentum=0.9),\n                  metrics=['accuracy'])\n\n    model.fit(x_train, y_train,\n              epochs=epochs,\n              validation_data=(x_test, y_test))\n    return model\n\n\ndef make_wider_student_model(teacher_model,\n                             x_train, y_train,\n                             x_test, y_test,\n                             init, epochs):\n    '''Train a wider student model based on teacher_model,\n       with either 'random-pad' (baseline) or 'net2wider'\n    '''\n    new_conv1_width = 128\n    new_fc1_width = 128\n\n    model = Sequential()\n    # a wider conv1 compared to teacher_model\n    model.add(Conv2D(new_conv1_width, 3, input_shape=input_shape,\n                     padding='same', name='conv1'))\n    model.add(MaxPooling2D(2, name='pool1'))\n    model.add(Conv2D(64, 3, padding='same', name='conv2'))\n    model.add(MaxPooling2D(2, name='pool2'))\n    model.add(Flatten(name='flatten'))\n    # a wider fc1 compared to teacher model\n    model.add(Dense(new_fc1_width, activation='relu', name='fc1'))\n    model.add(Dense(num_classes, activation='softmax', name='fc2'))\n\n    # The weights for other layers need to be copied from teacher_model\n    # to student_model, except for widened layers\n    # and their immediate downstreams, which will be initialized separately.\n    # For this example there are no other layers that need to be copied.\n\n    w_conv1, b_conv1 = teacher_model.get_layer('conv1').get_weights()\n    w_conv2, b_conv2 = teacher_model.get_layer('conv2').get_weights()\n    new_w_conv1, new_b_conv1, new_w_conv2 = wider2net_conv2d(\n        w_conv1, b_conv1, w_conv2, new_conv1_width, init)\n    model.get_layer('conv1').set_weights([new_w_conv1, new_b_conv1])\n    model.get_layer('conv2').set_weights([new_w_conv2, b_conv2])\n\n    w_fc1, b_fc1 = teacher_model.get_layer('fc1').get_weights()\n    w_fc2, b_fc2 = teacher_model.get_layer('fc2').get_weights()\n    new_w_fc1, new_b_fc1, new_w_fc2 = wider2net_fc(\n        w_fc1, b_fc1, w_fc2, new_fc1_width, init)\n    model.get_layer('fc1').set_weights([new_w_fc1, new_b_fc1])\n    model.get_layer('fc2').set_weights([new_w_fc2, b_fc2])\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=SGD(learning_rate=0.001, momentum=0.9),\n                  metrics=['accuracy'])\n\n    model.fit(x_train, y_train,\n              epochs=epochs,\n              validation_data=(x_test, y_test))\n\n\ndef make_deeper_student_model(teacher_model,\n                              x_train, y_train,\n                              x_test, y_test,\n                              init, epochs):\n    '''Train a deeper student model based on teacher_model,\n       with either 'random-init' (baseline) or 'net2deeper'\n    '''\n    model = Sequential()\n    model.add(Conv2D(64, 3, input_shape=input_shape,\n                     padding='same', name='conv1'))\n    model.add(MaxPooling2D(2, name='pool1'))\n    model.add(Conv2D(64, 3, padding='same', name='conv2'))\n    # add another conv2d layer to make original conv2 deeper\n    if init == 'net2deeper':\n        prev_w, _ = model.get_layer('conv2').get_weights()\n        new_weights = deeper2net_conv2d(prev_w)\n        model.add(Conv2D(64, 3, padding='same',\n                         name='conv2-deeper', weights=new_weights))\n    elif init == 'random-init':\n        model.add(Conv2D(64, 3, padding='same', name='conv2-deeper'))\n    else:\n        raise ValueError('Unsupported weight initializer: %s' % init)\n    model.add(MaxPooling2D(2, name='pool2'))\n    model.add(Flatten(name='flatten'))\n    model.add(Dense(64, activation='relu', name='fc1'))\n    # add another fc layer to make original fc1 deeper\n    if init == 'net2deeper':\n        # net2deeper for fc layer with relu, is just an identity initializer\n        model.add(Dense(64, kernel_initializer='identity',\n                        activation='relu', name='fc1-deeper'))\n    elif init == 'random-init':\n        model.add(Dense(64, activation='relu', name='fc1-deeper'))\n    else:\n        raise ValueError('Unsupported weight initializer: %s' % init)\n    model.add(Dense(num_classes, activation='softmax', name='fc2'))\n\n    # copy weights for other layers\n    copy_weights(teacher_model, model, layer_names=[\n                 'conv1', 'conv2', 'fc1', 'fc2'])\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=SGD(learning_rate=0.001, momentum=0.9),\n                  metrics=['accuracy'])\n\n    model.fit(x_train, y_train,\n              epochs=epochs,\n              validation_data=(x_test, y_test))\n\n\n# experiments setup\ndef net2wider_experiment():\n    '''Benchmark performances of\n    (1) a wider student model with `random_pad` initializer\n    (2) a wider student model with `Net2WiderNet` initializer\n    '''\n    print('\\nExperiment of Net2WiderNet ...')\n\n    print('\\n(1) building wider student model by random padding ...')\n    make_wider_student_model(teacher_model,\n                             x_train, y_train,\n                             x_test, y_test,\n                             init='random-pad',\n                             epochs=epochs)\n    print('\\n(2) building wider student model by net2wider ...')\n    make_wider_student_model(teacher_model,\n                             x_train, y_train,\n                             x_test, y_test,\n                             init='net2wider',\n                             epochs=epochs)\n\n\ndef net2deeper_experiment():\n    '''Benchmark performances of\n    (3) a deeper student model with `random_init` initializer\n    (4) a deeper student model with `Net2DeeperNet` initializer\n    '''\n    print('\\nExperiment of Net2DeeperNet ...')\n\n    print('\\n(3) building deeper student model by random init ...')\n    make_deeper_student_model(teacher_model,\n                              x_train, y_train,\n                              x_test, y_test,\n                              init='random-init',\n                              epochs=epochs)\n    print('\\n(4) building deeper student model by net2deeper ...')\n    make_deeper_student_model(teacher_model,\n                              x_train, y_train,\n                              x_test, y_test,\n                              init='net2deeper',\n                              epochs=epochs)\n\n\nprint('\\n(0) building teacher model ...')\nteacher_model = make_teacher_model(x_train, y_train,\n                                   x_test, y_test,\n                                   epochs=epochs)\n\n# run the experiments\nnet2wider_experiment()\nnet2deeper_experiment()\n"""
examples/mnist_siamese.py,0,"b""'''Trains a Siamese MLP on pairs of digits from the MNIST dataset.\n\nIt follows Hadsell-et-al.'06 [1] by computing the Euclidean distance on the\noutput of the shared network and by optimizing the contrastive loss (see paper\nfor more details).\n\n# References\n\n- Dimensionality Reduction by Learning an Invariant Mapping\n    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n\nGets to 97.2% test accuracy after 20 epochs.\n2 seconds per epoch on a Titan X Maxwell GPU\n'''\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nimport numpy as np\n\nimport random\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom keras.layers import Input, Flatten, Dense, Dropout, Lambda\nfrom keras.optimizers import RMSprop\nfrom keras import backend as K\n\nnum_classes = 10\nepochs = 20\n\n\ndef euclidean_distance(vects):\n    x, y = vects\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n\n\ndef eucl_dist_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)\n\n\ndef contrastive_loss(y_true, y_pred):\n    '''Contrastive loss from Hadsell-et-al.'06\n    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n    '''\n    margin = 1\n    square_pred = K.square(y_pred)\n    margin_square = K.square(K.maximum(margin - y_pred, 0))\n    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n\n\ndef create_pairs(x, digit_indices):\n    '''Positive and negative pair creation.\n    Alternates between positive and negative pairs.\n    '''\n    pairs = []\n    labels = []\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n    for d in range(num_classes):\n        for i in range(n):\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n            pairs += [[x[z1], x[z2]]]\n            inc = random.randrange(1, num_classes)\n            dn = (d + inc) % num_classes\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n            pairs += [[x[z1], x[z2]]]\n            labels += [1, 0]\n    return np.array(pairs), np.array(labels)\n\n\ndef create_base_network(input_shape):\n    '''Base network to be shared (eq. to feature extraction).\n    '''\n    input = Input(shape=input_shape)\n    x = Flatten()(input)\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.1)(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.1)(x)\n    x = Dense(128, activation='relu')(x)\n    return Model(input, x)\n\n\ndef compute_accuracy(y_true, y_pred):\n    '''Compute classification accuracy with a fixed threshold on distances.\n    '''\n    pred = y_pred.ravel() < 0.5\n    return np.mean(pred == y_true)\n\n\ndef accuracy(y_true, y_pred):\n    '''Compute classification accuracy with a fixed threshold on distances.\n    '''\n    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\ninput_shape = x_train.shape[1:]\n\n# create training+test positive and negative pairs\ndigit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\ntr_pairs, tr_y = create_pairs(x_train, digit_indices)\n\ndigit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\nte_pairs, te_y = create_pairs(x_test, digit_indices)\n\n# network definition\nbase_network = create_base_network(input_shape)\n\ninput_a = Input(shape=input_shape)\ninput_b = Input(shape=input_shape)\n\n# because we re-use the same instance `base_network`,\n# the weights of the network\n# will be shared across the two branches\nprocessed_a = base_network(input_a)\nprocessed_b = base_network(input_b)\n\ndistance = Lambda(euclidean_distance,\n                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n\nmodel = Model([input_a, input_b], distance)\n\n# train\nrms = RMSprop()\nmodel.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\nmodel.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n          batch_size=128,\n          epochs=epochs,\n          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n\n# compute final accuracy on training and test sets\ny_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\ntr_acc = compute_accuracy(tr_y, y_pred)\ny_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\nte_acc = compute_accuracy(te_y, y_pred)\n\nprint('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\nprint('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n"""
examples/mnist_sklearn_wrapper.py,0,"b""'''Example of how to use sklearn wrapper\n\nBuilds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model\n'''\n\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import backend as K\nfrom sklearn.model_selection import GridSearchCV\n\n\nnum_classes = 10\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# load training data and do basic data normalization\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n\ndef make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n    '''Creates model comprised of 2 convolutional layers followed by dense layers\n\n    dense_layer_sizes: List of layer sizes.\n        This list has one number for each layer\n    filters: Number of convolutional filters in each convolutional layer\n    kernel_size: Convolutional kernel size\n    pool_size: Size of pooling area for max pooling\n    '''\n\n    model = Sequential()\n    model.add(Conv2D(filters, kernel_size,\n                     padding='valid',\n                     input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(Conv2D(filters, kernel_size))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=pool_size))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    for layer_size in dense_layer_sizes:\n        model.add(Dense(layer_size))\n        model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adadelta',\n                  metrics=['accuracy'])\n    return model\n\n\ndense_size_candidates = [[32], [64], [32, 32], [64, 64]]\nmy_classifier = KerasClassifier(make_model, batch_size=32)\nvalidator = GridSearchCV(my_classifier,\n                         param_grid={'dense_layer_sizes': dense_size_candidates,\n                                     # epochs is avail for tuning even when not\n                                     # an argument to model building function\n                                     'epochs': [3, 6],\n                                     'filters': [8],\n                                     'kernel_size': [3],\n                                     'pool_size': [2]},\n                         scoring='neg_log_loss',\n                         n_jobs=1)\nvalidator.fit(x_train, y_train)\n\nprint('The parameters of the best model are: ')\nprint(validator.best_params_)\n\n# validator.best_estimator_ returns sklearn-wrapped version of best model.\n# validator.best_estimator_.model returns the (unwrapped) keras model\nbest_model = validator.best_estimator_.model\nmetric_names = best_model.metrics_names\nmetric_values = best_model.evaluate(x_test, y_test)\nfor metric, value in zip(metric_names, metric_values):\n    print(metric, ': ', value)\n"""
examples/mnist_swwae.py,0,"b'\'\'\'Trains a stacked what-where autoencoder built on residual blocks on the\r\nMNIST dataset. It exemplifies two influential methods that have been developed\r\nin the past few years.\r\n\r\nThe first is the idea of properly \'unpooling.\' During any max pool, the\r\nexact location (the \'where\') of the maximal value in a pooled receptive field\r\nis lost, however it can be very useful in the overall reconstruction of an\r\ninput image. Therefore, if the \'where\' is handed from the encoder\r\nto the corresponding decoder layer, features being decoded can be \'placed\' in\r\nthe right location, allowing for reconstructions of much higher fidelity.\r\n\r\n# References\r\n\r\n- Visualizing and Understanding Convolutional Networks\r\n  Matthew D Zeiler, Rob Fergus\r\n  https://arxiv.org/abs/1311.2901v3\r\n- Stacked What-Where Auto-encoders\r\n  Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann LeCun\r\n  https://arxiv.org/abs/1506.02351v8\r\n\r\nThe second idea exploited here is that of residual learning. Residual blocks\r\nease the training process by allowing skip connections that give the network\r\nthe ability to be as linear (or non-linear) as the data sees fit.  This allows\r\nfor much deep networks to be easily trained. The residual element seems to\r\nbe advantageous in the context of this example as it allows a nice symmetry\r\nbetween the encoder and decoder. Normally, in the decoder, the final\r\nprojection to the space where the image is reconstructed is linear, however\r\nthis does not have to be the case for a residual block as the degree to which\r\nits output is linear or non-linear is determined by the data it is fed.\r\nHowever, in order to cap the reconstruction in this example, a hard softmax is\r\napplied as a bias because we know the MNIST digits are mapped to [0, 1].\r\n\r\n# References\r\n- Deep Residual Learning for Image Recognition\r\n  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n  https://arxiv.org/abs/1512.03385v1\r\n- Identity Mappings in Deep Residual Networks\r\n  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n  https://arxiv.org/abs/1603.05027v3\r\n\'\'\'\r\nfrom __future__ import print_function\r\nimport numpy as np\r\n\r\nfrom keras.datasets import mnist\r\nfrom keras.models import Model\r\nfrom keras.layers import Activation\r\nfrom keras.layers import UpSampling2D, Conv2D, MaxPooling2D\r\nfrom keras.layers import Input, BatchNormalization, ELU\r\nimport matplotlib.pyplot as plt\r\nimport keras.backend as K\r\nfrom keras import layers\r\n\r\n\r\ndef convresblock(x, nfeats=8, ksize=3, nskipped=2, elu=True):\r\n    """"""The proposed residual block from [4].\r\n\r\n    Running with elu=True will use ELU nonlinearity and running with\r\n    elu=False will use BatchNorm + RELU nonlinearity.  While ELU\'s are fast\r\n    due to the fact they do not suffer from BatchNorm overhead, they may\r\n    overfit because they do not offer the stochastic element of the batch\r\n    formation process of BatchNorm, which acts as a good regularizer.\r\n\r\n    # Arguments\r\n        x: 4D tensor, the tensor to feed through the block\r\n        nfeats: Integer, number of feature maps for conv layers.\r\n        ksize: Integer, width and height of conv kernels in first convolution.\r\n        nskipped: Integer, number of conv layers for the residual function.\r\n        elu: Boolean, whether to use ELU or BN+RELU.\r\n\r\n    # Input shape\r\n        4D tensor with shape:\r\n        `(batch, channels, rows, cols)`\r\n\r\n    # Output shape\r\n        4D tensor with shape:\r\n        `(batch, filters, rows, cols)`\r\n    """"""\r\n    y0 = Conv2D(nfeats, ksize, padding=\'same\')(x)\r\n    y = y0\r\n    for i in range(nskipped):\r\n        if elu:\r\n            y = ELU()(y)\r\n        else:\r\n            y = BatchNormalization(axis=1)(y)\r\n            y = Activation(\'relu\')(y)\r\n        y = Conv2D(nfeats, 1, padding=\'same\')(y)\r\n    return layers.add([y0, y])\r\n\r\n\r\ndef getwhere(x):\r\n    \'\'\' Calculate the \'where\' mask that contains switches indicating which\r\n    index contained the max value when MaxPool2D was applied.  Using the\r\n    gradient of the sum is a nice trick to keep everything high level.\'\'\'\r\n    y_prepool, y_postpool = x\r\n    return K.gradients(K.sum(y_postpool), y_prepool)\r\n\r\n# This example assume \'channels_first\' data format.\r\nK.set_image_data_format(\'channels_first\')\r\n\r\n# input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n# the data, split between train and test sets\r\n(x_train, _), (x_test, _) = mnist.load_data()\r\n\r\nx_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\nx_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\nx_train = x_train.astype(\'float32\')\r\nx_test = x_test.astype(\'float32\')\r\nx_train /= 255\r\nx_test /= 255\r\nprint(\'x_train shape:\', x_train.shape)\r\nprint(x_train.shape[0], \'train samples\')\r\nprint(x_test.shape[0], \'test samples\')\r\n\r\n# The size of the kernel used for the MaxPooling2D\r\npool_size = 2\r\n# The total number of feature maps at each layer\r\nnfeats = [8, 16, 32, 64, 128]\r\n# The sizes of the pooling kernel at each layer\r\npool_sizes = np.array([1, 1, 1, 1, 1]) * pool_size\r\n# The convolution kernel size\r\nksize = 3\r\n# Number of epochs to train for\r\nepochs = 5\r\n# Batch size during training\r\nbatch_size = 128\r\n\r\nif pool_size == 2:\r\n    # if using a 5 layer net of pool_size = 2\r\n    x_train = np.pad(x_train, [[0, 0], [0, 0], [2, 2], [2, 2]],\r\n                     mode=\'constant\')\r\n    x_test = np.pad(x_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode=\'constant\')\r\n    nlayers = 5\r\nelif pool_size == 3:\r\n    # if using a 3 layer net of pool_size = 3\r\n    x_train = x_train[:, :, :-1, :-1]\r\n    x_test = x_test[:, :, :-1, :-1]\r\n    nlayers = 3\r\nelse:\r\n    import sys\r\n    sys.exit(\'Script supports pool_size of 2 and 3.\')\r\n\r\n# Shape of input to train on (note that model is fully convolutional however)\r\ninput_shape = x_train.shape[1:]\r\n# The final list of the size of axis=1 for all layers, including input\r\nnfeats_all = [input_shape[0]] + nfeats\r\n\r\n# First build the encoder, all the while keeping track of the \'where\' masks\r\nimg_input = Input(shape=input_shape)\r\n\r\n# We push the \'where\' masks to the following list\r\nwheres = [None] * nlayers\r\ny = img_input\r\nfor i in range(nlayers):\r\n    y_prepool = convresblock(y, nfeats=nfeats_all[i + 1], ksize=ksize)\r\n    y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)\r\n    wheres[i] = layers.Lambda(\r\n        getwhere, output_shape=lambda x: x[0])([y_prepool, y])\r\n\r\n# Now build the decoder, and use the stored \'where\' masks to place the features\r\nfor i in range(nlayers):\r\n    ind = nlayers - 1 - i\r\n    y = UpSampling2D(size=(pool_sizes[ind], pool_sizes[ind]))(y)\r\n    y = layers.multiply([y, wheres[ind]])\r\n    y = convresblock(y, nfeats=nfeats_all[ind], ksize=ksize)\r\n\r\n# Use hard_simgoid to clip range of reconstruction\r\ny = Activation(\'hard_sigmoid\')(y)\r\n\r\n# Define the model and it\'s mean square error loss, and compile it with Adam\r\nmodel = Model(img_input, y)\r\nmodel.compile(\'adam\', \'mse\')\r\n\r\n# Fit the model\r\nmodel.fit(x_train, x_train,\r\n          batch_size=batch_size,\r\n          epochs=epochs,\r\n          validation_data=(x_test, x_test))\r\n\r\n# Plot\r\nx_recon = model.predict(x_test[:25])\r\nx_plot = np.concatenate((x_test[:25], x_recon), axis=1)\r\nx_plot = x_plot.reshape((5, 10, input_shape[-2], input_shape[-1]))\r\nx_plot = np.vstack([np.hstack(x) for x in x_plot])\r\nplt.figure()\r\nplt.axis(\'off\')\r\nplt.title(\'Test Samples: Originals/Reconstructions\')\r\nplt.imshow(x_plot, interpolation=\'none\', cmap=\'gray\')\r\nplt.savefig(\'reconstructions.png\')\r\n'"
examples/mnist_transfer_cnn.py,0,"b""'''Transfer learning toy example.\n\n1 - Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n2 - Freeze convolutional layers and fine-tune dense layers\n   for the classification of digits [5..9].\n\nGet to 99.8% test accuracy after 5 epochs\nfor the first five digits classifier\nand 99.2% for the last five digits after transfer + fine-tuning.\n'''\n\nfrom __future__ import print_function\n\nimport datetime\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nnow = datetime.datetime.now\n\nbatch_size = 128\nnum_classes = 5\nepochs = 5\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of convolutional filters to use\nfilters = 32\n# size of pooling area for max pooling\npool_size = 2\n# convolution kernel size\nkernel_size = 3\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (1, img_rows, img_cols)\nelse:\n    input_shape = (img_rows, img_cols, 1)\n\n\ndef train_model(model, train, test, num_classes):\n    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    x_train /= 255\n    x_test /= 255\n    print('x_train shape:', x_train.shape)\n    print(x_train.shape[0], 'train samples')\n    print(x_test.shape[0], 'test samples')\n\n    # convert class vectors to binary class matrices\n    y_train = keras.utils.to_categorical(train[1], num_classes)\n    y_test = keras.utils.to_categorical(test[1], num_classes)\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adadelta',\n                  metrics=['accuracy'])\n\n    t = now()\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data=(x_test, y_test))\n    print('Training time: %s' % (now() - t))\n    score = model.evaluate(x_test, y_test, verbose=0)\n    print('Test score:', score[0])\n    print('Test accuracy:', score[1])\n\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# create two datasets one with digits below 5 and one with 5 and above\nx_train_lt5 = x_train[y_train < 5]\ny_train_lt5 = y_train[y_train < 5]\nx_test_lt5 = x_test[y_test < 5]\ny_test_lt5 = y_test[y_test < 5]\n\nx_train_gte5 = x_train[y_train >= 5]\ny_train_gte5 = y_train[y_train >= 5] - 5\nx_test_gte5 = x_test[y_test >= 5]\ny_test_gte5 = y_test[y_test >= 5] - 5\n\n# define two groups of layers: feature (convolutions) and classification (dense)\nfeature_layers = [\n    Conv2D(filters, kernel_size,\n           padding='valid',\n           input_shape=input_shape),\n    Activation('relu'),\n    Conv2D(filters, kernel_size),\n    Activation('relu'),\n    MaxPooling2D(pool_size=pool_size),\n    Dropout(0.25),\n    Flatten(),\n]\n\nclassification_layers = [\n    Dense(128),\n    Activation('relu'),\n    Dropout(0.5),\n    Dense(num_classes),\n    Activation('softmax')\n]\n\n# create complete model\nmodel = Sequential(feature_layers + classification_layers)\n\n# train model for 5-digit classification [0..4]\ntrain_model(model,\n            (x_train_lt5, y_train_lt5),\n            (x_test_lt5, y_test_lt5), num_classes)\n\n# freeze feature layers and rebuild model\nfor l in feature_layers:\n    l.trainable = False\n\n# transfer: train dense layers for new classification task [5..9]\ntrain_model(model,\n            (x_train_gte5, y_train_gte5),\n            (x_test_gte5, y_test_gte5), num_classes)\n"""
examples/neural_doodle.py,0,"b""'''Neural doodle with Keras\r\n\r\n# Script Usage\r\n\r\n## Arguments\r\n```\r\n--nlabels:              # of regions (colors) in mask images\r\n--style-image:          image to learn style from\r\n--style-mask:           semantic labels for style image\r\n--target-mask:          semantic labels for target image (your doodle)\r\n--content-image:        optional image to learn content from\r\n--target-image-prefix:  path prefix for generated target images\r\n```\r\n\r\n## Example 1: doodle using a style image, style mask\r\nand target mask.\r\n```\r\npython neural_doodle.py --nlabels 4 --style-image Monet/style.png \\\r\n--style-mask Monet/style_mask.png --target-mask Monet/target_mask.png \\\r\n--target-image-prefix generated/monet\r\n```\r\n\r\n## Example 2: doodle using a style image, style mask,\r\ntarget mask and an optional content image.\r\n```\r\npython neural_doodle.py --nlabels 4 --style-image Renoir/style.png \\\r\n--style-mask Renoir/style_mask.png --target-mask Renoir/target_mask.png \\\r\n--content-image Renoir/creek.jpg \\\r\n--target-image-prefix generated/renoir\r\n```\r\n\r\n# References\r\n\r\n- [Dmitry Ulyanov's blog on fast-neural-doodle]\r\n    (http://dmitryulyanov.github.io/feed-forward-neural-doodle/)\r\n- [Torch code for fast-neural-doodle]\r\n    (https://github.com/DmitryUlyanov/fast-neural-doodle)\r\n- [Torch code for online-neural-doodle]\r\n    (https://github.com/DmitryUlyanov/online-neural-doodle)\r\n- [Paper Texture Networks: Feed-forward Synthesis of Textures and Stylized Images]\r\n    (http://arxiv.org/abs/1603.03417)\r\n- [Discussion on parameter tuning]\r\n    (https://github.com/keras-team/keras/issues/3705)\r\n\r\n# Resources\r\n\r\nExample images can be downloaded from\r\nhttps://github.com/DmitryUlyanov/fast-neural-doodle/tree/master/data\r\n'''\r\nfrom __future__ import print_function\r\nimport time\r\nimport argparse\r\nimport numpy as np\r\nfrom scipy.optimize import fmin_l_bfgs_b\r\n\r\nfrom keras import backend as K\r\nfrom keras.layers import Input, AveragePooling2D\r\nfrom keras.models import Model\r\nfrom keras.preprocessing.image import load_img, save_img, img_to_array\r\nfrom keras.applications import vgg19\r\n\r\n# Command line arguments\r\nparser = argparse.ArgumentParser(description='Keras neural doodle example')\r\nparser.add_argument('--nlabels', type=int,\r\n                    help='number of semantic labels'\r\n                    ' (regions in differnet colors)'\r\n                    ' in style_mask/target_mask')\r\nparser.add_argument('--style-image', type=str,\r\n                    help='path to image to learn style from')\r\nparser.add_argument('--style-mask', type=str,\r\n                    help='path to semantic mask of style image')\r\nparser.add_argument('--target-mask', type=str,\r\n                    help='path to semantic mask of target image')\r\nparser.add_argument('--content-image', type=str, default=None,\r\n                    help='path to optional content image')\r\nparser.add_argument('--target-image-prefix', type=str,\r\n                    help='path prefix for generated results')\r\nargs = parser.parse_args()\r\n\r\nstyle_img_path = args.style_image\r\nstyle_mask_path = args.style_mask\r\ntarget_mask_path = args.target_mask\r\ncontent_img_path = args.content_image\r\ntarget_img_prefix = args.target_image_prefix\r\nuse_content_img = content_img_path is not None\r\n\r\nnum_labels = args.nlabels\r\nnum_colors = 3  # RGB\r\n# determine image sizes based on target_mask\r\nref_img = img_to_array(load_img(target_mask_path))\r\nimg_nrows, img_ncols = ref_img.shape[:2]\r\n\r\nnum_iterations = 50\r\n\r\ntotal_variation_weight = 50.\r\nstyle_weight = 1.\r\ncontent_weight = 0.1 if use_content_img else 0\r\n\r\ncontent_feature_layers = ['block5_conv2']\r\n# To get better generation qualities, use more conv layers for style features\r\nstyle_feature_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1',\r\n                        'block4_conv1', 'block5_conv1']\r\n\r\n\r\n# helper functions for reading/processing images\r\ndef preprocess_image(image_path):\r\n    img = load_img(image_path, target_size=(img_nrows, img_ncols))\r\n    img = img_to_array(img)\r\n    img = np.expand_dims(img, axis=0)\r\n    img = vgg19.preprocess_input(img)\r\n    return img\r\n\r\n\r\ndef deprocess_image(x):\r\n    if K.image_data_format() == 'channels_first':\r\n        x = x.reshape((3, img_nrows, img_ncols))\r\n        x = x.transpose((1, 2, 0))\r\n    else:\r\n        x = x.reshape((img_nrows, img_ncols, 3))\r\n    # Remove zero-center by mean pixel\r\n    x[:, :, 0] += 103.939\r\n    x[:, :, 1] += 116.779\r\n    x[:, :, 2] += 123.68\r\n    # 'BGR'->'RGB'\r\n    x = x[:, :, ::-1]\r\n    x = np.clip(x, 0, 255).astype('uint8')\r\n    return x\r\n\r\n\r\ndef kmeans(xs, k):\r\n    assert xs.ndim == 2\r\n    try:\r\n        from sklearn.cluster import k_means\r\n        _, labels, _ = k_means(xs.astype('float64'), k)\r\n    except ImportError:\r\n        from scipy.cluster.vq import kmeans2\r\n        _, labels = kmeans2(xs, k, missing='raise')\r\n    return labels\r\n\r\n\r\ndef load_mask_labels():\r\n    '''Load both target and style masks.\r\n    A mask image (nr x nc) with m labels/colors will be loaded\r\n    as a 4D boolean tensor:\r\n        (1, m, nr, nc) for 'channels_first' or (1, nr, nc, m) for 'channels_last'\r\n    '''\r\n    target_mask_img = load_img(target_mask_path,\r\n                               target_size=(img_nrows, img_ncols))\r\n    target_mask_img = img_to_array(target_mask_img)\r\n    style_mask_img = load_img(style_mask_path,\r\n                              target_size=(img_nrows, img_ncols))\r\n    style_mask_img = img_to_array(style_mask_img)\r\n    if K.image_data_format() == 'channels_first':\r\n        mask_vecs = np.vstack([style_mask_img.reshape((3, -1)).T,\r\n                               target_mask_img.reshape((3, -1)).T])\r\n    else:\r\n        mask_vecs = np.vstack([style_mask_img.reshape((-1, 3)),\r\n                               target_mask_img.reshape((-1, 3))])\r\n\r\n    labels = kmeans(mask_vecs, num_labels)\r\n    style_mask_label = labels[:img_nrows *\r\n                              img_ncols].reshape((img_nrows, img_ncols))\r\n    target_mask_label = labels[img_nrows *\r\n                               img_ncols:].reshape((img_nrows, img_ncols))\r\n\r\n    stack_axis = 0 if K.image_data_format() == 'channels_first' else -1\r\n    style_mask = np.stack([style_mask_label == r for r in range(num_labels)],\r\n                          axis=stack_axis)\r\n    target_mask = np.stack([target_mask_label == r for r in range(num_labels)],\r\n                           axis=stack_axis)\r\n\r\n    return (np.expand_dims(style_mask, axis=0),\r\n            np.expand_dims(target_mask, axis=0))\r\n\r\n\r\n# Create tensor variables for images\r\nif K.image_data_format() == 'channels_first':\r\n    shape = (1, num_colors, img_nrows, img_ncols)\r\nelse:\r\n    shape = (1, img_nrows, img_ncols, num_colors)\r\n\r\nstyle_image = K.variable(preprocess_image(style_img_path))\r\ntarget_image = K.placeholder(shape=shape)\r\nif use_content_img:\r\n    content_image = K.variable(preprocess_image(content_img_path))\r\nelse:\r\n    content_image = K.zeros(shape=shape)\r\n\r\nimages = K.concatenate([style_image, target_image, content_image], axis=0)\r\n\r\n# Create tensor variables for masks\r\nraw_style_mask, raw_target_mask = load_mask_labels()\r\nstyle_mask = K.variable(raw_style_mask.astype('float32'))\r\ntarget_mask = K.variable(raw_target_mask.astype('float32'))\r\nmasks = K.concatenate([style_mask, target_mask], axis=0)\r\n\r\n# index constants for images and tasks variables\r\nSTYLE, TARGET, CONTENT = 0, 1, 2\r\n\r\n# Build image model, mask model and use layer outputs as features\r\n# image model as VGG19\r\nimage_model = vgg19.VGG19(include_top=False, input_tensor=images)\r\n\r\n# mask model as a series of pooling\r\nmask_input = Input(tensor=masks, shape=(None, None, None), name='mask_input')\r\nx = mask_input\r\nfor layer in image_model.layers[1:]:\r\n    name = 'mask_%s' % layer.name\r\n    if 'conv' in layer.name:\r\n        x = AveragePooling2D((3, 3), padding='same', strides=(\r\n            1, 1), name=name)(x)\r\n    elif 'pool' in layer.name:\r\n        x = AveragePooling2D((2, 2), name=name)(x)\r\nmask_model = Model(mask_input, x)\r\n\r\n# Collect features from image_model and task_model\r\nimage_features = {}\r\nmask_features = {}\r\nfor img_layer, mask_layer in zip(image_model.layers, mask_model.layers):\r\n    if 'conv' in img_layer.name:\r\n        assert 'mask_' + img_layer.name == mask_layer.name\r\n        layer_name = img_layer.name\r\n        img_feat, mask_feat = img_layer.output, mask_layer.output\r\n        image_features[layer_name] = img_feat\r\n        mask_features[layer_name] = mask_feat\r\n\r\n\r\n# Define loss functions\r\ndef gram_matrix(x):\r\n    assert K.ndim(x) == 3\r\n    features = K.batch_flatten(x)\r\n    gram = K.dot(features, K.transpose(features))\r\n    return gram\r\n\r\n\r\ndef region_style_loss(style_image, target_image, style_mask, target_mask):\r\n    '''Calculate style loss between style_image and target_image,\r\n    for one common region specified by their (boolean) masks\r\n    '''\r\n    assert 3 == K.ndim(style_image) == K.ndim(target_image)\r\n    assert 2 == K.ndim(style_mask) == K.ndim(target_mask)\r\n    if K.image_data_format() == 'channels_first':\r\n        masked_style = style_image * style_mask\r\n        masked_target = target_image * target_mask\r\n        num_channels = K.shape(style_image)[0]\r\n    else:\r\n        masked_style = K.permute_dimensions(\r\n            style_image, (2, 0, 1)) * style_mask\r\n        masked_target = K.permute_dimensions(\r\n            target_image, (2, 0, 1)) * target_mask\r\n        num_channels = K.shape(style_image)[-1]\r\n    num_channels = K.cast(num_channels, dtype='float32')\r\n    s = gram_matrix(masked_style) / K.mean(style_mask) / num_channels\r\n    c = gram_matrix(masked_target) / K.mean(target_mask) / num_channels\r\n    return K.mean(K.square(s - c))\r\n\r\n\r\ndef style_loss(style_image, target_image, style_masks, target_masks):\r\n    '''Calculate style loss between style_image and target_image,\r\n    in all regions.\r\n    '''\r\n    assert 3 == K.ndim(style_image) == K.ndim(target_image)\r\n    assert 3 == K.ndim(style_masks) == K.ndim(target_masks)\r\n    loss = K.variable(0)\r\n    for i in range(num_labels):\r\n        if K.image_data_format() == 'channels_first':\r\n            style_mask = style_masks[i, :, :]\r\n            target_mask = target_masks[i, :, :]\r\n        else:\r\n            style_mask = style_masks[:, :, i]\r\n            target_mask = target_masks[:, :, i]\r\n        loss = loss + region_style_loss(style_image,\r\n                                        target_image,\r\n                                        style_mask,\r\n                                        target_mask)\r\n    return loss\r\n\r\n\r\ndef content_loss(content_image, target_image):\r\n    return K.sum(K.square(target_image - content_image))\r\n\r\n\r\ndef total_variation_loss(x):\r\n    assert 4 == K.ndim(x)\r\n    if K.image_data_format() == 'channels_first':\r\n        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\r\n                     x[:, :, 1:, :img_ncols - 1])\r\n        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\r\n                     x[:, :, :img_nrows - 1, 1:])\r\n    else:\r\n        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] -\r\n                     x[:, 1:, :img_ncols - 1, :])\r\n        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] -\r\n                     x[:, :img_nrows - 1, 1:, :])\r\n    return K.sum(K.pow(a + b, 1.25))\r\n\r\n\r\n# Overall loss is the weighted sum of content_loss, style_loss and tv_loss\r\n# Each individual loss uses features from image/mask models.\r\nloss = K.variable(0)\r\nfor layer in content_feature_layers:\r\n    content_feat = image_features[layer][CONTENT, :, :, :]\r\n    target_feat = image_features[layer][TARGET, :, :, :]\r\n    loss = loss + content_weight * content_loss(content_feat, target_feat)\r\n\r\nfor layer in style_feature_layers:\r\n    style_feat = image_features[layer][STYLE, :, :, :]\r\n    target_feat = image_features[layer][TARGET, :, :, :]\r\n    style_masks = mask_features[layer][STYLE, :, :, :]\r\n    target_masks = mask_features[layer][TARGET, :, :, :]\r\n    sl = style_loss(style_feat, target_feat, style_masks, target_masks)\r\n    loss = loss + (style_weight / len(style_feature_layers)) * sl\r\n\r\nloss = loss + total_variation_weight * total_variation_loss(target_image)\r\nloss_grads = K.gradients(loss, target_image)\r\n\r\n# Evaluator class for computing efficiency\r\noutputs = [loss]\r\nif isinstance(loss_grads, (list, tuple)):\r\n    outputs += loss_grads\r\nelse:\r\n    outputs.append(loss_grads)\r\n\r\nf_outputs = K.function([target_image], outputs)\r\n\r\n\r\ndef eval_loss_and_grads(x):\r\n    if K.image_data_format() == 'channels_first':\r\n        x = x.reshape((1, 3, img_nrows, img_ncols))\r\n    else:\r\n        x = x.reshape((1, img_nrows, img_ncols, 3))\r\n    outs = f_outputs([x])\r\n    loss_value = outs[0]\r\n    if len(outs[1:]) == 1:\r\n        grad_values = outs[1].flatten().astype('float64')\r\n    else:\r\n        grad_values = np.array(outs[1:]).flatten().astype('float64')\r\n    return loss_value, grad_values\r\n\r\n\r\nclass Evaluator(object):\r\n\r\n    def __init__(self):\r\n        self.loss_value = None\r\n        self.grads_values = None\r\n\r\n    def loss(self, x):\r\n        assert self.loss_value is None\r\n        loss_value, grad_values = eval_loss_and_grads(x)\r\n        self.loss_value = loss_value\r\n        self.grad_values = grad_values\r\n        return self.loss_value\r\n\r\n    def grads(self, x):\r\n        assert self.loss_value is not None\r\n        grad_values = np.copy(self.grad_values)\r\n        self.loss_value = None\r\n        self.grad_values = None\r\n        return grad_values\r\n\r\n\r\nevaluator = Evaluator()\r\n\r\n# Generate images by iterative optimization\r\nif K.image_data_format() == 'channels_first':\r\n    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\r\nelse:\r\n    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\r\n\r\nfor i in range(num_iterations):\r\n    print('Start of iteration', i, '/', num_iterations)\r\n    start_time = time.time()\r\n    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\r\n                                     fprime=evaluator.grads, maxfun=20)\r\n    print('Current loss value:', min_val)\r\n    # save current generated image\r\n    img = deprocess_image(x.copy())\r\n    fname = target_img_prefix + '_at_iteration_%d.png' % i\r\n    save_img(fname, img)\r\n    end_time = time.time()\r\n    print('Image saved as', fname)\r\n    print('Iteration %d completed in %ds' % (i, end_time - start_time))\r\n"""
examples/neural_style_transfer.py,0,"b'\'\'\'Neural style transfer with Keras.\n\nRun the script with:\n```\npython neural_style_transfer.py path_to_your_base_image.jpg \\\n    path_to_your_reference.jpg prefix_for_results\n```\ne.g.:\n```\npython neural_style_transfer.py img/tuebingen.jpg \\\n    img/starry_night.jpg results/my_result\n```\nOptional parameters:\n```\n--iter, To specify the number of iterations \\\n    the style transfer takes place (Default is 10)\n--content_weight, The weight given to the content loss (Default is 0.025)\n--style_weight, The weight given to the style loss (Default is 1.0)\n--tv_weight, The weight given to the total variation loss (Default is 1.0)\n```\n\nIt is preferable to run this script on GPU, for speed.\n\nExample result: https://twitter.com/fchollet/status/686631033085677568\n\n# Details\n\nStyle transfer consists in generating an image\nwith the same ""content"" as a base image, but with the\n""style"" of a different picture (typically artistic).\n\nThis is achieved through the optimization of a loss function\nthat has 3 components: ""style loss"", ""content loss"",\nand ""total variation loss"":\n\n- The total variation loss imposes local spatial continuity between\nthe pixels of the combination image, giving it visual coherence.\n\n- The style loss is where the deep learning keeps in --that one is defined\nusing a deep convolutional neural network. Precisely, it consists in a sum of\nL2 distances between the Gram matrices of the representations of\nthe base image and the style reference image, extracted from\ndifferent layers of a convnet (trained on ImageNet). The general idea\nis to capture color/texture information at different spatial\nscales (fairly large scales --defined by the depth of the layer considered).\n\n - The content loss is a L2 distance between the features of the base\nimage (extracted from a deep layer) and the features of the combination image,\nkeeping the generated image close enough to the original one.\n\n# References\n    - [A Neural Algorithm of Artistic Style](http://arxiv.org/abs/1508.06576)\n\'\'\'\n\nfrom __future__ import print_function\nfrom keras.preprocessing.image import load_img, save_img, img_to_array\nimport numpy as np\nfrom scipy.optimize import fmin_l_bfgs_b\nimport time\nimport argparse\n\nfrom keras.applications import vgg19\nfrom keras import backend as K\n\nparser = argparse.ArgumentParser(description=\'Neural style transfer with Keras.\')\nparser.add_argument(\'base_image_path\', metavar=\'base\', type=str,\n                    help=\'Path to the image to transform.\')\nparser.add_argument(\'style_reference_image_path\', metavar=\'ref\', type=str,\n                    help=\'Path to the style reference image.\')\nparser.add_argument(\'result_prefix\', metavar=\'res_prefix\', type=str,\n                    help=\'Prefix for the saved results.\')\nparser.add_argument(\'--iter\', type=int, default=10, required=False,\n                    help=\'Number of iterations to run.\')\nparser.add_argument(\'--content_weight\', type=float, default=0.025, required=False,\n                    help=\'Content weight.\')\nparser.add_argument(\'--style_weight\', type=float, default=1.0, required=False,\n                    help=\'Style weight.\')\nparser.add_argument(\'--tv_weight\', type=float, default=1.0, required=False,\n                    help=\'Total Variation weight.\')\n\nargs = parser.parse_args()\nbase_image_path = args.base_image_path\nstyle_reference_image_path = args.style_reference_image_path\nresult_prefix = args.result_prefix\niterations = args.iter\n\n# these are the weights of the different loss components\ntotal_variation_weight = args.tv_weight\nstyle_weight = args.style_weight\ncontent_weight = args.content_weight\n\n# dimensions of the generated picture.\nwidth, height = load_img(base_image_path).size\nimg_nrows = 400\nimg_ncols = int(width * img_nrows / height)\n\n# util function to open, resize and format pictures into appropriate tensors\n\n\ndef preprocess_image(image_path):\n    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = vgg19.preprocess_input(img)\n    return img\n\n# util function to convert a tensor into a valid image\n\n\ndef deprocess_image(x):\n    if K.image_data_format() == \'channels_first\':\n        x = x.reshape((3, img_nrows, img_ncols))\n        x = x.transpose((1, 2, 0))\n    else:\n        x = x.reshape((img_nrows, img_ncols, 3))\n    # Remove zero-center by mean pixel\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    # \'BGR\'->\'RGB\'\n    x = x[:, :, ::-1]\n    x = np.clip(x, 0, 255).astype(\'uint8\')\n    return x\n\n# get tensor representations of our images\nbase_image = K.variable(preprocess_image(base_image_path))\nstyle_reference_image = K.variable(preprocess_image(style_reference_image_path))\n\n# this will contain our generated image\nif K.image_data_format() == \'channels_first\':\n    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\nelse:\n    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n\n# combine the 3 images into a single Keras tensor\ninput_tensor = K.concatenate([base_image,\n                              style_reference_image,\n                              combination_image], axis=0)\n\n# build the VGG19 network with our 3 images as input\n# the model will be loaded with pre-trained ImageNet weights\nmodel = vgg19.VGG19(input_tensor=input_tensor,\n                    weights=\'imagenet\', include_top=False)\nprint(\'Model loaded.\')\n\n# get the symbolic outputs of each ""key"" layer (we gave them unique names).\noutputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n\n# compute the neural style loss\n# first we need to define 4 util functions\n\n# the gram matrix of an image tensor (feature-wise outer product)\n\n\ndef gram_matrix(x):\n    assert K.ndim(x) == 3\n    if K.image_data_format() == \'channels_first\':\n        features = K.batch_flatten(x)\n    else:\n        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n    gram = K.dot(features, K.transpose(features))\n    return gram\n\n# the ""style loss"" is designed to maintain\n# the style of the reference image in the generated image.\n# It is based on the gram matrices (which capture style) of\n# feature maps from the style reference image\n# and from the generated image\n\n\ndef style_loss(style, combination):\n    assert K.ndim(style) == 3\n    assert K.ndim(combination) == 3\n    S = gram_matrix(style)\n    C = gram_matrix(combination)\n    channels = 3\n    size = img_nrows * img_ncols\n    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n\n# an auxiliary loss function\n# designed to maintain the ""content"" of the\n# base image in the generated image\n\n\ndef content_loss(base, combination):\n    return K.sum(K.square(combination - base))\n\n# the 3rd loss function, total variation loss,\n# designed to keep the generated image locally coherent\n\n\ndef total_variation_loss(x):\n    assert K.ndim(x) == 4\n    if K.image_data_format() == \'channels_first\':\n        a = K.square(\n            x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n        b = K.square(\n            x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n    else:\n        a = K.square(\n            x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n        b = K.square(\n            x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n    return K.sum(K.pow(a + b, 1.25))\n\n\n# combine these loss functions into a single scalar\nloss = K.variable(0.0)\nlayer_features = outputs_dict[\'block5_conv2\']\nbase_image_features = layer_features[0, :, :, :]\ncombination_features = layer_features[2, :, :, :]\nloss = loss + content_weight * content_loss(base_image_features,\n                                            combination_features)\n\nfeature_layers = [\'block1_conv1\', \'block2_conv1\',\n                  \'block3_conv1\', \'block4_conv1\',\n                  \'block5_conv1\']\nfor layer_name in feature_layers:\n    layer_features = outputs_dict[layer_name]\n    style_reference_features = layer_features[1, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    sl = style_loss(style_reference_features, combination_features)\n    loss = loss + (style_weight / len(feature_layers)) * sl\nloss = loss + total_variation_weight * total_variation_loss(combination_image)\n\n# get the gradients of the generated image wrt the loss\ngrads = K.gradients(loss, combination_image)\n\noutputs = [loss]\nif isinstance(grads, (list, tuple)):\n    outputs += grads\nelse:\n    outputs.append(grads)\n\nf_outputs = K.function([combination_image], outputs)\n\n\ndef eval_loss_and_grads(x):\n    if K.image_data_format() == \'channels_first\':\n        x = x.reshape((1, 3, img_nrows, img_ncols))\n    else:\n        x = x.reshape((1, img_nrows, img_ncols, 3))\n    outs = f_outputs([x])\n    loss_value = outs[0]\n    if len(outs[1:]) == 1:\n        grad_values = outs[1].flatten().astype(\'float64\')\n    else:\n        grad_values = np.array(outs[1:]).flatten().astype(\'float64\')\n    return loss_value, grad_values\n\n# this Evaluator class makes it possible\n# to compute loss and gradients in one pass\n# while retrieving them via two separate functions,\n# ""loss"" and ""grads"". This is done because scipy.optimize\n# requires separate functions for loss and gradients,\n# but computing them separately would be inefficient.\n\n\nclass Evaluator(object):\n\n    def __init__(self):\n        self.loss_value = None\n        self.grads_values = None\n\n    def loss(self, x):\n        assert self.loss_value is None\n        loss_value, grad_values = eval_loss_and_grads(x)\n        self.loss_value = loss_value\n        self.grad_values = grad_values\n        return self.loss_value\n\n    def grads(self, x):\n        assert self.loss_value is not None\n        grad_values = np.copy(self.grad_values)\n        self.loss_value = None\n        self.grad_values = None\n        return grad_values\n\n\nevaluator = Evaluator()\n\n# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n# so as to minimize the neural style loss\nx = preprocess_image(base_image_path)\n\nfor i in range(iterations):\n    print(\'Start of iteration\', i)\n    start_time = time.time()\n    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n                                     fprime=evaluator.grads, maxfun=20)\n    print(\'Current loss value:\', min_val)\n    # save current generated image\n    img = deprocess_image(x.copy())\n    fname = result_prefix + \'_at_iteration_%d.png\' % i\n    save_img(fname, img)\n    end_time = time.time()\n    print(\'Image saved as\', fname)\n    print(\'Iteration %d completed in %ds\' % (i, end_time - start_time))\n'"
examples/pretrained_word_embeddings.py,0,"b""'''This script loads pre-trained word embeddings (GloVe embeddings)\ninto a frozen Keras Embedding layer, and uses it to\ntrain a text classification model on the 20 Newsgroup dataset\n(classification of newsgroup messages into 20 different categories).\n\nGloVe embedding data can be found at:\nhttp://nlp.stanford.edu/data/glove.6B.zip\n(source page: http://nlp.stanford.edu/projects/glove/)\n\n20 Newsgroup data can be found at:\nhttp://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html\n'''\n\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport numpy as np\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Input, GlobalMaxPooling1D\nfrom keras.layers import Conv1D, MaxPooling1D, Embedding\nfrom keras.models import Model\nfrom keras.initializers import Constant\n\n\nBASE_DIR = ''\nGLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\nTEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\nMAX_SEQUENCE_LENGTH = 1000\nMAX_NUM_WORDS = 20000\nEMBEDDING_DIM = 100\nVALIDATION_SPLIT = 0.2\n\n# first, build index mapping words in the embeddings set\n# to their embedding vector\n\nprint('Indexing word vectors.')\n\nembeddings_index = {}\nwith open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n    for line in f:\n        word, coefs = line.split(maxsplit=1)\n        coefs = np.fromstring(coefs, 'f', sep=' ')\n        embeddings_index[word] = coefs\n\nprint('Found %s word vectors.' % len(embeddings_index))\n\n# second, prepare text samples and their labels\nprint('Processing text dataset')\n\ntexts = []  # list of text samples\nlabels_index = {}  # dictionary mapping label name to numeric id\nlabels = []  # list of label ids\nfor name in sorted(os.listdir(TEXT_DATA_DIR)):\n    path = os.path.join(TEXT_DATA_DIR, name)\n    if os.path.isdir(path):\n        label_id = len(labels_index)\n        labels_index[name] = label_id\n        for fname in sorted(os.listdir(path)):\n            if fname.isdigit():\n                fpath = os.path.join(path, fname)\n                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n                with open(fpath, **args) as f:\n                    t = f.read()\n                    i = t.find('\\n\\n')  # skip header\n                    if 0 < i:\n                        t = t[i:]\n                    texts.append(t)\n                labels.append(label_id)\n\nprint('Found %s texts.' % len(texts))\n\n# finally, vectorize the text samples into a 2D integer tensor\ntokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n\nlabels = to_categorical(np.asarray(labels))\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)\n\n# split the data into a training set and a validation set\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\nnum_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n\nx_train = data[:-num_validation_samples]\ny_train = labels[:-num_validation_samples]\nx_val = data[-num_validation_samples:]\ny_val = labels[-num_validation_samples:]\n\nprint('Preparing embedding matrix.')\n\n# prepare embedding matrix\nnum_words = min(MAX_NUM_WORDS, len(word_index) + 1)\nembedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    if i >= MAX_NUM_WORDS:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector\n\n# load pre-trained word embeddings into an Embedding layer\n# note that we set trainable = False so as to keep the embeddings fixed\nembedding_layer = Embedding(num_words,\n                            EMBEDDING_DIM,\n                            embeddings_initializer=Constant(embedding_matrix),\n                            input_length=MAX_SEQUENCE_LENGTH,\n                            trainable=False)\n\nprint('Training model.')\n\n# train a 1D convnet with global maxpooling\nsequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\nembedded_sequences = embedding_layer(sequence_input)\nx = Conv1D(128, 5, activation='relu')(embedded_sequences)\nx = MaxPooling1D(5)(x)\nx = Conv1D(128, 5, activation='relu')(x)\nx = MaxPooling1D(5)(x)\nx = Conv1D(128, 5, activation='relu')(x)\nx = GlobalMaxPooling1D()(x)\nx = Dense(128, activation='relu')(x)\npreds = Dense(len(labels_index), activation='softmax')(x)\n\nmodel = Model(sequence_input, preds)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['acc'])\n\nmodel.fit(x_train, y_train,\n          batch_size=128,\n          epochs=10,\n          validation_data=(x_val, y_val))\n"""
examples/reuters_mlp.py,0,"b""'''Trains and evaluate a simple MLP\non the Reuters newswire topic classification task.\n'''\nfrom __future__ import print_function\n\nimport numpy as np\nimport keras\nfrom keras.datasets import reuters\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.preprocessing.text import Tokenizer\n\nmax_words = 1000\nbatch_size = 32\nepochs = 5\n\nprint('Loading data...')\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2)\nprint(len(x_train), 'train sequences')\nprint(len(x_test), 'test sequences')\n\nnum_classes = np.max(y_train) + 1\nprint(num_classes, 'classes')\n\nprint('Vectorizing sequence data...')\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n\nprint('Convert class vector to binary class matrix '\n      '(for use with categorical_crossentropy)')\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\nprint('y_train shape:', y_train.shape)\nprint('y_test shape:', y_test.shape)\n\nprint('Building model...')\nmodel = Sequential()\nmodel.add(Dense(512, input_shape=(max_words,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_split=0.1)\nscore = model.evaluate(x_test, y_test,\n                       batch_size=batch_size, verbose=1)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\n"""
examples/reuters_mlp_relu_vs_selu.py,0,"b'\'\'\'Compares self-normalizing MLPs with regular MLPs.\n\nCompares the performance of a simple MLP using two\ndifferent activation functions: RELU and SELU\non the Reuters newswire topic classification task.\n\n# Reference\n\n- Klambauer, G., Unterthiner, T., Mayr, A., & Hochreiter, S. (2017).\n  Self-Normalizing Neural Networks. arXiv preprint arXiv:1706.02515.\n  https://arxiv.org/abs/1706.02515\n\'\'\'\nfrom __future__ import print_function\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.datasets import reuters\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers.noise import AlphaDropout\nfrom keras.preprocessing.text import Tokenizer\n\nmax_words = 1000\nbatch_size = 16\nepochs = 40\nplot = True\n\n\ndef create_network(n_dense=6,\n                   dense_units=16,\n                   activation=\'selu\',\n                   dropout=AlphaDropout,\n                   dropout_rate=0.1,\n                   kernel_initializer=\'lecun_normal\',\n                   optimizer=\'adam\',\n                   num_classes=1,\n                   max_words=max_words):\n    """"""Generic function to create a fully-connected neural network.\n\n    # Arguments\n        n_dense: int > 0. Number of dense layers.\n        dense_units: int > 0. Number of dense units per layer.\n        dropout: keras.layers.Layer. A dropout layer to apply.\n        dropout_rate: 0 <= float <= 1. The rate of dropout.\n        kernel_initializer: str. The initializer for the weights.\n        optimizer: str/keras.optimizers.Optimizer. The optimizer to use.\n        num_classes: int > 0. The number of classes to predict.\n        max_words: int > 0. The maximum number of words per data point.\n\n    # Returns\n        A Keras model instance (compiled).\n    """"""\n    model = Sequential()\n    model.add(Dense(dense_units, input_shape=(max_words,),\n                    kernel_initializer=kernel_initializer))\n    model.add(Activation(activation))\n    model.add(dropout(dropout_rate))\n\n    for i in range(n_dense - 1):\n        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n        model.add(Activation(activation))\n        model.add(dropout(dropout_rate))\n\n    model.add(Dense(num_classes))\n    model.add(Activation(\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=optimizer,\n                  metrics=[\'accuracy\'])\n    return model\n\n\nnetwork1 = {\n    \'n_dense\': 6,\n    \'dense_units\': 16,\n    \'activation\': \'relu\',\n    \'dropout\': Dropout,\n    \'dropout_rate\': 0.5,\n    \'kernel_initializer\': \'glorot_uniform\',\n    \'optimizer\': \'sgd\'\n}\n\nnetwork2 = {\n    \'n_dense\': 6,\n    \'dense_units\': 16,\n    \'activation\': \'selu\',\n    \'dropout\': AlphaDropout,\n    \'dropout_rate\': 0.1,\n    \'kernel_initializer\': \'lecun_normal\',\n    \'optimizer\': \'sgd\'\n}\n\nprint(\'Loading data...\')\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2)\nprint(len(x_train), \'train sequences\')\nprint(len(x_test), \'test sequences\')\n\nnum_classes = np.max(y_train) + 1\nprint(num_classes, \'classes\')\n\nprint(\'Vectorizing sequence data...\')\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode=\'binary\')\nx_test = tokenizer.sequences_to_matrix(x_test, mode=\'binary\')\nprint(\'x_train shape:\', x_train.shape)\nprint(\'x_test shape:\', x_test.shape)\n\nprint(\'Convert class vector to binary class matrix \'\n      \'(for use with categorical_crossentropy)\')\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\nprint(\'y_train shape:\', y_train.shape)\nprint(\'y_test shape:\', y_test.shape)\n\nprint(\'\\nBuilding network 1...\')\n\nmodel1 = create_network(num_classes=num_classes, **network1)\nhistory_model1 = model1.fit(x_train,\n                            y_train,\n                            batch_size=batch_size,\n                            epochs=epochs,\n                            verbose=1,\n                            validation_split=0.1)\n\nscore_model1 = model1.evaluate(x_test,\n                               y_test,\n                               batch_size=batch_size,\n                               verbose=1)\n\n\nprint(\'\\nBuilding network 2...\')\nmodel2 = create_network(num_classes=num_classes, **network2)\n\nhistory_model2 = model2.fit(x_train,\n                            y_train,\n                            batch_size=batch_size,\n                            epochs=epochs,\n                            verbose=1,\n                            validation_split=0.1)\n\nscore_model2 = model2.evaluate(x_test,\n                               y_test,\n                               batch_size=batch_size,\n                               verbose=1)\n\nprint(\'\\nNetwork 1 results\')\nprint(\'Hyperparameters:\', network1)\nprint(\'Test score:\', score_model1[0])\nprint(\'Test accuracy:\', score_model1[1])\nprint(\'Network 2 results\')\nprint(\'Hyperparameters:\', network2)\nprint(\'Test score:\', score_model2[0])\nprint(\'Test accuracy:\', score_model2[1])\n\nplt.plot(range(epochs),\n         history_model1.history[\'val_loss\'],\n         \'g-\',\n         label=\'Network 1 Val Loss\')\nplt.plot(range(epochs),\n         history_model2.history[\'val_loss\'],\n         \'r-\',\n         label=\'Network 2 Val Loss\')\nplt.plot(range(epochs),\n         history_model1.history[\'loss\'],\n         \'g--\',\n         label=\'Network 1 Loss\')\nplt.plot(range(epochs),\n         history_model2.history[\'loss\'],\n         \'r--\',\n         label=\'Network 2 Loss\')\nplt.xlabel(\'Epochs\')\nplt.ylabel(\'Loss\')\nplt.legend()\nplt.savefig(\'comparison_of_networks.png\')\n'"
examples/variational_autoencoder.py,0,"b'\'\'\'Example of VAE on MNIST dataset using MLP\n\nThe VAE has a modular design. The encoder, decoder and VAE\nare 3 models that share weights. After training the VAE model,\nthe encoder can be used to generate latent vectors.\nThe decoder can be used to generate MNIST digits by sampling the\nlatent vector from a Gaussian distribution with mean = 0 and std = 1.\n\n# Reference\n\n[1] Kingma, Diederik P., and Max Welling.\n""Auto-Encoding Variational Bayes.""\nhttps://arxiv.org/abs/1312.6114\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras.layers import Lambda, Input, Dense\nfrom keras.models import Model\nfrom keras.datasets import mnist\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.utils import plot_model\nfrom keras import backend as K\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport os\n\n\n# reparameterization trick\n# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n# z = z_mean + sqrt(var) * epsilon\ndef sampling(args):\n    """"""Reparameterization trick by sampling from an isotropic unit Gaussian.\n\n    # Arguments\n        args (tensor): mean and log of variance of Q(z|X)\n\n    # Returns\n        z (tensor): sampled latent vector\n    """"""\n\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean = 0 and std = 1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n\n\ndef plot_results(models,\n                 data,\n                 batch_size=128,\n                 model_name=""vae_mnist""):\n    """"""Plots labels and MNIST digits as a function of the 2D latent vector\n\n    # Arguments\n        models (tuple): encoder and decoder models\n        data (tuple): test data and label\n        batch_size (int): prediction batch size\n        model_name (string): which model is using this function\n    """"""\n\n    encoder, decoder = models\n    x_test, y_test = data\n    os.makedirs(model_name, exist_ok=True)\n\n    filename = os.path.join(model_name, ""vae_mean.png"")\n    # display a 2D plot of the digit classes in the latent space\n    z_mean, _, _ = encoder.predict(x_test,\n                                   batch_size=batch_size)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n    plt.colorbar()\n    plt.xlabel(""z[0]"")\n    plt.ylabel(""z[1]"")\n    plt.savefig(filename)\n    plt.show()\n\n    filename = os.path.join(model_name, ""digits_over_latent.png"")\n    # display a 30x30 2D manifold of digits\n    n = 30\n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-4, 4, n)\n    grid_y = np.linspace(-4, 4, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            figure[i * digit_size: (i + 1) * digit_size,\n                   j * digit_size: (j + 1) * digit_size] = digit\n\n    plt.figure(figsize=(10, 10))\n    start_range = digit_size // 2\n    end_range = (n - 1) * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(""z[0]"")\n    plt.ylabel(""z[1]"")\n    plt.imshow(figure, cmap=\'Greys_r\')\n    plt.savefig(filename)\n    plt.show()\n\n\n# MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nimage_size = x_train.shape[1]\noriginal_dim = image_size * image_size\nx_train = np.reshape(x_train, [-1, original_dim])\nx_test = np.reshape(x_test, [-1, original_dim])\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\ninput_shape = (original_dim, )\nintermediate_dim = 512\nbatch_size = 128\nlatent_dim = 2\nepochs = 50\n\n# VAE model = encoder + decoder\n# build encoder model\ninputs = Input(shape=input_shape, name=\'encoder_input\')\nx = Dense(intermediate_dim, activation=\'relu\')(inputs)\nz_mean = Dense(latent_dim, name=\'z_mean\')(x)\nz_log_var = Dense(latent_dim, name=\'z_log_var\')(x)\n\n# use reparameterization trick to push the sampling out as input\n# note that ""output_shape"" isn\'t necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,), name=\'z\')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = Model(inputs, [z_mean, z_log_var, z], name=\'encoder\')\nencoder.summary()\nplot_model(encoder, to_file=\'vae_mlp_encoder.png\', show_shapes=True)\n\n# build decoder model\nlatent_inputs = Input(shape=(latent_dim,), name=\'z_sampling\')\nx = Dense(intermediate_dim, activation=\'relu\')(latent_inputs)\noutputs = Dense(original_dim, activation=\'sigmoid\')(x)\n\n# instantiate decoder model\ndecoder = Model(latent_inputs, outputs, name=\'decoder\')\ndecoder.summary()\nplot_model(decoder, to_file=\'vae_mlp_decoder.png\', show_shapes=True)\n\n# instantiate VAE model\noutputs = decoder(encoder(inputs)[2])\nvae = Model(inputs, outputs, name=\'vae_mlp\')\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    help_ = ""Load h5 model trained weights""\n    parser.add_argument(""-w"", ""--weights"", help=help_)\n    help_ = ""Use mse loss instead of binary cross entropy (default)""\n    parser.add_argument(""-m"",\n                        ""--mse"",\n                        help=help_, action=\'store_true\')\n    args = parser.parse_args()\n    models = (encoder, decoder)\n    data = (x_test, y_test)\n\n    # VAE loss = mse_loss or xent_loss + kl_loss\n    if args.mse:\n        reconstruction_loss = mse(inputs, outputs)\n    else:\n        reconstruction_loss = binary_crossentropy(inputs,\n                                                  outputs)\n\n    reconstruction_loss *= original_dim\n    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n    vae_loss = K.mean(reconstruction_loss + kl_loss)\n    vae.add_loss(vae_loss)\n    vae.compile(optimizer=\'adam\')\n    vae.summary()\n    plot_model(vae,\n               to_file=\'vae_mlp.png\',\n               show_shapes=True)\n\n    if args.weights:\n        vae.load_weights(args.weights)\n    else:\n        # train the autoencoder\n        vae.fit(x_train,\n                epochs=epochs,\n                batch_size=batch_size,\n                validation_data=(x_test, None))\n        vae.save_weights(\'vae_mlp_mnist.h5\')\n\n    plot_results(models,\n                 data,\n                 batch_size=batch_size,\n                 model_name=""vae_mlp"")\n'"
examples/variational_autoencoder_deconv.py,0,"b'\'\'\'Example of VAE on MNIST dataset using CNN\n\nThe VAE has a modular design. The encoder, decoder and VAE\nare 3 models that share weights. After training the VAE model,\nthe encoder can be used to  generate latent vectors.\nThe decoder can be used to generate MNIST digits by sampling the\nlatent vector from a Gaussian distribution with mean=0 and std=1.\n\n# Reference\n\n[1] Kingma, Diederik P., and Max Welling.\n""Auto-encoding variational bayes.""\nhttps://arxiv.org/abs/1312.6114\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras.layers import Dense, Input\nfrom keras.layers import Conv2D, Flatten, Lambda\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.datasets import mnist\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.utils import plot_model\nfrom keras import backend as K\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport os\n\n\n# reparameterization trick\n# instead of sampling from Q(z|X), sample eps = N(0,I)\n# then z = z_mean + sqrt(var)*eps\ndef sampling(args):\n    """"""Reparameterization trick by sampling fr an isotropic unit Gaussian.\n\n    # Arguments\n        args (tensor): mean and log of variance of Q(z|X)\n\n    # Returns\n        z (tensor): sampled latent vector\n    """"""\n\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n\n\ndef plot_results(models,\n                 data,\n                 batch_size=128,\n                 model_name=""vae_mnist""):\n    """"""Plots labels and MNIST digits as function of 2-dim latent vector\n\n    # Arguments\n        models (tuple): encoder and decoder models\n        data (tuple): test data and label\n        batch_size (int): prediction batch size\n        model_name (string): which model is using this function\n    """"""\n\n    encoder, decoder = models\n    x_test, y_test = data\n    os.makedirs(model_name, exist_ok=True)\n\n    filename = os.path.join(model_name, ""vae_mean.png"")\n    # display a 2D plot of the digit classes in the latent space\n    z_mean, _, _ = encoder.predict(x_test,\n                                   batch_size=batch_size)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n    plt.colorbar()\n    plt.xlabel(""z[0]"")\n    plt.ylabel(""z[1]"")\n    plt.savefig(filename)\n    plt.show()\n\n    filename = os.path.join(model_name, ""digits_over_latent.png"")\n    # display a 30x30 2D manifold of digits\n    n = 30\n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-4, 4, n)\n    grid_y = np.linspace(-4, 4, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            figure[i * digit_size: (i + 1) * digit_size,\n                   j * digit_size: (j + 1) * digit_size] = digit\n\n    plt.figure(figsize=(10, 10))\n    start_range = digit_size // 2\n    end_range = n * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(""z[0]"")\n    plt.ylabel(""z[1]"")\n    plt.imshow(figure, cmap=\'Greys_r\')\n    plt.savefig(filename)\n    plt.show()\n\n\n# MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1])\nx_test = np.reshape(x_test, [-1, image_size, image_size, 1])\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\nfilters = 16\nlatent_dim = 2\nepochs = 30\n\n# VAE model = encoder + decoder\n# build encoder model\ninputs = Input(shape=input_shape, name=\'encoder_input\')\nx = inputs\nfor i in range(2):\n    filters *= 2\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               activation=\'relu\',\n               strides=2,\n               padding=\'same\')(x)\n\n# shape info needed to build decoder model\nshape = K.int_shape(x)\n\n# generate latent vector Q(z|X)\nx = Flatten()(x)\nx = Dense(16, activation=\'relu\')(x)\nz_mean = Dense(latent_dim, name=\'z_mean\')(x)\nz_log_var = Dense(latent_dim, name=\'z_log_var\')(x)\n\n# use reparameterization trick to push the sampling out as input\n# note that ""output_shape"" isn\'t necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,), name=\'z\')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = Model(inputs, [z_mean, z_log_var, z], name=\'encoder\')\nencoder.summary()\nplot_model(encoder, to_file=\'vae_cnn_encoder.png\', show_shapes=True)\n\n# build decoder model\nlatent_inputs = Input(shape=(latent_dim,), name=\'z_sampling\')\nx = Dense(shape[1] * shape[2] * shape[3], activation=\'relu\')(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\n\nfor i in range(2):\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        activation=\'relu\',\n                        strides=2,\n                        padding=\'same\')(x)\n    filters //= 2\n\noutputs = Conv2DTranspose(filters=1,\n                          kernel_size=kernel_size,\n                          activation=\'sigmoid\',\n                          padding=\'same\',\n                          name=\'decoder_output\')(x)\n\n# instantiate decoder model\ndecoder = Model(latent_inputs, outputs, name=\'decoder\')\ndecoder.summary()\nplot_model(decoder, to_file=\'vae_cnn_decoder.png\', show_shapes=True)\n\n# instantiate VAE model\noutputs = decoder(encoder(inputs)[2])\nvae = Model(inputs, outputs, name=\'vae\')\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    help_ = ""Load h5 model trained weights""\n    parser.add_argument(""-w"", ""--weights"", help=help_)\n    help_ = ""Use mse loss instead of binary cross entropy (default)""\n    parser.add_argument(""-m"", ""--mse"", help=help_, action=\'store_true\')\n    args = parser.parse_args()\n    models = (encoder, decoder)\n    data = (x_test, y_test)\n\n    # VAE loss = mse_loss or xent_loss + kl_loss\n    if args.mse:\n        reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n    else:\n        reconstruction_loss = binary_crossentropy(K.flatten(inputs),\n                                                  K.flatten(outputs))\n\n    reconstruction_loss *= image_size * image_size\n    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n    vae_loss = K.mean(reconstruction_loss + kl_loss)\n    vae.add_loss(vae_loss)\n    vae.compile(optimizer=\'rmsprop\')\n    vae.summary()\n    plot_model(vae, to_file=\'vae_cnn.png\', show_shapes=True)\n\n    if args.weights:\n        vae.load_weights(args.weights)\n    else:\n        # train the autoencoder\n        vae.fit(x_train,\n                epochs=epochs,\n                batch_size=batch_size,\n                validation_data=(x_test, None))\n        vae.save_weights(\'vae_cnn_mnist.h5\')\n\n    plot_results(models, data, batch_size=batch_size, model_name=""vae_cnn"")\n'"
keras/__init__.py,0,"b""from __future__ import absolute_import\r\n\r\nfrom . import utils\r\nfrom . import activations\r\nfrom . import applications\r\nfrom . import backend\r\nfrom . import datasets\r\nfrom . import engine\r\nfrom . import layers\r\nfrom . import preprocessing\r\nfrom . import wrappers\r\nfrom . import callbacks\r\nfrom . import constraints\r\nfrom . import initializers\r\nfrom . import metrics\r\nfrom . import models\r\nfrom . import losses\r\nfrom . import optimizers\r\nfrom . import regularizers\r\n\r\n# Also importable from root\r\nfrom .layers import Input\r\nfrom .models import Model\r\nfrom .models import Sequential\r\n\r\n__version__ = '2.3.1'\r\n"""
keras/activations.py,0,"b'""""""Built-in activation functions.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport warnings\nfrom . import backend as K\nfrom .utils.generic_utils import deserialize_keras_object\nfrom .engine import Layer\n\n\ndef softmax(x, axis=-1):\n    """"""Softmax activation function.\n\n    # Arguments\n        x: Input tensor.\n        axis: Integer, axis along which the softmax normalization is applied.\n\n    # Returns\n        Tensor, output of softmax transformation.\n\n    # Raises\n        ValueError: In case `dim(x) == 1`.\n    """"""\n    ndim = K.ndim(x)\n    if ndim == 2:\n        return K.softmax(x)\n    elif ndim > 2:\n        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n        s = K.sum(e, axis=axis, keepdims=True)\n        return e / s\n    else:\n        raise ValueError(\'Cannot apply softmax to a tensor that is 1D. \'\n                         \'Received input: %s\' % x)\n\n\ndef elu(x, alpha=1.0):\n    """"""Exponential linear unit.\n\n    # Arguments\n        x: Input tensor.\n        alpha: A scalar, slope of negative section.\n\n    # Returns\n        The exponential linear activation: `x` if `x > 0` and\n        `alpha * (exp(x)-1)` if `x < 0`.\n\n    # References\n        - [Fast and Accurate Deep Network Learning by Exponential\n           Linear Units (ELUs)](https://arxiv.org/abs/1511.07289)\n    """"""\n    return K.elu(x, alpha)\n\n\ndef selu(x):\n    """"""Scaled Exponential Linear Unit (SELU).\n\n    SELU is equal to: `scale * elu(x, alpha)`, where alpha and scale\n    are predefined constants. The values of `alpha` and `scale` are\n    chosen so that the mean and variance of the inputs are preserved\n    between two consecutive layers as long as the weights are initialized\n    correctly (see `lecun_normal` initialization) and the number of inputs\n    is ""large enough"" (see references for more information).\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n\n    # Returns\n       The scaled exponential unit activation: `scale * elu(x, alpha)`.\n\n    # Note\n        - To be used together with the initialization ""lecun_normal"".\n        - To be used together with the dropout variant ""AlphaDropout"".\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n    """"""\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    return scale * K.elu(x, alpha)\n\n\ndef softplus(x):\n    """"""Softplus activation function.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        The softplus activation: `log(exp(x) + 1)`.\n    """"""\n    return K.softplus(x)\n\n\ndef softsign(x):\n    """"""Softsign activation function.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        The softsign activation: `x / (abs(x) + 1)`.\n    """"""\n    return K.softsign(x)\n\n\ndef relu(x, alpha=0., max_value=None, threshold=0.):\n    """"""Rectified Linear Unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    Otherwise, it follows:\n    `f(x) = max_value` for `x >= max_value`,\n    `f(x) = x` for `threshold <= x < max_value`,\n    `f(x) = alpha * (x - threshold)` otherwise.\n\n    # Arguments\n        x: Input tensor.\n        alpha: float. Slope of the negative part. Defaults to zero.\n        max_value: float. Saturation threshold.\n        threshold: float. Threshold value for thresholded activation.\n\n    # Returns\n        A tensor.\n    """"""\n    return K.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n\n\ndef tanh(x):\n    """"""Hyperbolic tangent activation function.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        The hyperbolic activation:\n        `tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`\n\n    """"""\n    return K.tanh(x)\n\n\ndef sigmoid(x):\n    """"""Sigmoid activation function.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        The sigmoid activation: `1 / (1 + exp(-x))`.\n    """"""\n    return K.sigmoid(x)\n\n\ndef hard_sigmoid(x):\n    """"""Hard sigmoid activation function.\n\n    Faster to compute than sigmoid activation.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        Hard sigmoid activation:\n\n        - `0` if `x < -2.5`\n        - `1` if `x > 2.5`\n        - `0.2 * x + 0.5` if `-2.5 <= x <= 2.5`.\n    """"""\n    return K.hard_sigmoid(x)\n\n\ndef exponential(x):\n    """"""Exponential (base e) activation function.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        Exponential activation: `exp(x)`.\n    """"""\n    return K.exp(x)\n\n\ndef linear(x):\n    """"""Linear (i.e. identity) activation function.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        Input tensor, unchanged.\n    """"""\n    return x\n\n\ndef serialize(activation):\n    return activation.__name__\n\n\ndef deserialize(name, custom_objects=None):\n    return deserialize_keras_object(\n        name,\n        module_objects=globals(),\n        custom_objects=custom_objects,\n        printable_module_name=\'activation function\')\n\n\ndef get(identifier):\n    """"""Get the `identifier` activation function.\n\n    # Arguments\n        identifier: None or str, name of the function.\n\n    # Returns\n        The activation function, `linear` if `identifier` is None.\n\n    # Raises\n        ValueError if unknown identifier\n    """"""\n    if identifier is None:\n        return linear\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    elif callable(identifier):\n        if isinstance(identifier, Layer):\n            warnings.warn(\n                \'Do not pass a layer instance (such as {identifier}) as the \'\n                \'activation argument of another layer. Instead, advanced \'\n                \'activation layers should be used just like any other \'\n                \'layer in a model.\'.format(\n                    identifier=identifier.__class__.__name__))\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret \'\n                         \'activation function identifier:\', identifier)\n'"
keras/constraints.py,0,"b'""""""Constraints: functions that impose constraints on weight values.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nfrom . import backend as K\nfrom .utils.generic_utils import serialize_keras_object\nfrom .utils.generic_utils import deserialize_keras_object\n\n\nclass Constraint(object):\n\n    def __call__(self, w):\n        return w\n\n    def get_config(self):\n        return {}\n\n\nclass MaxNorm(Constraint):\n    """"""MaxNorm weight constraint.\n\n    Constrains the weights incident to each hidden unit\n    to have a norm less than or equal to a desired value.\n\n    # Arguments\n        max_value: the maximum norm for the incoming weights.\n        axis: integer, axis along which to calculate weight norms.\n            For instance, in a `Dense` layer the weight matrix\n            has shape `(input_dim, output_dim)`,\n            set `axis` to `0` to constrain each weight vector\n            of length `(input_dim,)`.\n            In a `Conv2D` layer with `data_format=""channels_last""`,\n            the weight tensor has shape\n            `(rows, cols, input_depth, output_depth)`,\n            set `axis` to `[0, 1, 2]`\n            to constrain the weights of each filter tensor of size\n            `(rows, cols, input_depth)`.\n\n    # References\n        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n           http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n    """"""\n\n    def __init__(self, max_value=2, axis=0):\n        self.max_value = max_value\n        self.axis = axis\n\n    def __call__(self, w):\n        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n        desired = K.clip(norms, 0, self.max_value)\n        return w * (desired / (K.epsilon() + norms))\n\n    def get_config(self):\n        return {\'max_value\': self.max_value,\n                \'axis\': self.axis}\n\n\nclass NonNeg(Constraint):\n    """"""Constrains the weights to be non-negative.\n    """"""\n\n    def __call__(self, w):\n        return w * K.cast(K.greater_equal(w, 0.), K.floatx())\n\n\nclass UnitNorm(Constraint):\n    """"""Constrains the weights incident to each hidden unit to have unit norm.\n\n    # Arguments\n        axis: integer, axis along which to calculate weight norms.\n            For instance, in a `Dense` layer the weight matrix\n            has shape `(input_dim, output_dim)`,\n            set `axis` to `0` to constrain each weight vector\n            of length `(input_dim,)`.\n            In a `Conv2D` layer with `data_format=""channels_last""`,\n            the weight tensor has shape\n            `(rows, cols, input_depth, output_depth)`,\n            set `axis` to `[0, 1, 2]`\n            to constrain the weights of each filter tensor of size\n            `(rows, cols, input_depth)`.\n    """"""\n\n    def __init__(self, axis=0):\n        self.axis = axis\n\n    def __call__(self, w):\n        return w / (K.epsilon() + K.sqrt(K.sum(K.square(w),\n                                               axis=self.axis,\n                                               keepdims=True)))\n\n    def get_config(self):\n        return {\'axis\': self.axis}\n\n\nclass MinMaxNorm(Constraint):\n    """"""MinMaxNorm weight constraint.\n\n    Constrains the weights incident to each hidden unit\n    to have the norm between a lower bound and an upper bound.\n\n    # Arguments\n        min_value: the minimum norm for the incoming weights.\n        max_value: the maximum norm for the incoming weights.\n        rate: rate for enforcing the constraint: weights will be\n            rescaled to yield\n            `(1 - rate) * norm + rate * norm.clip(min_value, max_value)`.\n            Effectively, this means that rate=1.0 stands for strict\n            enforcement of the constraint, while rate<1.0 means that\n            weights will be rescaled at each step to slowly move\n            towards a value inside the desired interval.\n        axis: integer, axis along which to calculate weight norms.\n            For instance, in a `Dense` layer the weight matrix\n            has shape `(input_dim, output_dim)`,\n            set `axis` to `0` to constrain each weight vector\n            of length `(input_dim,)`.\n            In a `Conv2D` layer with `data_format=""channels_last""`,\n            the weight tensor has shape\n            `(rows, cols, input_depth, output_depth)`,\n            set `axis` to `[0, 1, 2]`\n            to constrain the weights of each filter tensor of size\n            `(rows, cols, input_depth)`.\n    """"""\n\n    def __init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0):\n        self.min_value = min_value\n        self.max_value = max_value\n        self.rate = rate\n        self.axis = axis\n\n    def __call__(self, w):\n        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n        desired = (self.rate * K.clip(norms, self.min_value, self.max_value) +\n                   (1 - self.rate) * norms)\n        return w * (desired / (K.epsilon() + norms))\n\n    def get_config(self):\n        return {\'min_value\': self.min_value,\n                \'max_value\': self.max_value,\n                \'rate\': self.rate,\n                \'axis\': self.axis}\n\n\n# Aliases.\n\nmax_norm = MaxNorm\nnon_neg = NonNeg\nunit_norm = UnitNorm\nmin_max_norm = MinMaxNorm\n\n\n# Legacy aliases.\nmaxnorm = max_norm\nnonneg = non_neg\nunitnorm = unit_norm\n\n\ndef serialize(constraint):\n    return serialize_keras_object(constraint)\n\n\ndef deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'constraint\')\n\n\ndef get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {\'class_name\': str(identifier), \'config\': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret constraint identifier: \' +\n                         str(identifier))\n'"
keras/initializers.py,1,"b'""""""Built-in weight initializers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport six\nfrom . import backend as K\nfrom .utils.generic_utils import serialize_keras_object\nfrom .utils.generic_utils import deserialize_keras_object\n\n\nclass Initializer(object):\n    """"""Initializer base class: all initializers inherit from this class.\n    """"""\n\n    def __call__(self, shape, dtype=None):\n        raise NotImplementedError\n\n    def get_config(self):\n        return {}\n\n    @classmethod\n    def from_config(cls, config):\n        if \'dtype\' in config:\n            # Initializers saved from `tf.keras`\n            # may contain an unused `dtype` argument.\n            config.pop(\'dtype\')\n        return cls(**config)\n\n\nclass Zeros(Initializer):\n    """"""Initializer that generates tensors initialized to 0.\n    """"""\n\n    def __call__(self, shape, dtype=None):\n        return K.constant(0, shape=shape, dtype=dtype)\n\n\nclass Ones(Initializer):\n    """"""Initializer that generates tensors initialized to 1.\n    """"""\n\n    def __call__(self, shape, dtype=None):\n        return K.constant(1, shape=shape, dtype=dtype)\n\n\nclass Constant(Initializer):\n    """"""Initializer that generates tensors initialized to a constant value.\n\n    # Arguments\n        value: float; the value of the generator tensors.\n    """"""\n\n    def __init__(self, value=0):\n        self.value = value\n\n    def __call__(self, shape, dtype=None):\n        return K.constant(self.value, shape=shape, dtype=dtype)\n\n    def get_config(self):\n        return {\'value\': self.value}\n\n\nclass RandomNormal(Initializer):\n    """"""Initializer that generates tensors with a normal distribution.\n\n    # Arguments\n        mean: a python scalar or a scalar tensor. Mean of the random values\n          to generate.\n        stddev: a python scalar or a scalar tensor. Standard deviation of the\n          random values to generate.\n        seed: A Python integer. Used to seed the random generator.\n    """"""\n\n    def __init__(self, mean=0., stddev=0.05, seed=None):\n        self.mean = mean\n        self.stddev = stddev\n        self.seed = seed\n\n    def __call__(self, shape, dtype=None):\n        x = K.random_normal(shape, self.mean, self.stddev,\n                            dtype=dtype, seed=self.seed)\n        if self.seed is not None:\n            self.seed += 1\n        return x\n\n    def get_config(self):\n        return {\n            \'mean\': self.mean,\n            \'stddev\': self.stddev,\n            \'seed\': self.seed\n        }\n\n\nclass RandomUniform(Initializer):\n    """"""Initializer that generates tensors with a uniform distribution.\n\n    # Arguments\n        minval: A python scalar or a scalar tensor. Lower bound of the range\n          of random values to generate.\n        maxval: A python scalar or a scalar tensor. Upper bound of the range\n          of random values to generate.  Defaults to 1 for float types.\n        seed: A Python integer. Used to seed the random generator.\n    """"""\n\n    def __init__(self, minval=-0.05, maxval=0.05, seed=None):\n        self.minval = minval\n        self.maxval = maxval\n        self.seed = seed\n\n    def __call__(self, shape, dtype=None):\n        x = K.random_uniform(shape, self.minval, self.maxval,\n                             dtype=dtype, seed=self.seed)\n        if self.seed is not None:\n            self.seed += 1\n        return x\n\n    def get_config(self):\n        return {\n            \'minval\': self.minval,\n            \'maxval\': self.maxval,\n            \'seed\': self.seed,\n        }\n\n\nclass TruncatedNormal(Initializer):\n    """"""Initializer that generates a truncated normal distribution.\n\n    These values are similar to values from a `RandomNormal`\n    except that values more than two standard deviations from the mean\n    are discarded and redrawn. This is the recommended initializer for\n    neural network weights and filters.\n\n    # Arguments\n        mean: a python scalar or a scalar tensor. Mean of the random values\n          to generate.\n        stddev: a python scalar or a scalar tensor. Standard deviation of the\n          random values to generate.\n        seed: A Python integer. Used to seed the random generator.\n    """"""\n\n    def __init__(self, mean=0., stddev=0.05, seed=None):\n        self.mean = mean\n        self.stddev = stddev\n        self.seed = seed\n\n    def __call__(self, shape, dtype=None):\n        x = K.truncated_normal(shape, self.mean, self.stddev,\n                               dtype=dtype, seed=self.seed)\n        if self.seed is not None:\n            self.seed += 1\n        return x\n\n    def get_config(self):\n        return {\n            \'mean\': self.mean,\n            \'stddev\': self.stddev,\n            \'seed\': self.seed\n        }\n\n\nclass VarianceScaling(Initializer):\n    """"""Initializer capable of adapting its scale to the shape of weights.\n\n    With `distribution=""normal""`, samples are drawn from a truncated normal\n    distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n\n        - number of input units in the weight tensor, if mode = ""fan_in""\n        - number of output units, if mode = ""fan_out""\n        - average of the numbers of input and output units, if mode = ""fan_avg""\n\n    With `distribution=""uniform""`,\n    samples are drawn from a uniform distribution\n    within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n\n    # Arguments\n        scale: Scaling factor (positive float).\n        mode: One of ""fan_in"", ""fan_out"", ""fan_avg"".\n        distribution: Random distribution to use. One of ""normal"", ""uniform"".\n        seed: A Python integer. Used to seed the random generator.\n\n    # Raises\n        ValueError: In case of an invalid value for the ""scale"", mode"" or\n          ""distribution"" arguments.\n    """"""\n\n    def __init__(self, scale=1.0,\n                 mode=\'fan_in\',\n                 distribution=\'normal\',\n                 seed=None):\n        if scale <= 0.:\n            raise ValueError(\'`scale` must be a positive float. Got:\', scale)\n        mode = mode.lower()\n        if mode not in {\'fan_in\', \'fan_out\', \'fan_avg\'}:\n            raise ValueError(\'Invalid `mode` argument: \'\n                             \'expected on of {""fan_in"", ""fan_out"", ""fan_avg""} \'\n                             \'but got\', mode)\n        distribution = distribution.lower()\n        if distribution not in {\'normal\', \'uniform\'}:\n            raise ValueError(\'Invalid `distribution` argument: \'\n                             \'expected one of {""normal"", ""uniform""} \'\n                             \'but got\', distribution)\n        self.scale = scale\n        self.mode = mode\n        self.distribution = distribution\n        self.seed = seed\n\n    def __call__(self, shape, dtype=None):\n        fan_in, fan_out = _compute_fans(shape)\n        scale = self.scale\n        if self.mode == \'fan_in\':\n            scale /= max(1., fan_in)\n        elif self.mode == \'fan_out\':\n            scale /= max(1., fan_out)\n        else:\n            scale /= max(1., float(fan_in + fan_out) / 2)\n        if self.distribution == \'normal\':\n            # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n            stddev = np.sqrt(scale) / .87962566103423978\n            x = K.truncated_normal(shape, 0., stddev,\n                                   dtype=dtype, seed=self.seed)\n        else:\n            limit = np.sqrt(3. * scale)\n            x = K.random_uniform(shape, -limit, limit,\n                                 dtype=dtype, seed=self.seed)\n        if self.seed is not None:\n            self.seed += 1\n        return x\n\n    def get_config(self):\n        return {\n            \'scale\': self.scale,\n            \'mode\': self.mode,\n            \'distribution\': self.distribution,\n            \'seed\': self.seed\n        }\n\n\nclass Orthogonal(Initializer):\n    """"""Initializer that generates a random orthogonal matrix.\n\n    # Arguments\n        gain: Multiplicative factor to apply to the orthogonal matrix.\n        seed: A Python integer. Used to seed the random generator.\n\n    # References\n        - [Exact solutions to the nonlinear dynamics of learning in deep\n           linear neural networks](http://arxiv.org/abs/1312.6120)\n    """"""\n\n    def __init__(self, gain=1., seed=None):\n        self.gain = gain\n        self.seed = seed\n\n    def __call__(self, shape, dtype=None):\n        num_rows = 1\n        for dim in shape[:-1]:\n            num_rows *= dim\n        num_cols = shape[-1]\n        flat_shape = (num_rows, num_cols)\n        rng = np.random\n        if self.seed is not None:\n            rng = np.random.RandomState(self.seed)\n            self.seed += 1\n        a = rng.normal(0.0, 1.0, flat_shape)\n        u, _, v = np.linalg.svd(a, full_matrices=False)\n        # Pick the one with the correct shape.\n        q = u if u.shape == flat_shape else v\n        q = q.reshape(shape)\n        return self.gain * q[:shape[0], :shape[1]]\n\n    def get_config(self):\n        return {\n            \'gain\': self.gain,\n            \'seed\': self.seed\n        }\n\n\nclass Identity(Initializer):\n    """"""Initializer that generates the identity matrix.\n\n    Only use for 2D matrices.\n    If the desired matrix is not square, it gets padded\n    with zeros for the additional rows/columns.\n\n    # Arguments\n        gain: Multiplicative factor to apply to the identity matrix.\n    """"""\n\n    def __init__(self, gain=1.):\n        self.gain = gain\n\n    @K.eager\n    def __call__(self, shape, dtype=None):\n        if len(shape) != 2:\n            raise ValueError(\n                \'Identity matrix initializer \'\n                \'can only be used for 2D matrices.\')\n        return self.gain * K.eye((shape[0], shape[1]), dtype=dtype)\n\n    def get_config(self):\n        return {\n            \'gain\': self.gain\n        }\n\n\ndef lecun_uniform(seed=None):\n    """"""LeCun uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(3 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n    """"""\n    return VarianceScaling(scale=1.,\n                           mode=\'fan_in\',\n                           distribution=\'uniform\',\n                           seed=seed)\n\n\ndef glorot_normal(seed=None):\n    """"""Glorot normal initializer, also called Xavier normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Understanding the difficulty of training deep feedforward neural\n           networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n    """"""\n    return VarianceScaling(scale=1.,\n                           mode=\'fan_avg\',\n                           distribution=\'normal\',\n                           seed=seed)\n\n\ndef glorot_uniform(seed=None):\n    """"""Glorot uniform initializer, also called Xavier uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Understanding the difficulty of training deep feedforward neural\n           networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n    """"""\n    return VarianceScaling(scale=1.,\n                           mode=\'fan_avg\',\n                           distribution=\'uniform\',\n                           seed=seed)\n\n\ndef he_normal(seed=None):\n    """"""He normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n           ImageNet Classification](http://arxiv.org/abs/1502.01852)\n    """"""\n    return VarianceScaling(scale=2.,\n                           mode=\'fan_in\',\n                           distribution=\'normal\',\n                           seed=seed)\n\n\ndef lecun_normal(seed=None):\n    """"""LeCun normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(1 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n        - [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n    """"""\n    return VarianceScaling(scale=1.,\n                           mode=\'fan_in\',\n                           distribution=\'normal\',\n                           seed=seed)\n\n\ndef he_uniform(seed=None):\n    """"""He uniform variance scaling initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n           ImageNet Classification](http://arxiv.org/abs/1502.01852)\n    """"""\n    return VarianceScaling(scale=2.,\n                           mode=\'fan_in\',\n                           distribution=\'uniform\',\n                           seed=seed)\n\n\n# Compatibility aliases\n\nzero = zeros = Zeros\none = ones = Ones\nconstant = Constant\nuniform = random_uniform = RandomUniform\nnormal = random_normal = RandomNormal\ntruncated_normal = TruncatedNormal\nidentity = Identity\northogonal = Orthogonal\n\n# Utility functions\n\n\ndef _compute_fans(shape, data_format=\'channels_last\'):\n    """"""Computes the number of input and output units for a weight shape.\n\n    # Arguments\n        shape: Integer shape tuple.\n        data_format: Image data format to use for convolution kernels.\n            Note that all kernels in Keras are standardized on the\n            `channels_last` ordering (even when inputs are set\n            to `channels_first`).\n\n    # Returns\n        A tuple of scalars, `(fan_in, fan_out)`.\n\n    # Raises\n        ValueError: in case of invalid `data_format` argument.\n    """"""\n    if len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    elif len(shape) in {3, 4, 5}:\n        # Assuming convolution kernels (1D, 2D or 3D).\n        # TH kernel shape: (depth, input_depth, ...)\n        # TF kernel shape: (..., input_depth, depth)\n        if data_format == \'channels_first\':\n            receptive_field_size = np.prod(shape[2:])\n            fan_in = shape[1] * receptive_field_size\n            fan_out = shape[0] * receptive_field_size\n        elif data_format == \'channels_last\':\n            receptive_field_size = np.prod(shape[:-2])\n            fan_in = shape[-2] * receptive_field_size\n            fan_out = shape[-1] * receptive_field_size\n        else:\n            raise ValueError(\'Invalid data_format: \' + data_format)\n    else:\n        # No specific assumptions.\n        fan_in = np.sqrt(np.prod(shape))\n        fan_out = np.sqrt(np.prod(shape))\n    return fan_in, fan_out\n\n\ndef serialize(initializer):\n    return serialize_keras_object(initializer)\n\n\ndef deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'initializer\')\n\n\ndef get(identifier):\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {\'class_name\': str(identifier), \'config\': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret initializer identifier: \' +\n                         str(identifier))\n'"
keras/losses.py,0,"b'""""""Built-in loss functions.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport six\n\nfrom . import backend as K\nfrom .utils import losses_utils\nfrom .utils.generic_utils import deserialize_keras_object\nfrom .utils.generic_utils import serialize_keras_object\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Loss(object):\n    """"""Loss base class.\n\n    To be implemented by subclasses:\n        * `call()`: Contains the logic for loss calculation using `y_true`, `y_pred`.\n\n    Example subclass implementation:\n    ```python\n    class MeanSquaredError(Loss):\n        def call(self, y_true, y_pred):\n            y_pred = ops.convert_to_tensor(y_pred)\n            y_true = math_ops.cast(y_true, y_pred.dtype)\n            return K.mean(math_ops.square(y_pred - y_true), axis=-1)\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss Reduction to apply to loss.\n          Default value is `SUM_OVER_BATCH_SIZE`.\n        name: Optional name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=None):\n        self.reduction = reduction\n        self.name = name\n\n    def __call__(self, y_true, y_pred, sample_weight=None):\n        """"""Invokes the `Loss` instance.\n\n        # Arguments\n            y_true: Ground truth values.\n            y_pred: The predicted values.\n            sample_weight: Optional `Tensor` whose rank is either 0, or the same rank\n            as `y_true`, or is broadcastable to `y_true`. `sample_weight` acts as a\n            coefficient for the loss. If a scalar is provided, then the loss is\n            simply scaled by the given value. If `sample_weight` is a tensor of size\n            `[batch_size]`, then the total loss for each sample of the batch is\n            rescaled by the corresponding element in the `sample_weight` vector. If\n            the shape of `sample_weight` matches the shape of `y_pred`, then the\n            loss of each measurable element of `y_pred` is scaled by the\n            corresponding value of `sample_weight`.\n\n        # Returns\n            Weighted loss float `Tensor`. If `reduction` is `NONE`, this has the same\n                shape as `y_true`; otherwise, it is scalar.\n\n        # Raises\n            ValueError: If the shape of `sample_weight` is invalid.\n        """"""\n        # If we are wrapping a lambda function strip \'<>\' from the name as it is not\n        # accepted in scope name.\n        scope_name = \'lambda\' if self.name == \'<lambda>\' else self.name\n        with K.name_scope(scope_name):\n            losses = self.call(y_true, y_pred)\n            return losses_utils.compute_weighted_loss(\n                losses, sample_weight, reduction=self.reduction)\n\n    @classmethod\n    def from_config(cls, config):\n        """"""Instantiates a `Loss` from its config (output of `get_config()`).\n\n        # Arguments\n            config: Output of `get_config()`.\n\n        # Returns\n            A `Loss` instance.\n        """"""\n        return cls(**config)\n\n    def get_config(self):\n        return {\'reduction\': self.reduction, \'name\': self.name}\n\n    @abc.abstractmethod\n    def call(self, y_true, y_pred):\n        """"""Invokes the `Loss` instance.\n\n        # Arguments\n            y_true: Ground truth values, with the same shape as \'y_pred\'.\n            y_pred: The predicted values.\n        """"""\n        raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n\nclass LossFunctionWrapper(Loss):\n    """"""Wraps a loss function in the `Loss` class.\n\n    # Arguments\n        fn: The loss function to wrap, with signature `fn(y_true, y_pred,\n            **kwargs)`.\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) name for the loss.\n        **kwargs: The keyword arguments that are passed on to `fn`.\n    """"""\n\n    def __init__(self,\n                 fn,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=None,\n                 **kwargs):\n        super(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)\n        self.fn = fn\n        self._fn_kwargs = kwargs\n\n    def call(self, y_true, y_pred):\n        """"""Invokes the `LossFunctionWrapper` instance.\n\n        # Arguments\n            y_true: Ground truth values.\n            y_pred: The predicted values.\n\n        # Returns\n            Loss values per sample.\n        """"""\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n\n    def get_config(self):\n        config = {}\n        for k, v in six.iteritems(self._fn_kwargs):\n            config[k] = K.eval(v) if K.is_tensor(v) or K.is_variable(v) else v\n        base_config = super(LossFunctionWrapper, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass MeanSquaredError(LossFunctionWrapper):\n    """"""Computes the mean of squares of errors between labels and predictions.\n\n    Standalone usage:\n\n    ```python\n    mse = keras.losses.MeanSquaredError()\n    loss = mse([0., 0., 1., 1.], [1., 1., 1., 0.])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.MeanSquaredError())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) name for the loss.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'mean_squared_error\'):\n        super(MeanSquaredError, self).__init__(\n            mean_squared_error, name=name, reduction=reduction)\n\n\nclass MeanAbsoluteError(LossFunctionWrapper):\n    """"""Computes the mean of absolute difference between labels and predictions.\n\n    Standalone usage:\n\n    ```python\n    mae = keras.losses.MeanAbsoluteError()\n    loss = mae([0., 0., 1., 1.], [1., 1., 1., 0.])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.MeanAbsoluteError())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) name for the loss.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'mean_absolute_error\'):\n        super(MeanAbsoluteError, self).__init__(\n            mean_absolute_error, name=name, reduction=reduction)\n\n\nclass MeanAbsolutePercentageError(LossFunctionWrapper):\n    """"""Computes the mean absolute percentage error between `y_true` and `y_pred`.\n\n    Standalone usage:\n\n    ```python\n    mape = keras.losses.MeanAbsolutePercentageError()\n    loss = mape([0., 0., 1., 1.], [1., 1., 1., 0.])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.MeanAbsolutePercentageError())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) name for the loss.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'mean_absolute_percentage_error\'):\n        super(MeanAbsolutePercentageError, self).__init__(\n            mean_absolute_percentage_error, name=name, reduction=reduction)\n\n\nclass MeanSquaredLogarithmicError(LossFunctionWrapper):\n    """"""Computes the mean squared logarithmic error between `y_true` and `y_pred`.\n\n    Standalone usage:\n\n    ```python\n    msle = keras.losses.MeanSquaredLogarithmicError()\n    loss = msle([0., 0., 1., 1.], [1., 1., 1., 0.])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.MeanSquaredLogarithmicError())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) name for the loss.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'mean_squared_logarithmic_error\'):\n        super(MeanSquaredLogarithmicError, self).__init__(\n            mean_squared_logarithmic_error, name=name, reduction=reduction)\n\n\nclass BinaryCrossentropy(LossFunctionWrapper):\n    """"""Computes the cross-entropy loss between true labels and predicted labels.\n\n    Use this cross-entropy loss when there are only two label classes (assumed to\n    be 0 and 1). For each example, there should be a single floating-point value\n    per prediction.\n\n    In the snippet below, each of the four examples has only a single\n    floating-pointing value, and both `y_pred` and `y_true` have the shape\n    `[batch_size]`.\n\n    Standalone usage:\n\n    ```python\n    bce = keras.losses.BinaryCrossentropy()\n    loss = bce([0., 0., 1., 1.], [1., 1., 1., 0.])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.BinaryCrossentropy())\n    ```\n\n    # Arguments\n        from_logits: Whether to interpret `y_pred` as a tensor of\n            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n            we assume that `y_pred` contains probabilities\n            (i.e., values in [0, 1]).\n        label_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When > 0, we\n            compute the loss between the predicted labels and a smoothed version of\n            the true labels, where the smoothing squeezes the labels towards 0.5.\n            Larger values of `label_smoothing` correspond to heavier smoothing.\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 from_logits=False,\n                 label_smoothing=0,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'binary_crossentropy\'):\n        super(BinaryCrossentropy, self).__init__(\n            binary_crossentropy,\n            name=name,\n            reduction=reduction,\n            from_logits=from_logits,\n            label_smoothing=label_smoothing)\n        self.from_logits = from_logits\n\n\nclass CategoricalCrossentropy(LossFunctionWrapper):\n    """"""Computes the crossentropy loss between the labels and predictions.\n\n    Use this crossentropy loss function when there are two or more label classes.\n    We expect labels to be provided in a `one_hot` representation. If you want to\n    provide labels as integers, please use `SparseCategoricalCrossentropy` loss.\n    There should be `# classes` floating point values per feature.\n\n    In the snippet below, there is `# classes` floating pointing values per\n    example. The shape of both `y_pred` and `y_true` are\n    `[batch_size, num_classes]`.\n\n    Standalone usage:\n\n    ```python\n    cce = keras.losses.CategoricalCrossentropy()\n    loss = cce(\n        [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]],\n        [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.CategoricalCrossentropy())\n    ```\n\n    # Arguments\n        from_logits: Whether to interpret `y_pred` as a tensor of\n            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n            we assume that `y_pred` contains probabilities\n            (i.e., values in [0, 1]).\n        label_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When > 0, we\n            compute the loss between the predicted labels and a smoothed version of\n            the true labels, where the smoothing squeezes the labels towards 0.5.\n            Larger values of `label_smoothing` correspond to heavier smoothing.\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 from_logits=False,\n                 label_smoothing=0,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'categorical_crossentropy\'):\n        super(CategoricalCrossentropy, self).__init__(\n            categorical_crossentropy,\n            name=name,\n            reduction=reduction,\n            from_logits=from_logits,\n            label_smoothing=label_smoothing)\n\n\nclass SparseCategoricalCrossentropy(LossFunctionWrapper):\n    """"""Computes the crossentropy loss between the labels and predictions.\n\n    Use this crossentropy loss function when there are two or more label classes.\n    We expect labels to be provided as integers. If you want to provide labels\n    using `one-hot` representation, please use `CategoricalCrossentropy` loss.\n    There should be `# classes` floating point values per feature for `y_pred`\n    and a single floating point value per feature for `y_true`.\n\n    In the snippet below, there is a single floating point value per example for\n    `y_true` and `# classes` floating pointing values per example for `y_pred`.\n    The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n    `[batch_size, num_classes]`.\n\n    Standalone usage:\n\n    ```python\n    cce = keras.losses.SparseCategoricalCrossentropy()\n    loss = cce(\n        [0, 1, 2],\n        [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.SparseCategoricalCrossentropy())\n    ```\n\n    # Arguments\n        from_logits: Whether to interpret `y_pred` as a tensor of\n            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n            we assume that `y_pred` contains probabilities\n            (i.e., values in [0, 1]).\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 from_logits=False,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'sparse_categorical_crossentropy\'):\n        super(SparseCategoricalCrossentropy, self).__init__(\n            sparse_categorical_crossentropy,\n            name=name,\n            reduction=reduction,\n            from_logits=from_logits)\n\n\nclass Hinge(LossFunctionWrapper):\n    """"""Computes the hinge loss between `y_true` and `y_pred`.\n\n    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n    provided we will convert them to -1 or 1.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.Hinge())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'hinge\'):\n        super(Hinge, self).__init__(hinge, name=name, reduction=reduction)\n\n\nclass SquaredHinge(LossFunctionWrapper):\n    """"""Computes the squared hinge loss between `y_true` and `y_pred`.\n\n    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n    provided we will convert them to -1 or 1.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.SquaredHinge())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'squared_hinge\'):\n        super(SquaredHinge, self).__init__(\n            squared_hinge, name=name, reduction=reduction)\n\n\nclass CategoricalHinge(LossFunctionWrapper):\n    """"""Computes the categorical hinge loss between `y_true` and `y_pred`.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.CategoricalHinge())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'categorical_hinge\'):\n        super(CategoricalHinge, self).__init__(\n            categorical_hinge, name=name, reduction=reduction)\n\n\nclass Poisson(LossFunctionWrapper):\n    """"""Computes the Poisson loss between `y_true` and `y_pred`.\n\n    `loss = y_pred - y_true * log(y_pred)`\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.Poisson())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'poisson\'):\n        super(Poisson, self).__init__(poisson, name=name, reduction=reduction)\n\n\nclass LogCosh(LossFunctionWrapper):\n    """"""Computes the logarithm of the hyperbolic cosine of the prediction error.\n\n    `logcosh = log((exp(x) + exp(-x))/2)`,\n    where x is the error (y_pred - y_true)\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.LogCosh())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'logcosh\'):\n        super(LogCosh, self).__init__(logcosh, name=name, reduction=reduction)\n\n\nclass KLDivergence(LossFunctionWrapper):\n    """"""Computes Kullback-Leibler divergence loss between `y_true` and `y_pred`.\n\n    `loss = y_true * log(y_true / y_pred)`\n\n    See: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.KLDivergence())\n    ```\n\n    # Arguments\n        reduction: (Optional) Type of loss reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: (Optional) Name for the object.\n    """"""\n\n    def __init__(self,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'kullback_leibler_divergence\'):\n        super(KLDivergence, self).__init__(\n            kullback_leibler_divergence, name=name, reduction=reduction)\n\n\nclass Huber(LossFunctionWrapper):\n    """"""Computes the Huber loss between `y_true` and `y_pred`.\n\n    Given `x = y_true - y_pred`:\n    ```\n    loss = 0.5 * x^2                  if |x| <= d\n    loss = 0.5 * d^2 + d * (|x| - d)  if |x| > d\n    ```\n    where d is `delta`. See: https://en.wikipedia.org/wiki/Huber_loss\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=keras.losses.Huber())\n    ```\n\n    # Arguments\n        delta: A float, the point where the Huber loss function changes from a\n            quadratic to linear.\n        reduction: (Optional) Type of reduction to apply to loss.\n        name: Optional name for the object.\n    """"""\n    def __init__(self,\n                 delta=1.0,\n                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                 name=\'huber_loss\'):\n        super(Huber, self).__init__(\n            huber_loss, name=name, reduction=reduction, delta=delta)\n\n\ndef mean_squared_error(y_true, y_pred):\n    if not K.is_tensor(y_pred):\n        y_pred = K.constant(y_pred)\n    y_true = K.cast(y_true, y_pred.dtype)\n    return K.mean(K.square(y_pred - y_true), axis=-1)\n\n\ndef mean_absolute_error(y_true, y_pred):\n    if not K.is_tensor(y_pred):\n        y_pred = K.constant(y_pred)\n    y_true = K.cast(y_true, y_pred.dtype)\n    return K.mean(K.abs(y_pred - y_true), axis=-1)\n\n\ndef mean_absolute_percentage_error(y_true, y_pred):\n    if not K.is_tensor(y_pred):\n        y_pred = K.constant(y_pred)\n    y_true = K.cast(y_true, y_pred.dtype)\n    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n                                            K.epsilon(),\n                                            None))\n    return 100. * K.mean(diff, axis=-1)\n\n\ndef mean_squared_logarithmic_error(y_true, y_pred):\n    if not K.is_tensor(y_pred):\n        y_pred = K.constant(y_pred)\n    y_true = K.cast(y_true, y_pred.dtype)\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n\n\ndef squared_hinge(y_true, y_pred):\n    y_true = _maybe_convert_labels(y_true)\n    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)\n\n\ndef hinge(y_true, y_pred):\n    y_true = _maybe_convert_labels(y_true)\n    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)\n\n\ndef categorical_hinge(y_true, y_pred):\n    pos = K.sum(y_true * y_pred, axis=-1)\n    neg = K.max((1. - y_true) * y_pred, axis=-1)\n    return K.maximum(0., neg - pos + 1.)\n\n\ndef logcosh(y_true, y_pred):\n    """"""Logarithm of the hyperbolic cosine of the prediction error.\n\n    `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n    to `abs(x) - log(2)` for large `x`. This means that \'logcosh\' works mostly\n    like the mean squared error, but will not be so strongly affected by the\n    occasional wildly incorrect prediction.\n\n    # Arguments\n        y_true: tensor of true targets.\n        y_pred: tensor of predicted targets.\n\n    # Returns\n        Tensor with one scalar loss entry per sample.\n    """"""\n    def _logcosh(x):\n        return x + K.softplus(-2. * x) - K.log(2.)\n    return K.mean(_logcosh(y_pred - y_true), axis=-1)\n\n\ndef huber_loss(y_true, y_pred, delta=1.0):\n    error = y_pred - y_true\n    abs_error = K.abs(error)\n    quadratic = K.minimum(abs_error, delta)\n    linear = abs_error - quadratic\n    return 0.5 * K.square(quadratic) + delta * linear\n\n\ndef categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n    y_true = K.cast(y_true, y_pred.dtype)\n\n    if label_smoothing is not 0:\n        smoothing = K.cast_to_floatx(label_smoothing)\n\n        def _smooth_labels():\n            num_classes = K.cast(K.shape(y_true)[1], y_pred.dtype)\n            return y_true * (1.0 - smoothing) + (smoothing / num_classes)\n\n        y_true = K.switch(K.greater(smoothing, 0), _smooth_labels, lambda: y_true)\n    return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n\n\ndef sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n    return K.sparse_categorical_crossentropy(\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n\n\ndef binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n    y_true = K.cast(y_true, y_pred.dtype)\n    if label_smoothing is not 0:\n        smoothing = K.cast_to_floatx(label_smoothing)\n        y_true = K.switch(K.greater(smoothing, 0),\n                          lambda: y_true * (1.0 - smoothing) + 0.5 * smoothing,\n                          lambda: y_true)\n    return K.mean(\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n\n\ndef kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true, K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n\n\ndef poisson(y_true, y_pred):\n    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n\n\ndef cosine_proximity(y_true, y_pred, axis=-1):\n    y_true = K.l2_normalize(y_true, axis=axis)\n    y_pred = K.l2_normalize(y_pred, axis=axis)\n    return - K.sum(y_true * y_pred, axis=axis)\n\n\ndef _maybe_convert_labels(y_true):\n    """"""Converts binary labels into -1/1.""""""\n    are_zeros = K.equal(y_true, 0)\n    are_ones = K.equal(y_true, 1)\n\n    are_zeros = K.expand_dims(are_zeros, 0)\n    are_ones = K.expand_dims(are_ones, 0)\n\n    are_different = K.concatenate([are_zeros, are_ones], axis=0)\n    are_different = K.any(are_different, axis=0)\n    is_binary = K.all(are_different)\n\n    def _convert_binary_labels():\n        # Convert the binary labels to -1 or 1.\n        return 2. * y_true - 1.\n\n    updated_y_true = K.switch(is_binary,\n                              _convert_binary_labels,\n                              lambda: y_true)\n    return updated_y_true\n\n\n# Aliases.\n\nmse = MSE = mean_squared_error\nmae = MAE = mean_absolute_error\nmape = MAPE = mean_absolute_percentage_error\nmsle = MSLE = mean_squared_logarithmic_error\nkld = KLD = kullback_leibler_divergence\ncosine = cosine_similarity = cosine_proximity\n\n\ndef is_categorical_crossentropy(loss):\n    return (isinstance(loss, CategoricalCrossentropy) or\n            (isinstance(loss, LossFunctionWrapper) and\n                loss.fn == categorical_crossentropy) or\n            (hasattr(loss, \'__name__\') and\n                loss.__name__ == \'categorical_crossentropy\') or\n            loss == \'categorical_crossentropy\')\n\n\ndef serialize(loss):\n    return serialize_keras_object(loss)\n\n\ndef deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'loss function\')\n\n\ndef get(identifier):\n    """"""Get the `identifier` loss function.\n\n    # Arguments\n        identifier: None or str, name of the function.\n\n    # Returns\n        The loss function or None if `identifier` is None.\n\n    # Raises\n        ValueError if unknown identifier.\n    """"""\n    if identifier is None:\n        return None\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret \'\n                         \'loss function identifier:\', identifier)\n'"
keras/metrics.py,2,"b'""""""Built-in metrics.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport numpy as np\nimport six\nimport types\n\nfrom . import backend as K\nfrom .layers import Layer\nfrom .losses import mean_squared_error\nfrom .losses import mean_absolute_error\nfrom .losses import mean_absolute_percentage_error\nfrom .losses import mean_squared_logarithmic_error\nfrom .losses import hinge\nfrom .losses import logcosh\nfrom .losses import squared_hinge\nfrom .losses import categorical_hinge\nfrom .losses import categorical_crossentropy\nfrom .losses import sparse_categorical_crossentropy\nfrom .losses import binary_crossentropy\nfrom .losses import kullback_leibler_divergence\nfrom .losses import poisson\nfrom .utils import losses_utils\nfrom .utils import metrics_utils\nfrom .utils.generic_utils import deserialize_keras_object\nfrom .utils.generic_utils import serialize_keras_object\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Metric(Layer):\n    """"""Encapsulates metric logic and state.\n\n    Standalone usage:\n    ```python\n    m = SomeMetric(...)\n    for input in ...:\n        m.update_state(input)\n    m.result()\n    ```\n\n    Usage with the `compile` API:\n    ```python\n    model.compile(optimizer=\'rmsprop\',\n                  loss=keras.losses.categorical_crossentropy,\n                  metrics=[keras.metrics.CategoricalAccuracy()])\n    ```\n\n    To be implemented by subclasses:\n    * `__init__()`: All state variables should be created in this method by\n        calling `self.add_weight()` like: `self.var = self.add_weight(...)`\n    * `update_state()`: Has all updates to the state variables like:\n        self.var.assign_add(...).\n    * `result()`: Computes and returns a value for the metric\n        from the state variables.\n    """"""\n\n    def __init__(self, name=None, dtype=None, **kwargs):\n        super(Metric, self).__init__(name=name, dtype=dtype, **kwargs)\n        self.stateful = True  # All metric layers are stateful.\n        self.built = True\n        self.dtype = dtype or K.floatx()\n\n    def __new__(cls, *args, **kwargs):\n        obj = super(Metric, cls).__new__(cls)\n\n        obj.update_state = types.MethodType(\n            metrics_utils.update_state_wrapper(obj.update_state), obj)\n\n        obj.result = types.MethodType(\n            metrics_utils.result_wrapper(obj.result), obj)\n        return obj\n\n    @K.symbolic\n    def __call__(self, *args, **kwargs):\n        """"""Accumulates statistics and then computes metric result value.""""""\n        update_op = self.update_state(*args, **kwargs)\n        with K.control_dependencies(update_op):  # For TF\n            result_t = self.result()\n\n            # We are adding the metric object as metadata on the result tensor.\n            # This is required when we want to use a metric with `add_metric` API on\n            # a Model/Layer in graph mode. This metric instance will later be used\n            # to reset variable state after each epoch of training.\n            # Example:\n            #   model = Model()\n            #   mean = Mean()\n            #   model.add_metric(mean(values), name=\'mean\')\n            result_t._metric_obj = self\n            return result_t\n\n    def get_config(self):\n        """"""Returns the serializable config of the metric.""""""\n        return {\'name\': self.name, \'dtype\': self.dtype}\n\n    def reset_states(self):\n        """"""Resets all of the metric state variables.\n\n        This function is called between epochs/steps,\n        when a metric is evaluated during training.\n        """"""\n        K.batch_set_value([(v, 0) for v in self.weights])\n\n    @abc.abstractmethod\n    def update_state(self, *args, **kwargs):\n        """"""Accumulates statistics for the metric. """"""\n        raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n    @abc.abstractmethod\n    def result(self):\n        """"""Computes and returns the metric value tensor.\n\n        Result computation is an idempotent operation that simply calculates the\n        metric value using the state variables.\n        """"""\n        raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n    # For use by subclasses #\n    def add_weight(self,\n                   name,\n                   shape=(),\n                   initializer=None,\n                   dtype=None):\n        """"""Adds state variable. Only for use by subclasses.""""""\n        return super(Metric, self).add_weight(\n            name=name,\n            shape=shape,\n            dtype=self.dtype if dtype is None else dtype,\n            trainable=False,\n            initializer=initializer)\n\n    # End: For use by subclasses ###\n\n\nclass Reduce(Metric):\n    """"""Encapsulates metrics that perform a reduce operation on the values.""""""\n\n    def __init__(self, reduction, name, dtype=None):\n        """"""Creates a `Reduce` instance.\n\n        # Arguments\n            reduction: a metrics `Reduction` enum value.\n            name: string name of the metric instance.\n            dtype: (Optional) data type of the metric result.\n        """"""\n        super(Reduce, self).__init__(name=name, dtype=dtype)\n        self.reduction = reduction\n        self.total = self.add_weight(\n            \'total\', initializer=\'zeros\')\n        if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                         metrics_utils.Reduction.WEIGHTED_MEAN]:\n            self.count = self.add_weight(\n                \'count\', initializer=\'zeros\')\n\n    def update_state(self, values, sample_weight=None):\n        """"""Accumulates statistics for computing the reduction metric.\n\n        For example, if `values` is [1, 3, 5, 7] and reduction=SUM_OVER_BATCH_SIZE,\n        then the value of `result()` is 4. If the `sample_weight` is specified as\n        [1, 1, 0, 0] then value of `result()` would be 2.\n\n        # Arguments\n            values: Per-example value.\n            sample_weight: Optional weighting of each example. Defaults to 1.\n\n        # Returns\n            List of update ops.\n        """"""\n        values = K.cast(values, self.dtype)\n        if sample_weight is not None:\n            sample_weight = K.cast(sample_weight, self.dtype)\n\n            # Update dimensions of weights to match with values if possible.\n            values, _, sample_weight = losses_utils.squeeze_or_expand_dimensions(\n                values, sample_weight=sample_weight)\n\n            # Broadcast weights if possible.\n            sample_weight = losses_utils.broadcast_weights(values, sample_weight)\n\n            values = values * sample_weight\n\n        value_sum = K.sum(values)\n        update_total_op = K.update_add(self.total, value_sum)\n\n        # Exit early if the reduction doesn\'t have a denominator.\n        if self.reduction == metrics_utils.Reduction.SUM:\n            return [update_total_op]\n\n        # Update `count` for reductions that require a denominator.\n        if self.reduction == metrics_utils.Reduction.SUM_OVER_BATCH_SIZE:\n            num_values = K.cast(K.size(values), self.dtype)\n        elif self.reduction == metrics_utils.Reduction.WEIGHTED_MEAN:\n            if sample_weight is None:\n                num_values = K.cast(K.size(values), self.dtype)\n            else:\n                num_values = K.sum(sample_weight)\n        else:\n            raise NotImplementedError(\n                \'reduction [%s] not implemented\' % self.reduction)\n\n        return [update_total_op, K.update_add(self.count, num_values)]\n\n    def result(self):\n        if self.reduction == metrics_utils.Reduction.SUM:\n            return self.total\n        elif self.reduction in [\n            metrics_utils.Reduction.WEIGHTED_MEAN,\n            metrics_utils.Reduction.SUM_OVER_BATCH_SIZE\n        ]:\n            return self.total / self.count\n        else:\n            raise NotImplementedError(\n                \'reduction [%s] not implemented\' % self.reduction)\n\n\nclass Sum(Reduce):\n    """"""Computes the (weighted) sum of the given values.\n\n    For example, if values is [1, 3, 5, 7] then the sum is 16.\n    If the weights were specified as [1, 1, 0, 0] then the sum would be 4.\n\n    This metric creates one variable, `total`, that is used to compute the sum of\n    `values`. This is ultimately returned as `sum`.\n    If `sample_weight` is `None`, weights default to 1.  Use `sample_weight` of 0\n    to mask values.\n\n    Standalone usage:\n    ```python\n    m = keras.metrics.Sum()\n    m.update_state([1, 3, 5, 7])\n    m.result()\n    ```\n    """"""\n\n    def __init__(self, name=\'sum\', dtype=None):\n        """"""Creates a `Sum` instance.\n\n        # Arguments\n            name: (Optional) string name of the metric instance.\n            dtype: (Optional) data type of the metric result.\n        """"""\n        super(Sum, self).__init__(reduction=metrics_utils.Reduction.SUM,\n                                  name=name, dtype=dtype)\n\n\nclass Mean(Reduce):\n    """"""Computes the (weighted) mean of the given values.\n\n    For example, if values is [1, 3, 5, 7] then the mean is 4.\n    If the weights were specified as [1, 1, 0, 0] then the mean would be 2.\n\n    This metric creates two variables, `total` and `count` that are used to\n    compute the average of `values`. This average is ultimately returned as `mean`\n    which is an idempotent operation that simply divides `total` by `count`.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage:\n\n    ```python\n    m = keras.metrics.Mean()\n    m.update_state([1, 3, 5, 7])\n    m.result()\n    ```\n    """"""\n\n    def __init__(self, name=\'mean\', dtype=None):\n        """"""Creates a `Mean` instance.\n\n        #Arguments\n            name: (Optional) string name of the metric instance.\n            dtype: (Optional) data type of the metric result.\n        """"""\n        super(Mean, self).__init__(\n            reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\n\n\nclass MeanMetricWrapper(Mean):\n    """"""Wraps a stateless metric function with the Mean metric.""""""\n\n    def __init__(self, fn, name=None, dtype=None, **kwargs):\n        """"""Creates a `MeanMetricWrapper` instance.\n\n        # Arguments\n            fn: The metric function to wrap, with signature\n                `fn(y_true, y_pred, **kwargs)`.\n            name: (Optional) string name of the metric instance.\n            dtype: (Optional) data type of the metric result.\n            **kwargs: The keyword arguments that are passed on to `fn`.\n        """"""\n        super(MeanMetricWrapper, self).__init__(name=name, dtype=dtype)\n        self._fn = fn\n        self._fn_kwargs = kwargs\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        """"""Accumulates metric statistics.\n\n        `y_true` and `y_pred` should have the same shape.\n\n        # Arguments\n            y_true: The ground truth values.\n            y_pred: The predicted values.\n            sample_weight: Optional weighting of each example. Defaults to 1. Can be\n                a `Tensor` whose rank is either 0, or the same rank as `y_true`,\n                and must be broadcastable to `y_true`.\n\n        # Returns\n            Update op.\n        """"""\n        y_true = K.cast(y_true, self.dtype)\n        y_pred = K.cast(y_pred, self.dtype)\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n\n        matches = self._fn(y_true, y_pred, **self._fn_kwargs)\n        return super(MeanMetricWrapper, self).update_state(\n            matches, sample_weight=sample_weight)\n\n    def get_config(self):\n        config = {}\n        for k, v in six.iteritems(self._fn_kwargs):\n            config[k] = K.eval(v) if K.is_tensor(v) else v\n        base_config = super(MeanMetricWrapper, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass MeanSquaredError(MeanMetricWrapper):\n    """"""Computes the mean squared error between `y_true` and `y_pred`.\n\n    Standalone usage:\n\n    ```python\n    m = keras.metrics.MeanSquaredError()\n    m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.])\n    m.result()\n    ```\n\n    Usage with compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.MeanSquaredError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'mean_squared_error\', dtype=None):\n        super(MeanSquaredError, self).__init__(\n            mean_squared_error, name, dtype=dtype)\n\n\nclass Hinge(MeanMetricWrapper):\n    """"""Computes the hinge metric between `y_true` and `y_pred`.\n\n    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n    provided we will convert them to -1 or 1.\n    For example, if `y_true` is [-1., 1., 1.], and `y_pred` is [0.6, -0.7, -0.5]\n    the hinge metric value is 1.6.\n\n    Usage:\n\n    ```python\n    m = keras.metrics.Hinge()\n    m.update_state([-1., 1., 1.], [0.6, -0.7, -0.5])\n    # result = max(0, 1-y_true * y_pred) = [1.6 + 1.7 + 1.5] / 3\n    # Final result: 1.6\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.Hinge()])\n    ```\n    """"""\n\n    def __init__(self, name=\'hinge\', dtype=None):\n        super(Hinge, self).__init__(hinge, name, dtype=dtype)\n\n\nclass SquaredHinge(MeanMetricWrapper):\n    """"""Computes the squared hinge metric between `y_true` and `y_pred`.\n\n    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n    provided we will convert them to -1 or 1.\n    For example, if `y_true` is [-1., 1., 1.], and `y_pred` is [0.6, -0.7, -0.5]\n    the squared hinge metric value is 2.6.\n\n    Usage:\n\n    ```python\n    m = keras.metrics.SquaredHinge()\n    m.update_state([-1., 1., 1.], [0.6, -0.7, -0.5])\n    # result = max(0, 1-y_true * y_pred) = [1.6^2 + 1.7^2 + 1.5^2] / 3\n    # Final result: 2.6\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.SquaredHinge()])\n    ```\n    """"""\n\n    def __init__(self, name=\'squared_hinge\', dtype=None):\n        super(SquaredHinge, self).__init__(squared_hinge, name, dtype=dtype)\n\n\nclass CategoricalHinge(MeanMetricWrapper):\n    """"""Computes the categorical hinge metric between `y_true` and `y_pred`.\n\n    For example, if `y_true` is [0., 1., 1.], and `y_pred` is [1., 0., 1.]\n    the categorical hinge metric value is 1.0.\n\n    Usage:\n\n    ```python\n    m = keras.metrics.CategoricalHinge()\n    m.update_state([0., 1., 1.], [1., 0., 1.])\n    # Final result: 1.0\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.CategoricalHinge()])\n    ```\n    """"""\n\n    def __init__(self, name=\'categorical_hinge\', dtype=None):\n        super(CategoricalHinge, self).__init__(\n            categorical_hinge, name, dtype=dtype)\n\n\nclass Accuracy(MeanMetricWrapper):\n    """"""Calculates how often predictions matches labels.\n\n    For example, if `y_true` is [1, 2, 3, 4] and `y_pred` is [0, 2, 3, 4]\n    then the accuracy is 3/4 or .75.  If the weights were specified as\n    [1, 1, 0, 0] then the accuracy would be 1/2 or .5.\n\n    This metric creates two local variables, `total` and `count` that are used to\n    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n    ultimately returned as `binary accuracy`: an idempotent operation that simply\n    divides `total` by `count`.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    ```\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.Accuracy()])\n    ```\n    """"""\n\n    def __init__(self, name=\'accuracy\', dtype=None):\n        super(Accuracy, self).__init__(accuracy, name, dtype=dtype)\n\n\nclass BinaryAccuracy(MeanMetricWrapper):\n    """"""Calculates how often predictions matches labels.\n\n    For example, if `y_true` is [1, 1, 0, 0] and `y_pred` is [0.98, 1, 0, 0.6]\n    then the binary accuracy is 3/4 or .75.  If the weights were specified as\n    [1, 0, 0, 1] then the binary accuracy would be 1/2 or .5.\n\n    This metric creates two local variables, `total` and `count` that are used to\n    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n    ultimately returned as `binary accuracy`: an idempotent operation that simply\n    divides `total` by `count`.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.BinaryAccuracy()])\n    ```\n\n    # Arguments\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n        threshold: (Optional) Float representing the threshold for deciding\n            whether prediction values are 1 or 0.\n    """"""\n\n    def __init__(self, name=\'binary_accuracy\', dtype=None, threshold=0.5):\n        super(BinaryAccuracy, self).__init__(\n            binary_accuracy, name, dtype=dtype, threshold=threshold)\n\n\nclass CategoricalAccuracy(MeanMetricWrapper):\n    """"""Calculates how often predictions matches labels.\n\n    For example, if `y_true` is [[0, 0, 1], [0, 1, 0]] and `y_pred` is\n    [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5.\n    If the weights were specified as [0.7, 0.3] then the categorical accuracy\n    would be .3. You can provide logits of classes as `y_pred`, since argmax of\n    logits and probabilities are same.\n\n    This metric creates two local variables, `total` and `count` that are used to\n    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n    ultimately returned as `categorical accuracy`: an idempotent operation that\n    simply divides `total` by `count`.\n\n    `y_pred` and `y_true` should be passed in as vectors of probabilities, rather\n    than as labels. If necessary, use `K.one_hot` to expand `y_true` as a vector.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n        \'sgd\',\n        loss=\'mse\',\n        metrics=[keras.metrics.CategoricalAccuracy()])\n    ```\n\n    # Arguments\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, name=\'categorical_accuracy\', dtype=None):\n        super(CategoricalAccuracy, self).__init__(\n            categorical_accuracy, name, dtype=dtype)\n\n\nclass SparseCategoricalAccuracy(MeanMetricWrapper):\n    """"""Calculates how often predictions matches integer labels.\n\n    For example, if `y_true` is [[2], [1]] and `y_pred` is\n    [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5.\n    If the weights were specified as [0.7, 0.3] then the categorical accuracy\n    would be .3. You can provide logits of classes as `y_pred`, since argmax of\n    logits and probabilities are same.\n\n    This metric creates two local variables, `total` and `count` that are used to\n    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n    ultimately returned as `sparse categorical accuracy`: an idempotent operation\n    that simply divides `total` by `count`.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n        \'sgd\',\n        loss=\'mse\',\n        metrics=[keras.metrics.SparseCategoricalAccuracy()])\n    ```\n    """"""\n\n    def __init__(self, name=\'sparse_categorical_accuracy\', dtype=None):\n        super(SparseCategoricalAccuracy, self).__init__(\n            sparse_categorical_accuracy, name, dtype=dtype)\n\n\nclass TopKCategoricalAccuracy(MeanMetricWrapper):\n    """"""Computes how often targets are in the top `K` predictions.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.TopKCategoricalAccuracy()])\n    ```\n\n    # Arguments\n        k: (Optional) Number of top elements to look at for computing accuracy.\n            Defaults to 5.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, k=5, name=\'top_k_categorical_accuracy\', dtype=None):\n        super(TopKCategoricalAccuracy, self).__init__(\n            top_k_categorical_accuracy, name, dtype=dtype, k=k)\n\n\nclass SparseTopKCategoricalAccuracy(MeanMetricWrapper):\n    """"""Computes how often integer targets are in the top `K` predictions.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n        \'sgd\',\n        metrics=[keras.metrics.SparseTopKCategoricalAccuracy()])\n    ```\n\n    # Arguments\n        k: (Optional) Number of top elements to look at for computing accuracy.\n            Defaults to 5.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, k=5, name=\'sparse_top_k_categorical_accuracy\', dtype=None):\n        super(SparseTopKCategoricalAccuracy, self).__init__(\n            sparse_top_k_categorical_accuracy, name, dtype=dtype, k=k)\n\n\nclass LogCoshError(MeanMetricWrapper):\n    """"""Computes the logarithm of the hyperbolic cosine of the prediction error.\n\n    `metric = log((exp(x) + exp(-x))/2)`, where x is the error (y_pred - y_true)\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.LogCoshError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'logcosh\', dtype=None):\n        super(LogCoshError, self).__init__(logcosh, name, dtype=dtype)\n\n\nclass Poisson(MeanMetricWrapper):\n    """"""Computes the Poisson metric between `y_true` and `y_pred`.\n\n    `metric = y_pred - y_true * log(y_pred)`\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.Poisson()])\n    ```\n    """"""\n\n    def __init__(self, name=\'poisson\', dtype=None):\n        super(Poisson, self).__init__(poisson, name, dtype=dtype)\n\n\nclass KLDivergence(MeanMetricWrapper):\n    """"""Computes Kullback-Leibler divergence metric between `y_true` and `y_pred`.\n\n    `metric = y_true * log(y_true / y_pred)`\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.KLDivergence()])\n    ```\n    """"""\n\n    def __init__(self, name=\'kullback_leibler_divergence\', dtype=None):\n        super(KLDivergence, self).__init__(\n            kullback_leibler_divergence, name, dtype=dtype)\n\n\nclass CosineSimilarity(MeanMetricWrapper):\n    """"""Computes the cosine similarity between the labels and predictions.\n\n    cosine similarity = (a . b) / ||a|| ||b||\n    [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n    For example, if `y_true` is [0, 1, 1], and `y_pred` is [1, 0, 1], the cosine\n    similarity is 0.5.\n\n    This metric keeps the average cosine similarity between `predictions` and\n    `labels` over a stream of data.\n\n    # Arguments\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n        axis: (Optional) Defaults to -1. The dimension along which the cosine\n        similarity is computed.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n      \'sgd\',\n      loss=\'mse\',\n      metrics=[keras.metrics.CosineSimilarity(axis=1)])\n    ```\n    """"""\n\n    def __init__(self, name=\'cosine_similarity\', dtype=None, axis=-1):\n        super(CosineSimilarity, self).__init__(\n            cosine_similarity, name, dtype=dtype, axis=axis)\n\n\nclass MeanAbsoluteError(MeanMetricWrapper):\n    """"""Computes the mean absolute error between the labels and predictions.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.MeanAbsoluteError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'mean_absolute_error\', dtype=None):\n        super(MeanAbsoluteError, self).__init__(\n            mean_absolute_error, name, dtype=dtype)\n\n\nclass MeanAbsolutePercentageError(MeanMetricWrapper):\n    """"""Computes the mean absolute percentage error between `y_true` and `y_pred`.\n\n    For example, if `y_true` is [0., 0., 1., 1.], and `y_pred` is [1., 1., 1., 0.]\n    the mean absolute percentage error is 5e+08.\n\n    Usage:\n\n    ```python\n    m = keras.metrics.MeanAbsolutePercentageError()\n    m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.])\n    # Final result: 5e+08\n    ```\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.MeanAbsolutePercentageError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'mean_absolute_percentage_error\', dtype=None):\n        super(MeanAbsolutePercentageError, self).__init__(\n            mean_absolute_percentage_error, name, dtype=dtype)\n\n\nclass MeanSquaredError(MeanMetricWrapper):\n    """"""Computes the mean squared error between `y_true` and `y_pred`.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.MeanSquaredError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'mean_squared_error\', dtype=None):\n        super(MeanSquaredError, self).__init__(\n            mean_squared_error, name, dtype=dtype)\n\n\nclass MeanSquaredLogarithmicError(MeanMetricWrapper):\n    """"""Computes the mean squared logarithmic error between `y_true` and `y_pred`.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.MeanSquaredLogarithmicError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'mean_squared_logarithmic_error\', dtype=None):\n        super(MeanSquaredLogarithmicError, self).__init__(\n            mean_squared_logarithmic_error, name, dtype=dtype)\n\n\nclass RootMeanSquaredError(Mean):\n    """"""Computes root mean squared error metric between `y_true` and `y_pred`.\n\n    Usage with the `compile` API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', metrics=[keras.metrics.RootMeanSquaredError()])\n    ```\n    """"""\n\n    def __init__(self, name=\'root_mean_squared_error\', dtype=None):\n        super(RootMeanSquaredError, self).__init__(name, dtype=dtype)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        """"""Accumulates root mean squared error statistics.\n\n        # Arguments\n            y_true: The ground truth values.\n            y_pred: The predicted values.\n            sample_weight: Optional weighting of each example. Defaults to 1.\n                Can be a `Tensor` whose rank is either 0,\n                or the same rank as `y_true`,\n                and must be broadcastable to `y_true`.\n\n        # Returns\n            List of update ops.\n        """"""\n        error_sq = K.square(y_pred - y_true)\n        return super(RootMeanSquaredError, self).update_state(\n            error_sq, sample_weight=sample_weight)\n\n    def result(self):\n        return K.sqrt(self.total / self.count)\n\n\nclass BinaryCrossentropy(MeanMetricWrapper):\n    """"""Computes the crossentropy metric between the labels and predictions.\n\n    This is the crossentropy metric class to be used when there are only two\n    label classes (0 and 1).\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n      \'sgd\',\n      loss=\'mse\',\n      metrics=[keras.metrics.BinaryCrossentropy()])\n    ```\n\n    # Arguments\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n        from_logits: (Optional )Whether output is expected to be a logits tensor.\n            By default, we consider that output encodes a probability distribution.\n        label_smoothing: (Optional) Float in [0, 1]. When > 0, label values are\n            smoothed, meaning the confidence on label values are relaxed.\n            e.g. `label_smoothing=0.2` means that we will use a value of `0.1` for\n            label `0` and `0.9` for label `1`""\n    """"""\n\n    def __init__(self,\n                 name=\'binary_crossentropy\',\n                 dtype=None,\n                 from_logits=False,\n                 label_smoothing=0):\n        super(BinaryCrossentropy, self).__init__(\n            binary_crossentropy,\n            name,\n            dtype=dtype,\n            from_logits=from_logits,\n            label_smoothing=label_smoothing)\n\n\nclass CategoricalCrossentropy(MeanMetricWrapper):\n    """"""Computes the crossentropy metric between the labels and predictions.\n\n    This is the crossentropy metric class to be used when there are multiple\n    label classes (2 or more). Here we assume that labels are given as a `one_hot`\n    representation. eg., When labels values are [2, 0, 1],\n    `y_true` = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n    \'sgd\',\n    loss=\'mse\',\n    metrics=[keras.metrics.CategoricalCrossentropy()])\n    ```\n\n    # Arguments\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n        from_logits: (Optional ) Whether `y_pred` is expected to be a logits tensor.\n            By default, we assume that `y_pred` encodes a probability distribution.\n        label_smoothing: Float in [0, 1]. When > 0, label values are smoothed,\n            meaning the confidence on label values are relaxed. e.g.\n            `label_smoothing=0.2` means that we will use a value of `0.1` for label\n            `0` and `0.9` for label `1`""\n    """"""\n\n    def __init__(self,\n                 name=\'categorical_crossentropy\',\n                 dtype=None,\n                 from_logits=False,\n                 label_smoothing=0):\n        super(CategoricalCrossentropy, self).__init__(\n            categorical_crossentropy,\n            name,\n            dtype=dtype,\n            from_logits=from_logits,\n            label_smoothing=label_smoothing)\n\n\nclass SparseCategoricalCrossentropy(MeanMetricWrapper):\n    """"""Computes the crossentropy metric between the labels and predictions.\n\n    Use this crossentropy metric when there are two or more label classes.\n    We expect labels to be provided as integers. If you want to provide labels\n    using `one-hot` representation, please use `CategoricalCrossentropy` metric.\n    There should be `# classes` floating point values per feature for `y_pred`\n    and a single floating point value per feature for `y_true`.\n\n    In the snippet below, there is a single floating point value per example for\n    `y_true` and `# classes` floating pointing values per example for `y_pred`.\n    The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n    `[batch_size, num_classes]`.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n    \'sgd\',\n    loss=\'mse\',\n    metrics=[keras.metrics.SparseCategoricalCrossentropy()])\n    ```\n\n    # Arguments\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n        from_logits: (Optional ) Whether `y_pred` is expected to be a logits tensor.\n            By default, we assume that `y_pred` encodes a probability distribution.\n        axis: (Optional) Defaults to -1. The dimension along which the metric is\n            computed.\n    """"""\n\n    def __init__(self,\n                 name=\'sparse_categorical_crossentropy\',\n                 dtype=None,\n                 from_logits=False,\n                 axis=-1):\n        super(SparseCategoricalCrossentropy, self).__init__(\n            sparse_categorical_crossentropy,\n            name,\n            dtype=dtype,\n            from_logits=from_logits,\n            axis=axis)\n\n\nclass _ConfusionMatrixConditionCount(Metric):\n    """"""Calculates the number of the given confusion matrix condition.\n\n    # Arguments\n        confusion_matrix_cond: One of `metrics_utils.ConfusionMatrix` conditions.\n        thresholds: (Optional) Defaults to 0.5. A float value or a python\n            list/tuple of float threshold values in [0, 1]. A threshold is compared\n            with prediction values to determine the truth value of predictions\n            (i.e., above the threshold is `true`, below is `false`). One metric\n            value is generated for each threshold value.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self,\n                 confusion_matrix_cond,\n                 thresholds=None,\n                 name=None,\n                 dtype=None):\n        super(_ConfusionMatrixConditionCount, self).__init__(name=name, dtype=dtype)\n        self._confusion_matrix_cond = confusion_matrix_cond\n        self.init_thresholds = thresholds\n        self.thresholds = metrics_utils.parse_init_thresholds(\n            thresholds, default_threshold=0.5)\n        self.accumulator = self.add_weight(\n            \'accumulator\',\n            shape=(len(self.thresholds),),\n            initializer=\'zeros\')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        return metrics_utils.update_confusion_matrix_variables(\n            {self._confusion_matrix_cond: self.accumulator},\n            y_true,\n            y_pred,\n            thresholds=self.thresholds,\n            sample_weight=sample_weight)\n\n    def result(self):\n        if len(self.thresholds) == 1:\n            return self.accumulator[0]\n        return self.accumulator\n\n    def reset_states(self):\n        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n        K.batch_set_value(\n            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n\n    def get_config(self):\n        config = {\'thresholds\': self.init_thresholds}\n        base_config = super(_ConfusionMatrixConditionCount, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass FalsePositives(_ConfusionMatrixConditionCount):\n    """"""Calculates the number of false positives.\n\n    For example, if `y_true` is [0, 1, 0, 0] and `y_pred` is [0, 0, 1, 1]\n    then the false positives value is 2.  If the weights were specified as\n    [0, 0, 1, 0] then the false positives value would be 1.\n\n    If `sample_weight` is given, calculates the sum of the weights of\n    false positives. This metric creates one local variable, `accumulator`\n    that is used to keep track of the number of false positives.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.FalsePositives()])\n    ```\n\n    # Arguments\n        thresholds: (Optional) Defaults to 0.5. A float value or a python\n            list/tuple of float threshold values in [0, 1]. A threshold is\n            compared with prediction values to determine the truth value of\n            predictions (i.e., above the threshold is `true`, below is `false`).\n            One metric value is generated for each threshold value.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, thresholds=None, name=None, dtype=None):\n        super(FalsePositives, self).__init__(\n            confusion_matrix_cond=metrics_utils.ConfusionMatrix.FALSE_POSITIVES,\n            thresholds=thresholds,\n            name=name,\n            dtype=dtype)\n\n\nclass TruePositives(_ConfusionMatrixConditionCount):\n    """"""Calculates the number of true positives.\n\n    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [1, 0, 1, 1]\n    then the true positives value is 2.  If the weights were specified as\n    [0, 0, 1, 0] then the true positives value would be 1.\n\n    If `sample_weight` is given, calculates the sum of the weights of\n    true positives. This metric creates one local variable, `accumulator`\n    that is used to keep track of the number of true positives.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.TruePositives()])\n    ```\n\n    # Arguments\n        thresholds: (Optional) Defaults to 0.5. A float value or a python\n            list/tuple of float threshold values in [0, 1]. A threshold is compared\n            with prediction values to determine the truth value of predictions\n            (i.e., above the threshold is `true`, below is `false`). One metric\n            value is generated for each threshold value.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, thresholds=None, name=None, dtype=None):\n        super(TruePositives, self).__init__(\n            confusion_matrix_cond=metrics_utils.ConfusionMatrix.TRUE_POSITIVES,\n            thresholds=thresholds,\n            name=name,\n            dtype=dtype)\n\n\nclass TrueNegatives(_ConfusionMatrixConditionCount):\n    """"""Calculates the number of true negatives.\n\n    For example, if `y_true` is [0, 1, 0, 0] and `y_pred` is [1, 1, 0, 0]\n    then the true negatives value is 2.  If the weights were specified as\n    [0, 0, 1, 0] then the true negatives value would be 1.\n\n    If `sample_weight` is given, calculates the sum of the weights of\n    true negatives. This metric creates one local variable, `accumulator`\n    that is used to keep track of the number of true negatives.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.TrueNegatives()])\n    ```\n\n    # Arguments\n        thresholds: (Optional) Defaults to 0.5. A float value or a python\n            list/tuple of float threshold values in [0, 1]. A threshold is compared\n            with prediction values to determine the truth value of predictions\n            (i.e., above the threshold is `true`, below is `false`). One metric\n            value is generated for each threshold value.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, thresholds=None, name=None, dtype=None):\n        super(TrueNegatives, self).__init__(\n            confusion_matrix_cond=metrics_utils.ConfusionMatrix.TRUE_NEGATIVES,\n            thresholds=thresholds,\n            name=name,\n            dtype=dtype)\n\n\nclass FalseNegatives(_ConfusionMatrixConditionCount):\n    """"""Calculates the number of false negatives.\n\n    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [0, 1, 0, 0]\n    then the false negatives value is 2.  If the weights were specified as\n    [0, 0, 1, 0] then the false negatives value would be 1.\n\n    If `sample_weight` is given, calculates the sum of the weights of\n    false negatives. This metric creates one local variable, `accumulator`\n    that is used to keep track of the number of false negatives.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.FalseNegatives()])\n    ```\n\n    # Arguments\n        thresholds: (Optional) Defaults to 0.5. A float value or a python\n            list/tuple of float threshold values in [0, 1]. A threshold is compared\n            with prediction values to determine the truth value of predictions\n            (i.e., above the threshold is `true`, below is `false`). One metric\n            value is generated for each threshold value.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, thresholds=None, name=None, dtype=None):\n        super(FalseNegatives, self).__init__(\n            confusion_matrix_cond=metrics_utils.ConfusionMatrix.FALSE_NEGATIVES,\n            thresholds=thresholds,\n            name=name,\n            dtype=dtype)\n\n\nclass SensitivitySpecificityBase(Metric):\n    """"""Abstract base class for computing sensitivity and specificity.\n\n    For additional information about specificity and sensitivity, see the\n    following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n    """"""\n\n    def __init__(self, value, num_thresholds=200, name=None, dtype=None):\n        super(SensitivitySpecificityBase, self).__init__(name=name, dtype=dtype)\n        if num_thresholds <= 0:\n            raise ValueError(\'`num_thresholds` must be > 0.\')\n        self.value = value\n        self.true_positives = self.add_weight(\n            \'true_positives\',\n            shape=(num_thresholds,),\n            initializer=\'zeros\')\n        self.true_negatives = self.add_weight(\n            \'true_negatives\',\n            shape=(num_thresholds,),\n            initializer=\'zeros\')\n        self.false_positives = self.add_weight(\n            \'false_positives\',\n            shape=(num_thresholds,),\n            initializer=\'zeros\')\n        self.false_negatives = self.add_weight(\n            \'false_negatives\',\n            shape=(num_thresholds,),\n            initializer=\'zeros\')\n\n        # Compute `num_thresholds` thresholds in [0, 1]\n        if num_thresholds == 1:\n            self.thresholds = [0.5]\n        else:\n            thresholds = [(i + 1) * 1.0 / (num_thresholds - 1)\n                          for i in range(num_thresholds - 2)]\n            self.thresholds = [0.0] + thresholds + [1.0]\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        return metrics_utils.update_confusion_matrix_variables(\n            {\n                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n                metrics_utils.ConfusionMatrix.TRUE_NEGATIVES: self.true_negatives,\n                metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives,\n                metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives,\n            },\n            y_true,\n            y_pred,\n            thresholds=self.thresholds,\n            sample_weight=sample_weight)\n\n    def reset_states(self):\n        num_thresholds = len(self.thresholds)\n        K.batch_set_value(\n            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n\n\nclass SensitivityAtSpecificity(SensitivitySpecificityBase):\n    """"""Computes the sensitivity at a given specificity.\n\n    `Sensitivity` measures the proportion of actual positives that are correctly\n    identified as such (tp / (tp + fn)).\n    `Specificity` measures the proportion of actual negatives that are correctly\n    identified as such (tn / (tn + fp)).\n\n    This metric creates four local variables, `true_positives`, `true_negatives`,\n    `false_positives` and `false_negatives` that are used to compute the\n    sensitivity at the given specificity. The threshold for the given specificity\n    value is computed and used to evaluate the corresponding sensitivity.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    For additional information about specificity and sensitivity, see the\n    following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n        \'sgd\',\n        loss=\'mse\',\n        metrics=[keras.metrics.SensitivityAtSpecificity()])\n    ```\n\n    # Arguments\n        specificity: A scalar value in range `[0, 1]`.\n        num_thresholds: (Optional) Defaults to 200. The number of thresholds to\n            use for matching the given specificity.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, specificity, num_thresholds=200, name=None, dtype=None):\n        if specificity < 0 or specificity > 1:\n            raise ValueError(\'`specificity` must be in the range [0, 1].\')\n        self.specificity = specificity\n        self.num_thresholds = num_thresholds\n        super(SensitivityAtSpecificity, self).__init__(\n            specificity, num_thresholds=num_thresholds, name=name, dtype=dtype)\n\n    def result(self):\n        # Calculate specificities at all the thresholds.\n        specificities = K.switch(\n            K.greater(self.true_negatives + self.false_positives, 0),\n            (self.true_negatives / (self.true_negatives + self.false_positives)),\n            K.zeros_like(self.thresholds))\n\n        # Find the index of the threshold where the specificity is closest to the\n        # given specificity.\n        min_index = K.argmin(\n            K.abs(specificities - self.value), axis=0)\n        min_index = K.cast(min_index, \'int32\')\n\n        # Compute sensitivity at that index.\n        denom = self.true_positives[min_index] + self.false_negatives[min_index]\n        return K.switch(\n            K.greater(denom, 0),\n            self.true_positives[min_index] / denom,\n            K.zeros_like(self.true_positives[min_index]))\n\n    def get_config(self):\n        config = {\n            \'num_thresholds\': self.num_thresholds,\n            \'specificity\': self.specificity\n        }\n        base_config = super(SensitivityAtSpecificity, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass SpecificityAtSensitivity(SensitivitySpecificityBase):\n    """"""Computes the specificity at a given sensitivity.\n\n    `Sensitivity` measures the proportion of actual positives that are correctly\n    identified as such (tp / (tp + fn)).\n    `Specificity` measures the proportion of actual negatives that are correctly\n    identified as such (tn / (tn + fp)).\n\n    This metric creates four local variables, `true_positives`, `true_negatives`,\n    `false_positives` and `false_negatives` that are used to compute the\n    specificity at the given sensitivity. The threshold for the given sensitivity\n    value is computed and used to evaluate the corresponding specificity.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    For additional information about specificity and sensitivity, see the\n    following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n\n    Usage with the compile API:\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n        \'sgd\',\n        loss=\'mse\',\n        metrics=[keras.metrics.SpecificityAtSensitivity()])\n    ```\n\n    # Arguments\n        sensitivity: A scalar value in range `[0, 1]`.\n        num_thresholds: (Optional) Defaults to 200. The number of thresholds to\n            use for matching the given specificity.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self, sensitivity, num_thresholds=200, name=None, dtype=None):\n        if sensitivity < 0 or sensitivity > 1:\n            raise ValueError(\'`sensitivity` must be in the range [0, 1].\')\n        self.sensitivity = sensitivity\n        self.num_thresholds = num_thresholds\n        super(SpecificityAtSensitivity, self).__init__(\n            sensitivity, num_thresholds=num_thresholds, name=name, dtype=dtype)\n\n    def result(self):\n        # Calculate sensitivities at all the thresholds.\n        sensitivities = K.switch(\n            K.greater(self.true_positives + self.false_negatives, 0),\n            (self.true_positives / (self.true_positives + self.false_negatives)),\n            K.zeros_like(self.thresholds))\n\n        # Find the index of the threshold where the sensitivity is closest to the\n        # given specificity.\n        min_index = K.argmin(\n            K.abs(sensitivities - self.value), axis=0)\n        min_index = K.cast(min_index, \'int32\')\n\n        # Compute specificity at that index.\n        denom = (self.true_negatives[min_index] + self.false_positives[min_index])\n        return K.switch(\n            K.greater(denom, 0),\n            self.true_negatives[min_index] / denom,\n            K.zeros_like(self.true_negatives[min_index]))\n\n    def get_config(self):\n        config = {\n            \'num_thresholds\': self.num_thresholds,\n            \'sensitivity\': self.sensitivity\n        }\n        base_config = super(SpecificityAtSensitivity, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Precision(Metric):\n    """"""Computes the precision of the predictions with respect to the labels.\n\n    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [1, 0, 1, 1]\n    then the precision value is 2/(2+1) ie. 0.66. If the weights were specified as\n    [0, 0, 1, 0] then the precision value would be 1.\n\n    The metric creates two local variables, `true_positives` and `false_positives`\n    that are used to compute the precision. This value is ultimately returned as\n    `precision`, an idempotent operation that simply divides `true_positives`\n    by the sum of `true_positives` and `false_positives`.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    If `top_k` is set, we\'ll calculate precision as how often on average a class\n    among the top-k classes with the highest predicted values of a batch entry is\n    correct and can be found in the label for that entry.\n\n    If `class_id` is specified, we calculate precision by considering only the\n    entries in the batch for which `class_id` is above the threshold and/or in the\n    top-k highest predictions, and computing the fraction of them for which\n    `class_id` is indeed a correct label.\n\n    Usage with the compile API:\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.Precision()])\n    ```\n\n    # Arguments\n        thresholds: (Optional) A float value or a python list/tuple of float\n            threshold values in [0, 1]. A threshold is compared with prediction\n            values to determine the truth value of predictions (i.e., above the\n            threshold is `true`, below is `false`). One metric value is generated\n            for each threshold value. If neither thresholds nor top_k are set, the\n            default is to calculate precision with `thresholds=0.5`.\n        top_k: (Optional) Unset by default. An int value specifying the top-k\n            predictions to consider when calculating precision.\n        class_id: (Optional) Integer class ID for which we want binary metrics.\n            This must be in the half-open interval `[0, num_classes)`, where\n            `num_classes` is the last dimension of predictions.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self,\n                 thresholds=None,\n                 top_k=None,\n                 class_id=None,\n                 name=None,\n                 dtype=None):\n        super(Precision, self).__init__(name=name, dtype=dtype)\n        self.init_thresholds = thresholds\n        if top_k is not None and K.backend() != \'tensorflow\':\n            raise RuntimeError(\n                \'`top_k` argument for `Precision` metric is currently supported \'\n                \'only with TensorFlow backend.\')\n\n        self.top_k = top_k\n        self.class_id = class_id\n\n        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF\n        self.thresholds = metrics_utils.parse_init_thresholds(\n            thresholds, default_threshold=default_threshold)\n        self.true_positives = self.add_weight(\n            \'true_positives\',\n            shape=(len(self.thresholds),),\n            initializer=\'zeros\')\n        self.false_positives = self.add_weight(\n            \'false_positives\',\n            shape=(len(self.thresholds),),\n            initializer=\'zeros\')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        return metrics_utils.update_confusion_matrix_variables(\n            {\n                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n                metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives\n            },\n            y_true,\n            y_pred,\n            thresholds=self.thresholds,\n            top_k=self.top_k,\n            class_id=self.class_id,\n            sample_weight=sample_weight)\n\n    def result(self):\n        denom = (self.true_positives + self.false_positives)\n        result = K.switch(\n            K.greater(denom, 0),\n            self.true_positives / denom,\n            K.zeros_like(self.true_positives))\n\n        return result[0] if len(self.thresholds) == 1 else result\n\n    def reset_states(self):\n        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n        K.batch_set_value(\n            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n\n    def get_config(self):\n        config = {\n            \'thresholds\': self.init_thresholds,\n            \'top_k\': self.top_k,\n            \'class_id\': self.class_id\n        }\n        base_config = super(Precision, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Recall(Metric):\n    """"""Computes the recall of the predictions with respect to the labels.\n\n    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [1, 0, 1, 1]\n    then the recall value is 2/(2+1) ie. 0.66. If the weights were specified as\n    [0, 0, 1, 0] then the recall value would be 1.\n\n    This metric creates two local variables, `true_positives` and\n    `false_negatives`, that are used to compute the recall. This value is\n    ultimately returned as `recall`, an idempotent operation that simply divides\n    `true_positives` by the sum of `true_positives` and `false_negatives`.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    If `top_k` is set, recall will be computed as how often on average a class\n    among the labels of a batch entry is in the top-k predictions.\n\n    If `class_id` is specified, we calculate recall by considering only the\n    entries in the batch for which `class_id` is in the label, and computing the\n    fraction of them for which `class_id` is above the threshold and/or in the\n    top-k predictions.\n\n    Usage with the compile API:\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.Recall()])\n    ```\n\n    # Arguments\n        thresholds: (Optional) A float value or a python list/tuple of float\n            threshold values in [0, 1]. A threshold is compared with prediction\n            values to determine the truth value of predictions (i.e., above the\n            threshold is `true`, below is `false`). One metric value is generated\n            for each threshold value. If neither thresholds nor top_k are set, the\n            default is to calculate recall with `thresholds=0.5`.\n        top_k: (Optional) Unset by default. An int value specifying the top-k\n            predictions to consider when calculating recall.\n        class_id: (Optional) Integer class ID for which we want binary metrics.\n            This must be in the half-open interval `[0, num_classes)`, where\n            `num_classes` is the last dimension of predictions.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n\n    def __init__(self,\n                 thresholds=None,\n                 top_k=None,\n                 class_id=None,\n                 name=None,\n                 dtype=None):\n        super(Recall, self).__init__(name=name, dtype=dtype)\n        self.init_thresholds = thresholds\n        if top_k is not None and K.backend() != \'tensorflow\':\n            raise RuntimeError(\n                \'`top_k` argument for `Recall` metric is currently supported only \'\n                \'with TensorFlow backend.\')\n\n        self.top_k = top_k\n        self.class_id = class_id\n\n        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF\n        self.thresholds = metrics_utils.parse_init_thresholds(\n            thresholds, default_threshold=default_threshold)\n        self.true_positives = self.add_weight(\n            \'true_positives\',\n            shape=(len(self.thresholds),),\n            initializer=\'zeros\')\n        self.false_negatives = self.add_weight(\n            \'false_negatives\',\n            shape=(len(self.thresholds),),\n            initializer=\'zeros\')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        return metrics_utils.update_confusion_matrix_variables(\n            {\n                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n                metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives\n            },\n            y_true,\n            y_pred,\n            thresholds=self.thresholds,\n            top_k=self.top_k,\n            class_id=self.class_id,\n            sample_weight=sample_weight)\n\n    def result(self):\n        denom = (self.true_positives + self.false_negatives)\n        result = K.switch(\n            K.greater(denom, 0),\n            self.true_positives / denom,\n            K.zeros_like(self.true_positives))\n        return result[0] if len(self.thresholds) == 1 else result\n\n    def reset_states(self):\n        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n        K.batch_set_value(\n            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n\n    def get_config(self):\n        config = {\n            \'thresholds\': self.init_thresholds,\n            \'top_k\': self.top_k,\n            \'class_id\': self.class_id\n        }\n        base_config = super(Recall, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass AUC(Metric):\n    """"""Computes the approximate AUC (Area under the curve) via a Riemann sum.\n\n    This metric creates four local variables, `true_positives`, `true_negatives`,\n    `false_positives` and `false_negatives` that are used to compute the AUC.\n    To discretize the AUC curve, a linearly spaced set of thresholds is used to\n    compute pairs of recall and precision values. The area under the ROC-curve is\n    therefore computed using the height of the recall values by the false positive\n    rate, while the area under the PR-curve is the computed using the height of\n    the precision values by the recall.\n\n    This value is ultimately returned as `auc`, an idempotent operation that\n    computes the area under a discretized curve of precision versus recall values\n    (computed using the aforementioned variables). The `num_thresholds` variable\n    controls the degree of discretization with larger numbers of thresholds more\n    closely approximating the true AUC. The quality of the approximation may vary\n    dramatically depending on `num_thresholds`. The `thresholds` parameter can be\n    used to manually specify thresholds which split the predictions more evenly.\n\n    For best results, `predictions` should be distributed approximately uniformly\n    in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC\n    approximation may be poor if this is not the case. Setting `summation_method`\n    to \'minoring\' or \'majoring\' can help quantify the error in the approximation\n    by providing lower or upper bound estimate of the AUC.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\'sgd\', loss=\'mse\', metrics=[keras.metrics.AUC()])\n    ```\n\n    # Arguments\n        num_thresholds: (Optional) Defaults to 200. The number of thresholds to\n            use when discretizing the roc curve. Values must be > 1.\n            curve: (Optional) Specifies the name of the curve to be computed, \'ROC\'\n            [default] or \'PR\' for the Precision-Recall-curve.\n        summation_method: (Optional) Specifies the Riemann summation method used\n            (https://en.wikipedia.org/wiki/Riemann_sum): \'interpolation\' [default],\n              applies mid-point summation scheme for `ROC`. For PR-AUC, interpolates\n              (true/false) positives but not the ratio that is precision (see Davis\n              & Goadrich 2006 for details); \'minoring\' that applies left summation\n              for increasing intervals and right summation for decreasing intervals;\n              \'majoring\' that does the opposite.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n        thresholds: (Optional) A list of floating point values to use as the\n            thresholds for discretizing the curve. If set, the `num_thresholds`\n            parameter is ignored. Values should be in [0, 1]. Endpoint thresholds\n            equal to {-epsilon, 1+epsilon} for a small positive epsilon value will\n            be automatically included with these to correctly handle predictions\n            equal to exactly 0 or 1.\n    """"""\n\n    def __init__(self,\n                 num_thresholds=200,\n                 curve=\'ROC\',\n                 summation_method=\'interpolation\',\n                 name=None,\n                 dtype=None,\n                 thresholds=None):\n        # Validate configurations.\n        if (isinstance(curve, metrics_utils.AUCCurve) and\n                curve not in list(metrics_utils.AUCCurve)):\n            raise ValueError(\'Invalid curve: ""{}"". Valid options are: ""{}""\'.format(\n                curve, list(metrics_utils.AUCCurve)))\n        if isinstance(\n            summation_method,\n            metrics_utils.AUCSummationMethod) and summation_method not in list(\n                metrics_utils.AUCSummationMethod):\n            raise ValueError(\n                \'Invalid summation method: ""{}"". Valid options are: ""{}""\'.format(\n                    summation_method, list(metrics_utils.AUCSummationMethod)))\n\n        # Update properties.\n        if thresholds is not None:\n            # If specified, use the supplied thresholds.\n            self.num_thresholds = len(thresholds) + 2\n            thresholds = sorted(thresholds)\n        else:\n            if num_thresholds <= 1:\n                raise ValueError(\'`num_thresholds` must be > 1.\')\n\n            # Otherwise, linearly interpolate (num_thresholds - 2) thresholds in\n            # (0, 1).\n            self.num_thresholds = num_thresholds\n            thresholds = [(i + 1) * 1.0 / (num_thresholds - 1)\n                          for i in range(num_thresholds - 2)]\n\n        # Add an endpoint ""threshold"" below zero and above one for either\n        # threshold method to account for floating point imprecisions.\n        self.thresholds = [0.0 - K.epsilon()] + thresholds + [1.0 + K.epsilon()]\n\n        if isinstance(curve, metrics_utils.AUCCurve):\n            self.curve = curve\n        else:\n            self.curve = metrics_utils.AUCCurve.from_str(curve)\n        if isinstance(summation_method, metrics_utils.AUCSummationMethod):\n            self.summation_method = summation_method\n        else:\n            self.summation_method = metrics_utils.AUCSummationMethod.from_str(\n                summation_method)\n        super(AUC, self).__init__(name=name, dtype=dtype)\n\n        # Create metric variables\n        self.true_positives = self.add_weight(\n            \'true_positives\',\n            shape=(self.num_thresholds,),\n            initializer=\'zeros\')\n        self.true_negatives = self.add_weight(\n            \'true_negatives\',\n            shape=(self.num_thresholds,),\n            initializer=\'zeros\')\n        self.false_positives = self.add_weight(\n            \'false_positives\',\n            shape=(self.num_thresholds,),\n            initializer=\'zeros\')\n        self.false_negatives = self.add_weight(\n            \'false_negatives\',\n            shape=(self.num_thresholds,),\n            initializer=\'zeros\')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        return metrics_utils.update_confusion_matrix_variables({\n            metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n            metrics_utils.ConfusionMatrix.TRUE_NEGATIVES: self.true_negatives,\n            metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives,\n            metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives,\n        }, y_true, y_pred, self.thresholds, sample_weight=sample_weight)\n\n    def interpolate_pr_auc(self):\n        """"""Interpolation formula inspired by section 4 of Davis & Goadrich 2006.\n\n        https://www.biostat.wisc.edu/~page/rocpr.pdf\n\n        Note here we derive & use a closed formula not present in the paper\n        as follows:\n\n          Precision = TP / (TP + FP) = TP / P\n\n        Modeling all of TP (true positive), FP (false positive) and their sum\n        P = TP + FP (predicted positive) as varying linearly within each interval\n        [A, B] between successive thresholds, we get\n\n          Precision slope = dTP / dP\n                          = (TP_B - TP_A) / (P_B - P_A)\n                          = (TP - TP_A) / (P - P_A)\n          Precision = (TP_A + slope * (P - P_A)) / P\n\n        The area within the interval is (slope / total_pos_weight) times\n\n          int_A^B{Precision.dP} = int_A^B{(TP_A + slope * (P - P_A)) * dP / P}\n          int_A^B{Precision.dP} = int_A^B{slope * dP + intercept * dP / P}\n\n        where intercept = TP_A - slope * P_A = TP_B - slope * P_B, resulting in\n\n          int_A^B{Precision.dP} = TP_B - TP_A + intercept * log(P_B / P_A)\n\n        Bringing back the factor (slope / total_pos_weight) we\'d put aside, we get\n\n          slope * [dTP + intercept *  log(P_B / P_A)] / total_pos_weight\n\n        where dTP == TP_B - TP_A.\n\n        Note that when P_A == 0 the above calculation simplifies into\n\n          int_A^B{Precision.dTP} = int_A^B{slope * dTP} = slope * (TP_B - TP_A)\n\n        which is really equivalent to imputing constant precision throughout the\n        first bucket having >0 true positives.\n\n        # Returns\n            pr_auc: an approximation of the area under the P-R curve.\n        """"""\n        dtp = self.true_positives[:self.num_thresholds -\n                                  1] - self.true_positives[1:]\n        p = self.true_positives + self.false_positives\n        dp = p[:self.num_thresholds - 1] - p[1:]\n\n        dp = K.maximum(dp, 0)\n        prec_slope = K.switch(\n            K.greater(dp, 0),\n            dtp / dp,\n            K.zeros_like(dtp))\n        intercept = self.true_positives[1:] - (prec_slope * p[1:])\n\n        # Logical and\n        pMin = K.expand_dims(p[:self.num_thresholds - 1] > 0, 0)\n        pMax = K.expand_dims(p[1:] > 0, 0)\n        are_different = K.concatenate([pMin, pMax], axis=0)\n        switch_condition = K.all(are_different, axis=0)\n\n        safe_p_ratio = K.switch(\n            switch_condition,\n            K.switch(\n                K.greater(p[1:], 0),\n                p[:self.num_thresholds - 1] / p[1:],\n                K.zeros_like(p[:self.num_thresholds - 1])),\n            K.ones_like(p[1:]))\n\n        numer = prec_slope * (dtp + intercept * K.log(safe_p_ratio))\n        denom = K.maximum(self.true_positives[1:] + self.false_negatives[1:], 0)\n        return K.sum(K.switch(\n            K.greater(denom, 0),\n            numer / denom,\n            K.zeros_like(numer)))\n\n    def result(self):\n        if (self.curve == metrics_utils.AUCCurve.PR and\n                (self.summation_method ==\n                 metrics_utils.AUCSummationMethod.INTERPOLATION)):\n            # This use case is different and is handled separately.\n            return self.interpolate_pr_auc()\n\n        # Set `x` and `y` values for the curves based on `curve` config.\n        recall = K.switch(\n            K.greater((self.true_positives), 0),\n            (self.true_positives /\n                (self.true_positives + self.false_negatives)),\n            K.zeros_like(self.true_positives))\n        if self.curve == metrics_utils.AUCCurve.ROC:\n            fp_rate = K.switch(\n                K.greater((self.false_positives), 0),\n                (self.false_positives /\n                    (self.false_positives + self.true_negatives)),\n                K.zeros_like(self.false_positives))\n            x = fp_rate\n            y = recall\n        else:  # curve == \'PR\'.\n            precision = K.switch(\n                K.greater((self.true_positives), 0),\n                (self.true_positives / (self.true_positives + self.false_positives)),\n                K.zeros_like(self.true_positives))\n            x = recall\n            y = precision\n\n        # Find the rectangle heights based on `summation_method`.\n        if self.summation_method == metrics_utils.AUCSummationMethod.INTERPOLATION:\n            # Note: the case (\'PR\', \'interpolation\') has been handled above.\n            heights = (y[:self.num_thresholds - 1] + y[1:]) / 2.\n        elif self.summation_method == metrics_utils.AUCSummationMethod.MINORING:\n            heights = K.minimum(y[:self.num_thresholds - 1], y[1:])\n        else:  # self.summation_method = metrics_utils.AUCSummationMethod.MAJORING:\n            heights = K.maximum(y[:self.num_thresholds - 1], y[1:])\n\n        # Sum up the areas of all the rectangles.\n        return K.sum((x[:self.num_thresholds - 1] - x[1:]) * heights)\n\n    def reset_states(self):\n        K.batch_set_value(\n            [(v, np.zeros((self.num_thresholds,))) for v in self.weights])\n\n    def get_config(self):\n        config = {\n            \'num_thresholds\': self.num_thresholds,\n            \'curve\': self.curve.value,\n            \'summation_method\': self.summation_method.value,\n            # We remove the endpoint thresholds as an inverse of how the thresholds\n            # were initialized. This ensures that a metric initialized from this\n            # config has the same thresholds.\n            \'thresholds\': self.thresholds[1:-1],\n        }\n        base_config = super(AUC, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nBaseMeanIoU = object\nif K.backend() == \'tensorflow\':\n    import tensorflow as tf\n    if tf.__version__ >= \'2.0.0\':\n        BaseMeanIoU = tf.keras.metrics.MeanIoU\n\n\nclass MeanIoU(BaseMeanIoU):\n    """"""Computes the mean Intersection-Over-Union metric.\n\n    Mean Intersection-Over-Union is a common evaluation metric for semantic image\n    segmentation, which first computes the IOU for each semantic class and then\n    computes the average over classes. IOU is defined as follows:\n    IOU = true_positive / (true_positive + false_positive + false_negative).\n    The predictions are accumulated in a confusion matrix, weighted by\n    `sample_weight` and the metric is then calculated from it.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use `sample_weight` of 0 to mask values.\n\n    Usage with the compile API:\n\n    ```python\n    model = keras.Model(inputs, outputs)\n    model.compile(\n        \'sgd\',\n        loss=\'mse\',\n        metrics=[keras.metrics.MeanIoU(num_classes=2)])\n    ```\n\n    # Arguments\n        num_classes: The possible number of labels the prediction task can have.\n            This value must be provided, since a confusion matrix of dimension =\n            [num_classes, num_classes] will be allocated.\n        name: (Optional) string name of the metric instance.\n        dtype: (Optional) data type of the metric result.\n    """"""\n    def __init__(self, num_classes, name=None, dtype=None):\n        if K.backend() != \'tensorflow\' or BaseMeanIoU is object:\n            raise RuntimeError(\n                \'`MeanIoU` metric is currently supported only \'\n                \'with TensorFlow backend and TF version >= 2.0.0.\')\n        super(MeanIoU, self).__init__(num_classes, name=name, dtype=dtype)\n\n\ndef accuracy(y_true, y_pred):\n    if not K.is_tensor(y_pred):\n        y_pred = K.constant(y_pred)\n    y_true = K.cast(y_true, y_pred.dtype)\n    return K.cast(K.equal(y_true, y_pred), K.floatx())\n\n\ndef binary_accuracy(y_true, y_pred, threshold=0.5):\n    if threshold != 0.5:\n        threshold = K.cast(threshold, y_pred.dtype)\n        y_pred = K.cast(y_pred > threshold, y_pred.dtype)\n    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n\n\ndef categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.argmax(y_true, axis=-1),\n                          K.argmax(y_pred, axis=-1)),\n                  K.floatx())\n\n\ndef sparse_categorical_accuracy(y_true, y_pred):\n    # reshape in case it\'s in shape (num_samples, 1) instead of (num_samples,)\n    if K.ndim(y_true) == K.ndim(y_pred):\n        y_true = K.squeeze(y_true, -1)\n    # convert dense predictions to labels\n    y_pred_labels = K.argmax(y_pred, axis=-1)\n    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n    return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n\n\ndef top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.cast(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), K.floatx())\n\n\ndef sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    # If the shape of y_true is (num_samples, 1), flatten to (num_samples,)\n    return K.cast(K.in_top_k(y_pred, K.cast(K.flatten(y_true), \'int32\'), k),\n                  K.floatx())\n\n\ndef cosine_proximity(y_true, y_pred, axis=-1):\n    y_true = K.l2_normalize(y_true, axis=axis)\n    y_pred = K.l2_normalize(y_pred, axis=axis)\n    return K.sum(y_true * y_pred, axis=axis)\n\n\ndef clone_metric(metric):\n    """"""Returns a clone of the metric if stateful, otherwise returns it as is.""""""\n    if isinstance(metric, Metric):\n        return metric.__class__.from_config(metric.get_config())\n    return metric\n\n\ndef clone_metrics(metrics):\n    """"""Clones the given metric list/dict.""""""\n    if metrics is None:\n        return None\n    if isinstance(metrics, dict):\n        return {key: clone_metric(value) for key, value in metrics.items()}\n    return [clone_metric(metric) for metric in metrics]\n\n\n# Aliases\n\nmse = MSE = mean_squared_error\nmae = MAE = mean_absolute_error\nmape = MAPE = mean_absolute_percentage_error\nmsle = MSLE = mean_squared_logarithmic_error\ncosine = cosine_similarity = cosine_proximity\n\n\ndef serialize(metric):\n    return serialize_keras_object(metric)\n\n\ndef deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'metric function\')\n\n\ndef get(identifier):\n    if isinstance(identifier, dict):\n        config = {\'class_name\': str(identifier), \'config\': {}}\n        return deserialize(config)\n    elif isinstance(identifier, six.string_types):\n        return deserialize(str(identifier))\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret \'\n                         \'metric function identifier:\', identifier)\n'"
keras/models.py,0,"b'""""""Model-related utilities.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom . import backend as K\nfrom .utils.generic_utils import has_arg\nfrom .utils.generic_utils import to_list\nfrom .engine.input_layer import Input\nfrom .engine.input_layer import InputLayer\nfrom .engine.training import Model\nfrom .engine.sequential import Sequential\nfrom .engine.saving import save_model\nfrom .engine.saving import load_model\nfrom .engine.saving import model_from_config\nfrom .engine.saving import model_from_yaml\nfrom .engine.saving import model_from_json\n\ntry:\n    import h5py\nexcept ImportError:\n    h5py = None\n\n\ndef _clone_functional_model(model, input_tensors=None):\n    """"""Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    """"""\n    if not isinstance(model, Model):\n        raise ValueError(\'Expected `model` argument \'\n                         \'to be a `Model` instance, got \', model)\n    if isinstance(model, Sequential):\n        raise ValueError(\'Expected `model` argument \'\n                         \'to be a functional `Model` instance, \'\n                         \'got a `Sequential` instance instead:\', model)\n\n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers = []\n        input_tensors = []\n        for layer in model._input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] = _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors = to_list(input_tensors)\n        _input_tensors = []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model._input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name=\'input_wrapper_for_\' + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors = _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[id(x)] = (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys = list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n    for depth in depth_keys:\n        nodes = model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer = node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer = layer.__class__.from_config(layer.get_config())\n                layer_map[layer] = new_layer\n                layer = new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer = layer_map[layer]\n                # Don\'t call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors = node.input_tensors\n            reference_output_tensors = node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data = []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if id(x) in tensor_map:\n                    computed_data.append(tensor_map[id(x)])\n\n            if len(computed_data) == len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs = node.arguments\n                else:\n                    kwargs = {}\n                if len(computed_data) == 1:\n                    computed_tensor, computed_mask = computed_data[0]\n                    if has_arg(layer.call, \'mask\'):\n                        if \'mask\' not in kwargs:\n                            kwargs[\'mask\'] = computed_mask\n                    output_tensors = to_list(\n                        layer(computed_tensor, **kwargs))\n                    if layer.supports_masking:\n                        output_masks = to_list(\n                            layer.compute_mask(computed_tensor,\n                                               computed_mask))\n                    else:\n                        output_masks = [None] * len(output_tensors)\n                    computed_tensors = [computed_tensor]\n                    computed_masks = [computed_mask]\n                else:\n                    computed_tensors = [x[0] for x in computed_data]\n                    computed_masks = [x[1] for x in computed_data]\n                    if has_arg(layer.call, \'mask\'):\n                        if \'mask\' not in kwargs:\n                            kwargs[\'mask\'] = computed_masks\n                    output_tensors = to_list(\n                        layer(computed_tensors, **kwargs))\n                    if layer.supports_masking:\n                        output_masks = to_list(\n                            layer.compute_mask(computed_tensors,\n                                               computed_masks))\n                    else:\n                        output_masks = [None] * len(output_tensors)\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[id(x)] = (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors = []\n    for x in model.outputs:\n        assert id(x) in tensor_map, \'Could not compute output \' + str(x)\n        tensor, _ = tensor_map[id(x)]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name=model.name)\n\n\ndef _clone_sequential_model(model, input_tensors=None):\n    """"""Clone a `Sequential` model instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Sequential`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Sequential` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    """"""\n    if not isinstance(model, Sequential):\n        raise ValueError(\'Expected `model` argument \'\n                         \'to be a `Sequential` model instance, \'\n                         \'but got:\', model)\n\n    def clone(layer):\n        return layer.__class__.from_config(layer.get_config())\n\n    layers = [clone(layer) for layer in model.layers]\n    if input_tensors is None:\n        return Sequential(layers=layers, name=model.name)\n    else:\n        if len(to_list(input_tensors)) != 1:\n            raise ValueError(\'To clone a `Sequential` model, we expect \'\n                             \' at most one tensor \'\n                             \'as part of `input_tensors`.\')\n        x = to_list(input_tensors)[0]\n        if K.is_keras_tensor(x):\n            origin_layer = x._keras_history[0]\n            if isinstance(origin_layer, InputLayer):\n                return Sequential(layers=[origin_layer] + layers,\n                                  name=model.name)\n            else:\n                raise ValueError(\'Cannot clone a `Sequential` model on top \'\n                                 \'of a tensor that comes from a Keras layer \'\n                                 \'other than an `InputLayer`. \'\n                                 \'Use the functional API instead.\')\n        input_tensor = Input(tensor=x,\n                             name=\'input_wrapper_for_\' + str(x.name))\n        input_layer = input_tensor._keras_history[0]\n        return Sequential(layers=[input_layer] + layers, name=model.name)\n\n\ndef clone_model(model, input_tensors=None):\n    """"""Clone any `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`\n            (could be a functional model or a Sequential model).\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    """"""\n    if isinstance(model, Sequential):\n        return _clone_sequential_model(model, input_tensors=input_tensors)\n    else:\n        return _clone_functional_model(model, input_tensors=input_tensors)\n'"
keras/objectives.py,0,"b'""""""Legacy objectives module.\n\nOnly kept for backwards API compatibility.\n""""""\nfrom __future__ import absolute_import\nfrom .losses import *\n'"
keras/optimizers.py,16,"b'""""""Built-in optimizer classes.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport copy\nimport numpy as np\nfrom six.moves import zip\n\nfrom . import backend as K\nfrom .utils.generic_utils import serialize_keras_object\nfrom .utils.generic_utils import deserialize_keras_object\nfrom .legacy import interfaces\n\nif K.backend() == \'tensorflow\':\n    import tensorflow as tf\n\n\ndef clip_norm(g, c, n):\n    """"""Clip the gradient `g` if the L2 norm `n` exceeds `c`.\n\n    # Arguments\n        g: Tensor, the gradient tensor\n        c: float >= 0. Gradients will be clipped\n            when their L2 norm exceeds this value.\n        n: Tensor, actual norm of `g`.\n\n    # Returns\n        Tensor, the gradient clipped if required.\n    """"""\n    if c <= 0:  # if clipnorm == 0 no need to add ops to the graph\n        return g\n\n    # tf require using a special op to multiply IndexedSliced by scalar\n    if K.backend() == \'tensorflow\':\n        condition = n >= c\n        then_expression = tf.scalar_mul(c / n, g)\n        else_expression = g\n\n        # saving the shape to avoid converting sparse tensor to dense\n        if isinstance(then_expression, tf.Tensor):\n            g_shape = copy.copy(then_expression.get_shape())\n        elif isinstance(then_expression, tf.IndexedSlices):\n            g_shape = copy.copy(then_expression.dense_shape)\n        if condition.dtype != tf.bool:\n            condition = tf.cast(condition, \'bool\')\n        g = tf.cond(condition,\n                    lambda: then_expression,\n                    lambda: else_expression)\n        if isinstance(then_expression, tf.Tensor):\n            g.set_shape(g_shape)\n        elif isinstance(then_expression, tf.IndexedSlices):\n            g._dense_shape = g_shape\n    else:\n        g = K.switch(K.greater_equal(n, c), g * c / n, g)\n    return g\n\n\nclass Optimizer(object):\n    """"""Abstract optimizer base class.\n\n    Note: this is the parent class of all optimizers, not an actual optimizer\n    that can be used for training models.\n\n    All Keras optimizers support the following keyword arguments:\n\n        clipnorm: float >= 0. Gradients will be clipped\n            when their L2 norm exceeds this value.\n        clipvalue: float >= 0. Gradients will be clipped\n            when their absolute value exceeds this value.\n    """"""\n\n    def __init__(self, **kwargs):\n        allowed_kwargs = {\'clipnorm\', \'clipvalue\'}\n        for k in kwargs:\n            if k not in allowed_kwargs:\n                raise TypeError(\'Unexpected keyword argument \'\n                                \'passed to optimizer: \' + str(k))\n        self.__dict__.update(kwargs)\n        self.updates = []\n        self.weights = []\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        raise NotImplementedError\n\n    def get_gradients(self, loss, params):\n        grads = K.gradients(loss, params)\n        if any(x is None for x in grads):\n            raise ValueError(\'An operation has `None` for gradient. \'\n                             \'Please make sure that all of your ops have a \'\n                             \'gradient defined (i.e. are differentiable). \'\n                             \'Common ops without gradient: \'\n                             \'K.argmax, K.round, K.eval.\')\n        if hasattr(self, \'clipnorm\') and self.clipnorm > 0:\n            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))\n            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n        if hasattr(self, \'clipvalue\') and self.clipvalue > 0:\n            grads = [K.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n        return grads\n\n    def set_weights(self, weights):\n        """"""Sets the weights of the optimizer, from Numpy arrays.\n\n        Should only be called after computing the gradients\n        (otherwise the optimizer has no weights).\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the optimizer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: in case of incompatible weight shapes.\n        """"""\n        params = self.weights\n        if len(params) != len(weights):\n            raise ValueError(\'Length of the specified weight list (\' +\n                             str(len(weights)) +\n                             \') does not match the number of weights \' +\n                             \'of the optimizer (\' + str(len(params)) + \')\')\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError(\'Optimizer weight shape \' +\n                                 str(pv.shape) +\n                                 \' not compatible with \'\n                                 \'provided weight shape \' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)\n\n    def get_weights(self):\n        """"""Returns the current value of the weights of the optimizer.\n\n        # Returns\n            A list of numpy arrays.\n        """"""\n        return K.batch_get_value(self.weights)\n\n    def get_config(self):\n        config = {}\n        if hasattr(self, \'clipnorm\'):\n            config[\'clipnorm\'] = self.clipnorm\n        if hasattr(self, \'clipvalue\'):\n            config[\'clipvalue\'] = self.clipvalue\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n    @property\n    def lr(self):\n        # Legacy support.\n        return self.learning_rate\n\n\nclass SGD(Optimizer):\n    """"""Stochastic gradient descent optimizer.\n\n    Includes support for momentum,\n    learning rate decay, and Nesterov momentum.\n\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        momentum: float >= 0. Parameter that accelerates SGD\n            in the relevant direction and dampens oscillations.\n        nesterov: boolean. Whether to apply Nesterov momentum.\n    """"""\n\n    def __init__(self, learning_rate=0.01, momentum=0.,\n                 nesterov=False, **kwargs):\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        self.initial_decay = kwargs.pop(\'decay\', 0.0)\n        super(SGD, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.momentum = K.variable(momentum, name=\'momentum\')\n            self.decay = K.variable(self.initial_decay, name=\'decay\')\n        self.nesterov = nesterov\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.learning_rate\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n        # momentum\n        shapes = [K.int_shape(p) for p in params]\n        moments = [K.zeros(shape, name=\'moment_\' + str(i))\n                   for (i, shape) in enumerate(shapes)]\n        self.weights = [self.iterations] + moments\n        for p, g, m in zip(params, grads, moments):\n            v = self.momentum * m - lr * g  # velocity\n            self.updates.append(K.update(m, v))\n\n            if self.nesterov:\n                new_p = p + self.momentum * v - lr * g\n            else:\n                new_p = p + v\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'momentum\': float(K.get_value(self.momentum)),\n                  \'decay\': float(K.get_value(self.decay)),\n                  \'nesterov\': self.nesterov}\n        base_config = super(SGD, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass RMSprop(Optimizer):\n    """"""RMSProp optimizer.\n\n    It is recommended to leave the parameters of this optimizer\n    at their default values\n    (except the learning rate, which can be freely tuned).\n\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        rho: float >= 0.\n\n    # References\n        - [rmsprop: Divide the gradient by a running average of its recent magnitude\n           ](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n    """"""\n\n    def __init__(self, learning_rate=0.001, rho=0.9, **kwargs):\n        self.initial_decay = kwargs.pop(\'decay\', 0.0)\n        self.epsilon = kwargs.pop(\'epsilon\', K.epsilon())\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        super(RMSprop, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.rho = K.variable(rho, name=\'rho\')\n            self.decay = K.variable(self.initial_decay, name=\'decay\')\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        accumulators = [K.zeros(K.int_shape(p),\n                        dtype=K.dtype(p),\n                        name=\'accumulator_\' + str(i))\n                        for (i, p) in enumerate(params)]\n        self.weights = [self.iterations] + accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.learning_rate\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def set_weights(self, weights):\n        params = self.weights\n        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n        # since it does not include iteration at head of the weight list. Set\n        # iteration to 0.\n        if len(params) == len(weights) + 1:\n            weights = [np.array(0)] + weights\n        super(RMSprop, self).set_weights(weights)\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'rho\': float(K.get_value(self.rho)),\n                  \'decay\': float(K.get_value(self.decay)),\n                  \'epsilon\': self.epsilon}\n        base_config = super(RMSprop, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Adagrad(Optimizer):\n    """"""Adagrad optimizer.\n\n    Adagrad is an optimizer with parameter-specific learning rates,\n    which are adapted relative to how frequently a parameter gets\n    updated during training. The more updates a parameter receives,\n    the smaller the learning rate.\n\n    It is recommended to leave the parameters of this optimizer\n    at their default values.\n\n    # Arguments\n        learning_rate: float >= 0. Initial learning rate.\n\n    # References\n        - [Adaptive Subgradient Methods for Online Learning and Stochastic\n           Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n    """"""\n\n    def __init__(self, learning_rate=0.01, **kwargs):\n        self.initial_decay = kwargs.pop(\'decay\', 0.0)\n        self.epsilon = kwargs.pop(\'epsilon\', K.epsilon())\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        super(Adagrad, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.decay = K.variable(self.initial_decay, name=\'decay\')\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators = [K.zeros(shape, name=\'accumulator_\' + str(i))\n                        for (i, shape) in enumerate(shapes)]\n        self.weights = [self.iterations] + accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.learning_rate\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            new_a = a + K.square(g)  # update accumulator\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def set_weights(self, weights):\n        params = self.weights\n        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n        # since it does not include iteration at head of the weight list. Set\n        # iteration to 0.\n        if len(params) == len(weights) + 1:\n            weights = [np.array(0)] + weights\n        super(Adagrad, self).set_weights(weights)\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'decay\': float(K.get_value(self.decay)),\n                  \'epsilon\': self.epsilon}\n        base_config = super(Adagrad, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Adadelta(Optimizer):\n    """"""Adadelta optimizer.\n\n    Adadelta is a more robust extension of Adagrad\n    that adapts learning rates based on a moving window of gradient updates,\n    instead of accumulating all past gradients. This way, Adadelta continues\n    learning even when many updates have been done. Compared to Adagrad, in the\n    original version of Adadelta you don\'t have to set an initial learning\n    rate. In this version, initial learning rate and decay factor can\n    be set, as in most other Keras optimizers.\n\n    It is recommended to leave the parameters of this optimizer\n    at their default values.\n\n    # Arguments\n        learning_rate: float >= 0. Initial learning rate, defaults to 1.\n            It is recommended to leave it at the default value.\n        rho: float >= 0. Adadelta decay factor, corresponding to fraction of\n            gradient to keep at each time step.\n\n    # References\n        - [Adadelta - an adaptive learning rate method](\n           https://arxiv.org/abs/1212.5701)\n    """"""\n\n    def __init__(self, learning_rate=1.0, rho=0.95, **kwargs):\n        self.initial_decay = kwargs.pop(\'decay\', 0.0)\n        self.epsilon = kwargs.pop(\'epsilon\', K.epsilon())\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        super(Adadelta, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.decay = K.variable(self.initial_decay, name=\'decay\')\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n        self.rho = rho\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators = [K.zeros(shape, name=\'accumulator_\' + str(i))\n                        for (i, shape) in enumerate(shapes)]\n        delta_accumulators = [K.zeros(shape, name=\'delta_accumulator_\' + str(i))\n                              for (i, shape) in enumerate(shapes)]\n        self.weights = [self.iterations] + accumulators + delta_accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.learning_rate\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n\n            # use the new accumulator and the *old* delta_accumulator\n            update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n            new_p = p - lr * update\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n\n            # update delta_accumulator\n            new_d_a = self.rho * d_a + (1 - self.rho) * K.square(update)\n            self.updates.append(K.update(d_a, new_d_a))\n        return self.updates\n\n    def set_weights(self, weights):\n        params = self.weights\n        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n        # since it does not include iteration at head of the weight list. Set\n        # iteration to 0.\n        if len(params) == len(weights) + 1:\n            weights = [np.array(0)] + weights\n        super(Adadelta, self).set_weights(weights)\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'rho\': self.rho,\n                  \'decay\': float(K.get_value(self.decay)),\n                  \'epsilon\': self.epsilon}\n        base_config = super(Adadelta, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Adam(Optimizer):\n    """"""Adam optimizer.\n\n    Default parameters follow those provided in the original paper.\n\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n            algorithm from the paper ""On the Convergence of Adam and\n            Beyond"".\n\n    # References\n        - [Adam - A Method for Stochastic Optimization](\n           https://arxiv.org/abs/1412.6980v8)\n        - [On the Convergence of Adam and Beyond](\n           https://openreview.net/forum?id=ryQu7f-RZ)\n    """"""\n\n    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n                 amsgrad=False, **kwargs):\n        self.initial_decay = kwargs.pop(\'decay\', 0.0)\n        self.epsilon = kwargs.pop(\'epsilon\', K.epsilon())\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        super(Adam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.beta_1 = K.variable(beta_1, name=\'beta_1\')\n            self.beta_2 = K.variable(beta_2, name=\'beta_2\')\n            self.decay = K.variable(self.initial_decay, name=\'decay\')\n        self.amsgrad = amsgrad\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.learning_rate\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p),\n              dtype=K.dtype(p),\n              name=\'m_\' + str(i))\n              for (i, p) in enumerate(params)]\n        vs = [K.zeros(K.int_shape(p),\n              dtype=K.dtype(p),\n              name=\'v_\' + str(i))\n              for (i, p) in enumerate(params)]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p),\n                     dtype=K.dtype(p),\n                     name=\'vhat_\' + str(i))\n                     for (i, p) in enumerate(params)]\n        else:\n            vhats = [K.zeros(1, name=\'vhat_\' + str(i))\n                     for i in range(len(params))]\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'beta_1\': float(K.get_value(self.beta_1)),\n                  \'beta_2\': float(K.get_value(self.beta_2)),\n                  \'decay\': float(K.get_value(self.decay)),\n                  \'epsilon\': self.epsilon,\n                  \'amsgrad\': self.amsgrad}\n        base_config = super(Adam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Adamax(Optimizer):\n    """"""Adamax optimizer from Adam paper\'s Section 7.\n\n    It is a variant of Adam based on the infinity norm.\n    Default parameters follow those provided in the paper.\n\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n\n    # References\n        - [Adam - A Method for Stochastic Optimization](\n           https://arxiv.org/abs/1412.6980v8)\n    """"""\n\n    def __init__(self, learning_rate=0.002, beta_1=0.9, beta_2=0.999, **kwargs):\n        self.initial_decay = kwargs.pop(\'decay\', 0.0)\n        self.epsilon = kwargs.pop(\'epsilon\', K.epsilon())\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        super(Adamax, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.beta_1 = K.variable(beta_1, name=\'beta_1\')\n            self.beta_2 = K.variable(beta_2, name=\'beta_2\')\n            self.decay = K.variable(self.initial_decay, name=\'decay\')\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.learning_rate\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr / (1. - K.pow(self.beta_1, t))\n\n        shapes = [K.int_shape(p) for p in params]\n        # zero init of 1st moment\n        ms = [K.zeros(shape, name=\'m_\' + str(i))\n              for (i, shape) in enumerate(shapes)]\n        # zero init of exponentially weighted infinity norm\n        us = [K.zeros(shape, name=\'u_\' + str(i))\n              for (i, shape) in enumerate(shapes)]\n        self.weights = [self.iterations] + ms + us\n\n        for p, g, m, u in zip(params, grads, ms, us):\n\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            u_t = K.maximum(self.beta_2 * u, K.abs(g))\n            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(u, u_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'beta_1\': float(K.get_value(self.beta_1)),\n                  \'beta_2\': float(K.get_value(self.beta_2)),\n                  \'decay\': float(K.get_value(self.decay)),\n                  \'epsilon\': self.epsilon}\n        base_config = super(Adamax, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Nadam(Optimizer):\n    """"""Nesterov Adam optimizer.\n\n    Much like Adam is essentially RMSprop with momentum,\n    Nadam is RMSprop with Nesterov momentum.\n\n    Default parameters follow those provided in the paper.\n    It is recommended to leave the parameters of this optimizer\n    at their default values.\n\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n\n    # References\n        - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n        - [On the importance of initialization and momentum in deep learning](\n           http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)\n    """"""\n\n    def __init__(self, learning_rate=0.002, beta_1=0.9, beta_2=0.999, **kwargs):\n        self.schedule_decay = kwargs.pop(\'schedule_decay\', 0.004)\n        self.epsilon = kwargs.pop(\'epsilon\', K.epsilon())\n        learning_rate = kwargs.pop(\'lr\', learning_rate)\n        super(Nadam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n            self.m_schedule = K.variable(1., name=\'m_schedule\')\n            self.learning_rate = K.variable(learning_rate, name=\'learning_rate\')\n            self.beta_1 = K.variable(beta_1, name=\'beta_1\')\n            self.beta_2 = K.variable(beta_2, name=\'beta_2\')\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        # Due to the recommendations in [2], i.e. warming momentum schedule\n        momentum_cache_t = self.beta_1 * (1. - 0.5 * (\n            K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))\n        momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (\n            K.pow(K.cast_to_floatx(0.96), (t + 1) * self.schedule_decay)))\n        m_schedule_new = self.m_schedule * momentum_cache_t\n        m_schedule_next = self.m_schedule * momentum_cache_t * momentum_cache_t_1\n        self.updates.append((self.m_schedule, m_schedule_new))\n\n        shapes = [K.int_shape(p) for p in params]\n        ms = [K.zeros(shape, name=\'m_\' + str(i))\n              for (i, shape) in enumerate(shapes)]\n        vs = [K.zeros(shape, name=\'v_\' + str(i))\n              for (i, shape) in enumerate(shapes)]\n\n        self.weights = [self.iterations, self.m_schedule] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            # the following equations given in [1]\n            g_prime = g / (1. - m_schedule_new)\n            m_t = self.beta_1 * m + (1. - self.beta_1) * g\n            m_t_prime = m_t / (1. - m_schedule_next)\n            v_t = self.beta_2 * v + (1. - self.beta_2) * K.square(g)\n            v_t_prime = v_t / (1. - K.pow(self.beta_2, t))\n            m_t_bar = (1. - momentum_cache_t) * g_prime + (\n                momentum_cache_t_1 * m_t_prime)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n\n            p_t = (p - self.learning_rate * m_t_bar / (K.sqrt(v_t_prime) +\n                   self.epsilon))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, \'constraint\', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def set_weights(self, weights):\n        params = self.weights\n        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n        # since it does not include m_schedule at head of the weight list. Set\n        # m_schedule to 1.\n        if len(params) == len(weights) + 1:\n            weights = [weights[0]] + [np.array(1.)] + weights[1:]\n        super(Nadam, self).set_weights(weights)\n\n    def get_config(self):\n        config = {\'learning_rate\': float(K.get_value(self.learning_rate)),\n                  \'beta_1\': float(K.get_value(self.beta_1)),\n                  \'beta_2\': float(K.get_value(self.beta_2)),\n                  \'epsilon\': self.epsilon,\n                  \'schedule_decay\': self.schedule_decay}\n        base_config = super(Nadam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass TFOptimizer(Optimizer):\n    """"""Wrapper class for native TensorFlow optimizers.\n\n    # Arguments\n        optimizer: Selected optimizer\n    """"""\n\n    def __init__(self, optimizer):\n        self.optimizer = optimizer\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype=\'int64\', name=\'iterations\')\n\n    @interfaces.legacy_get_updates_support\n    @K.symbolic\n    def get_updates(self, loss, params):\n        if isinstance(self.optimizer, tf.keras.optimizers.Optimizer):\n            return self.optimizer.get_updates(loss, params)\n        else:\n            grads = self.optimizer.compute_gradients(loss, var_list=params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        opt_update = self.optimizer.apply_gradients(\n            grads, global_step=self.iterations)\n        self.updates.append(opt_update)\n        return self.updates\n\n    @property\n    def weights(self):\n        if isinstance(self.optimizer, tf.keras.optimizers.Optimizer):\n            return self.optimizer.weights\n        raise NotImplementedError\n\n    def get_config(self):\n        if isinstance(self.optimizer, tf.keras.optimizers.Optimizer):\n            return self.optimizer.get_config\n        raise NotImplementedError\n\n    @classmethod\n    def from_config(cls, config):\n        if tf.__version__.startswith(\'1.\'):\n            raise NotImplementedError\n        return cls(**config)\n\n\n# Aliases.\n\nsgd = SGD\nrmsprop = RMSprop\nadagrad = Adagrad\nadadelta = Adadelta\nadam = Adam\nadamax = Adamax\nnadam = Nadam\n\n\ndef serialize(optimizer):\n    return serialize_keras_object(optimizer)\n\n\ndef deserialize(config, custom_objects=None):\n    """"""Inverse of the `serialize` function.\n\n    # Arguments\n        config: Optimizer configuration dictionary.\n        custom_objects: Optional dictionary mapping\n            names (strings) to custom objects\n            (classes and functions)\n            to be considered during deserialization.\n\n    # Returns\n        A Keras Optimizer instance.\n    """"""\n    all_classes = {\n        \'sgd\': SGD,\n        \'rmsprop\': RMSprop,\n        \'adagrad\': Adagrad,\n        \'adadelta\': Adadelta,\n        \'adam\': Adam,\n        \'adamax\': Adamax,\n        \'nadam\': Nadam,\n        \'tfoptimizer\': TFOptimizer,\n    }\n    # Make deserialization case-insensitive for built-in optimizers.\n    if config[\'class_name\'].lower() in all_classes:\n        config[\'class_name\'] = config[\'class_name\'].lower()\n    return deserialize_keras_object(config,\n                                    module_objects=all_classes,\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'optimizer\')\n\n\ndef get(identifier):\n    """"""Retrieves a Keras Optimizer instance.\n\n    # Arguments\n        identifier: Optimizer identifier, one of\n            - String: name of an optimizer\n            - Dictionary: configuration dictionary.\n            - Keras Optimizer instance (it will be returned unchanged).\n            - TensorFlow Optimizer instance\n                (it will be wrapped as a Keras Optimizer).\n\n    # Returns\n        A Keras Optimizer instance.\n\n    # Raises\n        ValueError: If `identifier` cannot be interpreted.\n    """"""\n    if K.backend() == \'tensorflow\':\n        # Wrap TF optimizer instances\n        if tf.__version__.startswith(\'1.\'):\n            try:\n                TFOpt = tf.compat.v1.train.Optimizer\n            except AttributeError:\n                TFOpt = tf.train.Optimizer\n            if isinstance(identifier, TFOpt):\n                return TFOptimizer(identifier)\n        elif isinstance(identifier, tf.keras.optimizers.Optimizer):\n            return TFOptimizer(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {\'class_name\': str(identifier), \'config\': {}}\n        return deserialize(config)\n    if isinstance(identifier, Optimizer):\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret optimizer identifier: \' +\n                         str(identifier))\n'"
keras/regularizers.py,0,"b'""""""Built-in regularizers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nfrom . import backend as K\nfrom .utils.generic_utils import serialize_keras_object\nfrom .utils.generic_utils import deserialize_keras_object\n\n\nclass Regularizer(object):\n    """"""Regularizer base class.\n    """"""\n\n    def __call__(self, x):\n        return 0.\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n\nclass L1L2(Regularizer):\n    """"""Regularizer for L1 and L2 regularization.\n\n    # Arguments\n        l1: Float; L1 regularization factor.\n        l2: Float; L2 regularization factor.\n    """"""\n\n    def __init__(self, l1=0., l2=0.):\n        self.l1 = K.cast_to_floatx(l1)\n        self.l2 = K.cast_to_floatx(l2)\n\n    def __call__(self, x):\n        regularization = 0.\n        if self.l1:\n            regularization += self.l1 * K.sum(K.abs(x))\n        if self.l2:\n            regularization += self.l2 * K.sum(K.square(x))\n        return regularization\n\n    def get_config(self):\n        return {\'l1\': float(self.l1),\n                \'l2\': float(self.l2)}\n\n\n# Aliases.\n\n\ndef l1(l=0.01):\n    return L1L2(l1=l)\n\n\ndef l2(l=0.01):\n    return L1L2(l2=l)\n\n\ndef l1_l2(l1=0.01, l2=0.01):\n    return L1L2(l1=l1, l2=l2)\n\n\ndef serialize(regularizer):\n    return serialize_keras_object(regularizer)\n\n\ndef deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'regularizer\')\n\n\ndef get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {\'class_name\': str(identifier), \'config\': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError(\'Could not interpret regularizer identifier: \' +\n                         str(identifier))\n'"
tests/conftest.py,0,"b'import pytest\r\nfrom keras import backend as K\r\n\r\n\r\n@pytest.fixture(autouse=True)\r\ndef clear_session_after_test():\r\n    """"""Test wrapper to clean up after TensorFlow and CNTK tests.\r\n\r\n    This wrapper runs for all the tests in the keras test suite.\r\n    """"""\r\n    yield\r\n    if K.backend() == \'tensorflow\' or K.backend() == \'cntk\':\r\n        K.clear_session()\r\n'"
tests/test_api.py,0,"b""import pytest\nimport pyux\nimport keras\nimport json\nimport os\n\nimport keras.backend.tensorflow_backend\nimport keras.backend.theano_backend\nimport keras.backend.cntk_backend\nimport keras.backend.numpy_backend\nimport keras.utils.test_utils\n\n\ndef test_api():\n    api_file = os.path.join(os.getcwd(), 'api.json')\n    with open(api_file, 'r') as f:\n        previous_api = json.load(f)\n    current_api = pyux.sign(keras)\n    diff = pyux.diff(current_api, previous_api)\n\n    exceptions = [\n        pyux.ADDED_ARG_WITH_DEFAULT_IN_METHOD,\n        pyux.ADDED_DEFAULT_IN_METHOD\n    ]\n\n    diff = list(filter(lambda c: c[0] not in exceptions, diff))\n    if diff:\n        raise pyux.APIChangedException(diff)\n\n\nif __name__ == '__main__':\n    test_api()\n"""
tests/test_dynamic_trainability.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\nimport pytest\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Input\n\n\ndef test_layer_trainability_switch():\n    # with constructor argument, in Sequential\n    model = Sequential()\n    model.add(Dense(2, trainable=False, input_dim=1))\n    assert model.trainable_weights == []\n\n    # by setting the `trainable` argument, in Sequential\n    model = Sequential()\n    layer = Dense(2, input_dim=1)\n    model.add(layer)\n    assert model.trainable_weights == layer.trainable_weights\n    layer.trainable = False\n    assert model.trainable_weights == []\n\n    # with constructor argument, in Model\n    x = Input(shape=(1,))\n    y = Dense(2, trainable=False)(x)\n    model = Model(x, y)\n    assert model.trainable_weights == []\n\n    # by setting the `trainable` argument, in Model\n    x = Input(shape=(1,))\n    layer = Dense(2)\n    y = layer(x)\n    model = Model(x, y)\n    assert model.trainable_weights == layer.trainable_weights\n    layer.trainable = False\n    assert model.trainable_weights == []\n\n\ndef test_model_trainability_switch():\n    # a non-trainable model has no trainable weights\n    x = Input(shape=(1,))\n    y = Dense(2)(x)\n    model = Model(x, y)\n    model.trainable = False\n    assert model.trainable_weights == []\n\n    # same for Sequential\n    model = Sequential()\n    model.add(Dense(2, input_dim=1))\n    model.trainable = False\n    assert model.trainable_weights == []\n\n\ndef test_nested_model_trainability():\n    # a Sequential inside a Model\n    inner_model = Sequential()\n    inner_model.add(Dense(2, input_dim=1))\n\n    x = Input(shape=(1,))\n    y = inner_model(x)\n    outer_model = Model(x, y)\n    assert outer_model.trainable_weights == inner_model.trainable_weights\n    inner_model.trainable = False\n    assert outer_model.trainable_weights == []\n    inner_model.trainable = True\n    inner_model.layers[-1].trainable = False\n    assert outer_model.trainable_weights == []\n\n    # a Sequential inside a Sequential\n    inner_model = Sequential()\n    inner_model.add(Dense(2, input_dim=1))\n    outer_model = Sequential()\n    outer_model.add(inner_model)\n    assert outer_model.trainable_weights == inner_model.trainable_weights\n    inner_model.trainable = False\n    assert outer_model.trainable_weights == []\n    inner_model.trainable = True\n    inner_model.layers[-1].trainable = False\n    assert outer_model.trainable_weights == []\n\n    # a Model inside a Model\n    x = Input(shape=(1,))\n    y = Dense(2)(x)\n    inner_model = Model(x, y)\n    x = Input(shape=(1,))\n    y = inner_model(x)\n    outer_model = Model(x, y)\n    assert outer_model.trainable_weights == inner_model.trainable_weights\n    inner_model.trainable = False\n    assert outer_model.trainable_weights == []\n    inner_model.trainable = True\n    inner_model.layers[-1].trainable = False\n    assert outer_model.trainable_weights == []\n\n    # a Model inside a Sequential\n    x = Input(shape=(1,))\n    y = Dense(2)(x)\n    inner_model = Model(x, y)\n    outer_model = Sequential()\n    outer_model.add(inner_model)\n    assert outer_model.trainable_weights == inner_model.trainable_weights\n    inner_model.trainable = False\n    assert outer_model.trainable_weights == []\n    inner_model.trainable = True\n    inner_model.layers[-1].trainable = False\n    assert outer_model.trainable_weights == []\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/test_loss_masking.py,0,"b""import numpy as np\nimport pytest\n\nfrom keras.models import Sequential\nfrom keras.engine.training_utils import weighted_masked_objective\nfrom keras.layers import TimeDistributed, Masking, Dense\nfrom keras import losses\nfrom keras import backend as K\n\n\ndef create_masking_model():\n    model = Sequential()\n    model.add(Masking(mask_value=0, input_shape=(None, 1)))\n    model.add(TimeDistributed(Dense(1, kernel_initializer='one')))\n    model.compile(loss='mse', optimizer='sgd')\n    return model\n\n\ndef test_masking():\n    np.random.seed(1337)\n    x = np.array([[[1], [1]],\n                  [[0], [0]]])\n    model = create_masking_model()\n    y = np.array([[[1], [1]],\n                  [[1], [1]]])\n    loss = model.train_on_batch(x, y)\n    assert loss == 0\n\n\ndef test_masking_is_all_zeros():\n    x = y = np.array([[[0], [0]]])\n    model = create_masking_model()\n    loss = model.train_on_batch(x, y)\n    assert loss == 0\n\n\ndef test_loss_masking():\n    weighted_loss = weighted_masked_objective(losses.get('mae'))\n    shape = (3, 4, 2)\n    x = np.arange(24).reshape(shape)\n    y = 2 * x\n\n    # Normally the trailing 1 is added by standardize_weights\n    weights = np.ones((3,))\n    mask = np.ones((3, 4))\n    mask[1, 0] = 0\n\n    out = K.eval(weighted_loss(K.variable(x),\n                               K.variable(y),\n                               K.variable(weights),\n                               K.variable(mask)))\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/test_loss_weighting.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\nimport pytest\nimport numpy as np\n\nfrom keras import backend as K\nfrom keras.utils.test_utils import get_test_data\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Activation, GRU, TimeDistributed, Input\nfrom keras.utils import np_utils\nfrom numpy.testing import assert_almost_equal, assert_array_almost_equal\n\nnum_classes = 10\nbatch_size = 128\nepochs = 15\nweighted_class = 5\nhigh_weight = 10\ntrain_samples = 5000\ntest_samples = 1000\ntimesteps = 3\ninput_dim = 10\nloss = 'mse'\nstandard_weight = 1\nstandard_score_sequential = 0.5\n\ndecimal_precision = {\n    'cntk': 2,\n    'theano': 6,\n    'tensorflow': 6\n}\n\n\ndef _get_test_data():\n    np.random.seed(1337)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    int_y_test = y_test.copy()\n    int_y_train = y_train.copy()\n    # convert class vectors to binary class matrices\n    y_train = np_utils.to_categorical(y_train, num_classes)\n    y_test = np_utils.to_categorical(y_test, num_classes)\n    test_ids = np.where(int_y_test == np.array(weighted_class))[0]\n\n    class_weight = dict([(i, standard_weight) for i in range(num_classes)])\n    class_weight[weighted_class] = high_weight\n\n    sample_weight = np.ones((y_train.shape[0])) * standard_weight\n    sample_weight[int_y_train == weighted_class] = high_weight\n\n    return ((x_train, y_train), (x_test, y_test),\n            (sample_weight, class_weight, test_ids))\n\n\ndef create_sequential_model():\n    model = Sequential()\n    model.add(Dense(32, input_shape=(input_dim,)))\n    model.add(Activation('relu'))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    return model\n\n\ndef create_temporal_sequential_model():\n    model = Sequential()\n    model.add(GRU(32, input_shape=(timesteps, input_dim), return_sequences=True))\n    model.add(TimeDistributed(Dense(num_classes)))\n    model.add(Activation('softmax'))\n    return model\n\n\ndef test_sequential_class_weights():\n    model = create_sequential_model()\n    model.compile(loss=loss, optimizer='rmsprop')\n\n    ((x_train, y_train), (x_test, y_test),\n     (sample_weight, class_weight, test_ids)) = _get_test_data()\n\n    model.fit(x_train, y_train, batch_size=batch_size,\n              epochs=epochs // 3, verbose=0,\n              class_weight=class_weight,\n              validation_data=(x_train, y_train, sample_weight))\n    model.fit(x_train, y_train, batch_size=batch_size,\n              epochs=epochs // 2, verbose=0,\n              class_weight=class_weight)\n    model.fit(x_train, y_train, batch_size=batch_size,\n              epochs=epochs // 2, verbose=0,\n              class_weight=class_weight,\n              validation_split=0.1)\n\n    model.train_on_batch(x_train[:32], y_train[:32],\n                         class_weight=class_weight)\n    score = model.evaluate(x_test[test_ids, :], y_test[test_ids, :], verbose=0)\n    assert(score < standard_score_sequential)\n\n\ndef test_sequential_sample_weights():\n    model = create_sequential_model()\n    model.compile(loss=loss, optimizer='rmsprop')\n\n    ((x_train, y_train), (x_test, y_test),\n     (sample_weight, class_weight, test_ids)) = _get_test_data()\n\n    model.fit(x_train, y_train, batch_size=batch_size,\n              epochs=epochs // 3, verbose=0,\n              sample_weight=sample_weight)\n    model.fit(x_train, y_train, batch_size=batch_size,\n              epochs=epochs // 3, verbose=0,\n              sample_weight=sample_weight,\n              validation_split=0.1)\n\n    model.train_on_batch(x_train[:32], y_train[:32],\n                         sample_weight=sample_weight[:32])\n    model.test_on_batch(x_train[:32], y_train[:32],\n                        sample_weight=sample_weight[:32])\n    score = model.evaluate(x_test[test_ids, :], y_test[test_ids, :], verbose=0)\n    assert(score < standard_score_sequential)\n\n\ndef test_sequential_temporal_sample_weights():\n    ((x_train, y_train), (x_test, y_test),\n     (sample_weight, class_weight, test_ids)) = _get_test_data()\n\n    temporal_x_train = np.reshape(x_train, (len(x_train), 1, x_train.shape[1]))\n    temporal_x_train = np.repeat(temporal_x_train, timesteps, axis=1)\n    temporal_x_test = np.reshape(x_test, (len(x_test), 1, x_test.shape[1]))\n    temporal_x_test = np.repeat(temporal_x_test, timesteps, axis=1)\n\n    temporal_y_train = np.reshape(y_train, (len(y_train), 1, y_train.shape[1]))\n    temporal_y_train = np.repeat(temporal_y_train, timesteps, axis=1)\n    temporal_y_test = np.reshape(y_test, (len(y_test), 1, y_test.shape[1]))\n    temporal_y_test = np.repeat(temporal_y_test, timesteps, axis=1)\n\n    temporal_sample_weight = np.reshape(sample_weight, (len(sample_weight), 1))\n    temporal_sample_weight = np.repeat(temporal_sample_weight, timesteps, axis=1)\n\n    model = create_temporal_sequential_model()\n    model.compile(loss=loss, optimizer='rmsprop',\n                  sample_weight_mode='temporal')\n\n    model.fit(temporal_x_train, temporal_y_train, batch_size=batch_size,\n              epochs=epochs // 3, verbose=0,\n              sample_weight=temporal_sample_weight)\n    model.fit(temporal_x_train, temporal_y_train, batch_size=batch_size,\n              epochs=epochs // 3, verbose=0,\n              sample_weight=temporal_sample_weight,\n              validation_split=0.1)\n\n    model.train_on_batch(temporal_x_train[:32], temporal_y_train[:32],\n                         sample_weight=temporal_sample_weight[:32])\n    model.test_on_batch(temporal_x_train[:32], temporal_y_train[:32],\n                        sample_weight=temporal_sample_weight[:32])\n    score = model.evaluate(temporal_x_test[test_ids], temporal_y_test[test_ids],\n                           verbose=0)\n    assert(score < standard_score_sequential)\n\n\ndef test_class_weight_wrong_classes():\n    model = create_sequential_model()\n    model.compile(loss=loss, optimizer='rmsprop')\n\n    ((x_train, y_train), (x_test, y_test),\n     (sample_weight, class_weight, test_ids)) = _get_test_data()\n\n    del class_weight[1]\n    with pytest.raises(ValueError):\n        model.fit(x_train, y_train,\n                  epochs=0, verbose=0, class_weight=class_weight)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/test_model_pickling.py,0,"b'import pytest\nimport sys\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nimport keras\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import losses\nfrom keras import metrics\n\nif sys.version_info[0] == 3:\n    import pickle\nelse:\n    import cPickle as pickle\n\n\ndef test_sequential_model_pickling():\n    model = keras.Sequential()\n    model.add(layers.Dense(2, input_shape=(3,)))\n    model.add(layers.RepeatVector(3))\n    model.add(layers.TimeDistributed(layers.Dense(3)))\n    model.compile(loss=losses.MSE,\n                  optimizer=optimizers.RMSprop(lr=0.0001),\n                  metrics=[metrics.categorical_accuracy],\n                  sample_weight_mode=\'temporal\')\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n\n    state = pickle.dumps(model)\n\n    new_model = pickle.loads(state)\n\n    out2 = new_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n    # test that new updates are the same with both models\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3, 3))\n    model.train_on_batch(x, y)\n    new_model.train_on_batch(x, y)\n    out = model.predict(x)\n    out2 = new_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_sequential_model_pickling_custom_objects():\n    # test with custom optimizer, loss\n    class CustomSGD(optimizers.SGD):\n        pass\n\n    def custom_mse(*args, **kwargs):\n        return losses.mse(*args, **kwargs)\n\n    model = keras.Sequential()\n    model.add(layers.Dense(2, input_shape=(3,)))\n    model.add(layers.Dense(3))\n    model.compile(loss=custom_mse, optimizer=CustomSGD(), metrics=[\'acc\'])\n\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n\n    state = pickle.dumps(model)\n\n    with keras.utils.CustomObjectScope(\n            {\'CustomSGD\': CustomSGD, \'custom_mse\': custom_mse}):\n        model = pickle.loads(state)\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_functional_model_pickling():\n    inputs = keras.Input(shape=(3,))\n    x = layers.Dense(2)(inputs)\n    outputs = layers.Dense(3)(x)\n\n    model = keras.Model(inputs, outputs)\n    model.compile(loss=losses.MSE,\n                  optimizer=optimizers.Adam(),\n                  metrics=[metrics.categorical_accuracy])\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n    state = pickle.dumps(model)\n\n    model = pickle.loads(state)\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_pickling_multiple_metrics_outputs():\n    inputs = keras.Input(shape=(5,))\n    x = layers.Dense(5)(inputs)\n    output1 = layers.Dense(1, name=\'output1\')(x)\n    output2 = layers.Dense(1, name=\'output2\')(x)\n\n    model = keras.Model(inputs=inputs, outputs=[output1, output2])\n\n    metrics = {\'output1\': [\'mse\', \'binary_accuracy\'],\n               \'output2\': [\'mse\', \'binary_accuracy\']\n               }\n    loss = {\'output1\': \'mse\', \'output2\': \'mse\'}\n\n    model.compile(loss=loss, optimizer=\'sgd\', metrics=metrics)\n\n    # assure that model is working\n    x = np.array([[1, 1, 1, 1, 1]])\n    out = model.predict(x)\n\n    model = pickle.loads(pickle.dumps(model))\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_pickling_without_compilation():\n    """"""Test pickling model without compiling.\n    """"""\n    model = keras.Sequential()\n    model.add(layers.Dense(2, input_shape=(3,)))\n    model.add(layers.Dense(3))\n\n    model = pickle.loads(pickle.dumps(model))\n\n\ndef test_pickling_right_after_compilation():\n    model = keras.Sequential()\n    model.add(layers.Dense(2, input_shape=(3,)))\n    model.add(layers.Dense(3))\n    model.compile(loss=\'mse\', optimizer=\'sgd\', metrics=[\'acc\'])\n    model._make_train_function()\n\n    model = pickle.loads(pickle.dumps(model))\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/test_model_saving.py,0,"b'import io\nimport pytest\nimport os\nimport h5py\nimport tempfile\nimport warnings\nfrom contextlib import contextmanager\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\n\nfrom keras import backend as K\nfrom keras.engine.saving import preprocess_weights_for_loading\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Lambda, RepeatVector, TimeDistributed\nfrom keras.layers import Bidirectional, GRU, LSTM, CuDNNGRU, CuDNNLSTM\nfrom keras.layers import Conv2D, Flatten, Activation\nfrom keras.layers import Input, InputLayer\nfrom keras.initializers import Constant\nfrom keras import optimizers\nfrom keras import losses\nfrom keras import metrics\nfrom keras.models import save_model, load_model\nfrom keras.utils.test_utils import tf_file_io_proxy\ntry:\n    from unittest.mock import patch\nexcept:\n    from mock import patch\n\n\nskipif_no_tf_gpu = pytest.mark.skipif(\n    (K.backend() != \'tensorflow\' or\n     not K.tensorflow_backend._get_available_gpus()),\n    reason=\'Requires TensorFlow backend and a GPU\')\n\n\ndef test_sequential_model_saving():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    model.add(RepeatVector(3))\n    model.add(TimeDistributed(Dense(3)))\n    model.compile(loss=losses.MeanSquaredError(),\n                  optimizer=optimizers.RMSprop(lr=0.0001),\n                  metrics=[metrics.categorical_accuracy],\n                  sample_weight_mode=\'temporal\')\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    new_model_disk = load_model(fname)\n    os.remove(fname)\n\n    with tf_file_io_proxy(\'keras.engine.saving.tf_file_io\') as file_io_proxy:\n        gcs_filepath = file_io_proxy.get_filepath(filename=fname)\n        save_model(model, gcs_filepath)\n        file_io_proxy.assert_exists(gcs_filepath)\n        new_model_gcs = load_model(gcs_filepath)\n        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n\n    x2 = np.random.random((1, 3))\n    y2 = np.random.random((1, 3, 3))\n    model.train_on_batch(x2, y2)\n    out_2 = model.predict(x2)\n\n    for new_model in [new_model_disk, new_model_gcs]:\n        new_out = new_model.predict(x)\n        assert_allclose(out, new_out, atol=1e-05)\n        # test that new updates are the same with both models\n        new_model.train_on_batch(x2, y2)\n        new_out_2 = new_model.predict(x2)\n        assert_allclose(out_2, new_out_2, atol=1e-05)\n\n\ndef test_sequential_model_saving_2():\n    # test with custom optimizer, loss\n    custom_opt = optimizers.rmsprop\n    custom_loss = losses.mse\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    model.add(Dense(3))\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n    out = model.predict(x)\n\n    load_kwargs = {\'custom_objects\': {\'custom_opt\': custom_opt,\n                                      \'custom_loss\': custom_loss}}\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    new_model_disk = load_model(fname, **load_kwargs)\n    os.remove(fname)\n\n    with tf_file_io_proxy(\'keras.engine.saving.tf_file_io\') as file_io_proxy:\n        gcs_filepath = file_io_proxy.get_filepath(filename=fname)\n        save_model(model, gcs_filepath)\n        file_io_proxy.assert_exists(gcs_filepath)\n        new_model_gcs = load_model(gcs_filepath, **load_kwargs)\n        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n\n    for new_model in [new_model_disk, new_model_gcs]:\n        new_out = new_model.predict(x)\n        assert_allclose(out, new_out, atol=1e-05)\n\n\ndef _get_sample_model_and_input():\n    inputs = Input(shape=(3,))\n    x = Dense(2)(inputs)\n    outputs = Dense(3)(x)\n\n    model = Model(inputs, outputs)\n    model.compile(loss=losses.MSE,\n                  optimizer=optimizers.Adam(),\n                  metrics=[metrics.categorical_accuracy])\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    return model, x\n\n\ndef test_functional_model_saving():\n    model, x = _get_sample_model_and_input()\n    out = model.predict(x)\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    new_model_disk = load_model(fname)\n    os.remove(fname)\n\n    with tf_file_io_proxy(\'keras.engine.saving.tf_file_io\') as file_io_proxy:\n        gcs_filepath = file_io_proxy.get_filepath(filename=fname)\n        save_model(model, gcs_filepath)\n        file_io_proxy.assert_exists(gcs_filepath)\n        new_model_gcs = load_model(gcs_filepath)\n        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n\n    for new_model in [new_model_disk, new_model_gcs]:\n        new_out = new_model.predict(x)\n        assert_allclose(out, new_out, atol=1e-05)\n\n\ndef test_model_saving_to_pre_created_h5py_file():\n    model, x = _get_sample_model_and_input()\n\n    out = model.predict(x)\n    _, fname = tempfile.mkstemp(\'.h5\')\n    with h5py.File(fname, mode=\'r+\') as h5file:\n        save_model(model, h5file)\n        loaded_model = load_model(h5file)\n        out2 = loaded_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n    # test non-default options in h5\n    with h5py.File(\'does not matter\', driver=\'core\',\n                   backing_store=False) as h5file:\n        save_model(model, h5file)\n        loaded_model = load_model(h5file)\n        out2 = loaded_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n    with h5py.File(fname, mode=\'r+\') as h5file:\n        g = h5file.create_group(\'model\')\n        save_model(model, g)\n        loaded_model = load_model(g)\n        out2 = loaded_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\n@contextmanager\ndef temp_filename(filename):\n    """"""Context that returns a temporary filename and deletes the file on exit if\n    it still exists (so that this is not forgotten).\n    """"""\n    _, temp_fname = tempfile.mkstemp(filename)\n    yield temp_fname\n    if os.path.exists(temp_fname):\n        os.remove(temp_fname)\n\n\ndef test_model_saving_to_binary_stream():\n    model, x = _get_sample_model_and_input()\n    out = model.predict(x)\n\n    with temp_filename(\'h5\') as fname:\n        # save directly to binary file\n        with open(fname, \'wb\') as raw_file:\n            save_model(model, raw_file)\n        # Load the data the usual way, and make sure the model is intact.\n        with h5py.File(fname, mode=\'r\') as h5file:\n            loaded_model = load_model(h5file)\n    out2 = loaded_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_model_loading_from_binary_stream():\n    model, x = _get_sample_model_and_input()\n    out = model.predict(x)\n\n    with temp_filename(\'h5\') as fname:\n        # save the model the usual way\n        with h5py.File(fname, mode=\'w\') as h5file:\n            save_model(model, h5file)\n        # Load the data binary, and make sure the model is intact.\n        with open(fname, \'rb\') as raw_file:\n            loaded_model = load_model(raw_file)\n    out2 = loaded_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_model_save_load_binary_in_memory():\n    model, x = _get_sample_model_and_input()\n    out = model.predict(x)\n\n    stream = io.BytesIO()\n    save_model(model, stream)\n    stream.seek(0)\n    loaded_model = load_model(stream)\n    out2 = loaded_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_multiple_metrics_outputs():\n    inputs = Input(shape=(5,))\n    x = Dense(5)(inputs)\n    output1 = Dense(1, name=\'output1\')(x)\n    output2 = Dense(1, name=\'output2\')(x)\n\n    model = Model(inputs=inputs, outputs=[output1, output2])\n\n    metrics = {\'output1\': [\'mse\', \'binary_accuracy\'],\n               \'output2\': [\'mse\', \'binary_accuracy\']\n               }\n    loss = {\'output1\': \'mse\', \'output2\': \'mse\'}\n\n    model.compile(loss=loss, optimizer=\'sgd\', metrics=metrics)\n\n    # assure that model is working\n    x = np.array([[1, 1, 1, 1, 1]])\n    out = model.predict(x)\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n\n    model = load_model(fname)\n    os.remove(fname)\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_without_compilation():\n    """"""Test saving model without compiling.\n    """"""\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    model.add(Dense(3))\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    model = load_model(fname)\n    os.remove(fname)\n\n\ndef test_saving_right_after_compilation():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    model.add(Dense(3))\n    model.compile(loss=\'mse\', optimizer=\'sgd\', metrics=[\'acc\'])\n    model._make_train_function()\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    model = load_model(fname)\n    os.remove(fname)\n\n\ndef test_saving_unused_layers_is_ok():\n    a = Input(shape=(256, 512, 6))\n    b = Input(shape=(256, 512, 1))\n    c = Lambda(lambda x: x[:, :, :, :1])(a)\n\n    model = Model(inputs=[a, b], outputs=c)\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    load_model(fname)\n    os.remove(fname)\n\n\ndef test_loading_weights_by_name_and_reshape():\n    """"""\n    test loading model weights by name on:\n        - sequential model\n    """"""\n\n    # test with custom optimizer, loss\n    custom_opt = optimizers.rmsprop\n    custom_loss = losses.mse\n\n    # sequential model\n    model = Sequential()\n    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), name=\'rick\'))\n    model.add(Flatten())\n    model.add(Dense(3, name=\'morty\'))\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    x = np.random.random((1, 1, 1, 1))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n    old_weights = [layer.get_weights() for layer in model.layers]\n    _, fname = tempfile.mkstemp(\'.h5\')\n\n    model.save_weights(fname)\n\n    # delete and recreate model\n    del(model)\n    model = Sequential()\n    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), name=\'rick\'))\n    model.add(Conv2D(3, (1, 1), name=\'morty\'))\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    # load weights from first model\n    with pytest.raises(ValueError):\n        model.load_weights(fname, by_name=True, reshape=False)\n    with pytest.raises(ValueError):\n        model.load_weights(fname, by_name=False, reshape=False)\n    model.load_weights(fname, by_name=False, reshape=True)\n    model.load_weights(fname, by_name=True, reshape=True)\n\n    out2 = model.predict(x)\n    assert_allclose(np.squeeze(out), np.squeeze(out2), atol=1e-05)\n    for i in range(len(model.layers)):\n        new_weights = model.layers[i].get_weights()\n        for j in range(len(new_weights)):\n            # only compare layers that have weights, skipping Flatten()\n            if old_weights[i]:\n                assert_allclose(old_weights[i][j], new_weights[j], atol=1e-05)\n\n    # delete and recreate model with `use_bias=False`\n    del(model)\n    model = Sequential()\n    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), use_bias=False, name=\'rick\'))\n    model.add(Flatten())\n    model.add(Dense(3, name=\'morty\'))\n    with pytest.raises(ValueError,\n                       match=r\'.* expects [0-9]+ .* but the saved .* [0-9]+ .*\'):\n        model.load_weights(fname)\n    with pytest.raises(ValueError,\n                       match=r\'.* expects [0-9]+ .* but the saved .* [0-9]+ .*\'):\n        model.load_weights(fname, by_name=True)\n    with pytest.warns(UserWarning,\n                      match=r\'Skipping loading .* due to mismatch .*\'):\n        model.load_weights(fname, by_name=True, skip_mismatch=True)\n\n    # delete and recreate model with `filters=10`\n    del(model)\n    model = Sequential()\n    model.add(Conv2D(10, (1, 1), input_shape=(1, 1, 1), name=\'rick\'))\n    with pytest.raises(ValueError,\n                       match=r\'.* has shape .* but the saved .* shape .*\'):\n        model.load_weights(fname, by_name=True)\n    with pytest.raises(ValueError,\n                       match=r\'.* load .* [0-9]+ layers into .* [0-9]+ layers.\'):\n        model.load_weights(fname)\n\n    os.remove(fname)\n\n\ndef test_loading_weights_by_name_2():\n    """"""\n    test loading model weights by name on:\n        - both sequential and functional api models\n        - different architecture with shared names\n    """"""\n\n    # test with custom optimizer, loss\n    custom_opt = optimizers.rmsprop\n    custom_loss = losses.mse\n\n    # sequential model\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,), name=\'rick\'))\n    model.add(Dense(3, name=\'morty\'))\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n    old_weights = [layer.get_weights() for layer in model.layers]\n    _, fname = tempfile.mkstemp(\'.h5\')\n\n    model.save_weights(fname)\n\n    # delete and recreate model using Functional API\n    del(model)\n    data = Input(shape=(3,))\n    rick = Dense(2, name=\'rick\')(data)\n    jerry = Dense(3, name=\'jerry\')(rick)  # add 2 layers (but maintain shapes)\n    jessica = Dense(2, name=\'jessica\')(jerry)\n    morty = Dense(3, name=\'morty\')(jessica)\n\n    model = Model(inputs=[data], outputs=[morty])\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    # load weights from first model\n    model.load_weights(fname, by_name=True)\n    os.remove(fname)\n\n    out2 = model.predict(x)\n    assert np.max(np.abs(out - out2)) > 1e-05\n\n    rick = model.layers[1].get_weights()\n    jerry = model.layers[2].get_weights()\n    jessica = model.layers[3].get_weights()\n    morty = model.layers[4].get_weights()\n\n    assert_allclose(old_weights[0][0], rick[0], atol=1e-05)\n    assert_allclose(old_weights[0][1], rick[1], atol=1e-05)\n    assert_allclose(old_weights[1][0], morty[0], atol=1e-05)\n    assert_allclose(old_weights[1][1], morty[1], atol=1e-05)\n    assert_allclose(np.zeros_like(jerry[1]), jerry[1])  # biases init to 0\n    assert_allclose(np.zeros_like(jessica[1]), jessica[1])  # biases init to 0\n\n\ndef test_loading_weights_by_name_skip_mismatch():\n    """"""\n    test skipping layers while loading model weights by name on:\n        - sequential model\n    """"""\n\n    # test with custom optimizer, loss\n    custom_opt = optimizers.rmsprop\n    custom_loss = losses.mse\n\n    # sequential model\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,), name=\'rick\'))\n    model.add(Dense(3, name=\'morty\'))\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n    old_weights = [layer.get_weights() for layer in model.layers]\n    _, fname = tempfile.mkstemp(\'.h5\')\n\n    model.save_weights(fname)\n\n    # delete and recreate model\n    del(model)\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,), name=\'rick\'))\n    model.add(Dense(4, name=\'morty\'))  # different shape w.r.t. previous model\n    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=[\'acc\'])\n\n    # load weights from first model\n    with pytest.warns(UserWarning):  # expect UserWarning for skipping weights\n        model.load_weights(fname, by_name=True, skip_mismatch=True)\n    os.remove(fname)\n\n    # assert layers \'rick\' are equal\n    for old, new in zip(old_weights[0], model.layers[0].get_weights()):\n        assert_allclose(old, new, atol=1e-05)\n\n    # assert layers \'morty\' are not equal, since we skipped loading this layer\n    for old, new in zip(old_weights[1], model.layers[1].get_weights()):\n        assert_raises(AssertionError, assert_allclose, old, new, atol=1e-05)\n\n\n# a function to be called from the Lambda layer\ndef square_fn(x):\n    return x * x\n\n\ndef test_saving_lambda_custom_objects():\n    inputs = Input(shape=(3,))\n    x = Lambda(lambda x: square_fn(x), output_shape=(3,))(inputs)\n    outputs = Dense(3)(x)\n\n    model = Model(inputs, outputs)\n    model.compile(loss=losses.MSE,\n                  optimizer=optimizers.RMSprop(lr=0.0001),\n                  metrics=[metrics.categorical_accuracy])\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n\n    model = load_model(fname, custom_objects={\'square_fn\': square_fn})\n    os.remove(fname)\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_lambda_numpy_array_arguments():\n    mean = np.random.random((4, 2, 3))\n    std = np.abs(np.random.random((4, 2, 3))) + 1e-5\n    inputs = Input(shape=(4, 2, 3))\n    outputs = Lambda(lambda image, mu, std: (image - mu) / std,\n                     arguments={\'mu\': mean, \'std\': std})(inputs)\n    model = Model(inputs, outputs)\n    model.compile(loss=\'mse\', optimizer=\'sgd\', metrics=[\'acc\'])\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n\n    model = load_model(fname)\n    os.remove(fname)\n\n    assert_allclose(mean, model.layers[1].arguments[\'mu\'])\n    assert_allclose(std, model.layers[1].arguments[\'std\'])\n\n\ndef test_saving_custom_activation_function():\n    x = Input(shape=(3,))\n    output = Dense(3, activation=K.cos)(x)\n\n    model = Model(x, output)\n    model.compile(loss=losses.MSE,\n                  optimizer=optimizers.RMSprop(lr=0.0001),\n                  metrics=[metrics.categorical_accuracy])\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 3))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n\n    model = load_model(fname, custom_objects={\'cos\': K.cos})\n    os.remove(fname)\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_model_with_long_layer_names():\n    # This layer name will make the `layers_name` HDF5 attribute blow\n    # out of proportion. Note that it fits into the internal HDF5\n    # attribute memory limit on its own but because h5py converts\n    # the list of layer names into numpy array, which uses the same\n    # amout of memory for every item, it increases the memory\n    # requirements substantially.\n    x = Input(shape=(2,), name=\'input_\' + (\'x\' * (2**15)))\n    f = x\n    for i in range(4):\n        f = Dense(2, name=\'dense_%d\' % (i,))(f)\n\n    model = Model(inputs=[x], outputs=[f])\n\n    model.compile(loss=\'mse\', optimizer=\'adam\', metrics=[\'acc\'])\n\n    x = np.random.random((1, 2))\n    y = np.random.random((1, 2))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n\n    model = load_model(fname)\n\n    # Check that the HDF5 files contains chunked array\n    # of layer names.\n    with h5py.File(fname, \'r\') as h5file:\n        n_layer_names_arrays = len([attr for attr in h5file[\'model_weights\'].attrs\n                                    if attr.startswith(\'layer_names\')])\n\n    os.remove(fname)\n\n    # The chunking of layer names array should have happened.\n    assert n_layer_names_arrays > 0\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_model_with_long_weights_names():\n    x = Input(shape=(2,), name=\'nested_model_input\')\n    f = x\n    for i in range(4):\n        f = Dense(2, name=\'nested_model_dense_%d\' % (i,))(f)\n    f = Dense(2, name=\'nested_model_dense_4\', trainable=False)(f)\n    # This layer name will make the `weights_name`\n    # HDF5 attribute blow out of proportion.\n    f = Dense(2, name=\'nested_model_output\' + (\'x\' * (2**15)))(f)\n    nested_model = Model(inputs=[x], outputs=[f], name=\'nested_model\')\n\n    x = Input(shape=(2,), name=\'outer_model_input\')\n    f = nested_model(x)\n    f = Dense(2, name=\'outer_model_output\')(f)\n\n    model = Model(inputs=[x], outputs=[f])\n\n    model.compile(loss=\'mse\', optimizer=\'adam\', metrics=[\'acc\'])\n\n    x = np.random.random((1, 2))\n    y = np.random.random((1, 2))\n    model.train_on_batch(x, y)\n\n    out = model.predict(x)\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n\n    model = load_model(fname)\n\n    # Check that the HDF5 files contains chunked array\n    # of weight names.\n    with h5py.File(fname, \'r\') as h5file:\n        attrs = [attr for attr in h5file[\'model_weights\'][\'nested_model\'].attrs\n                 if attr.startswith(\'weight_names\')]\n        n_weight_names_arrays = len(attrs)\n\n    os.remove(fname)\n\n    # The chunking of layer names array should have happened.\n    assert n_weight_names_arrays > 0\n\n    out2 = model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_recurrent_layer_with_init_state():\n    vector_size = 8\n    input_length = 20\n\n    input_initial_state = Input(shape=(vector_size,))\n    input_x = Input(shape=(input_length, vector_size))\n\n    lstm = LSTM(vector_size, return_sequences=True)(\n        input_x, initial_state=[input_initial_state, input_initial_state])\n\n    model = Model(inputs=[input_x, input_initial_state], outputs=[lstm])\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    model.save(fname)\n\n    loaded_model = load_model(fname)\n    os.remove(fname)\n\n\ndef test_saving_recurrent_layer_without_bias():\n    vector_size = 8\n    input_length = 20\n\n    input_x = Input(shape=(input_length, vector_size))\n    lstm = LSTM(vector_size, use_bias=False)(input_x)\n    model = Model(inputs=[input_x], outputs=[lstm])\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    model.save(fname)\n\n    loaded_model = load_model(fname)\n    os.remove(fname)\n\n\ndef test_loop_model_saving():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    model.compile(loss=losses.MSE,\n                  optimizer=optimizers.RMSprop(lr=0.0001),\n                  metrics=[metrics.categorical_accuracy])\n\n    x = np.random.random((1, 3))\n    y = np.random.random((1, 2))\n    _, fname = tempfile.mkstemp(\'.h5\')\n\n    for _ in range(3):\n        model.train_on_batch(x, y)\n        save_model(model, fname, overwrite=True)\n        out = model.predict(x)\n\n    new_model = load_model(fname)\n    os.remove(fname)\n\n    out2 = new_model.predict(x)\n    assert_allclose(out, out2, atol=1e-05)\n\n\ndef test_saving_constant_initializer_with_numpy():\n    """"""Test saving and loading model of constant initializer with numpy inputs.\n    """"""\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,),\n                    kernel_initializer=Constant(np.ones((3, 2)))))\n    model.add(Dense(3))\n    model.compile(loss=\'mse\', optimizer=\'sgd\', metrics=[\'acc\'])\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    model = load_model(fname)\n    os.remove(fname)\n\n\ndef test_saving_group_naming_h5py(tmpdir):\n    """"""Test saving model with layer which name is prefix to a previous layer\n    name\n    """"""\n\n    input_layer = Input((None, None, 3), name=\'test_input\')\n    x = Conv2D(1, 1, name=\'conv1/conv\')(input_layer)\n    x = Activation(\'relu\', name=\'conv1\')(x)\n\n    model = Model(inputs=input_layer, outputs=x)\n    p = tmpdir.mkdir(""test"").join(""test.h5"")\n    model.save_weights(p)\n    model.load_weights(p)\n\n\ndef test_save_load_weights_gcs():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    org_weights = model.get_weights()\n\n    with tf_file_io_proxy(\'keras.engine.saving.tf_file_io\') as file_io_proxy:\n        gcs_filepath = file_io_proxy.get_filepath(\n            filename=\'test_save_load_weights_gcs.h5\')\n        # we should not use same filename in several tests to allow for parallel\n        # execution\n        model.save_weights(gcs_filepath)\n        model.set_weights([np.random.random(w.shape) for w in org_weights])\n        for w, org_w in zip(model.get_weights(), org_weights):\n            assert not (w == org_w).all()\n        model.load_weights(gcs_filepath)\n        for w, org_w in zip(model.get_weights(), org_weights):\n            assert_allclose(w, org_w)\n\n        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n\n\ndef test_saving_overwrite_option():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    org_weights = model.get_weights()\n    new_weights = [np.random.random(w.shape) for w in org_weights]\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    save_model(model, fname)\n    model.set_weights(new_weights)\n\n    with patch(\'keras.engine.saving.ask_to_proceed_with_overwrite\') as ask:\n        ask.return_value = False\n        save_model(model, fname, overwrite=False)\n        ask.assert_called_once()\n        new_model = load_model(fname)\n        for w, org_w in zip(new_model.get_weights(), org_weights):\n            assert_allclose(w, org_w)\n\n        ask.return_value = True\n        save_model(model, fname, overwrite=False)\n        assert ask.call_count == 2\n        new_model = load_model(fname)\n        for w, new_w in zip(new_model.get_weights(), new_weights):\n            assert_allclose(w, new_w)\n\n    os.remove(fname)\n\n\ndef test_saving_overwrite_option_gcs():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n    org_weights = model.get_weights()\n    new_weights = [np.random.random(w.shape) for w in org_weights]\n\n    with tf_file_io_proxy(\'keras.engine.saving.tf_file_io\') as file_io_proxy:\n        gcs_filepath = file_io_proxy.get_filepath(\n            filename=\'test_saving_overwrite_option_gcs.h5\')\n        # we should not use same filename in several tests to allow for parallel\n        # execution\n        save_model(model, gcs_filepath)\n        model.set_weights(new_weights)\n\n        with patch(\'keras.engine.saving.ask_to_proceed_with_overwrite\') as ask:\n            ask.return_value = False\n            save_model(model, gcs_filepath, overwrite=False)\n            ask.assert_called_once()\n            new_model = load_model(gcs_filepath)\n            for w, org_w in zip(new_model.get_weights(), org_weights):\n                assert_allclose(w, org_w)\n\n            ask.return_value = True\n            save_model(model, gcs_filepath, overwrite=False)\n            assert ask.call_count == 2\n            new_model = load_model(gcs_filepath)\n            for w, new_w in zip(new_model.get_weights(), new_weights):\n                assert_allclose(w, new_w)\n\n        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n\n\n@pytest.mark.parametrize(\'implementation\', [1, 2], ids=[\'impl1\', \'impl2\'])\n@pytest.mark.parametrize(\'bidirectional\',\n                         [False, True],\n                         ids=[\'single\', \'bidirectional\'])\n@pytest.mark.parametrize(\'to_cudnn\', [False, True], ids=[\'from_cudnn\', \'to_cudnn\'])\n@pytest.mark.parametrize(\'rnn_type\', [\'LSTM\', \'GRU\'], ids=[\'LSTM\', \'GRU\'])\n@pytest.mark.parametrize(\'model_nest_level\',\n                         [1, 2],\n                         ids=[\'model_plain\', \'model_nested\'])\n@pytest.mark.parametrize(\'model_type\',\n                         [\'func\', \'seq\'],\n                         ids=[\'model_func\', \'model_seq\'])\n@skipif_no_tf_gpu\ndef test_load_weights_between_noncudnn_rnn(rnn_type, to_cudnn, bidirectional,\n                                           implementation, model_nest_level,\n                                           model_type):\n    input_size = 10\n    timesteps = 6\n    input_shape = (timesteps, input_size)\n    units = 2\n    num_samples = 32\n    inputs = np.random.random((num_samples, timesteps, input_size))\n\n    rnn_layer_kwargs = {\n        \'recurrent_activation\': \'sigmoid\',\n        # ensure biases are non-zero and properly converted\n        \'bias_initializer\': \'random_uniform\',\n        \'implementation\': implementation\n    }\n    if rnn_type == \'LSTM\':\n        rnn_layer_class = LSTM\n        cudnn_rnn_layer_class = CuDNNLSTM\n    else:\n        rnn_layer_class = GRU\n        cudnn_rnn_layer_class = CuDNNGRU\n        rnn_layer_kwargs[\'reset_after\'] = True\n\n    layer = rnn_layer_class(units, **rnn_layer_kwargs)\n    if bidirectional:\n        layer = Bidirectional(layer)\n\n    cudnn_layer = cudnn_rnn_layer_class(units)\n    if bidirectional:\n        cudnn_layer = Bidirectional(cudnn_layer)\n\n    model = _make_nested_model(input_shape, layer, model_nest_level, model_type)\n    cudnn_model = _make_nested_model(input_shape, cudnn_layer,\n                                     model_nest_level, model_type)\n\n    if to_cudnn:\n        _convert_model_weights(model, cudnn_model)\n    else:\n        _convert_model_weights(cudnn_model, model)\n\n    assert_allclose(model.predict(inputs), cudnn_model.predict(inputs), atol=1e-4)\n\n\ndef _make_nested_model(input_shape, layer, level=1, model_type=\'func\'):\n    # example: make_nested_seq_model((1,), Dense(10), level=2).summary()\n    def make_nested_seq_model(input_shape, layer, level=1):\n        model = layer\n        for i in range(1, level + 1):\n            layers = [InputLayer(input_shape), model] if (i == 1) else [model]\n            model = Sequential(layers)\n        return model\n\n    # example: make_nested_func_model((1,), Dense(10), level=2).summary()\n    def make_nested_func_model(input_shape, layer, level=1):\n        input = Input(input_shape)\n        model = layer\n        for i in range(level):\n            model = Model(input, model(input))\n        return model\n\n    if model_type == \'func\':\n        return make_nested_func_model(input_shape, layer, level)\n    elif model_type == \'seq\':\n        return make_nested_seq_model(input_shape, layer, level)\n\n\ndef _convert_model_weights(source_model, target_model):\n    _, fname = tempfile.mkstemp(\'.h5\')\n    source_model.save_weights(fname)\n    target_model.load_weights(fname)\n    os.remove(fname)\n\n\n@pytest.mark.parametrize(\'to_cudnn\', [False, True], ids=[\'from_cudnn\', \'to_cudnn\'])\n@pytest.mark.parametrize(\'rnn_type\', [\'LSTM\', \'GRU\'], ids=[\'LSTM\', \'GRU\'])\n@skipif_no_tf_gpu\ndef test_load_weights_between_noncudnn_rnn_time_distributed(rnn_type, to_cudnn):\n    """"""\n    Similar test as  test_load_weights_between_noncudnn_rnn() but has different\n    rank of input due to usage of TimeDistributed. Issue: #10356.\n    """"""\n    input_size = 10\n    steps = 6\n    timesteps = 6\n    input_shape = (timesteps, steps, input_size)\n    units = 2\n    num_samples = 32\n    inputs = np.random.random((num_samples,) + input_shape)\n\n    rnn_layer_kwargs = {\n        \'recurrent_activation\': \'sigmoid\',\n        # ensure biases are non-zero and properly converted\n        \'bias_initializer\': \'random_uniform\',\n    }\n    if rnn_type == \'LSTM\':\n        rnn_layer_class = LSTM\n        cudnn_rnn_layer_class = CuDNNLSTM\n    else:\n        rnn_layer_class = GRU\n        cudnn_rnn_layer_class = CuDNNGRU\n        rnn_layer_kwargs[\'reset_after\'] = True\n\n    layer = rnn_layer_class(units, **rnn_layer_kwargs)\n    layer = TimeDistributed(layer)\n\n    cudnn_layer = cudnn_rnn_layer_class(units)\n    cudnn_layer = TimeDistributed(cudnn_layer)\n\n    model = _make_nested_model(input_shape, layer)\n    cudnn_model = _make_nested_model(input_shape, cudnn_layer)\n\n    if to_cudnn:\n        _convert_model_weights(model, cudnn_model)\n    else:\n        _convert_model_weights(cudnn_model, model)\n\n    assert_allclose(model.predict(inputs), cudnn_model.predict(inputs), atol=1e-4)\n\n\n@skipif_no_tf_gpu\ndef test_preprocess_weights_for_loading_gru_incompatible():\n    """"""\n    Loading weights between incompatible layers should fail fast with an exception.\n    """"""\n    def gru(cudnn=False, **kwargs):\n        layer_class = CuDNNGRU if cudnn else GRU\n        return layer_class(2, input_shape=[3, 5], **kwargs)\n\n    def initialize_weights(layer):\n        # A model is needed to initialize weights.\n        _ = Sequential([layer])\n        return layer\n\n    def assert_not_compatible(src, dest, message):\n        with pytest.raises(ValueError) as ex:\n            preprocess_weights_for_loading(dest,\n                                           initialize_weights(src).get_weights())\n        assert message in ex.value.message\n\n    assert_not_compatible(gru(), gru(cudnn=True),\n                          \'GRU(reset_after=False) is not compatible with CuDNNGRU\')\n    assert_not_compatible(gru(cudnn=True), gru(),\n                          \'CuDNNGRU is not compatible with GRU(reset_after=False)\')\n    assert_not_compatible(gru(), gru(reset_after=True),\n                          \'GRU(reset_after=False) is not compatible with \'\n                          \'GRU(reset_after=True)\')\n    assert_not_compatible(gru(reset_after=True), gru(),\n                          \'GRU(reset_after=True) is not compatible with \'\n                          \'GRU(reset_after=False)\')\n\n\ndef test_model_saving_with_rnn_initial_state_and_args():\n    class CustomRNN(LSTM):\n        def call(self, inputs, arg=1, mask=None, training=None, initial_state=None):\n            if isinstance(inputs, list):\n                inputs = inputs[:]\n                shape = K.int_shape(inputs[0])\n                inputs[0] *= arg\n                inputs[0]._keras_shape = shape  # for theano backend\n            else:\n                shape = K.int_shape(inputs)\n                inputs *= arg\n                inputs._keras_shape = shape  # for theano backend\n            return super(CustomRNN, self).call(inputs, mask, training, initial_state)\n\n    inp = Input((3, 2))\n    rnn_out, h, c = CustomRNN(2, return_state=True, return_sequences=True)(inp)\n    assert hasattr(rnn_out, \'_keras_history\')\n    assert hasattr(h, \'_keras_history\')\n    assert hasattr(c, \'_keras_history\')\n    rnn2_out = CustomRNN(2)(rnn_out, arg=2, initial_state=[h, c])\n    assert hasattr(rnn2_out, \'_keras_history\')\n    model = Model(inputs=inp, outputs=rnn2_out)\n    x = np.random.random((2, 3, 2))\n    y1 = model.predict(x)\n    _, fname = tempfile.mkstemp(\'.h5\')\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\'error\')\n        model.save(fname)\n    model2 = load_model(fname, custom_objects={\'CustomRNN\': CustomRNN})\n    y2 = model2.predict(x)\n    assert_allclose(y1, y2, atol=1e-5)\n    os.remove(fname)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/test_multiprocessing.py,0,"b'from __future__ import print_function\n\nimport multiprocessing as mp\nimport os\nimport sys\nimport threading\nimport pytest\nimport numpy as np\nimport six\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.utils import Sequence\nfrom keras import backend as K\n\npytestmark = pytest.mark.skipif(\n    True,\n    reason=\'Temporarily disabled until the use_multiprocessing problem is solved\')\n\nskip_generators = pytest.mark.skipif(K.backend() in {\'tensorflow\', \'cntk\'} and\n                                     \'TRAVIS_PYTHON_VERSION\' in os.environ,\n                                     reason=\'Generators do not work with `spawn`.\')\n\n\ndef use_spawn(func):\n    """"""Decorator which uses `spawn` when possible.\n    This is useful on Travis to avoid memory issues.\n    """"""\n\n    @six.wraps(func)\n    def wrapper(*args, **kwargs):\n        if sys.version_info > (3, 4) and os.name != \'nt\':\n            mp.set_start_method(\'spawn\', force=True)\n            out = func(*args, **kwargs)\n            mp.set_start_method(\'fork\', force=True)\n        else:\n            out = func(*args, **kwargs)\n        return out\n\n    return wrapper\n\n\nSTEPS_PER_EPOCH = 100\nSTEPS = 100\nWORKERS = 4 if K.backend() != \'tensorflow\' else 2\n\n\nclass DummySequence(Sequence):\n    def __getitem__(self, idx):\n        return np.zeros([10, 2]), np.ones([10])\n\n    def __len__(self):\n        return 10\n\n\nclass threadsafe_iter:\n    """"""Takes an iterator/generator and makes it thread-safe by\n    serializing call to the `next` method of given iterator/generator.\n    """"""\n\n    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        return self.next()\n\n    def next(self):\n        with self.lock:\n            return next(self.it)\n\n\ndef threadsafe_generator(f):\n    """"""A decorator that takes a generator function and makes it thread-safe.\n    """"""\n\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n\n    return g\n\n\n@pytest.fixture\ndef in_tmpdir(tmpdir):\n    """"""Runs a function in a temporary directory.\n\n    Checks that the directory is empty afterwards.\n    """"""\n    with tmpdir.as_cwd():\n        yield None\n    assert not tmpdir.listdir()\n\n\n@skip_generators\ndef test_multiprocessing_training():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    arr_weights = np.random.random(50)\n\n    @threadsafe_generator\n    def custom_generator(use_weights=False):\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            if use_weights:\n                w = arr_weights[start: end]\n                yield X, y, w\n            else:\n                yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                epochs=1,\n                                verbose=1,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            epochs=1,\n                            verbose=1,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=WORKERS,\n                        use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(True),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                validation_data=(arr_data[:10],\n                                                 arr_labels[:10],\n                                                 arr_weights[:10]),\n                                validation_steps=1,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(True),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=(arr_data[:10],\n                                             arr_labels[:10],\n                                             arr_weights[:10]),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=(arr_data[:10],\n                                         arr_labels[:10],\n                                         arr_weights[:10]),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(True),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                validation_data=custom_generator(True),\n                                validation_steps=1,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(True),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=custom_generator(True),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread AT A TIME, consume on main thread:\n    #   - Worker threads for training and validation run generator SEQUENTIALLY\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=True)\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=False)\n\n    # Test invalid use cases\n    @threadsafe_generator\n    def invalid_generator():\n        while True:\n            yield arr_data[:10], arr_data[:10], arr_labels[:10], arr_labels[:10]\n\n    # not specified `validation_steps`\n    with pytest.raises(ValueError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=custom_generator(),\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # validation data is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=(arr_data[:10],\n                                             arr_data[:10],\n                                             arr_labels[:10],\n                                             arr_weights[:10]),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # validation generator is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=invalid_generator(),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # - For Sequence\n    model.fit_generator(DummySequence(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=DummySequence(),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=True)\n    model.fit_generator(DummySequence(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=DummySequence(),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=False)\n\n\n@skip_generators\ndef test_multiprocessing_training_from_file(in_tmpdir):\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    np.savez(\'data.npz\', **{\'data\': arr_data, \'labels\': arr_labels})\n\n    @threadsafe_generator\n    def custom_generator():\n\n        batch_size = 10\n        n_samples = 50\n\n        with np.load(\'data.npz\') as arr:\n            while True:\n                batch_index = np.random.randint(0, n_samples - batch_size)\n                start = batch_index\n                end = start + batch_size\n                X = arr[\'data\'][start: end]\n                y = arr[\'labels\'][start: end]\n                yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                epochs=1,\n                                verbose=1,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            epochs=1,\n                            verbose=1,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                epochs=1,\n                                verbose=1,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            epochs=1,\n                            verbose=1,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=True)\n\n    os.remove(\'data.npz\')\n\n\ndef test_multithreading_from_file():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    np.savez(\'data_threads.npz\', **{\'data\': arr_data, \'labels\': arr_labels})\n\n    @threadsafe_generator\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        with np.load(\'data_threads.npz\') as arr:\n            while True:\n                batch_index = np.random.randint(0, n_samples - batch_size)\n                start = batch_index\n                end = start + batch_size\n                X = arr[\'data\'][start: end]\n                y = arr[\'labels\'][start: end]\n                yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=WORKERS,\n                        use_multiprocessing=False)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=False)\n\n    os.remove(\'data_threads.npz\')\n\n\n@skip_generators\ndef test_multiprocessing_predicting():\n    arr_data = np.random.randint(0, 256, (50, 2))\n\n    @threadsafe_generator\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.predict_generator(custom_generator(),\n                                    steps=STEPS,\n                                    max_queue_size=10,\n                                    workers=WORKERS,\n                                    use_multiprocessing=True)\n    else:\n        model.predict_generator(custom_generator(),\n                                steps=STEPS,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.predict_generator(custom_generator(),\n                                    steps=STEPS,\n                                    max_queue_size=10,\n                                    workers=1,\n                                    use_multiprocessing=True)\n    else:\n        model.predict_generator(custom_generator(),\n                                steps=STEPS,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n\n    # - Main thread runs the generator without a queue\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=True)\n\n\ndef test_multithreading_predicting():\n    arr_data = np.random.randint(0, 256, (50, 2))\n\n    @threadsafe_generator\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=False)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # - Main thread runs the generator without a queue\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=False)\n\n\n@skip_generators\ndef test_multiprocessing_evaluating():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n\n    @threadsafe_generator\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries\n    #       -> make sure `evaluate_generator()` raises raises ValueError\n    #          exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=STEPS,\n                                     max_queue_size=10,\n                                     workers=WORKERS,\n                                     use_multiprocessing=True)\n    else:\n        model.evaluate_generator(custom_generator(),\n                                 steps=STEPS,\n                                 max_queue_size=10,\n                                 workers=WORKERS,\n                                 use_multiprocessing=True)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=STEPS,\n                                     max_queue_size=10,\n                                     workers=1,\n                                     use_multiprocessing=True)\n    else:\n        model.evaluate_generator(custom_generator(),\n                                 steps=STEPS,\n                                 max_queue_size=10,\n                                 workers=1,\n                                 use_multiprocessing=True)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=0,\n                             use_multiprocessing=True)\n\n\ndef test_multithreading_evaluating():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n\n    @threadsafe_generator\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=WORKERS,\n                             use_multiprocessing=False)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=1,\n                             use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=0,\n                             use_multiprocessing=False)\n\n\n@skip_generators\ndef test_multiprocessing_fit_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    batch_size = 10\n    n_samples = 50\n    good_batches = 3\n\n    @threadsafe_generator\n    def custom_generator(use_weights=False):\n        """"""Raises an exception after a few good batches""""""\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    samples = batch_size * (good_batches + 1)\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name == \'nt\':\n        with pytest.raises(RuntimeError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name == \'nt\':\n        with pytest.raises(RuntimeError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=True)\n\n\ndef test_multithreading_fit_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    batch_size = 10\n    n_samples = 50\n    good_batches = 3\n\n    @threadsafe_generator\n    def custom_generator():\n        """"""Raises an exception after a few good batches""""""\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    samples = batch_size * (good_batches + 1)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=False)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=False)\n\n\n@skip_generators\ndef test_multiprocessing_evaluate_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    batch_size = 10\n    n_samples = 50\n    good_batches = 3\n\n    @threadsafe_generator\n    def custom_generator():\n        """"""Raises an exception after a few good batches""""""\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name == \'nt\':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches * WORKERS + 1,\n                                     max_queue_size=10,\n                                     workers=WORKERS,\n                                     use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches * WORKERS + 1,\n                                     max_queue_size=10,\n                                     workers=WORKERS,\n                                     use_multiprocessing=True)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name == \'nt\':\n        with pytest.raises(RuntimeError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches + 1,\n                                     max_queue_size=10,\n                                     workers=1,\n                                     use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches + 1,\n                                     max_queue_size=10,\n                                     workers=1,\n                                     use_multiprocessing=True)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches + 1,\n                                 max_queue_size=10,\n                                 workers=0,\n                                 use_multiprocessing=True)\n\n\ndef test_multithreading_evaluate_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    batch_size = 10\n    n_samples = 50\n    good_batches = 3\n\n    @threadsafe_generator\n    def custom_generator():\n        """"""Raises an exception after a few good batches""""""\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches * WORKERS + 1,\n                                 max_queue_size=10,\n                                 workers=WORKERS,\n                                 use_multiprocessing=False)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches + 1,\n                                 max_queue_size=10,\n                                 workers=1,\n                                 use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches + 1,\n                                 max_queue_size=10,\n                                 workers=0,\n                                 use_multiprocessing=False)\n\n\n@skip_generators\ndef test_multiprocessing_predict_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    good_batches = 3\n\n    @threadsafe_generator\n    def custom_generator():\n        """"""Raises an exception after a few good batches""""""\n        batch_size = 10\n        n_samples = 50\n\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name == \'nt\':\n        with pytest.raises(StopIteration):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches * WORKERS + 1,\n                                    max_queue_size=10,\n                                    workers=WORKERS,\n                                    use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches * WORKERS + 1,\n                                    max_queue_size=10,\n                                    workers=WORKERS,\n                                    use_multiprocessing=True)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won\'t marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name == \'nt\':\n        with pytest.raises(RuntimeError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches + 1,\n                                    max_queue_size=10,\n                                    workers=1,\n                                    use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches + 1,\n                                    max_queue_size=10,\n                                    workers=1,\n                                    use_multiprocessing=True)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches + 1,\n                                max_queue_size=10,\n                                workers=0,\n                                use_multiprocessing=True)\n\n\ndef test_multithreading_predict_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    good_batches = 3\n\n    @threadsafe_generator\n    def custom_generator():\n        """"""Raises an exception after a few good batches""""""\n        batch_size = 10\n        n_samples = 50\n\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2,)))\n    model.compile(loss=\'mse\', optimizer=\'adadelta\')\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches * WORKERS + 1,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=False)\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches + 1,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches + 1,\n                                max_queue_size=10,\n                                workers=0,\n                                use_multiprocessing=False)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
keras/applications/__init__.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend\nfrom .. import layers\nfrom .. import models\nfrom .. import utils\n\nimport keras_applications\n\n\ndef keras_modules_injection(base_fun):\n\n    def wrapper(*args, **kwargs):\n        kwargs['backend'] = backend\n        kwargs['layers'] = layers\n        kwargs['models'] = models\n        kwargs['utils'] = utils\n        return base_fun(*args, **kwargs)\n\n    return wrapper\n\n\nfrom .vgg16 import VGG16\nfrom .vgg19 import VGG19\nfrom .resnet50 import ResNet50\nfrom .inception_v3 import InceptionV3\nfrom .inception_resnet_v2 import InceptionResNetV2\nfrom .xception import Xception\nfrom .mobilenet import MobileNet\nfrom .mobilenet_v2 import MobileNetV2\nfrom .densenet import DenseNet121, DenseNet169, DenseNet201\nfrom .nasnet import NASNetMobile, NASNetLarge\nfrom .resnet import ResNet101, ResNet152\nfrom .resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n"""
keras/applications/densenet.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import densenet\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef DenseNet121(*args, **kwargs):\n    return densenet.DenseNet121(*args, **kwargs)\n\n\n@keras_modules_injection\ndef DenseNet169(*args, **kwargs):\n    return densenet.DenseNet169(*args, **kwargs)\n\n\n@keras_modules_injection\ndef DenseNet201(*args, **kwargs):\n    return densenet.DenseNet201(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return densenet.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return densenet.preprocess_input(*args, **kwargs)\n'"
keras/applications/imagenet_utils.py,0,"b'""""""Utilities for ImageNet data preprocessing & prediction decoding.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import imagenet_utils\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return imagenet_utils.decode_predictions(\n        *args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return imagenet_utils.preprocess_input(*args, **kwargs)\n'"
keras/applications/inception_resnet_v2.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import inception_resnet_v2\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef InceptionResNetV2(*args, **kwargs):\n    return inception_resnet_v2.InceptionResNetV2(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return inception_resnet_v2.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return inception_resnet_v2.preprocess_input(*args, **kwargs)\n'"
keras/applications/inception_v3.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import inception_v3\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef InceptionV3(*args, **kwargs):\n    return inception_v3.InceptionV3(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return inception_v3.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return inception_v3.preprocess_input(*args, **kwargs)\n'"
keras/applications/mobilenet.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import mobilenet\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef MobileNet(*args, **kwargs):\n    return mobilenet.MobileNet(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return mobilenet.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return mobilenet.preprocess_input(*args, **kwargs)\n'"
keras/applications/mobilenet_v2.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import mobilenet_v2\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef MobileNetV2(*args, **kwargs):\n    return mobilenet_v2.MobileNetV2(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return mobilenet_v2.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return mobilenet_v2.preprocess_input(*args, **kwargs)\n'"
keras/applications/nasnet.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import nasnet\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef NASNetMobile(*args, **kwargs):\n    return nasnet.NASNetMobile(*args, **kwargs)\n\n\n@keras_modules_injection\ndef NASNetLarge(*args, **kwargs):\n    return nasnet.NASNetLarge(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return nasnet.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return nasnet.preprocess_input(*args, **kwargs)\n'"
keras/applications/resnet.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\ntry:\n    from keras_applications import resnet\nexcept:\n    resnet = None\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef ResNet50(*args, **kwargs):\n    return resnet.ResNet50(*args, **kwargs)\n\n\n@keras_modules_injection\ndef ResNet101(*args, **kwargs):\n    return resnet.ResNet101(*args, **kwargs)\n\n\n@keras_modules_injection\ndef ResNet152(*args, **kwargs):\n    return resnet.ResNet152(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return resnet.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return resnet.preprocess_input(*args, **kwargs)\n'"
keras/applications/resnet50.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import resnet50\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef ResNet50(*args, **kwargs):\n    return resnet50.ResNet50(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return resnet50.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return resnet50.preprocess_input(*args, **kwargs)\n'"
keras/applications/resnet_v2.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\ntry:\n    from keras_applications import resnet_v2\nexcept:\n    resnet_v2 = None\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef ResNet50V2(*args, **kwargs):\n    return resnet_v2.ResNet50V2(*args, **kwargs)\n\n\n@keras_modules_injection\ndef ResNet101V2(*args, **kwargs):\n    return resnet_v2.ResNet101V2(*args, **kwargs)\n\n\n@keras_modules_injection\ndef ResNet152V2(*args, **kwargs):\n    return resnet_v2.ResNet152V2(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return resnet_v2.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return resnet_v2.preprocess_input(*args, **kwargs)\n'"
keras/applications/vgg16.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import vgg16\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef VGG16(*args, **kwargs):\n    return vgg16.VGG16(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return vgg16.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return vgg16.preprocess_input(*args, **kwargs)\n'"
keras/applications/vgg19.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import vgg19\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef VGG19(*args, **kwargs):\n    return vgg19.VGG19(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return vgg19.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return vgg19.preprocess_input(*args, **kwargs)\n'"
keras/applications/xception.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_applications import xception\nfrom . import keras_modules_injection\n\n\n@keras_modules_injection\ndef Xception(*args, **kwargs):\n    return xception.Xception(*args, **kwargs)\n\n\n@keras_modules_injection\ndef decode_predictions(*args, **kwargs):\n    return xception.decode_predictions(*args, **kwargs)\n\n\n@keras_modules_injection\ndef preprocess_input(*args, **kwargs):\n    return xception.preprocess_input(*args, **kwargs)\n'"
keras/backend/__init__.py,0,"b""from .load_backend import epsilon\r\nfrom .load_backend import set_epsilon\r\nfrom .load_backend import floatx\r\nfrom .load_backend import set_floatx\r\nfrom .load_backend import cast_to_floatx\r\nfrom .load_backend import image_data_format\r\nfrom .load_backend import set_image_data_format\r\nfrom .load_backend import reset_uids\r\nfrom .load_backend import get_uid\r\nfrom .load_backend import learning_phase\r\nfrom .load_backend import set_learning_phase\r\nfrom .load_backend import is_sparse\r\nfrom .load_backend import to_dense\r\nfrom .load_backend import variable\r\nfrom .load_backend import is_variable\r\nfrom .load_backend import constant\r\nfrom .load_backend import is_keras_tensor\r\nfrom .load_backend import is_tensor\r\nfrom .load_backend import placeholder\r\nfrom .load_backend import is_placeholder\r\nfrom .load_backend import shape\r\nfrom .load_backend import int_shape\r\nfrom .load_backend import ndim\r\nfrom .load_backend import dtype\r\nfrom .load_backend import eval\r\nfrom .load_backend import zeros\r\nfrom .load_backend import ones\r\nfrom .load_backend import eye\r\nfrom .load_backend import zeros_like\r\nfrom .load_backend import ones_like\r\nfrom .load_backend import identity\r\nfrom .load_backend import random_uniform_variable\r\nfrom .load_backend import random_normal_variable\r\nfrom .load_backend import count_params\r\nfrom .load_backend import cast\r\nfrom .load_backend import update\r\nfrom .load_backend import update_add\r\nfrom .load_backend import update_sub\r\nfrom .load_backend import moving_average_update\r\nfrom .load_backend import dot\r\nfrom .load_backend import batch_dot\r\nfrom .load_backend import transpose\r\nfrom .load_backend import gather\r\nfrom .load_backend import max\r\nfrom .load_backend import min\r\nfrom .load_backend import sum\r\nfrom .load_backend import prod\r\nfrom .load_backend import cumsum\r\nfrom .load_backend import cumprod\r\nfrom .load_backend import var\r\nfrom .load_backend import std\r\nfrom .load_backend import mean\r\nfrom .load_backend import any\r\nfrom .load_backend import all\r\nfrom .load_backend import argmax\r\nfrom .load_backend import argmin\r\nfrom .load_backend import square\r\nfrom .load_backend import abs\r\nfrom .load_backend import sqrt\r\nfrom .load_backend import exp\r\nfrom .load_backend import log\r\nfrom .load_backend import logsumexp\r\nfrom .load_backend import round\r\nfrom .load_backend import sign\r\nfrom .load_backend import pow\r\nfrom .load_backend import clip\r\nfrom .load_backend import equal\r\nfrom .load_backend import not_equal\r\nfrom .load_backend import greater\r\nfrom .load_backend import greater_equal\r\nfrom .load_backend import less\r\nfrom .load_backend import less_equal\r\nfrom .load_backend import maximum\r\nfrom .load_backend import minimum\r\nfrom .load_backend import sin\r\nfrom .load_backend import cos\r\nfrom .load_backend import normalize_batch_in_training\r\nfrom .load_backend import batch_normalization\r\nfrom .load_backend import concatenate\r\nfrom .load_backend import reshape\r\nfrom .load_backend import permute_dimensions\r\nfrom .load_backend import resize_images\r\nfrom .load_backend import resize_volumes\r\nfrom .load_backend import repeat_elements\r\nfrom .load_backend import repeat\r\nfrom .load_backend import arange\r\nfrom .load_backend import tile\r\nfrom .load_backend import flatten\r\nfrom .load_backend import batch_flatten\r\nfrom .load_backend import expand_dims\r\nfrom .load_backend import squeeze\r\nfrom .load_backend import temporal_padding\r\nfrom .load_backend import spatial_2d_padding\r\nfrom .load_backend import spatial_3d_padding\r\nfrom .load_backend import stack\r\nfrom .load_backend import one_hot\r\nfrom .load_backend import reverse\r\nfrom .load_backend import slice\r\nfrom .load_backend import get_value\r\nfrom .load_backend import batch_get_value\r\nfrom .load_backend import set_value\r\nfrom .load_backend import batch_set_value\r\nfrom .load_backend import print_tensor\r\nfrom .load_backend import function\r\nfrom .load_backend import gradients\r\nfrom .load_backend import stop_gradient\r\nfrom .load_backend import rnn\r\nfrom .load_backend import switch\r\nfrom .load_backend import in_train_phase\r\nfrom .load_backend import in_test_phase\r\nfrom .load_backend import relu\r\nfrom .load_backend import elu\r\nfrom .load_backend import softmax\r\nfrom .load_backend import softplus\r\nfrom .load_backend import softsign\r\nfrom .load_backend import categorical_crossentropy\r\nfrom .load_backend import sparse_categorical_crossentropy\r\nfrom .load_backend import binary_crossentropy\r\nfrom .load_backend import sigmoid\r\nfrom .load_backend import hard_sigmoid\r\nfrom .load_backend import tanh\r\nfrom .load_backend import dropout\r\nfrom .load_backend import l2_normalize\r\nfrom .load_backend import in_top_k\r\nfrom .load_backend import conv1d\r\nfrom .load_backend import separable_conv1d\r\nfrom .load_backend import conv2d\r\nfrom .load_backend import separable_conv2d\r\nfrom .load_backend import conv2d_transpose\r\nfrom .load_backend import depthwise_conv2d\r\nfrom .load_backend import conv3d\r\nfrom .load_backend import conv3d_transpose\r\nfrom .load_backend import pool2d\r\nfrom .load_backend import pool3d\r\nfrom .load_backend import bias_add\r\nfrom .load_backend import random_normal\r\nfrom .load_backend import random_uniform\r\nfrom .load_backend import random_binomial\r\nfrom .load_backend import truncated_normal\r\nfrom .load_backend import ctc_label_dense_to_sparse\r\nfrom .load_backend import ctc_batch_cost\r\nfrom .load_backend import ctc_decode\r\nfrom .load_backend import map_fn\r\nfrom .load_backend import foldl\r\nfrom .load_backend import foldr\r\nfrom .load_backend import local_conv1d\r\nfrom .load_backend import local_conv2d\r\nfrom .load_backend import backend\r\nfrom .load_backend import normalize_data_format\r\nfrom .load_backend import name_scope\r\nfrom .load_backend import symbolic\r\nfrom .load_backend import eager\r\nfrom .load_backend import size\r\nfrom .load_backend import control_dependencies\r\n\r\nif backend() == 'theano':\r\n    from .load_backend import pattern_broadcast\r\nelif backend() == 'tensorflow':\r\n    from .load_backend import clear_session\r\n    from .load_backend import manual_variable_initialization\r\n    from .load_backend import get_session\r\n    from .load_backend import set_session\r\nelif backend() == 'cntk':\r\n    from .load_backend import clear_session\r\n"""
keras/backend/cntk_backend.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport cntk as C\nimport numpy as np\nfrom .common import floatx\nfrom .common import epsilon\nfrom .common import image_data_format\nfrom .common import normalize_data_format\nfrom ..utils.generic_utils import transpose_shape\nfrom collections import defaultdict\nfrom contextlib import contextmanager\nimport warnings\n\n\nC.set_global_option(\'align_axis\', 1)\n\nb_any = any\npy_slice = slice\n\n\ndev = C.device.use_default_device()\nif dev.type() == 0:\n    warnings.warn(\n        \'CNTK backend warning: GPU is not detected. \'\n        \'CNTK\\\'s CPU version is not fully optimized,\'\n        \'please run with GPU to get better performance.\')\n\n# A learning phase is a bool tensor used to run Keras models in\n# either train mode (learning_phase == 1) or test mode (learning_phase == 0).\n# LEARNING_PHASE_PLACEHOLDER is the placeholder for dynamic learning phase\n_LEARNING_PHASE_PLACEHOLDER = C.constant(\n    shape=(), dtype=np.float32,\n    value=1.0,\n    name=\'_keras_learning_phase\')\n# static learning phase flag, if it is not 0 or 1, we will go with dynamic\n# learning phase tensor.\n_LEARNING_PHASE = -1\n_UID_PREFIXES = defaultdict(int)\n\n# cntk doesn\'t support gradient as symbolic op, to hook up with keras model,\n# we will create gradient as a constant placeholder, here use this global\n# map to keep the mapping from grad placeholder to parameter\ngrad_parameter_dict = {}\n\nNAME_SCOPE_STACK = []\n\n\n@contextmanager\ndef name_scope(name):\n    global NAME_SCOPE_STACK\n    NAME_SCOPE_STACK.append(name)\n    yield\n    NAME_SCOPE_STACK.pop()\n\n\ndef get_uid(prefix=\'\'):\n    _UID_PREFIXES[prefix] += 1\n    return _UID_PREFIXES[prefix]\n\n\ndef learning_phase():\n    # If _LEARNING_PHASE is not 0 or 1, return dynamic learning phase tensor\n    if _LEARNING_PHASE in {0, 1}:\n        return _LEARNING_PHASE\n    else:\n        return _LEARNING_PHASE_PLACEHOLDER\n\n\ndef set_learning_phase(value):\n    global _LEARNING_PHASE\n    if value not in {0, 1}:\n        raise ValueError(\'CNTK Backend: Set learning phase \'\n                         \'with value %s is not supported, \'\n                         \'expected 0 or 1.\' % value)\n    _LEARNING_PHASE = value\n\n\ndef clear_session():\n    """"""Reset learning phase flag for cntk backend.\n    """"""\n    global _LEARNING_PHASE\n    global _LEARNING_PHASE_PLACEHOLDER\n    _LEARNING_PHASE = -1\n    _LEARNING_PHASE_PLACEHOLDER.value = np.asarray(1.0)\n\n\ndef in_train_phase(x, alt, training=None):\n    global _LEARNING_PHASE\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    # CNTK currently don\'t support cond op, so here we use\n    # element_select approach as workaround. It may have\n    # perf issue, will resolve it later with cntk cond op.\n    if callable(x) and isinstance(x, C.cntk_py.Function) is False:\n        x = x()\n    if callable(alt) and isinstance(alt, C.cntk_py.Function) is False:\n        alt = alt()\n\n    if training is True:\n        x._uses_learning_phase = uses_learning_phase\n        return x\n    else:\n        # if _LEARNING_PHASE is static\n        if isinstance(training, int) or isinstance(training, bool):\n            result = x if training == 1 or training is True else alt\n        else:\n            result = C.element_select(training, x, alt)\n        result._uses_learning_phase = uses_learning_phase\n        return result\n\n\ndef in_test_phase(x, alt, training=None):\n    return in_train_phase(alt, x, training=training)\n\n\ndef _convert_string_dtype(dtype):\n    if dtype == \'float32\':\n        return np.float32\n    elif dtype == \'float64\':\n        return np.float64\n    elif dtype == \'float16\':\n        return np.float16\n    else:\n        # cntk only running with float,\n        # try to cast to float to run the model\n        return np.float32\n\n\ndef _convert_dtype_string(dtype):\n    if dtype == np.float32:\n        return \'float32\'\n    elif dtype == np.float64:\n        return \'float64\'\n    elif dtype == np.float16:\n        return \'float16\'\n    else:\n        raise ValueError(\'CNTK Backend: Unsupported dtype: %s. \'\n                         \'CNTK only supports float32, float64, and \'\n                         \'float16.\' % dtype)\n\n\ndef variable(value, dtype=None, name=None, constraint=None):\n    """"""Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n    """"""\n    if dtype is None:\n        dtype = floatx()\n\n    if name is None:\n        name = \'\'\n\n    if isinstance(\n            value,\n            C.variables.Constant) or isinstance(\n            value,\n            C.variables.Parameter):\n        value = value.value\n\n    # we don\'t support init parameter with symbolic op, so eval it first as\n    # workaround\n    if isinstance(value, C.cntk_py.Function):\n        value = eval(value)\n\n    shape = value.shape if hasattr(value, \'shape\') else ()\n    if hasattr(value, \'dtype\') and value.dtype != dtype and len(shape) > 0:\n        value = value.astype(dtype)\n\n    # TODO: remove the conversion when cntk supports int32, int64\n    # https://www.cntk.ai/pythondocs/cntk.variables.html#cntk.variables.Parameter\n    dtype = \'float32\' if \'int\' in str(dtype) else dtype\n\n    v = C.parameter(shape=shape,\n                    init=value,\n                    dtype=dtype,\n                    name=_prepare_name(name, \'variable\'))\n    v._keras_shape = v.shape\n    v._uses_learning_phase = False\n    v.constraint = constraint\n    return v\n\n\ndef is_variable(x):\n    return isinstance(x, C.variables.Parameter)\n\n\ndef bias_add(x, bias, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    dims = len(x.shape)\n    if dims > 0 and x.shape[0] == C.InferredDimension:\n        dims -= 1\n\n    bias_dims = len(bias.shape)\n    if bias_dims != 1 and bias_dims != dims:\n        raise ValueError(\'Unexpected bias dimensions %d, \'\n                         \'expected 1 or %d dimensions\' % (bias_dims, dims))\n\n    if dims == 4:\n        if data_format == \'channels_first\':\n            if bias_dims == 1:\n                shape = (bias.shape[0], 1, 1, 1)\n            else:\n                shape = (bias.shape[3],) + bias.shape[:3]\n        elif data_format == \'channels_last\':\n            if bias_dims == 1:\n                shape = (1, 1, 1, bias.shape[0])\n            else:\n                shape = bias.shape\n    elif dims == 3:\n        if data_format == \'channels_first\':\n            if bias_dims == 1:\n                shape = (bias.shape[0], 1, 1)\n            else:\n                shape = (bias.shape[2],) + bias.shape[:2]\n        elif data_format == \'channels_last\':\n            if bias_dims == 1:\n                shape = (1, 1, bias.shape[0])\n            else:\n                shape = bias.shape\n    elif dims == 2:\n        if data_format == \'channels_first\':\n            if bias_dims == 1:\n                shape = (bias.shape[0], 1)\n            else:\n                shape = (bias.shape[1],) + bias.shape[:1]\n        elif data_format == \'channels_last\':\n            if bias_dims == 1:\n                shape = (1, bias.shape[0])\n            else:\n                shape = bias.shape\n    else:\n        shape = bias.shape\n    return x + reshape(bias, shape)\n\n\ndef eval(x):\n    if isinstance(x, C.cntk_py.Function):\n        return x.eval()\n    elif (isinstance(x, C.variables.Constant) or isinstance(\n            x, C.variables.Parameter)):\n        return x.value\n    else:\n        raise ValueError(\'CNTK Backend: `eval` method on \'\n                         \'`%s` type is not supported. \'\n                         \'CNTK only supports `eval` with \'\n                         \'`Function`, `Constant` or \'\n                         \'`Parameter`.\' % type(x))\n\n\ndef placeholder(\n        shape=None,\n        ndim=None,\n        dtype=None,\n        sparse=False,\n        name=None,\n        dynamic_axis_num=1):\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n\n    if _get_cntk_version() >= 2.2:\n        dynamic_dimension = C.FreeDimension\n    else:\n        dynamic_dimension = C.InferredDimension\n\n    cntk_shape = [dynamic_dimension if s is None else s for s in shape]\n    cntk_shape = tuple(cntk_shape)\n\n    if dynamic_axis_num > len(cntk_shape):\n        raise ValueError(\'CNTK backend: creating placeholder with \'\n                         \'%d dimension is not supported, at least \'\n                         \'%d dimensions are needed.\'\n                         % (len(cntk_shape), dynamic_axis_num))\n\n    if name is None:\n        name = \'\'\n\n    cntk_shape = cntk_shape[dynamic_axis_num:]\n\n    x = C.input(\n        shape=cntk_shape,\n        dtype=_convert_string_dtype(dtype),\n        is_sparse=sparse,\n        name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    x._cntk_placeholder = True\n    return x\n\n\ndef is_placeholder(x):\n    """"""Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    """"""\n    return hasattr(x, \'_cntk_placeholder\') and x._cntk_placeholder\n\n\ndef is_keras_tensor(x):\n    if not is_tensor(x):\n        raise ValueError(\'Unexpectedly found an instance of type `\' +\n                         str(type(x)) + \'`. \'\n                         \'Expected a symbolic tensor instance.\')\n    return hasattr(x, \'_keras_history\')\n\n\ndef is_tensor(x):\n    return isinstance(x, (C.variables.Constant,\n                          C.variables.Variable,\n                          C.variables.Parameter,\n                          C.ops.functions.Function))\n\n\ndef shape(x):\n    shape = list(int_shape(x))\n    num_dynamic = _get_dynamic_axis_num(x)\n    non_dyn_shape = []\n    for i in range(len(x.shape)):\n        if shape[i + num_dynamic] is None:\n            non_dyn_shape.append(x.shape[i])\n        else:\n            non_dyn_shape.append(shape[i + num_dynamic])\n    return shape[:num_dynamic] + non_dyn_shape\n\n\ndef is_sparse(tensor):\n    return tensor.is_sparse\n\n\ndef int_shape(x):\n    if hasattr(x, \'_keras_shape\'):\n        return x._keras_shape\n\n    if hasattr(x, \'shape\'):\n        shape = x.shape\n    else:\n        shape = np.array(x).shape\n\n    if hasattr(x, \'dynamic_axes\'):\n        dynamic_shape = [None for a in x.dynamic_axes]\n        shape = tuple(dynamic_shape) + shape\n    return shape\n\n\ndef ndim(x):\n    shape = int_shape(x)\n    return len(shape)\n\n\ndef _prepare_name(name, default):\n    prefix = \'_\'.join(NAME_SCOPE_STACK)\n    if name is None or name == \'\':\n        return prefix + \'/\' + default\n    return prefix + \'/\' + name\n\n\ndef constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    np_value = value * np.ones(shape)\n    const = C.constant(np_value,\n                       dtype=dtype,\n                       name=_prepare_name(name, \'constant\'))\n    const._keras_shape = const.shape\n    const._uses_learning_phase = False\n    return const\n\n\ndef random_binomial(shape, p=0.0, dtype=None, seed=None):\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e7)\n    if dtype is None:\n        dtype = floatx()\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    for _ in shape:\n        if _ is None:\n            raise ValueError(\'CNTK Backend: randomness op with \'\n                             \'dynamic shape is not supported now. \'\n                             \'Please provide fixed dimension \'\n                             \'instead of `None`.\')\n    return C.random.bernoulli(shape=shape, dtype=dtype, mean=p, seed=seed)\n\n\ndef random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    for _ in shape:\n        if _ is None:\n            raise ValueError(\'CNTK Backend: randomness op with \'\n                             \'dynamic shape is not supported now. \'\n                             \'Please provide fixed dimension \'\n                             \'instead of `None`.\')\n\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e3)\n    return C.random.uniform(\n        shape=shape,\n        dtype=dtype,\n        low=minval,\n        high=maxval,\n        seed=seed)\n\n\ndef random_uniform_variable(shape, low, high,\n                            dtype=None, name=None, seed=None):\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e3)\n\n    if dtype is None:\n        dtype = floatx()\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    if name is None:\n        name = \'\'\n\n    scale = (high - low) / 2\n    p = C.parameter(\n        shape,\n        init=C.initializer.uniform(\n            scale,\n            seed=seed),\n        dtype=dtype,\n        name=name)\n    return variable(value=p.value + low + scale)\n\n\ndef random_normal_variable(\n        shape,\n        mean,\n        scale,\n        dtype=None,\n        name=None,\n        seed=None):\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e7)\n    if dtype is None:\n        dtype = floatx()\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    if name is None:\n        name = \'\'\n\n    p = C.parameter(\n        shape=shape,\n        init=C.initializer.normal(\n            scale=scale,\n            seed=seed),\n        dtype=dtype,\n        name=name)\n    return variable(value=p.value + mean)\n\n\ndef random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    for _ in shape:\n        if _ is None:\n            raise ValueError(\'CNTK Backend: randomness op with \'\n                             \'dynamic shape is not supported now. \'\n                             \'Please provide fixed dimension \'\n                             \'instead of `None`.\')\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e3)\n    return C.random.normal(\n        shape=shape, mean=mean,\n        scale=stddev, seed=seed,\n        dtype=dtype)\n\n\ndef truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    if dtype is None:\n        dtype = floatx()\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    return C.parameter(\n        shape, init=C.initializer.truncated_normal(\n            stddev, seed=seed), dtype=dtype)\n\n\ndef dtype(x):\n    return _convert_dtype_string(x.dtype)\n\n\ndef zeros(shape, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    ctype = _convert_string_dtype(dtype)\n    return variable(value=np.zeros(shape, ctype), dtype=dtype, name=name)\n\n\ndef ones(shape, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    ctype = _convert_string_dtype(dtype)\n    return variable(value=np.ones(shape, ctype), dtype=dtype, name=name)\n\n\ndef eye(size, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if isinstance(size, (list, tuple)):\n        n, m = size\n    else:\n        n, m = size, size\n    return variable(np.eye(n, m), dtype, name)\n\n\ndef zeros_like(x, dtype=None, name=None):\n    name = name or \'\'\n    if dtype is None:\n        dtype = floatx()\n    return C.cast(C.zeros_like(x, name), dtype)\n\n\ndef ones_like(x, dtype=None, name=None):\n    name = name or \'\'\n    if dtype is None:\n        dtype = floatx()\n    return C.cast(C.ones_like(x, name), dtype)\n\n\ndef count_params(x):\n    for _ in x.shape:\n        if _ == C.InferredDimension or _ == C.FreeDimension:\n            raise ValueError(\'CNTK backend: `count_params` with dynamic \'\n                             \'shape is not supported. Please provide \'\n                             \'fixed dimension instead of `None`.\')\n\n    return np.prod(int_shape(x))\n\n\ndef cast(x, dtype):\n    # cntk calculate everything in float, so don\'t need case from bool / int\n    return x\n\n\ndef size(x, name=None):\n    return sum(ones_like(x, name=name))\n\n\ndef dot(x, y):\n    if len(x.shape) > 2 or len(y.shape) > 2:\n        y_shape = int_shape(y)\n        if len(y_shape) > 2:\n            permutation = [len(y_shape) - 2]\n            permutation += list(range(len(y_shape) - 2))\n            permutation += [len(y_shape) - 1]\n            y = C.transpose(y, perm=permutation)\n        return C.times(x, y, len(y_shape) - 1)\n    else:\n        return C.times(x, y)\n\n\ndef batch_dot(x, y, axes=None):\n    x_shape = int_shape(x)\n    y_shape = int_shape(y)\n\n    x_ndim = len(x_shape)\n    y_ndim = len(y_shape)\n\n    if x_ndim < 2 or y_ndim < 2:\n        raise ValueError(\'Can not do batch_dot on inputs \'\n                         \'with rank < 2. \'\n                         \'Received inputs with shapes \' +\n                         str(x_shape) + \' and \' +\n                         str(y_shape) + \'.\')\n\n    x_batch_size = x_shape[0]\n    y_batch_size = y_shape[0]\n\n    if x_batch_size is not None and y_batch_size is not None:\n        if x_batch_size != y_batch_size:\n            raise ValueError(\'Can not do batch_dot on inputs \'\n                             \'with different batch sizes. \'\n                             \'Received inputs with shapes \' +\n                             str(x_shape) + \' and \' +\n                             str(y_shape) + \'.\')\n\n    if isinstance(axes, int):\n        axes = [axes, axes]\n\n    if axes is None:\n        if y_ndim == 2:\n            axes = [x_ndim - 1, y_ndim - 1]\n        else:\n            axes = [x_ndim - 1, y_ndim - 2]\n\n    if b_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError(\'Multiple target dimensions are not supported. \' +\n                         \'Expected: None, int, (int, int), \' +\n                         \'Provided: \' + str(axes))\n\n    # if tuple, convert to list\n    axes = list(axes)\n\n    # convert negative indices\n    if axes[0] < 0:\n        axes[0] += x_ndim\n    if axes[1] < 0:\n        axes[1] += y_ndim\n\n    if 0 in axes:\n        raise ValueError(\'Can not perform batch_dot over axis 0.\'\n                         \' If your inputs are not batched,\'\n                         \' add a dummy batch dimension to your \'\n                         \'inputs using K.expand_dims(x, 0)\')\n    d1 = x_shape[axes[0]]\n    d2 = y_shape[axes[1]]\n\n    if d1 is not None and d2 is not None and d1 != d2:\n        raise ValueError(\'Can not do batch_dot on inputs with shapes \' +\n                         str(x_shape) + \' and \' + str(y_shape) +\n                         \' with axes=\' + str(axes) + \'. x.shape[%d] != \'\n                         \'y.shape[%d] (%d != %d).\' % (axes[0], axes[1], d1, d2))\n\n    # Input shapes:\n    # x: (b_size, x1, ..., d, ..., xn)\n    # y: (b_size, y1, ..., d, ..., yn)\n    # where d is the dimension to reduce.\n\n    # Bring d to the last dimension in x\n    # x: (b_size, ..., d)\n\n    permute_pattern = list(range(x_ndim))\n    for i in range(axes[0], x_ndim - 1):\n        permute_pattern[i] = permute_pattern[i + 1]\n    permute_pattern[-1] = axes[0]\n\n    x = permute_dimensions(x, permute_pattern)\n\n    # Bring d to the second dimension in y\n    # y: (b_size, d, ...)\n    permute_pattern = list(range(y_ndim))\n\n    for i in range(axes[1], 1, -1):\n        permute_pattern[i] = permute_pattern[i - 1]\n    permute_pattern[1] = axes[1]\n    y = permute_dimensions(y, permute_pattern)\n\n    # Expand to rank 3 if needed\n    if x_ndim == 2:\n        x = expand_dims(x, 1)\n        x_expanded = True\n    else:\n        x_expanded = False\n\n    if y_ndim == 2:\n        y = expand_dims(y, -1)\n        y_expanded = True\n    else:\n        y_expanded = False\n\n    x_shape = int_shape(x)\n    y_shape = int_shape(y)\n\n    # batch size might be lost at this point\n    x_batch_size = x_shape[0]\n    y_batch_size = y_shape[0]\n\n    if x_batch_size is None and y_batch_size is None:\n        dynamic_batch_size = True\n    elif x_batch_size is not None and y_batch_size is not None:\n        dynamic_batch_size = False\n    else:\n        raise ValueError(\'Can not perform batch_dot on inputs\' +\n                         \' with both static and dynamic batch sizes.\' +\n                         \'You probably attempted to permform the \' +\n                         \'operation on a placeholder and a variable, \' +\n                         \'which is not yet supported on the CNTK backend.\')\n\n    if dynamic_batch_size:\n        result = C.times(x, y, output_rank=y_ndim - 2 + int(y_expanded))\n    else:\n        result = []\n\n        for i in range(x_batch_size):\n            xi = x[i]\n            yi = y[i]\n            if ndim(xi) == ndim(x):  # for older versions of CNTK\n                xi = squeeze(xi, 0)\n                yi = squeeze(yi, 0)\n            result.append(C.times(xi, yi, output_rank=y_ndim - 2 + int(y_expanded)))\n        result = stack(result, 0)\n\n    if x_expanded:\n        result = squeeze(result, 1)\n\n    if y_expanded:\n        result = squeeze(result, -1)\n\n    if ndim(result) == 1:\n        return expand_dims(result)\n    return result\n\n\ndef transpose(x):\n    return C.swapaxes(x, 0, 1)\n\n\ndef gather(reference, indices):\n    # There is a bug in cntk gather op which may cause crash.\n    # We have made a fix but not catched in CNTK 2.1 release.\n    # Will update with gather op in next release\n    if _get_cntk_version() >= 2.2:\n        return C.ops.gather(reference, indices)\n    else:\n        num_classes = reference.shape[0]\n        one_hot_matrix = C.ops.one_hot(indices, num_classes)\n        return C.times(\n            one_hot_matrix, reference,\n            output_rank=len(reference.shape) - 1)\n\n\ndef _remove_dims(x, axis, keepdims=False):\n    if keepdims is False and isinstance(axis, list):\n        # sequence axis is removed by default, so don\'t need reshape on it\n        reduce_axes = []\n        for a in axis:\n            if isinstance(a, C.Axis) is False:\n                reduce_axes.append(a)\n        return _reshape_dummy_dim(x, reduce_axes)\n    else:\n        if isinstance(axis, list):\n            has_seq = False\n            for a in axis:\n                if isinstance(a, C.Axis):\n                    has_seq = True\n                    break\n            if has_seq:\n                nones = _get_dynamic_axis_num(x)\n                x = expand_dims(x, nones)\n        return x\n\n\ndef max(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, \'reduce_max\')\n\n    return _remove_dims(output, axis, keepdims)\n\n\ndef min(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, \'reduce_min\')\n\n    return _remove_dims(output, axis, keepdims)\n\n\ndef sum(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, \'reduce_sum\')\n\n    return _remove_dims(output, axis, keepdims)\n\n\ndef prod(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, \'reduce_prod\')\n\n    return _remove_dims(output, axis, keepdims)\n\n\ndef logsumexp(x, axis=None, keepdims=False):\n    return log(sum(exp(x), axis=axis, keepdims=keepdims))\n\n\ndef var(x, axis=None, keepdims=False):\n    m = mean(x, axis, keepdims=True)\n    devs_squared = C.square(x - m)\n    return mean(devs_squared, axis=axis, keepdims=keepdims)\n\n\ndef std(x, axis=None, keepdims=False):\n    return C.sqrt(var(x, axis=axis, keepdims=keepdims))\n\n\ndef expand_dims(x, axis=-1):\n    shape = list(int_shape(x))\n    nones = _get_dynamic_axis_num(x)\n    index = axis if axis >= 0 else len(shape) + 1\n    shape.insert(index, 1)\n    new_shape = shape[nones:]\n    new_shape = tuple(\n        [C.InferredDimension if _ is None else _ for _ in new_shape])\n    result = C.reshape(x, new_shape)\n    if index < nones:\n        result._keras_shape = shape\n    return result\n\n\ndef squeeze(x, axis):\n    if isinstance(axis, tuple):\n        axis = list(axis)\n    if not isinstance(axis, list):\n        axis = [axis]\n\n    shape = list(int_shape(x))\n\n    _axis = []\n    for _ in axis:\n        if isinstance(_, int):\n            _axis.append(_ if _ >= 0 else _ + len(shape))\n\n    if len(_axis) == 0:\n        return x\n\n    nones = _get_dynamic_axis_num(x)\n    for _ in sorted(_axis, reverse=True):\n        del shape[_]\n\n    new_shape = shape[nones:]\n\n    new_shape_temp = []\n    for _ in new_shape:\n        if _ == C.FreeDimension:\n            new_shape_temp.append(C.InferredDimension)\n        else:\n            new_shape_temp.append(_)\n\n    new_shape = tuple(new_shape_temp)\n\n    return C.reshape(x, new_shape)\n\n\ndef tile(x, n):\n    if isinstance(n, int):\n        n = (n,)\n    elif isinstance(n, list):\n        n = tuple(n)\n\n    shape = int_shape(x)\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    if len(n) < len(shape):  # Padding the axis\n        n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n    elif len(n) != len(shape):\n        raise NotImplementedError\n\n    i = num_dynamic_axis\n    for i, rep in enumerate(n):\n        if i >= num_dynamic_axis and shape[i] is not None:\n            tmp = [x] * rep\n            x = C.splice(*tmp, axis=i - num_dynamic_axis)\n        i += 1\n\n    return x\n\n\ndef _normalize_axis(axis, x):\n    shape = int_shape(x)\n    ndim = len(shape)\n\n    nones = _get_dynamic_axis_num(x)\n\n    if nones > ndim:\n        raise ValueError(\n            \'CNTK Backend: tensor with keras shape: `%s` has \'\n            \'%d cntk dynamic axis, this is not expected, please \'\n            \'double check the keras shape history.\'\n            % (str(shape), nones))\n\n    # Current cntk does not support shape like (1, batch). so using the workaround\n    # here to mapping the correct axis. Will remove this tricky after we add support\n    # in native cntk op\n    cntk_axis = []\n    dynamic_axis_index = 0\n    for i in range(ndim):\n        if shape[i] is None and dynamic_axis_index < nones:\n            cntk_axis.append(x.dynamic_axes[dynamic_axis_index])\n            dynamic_axis_index += 1\n        else:\n            cntk_axis.append(i - dynamic_axis_index)\n\n    if dynamic_axis_index < nones:\n        i = 0\n        while dynamic_axis_index < nones:\n            cntk_axis[i] = x.dynamic_axes[dynamic_axis_index]\n            i += 1\n            dynamic_axis_index += 1\n\n        while i < len(cntk_axis):\n            cntk_axis[i] -= nones\n            i += 1\n\n    if isinstance(axis, tuple):\n        _axis = list(axis)\n    elif isinstance(axis, int):\n        _axis = [axis]\n    elif isinstance(axis, list):\n        _axis = list(axis)\n    else:\n        _axis = axis\n\n    if isinstance(_axis, list):\n        for i, a in enumerate(_axis):\n            if a is not None and a < 0:\n                _axis[i] = (a % ndim)\n            if _axis[i] is not None:\n                _axis[i] = cntk_axis[_axis[i]]\n    else:\n        if _axis is None:\n            _axis = C.Axis.all_axes()\n\n    return _axis\n\n\ndef _reshape_dummy_dim(x, axis):\n    shape = list(x.shape)\n\n    _axis = [_ + len(shape) if _ < 0 else _ for _ in axis]\n\n    if shape.count(C.InferredDimension) > 1 or shape.count(C.FreeDimension) > 1:\n        result = x\n        for index in sorted(_axis, reverse=True):\n            result = C.reshape(result,\n                               shape=(),\n                               begin_axis=index,\n                               end_axis=index + 1)\n        return result\n    else:\n        for index in sorted(_axis, reverse=True):\n            del shape[index]\n\n        shape = [C.InferredDimension if _ == C.FreeDimension else _ for _ in shape]\n        return C.reshape(x, shape)\n\n\ndef mean(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, \'reduce_mean\')\n\n    return _remove_dims(output, axis, keepdims)\n\n\ndef any(x, axis=None, keepdims=False):\n    reduce_result = sum(x, axis, keepdims=keepdims)\n    any_matrix = C.element_select(\n        reduce_result,\n        ones_like(reduce_result),\n        zeros_like(reduce_result))\n    if len(reduce_result.shape) == 0 and _get_dynamic_axis_num(x) == 0:\n        return C.reduce_sum(any_matrix)\n    else:\n        return any_matrix\n\n\ndef all(x, axis=None, keepdims=False):\n    reduce_result = prod(x, axis, keepdims=keepdims)\n    all_matrix = C.element_select(\n        reduce_result,\n        ones_like(reduce_result),\n        zeros_like(reduce_result))\n    if len(reduce_result.shape) == 0 and _get_dynamic_axis_num(x) == 0:\n        return C.reduce_sum(all_matrix)\n    else:\n        return all_matrix\n\n\ndef classification_error(target, output, axis=-1):\n    return C.ops.reduce_mean(\n        C.equal(\n            argmax(\n                output,\n                axis=-1),\n            argmax(\n                target,\n                axis=-1)),\n        axis=C.Axis.all_axes())\n\n\ndef argmax(x, axis=-1):\n    axis = [axis]\n    axis = _normalize_axis(axis, x)\n    output = C.ops.argmax(x, axis=axis[0])\n    return _reshape_dummy_dim(output, axis)\n\n\ndef argmin(x, axis=-1):\n    axis = [axis]\n    axis = _normalize_axis(axis, x)\n    output = C.ops.argmin(x, axis=axis[0])\n    return _reshape_dummy_dim(output, axis)\n\n\ndef square(x):\n    return C.square(x)\n\n\ndef abs(x):\n    return C.abs(x)\n\n\ndef sqrt(x):\n    return C.sqrt(x)\n\n\ndef exp(x):\n    return C.exp(x)\n\n\ndef log(x):\n    return C.log(x)\n\n\ndef round(x):\n    return C.round(x)\n\n\ndef sigmoid(x):\n    return C.sigmoid(x)\n\n\ndef sign(x):\n    return x / C.abs(x)\n\n\ndef pow(x, a):\n    return C.pow(x, a)\n\n\ndef clip(x, min_value, max_value):\n    if (isinstance(min_value, (int, float)) and\n            isinstance(max_value, (int, float))):\n        if max_value < min_value:\n            max_value = min_value\n    if min_value is None:\n        min_value = -np.inf\n    if max_value is None:\n        max_value = np.inf\n    return C.clip(x, min_value, max_value)\n\n\ndef binary_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = C.sigmoid(output)\n    output = C.clip(output, epsilon(), 1.0 - epsilon())\n    output = -target * C.log(output) - (1.0 - target) * C.log(1.0 - output)\n    return output\n\n\ndef get_variable_shape(x):\n    return int_shape(x)\n\n\ndef update(x, new_x):\n    return C.assign(x, new_x)\n\n\ndef moving_average_update(variable, value, momentum):\n    return C.assign(variable, variable * momentum + value * (1. - momentum))\n\n\ndef update_add(x, increment):\n    result = x + increment\n    return C.assign(x, result)\n\n\ndef update_sub(x, decrement):\n    result = x - decrement\n    return C.assign(x, result)\n\n\ndef gradients(loss, variables):\n    # cntk does not support gradients as symbolic op,\n    # to hook up with keras model\n    # we will return a constant as place holder, the cntk learner will apply\n    # the gradient during training.\n    global grad_parameter_dict\n    if isinstance(variables, list) is False:\n        variables = [variables]\n    grads = []\n    for v in variables:\n        g = C.constant(0, shape=v.shape, name=\'keras_grad_placeholder\')\n        grads.append(g)\n        grad_parameter_dict[g] = v\n    return grads\n\n\ndef equal(x, y):\n    return C.equal(x, y)\n\n\ndef not_equal(x, y):\n    return C.not_equal(x, y)\n\n\ndef greater(x, y):\n    return C.greater(x, y)\n\n\ndef greater_equal(x, y):\n    return C.greater_equal(x, y)\n\n\ndef less(x, y):\n    return C.less(x, y)\n\n\ndef less_equal(x, y):\n    return C.less_equal(x, y)\n\n\ndef maximum(x, y):\n    return C.element_max(x, y)\n\n\ndef minimum(x, y):\n    return C.element_min(x, y)\n\n\ndef sin(x):\n    return C.sin(x)\n\n\ndef cos(x):\n    return C.cos(x)\n\n\ndef normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    if gamma is None:\n        if beta is None:\n            gamma = ones_like(x)\n        else:\n            gamma = ones_like(beta)\n    if beta is None:\n        if gamma is None:\n            beta = zeros_like(x)\n        else:\n            beta = zeros_like(gamma)\n\n    mean, variant = _moments(x, _normalize_axis(reduction_axes, x))\n\n    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n        normalized = batch_normalization(\n            x, mean, variant, beta, gamma, epsilon)\n    else:\n        # need broadcasting\n        target_shape = []\n        x_shape = int_shape(x)\n        # skip the batch axis\n        for axis in range(1, ndim(x)):\n            if axis in reduction_axes:\n                target_shape.append(1)\n                if ndim(gamma) > axis:\n                    gamma = C.reduce_mean(gamma, axis - 1)\n                    beta = C.reduce_mean(beta, axis - 1)\n            else:\n                target_shape.append(x_shape[axis])\n\n        broadcast_mean = C.reshape(mean, target_shape)\n        broadcast_var = C.reshape(variant, target_shape)\n        broadcast_gamma = C.reshape(gamma, target_shape)\n        broadcast_beta = C.reshape(beta, target_shape)\n        normalized = batch_normalization(\n            x,\n            broadcast_mean,\n            broadcast_var,\n            broadcast_beta,\n            broadcast_gamma,\n            epsilon)\n\n    return normalized, mean, variant\n\n\ndef _moments(x, axes=None, shift=None, keep_dims=False):\n    _axes = tuple(axes)\n    if shift is None:\n        shift = x\n        # Compute true mean while keeping the dims for proper broadcasting.\n        for axis in _axes:\n            shift = C.reduce_mean(shift, axis=axis)\n\n    shift = C.stop_gradient(shift)\n    shifted_mean = C.minus(x, shift)\n    for axis in _axes:\n        shifted_mean = C.reduce_mean(shifted_mean, axis=axis)\n\n    variance_mean = C.square(C.minus(x, shift))\n    for axis in _axes:\n        variance_mean = C.reduce_mean(variance_mean, axis=axis)\n\n    variance = C.minus(variance_mean, C.square(shifted_mean))\n    mean = C.plus(shifted_mean, shift)\n\n    if not keep_dims:\n        mean = squeeze(mean, _axes)\n        variance = squeeze(variance, _axes)\n\n    return mean, variance\n\n\ndef batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n    # The mean / var / beta / gamma may be processed by broadcast\n    # so it may have an extra batch axis with 1, it is not needed\n    # in cntk, need to remove those dummy axis.\n    if ndim(mean) == ndim(x) and shape(mean)[0] == 1:\n        mean = _reshape_dummy_dim(mean, [0])\n    if ndim(var) == ndim(x) and shape(var)[0] == 1:\n        var = _reshape_dummy_dim(var, [0])\n\n    if gamma is None:\n        gamma = ones_like(var)\n    elif ndim(gamma) == ndim(x) and shape(gamma)[0] == 1:\n        gamma = _reshape_dummy_dim(gamma, [0])\n\n    if beta is None:\n        beta = zeros_like(mean)\n    elif ndim(beta) == ndim(x) and shape(beta)[0] == 1:\n        beta = _reshape_dummy_dim(beta, [0])\n\n    return (x - mean) / C.sqrt(var + epsilon) * gamma + beta\n\n\ndef concatenate(tensors, axis=-1):\n    if len(tensors) == 0:\n        return None\n\n    axis = [axis]\n    axis = _normalize_axis(axis, tensors[0])\n    return C.splice(*tensors, axis=axis[0])\n\n\ndef stack(x, axis=0):\n    x = [expand_dims(t, axis) for t in x]\n    return concatenate(x, axis)\n\n\ndef flatten(x):\n    return reshape(x, (-1,))\n\n\ndef reshape(x, shape):\n    shape_temp = []\n    for _ in shape:\n        if _ == C.FreeDimension:\n            shape_temp.append(C.InferredDimension)\n        else:\n            shape_temp.append(_)\n\n    shape = tuple(shape_temp)\n\n    if isinstance(x, C.variables.Parameter):\n        return C.reshape(x, shape)\n    else:\n        num_dynamic_axis = _get_dynamic_axis_num(x)\n\n        if num_dynamic_axis == 1 and len(shape) > 0 and shape[0] == -1:\n            # collapse axis with batch axis\n            if b_any(_ == C.InferredDimension for _ in x.shape) or b_any(\n                    _ == C.FreeDimension for _ in x.shape):\n                warnings.warn(\n                    \'Warning: CNTK backend does not support \'\n                    \'collapse of batch axis with inferred dimension. \'\n                    \'The reshape did not take place.\')\n                return x\n            return _reshape_batch(x, shape)\n        else:\n            # no collapse, then first need to padding the shape\n            if num_dynamic_axis >= len(shape):\n                i = 0\n                while i < len(shape):\n                    if shape[i] is None or shape[i] == -1:\n                        i += 1\n                    else:\n                        break\n                shape = tuple([-1 for _ in range(num_dynamic_axis - i)]) + shape\n\n            new_shape = list(shape)\n            new_shape = new_shape[num_dynamic_axis:]\n            new_shape = [C.InferredDimension if _ is None else _ for _ in new_shape]\n            return C.reshape(x, new_shape)\n\n\ndef permute_dimensions(x, pattern):\n    dims = len(int_shape(x))\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    if isinstance(pattern, list):\n        current_layout = [i for i in range(dims)]\n    else:\n        current_layout = tuple([i for i in range(dims)])\n\n    if (num_dynamic_axis > 0 and\n            pattern[:num_dynamic_axis] != current_layout[:num_dynamic_axis]):\n                raise ValueError(\'CNTK backend: the permute pattern %s \'\n                                 \'requested permute on dynamic axis, \'\n                                 \'which is not supported. Please do permute \'\n                                 \'on static axis.\' % pattern)\n\n    axis = list(pattern)\n    axis = axis[num_dynamic_axis:]\n    axis = _normalize_axis(axis, x)\n    return C.transpose(x, axis)\n\n\ndef resize_images(x, height_factor, width_factor, data_format,\n                  interpolation=\'nearest\'):\n    if interpolation == \'nearest\':\n        if data_format == \'channels_first\':\n            output = repeat_elements(x, height_factor, axis=2)\n            output = repeat_elements(output, width_factor, axis=3)\n            return output\n        elif data_format == \'channels_last\':\n            output = repeat_elements(x, height_factor, axis=1)\n            output = repeat_elements(output, width_factor, axis=2)\n            return output\n        else:\n            raise ValueError(\'CNTK Backend: Invalid data_format: %s\' % data_format)\n    else:\n        raise NotImplementedError(\'CNTK only supports `nearest` interpolation.\')\n\n\ndef resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    if data_format == \'channels_first\':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == \'channels_last\':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError(\'CNTK Backend: Invalid data_format: %s\' % data_format)\n\n\ndef repeat_elements(x, rep, axis):\n    axis = _normalize_axis(axis, x)\n    axis = axis[0]\n    slices = []\n    shape = x.shape\n    i = 0\n    while i < shape[axis]:\n        tmp = C.ops.slice(x, axis, i, i + 1)\n        for _ in range(rep):\n            slices.append(tmp)\n        i += 1\n    return C.splice(*slices, axis=axis)\n\n\ndef repeat(x, n):\n    # this is a workaround for recurrent layer\n    # if n is inferred dimension,\n    # we can\'t figure out how to repeat it in cntk now\n    # return the same x to take cntk broadcast feature\n    # to make the recurrent layer work.\n    # need to be fixed in GA.\n    if n is C.InferredDimension or n is C.FreeDimension:\n        return x\n    index = 1 - _get_dynamic_axis_num(x)\n    if index < 0 or index > 1:\n        raise NotImplementedError\n\n    new_shape = list(x.shape)\n    new_shape.insert(index, 1)\n    new_shape = tuple(new_shape)\n    x = C.reshape(x, new_shape)\n    temp = [x] * n\n    return C.splice(*temp, axis=index)\n\n\ndef tanh(x):\n    return C.tanh(x)\n\n\ndef _static_rnn(step_function, inputs, initial_states,\n                go_backwards=False, mask=None, constants=None,\n                unroll=False, input_length=None):\n\n    shape = int_shape(inputs)\n    dims = len(shape)\n\n    uses_learning_phase = False\n\n    if dims < 3:\n        raise ValueError(\'Input should be at least 3D.\')\n\n    # if the second axis is static axis, CNTK will do unroll by default\n    if shape[1] is None:\n        raise ValueError(\'CNTK Backend: the input of static rnn \'\n                         \'has shape `%s`, the second axis \'\n                         \'is not static. If you want to run \'\n                         \'rnn with non-static axis, please try \'\n                         \'dynamic rnn with sequence axis.\' % shape)\n    if constants is None:\n        constants = []\n\n    if mask is not None:\n        mask_shape = int_shape(mask)\n        if len(mask_shape) == dims - 1:\n            mask = expand_dims(mask)\n\n    nones = _get_dynamic_axis_num(inputs)\n\n    states = tuple(initial_states)\n\n    outputs = []\n\n    time_axis = 1 - nones if nones > 0 else 1\n\n    if go_backwards:\n        i = shape[1] - 1\n        while i >= 0:\n            current = C.ops.slice(inputs, time_axis, i, i + 1)\n            # remove dummy dimension\n            current = squeeze(current, time_axis)\n\n            output, new_states = step_function(\n                current, tuple(states) + tuple(constants))\n            if getattr(output, \'_uses_learning_phase\', False):\n                uses_learning_phase = True\n\n            if mask is not None:\n                mask_slice = C.ops.slice(mask, time_axis, i, i + 1)\n                mask_slice = squeeze(mask_slice, time_axis)\n                if len(outputs) == 0:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = outputs[-1]\n                output = C.ops.element_select(mask_slice, output, prev_output)\n\n                return_states = []\n                for s, n_s in zip(states, new_states):\n                    return_states.append(\n                        C.ops.element_select(\n                            mask_slice, n_s, s))\n                new_states = return_states\n            outputs.append(output)\n            states = new_states\n            i -= 1\n    else:\n        i = 0\n        while i < shape[1]:\n            current = C.ops.slice(inputs, time_axis, i, i + 1)\n            # remove dummy dimension\n            current = squeeze(current, 1)\n\n            output, new_states = step_function(\n                current, tuple(states) + tuple(constants))\n            if getattr(output, \'_uses_learning_phase\', False):\n                uses_learning_phase = True\n\n            if mask is not None:\n                mask_slice = C.ops.slice(mask, time_axis, i, i + 1)\n                mask_slice = squeeze(mask_slice, 1)\n                if len(outputs) == 0:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = outputs[-1]\n                output = C.ops.element_select(mask_slice, output, prev_output)\n\n                return_states = []\n                for s, n_s in zip(states, new_states):\n                    return_states.append(\n                        C.ops.element_select(\n                            mask_slice, n_s, s))\n                new_states = return_states\n            outputs.append(output)\n            states = new_states[:len(states)]\n            i += 1\n\n    i = 1\n    # add the time_step axis back\n    final_output = expand_dims(outputs[0], 1)\n    last_output = outputs[0]\n    while i < len(outputs):\n        # add the time_step axis back\n        output_slice = expand_dims(outputs[i], 1)\n        final_output = C.splice(final_output, output_slice, axis=time_axis)\n        last_output = outputs[i]\n        i += 1\n\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, final_output, states\n\n\ndef rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n\n    if not unroll and mask is not None:\n        warnings.warn(\n            \'CNTK Backend only supports accurate masking if \'\n            \'`output == new_states[0]` for \'\n            \'`output, new_states = step_function(inputs, states)`\')\n\n    shape = int_shape(inputs)\n    dims = len(shape)\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if dims < 3:\n        raise ValueError(\'CNTK Backend: the input of rnn has only rank %d \'\n                         \'Need at least rank 3 to run RNN.\' % dims)\n\n    if _get_dynamic_axis_num(inputs) == 0 or unroll:\n        return _static_rnn(\n            step_function,\n            inputs,\n            initial_states,\n            go_backwards,\n            mask,\n            constants,\n            unroll,\n            input_length)\n\n    if constants is None:\n        constants = []\n\n    num_time_step = shape[1]\n    if num_time_step is None and not has_seq_axis(inputs):\n        num_time_step = inputs.shape[0]\n\n    initial = []\n    for s in initial_states:\n        if _get_dynamic_axis_num(s) == 0:\n            if hasattr(C, \'to_batch\'):\n                initial.append(C.to_batch(s))\n            else:\n                initial.append(C.user_function(ConvertToBatch(s)))\n        else:\n            initial.append(s)\n\n    need_convert = not has_seq_axis(inputs)\n    if go_backwards and need_convert is False:\n        raise NotImplementedError(\n            \'CNTK Backend: `go_backwards` is not supported with \'\n            \'variable-length sequences. Please specify a \'\n            \'static length for your sequences.\')\n\n    rnn_inputs = inputs\n    if need_convert:\n        if go_backwards:\n            rnn_inputs = reverse(rnn_inputs, 1)\n\n        rnn_inputs = C.to_sequence(rnn_inputs)\n\n        rnn_constants = []\n        for constant in constants:\n            if isinstance(constant, list):\n                new_c = []\n                for c in constant:\n                    if _get_dynamic_axis_num(c) == 1:\n                        new_c.append(C.sequence.broadcast_as(c, rnn_inputs))\n                    else:\n                        new_c.append(c)\n                rnn_constants.append(new_c)\n            else:\n                if _get_dynamic_axis_num(constant) == 1:\n                    rnn_constants.append(C.sequence.broadcast_as(\n                        constant,\n                        rnn_inputs))\n                else:\n                    rnn_constants.append(constant)\n    else:\n        rnn_constants = constants\n\n    if mask is not None and not has_seq_axis(mask):\n        if go_backwards:\n            mask = reverse(mask, 1)\n        if len(int_shape(mask)) == 2:\n            mask = expand_dims(mask)\n        mask = C.to_sequence_like(mask, rnn_inputs)\n\n    states = tuple(initial)\n\n    with C.default_options(axis_offset=1):\n        def _recurrence(x, states, m):\n            # create place holder\n            place_holders = [C.placeholder(\n                dynamic_axes=x.dynamic_axes) for _ in states]\n            past_values = []\n            for s, p in zip(states, place_holders):\n                past_values.append(C.sequence.past_value(p, s))\n            new_output, new_states = step_function(\n                x, tuple(past_values) + tuple(rnn_constants))\n\n            if getattr(new_output, \'_uses_learning_phase\', False):\n                global uses_learning_phase\n                uses_learning_phase = True\n\n            if m is not None:\n                new_states_temp = []\n                for n, s in zip(new_states, past_values):\n                    new_states_temp.append(C.element_select(m, n, s))\n\n                new_states = new_states_temp\n\n            n_s = []\n            for o, p in zip(new_states, place_holders):\n                n_s.append(o.replace_placeholders({p: o.output}))\n            if len(n_s) > 0:\n                new_output = n_s[-1]\n            return new_output, n_s\n\n        final_output, final_states = _recurrence(rnn_inputs, states, mask)\n        last_output = C.sequence.last(final_output)\n        last_states = [C.sequence.last(s) for s in final_states]\n\n    if need_convert:\n        final_output = C.sequence.unpack(final_output, 0, no_mask_output=True)\n        if num_time_step is not None and num_time_step is not C.FreeDimension:\n            final_output = _reshape_sequence(final_output, num_time_step)\n\n    f_stats = []\n    for l_s, i_s in zip(last_states, initial_states):\n        if _get_dynamic_axis_num(i_s) == 0 and _get_dynamic_axis_num(l_s) == 1:\n            if hasattr(C, \'unpack_batch\'):\n                f_stats.append(C.unpack_batch(l_s))\n            else:\n                f_stats.append(\n                    C.user_function(ConvertToStatic(l_s, batch_size=i_s.shape[0])))\n        else:\n            f_stats.append(l_s)\n\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, final_output, f_stats\n\n\ndef has_seq_axis(x):\n    return hasattr(x, \'dynamic_axes\') and len(x.dynamic_axes) > 1\n\n\ndef l2_normalize(x, axis=None):\n    axis = [axis]\n    axis = _normalize_axis(axis, x)\n    norm = C.sqrt(C.reduce_sum(C.square(x), axis=axis[0]))\n    return x / norm\n\n\ndef hard_sigmoid(x):\n    x = (0.2 * x) + 0.5\n    x = C.clip(x, 0.0, 1.0)\n    return x\n\n\ndef conv1d(x, kernel, strides=1, padding=\'valid\',\n           data_format=None, dilation_rate=1):\n    data_format = normalize_data_format(data_format)\n\n    if padding == \'causal\':\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel.shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = \'valid\'\n\n    if data_format == \'channels_last\':\n        x = C.swapaxes(x, 0, 1)\n\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(steps, input_depth, depth)`,\n    # independently of `data_format`.\n    # CNTK expects `(depth, input_depth, steps)`.\n    kernel = C.swapaxes(kernel, 0, 2)\n\n    padding = _preprocess_border_mode(padding)\n\n    if dev.type() == 0 and dilation_rate != 1:\n        raise ValueError(\n            \'Dilated convolution on CPU is not supported by CNTK backend. \'\n            \'Please set `dilation_rate` to 1. You passed: %s\' % (dilation_rate,))\n\n    dilation_rate = (1, dilation_rate)\n\n    x = C.convolution(\n        kernel,\n        x,\n        strides=strides,\n        auto_padding=[False, padding],\n        dilation=dilation_rate)\n\n    if data_format == \'channels_last\':\n        x = C.swapaxes(x, 0, 1)\n    return x\n\n\ndef conv2d(x, kernel, strides=(1, 1), padding=\'valid\',\n           data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dev.type() == 0 and dilation_rate != (1, 1):\n        raise ValueError(\n            \'Dilated convolution on CPU is not supported by CNTK backend. \'\n            \'Please set `dilation_rate` to (1, 1). \'\n            \'You passed: %s\' % (dilation_rate,))\n\n    dilation_rate = (1,) + dilation_rate\n\n    x = C.convolution(kernel,\n                      x,\n                      strides,\n                      auto_padding=[False, padding, padding],\n                      dilation=dilation_rate)\n\n    return _postprocess_conv2d_output(x, data_format)\n\n\ndef separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding=\'valid\', data_format=None, dilation_rate=1):\n    data_format = normalize_data_format(data_format)\n    if isinstance(strides, int):\n        strides = (strides,)\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,)\n\n    if dilation_rate != (1,):\n        raise ValueError(\n            \'Dilated separable 1D convolution is currently not supported \'\n            \'by CNTK backend. Please set `dilation_rate` to 1. \'\n            \'You passed: %s\' % (dilation_rate,))\n\n    if data_format == \'channels_last\':\n        spatial_start_dim = 2\n    else:\n        spatial_start_dim = 3\n    x = expand_dims(x, spatial_start_dim)\n    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n    strides = (1,) + strides + (1,)\n    dilation_rate = (1,) + dilation_rate\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n                                 (-1, 1) + depthwise_kernel.shape[2:])\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    x = C.convolution(depthwise_kernel, x,\n                      strides=strides,\n                      auto_padding=[False, padding, padding],\n                      groups=x.shape[0])\n    x = C.convolution(pointwise_kernel, x,\n                      strides=(1, 1, 1),\n                      auto_padding=[False])\n\n    x = _postprocess_conv2d_output(x, data_format)\n    return squeeze(x, spatial_start_dim)\n\n\ndef separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding=\'valid\', data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n                                 (-1, 1) + depthwise_kernel.shape[2:])\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dilation_rate == (1, 1):\n        strides = (1,) + strides\n        x = C.convolution(depthwise_kernel, x,\n                          strides=strides,\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n        x = C.convolution(pointwise_kernel, x,\n                          strides=(1, 1, 1),\n                          auto_padding=[False])\n    else:\n        if dilation_rate[0] != dilation_rate[1]:\n            raise ValueError(\'CNTK Backend: non-square dilation_rate is \'\n                             \'not supported.\')\n        if strides != (1, 1):\n            raise ValueError(\'Invalid strides for dilated convolution\')\n        x = C.convolution(depthwise_kernel, x,\n                          strides=dilation_rate[0],\n                          auto_padding=[False, padding, padding])\n        x = C.convolution(pointwise_kernel, x,\n                          strides=(1, 1, 1),\n                          auto_padding=[False])\n    return _postprocess_conv2d_output(x, data_format)\n\n\ndef depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding=\'valid\',\n                     data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n                                 (-1, 1) + depthwise_kernel.shape[2:])\n    padding = _preprocess_border_mode(padding)\n    if dilation_rate == (1, 1):\n        strides = (1,) + strides\n        x = C.convolution(depthwise_kernel, x,\n                          strides=strides,\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n    else:\n        if dilation_rate[0] != dilation_rate[1]:\n            raise ValueError(\'CNTK Backend: non-square dilation_rate is \'\n                             \'not supported.\')\n        if strides != (1, 1):\n            raise ValueError(\'Invalid strides for dilated convolution\')\n        x = C.convolution(depthwise_kernel, x,\n                          strides=dilation_rate[0],\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n    return _postprocess_conv2d_output(x, data_format)\n\n\ndef conv3d(x, kernel, strides=(1, 1, 1), padding=\'valid\',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dev.type() == 0 and dilation_rate != (1, 1, 1):\n        raise ValueError(\n            \'Dilated convolution on CPU is not supported by CNTK backend. \'\n            \'Please set `dilation_rate` to (1, 1, 1). \'\n            \'You passed: %s\' % (dilation_rate,))\n\n    dilation_rate = (1,) + dilation_rate\n\n    x = C.convolution(\n        kernel,\n        x,\n        strides,\n        auto_padding=[False, padding, padding, padding],\n        dilation=dilation_rate)\n\n    return _postprocess_conv3d_output(x, data_format)\n\n\ndef conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding=\'valid\', data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n    strides = (1,) + strides\n    # cntk output_shape does not include batch axis\n    output_shape = output_shape[1:]\n    # in keras2, need handle output shape in different format\n    if data_format == \'channels_last\':\n        output_shape = transpose_shape(output_shape, \'channels_first\',\n                                       spatial_axes=(0, 1, 2))\n\n    x = C.convolution_transpose(\n        kernel,\n        x,\n        strides,\n        auto_padding=[\n            False,\n            padding,\n            padding,\n            padding],\n        output_shape=output_shape)\n    return _postprocess_conv3d_output(x, data_format)\n\n\ndef pool2d(x, pool_size, strides=(1, 1),\n           padding=\'valid\', data_format=None,\n           pool_mode=\'max\'):\n    data_format = normalize_data_format(data_format)\n\n    padding = _preprocess_border_mode(padding)\n    x = _preprocess_conv2d_input(x, data_format)\n    if pool_mode == \'max\':\n        x = C.pooling(\n            x,\n            C.MAX_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    elif pool_mode == \'avg\':\n        x = C.pooling(\n            x,\n            C.AVG_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    else:\n        raise ValueError(\'Invalid pooling mode: \' + str(pool_mode))\n    return _postprocess_conv2d_output(x, data_format)\n\n\ndef pool3d(x, pool_size, strides=(1, 1, 1), padding=\'valid\',\n           data_format=None, pool_mode=\'max\'):\n    data_format = normalize_data_format(data_format)\n\n    padding = _preprocess_border_mode(padding)\n\n    x = _preprocess_conv3d_input(x, data_format)\n\n    if pool_mode == \'max\':\n        x = C.pooling(\n            x,\n            C.MAX_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    elif pool_mode == \'avg\':\n        x = C.pooling(\n            x,\n            C.AVG_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    else:\n        raise ValueError(\'Invalid pooling mode: \' + str(pool_mode))\n\n    return _postprocess_conv3d_output(x, data_format)\n\n\ndef relu(x, alpha=0., max_value=None, threshold=0.):\n\n    if alpha != 0.:\n        if threshold != 0.:\n            negative_part = C.relu(-x + threshold)\n        else:\n            negative_part = C.relu(-x)\n\n    if threshold != 0.:\n        x = x * C.greater(x, threshold)\n    else:\n        x = C.relu(x)\n\n    if max_value is not None:\n        x = C.clip(x, 0.0, max_value)\n\n    if alpha != 0.:\n        x -= alpha * negative_part\n\n    return x\n\n\ndef dropout(x, level, noise_shape=None, seed=None):\n    if level < 0. or level >= 1:\n        raise ValueError(\'CNTK Backend: Invalid dropout level %s, \'\n                         \'must be in interval [0, 1].\' % level)\n    return C.dropout(x, level)\n\n\ndef batch_flatten(x):\n    # cntk\'s batch axis is not in shape,\n    # so just flatten all the dim in x.shape\n    dim = np.prod(x.shape)\n    x = C.reshape(x, (-1,))\n    x._keras_shape = (None, dim)\n    return x\n\n\ndef softmax(x, axis=-1):\n    return C.softmax(x, axis=axis)\n\n\ndef softplus(x):\n    return C.softplus(x)\n\n\ndef softsign(x):\n    return x / (1 + C.abs(x))\n\n\ndef categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    # Here, unlike other backends, the tensors lack a batch dimension:\n    axis_without_batch = -1 if axis == -1 else axis - 1\n    output_dimensions = list(range(len(output.shape)))\n    if axis_without_batch != -1 and axis_without_batch not in output_dimensions:\n        raise ValueError(\n            \'{}{}{}\'.format(\n                \'Unexpected channels axis {}. \'.format(axis_without_batch),\n                \'Expected to be -1 or one of the axes of `output`, \',\n                \'which has {} dimensions.\'.format(len(output.shape))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis_without_batch != -1 and axis_without_batch != output_dimensions[-1]:\n        permutation = output_dimensions[:axis_without_batch]\n        permutation += output_dimensions[axis_without_batch + 1:]\n        permutation += [axis_without_batch]\n        output = C.transpose(output, permutation)\n        target = C.transpose(target, permutation)\n    if from_logits:\n        result = C.cross_entropy_with_softmax(output, target)\n        # cntk\'s result shape is (batch, 1), while keras expect (batch, )\n        return C.reshape(result, ())\n    else:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= C.reduce_sum(output, axis=-1)\n        # avoid numerical instability with epsilon clipping\n        output = C.clip(output, epsilon(), 1.0 - epsilon())\n        return -sum(target * C.log(output), axis=-1)\n\n\ndef sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    # Here, unlike other backends, the tensors lack a batch dimension:\n    axis_without_batch = -1 if axis == -1 else axis - 1\n    output_dimensions = list(range(len(output.shape)))\n    if axis_without_batch != -1 and axis_without_batch not in output_dimensions:\n        raise ValueError(\n            \'{}{}{}\'.format(\n                \'Unexpected channels axis {}. \'.format(axis_without_batch),\n                \'Expected to be -1 or one of the axes of `output`, \',\n                \'which has {} dimensions.\'.format(len(output.shape))))\n    target = C.one_hot(target, output.shape[axis_without_batch],\n                       axis=axis_without_batch)\n    target = C.reshape(target, output.shape)\n    return categorical_crossentropy(target, output, from_logits, axis=axis)\n\n\nclass Function(object):\n\n    def __init__(self, inputs, outputs, updates=[], **kwargs):\n        self.placeholders = inputs\n        self.trainer = None\n        self.unrelated_updates = None\n        self.updates = updates\n        if len(updates) > 0:\n            assert len(outputs) > 0\n            self.loss = outputs[0]\n            # need group update by gradient place holder\n            u_ops = []\n            unrelated_updates = []\n            for update in updates:\n                if isinstance(update, tuple):\n                    if len(update) != 2:\n                        raise NotImplementedError\n                    else:\n                        u = C.assign(update[0], update[1])\n                else:\n                    u = update\n\n                if len(u.arguments) == 0:\n                    u_ops.append(u)\n                else:\n                    unrelated_updates.append(u)\n\n            update_func = C.combine([u.output for u in u_ops])\n\n            grads = update_func.find_all_with_name(\'keras_grad_placeholder\')\n\n            u_list = []\n            p_list = []\n            for g in grads:\n                if g in grad_parameter_dict:\n                    p_list.append(grad_parameter_dict[g])\n                    u_list.append(g)\n                else:\n                    raise ValueError(\n                        \'CNTK backend: when constructing trainer, \'\n                        \'found gradient node `%s` which is not \'\n                        \'related to any parameters in the model. \'\n                        \'Please double check how the gradient node \'\n                        \'is constructed.\' % g)\n\n            if len(u_list) > 0:\n                learner = C.cntk_py.universal_learner(p_list, u_list, update_func)\n\n                criterion = (\n                    outputs[0],\n                    outputs[1]) if len(outputs) > 1 else (\n                    outputs[0],\n                )\n                self.trainer = C.trainer.Trainer(\n                    outputs[0], criterion, [learner])\n                self.trainer_output = tuple([f.output for f in criterion])\n            elif len(u_ops) > 0:\n                unrelated_updates.extend(u_ops)\n\n            if len(unrelated_updates) > 0:\n                self.unrelated_updates = C.combine(\n                    [_.output for _ in unrelated_updates])\n\n        if self.trainer is None:\n            self.metrics_outputs = [f.output for f in outputs]\n            self.metrics_func = C.combine(self.metrics_outputs)\n        # cntk only could handle loss and 1 metric in trainer, for metrics more\n        # than 2, need manual eval\n        elif len(outputs) > 2:\n            self.metrics_outputs = [f.output for f in outputs[2:]]\n            self.metrics_func = C.combine(self.metrics_outputs)\n        else:\n            self.metrics_func = None\n\n    @staticmethod\n    def _is_input_shape_compatible(input, placeholder):\n        if hasattr(input, \'shape\') and hasattr(placeholder, \'shape\'):\n            num_dynamic = get_num_dynamic_axis(placeholder)\n            input_shape = input.shape[num_dynamic:]\n            placeholder_shape = placeholder.shape\n            for i, p in zip(input_shape, placeholder_shape):\n                if i != p and p != C.InferredDimension and p != C.FreeDimension:\n                    return False\n        return True\n\n    def __call__(self, inputs):\n        global _LEARNING_PHASE_PLACEHOLDER\n        global _LEARNING_PHASE\n        assert isinstance(inputs, (list, tuple))\n        feed_dict = {}\n        for tensor, value in zip(self.placeholders, inputs):\n            # cntk only support calculate on float, do auto cast here\n            if (hasattr(value, \'dtype\') and\n               value.dtype != np.float32 and\n               value.dtype != np.float64):\n                value = value.astype(np.float32)\n\n            if tensor == _LEARNING_PHASE_PLACEHOLDER:\n                _LEARNING_PHASE_PLACEHOLDER.value = np.asarray(value)\n            else:\n                # in current version cntk can\'t support input with variable\n                # length. Will support it in next release.\n                if not self._is_input_shape_compatible(value, tensor):\n                    raise ValueError(\n                        \'CNTK backend: The placeholder has been resolved \'\n                        \'to shape `%s`, but input shape is `%s`. Currently \'\n                        \'CNTK can not take variable length inputs. Please \'\n                        \'pass inputs that have a static shape.\'\n                        % (str(tensor.shape), str(value.shape)))\n            feed_dict[tensor] = value\n\n        updated = []\n        if self.trainer is not None:\n            input_dict = {}\n            for argument in self.loss.arguments:\n                if argument in feed_dict:\n                    input_dict[argument] = feed_dict[argument]\n                else:\n                    raise ValueError(\n                        \'CNTK backend: argument %s is not found in inputs. \'\n                        \'Please double check the model and inputs in \'\n                        \'`train_function`.\' % argument.name)\n\n            result = self.trainer.train_minibatch(\n                input_dict, self.trainer_output)\n\n            assert(len(result) == 2)\n            outputs = result[1]\n            for o in self.trainer_output:\n                updated.append(outputs[o])\n\n        if self.metrics_func is not None:\n            input_dict = {}\n            for argument in self.metrics_func.arguments:\n                if argument in feed_dict:\n                    input_dict[argument] = feed_dict[argument]\n                else:\n                    raise ValueError(\'CNTK backend: metrics argument %s \'\n                                     \'is not found in inputs. Please double \'\n                                     \'check the model and inputs.\' % argument.name)\n            # Some ops (like dropout) won\'t be applied during ""eval"" in cntk.\n            # They only evaluated in training phase. To make it work, call\n            # ""forward"" method to let cntk know we want to evaluate them.from\n            # But the assign ops won\'t be executed under this mode, that\'s why\n            # we need this check.\n            if (self.unrelated_updates is None and\n                    (_LEARNING_PHASE_PLACEHOLDER.value == 1.0 or\n                        _LEARNING_PHASE == 1)):\n                _, output_values = self.metrics_func.forward(\n                    input_dict,\n                    self.metrics_func.outputs,\n                    (self.metrics_func.outputs[0],),\n                    as_numpy=False)\n            else:\n                output_values = self.metrics_func.eval(input_dict, as_numpy=False)\n            if isinstance(output_values, dict):\n                for o in self.metrics_outputs:\n                    value = output_values[o]\n                    v = value.asarray()\n                    updated.append(v)\n            else:\n                v = output_values.asarray()\n                for o in self.metrics_outputs:\n                    updated.append(v)\n\n        if self.unrelated_updates is not None:\n            input_dict = {}\n            for argument in self.unrelated_updates.arguments:\n                if argument in feed_dict:\n                    input_dict[argument] = feed_dict[argument]\n                else:\n                    raise ValueError(\n                        \'CNTK backend: assign ops argument %s \'\n                        \'is not found in inputs. Please double \'\n                        \'check the model and inputs.\' % argument.name)\n            self.unrelated_updates.eval(input_dict, as_numpy=False)\n        return updated\n\n\ndef function(inputs, outputs, updates=[], **kwargs):\n    return Function(inputs, outputs, updates=updates, **kwargs)\n\n\ndef temporal_padding(x, padding=(1, 1)):\n    assert len(padding) == 2\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    assert len(x.shape) == 3 - (1 if num_dynamic_axis > 0 else 0)\n    return pad(x, [padding], \'channels_last\', num_dynamic_axis)\n\n\ndef _padding(x, pattern, axis):  # pragma: no cover\n    base_shape = x.shape\n    if b_any([dim < 0 for dim in base_shape]):\n        raise ValueError(\'CNTK Backend: padding input tensor with \'\n                         \'shape `%s` contains non-specified dimension, \'\n                         \'which is not supported. Please give fixed \'\n                         \'dimension to enable padding.\' % base_shape)\n    if pattern[0] > 0:\n        prefix_shape = list(base_shape)\n        prefix_shape[axis] = pattern[0]\n        prefix_shape = tuple(prefix_shape)\n        x = C.splice(C.constant(value=0, shape=prefix_shape), x, axis=axis)\n        base_shape = x.shape\n    if pattern[1] > 0:\n        postfix_shape = list(base_shape)\n        postfix_shape[axis] = pattern[1]\n        postfix_shape = tuple(postfix_shape)\n        x = C.splice(x, C.constant(value=0, shape=postfix_shape), axis=axis)\n    return x\n\n\ndef pad(x, pad_info, data_format, num_dynamic_axis):\n    if hasattr(C, \'pad\'):\n        pattern = [list(p) for p in pad_info]\n        if data_format == \'channels_first\':\n            pattern = [[0, 0]] + pattern\n        else:\n            pattern = pattern + [[0, 0]]\n        if num_dynamic_axis == 0:\n            pattern = [[0, 0]] + pattern\n        return C.pad(x, pattern=pattern)\n    else:  # pragma: no cover\n        for (a, p) in enumerate(pad_info):\n            x = _padding(x, p,\n                         a + (1 if num_dynamic_axis == 0 else 0) +\n                         (1 if data_format == \'channels_first\' else 0))\n        return x\n\n\ndef spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    data_format = normalize_data_format(data_format)\n\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    assert len(x.shape) == 4 - (1 if num_dynamic_axis > 0 else 0)\n    return pad(x, padding, data_format, num_dynamic_axis)\n\n\ndef spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    data_format = normalize_data_format(data_format)\n\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    assert len(x.shape) == 5 - (1 if num_dynamic_axis > 0 else 0)\n    return pad(x, padding, data_format, num_dynamic_axis)\n\n\ndef one_hot(indices, num_classes):\n    return C.one_hot(indices, num_classes)\n\n\ndef get_value(x):\n    if isinstance(\n            x,\n            (C.variables.Parameter, C.variables.Constant)):\n        return x.value\n    else:\n        return eval(x)\n\n\ndef batch_get_value(xs):\n    result = [get_value(x) for x in xs]\n\n    return result\n\n\ndef set_value(x, value):\n    if (isinstance(x, C.variables.Parameter) or\n       isinstance(x, C.variables.Constant)):\n        if isinstance(value, (float, int)):\n            value = np.full(x.shape, value, dtype=floatx())\n        x.value = value\n    else:\n        raise NotImplementedError\n\n\ndef print_tensor(x, message=\'\'):\n    return C.user_function(\n        LambdaFunc(x,\n                   when=lambda x: True,\n                   execute=lambda x: print(message)))\n\n\ndef batch_set_value(tuples):\n    for t in tuples:\n        x = t[0]\n        value = t[1]\n        if isinstance(value, np.ndarray) is False:\n            value = np.asarray(value)\n        if isinstance(x, C.variables.Parameter):\n            x.value = value\n        else:\n            raise NotImplementedError\n\n\ndef stop_gradient(variables):\n    if isinstance(variables, (list, tuple)):\n        return map(C.stop_gradient, variables)\n    else:\n        return C.stop_gradient(variables)\n\n\ndef switch(condition, then_expression, else_expression):\n    if callable(then_expression):\n        then_expression = then_expression()\n    if callable(else_expression):\n        else_expression = else_expression()\n    ndim_cond = ndim(condition)\n    ndim_expr = ndim(then_expression)\n    if ndim_cond > ndim_expr:\n        raise ValueError(\'Rank of condition should be less\'\n                         \' than or equal to rank of then and\'\n                         \' else expressions. ndim(condition)=\' +\n                         str(ndim_cond) + \', ndim(then_expression)\'\n                         \'=\' + str(ndim_expr))\n    elif ndim_cond < ndim_expr:\n        shape_expr = int_shape(then_expression)\n        ndim_diff = ndim_expr - ndim_cond\n        for i in range(ndim_diff):\n            condition = expand_dims(condition)\n            condition = tile(condition, shape_expr[ndim_cond + i])\n    return C.element_select(condition,\n                            then_expression,\n                            else_expression)\n\n\ndef elu(x, alpha=1.):\n    res = C.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return C.element_select(C.greater(x, 0), res, alpha * res)\n\n\ndef in_top_k(predictions, targets, k):\n    _targets = C.one_hot(targets, predictions.shape[-1])\n    result = [C.classification_error(predictions[i], _targets[i], topN=k)\n              for i in range(predictions.shape[0])]\n    result = concatenate(result, axis=-1)\n    return 1 - C.reshape(result, shape=(-1,))\n\n\ndef conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding=\'valid\', data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n    strides = (1,) + strides\n    # cntk output_shape does not include batch axis\n    output_shape = output_shape[1:]\n    # in keras2, need handle output shape in different format\n    if data_format == \'channels_last\':\n        output_shape = transpose_shape(output_shape, \'channels_first\',\n                                       spatial_axes=(0, 1))\n\n    dilation_rate = (1,) + dilation_rate\n\n    x = C.convolution_transpose(\n        kernel,\n        x,\n        strides,\n        auto_padding=[\n            False,\n            padding,\n            padding],\n        output_shape=output_shape,\n        dilation=dilation_rate)\n    return _postprocess_conv2d_output(x, data_format)\n\n\ndef identity(x, name=None):\n    if name is None:\n        name = \'%s_alias\' % x.name\n    return C.alias(x, name=name)\n\n\ndef _preprocess_conv2d_input(x, data_format):\n    if data_format == \'channels_last\':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, rows, cols)\n        # TF input shape: (samples, rows, cols, input_depth)\n        x = C.transpose(x, (2, 0, 1))\n    return x\n\n\ndef _preprocess_conv2d_kernel(kernel, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(rows, cols, input_depth, depth)`,\n    # independently of `data_format`.\n    # CNTK expects `(depth, input_depth, rows, cols)`.\n    kernel = C.transpose(kernel, (3, 2, 0, 1))\n    return kernel\n\n\ndef _preprocess_border_mode(padding):\n    if padding == \'same\':\n        padding = True\n    elif padding == \'valid\':\n        padding = False\n    else:\n        raise ValueError(\'Invalid border mode: \' + str(padding))\n    return padding\n\n\ndef _postprocess_conv2d_output(x, data_format):\n    if data_format == \'channels_last\':\n        x = C.transpose(x, (1, 2, 0))\n    return x\n\n\ndef _preprocess_conv3d_input(x, data_format):\n    if data_format == \'channels_last\':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n        # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3,\n        # input_depth)\n        x = C.transpose(x, (3, 0, 1, 2))\n    return x\n\n\ndef _preprocess_conv3d_kernel(kernel, dim_ordering):\n    kernel = C.transpose(kernel, (4, 3, 0, 1, 2))\n    return kernel\n\n\ndef _postprocess_conv3d_output(x, dim_ordering):\n    if dim_ordering == \'channels_last\':\n        x = C.transpose(x, (1, 2, 3, 0))\n    return x\n\n\ndef _get_dynamic_axis_num(x):\n    if hasattr(x, \'dynamic_axes\'):\n        return len(x.dynamic_axes)\n    else:\n        return 0\n\n\ndef _contain_seqence_axis(x):\n    if _get_dynamic_axis_num(x) > 1:\n        return x.dynamic_axes[1] == C.Axis.default_dynamic_axis()\n    else:\n        return False\n\n\ndef get_num_dynamic_axis(x):\n    return _get_dynamic_axis_num(x)\n\n\ndef _reduce_on_axis(x, axis, reduce_fun_name):\n    if isinstance(axis, list):\n        for a in axis:\n            if isinstance(a, C.Axis) \\\n                    and a != C.Axis.default_batch_axis() \\\n                    and hasattr(C.sequence, reduce_fun_name):\n                x = getattr(C.sequence, reduce_fun_name)(x, a)\n            else:\n                x = getattr(C, reduce_fun_name)(x, a)\n    else:\n        x = getattr(C, reduce_fun_name)(x, axis)\n    return x\n\n\ndef _reshape_sequence(x, time_step):\n    tmp_shape = list(int_shape(x))\n    tmp_shape[1] = time_step\n    return reshape(x, tmp_shape)\n\n\ndef local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = py_slice(i * stride,\n                                i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (-1, 1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=1)\n    # transpose kernel to output_filters first, to apply broadcast\n    weight = permute_dimensions(kernel, (2, 0, 1))\n    # Shape: (batch, filters, output_length, input_length * kernel_size)\n    output = x_aggregate * weight\n    # Shape: (batch, filters, output_length)\n    output = sum(output, axis=3)\n    # Shape: (batch, output_length, filters)\n    return permute_dimensions(output, (0, 2, 1))\n\n\ndef local_conv2d(inputs,\n                 kernel,\n                 kernel_size,\n                 strides,\n                 output_shape,\n                 data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n    xs = []\n\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = py_slice(i * stride_row,\n                                 i * stride_row + kernel_size[0])\n            slice_col = py_slice(j * stride_col,\n                                 j * stride_col + kernel_size[1])\n            if data_format == \'channels_first\':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (-1, 1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (-1, 1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=1)\n    # transpose kernel to put filters first\n    weight = permute_dimensions(kernel, (2, 0, 1))\n    # shape: batch, filters, output_length, input_length * kernel_size\n    output = x_aggregate * weight\n    # shape: batch, filters, output_length\n    output = sum(output, axis=3)\n    # shape: batch, filters, row, col\n    output = reshape(output,\n                     (-1, filters, output_row, output_col))\n\n    if data_format == \'channels_last\':\n        # shape: batch, row, col, filters\n        output = permute_dimensions(output, (0, 2, 3, 1))\n\n    return output\n\n\ndef reverse(x, axes):\n    if isinstance(axes, int):\n        axes = [axes]\n    cntk_axes = _normalize_axis(axes, x)\n    begin_index = [0 for _ in cntk_axes]\n    end_index = [0 for _ in cntk_axes]\n    strides = [-1 for _ in cntk_axes]\n    return C.slice(x, cntk_axes, begin_index, end_index, strides)\n\n\ndef slice(x, start, size):\n    if not (len(int_shape(x)) == len(start) == len(size)):\n        raise ValueError(\'The dimension and the size of indices should match.\')\n    out = x[tuple([py_slice(i, i + j) for (i, j) in zip(start, size)])]\n    out._keras_shape = tuple(size)\n    return out\n\n\ndef _reshape_batch(x, shape):\n    # there is a bug in cntk 2.1\'s unpack_batch implementation\n    if hasattr(C, \'unpack_batch\') and _get_cntk_version() >= 2.2:\n        const_a = C.unpack_batch(x)\n        const_a = C.reshape(const_a, shape)\n        return C.to_batch(const_a)\n    else:\n        return C.user_function(ReshapeBatch(x, shape[1:]))\n\n\ndef _get_cntk_version():\n    version = C.__version__\n    if version.endswith(\'+\'):\n        version = version[:-1]\n    # for hot fix, ignore all the . except the first one.\n    if len(version) > 2 and version[1] == \'.\':\n        version = version[:2] + version[2:].replace(\'.\', \'\')\n    try:\n        return float(version)\n    except:\n        warnings.warn(\n            \'CNTK backend warning: CNTK version not detected. \'\n            \'Will using CNTK 2.0 GA as default.\')\n        return float(2.0)\n\n\nclass ReshapeBatch(C.ops.functions.UserFunction):\n    def __init__(self, input, shape, name=\'reshape_with_batch\'):\n        super(ReshapeBatch, self).__init__([input], as_numpy=False, name=name)\n        self.from_shape = input.shape\n        self.target_shape = shape\n\n    def infer_outputs(self):\n        batch_axis = C.Axis.default_batch_axis()\n        return [\n            C.output_variable(\n                self.target_shape,\n                self.inputs[0].dtype,\n                [batch_axis])]\n\n    def forward(self, arguments, device=None, outputs_to_retain=None):\n        num_element = arguments.shape()[0] * np.prod(np.asarray(self.from_shape))\n        num_static_element = np.prod(np.asarray(self.target_shape))\n        num_batch = int(num_element / num_static_element)\n        result = arguments.data().as_shape((num_batch,) + self.target_shape)\n        return None, C.cntk_py.Value(result)\n\n    def backward(self, state, root_gradients):\n        grad_array_view = root_gradients.data()\n        num_element = root_gradients.shape()[0] * np.prod(\n            np.asarray(self.target_shape))\n        num_static_element = np.prod(np.asarray(self.from_shape))\n        num_old_batch = int(num_element / num_static_element)\n        return C.cntk_py.Value(\n            grad_array_view.as_shape(\n                (num_old_batch,) + self.from_shape))\n\n\nclass ConvertToBatch(C.ops.functions.UserFunction):\n    """"""Converts input first axis to CNTK batch axis.\n\n    We may introduce this operation in CNTK native\n    implementation later.\n\n    # Arguments\n        inputs: a cntk variable (parameter/constant)\n        name: name of this node\n    """"""\n\n    def __init__(self, input, name=\'convert_to_batch\'):\n        super(ConvertToBatch, self).__init__([input], as_numpy=False, name=name)\n\n    def infer_outputs(self):\n        batch_axis = C.Axis.default_batch_axis()\n        return [\n            C.output_variable(\n                self.inputs[0].shape[1:],\n                self.inputs[0].dtype,\n                [batch_axis])]\n\n    def forward(self, arguments, device=None, outputs_to_retain=None):\n        return None, C.cntk_py.Value(arguments.data())\n\n    def backward(self, state, root_gradients):\n        return C.cntk_py.Value(root_gradients.data())\n\n\nclass ConvertToStatic(C.ops.functions.UserFunction):\n    """"""Converts input first axis to CNTK static axis.\n\n    We may introduce this operation in CNTK native\n    implementation later.\n\n    # Arguments\n        inputs: a cntk tensor which has batch axis\n        batch_size: size of batch axis.\n        name: name of this node.\n    """"""\n\n    def __init__(self, input, batch_size, name=\'convert_to_static\'):\n        super(ConvertToStatic, self).__init__([input], as_numpy=False, name=name)\n        self.target_shape = (batch_size,) + input.shape\n\n    def infer_outputs(self):\n        return [\n            C.output_variable(\n                self.target_shape,\n                self.inputs[0].dtype,\n                [])]\n\n    def forward(self, arguments, device=None, outputs_to_retain=None):\n        return None, C.cntk_py.Value(arguments.data())\n\n    def backward(self, state, root_gradients):\n        return C.cntk_py.Value(root_gradients.data())\n\n\nclass LambdaFunc(C.ops.functions.UserFunction):\n    def __init__(self,\n                 arg,\n                 when=lambda arg: True,\n                 execute=lambda arg: print(arg),\n                 name=\'\'):\n        self.when = when\n        self.execute = execute\n\n        super(LambdaFunc, self).__init__([arg], name=name)\n\n    def infer_outputs(self):\n        return [\n            C.output_variable(\n                self.inputs[0].shape,\n                self.inputs[0].dtype,\n                self.inputs[0].dynamic_axes)]\n\n    def forward(self, argument, device=None, outputs_to_retain=None):\n        if self.when(argument):\n            self.execute(argument)\n\n        return None, argument\n\n    def backward(self, state, root_gradients):\n        return root_gradients\n\n\ndef reset_uids():\n    global _UID_PREFIXES\n    _UID_PREFIXES = defaultdict(int)\n\n\ndef to_dense(tensor):\n    raise NotImplementedError\n\n\ndef cumsum(x, axis=0):\n    dim = x.shape[axis]\n    U = C.constant(np.triu(np.ones((dim, dim))).astype(x.dtype))\n    if axis != -1:\n        x = C.swapaxes(x, -1, axis)\n    out = C.times(x, U)\n    if axis != -1:\n        out = C.swapaxes(out, -1, axis)\n    return out\n\n\ndef cumprod(x, axis=0):\n    shape = x.shape\n    out = x\n    for rep in range(shape[axis] - 1):\n        sliced_shape = list(shape)\n        sliced_shape[axis] = rep + 1\n        if axis == 0:\n            _x = x[rep:(rep + 1)]\n        elif axis == 1:\n            _x = x[:, rep:(rep + 1)]\n        elif axis == 2:\n            _x = x[:, :, rep:(rep + 1)]\n        y = concatenate([ones(sliced_shape, dtype=x.dtype),\n                         repeat_elements(_x, rep=shape[axis] - 1 - rep, axis=axis)],\n                        axis=axis)\n        out = C.element_times(out, y)\n    return out\n\n\ndef arange(start, stop=None, step=1, dtype=\'int32\'):\n    raise NotImplementedError\n\n\ndef ctc_label_dense_to_sparse(labels, label_lengths):\n    raise NotImplementedError\n\n\ndef ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    raise NotImplementedError\n\n\ndef ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1,\n               merge_repeated=False):\n    raise NotImplementedError\n\n\ndef map_fn(fn, elems, name=None, dtype=None):\n    raise NotImplementedError\n\n\ndef foldl(fn, elems, initializer=None, name=None):\n    """"""Reduce `elems` by `fn` combined them from left to right on dimension 0.\n\n    # Arguments\n        fn: Callable that will be called upon each element in `elems`\n            (and on the optional `initializer`) passed as a second argument.\n            The first argument passed to `fn` is the accumulator which is the\n            accumulated value calculated from the preceding invocation of `fn`.\n            Example For `fn`:\n            ```python\n            lambda acc, x: acc + x\n            ```\n        elems: Tensor\n        initializer: (optional) Tensor, the initial value for the accumulator.\n            In case of None value is provided during the call\n            the first value is used (`elems[0]`) as `initializer` from `elems`\n        name: (optional) String, name for the foldl node in the graph.\n\n    # Returns\n        Same type and shape as `initializer`\n\n    # Raises:\n        TypeError: if `fn` is not callable.\n        TypeError: if `initializer` is neither a tensor nor None value.\n        TypeError: if `elems` is not a tensor.\n    """"""\n    if not callable(fn):\n        raise TypeError(""`fn` must be callable."")\n    if initializer is not None and not is_tensor(initializer):\n        raise TypeError(""`initializer` must be a tensor or None"")\n    if not is_tensor(elems):\n        raise TypeError(\'`elems` must be a tensor\')\n\n    if initializer is None and shape(elems)[0] > 1:\n        initializer = elems[0]\n        elems = elems[1:]\n    elif initializer is None:\n        initializer = elems[0]\n        elems = None\n\n    accumulator = initializer\n    if elems is not None:\n        for i in range(shape(elems)[0]):\n            accumulator = fn(accumulator, elems[i])\n\n    if name is not None:\n        accumulator.name = str(name)\n\n    return reshape(accumulator, shape(initializer)[1:])\n\n\ndef foldr(fn, elems, initializer=None, name=None):\n    """"""Reduce `elems` by `fn` combined them from right to left on dimension 0.\n\n    # Arguments\n        fn: Callable that will be called upon each element in `elems`\n            (and on the optional `initializer`) passed as a second argument.\n            The first argument passed to `fn` is the accumulator which is the\n            accumulated value calculated from the preceding invocation of `fn`.\n            Example For `fn`:\n            ```python\n            lambda acc, x: acc + x\n            ```\n        elems: Tensor\n        initializer: (optional) Tensor, the initial value for the accumulator.\n            In case of None value is provided during the call\n            the last value is used (`elems[-1]`) as `initializer` from `elems`\n        name: (optional) String, name for the foldr node in the graph.\n\n    # Returns\n        Same type and shape as `initializer`\n\n    # Raises:\n        TypeError: if `fn` is not callable.\n        TypeError: if `initializer` is neither a tensor nor None value.\n        TypeError: if `elems` is not a tensor.\n    """"""\n    if not callable(fn):\n        raise TypeError(""`fn` must be callable."")\n    if initializer is not None and not is_tensor(initializer):\n        raise TypeError(""`initializer` must be a tensor or None"")\n    if not is_tensor(elems):\n        raise TypeError(\'`elems` must be a tensor\')\n\n    if initializer is None and shape(elems)[0] > 1:\n        initializer = elems[-1]\n        elems = elems[:-1]\n    elif initializer is None:\n        initializer = elems[0]\n        elems = None\n\n    accumulator = initializer\n    if elems is not None:\n        for i in range(shape(elems)[0]):\n            accumulator = fn(accumulator, elems[-i])\n\n    if name is not None:\n        accumulator.name = str(name)\n\n    return reshape(accumulator, shape(initializer)[1:])\n\n\ndef control_dependencies(control_inputs):\n    @contextmanager\n    def nullcontextmanager():\n        yield\n\n    return nullcontextmanager()\n'"
keras/backend/common.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\n# the type of float to use throughout the session.\n_FLOATX = \'float32\'\n_EPSILON = 1e-7\n_IMAGE_DATA_FORMAT = \'channels_last\'\n\n\ndef epsilon():\n    """"""Returns the value of the fuzz factor used in numeric expressions.\n\n    # Returns\n        A float.\n\n    # Example\n    ```python\n        >>> keras.backend.epsilon()\n        1e-07\n    ```\n    """"""\n    return _EPSILON\n\n\ndef set_epsilon(e):\n    """"""Sets the value of the fuzz factor used in numeric expressions.\n\n    # Arguments\n        e: float. New value of epsilon.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.epsilon()\n        1e-07\n        >>> K.set_epsilon(1e-05)\n        >>> K.epsilon()\n        1e-05\n    ```\n    """"""\n\n    global _EPSILON\n    _EPSILON = float(e)\n\n\ndef floatx():\n    """"""Returns the default float type, as a string.\n    (e.g. \'float16\', \'float32\', \'float64\').\n\n    # Returns\n        String, the current default float type.\n\n    # Example\n    ```python\n        >>> keras.backend.floatx()\n        \'float32\'\n    ```\n    """"""\n    return _FLOATX\n\n\ndef set_floatx(floatx):\n    """"""Sets the default float type.\n\n    # Arguments\n        floatx: String, \'float16\', \'float32\', or \'float64\'.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        \'float32\'\n        >>> K.set_floatx(\'float16\')\n        >>> K.floatx()\n        \'float16\'\n    ```\n    """"""\n    global _FLOATX\n    if floatx not in {\'float16\', \'float32\', \'float64\'}:\n        raise ValueError(\'Unknown floatx type: \' + str(floatx))\n    _FLOATX = str(floatx)\n\n\ndef cast_to_floatx(x):\n    """"""Cast a Numpy array to the default Keras float type.\n\n    # Arguments\n        x: Numpy array.\n\n    # Returns\n        The same Numpy array, cast to its new type.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        \'float32\'\n        >>> arr = numpy.array([1.0, 2.0], dtype=\'float64\')\n        >>> arr.dtype\n        dtype(\'float64\')\n        >>> new_arr = K.cast_to_floatx(arr)\n        >>> new_arr\n        array([ 1.,  2.], dtype=float32)\n        >>> new_arr.dtype\n        dtype(\'float32\')\n    ```\n    """"""\n    return np.asarray(x, dtype=_FLOATX)\n\n\ndef image_data_format():\n    """"""Returns the default image data format convention.\n\n    # Returns\n        A string, either `\'channels_first\'` or `\'channels_last\'`\n\n    # Example\n    ```python\n        >>> keras.backend.image_data_format()\n        \'channels_first\'\n    ```\n    """"""\n    return _IMAGE_DATA_FORMAT\n\n\ndef set_image_data_format(data_format):\n    """"""Sets the value of the data format convention.\n\n    # Arguments\n        data_format: string. `\'channels_first\'` or `\'channels_last\'`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.image_data_format()\n        \'channels_first\'\n        >>> K.set_image_data_format(\'channels_last\')\n        >>> K.image_data_format()\n        \'channels_last\'\n    ```\n    """"""\n    global _IMAGE_DATA_FORMAT\n    if data_format not in {\'channels_last\', \'channels_first\'}:\n        raise ValueError(\'Unknown data_format:\', data_format)\n    _IMAGE_DATA_FORMAT = str(data_format)\n\n\ndef normalize_data_format(value):\n    """"""Checks that the value correspond to a valid data format.\n\n    # Arguments\n        value: String or None. `\'channels_first\'` or `\'channels_last\'`.\n\n    # Returns\n        A string, either `\'channels_first\'` or `\'channels_last\'`\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.normalize_data_format(None)\n        \'channels_first\'\n        >>> K.normalize_data_format(\'channels_last\')\n        \'channels_last\'\n    ```\n\n    # Raises\n        ValueError: if `value` or the global `data_format` invalid.\n    """"""\n    if value is None:\n        value = image_data_format()\n    data_format = value.lower()\n    if data_format not in {\'channels_first\', \'channels_last\'}:\n        raise ValueError(\'The `data_format` argument must be one of \'\n                         \'""channels_first"", ""channels_last"". Received: \' +\n                         str(value))\n    return data_format\n\n\ndef symbolic(func):\n    """"""Dummy decorator used in TensorFlow 2.0 to enter the Keras graph.""""""\n    return func\n\n\ndef eager(func):\n    """"""Dummy decorator used in TensorFlow 2.0 to exit the Keras graph.""""""\n    return func\n\n\n# Legacy methods\n\ndef set_image_dim_ordering(dim_ordering):\n    """"""Legacy setter for `image_data_format`.\n\n    # Arguments\n        dim_ordering: string. `tf` or `th`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.image_data_format()\n        \'channels_first\'\n        >>> K.set_image_data_format(\'channels_last\')\n        >>> K.image_data_format()\n        \'channels_last\'\n    ```\n\n    # Raises\n        ValueError: if `dim_ordering` is invalid.\n    """"""\n    global _IMAGE_DATA_FORMAT\n    if dim_ordering not in {\'tf\', \'th\'}:\n        raise ValueError(\'Unknown dim_ordering:\', dim_ordering)\n    if dim_ordering == \'th\':\n        data_format = \'channels_first\'\n    else:\n        data_format = \'channels_last\'\n    _IMAGE_DATA_FORMAT = data_format\n\n\ndef image_dim_ordering():\n    """"""Legacy getter for `image_data_format`.\n\n    # Returns\n        string, one of `\'th\'`, `\'tf\'`\n    """"""\n    if _IMAGE_DATA_FORMAT == \'channels_first\':\n        return \'th\'\n    else:\n        return \'tf\'\n'"
keras/backend/load_backend.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\nimport os\nimport json\nimport sys\nimport importlib\nfrom .common import epsilon\nfrom .common import floatx\nfrom .common import set_epsilon\nfrom .common import set_floatx\nfrom .common import cast_to_floatx\nfrom .common import image_data_format\nfrom .common import set_image_data_format\nfrom .common import normalize_data_format\nfrom .common import symbolic, eager\n\n# Set Keras base dir path given KERAS_HOME env variable, if applicable.\n# Otherwise either ~/.keras or /tmp.\nif \'KERAS_HOME\' in os.environ:\n    _keras_dir = os.environ.get(\'KERAS_HOME\')\nelse:\n    _keras_base_dir = os.path.expanduser(\'~\')\n    if not os.access(_keras_base_dir, os.W_OK):\n        _keras_base_dir = \'/tmp\'\n    _keras_dir = os.path.join(_keras_base_dir, \'.keras\')\n\n# Default backend: TensorFlow.\n_BACKEND = \'tensorflow\'\n\n# Attempt to read Keras config file.\n_config_path = os.path.expanduser(os.path.join(_keras_dir, \'keras.json\'))\nif os.path.exists(_config_path):\n    try:\n        with open(_config_path) as f:\n            _config = json.load(f)\n    except ValueError:\n        _config = {}\n    _floatx = _config.get(\'floatx\', floatx())\n    assert _floatx in {\'float16\', \'float32\', \'float64\'}\n    _epsilon = _config.get(\'epsilon\', epsilon())\n    assert isinstance(_epsilon, float)\n    _backend = _config.get(\'backend\', _BACKEND)\n    _image_data_format = _config.get(\'image_data_format\',\n                                     image_data_format())\n    assert _image_data_format in {\'channels_last\', \'channels_first\'}\n\n    set_floatx(_floatx)\n    set_epsilon(_epsilon)\n    set_image_data_format(_image_data_format)\n    _BACKEND = _backend\n\n# Save config file, if possible.\nif not os.path.exists(_keras_dir):\n    try:\n        os.makedirs(_keras_dir)\n    except OSError:\n        # Except permission denied and potential race conditions\n        # in multi-threaded environments.\n        pass\n\nif not os.path.exists(_config_path):\n    _config = {\n        \'floatx\': floatx(),\n        \'epsilon\': epsilon(),\n        \'backend\': _BACKEND,\n        \'image_data_format\': image_data_format()\n    }\n    try:\n        with open(_config_path, \'w\') as f:\n            f.write(json.dumps(_config, indent=4))\n    except IOError:\n        # Except permission denied.\n        pass\n\n# Set backend based on KERAS_BACKEND flag, if applicable.\nif \'KERAS_BACKEND\' in os.environ:\n    _backend = os.environ[\'KERAS_BACKEND\']\n    if _backend:\n        _BACKEND = _backend\n\n# Import backend functions.\nif _BACKEND == \'cntk\':\n    sys.stderr.write(\'Using CNTK backend\\n\')\n    from .cntk_backend import *\nelif _BACKEND == \'theano\':\n    sys.stderr.write(\'Using Theano backend.\\n\')\n    from .theano_backend import *\nelif _BACKEND == \'tensorflow\':\n    sys.stderr.write(\'Using TensorFlow backend.\\n\')\n    from .tensorflow_backend import *\nelse:\n    # Try and load external backend.\n    try:\n        backend_module = importlib.import_module(_BACKEND)\n        entries = backend_module.__dict__\n        # Check if valid backend.\n        # Module is a valid backend if it has the required entries.\n        required_entries = [\'placeholder\', \'variable\', \'function\']\n        for e in required_entries:\n            if e not in entries:\n                raise ValueError(\'Invalid backend. Missing required entry : \' + e)\n        namespace = globals()\n        for k, v in entries.items():\n            # Make sure we don\'t override any entries from common, such as epsilon.\n            if k not in namespace:\n                namespace[k] = v\n        sys.stderr.write(\'Using \' + _BACKEND + \' backend.\\n\')\n    except ImportError:\n        raise ValueError(\'Unable to import backend : \' + str(_BACKEND))\n\n\ndef backend():\n    """"""Returns the name of the current backend (e.g. ""tensorflow"").\n\n    # Returns\n        String, the name of the backend Keras is currently using.\n\n    # Example\n    ```python\n        >>> keras.backend.backend()\n        \'tensorflow\'\n    ```\n    """"""\n    return _BACKEND\n'"
keras/backend/numpy_backend.py,0,"b'""""""Utilities for backend functionality checks.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport scipy.signal as signal\nimport scipy as sp\nfrom .common import floatx\nfrom keras.utils.generic_utils import transpose_shape\nfrom keras.utils import to_categorical\n\n\ndef normalize_conv(func):\n    def wrapper(*args, **kwargs):\n        x = args[0]\n        w = args[1]\n        if x.ndim == 3:\n            w = np.flipud(w)\n            w = np.transpose(w, (1, 2, 0))\n            if kwargs[\'data_format\'] == \'channels_last\':\n                x = np.transpose(x, (0, 2, 1))\n        elif x.ndim == 4:\n            w = np.fliplr(np.flipud(w))\n            w = np.transpose(w, (2, 3, 0, 1))\n            if kwargs[\'data_format\'] == \'channels_last\':\n                x = np.transpose(x, (0, 3, 1, 2))\n        else:\n            w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n            w = np.transpose(w, (3, 4, 0, 1, 2))\n            if kwargs[\'data_format\'] == \'channels_last\':\n                x = np.transpose(x, (0, 4, 1, 2, 3))\n\n        dilation_rate = kwargs.pop(\'dilation_rate\', 1)\n        if isinstance(dilation_rate, int):\n            dilation_rate = (dilation_rate,) * (x.ndim - 2)\n        for (i, d) in enumerate(dilation_rate):\n            if d > 1:\n                for j in range(w.shape[2 + i] - 1):\n                    w = np.insert(w, 2 * j + 1, 0, axis=2 + i)\n\n        y = func(x, w, **kwargs)\n\n        if kwargs[\'data_format\'] == \'channels_last\':\n            if y.ndim == 3:\n                y = np.transpose(y, (0, 2, 1))\n            elif y.ndim == 4:\n                y = np.transpose(y, (0, 2, 3, 1))\n            else:\n                y = np.transpose(y, (0, 2, 3, 4, 1))\n\n        return y\n\n    return wrapper\n\n\n@normalize_conv\ndef conv(x, w, padding, data_format):\n    y = []\n    for i in range(x.shape[0]):\n        _y = []\n        for j in range(w.shape[1]):\n            __y = []\n            for k in range(w.shape[0]):\n                __y.append(signal.convolve(x[i, k], w[k, j], mode=padding))\n            _y.append(np.sum(np.stack(__y, axis=-1), axis=-1))\n        y.append(_y)\n    y = np.array(y)\n    return y\n\n\n@normalize_conv\ndef depthwise_conv(x, w, padding, data_format):\n    y = []\n    for i in range(x.shape[0]):\n        _y = []\n        for j in range(w.shape[0]):\n            __y = []\n            for k in range(w.shape[1]):\n                __y.append(signal.convolve(x[i, j], w[j, k], mode=padding))\n            _y.append(np.stack(__y, axis=0))\n        y.append(np.concatenate(_y, axis=0))\n    y = np.array(y)\n    return y\n\n\ndef separable_conv(x, w1, w2, padding, data_format):\n    x2 = depthwise_conv(x, w1, padding=padding, data_format=data_format)\n    return conv(x2, w2, padding=padding, data_format=data_format)\n\n\ndef conv_transpose(x, w, output_shape, padding, data_format, dilation_rate=1):\n    if x.ndim == 4:\n        w = np.fliplr(np.flipud(w))\n        w = np.transpose(w, (0, 1, 3, 2))\n    else:\n        w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n        w = np.transpose(w, (0, 1, 2, 4, 3))\n\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,) * (x.ndim - 2)\n    for (i, d) in enumerate(dilation_rate):\n        if d > 1:\n            for j in range(w.shape[i] - 1):\n                w = np.insert(w, 2 * j + 1, 0, axis=i)\n\n    return conv(x, w, padding=padding, data_format=data_format)\n\n\nconv1d = conv\nconv2d = conv\nconv3d = conv\ndepthwise_conv2d = depthwise_conv\nseparable_conv1d = separable_conv\nseparable_conv2d = separable_conv\nconv2d_transpose = conv_transpose\nconv3d_transpose = conv_transpose\n\n\ndef pool(x, pool_size, strides, padding, data_format, pool_mode):\n    if data_format == \'channels_last\':\n        if x.ndim == 3:\n            x = np.transpose(x, (0, 2, 1))\n        elif x.ndim == 4:\n            x = np.transpose(x, (0, 3, 1, 2))\n        else:\n            x = np.transpose(x, (0, 4, 1, 2, 3))\n\n    if padding == \'same\':\n        pad = [(0, 0), (0, 0)] + [(s // 2, s // 2) for s in pool_size]\n        x = np.pad(x, pad, \'constant\', constant_values=-np.inf)\n\n    # indexing trick\n    x = np.pad(x, [(0, 0), (0, 0)] + [(0, 1) for _ in pool_size],\n               \'constant\', constant_values=0)\n\n    if x.ndim == 3:\n        y = [x[:, :, k:k1:strides[0]]\n             for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0))]\n    elif x.ndim == 4:\n        y = []\n        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                y.append(x[:, :, k:k1:strides[0], l:l1:strides[1]])\n    else:\n        y = []\n        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                for (m, m1) in zip(range(pool_size[2]), range(-pool_size[2], 0)):\n                    y.append(x[:,\n                               :,\n                               k:k1:strides[0],\n                               l:l1:strides[1],\n                               m:m1:strides[2]])\n    y = np.stack(y, axis=-1)\n    if pool_mode == \'avg\':\n        y = np.mean(np.ma.masked_invalid(y), axis=-1).data\n    elif pool_mode == \'max\':\n        y = np.max(y, axis=-1)\n\n    if data_format == \'channels_last\':\n        if y.ndim == 3:\n            y = np.transpose(y, (0, 2, 1))\n        elif y.ndim == 4:\n            y = np.transpose(y, (0, 2, 3, 1))\n        else:\n            y = np.transpose(y, (0, 2, 3, 4, 1))\n\n    return y\n\n\npool2d = pool\npool3d = pool\n\n\ndef bias_add(x, y, data_format):\n    if data_format == \'channels_first\':\n        if y.ndim > 1:\n            y = np.reshape(y, y.shape[::-1])\n        for _ in range(x.ndim - y.ndim - 1):\n            y = np.expand_dims(y, -1)\n    else:\n        for _ in range(x.ndim - y.ndim - 1):\n            y = np.expand_dims(y, 0)\n    return x + y\n\n\ndef rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n\n    if constants is None:\n        constants = []\n\n    output_sample, _ = step_function(inputs[:, 0], initial_states + constants)\n    if mask is not None:\n        if mask.dtype != np.bool:\n            mask = mask.astype(np.bool)\n        if mask.shape != inputs.shape[:2]:\n            raise ValueError(\n                \'mask should have `shape=(samples, time)`, \'\n                \'got {}\'.format(mask.shape))\n\n        def expand_mask(mask_, x):\n            # expand mask so that `mask[:, t].ndim == x.ndim`\n            while mask_.ndim < x.ndim + 1:\n                mask_ = np.expand_dims(mask_, axis=-1)\n            return mask_\n        output_mask = expand_mask(mask, output_sample)\n        states_masks = [expand_mask(mask, state) for state in initial_states]\n\n    if input_length is None:\n        input_length = inputs.shape[1]\n    assert input_length == inputs.shape[1]\n    time_index = range(input_length)\n    if go_backwards:\n        time_index = time_index[::-1]\n\n    outputs = []\n    states_tm1 = initial_states  # tm1 means ""t minus one"" as in ""previous timestep""\n    output_tm1 = np.zeros(output_sample.shape)\n    for t in time_index:\n        output_t, states_t = step_function(inputs[:, t], states_tm1 + constants)\n        if mask is not None:\n            output_t = np.where(output_mask[:, t], output_t, output_tm1)\n            states_t = [np.where(state_mask[:, t], state_t, state_tm1)\n                        for state_mask, state_t, state_tm1\n                        in zip(states_masks, states_t, states_tm1)]\n        outputs.append(output_t)\n        states_tm1 = states_t\n        output_tm1 = output_t\n\n    return outputs[-1], np.stack(outputs, axis=1), states_tm1\n\n\n_LEARNING_PHASE = True\n\n\ndef learning_phase():\n    return _LEARNING_PHASE\n\n\ndef set_learning_phase(value):\n    global _LEARNING_PHASE\n    _LEARNING_PHASE = value\n\n\ndef in_train_phase(x, alt, training=None):\n    if training is None:\n        training = learning_phase()\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n    else:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n\ndef in_test_phase(x, alt, training=None):\n    return in_train_phase(alt, x, training=training)\n\n\ndef relu(x, alpha=0., max_value=None, threshold=0.):\n    if max_value is None:\n        max_value = np.inf\n    above_threshold = x * (x >= threshold)\n    above_threshold = np.clip(above_threshold, 0.0, max_value)\n    below_threshold = alpha * (x - threshold) * (x < threshold)\n    return below_threshold + above_threshold\n\n\ndef switch(condition, then_expression, else_expression):\n    cond_float = condition.astype(floatx())\n    while cond_float.ndim < then_expression.ndim:\n        cond_float = cond_float[..., np.newaxis]\n    return cond_float * then_expression + (1 - cond_float) * else_expression\n\n\ndef softplus(x):\n    return np.log(1. + np.exp(x))\n\n\ndef softsign(x):\n    return x / (1 + np.abs(x))\n\n\ndef elu(x, alpha=1.):\n    return x * (x > 0) + alpha * (np.exp(x) - 1.) * (x < 0)\n\n\ndef sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n\n\ndef hard_sigmoid(x):\n    y = 0.2 * x + 0.5\n    return np.clip(y, 0, 1)\n\n\ndef tanh(x):\n    return np.tanh(x)\n\n\ndef softmax(x, axis=-1):\n    y = np.exp(x - np.max(x, axis, keepdims=True))\n    return y / np.sum(y, axis, keepdims=True)\n\n\ndef l2_normalize(x, axis=-1):\n    y = np.max(np.sum(x ** 2, axis, keepdims=True), axis, keepdims=True)\n    return x / np.sqrt(y)\n\n\ndef in_top_k(predictions, targets, k):\n    top_k = np.argsort(-predictions)[:, :k]\n    targets = targets.reshape(-1, 1)\n    return np.any(targets == top_k, axis=-1)\n\n\ndef binary_crossentropy(target, output, from_logits=False):\n    if not from_logits:\n        output = np.clip(output, 1e-7, 1 - 1e-7)\n        output = np.log(output / (1 - output))\n    return (target * -np.log(sigmoid(output)) +\n            (1 - target) * -np.log(1 - sigmoid(output)))\n\n\ndef categorical_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = softmax(output)\n    else:\n        output /= output.sum(axis=-1, keepdims=True)\n    output = np.clip(output, 1e-7, 1 - 1e-7)\n    return np.sum(target * -np.log(output), axis=-1, keepdims=False)\n\n\ndef max(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.max(x, axis=axis, keepdims=keepdims)\n\n\ndef min(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.min(x, axis=axis, keepdims=keepdims)\n\n\ndef mean(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.mean(x, axis=axis, keepdims=keepdims)\n\n\ndef var(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.var(x, axis=axis, keepdims=keepdims)\n\n\ndef std(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.std(x, axis=axis, keepdims=keepdims)\n\n\ndef logsumexp(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return sp.special.logsumexp(x, axis=axis, keepdims=keepdims)\n\n\ndef sum(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.sum(x, axis=axis, keepdims=keepdims)\n\n\ndef prod(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.prod(x, axis=axis, keepdims=keepdims)\n\n\ndef cumsum(x, axis=0):\n    return np.cumsum(x, axis=axis)\n\n\ndef cumprod(x, axis=0):\n    return np.cumprod(x, axis=axis)\n\n\ndef any(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.any(x, axis=axis, keepdims=keepdims)\n\n\ndef all(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.all(x, axis=axis, keepdims=keepdims)\n\n\ndef argmax(x, axis=-1):\n    return np.argmax(x, axis=axis)\n\n\ndef argmin(x, axis=-1):\n    return np.argmin(x, axis=axis)\n\n\ndef sqrt(x):\n    y = np.sqrt(x)\n    y[np.isnan(y)] = 0.\n    return y\n\n\ndef pow(x, a=1.):\n    return np.power(x, a)\n\n\ndef clip(x, min_value, max_value):\n    return np.clip(x, min_value, max_value)\n\n\ndef concatenate(tensors, axis=-1):\n    return np.concatenate(tensors, axis)\n\n\ndef permute_dimensions(x, pattern):\n    return np.transpose(x, pattern)\n\n\ndef reshape(x, shape):\n    return np.reshape(x, shape)\n\n\ndef repeat_elements(x, rep, axis):\n    return np.repeat(x, rep, axis=axis)\n\n\ndef repeat(x, n):\n    y = np.expand_dims(x, 1)\n    y = np.repeat(y, n, axis=1)\n    return y\n\n\ndef temporal_padding(x, padding=(1, 1)):\n    return np.pad(x, [(0, 0), padding, (0, 0)], mode=\'constant\')\n\n\ndef spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    all_dims_padding = ((0, 0),) + padding + ((0, 0),)\n    all_dims_padding = transpose_shape(all_dims_padding, data_format,\n                                       spatial_axes=(1, 2))\n    return np.pad(x, all_dims_padding, mode=\'constant\')\n\n\ndef spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    all_dims_padding = ((0, 0),) + padding + ((0, 0),)\n    all_dims_padding = transpose_shape(all_dims_padding, data_format,\n                                       spatial_axes=(1, 2, 3))\n    return np.pad(x, all_dims_padding, mode=\'constant\')\n\n\ndef tile(x, n):\n    return np.tile(x, n)\n\n\ndef arange(start, stop=None, step=1, dtype=\'int32\'):\n    return np.arange(start, stop, step, dtype)\n\n\ndef flatten(x):\n    return np.reshape(x, (-1,))\n\n\ndef batch_flatten(x):\n    return np.reshape(x, (x.shape[0], -1))\n\n\ndef gather(reference, indices):\n    return reference[indices]\n\n\ndef eval(x):\n    return x\n\n\ndef get_value(x):\n    return x\n\n\ndef count_params(x):\n    return x.size\n\n\ndef int_shape(x):\n    return x.shape\n\n\ndef get_variable_shape(x):\n    return int_shape(x)\n\n\ndef dtype(x):\n    return x.dtype.name\n\n\ndef constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    np_value = value * np.ones(shape)\n    np_value.astype(dtype)\n    return np_value\n\n\ndef print_tensor(x, message=\'\'):\n    print(x, message)\n    return x\n\n\ndef batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=0.001):\n    return ((x - mean) / sqrt(var + epsilon)) * gamma + beta\n\n\ndef dot(x, y):\n    return np.dot(x, y)\n\n\ndef batch_dot(x, y, axes=None):\n    if x.ndim < 2 or y.ndim < 2:\n        raise ValueError(\'Batch dot requires inputs of rank 2 or more.\')\n\n    if isinstance(axes, int):\n        axes = [axes, axes]\n    elif isinstance(axes, tuple):\n        axes = list(axes)\n\n    if axes is None:\n        if y.ndim == 2:\n            axes = [x.ndim - 1, y.ndim - 1]\n        else:\n            axes = [x.ndim - 1, y.ndim - 2]\n\n    if any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError(\'Multiple target dimensions are not supported. \' +\n                         \'Expected: None, int, (int, int), \' +\n                         \'Provided: \' + str(axes))\n\n    # Handle negative axes\n    if axes[0] < 0:\n        axes[0] += x.ndim\n    if axes[1] < 0:\n        axes[1] += y.ndim\n\n    if 0 in axes:\n        raise ValueError(\'Can not perform batch dot over axis 0.\')\n\n    if x.shape[0] != y.shape[0]:\n        raise ValueError(\'Can not perform batch dot on inputs\'\n                         \' with different batch sizes.\')\n\n    d1 = x.shape[axes[0]]\n    d2 = y.shape[axes[1]]\n    if d1 != d2:\n        raise ValueError(\'Can not do batch_dot on inputs with shapes \' +\n                         str(x.shape) + \' and \' + str(y.shape) +\n                         \' with axes=\' + str(axes) + \'. x.shape[%d] != \'\n                         \'y.shape[%d] (%d != %d).\' % (axes[0], axes[1], d1, d2))\n\n    result = []\n    axes = [axes[0] - 1, axes[1] - 1]  # ignore batch dimension\n    for xi, yi in zip(x, y):\n        result.append(np.tensordot(xi, yi, axes))\n    result = np.array(result)\n\n    if result.ndim == 1:\n        result = np.expand_dims(result, -1)\n\n    return result\n\n\ndef transpose(x):\n    return np.transpose(x)\n\n\ndef reverse(x, axes):\n    if isinstance(axes, list):\n        axes = tuple(axes)\n    return np.flip(x, axes)\n\n\npy_slice = slice\n\n\ndef slice(x, start, size):\n    slices = [py_slice(i, i + j) for i, j in zip(start, size)]\n    return x[tuple(slices)]\n\n\ndef variable(value, dtype=None, name=None, constraint=None):\n    if constraint is not None:\n        raise TypeError(""Constraint must be None when ""\n                        ""using the NumPy backend."")\n    return np.array(value, dtype)\n\n\ndef dropout(x, level, noise_shape=None, seed=None):\n    if noise_shape is None:\n        noise_shape = x.shape\n    if learning_phase():\n        noise = np.random.choice([0, 1],\n                                 noise_shape,\n                                 replace=True,\n                                 p=[level, 1 - level])\n        return x * noise / (1 - level)\n    else:\n        return x\n\n\ndef equal(x, y):\n    return x == y\n\n\ndef not_equal(x, y):\n    return x != y\n\n\ndef greater(x, y):\n    return x > y\n\n\ndef greater_equal(x, y):\n    return x >= y\n\n\ndef less(x, y):\n    return x < y\n\n\ndef less_equal(x, y):\n    return x <= y\n\n\ndef maximum(x, y):\n    return np.maximum(x, y)\n\n\ndef minimum(x, y):\n    return np.minimum(x, y)\n\n\ndef ndim(x):\n    return x.ndim\n\n\ndef random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None):\n    return (high - low) * np.random.random(shape).astype(dtype) + low\n\n\ndef random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None):\n    return scale * np.random.randn(*shape).astype(dtype) + mean\n\n\ndef zeros(shape, dtype=floatx(), name=None):\n    return np.zeros(shape, dtype=dtype)\n\n\ndef zeros_like(x, dtype=floatx(), name=None):\n    return np.zeros_like(x, dtype=dtype)\n\n\ndef ones(shape, dtype=floatx(), name=None):\n    return np.ones(shape, dtype=dtype)\n\n\ndef ones_like(x, dtype=floatx(), name=None):\n    return np.ones_like(x, dtype=dtype)\n\n\ndef eye(size, dtype=None, name=None):\n    if isinstance(size, (list, tuple)):\n        n, m = size\n    else:\n        n, m = size, size\n    return np.eye(n, m, dtype=dtype)\n\n\ndef resize_images(x, height_factor, width_factor, data_format):\n    if data_format == \'channels_first\':\n        x = repeat_elements(x, height_factor, axis=2)\n        x = repeat_elements(x, width_factor, axis=3)\n    elif data_format == \'channels_last\':\n        x = repeat_elements(x, height_factor, axis=1)\n        x = repeat_elements(x, width_factor, axis=2)\n    return x\n\n\ndef resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    if data_format == \'channels_first\':\n        x = repeat_elements(x, depth_factor, axis=2)\n        x = repeat_elements(x, height_factor, axis=3)\n        x = repeat_elements(x, width_factor, axis=4)\n    elif data_format == \'channels_last\':\n        x = repeat_elements(x, depth_factor, axis=1)\n        x = repeat_elements(x, height_factor, axis=2)\n        x = repeat_elements(x, width_factor, axis=3)\n    return x\n\n\ndef one_hot(indices, num_classes):\n    return to_categorical(indices, num_classes)\n\n\ndef ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1,\n               merge_repeated=False):\n    num_samples = y_pred.shape[0]\n    num_classes = y_pred.shape[-1]\n    log_prob = np.zeros((num_samples, 1))\n    decoded_dense = -np.ones_like(y_pred[..., 0])\n    decoded_length = np.zeros((num_samples,), dtype=np.int)\n    if greedy:\n        for i in range(num_samples):\n            prob = y_pred[i]\n            length = input_length[i]\n            decoded = np.argmax(prob[:length], axis=-1)\n            log_prob[i] = -np.sum(np.log(prob[np.arange(length), decoded]))\n            decoded = _remove_repeats(decoded)\n            decoded = _remove_blanks(decoded, num_classes)\n            decoded_length[i] = len(decoded)\n            decoded_dense[i, :len(decoded)] = decoded\n        return decoded_dense[:, :np.max(decoded_length)], log_prob\n    else:\n        raise NotImplementedError\n\n\ndef _remove_repeats(inds):\n    is_not_repeat = np.insert(np.diff(inds).astype(np.bool), 0, True)\n    return inds[is_not_repeat]\n\n\ndef _remove_blanks(inds, num_classes):\n    return inds[inds < (num_classes - 1)]\n\n\ndef stack(x, axis=0):\n    return np.stack(x, axis=axis)\n\n\nsquare = np.square\nabs = np.abs\nexp = np.exp\nlog = np.log\nround = np.round\nsign = np.sign\nexpand_dims = np.expand_dims\nsqueeze = np.squeeze\ncos = np.cos\nsin = np.sin\n'"
keras/backend/tensorflow_backend.py,278,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import device as tfdev\nfrom tensorflow.python.framework import ops as tf_ops\nfrom tensorflow.python.ops import image_ops as tf_image_ops\nfrom tensorflow.python.ops import math_ops as tf_math_ops\nfrom tensorflow.python.ops import state_ops as tf_state_ops\nfrom tensorflow.python.keras import backend as tf_keras_backend\nfrom tensorflow.python.keras.utils import tf_utils\nfrom tensorflow.python.ops import functional_ops\nfrom tensorflow.python.ops import ctc_ops as ctc\nfrom .common import floatx, epsilon, image_data_format\n\nimport sys\nimport functools\nimport threading\n\nimport numpy as np\nfrom distutils.version import StrictVersion\n\nfrom ..utils.generic_utils import transpose_shape\n\npy_all = all\npy_any = any\npy_sum = sum\npy_slice = slice\n\n# INTERNAL UTILS\n\n# This list holds the available devices.\n# It is populated when `_get_available_gpus()` is called for the first time.\n# We assume our devices don\'t change during our lifetime.\n_LOCAL_DEVICES = None\n\n_SYMBOLIC_SCOPE = threading.local()\n_SYMBOLIC_SCOPE.value = True\n_LEARNING_PHASE_CACHE = {}\n\n\ndef _is_tf_1():\n    return tf.__version__.startswith(\'1.\')\n\n# Set initial config\ntf_keras_backend.set_floatx(floatx())\ntf_keras_backend.set_epsilon(epsilon())\ntf_keras_backend.set_image_data_format(image_data_format())\n\n\n# Private TF Keras utils\nget_graph = tf_keras_backend.get_graph\n# learning_phase_scope = tf_keras_backend.learning_phase_scope  # TODO\nname_scope = tf.name_scope\n\n\ndef symbolic(func):\n    """"""Decorator used in TensorFlow 2.0 to enter the Keras graph.\n\n    # Arguments\n        func: Function to decorate.\n\n    # Returns\n        Decorated function.\n    """"""\n    if _is_tf_1():\n        return func\n\n    @functools.wraps(func)\n    def symbolic_fn_wrapper(*args, **kwargs):\n        if _SYMBOLIC_SCOPE.value:\n            with get_graph().as_default():\n                return func(*args, **kwargs)\n        else:\n            return func(*args, **kwargs)\n    return symbolic_fn_wrapper\n\n\ndef is_symbolic(x):\n    return isinstance(x, tf.Tensor) and hasattr(x, \'op\')\n\n\ndef eager(func):\n    """"""Decorator used in TensorFlow 2.0 to exit the Keras graph.\n\n    # Arguments\n        func: Function to decorate.\n\n    # Returns\n        Decorated function.\n    """"""\n    if _is_tf_1():\n        return func\n\n    global _SYMBOLIC_SCOPE\n\n    @functools.wraps(func)\n    def eager_fn_wrapper(*args, **kwargs):\n        prev_value = _SYMBOLIC_SCOPE.value\n        try:\n            _SYMBOLIC_SCOPE.value = False\n            with context.eager_mode():\n                out = func(*args, **kwargs)\n        finally:\n            _SYMBOLIC_SCOPE.value = prev_value\n        return out\n    return eager_fn_wrapper\n\n\ndef _has_compat_v1():\n    if hasattr(tf, \'compat\') and hasattr(tf.compat, \'v1\'):\n        return True\n    return False\n\n\ndef get_uid(prefix=\'\'):\n    """"""Provides a unique UID given a string prefix.\n\n    # Arguments\n        prefix: string.\n\n    # Returns\n        An integer.\n\n    # Example\n    ```python\n        >>> keras.backend.get_uid(\'dense\')\n        1\n        >>> keras.backend.get_uid(\'dense\')\n        2\n    ```\n\n    """"""\n    return tf_keras_backend.get_uid(prefix)\n\n\ndef manual_variable_initialization(value):\n    """"""Sets the manual variable initialization flag.\n\n    This boolean flag determines whether\n    variables should be initialized\n    as they are instantiated (default), or if\n    the user should handle the initialization.\n\n    # Arguments\n        value: Python boolean.\n    """"""\n    tf_keras_backend.manual_variable_initialization(value)\n\n\ndef epsilon():\n    """"""Returns the value of the fuzz factor used in numeric expressions.\n\n    # Returns\n        A float.\n\n    # Example\n    ```python\n        >>> keras.backend.epsilon()\n        1e-07\n    ```\n    """"""\n    return tf_keras_backend.epsilon()\n\n\ndef reset_uids():\n    """"""Resets graph identifiers.""""""\n    tf_keras_backend.reset_uids()\n\n\ndef set_epsilon(e):\n    """"""Sets the value of the fuzz factor used in numeric expressions.\n\n    # Arguments\n        e: float. New value of epsilon.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.epsilon()\n        1e-07\n        >>> K.set_epsilon(1e-05)\n        >>> K.epsilon()\n        1e-05\n    ```\n    """"""\n    tf_keras_backend.set_epsilon(e)\n\n\ndef floatx():\n    """"""Returns the default float type, as a string.\n    (e.g. \'float16\', \'float32\', \'float64\').\n\n    # Returns\n        String, the current default float type.\n\n    # Example\n    ```python\n        >>> keras.backend.floatx()\n        \'float32\'\n    ```\n    """"""\n    return tf_keras_backend.floatx()\n\n\ndef set_floatx(floatx):\n    """"""Sets the default float type.\n\n    # Arguments\n        floatx: String, \'float16\', \'float32\', or \'float64\'.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        \'float32\'\n        >>> K.set_floatx(\'float16\')\n        >>> K.floatx()\n        \'float16\'\n    ```\n    """"""\n    tf_keras_backend.set_floatx(floatx)\n\n\ndef cast_to_floatx(x):\n    """"""Cast a Numpy array to the default Keras float type.\n\n    # Arguments\n        x: Numpy array.\n\n    # Returns\n        The same Numpy array, cast to its new type.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        \'float32\'\n        >>> arr = numpy.array([1.0, 2.0], dtype=\'float64\')\n        >>> arr.dtype\n        dtype(\'float64\')\n        >>> new_arr = K.cast_to_floatx(arr)\n        >>> new_arr\n        array([ 1.,  2.], dtype=float32)\n        >>> new_arr.dtype\n        dtype(\'float32\')\n    ```\n    """"""\n    return tf_keras_backend.cast_to_floatx(x)\n\n\ndef image_data_format():\n    """"""Returns the default image data format convention.\n\n    # Returns\n        A string, either `\'channels_first\'` or `\'channels_last\'`\n\n    # Example\n    ```python\n        >>> keras.backend.image_data_format()\n        \'channels_first\'\n    ```\n    """"""\n    return tf_keras_backend.image_data_format()\n\n\ndef set_image_data_format(data_format):\n    """"""Sets the value of the data format convention.\n\n    # Arguments\n        data_format: string. `\'channels_first\'` or `\'channels_last\'`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.image_data_format()\n        \'channels_first\'\n        >>> K.set_image_data_format(\'channels_last\')\n        >>> K.image_data_format()\n        \'channels_last\'\n    ```\n    """"""\n    tf_keras_backend.set_image_data_format(data_format)\n\n\ndef normalize_data_format(value):\n    """"""Checks that the value correspond to a valid data format.\n\n    # Arguments\n        value: String or None. `\'channels_first\'` or `\'channels_last\'`.\n\n    # Returns\n        A string, either `\'channels_first\'` or `\'channels_last\'`\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.normalize_data_format(None)\n        \'channels_first\'\n        >>> K.normalize_data_format(\'channels_last\')\n        \'channels_last\'\n    ```\n\n    # Raises\n        ValueError: if `value` or the global `data_format` invalid.\n    """"""\n    if value is None:\n        value = image_data_format()\n    data_format = value.lower()\n    if data_format not in {\'channels_first\', \'channels_last\'}:\n        raise ValueError(\'The `data_format` argument must be one of \'\n                         \'""channels_first"", ""channels_last"". Received: \' +\n                         str(value))\n    return data_format\n\n\n@symbolic\ndef learning_phase():\n    """"""Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    """"""\n    lp = tf_keras_backend.learning_phase()\n    if _is_tf_1():\n        return lp\n    else:\n        if isinstance(lp, int):\n            return lp\n        if id(lp) in _LEARNING_PHASE_CACHE:\n            return _LEARNING_PHASE_CACHE[id(lp)]\n        with name_scope(\'\'):\n            int_lp = tf.cast(lp, \'int32\', name=\'learning_phase\')\n        _LEARNING_PHASE_CACHE[id(lp)] = int_lp\n        return int_lp\n\n\n@symbolic\ndef set_learning_phase(value):\n    """"""Sets the learning phase to a fixed value.\n\n    # Arguments\n        value: Learning phase value, either 0 or 1 (integers).\n\n    # Raises\n        ValueError: if `value` is neither `0` nor `1`.\n    """"""\n    tf_keras_backend.set_learning_phase(value)\n\n\ndef get_session():\n    """"""Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n\n    # Raises\n        RuntimeError: if no session is available\n            (e.g. when using TensorFlow 2.0).\n    """"""\n    if not _is_tf_1():\n        raise RuntimeError(\n            \'`get_session` is not available \'\n            \'when using TensorFlow 2.0.\')\n    if tf.executing_eagerly():\n        raise RuntimeError(\n            \'`get_session` is not available when \'\n            \'TensorFlow is executing eagerly.\')\n    return tf_keras_backend.get_session()\n\n\ndef set_session(session):\n    """"""Sets the global TensorFlow session.\n\n    # Arguments\n        session: A TF Session.\n\n    # Raises\n        RuntimeError: if no session is available\n            (e.g. when using TensorFlow 2.0).\n    """"""\n    if not _is_tf_1():\n        raise RuntimeError(\n            \'`set_session` is not available \'\n            \'when using TensorFlow 2.0.\')\n    if tf.executing_eagerly():\n        raise RuntimeError(\n            \'`set_session` is not available when \'\n            \'TensorFlow is executing eagerly.\')\n    tf_keras_backend.set_session(session)\n\n\ndef clear_session():\n    """"""Destroys the current Keras graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    """"""\n    tf_keras_backend.clear_session()\n    global _LEARNING_PHASE_CACHE\n    _LEARNING_PHASE_CACHE = {}\n\n\ndef v1_variable_initialization():\n    session = get_session()\n    with session.graph.as_default():\n        variables = tf.global_variables()\n        candidate_vars = []\n        for v in variables:\n            if not getattr(v, \'_keras_initialized\', False):\n                candidate_vars.append(v)\n        if candidate_vars:\n            # This step is expensive, so we only run it on variables\n            # not already marked as initialized.\n            is_initialized = session.run(\n                [tf.is_variable_initialized(v) for v in candidate_vars])\n            uninitialized_vars = []\n            for flag, v in zip(is_initialized, candidate_vars):\n                if not flag:\n                    uninitialized_vars.append(v)\n                v._keras_initialized = True\n            if uninitialized_vars:\n                session.run(tf.variables_initializer(uninitialized_vars))\n\n\n# DEVICE MANIPULATION AND PROBING\n\nclass _TfDeviceCaptureOp(object):\n    """"""Class for capturing the TF device scope.""""""\n\n    def __init__(self):\n        # NOTE(robieta): This differs from tf.keras in that self.device is a\n        # DeviceSpec rather than a string. This is done for compatibility\n        # with a range of TensorFlow versions.\n        self.device = None\n\n    def _set_device(self, device):\n        """"""This method captures TF\'s explicit device scope setting.""""""\n        self.device = device\n\n    def _set_device_from_string(self, device_str):\n        self.device = tfdev.DeviceSpec.from_string(device_str)\n\n\ndef _get_current_tf_device():\n    """"""Return explicit device of current context, otherwise returns `None`.\n\n    # Returns\n        If the current device scope is explicitly set, it returns a string with\n        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n        return `None`.\n    """"""\n    g = get_graph()\n    op = _TfDeviceCaptureOp()\n    g._apply_device_functions(op)\n    return op.device\n\n\ndef _is_current_explicit_device(device_type):\n    """"""Check if the current device is explicitly set on the device type specified.\n\n    # Arguments\n        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n\n    # Returns\n        A boolean indicating if the current device\n        scope is explicitly set on the device type.\n\n    # Raises\n        ValueError: If the `device_type` string indicates an unsupported device.\n    """"""\n    device_type = device_type.lower()\n    if device_type not in [\'cpu\', \'gpu\']:\n        raise ValueError(\'`device_type` should be either ""cpu"" or ""gpu"".\')\n    device = _get_current_tf_device()\n    return (device is not None and device.device_type.lower() == device_type)\n\n\ndef _get_available_gpus():\n    """"""Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    """"""\n    global _LOCAL_DEVICES\n    if _LOCAL_DEVICES is None:\n        if _is_tf_1():\n            devices = get_session().list_devices()\n            _LOCAL_DEVICES = [x.name for x in devices]\n        else:\n            _LOCAL_DEVICES = tf.config.experimental_list_devices()\n    return [x for x in _LOCAL_DEVICES if \'device:gpu\' in x.lower()]\n\n\ndef _has_nchw_support():\n    """"""Check whether the current scope supports NCHW ops.\n\n    TensorFlow does not support NCHW on CPU.\n    Therefore we check if we are not explicitly put on\n    CPU, and have GPUs available.\n    In this case there will be soft-placing on the GPU device.\n\n    # Returns\n        bool: if the current scope device placement would support nchw\n    """"""\n    explicitly_on_cpu = _is_current_explicit_device(\'cpu\')\n    gpus_available = len(_get_available_gpus()) > 0\n    return (not explicitly_on_cpu and gpus_available)\n\n\n# VARIABLE MANIPULATION\n\n@symbolic\ndef _to_tensor(x, dtype):\n    """"""Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.convert_to_tensor(x, dtype=dtype)\n\n\ndef is_sparse(tensor):\n    """"""Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    """"""\n    return isinstance(tensor, tf.SparseTensor)\n\n\n@symbolic\ndef to_dense(tensor):\n    """"""Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    """"""\n    if is_sparse(tensor):\n        return tf.sparse.to_dense(tensor)\n    else:\n        return tensor\n\n\ndef variable(value, dtype=None, name=None, constraint=None):\n    """"""Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype=\'float64\', name=\'example_var\')\n        >>> K.dtype(kvar)\n        \'float64\'\n        >>> print(kvar)\n        example_var\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    """"""\n    v = tf_keras_backend.variable(\n        value, dtype=dtype, name=name, constraint=constraint)\n    if hasattr(value, \'tocoo\'):\n        v._keras_shape = value.tocoo().shape\n    elif isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, \'shape\'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    return v\n\n\ndef is_variable(x):\n    return isinstance(x, tf.Variable)\n\n\ndef constant(value, dtype=None, shape=None, name=None):\n    """"""Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    """"""\n    with tf_ops.init_scope():\n        return tf_keras_backend.constant(\n            value, dtype=dtype, shape=shape, name=name)\n\n\ndef is_keras_tensor(x):\n    """"""Returns whether `x` is a Keras tensor.\n\n    A ""Keras tensor"" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder(\'float32\', shape=(1,1))\n        >>> # A variable indirectly created outside of keras is not a Keras tensor.\n        >>> K.is_keras_tensor(k_var)\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> # A variable created with the keras backend is not a Keras tensor.\n        >>> K.is_keras_tensor(keras_var)\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> # A placeholder is not a Keras tensor.\n        >>> K.is_keras_tensor(keras_placeholder)\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> # Any Keras layer output is a Keras tensor.\n        >>> K.is_keras_tensor(keras_layer_output)\n        True\n    ```\n    """"""\n    if not is_tensor(x):\n        raise ValueError(\'Unexpectedly found an instance of type `\' +\n                         str(type(x)) + \'`. \'\n                         \'Expected a symbolic tensor instance.\')\n    return hasattr(x, \'_keras_history\')\n\n\ndef is_tensor(x):\n    return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)\n\n\n@symbolic\ndef placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    """"""Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor \'Placeholder_4:0\' shape=(2, 4, 5) dtype=float32>\n    ```\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    x = tf_keras_backend.placeholder(\n        shape=shape, ndim=ndim, dtype=dtype, sparse=sparse, name=name)\n    if shape is None:\n        if ndim is not None:\n            shape = tuple(None for _ in range(ndim))\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x\n\n\n@symbolic\ndef is_placeholder(x):\n    """"""Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    """"""\n    try:\n        return x.op.type == \'Placeholder\'\n    except AttributeError:\n        return False\n\n\ndef shape(x):\n    """"""Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor \'Shape_8:0\' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor \'Shape_9:0\' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    """"""\n    return tf.shape(x)\n\n\ndef int_shape(x):\n    """"""Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n\n    {{np_implementation}}\n    """"""\n    if hasattr(x, \'_keras_shape\'):\n        return x._keras_shape\n    try:\n        if isinstance(x.shape, tuple):\n            return x.shape\n        return tuple(x.shape.as_list())\n    except ValueError:\n        return None\n\n\ndef ndim(x):\n    """"""Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n\n    {{np_implementation}}\n    """"""\n    return x.shape.rank\n\n\ndef size(x, name=None):\n    """"""Returns the size of a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        name: A name for the operation (optional).\n\n    # Returns\n        Size of the tensor.\n\n    # Examples\n    ```python\n    >>> from keras import backend as K\n    >>> val = np.array([[1, 2], [3, 4]])\n    >>> kvar = K.variable(value=val)\n    >>> K.size(inputs)\n    <tf.Tensor: id=9, shape=(), dtype=int32, numpy=4>\n    ```\n\n    """"""\n    if is_symbolic(x):\n        with get_graph().as_default():\n            return tf.size(x)\n    return tf.size(x, name=name)\n\n\ndef dtype(x):\n    """"""Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        \'float32\'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype=\'float32\'))\n        \'float32\'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype=\'float64\'))\n        \'float64\'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        \'float32_ref\'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype=\'float32\')\n        >>> K.dtype(kvar)\n        \'float32_ref\'\n    ```\n    {{np_implementation}}\n    """"""\n    return x.dtype.base_dtype.name\n\n\ndef eval(x):\n    """"""Evaluates the value of a tensor.\n\n    # Arguments\n        x: A tensor.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype=\'float32\')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if _is_tf_1():\n        return to_dense(x).eval(session=get_session())\n    if hasattr(x, \'numpy\'):\n        with context.eager_mode():\n            return x.numpy()\n    eval_fn = function([], [x])\n    return eval_fn([])[0]\n\n\ndef zeros(shape, dtype=None, name=None):\n    """"""Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    with tf_ops.init_scope():\n        v = tf.zeros(shape=shape, dtype=dtype, name=name)\n        if py_all(v.shape.as_list()):\n            return variable(v, dtype=dtype, name=name)\n        return v\n\n\ndef ones(shape, dtype=None, name=None):\n    """"""Instantiates an all-ones variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, filled with `1.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.ones((3,4))\n        >>> K.eval(kvar)\n        array([[ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    with tf_ops.init_scope():\n        v = tf.ones(shape=shape, dtype=dtype, name=name)\n        if py_all(v.shape.as_list()):\n            return variable(v, dtype=dtype, name=name)\n        return v\n\n\ndef eye(size, dtype=None, name=None):\n    """"""Instantiate an identity matrix and returns it.\n\n    # Arguments\n        size: Tuple, number of rows and columns. If Integer, number of rows.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, an identity matrix.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.eval(K.eye(3))\n        array([[ 1.,  0.,  0.],\n               [ 0.,  1.,  0.],\n               [ 0.,  0.,  1.]], dtype=float32)\n        >>> K.eval(K.eye((2, 3)))\n        array([[1., 0., 0.],\n               [0., 1., 0.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if isinstance(size, (list, tuple)):\n        n, m = size\n    else:\n        n, m = size, size\n    with tf_ops.init_scope():\n        return tf.eye(n, m, dtype=dtype, name=name)\n\n\n@symbolic\ndef zeros_like(x, dtype=None, name=None):\n    """"""Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    return tf.zeros_like(x, dtype=dtype, name=name)\n\n\n@symbolic\ndef ones_like(x, dtype=None, name=None):\n    """"""Instantiates an all-ones variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with ones.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_ones = K.ones_like(kvar)\n        >>> K.eval(kvar_ones)\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    return tf.ones_like(x, dtype=dtype, name=name)\n\n\n@symbolic\ndef identity(x, name=None):\n    """"""Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    """"""\n    return tf.identity(x, name)\n\n\ndef random_uniform_variable(shape, low, high,\n                            dtype=None,\n                            name=None,\n                            seed=None):\n    """"""Instantiates a variable with values drawn from a uniform distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        low: Float, lower boundary of the output interval.\n        high: Float, upper boundary of the output interval.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n        >>> K.eval(kvar)\n        array([[ 0.10940075,  0.10047495,  0.476143  ],\n               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    with tf_ops.init_scope():\n        value = tf.random_uniform_initializer(\n            low, high, seed=seed)(shape, dtype=dtype)\n        return variable(value, dtype=dtype, name=name)\n\n\ndef random_normal_variable(shape, mean, scale, dtype=None,\n                           name=None, seed=None):\n    """"""Instantiates a variable with values drawn from a normal distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        mean: Float, mean of the normal distribution.\n        scale: Float, standard deviation of the normal distribution.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n        >>> K.eval(kvar)\n        array([[ 1.19591331,  0.68685907, -0.63814116],\n               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    with tf_ops.init_scope():\n        value = tf.random_normal_initializer(\n            mean, scale, seed=seed)(shape, dtype=dtype)\n        return variable(value, dtype=dtype, name=name)\n\n\ndef count_params(x):\n    """"""Returns the static number of elements in a Keras variable or tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n\n    # Returns\n        Integer, the number of elements in `x`, i.e., the product of the\n        array\'s static dimensions.\n\n    # Example\n    ```python\n        >>> kvar = K.zeros((2,3))\n        >>> K.count_params(kvar)\n        6\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    return np.prod(int_shape(x))\n\n\ndef cast(x, dtype):\n    """"""Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`\'float16\'`, `\'float32\'`, or `\'float64\'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype=\'float32\')\n        >>> input\n        <tf.Tensor \'Placeholder_2:0\' shape=(2, 3) dtype=float32>\n        # It doesn\'t work in-place as below.\n        >>> K.cast(input, dtype=\'float16\')\n        <tf.Tensor \'Cast_1:0\' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor \'Placeholder_2:0\' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype=\'float16\')\n        >>> input\n        <tf.Tensor \'Cast_2:0\' shape=(2, 3) dtype=float16>\n    ```\n    """"""\n    return tf.cast(x, dtype)\n\n\n# UPDATES OPS\n\n\ndef update(x, new_x):\n    """"""Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    """"""\n    return tf_state_ops.assign(x, new_x)\n\n\ndef update_add(x, increment):\n    """"""Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    """"""\n    return tf_state_ops.assign_add(x, increment)\n\n\ndef update_sub(x, decrement):\n    """"""Update the value of `x` by subtracting `decrement`.\n\n    # Arguments\n        x: A `Variable`.\n        decrement: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    """"""\n    return tf_state_ops.assign_sub(x, decrement)\n\n\n@symbolic\ndef moving_average_update(x, value, momentum):\n    """"""Compute the moving average of a variable.\n\n    # Arguments\n        x: A `Variable`.\n        value: A tensor with the same shape as `x`.\n        momentum: The moving average momentum.\n\n    # Returns\n        An operation to update the variable.\n    """"""\n    with tf_ops.colocate_with(x):\n        decay = tf_ops.convert_to_tensor(1.0 - momentum)\n        if decay.dtype != x.dtype.base_dtype:\n            decay = tf_math_ops.cast(decay, x.dtype.base_dtype)\n        update_delta = (x - tf_math_ops.cast(value, x.dtype)) * decay\n        return tf_state_ops.assign_sub(x, update_delta)\n\n\n# LINEAR ALGEBRA\n\ndef dot(x, y):\n    """"""Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor \'MatMul_9:0\' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor \'MatMul_9:0\' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    {{np_implementation}}\n    """"""\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse.sparse_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out\n\n\ndef batch_dot(x, y, axes=None):\n    """"""Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batches, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: int or tuple(int, int). Target dimensions to be reduced.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`\'s shape\n        (less the dimension that was summed over) and `y`\'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Pseudocode:\n        ```\n        inner_products = []\n        for xi, yi in zip(x, y):\n            inner_products.append(xi.dot(yi))\n        result = stack(inner_products)\n        ```\n\n        Shape inference:\n        Let `x`\'s shape be `(100, 20)` and `y`\'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`\'s shape and `y`\'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=(1, 2))\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n\n    {{np_implementation}}\n    """"""\n    x_shape = int_shape(x)\n    y_shape = int_shape(y)\n\n    x_ndim = len(x_shape)\n    y_ndim = len(y_shape)\n\n    if x_ndim < 2 or y_ndim < 2:\n        raise ValueError(\'Can not do batch_dot on inputs \'\n                         \'with rank < 2. \'\n                         \'Received inputs with shapes \' +\n                         str(x_shape) + \' and \' +\n                         str(y_shape) + \'.\')\n\n    x_batch_size = x_shape[0]\n    y_batch_size = y_shape[0]\n\n    if x_batch_size is not None and y_batch_size is not None:\n        if x_batch_size != y_batch_size:\n            raise ValueError(\'Can not do batch_dot on inputs \'\n                             \'with different batch sizes. \'\n                             \'Received inputs with shapes \' +\n                             str(x_shape) + \' and \' +\n                             str(y_shape) + \'.\')\n\n    if isinstance(axes, int):\n        axes = [axes, axes]\n\n    if axes is None:\n        if y_ndim == 2:\n            axes = [x_ndim - 1, y_ndim - 1]\n        else:\n            axes = [x_ndim - 1, y_ndim - 2]\n\n    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError(\'Multiple target dimensions are not supported. \' +\n                         \'Expected: None, int, (int, int), \' +\n                         \'Provided: \' + str(axes))\n\n    # if tuple, convert to list.\n    axes = list(axes)\n\n    # convert negative indices.\n    if axes[0] < 0:\n        axes[0] += x_ndim\n    if axes[1] < 0:\n        axes[1] += y_ndim\n\n    # sanity checks\n    if 0 in axes:\n        raise ValueError(\'Can not perform batch_dot over axis 0.\'\n                         \'If your inputs are not batched,\'\n                         \' add a dummy batch dimension to your \'\n                         \'inputs using K.expand_dims(x, 0)\')\n\n    a0, a1 = axes\n    d1 = x_shape[a0]\n    d2 = y_shape[a1]\n\n    if d1 is not None and d2 is not None and d1 != d2:\n        raise ValueError(\'Can not do batch_dot on inputs with shapes \' +\n                         str(x_shape) + \' and \' + str(y_shape) +\n                         \' with axes=\' + str(axes) + \'. x.shape[%d] != \'\n                         \'y.shape[%d] (%d != %d).\' % (axes[0], axes[1], d1, d2))\n\n    # backup ndims. Need them later.\n    orig_x_ndim = x_ndim\n    orig_y_ndim = y_ndim\n\n    # if rank is 2, expand to 3.\n    if x_ndim == 2:\n        x = tf.expand_dims(x, 1)\n        a0 += 1\n        x_ndim += 1\n    if y_ndim == 2:\n        y = tf.expand_dims(y, 2)\n        y_ndim += 1\n\n    # bring x\'s dimension to be reduced to last axis.\n    if a0 != x_ndim - 1:\n        pattern = list(range(x_ndim))\n        for i in range(a0, x_ndim - 1):\n            pattern[i] = pattern[i + 1]\n        pattern[-1] = a0\n        x = tf.transpose(x, pattern)\n\n    # bring y\'s dimension to be reduced to axis 1.\n    if a1 != 1:\n        pattern = list(range(y_ndim))\n        for i in range(a1, 1, -1):\n            pattern[i] = pattern[i - 1]\n        pattern[1] = a1\n        y = tf.transpose(y, pattern)\n\n    # normalize both inputs to rank 3.\n    if x_ndim > 3:\n        # squash middle dimensions of x.\n        x_shape = shape(x)\n        x_mid_dims = x_shape[1:-1]\n        x_squashed_dim = tf.reduce_prod(x_mid_dims)\n        x_squashed_shape = tf.stack([x_shape[0], x_squashed_dim, x_shape[-1]])\n        x = tf.reshape(x, x_squashed_shape)\n        x_squashed = True\n    else:\n        x_squashed = False\n\n    if y_ndim > 3:\n        # squash trailing dimensions of y.\n        y_shape = shape(y)\n        y_trail_dims = y_shape[2:]\n        y_squashed_dim = tf.reduce_prod(y_trail_dims)\n        y_squashed_shape = tf.stack([y_shape[0], y_shape[1], y_squashed_dim])\n        y = tf.reshape(y, y_squashed_shape)\n        y_squashed = True\n    else:\n        y_squashed = False\n\n    result = tf.matmul(x, y)\n\n    # if inputs were squashed, we have to reshape the matmul output.\n    output_shape = tf.shape(result)\n    do_reshape = False\n\n    if x_squashed:\n        output_shape = tf.concat([output_shape[:1],\n                                  x_mid_dims,\n                                  output_shape[-1:]], 0)\n        do_reshape = True\n\n    if y_squashed:\n        output_shape = tf.concat([output_shape[:-1], y_trail_dims], 0)\n        do_reshape = True\n\n    if do_reshape:\n        result = tf.reshape(result, output_shape)\n\n    # if the inputs were originally rank 2, we remove the added 1 dim.\n    if orig_x_ndim == 2:\n        result = tf.squeeze(result, 1)\n    elif orig_y_ndim == 2:\n        result = tf.squeeze(result, -1)\n\n    return result\n\n\ndef transpose(x):\n    """"""Transposes a tensor and returns it.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    # Examples\n    ```python\n        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n        >>> K.eval(var)\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]], dtype=float32)\n        >>> var_transposed = K.transpose(var)\n        >>> K.eval(var_transposed)\n        array([[ 1.,  4.],\n               [ 2.,  5.],\n               [ 3.,  6.]], dtype=float32)\n    ```\n\n    ```python\n        >>> inputs = K.placeholder((2, 3))\n        >>> inputs\n        <tf.Tensor \'Placeholder_11:0\' shape=(2, 3) dtype=float32>\n        >>> input_transposed = K.transpose(inputs)\n        >>> input_transposed\n        <tf.Tensor \'transpose_4:0\' shape=(3, 2) dtype=float32>\n\n    ```\n    {{np_implementation}}\n    """"""\n    return tf.transpose(x)\n\n\ndef gather(reference, indices):\n    """"""Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.embedding_lookup(reference, indices)\n\n\n# ELEMENT-WISE OPERATIONS\n\n\ndef max(x, axis=None, keepdims=False):\n    """"""Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to find maximum values. If `None` (default), finds the\n            maximum over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n\n    {{np_implementation}}\n    """"""\n    return tf.reduce_max(x, axis, keepdims)\n\n\ndef min(x, axis=None, keepdims=False):\n    """"""Minimum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to find minimum values. If `None` (default), finds the\n            minimum over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with miminum values of `x`.\n\n    {{np_implementation}}\n    """"""\n    return tf.reduce_min(x, axis, keepdims)\n\n\ndef sum(x, axis=None, keepdims=False):\n    """"""Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to sum over. If `None` (default), sums over all\n            dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n\n    {{np_implementation}}\n    """"""\n    return tf.reduce_sum(x, axis, keepdims)\n\n\ndef prod(x, axis=None, keepdims=False):\n    """"""Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the product. If `None` (default), computes\n            the product over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n\n    {{np_implementation}}\n    """"""\n    return tf.reduce_prod(x, axis, keepdims)\n\n\ndef cumsum(x, axis=0):\n    """"""Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    {{np_implementation}}\n    """"""\n    return tf_math_ops.cumsum(x, axis=axis)\n\n\ndef cumprod(x, axis=0):\n    """"""Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    {{np_implementation}}\n    """"""\n    return tf_math_ops.cumprod(x, axis=axis)\n\n\ndef var(x, axis=None, keepdims=False):\n    """"""Variance of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the variance. If `None` (default), computes\n            the variance over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the variance of elements of `x`.\n    {{np_implementation}}\n    """"""\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    m = tf.reduce_mean(x, axis, True)\n    devs_squared = tf.square(x - m)\n    return tf.reduce_mean(devs_squared,\n                          axis,\n                          keepdims)\n\n\ndef std(x, axis=None, keepdims=False):\n    """"""Standard deviation of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the standard deviation. If `None` (default),\n            computes the standard deviation over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the standard deviation of elements of `x`.\n    {{np_implementation}}\n    """"""\n    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))\n\n\ndef mean(x, axis=None, keepdims=False):\n    """"""Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the mean. If `None` (default), computes\n            the mean over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keepdims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    {{np_implementation}}\n    """"""\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis, keepdims)\n\n\ndef any(x, axis=None, keepdims=False):\n    """"""Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the logical or. If `None` (default), computes\n            the logical or over all dimensions.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    {{np_implementation}}\n    """"""\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis, keepdims)\n\n\ndef all(x, axis=None, keepdims=False):\n    """"""Bitwise reduction (logical AND).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the logical and. If `None` (default), computes\n            the logical and over all dimensions.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    {{np_implementation}}\n    """"""\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_all(x, axis, keepdims)\n\n\ndef argmax(x, axis=-1):\n    """"""Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    """"""\n    return tf.argmax(x, axis)\n\n\ndef argmin(x, axis=-1):\n    """"""Returns the index of the minimum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    """"""\n    return tf.argmin(x, axis)\n\n\ndef square(x):\n    """"""Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.square(x)\n\n\ndef abs(x):\n    """"""Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.abs(x)\n\n\ndef sqrt(x):\n    """"""Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    """"""\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)\n\n\ndef exp(x):\n    """"""Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.exp(x)\n\n\ndef log(x):\n    """"""Element-wise log.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf_math_ops.log(x)\n\n\ndef logsumexp(x, axis=None, keepdims=False):\n    """"""Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the logsumexp. If `None` (default), computes\n            the logsumexp over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    {{np_implementation}}\n    """"""\n    return tf.reduce_logsumexp(x, axis, keepdims)\n\n\ndef round(x):\n    """"""Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is ""half to even"".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.round(x)\n\n\ndef sign(x):\n    """"""Element-wise sign.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.sign(x)\n\n\ndef pow(x, a):\n    """"""Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    """"""\n    return tf.pow(x, a)\n\n\ndef clip(x, min_value, max_value):\n    """"""Element-wise value clipping.\n\n    # Arguments\n        x: Tensor or variable.\n        min_value: Python float, integer or tensor.\n        max_value: Python float, integer or tensor.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    """"""\n    if (isinstance(min_value, (int, float)) and\n            isinstance(max_value, (int, float))):\n        if max_value < min_value:\n            max_value = min_value\n    if min_value is None:\n        min_value = -np.inf\n    if max_value is None:\n        max_value = np.inf\n    return tf.clip_by_value(x, min_value, max_value)\n\n\ndef equal(x, y):\n    """"""Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.equal(x, y)\n\n\ndef not_equal(x, y):\n    """"""Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.not_equal(x, y)\n\n\ndef greater(x, y):\n    """"""Element-wise truth value of (x > y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.greater(x, y)\n\n\ndef greater_equal(x, y):\n    """"""Element-wise truth value of (x >= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.greater_equal(x, y)\n\n\ndef less(x, y):\n    """"""Element-wise truth value of (x < y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.less(x, y)\n\n\ndef less_equal(x, y):\n    """"""Element-wise truth value of (x <= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.less_equal(x, y)\n\n\ndef maximum(x, y):\n    """"""Element-wise maximum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.maximum(x, y)\n\n\ndef minimum(x, y):\n    """"""Element-wise minimum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.minimum(x, y)\n\n\ndef sin(x):\n    """"""Computes sin of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.sin(x)\n\n\ndef cos(x):\n    """"""Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.cos(x)\n\n\ndef _regular_normalize_batch_in_training(x, gamma, beta,\n                                         reduction_axes, epsilon=1e-3):\n    """"""Non-fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    """"""\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    normed = tf.nn.batch_normalization(x, mean, var,\n                                       beta, gamma,\n                                       epsilon)\n    return normed, mean, var\n\n\ndef _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                           reduction_axes, epsilon=1e-3):\n    """"""Non-fused, broadcast version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    """"""\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(tf.shape(x)[axis])\n    target_shape = tf.stack(target_shape)\n\n    broadcast_mean = tf.reshape(mean, target_shape)\n    broadcast_var = tf.reshape(var, target_shape)\n    if gamma is None:\n        broadcast_gamma = None\n    else:\n        broadcast_gamma = tf.reshape(gamma, target_shape)\n    if beta is None:\n        broadcast_beta = None\n    else:\n        broadcast_beta = tf.reshape(beta, target_shape)\n\n    normed = tf.nn.batch_normalization(\n        x,\n        broadcast_mean,\n        broadcast_var,\n        broadcast_beta,\n        broadcast_gamma,\n        epsilon)\n    return normed, mean, var\n\n\ndef _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                       epsilon=1e-3):\n    """"""Fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    """"""\n    if list(reduction_axes) == [0, 1, 2]:\n        normalization_axis = 3\n        tf_data_format = \'NHWC\'\n    else:\n        normalization_axis = 1\n        tf_data_format = \'NCHW\'\n\n    if gamma is None:\n        gamma = tf.constant(1.0,\n                            dtype=x.dtype,\n                            shape=[x.shape[normalization_axis]])\n    if beta is None:\n        beta = tf.constant(0.0,\n                           dtype=x.dtype,\n                           shape=[x.shape[normalization_axis]])\n\n    if gamma.dtype != tf.float32:\n        gamma = tf.cast(gamma, tf.float32)\n    if beta.dtype != tf.float32:\n        beta = tf.cast(beta, tf.float32)\n\n    if _has_compat_v1:\n        fused_batch_norm = tf.compat.v1.nn.fused_batch_norm\n    else:\n        fused_batch_norm = tf.nn.fused_batch_norm\n    return fused_batch_norm(\n        x,\n        gamma,\n        beta,\n        epsilon=epsilon,\n        data_format=tf_data_format)\n\n\ndef normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    """"""Computes mean and std for batch then apply batch_normalization on batch.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    """"""\n    if (ndim(x) == 4 and\n            list(reduction_axes) in [[0, 1, 2], [0, 2, 3]] and\n            _is_tf_1()):\n        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)\n        return _fused_normalize_batch_in_training(\n            x, gamma, beta, reduction_axes,\n            epsilon=epsilon)\n    else:\n        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n            return _regular_normalize_batch_in_training(x, gamma, beta,\n                                                        reduction_axes,\n                                                        epsilon=epsilon)\n        else:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)\n\n\ndef batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n    """"""Applies batch normalization on x given mean, var, beta and gamma.\n\n    I.e. returns:\n    `output = (x - mean) / sqrt(var + epsilon) * gamma + beta`\n\n    # Arguments\n        x: Input tensor or variable.\n        mean: Mean of batch.\n        var: Variance of batch.\n        beta: Tensor with which to center the input.\n        gamma: Tensor by which to scale the input.\n        axis: Integer, the axis that should be normalized.\n            (typically the features axis).\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    if ndim(x) == 4:\n        # The CPU implementation of FusedBatchNorm only support NHWC\n        if axis == 1 or axis == -3:\n            tf_data_format = \'NCHW\'\n        elif axis == 3 or axis == -1:\n            tf_data_format = \'NHWC\'\n        else:\n            tf_data_format = None\n\n        if ((tf_data_format == \'NHWC\' or\n                (tf_data_format == \'NCHW\' and\n                 _has_nchw_support())) and\n                _is_tf_1()):\n            # The mean / var / beta / gamma may be processed by broadcast\n            # so it may have extra axes with 1,\n            # it is not needed and should be removed\n            if ndim(mean) > 1:\n                mean = tf.reshape(mean, [-1])\n            if ndim(var) > 1:\n                var = tf.reshape(var, [-1])\n            if beta is None:\n                beta = zeros_like(mean)\n            elif ndim(beta) > 1:\n                beta = tf.reshape(beta, [-1])\n            if gamma is None:\n                gamma = ones_like(mean)\n            elif ndim(gamma) > 1:\n                gamma = tf.reshape(gamma, [-1])\n\n            if gamma.dtype != tf.float32:\n                gamma = tf.cast(gamma, tf.float32)\n            if beta.dtype != tf.float32:\n                beta = tf.cast(beta, tf.float32)\n            if mean.dtype != tf.float32:\n                mean = tf.cast(mean, tf.float32)\n            if var.dtype != tf.float32:\n                var = tf.cast(var, tf.float32)\n\n            if _has_compat_v1:\n                fused_batch_norm = tf.compat.v1.nn.fused_batch_norm\n            else:\n                fused_batch_norm = tf.nn.fused_batch_norm\n\n            y, _, _ = fused_batch_norm(\n                x,\n                gamma,\n                beta,\n                epsilon=epsilon,\n                mean=mean,\n                variance=var,\n                data_format=tf_data_format,\n                is_training=False\n            )\n            return y\n    # default\n    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)\n\n\n# SHAPE OPERATIONS\n\ndef concatenate(tensors, axis=-1):\n    """"""Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    """"""\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse.concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n\ndef reshape(x, shape):\n    """"""Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.reshape(x, shape)\n\n\ndef permute_dimensions(x, pattern):\n    """"""Permutes axes in a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        pattern: A tuple of\n            dimension indices, e.g. `(0, 2, 1)`.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf.transpose(x, perm=pattern)\n\n\ndef resize_images(x,\n                  height_factor,\n                  width_factor,\n                  data_format,\n                  interpolation=\'nearest\'):\n    """"""Resizes the images contained in a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        interpolation: A string, one of `nearest` or `bilinear`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is\n        neither `""channels_last""` or `""channels_first""`.\n    """"""\n    if data_format == \'channels_first\':\n        rows, cols = 2, 3\n    else:\n        rows, cols = 1, 2\n\n    original_shape = int_shape(x)\n    new_shape = tf.shape(x)[rows:cols + 1]\n    new_shape *= tf.constant(np.array([height_factor, width_factor],\n                             dtype=\'int32\'))\n    if data_format == \'channels_first\':\n        x = permute_dimensions(x, [0, 2, 3, 1])\n    if interpolation == \'nearest\':\n        x = tf_image_ops.resize_nearest_neighbor(x, new_shape)\n    elif interpolation == \'bilinear\':\n        x = tf_image_ops.resize_bilinear(x, new_shape)\n    else:\n        raise ValueError(\'interpolation should be one \'\n                         \'of ""nearest"" or ""bilinear"".\')\n    if data_format == \'channels_first\':\n        x = permute_dimensions(x, [0, 3, 1, 2])\n\n    if original_shape[rows] is None:\n        new_height = None\n    else:\n        new_height = original_shape[rows] * height_factor\n\n    if original_shape[cols] is None:\n        new_width = None\n    else:\n        new_width = original_shape[cols] * width_factor\n\n    output_shape = (None, new_height, new_width, None)\n    x.set_shape(transpose_shape(output_shape, data_format,\n                                spatial_axes=(1, 2)))\n    return x\n\n\ndef resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    """"""Resizes the volume contained in a 5D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        depth_factor: Positive integer.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is\n        neither `""channels_last""` or `""channels_first""`.\n    """"""\n    if data_format == \'channels_first\':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == \'channels_last\':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError(\'Unknown data_format: \' + str(data_format))\n\n\ndef repeat_elements(x, rep, axis):\n    """"""Repeats the elements of a tensor along an axis, like `np.repeat`.\n\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n\n    # Returns\n        A tensor.\n    """"""\n    x_shape = x.shape.as_list()\n    # For static axis\n    if x_shape[axis] is not None:\n        # slices along the repeat axis\n        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n        # repeat each slice the given number of reps\n        x_rep = [s for s in splits for _ in range(rep)]\n        return concatenate(x_rep, axis)\n\n    # Here we use tf.tile to mimic behavior of np.repeat so that\n    # we can handle dynamic shapes (that include None).\n    # To do that, we need an auxiliary axis to repeat elements along\n    # it and then merge them along the desired axis.\n\n    # Repeating\n    auxiliary_axis = axis + 1\n    x_shape = tf.shape(x)\n    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n    reps = np.ones(len(x.shape) + 1)\n    reps[auxiliary_axis] = rep\n    x_rep = tf.tile(x_rep, reps)\n\n    # Merging\n    reps = np.delete(reps, auxiliary_axis)\n    reps[axis] = rep\n    reps = tf.constant(reps, dtype=\'int32\')\n    x_shape = x_shape * reps\n    x_rep = tf.reshape(x_rep, x_shape)\n\n    # Fix shape representation\n    x_shape = x.shape.as_list()\n    x_rep.set_shape(x_shape)\n    x_rep._keras_shape = tuple(x_shape)\n    return x_rep\n\n\ndef repeat(x, n):\n    """"""Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    """"""\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)\n\n\ndef arange(start, stop=None, step=1, dtype=\'int32\'):\n    """"""Creates a 1D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano\'s arange: if only one argument is provided,\n    it is in fact the ""stop"" argument and ""start"" is 0.\n\n    The default type of the returned tensor is `\'int32\'` to\n    match TensorFlow\'s default.\n\n    # Arguments\n        start: Start value.\n        stop: Stop value.\n        step: Difference between two successive values.\n        dtype: Integer dtype to use.\n\n    # Returns\n        An integer tensor.\n\n    """"""\n    # Match the behavior of numpy and Theano by returning an empty sequence.\n    if stop is None:\n        try:\n            if start < 0:\n                start = 0\n        except TypeError:\n            # Handle case where start is a tensor\n            start = tf.cond(start < 0,\n                            true_fn=lambda: tf.constant(0, dtype=start.dtype),\n                            false_fn=lambda: start)\n\n    result = tf.range(start, limit=stop, delta=step, name=\'arange\')\n    if dtype != \'int32\':\n        result = cast(result, dtype)\n    return result\n\n\ndef tile(x, n):\n    """"""Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2, 3)))\n        >>> kvar_tile = K.tile(K.eye(2), (2, 3))\n        >>> K.eval(kvar_tile)\n        array([[1., 0., 1., 0., 1., 0.],\n               [0., 1., 0., 1., 0., 1.],\n               [1., 0., 1., 0., 1., 0.],\n               [0., 1., 0., 1., 0., 1.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    """"""\n    if isinstance(n, int):\n        n = (n,)\n    elif isinstance(n, list):\n        n = tuple(n)\n\n    shape = int_shape(x)\n    if not is_tensor(n):\n        if len(n) < len(shape):  # Padding the axis\n            n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n        elif len(n) != len(shape):\n            raise NotImplementedError\n\n    return tf.tile(x, n)\n\n\ndef flatten(x):\n    """"""Flatten a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor, reshaped into 1-D\n    """"""\n    return tf.reshape(x, [-1])\n\n\ndef batch_flatten(x):\n    """"""Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    """"""\n    x = tf.reshape(\n        x, tf.stack([-1, prod(shape(x)[1:])],\n                    name=\'stack_\' + str(np.random.randint(1e4))))\n    return x\n\n\ndef expand_dims(x, axis=-1):\n    """"""Adds a 1-sized dimension at index ""axis"".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    """"""\n    return tf.expand_dims(x, axis)\n\n\ndef squeeze(x, axis):\n    """"""Removes a 1-dimension from the tensor at index ""axis"".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Axis to drop.\n\n    # Returns\n        A tensor with the same data as `x` but reduced dimensions.\n    """"""\n    return tf.squeeze(x, [axis])\n\n\ndef temporal_padding(x, padding=(1, 1)):\n    """"""Pads the middle dimension of a 3D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 integers, how many zeros to\n            add at the start and end of dim 1.\n\n    # Returns\n        A padded 3D tensor.\n    """"""\n    assert len(padding) == 2\n    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n    return tf.pad(x, pattern)\n\n\ndef spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    """"""Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 tuples, padding pattern.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n\n    # Returns\n        A padded 4D tensor.\n\n    # Raises\n        ValueError: if `data_format` is\n        neither `""channels_last""` or `""channels_first""`.\n    """"""\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    data_format = normalize_data_format(data_format)\n\n    pattern = [[0, 0],\n               list(padding[0]),\n               list(padding[1]),\n               [0, 0]]\n    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2))\n    return tf.pad(x, pattern)\n\n\ndef spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    """"""Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n    Pads these dimensions with respectively\n    ""padding[0]"", ""padding[1]"" and ""padding[2]"" zeros left and right.\n\n    For \'channels_last\' data_format,\n    the 2nd, 3rd and 4th dimension will be padded.\n    For \'channels_first\' data_format,\n    the 3rd, 4th and 5th dimension will be padded.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 3 tuples, padding pattern.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n\n    # Returns\n        A padded 5D tensor.\n\n    # Raises\n        ValueError: if `data_format` is\n        neither `""channels_last""` or `""channels_first""`.\n\n    """"""\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    data_format = normalize_data_format(data_format)\n\n    pattern = [\n        [0, 0],\n        [padding[0][0], padding[0][1]],\n        [padding[1][0], padding[1][1]],\n        [padding[2][0], padding[2][1]],\n        [0, 0]\n    ]\n    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2, 3))\n\n    return tf.pad(x, pattern)\n\n\ndef stack(x, axis=0):\n    """"""Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n\n    # Arguments\n        x: List of tensors.\n        axis: Axis along which to perform stacking.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.stack(x, axis=axis)\n\n\ndef one_hot(indices, num_classes):\n    """"""Computes the one-hot representation of an integer tensor.\n\n    # Arguments\n        indices: nD integer tensor of shape\n            `(batch_size, dim1, dim2, ... dim(n-1))`\n        num_classes: Integer, number of classes to consider.\n\n    # Returns\n        (n + 1)D one hot representation of the input\n        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n    """"""\n    return tf.one_hot(indices, depth=num_classes, axis=-1)\n\n\ndef reverse(x, axes):\n    """"""Reverses a tensor along the specified axes.\n\n    # Arguments\n        x: Tensor to reverse.\n        axes: Integer or iterable of integers.\n            Axes to reverse.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    if isinstance(axes, int):\n        axes = [axes]\n    return tf.reverse(x, axes)\n\n\ndef slice(x, start, size):\n    """"""Extracts a slice from a tensor.\n\n    # Arguments\n        x: Input tensor.\n        start: Integer list/tuple or tensor\n            indicating the start indices of the slice\n            along each axis.\n        size: Integer list/tuple or tensor\n            indicating how many dimensions to slice\n            along each axis.\n\n    # Returns\n        A sliced tensor:\n        ```python\n        new_x = x[start[0]: start[0] + size[0], ..., start[-1]: start[-1] + size[-1]]\n        ```\n\n    # Raises\n        ValueError: if the dimension and the size of indices mismatches.\n\n    {{np_implementation}}\n    """"""\n    x_shape = int_shape(x)\n    if (x_shape is not None) and (x_shape[0] is not None):\n        len_start = int_shape(start)[0] if is_tensor(start) else len(start)\n        len_size = int_shape(size)[0] if is_tensor(size) else len(size)\n        if not (len(int_shape(x)) == len_start == len_size):\n            raise ValueError(\'The dimension and the size of indices should match.\')\n    return tf.slice(x, start, size)\n\n\n# VALUE MANIPULATION\n\n\ndef get_value(x):\n    """"""Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    """"""\n    if _is_tf_1():\n        return x.eval(session=get_session())\n    else:\n        return x.numpy()\n\n\ndef batch_get_value(ops):\n    """"""Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    """"""\n    return tf_keras_backend.batch_get_value(ops)\n\n\ndef set_value(x, value):\n    """"""Sets the value of a variable, from a Numpy array.\n\n    # Arguments\n        x: Variable to set to a new value.\n        value: Value to set the tensor to, as a Numpy array\n            (of the same shape).\n    """"""\n    tf_keras_backend.set_value(x, value)\n\n\ndef batch_set_value(tuples):\n    """"""Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    """"""\n    tf_keras_backend.batch_set_value(tuples)\n\n\ndef get_variable_shape(x):\n    """"""Returns the shape of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A tuple of integers.\n    """"""\n    return int_shape(x)\n\n\n@symbolic\ndef print_tensor(x, message=\'\'):\n    """"""Prints `message` and the tensor value when evaluated.\n\n    Note that `print_tensor` returns a new tensor identical to `x`\n    which should be used in the following code. Otherwise the\n    print operation is not taken into account during evaluation.\n\n    # Example\n\n    ```python\n        >>> x = K.print_tensor(x, message=""x is: "")\n    ```\n\n    # Arguments\n        x: Tensor to print.\n        message: Message to print jointly with the tensor.\n\n    # Returns\n        The same tensor `x`, unchanged.\n    """"""\n    op = tf.print(message, x, output_stream=sys.stdout)\n    with tf.control_dependencies([op]):\n        return tf.identity(x)\n\n\n# GRAPH MANIPULATION\n\n\ndef function(inputs, outputs, updates=None, **kwargs):\n    if _is_tf_1():\n        v1_variable_initialization()\n    return tf_keras_backend.function(inputs, outputs,\n                                     updates=updates,\n                                     **kwargs)\n\n\n@symbolic\ndef gradients(loss, variables):\n    """"""Returns the gradients of `loss` w.r.t. `variables`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    """"""\n    if _is_tf_1():\n        return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n    return tf.gradients(loss, variables)\n\n\n@symbolic\ndef stop_gradient(variables):\n    """"""Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    """"""\n    if isinstance(variables, (list, tuple)):\n        return map(tf.stop_gradient, variables)\n    else:\n        return tf.stop_gradient(variables)\n\n\n# CONTROL FLOW\n\ndef rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    """"""Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function:\n            Parameters:\n                inputs: Tensor with shape (samples, ...) (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: List of tensors.\n            Returns:\n                outputs: Tensor with shape (samples, ...) (no time dimension),\n                new_states: List of tensors, same length and shapes\n                    as \'states\'.\n        inputs: Tensor of temporal data of shape (samples, time, ...)\n            (at least 3D).\n        initial_states: Tensor with shape (samples, ...) (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: Boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: Binary tensor with shape (samples, time),\n            with a zero for every element that is masked.\n        constants: A list of constant values passed at each step.\n        unroll: Whether to unroll the RNN or to use a symbolic loop\n            (`while_loop` or `scan` depending on backend).\n        input_length: Static number of timesteps in the input.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n        last_output: The latest output of the rnn, of shape `(samples, ...)`\n        outputs: Tensor with shape `(samples, time, ...)` where each\n            entry `outputs[s, t]` is the output of the step function\n            at time `t` for sample `s`.\n        new_states: List of tensors, latest states returned by\n            the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: If input dimension is less than 3.\n        ValueError: If `unroll` is `True`\n            but input timestep is not a fixed number.\n        ValueError: If `mask` is provided (not `None`)\n            but states is not provided (`len(states)` == 0).\n\n    {{np_implementation}}\n    """"""\n    last_output, outputs, new_states = tf_keras_backend.rnn(\n        step_function, inputs, initial_states,\n        go_backwards=go_backwards,\n        mask=mask,\n        constants=constants,\n        unroll=unroll,\n        input_length=input_length)\n    reachable = tf_utils.get_reachable_from_inputs([learning_phase()],\n                                                   targets=[last_output])\n    if last_output in reachable:\n        last_output._uses_learning_phase = True\n    return last_output, outputs, new_states\n\n\n@symbolic\ndef switch(condition, then_expression, else_expression):\n    """"""Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n\n    {{np_implementation}}\n    """"""\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, \'bool\')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError(\'Rank of `condition` should be less than or\'\n                             \' equal to rank of `then_expression` and \'\n                             \'`else_expression`. ndim(condition)=\' +\n                             str(cond_ndim) + \', ndim(then_expression)\'\n                             \'=\' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            zero_expr_shape = tf.ones_like(expr_shape)\n            tile_shape = tf.where(shape_diff > 0, expr_shape, zero_expr_shape)\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x\n\n\n@symbolic\ndef in_train_phase(x, alt, training=None):\n    """"""Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in train phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    """"""\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    # else: assume learning phase is a placeholder tensor.\n    x = switch(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x\n\n\n@symbolic\ndef in_test_phase(x, alt, training=None):\n    """"""Selects `x` in test phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in test phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    """"""\n    return in_train_phase(alt, x, training=training)\n\n\n# NN OPERATIONS\n\ndef relu(x, alpha=0., max_value=None, threshold=0.):\n    """"""Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    Otherwise, it follows:\n    `f(x) = max_value` for `x >= max_value`,\n    `f(x) = x` for `threshold <= x < max_value`,\n    `f(x) = alpha * (x - threshold)` otherwise.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: float. Saturation threshold.\n        threshold: float. Threshold value for thresholded activation.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n\n    if alpha != 0.:\n        if max_value is None and threshold == 0.:\n            return tf.nn.leaky_relu(x, alpha=alpha)\n\n        if threshold != 0.:\n            negative_part = tf.nn.relu(-x + threshold)\n        else:\n            negative_part = tf.nn.relu(-x)\n\n    clip_max = max_value is not None\n\n    if threshold != 0:\n        # computes x for x > threshold else 0\n        x = x * tf.cast(tf.greater(x, threshold), floatx())\n    elif max_value == 6:\n        # if no threshold, then can use nn.relu6 native TF op for performance\n        x = tf.nn.relu6(x)\n        clip_max = False\n    else:\n        x = tf.nn.relu(x)\n\n    if clip_max:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        zero = _to_tensor(0., x.dtype.base_dtype)\n        x = tf.clip_by_value(x, zero, max_value)\n\n    if alpha != 0:\n        alpha = _to_tensor(alpha, x.dtype.base_dtype)\n        x -= alpha * negative_part\n    return x\n\n\ndef elu(x, alpha=1.):\n    """"""Exponential linear unit.\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n        alpha: A scalar, slope of negative section.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    res = tf.nn.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return tf.where(x > 0, res, alpha * res)\n\n\ndef softmax(x, axis=-1):\n    """"""Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: The dimension softmax would be performed on.\n            The default is -1 which indicates the last dimension.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.softmax(x, axis=axis)\n\n\ndef softplus(x):\n    """"""Softplus of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.softplus(x)\n\n\ndef softsign(x):\n    """"""Softsign of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.softsign(x)\n\n\ndef categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    """"""Categorical crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor of the same shape as `output`.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n        axis: Int specifying the channels axis. `axis=-1`\n            corresponds to data format `channels_last`,\n            and `axis=1` corresponds to data format\n            `channels_first`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `axis` is neither -1 nor one of\n            the axes of `output`.\n    """"""\n    return tf_keras_backend.categorical_crossentropy(\n        target, output, from_logits=from_logits, axis=axis)\n\n\ndef sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    """"""Categorical crossentropy with integer targets.\n\n    # Arguments\n        target: An integer tensor.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n        axis: Int specifying the channels axis. `axis=-1`\n            corresponds to data format `channels_last`,\n            and `axis=1` corresponds to data format\n            `channels_first`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `axis` is neither -1 nor one of\n            the axes of `output`.\n    """"""\n    return tf_keras_backend.sparse_categorical_crossentropy(\n        target, output, from_logits=from_logits, axis=axis)\n\n\ndef binary_crossentropy(target, output, from_logits=False):\n    """"""Binary crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        from_logits: Whether `output` is expected to be a logits tensor.\n            By default, we consider that `output`\n            encodes a probability distribution.\n\n    # Returns\n        A tensor.\n    """"""\n    return tf_keras_backend.binary_crossentropy(\n        target, output, from_logits=from_logits)\n\n\ndef sigmoid(x):\n    """"""Element-wise sigmoid.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.sigmoid(x)\n\n\ndef hard_sigmoid(x):\n    """"""Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf_keras_backend.hard_sigmoid(x)\n\n\ndef tanh(x):\n    """"""Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.tanh(x)\n\n\ndef dropout(x, level, noise_shape=None, seed=None):\n    """"""Sets entries in `x` to zero at random, while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    """"""\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.nn.dropout(x, rate=level, noise_shape=noise_shape, seed=seed)\n\n\ndef l2_normalize(x, axis=None):\n    """"""Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform normalization.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    """"""\n    return tf.nn.l2_normalize(x, axis=axis)\n\n\ndef in_top_k(predictions, targets, k):\n    """"""Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    """"""\n    # Note that the order of the 2 first positional arguments\n    # has been inverted in TF 2.\n    return tf.nn.in_top_k(predictions=predictions,\n                          targets=targets,\n                          k=k)\n\n\n# CONVOLUTIONS\n\n\ndef _preprocess_conv1d_input(x, data_format):\n    """"""Transpose and cast the input before the conv1d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n\n    # Returns\n        A tensor.\n    """"""\n    # tensorflow doesn\'t support float64 for conv layer before 1.8.0\n    if (dtype(x) == \'float64\' and\n            StrictVersion(tf.__version__.split(\'-\')[0]) < StrictVersion(\'1.8.0\')):\n        x = tf.cast(x, \'float32\')\n    tf_data_format = \'NWC\'  # to pass TF Conv2dNative operations\n    if data_format == \'channels_first\':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 1))  # NCW -> NWC\n        else:\n            tf_data_format = \'NCW\'\n    return x, tf_data_format\n\n\ndef _preprocess_conv2d_input(x, data_format, force_transpose=False):\n    """"""Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        force_transpose: boolean, whether force to transpose input from NCHW to NHWC\n                        if the `data_format` is `""channels_first""`.\n\n    # Returns\n        A tensor.\n    """"""\n    # tensorflow doesn\'t support float64 for conv layer before 1.8.0\n    if (dtype(x) == \'float64\' and\n            StrictVersion(tf.__version__.split(\'-\')[0]) < StrictVersion(\'1.8.0\')):\n        x = tf.cast(x, \'float32\')\n    tf_data_format = \'NHWC\'\n    if data_format == \'channels_first\':\n        if not _has_nchw_support() or force_transpose:\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = \'NCHW\'\n    return x, tf_data_format\n\n\ndef _preprocess_conv3d_input(x, data_format):\n    """"""Transpose and cast the input before the conv3d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n\n    # Returns\n        A tensor.\n    """"""\n    # tensorflow doesn\'t support float64 for conv layer before 1.8.0\n    if (dtype(x) == \'float64\' and\n            StrictVersion(tf.__version__.split(\'-\')[0]) < StrictVersion(\'1.8.0\')):\n        x = tf.cast(x, \'float32\')\n    tf_data_format = \'NDHWC\'\n    if data_format == \'channels_first\':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 4, 1))\n        else:\n            tf_data_format = \'NCDHW\'\n    return x, tf_data_format\n\n\ndef _preprocess_padding(padding):\n    """"""Convert keras\' padding to tensorflow\'s padding.\n\n    # Arguments\n        padding: string, `""same""` or `""valid""`.\n\n    # Returns\n        a string, `""SAME""` or `""VALID""`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    """"""\n    if padding == \'same\':\n        padding = \'SAME\'\n    elif padding == \'valid\':\n        padding = \'VALID\'\n    else:\n        raise ValueError(\'Invalid padding: \' + str(padding))\n    return padding\n\n\ndef conv1d(x, kernel, strides=1, padding=\'valid\',\n           data_format=None, dilation_rate=1):\n    """"""1D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `""same""`, `""causal""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: integer dilate rate.\n\n    # Returns\n        A tensor, result of 1D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    kernel_shape = kernel.shape.as_list()\n    if padding == \'causal\':\n        if data_format != \'channels_last\':\n            raise ValueError(\'When using causal padding in `conv1d`, \'\n                             \'`data_format` must be ""channels_last"" \'\n                             \'(temporal data).\')\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = \'valid\'\n    padding = _preprocess_padding(padding)\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs[\'dilation_rate\'] = (dilation_rate,)\n    else:\n        kwargs[\'dilations\'] = (dilation_rate,)\n\n    x = tf.nn.convolution(\n        x, kernel,\n        strides=(strides,),\n        padding=padding,\n        data_format=tf_data_format,\n        **kwargs)\n\n    if data_format == \'channels_first\' and tf_data_format == \'NWC\':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n    return x\n\n\ndef conv2d(x, kernel, strides=(1, 1), padding=\'valid\',\n           data_format=None, dilation_rate=(1, 1)):\n    """"""2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs[\'dilation_rate\'] = dilation_rate\n    else:\n        kwargs[\'dilations\'] = dilation_rate\n\n    x = tf.nn.convolution(\n        x, kernel,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format,\n        **kwargs)\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x\n\n\ndef conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding=\'valid\', data_format=None, dilation_rate=(1, 1)):\n    """"""2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    # tf.nn.atrous_conv2d_transpose input only supports NHWC format\n    if data_format == \'channels_first\' and dilation_rate != (1, 1):\n        force_transpose = True\n    else:\n        force_transpose = False\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format, force_transpose)\n\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (shape(x)[0],) + tuple(output_shape[1:])\n\n    output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NHWC\':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    if dilation_rate == (1, 1):\n        x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                                   padding=padding,\n                                   data_format=tf_data_format)\n    else:\n        assert dilation_rate[0] == dilation_rate[1]\n        x = tf.nn.atrous_conv2d_transpose(\n            x, kernel, output_shape, dilation_rate[0], padding)\n\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x\n\n\ndef separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding=\'valid\', data_format=None, dilation_rate=1):\n    """"""1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: stride integer.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n    if isinstance(strides, int):\n        strides = (strides,)\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,)\n\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n    if tf_data_format == \'NWC\':\n        tf_data_format = \'NHWC\'\n    else:\n        tf_data_format = \'NCHW\'\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NHWC\':\n        spatial_start_dim = 1\n        strides = (1,) + strides * 2 + (1,)\n    else:\n        spatial_start_dim = 2\n        strides = (1, 1) + strides * 2\n    x = tf.expand_dims(x, spatial_start_dim)\n    depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n    pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n    dilation_rate = (1,) + dilation_rate\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs[\'rate\'] = dilation_rate\n    else:\n        kwargs[\'dilations\'] = dilation_rate\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               data_format=tf_data_format,\n                               **kwargs)\n\n    x = tf.squeeze(x, [spatial_start_dim])\n\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n\n    return x\n\n\ndef separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding=\'valid\', data_format=None, dilation_rate=(1, 1)):\n    """"""2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NHWC\':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs[\'rate\'] = dilation_rate\n    else:\n        kwargs[\'dilations\'] = dilation_rate\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               data_format=tf_data_format,\n                               **kwargs)\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x\n\n\ndef depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding=\'valid\',\n                     data_format=None, dilation_rate=(1, 1)):\n    """"""2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NHWC\':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs[\'rate\'] = dilation_rate\n    else:\n        kwargs[\'dilations\'] = dilation_rate\n\n    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               data_format=tf_data_format,\n                               **kwargs)\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x\n\n\ndef conv3d(x, kernel, strides=(1, 1, 1), padding=\'valid\',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    """"""3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs[\'dilation_rate\'] = dilation_rate\n    else:\n        kwargs[\'dilations\'] = dilation_rate\n\n    x = tf.nn.convolution(\n        x, kernel,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format,\n        **kwargs)\n    if data_format == \'channels_first\' and tf_data_format == \'NDHWC\':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x\n\n\ndef conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding=\'valid\', data_format=None):\n    """"""3D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: input tensor.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, ""same"" or ""valid"".\n        data_format: string, `""channels_last""` or `""channels_first""`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 3D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n\n    if data_format == \'channels_first\' and tf_data_format == \'NDHWC\':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[4],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NDHWC\':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv3d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == \'channels_first\' and tf_data_format == \'NDHWC\':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x\n\n\ndef pool2d(x, pool_size, strides=(1, 1),\n           padding=\'valid\', data_format=None,\n           pool_mode=\'max\'):\n    """"""2D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 2 integers.\n        strides: tuple of 2 integers.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        pool_mode: string, `""max""` or `""avg""`.\n\n    # Returns\n        A tensor, result of 2D pooling.\n\n    # Raises\n        ValueError: if `data_format` is\n        neither `""channels_last""` or `""channels_first""`.\n        ValueError: if `pool_mode` is neither `""max""` or `""avg""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NHWC\':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == \'max\':\n        x = tf.nn.max_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    elif pool_mode == \'avg\':\n        x = tf.nn.avg_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    else:\n        raise ValueError(\'Invalid pool_mode: \' + str(pool_mode))\n\n    if data_format == \'channels_first\' and tf_data_format == \'NHWC\':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x\n\n\ndef pool3d(x, pool_size, strides=(1, 1, 1), padding=\'valid\',\n           data_format=None, pool_mode=\'max\'):\n    """"""3D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 3 integers.\n        strides: tuple of 3 integers.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        pool_mode: string, `""max""` or `""avg""`.\n\n    # Returns\n        A tensor, result of 3D pooling.\n\n    # Raises\n        ValueError: if `data_format` is\n        neither `""channels_last""` or `""channels_first""`.\n        ValueError: if `pool_mode` is neither `""max""` or `""avg""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == \'NDHWC\':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == \'max\':\n        x = tf.nn.max_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    elif pool_mode == \'avg\':\n        x = tf.nn.avg_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    else:\n        raise ValueError(\'Invalid pool_mode: \' + str(pool_mode))\n\n    if data_format == \'channels_first\' and tf_data_format == \'NDHWC\':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x\n\n\ndef local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    """"""Apply 1D conv with un-shared weights.\n\n    # Arguments\n        inputs: 3D tensor with shape: (batch_size, steps, input_dim)\n        kernel: the unshared weight for convolution,\n                with shape (output_length, feature_dim, filters)\n        kernel_size: a tuple of a single integer,\n                     specifying the length of the 1D convolution window\n        strides: a tuple of a single integer,\n                 specifying the stride length of the convolution\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        the tensor after 1d conv with un-shared weights,\n        with shape (batch_size, output_length, filters)\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `""channels_last""` nor `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = py_slice(i * stride,\n                                i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))\n\n\ndef local_conv2d(inputs,\n                 kernel,\n                 kernel_size,\n                 strides,\n                 output_shape,\n                 data_format=None):\n    """"""Apply 2D conv with un-shared weights.\n\n    # Arguments\n        inputs: 4D tensor with shape:\n                (batch_size, filters, new_rows, new_cols)\n                if data_format=\'channels_first\'\n                or 4D tensor with shape:\n                (batch_size, new_rows, new_cols, filters)\n                if data_format=\'channels_last\'.\n        kernel: the unshared weight for convolution,\n                with shape (output_items, feature_dim, filters)\n        kernel_size: a tuple of 2 integers, specifying the\n                     width and height of the 2D convolution window.\n        strides: a tuple of 2 integers, specifying the strides\n                 of the convolution along the width and height.\n        output_shape: a tuple with (output_row, output_col)\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        A 4d tensor with shape:\n        (batch_size, filters, new_rows, new_cols)\n        if data_format=\'channels_first\'\n        or 4D tensor with shape:\n        (batch_size, new_rows, new_cols, filters)\n        if data_format=\'channels_last\'.\n\n    # Raises\n        ValueError: if `data_format` is neither\n                    `channels_last` or `channels_first`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = py_slice(i * stride_row,\n                                 i * stride_row + kernel_size[0])\n            slice_col = py_slice(j * stride_col,\n                                 j * stride_col + kernel_size[1])\n            if data_format == \'channels_first\':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (1, -1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n    x_aggregate = concatenate(xs, axis=0)\n    output = batch_dot(x_aggregate, kernel)\n    output = reshape(output,\n                     (output_row, output_col, -1, filters))\n\n    if data_format == \'channels_first\':\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output\n\n\ndef bias_add(x, bias, data_format=None):\n    """"""Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    {{np_implementation}}\n    """"""\n    data_format = normalize_data_format(data_format)\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError(\'Unexpected bias dimensions %d, \'\n                         \'expect to be 1 or %d dimensions\'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if len(bias_shape) == 1:\n            new_shape = (1, 1, 1, 1, bias_shape[0])\n        else:\n            new_shape = (1,) + bias_shape\n        new_shape = transpose_shape(new_shape, data_format,\n                                    spatial_axes=(1, 2, 3))\n        x = x + reshape(bias, new_shape)\n    elif ndim(x) == 4:\n        if data_format == \'channels_first\':\n            if len(bias_shape) == 1:\n                if _has_nchw_support():\n                    x = tf.nn.bias_add(x, bias,\n                                       data_format=\'NCHW\')\n                else:\n                    x = x + reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x = x + reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == \'channels_last\':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format=\'NHWC\')\n            else:\n                x = x + reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if len(bias_shape) == 1:\n            new_shape = (1, 1, bias_shape[0])\n        else:\n            new_shape = (1,) + bias_shape\n        new_shape = transpose_shape(new_shape, data_format,\n                                    spatial_axes=(1,))\n        x = x + reshape(bias, new_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x\n\n\n# RANDOMNESS\n\n\ndef random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    """"""Returns a tensor with normal distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: A float, mean of the normal distribution to draw samples.\n        stddev: A float, standard deviation of the normal distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    if py_any(list(is_symbolic(x) for x in (shape, mean, stddev))):\n        with get_graph().as_default():\n            return tf_keras_backend.random_normal(\n                shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)\n    with tf_ops.init_scope():\n        return tf_keras_backend.random_normal(\n            shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)\n\n\ndef random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    """"""Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    if py_any(list(is_symbolic(x) for x in (shape, minval, maxval))):\n        with get_graph().as_default():\n            return tf_keras_backend.random_uniform(\n                shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n    with tf_ops.init_scope():\n        return tf_keras_backend.random_uniform(\n            shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\n\ndef random_binomial(shape, p=0.0, dtype=None, seed=None):\n    """"""Returns a tensor with random binomial distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    if py_any(list(is_symbolic(x) for x in (shape, p))):\n        with get_graph().as_default():\n            return tf_keras_backend.random_binomial(\n                shape, p=p, dtype=dtype, seed=seed)\n    with tf_ops.init_scope():\n        return tf_keras_backend.random_binomial(\n            shape, p=p, dtype=dtype, seed=seed)\n\n\ndef truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    """"""Returns a tensor with truncated random normal distribution of values.\n\n    The generated values follow a normal distribution\n    with specified mean and standard deviation,\n    except that values whose magnitude is more than\n    two standard deviations from the mean are dropped and re-picked.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: Mean of the values.\n        stddev: Standard deviation of the values.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    if py_any(list(is_symbolic(x) for x in (shape, mean, stddev))):\n        with get_graph().as_default():\n            return tf_keras_backend.truncated_normal(\n                shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)\n    with tf_ops.init_scope():\n        return tf_keras_backend.truncated_normal(\n            shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)\n\n\n# CTC\n# TensorFlow has a native implementation, but it uses sparse tensors\n# and therefore requires a wrapper for Keras. The functions below convert\n# dense to sparse tensors and also wraps up the beam search code that is\n# in TensorFlow\'s CTC implementation\n\n\ndef ctc_label_dense_to_sparse(labels, label_lengths):\n    """"""Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    """"""\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    tmp = tf.tile(tf.range(label_shape[0]), max_num_labels_tns)\n    batch_array = tf.transpose(tf.reshape(tmp, reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n\n    indices = concatenate([batch_ind, label_ind], axis=0)\n    indices = tf.transpose(tf.reshape(indices, [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    indices = tf.cast(indices, tf.int64)\n    label_shape = tf.cast(label_shape, tf.int64)\n    return tf.SparseTensor(indices, vals_sparse, label_shape)\n\n\ndef ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    """"""Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    """"""\n    label_length = tf.cast(tf.squeeze(label_length, axis=-1), tf.int32)\n    input_length = tf.cast(tf.squeeze(input_length, axis=-1), tf.int32)\n    sparse_labels = tf.cast(\n        ctc_label_dense_to_sparse(y_true, label_length), tf.int32)\n    y_pred = tf_math_ops.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)\n\n\ndef ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n               top_paths=1, merge_repeated=False):\n    """"""Decodes the output of a softmax.\n\n    Can use either greedy search (also known as best path)\n    or a constrained dictionary search.\n\n    # Arguments\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, )` containing the sequence length for\n            each batch item in `y_pred`.\n        greedy: perform much faster best-path search if `True`.\n            This does not use a dictionary.\n        beam_width: if `greedy` is `False`: a beam search decoder will be used\n            with a beam of this width.\n        top_paths: if `greedy` is `False`,\n            how many of the most probable paths will be returned.\n        merge_repeated: if `greedy` is `False`,\n            merge repeated classes in the output beams.\n\n    # Returns\n        Tuple:\n            List: if `greedy` is `True`, returns a list of one element that\n                contains the decoded sequence.\n                If `False`, returns the `top_paths` most probable\n                decoded sequences.\n                Important: blank labels are returned as `-1`.\n            Tensor `(top_paths, )` that contains\n                the log probability of each decoded sequence.\n    """"""\n    y_pred = tf_math_ops.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n    input_length = tf.cast(input_length, tf.int32)\n\n    if greedy:\n        (decoded, log_prob) = ctc.ctc_greedy_decoder(\n            inputs=y_pred,\n            sequence_length=input_length)\n    else:\n        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n            inputs=y_pred,\n            sequence_length=input_length, beam_width=beam_width,\n            top_paths=top_paths, merge_repeated=merge_repeated)\n\n    decoded_dense = []\n    for st in decoded:\n        dense_tensor = tf.sparse.to_dense(st, default_value=-1)\n        decoded_dense.append(dense_tensor)\n    return decoded_dense, log_prob\n\n\ndef control_dependencies(control_inputs):\n    """"""A context manager that specifies control dependencies.\n\n    # Arguments\n        control_inputs: A list of Operation or Tensor objects\n            which must be executed\n            or computed before running the operations defined in the context.\n            Can also be None to clear the control dependencies.\n\n    # Returns\n        A context manager.\n    """"""\n    return tf.control_dependencies(control_inputs)\n\n\n# HIGH ORDER FUNCTIONS\n\ndef map_fn(fn, elems, name=None, dtype=None):\n    """"""Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor\n        name: A string name for the map node in the graph\n        dtype: Output data type.\n\n    # Returns\n        Tensor with dtype `dtype`.\n    """"""\n    return tf.map_fn(fn, elems, name=name, dtype=dtype)\n\n\ndef foldl(fn, elems, initializer=None, name=None):\n    """"""Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[0]` in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    """"""\n    return tf.foldl(fn, elems, initializer=initializer, name=name)\n\n\ndef foldr(fn, elems, initializer=None, name=None):\n    """"""Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[-1]` in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    """"""\n    return tf.foldr(fn, elems, initializer=initializer, name=name)\n'"
keras/backend/theano_backend.py,3,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom collections import defaultdict\nfrom contextlib import contextmanager\nimport theano\nfrom theano import tensor as T\nfrom theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\nfrom theano.tensor.signal import pool\nfrom theano.printing import Print\nfrom theano.ifelse import ifelse\ntry:\n    import theano.sparse as th_sparse_module\nexcept ImportError:\n    th_sparse_module = None\ntry:\n    from theano.tensor.nnet.nnet import softsign as T_softsign\nexcept ImportError:\n    from theano.sandbox.softsign import softsign as T_softsign\n\nimport numpy as np\nfrom .common import floatx\nfrom .common import epsilon\nfrom .common import normalize_data_format\nfrom ..utils.generic_utils import transpose_shape\nfrom ..utils.generic_utils import has_arg\n# Legacy functions\nfrom .common import set_image_dim_ordering, image_dim_ordering\n\npy_all = all\npy_any = any\npy_sum = sum\npy_slice = slice\n\n\n# INTERNAL UTILS\ntheano.config.floatX = floatx()\n# 0 = test, 1 = train\n_LEARNING_PHASE = T.scalar(dtype=\'uint8\', name=\'keras_learning_phase\')\n_UID_PREFIXES = defaultdict(int)\n\n\ndef learning_phase():\n    # False = test, True = train\n    return _LEARNING_PHASE\n\n\ndef set_learning_phase(value):\n    global _LEARNING_PHASE\n    if value not in {0, 1}:\n        raise ValueError(\'Expected learning phase to be \'\n                         \'0 or 1.\')\n    _LEARNING_PHASE = value\n\n\ndef get_uid(prefix=\'\'):\n    """"""Provides a unique UID given a string prefix.\n\n    # Arguments\n        prefix: string.\n\n    # Returns\n        An integer.\n\n    # Example\n    ```python\n        >>> keras.backend.get_uid(\'dense\')\n        1\n        >>> keras.backend.get_uid(\'dense\')\n        2\n    ```\n\n    """"""\n    _UID_PREFIXES[prefix] += 1\n    return _UID_PREFIXES[prefix]\n\n\ndef reset_uids():\n    global _UID_PREFIXES\n    _UID_PREFIXES = defaultdict(int)\n\n\n# VARIABLE MANIPULATION\n\n\ndef _assert_sparse_module():\n    if not th_sparse_module:\n        raise ImportError(""Failed to import theano.sparse\\n""\n                          ""You probably need to pip install nose-parameterized"")\n\n\ndef is_sparse(tensor):\n    return th_sparse_module and isinstance(tensor.type, th_sparse_module.SparseType)\n\n\ndef to_dense(tensor):\n    if is_sparse(tensor):\n        return th_sparse_module.dense_from_sparse(tensor)\n    else:\n        return tensor\n\n\nNAME_SCOPE_STACK = []\n\n\n@contextmanager\ndef name_scope(name):\n    global NAME_SCOPE_STACK\n    NAME_SCOPE_STACK.append(name)\n    yield\n    NAME_SCOPE_STACK.pop()\n\n\ndef _prepare_name(name, default):\n    prefix = \'/\'.join(NAME_SCOPE_STACK)\n    if name is None:\n        return prefix + \'/\' + default\n    return prefix + \'/\' + name\n\n\ndef variable(value, dtype=None, name=None, constraint=None):\n    """"""Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, \'tocoo\'):\n        _assert_sparse_module()\n        variable = th_sparse_module.as_sparse_variable(\n            value, name=_prepare_name(name, \'variable\'))\n    else:\n        if isinstance(value, (theano.tensor.TensorVariable,\n                              theano.tensor.sharedvar.TensorSharedVariable,\n                              theano.tensor.TensorConstant)):\n            # Support for RandomStreams().normal(), .uniform().\n            value = value.eval()\n        value = np.asarray(value, dtype=dtype)\n        variable = theano.shared(value=value,\n                                 name=_prepare_name(name, \'variable\'),\n                                 strict=False)\n    variable._keras_shape = value.shape\n    variable._uses_learning_phase = False\n    variable.constraint = constraint\n    return variable\n\n\ndef is_variable(x):\n    return isinstance(x, theano.tensor.sharedvar.TensorSharedVariable)\n\n\ndef constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    if not is_tensor(value):\n        value = np.array(value)\n        if len(value.shape) == 0:\n            value = value * np.ones(shape)\n        if shape and value.shape != shape:\n            value = np.reshape(value, shape)\n    const = T.constant(value,\n                       dtype=dtype,\n                       name=_prepare_name(name, \'constant\'))\n    const._keras_shape = shape\n    const._uses_learning_phase = False\n    return const\n\n\ndef is_keras_tensor(x):\n    """"""Returns whether `x` is a Keras tensor.\n\n    A ""Keras tensor"" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder(\'float32\', shape=(1,1))\n        >>> # A variable indirectly created outside of keras is not a Keras tensor.\n        >>> K.is_keras_tensor(k_var)\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> # A variable created with the keras backend is not a Keras tensor.\n        >>> K.is_keras_tensor(keras_var)\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> # A placeholder is not a Keras tensor.\n        >>> K.is_keras_tensor(keras_placeholder)\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> # Any Keras layer output is a Keras tensor.\n        >>> K.is_keras_tensor(keras_layer_output)\n        True\n    ```\n    """"""\n    if not is_tensor(x):\n        raise ValueError(\'Unexpectedly found an instance of type `\' +\n                         str(type(x)) + \'`. \'\n                         \'Expected a symbolic tensor instance.\')\n    return hasattr(x, \'_keras_history\')\n\n\ndef is_tensor(x):\n    return isinstance(x, (T.TensorVariable,\n                          T.sharedvar.TensorSharedVariable,\n                          T.TensorConstant))\n\n\ndef placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    """"""Instantiate an input data placeholder variable.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if shape is None and ndim is None:\n        raise ValueError(\'Specify either a shape or ndim value.\')\n    if shape is not None:\n        ndim = len(shape)\n    else:\n        shape = tuple([None for _ in range(ndim)])\n\n    name = _prepare_name(name, \'placeholder\')\n    broadcast = (False,) * ndim\n    if sparse:\n        _assert_sparse_module()\n        x = th_sparse_module.csr_matrix(name=name, dtype=dtype)\n    else:\n        x = T.TensorType(dtype, broadcast)(name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    x._theano_placeholder = True\n    return x\n\n\ndef is_placeholder(x):\n    """"""Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    """"""\n    return hasattr(x, \'_theano_placeholder\') and x._theano_placeholder\n\n\ndef shape(x):\n    """"""Returns the shape of a tensor.\n\n    Warning: type returned will be different for\n    Theano backend (Theano tensor type) and TF backend (TF TensorShape).\n    """"""\n    return x.shape\n\n\ndef int_shape(x):\n    """"""Returns the shape of a Keras tensor or a Keras variable as a tuple of\n    integers or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n    """"""\n    if hasattr(x, \'_keras_shape\'):\n        return x._keras_shape\n    else:\n        return None\n\n\ndef ndim(x):\n    return x.ndim\n\n\ndef dtype(x):\n    return x.dtype\n\n\ndef eval(x):\n    """"""Returns the value of a tensor.\n    """"""\n    return to_dense(x).eval()\n\n\ndef zeros(shape, dtype=None, name=None):\n    """"""Instantiates an all-zeros variable.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    return variable(np.zeros(shape), dtype, name)\n\n\ndef ones(shape, dtype=None, name=None):\n    """"""Instantiates an all-ones variable.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    return variable(np.ones(shape), dtype, name)\n\n\ndef eye(size, dtype=None, name=None):\n    """"""Instantiates an identity matrix.\n    """"""\n    if dtype is None:\n        dtype = floatx()\n    if isinstance(size, (list, tuple)):\n        n, m = size\n    else:\n        n, m = size, size\n    return variable(np.eye(n, m), dtype, name)\n\n\ndef ones_like(x, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    return T.ones_like(x, dtype=dtype)\n\n\ndef zeros_like(x, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    return T.zeros_like(x, dtype=dtype)\n\n\ndef identity(x, name=None):\n    """"""Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    """"""\n    return x.copy(name=name)\n\n\ndef random_uniform_variable(shape, low, high, dtype=None, name=None):\n    return variable(np.random.uniform(low=low, high=high, size=shape),\n                    dtype=dtype, name=name)\n\n\ndef random_normal_variable(shape, mean, scale, dtype=None, name=None):\n    return variable(np.random.normal(loc=0.0, scale=scale, size=shape),\n                    dtype=dtype, name=name)\n\n\ndef count_params(x):\n    """"""Returns the number of scalars in a tensor.\n\n    Return: numpy integer.\n    """"""\n    # We don\'t want those compilation to show up in Theano profiler.\n    f = theano.function([], x.shape, profile=False)\n    return np.prod(f())\n\n\ndef cast(x, dtype):\n    return T.cast(x, dtype)\n\n\ndef size(x, name=None):\n    """"""Returns the size of a tensor.\n    # Arguments\n        x: The input tensor.\n        name: A name for the operation (optional).\n    # Returns\n        Size of the tensor.\n    ```\n    """"""\n    return sum(ones_like(x, name=name))\n\n\n# UPDATES OPS\n\n\ndef update(x, new_x):\n    return (x, new_x)\n\n\ndef update_add(x, increment):\n    return (x, x + increment)\n\n\ndef update_sub(x, decrement):\n    return (x, x - decrement)\n\n\ndef moving_average_update(variable, value, momentum):\n    return (variable, variable * momentum + value * (1. - momentum))\n\n\n# LINEAR ALGEBRA\n\n""""""\nAssumed overridden:\n+, -, /, *, +=, -=, *=, /=\n""""""\n\n\ndef dot(x, y):\n    if is_sparse(x):\n        out = th_sparse_module.basic.structured_dot(x, y)\n    else:\n        out = T.dot(x, y)\n    if hasattr(x, \'_keras_shape\') and hasattr(y, \'_keras_shape\'):\n        x_shape = list(x._keras_shape)\n        y_shape = list(y._keras_shape)\n        if len(x_shape) > 0:\n            x_shape.pop()\n        if len(y_shape) == 1:\n            y_shape.pop()\n        elif len(y_shape) > 1:\n            y_shape.pop(-2)\n        out._keras_shape = tuple(x_shape + y_shape)\n    return out\n\n\ndef batch_dot(x, y, axes=None):\n    """"""Batchwise dot product.\n\n    batch_dot results in a tensor with less dimensions than the input.\n    If the number of dimensions is reduced to 1, we use `expand_dims` to\n    make sure that ndim is at least 2.\n\n    # Arguments\n        x, y: tensors with ndim >= 2\n        axes: list (or single) int with target dimensions\n\n    # Returns\n        A tensor with shape equal to the concatenation of x\'s shape\n        (less the dimension that was summed over) and y\'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to (batch_size, 1).\n\n    # Examples\n        Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]\n        batch_dot(x, y, axes=1) = [[17, 53]] which is the main diagonal\n        of x.dot(y.T), although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let x\'s shape be (100, 20) and y\'s shape be (100, 30, 20).\n        If dot_axes is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in x\'s shape and y\'s shape:\n        x.shape[0] : 100 : append to output shape\n        x.shape[1] : 20 : do not append to output shape,\n            dimension 1 of x has been summed over. (dot_axes[0] = 1)\n        y.shape[0] : 100 : do not append to output shape,\n            always ignore first dimension of y\n        y.shape[1] : 30 : append to output shape\n        y.shape[2] : 20 : do not append to output shape,\n            dimension 2 of y has been summed over. (dot_axes[1] = 2)\n\n        output_shape = (100, 30)\n    """"""\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    if axes is None:\n        # behaves like tf.batch_matmul as default\n        if y.ndim == 2:\n            axes = [x.ndim - 1, y.ndim - 1]\n        else:\n            axes = [x.ndim - 1, y.ndim - 2]\n    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError(\'Multiple target dimensions are not supported. \' +\n                         \'Expected: None, int, (int, int), \' +\n                         \'Provided: \' + str(axes))\n    if isinstance(axes, tuple):\n        axes = list(axes)\n\n    if 0 in axes:\n        raise ValueError(\'Can not perform batch_dot over axis 0.\'\n                         \'If your inputs are not batched,\'\n                         \' add a dummy batch dimension to your \'\n                         \'inputs using K.expand_dims(x, 0)\')\n\n    out = T.batched_tensordot(x, y, axes=axes)\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n\n    if hasattr(x, \'_keras_shape\') and hasattr(y, \'_keras_shape\'):\n        shape = []\n        for axis in range(len(x._keras_shape)):\n            if axis != axes[0]:\n                shape.append(x._keras_shape[axis])\n        for axis in range(1, len(y._keras_shape)):\n            if axis != axes[1]:\n                shape.append(y._keras_shape[axis])\n        if len(shape) == 1:\n            shape.append(1)     # Expand dims if ndim == 1\n        out._keras_shape = tuple(shape)\n    return out\n\n\ndef transpose(x):\n    y = T.transpose(x)\n    if hasattr(x, \'_keras_shape\'):\n        y._keras_shape = tuple(reversed(x._keras_shape))\n    return y\n\n\ndef gather(reference, indices):\n    """"""Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    """"""\n    y = reference[indices]\n    if hasattr(reference, \'_keras_shape\') and hasattr(indices, \'_keras_shape\'):\n        y._keras_shape = indices._keras_shape + reference._keras_shape[1:]\n    return y\n\n\n# ELEMENT-WISE OPERATIONS\n\n\ndef max(x, axis=None, keepdims=False):\n    return T.max(x, axis=axis, keepdims=keepdims)\n\n\ndef min(x, axis=None, keepdims=False):\n    return T.min(x, axis=axis, keepdims=keepdims)\n\n\ndef sum(x, axis=None, keepdims=False):\n    """"""Sum of the values in a tensor, alongside the specified axis.\n    """"""\n    return T.sum(x, axis=axis, keepdims=keepdims)\n\n\ndef prod(x, axis=None, keepdims=False):\n    """"""Multiply the values in a tensor, alongside the specified axis.\n    """"""\n    return T.prod(x, axis=axis, keepdims=keepdims)\n\n\ndef cumsum(x, axis=0):\n    """"""Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    """"""\n    return T.extra_ops.cumsum(x, axis=axis)\n\n\ndef cumprod(x, axis=0):\n    """"""Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    """"""\n    return T.extra_ops.cumprod(x, axis=axis)\n\n\ndef mean(x, axis=None, keepdims=False):\n    """"""Mean of a tensor, alongside the specified axis.\n    """"""\n    dtype = None\n    # bool is available since theano v0.9dev\n    if \'int\' in x.dtype or x.dtype == \'bool\':\n        dtype = floatx()\n    return T.mean(x, axis=axis, keepdims=keepdims, dtype=dtype)\n\n\ndef std(x, axis=None, keepdims=False):\n    return T.std(x, axis=axis, keepdims=keepdims)\n\n\ndef var(x, axis=None, keepdims=False):\n    return T.var(x, axis=axis, keepdims=keepdims)\n\n\ndef any(x, axis=None, keepdims=False):\n    """"""Bitwise reduction (logical OR).\n    """"""\n    y = T.any(x, axis=axis, keepdims=keepdims)\n    y = _set_keras_shape_for_reduction(x, y, axis, keepdims)\n    return y\n\n\ndef all(x, axis=None, keepdims=False):\n    """"""Bitwise reduction (logical AND).\n    """"""\n    y = T.all(x, axis=axis, keepdims=keepdims)\n    y = _set_keras_shape_for_reduction(x, y, axis, keepdims)\n    return y\n\n\ndef _set_keras_shape_for_reduction(x, y, axis, keepdims):\n    if hasattr(x, \'_keras_shape\'):\n        if axis is None:\n            y._keras_shape = (1,) * len(x._keras_shape) if keepdims else (1,)\n        else:\n            if isinstance(axis, int):\n                axis_list = [axis]\n            else:\n                axis_list = list(set(int(a) for a in axis))\n            keras_shape_list = list(x._keras_shape)\n            if keepdims:\n                for a in axis_list:\n                    keras_shape_list[a] = 1\n            else:\n                for a in axis_list[::-1]:\n                    keras_shape_list.pop(a)\n                if not keras_shape_list:\n                    keras_shape_list = (1,)\n            y._keras_shape = tuple(keras_shape_list)\n    return y\n\n\ndef argmax(x, axis=-1):\n    return T.argmax(x, axis=axis, keepdims=False)\n\n\ndef argmin(x, axis=-1):\n    return T.argmin(x, axis=axis, keepdims=False)\n\n\ndef square(x):\n    return T.sqr(x)\n\n\ndef abs(x):\n    return T.abs_(x)\n\n\ndef sqrt(x):\n    x = T.clip(x, 0., np.inf)\n    return T.sqrt(x)\n\n\ndef exp(x):\n    return T.exp(x)\n\n\ndef log(x):\n    return T.log(x)\n\n\ndef logsumexp(x, axis=None, keepdims=False):\n    """"""Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    """"""\n    # Theano has a built-in optimization for logsumexp\n    # (see https://github.com/Theano/Theano/pull/4736)\n    # so we can just write the expression directly:\n    return T.log(T.sum(T.exp(x), axis=axis, keepdims=keepdims))\n\n\ndef round(x):\n    return T.round(x, mode=\'half_to_even\')\n\n\ndef sign(x):\n    return T.sgn(x)\n\n\ndef pow(x, a):\n    return T.pow(x, a)\n\n\ndef clip(x, min_value, max_value):\n    if (isinstance(min_value, (int, float)) and\n            isinstance(max_value, (int, float))):\n        if max_value < min_value:\n            max_value = min_value\n    if min_value is None:\n        min_value = -np.inf\n    if max_value is None:\n        max_value = np.inf\n    return T.clip(x, min_value, max_value)\n\n\ndef equal(x, y):\n    return T.eq(x, y)\n\n\ndef not_equal(x, y):\n    z = T.neq(x, y)\n    if hasattr(x, \'_keras_shape\'):\n        z._keras_shape = x._keras_shape\n    elif hasattr(y, \'_keras_shape\'):\n        z._keras_shape = y._keras_shape\n    return z\n\n\ndef greater(x, y):\n    return T.gt(x, y)\n\n\ndef greater_equal(x, y):\n    return T.ge(x, y)\n\n\ndef less(x, y):\n    return T.lt(x, y)\n\n\ndef less_equal(x, y):\n    return T.le(x, y)\n\n\ndef maximum(x, y):\n    return T.maximum(x, y)\n\n\ndef minimum(x, y):\n    return T.minimum(x, y)\n\n\ndef sin(x):\n    return T.sin(x)\n\n\ndef cos(x):\n    return T.cos(x)\n\n\ndef normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    """"""Computes mean and std for batch then apply batch_normalization on batch.\n    """"""\n    # TODO remove this if statement when Theano without\n    # T.nnet.bn.batch_normalization_train is deprecated\n    if not hasattr(T.nnet.bn, \'batch_normalization_train\'):\n        return _old_normalize_batch_in_training(\n            x, gamma, beta, reduction_axes, epsilon)\n\n    if gamma is None:\n        if beta is None:\n            gamma = ones_like(x)\n        else:\n            gamma = ones_like(beta)\n    if beta is None:\n        if gamma is None:\n            beta = zeros_like(x)\n        beta = zeros_like(gamma)\n\n    normed, mean, stdinv = T.nnet.bn.batch_normalization_train(\n        x, gamma, beta, reduction_axes, epsilon)\n\n    return normed, mean, T.inv(stdinv ** 2)\n\n\ndef batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n    """"""Apply batch normalization on x given mean, var, beta and gamma.\n    """"""\n    # TODO remove this if statement when Theano without\n    # T.nnet.bn.batch_normalization_test is deprecated\n    if not hasattr(T.nnet.bn, \'batch_normalization_test\'):\n        return _old_batch_normalization(x, mean, var, beta, gamma, epsilon)\n\n    if gamma is None:\n        gamma = ones_like(var)\n    if beta is None:\n        beta = zeros_like(mean)\n\n    if mean.ndim == 1:\n        # based on TensorFlow\'s default: normalize along rightmost dimension\n        reduction_axes = list(range(x.ndim - 1))\n    else:\n        reduction_axes = [i for i in range(x.ndim) if mean.broadcastable[i]]\n\n    return T.nnet.bn.batch_normalization_test(\n        x, gamma, beta, mean, var, reduction_axes, epsilon)\n\n\n# TODO remove this function when Theano without\n# T.nnet.bn.batch_normalization_train is deprecated\ndef _old_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                     epsilon=1e-3):  # pragma: no cover\n    """"""Computes mean and std for batch then apply batch_normalization on batch.\n    """"""\n    if gamma is None:\n        gamma = ones_like(x)\n    if beta is None:\n        beta = zeros_like(x)\n\n    dev = theano.config.device\n    use_cudnn = (ndim(x) < 5 and\n                 reduction_axes == [0, 2, 3] and\n                 (dev.startswith(\'cuda\') or dev.startswith(\'gpu\')))\n    if use_cudnn:\n        broadcast_beta = beta.dimshuffle(\'x\', 0, \'x\', \'x\')\n        broadcast_gamma = gamma.dimshuffle(\'x\', 0, \'x\', \'x\')\n        try:\n            trained = theano.sandbox.cuda.dnn.dnn_batch_normalization_train(\n                x, broadcast_gamma, broadcast_beta, \'spatial\', epsilon)\n            normed, mean, stdinv = trained\n            normed = theano.tensor.as_tensor_variable(normed)\n            mean = theano.tensor.as_tensor_variable(mean)\n            stdinv = theano.tensor.as_tensor_variable(stdinv)\n            var = T.inv(stdinv ** 2)\n            return normed, T.flatten(mean), T.flatten(var)\n        except AttributeError:\n            pass\n\n    var = x.var(reduction_axes)\n    mean = x.mean(reduction_axes)\n\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(x.shape[axis])\n    target_shape = T.stack(*target_shape)\n\n    broadcast_mean = T.reshape(mean, target_shape)\n    broadcast_var = T.reshape(var, target_shape)\n    broadcast_beta = T.reshape(beta, target_shape)\n    broadcast_gamma = T.reshape(gamma, target_shape)\n    normed = batch_normalization(x, broadcast_mean, broadcast_var,\n                                 broadcast_beta, broadcast_gamma,\n                                 epsilon)\n    return normed, mean, var\n\n\n# TODO remove this if statement when Theano without\n# T.nnet.bn.batch_normalization_test is deprecated\ndef _old_batch_normalization(x, mean, var, beta, gamma,\n                             epsilon=1e-3):  # pragma: no cover\n    """"""Apply batch normalization on x given mean, var, beta and gamma.\n    """"""\n    if gamma is None:\n        gamma = ones_like(var)\n    if beta is None:\n        beta = zeros_like(mean)\n\n    if mean.ndim == 1 and x.ndim > 1:\n        # in TensorFlow\'s batch_normalization, if the parameters are vectors\n        # the batch normalization should be applied along the rightmost axis.\n        # Theano expects the parameters to always have x.ndim dimensions.\n        shuffle_pattern = [\'x\'] * (x.ndim - 1) + [0]\n        mean = mean.dimshuffle(shuffle_pattern)\n        var = var.dimshuffle(shuffle_pattern)\n        beta = beta.dimshuffle(shuffle_pattern)\n        gamma = gamma.dimshuffle(shuffle_pattern)\n\n    ndim = x.ndim\n    dev = theano.config.device\n    use_cudnn = ndim < 5 and (dev.startswith(\'cuda\') or dev.startswith(\'gpu\'))\n    if use_cudnn:\n        try:\n            axis = mean.broadcastable.index(False)\n            if axis != 1:\n                shuffle_pattern = list(range(ndim))\n                shuffle_pattern[1] = shuffle_pattern[axis]\n                shuffle_pattern[axis] = 1\n                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n                    x.dimshuffle(shuffle_pattern),\n                    gamma.dimshuffle(shuffle_pattern),\n                    beta.dimshuffle(shuffle_pattern),\n                    mean.dimshuffle(shuffle_pattern),\n                    var.dimshuffle(shuffle_pattern),\n                    \'spatial\', epsilon).dimshuffle(shuffle_pattern)\n            else:\n                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n                    x, gamma, beta, mean, var, \'spatial\', epsilon)\n            return theano.tensor.as_tensor_variable(result)\n        except AttributeError:\n            pass\n        except ValueError:\n            pass\n    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),\n                                         mode=\'high_mem\')\n\n\n# SHAPE OPERATIONS\n\ndef concatenate(tensors, axis=-1):\n    if py_all([is_sparse(x) for x in tensors]):\n        axis = axis % ndim(tensors[0])\n        if axis == 0:\n            output = th_sparse_module.basic.vstack(tensors, format=\'csr\')\n        elif axis == 1:\n            output = th_sparse_module.basic.hstack(tensors, format=\'csr\')\n        else:\n            raise ValueError(\'Invalid concat axis for sparse matrix:\', axis)\n    else:\n        output = T.concatenate([to_dense(x) for x in tensors], axis=axis)\n\n    if py_all([hasattr(tensor, \'_keras_shape\') for tensor in tensors]):\n        input_shapes = [tensor._keras_shape for tensor in tensors]\n        output_shape = list(input_shapes[0])\n        for shape in input_shapes[1:]:\n            if output_shape[axis] is None or shape[axis] is None:\n                output_shape[axis] = None\n                break\n            output_shape[axis] += shape[axis]\n        output._keras_shape = tuple(output_shape)\n\n    return output\n\n\ndef reshape(x, shape):\n    y = T.reshape(x, shape)\n    shape = tuple(x if isinstance(x, int) and x > 0 else None for x in shape)\n    y._keras_shape = shape\n    if hasattr(x, \'_uses_learning_phase\'):\n        y._uses_learning_phase = x._uses_learning_phase\n    else:\n        y._uses_learning_phase = False\n    return y\n\n\ndef permute_dimensions(x, pattern):\n    """"""Transpose dimensions.\n\n    pattern should be a tuple or list of\n    dimension indices, e.g. [0, 2, 1].\n    """"""\n    pattern = tuple(pattern)\n    y = x.dimshuffle(pattern)\n    if hasattr(x, \'_keras_shape\'):\n        y._keras_shape = tuple(np.asarray(x._keras_shape)[list(pattern)])\n    return y\n\n\ndef repeat_elements(x, rep, axis):\n    """"""Repeat the elements of a tensor along an axis, like np.repeat.\n\n    If x has shape (s1, s2, s3) and axis=1, the output\n    will have shape (s1, s2 * rep, s3).\n    """"""\n    y = T.repeat(x, rep, axis=axis)\n    if hasattr(x, \'_keras_shape\'):\n        y._keras_shape = list(x._keras_shape)\n        repeat_dim = x._keras_shape[axis]\n        if repeat_dim is not None:\n                y._keras_shape[axis] = repeat_dim * rep\n        y._keras_shape = tuple(y._keras_shape)\n    return y\n\n\ndef resize_images(x,\n                  height_factor,\n                  width_factor,\n                  data_format,\n                  interpolation=\'nearest\'):\n    """"""Resize the images contained in a 4D tensor of shape\n    - [batch, channels, height, width] (for \'channels_first\' data_format)\n    - [batch, height, width, channels] (for \'channels_last\' data_format)\n    by a factor of (height_factor, width_factor). Both factors should be\n    positive integers.\n    """"""\n    if data_format == \'channels_first\':\n        axis_1 = 2\n        axis_2 = 3\n    elif data_format == \'channels_last\':\n        axis_1 = 1\n        axis_2 = 2\n    else:\n        raise ValueError(\'Invalid data_format:\', data_format)\n\n    if interpolation == \'nearest\':\n        output = repeat_elements(x, height_factor, axis=axis_1)\n        output = repeat_elements(output, width_factor, axis=axis_2)\n    elif interpolation == \'bilinear\':\n        if not (height_factor == width_factor == 2):\n            raise NotImplementedError(\n                \'Bilinear upscaling with factors other than (2, 2)\'\n                \'is not available when using the Theano backend.\')\n        if data_format == \'channels_last\':\n            output = permute_dimensions(x, [0, 3, 1, 2])\n        else:\n            output = x\n        output = T.nnet.abstract_conv.bilinear_upsampling(output,\n                                                          ratio=height_factor)\n        if data_format == \'channels_last\':\n            output = permute_dimensions(output, [0, 2, 3, 1])\n        if hasattr(x, \'_keras_shape\'):\n            output._keras_shape = list(x._keras_shape)\n            output._keras_shape[axis_1] *= height_factor\n            output._keras_shape[axis_2] *= width_factor\n            output._keras_shape = tuple(output._keras_shape)\n    else:\n        raise ValueError(\'interpolation should be one of ""nearest"" or ""bilinear"".\')\n\n    return output\n\n\ndef resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    """"""Resize the volume contained in a 5D tensor of shape\n    - [batch, channels, depth, height, width] (for \'channels_first\' data_format)\n    - [batch, depth, height, width, channels] (for \'channels_last\' data_format)\n    by a factor of (depth_factor, height_factor, width_factor).\n    Both factors should be positive integers.\n    """"""\n    if data_format == \'channels_first\':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == \'channels_last\':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError(\'Invalid data_format:\', data_format)\n\n\ndef repeat(x, n):\n    """"""Repeat a 2D tensor.\n\n    If x has shape (samples, dim) and n=2,\n    the output will have shape (samples, 2, dim).\n    """"""\n    assert x.ndim == 2\n    y = x.dimshuffle((0, \'x\', 1))\n    y = T.extra_ops.repeat(y, n, axis=1)\n    if hasattr(x, \'_keras_shape\'):\n        shape = list(x._keras_shape)\n        shape.insert(1, n)\n        y._keras_shape = tuple(shape)\n\n    return y\n\n\ndef arange(start, stop=None, step=1, dtype=\'int32\'):\n    """"""Creates a 1-D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano\'s arange: if only one argument is provided,\n    it is in fact the ""stop"" argument.\n\n    The default type of the returned tensor is \'int32\' to\n    match TensorFlow\'s default.\n    """"""\n    return T.arange(start, stop=stop, step=step, dtype=dtype)\n\n\ndef tile(x, n):\n    if isinstance(n, int):\n        n = (n,)\n    elif isinstance(n, list):\n        n = tuple(n)\n\n    y = T.tile(x, n, ndim=x.ndim)\n    shape = int_shape(x)\n    if shape is None:\n        return y\n    elif isinstance(n, tuple) and len(n) < len(shape):  # Padding the axis\n        n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n    elif isinstance(n, tuple) and len(n) != len(shape):\n        raise NotImplementedError\n\n    if isinstance(n, tuple):\n        y._keras_shape = tuple([None if a is None else a * b\n                                for (a, b) in zip(shape, n)])\n    return y\n\n\ndef flatten(x):\n    y = T.flatten(x)\n    if hasattr(x, \'_keras_shape\'):\n        if None in x._keras_shape:\n            y._keras_shape = (None,)\n        else:\n            y._keras_shape = (np.prod(x._keras_shape), )\n    return y\n\n\ndef batch_flatten(x):\n    """"""Turn a n-D tensor into a 2D tensor where\n    the first dimension is conserved.\n    """"""\n    y = T.reshape(x, (x.shape[0], T.prod(x.shape[1:])))\n    if hasattr(x, \'_keras_shape\'):\n        if None in x._keras_shape[1:]:\n            y._keras_shape = (x._keras_shape[0], None)\n        else:\n            y._keras_shape = (x._keras_shape[0], np.prod(x._keras_shape[1:]))\n    return y\n\n\ndef expand_dims(x, axis=-1):\n    """"""Add a 1-sized dimension at index ""dim"".\n    """"""\n    pattern = [i for i in range(x.type.ndim)]\n    if axis < 0:\n        if x.type.ndim == 0:\n            axis = 0\n        else:\n            axis = axis % x.type.ndim + 1\n    pattern.insert(axis, \'x\')\n    y = x.dimshuffle(pattern)\n    if hasattr(x, \'_keras_shape\'):\n        shape = list(x._keras_shape)\n        shape.insert(axis, 1)\n        y._keras_shape = tuple(shape)\n    return y\n\n\ndef squeeze(x, axis):\n    """"""Remove a 1-dimension from the tensor at index ""axis"".\n    """"""\n    shape = list(x.shape)\n    shape.pop(axis)\n    y = T.reshape(x, tuple(shape))\n    if hasattr(x, \'_keras_shape\'):\n        kshape = list(x._keras_shape)\n        kshape.pop(axis)\n        y._keras_shape = tuple(kshape)\n    return y\n\n\ndef temporal_padding(x, padding=(1, 1)):\n    """"""Pad the middle dimension of a 3D tensor\n    with ""padding"" zeros left and right.\n\n    Apologies for the inane API, but Theano makes this\n    really hard.\n    """"""\n    assert len(padding) == 2\n    input_shape = x.shape\n    output_shape = (input_shape[0],\n                    input_shape[1] + padding[0] + padding[1],\n                    input_shape[2])\n    output = T.zeros(output_shape)\n    result = T.set_subtensor(output[:, padding[0]:x.shape[1] + padding[0], :], x)\n    if hasattr(x, \'_keras_shape\'):\n        result._keras_shape = (x._keras_shape[0],\n                               x._keras_shape[1] + py_sum(padding),\n                               x._keras_shape[2])\n    return result\n\n\ndef spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    """"""Pad the 2nd and 3rd dimensions of a 4D tensor\n    with ""padding[0]"" and ""padding[1]"" (resp.) zeros left and right.\n    """"""\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    top_pad, bottom_pad = padding[0]\n    left_pad, right_pad = padding[1]\n    data_format = normalize_data_format(data_format)\n\n    input_shape = x.shape\n    if data_format == \'channels_first\':\n        output_shape = (input_shape[0],\n                        input_shape[1],\n                        input_shape[2] + top_pad + bottom_pad,\n                        input_shape[3] + left_pad + right_pad)\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(None),\n                   py_slice(top_pad, input_shape[2] + top_pad),\n                   py_slice(left_pad, input_shape[3] + left_pad))\n\n    else:\n        output_shape = (input_shape[0],\n                        input_shape[1] + top_pad + bottom_pad,\n                        input_shape[2] + left_pad + right_pad,\n                        input_shape[3])\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(top_pad, input_shape[1] + top_pad),\n                   py_slice(left_pad, input_shape[2] + left_pad),\n                   py_slice(None))\n    y = T.set_subtensor(output[indices], x)\n    if hasattr(x, \'_keras_shape\'):\n        if data_format == \'channels_first\':\n            if x._keras_shape[2] is not None:\n                h = x._keras_shape[2] + top_pad + bottom_pad\n            else:\n                h = None\n            if x._keras_shape[3] is not None:\n                w = x._keras_shape[3] + left_pad + right_pad\n            else:\n                w = None\n            output_keras_shape = (x._keras_shape[0],\n                                  x._keras_shape[1],\n                                  h,\n                                  w)\n        else:\n            if x._keras_shape[1] is not None:\n                h = x._keras_shape[1] + top_pad + bottom_pad\n            else:\n                h = None\n            if x._keras_shape[2] is not None:\n                w = x._keras_shape[2] + left_pad + right_pad\n            else:\n                w = None\n            output_keras_shape = (x._keras_shape[0],\n                                  h,\n                                  w,\n                                  x._keras_shape[3])\n        y._keras_shape = output_keras_shape\n    return y\n\n\ndef spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    """"""Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n    with ""padding[0]"", ""padding[1]"" and ""padding[2]"" (resp.) zeros left and right.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    input_shape = x.shape\n    if data_format == \'channels_first\':\n        output_shape = (input_shape[0],\n                        input_shape[1],\n                        input_shape[2] + padding[0][0] + padding[0][1],\n                        input_shape[3] + padding[1][0] + padding[1][1],\n                        input_shape[4] + padding[2][0] + padding[2][1])\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(None),\n                   py_slice(padding[0][0], input_shape[2] + padding[0][0]),\n                   py_slice(padding[1][0], input_shape[3] + padding[1][0]),\n                   py_slice(padding[2][0], input_shape[4] + padding[2][0]))\n\n    else:\n        output_shape = (input_shape[0],\n                        input_shape[1] + padding[0][0] + padding[0][1],\n                        input_shape[2] + padding[1][0] + padding[1][1],\n                        input_shape[3] + padding[2][0] + padding[2][1],\n                        input_shape[4])\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(padding[0][0], input_shape[1] + padding[0][0]),\n                   py_slice(padding[1][0], input_shape[2] + padding[1][0]),\n                   py_slice(padding[2][0], input_shape[3] + padding[2][0]),\n                   py_slice(None))\n    y = T.set_subtensor(output[indices], x)\n    if hasattr(x, \'_keras_shape\'):\n        if data_format == \'channels_first\':\n            if x._keras_shape[2] is not None:\n                h = x._keras_shape[2] + padding[0][0] + padding[0][1]\n            else:\n                h = None\n            if x._keras_shape[3] is not None:\n                w = x._keras_shape[3] + padding[1][0] + padding[1][1]\n            else:\n                w = None\n            if x._keras_shape[4] is not None:\n                d = x._keras_shape[4] + padding[2][0] + padding[2][1]\n            else:\n                d = None\n            output_keras_shape = (x._keras_shape[0],\n                                  x._keras_shape[1],\n                                  h,\n                                  w,\n                                  d)\n        else:\n            if x._keras_shape[1] is not None:\n                h = x._keras_shape[1] + padding[0][0] + padding[0][1]\n            else:\n                h = None\n            if x._keras_shape[2] is not None:\n                w = x._keras_shape[2] + padding[1][0] + padding[1][1]\n            else:\n                w = None\n            if x._keras_shape[3] is not None:\n                d = x._keras_shape[3] + padding[2][0] + padding[2][1]\n            else:\n                d = None\n            output_keras_shape = (x._keras_shape[0],\n                                  h,\n                                  w,\n                                  d,\n                                  x._keras_shape[4])\n        y._keras_shape = output_keras_shape\n    return y\n\n\ndef stack(x, axis=0):\n    return T.stack(x, axis=axis)\n\n\ndef one_hot(indices, num_classes):\n    """"""Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n    Output: (n + 1)D one hot representation of the input\n    with shape (batch_size, dim1, dim2, ... dim(n-1), num_classes)\n    """"""\n    input_shape = tuple((indices.shape[i] for i in range(indices.ndim)))\n    indices = T.flatten(indices)\n    oh = T.extra_ops.to_one_hot(indices, num_classes)\n    oh = T.reshape(oh, input_shape + (num_classes,))\n    return oh\n\n\ndef reverse(x, axes):\n    """"""Reverse a tensor along the specified axes\n    """"""\n    if isinstance(axes, int):\n        axes = [axes]\n    elif isinstance(axes, tuple):\n        axes = list(axes)\n    for i in range(len(axes)):\n        if axes[i] == -1:\n            axes[i] = x.ndim - 1\n    slices = []\n    for i in range(x.ndim):\n        if i in axes:\n            slices.append(py_slice(None, None, -1))\n        else:\n            slices.append(py_slice(None, None, None))\n    return x[slices]\n\n\ndef slice(x, start, size):\n    if not (len(int_shape(x)) == len(start) == len(size)):\n        raise ValueError(\'The dimension and the size of indices should match.\')\n    out = x[tuple([py_slice(i, i + j) for (i, j) in zip(start, size)])]\n    out._keras_shape = tuple(size)\n    return out\n\n\ndef pattern_broadcast(x, broadcastable):\n    return T.patternbroadcast(x, broadcastable)\n\n# VALUE MANIPULATION\n\n\ndef get_value(x):\n    if not hasattr(x, \'get_value\'):\n        raise TypeError(\'`get_value` can only be called on a variable. \'\n                        \'If you have an expression instead, use `eval()`.\')\n    return x.get_value()\n\n\ndef batch_get_value(xs):\n    """"""Returns the value of more than one tensor variable,\n    as a list of Numpy arrays.\n    """"""\n    return [get_value(x) for x in xs]\n\n\ndef set_value(x, value):\n    x.set_value(np.asarray(value, dtype=x.dtype))\n\n\ndef batch_set_value(tuples):\n    for x, value in tuples:\n        x.set_value(np.asarray(value, dtype=x.dtype))\n\n\ndef get_variable_shape(x):\n    return x.get_value(borrow=True, return_internal_type=True).shape\n\n\ndef print_tensor(x, message=\'\'):\n    """"""Print the message & the tensor when evaluated & return the same tensor.\n    """"""\n    p_op = Print(message)\n    return p_op(x)\n\n\n# GRAPH MANIPULATION\n\nclass Function(object):\n\n    def __init__(self, inputs, outputs, updates=[], name=None, **kwargs):\n        unique_variables_to_update = {}\n        for v, nv in updates:\n            if v not in unique_variables_to_update:\n                unique_variables_to_update[v] = nv\n        updates = unique_variables_to_update.items()\n        self.outputs = outputs\n        self.function = theano.function(inputs, outputs, updates=updates,\n                                        allow_input_downcast=True,\n                                        on_unused_input=\'ignore\',\n                                        name=name,\n                                        **kwargs)\n        self._metrics = [x for x in outputs if hasattr(x, \'_is_metric\')]\n        self._metrics_function = theano.function(\n            [], self._metrics,\n            name=name + \'_metrics\' if name else None)\n        self.name = name\n\n    def __call__(self, inputs):\n        assert isinstance(inputs, (list, tuple))\n        outputs = self.function(*inputs)\n        if self._metrics:\n            metrics = self._metrics_function()\n        i = 0\n        j = 0\n        for x in self.outputs:\n            if hasattr(x, \'_is_metric\'):\n                v = metrics[j]\n                outputs[i] = v\n                j += 1\n            i += 1\n        return outputs\n\n\ndef _raise_invalid_arg(key):\n    msg = \'Invalid argument ""%s"" passed to K.function with Theano backend\' % key\n    raise ValueError(msg)\n\n\ndef function(inputs, outputs, updates=[], **kwargs):\n    if len(kwargs) > 0:\n        for key in kwargs.keys():\n            if not has_arg(theano.function, key, True):\n                _raise_invalid_arg(key)\n    return Function(inputs, outputs, updates=updates, **kwargs)\n\n\ndef gradients(loss, variables):\n    return T.grad(loss, variables)\n\n\ndef stop_gradient(variables):\n    """"""Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    """"""\n    if isinstance(variables, (list, tuple)):\n        return map(theano.gradient.disconnected_grad, variables)\n    else:\n        return theano.gradient.disconnected_grad(variables)\n\n\n# CONTROL FLOW\n\ndef rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    """"""Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function:\n            Parameters:\n                inputs: Tensor with shape (samples, ...) (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: List of tensors.\n            Returns:\n                outputs: Tensor with shape (samples, ...) (no time dimension),\n                new_states: List of tensors, same length and shapes\n                    as \'states\'.\n        inputs: Tensor of temporal data of shape (samples, time, ...)\n            (at least 3D).\n        initial_states: Tensor with shape (samples, ...) (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: Boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: Binary tensor with shape (samples, time),\n            with a zero for every element that is masked.\n        constants: A list of constant values passed at each step.\n        unroll: Whether to unroll the RNN or to use a symbolic loop\n            (`while_loop` or `scan` depending on backend).\n        input_length: Static number of timesteps in the input.\n            Must be specified if using `unroll`.\n\n    # Returns\n        A tuple (last_output, outputs, new_states).\n\n        last_output: The latest output of the rnn, of shape `(samples, ...)`\n        outputs: Tensor with shape `(samples, time, ...)` where each\n            entry `outputs[s, t]` is the output of the step function\n            at time `t` for sample `s`.\n        new_states: List of tensors, latest states returned by\n            the step function, of shape `(samples, ...)`.\n    """"""\n    ndim = inputs.ndim\n    assert ndim >= 3, \'Input should be at least 3D.\'\n\n    if unroll:\n        if input_length is None:\n            raise ValueError(\'When specifying `unroll=True`, \'\n                             \'an `input_length` \'\n                             \'must be provided to `rnn`.\')\n        if input_length == 1:\n            raise ValueError(\'`input_length=1` is not\'\n                             \' supported when `unroll=True`.\')\n\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = inputs.dimshuffle(axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if mask is not None:\n        if mask.ndim != 2:\n            raise ValueError(\n                \'mask should have `shape=(samples, time)`, \'\n                \'got {}\'.format(mask.shape))\n        mask = mask.dimshuffle([1, 0])\n\n        def get_matching_mask(mask_t, ref_tensor_t):\n            # tf.where needs its condition tensor\n            # to be the same shape as its two\n            # result tensors\n            ndim = ref_tensor_t.ndim\n            for _ in range(ndim - 1):\n                mask_t = expand_dims(mask_t)\n            add_shape = ref_tensor_t.shape[1:]\n            reps = T.concatenate([[1], add_shape], 0)\n            return T.tile(mask_t, reps, ndim=ndim)\n\n        if unroll:\n            indices = list(range(input_length))\n            if go_backwards:\n                indices = indices[::-1]\n\n            successive_outputs = []\n            successive_states = []\n            states = initial_states\n            for i in indices:\n                output, new_states = step_function(inputs[i], states + constants)\n                if getattr(output, \'_uses_learning_phase\', False):\n                    uses_learning_phase = True\n\n                if len(successive_outputs) == 0:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output_mask = get_matching_mask(mask[i], output)\n                output = T.switch(output_mask, output, prev_output)\n                kept_states = []\n                for state, new_state in zip(states, new_states):\n                    state_mask = get_matching_mask(mask[i], state)\n                    kept_states.append(T.switch(state_mask, new_state, state))\n                states = kept_states\n\n                successive_outputs.append(output)\n                successive_states.append(states)\n\n            outputs = T.stack(*successive_outputs)\n            states = []\n            for i in range(len(successive_states[-1])):\n                new_states = []\n                for states_at_step in successive_states:\n                    new_states.append(states_at_step[i])\n                states.append(T.stack(*new_states))\n        else:\n            # build an all-zero tensor of shape (samples, output_dim)\n            initial_output = step_function(inputs[0], initial_states + constants)\n            initial_output = initial_output[0] * 0\n            # Theano gets confused by broadcasting patterns in the scan op\n            initial_output = T.unbroadcast(initial_output, 0, 1)\n            if len(initial_states) > 0:\n                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n\n            def _step(inputs, mask, output_tm1, *states):\n                outputs, new_states = step_function(inputs, states)\n                if getattr(outputs, \'_uses_learning_phase\', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                # output previous output if masked.\n                output_mask = get_matching_mask(mask, outputs)\n                outputs = T.switch(output_mask, outputs, output_tm1)\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    state_mask = get_matching_mask(mask, state)\n                    return_states.append(T.switch(state_mask, new_state, state))\n                return [outputs] + return_states\n\n            results, _ = theano.scan(\n                _step,\n                sequences=[inputs, mask],\n                outputs_info=[initial_output] + initial_states,\n                non_sequences=constants,\n                go_backwards=go_backwards)\n\n            # deal with Theano API inconsistency\n            if isinstance(results, list):\n                outputs = results[0]\n                states = results[1:]\n            else:\n                outputs = results\n                states = []\n    else:\n        if unroll:\n            indices = list(range(input_length))\n            if go_backwards:\n                indices = indices[::-1]\n\n            successive_outputs = []\n            successive_states = []\n            states = initial_states\n            for i in indices:\n                outputs, states = step_function(inputs[i], states + constants)\n                if getattr(outputs, \'_uses_learning_phase\', False):\n                    uses_learning_phase = True\n                successive_outputs.append(outputs)\n                successive_states.append(states)\n            outputs = T.stack(*successive_outputs)\n            states = []\n            for i in range(len(successive_states[-1])):\n                states.append(T.stack(\n                    *[states_at_step[i] for states_at_step in successive_states]))\n\n        else:\n            def _step(inputs, *states):\n                outputs, new_states = step_function(inputs, states)\n                if getattr(outputs, \'_uses_learning_phase\', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                return [outputs] + new_states\n\n            # Theano likes to make shape==1 dimensions\n            # in the initial states (outputs_info) broadcastable\n            if len(initial_states) > 0:\n                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n\n            results, _ = theano.scan(\n                _step,\n                sequences=inputs,\n                outputs_info=[None] + initial_states,\n                non_sequences=constants,\n                go_backwards=go_backwards)\n\n            # deal with Theano API inconsistency\n            if isinstance(results, list):\n                outputs = results[0]\n                states = results[1:]\n            else:\n                outputs = results\n                states = []\n\n    outputs = T.squeeze(outputs)\n    last_output = outputs[-1]\n\n    axes = [1, 0] + list(range(2, outputs.ndim))\n    outputs = outputs.dimshuffle(axes)\n    states = [T.squeeze(state[-1]) for state in states]\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, states\n\n\ndef switch(condition, then_expression, else_expression):\n    """"""Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: scalar tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n    """"""\n    if callable(then_expression):\n        then_expression = then_expression()\n    if callable(else_expression):\n        else_expression = else_expression()\n    cond_ndim = ndim(condition)\n    expr_ndim = ndim(then_expression)\n    if cond_ndim < expr_ndim:\n        ndim_diff = expr_ndim - cond_ndim\n        for _ in range(ndim_diff):\n            condition = expand_dims(condition)\n    return T.switch(condition, then_expression, else_expression)\n\n\ndef in_train_phase(x, alt, training=None):\n    """"""Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    """"""\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    if callable(x):\n        x = x()\n    if callable(alt):\n        alt = alt()\n\n    # else: assume learning phase is a placeholder tensor.\n    x = ifelse(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x\n\n\ndef in_test_phase(x, alt, training=None):\n    """"""Selects `x` in test phase, and `alt` otherwise.\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    """"""\n    return in_train_phase(alt, x, training=training)\n\n\n# NN OPERATIONS\n\ndef _assert_has_capability(module, func):\n    if not hasattr(module, func):\n        raise EnvironmentError(\n            \'It looks like like your version of \'\n            \'Theano is out of date. \'\n            \'Install the latest version with:\\n\'\n            \'pip install git+git://github.com/Theano/Theano.git \'\n            \'--upgrade --no-deps\')\n\n\ndef elu(x, alpha=1.0):\n    """""" Exponential linear unit\n\n    # Arguments\n        x: Tensor to compute the activation function for.\n        alpha: scalar\n    """"""\n    _assert_has_capability(T.nnet, \'elu\')\n    return T.nnet.elu(x, alpha)\n\n\ndef relu(x, alpha=0., max_value=None, threshold=0.):\n    _assert_has_capability(T.nnet, \'relu\')\n\n    if alpha != 0.:\n        if threshold != 0.:\n            negative_part = T.nnet.relu(-x + threshold)\n        else:\n            negative_part = T.nnet.relu(-x)\n\n    if threshold != 0.:\n        x = x * T.cast(T.gt(x, threshold), floatx())\n    else:\n        x = T.nnet.relu(x)\n\n    if max_value is not None:\n        x = T.clip(x, 0.0, max_value)\n\n    if alpha != 0.:\n        x -= alpha * negative_part\n\n    return x\n\n\ndef softmax(x, axis=-1):\n    if (axis == -1 or axis == x.ndim - 1) and x.ndim == 2:\n        return T.nnet.softmax(x)\n    xm = x.max(axis=axis, keepdims=True)\n    return T.exp(x - xm) / T.exp(\n        x - xm).sum(axis=axis, keepdims=True)\n\n\ndef softplus(x):\n    return T.nnet.softplus(x)\n\n\ndef softsign(x):\n    return T_softsign(x)\n\n\ndef categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    output_dimensions = list(range(len(int_shape(output))))\n    if axis != -1 and axis not in output_dimensions:\n        raise ValueError(\n            \'{}{}{}\'.format(\n                \'Unexpected channels axis {}. \'.format(axis),\n                \'Expected to be -1 or one of the axes of `output`, \',\n                \'which has {} dimensions.\'.format(len(int_shape(output)))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis != -1 and axis != output_dimensions[-1]:\n        permutation = output_dimensions[:axis]\n        permutation += output_dimensions[axis + 1:] + [axis]\n        output = permute_dimensions(output, permutation)\n        target = permute_dimensions(target, permutation)\n    if from_logits:\n        output = T.nnet.softmax(output)\n    else:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= output.sum(axis=-1, keepdims=True)\n    # avoid numerical instability with _EPSILON clipping\n    output = T.clip(output, epsilon(), 1.0 - epsilon())\n    return T.nnet.categorical_crossentropy(output, target)\n\n\ndef sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    output_dimensions = list(range(len(int_shape(output))))\n    if axis != -1 and axis not in output_dimensions:\n        raise ValueError(\n            \'{}{}{}\'.format(\n                \'Unexpected channels axis {}. \'.format(axis),\n                \'Expected to be -1 or one of the axes of `output`, \',\n                \'which has {} dimensions.\'.format(len(int_shape(output)))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis != -1 and axis != output_dimensions[-1]:\n        permutation = output_dimensions[:axis]\n        permutation += output_dimensions[axis + 1:] + [axis]\n        output = permute_dimensions(output, permutation)\n        target = permute_dimensions(target, permutation)\n    target = T.cast(T.flatten(target), \'int32\')\n    target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])\n    target = reshape(target, shape(output))\n    return categorical_crossentropy(target, output, from_logits, axis=-1)\n\n\ndef binary_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = T.nnet.sigmoid(output)\n    # avoid numerical instability with _EPSILON clipping\n    output = T.clip(output, epsilon(), 1.0 - epsilon())\n    return T.nnet.binary_crossentropy(output, target)\n\n\ndef sigmoid(x):\n    return T.nnet.sigmoid(x)\n\n\ndef hard_sigmoid(x):\n    return T.nnet.hard_sigmoid(x)\n\n\ndef tanh(x):\n    return T.tanh(x)\n\n\ndef dropout(x, level, noise_shape=None, seed=None):\n    """"""Sets entries in `x` to zero at random,\n    while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n    """"""\n    if level < 0. or level >= 1:\n        raise ValueError(\'Dropout level must be in interval [0, 1[.\')\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    if isinstance(noise_shape, list):\n        noise_shape = tuple(noise_shape)\n\n    rng = RandomStreams(seed=seed)\n    retain_prob = 1. - level\n\n    if noise_shape is None:\n        random_tensor = rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)\n    else:\n        random_tensor = rng.binomial(noise_shape, p=retain_prob, dtype=x.dtype)\n        random_tensor = T.patternbroadcast(random_tensor,\n                                           [dim == 1 for dim in noise_shape])\n    x *= random_tensor\n    x /= retain_prob\n    return x\n\n\ndef l2_normalize(x, axis=None):\n    square_sum = T.sum(T.square(x), axis=axis, keepdims=True)\n    norm = T.sqrt(T.maximum(square_sum, epsilon()))\n    return x / norm\n\n\ndef in_top_k(predictions, targets, k):\n    """"""Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    """"""\n    # handle k < 1 and k >= predictions.shape[1] cases to match TF behavior\n    if k < 1:\n        # dtype=\'bool\' is only available since Theano 0.9.0\n        try:\n            return T.zeros_like(targets, dtype=\'bool\')\n        except TypeError:\n            return T.zeros_like(targets, dtype=\'int8\')\n\n    if k >= int_shape(predictions)[1]:\n        try:\n            return T.ones_like(targets, dtype=\'bool\')\n        except TypeError:\n            return T.ones_like(targets, dtype=\'int8\')\n\n    predictions_k = T.sort(predictions)[:, -k]\n    targets_values = predictions[T.arange(targets.shape[0]), targets]\n    return T.ge(targets_values, predictions_k)\n\n\n# CONVOLUTIONS\n\ndef _preprocess_conv2d_input(x, data_format):\n    if data_format == \'channels_last\':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, rows, cols)\n        # TF input shape: (samples, rows, cols, input_depth)\n        x = x.dimshuffle((0, 3, 1, 2))\n    return x\n\n\ndef _preprocess_conv3d_input(x, data_format):\n    if data_format == \'channels_last\':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, rows, cols, slices)\n        # TF input shape: (samples, rows, cols, slices, input_depth)\n        x = x.dimshuffle((0, 4, 1, 2, 3))\n    return x\n\n\ndef _preprocess_conv2d_kernel(kernel, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(rows, cols, input_depth, depth)`,\n    # independently of `data_format`.\n    # Theano expects `(depth, input_depth, rows, cols)`.\n    kernel = kernel.dimshuffle((3, 2, 0, 1))\n    return kernel\n\n\ndef _preprocess_conv2d_depthwise_kernel(kernel, kernel_shape, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(rows, cols, input_depth, depth)`,\n    # independently of `data_format`.\n    # Theano expects `(input_depth * depth, 1, rows, cols)`\n    # for depthwise convolution.\n    kernel = kernel[::-1, ::-1, :, :]\n    kernel = kernel.dimshuffle((2, 3, 0, 1))\n    kernel = reshape(kernel, kernel_shape)\n    return kernel\n\n\ndef _preprocess_conv3d_kernel(kernel, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(space, input_depth, depth)`,\n    # independently of `data_format`.\n    # Theano expects `(depth, input_depth, space)`.\n    kernel = kernel.dimshuffle((4, 3, 0, 1, 2))\n    return kernel\n\n\ndef _preprocess_padding(padding):\n    if padding == \'same\':\n        th_padding = \'half\'\n    elif padding == \'valid\':\n        th_padding = \'valid\'\n    elif padding == \'full\':\n        th_padding = \'full\'\n    else:\n        raise ValueError(\'Border mode not supported:\', str(padding))\n    return th_padding\n\n\ndef _preprocess_conv2d_image_shape(image_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if data_format == \'channels_last\':\n        if image_shape:\n            image_shape = transpose_shape(image_shape, \'channels_first\',\n                                          spatial_axes=(1, 2))\n    if image_shape is not None:\n        image_shape = tuple(int_or_none(v) for v in image_shape)\n    return image_shape\n\n\ndef _preprocess_conv3d_volume_shape(volume_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if data_format == \'channels_last\':\n        if volume_shape:\n            volume_shape = (volume_shape[0], volume_shape[4],\n                            volume_shape[1], volume_shape[2], volume_shape[3])\n    if volume_shape is not None:\n        volume_shape = tuple(int_or_none(v) for v in volume_shape)\n    return volume_shape\n\n\ndef _preprocess_conv2d_filter_shape(filter_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if filter_shape:\n        filter_shape = (filter_shape[3], filter_shape[2],\n                        filter_shape[0], filter_shape[1])\n    if filter_shape is not None:\n        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n    return filter_shape\n\n\ndef _preprocess_conv2d_depthwise_filter_shape(filter_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if filter_shape:\n        filter_shape = (filter_shape[3] * filter_shape[2], 1,\n                        filter_shape[0], filter_shape[1])\n    if filter_shape is not None:\n        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n    return filter_shape\n\n\ndef _preprocess_conv3d_filter_shape(filter_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if filter_shape:\n        filter_shape = (filter_shape[4], filter_shape[3],\n                        filter_shape[0], filter_shape[1], filter_shape[2])\n    if filter_shape is not None:\n        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n    return filter_shape\n\n\ndef _postprocess_conv2d_output(conv_out, x,\n                               padding, kernel_shape,\n                               strides, data_format):\n    if padding == \'same\':\n        if kernel_shape[2] % 2 == 0:\n            i = (x.shape[2] + strides[0] - 1) // strides[0]\n            conv_out = conv_out[:, :, :i, :]\n        if kernel_shape[3] % 2 == 0:\n            i = (x.shape[3] + strides[1] - 1) // strides[1]\n            conv_out = conv_out[:, :, :, :i]\n    if data_format == \'channels_last\':\n        conv_out = conv_out.dimshuffle((0, 2, 3, 1))\n    return conv_out\n\n\ndef _postprocess_conv3d_output(conv_out, x,\n                               padding, kernel_shape,\n                               strides, data_format):\n    if padding == \'same\':\n        if kernel_shape[2] % 2 == 0:\n            i = (x.shape[2] + strides[0] - 1) // strides[0]\n            conv_out = conv_out[:, :, :i, :, :]\n        if kernel_shape[3] % 2 == 0:\n            i = (x.shape[3] + strides[1] - 1) // strides[1]\n            conv_out = conv_out[:, :, :, :i, :]\n        if kernel_shape[4] % 2 == 0:\n            i = (x.shape[4] + strides[2] - 1) // strides[2]\n            conv_out = conv_out[:, :, :, :, :i]\n    if data_format == \'channels_last\':\n        conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n    return conv_out\n\n\ndef conv1d(x, kernel, strides=1, padding=\'valid\',\n           data_format=None, dilation_rate=1):\n    """"""1D convolution.\n\n    # Arguments\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `""same""`, `""causal""` or `""valid""`.\n        data_format: string, one of ""channels_last"", ""channels_first""\n        dilation_rate: integer.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    kernel_shape = int_shape(kernel)\n    if padding == \'causal\':\n        # causal (dilated) convolution:\n        if not kernel_shape:\n            raise AttributeError(\'Causal padding requires kernel._keras_shape set.\')\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = \'valid\'\n    shape = int_shape(x)\n    if data_format == \'channels_last\':\n        # original shape: (batch, length, input_dim)\n        # add dim to x to have (batch, length, 1, input_dim)\n        x = expand_dims(x, 2)\n        # update x._keras_shape\n        if shape is not None:\n            x._keras_shape = (shape[0], shape[1], 1, shape[2])\n    else:\n        # original shape: (batch, input_dim, length)\n        # add dim to x to have (batch, input_dim, length, 1)\n        x = expand_dims(x, 3)\n        # update x._keras_shape\n        if shape is not None:\n            x._keras_shape = (shape[0], shape[1], shape[2], 1)\n    # update dilation rate, strides\n    dilation_rate = (dilation_rate, 1)\n    strides = (strides, 1)\n    # add dim to kernel (always same format independently of data_format)\n    # i.e. (rows, 1, input_depth, depth)\n    kernel = expand_dims(kernel, 1)\n    output = conv2d(x, kernel,\n                    strides=strides, padding=padding,\n                    data_format=data_format, dilation_rate=dilation_rate)\n    # remove added dim\n    if data_format == \'channels_last\':\n        output = squeeze(output, 2)\n    else:\n        output = squeeze(output, 3)\n    return output\n\n\ndef conv2d(x, kernel, strides=(1, 1), padding=\'valid\',\n           data_format=None, dilation_rate=(1, 1)):\n    """"""2D convolution.\n\n    # Arguments\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, ""same"" or ""valid"".\n        data_format: ""channels_last"" or ""channels_first"".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out\n\n\ndef conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding=\'valid\', data_format=None, dilation_rate=(1, 1)):\n    """"""2D deconvolution (transposed convolution).\n\n    # Arguments\n        kernel: kernel tensor.\n        output_shape: desired dimensions of output.\n        strides: strides tuple.\n        padding: string, ""same"" or ""valid"".\n        data_format: ""channels_last"" or ""channels_first"".\n            Whether to use Theano or TensorFlow data format\n            in inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Raises\n        ValueError: if using an even kernel size with padding \'same\'.\n    """"""\n    flip_filters = False\n    data_format = normalize_data_format(data_format)\n\n    if data_format == \'channels_last\':\n        output_shape = (output_shape[0],\n                        output_shape[3],\n                        output_shape[1],\n                        output_shape[2])\n\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n\n    if padding == \'same\' and kernel_shape[0] % 2 == 0:\n        raise ValueError(\'In `Conv2DTranspose`, with padding mode `same`, \'\n                         \'even kernel sizes are not supported with Theano. \'\n                         \'You can set `kernel_size` to an odd number.\')\n\n    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n\n    th_padding = _preprocess_padding(padding)\n    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(\n        imshp=None,\n        kshp=kernel_shape,\n        subsample=strides,\n        border_mode=th_padding,\n        filter_flip=not flip_filters,\n        filter_dilation=dilation_rate)\n    conv_out = op(kernel, x, output_shape[2:])\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out\n\n\ndef separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding=\'valid\', data_format=None, dilation_rate=1):\n    """"""1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides integer.\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `""channels_last""` or\n        `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n    if isinstance(strides, int):\n        strides = (strides,)\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,)\n\n    if data_format == \'channels_last\':\n        spatial_start_dim = 2\n    else:\n        spatial_start_dim = 3\n    x = expand_dims(x, spatial_start_dim)\n    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n    strides = strides + (1,)\n    dilation_rate = dilation_rate + (1,)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    depthwise_kernel_shape = int_shape(depthwise_kernel)\n    if depthwise_kernel_shape is None:\n        # in case of a shared variable\n        depthwise_kernel_shape = depthwise_kernel.eval().shape\n    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(\n        depthwise_kernel_shape, data_format)\n    pointwise_kernel_shape = int_shape(pointwise_kernel)\n    if pointwise_kernel_shape is None:\n        # in case of a shared variable\n        pointwise_kernel_shape = pointwise_kernel.eval().shape\n    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(\n        pointwise_kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(\n        depthwise_kernel, depthwise_kernel_shape, data_format)\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=depthwise_kernel_shape,\n                             filter_dilation=dilation_rate,\n                             num_groups=image_shape[1])\n    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n                             border_mode=th_padding,\n                             subsample=(1, 1),\n                             input_shape=None,\n                             filter_shape=pointwise_kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          pointwise_kernel_shape,\n                                          strides, data_format)\n    conv_out = squeeze(conv_out, spatial_start_dim)\n    return conv_out\n\n\ndef separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding=\'valid\', data_format=None, dilation_rate=(1, 1)):\n    """"""2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `""channels_last""` or\n        `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    depthwise_kernel_shape = int_shape(depthwise_kernel)\n    if depthwise_kernel_shape is None:\n        # in case of a shared variable\n        depthwise_kernel_shape = depthwise_kernel.eval().shape\n    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(\n        depthwise_kernel_shape, data_format)\n    pointwise_kernel_shape = int_shape(pointwise_kernel)\n    if pointwise_kernel_shape is None:\n        # in case of a shared variable\n        pointwise_kernel_shape = pointwise_kernel.eval().shape\n    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(\n        pointwise_kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(\n        depthwise_kernel, depthwise_kernel_shape, data_format)\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=depthwise_kernel_shape,\n                             filter_dilation=dilation_rate,\n                             num_groups=image_shape[1])\n    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n                             border_mode=th_padding,\n                             subsample=(1, 1),\n                             input_shape=None,\n                             filter_shape=pointwise_kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          pointwise_kernel_shape,\n                                          strides, data_format)\n    return conv_out\n\n\ndef depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding=\'valid\',\n                     data_format=None, dilation_rate=(1, 1)):\n    """"""2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `""same""` or `""valid""`.\n        data_format: string, `""channels_last""` or `""channels_first""`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `""channels_last""` or\n        `""channels_first""`.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    depthwise_kernel_shape = int_shape(depthwise_kernel)\n    if depthwise_kernel_shape is None:\n        # in case of a shared variable\n        depthwise_kernel_shape = depthwise_kernel.eval().shape\n    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(\n        depthwise_kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(\n        depthwise_kernel, depthwise_kernel_shape, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=depthwise_kernel_shape,\n                             filter_dilation=dilation_rate,\n                             num_groups=image_shape[1])\n    conv_out = _postprocess_conv2d_output(\n        conv_out, x, padding, depthwise_kernel_shape, strides, data_format)\n    return conv_out\n\n\ndef conv3d(x, kernel, strides=(1, 1, 1),\n           padding=\'valid\', data_format=None,\n           dilation_rate=(1, 1, 1)):\n    """"""3D convolution.\n\n    # Arguments\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, ""same"" or ""valid"".\n        data_format: ""channels_last"" or ""channels_first"".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n    """"""\n    data_format = normalize_data_format(data_format)\n\n    volume_shape = _preprocess_conv3d_volume_shape(int_shape(x), data_format)\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv3d(x, kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=volume_shape,\n                             filter_shape=kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out\n\n\ndef conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding=\'valid\', data_format=None):\n    """"""3D deconvolution (transposed convolution).\n\n    # Arguments\n        kernel: kernel tensor.\n        output_shape: desired dimensions of output.\n        strides: strides tuple.\n        padding: string, ""same"" or ""valid"".\n        data_format: ""channels_last"" or ""channels_first"".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n\n    # Raises\n        ValueError: if using an even kernel size with padding \'same\'.\n    """"""\n    flip_filters = False\n    data_format = normalize_data_format(data_format)\n\n    if data_format == \'channels_last\':\n        output_shape = (output_shape[0],\n                        output_shape[4],\n                        output_shape[1],\n                        output_shape[2],\n                        output_shape[3])\n\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n\n    if padding == \'same\' and kernel_shape[0] % 2 == 0:\n        raise ValueError(\'In `Conv3DTranspose`, with padding mode `same`, \'\n                         \'even kernel sizes are not supported with Theano. \'\n                         \'You can set `kernel_size` to an odd number.\')\n\n    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n\n    th_padding = _preprocess_padding(padding)\n    op = T.nnet.abstract_conv.AbstractConv3d_gradInputs(imshp=None,\n                                                        kshp=kernel_shape,\n                                                        subsample=strides,\n                                                        border_mode=th_padding,\n                                                        filter_flip=not flip_filters)\n    conv_out = op(kernel, x, output_shape[2:])\n    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out\n\n\ndef pool2d(x, pool_size, strides=(1, 1), padding=\'valid\',\n           data_format=None, pool_mode=\'max\'):\n    data_format = normalize_data_format(data_format)\n\n    assert pool_size[0] >= 1 and pool_size[1] >= 1\n\n    if padding == \'same\':\n        odd_pad_w = pool_size[0] > 2 and pool_size[0] % 2 == 1\n        w_pad = pool_size[0] - 2 if odd_pad_w else pool_size[0] - 1\n        odd_pad_h = pool_size[1] > 2 and pool_size[1] % 2 == 1\n        h_pad = pool_size[1] - 2 if odd_pad_h else pool_size[1] - 1\n        pad = (w_pad, h_pad)\n    elif padding == \'valid\':\n        pad = (0, 0)\n    else:\n        raise ValueError(\'Invalid border mode:\', padding)\n\n    if data_format == \'channels_last\':\n        x = x.dimshuffle((0, 3, 1, 2))\n\n    if pool_mode == \'max\':\n        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode=\'max\')\n    elif pool_mode == \'avg\':\n        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode=\'average_exc_pad\')\n    else:\n        raise ValueError(\'Invalid pooling mode:\', pool_mode)\n    if padding == \'same\':\n        expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n        expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n        pool_out = pool_out[:, :,\n                            : expected_width,\n                            : expected_height]\n\n    if data_format == \'channels_last\':\n        pool_out = pool_out.dimshuffle((0, 2, 3, 1))\n    return pool_out\n\n\ndef pool3d(x, pool_size, strides=(1, 1, 1), padding=\'valid\',\n           data_format=None, pool_mode=\'max\'):\n    data_format = normalize_data_format(data_format)\n\n    if padding == \'same\':\n        w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n        h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n        d_pad = pool_size[2] - 2 if pool_size[2] % 2 == 1 else pool_size[2] - 1\n        pad = (w_pad, h_pad, d_pad)\n    elif padding == \'valid\':\n        pad = (0, 0, 0)\n    else:\n        raise ValueError(\'Invalid padding:\', padding)\n\n    if data_format == \'channels_last\':\n        x = x.dimshuffle((0, 4, 1, 2, 3))\n\n    if pool_mode == \'max\':\n        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode=\'max\')\n    elif pool_mode == \'avg\':\n        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode=\'average_exc_pad\')\n    else:\n        raise ValueError(\'Invalid pooling mode:\', pool_mode)\n\n    if padding == \'same\':\n        expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n        expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n        expected_depth = (x.shape[4] + strides[2] - 1) // strides[2]\n\n        pool_out = pool_out[:, :,\n                            : expected_width,\n                            : expected_height,\n                            : expected_depth]\n\n    if data_format == \'channels_last\':\n        pool_out = pool_out.dimshuffle((0, 2, 3, 4, 1))\n    return pool_out\n\n\ndef bias_add(x, bias, data_format=None):\n    data_format = normalize_data_format(data_format)\n    if ndim(bias) != 1 and ndim(bias) != ndim(x) - 1:\n        raise ValueError(\'Unexpected bias dimensions %d, \'\n                         \'expect to be 1 or %d dimensions\'\n                         % (ndim(bias), ndim(x) - 1))\n    bias_shape = tuple(bias.shape)\n    if ndim(x) == 5:\n        if data_format == \'channels_first\':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n        elif data_format == \'channels_last\':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, 1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 4:\n        if data_format == \'channels_first\':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == \'channels_last\':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if data_format == \'channels_first\':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1))\n            else:\n                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n        elif data_format == \'channels_last\':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    else:\n        x += bias\n    return x\n\n\n# RANDOMNESS\n\n\ndef random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n    return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n\n\ndef random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n    return rng.uniform(shape, low=minval, high=maxval, dtype=dtype)\n\n\ndef random_binomial(shape, p=0.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n    return rng.binomial(shape, p=p, dtype=dtype)\n\n\ndef truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n\n    try:\n        return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype,\n                          truncate=True)\n    except TypeError:\n        normal_t = rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n        # Poor man\'s truncated normal: we literally clip the tensor\n        return T.clip(normal_t, mean - 2 * stddev, mean + 2 * stddev)\n\n\n# Theano implementation of CTC\n# Used with permission from Shawn Tan\n# https://github.com/shawntan/\n# Note that TensorFlow\'s native CTC code is significantly\n# faster than this\n\n\ndef ctc_interleave_blanks(Y):\n    Y_ = T.alloc(-1, Y.shape[0] * 2 + 1)\n    Y_ = T.set_subtensor(Y_[T.arange(Y.shape[0]) * 2 + 1], Y)\n    return Y_\n\n\ndef ctc_create_skip_idxs(Y):\n    skip_idxs = T.arange((Y.shape[0] - 3) // 2) * 2 + 1\n    non_repeats = T.neq(Y[skip_idxs], Y[skip_idxs + 2])\n    return skip_idxs[non_repeats.nonzero()]\n\n\ndef ctc_update_log_p(skip_idxs, zeros, active, log_p_curr, log_p_prev):\n    active_skip_idxs = skip_idxs[(skip_idxs < active).nonzero()]\n    active_next = T.cast(T.minimum(\n        T.maximum(\n            active + 1,\n            T.max(T.concatenate([active_skip_idxs, [-1]])) + 2 + 1\n        ), log_p_curr.shape[0]), \'int32\')\n\n    common_factor = T.max(log_p_prev[:active])\n    p_prev = T.exp(log_p_prev[:active] - common_factor)\n    _p_prev = zeros[:active_next]\n    # copy over\n    _p_prev = T.set_subtensor(_p_prev[:active], p_prev)\n    # previous transitions\n    _p_prev = T.inc_subtensor(_p_prev[1:], _p_prev[:-1])\n    # skip transitions\n    _p_prev = T.inc_subtensor(\n        _p_prev[active_skip_idxs + 2], p_prev[active_skip_idxs])\n    updated_log_p_prev = T.log(_p_prev) + common_factor\n\n    log_p_next = T.set_subtensor(\n        zeros[:active_next],\n        log_p_curr[:active_next] + updated_log_p_prev\n    )\n    return active_next, log_p_next\n\n\ndef ctc_path_probs(predict, Y, alpha=1e-4):\n    smoothed = (1 - alpha) * predict[:, Y] + alpha * np.float32(1.) / Y.shape[0]\n    L = T.log(smoothed)\n    zeros = T.zeros_like(L[0])\n    log_first = zeros\n\n    f_skip_idxs = ctc_create_skip_idxs(Y)\n    # there should be a shortcut to calculating this\n    b_skip_idxs = ctc_create_skip_idxs(Y[::-1])\n\n    def step(log_f_curr, log_b_curr, f_active, log_f_prev, b_active, log_b_prev):\n        f_active_next, log_f_next = ctc_update_log_p(\n            f_skip_idxs, zeros, f_active, log_f_curr, log_f_prev)\n        b_active_next, log_b_next = ctc_update_log_p(\n            b_skip_idxs, zeros, b_active, log_b_curr, log_b_prev)\n        return f_active_next, log_f_next, b_active_next, log_b_next\n\n    [f_active, log_f_probs, b_active, log_b_probs], _ = theano.scan(\n        step,\n        sequences=[L, L[::-1, ::-1]],\n        outputs_info=[np.int32(1), log_first, np.int32(1), log_first])\n\n    idxs = T.arange(L.shape[1]).dimshuffle(\'x\', 0)\n    mask = ((idxs < f_active.dimshuffle(0, \'x\')) &\n            (idxs < b_active.dimshuffle(0, \'x\'))[::-1, ::-1])\n    log_probs = log_f_probs + log_b_probs[::-1, ::-1] - L\n    return log_probs, mask\n\n\ndef ctc_cost(predict, Y):\n    log_probs, mask = ctc_path_probs(predict, ctc_interleave_blanks(Y))\n    common_factor = T.max(log_probs)\n    total_log_prob = T.log(T.sum(T.exp(log_probs - common_factor)[mask.nonzero()]))\n    total_log_prob = total_log_prob + common_factor\n    return -total_log_prob\n\n\n# batchifies original CTC code\ndef ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    """"""Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor (samples, max_string_length) containing the truth labels\n        y_pred: tensor (samples, time_steps, num_categories) containing the\n                prediction, or output of the softmax\n        input_length: tensor (samples,1) containing the sequence length for\n                each batch item in y_pred\n        label_length: tensor (samples,1) containing the sequence length for\n                each batch item in y_true\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element\n    """"""\n\n    def ctc_step(y_true_step, y_pred_step, input_length_step, label_length_step):\n        y_pred_step = y_pred_step[0: input_length_step[0]]\n        y_true_step = y_true_step[0:label_length_step[0]]\n        return ctc_cost(y_pred_step, y_true_step)\n\n    ret, _ = theano.scan(\n        fn=ctc_step,\n        outputs_info=None,\n        sequences=[y_true, y_pred, input_length, label_length]\n    )\n\n    ret = ret.dimshuffle(\'x\', 0)\n    return ret\n\n\n# HIGH ORDER FUNCTIONS\n\ndef map_fn(fn, elems, name=None, dtype=None):\n    """"""Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor, at least 2 dimensional\n        name: A string name for the map node in the graph\n\n    # Returns\n        Tensor with first dimension equal to the elems and second depending on\n        fn\n    """"""\n    return theano.map(fn, elems, name=name)[0]\n\n\ndef foldl(fn, elems, initializer=None, name=None):\n    """"""Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance lambda acc, x: acc + x\n        elems: tensor\n        initializer: The first value used (elems[0] in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Same type and shape as initializer\n    """"""\n    if initializer is None:\n        initializer = elems[0]\n        elems = elems[1:]\n\n    # We need to change the order of the arguments because theano accepts x as\n    # first parameter and accumulator as second\n    return theano.foldl(lambda x, acc: fn(acc, x),\n                        elems, initializer, name=name)[0]\n\n\ndef foldr(fn, elems, initializer=None, name=None):\n    """"""Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance lambda acc, x: acc + x\n        elems: tensor\n        initializer: The first value used (elems[-1] in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Same type and shape as initializer\n    """"""\n    if initializer is None:\n        initializer = elems[-1]\n        elems = elems[:-1]\n\n    # We need to change the order of the arguments because theano accepts x as\n    # first parameter and accumulator as second\n    return theano.foldr(lambda x, acc: fn(acc, x),\n                        elems, initializer, name=name)[0]\n\n\ndef local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = py_slice(i * stride,\n                                i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))\n\n\ndef local_conv2d(inputs,\n                 kernel,\n                 kernel_size,\n                 strides,\n                 output_shape,\n                 data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    if data_format == \'channels_first\':\n        output = []\n        for i in range(output_row):\n            for j in range(output_col):\n                slice_row = py_slice(i * stride_row,\n                                     i * stride_row + kernel_size[0])\n                slice_col = py_slice(j * stride_col,\n                                     j * stride_col + kernel_size[1])\n                x_flatten = reshape(inputs[:, :, slice_row, slice_col],\n                                    (1, -1, feature_dim))\n                output.append(dot(x_flatten,\n                                  kernel[i * output_col + j, :, :]))\n        output = concatenate(output, axis=0)\n        output = reshape(output,\n                         (output_row, output_col, -1, filters))\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        xs = []\n        for i in range(output_row):\n            for j in range(output_col):\n                slice_row = py_slice(i * stride_row,\n                                     i * stride_row + kernel_size[0])\n                slice_col = py_slice(j * stride_col,\n                                     j * stride_col + kernel_size[1])\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n        x_aggregate = concatenate(xs, axis=0)\n        output = batch_dot(x_aggregate, kernel)\n        output = reshape(output,\n                         (output_row, output_col, -1, filters))\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output\n\n\ndef ctc_label_dense_to_sparse(labels, label_lengths):\n    raise NotImplementedError\n\n\ndef ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1,\n               merge_repeated=False):\n    raise NotImplementedError\n\n\ndef control_dependencies(control_inputs):\n    @contextmanager\n    def nullcontextmanager():\n        yield\n\n    return nullcontextmanager()\n'"
keras/callbacks/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .callbacks import Callback\nfrom .callbacks import CallbackList\nfrom .callbacks import BaseLogger\nfrom .callbacks import TerminateOnNaN\nfrom .callbacks import ProgbarLogger\nfrom .callbacks import History\nfrom .callbacks import ModelCheckpoint\nfrom .callbacks import EarlyStopping\nfrom .callbacks import RemoteMonitor\nfrom .callbacks import LearningRateScheduler\nfrom .callbacks import ReduceLROnPlateau\nfrom .callbacks import CSVLogger\nfrom .callbacks import LambdaCallback\n\nfrom .. import backend as K\n\nif K.backend() == 'tensorflow' and not K.tensorflow_backend._is_tf_1():\n    from .tensorboard_v2 import TensorBoard\nelse:\n    from .tensorboard_v1 import TensorBoard\n"""
keras/callbacks/callbacks.py,0,"b'""""""Callbacks: utilities called at certain points during model training.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport csv\nimport six\n\nimport numpy as np\nimport time\nimport json\nimport warnings\nimport io\n\nfrom collections import deque\nfrom collections import OrderedDict\nfrom collections import Iterable\nfrom collections import defaultdict\nfrom ..utils.generic_utils import Progbar\nfrom .. import backend as K\nfrom ..engine.training_utils import standardize_input_data\n\ntry:\n    import requests\nexcept ImportError:\n    requests = None\n\n\n_TRAIN = \'train\'\n_TEST = \'test\'\n_PREDICT = \'predict\'\n\n\nclass CallbackList(object):\n    """"""Container abstracting a list of callbacks.\n\n    # Arguments\n        callbacks: List of `Callback` instances.\n        queue_length: Queue length for keeping\n            running statistics over callback execution time.\n    """"""\n\n    def __init__(self, callbacks=None, queue_length=10):\n        callbacks = callbacks or []\n        self.callbacks = [c for c in callbacks]\n        self.queue_length = queue_length\n        self.params = {}\n        self.model = None\n        self._reset_batch_timing()\n\n    def _reset_batch_timing(self):\n        self._delta_t_batch = 0.\n        self._delta_ts = defaultdict(lambda: deque([], maxlen=self.queue_length))\n\n    def append(self, callback):\n        self.callbacks.append(callback)\n\n    def set_params(self, params):\n        self.params = params\n        for callback in self.callbacks:\n            callback.set_params(params)\n\n    def set_model(self, model):\n        self.model = model\n        for callback in self.callbacks:\n            callback.set_model(model)\n\n    def _call_batch_hook(self, mode, hook, batch, logs=None):\n        """"""Helper function for all batch_{begin | end} methods.""""""\n        if not self.callbacks:\n            return\n        hook_name = \'on_{mode}_batch_{hook}\'.format(mode=mode, hook=hook)\n        if hook == \'end\':\n            if not hasattr(self, \'_t_enter_batch\'):\n                self._t_enter_batch = time.time()\n            # Batch is ending, calculate batch time\n            self._delta_t_batch = time.time() - self._t_enter_batch\n\n        logs = logs or {}\n        t_before_callbacks = time.time()\n        for callback in self.callbacks:\n            batch_hook = getattr(callback, hook_name)\n            batch_hook(batch, logs)\n        self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\n\n        delta_t_median = np.median(self._delta_ts[hook_name])\n        if (self._delta_t_batch > 0. and\n           delta_t_median > 0.95 * self._delta_t_batch and\n           delta_t_median > 0.1):\n            warnings.warn(\n                \'Method (%s) is slow compared \'\n                \'to the batch update (%f). Check your callbacks.\'\n                % (hook_name, delta_t_median), RuntimeWarning)\n\n        if hook == \'begin\':\n            self._t_enter_batch = time.time()\n\n    def _call_begin_hook(self, mode):\n        """"""Helper function for on_{train|test|predict}_begin methods.""""""\n        if mode == _TRAIN:\n            self.on_train_begin()\n        elif mode == _TEST:\n            self.on_test_begin()\n        else:\n            self.on_predict_begin()\n\n    def _call_end_hook(self, mode):\n        """"""Helper function for on_{train|test|predict}_end methods.""""""\n        if mode == _TRAIN:\n            self.on_train_end()\n        elif mode == _TEST:\n            self.on_test_end()\n        else:\n            self.on_predict_end()\n\n    def on_batch_begin(self, batch, logs=None):\n        self._call_batch_hook(_TRAIN, \'begin\', batch, logs=logs)\n\n    def on_batch_end(self, batch, logs=None):\n        self._call_batch_hook(_TRAIN, \'end\', batch, logs=logs)\n\n    def on_epoch_begin(self, epoch, logs=None):\n        """"""Calls the `on_epoch_begin` methods of its callbacks.\n\n        This function should only be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, Currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n        self._reset_batch_timing()\n\n    def on_epoch_end(self, epoch, logs=None):\n        """"""Calls the `on_epoch_end` methods of its callbacks.\n\n        This function should only be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, metric results for this training epoch, and for the\n                validation epoch if validation is performed. Validation result keys\n                are prefixed with `val_`.\n        """"""\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)\n\n    def on_train_batch_begin(self, batch, logs=None):\n        """"""Calls the `on_train_batch_begin` methods of its callbacks.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        """"""\n        self._call_batch_hook(_TRAIN, \'begin\', batch, logs=logs)\n\n    def on_train_batch_end(self, batch, logs=None):\n        """"""Calls the `on_train_batch_end` methods of its callbacks.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        """"""\n        self._call_batch_hook(_TRAIN, \'end\', batch, logs=logs)\n\n    def on_test_batch_begin(self, batch, logs=None):\n        """"""Calls the `on_test_batch_begin` methods of its callbacks.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        """"""\n        self._call_batch_hook(_TEST, \'begin\', batch, logs=logs)\n\n    def on_test_batch_end(self, batch, logs=None):\n        """"""Calls the `on_test_batch_end` methods of its callbacks.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        """"""\n        self._call_batch_hook(_TEST, \'end\', batch, logs=logs)\n\n    def on_predict_batch_begin(self, batch, logs=None):\n        """"""Calls the `on_predict_batch_begin` methods of its callbacks.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        """"""\n        self._call_batch_hook(_PREDICT, \'begin\', batch, logs=logs)\n\n    def on_predict_batch_end(self, batch, logs=None):\n        """"""Calls the `on_predict_batch_end` methods of its callbacks.\n\n        # Argument\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        """"""\n        self._call_batch_hook(_PREDICT, \'end\', batch, logs=logs)\n\n    def on_train_begin(self, logs=None):\n        """"""Calls the `on_train_begin` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)\n\n    def on_train_end(self, logs=None):\n        """"""Calls the `on_train_end` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        for callback in self.callbacks:\n            callback.on_train_end(logs)\n\n    def on_test_begin(self, logs=None):\n        """"""Calls the `on_test_begin` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        for callback in self.callbacks:\n            callback.on_test_begin(logs)\n\n    def on_test_end(self, logs=None):\n        """"""Calls the `on_test_end` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        for callback in self.callbacks:\n            callback.on_test_end(logs)\n\n    def on_predict_begin(self, logs=None):\n        """"""Calls the `on_predict_begin` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        for callback in self.callbacks:\n            callback.on_predict_begin(logs)\n\n    def on_predict_end(self, logs=None):\n        """"""Calls the `on_predict_end` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n        for callback in self.callbacks:\n            callback.on_predict_end(logs)\n\n    def __iter__(self):\n        return iter(self.callbacks)\n\n\nclass Callback(object):\n    """"""Abstract base class used to build new callbacks.\n\n    # Properties\n        params: dict. Training parameters\n            (eg. verbosity, batch size, number of epochs...).\n        model: instance of `keras.models.Model`.\n            Reference of the model being trained.\n\n    The `logs` dictionary that callback methods\n    take as argument will contain keys for quantities relevant to\n    the current batch or epoch.\n\n    Currently, the `.fit()` method of the `Sequential` model class\n    will include the following quantities in the `logs` that\n    it passes to its callbacks:\n\n        on_epoch_end: logs include `acc` and `loss`, and\n            optionally include `val_loss`\n            (if validation is enabled in `fit`), and `val_acc`\n            (if validation and accuracy monitoring are enabled).\n        on_batch_begin: logs include `size`,\n            the number of samples in the current batch.\n        on_batch_end: logs include `loss`, and optionally `acc`\n            (if accuracy monitoring is enabled).\n    """"""\n\n    def __init__(self):\n        self.validation_data = None\n        self.model = None\n\n    def set_params(self, params):\n        self.params = params\n\n    def set_model(self, model):\n        self.model = model\n\n    def on_batch_begin(self, batch, logs=None):\n        """"""A backwards compatibility alias for `on_train_batch_begin`.""""""\n\n    def on_batch_end(self, batch, logs=None):\n        """"""A backwards compatibility alias for `on_train_batch_end`.""""""\n\n    def on_epoch_begin(self, epoch, logs=None):\n        """"""Called at the start of an epoch.\n\n        Subclasses should override for any actions to run. This function should only\n        be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n    def on_epoch_end(self, epoch, logs=None):\n        """"""Called at the end of an epoch.\n\n        Subclasses should override for any actions to run. This function should only\n        be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, metric results for this training epoch, and for the\n                validation epoch if validation is performed. Validation result keys\n                are prefixed with `val_`.\n        """"""\n\n    def on_train_batch_begin(self, batch, logs=None):\n        """"""Called at the beginning of a training batch in `fit` methods.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        """"""\n        # For backwards compatibility\n        self.on_batch_begin(batch, logs=logs)\n\n    def on_train_batch_end(self, batch, logs=None):\n        """"""Called at the end of a training batch in `fit` methods.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        """"""\n        # For backwards compatibility\n        self.on_batch_end(batch, logs=logs)\n\n    def on_test_batch_begin(self, batch, logs=None):\n        """"""Called at the beginning of a batch in `evaluate` methods.\n\n        Also called at the beginning of a validation batch in the `fit` methods,\n        if validation data is provided.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        """"""\n\n    def on_test_batch_end(self, batch, logs=None):\n        """"""Called at the end of a batch in `evaluate` methods.\n\n        Also called at the end of a validation batch in the `fit` methods,\n        if validation data is provided.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        """"""\n\n    def on_predict_batch_begin(self, batch, logs=None):\n        """"""Called at the beginning of a batch in `predict` methods.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        """"""\n\n    def on_predict_batch_end(self, batch, logs=None):\n        """"""Called at the end of a batch in `predict` methods.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        """"""\n\n    def on_train_begin(self, logs=None):\n        """"""Called at the beginning of training.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n    def on_train_end(self, logs=None):\n        """"""Called at the end of training.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n    def on_test_begin(self, logs=None):\n        """"""Called at the beginning of evaluation or validation.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n    def on_test_end(self, logs=None):\n        """"""Called at the end of evaluation or validation.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n    def on_predict_begin(self, logs=None):\n        """"""Called at the beginning of prediction.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n    def on_predict_end(self, logs=None):\n        """"""Called at the end of prediction.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        """"""\n\n\nclass BaseLogger(Callback):\n    """"""Callback that accumulates epoch averages of metrics.\n\n    This callback is automatically applied to every Keras model.\n\n    # Arguments\n        stateful_metrics: Iterable of string names of metrics that\n            should *not* be averaged over an epoch.\n            Metrics in this list will be logged as-is in `on_epoch_end`.\n            All others will be averaged in `on_epoch_end`.\n    """"""\n\n    def __init__(self, stateful_metrics=None):\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.seen = 0\n        self.totals = {}\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get(\'size\', 0)\n        self.seen += batch_size\n\n        for k, v in logs.items():\n            if k in self.stateful_metrics:\n                self.totals[k] = v\n            else:\n                if k in self.totals:\n                    self.totals[k] += v * batch_size\n                else:\n                    self.totals[k] = v * batch_size\n\n    def on_epoch_end(self, epoch, logs=None):\n        if logs is not None:\n            for k in self.params[\'metrics\']:\n                if k in self.totals:\n                    # Make value available to next callbacks.\n                    if k in self.stateful_metrics:\n                        logs[k] = self.totals[k]\n                    else:\n                        logs[k] = self.totals[k] / self.seen\n\n\nclass TerminateOnNaN(Callback):\n    """"""Callback that terminates training when a NaN loss is encountered.\n    """"""\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        loss = logs.get(\'loss\')\n        if loss is not None:\n            if np.isnan(loss) or np.isinf(loss):\n                print(\'Batch %d: Invalid loss, terminating training\' % (batch))\n                self.model.stop_training = True\n\n\nclass ProgbarLogger(Callback):\n    """"""Callback that prints metrics to stdout.\n\n    # Arguments\n        count_mode: One of ""steps"" or ""samples"".\n            Whether the progress bar should\n            count samples seen or steps (batches) seen.\n        stateful_metrics: Iterable of string names of metrics that\n            should *not* be averaged over an epoch.\n            Metrics in this list will be logged as-is.\n            All others will be averaged over time (e.g. loss, etc).\n\n    # Raises\n        ValueError: In case of invalid `count_mode`.\n    """"""\n\n    def __init__(self, count_mode=\'samples\',\n                 stateful_metrics=None):\n        super(ProgbarLogger, self).__init__()\n        if count_mode == \'samples\':\n            self.use_steps = False\n        elif count_mode == \'steps\':\n            self.use_steps = True\n        else:\n            raise ValueError(\'Unknown `count_mode`: \' + str(count_mode))\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n    def on_train_begin(self, logs=None):\n        self.verbose = self.params[\'verbose\']\n        self.epochs = self.params[\'epochs\']\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if self.verbose:\n            print(\'Epoch %d/%d\' % (epoch + 1, self.epochs))\n            if self.use_steps:\n                target = self.params[\'steps\']\n            else:\n                target = self.params[\'samples\']\n            self.target = target\n            self.progbar = Progbar(target=self.target,\n                                   verbose=self.verbose,\n                                   stateful_metrics=self.stateful_metrics)\n        self.seen = 0\n\n    def on_batch_begin(self, batch, logs=None):\n        if self.seen < self.target:\n            self.log_values = []\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get(\'size\', 0)\n        if self.use_steps:\n            self.seen += 1\n        else:\n            self.seen += batch_size\n\n        for k in self.params[\'metrics\']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n\n        # Skip progbar update for the last batch;\n        # will be handled by on_epoch_end.\n        if self.verbose and self.seen < self.target:\n            self.progbar.update(self.seen, self.log_values)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for k in self.params[\'metrics\']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n        if self.verbose:\n            self.progbar.update(self.seen, self.log_values)\n\n\nclass History(Callback):\n    """"""Callback that records events into a `History` object.\n\n    This callback is automatically applied to\n    every Keras model. The `History` object\n    gets returned by the `fit` method of models.\n    """"""\n\n    def on_train_begin(self, logs=None):\n        self.epoch = []\n        self.history = {}\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epoch.append(epoch)\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n\n\nclass ModelCheckpoint(Callback):\n    """"""Save the model after every epoch.\n\n    `filepath` can contain named formatting options,\n    which will be filled with the values of `epoch` and\n    keys in `logs` (passed in `on_epoch_end`).\n\n    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\n    then the model checkpoints will be saved with the epoch number and\n    the validation loss in the filename.\n\n    # Arguments\n        filepath: string, path to save the model file.\n        monitor: quantity to monitor.\n        verbose: verbosity mode, 0 or 1.\n        save_best_only: if `save_best_only=True`,\n            the latest best model according to\n            the quantity monitored will not be overwritten.\n        save_weights_only: if True, then only the model\'s weights will be\n            saved (`model.save_weights(filepath)`), else the full model\n            is saved (`model.save(filepath)`).\n        mode: one of {auto, min, max}.\n            If `save_best_only=True`, the decision\n            to overwrite the current save file is made\n            based on either the maximization or the\n            minimization of the monitored quantity. For `val_acc`,\n            this should be `max`, for `val_loss` this should\n            be `min`, etc. In `auto` mode, the direction is\n            automatically inferred from the name of the monitored quantity.\n        period: Interval (number of epochs) between checkpoints.\n    """"""\n\n    def __init__(self, filepath, monitor=\'val_loss\', verbose=0,\n                 save_best_only=False, save_weights_only=False,\n                 mode=\'auto\', period=1):\n        super(ModelCheckpoint, self).__init__()\n        self.monitor = monitor\n        self.verbose = verbose\n        self.filepath = filepath\n        self.save_best_only = save_best_only\n        self.save_weights_only = save_weights_only\n        self.period = period\n        self.epochs_since_last_save = 0\n\n        if mode not in [\'auto\', \'min\', \'max\']:\n            warnings.warn(\'ModelCheckpoint mode %s is unknown, \'\n                          \'fallback to auto mode.\' % (mode),\n                          RuntimeWarning)\n            mode = \'auto\'\n\n        if mode == \'min\':\n            self.monitor_op = np.less\n            self.best = np.Inf\n        elif mode == \'max\':\n            self.monitor_op = np.greater\n            self.best = -np.Inf\n        else:\n            if \'acc\' in self.monitor or self.monitor.startswith(\'fmeasure\'):\n                self.monitor_op = np.greater\n                self.best = -np.Inf\n            else:\n                self.monitor_op = np.less\n                self.best = np.Inf\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epochs_since_last_save += 1\n        if self.epochs_since_last_save >= self.period:\n            self.epochs_since_last_save = 0\n            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n            if self.save_best_only:\n                current = logs.get(self.monitor)\n                if current is None:\n                    warnings.warn(\'Can save best model only with %s available, \'\n                                  \'skipping.\' % (self.monitor), RuntimeWarning)\n                else:\n                    if self.monitor_op(current, self.best):\n                        if self.verbose > 0:\n                            print(\'\\nEpoch %05d: %s improved from %0.5f to %0.5f,\'\n                                  \' saving model to %s\'\n                                  % (epoch + 1, self.monitor, self.best,\n                                     current, filepath))\n                        self.best = current\n                        if self.save_weights_only:\n                            self.model.save_weights(filepath, overwrite=True)\n                        else:\n                            self.model.save(filepath, overwrite=True)\n                    else:\n                        if self.verbose > 0:\n                            print(\'\\nEpoch %05d: %s did not improve from %0.5f\' %\n                                  (epoch + 1, self.monitor, self.best))\n            else:\n                if self.verbose > 0:\n                    print(\'\\nEpoch %05d: saving model to %s\' % (epoch + 1, filepath))\n                if self.save_weights_only:\n                    self.model.save_weights(filepath, overwrite=True)\n                else:\n                    self.model.save(filepath, overwrite=True)\n\n\nclass EarlyStopping(Callback):\n    """"""Stop training when a monitored quantity has stopped improving.\n\n    # Arguments\n        monitor: quantity to be monitored.\n        min_delta: minimum change in the monitored quantity\n            to qualify as an improvement, i.e. an absolute\n            change of less than min_delta, will count as no\n            improvement.\n        patience: number of epochs that produced the monitored\n            quantity with no improvement after which training will\n            be stopped.\n            Validation quantities may not be produced for every\n            epoch, if the validation frequency\n            (`model.fit(validation_freq=5)`) is greater than one.\n        verbose: verbosity mode.\n        mode: one of {auto, min, max}. In `min` mode,\n            training will stop when the quantity\n            monitored has stopped decreasing; in `max`\n            mode it will stop when the quantity\n            monitored has stopped increasing; in `auto`\n            mode, the direction is automatically inferred\n            from the name of the monitored quantity.\n        baseline: Baseline value for the monitored quantity to reach.\n            Training will stop if the model doesn\'t show improvement\n            over the baseline.\n        restore_best_weights: whether to restore model weights from\n            the epoch with the best value of the monitored quantity.\n            If False, the model weights obtained at the last step of\n            training are used.\n    """"""\n\n    def __init__(self,\n                 monitor=\'val_loss\',\n                 min_delta=0,\n                 patience=0,\n                 verbose=0,\n                 mode=\'auto\',\n                 baseline=None,\n                 restore_best_weights=False):\n        super(EarlyStopping, self).__init__()\n\n        self.monitor = monitor\n        self.baseline = baseline\n        self.patience = patience\n        self.verbose = verbose\n        self.min_delta = min_delta\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.restore_best_weights = restore_best_weights\n        self.best_weights = None\n\n        if mode not in [\'auto\', \'min\', \'max\']:\n            warnings.warn(\'EarlyStopping mode %s is unknown, \'\n                          \'fallback to auto mode.\' % mode,\n                          RuntimeWarning)\n            mode = \'auto\'\n\n        if mode == \'min\':\n            self.monitor_op = np.less\n        elif mode == \'max\':\n            self.monitor_op = np.greater\n        else:\n            if \'acc\' in self.monitor:\n                self.monitor_op = np.greater\n            else:\n                self.monitor_op = np.less\n\n        if self.monitor_op == np.greater:\n            self.min_delta *= 1\n        else:\n            self.min_delta *= -1\n\n    def on_train_begin(self, logs=None):\n        # Allow instances to be re-used\n        self.wait = 0\n        self.stopped_epoch = 0\n        if self.baseline is not None:\n            self.best = self.baseline\n        else:\n            self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n\n    def on_epoch_end(self, epoch, logs=None):\n        current = self.get_monitor_value(logs)\n        if current is None:\n            return\n\n        if self.monitor_op(current - self.min_delta, self.best):\n            self.best = current\n            self.wait = 0\n            if self.restore_best_weights:\n                self.best_weights = self.model.get_weights()\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n                self.model.stop_training = True\n                if self.restore_best_weights:\n                    if self.verbose > 0:\n                        print(\'Restoring model weights from the end of \'\n                              \'the best epoch\')\n                    self.model.set_weights(self.best_weights)\n\n    def on_train_end(self, logs=None):\n        if self.stopped_epoch > 0 and self.verbose > 0:\n            print(\'Epoch %05d: early stopping\' % (self.stopped_epoch + 1))\n\n    def get_monitor_value(self, logs):\n        monitor_value = logs.get(self.monitor)\n        if monitor_value is None:\n            warnings.warn(\n                \'Early stopping conditioned on metric `%s` \'\n                \'which is not available. Available metrics are: %s\' %\n                (self.monitor, \',\'.join(list(logs.keys()))), RuntimeWarning\n            )\n        return monitor_value\n\n\nclass RemoteMonitor(Callback):\n    """"""Callback used to stream events to a server.\n\n    Requires the `requests` library.\n    Events are sent to `root + \'/publish/epoch/end/\'` by default. Calls are\n    HTTP POST, with a `data` argument which is a\n    JSON-encoded dictionary of event data.\n    If send_as_json is set to True, the content type of the request will be\n    application/json. Otherwise the serialized JSON will be send within a form\n\n    # Arguments\n        root: String; root url of the target server.\n        path: String; path relative to `root` to which the events will be sent.\n        field: String; JSON field under which the data will be stored.\n            The field is used only if the payload is sent within a form\n            (i.e. send_as_json is set to False).\n        headers: Dictionary; optional custom HTTP headers.\n        send_as_json: Boolean; whether the request should be send as\n            application/json.\n    """"""\n\n    def __init__(self,\n                 root=\'http://localhost:9000\',\n                 path=\'/publish/epoch/end/\',\n                 field=\'data\',\n                 headers=None,\n                 send_as_json=False):\n        super(RemoteMonitor, self).__init__()\n\n        self.root = root\n        self.path = path\n        self.field = field\n        self.headers = headers\n        self.send_as_json = send_as_json\n\n    def on_epoch_end(self, epoch, logs=None):\n        if requests is None:\n            raise ImportError(\'RemoteMonitor requires \'\n                              \'the `requests` library.\')\n        logs = logs or {}\n        send = {}\n        send[\'epoch\'] = epoch\n        for k, v in logs.items():\n            if isinstance(v, (np.ndarray, np.generic)):\n                send[k] = v.item()\n            else:\n                send[k] = v\n        try:\n            if self.send_as_json:\n                requests.post(self.root + self.path, json=send, headers=self.headers)\n            else:\n                requests.post(self.root + self.path,\n                              {self.field: json.dumps(send)},\n                              headers=self.headers)\n        except requests.exceptions.RequestException:\n            warnings.warn(\'Warning: could not reach RemoteMonitor \'\n                          \'root server at \' + str(self.root))\n\n\nclass LearningRateScheduler(Callback):\n    """"""Learning rate scheduler.\n\n    # Arguments\n        schedule: a function that takes an epoch index as input\n            (integer, indexed from 0) and current learning rate\n            and returns a new learning rate as output (float).\n        verbose: int. 0: quiet, 1: update messages.\n    """"""\n\n    def __init__(self, schedule, verbose=0):\n        super(LearningRateScheduler, self).__init__()\n        self.schedule = schedule\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, \'lr\'):\n            raise ValueError(\'Optimizer must have a ""lr"" attribute.\')\n        lr = float(K.get_value(self.model.optimizer.lr))\n        try:  # new API\n            lr = self.schedule(epoch, lr)\n        except TypeError:  # old API for backward compatibility\n            lr = self.schedule(epoch)\n        if not isinstance(lr, (float, np.float32, np.float64)):\n            raise ValueError(\'The output of the ""schedule"" function \'\n                             \'should be float.\')\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print(\'\\nEpoch %05d: LearningRateScheduler setting learning \'\n                  \'rate to %s.\' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs[\'lr\'] = K.get_value(self.model.optimizer.lr)\n\n\nclass ReduceLROnPlateau(Callback):\n    """"""Reduce learning rate when a metric has stopped improving.\n\n    Models often benefit from reducing the learning rate by a factor\n    of 2-10 once learning stagnates. This callback monitors a\n    quantity and if no improvement is seen for a \'patience\' number\n    of epochs, the learning rate is reduced.\n\n    # Example\n\n    ```python\n    reduce_lr = ReduceLROnPlateau(monitor=\'val_loss\', factor=0.2,\n                                  patience=5, min_lr=0.001)\n    model.fit(X_train, Y_train, callbacks=[reduce_lr])\n    ```\n\n    # Arguments\n        monitor: quantity to be monitored.\n        factor: factor by which the learning rate will\n            be reduced. new_lr = lr * factor\n        patience: number of epochs that produced the monitored\n            quantity with no improvement after which training will\n            be stopped.\n            Validation quantities may not be produced for every\n            epoch, if the validation frequency\n            (`model.fit(validation_freq=5)`) is greater than one.\n        verbose: int. 0: quiet, 1: update messages.\n        mode: one of {auto, min, max}. In `min` mode,\n            lr will be reduced when the quantity\n            monitored has stopped decreasing; in `max`\n            mode it will be reduced when the quantity\n            monitored has stopped increasing; in `auto`\n            mode, the direction is automatically inferred\n            from the name of the monitored quantity.\n        min_delta: threshold for measuring the new optimum,\n            to only focus on significant changes.\n        cooldown: number of epochs to wait before resuming\n            normal operation after lr has been reduced.\n        min_lr: lower bound on the learning rate.\n    """"""\n\n    def __init__(self, monitor=\'val_loss\', factor=0.1, patience=10,\n                 verbose=0, mode=\'auto\', min_delta=1e-4, cooldown=0, min_lr=0,\n                 **kwargs):\n        super(ReduceLROnPlateau, self).__init__()\n\n        self.monitor = monitor\n        if factor >= 1.0:\n            raise ValueError(\'ReduceLROnPlateau \'\n                             \'does not support a factor >= 1.0.\')\n        if \'epsilon\' in kwargs:\n            min_delta = kwargs.pop(\'epsilon\')\n            warnings.warn(\'`epsilon` argument is deprecated and \'\n                          \'will be removed, use `min_delta` instead.\')\n        self.factor = factor\n        self.min_lr = min_lr\n        self.min_delta = min_delta\n        self.patience = patience\n        self.verbose = verbose\n        self.cooldown = cooldown\n        self.cooldown_counter = 0  # Cooldown counter.\n        self.wait = 0\n        self.best = 0\n        self.mode = mode\n        self.monitor_op = None\n        self._reset()\n\n    def _reset(self):\n        """"""Resets wait counter and cooldown counter.\n        """"""\n        if self.mode not in [\'auto\', \'min\', \'max\']:\n            warnings.warn(\'Learning Rate Plateau Reducing mode %s is unknown, \'\n                          \'fallback to auto mode.\' % (self.mode),\n                          RuntimeWarning)\n            self.mode = \'auto\'\n        if (self.mode == \'min\' or\n           (self.mode == \'auto\' and \'acc\' not in self.monitor)):\n            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n            self.best = np.Inf\n        else:\n            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n            self.best = -np.Inf\n        self.cooldown_counter = 0\n        self.wait = 0\n\n    def on_train_begin(self, logs=None):\n        self._reset()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs[\'lr\'] = K.get_value(self.model.optimizer.lr)\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\n                \'Reduce LR on plateau conditioned on metric `%s` \'\n                \'which is not available. Available metrics are: %s\' %\n                (self.monitor, \',\'.join(list(logs.keys()))), RuntimeWarning\n            )\n\n        else:\n            if self.in_cooldown():\n                self.cooldown_counter -= 1\n                self.wait = 0\n\n            if self.monitor_op(current, self.best):\n                self.best = current\n                self.wait = 0\n            elif not self.in_cooldown():\n                self.wait += 1\n                if self.wait >= self.patience:\n                    old_lr = float(K.get_value(self.model.optimizer.lr))\n                    if old_lr > self.min_lr:\n                        new_lr = old_lr * self.factor\n                        new_lr = max(new_lr, self.min_lr)\n                        K.set_value(self.model.optimizer.lr, new_lr)\n                        if self.verbose > 0:\n                            print(\'\\nEpoch %05d: ReduceLROnPlateau reducing \'\n                                  \'learning rate to %s.\' % (epoch + 1, new_lr))\n                        self.cooldown_counter = self.cooldown\n                        self.wait = 0\n\n    def in_cooldown(self):\n        return self.cooldown_counter > 0\n\n\nclass CSVLogger(Callback):\n    """"""Callback that streams epoch results to a csv file.\n\n    Supports all values that can be represented as a string,\n    including 1D iterables such as np.ndarray.\n\n    # Example\n\n    ```python\n    csv_logger = CSVLogger(\'training.log\')\n    model.fit(X_train, Y_train, callbacks=[csv_logger])\n    ```\n\n    # Arguments\n        filename: filename of the csv file, e.g. \'run/log.csv\'.\n        separator: string used to separate elements in the csv file.\n        append: True: append if file exists (useful for continuing\n            training). False: overwrite existing file,\n    """"""\n\n    def __init__(self, filename, separator=\',\', append=False):\n        self.sep = separator\n        self.filename = filename\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        if six.PY2:\n            self.file_flags = \'b\'\n            self._open_args = {}\n        else:\n            self.file_flags = \'\'\n            self._open_args = {\'newline\': \'\\n\'}\n        super(CSVLogger, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        if self.append:\n            if os.path.exists(self.filename):\n                with open(self.filename, \'r\' + self.file_flags) as f:\n                    self.append_header = not bool(len(f.readline()))\n            mode = \'a\'\n        else:\n            mode = \'w\'\n        self.csv_file = io.open(self.filename,\n                                mode + self.file_flags,\n                                **self._open_args)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return \'""[%s]""\' % (\', \'.join(map(str, k)))\n            else:\n                return k\n\n        if self.keys is None:\n            self.keys = sorted(logs.keys())\n\n        if self.model.stop_training:\n            # We set NA so that csv parsers do not fail for this last epoch.\n            logs = dict([(k, logs[k] if k in logs else \'NA\') for k in self.keys])\n\n        if not self.writer:\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n            fieldnames = [\'epoch\'] + self.keys\n            if six.PY2:\n                fieldnames = [unicode(x) for x in fieldnames]\n            self.writer = csv.DictWriter(self.csv_file,\n                                         fieldnames=fieldnames,\n                                         dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({\'epoch\': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()\n\n    def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer = None\n\n    def __del__(self):\n        if hasattr(self, \'csv_file\') and not self.csv_file.closed:\n            self.csv_file.close()\n\n\nclass LambdaCallback(Callback):\n    r""""""Callback for creating simple, custom callbacks on-the-fly.\n\n    This callback is constructed with anonymous functions that will be called\n    at the appropriate time. Note that the callbacks expects positional\n    arguments, as:\n\n     - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:\n        `epoch`, `logs`\n     - `on_batch_begin` and `on_batch_end` expect two positional arguments:\n        `batch`, `logs`\n     - `on_train_begin` and `on_train_end` expect one positional argument:\n        `logs`\n\n    # Arguments\n        on_epoch_begin: called at the beginning of every epoch.\n        on_epoch_end: called at the end of every epoch.\n        on_batch_begin: called at the beginning of every batch.\n        on_batch_end: called at the end of every batch.\n        on_train_begin: called at the beginning of model training.\n        on_train_end: called at the end of model training.\n\n    # Example\n\n    ```python\n    # Print the batch number at the beginning of every batch.\n    batch_print_callback = LambdaCallback(\n        on_batch_begin=lambda batch,logs: print(batch))\n\n    # Stream the epoch loss to a file in JSON format. The file content\n    # is not well-formed JSON but rather has a JSON object per line.\n    import json\n    json_log = open(\'loss_log.json\', mode=\'wt\', buffering=1)\n    json_logging_callback = LambdaCallback(\n        on_epoch_end=lambda epoch, logs: json_log.write(\n            json.dumps({\'epoch\': epoch, \'loss\': logs[\'loss\']}) + \'\\n\'),\n        on_train_end=lambda logs: json_log.close()\n    )\n\n    # Terminate some processes after having finished model training.\n    processes = ...\n    cleanup_callback = LambdaCallback(\n        on_train_end=lambda logs: [\n            p.terminate() for p in processes if p.is_alive()])\n\n    model.fit(...,\n              callbacks=[batch_print_callback,\n                         json_logging_callback,\n                         cleanup_callback])\n    ```\n    """"""\n\n    def __init__(self,\n                 on_epoch_begin=None,\n                 on_epoch_end=None,\n                 on_batch_begin=None,\n                 on_batch_end=None,\n                 on_train_begin=None,\n                 on_train_end=None,\n                 **kwargs):\n        super(LambdaCallback, self).__init__()\n        self.__dict__.update(kwargs)\n        if on_epoch_begin is not None:\n            self.on_epoch_begin = on_epoch_begin\n        else:\n            self.on_epoch_begin = lambda epoch, logs: None\n        if on_epoch_end is not None:\n            self.on_epoch_end = on_epoch_end\n        else:\n            self.on_epoch_end = lambda epoch, logs: None\n        if on_batch_begin is not None:\n            self.on_batch_begin = on_batch_begin\n        else:\n            self.on_batch_begin = lambda batch, logs: None\n        if on_batch_end is not None:\n            self.on_batch_end = on_batch_end\n        else:\n            self.on_batch_end = lambda batch, logs: None\n        if on_train_begin is not None:\n            self.on_train_begin = on_train_begin\n        else:\n            self.on_train_begin = lambda logs: None\n        if on_train_end is not None:\n            self.on_train_end = on_train_end\n        else:\n            self.on_train_end = lambda logs: None\n'"
keras/callbacks/tensorboard_v1.py,21,"b'""""""TensorBoard callback for training visualization.\n\nThis is the TF v1 version. A subset of the functionality\nalso works with other backends.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport warnings\n\nfrom .. import backend as K\nfrom ..engine.training_utils import standardize_input_data\nfrom . import Callback\n\n\nclass TensorBoard(Callback):\n    """"""TensorBoard basic visualizations.\n\n    [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard)\n    is a visualization tool provided with TensorFlow.\n\n    This callback writes a log for TensorBoard, which allows\n    you to visualize dynamic graphs of your training and test\n    metrics, as well as activation histograms for the different\n    layers in your model.\n\n    If you have installed TensorFlow with pip, you should be able\n    to launch TensorBoard from the command line:\n    ```sh\n    tensorboard --logdir=/full_path_to_your_logs\n    ```\n\n    When using a backend other than TensorFlow, TensorBoard will still work\n    (if you have TensorFlow installed), but the only feature available will\n    be the display of the losses and metrics plots.\n\n    # Arguments\n        log_dir: the path of the directory where to save the log\n            files to be parsed by TensorBoard.\n        histogram_freq: frequency (in epochs) at which to compute activation\n            and weight histograms for the layers of the model. If set to 0,\n            histograms won\'t be computed. Validation data (or split) must be\n            specified for histogram visualizations.\n        batch_size: size of batch of inputs to feed to the network\n            for histograms computation.\n        write_graph: whether to visualize the graph in TensorBoard.\n            The log file can become quite large when\n            write_graph is set to True.\n        write_grads: whether to visualize gradient histograms in TensorBoard.\n            `histogram_freq` must be greater than 0.\n        write_images: whether to write model weights to visualize as\n            image in TensorBoard.\n        embeddings_freq: frequency (in epochs) at which selected embedding\n            layers will be saved. If set to 0, embeddings won\'t be computed.\n            Data to be visualized in TensorBoard\'s Embedding tab must be passed\n            as `embeddings_data`.\n        embeddings_layer_names: a list of names of layers to keep eye on. If\n            None or empty list all the embedding layer will be watched.\n        embeddings_metadata: a dictionary which maps layer name to a file name\n            in which metadata for this embedding layer is saved. See the\n            [details](https://www.tensorflow.org/guide/embedding#metadata)\n            about metadata files format. In case if the same metadata file is\n            used for all embedding layers, string can be passed.\n        embeddings_data: data to be embedded at layers specified in\n            `embeddings_layer_names`. Numpy array (if the model has a single\n            input) or list of Numpy arrays (if the model has multiple inputs).\n            Learn [more about embeddings](\n            https://www.tensorflow.org/guide/embedding).\n        update_freq: `\'batch\'` or `\'epoch\'` or integer. When using `\'batch\'`, writes\n            the losses and metrics to TensorBoard after each batch. The same\n            applies for `\'epoch\'`. If using an integer, let\'s say `10000`,\n            the callback will write the metrics and losses to TensorBoard every\n            10000 samples. Note that writing too frequently to TensorBoard\n            can slow down your training.\n    """"""\n\n    def __init__(self, log_dir=\'./logs\',\n                 histogram_freq=0,\n                 batch_size=32,\n                 write_graph=True,\n                 write_grads=False,\n                 write_images=False,\n                 embeddings_freq=0,\n                 embeddings_layer_names=None,\n                 embeddings_metadata=None,\n                 embeddings_data=None,\n                 update_freq=\'epoch\'):\n        super(TensorBoard, self).__init__()\n        global tf, projector\n        try:\n            import tensorflow as tf\n            from tensorflow.contrib.tensorboard.plugins import projector\n        except ImportError:\n            raise ImportError(\'You need the TensorFlow (v1) module installed to \'\n                              \'use TensorBoard.\')\n\n        if K.backend() != \'tensorflow\':\n            if histogram_freq != 0:\n                warnings.warn(\'You are not using the TensorFlow backend. \'\n                              \'histogram_freq was set to 0\')\n                histogram_freq = 0\n            if write_graph:\n                warnings.warn(\'You are not using the TensorFlow backend. \'\n                              \'write_graph was set to False\')\n                write_graph = False\n            if write_images:\n                warnings.warn(\'You are not using the TensorFlow backend. \'\n                              \'write_images was set to False\')\n                write_images = False\n            if embeddings_freq != 0:\n                warnings.warn(\'You are not using the TensorFlow backend. \'\n                              \'embeddings_freq was set to 0\')\n                embeddings_freq = 0\n\n        self.log_dir = log_dir\n        self.histogram_freq = histogram_freq\n        self.merged = None\n        self.write_graph = write_graph\n        self.write_grads = write_grads\n        self.write_images = write_images\n        self.embeddings_freq = embeddings_freq\n        self.embeddings_layer_names = embeddings_layer_names\n        self.embeddings_metadata = embeddings_metadata or {}\n        self.batch_size = batch_size\n        self.embeddings_data = embeddings_data\n        if update_freq == \'batch\':\n            # It is the same as writing as frequently as possible.\n            self.update_freq = 1\n        else:\n            self.update_freq = update_freq\n        self.samples_seen = 0\n        self.samples_seen_at_last_write = 0\n\n    def set_model(self, model):\n        self.model = model\n        if K.backend() == \'tensorflow\':\n            self.sess = K.get_session()\n        if self.histogram_freq and self.merged is None:\n            for layer in self.model.layers:\n                for weight in layer.weights:\n                    mapped_weight_name = weight.name.replace(\':\', \'_\')\n                    tf.summary.histogram(mapped_weight_name, weight)\n                    if self.write_grads and weight in layer.trainable_weights:\n                        grads = model.optimizer.get_gradients(model.total_loss,\n                                                              weight)\n\n                        def is_indexed_slices(grad):\n                            return type(grad).__name__ == \'IndexedSlices\'\n                        grads = [\n                            grad.values if is_indexed_slices(grad) else grad\n                            for grad in grads]\n                        tf.summary.histogram(\'{}_grad\'.format(mapped_weight_name),\n                                             grads)\n                    if self.write_images:\n                        w_img = tf.squeeze(weight)\n                        shape = K.int_shape(w_img)\n                        if len(shape) == 2:  # dense layer kernel case\n                            if shape[0] > shape[1]:\n                                w_img = tf.transpose(w_img)\n                                shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img, [1,\n                                                       shape[0],\n                                                       shape[1],\n                                                       1])\n                        elif len(shape) == 3:  # convnet case\n                            if K.image_data_format() == \'channels_last\':\n                                # switch to channels_first to display\n                                # every kernel as a separate image\n                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n                                shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img, [shape[0],\n                                                       shape[1],\n                                                       shape[2],\n                                                       1])\n                        elif len(shape) == 1:  # bias case\n                            w_img = tf.reshape(w_img, [1,\n                                                       shape[0],\n                                                       1,\n                                                       1])\n                        else:\n                            # not possible to handle 3D convnets etc.\n                            continue\n\n                        shape = K.int_shape(w_img)\n                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n                        tf.summary.image(mapped_weight_name, w_img)\n\n                if hasattr(layer, \'output\'):\n                    if isinstance(layer.output, list):\n                        for i, output in enumerate(layer.output):\n                            tf.summary.histogram(\'{}_out_{}\'.format(layer.name, i),\n                                                 output)\n                    else:\n                        tf.summary.histogram(\'{}_out\'.format(layer.name),\n                                             layer.output)\n        self.merged = tf.summary.merge_all()\n\n        if self.write_graph:\n            self.writer = tf.summary.FileWriter(self.log_dir,\n                                                self.sess.graph)\n        else:\n            self.writer = tf.summary.FileWriter(self.log_dir)\n\n        if self.embeddings_freq and self.embeddings_data is not None:\n            self.embeddings_data = standardize_input_data(self.embeddings_data,\n                                                          model.input_names)\n\n            embeddings_layer_names = self.embeddings_layer_names\n\n            if not embeddings_layer_names:\n                embeddings_layer_names = [layer.name for layer in self.model.layers\n                                          if type(layer).__name__ == \'Embedding\']\n            self.assign_embeddings = []\n            embeddings_vars = {}\n\n            self.batch_id = batch_id = tf.placeholder(tf.int32)\n            self.step = step = tf.placeholder(tf.int32)\n\n            for layer in self.model.layers:\n                if layer.name in embeddings_layer_names:\n                    embedding_input = self.model.get_layer(layer.name).output\n                    embedding_size = np.prod(embedding_input.shape[1:])\n                    embedding_input = tf.reshape(embedding_input,\n                                                 (step, int(embedding_size)))\n                    shape = (self.embeddings_data[0].shape[0], int(embedding_size))\n                    embedding = K.variable(K.zeros(shape),\n                                           name=layer.name + \'_embedding\')\n                    embeddings_vars[layer.name] = embedding\n                    batch = tf.assign(embedding[batch_id:batch_id + step],\n                                      embedding_input)\n                    self.assign_embeddings.append(batch)\n\n            self.saver = tf.train.Saver(list(embeddings_vars.values()))\n\n            if not isinstance(self.embeddings_metadata, str):\n                embeddings_metadata = self.embeddings_metadata\n            else:\n                embeddings_metadata = {layer_name: self.embeddings_metadata\n                                       for layer_name in embeddings_vars.keys()}\n\n            config = projector.ProjectorConfig()\n\n            for layer_name, tensor in embeddings_vars.items():\n                embedding = config.embeddings.add()\n                embedding.tensor_name = tensor.name\n\n                if layer_name in embeddings_metadata:\n                    embedding.metadata_path = embeddings_metadata[layer_name]\n\n            projector.visualize_embeddings(self.writer, config)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        if not self.validation_data and self.histogram_freq:\n            raise ValueError(""If printing histograms, validation_data must be ""\n                             ""provided, and cannot be a generator."")\n        if self.embeddings_data is None and self.embeddings_freq:\n            raise ValueError(""To visualize embeddings, embeddings_data must ""\n                             ""be provided."")\n        if self.validation_data and self.histogram_freq:\n            if epoch % self.histogram_freq == 0:\n\n                val_data = self.validation_data\n                tensors = (self.model.inputs +\n                           self.model.targets +\n                           self.model.sample_weights)\n\n                if self.model.uses_learning_phase:\n                    tensors += [K.learning_phase()]\n\n                assert len(val_data) == len(tensors)\n                val_size = val_data[0].shape[0]\n                i = 0\n                while i < val_size:\n                    step = min(self.batch_size, val_size - i)\n                    if self.model.uses_learning_phase:\n                        # do not slice the learning phase\n                        batch_val = [x[i:i + step] for x in val_data[:-1]]\n                        batch_val.append(val_data[-1])\n                    else:\n                        batch_val = [x[i:i + step] for x in val_data]\n                    assert len(batch_val) == len(tensors)\n                    feed_dict = dict(zip(tensors, batch_val))\n                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n                    summary_str = result[0]\n                    self.writer.add_summary(summary_str, epoch)\n                    i += self.batch_size\n\n        if self.embeddings_freq and self.embeddings_data is not None:\n            if epoch % self.embeddings_freq == 0:\n                # We need a second forward-pass here because we\'re passing\n                # the `embeddings_data` explicitly. This design allows to pass\n                # arbitrary data as `embeddings_data` and results from the fact\n                # that we need to know the size of the `tf.Variable`s which\n                # hold the embeddings in `set_model`. At this point, however,\n                # the `validation_data` is not yet set.\n\n                # More details in this discussion:\n                # https://github.com/keras-team/keras/pull/7766#issuecomment-329195622\n\n                embeddings_data = self.embeddings_data\n                n_samples = embeddings_data[0].shape[0]\n\n                i = 0\n                while i < n_samples:\n                    step = min(self.batch_size, n_samples - i)\n                    batch = slice(i, i + step)\n\n                    if type(self.model.input) == list:\n                        feed_dict = {_input: embeddings_data[idx][batch]\n                                     for idx, _input in enumerate(self.model.input)}\n                    else:\n                        feed_dict = {self.model.input: embeddings_data[0][batch]}\n\n                    feed_dict.update({self.batch_id: i, self.step: step})\n\n                    if self.model.uses_learning_phase:\n                        feed_dict[K.learning_phase()] = False\n\n                    self.sess.run(self.assign_embeddings, feed_dict=feed_dict)\n                    self.saver.save(self.sess,\n                                    os.path.join(self.log_dir,\n                                                 \'keras_embedding.ckpt\'),\n                                    epoch)\n\n                    i += self.batch_size\n\n        if self.update_freq == \'epoch\':\n            index = epoch\n        else:\n            index = self.samples_seen\n        self._write_logs(logs, index)\n\n    def _write_logs(self, logs, index):\n        for name, value in logs.items():\n            if name in [\'batch\', \'size\']:\n                continue\n            summary = tf.Summary()\n            summary_value = summary.value.add()\n            if isinstance(value, np.ndarray):\n                summary_value.simple_value = value.item()\n            else:\n                summary_value.simple_value = value\n            summary_value.tag = name\n            self.writer.add_summary(summary, index)\n        self.writer.flush()\n\n    def on_train_end(self, _):\n        self.writer.close()\n\n    def on_batch_end(self, batch, logs=None):\n        if self.update_freq != \'epoch\':\n            self.samples_seen += logs[\'size\']\n            samples_seen_since = self.samples_seen - self.samples_seen_at_last_write\n            if samples_seen_since >= self.update_freq:\n                self._write_logs(logs, self.samples_seen)\n                self.samples_seen_at_last_write = self.samples_seen\n'"
keras/callbacks/tensorboard_v2.py,1,"b'""""""TensorBoard callback for training visualization.\n\nThis is the TF v2 version. A lot of the functionality\nfrom the v1 version isn\'t currently supported (but will\nlikely be added back later).\n\nThe docstring is left unchanged\nto avoid creating confusion on the docs website.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport warnings\n\n\nclass TensorBoard(tf.keras.callbacks.TensorBoard):\n    """"""TensorBoard basic visualizations.\n\n    [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard)\n    is a visualization tool provided with TensorFlow.\n\n    This callback writes a log for TensorBoard, which allows\n    you to visualize dynamic graphs of your training and test\n    metrics, as well as activation histograms for the different\n    layers in your model.\n\n    If you have installed TensorFlow with pip, you should be able\n    to launch TensorBoard from the command line:\n    ```sh\n    tensorboard --logdir=/full_path_to_your_logs\n    ```\n\n    When using a backend other than TensorFlow, TensorBoard will still work\n    (if you have TensorFlow installed), but the only feature available will\n    be the display of the losses and metrics plots.\n\n    # Arguments\n        log_dir: the path of the directory where to save the log\n            files to be parsed by TensorBoard.\n        histogram_freq: frequency (in epochs) at which to compute activation\n            and weight histograms for the layers of the model. If set to 0,\n            histograms won\'t be computed. Validation data (or split) must be\n            specified for histogram visualizations.\n        batch_size: size of batch of inputs to feed to the network\n            for histograms computation.\n        write_graph: whether to visualize the graph in TensorBoard.\n            The log file can become quite large when\n            write_graph is set to True.\n        write_grads: whether to visualize gradient histograms in TensorBoard.\n            `histogram_freq` must be greater than 0.\n        write_images: whether to write model weights to visualize as\n            image in TensorBoard.\n        embeddings_freq: frequency (in epochs) at which selected embedding\n            layers will be saved. If set to 0, embeddings won\'t be computed.\n            Data to be visualized in TensorBoard\'s Embedding tab must be passed\n            as `embeddings_data`.\n        embeddings_layer_names: a list of names of layers to keep eye on. If\n            None or empty list all the embedding layer will be watched.\n        embeddings_metadata: a dictionary which maps layer name to a file name\n            in which metadata for this embedding layer is saved. See the\n            [details](https://www.tensorflow.org/guide/embedding#metadata)\n            about metadata files format. In case if the same metadata file is\n            used for all embedding layers, string can be passed.\n        embeddings_data: data to be embedded at layers specified in\n            `embeddings_layer_names`. Numpy array (if the model has a single\n            input) or list of Numpy arrays (if the model has multiple inputs).\n            Learn [more about embeddings](\n            https://www.tensorflow.org/guide/embedding).\n        update_freq: `\'batch\'` or `\'epoch\'` or integer. When using `\'batch\'`, writes\n            the losses and metrics to TensorBoard after each batch. The same\n            applies for `\'epoch\'`. If using an integer, let\'s say `10000`,\n            the callback will write the metrics and losses to TensorBoard every\n            10000 samples. Note that writing too frequently to TensorBoard\n            can slow down your training.\n    """"""\n\n    def __init__(self, log_dir=\'./logs\',\n                 histogram_freq=0,\n                 batch_size=None,\n                 write_graph=True,\n                 write_grads=False,\n                 write_images=False,\n                 embeddings_freq=0,\n                 embeddings_layer_names=None,\n                 embeddings_metadata=None,\n                 embeddings_data=None,\n                 update_freq=\'epoch\',\n                 **kwargs):\n        if batch_size is not None:\n            warnings.warn(\'The TensorBoard callback `batch_size` argument \'\n                          \'(for histogram computation) \'\n                          \'is deprecated with TensorFlow 2.0. \'\n                          \'It will be ignored.\')\n        if write_grads:\n            warnings.warn(\'The TensorBoard callback does not support \'\n                          \'gradients display when using TensorFlow 2.0. \'\n                          \'The `write_grads` argument is ignored.\')\n        if (embeddings_freq or embeddings_layer_names or\n                embeddings_metadata or embeddings_data):\n            warnings.warn(\'The TensorBoard callback does not support \'\n                          \'embeddings display when using TensorFlow 2.0. \'\n                          \'Embeddings-related arguments are ignored.\')\n        super(TensorBoard, self).__init__(\n            log_dir=log_dir,\n            histogram_freq=histogram_freq,\n            write_graph=write_graph,\n            write_images=write_images,\n            update_freq=update_freq,\n            **kwargs)\n\n    def set_model(self, model):\n        """"""Sets Keras model and writes graph if specified.""""""\n        model.run_eagerly = False\n        super(TensorBoard, self).set_model(model)\n'"
keras/datasets/__init__.py,0,b'from __future__ import absolute_import\n\nfrom . import mnist\nfrom . import imdb\nfrom . import reuters\nfrom . import cifar10\nfrom . import cifar100\nfrom . import boston_housing\nfrom . import fashion_mnist\n'
keras/datasets/boston_housing.py,0,"b'""""""Boston housing price regression dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..utils.data_utils import get_file\nimport numpy as np\n\n\ndef load_data(path=\'boston_housing.npz\', test_split=0.2, seed=113):\n    """"""Loads the Boston Housing dataset.\n\n    # Arguments\n        path: path where to cache the dataset locally\n            (relative to ~/.keras/datasets).\n        test_split: fraction of the data to reserve as test set.\n        seed: Random seed for shuffling the data\n            before computing the test split.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    """"""\n    assert 0 <= test_split < 1\n    path = get_file(\n        path,\n        origin=\'https://s3.amazonaws.com/keras-datasets/boston_housing.npz\',\n        file_hash=\'f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5\')\n    with np.load(path, allow_pickle=True) as f:\n        x = f[\'x\']\n        y = f[\'y\']\n\n    rng = np.random.RandomState(seed)\n    indices = np.arange(len(x))\n    rng.shuffle(indices)\n    x = x[indices]\n    y = y[indices]\n\n    x_train = np.array(x[:int(len(x) * (1 - test_split))])\n    y_train = np.array(y[:int(len(x) * (1 - test_split))])\n    x_test = np.array(x[int(len(x) * (1 - test_split)):])\n    y_test = np.array(y[int(len(x) * (1 - test_split)):])\n    return (x_train, y_train), (x_test, y_test)\n'"
keras/datasets/cifar.py,0,"b'# -*- coding: utf-8 -*-\n""""""Utilities common to CIFAR10 and CIFAR100 datasets.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\nfrom six.moves import cPickle\n\n\ndef load_batch(fpath, label_key=\'labels\'):\n    """"""Internal utility for parsing CIFAR data.\n\n    # Arguments\n        fpath: path the file to parse.\n        label_key: key for label data in the retrieve\n            dictionary.\n\n    # Returns\n        A tuple `(data, labels)`.\n    """"""\n    with open(fpath, \'rb\') as f:\n        if sys.version_info < (3,):\n            d = cPickle.load(f)\n        else:\n            d = cPickle.load(f, encoding=\'bytes\')\n            # decode utf8\n            d_decoded = {}\n            for k, v in d.items():\n                d_decoded[k.decode(\'utf8\')] = v\n            d = d_decoded\n    data = d[\'data\']\n    labels = d[label_key]\n\n    data = data.reshape(data.shape[0], 3, 32, 32)\n    return data, labels\n'"
keras/datasets/cifar10.py,0,"b'""""""CIFAR10 small images classification dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .cifar import load_batch\nfrom ..utils.data_utils import get_file\nfrom .. import backend as K\nimport numpy as np\nimport os\n\n\ndef load_data():\n    """"""Loads CIFAR10 dataset.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    """"""\n    dirname = \'cifar-10-batches-py\'\n    origin = \'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\'\n    path = get_file(dirname, origin=origin, untar=True)\n\n    num_train_samples = 50000\n\n    x_train = np.empty((num_train_samples, 3, 32, 32), dtype=\'uint8\')\n    y_train = np.empty((num_train_samples,), dtype=\'uint8\')\n\n    for i in range(1, 6):\n        fpath = os.path.join(path, \'data_batch_\' + str(i))\n        (x_train[(i - 1) * 10000: i * 10000, :, :, :],\n         y_train[(i - 1) * 10000: i * 10000]) = load_batch(fpath)\n\n    fpath = os.path.join(path, \'test_batch\')\n    x_test, y_test = load_batch(fpath)\n\n    y_train = np.reshape(y_train, (len(y_train), 1))\n    y_test = np.reshape(y_test, (len(y_test), 1))\n\n    if K.image_data_format() == \'channels_last\':\n        x_train = x_train.transpose(0, 2, 3, 1)\n        x_test = x_test.transpose(0, 2, 3, 1)\n\n    return (x_train, y_train), (x_test, y_test)\n'"
keras/datasets/cifar100.py,0,"b'""""""CIFAR100 small images classification dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .cifar import load_batch\nfrom ..utils.data_utils import get_file\nfrom .. import backend as K\nimport numpy as np\nimport os\n\n\ndef load_data(label_mode=\'fine\'):\n    """"""Loads CIFAR100 dataset.\n\n    # Arguments\n        label_mode: one of ""fine"", ""coarse"".\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n    # Raises\n        ValueError: in case of invalid `label_mode`.\n    """"""\n    if label_mode not in [\'fine\', \'coarse\']:\n        raise ValueError(\'`label_mode` must be one of `""fine""`, `""coarse""`.\')\n\n    dirname = \'cifar-100-python\'\n    origin = \'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\'\n    path = get_file(dirname, origin=origin, untar=True)\n\n    fpath = os.path.join(path, \'train\')\n    x_train, y_train = load_batch(fpath, label_key=label_mode + \'_labels\')\n\n    fpath = os.path.join(path, \'test\')\n    x_test, y_test = load_batch(fpath, label_key=label_mode + \'_labels\')\n\n    y_train = np.reshape(y_train, (len(y_train), 1))\n    y_test = np.reshape(y_test, (len(y_test), 1))\n\n    if K.image_data_format() == \'channels_last\':\n        x_train = x_train.transpose(0, 2, 3, 1)\n        x_test = x_test.transpose(0, 2, 3, 1)\n\n    return (x_train, y_train), (x_test, y_test)\n'"
keras/datasets/fashion_mnist.py,0,"b'""""""Fashion-MNIST dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gzip\nimport os\n\nfrom ..utils.data_utils import get_file\nimport numpy as np\n\n\ndef load_data():\n    """"""Loads the Fashion-MNIST dataset.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    """"""\n    dirname = os.path.join(\'datasets\', \'fashion-mnist\')\n    base = \'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\'\n    files = [\'train-labels-idx1-ubyte.gz\', \'train-images-idx3-ubyte.gz\',\n             \'t10k-labels-idx1-ubyte.gz\', \'t10k-images-idx3-ubyte.gz\']\n\n    paths = []\n    for fname in files:\n        paths.append(get_file(fname,\n                              origin=base + fname,\n                              cache_subdir=dirname))\n\n    with gzip.open(paths[0], \'rb\') as lbpath:\n        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n\n    with gzip.open(paths[1], \'rb\') as imgpath:\n        x_train = np.frombuffer(imgpath.read(), np.uint8,\n                                offset=16).reshape(len(y_train), 28, 28)\n\n    with gzip.open(paths[2], \'rb\') as lbpath:\n        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n\n    with gzip.open(paths[3], \'rb\') as imgpath:\n        x_test = np.frombuffer(imgpath.read(), np.uint8,\n                               offset=16).reshape(len(y_test), 28, 28)\n\n    return (x_train, y_train), (x_test, y_test)\n'"
keras/datasets/imdb.py,0,"b'""""""IMDB sentiment classification dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..utils.data_utils import get_file\nfrom ..preprocessing.sequence import _remove_long_seq\nimport numpy as np\nimport json\nimport warnings\n\n\ndef load_data(path=\'imdb.npz\', num_words=None, skip_top=0,\n              maxlen=None, seed=113,\n              start_char=1, oov_char=2, index_from=3, **kwargs):\n    """"""Loads the IMDB dataset.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n        num_words: max number of words to include. Words are ranked\n            by how often they occur (in the training set) and only\n            the most frequent words are kept\n        skip_top: skip the top N most frequently occurring words\n            (which may not be informative).\n        maxlen: sequences longer than this will be filtered out.\n        seed: random seed for sample shuffling.\n        start_char: The start of a sequence will be marked with this character.\n            Set to 1 because 0 is usually the padding character.\n        oov_char: words that were cut out because of the `num_words`\n            or `skip_top` limit will be replaced with this character.\n        index_from: index actual words with this index and higher.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n    # Raises\n        ValueError: in case `maxlen` is so low\n            that no input sequence could be kept.\n\n    Note that the \'out of vocabulary\' character is only used for\n    words that were present in the training set but are not included\n    because they\'re not making the `num_words` cut here.\n    Words that were not seen in the training set but are in the test set\n    have simply been skipped.\n    """"""\n    # Legacy support\n    if \'nb_words\' in kwargs:\n        warnings.warn(\'The `nb_words` argument in `load_data` \'\n                      \'has been renamed `num_words`.\')\n        num_words = kwargs.pop(\'nb_words\')\n    if kwargs:\n        raise TypeError(\'Unrecognized keyword arguments: \' + str(kwargs))\n\n    path = get_file(path,\n                    origin=\'https://s3.amazonaws.com/text-datasets/imdb.npz\',\n                    file_hash=\'599dadb1135973df5b59232a0e9a887c\')\n    with np.load(path, allow_pickle=True) as f:\n        x_train, labels_train = f[\'x_train\'], f[\'y_train\']\n        x_test, labels_test = f[\'x_test\'], f[\'y_test\']\n\n    rng = np.random.RandomState(seed)\n    indices = np.arange(len(x_train))\n    rng.shuffle(indices)\n    x_train = x_train[indices]\n    labels_train = labels_train[indices]\n\n    indices = np.arange(len(x_test))\n    rng.shuffle(indices)\n    x_test = x_test[indices]\n    labels_test = labels_test[indices]\n\n    xs = np.concatenate([x_train, x_test])\n    labels = np.concatenate([labels_train, labels_test])\n\n    if start_char is not None:\n        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n    elif index_from:\n        xs = [[w + index_from for w in x] for x in xs]\n\n    if maxlen:\n        xs, labels = _remove_long_seq(maxlen, xs, labels)\n        if not xs:\n            raise ValueError(\'After filtering for sequences shorter than maxlen=\' +\n                             str(maxlen) + \', no sequence was kept. \'\n                             \'Increase maxlen.\')\n    if not num_words:\n        num_words = max([max(x) for x in xs])\n\n    # by convention, use 2 as OOV word\n    # reserve \'index_from\' (=3 by default) characters:\n    # 0 (padding), 1 (start), 2 (OOV)\n    if oov_char is not None:\n        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x]\n              for x in xs]\n    else:\n        xs = [[w for w in x if skip_top <= w < num_words]\n              for x in xs]\n\n    idx = len(x_train)\n    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n\n    return (x_train, y_train), (x_test, y_test)\n\n\ndef get_word_index(path=\'imdb_word_index.json\'):\n    """"""Retrieves the dictionary mapping words to word indices.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n\n    # Returns\n        The word index dictionary.\n    """"""\n    path = get_file(\n        path,\n        origin=\'https://s3.amazonaws.com/text-datasets/imdb_word_index.json\',\n        file_hash=\'bfafd718b763782e994055a2d397834f\')\n    with open(path) as f:\n        return json.load(f)\n'"
keras/datasets/mnist.py,0,"b'""""""MNIST handwritten digits dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..utils.data_utils import get_file\nimport numpy as np\n\n\ndef load_data(path=\'mnist.npz\'):\n    """"""Loads the MNIST dataset.\n\n    # Arguments\n        path: path where to cache the dataset locally\n            (relative to ~/.keras/datasets).\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    """"""\n    path = get_file(path,\n                    origin=\'https://s3.amazonaws.com/img-datasets/mnist.npz\',\n                    file_hash=\'8a61469f7ea1b51cbae51d4f78837e45\')\n    with np.load(path, allow_pickle=True) as f:\n        x_train, y_train = f[\'x_train\'], f[\'y_train\']\n        x_test, y_test = f[\'x_test\'], f[\'y_test\']\n    return (x_train, y_train), (x_test, y_test)\n'"
keras/datasets/reuters.py,0,"b'# -*- coding: utf-8 -*-\n""""""Reuters topic classification dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..utils.data_utils import get_file\nfrom ..preprocessing.sequence import _remove_long_seq\nimport numpy as np\nimport json\nimport warnings\n\n\ndef load_data(path=\'reuters.npz\', num_words=None, skip_top=0,\n              maxlen=None, test_split=0.2, seed=113,\n              start_char=1, oov_char=2, index_from=3, **kwargs):\n    """"""Loads the Reuters newswire classification dataset.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n        num_words: max number of words to include. Words are ranked\n            by how often they occur (in the training set) and only\n            the most frequent words are kept\n        skip_top: skip the top N most frequently occurring words\n            (which may not be informative).\n        maxlen: truncate sequences after this length.\n        test_split: Fraction of the dataset to be used as test data.\n        seed: random seed for sample shuffling.\n        start_char: The start of a sequence will be marked with this character.\n            Set to 1 because 0 is usually the padding character.\n        oov_char: words that were cut out because of the `num_words`\n            or `skip_top` limit will be replaced with this character.\n        index_from: index actual words with this index and higher.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n    Note that the \'out of vocabulary\' character is only used for\n    words that were present in the training set but are not included\n    because they\'re not making the `num_words` cut here.\n    Words that were not seen in the training set but are in the test set\n    have simply been skipped.\n    """"""\n    # Legacy support\n    if \'nb_words\' in kwargs:\n        warnings.warn(\'The `nb_words` argument in `load_data` \'\n                      \'has been renamed `num_words`.\')\n        num_words = kwargs.pop(\'nb_words\')\n    if kwargs:\n        raise TypeError(\'Unrecognized keyword arguments: \' + str(kwargs))\n\n    path = get_file(path,\n                    origin=\'https://s3.amazonaws.com/text-datasets/reuters.npz\',\n                    file_hash=\'87aedbeb0cb229e378797a632c1997b6\')\n    with np.load(path, allow_pickle=True) as f:\n        xs, labels = f[\'x\'], f[\'y\']\n\n    rng = np.random.RandomState(seed)\n    indices = np.arange(len(xs))\n    rng.shuffle(indices)\n    xs = xs[indices]\n    labels = labels[indices]\n\n    if start_char is not None:\n        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n    elif index_from:\n        xs = [[w + index_from for w in x] for x in xs]\n\n    if maxlen:\n        xs, labels = _remove_long_seq(maxlen, xs, labels)\n\n    if not num_words:\n        num_words = max([max(x) for x in xs])\n\n    # by convention, use 2 as OOV word\n    # reserve \'index_from\' (=3 by default) characters:\n    # 0 (padding), 1 (start), 2 (OOV)\n    if oov_char is not None:\n        xs = [[w if skip_top <= w < num_words else oov_char for w in x] for x in xs]\n    else:\n        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n\n    idx = int(len(xs) * (1 - test_split))\n    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n\n    return (x_train, y_train), (x_test, y_test)\n\n\ndef get_word_index(path=\'reuters_word_index.json\'):\n    """"""Retrieves the dictionary mapping words to word indices.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n\n    # Returns\n        The word index dictionary.\n    """"""\n    path = get_file(\n        path,\n        origin=\'https://s3.amazonaws.com/text-datasets/reuters_word_index.json\',\n        file_hash=\'4d44cc38712099c9e383dc6e5f11a921\')\n    with open(path) as f:\n        return json.load(f)\n'"
keras/engine/__init__.py,0,"b""# note: `Node` is an internal class,\n# it isn't meant to be used by Keras users.\nfrom .input_layer import Input\nfrom .input_layer import InputLayer\nfrom .base_layer import InputSpec\nfrom .base_layer import Layer\nfrom .network import get_source_inputs\nfrom .training import Model\n"""
keras/engine/base_layer.py,0,"b'""""""Contains the base Layer class, from which all layers inherit.\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nimport re\nfrom six.moves import zip\nimport threading\n\nfrom .. import backend as K\nfrom .. import initializers\nfrom ..utils.layer_utils import count_params\nfrom ..utils.generic_utils import has_arg\nfrom ..utils.generic_utils import object_list_uid\nfrom ..utils.generic_utils import to_list\nfrom ..utils.generic_utils import unpack_singleton\nfrom ..utils.generic_utils import is_all_none\nfrom ..legacy import interfaces\n\n_DISABLE_TRACKING = threading.local()\n_DISABLE_TRACKING.value = False\n\n\ndef disable_tracking(func):\n    def wrapped_fn(*args, **kwargs):\n        global _DISABLE_TRACKING\n        prev_value = _DISABLE_TRACKING.value\n        _DISABLE_TRACKING.value = True\n        out = func(*args, **kwargs)\n        _DISABLE_TRACKING.value = prev_value\n        return out\n    return wrapped_fn\n\n\nclass Layer(object):\n    """"""Abstract base layer class.\n\n    # Properties\n        input, output: Input/output tensor(s). Note that if the layer\n            is used more than once (shared layer), this is ill-defined\n            and will raise an exception. In such cases, use\n            `layer.get_input_at(node_index)`.\n        input_mask, output_mask: Mask tensors. Same caveats apply as\n            input, output.\n        input_shape: Shape tuple. Provided for convenience, but note\n            that there may be cases in which this attribute is\n            ill-defined (e.g. a shared layer with multiple input\n            shapes), in which case requesting `input_shape` will raise\n            an Exception. Prefer using\n            `layer.get_input_shape_at(node_index)`.\n        input_spec: List of InputSpec class instances\n            each entry describes one required input:\n                - ndim\n                - dtype\n            A layer with `n` input tensors must have\n            an `input_spec` of length `n`.\n        name: String, must be unique within a model.\n        non_trainable_weights: List of variables.\n        output_shape: Shape tuple. See `input_shape`.\n        stateful: Boolean indicating whether the layer carries\n            additional non-weight state. Used in, for instance, RNN\n            cells to carry information between batches.\n        supports_masking: Boolean indicator of whether the layer\n            supports masking, typically for unused timesteps in a\n            sequence.\n        trainable: Boolean, whether the layer weights\n            will be updated during training.\n        trainable_weights: List of variables.\n        uses_learning_phase: Whether any operation\n            of the layer uses `K.in_training_phase()`\n            or `K.in_test_phase()`.\n        weights: The concatenation of the lists trainable_weights and\n            non_trainable_weights (in this order).\n        dtype:  Default dtype of the layers\'s weights.\n\n\n    # Methods\n        call(x, mask=None): Where the layer\'s logic lives.\n        __call__(x, mask=None): Wrapper around the layer logic (`call`).\n            If x is a Keras tensor:\n                - Connect current layer with last layer from tensor:\n                    `self._add_inbound_node(last_layer)`\n                - Add layer to tensor history\n            If layer is not built:\n                - Build from x._keras_shape\n        compute_mask(x, mask)\n        compute_output_shape(input_shape)\n        count_params()\n        get_config()\n        get_input_at(node_index)\n        get_input_mask_at(node_index)\n        get_input_shape_at(node_index)\n        get_output_at(node_index)\n        get_output_mask_at(node_index)\n        get_output_shape_at(node_index)\n        get_weights()\n        set_weights(weights)\n\n    # Class Methods\n        from_config(config)\n\n    # Internal methods:\n        _add_inbound_node(layer, index=0)\n        assert_input_compatibility()\n        build(input_shape)\n    """"""\n\n    def __init__(self, **kwargs):\n        self.input_spec = None\n        self.supports_masking = False\n        self.stateful = False\n\n        # These properties will be set upon call of self.build()\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self._losses = []\n        self._updates = []\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n        self._built = False\n\n        # A list of metric instances corresponding to the metric tensors added using\n        # the `add_metric` API.\n        self._metrics = []\n\n        # These lists will be filled via successive calls\n        # to self._add_inbound_node().\n        self._inbound_nodes = []\n        self._outbound_nodes = []\n\n        # These properties should be set by the user via keyword arguments.\n        # note that \'dtype\', \'input_shape\' and \'batch_input_shape\'\n        # are only applicable to input layers: do not pass these keywords\n        # to non-input layers.\n        allowed_kwargs = {\'input_shape\',\n                          \'batch_input_shape\',\n                          \'batch_size\',\n                          \'dtype\',\n                          \'name\',\n                          \'trainable\',\n                          \'weights\',\n                          \'input_dtype\',  # legacy\n                          }\n        for kwarg in kwargs:\n            if kwarg not in allowed_kwargs:\n                raise TypeError(\'Keyword argument not understood:\', kwarg)\n        name = kwargs.get(\'name\')\n        if not name:\n            prefix = self.__class__.__name__\n            name = _to_snake_case(prefix) + \'_\' + str(K.get_uid(prefix))\n        self.name = name\n\n        self.trainable = kwargs.get(\'trainable\', True)\n        if \'input_shape\' in kwargs or \'batch_input_shape\' in kwargs:\n            # In this case we will later create an input layer\n            # to insert before the current layer\n            if \'batch_input_shape\' in kwargs:\n                batch_input_shape = tuple(kwargs[\'batch_input_shape\'])\n            elif \'input_shape\' in kwargs:\n                batch_size = kwargs.get(\'batch_size\')\n                batch_input_shape = (\n                    batch_size,) + tuple(kwargs[\'input_shape\'])\n            self.batch_input_shape = batch_input_shape\n\n        # Set dtype.\n        dtype = kwargs.get(\'dtype\')\n        if dtype is None:\n            dtype = kwargs.get(\'input_dtype\')\n        if dtype is None:\n            dtype = K.floatx()\n        self.dtype = dtype\n\n        self._initial_weights = kwargs.get(\'weights\')\n\n    @staticmethod\n    def _node_key(layer, node_index):\n        """"""Converts a layer and its index to a unique (immutable type) name.\n\n        This function is used internally with `self._network_nodes`.\n\n        # Arguments\n            layer: The layer.\n            node_index: The layer\'s position (e.g. via enumerate) in a list of\n                nodes.\n\n        # Returns\n            The unique name.\n        """"""\n        return layer.name + \'_ib-\' + str(node_index)\n\n    @property\n    def losses(self):\n        losses = self._losses[:]\n        for l in getattr(self, \'_layers\', []):\n            losses += l.losses\n        return losses\n\n    @property\n    def updates(self):\n        if not self.trainable and not self.stateful:\n            return []\n        updates = self._updates[:]\n        for l in getattr(self, \'_layers\', []):\n            updates += l.updates\n        return updates\n\n    @property\n    def built(self):\n        return self._built\n\n    @built.setter\n    def built(self, value):\n        self._built = value\n\n    @property\n    def trainable_weights(self):\n        trainable = getattr(self, \'trainable\', True)\n        if trainable:\n            trainable_weights = self._trainable_weights[:]\n            for l in getattr(self, \'_layers\', []):\n                trainable_weights += l.trainable_weights\n            return trainable_weights\n        else:\n            return []\n\n    @trainable_weights.setter\n    def trainable_weights(self, weights):\n        self._trainable_weights = weights\n\n    @property\n    def non_trainable_weights(self):\n        trainable = getattr(self, \'trainable\', True)\n        if trainable:\n            weights = self._non_trainable_weights[:]\n            for l in getattr(self, \'_layers\', []):\n                weights += l.non_trainable_weights\n            return weights\n\n        else:\n            weights = self._trainable_weights[:] + self._non_trainable_weights[:]\n            for l in getattr(self, \'_layers\', []):\n                weights += l.weights\n            return weights\n\n    @non_trainable_weights.setter\n    def non_trainable_weights(self, weights):\n        self._non_trainable_weights = weights\n\n    def add_weight(self,\n                   name=None,\n                   shape=None,\n                   dtype=None,\n                   initializer=None,\n                   regularizer=None,\n                   trainable=True,\n                   constraint=None):\n        """"""Adds a weight variable to the layer.\n\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n\n        # Returns\n            The created weight variable.\n        """"""\n        if shape is None:\n            shape = ()\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = self.dtype\n        weight = K.variable(initializer(shape, dtype=dtype),\n                            dtype=dtype,\n                            name=name,\n                            constraint=constraint)\n        if regularizer is not None:\n            with K.name_scope(\'weight_regularizer\'):\n                self.add_loss(regularizer(weight))\n        if trainable:\n            self._trainable_weights.append(weight)\n        else:\n            self._non_trainable_weights.append(weight)\n        weight._tracked = True\n        return weight\n\n    def assert_input_compatibility(self, inputs):\n        """"""Checks compatibility between the layer and provided inputs.\n\n        This checks that the tensor(s) `input`\n        verify the input assumptions of the layer\n        (if any). If not, exceptions are raised.\n\n        # Arguments\n            inputs: input tensor or list of input tensors.\n\n        # Raises\n            ValueError: in case of mismatch between\n                the provided inputs and the expectations of the layer.\n        """"""\n        inputs = to_list(inputs)\n        for x in inputs:\n            try:\n                K.is_keras_tensor(x)\n            except ValueError:\n                raise ValueError(\'Layer \' + self.name + \' was called with \'\n                                 \'an input that isn\\\'t a symbolic tensor. \'\n                                 \'Received type: \' +\n                                 str(type(x)) + \'. Full input: \' +\n                                 str(inputs) + \'. All inputs to the layer \'\n                                 \'should be tensors.\')\n\n        if not self.input_spec:\n            return\n        if not isinstance(self.input_spec, (list, tuple)):\n            input_spec = to_list(self.input_spec)\n        else:\n            input_spec = self.input_spec\n        if len(inputs) != len(input_spec):\n            raise ValueError(\'Layer \' + self.name + \' expects \' +\n                             str(len(input_spec)) + \' inputs, \'\n                             \'but it received \' + str(len(inputs)) +\n                             \' input tensors. Input received: \' +\n                             str(inputs))\n        for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n            if spec is None:\n                continue\n\n            # Check ndim.\n            if spec.ndim is not None:\n                if K.ndim(x) != spec.ndim:\n                    raise ValueError(\'Input \' + str(input_index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected ndim=\' +\n                                     str(spec.ndim) + \', found ndim=\' +\n                                     str(K.ndim(x)))\n            if spec.max_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim > spec.max_ndim:\n                    raise ValueError(\'Input \' + str(input_index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected max_ndim=\' +\n                                     str(spec.max_ndim) + \', found ndim=\' +\n                                     str(K.ndim(x)))\n            if spec.min_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim < spec.min_ndim:\n                    raise ValueError(\'Input \' + str(input_index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected min_ndim=\' +\n                                     str(spec.min_ndim) + \', found ndim=\' +\n                                     str(K.ndim(x)))\n            # Check dtype.\n            if spec.dtype is not None:\n                if K.dtype(x) != spec.dtype:\n                    raise ValueError(\'Input \' + str(input_index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected dtype=\' +\n                                     str(spec.dtype) + \', found dtype=\' +\n                                     str(K.dtype(x)))\n            # Check specific shape axes.\n            if spec.axes:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for axis, value in spec.axes.items():\n                        if (value is not None and\n                                x_shape[int(axis)] not in {value, None}):\n                            raise ValueError(\n                                \'Input \' + str(input_index) +\n                                \' is incompatible with layer \' +\n                                self.name + \': expected axis \' +\n                                str(axis) + \' of input shape to have \'\n                                \'value \' + str(value) +\n                                \' but got shape \' + str(x_shape))\n            # Check shape.\n            if spec.shape is not None:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for spec_dim, dim in zip(spec.shape, x_shape):\n                        if spec_dim is not None and dim is not None:\n                            if spec_dim != dim:\n                                raise ValueError(\n                                    \'Input \' + str(input_index) +\n                                    \' is incompatible with layer \' +\n                                    self.name + \': expected shape=\' +\n                                    str(spec.shape) + \', found shape=\' +\n                                    str(x_shape))\n\n    def call(self, inputs, **kwargs):\n        """"""This is where the layer\'s logic lives.\n\n        # Arguments\n            inputs: Input tensor, or list/tuple of input tensors.\n            **kwargs: Additional keyword arguments.\n\n        # Returns\n            A tensor or list/tuple of tensors.\n        """"""\n        return inputs\n\n    @K.symbolic\n    def __call__(self, inputs, **kwargs):\n        """"""Wrapper around self.call(), for handling internal references.\n\n        If a Keras tensor is passed:\n            - We call self._add_inbound_node().\n            - If necessary, we `build` the layer to match\n                the _keras_shape of the input(s).\n            - We update the _keras_shape of every input tensor with\n                its new shape (obtained via self.compute_output_shape).\n                This is done as part of _add_inbound_node().\n            - We update the _keras_history of the output tensor(s)\n                with the current layer.\n                This is done as part of _add_inbound_node().\n\n        # Arguments\n            inputs: Can be a tensor or list/tuple of tensors.\n            **kwargs: Additional keyword arguments to be passed to `call()`.\n\n        # Returns\n            Output of the layer\'s `call` method.\n\n        # Raises\n            ValueError: in case the layer is missing shape information\n                for its `build` call.\n        """"""\n        if isinstance(inputs, list):\n            inputs = inputs[:]\n        with K.name_scope(self.name):\n            # Handle laying building (weight creating, input spec locking).\n            if not self.built:\n                # Raise exceptions in case the input is not compatible\n                # with the input_spec specified in the layer constructor.\n                self.assert_input_compatibility(inputs)\n\n                # Collect input shapes to build layer.\n                input_shapes = []\n                for x_elem in to_list(inputs):\n                    if hasattr(x_elem, \'_keras_shape\'):\n                        input_shapes.append(x_elem._keras_shape)\n                    elif hasattr(K, \'int_shape\'):\n                        input_shapes.append(K.int_shape(x_elem))\n                    else:\n                        raise ValueError(\'You tried to call layer ""\' +\n                                         self.name +\n                                         \'"". This layer has no information\'\n                                         \' about its expected input shape, \'\n                                         \'and thus cannot be built. \'\n                                         \'You can build it manually via: \'\n                                         \'`layer.build(batch_input_shape)`\')\n                self.build(unpack_singleton(input_shapes))\n                self.built = True\n\n                # Load weights that were specified at layer instantiation.\n                if self._initial_weights is not None:\n                    self.set_weights(self._initial_weights)\n\n            # Raise exceptions in case the input is not compatible\n            # with the input_spec set at build time.\n            self.assert_input_compatibility(inputs)\n\n            # Handle mask propagation.\n            previous_mask = _collect_previous_mask(inputs)\n            user_kwargs = kwargs.copy()\n            if not is_all_none(previous_mask):\n                # The previous layer generated a mask.\n                if has_arg(self.call, \'mask\'):\n                    if \'mask\' not in kwargs:\n                        # If mask is explicitly passed to __call__,\n                        # we should override the default mask.\n                        kwargs[\'mask\'] = previous_mask\n            # Handle automatic shape inference (only useful for Theano).\n            input_shape = _collect_input_shape(inputs)\n\n            # Actually call the layer,\n            # collecting output(s), mask(s), and shape(s).\n            output = self.call(inputs, **kwargs)\n            output_mask = self.compute_mask(inputs, previous_mask)\n\n            # If the layer returns tensors from its inputs, unmodified,\n            # we copy them to avoid loss of tensor metadata.\n            output_ls = to_list(output)\n            inputs_ls = to_list(inputs)\n            output_ls_copy = []\n            for x in output_ls:\n                if id(x) in [id(i) for i in inputs_ls]:\n                    x = K.identity(x)\n                output_ls_copy.append(x)\n            output = unpack_singleton(output_ls_copy)\n\n            # Inferring the output shape is only relevant for Theano.\n            if all([s is not None\n                    for s in to_list(input_shape)]):\n                output_shape = self.compute_output_shape(input_shape)\n            else:\n                if isinstance(input_shape, list):\n                    output_shape = [None for _ in input_shape]\n                else:\n                    output_shape = None\n\n            if (not isinstance(output_mask, (list, tuple)) and\n                    len(output_ls) > 1):\n                # Augment the mask to match the length of the output.\n                output_mask = [output_mask] * len(output_ls)\n\n            # Add an inbound node to the layer, so that it keeps track\n            # of the call and of all new variables created during the call.\n            # This also updates the layer history of the output tensor(s).\n            # If the input tensor(s) had not previous Keras history,\n            # this does nothing.\n            self._add_inbound_node(input_tensors=inputs,\n                                   output_tensors=output,\n                                   input_masks=previous_mask,\n                                   output_masks=output_mask,\n                                   input_shapes=input_shape,\n                                   output_shapes=output_shape,\n                                   arguments=user_kwargs)\n\n            # Apply activity regularizer if any:\n            if (hasattr(self, \'activity_regularizer\') and\n                    self.activity_regularizer is not None):\n                with K.name_scope(\'activity_regularizer\'):\n                    regularization_losses = [\n                        self.activity_regularizer(x)\n                        for x in to_list(output)]\n                self.add_loss(regularization_losses,\n                              inputs=to_list(inputs))\n        return output\n\n    def _add_inbound_node(self, input_tensors, output_tensors,\n                          input_masks, output_masks,\n                          input_shapes, output_shapes, arguments=None):\n        """"""Internal method to create an inbound node for the layer.\n\n        # Arguments\n            input_tensors: list of input tensors.\n            output_tensors: list of output tensors.\n            input_masks: list of input masks (a mask can be a tensor, or None).\n            output_masks: list of output masks\n                (a mask can be a tensor, or None).\n            input_shapes: list of input shape tuples.\n            output_shapes: list of output shape tuples.\n            arguments: dictionary of keyword arguments that were passed to the\n                `call` method of the layer at the call that created the node.\n        """"""\n        input_tensors = to_list(input_tensors)\n        output_tensors = to_list(output_tensors)\n        input_masks = to_list(input_masks)\n        output_masks = to_list(output_masks)\n        input_shapes = to_list(input_shapes)\n        output_shapes = to_list(output_shapes)\n\n        # Collect input tensor(s) coordinates.\n        inbound_layers = []\n        node_indices = []\n        tensor_indices = []\n        for x in input_tensors:\n            if hasattr(x, \'_keras_history\'):\n                inbound_layer, node_index, tensor_index = x._keras_history\n                inbound_layers.append(inbound_layer)\n                node_indices.append(node_index)\n                tensor_indices.append(tensor_index)\n            else:\n                inbound_layers.append(None)\n                node_indices.append(None)\n                tensor_indices.append(None)\n\n        # Create node, add it to inbound nodes.\n        Node(\n            self,\n            inbound_layers=inbound_layers,\n            node_indices=node_indices,\n            tensor_indices=tensor_indices,\n            input_tensors=input_tensors,\n            output_tensors=output_tensors,\n            input_masks=input_masks,\n            output_masks=output_masks,\n            input_shapes=input_shapes,\n            output_shapes=output_shapes,\n            arguments=arguments\n        )\n\n        # Update tensor history, _keras_shape and _uses_learning_phase.\n        for i in range(len(output_tensors)):\n            output_tensors[i]._keras_shape = output_shapes[i]\n            uses_lp = any(\n                [getattr(x, \'_uses_learning_phase\', False)\n                 for x in input_tensors])\n            uses_lp = getattr(self, \'uses_learning_phase\', False) or uses_lp\n            output_tensors[i]._uses_learning_phase = getattr(\n                output_tensors[i], \'_uses_learning_phase\', False) or uses_lp\n            output_tensors[i]._keras_history = (self,\n                                                len(self._inbound_nodes) - 1,\n                                                i)\n\n    def compute_output_shape(self, input_shape):\n        """"""Computes the output shape of the layer.\n\n        Assumes that the layer will be built\n        to match that input shape provided.\n\n        # Arguments\n            input_shape: Shape tuple (tuple of integers)\n                or list of shape tuples (one per output tensor of the layer).\n                Shape tuples can include None for free dimensions,\n                instead of an integer.\n\n        # Returns\n            An output shape tuple.\n        """"""\n        return input_shape\n\n    def compute_mask(self, inputs, mask=None):\n        """"""Computes an output mask tensor.\n\n        # Arguments\n            inputs: Tensor or list of tensors.\n            mask: Tensor or list of tensors.\n\n        # Returns\n            None or a tensor (or list of tensors,\n                one per output tensor of the layer).\n        """"""\n        if not self.supports_masking:\n            if mask is not None:\n                if isinstance(mask, list):\n                    if any(m is not None for m in mask):\n                        raise TypeError(\'Layer \' + self.name +\n                                        \' does not support masking, \'\n                                        \'but was passed an input_mask: \' +\n                                        str(mask))\n                else:\n                    raise TypeError(\'Layer \' + self.name +\n                                    \' does not support masking, \'\n                                    \'but was passed an input_mask: \' +\n                                    str(mask))\n            # masking not explicitly supported: return None as mask\n            return None\n        # if masking is explicitly supported, by default\n        # carry over the input mask\n        return mask\n\n    def build(self, input_shape):\n        """"""Creates the layer weights.\n\n        Must be implemented on all layers that have weights.\n\n        # Arguments\n            input_shape: Keras tensor (future input to layer)\n                or list/tuple of Keras tensors to reference\n                for weight shape computations.\n        """"""\n        self.built = True\n\n    def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n        """"""Retrieves an attribute (e.g. input_tensors) from a node.\n\n        This is used to implement the methods:\n            - get_input_shape_at\n            - get_output_shape_at\n            - get_input_at\n            etc...\n\n        # Arguments\n            node_index: Integer index of the node from which\n                to retrieve the attribute.\n            attr: Exact node attribute name.\n            attr_name: Human-readable attribute name, for error messages.\n\n        # Returns\n            The layer\'s attribute `attr` at the node of index `node_index`.\n\n        # Raises\n            RuntimeError: If the layer has no inbound nodes.\n            ValueError: If the index is does not match any node.\n        """"""\n        if not self._inbound_nodes:\n            raise RuntimeError(\'The layer has never been called \'\n                               \'and thus has no defined \' + attr_name + \'.\')\n        if not len(self._inbound_nodes) > node_index:\n            raise ValueError(\'Asked to get \' + attr_name +\n                             \' at node \' + str(node_index) +\n                             \', but the layer has only \' +\n                             str(len(self._inbound_nodes)) + \' inbound nodes.\')\n        values = getattr(self._inbound_nodes[node_index], attr)\n        return unpack_singleton(values)\n\n    def get_input_shape_at(self, node_index):\n        """"""Retrieves the input shape(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A shape tuple\n            (or list of shape tuples if the layer has multiple inputs).\n        """"""\n        return self._get_node_attribute_at_index(node_index,\n                                                 \'input_shapes\',\n                                                 \'input shape\')\n\n    def get_output_shape_at(self, node_index):\n        """"""Retrieves the output shape(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A shape tuple\n            (or list of shape tuples if the layer has multiple outputs).\n        """"""\n        return self._get_node_attribute_at_index(node_index,\n                                                 \'output_shapes\',\n                                                 \'output shape\')\n\n    def get_input_at(self, node_index):\n        """"""Retrieves the input tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A tensor (or list of tensors if the layer has multiple inputs).\n        """"""\n        return self._get_node_attribute_at_index(node_index,\n                                                 \'input_tensors\',\n                                                 \'input\')\n\n    def get_output_at(self, node_index):\n        """"""Retrieves the output tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A tensor (or list of tensors if the layer has multiple outputs).\n        """"""\n        return self._get_node_attribute_at_index(node_index,\n                                                 \'output_tensors\',\n                                                 \'output\')\n\n    def get_input_mask_at(self, node_index):\n        """"""Retrieves the input mask tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A mask tensor\n            (or list of tensors if the layer has multiple inputs).\n        """"""\n        return self._get_node_attribute_at_index(node_index,\n                                                 \'input_masks\',\n                                                 \'input mask\')\n\n    def get_output_mask_at(self, node_index):\n        """"""Retrieves the output mask tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A mask tensor\n            (or list of tensors if the layer has multiple outputs).\n        """"""\n        return self._get_node_attribute_at_index(node_index,\n                                                 \'output_masks\',\n                                                 \'output mask\')\n\n    @property\n    def input(self):\n        """"""Retrieves the input tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input tensor or list of input tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        """"""\n        if len(self._inbound_nodes) > 1:\n            raise AttributeError(\'Layer \' + self.name +\n                                 \' has multiple inbound nodes, \'\n                                 \'hence the notion of ""layer input"" \'\n                                 \'is ill-defined. \'\n                                 \'Use `get_input_at(node_index)` instead.\')\n        elif not self._inbound_nodes:\n            raise AttributeError(\'Layer \' + self.name +\n                                 \' is not connected, no input to return.\')\n        return self._get_node_attribute_at_index(0, \'input_tensors\',\n                                                 \'input\')\n\n    @property\n    def output(self):\n        """"""Retrieves the output tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Output tensor or list of output tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        """"""\n        if not self._inbound_nodes:\n            raise AttributeError(\'Layer \' + self.name +\n                                 \' has no inbound nodes.\')\n        if len(self._inbound_nodes) > 1:\n            raise AttributeError(\'Layer \' + self.name +\n                                 \' has multiple inbound nodes, \'\n                                 \'hence the notion of ""layer output"" \'\n                                 \'is ill-defined. \'\n                                 \'Use `get_output_at(node_index)` instead.\')\n        return self._get_node_attribute_at_index(0, \'output_tensors\',\n                                                 \'output\')\n\n    @property\n    def input_mask(self):\n        """"""Retrieves the input mask tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input mask tensor (potentially None) or list of input\n            mask tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        """"""\n        if len(self._inbound_nodes) != 1:\n            raise AttributeError(\'Layer \' + self.name +\n                                 \' has multiple inbound nodes, \' +\n                                 \'hence the notion of ""layer input mask"" \'\n                                 \'is ill-defined. \'\n                                 \'Use `get_input_mask_at(node_index)` \'\n                                 \'instead.\')\n        return self._get_node_attribute_at_index(0, \'input_masks\',\n                                                 \'input mask\')\n\n    @property\n    def output_mask(self):\n        """"""Retrieves the output mask tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Output mask tensor (potentially None) or list of output\n            mask tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        """"""\n        if len(self._inbound_nodes) != 1:\n            raise AttributeError(\'Layer \' + self.name +\n                                 \' has multiple inbound nodes, \'\n                                 \'hence the notion of ""layer output mask"" \'\n                                 \'is ill-defined. \'\n                                 \'Use `get_output_mask_at(node_index)` \'\n                                 \'instead.\')\n        return self._get_node_attribute_at_index(0, \'output_masks\',\n                                                 \'output mask\')\n\n    @property\n    def input_shape(self):\n        """"""Retrieves the input shape tuple(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input shape tuple\n            (or list of input shape tuples, one tuple per input tensor).\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        """"""\n        if not self._inbound_nodes:\n            raise AttributeError(\'The layer has never been called \'\n                                 \'and thus has no defined input shape.\')\n        all_input_shapes = set(\n            [str(node.input_shapes) for node in self._inbound_nodes])\n        if len(all_input_shapes) == 1:\n            input_shapes = self._inbound_nodes[0].input_shapes\n            return unpack_singleton(input_shapes)\n        else:\n            raise AttributeError(\'The layer ""\' + str(self.name) +\n                                 \' has multiple inbound nodes, \'\n                                 \'with different input shapes. Hence \'\n                                 \'the notion of ""input shape"" is \'\n                                 \'ill-defined for the layer. \'\n                                 \'Use `get_input_shape_at(node_index)` \'\n                                 \'instead.\')\n\n    @property\n    def output_shape(self):\n        """"""Retrieves the output shape tuple(s) of a layer.\n\n        Only applicable if the layer has one inbound node,\n        or if all inbound nodes have the same output shape.\n\n        # Returns\n            Output shape tuple\n            (or list of input shape tuples, one tuple per output tensor).\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        """"""\n        if not self._inbound_nodes:\n            raise AttributeError(\'The layer has never been called \'\n                                 \'and thus has no defined output shape.\')\n        all_output_shapes = set(\n            [str(node.output_shapes) for node in self._inbound_nodes])\n        if len(all_output_shapes) == 1:\n            output_shapes = self._inbound_nodes[0].output_shapes\n            return unpack_singleton(output_shapes)\n        else:\n            raise AttributeError(\'The layer ""\' + str(self.name) +\n                                 \' has multiple inbound nodes, \'\n                                 \'with different output shapes. Hence \'\n                                 \'the notion of ""output shape"" is \'\n                                 \'ill-defined for the layer. \'\n                                 \'Use `get_output_shape_at(node_index)` \'\n                                 \'instead.\')\n\n    @property\n    def metrics(self):\n        metrics = self._metrics[:]\n        for l in getattr(self, \'_layers\', []):\n            metrics += l.metrics\n        return metrics\n\n    def add_metric(self, value, name=None):\n        """"""Adds metric tensor to the layer.\n\n        # Arguments\n            value: Metric tensor.\n            name: String metric name.\n        """"""\n        match = self._get_existing_metric(name)\n        if match:\n            return\n        if hasattr(value, \'_metric_obj\'):\n            # We track the instance using the metadata on the result tensor.\n            # Use case: model.add_metric(metrics.Mean(name=\'metric_2\')(y))\n            self._metrics.append(value._metric_obj)\n        else:\n            # Use cases: model.add_metric(K.sum(y), name=\'metric_1\')\n            metric_obj = _create_mean_metric(value, name)\n            self._metrics.append(metric_obj)\n\n    def add_loss(self, losses, inputs=None):\n        """"""Adds losses to the layer.\n\n        The loss may potentially be conditional on some inputs tensors,\n        for instance activity losses are conditional on the layer\'s inputs.\n\n        # Arguments\n            losses: loss tensor or list of loss tensors\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the losses as conditional on these inputs.\n                If None is passed, the loss is assumed unconditional\n                (e.g. L2 weight regularization, which only depends\n                on the layer\'s weights variables, not on any inputs tensors).\n        """"""\n        if losses is None:\n            return\n        # Update self.losses\n        losses = to_list(losses)\n        if losses == []:\n            return\n        if hasattr(self, \'_losses\'):\n            self._losses += losses\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_losses:\n            self._per_input_losses[inputs_hash] = []\n        self._per_input_losses[inputs_hash] += losses\n\n    def add_update(self, updates, inputs=None):\n        """"""Adds updates to the layer.\n\n        The updates may potentially be conditional on some inputs tensors,\n        for instance batch norm updates are conditional on the layer\'s inputs.\n\n        # Arguments\n            updates: update op or list of update ops\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the updates as conditional on these inputs.\n                If None is passed, the updates are assumed unconditional.\n        """"""\n        if updates is None:\n            return\n        # Update self.updates\n        updates = to_list(updates)\n        if updates == []:\n            return\n        if hasattr(self, \'_updates\'):\n            self._updates += updates\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_updates:\n            self._per_input_updates[inputs_hash] = []\n        self._per_input_updates[inputs_hash] += updates\n\n    def get_updates_for(self, inputs):\n        if not self.trainable and not self.stateful:\n            return []\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        updates = []\n        if inputs_hash in self._per_input_updates:\n            updates += self._per_input_updates[inputs_hash]\n        for l in getattr(self, \'_layers\', []):\n            updates += l.get_updates_for(inputs)\n        return updates\n\n    def get_losses_for(self, inputs):\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        losses = []\n        if inputs_hash in self._per_input_losses:\n            losses += self._per_input_losses[inputs_hash]\n        for l in getattr(self, \'_layers\', []):\n            losses += l.get_losses_for(inputs)\n        return losses\n\n    @property\n    def weights(self):\n        return self.trainable_weights + self.non_trainable_weights\n\n    @K.eager\n    def set_weights(self, weights):\n        """"""Sets the weights of the layer, from Numpy arrays.\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the layer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: If the provided weights list does not match the\n                layer\'s specifications.\n        """"""\n        params = self.weights\n        if len(params) != len(weights):\n            raise ValueError(\'You called `set_weights(weights)` on layer ""\' +\n                             self.name +\n                             \'"" with a weight list of length \' +\n                             str(len(weights)) +\n                             \', but the layer was expecting \' +\n                             str(len(params)) +\n                             \' weights. Provided weights: \' +\n                             str(weights)[:50] + \'...\')\n        if not params:\n            return\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError(\'Layer weight shape \' +\n                                 str(pv.shape) +\n                                 \' not compatible with \'\n                                 \'provided weight shape \' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)\n\n    @K.eager\n    def get_weights(self):\n        """"""Returns the current weights of the layer.\n\n        # Returns\n            Weights values as a list of numpy arrays.\n        """"""\n        params = self.weights\n        return K.batch_get_value(params)\n\n    def get_config(self):\n        """"""Returns the config of the layer.\n\n        A layer config is a Python dictionary (serializable)\n        containing the configuration of a layer.\n        The same layer can be reinstantiated later\n        (without its trained weights) from this configuration.\n\n        The config of a layer does not include connectivity\n        information, nor the layer class name. These are handled\n        by `Network` (one layer of abstraction above).\n\n        # Returns\n            Python dictionary.\n        """"""\n        config = {\'name\': self.name,\n                  \'trainable\': self.trainable}\n        if hasattr(self, \'batch_input_shape\'):\n            config[\'batch_input_shape\'] = self.batch_input_shape\n        if hasattr(self, \'dtype\'):\n            config[\'dtype\'] = self.dtype\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        """"""Creates a layer from its config.\n\n        This method is the reverse of `get_config`,\n        capable of instantiating the same layer from the config\n        dictionary. It does not handle layer connectivity\n        (handled by Network), nor weights (handled by `set_weights`).\n\n        # Arguments\n            config: A Python dictionary, typically the\n                output of get_config.\n\n        # Returns\n            A layer instance.\n        """"""\n        return cls(**config)\n\n    def count_params(self):\n        """"""Counts the total number of scalars composing the weights.\n\n        # Returns\n            An integer count.\n\n        # Raises\n            RuntimeError: if the layer isn\'t yet built\n                (in which case its weights aren\'t yet defined).\n        """"""\n        if not self.built:\n            if self.__class__.__name__ == \'Sequential\':\n                self.build()\n            else:\n                raise RuntimeError(\'You tried to call `count_params` on \' +\n                                   self.name + \', but the layer isn\\\'t built. \'\n                                   \'You can build it manually via: `\' +\n                                   self.name + \'.build(batch_input_shape)`.\')\n        return count_params(self.weights)\n\n    def _get_existing_metric(self, name=None):\n        match = [m for m in self._metrics if m.name == name]\n        if not match:\n            return\n        if len(match) > 1:\n            raise ValueError(\n                \'Please provide different names for the metrics you have added. \'\n                \'We found {} metrics with the name: ""{}""\'.format(len(match), name))\n        return match[0]\n\n    def __setattr__(self, name, value):\n        # Keep track of metric instance created in subclassed model/layer.\n        # We do this so that we can maintain the correct order of metrics by adding\n        # the instance to the `metrics` list as soon as it is created.\n        if not hasattr(_DISABLE_TRACKING, \'value\'):\n            _DISABLE_TRACKING.value = False\n        if not _DISABLE_TRACKING.value:\n            from .. import metrics as metrics_module\n            if isinstance(value, metrics_module.Metric):\n                if not hasattr(self, \'_metrics\'):\n                    self._metrics = []\n                self._metrics.append(value)\n            else:\n                # Automatically track layers set as attributes.\n                if isinstance(value, Layer):\n                    if not hasattr(self, \'_layers\'):\n                        self._layers = []\n                    if value not in self._layers:\n                        self._layers.append(value)\n                if K.is_variable(value) and not getattr(value, \'_tracked\', False):\n                    # Automatically track variables set as attributes.\n                    trainable = getattr(value, \'trainable\', False)\n                    if trainable:\n                        if not hasattr(self, \'_trainable_weights\'):\n                            self._trainable_weights = []\n                        if not any(v is value for v in self._trainable_weights):\n                            print(\'tracking\', value, name)\n                            self._trainable_weights.append(value)\n                    else:\n                        if not hasattr(self, \'_non_trainable_weights\'):\n                            self._non_trainable_weights = []\n                        if not any(v is value for v in self._non_trainable_weights):\n                            self._non_trainable_weights.append(value)\n\n        super(Layer, self).__setattr__(name, value)\n\n\ndef _create_mean_metric(value, name=None):\n    from .. import metrics\n    metric_obj = metrics.Mean(name=name)\n    _call_metric(metric_obj, value)\n    return metric_obj\n\n\n@K.symbolic\ndef _call_metric(metric_obj, *args, **kwargs):\n    update_op = metric_obj.update_state(*args, **kwargs)\n    with K.control_dependencies(update_op):  # For TF\n        result_t = metric_obj.result()\n\n\nclass InputSpec(object):\n    """"""Specifies the ndim, dtype and shape of every input to a layer.\n\n    Every layer should expose (if appropriate) an `input_spec` attribute:\n    a list of instances of InputSpec (one per input tensor).\n\n    A None entry in a shape is compatible with any dimension,\n    a None shape is compatible with any shape.\n\n    # Arguments\n        dtype: Expected datatype of the input.\n        shape: Shape tuple, expected shape of the input\n            (may include None for unchecked axes).\n        ndim: Integer, expected rank of the input.\n        max_ndim: Integer, maximum rank of the input.\n        min_ndim: Integer, minimum rank of the input.\n        axes: Dictionary mapping integer axes to\n            a specific dimension value.\n    """"""\n\n    def __init__(self, dtype=None,\n                 shape=None,\n                 ndim=None,\n                 max_ndim=None,\n                 min_ndim=None,\n                 axes=None):\n        self.dtype = dtype\n        self.shape = shape\n        if shape is not None:\n            self.ndim = len(shape)\n        else:\n            self.ndim = ndim\n        self.max_ndim = max_ndim\n        self.min_ndim = min_ndim\n        self.axes = axes or {}\n\n    def __repr__(self):\n        spec = [(\'dtype=\' + str(self.dtype)) if self.dtype else \'\',\n                (\'shape=\' + str(self.shape)) if self.shape else \'\',\n                (\'ndim=\' + str(self.ndim)) if self.ndim else \'\',\n                (\'max_ndim=\' + str(self.max_ndim)) if self.max_ndim else \'\',\n                (\'min_ndim=\' + str(self.min_ndim)) if self.min_ndim else \'\',\n                (\'axes=\' + str(self.axes)) if self.axes else \'\']\n        return \'InputSpec(%s)\' % \', \'.join(x for x in spec if x)\n\n\nclass Node(object):\n    """"""A `Node` describes the connectivity between two layers.\n\n    Each time a layer is connected to some new input,\n    a node is added to `layer._inbound_nodes`.\n    Each time the output of a layer is used by another layer,\n    a node is added to `layer._outbound_nodes`.\n\n    # Arguments\n        outbound_layer: the layer that takes\n            `input_tensors` and turns them into `output_tensors`\n            (the node gets created when the `call`\n            method of the layer was called).\n        inbound_layers: a list of layers, the same length as `input_tensors`,\n            the layers from where `input_tensors` originate.\n        node_indices: a list of integers, the same length as `inbound_layers`.\n            `node_indices[i]` is the origin node of `input_tensors[i]`\n            (necessary since each inbound layer might have several nodes,\n            e.g. if the layer is being shared with a different data stream).\n        tensor_indices: a list of integers,\n            the same length as `inbound_layers`.\n            `tensor_indices[i]` is the index of `input_tensors[i]` within the\n            output of the inbound layer\n            (necessary since each inbound layer might\n            have multiple tensor outputs, with each one being\n            independently manipulable).\n        input_tensors: list of input tensors.\n        output_tensors: list of output tensors.\n        input_masks: list of input masks (a mask can be a tensor, or None).\n        output_masks: list of output masks (a mask can be a tensor, or None).\n        input_shapes: list of input shape tuples.\n        output_shapes: list of output shape tuples.\n        arguments: dictionary of keyword arguments that were passed to the\n            `call` method of the layer at the call that created the node.\n\n    `node_indices` and `tensor_indices` are basically fine-grained coordinates\n    describing the origin of the `input_tensors`, verifying the following:\n\n    origin_node = inbound_layers[i]._inbound_nodes[node_indices[i]]\n    input_tensors[i] == origin_node.output_tensors[tensor_indices[i]]\n\n    A node from layer A to layer B is added to:\n        A._outbound_nodes\n        B._inbound_nodes\n    """"""\n\n    def __init__(self, outbound_layer,\n                 inbound_layers, node_indices, tensor_indices,\n                 input_tensors, output_tensors,\n                 input_masks, output_masks,\n                 input_shapes, output_shapes,\n                 arguments=None):\n        # Layer instance (NOT a list).\n        # this is the layer that takes a list of input tensors\n        # and turns them into a list of output tensors.\n        # the current node will be added to\n        # the inbound_nodes of outbound_layer.\n        self.outbound_layer = outbound_layer\n\n        # The following 3 properties describe where\n        # the input tensors come from: which layers,\n        # and for each layer, which node and which\n        # tensor output of each node.\n\n        # List of layer instances.\n        self.inbound_layers = inbound_layers\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.node_indices = node_indices\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.tensor_indices = tensor_indices\n\n        # Following 2 properties:\n        # tensor inputs and outputs of outbound_layer.\n\n        # List of tensors. 1:1 mapping with inbound_layers.\n        self.input_tensors = input_tensors\n        # List of tensors, created by outbound_layer.call().\n        self.output_tensors = output_tensors\n\n        # Following 2 properties: input and output masks.\n        # List of tensors, 1:1 mapping with input_tensor.\n        self.input_masks = input_masks\n        # List of tensors, created by outbound_layer.compute_mask().\n        self.output_masks = output_masks\n\n        # Following 2 properties: input and output shapes.\n\n        # List of shape tuples, shapes of input_tensors.\n        self.input_shapes = input_shapes\n        # List of shape tuples, shapes of output_tensors.\n        self.output_shapes = output_shapes\n\n        # Optional keyword arguments to layer\'s `call`.\n        self.arguments = arguments\n\n        # Add nodes to all layers involved.\n        for layer in inbound_layers:\n            if layer is not None:\n                layer._outbound_nodes.append(self)\n        outbound_layer._inbound_nodes.append(self)\n\n    def get_config(self):\n        inbound_names = []\n        for layer in self.inbound_layers:\n            if layer:\n                inbound_names.append(layer.name)\n            else:\n                inbound_names.append(None)\n        if self.outbound_layer:\n            outbound_layer = self.outbound_layer.name\n        else:\n            outbound_layer = None\n        return {\'outbound_layer\': outbound_layer,\n                \'inbound_layers\': inbound_names,\n                \'node_indices\': self.node_indices,\n                \'tensor_indices\': self.tensor_indices}\n\n\ndef _collect_previous_mask(input_tensors):\n    """"""Retrieves the output mask(s) of the previous node.\n\n    # Arguments\n        input_tensors: A tensor or list of tensors.\n\n    # Returns\n        A mask tensor or list of mask tensors.\n    """"""\n    input_tensors = to_list(input_tensors)\n    masks = []\n    for x in input_tensors:\n        if hasattr(x, \'_keras_history\'):\n            inbound_layer, node_index, tensor_index = x._keras_history\n            node = inbound_layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        else:\n            masks.append(None)\n    return unpack_singleton(masks)\n\n\ndef _to_snake_case(name):\n    intermediate = re.sub(\'(.)([A-Z][a-z0-9]+)\', r\'\\1_\\2\', name)\n    insecure = re.sub(\'([a-z])([A-Z])\', r\'\\1_\\2\', intermediate).lower()\n    # If the class is private the name starts with ""_"" which is not secure\n    # for creating scopes. We prefix the name with ""private"" in this case.\n    if insecure[0] != \'_\':\n        return insecure\n    return \'private\' + insecure\n\n\ndef _collect_input_shape(input_tensors):\n    """"""Collects the output shape(s) of a list of Keras tensors.\n\n    # Arguments\n        input_tensors: list of input tensors (or single input tensor).\n\n    # Returns\n        List of shape tuples (or single tuple), one tuple per input.\n    """"""\n    input_tensors = to_list(input_tensors)\n    shapes = []\n    for x in input_tensors:\n        try:\n            shapes.append(K.int_shape(x))\n        except TypeError:\n            shapes.append(None)\n    return unpack_singleton(shapes)\n'"
keras/engine/input_layer.py,0,"b'""""""Input layer code (`Input` and `InputLayer`).\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nfrom .base_layer import Layer\nfrom .base_layer import Node\nfrom .. import backend as K\nfrom ..legacy import interfaces\nfrom ..utils.generic_utils import unpack_singleton\n\n\nclass InputLayer(Layer):\n    """"""Layer to be used as an entry point into a model.\n\n    It can either wrap an existing tensor (pass an `input_tensor` argument)\n    or create its a placeholder tensor (pass arguments `input_shape`\n    or `batch_input_shape` as well as `dtype`).\n\n    # Arguments\n        input_shape: Shape tuple, not including the batch axis.\n        batch_size: Optional input batch size (integer or None).\n        batch_input_shape: Shape tuple, including the batch axis.\n        dtype: Datatype of the input.\n        input_tensor: Optional tensor to use as layer input\n            instead of creating a placeholder.\n        sparse: Boolean, whether the placeholder created\n            is meant to be sparse.\n        name: Name of the layer (string).\n    """"""\n\n    @interfaces.legacy_input_support\n    def __init__(self, input_shape=None, batch_size=None,\n                 batch_input_shape=None,\n                 dtype=None, input_tensor=None, sparse=False, name=None):\n        if not name:\n            prefix = \'input\'\n            name = prefix + \'_\' + str(K.get_uid(prefix))\n        super(InputLayer, self).__init__(dtype=dtype, name=name)\n\n        self.trainable = False\n        self.built = True\n        self.sparse = sparse\n        self.supports_masking = True\n\n        if input_shape and batch_input_shape:\n            raise ValueError(\'Only provide the input_shape OR \'\n                             \'batch_input_shape argument to \'\n                             \'InputLayer, not both at the same time.\')\n        if input_tensor is not None and batch_input_shape is None:\n            # If input_tensor is set, and batch_input_shape is not set:\n            # Attempt automatic input shape inference.\n            try:\n                batch_input_shape = K.int_shape(input_tensor)\n            except TypeError:\n                if not input_shape and not batch_input_shape:\n                    raise ValueError(\'InputLayer was provided \'\n                                     \'an input_tensor argument, \'\n                                     \'but its input shape cannot be \'\n                                     \'automatically inferred. \'\n                                     \'You should pass an input_shape or \'\n                                     \'batch_input_shape argument.\')\n        if not batch_input_shape:\n            if not input_shape:\n                raise ValueError(\'An Input layer should be passed either \'\n                                 \'a `batch_input_shape` or an `input_shape`.\')\n            else:\n                batch_input_shape = (batch_size,) + tuple(input_shape)\n        else:\n            batch_input_shape = tuple(batch_input_shape)\n\n        if not dtype:\n            if input_tensor is None:\n                dtype = K.floatx()\n            else:\n                dtype = K.dtype(input_tensor)\n\n        self.batch_input_shape = batch_input_shape\n        self.dtype = dtype\n\n        if input_tensor is None:\n            self.is_placeholder = True\n            input_tensor = K.placeholder(shape=batch_input_shape,\n                                         dtype=dtype,\n                                         sparse=self.sparse,\n                                         name=self.name)\n        else:\n            self.is_placeholder = False\n            input_tensor._keras_shape = batch_input_shape\n        # Create an input node to add to self.outbound_node\n        # and set output_tensors\' _keras_history.\n        input_tensor._uses_learning_phase = False\n        input_tensor._keras_history = (self, 0, 0)\n        Node(self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=[input_tensor],\n             output_tensors=[input_tensor],\n             input_masks=[None],\n             output_masks=[None],\n             input_shapes=[batch_input_shape],\n             output_shapes=[batch_input_shape])\n\n    def get_config(self):\n        config = {\'batch_input_shape\': self.batch_input_shape,\n                  \'dtype\': self.dtype,\n                  \'sparse\': self.sparse,\n                  \'name\': self.name}\n        return config\n\n\ndef Input(shape=None, batch_shape=None,\n          name=None, dtype=None, sparse=False,\n          tensor=None):\n    """"""`Input()` is used to instantiate a Keras tensor.\n\n    A Keras tensor is a tensor object from the underlying backend\n    (Theano, TensorFlow or CNTK), which we augment with certain\n    attributes that allow us to build a Keras model\n    just by knowing the inputs and outputs of the model.\n\n    For instance, if a, b and c are Keras tensors,\n    it becomes possible to do:\n    `model = Model(input=[a, b], output=c)`\n\n    The added Keras attributes are:\n        `_keras_shape`: Integer shape tuple propagated\n            via Keras-side shape inference.\n        `_keras_history`: Last layer applied to the tensor.\n            the entire layer graph is retrievable from that layer,\n            recursively.\n\n    # Arguments\n        shape: A shape tuple (integer), not including the batch size.\n            For instance, `shape=(32,)` indicates that the expected input\n            will be batches of 32-dimensional vectors.\n        batch_shape: A shape tuple (integer), including the batch size.\n            For instance, `batch_shape=(10, 32)` indicates that\n            the expected input will be batches of 10 32-dimensional vectors.\n            `batch_shape=(None, 32)` indicates batches of an arbitrary number\n            of 32-dimensional vectors.\n        name: An optional name string for the layer.\n            Should be unique in a model (do not reuse the same name twice).\n            It will be autogenerated if it isn\'t provided.\n        dtype: The data type expected by the input, as a string\n            (`float32`, `float64`, `int32`...)\n        sparse: A boolean specifying whether the placeholder\n            to be created is sparse.\n        tensor: Optional existing tensor to wrap into the `Input` layer.\n            If set, the layer will not create a placeholder tensor.\n\n    # Returns\n        A tensor.\n\n    # Example\n\n    ```python\n    # this is a logistic regression in Keras\n    x = Input(shape=(32,))\n    y = Dense(16, activation=\'softmax\')(x)\n    model = Model(x, y)\n    ```\n    """"""\n    if not batch_shape and tensor is None:\n        assert shape is not None, (\'Please provide to Input either a `shape`\'\n                                   \' or a `batch_shape` argument. Note that \'\n                                   \'`shape` does not include the batch \'\n                                   \'dimension.\')\n    if shape is not None and not batch_shape:\n        batch_shape = (None,) + tuple(shape)\n    if not dtype:\n        dtype = K.floatx()\n    input_layer = InputLayer(batch_input_shape=batch_shape,\n                             name=name, dtype=dtype,\n                             sparse=sparse,\n                             input_tensor=tensor)\n    # Return tensor including _keras_shape and _keras_history.\n    # Note that in this case train_output and test_output are the same pointer.\n    outputs = input_layer._inbound_nodes[0].output_tensors\n    return unpack_singleton(outputs)\n'"
keras/engine/network.py,0,"b'""""""A `Network` is way to compose layers: the topological form of a `Model`.\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nimport numpy as np\nimport json\nimport yaml\nimport warnings\nimport copy\nimport os\nfrom six.moves import zip\n\nfrom . import saving\nfrom .base_layer import Layer\nfrom .base_layer import Node\nfrom .input_layer import InputLayer\nfrom .. import backend as K\nfrom ..utils.io_utils import ask_to_proceed_with_overwrite\nfrom ..utils.layer_utils import print_summary as print_layer_summary\nfrom ..utils.layer_utils import get_source_inputs\nfrom ..utils.generic_utils import has_arg\nfrom ..utils.generic_utils import to_list\nfrom ..utils.generic_utils import object_list_uid\nfrom ..utils.generic_utils import unpack_singleton\nfrom ..legacy import interfaces\n\ntry:\n    import h5py\nexcept ImportError:\n    h5py = None\n\n\nclass Network(Layer):\n    """"""A Network is a directed acyclic graph of layers.\n\n    It is the topological form of a ""model"". A Model\n    is simply a Network with added training routines.\n\n    # Properties\n        name\n        inputs\n        outputs\n        layers\n        input_spec (list of class instances)\n            each entry describes one required input:\n                - ndim\n                - dtype\n        trainable (boolean)\n        dtype\n        input_shape\n        output_shape\n        weights (list of variables)\n        trainable_weights (list of variables)\n        non_trainable_weights (list of variables)\n        losses\n        updates\n        state_updates\n        stateful\n\n    # Methods\n        __call__\n        summary\n        get_layer\n        get_weights\n        set_weights\n        get_config\n        compute_output_shape\n        save\n        add_loss\n        add_update\n        get_losses_for\n        get_updates_for\n        to_json\n        to_yaml\n        reset_states\n\n    # Class Methods\n        from_config\n\n    # Raises\n        TypeError: if input tensors are not Keras tensors\n            (tensors returned by `Input`).\n    """"""\n\n    @interfaces.legacy_model_constructor_support\n    def __init__(self, *args, **kwargs):\n        # Signature detection\n        if (len(args) == 2 or\n            len(args) == 1 and \'outputs\' in kwargs or\n                \'inputs\' in kwargs and \'outputs\' in kwargs):\n            # Graph network\n            self._init_graph_network(*args, **kwargs)\n        else:\n            # Subclassed network\n            self._init_subclassed_network(**kwargs)\n\n    def _base_init(self, name=None, trainable=True, dtype=None):\n        # The following are implemented as property functions:\n        # self.trainable_weights\n        # self.non_trainable_weights\n        # self.input_spec\n        # self.losses\n        # self.updates\n\n        # Handle `name` argument.\n        if not name:\n            prefix = self.__class__.__name__.lower()\n            name = prefix + \'_\' + str(K.get_uid(prefix))\n        self.name = name\n\n        # This acts just like the `trainable` attribute of any layer instance.\n        # It does not affect users of the underlying layers, only users of the\n        # Network instance.\n        self.trainable = trainable\n        if dtype is None:\n            dtype = K.floatx()\n        self.dtype = dtype\n        self._is_compiled = False\n        self._expects_training_arg = False\n        self._initial_weights = None\n\n        self.supports_masking = False\n        if not hasattr(self, \'optimizer\'):\n            # Don\'t reset optimizer if already set.\n            self.optimizer = None\n\n        # Private attributes to implement compatibility with Layer.\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self._updates = []\n        self._losses = []\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n\n        # A list of metric instances corresponding to the metric tensors added using\n        # the `add_metric` API.\n        self._metrics = []\n\n        # All layers in order of horizontal graph traversal.\n        # Entries are unique. Includes input and output layers.\n        self._layers = []\n\n        # Used only in conjunction with graph-networks\n        self._outbound_nodes = []\n        self._inbound_nodes = []\n\n    def _init_graph_network(self, inputs, outputs, name=None, **kwargs):\n        self._uses_inputs_arg = True\n        # Normalize and set self.inputs, self.outputs.\n        self.inputs = to_list(inputs, allow_tuple=True)\n        self.outputs = to_list(outputs, allow_tuple=True)\n\n        # User-provided argument validation.\n        # Check for redundancy in inputs.\n        if len(set(id(x) for x in self.inputs)) != len(self.inputs):\n            raise ValueError(\'The list of inputs passed to the model \'\n                             \'is redundant. \'\n                             \'All inputs should only appear once.\'\n                             \' Found: \' + str(self.inputs))\n        for x in self.inputs:\n            # Check that x has appropriate `_keras_history` metadata.\n            if not hasattr(x, \'_keras_history\'):\n                cls_name = self.__class__.__name__\n                raise ValueError(\'Input tensors to a \' + cls_name + \' \' +\n                                 \'must come from `keras.layers.Input`. \'\n                                 \'Received: \' + str(x) +\n                                 \' (missing previous layer metadata).\')\n            # Check that x is an input tensor.\n            layer, node_index, tensor_index = x._keras_history\n            if (len(layer._inbound_nodes) > 1 or\n                    (layer._inbound_nodes and\n                     layer._inbound_nodes[0].inbound_layers)):\n                cls_name = self.__class__.__name__\n                warnings.warn(cls_name + \' inputs must come from \'\n                              \'`keras.layers.Input` \'\n                              \'(thus holding past layer metadata), \'\n                              \'they cannot be the output of \'\n                              \'a previous non-Input layer. \'\n                              \'Here, a tensor specified as \'\n                              \'input to your model \'\n                              \'was not an Input tensor, \'\n                              \'it was generated by layer \' +\n                              layer.name + \'.\\n\'\n                              \'Note that input tensors are \'\n                              \'instantiated via \'\n                              \'`tensor = keras.layers.Input(shape)`.\\n\'\n                              \'The tensor that caused the issue was: \' +\n                              str(x.name))\n        for x in self.outputs:\n            if not hasattr(x, \'_keras_history\'):\n                cls_name = self.__class__.__name__\n                raise ValueError(\'Output tensors to a \' + cls_name +\n                                 \' must be \'\n                                 \'the output of a Keras `Layer` \'\n                                 \'(thus holding past layer metadata). \'\n                                 \'Found: \' + str(x))\n        self._base_init(name=name, **kwargs)\n        self._compute_previous_mask = (\n            has_arg(self.call, \'mask\') or\n            hasattr(self, \'compute_mask\'))\n        # A Network does not create weights of its own,\n        # thus it is already built.\n        self.built = True\n        self._is_graph_network = True\n\n        self._input_layers = []\n        self._output_layers = []\n        self._input_coordinates = []\n        self._output_coordinates = []\n\n        # This is for performance optimization when calling the Network on new\n        # inputs. Every time the Network is called on a set on input tensors,\n        # we compute the output tensors,\n        # output masks and output shapes in one pass,\n        # then cache them here. When any of these outputs is queried later, we\n        # retrieve it from there instead of recomputing it.\n        self._output_mask_cache = {}\n        self._output_tensor_cache = {}\n        self._output_shape_cache = {}\n\n        # Build self._output_layers:\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            self._output_layers.append(layer)\n            self._output_coordinates.append((layer, node_index, tensor_index))\n\n        # Build self._input_layers:\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            # It\'s supposed to be an input layer, so only one node\n            # and one tensor output.\n            assert node_index == 0\n            assert tensor_index == 0\n            self._input_layers.append(layer)\n            self._input_coordinates.append((layer, node_index, tensor_index))\n\n        # Keep track of the network\'s nodes and layers.\n        nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n            self.inputs, self.outputs)\n        self._network_nodes = nodes\n        self._nodes_by_depth = nodes_by_depth\n        self._layers = layers\n        self._layers_by_depth = layers_by_depth\n\n        # Create the node linking internal inputs to internal outputs.\n        Node(outbound_layer=self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=self.inputs,\n             output_tensors=self.outputs,\n             # No network-level masking for now.\n             input_masks=[None for _ in self.inputs],\n             output_masks=[None for _ in self.outputs],\n             input_shapes=[x._keras_shape for x in self.inputs],\n             output_shapes=[x._keras_shape for x in self.outputs])\n\n        # Fill in the output mask cache.\n        masks = []\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        mask_cache_key = object_list_uid(inputs)\n        mask_cache_key += \'_\' + object_list_uid(masks)\n        masks = []\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        mask = unpack_singleton(masks)\n        self._output_mask_cache[mask_cache_key] = mask\n\n        # Build self.input_names and self.output_names.\n        self.input_names = []\n        self.output_names = []\n        self._feed_input_names = []\n        self._feed_inputs = []\n        self._feed_input_shapes = []\n        for i, layer in enumerate(self._input_layers):\n            # Check that layer is an InputLayer.\n            if not isinstance(layer, InputLayer):\n                raise TypeError(\n                    \'Input layers to a `Model` must be `InputLayer` objects. \'\n                    \'Received inputs: {}. \'\n                    \'Input {} (0-based) originates \'\n                    \'from layer type `{}`.\'.format(inputs,\n                                                   i,\n                                                   layer.__class__.__name__))\n            self.input_names.append(layer.name)\n            if layer.is_placeholder:\n                self._feed_inputs.append(layer.input)\n                self._feed_input_names.append(layer.name)\n                self._feed_input_shapes.append(self.inputs[i]._keras_shape)\n\n        for layer in self._output_layers:\n            self.output_names.append(layer.name)\n\n    def _init_subclassed_network(self, name=None, **kwargs):\n        self._base_init(name=name, **kwargs)\n        self._is_graph_network = False\n        self._expects_training_arg = has_arg(self.call, \'training\')\n        self._uses_inputs_arg = has_arg(self.call, \'inputs\')\n        self.outputs = None\n        self.inputs = None\n        self.built = False\n\n    def __setattr__(self, name, value):\n        # Automatically track layers set as Model\n        # attributes for subclassed Models.\n        if isinstance(value, Layer):\n            try:\n                is_graph_network = self._is_graph_network\n            except AttributeError:\n                raise RuntimeError(\n                    \'It looks like you are subclassing `Model` and you \'\n                    \'forgot to call `super(YourClass, self).__init__()`.\'\n                    \' Always start with this line.\')\n        super(Network, self).__setattr__(name, value)\n\n    @property\n    def layers(self):\n        return self._layers\n\n    def get_layer(self, name=None, index=None):\n        """"""Retrieves a layer based on either its name (unique) or index.\n\n        If `name` and `index` are both provided, `index` will take precedence.\n\n        Indices are based on order of horizontal graph traversal (bottom-up).\n\n        # Arguments\n            name: String, name of layer.\n            index: Integer, index of layer.\n\n        # Returns\n            A layer instance.\n\n        # Raises\n            ValueError: In case of invalid layer name or index.\n        """"""\n        # It would be unreliable to build a dictionary\n        # based on layer names, because names can potentially\n        # be changed at any point by the user\n        # without the network being notified of it.\n        if index is not None:\n            if len(self.layers) <= index:\n                raise ValueError(\'Was asked to retrieve layer at index \' +\n                                 str(index) + \' but model only has \' +\n                                 str(len(self.layers)) + \' layers.\')\n            else:\n                return self.layers[index]\n        else:\n            if not name:\n                raise ValueError(\'Provide either a layer name or layer index.\')\n\n        for layer in self.layers:\n            if layer.name == name:\n                return layer\n\n        raise ValueError(\'No such layer: \' + name)\n\n    @property\n    def updates(self):\n        """"""Retrieves the model\'s updates.\n\n        Will only include updates that are either\n        unconditional, or conditional on inputs to this model\n        (e.g. will not include updates that depend on tensors\n        that aren\'t inputs to this model).\n\n        # Returns\n            A list of update ops.\n        """"""\n        if not self.trainable and not self.stateful:\n            return []\n        updates = []\n        for layer in self.layers:\n            if hasattr(layer, \'updates\'):\n                if self._is_graph_network:\n                    # Collect updates that are dependent on inputs\n                    # that are part of the model.\n                    for node_index, node in enumerate(layer._inbound_nodes):\n                        node_key = self._node_key(layer, node_index)\n                        if node_key in self._network_nodes:\n                            # The model owns this layer node.\n                            inputs = node.input_tensors\n                            updates += layer.get_updates_for(inputs)\n                    # Collect unconditional updates.\n                    updates += layer.get_updates_for(None)\n                else:\n                    updates += layer.updates\n        return updates\n\n    @property\n    def losses(self):\n        """"""Retrieves the model\'s losses.\n\n        Will only include losses that are either\n        unconditional, or conditional on inputs to this model\n        (e.g. will not include losses that depend on tensors\n        that aren\'t inputs to this model).\n\n        # Returns\n            A list of loss tensors.\n        """"""\n        losses = []\n        for layer in self.layers:\n            if hasattr(layer, \'losses\'):\n                if self._is_graph_network:\n                    # Collect losses that are dependent on inputs\n                    # that are part of the model.\n                    for node_index, node in enumerate(layer._inbound_nodes):\n                        node_key = self._node_key(layer, node_index)\n                        if node_key in self._network_nodes:\n                            # The model owns this layer node.\n                            inputs = node.input_tensors\n                            losses += layer.get_losses_for(inputs)\n                    # Collect unconditional losses.\n                    losses += layer.get_losses_for(None)\n                else:\n                    losses += layer.losses\n\n        # Add any potential unconditional model-level loss.\n        losses += self.get_losses_for(None)\n\n        unique_tensors = []\n        unique_tensors_ids = set()\n        for x in losses:\n            if not isinstance(x, (float, int)):\n                if id(x) not in unique_tensors_ids:\n                    unique_tensors.append(x)\n                    unique_tensors_ids.add(id(x))\n        non_tensors = [x for x in losses if isinstance(x, (float, int))]\n        return unique_tensors + non_tensors\n\n    @property\n    def uses_learning_phase(self):\n        if not self.outputs:\n            return False\n        return any([x._uses_learning_phase for x in self.outputs])\n\n    @property\n    def stateful(self):\n        return any([(hasattr(layer, \'stateful\') and\n                    layer.stateful) for layer in self.layers])\n\n    def reset_states(self):\n        for layer in self.layers:\n            if hasattr(layer, \'reset_states\') and getattr(layer, \'stateful\', False):\n                layer.reset_states()\n\n    @property\n    def state_updates(self):\n        """"""Returns the `updates` from all layers that are stateful.\n\n        This is useful for separating training updates and\n        state updates, e.g. when we need to update a layer\'s internal state\n        during prediction.\n\n        # Returns\n            A list of update ops.\n        """"""\n        state_updates = []\n        for layer in self.layers:\n            if layer.stateful:\n                state_updates += layer.updates\n        return state_updates\n\n    @property\n    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = self._trainable_weights[:]\n        for layer in self.layers:\n            weights += layer.trainable_weights\n        return weights\n\n    @property\n    def non_trainable_weights(self):\n        weights = self._non_trainable_weights[:]\n        for layer in self.layers:\n            weights += layer.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = self._trainable_weights[:]\n            for layer in self.layers:\n                trainable_weights += layer.trainable_weights\n            return trainable_weights + weights\n        return weights\n\n    def get_weights(self):\n        """"""Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays.\n        """"""\n        weights = self._trainable_weights + self._non_trainable_weights\n        for layer in self.layers:\n            weights += layer.weights\n        return K.batch_get_value(weights)\n\n    def set_weights(self, weights):\n        """"""Sets the weights of the model.\n\n        # Arguments\n            weights: A list of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        """"""\n        tuples = []\n        own_weight_vars = self._trainable_weights + self._non_trainable_weights\n        num_param = len(own_weight_vars)\n        own_weights = weights[:num_param]\n        for sw, w in zip(own_weight_vars, own_weights):\n            tuples.append((sw, w))\n        weights = weights[num_param:]\n\n        for layer in self.layers:\n            num_param = len(layer.weights)\n            layer_weights = weights[:num_param]\n            for sw, w in zip(layer.weights, layer_weights):\n                tuples.append((sw, w))\n            weights = weights[num_param:]\n        K.batch_set_value(tuples)\n\n    @property\n    def input_spec(self):\n        """"""Gets the model\'s input specs.\n\n        # Returns\n            A list of `InputSpec` instances (one per input to the model)\n                or a single instance if the model has only one input.\n        """"""\n        if not self._is_graph_network:\n            # TODO: support it in subclassed networks after inputs are set.\n            return None\n\n        specs = []\n        for layer in getattr(self, \'_input_layers\', []):\n            if layer.input_spec is None:\n                specs.append(None)\n            else:\n                if not isinstance(layer.input_spec, list):\n                    raise TypeError(\'Layer \' + layer.name +\n                                    \' has an input_spec attribute that \'\n                                    \'is not a list. We expect a list. \'\n                                    \'Found input_spec = \' +\n                                    str(layer.input_spec))\n                specs += layer.input_spec\n        return unpack_singleton(specs)\n\n    def call(self, inputs, mask=None):\n        """"""Calls the model on new inputs.\n\n        In this case `call` just reapplies\n        all ops in the graph to the new inputs\n        (e.g. build a new computational graph from the provided inputs).\n\n        A model is callable on non-Keras tensors.\n\n        # Arguments\n            inputs: A tensor or list of tensors.\n            mask: A mask or list of masks. A mask can be\n                either a tensor or None (no mask).\n\n        # Returns\n            A tensor if there is a single output, or\n            a list of tensors if there are more than one outputs.\n        """"""\n        inputs = to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = to_list(mask)\n        cache_key = object_list_uid(inputs)\n        cache_key += \'_\' + object_list_uid(masks)\n        if cache_key in self._output_tensor_cache:\n            return self._output_tensor_cache[cache_key]\n        else:\n            output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n            return output_tensors\n\n    def compute_mask(self, inputs, mask):\n        if not self._is_graph_network:\n            return None\n\n        inputs = to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = to_list(mask)\n        cache_key = object_list_uid(inputs)\n        cache_key += \'_\' + object_list_uid(masks)\n        if cache_key in self._output_mask_cache:\n            return self._output_mask_cache[cache_key]\n        else:\n            _, output_masks, _ = self.run_internal_graph(inputs, masks)\n            return output_masks\n\n    def compute_output_shape(self, input_shape):\n        if not self._is_graph_network:\n            # Must be implemented by subclasses.\n            raise NotImplementedError\n\n        input_shapes = to_list(input_shape)\n        if len(input_shapes) != len(self._input_layers):\n            raise ValueError(\'Invalid input_shape argument \' +\n                             str(input_shape) + \': model has \' +\n                             str(len(self._input_layers)) + \' tensor inputs.\')\n\n        cache_key = \', \'.join([str(x) for x in input_shapes])\n        if cache_key in self._output_shape_cache:\n            output_shapes = self._output_shape_cache[cache_key]\n            if isinstance(output_shapes, list):\n                return unpack_singleton(output_shapes)\n            return output_shapes\n        else:\n            # Bad luck, we have to run the graph manually.\n            layers_to_output_shapes = {}\n            for i in range(len(input_shapes)):\n                layer = self._input_layers[i]\n                input_shape = input_shapes[i]\n                # It\'s an input layer: compute_output_shape is identity,\n                # and there is only one node and one tensor output.\n                shape_key = layer.name + \'_0_0\'\n                layers_to_output_shapes[shape_key] = input_shape\n\n            depth_keys = list(self._nodes_by_depth.keys())\n            depth_keys.sort(reverse=True)\n            # Iterate over nodes, by depth level.\n            if len(depth_keys) > 1:\n                for depth in depth_keys:\n                    nodes = self._nodes_by_depth[depth]\n                    for node in nodes:\n                        # This is always a single layer, never a list.\n                        layer = node.outbound_layer\n                        if layer in self._input_layers:\n                            # We\'ve already covered the input layers\n                            # a few lines above.\n                            continue\n                        # Potentially redundant list,\n                        # same size of node.input_tensors.\n                        input_shapes = []\n                        for j in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[j]\n                            node_index = node.node_indices[j]\n                            tensor_index = node.tensor_indices[j]\n                            shape_key = inbound_layer.name\n                            shape_key += \'_%s_%s\' % (node_index, tensor_index)\n                            input_shape = layers_to_output_shapes[shape_key]\n                            input_shapes.append(input_shape)\n\n                        output_shape = layer.compute_output_shape(\n                            unpack_singleton(input_shapes))\n\n                        output_shapes = to_list(output_shape)\n                        node_index = layer._inbound_nodes.index(node)\n                        for j in range(len(output_shapes)):\n                            shape_key = layer.name + \'_%s_%s\' % (node_index, j)\n                            layers_to_output_shapes[shape_key] = output_shapes[j]\n\n            # Read final output shapes from layers_to_output_shapes.\n            output_shapes = []\n            output_shape_keys = []\n            for i in range(len(self._output_layers)):\n                layer = self._output_layers[i]\n                node_index = self._output_coordinates[i][1]\n                tensor_index = self._output_coordinates[i][2]\n                shape_key = layer.name + \'_%s_%s\' % (node_index, tensor_index)\n                output_shape_keys.append(shape_key)\n\n            for i, key in enumerate(output_shape_keys):\n                assert key in layers_to_output_shapes\n                output_shapes.append(layers_to_output_shapes[key])\n            # Store in cache.\n            self._output_shape_cache[cache_key] = output_shapes\n            if isinstance(output_shapes, list):\n                return unpack_singleton(output_shapes)\n            return output_shapes\n\n    def run_internal_graph(self, inputs, masks=None):\n        """"""Computes output tensors for new inputs.\n\n        # Note:\n            - Expects `inputs` to be a list (potentially with 1 element).\n            - Can be run on non-Keras tensors.\n\n        # Arguments\n            inputs: List of tensors\n            masks: List of masks (tensors or None).\n\n        # Returns\n            Three lists: output_tensors, output_masks, output_shapes\n        """"""\n        if masks is None:\n            masks = [None for _ in range(len(inputs))]\n\n        # Dictionary mapping reference tensors to tuples\n        # (computed tensor, compute mask)\n        # we assume a 1:1 mapping from tensor to mask\n        # TODO: raise exception when a `.compute_mask()` call\n        # does not return a list the same size as `call`\n        tensor_map = {}\n        for x, y, mask in zip(self.inputs, inputs, masks):\n            tensor_map[str(id(x))] = (y, mask)\n\n        depth_keys = list(self._nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n        for depth in depth_keys:\n            nodes = self._nodes_by_depth[depth]\n            for node in nodes:\n                # This is always a single layer, never a list.\n                layer = node.outbound_layer\n                reference_input_tensors = node.input_tensors\n                reference_output_tensors = node.output_tensors\n\n                # If all previous input tensors are available in tensor_map,\n                # then call node.inbound_layer on them.\n                computed_data = []  # List of tuples (input, mask).\n                for x in reference_input_tensors:\n                    if str(id(x)) in tensor_map:\n                        computed_data.append(tensor_map[str(id(x))])\n\n                if len(computed_data) == len(reference_input_tensors):\n                    # call layer\n                    with K.name_scope(layer.name):\n                        if node.arguments:\n                            kwargs = node.arguments\n                        else:\n                            kwargs = {}\n                        if len(computed_data) == 1:\n                            computed_tensor, computed_mask = computed_data[0]\n                            if has_arg(layer.call, \'mask\'):\n                                if \'mask\' not in kwargs:\n                                    kwargs[\'mask\'] = computed_mask\n                            output_tensors = to_list(\n                                layer.call(computed_tensor, **kwargs))\n                            output_masks = layer.compute_mask(computed_tensor,\n                                                              computed_mask)\n                            if output_masks is None:\n                                output_masks = [None for _ in output_tensors]\n                            else:\n                                output_masks = to_list(output_masks)\n                            computed_tensors = [computed_tensor]\n\n                            # computed_masks might be used in the future.\n                            computed_masks = [computed_mask]\n                        else:\n                            computed_tensors = [x[0] for x in computed_data]\n                            computed_masks = [x[1] for x in computed_data]\n                            if has_arg(layer.call, \'mask\'):\n                                if \'mask\' not in kwargs:\n                                    kwargs[\'mask\'] = computed_masks\n                            output_tensors = to_list(\n                                layer.call(computed_tensors, **kwargs))\n                            output_masks = layer.compute_mask(computed_tensors,\n                                                              computed_masks)\n                            if output_masks is None:\n                                output_masks = [None for _ in output_tensors]\n                            else:\n                                output_masks = to_list(output_masks)\n                        # Apply activity regularizer if any:\n                        if (hasattr(layer, \'activity_regularizer\') and\n                                layer.activity_regularizer is not None):\n                            with K.name_scope(\'activity_regularizer\'):\n                                regularization_losses = [\n                                    layer.activity_regularizer(x)\n                                    for x in output_tensors]\n                            layer.add_loss(regularization_losses,\n                                           inputs=computed_tensors)\n\n                        if len(output_masks) != len(output_tensors):\n                            raise Exception(\n                                \'Layers should have equal number of output tensors \'\n                                \'and output masks. Layer \' + str(layer.name) + \' has\'\n                                \' \' + str(len(output_tensors)) + \' output tensors \'\n                                \'and \' + str(len(output_masks)) + \' output masks.\')\n                    # Update model updates and losses:\n                    # Keep track of updates that depend on the inputs\n                    # (e.g. BN updates).\n                    self.add_update(layer.get_updates_for(computed_tensors), inputs)\n                    # Keep track of unconditional updates (e.g. a counter).\n                    self.add_update(layer.get_updates_for(None), None)\n                    # Keep track of losses that depend on the inputs\n                    # (e.g. activity regularizers).\n                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)\n                    # Keep track of unconditional losses\n                    # (e.g. weight regularizers).\n                    self.add_loss(layer.get_losses_for(None), None)\n\n                    # Update _keras_shape.\n                    if all([hasattr(x, \'_keras_shape\') for x in computed_tensors]):\n                        input_shapes = unpack_singleton(\n                            [x._keras_shape for x in computed_tensors])\n                        shapes = to_list(layer.compute_output_shape(input_shapes))\n                        uses_learning_phase = any(\n                            [x._uses_learning_phase for x in computed_tensors])\n\n                        for x, s in zip(output_tensors, shapes):\n                            x._keras_shape = s\n                            _u = getattr(x, \'_uses_learning_phase\', False)\n                            x._uses_learning_phase = _u or uses_learning_phase\n\n                    # Update tensor_map.\n                    for x, y, mask in zip(reference_output_tensors,\n                                          output_tensors,\n                                          output_masks):\n                        tensor_map[str(id(x))] = (y, mask)\n\n        output_tensors = []\n        output_masks = []\n        output_shapes = []\n        for x in self.outputs:\n            assert str(id(x)) in tensor_map, \'Could not compute output \' + str(x)\n            tensor, mask = tensor_map[str(id(x))]\n            if hasattr(tensor, \'_keras_shape\') and output_shapes is not None:\n                shape = tensor._keras_shape\n                output_shapes.append(shape)\n            else:\n                output_shapes = None\n            output_tensors.append(tensor)\n            output_masks.append(mask)\n\n        # Update cache;\n        # keys are based on ids on input tensors and inputs masks.\n        cache_key = object_list_uid(inputs)\n        cache_key += \'_\' + object_list_uid(masks)\n\n        output_tensors = unpack_singleton(output_tensors)\n        self._output_tensor_cache[cache_key] = output_tensors\n\n        output_masks = unpack_singleton(output_masks)\n        self._output_mask_cache[cache_key] = output_masks\n\n        if output_shapes is not None:\n            input_shapes = [x._keras_shape for x in inputs]\n            cache_key = \', \'.join([str(x) for x in input_shapes])\n\n            output_shapes = unpack_singleton(output_shapes)\n            self._output_shape_cache[cache_key] = output_shapes\n        return output_tensors, output_masks, output_shapes\n\n    def get_config(self):\n        if not self._is_graph_network:\n            # Subclassed networks are not serializable\n            # (unless serialization is implemented by\n            # the author of the subclassed network).\n            raise NotImplementedError\n\n        config = {\n            \'name\': self.name,\n        }\n\n        # Build a map from a layer unique name (self._node_key)\n        # to the index of the nodes that are saved in the config.\n        # Only nodes in network_nodes are saved.\n        node_conversion_map = {}\n        for layer in self.layers:\n            if issubclass(layer.__class__, Network):\n                # Networks start with a pre-existing node\n                # linking their input to output.\n                kept_nodes = 1\n            else:\n                kept_nodes = 0\n            for original_node_index, node in enumerate(layer._inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self._network_nodes:\n                    # i.e. we mark it to be saved\n                    node_conversion_map[node_key] = kept_nodes\n                    kept_nodes += 1\n\n        # serialize and save the layers in layer_configs\n        layer_configs = []\n        for layer in self.layers:  # From the earliest layers on.\n            layer_class_name = layer.__class__.__name__\n            layer_config = layer.get_config()\n            filtered_inbound_nodes = []\n            for original_node_index, node in enumerate(layer._inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self._network_nodes:\n                    # The node is relevant to the model:\n                    # add to filtered_inbound_nodes.\n                    if node.arguments:\n                        try:\n                            json.dumps(node.arguments)\n                            kwargs = node.arguments\n                        except TypeError:\n                            warnings.warn(\n                                \'Layer \' + layer.name +\n                                \' was passed non-serializable \'\n                                \'keyword arguments: \' +\n                                str(node.arguments) +\n                                \'. They will not be included \'\n                                \'in the serialized model \'\n                                \'(and thus will be missing \'\n                                \'at deserialization time).\')\n                            kwargs = {}\n                    else:\n                        kwargs = {}\n                    if node.inbound_layers:\n                        node_data = []\n                        for i in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[i]\n                            node_index = node.node_indices[i]\n                            tensor_index = node.tensor_indices[i]\n\n                            new_node_index = node_conversion_map.get(\n                                self._node_key(inbound_layer, node_index), 0)\n                            node_data.append([inbound_layer.name,\n                                              new_node_index,\n                                              tensor_index,\n                                              kwargs])\n                        filtered_inbound_nodes.append(node_data)\n            layer_configs.append({\n                \'name\': layer.name,\n                \'class_name\': layer_class_name,\n                \'config\': layer_config,\n                \'inbound_nodes\': filtered_inbound_nodes,\n            })\n        config[\'layers\'] = layer_configs\n\n        # Gather info about inputs and outputs.\n        model_inputs = []\n        for i in range(len(self._input_layers)):\n            layer = self._input_layers[i]\n            node_index = self._input_coordinates[i][1]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self._network_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self._input_coordinates[i][2]\n            model_inputs.append([layer.name, new_node_index, tensor_index])\n        config[\'input_layers\'] = model_inputs\n        model_outputs = []\n        for i in range(len(self._output_layers)):\n            layer = self._output_layers[i]\n            node_index = self._output_coordinates[i][1]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self._network_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self._output_coordinates[i][2]\n            model_outputs.append([layer.name, new_node_index, tensor_index])\n        config[\'output_layers\'] = model_outputs\n        return copy.deepcopy(config)\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        """"""Instantiates a Model from its config (output of `get_config()`).\n\n        # Arguments\n            config: Model config dictionary.\n            custom_objects: Optional dictionary mapping names\n                (strings) to custom classes or functions to be\n                considered during deserialization.\n\n        # Returns\n            A model instance.\n\n        # Raises\n            ValueError: In case of improperly formatted config dict.\n        """"""\n        # Layer instances created during\n        # the graph reconstruction process\n        created_layers = {}\n\n        # Dictionary mapping layer instances to\n        # node data that specifies a layer call.\n        # It acts as a queue that maintains any unprocessed\n        # layer call until it becomes possible to process it\n        # (i.e. until the input tensors to the call all exist).\n        unprocessed_nodes = {}\n\n        def add_unprocessed_node(layer, node_data):\n            """"""Add node to layer list\n\n            # Arguments\n                layer: layer object\n                node_data: Node data specifying layer call\n            """"""\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)\n\n        def process_node(layer, node_data):\n            """"""Reconstruct node by linking to inbound layers\n\n            # Arguments\n                layer: Layer to process\n                node_data: List of layer configs\n\n            # Raises\n                ValueError: For incorrect layer config\n                LookupError: If layer required is not found\n            """"""\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError(\'Improperly formatted model config.\')\n                inbound_layer = created_layers[inbound_layer_name]\n                # Raise an error if the corresponding layer node\n                # has not yet been created\n                if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                    raise LookupError\n                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n                input_tensors.append(\n                    inbound_node.output_tensors[inbound_tensor_index])\n\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                layer(unpack_singleton(input_tensors), **kwargs)\n\n        def process_layer(layer_data):\n            """"""Deserializes a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            """"""\n            layer_name = layer_data[\'name\']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data[\'inbound_nodes\']\n            for node_data in inbound_nodes_data:\n                # We don\'t process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)\n\n        # First, we create all layers and enqueue nodes to be processed\n        for layer_data in config[\'layers\']:\n            process_layer(layer_data)\n\n        # Then we process nodes in order of layer depth.\n        # Nodes that cannot yet be processed (if the inbound node\n        # does not yet exist) are re-enqueued, and the process\n        # is repeated until all nodes are processed.\n        while unprocessed_nodes:\n            for layer_data in config[\'layers\']:\n                layer = created_layers[layer_data[\'name\']]\n\n                # Process all nodes in layer, if not yet processed\n                if layer in unprocessed_nodes:\n                    node_data_list = unprocessed_nodes[layer]\n\n                    # Process nodes in order\n                    node_index = 0\n                    while node_index < len(node_data_list):\n                        node_data = node_data_list[node_index]\n                        try:\n                            process_node(layer, node_data)\n\n                        # If the node does not have all inbound layers\n                        # available, stop processing and continue later\n                        except LookupError:\n                            break\n\n                        node_index += 1\n\n                    # If not all nodes processed then store unprocessed nodes\n                    if node_index < len(node_data_list):\n                        unprocessed_nodes[layer] = node_data_list[node_index:]\n                    # If all nodes processed remove the layer\n                    else:\n                        del unprocessed_nodes[layer]\n\n        # Create lits of input and output tensors and return new class\n        name = config.get(\'name\')\n        input_tensors = []\n        output_tensors = []\n        for layer_data in config[\'input_layers\']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n            input_tensors.append(layer_output_tensors[tensor_index])\n        for layer_data in config[\'output_layers\']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n            output_tensors.append(layer_output_tensors[tensor_index])\n        return cls(inputs=input_tensors, outputs=output_tensors, name=name)\n\n    def save(self, filepath, overwrite=True, include_optimizer=True):\n        """"""Saves the model to a single HDF5 file.\n\n        The savefile includes:\n            - The model architecture, allowing to re-instantiate the model.\n            - The model weights.\n            - The state of the optimizer, allowing to resume training\n                exactly where you left off.\n\n        This allows you to save the entirety of the state of a model\n        in a single file.\n\n        Saved models can be reinstantiated via `keras.models.load_model`.\n        The model returned by `load_model`\n        is a compiled model ready to be used (unless the saved model\n        was never compiled in the first place).\n\n        # Arguments\n            filepath: one of the following:\n                - string, path to the file to save the model to\n                - h5py.File or h5py.Group object where to save the model\n                - any file-like object implementing the method `write` that accepts\n                    `bytes` data (e.g. `io.BytesIO`).\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n            include_optimizer: If True, save optimizer\'s state together.\n\n        # Example\n\n        ```python\n        from keras.models import load_model\n\n        model.save(\'my_model.h5\')  # creates a HDF5 file \'my_model.h5\'\n        del model  # deletes the existing model\n\n        # returns a compiled model\n        # identical to the previous one\n        model = load_model(\'my_model.h5\')\n        ```\n        """"""\n        if not self._is_graph_network:\n            raise NotImplementedError\n        from ..models import save_model\n        save_model(self, filepath, overwrite, include_optimizer)\n\n    @saving.allow_write_to_gcs\n    def save_weights(self, filepath, overwrite=True):\n        """"""Dumps all layer weights to a HDF5 file.\n\n        The weight file has:\n            - `layer_names` (attribute), a list of strings\n                (ordered names of model layers).\n            - For every layer, a `group` named `layer.name`\n                - For every such layer group, a group attribute `weight_names`,\n                    a list of strings\n                    (ordered names of weights tensor of the layer).\n                - For every weight in the layer, a dataset\n                    storing the weight value, named after the weight tensor.\n\n        # Arguments\n            filepath: String, path to the file to save the weights to.\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n\n        # Raises\n            ImportError: If h5py is not available.\n        """"""\n        if h5py is None:\n            raise ImportError(\'`save_weights` requires h5py.\')\n        # If file exists and should not be overwritten:\n        if not overwrite and os.path.isfile(filepath):\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        with h5py.File(filepath, \'w\') as f:\n            saving.save_weights_to_hdf5_group(f, self.layers)\n            f.flush()\n\n    @saving.allow_read_from_gcs\n    def load_weights(self, filepath, by_name=False,\n                     skip_mismatch=False, reshape=False):\n        """"""Loads all layer weights from a HDF5 save file.\n\n        If `by_name` is False (default) weights are loaded\n        based on the network\'s topology, meaning the architecture\n        should be the same as when the weights were saved.\n        Note that layers that don\'t have weights are not taken\n        into account in the topological ordering, so adding or\n        removing layers is fine as long as they don\'t have weights.\n\n        If `by_name` is True, weights are loaded into layers\n        only if they share the same name. This is useful\n        for fine-tuning or transfer-learning models where\n        some of the layers have changed.\n\n        # Arguments\n            filepath: String, path to the weights file to load.\n            by_name: Boolean, whether to load weights by name\n                or by topological order.\n            skip_mismatch: Boolean, whether to skip loading of layers\n                where there is a mismatch in the number of weights,\n                or a mismatch in the shape of the weight\n                (only valid when `by_name`=True).\n            reshape: Reshape weights to fit the layer when the correct number\n                of weight arrays is present but their shape does not match.\n\n\n        # Raises\n            ImportError: If h5py is not available.\n        """"""\n        if h5py is None:\n            raise ImportError(\'`load_weights` requires h5py.\')\n        with h5py.File(filepath, mode=\'r\') as f:\n            if \'layer_names\' not in f.attrs and \'model_weights\' in f:\n                f = f[\'model_weights\']\n            if by_name:\n                saving.load_weights_from_hdf5_group_by_name(\n                    f, self.layers, skip_mismatch=skip_mismatch,\n                    reshape=reshape)\n            else:\n                saving.load_weights_from_hdf5_group(\n                    f, self.layers, reshape=reshape)\n            if hasattr(f, \'close\'):\n                f.close()\n            elif hasattr(f.file, \'close\'):\n                f.file.close()\n\n    def _updated_config(self):\n        """"""Util hared between different serialization methods.\n\n        # Returns\n            Model config with Keras version information added.\n        """"""\n        from .. import __version__ as keras_version\n\n        config = self.get_config()\n        model_config = {\n            \'class_name\': self.__class__.__name__,\n            \'config\': config,\n            \'keras_version\': keras_version,\n            \'backend\': K.backend()\n        }\n        return model_config\n\n    def to_json(self, **kwargs):\n        """"""Returns a JSON string containing the network configuration.\n\n        To load a network from a JSON save file, use\n        `keras.models.model_from_json(json_string, custom_objects={})`.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `json.dumps()`.\n\n        # Returns\n            A JSON string.\n        """"""\n        def get_json_type(obj):\n            # If obj is any numpy type\n            if type(obj).__module__ == np.__name__:\n                if isinstance(obj, np.ndarray):\n                    return obj.tolist()\n                else:\n                    return obj.item()\n\n            # If obj is a python \'type\'\n            if type(obj).__name__ == type.__name__:\n                return obj.__name__\n\n            raise TypeError(\'Not JSON Serializable:\', obj)\n\n        model_config = self._updated_config()\n        return json.dumps(model_config, default=get_json_type, **kwargs)\n\n    def to_yaml(self, **kwargs):\n        """"""Returns a yaml string containing the network configuration.\n\n        To load a network from a yaml save file, use\n        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n\n        `custom_objects` should be a dictionary mapping\n        the names of custom losses / layers / etc to the corresponding\n        functions / classes.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `yaml.dump()`.\n\n        # Returns\n            A YAML string.\n        """"""\n        return yaml.dump(self._updated_config(), **kwargs)\n\n    def summary(self, line_length=None, positions=None, print_fn=None):\n        """"""Prints a string summary of the network.\n\n        # Arguments\n            line_length: Total length of printed lines\n                (e.g. set this to adapt the display to different\n                terminal window sizes).\n            positions: Relative or absolute positions of log elements\n                in each line. If not provided,\n                defaults to `[.33, .55, .67, 1.]`.\n            print_fn: Print function to use.\n                It will be called on each line of the summary.\n                You can set it to a custom function\n                in order to capture the string summary.\n                It defaults to `print` (prints to stdout).\n        """"""\n        if not self.built:\n            raise ValueError(\n                \'This model has not yet been built. \'\n                \'Build the model first by calling build() \'\n                \'or calling fit() with some data. \'\n                \'Or specify input_shape or batch_input_shape \'\n                \'in the first layer for automatic build. \')\n        return print_layer_summary(self,\n                                   line_length=line_length,\n                                   positions=positions,\n                                   print_fn=print_fn)\n\n    def __getstate__(self):\n        return saving.pickle_model(self)\n\n    def __setstate__(self, state):\n        model = saving.unpickle_model(state)\n        self.__dict__.update(model.__dict__)\n\n\ndef _make_node_key(layer_name, node_index):\n    return layer_name + \'_ib-\' + str(node_index)\n\n\ndef _map_graph_network(inputs, outputs):\n    """"""Validates a network\'s topology and gather its layers and nodes.\n\n    # Arguments\n        inputs: List of input tensors.\n        outputs: List of outputs tensors.\n\n    # Returns\n        A tuple `(nodes, nodes_by_depth, layers, layers_by_depth)`.\n        - nodes: list of Node instances.\n        - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n        - layers: list of Layer instances.\n        - layers_by_depth: dict mapping ints (depth)\n            to lists of layer instances.\n\n    # Raises\n        ValueError: In case the network is not valid (e.g. disconnected graph).\n    """"""\n    # Network_nodes: set of nodes included in the graph of layers\n    # (not all nodes included in the layers are relevant to the current graph).\n    network_nodes = set()  # ids of all nodes relevant to the Network\n    nodes_depths = {}  # dict {node: depth value}\n    layers_depths = {}  # dict {layer: depth value}\n    layer_indices = {}  # dict {layer: index in traversal}\n    nodes_in_decreasing_depth = []\n\n    def build_map(tensor,\n                  finished_nodes,\n                  nodes_in_progress,\n                  layer,\n                  node_index,\n                  tensor_index):\n        """"""Builds a map of the graph of layers.\n\n        This recursively updates the map `layer_indices`,\n        the list `nodes_in_decreasing_depth` and the set `network_nodes`.\n\n        # Arguments\n            tensor: Some tensor in a graph.\n            finished_nodes: Set of nodes whose subgraphs have been traversed\n                completely. Useful to prevent duplicated work.\n            nodes_in_progress: Set of nodes that are currently active on the\n                recursion stack. Useful to detect cycles.\n            layer: Layer from which `tensor` comes from. If not provided,\n                will be obtained from `tensor._keras_history`.\n            node_index: Node index from which `tensor` comes from.\n            tensor_index: Tensor_index from which `tensor` comes from.\n\n        # Raises\n            ValueError: if a cycle is detected.\n        """"""\n        node = layer._inbound_nodes[node_index]\n\n        # Prevent cycles.\n        if node in nodes_in_progress:\n            raise ValueError(\'The tensor \' + str(tensor) + \' at layer ""\' +\n                             layer.name + \'"" is part of a cycle.\')\n\n        # Don\'t repeat work for shared subgraphs\n        if node in finished_nodes:\n            return\n\n        node_key = _make_node_key(layer.name, node_index)\n        # Update network_nodes.\n        network_nodes.add(node_key)\n\n        # Store the traversal order for layer sorting.\n        if layer not in layer_indices:\n            layer_indices[layer] = len(layer_indices)\n\n        nodes_in_progress.add(node)\n\n        # Propagate to all previous tensors connected to this node.\n        for i in range(len(node.inbound_layers)):\n            x = node.input_tensors[i]\n            layer = node.inbound_layers[i]\n            node_index = node.node_indices[i]\n            tensor_index = node.tensor_indices[i]\n            build_map(x, finished_nodes, nodes_in_progress, layer,\n                      node_index, tensor_index)\n\n        finished_nodes.add(node)\n        nodes_in_progress.remove(node)\n        nodes_in_decreasing_depth.append(node)\n\n    finished_nodes = set()\n    nodes_in_progress = set()\n    for x in outputs:\n        layer, node_index, tensor_index = x._keras_history\n        build_map(x, finished_nodes, nodes_in_progress,\n                  layer=layer,\n                  node_index=node_index,\n                  tensor_index=tensor_index)\n\n    for node in reversed(nodes_in_decreasing_depth):\n        # If the depth is not set, the node has no outbound nodes (depth 0).\n        depth = nodes_depths.setdefault(node, 0)\n\n        # Update the depth of the corresponding layer\n        previous_depth = layers_depths.get(node.outbound_layer, 0)\n        # If we\'ve seen this layer before at a higher depth,\n        # we should use that depth instead of the node depth.\n        # This is necessary for shared layers that have inputs at different\n        # depth levels in the graph.\n        depth = max(depth, previous_depth)\n        layers_depths[node.outbound_layer] = depth\n        nodes_depths[node] = depth\n\n        # Update the depth of inbound nodes.\n        # The ""depth"" of a node is the max of the depths\n        # of all layers it is connected to.\n        for i in range(len(node.inbound_layers)):\n            inbound_layer = node.inbound_layers[i]\n            node_index = node.node_indices[i]\n            inbound_node = inbound_layer._inbound_nodes[node_index]\n            previous_depth = nodes_depths.get(inbound_node, 0)\n            nodes_depths[inbound_node] = max(depth + 1, previous_depth)\n\n    # Build a dict {depth: list of nodes with this depth}\n    nodes_by_depth = {}\n    for node, depth in nodes_depths.items():\n        if depth not in nodes_by_depth:\n            nodes_by_depth[depth] = []\n        nodes_by_depth[depth].append(node)\n\n    # Build a dict {depth: list of layers with this depth}\n    layers_by_depth = {}\n    for layer, depth in layers_depths.items():\n        if depth not in layers_by_depth:\n            layers_by_depth[depth] = []\n        layers_by_depth[depth].append(layer)\n\n    # Get sorted list of layer depths.\n    depth_keys = list(layers_by_depth.keys())\n    depth_keys.sort(reverse=True)\n\n    # Set self.layers and self._layers_by_depth.\n    layers = []\n    for depth in depth_keys:\n        layers_for_depth = layers_by_depth[depth]\n        # Network.layers needs to have a deterministic order:\n        # here we order them by traversal order.\n        layers_for_depth.sort(key=lambda x: layer_indices[x])\n        layers.extend(layers_for_depth)\n\n    # Get sorted list of node depths.\n    depth_keys = list(nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n\n    # Check that all tensors required are computable.\n    # computable_tensors: all tensors in the graph\n    # that can be computed from the inputs provided.\n    computable_tensors = []\n    for x in inputs:\n        computable_tensors.append(x)\n\n    layers_with_complete_input = []  # To provide a better error msg.\n    for depth in depth_keys:\n        for node in nodes_by_depth[depth]:\n            layer = node.outbound_layer\n            if layer:\n                for x in node.input_tensors:\n                    if id(x) not in [id(ct) for ct in computable_tensors]:\n                        raise ValueError(\'Graph disconnected: \'\n                                         \'cannot obtain value for tensor \' +\n                                         str(x) + \' at layer ""\' +\n                                         layer.name + \'"". \'\n                                         \'The following previous layers \'\n                                         \'were accessed without issue: \' +\n                                         str(layers_with_complete_input))\n                for x in node.output_tensors:\n                    computable_tensors.append(x)\n                layers_with_complete_input.append(layer.name)\n\n    # Ensure name unicity, which will be crucial for serialization\n    # (since serialized nodes refer to layers by their name).\n    all_names = [layer.name for layer in layers]\n    for name in all_names:\n        if all_names.count(name) != 1:\n            raise ValueError(\'The name ""\' + name + \'"" is used \' +\n                             str(all_names.count(name)) +\n                             \' times in the model. \'\n                             \'All layer names should be unique.\')\n    return network_nodes, nodes_by_depth, layers, layers_by_depth\n'"
keras/engine/saving.py,0,"b'""""""Model saving utilities.\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nimport os\nimport json\nimport yaml\nimport inspect\nimport warnings\nimport tempfile\nfrom six.moves import zip\nfrom six import string_types\nfrom functools import wraps\n\nimport numpy as np\n\nfrom .. import backend as K\nfrom .. import losses\nfrom .. import optimizers\nfrom ..utils.io_utils import H5Dict\nfrom ..utils.io_utils import ask_to_proceed_with_overwrite\nfrom ..utils.io_utils import save_to_binary_h5py\nfrom ..utils.io_utils import load_from_binary_h5py\nfrom ..utils import conv_utils\n\ntry:\n    import h5py\n    HDF5_OBJECT_HEADER_LIMIT = 64512\nexcept ImportError:\n    h5py = None\n\ntry:\n    from tensorflow.python.lib.io import file_io as tf_file_io\nexcept ImportError:\n    tf_file_io = None\n\ntry:\n    getargspec = inspect.getfullargspec\nexcept AttributeError:  # getargspec() is deprecated since Python 3.0\n    getargspec = inspect.getargspec\n\n\ndef _uniquify(names):\n    """"""Uniquify list of strings.\n\n    Custom layers and optimizers written by users\n    for TF 1.x might produce weights with same variable\n    names in TF 2. This method ""uniquifies"" a given list\n    of names.\n\n    e.g: `[\'a\', \'b\', \'b\', \'c\'] -> [\'a\', \'b\', \'b_2\', \'c\']`\n\n    # Arguments\n        names: List of strings.\n\n    # Returns\n        List of unique strings.\n    """"""\n    counts = {}\n    unique_names = []\n    for name in names:\n        if name in counts:\n            counts[name] += 1\n            name = str(name) + \'_\' + str(counts[name])\n        else:\n            counts[name] = 1\n        unique_names.append(name)\n    return unique_names\n\n\ndef _serialize_model(model, h5dict, include_optimizer=True):\n    """"""Model serialization logic.\n\n    This method is used for both writing to HDF5 file/group,\n    as well as pickling. This is achieved via a\n    `keras.utils.hdf5_utls.H5Dict` object, which can wrap HDF5\n    files, groups and dicts with a common API.\n\n    # Arguments\n        model: Keras model instance to be serialized.\n        h5dict: keras.utils.io_utils.HD5Dict instance.\n        include_optimizer: If True, serialize optimizer\'s state together.\n\n    """"""\n    def get_json_type(obj):\n        """"""Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        """"""\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, \'get_config\'):\n            return {\'class_name\': obj.__class__.__name__,\n                    \'config\': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return obj.tolist()\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python \'type\'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError(\'Not JSON Serializable: %s\' % (obj,))\n\n    from .. import __version__ as keras_version\n\n    h5dict[\'keras_version\'] = str(keras_version).encode(\'utf8\')\n    h5dict[\'backend\'] = K.backend().encode(\'utf8\')\n\n    model_config = {}\n    model_config[\'class_name\'] = model.__class__.__name__\n    model_config[\'config\'] = model.get_config()\n    model_config = json.dumps(model_config, default=get_json_type)\n    model_config = model_config.encode(\'utf-8\')\n    h5dict[\'model_config\'] = model_config\n\n    model_weights_group = h5dict[\'model_weights\']\n    model_layers = model.layers\n    model_weights_group[\'layer_names\'] = [layer.name.encode(\'utf8\')\n                                          for layer in model_layers]\n    model_weights_group[\'backend\'] = K.backend().encode(\'utf8\')\n    model_weights_group[\'keras_version\'] = str(keras_version).encode(\'utf8\')\n    for layer in model_layers:\n        layer_group = model_weights_group[layer.name]\n        symbolic_weights = layer.weights\n        weight_values = K.batch_get_value(symbolic_weights)\n        weight_names = []\n        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n            if hasattr(w, \'name\') and w.name:\n                name = str(w.name)\n            else:\n                name = \'param_\' + str(i)\n            if name in weight_names:\n                idx = 2\n                unique_name = name + \'_1\'\n                while unique_name in weight_names:\n                    unique_name = name + \'_\' + str(idx)\n                    idx += 1\n                name = unique_name\n            weight_names.append(name.encode(\'utf8\'))\n        weight_names = _uniquify(weight_names)\n        layer_group[\'weight_names\'] = weight_names\n        for name, val in zip(weight_names, weight_values):\n            layer_group[name] = val\n    if include_optimizer and model.optimizer:\n        if isinstance(model.optimizer, optimizers.TFOptimizer):\n            warnings.warn(\n                \'TensorFlow optimizers do not \'\n                \'make it possible to access \'\n                \'optimizer attributes or optimizer state \'\n                \'after instantiation. \'\n                \'As a result, we cannot save the optimizer \'\n                \'as part of the model save file.\'\n                \'You will have to compile your model again \'\n                \'after loading it. \'\n                \'Prefer using a Keras optimizer instead \'\n                \'(see keras.io/optimizers).\')\n        else:\n            h5dict[\'training_config\'] = json.dumps({\n                \'optimizer_config\': {\n                    \'class_name\': model.optimizer.__class__.__name__,\n                    \'config\': model.optimizer.get_config()\n                },\n                \'loss\': model.loss,\n                \'metrics\': model._compile_metrics,\n                \'weighted_metrics\': model._compile_weighted_metrics,\n                \'sample_weight_mode\': model.sample_weight_mode,\n                \'loss_weights\': model.loss_weights,\n            }, default=get_json_type).encode(\'utf8\')\n            symbolic_weights = getattr(model.optimizer, \'weights\')\n            if symbolic_weights:\n                optimizer_weights_group = h5dict[\'optimizer_weights\']\n                weight_values = K.batch_get_value(symbolic_weights)\n                weight_names = []\n                for i, (w, val) in enumerate(zip(symbolic_weights,\n                                                 weight_values)):\n                    # Default values of symbolic_weights is /variable\n                    # for Theano and CNTK\n                    if K.backend() == \'theano\' or K.backend() == \'cntk\':\n                        if hasattr(w, \'name\'):\n                            if w.name.split(\'/\')[-1] == \'variable\':\n                                name = str(w.name) + \'_\' + str(i)\n                            else:\n                                name = str(w.name)\n                        else:\n                            name = \'param_\' + str(i)\n                    else:\n                        if hasattr(w, \'name\') and w.name:\n                            name = str(w.name)\n                        else:\n                            name = \'param_\' + str(i)\n                    if name in weight_names:\n                        idx = 2\n                        unique_name = name + \'_1\'\n                        while unique_name in weight_names:\n                            unique_name = name + \'_\' + str(idx)\n                            idx += 1\n                        name = unique_name\n                    weight_names.append(name.encode(\'utf8\'))\n                weight_names = _uniquify(weight_names)\n                optimizer_weights_group[\'weight_names\'] = weight_names\n                for name, val in zip(weight_names, weight_values):\n                    optimizer_weights_group[name] = val\n\n\ndef _deserialize_model(h5dict, custom_objects=None, compile=True):\n    """"""De-serializes a model serialized via _serialize_model\n\n    # Arguments\n        h5dict: `keras.utils.hdf5_utils.HFDict` instance.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n        compile: Boolean, whether to compile the model\n            after loading.\n\n    # Returns\n        A Keras model instance. If an optimizer was found\n        as part of the saved model, the model is already\n        compiled. Otherwise, the model is uncompiled and\n        a warning will be displayed. When `compile` is set\n        to False, the compilation is omitted without any\n        warning.\n    """"""\n    if not custom_objects:\n        custom_objects = {}\n\n    def convert_custom_objects(obj):\n        """"""Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        """"""\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj\n\n    model_config = h5dict[\'model_config\']\n    if model_config is None:\n        raise ValueError(\'No model found in config.\')\n    model_config = json.loads(model_config.decode(\'utf-8\'))\n    model = model_from_config(model_config, custom_objects=custom_objects)\n    model_weights_group = h5dict[\'model_weights\']\n\n    if \'keras_version\' in model_weights_group:\n        original_keras_version = model_weights_group[\'keras_version\'].decode(\'utf8\')\n    else:\n        original_keras_version = \'1\'\n    if \'backend\' in model_weights_group:\n        original_backend = model_weights_group[\'backend\'].decode(\'utf8\')\n    else:\n        original_backend = None\n\n    layer_names = model_weights_group[\'layer_names\']\n\n    layers = model.layers\n\n    filtered_layers = []\n    for layer in layers:\n        weights = layer.weights\n        if weights:\n            filtered_layers.append(layer)\n\n    filtered_layer_names = []\n    for name in layer_names:\n        layer_weights = model_weights_group[name]\n        weight_names = layer_weights[\'weight_names\']\n        if len(weight_names) > 0:\n            filtered_layer_names.append(name)\n\n    layer_names = filtered_layer_names\n    if len(layer_names) != len(filtered_layers):\n        raise ValueError(\'You are trying to load a weight file\'\n                         \' containing {} layers into a model with {} layers\'\n                         .format(len(layer_names), len(filtered_layers))\n                         )\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        layer_weights = model_weights_group[name]\n        weight_names = layer_weights[\'weight_names\']\n        weight_values = [layer_weights[weight_name] for weight_name in weight_names]\n        layer = filtered_layers[k]\n        symbolic_weights = layer.weights\n        weight_values = preprocess_weights_for_loading(layer,\n                                                       weight_values,\n                                                       original_keras_version,\n                                                       original_backend,\n                                                       reshape=False)\n        if len(weight_values) != len(symbolic_weights):\n            raise ValueError(\'Layer #\' + str(k) +\n                             \' (named ""\' + layer.name +\n                             \'"" in the current model) was found to \'\n                             \'correspond to layer \' + name +\n                             \' in the save file. \'\n                             \'However the new layer \' + layer.name +\n                             \' expects \' + str(len(symbolic_weights)) +\n                             \' weights, but the saved weights have \' +\n                             str(len(weight_values)) +\n                             \' elements.\')\n        weight_value_tuples += zip(symbolic_weights, weight_values)\n    K.batch_set_value(weight_value_tuples)\n\n    if compile:\n        training_config = h5dict.get(\'training_config\')\n        if training_config is None:\n            warnings.warn(\'No training configuration found in save file: \'\n                          \'the model was *not* compiled. \'\n                          \'Compile it manually.\')\n            return model\n        training_config = json.loads(training_config.decode(\'utf-8\'))\n        optimizer_config = training_config[\'optimizer_config\']\n        optimizer = optimizers.deserialize(optimizer_config,\n                                           custom_objects=custom_objects)\n\n        # Recover loss functions and metrics.\n        loss_config = training_config[\'loss\']  # Deserialize loss class.\n        if isinstance(loss_config, dict) and \'class_name\' in loss_config:\n            loss_config = losses.get(loss_config)\n        loss = convert_custom_objects(loss_config)\n        metrics = convert_custom_objects(training_config[\'metrics\'])\n        # Earlier versions of keras didn\'t dump weighted_metrics properly. Use\n        # a get to avoid failing if the key is missing\n        weighted_metrics = convert_custom_objects(\n            training_config.get(\'weighted_metrics\'))\n        sample_weight_mode = training_config[\'sample_weight_mode\']\n        loss_weights = training_config[\'loss_weights\']\n\n        # Compile model.\n        model.compile(optimizer=optimizer,\n                      loss=loss,\n                      metrics=metrics,\n                      weighted_metrics=weighted_metrics,\n                      loss_weights=loss_weights,\n                      sample_weight_mode=sample_weight_mode)\n\n        # Set optimizer weights.\n        if \'optimizer_weights\' in h5dict:\n            # Build train function (to get weight updates).\n            model._make_train_function()\n            optimizer_weights_group = h5dict[\'optimizer_weights\']\n            optimizer_weight_names = [\n                n.decode(\'utf8\') for n in\n                optimizer_weights_group[\'weight_names\']]\n            optimizer_weight_values = [optimizer_weights_group[n] for n in\n                                       optimizer_weight_names]\n            try:\n                model.optimizer.set_weights(optimizer_weight_values)\n            except ValueError:\n                warnings.warn(\'Error in loading the saved optimizer \'\n                              \'state. As a result, your model is \'\n                              \'starting with a freshly initialized \'\n                              \'optimizer.\')\n\n    return model\n\n\ndef _gcs_copy(source_filepath, target_filepath, overwrite=True):\n    """"""Copies a file to/from/within Google Cloud Storage (GCS).\n\n    # Arguments\n        source_filepath: String, path to the file on filesystem or object on GCS to\n            copy from.\n        target_filepath: String, path to the file on filesystem or object on GCS to\n            copy to.\n        overwrite: Whether we should overwrite an existing file/object at the target\n            location, or instead ask the user with a manual prompt.\n    """"""\n    if tf_file_io is None:\n        raise ImportError(\'Google Cloud Storage file transfer requires TensorFlow.\')\n    if not overwrite and tf_file_io.file_exists(target_filepath):\n        proceed = ask_to_proceed_with_overwrite(target_filepath)\n        if not proceed:\n            return\n    with tf_file_io.FileIO(source_filepath, mode=\'rb\') as source_f:\n        with tf_file_io.FileIO(target_filepath, mode=\'wb\') as target_f:\n            target_f.write(source_f.read())\n\n\ndef _is_gcs_location(filepath):\n    """"""Checks if `filepath` is referencing a google storage bucket.\n\n    # Arguments\n        filepath: The location to check.\n    """"""\n    return isinstance(filepath, string_types) and filepath.startswith(\'gs://\')\n\n\ndef allow_write_to_gcs(save_function):\n    """"""Function decorator to support saving to Google Cloud Storage (GCS).\n\n    This decorator parses the `filepath` argument of the `save_function` and\n    transfers the file to GCS if `filepath` starts with ""gs://"".\n\n    Note: the file is temporarily writen to local filesystem before copied to GSC.\n\n    # Arguments\n        save_function: The function to wrap, with requirements:\n            - second positional argument should indicate the location to save to.\n            - third positional argument should be the `overwrite` option indicating\n            whether we should overwrite an existing file/object at the target\n            location, or instead ask the user with a manual prompt.\n    """"""\n    @wraps(save_function)\n    def save_wrapper(obj, filepath, overwrite=True, *args, **kwargs):\n        if _is_gcs_location(filepath):\n            tmp_filepath = os.path.join(tempfile.gettempdir(),\n                                        os.path.basename(filepath))\n            save_function(obj, tmp_filepath, True, *args, **kwargs)\n            try:\n                _gcs_copy(tmp_filepath, filepath, overwrite)\n            finally:\n                os.remove(tmp_filepath)\n        else:\n            save_function(obj, filepath, overwrite, *args, **kwargs)\n\n    return save_wrapper\n\n\ndef allow_read_from_gcs(load_function):\n    """"""Function decorator to support loading from Google Cloud Storage (GCS).\n\n    This decorator parses the `filepath` argument of the `load_function` and\n    fetches the required object from GCS if `filepath` starts with ""gs://"".\n\n    Note: the file is temporarily copied to local filesystem from GCS before loaded.\n\n    # Arguments\n        load_function: The function to wrap, with requirements:\n            - should have one _named_ argument `filepath` indicating the location to\n            load from.\n    """"""\n    def extract_named_arg(f, name, args, kwargs):\n        if name in kwargs:\n            arg = kwargs.pop(name)\n            return arg, args, kwargs\n        argnames = getargspec(f)[0]\n        for i, (argname, arg) in enumerate(zip(argnames, args)):\n            if argname == name:\n                return arg, args[:i] + args[i + 1:], kwargs\n        else:\n            raise ValueError(\'function {} has no argument {}\'.format(f, name))\n\n    @wraps(load_function)\n    def load_wrapper(*args, **kwargs):\n        filepath, _args, _kwargs = extract_named_arg(\n            load_function, \'filepath\', args, kwargs)\n        if _is_gcs_location(filepath):\n            tmp_filepath = os.path.join(tempfile.gettempdir(),\n                                        os.path.basename(filepath))\n            _gcs_copy(filepath, tmp_filepath)\n            _kwargs[\'filepath\'] = tmp_filepath\n            try:\n                res = load_function(*_args, **_kwargs)\n            finally:\n                os.remove(tmp_filepath)\n            return res\n        return load_function(*args, **kwargs)\n\n    return load_wrapper\n\n\n@allow_write_to_gcs\ndef save_model(model, filepath, overwrite=True, include_optimizer=True):\n    """"""Save a model to a HDF5 file.\n\n    Note: Please also see\n    [How can I install HDF5 or h5py to save my models in Keras?](\n        /getting-started/faq/\n        #how-can-i-install-HDF5-or-h5py-to-save-my-models-in-Keras)\n    in the FAQ for instructions on how to install `h5py`.\n\n    The saved model contains:\n        - the model\'s configuration (topology)\n        - the model\'s weights\n        - the model\'s optimizer\'s state (if any)\n\n    Thus the saved model can be reinstantiated in\n    the exact same state, without any of the code\n    used for model definition or training.\n\n    # Arguments\n        model: Keras model instance to be saved.\n        filepath: one of the following:\n            - string, path to the file to save the model to\n            - h5py.File or h5py.Group object where to save the model\n            - any file-like object implementing the method `write` that accepts\n                `bytes` data (e.g. `io.BytesIO`).\n        overwrite: Whether we should overwrite any existing\n            model at the target location, or instead\n            ask the user with a manual prompt.\n        include_optimizer: If True, save optimizer\'s state together.\n\n    # Raises\n        ImportError: if h5py is not available.\n    """"""\n    if h5py is None:\n        raise ImportError(\'`save_model` requires h5py.\')\n\n    if H5Dict.is_supported_type(filepath):\n        opens_file = not isinstance(filepath, (dict, h5py.Group))\n        if opens_file and os.path.isfile(filepath) and not overwrite:\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        with H5Dict(filepath, mode=\'w\') as h5dict:\n            _serialize_model(model, h5dict, include_optimizer)\n    elif hasattr(filepath, \'write\') and callable(filepath.write):\n        # write as binary stream\n        def save_function(h5file):\n            _serialize_model(model, H5Dict(h5file), include_optimizer)\n        save_to_binary_h5py(save_function, filepath)\n    else:\n        raise ValueError(\'unexpected type {} for `filepath`\'.format(type(filepath)))\n\n\n@allow_read_from_gcs\ndef load_model(filepath, custom_objects=None, compile=True):\n    """"""Loads a model saved via `save_model`.\n\n    # Arguments\n        filepath: one of the following:\n            - string, path to the saved model\n            - h5py.File or h5py.Group object from which to load the model\n            - any file-like object implementing the method `read` that returns\n            `bytes` data (e.g. `io.BytesIO`) that represents a valid h5py file image.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n        compile: Boolean, whether to compile the model\n            after loading.\n\n    # Returns\n        A Keras model instance. If an optimizer was found\n        as part of the saved model, the model is already\n        compiled. Otherwise, the model is uncompiled and\n        a warning will be displayed. When `compile` is set\n        to False, the compilation is omitted without any\n        warning.\n\n    # Raises\n        ImportError: if h5py is not available.\n        ValueError: In case of an invalid savefile.\n    """"""\n    if h5py is None:\n        raise ImportError(\'`load_model` requires h5py.\')\n\n    if H5Dict.is_supported_type(filepath):\n        with H5Dict(filepath, mode=\'r\') as h5dict:\n            model = _deserialize_model(h5dict, custom_objects, compile)\n    elif hasattr(filepath, \'write\') and callable(filepath.write):\n        def load_function(h5file):\n            return _deserialize_model(H5Dict(h5file), custom_objects, compile)\n        model = load_from_binary_h5py(load_function, filepath)\n    else:\n        raise ValueError(\'unexpected type {} for `filepath`\'.format(type(filepath)))\n\n    return model\n\n\ndef pickle_model(model):\n    d = {}\n    h5dict = H5Dict(d)\n    _serialize_model(model, h5dict)\n    return d\n\n\ndef unpickle_model(state):\n    h5dict = H5Dict(state, mode=\'r\')\n    return _deserialize_model(h5dict)\n\n\ndef model_from_config(config, custom_objects=None):\n    """"""Instantiates a Keras model from its config.\n\n    # Arguments\n        config: Configuration dictionary.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n\n    # Raises\n        TypeError: if `config` is not a dictionary.\n    """"""\n    if isinstance(config, list):\n        raise TypeError(\'`model_from_config` expects a dictionary, \'\n                        \'not a list. Maybe you meant to use \'\n                        \'`Sequential.from_config(config)`?\')\n    from ..layers import deserialize\n    return deserialize(config, custom_objects=custom_objects)\n\n\ndef model_from_yaml(yaml_string, custom_objects=None):\n    """"""Parses a yaml model configuration file and returns a model instance.\n\n    # Arguments\n        yaml_string: YAML string encoding a model configuration.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n    """"""\n    if hasattr(yaml, \'FullLoader\'):\n        config = yaml.load(yaml_string, Loader=yaml.FullLoader)\n    else:\n        config = yaml.load(yaml_string)\n    from ..layers import deserialize\n    return deserialize(config, custom_objects=custom_objects)\n\n\ndef model_from_json(json_string, custom_objects=None):\n    """"""Parses a JSON model configuration file and returns a model instance.\n\n    # Arguments\n        json_string: JSON string encoding a model configuration.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n    """"""\n    config = json.loads(json_string)\n    from ..layers import deserialize\n    return deserialize(config, custom_objects=custom_objects)\n\n\ndef save_attributes_to_hdf5_group(group, name, data):\n    """"""Saves attributes (data) of the specified name into the HDF5 group.\n\n    This method deals with an inherent problem of HDF5 file which is not\n    able to store data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        name: A name of the attributes to save.\n        data: Attributes data to store.\n    """"""\n    # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n    # because in that case even chunking the array would not make the saving\n    # possible.\n    bad_attributes = [x for x in data if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n\n    # Expecting this to never be true.\n    if len(bad_attributes) > 0:\n        raise RuntimeError(\'The following attributes cannot be saved to HDF5 \'\n                           \'file because they are larger than %d bytes: %s\'\n                           % (HDF5_OBJECT_HEADER_LIMIT,\n                              \', \'.join([x for x in bad_attributes])))\n\n    data_npy = np.asarray(data)\n\n    num_chunks = 1\n    chunked_data = np.array_split(data_npy, num_chunks)\n\n    # This will never loop forever thanks to the test above.\n    while any(map(lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT, chunked_data)):\n        num_chunks += 1\n        chunked_data = np.array_split(data_npy, num_chunks)\n\n    if num_chunks > 1:\n        for chunk_id, chunk_data in enumerate(chunked_data):\n            group.attrs[\'%s%d\' % (name, chunk_id)] = chunk_data\n    else:\n        group.attrs[name] = data\n\n\ndef load_attributes_from_hdf5_group(group, name):\n    """"""Loads attributes of the specified name from the HDF5 group.\n\n    This method deals with an inherent problem\n    of HDF5 file which is not able to store\n    data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        name: A name of the attributes to load.\n\n    # Returns\n        data: Attributes data.\n    """"""\n    if name in group.attrs:\n        data = [n.decode(\'utf8\') for n in group.attrs[name]]\n    else:\n        data = []\n        chunk_id = 0\n        while (\'%s%d\' % (name, chunk_id)) in group.attrs:\n            data.extend([n.decode(\'utf8\')\n                         for n in group.attrs[\'%s%d\' % (name, chunk_id)]])\n            chunk_id += 1\n    return data\n\n\ndef save_weights_to_hdf5_group(group, layers):\n    """"""Saves weights into the HDF5 group.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        layers: Layers to load.\n    """"""\n    from .. import __version__ as keras_version\n\n    save_attributes_to_hdf5_group(\n        group, \'layer_names\', [layer.name.encode(\'utf8\') for layer in layers])\n    group.attrs[\'backend\'] = K.backend().encode(\'utf8\')\n    group.attrs[\'keras_version\'] = str(keras_version).encode(\'utf8\')\n\n    # Sort model layers by layer name to ensure that group names are strictly\n    # growing to avoid prefix issues.\n    for layer in sorted(layers, key=lambda x: x.name):\n        g = group.create_group(layer.name)\n        symbolic_weights = layer.weights\n        weight_values = K.batch_get_value(symbolic_weights)\n        weight_names = []\n        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n            if hasattr(w, \'name\') and w.name:\n                name = str(w.name)\n            else:\n                name = \'param_\' + str(i)\n            weight_names.append(name.encode(\'utf8\'))\n        save_attributes_to_hdf5_group(g, \'weight_names\', weight_names)\n        for name, val in zip(weight_names, weight_values):\n            param_dset = g.create_dataset(name, val.shape,\n                                          dtype=val.dtype)\n            if not val.shape:\n                # scalar\n                param_dset[()] = val\n            else:\n                param_dset[:] = val\n\n\ndef preprocess_weights_for_loading(layer, weights,\n                                   original_keras_version=None,\n                                   original_backend=None,\n                                   reshape=False):\n    """"""Converts layers weights from Keras 1 format to Keras 2.\n\n    # Arguments\n        layer: Layer instance.\n        weights: List of weights values (Numpy arrays).\n        original_keras_version: Keras version for the weights, as a string.\n        original_backend: Keras backend the weights were trained with,\n            as a string.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Returns\n        A list of weights values (Numpy arrays).\n    """"""\n    def convert_nested_bidirectional(weights):\n        """"""Converts layers nested in `Bidirectional` wrapper.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        """"""\n        num_weights_per_layer = len(weights) // 2\n        forward_weights = preprocess_weights_for_loading(\n            layer.forward_layer,\n            weights[:num_weights_per_layer],\n            original_keras_version,\n            original_backend)\n        backward_weights = preprocess_weights_for_loading(\n            layer.backward_layer,\n            weights[num_weights_per_layer:],\n            original_keras_version,\n            original_backend)\n        return forward_weights + backward_weights\n\n    def convert_nested_time_distributed(weights):\n        """"""Converts layers nested in `TimeDistributed` wrapper.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        """"""\n        return preprocess_weights_for_loading(\n            layer.layer, weights, original_keras_version, original_backend)\n\n    def convert_nested_model(weights):\n        """"""Converts layers nested in `Model` or `Sequential`.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        """"""\n        new_weights = []\n        # trainable weights\n        for sublayer in layer.layers:\n            num_weights = len(sublayer.trainable_weights)\n            if num_weights > 0:\n                new_weights.extend(preprocess_weights_for_loading(\n                    layer=sublayer,\n                    weights=weights[:num_weights],\n                    original_keras_version=original_keras_version,\n                    original_backend=original_backend))\n                weights = weights[num_weights:]\n\n        # non-trainable weights\n        for sublayer in layer.layers:\n            ref_ids = [id(w) for w in sublayer.trainable_weights]\n            num_weights = len([l for l in sublayer.weights\n                               if id(l) not in ref_ids])\n            if num_weights > 0:\n                new_weights.extend(preprocess_weights_for_loading(\n                    layer=sublayer,\n                    weights=weights[:num_weights],\n                    original_keras_version=original_keras_version,\n                    original_backend=original_backend))\n                weights = weights[num_weights:]\n        return new_weights\n\n    # Convert layers nested in Bidirectional/TimeDistributed/Model/Sequential.\n    # Both transformation should be ran for both Keras 1->2 conversion\n    # and for conversion of CuDNN layers.\n    if layer.__class__.__name__ == \'Bidirectional\':\n        weights = convert_nested_bidirectional(weights)\n    if layer.__class__.__name__ == \'TimeDistributed\':\n        weights = convert_nested_time_distributed(weights)\n    elif layer.__class__.__name__ in [\'Model\', \'Sequential\']:\n        weights = convert_nested_model(weights)\n\n    if original_keras_version == \'1\':\n        if layer.__class__.__name__ == \'TimeDistributed\':\n            weights = preprocess_weights_for_loading(layer.layer,\n                                                     weights,\n                                                     original_keras_version,\n                                                     original_backend)\n\n        if layer.__class__.__name__ == \'Conv1D\':\n            shape = weights[0].shape\n            # Handle Keras 1.1 format\n            if shape[:2] != (layer.kernel_size[0], 1) or shape[3] != layer.filters:\n                # Legacy shape:\n                # (filters, input_dim, filter_length, 1)\n                assert (shape[0] == layer.filters and\n                        shape[2:] == (layer.kernel_size[0], 1))\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n            weights[0] = weights[0][:, 0, :, :]\n\n        if layer.__class__.__name__ == \'Conv2D\':\n            if layer.data_format == \'channels_first\':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n\n        if layer.__class__.__name__ == \'Conv2DTranspose\':\n            if layer.data_format == \'channels_last\':\n                # old: (kernel_rows, kernel_cols, stack_size, filters)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (0, 1, 3, 2))\n            if layer.data_format == \'channels_first\':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (2, 3, 0, 1))\n\n        if layer.__class__.__name__ == \'Conv3D\':\n            if layer.data_format == \'channels_first\':\n                # old: (filters, stack_size, ...)\n                # new: (..., stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 4, 1, 0))\n\n        if layer.__class__.__name__ == \'GRU\':\n            if len(weights) == 9:\n                kernel = np.concatenate([weights[0],\n                                         weights[3],\n                                         weights[6]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[4],\n                                                   weights[7]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[5],\n                                       weights[8]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == \'LSTM\':\n            if len(weights) == 12:\n                # old: i, c, f, o\n                # new: i, f, c, o\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == \'ConvLSTM2D\':\n            if len(weights) == 12:\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                if layer.data_format == \'channels_first\':\n                    # old: (filters, stack_size, kernel_rows, kernel_cols)\n                    # new: (kernel_rows, kernel_cols, stack_size, filters)\n                    kernel = np.transpose(kernel, (2, 3, 1, 0))\n                    recurrent_kernel = np.transpose(recurrent_kernel,\n                                                    (2, 3, 1, 0))\n                weights = [kernel, recurrent_kernel, bias]\n\n    conv_layers = [\'Conv1D\',\n                   \'Conv2D\',\n                   \'Conv3D\',\n                   \'Conv2DTranspose\',\n                   \'ConvLSTM2D\']\n    if layer.__class__.__name__ in conv_layers:\n        layer_weights_shape = K.int_shape(layer.weights[0])\n        if _need_convert_kernel(original_backend):\n            weights[0] = conv_utils.convert_kernel(weights[0])\n            if layer.__class__.__name__ == \'ConvLSTM2D\':\n                weights[1] = conv_utils.convert_kernel(weights[1])\n        if reshape and layer_weights_shape != weights[0].shape:\n            if weights[0].size != np.prod(layer_weights_shape):\n                raise ValueError(\'Weights must be of equal size to \' +\n                                 \'apply a reshape operation. \' +\n                                 \'Layer \' + layer.name +\n                                 \'\\\'s weights have shape \' +\n                                 str(layer_weights_shape) + \' and size \' +\n                                 str(np.prod(layer_weights_shape)) + \'. \' +\n                                 \'The weights for loading have shape \' +\n                                 str(weights[0].shape) + \' and size \' +\n                                 str(weights[0].size) + \'. \')\n            weights[0] = np.reshape(weights[0], layer_weights_shape)\n        elif layer_weights_shape != weights[0].shape:\n            weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n            if layer.__class__.__name__ == \'ConvLSTM2D\':\n                weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n\n    # convert CuDNN layers\n    weights = _convert_rnn_weights(layer, weights)\n\n    return weights\n\n\ndef _convert_rnn_weights(layer, weights):\n    """"""Converts weights for RNN layers between native and CuDNN format.\n\n    Input kernels for each gate are transposed and converted between Fortran\n    and C layout, recurrent kernels are transposed. For LSTM biases are summed/\n    split in half, for GRU biases are reshaped.\n\n    Weights can be converted in both directions between `LSTM` and`CuDNNSLTM`\n    and between `CuDNNGRU` and `GRU(reset_after=True)`. Default `GRU` is not\n    compatible with `CuDNNGRU`.\n\n    For missing biases in `LSTM`/`GRU` (`use_bias=False`),\n    no conversion is made.\n\n    # Arguments\n        layer: Target layer instance.\n        weights: List of source weights values (input kernels, recurrent\n            kernels, [biases]) (Numpy arrays).\n\n    # Returns\n        A list of converted weights values (Numpy arrays).\n\n    # Raises\n        ValueError: for incompatible GRU layer/weights or incompatible biases\n    """"""\n\n    def transform_kernels(kernels, func, n_gates):\n        """"""Transforms kernel for each gate separately using given function.\n\n        # Arguments\n            kernels: Stacked array of kernels for individual gates.\n            func: Function applied to kernel of each gate.\n            n_gates: Number of gates (4 for LSTM, 3 for GRU).\n        # Returns\n            Stacked array of transformed kernels.\n        """"""\n        return np.hstack([func(k) for k in np.hsplit(kernels, n_gates)])\n\n    def transpose_input(from_cudnn):\n        """"""Makes a function that transforms input kernels from/to CuDNN format.\n\n        It keeps the shape, but changes between the layout (Fortran/C). Eg.:\n\n        ```\n        Keras                 CuDNN\n        [[0, 1, 2],  <--->  [[0, 2, 4],\n         [3, 4, 5]]          [1, 3, 5]]\n        ```\n\n        It can be passed to `transform_kernels()`.\n\n        # Arguments\n            from_cudnn: `True` if source weights are in CuDNN format, `False`\n                if they\'re in plain Keras format.\n        # Returns\n            Function that converts input kernel to the other format.\n        """"""\n        order = \'F\' if from_cudnn else \'C\'\n\n        def transform(kernel):\n            return kernel.T.reshape(kernel.shape, order=order)\n\n        return transform\n\n    target_class = layer.__class__.__name__\n\n    # convert the weights between CuDNNLSTM and LSTM\n    if target_class in [\'LSTM\', \'CuDNNLSTM\'] and len(weights) == 3:\n        # determine if we\'re loading a CuDNNLSTM layer\n        # from the number of bias weights:\n        # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n        # if there\'s no bias weight in the file, skip this conversion\n        units = weights[1].shape[0]\n        bias_shape = weights[2].shape\n        n_gates = 4\n\n        if bias_shape == (2 * units * n_gates,):\n            source = \'CuDNNLSTM\'\n        elif bias_shape == (units * n_gates,):\n            source = \'LSTM\'\n        else:\n            raise ValueError(\'Invalid bias shape: \' + str(bias_shape))\n\n        def convert_weights(weights, from_cudnn=True):\n            # transpose (and reshape) input and recurrent kernels\n            kernels = transform_kernels(weights[0],\n                                        transpose_input(from_cudnn),\n                                        n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            if from_cudnn:\n                # merge input and recurrent biases into a single set\n                biases = np.sum(np.split(weights[2], 2, axis=0), axis=0)\n            else:\n                # Split single set of biases evenly to two sets. The way of\n                # splitting doesn\'t matter as long as the two sets sum is kept.\n                biases = np.tile(0.5 * weights[2], 2)\n            return [kernels, recurrent_kernels, biases]\n\n        if source != target_class:\n            weights = convert_weights(weights, from_cudnn=source == \'CuDNNLSTM\')\n\n    # convert the weights between CuDNNGRU and GRU(reset_after=True)\n    if target_class in [\'GRU\', \'CuDNNGRU\'] and len(weights) == 3:\n        # We can determine the source of the weights from the shape of the bias.\n        # If there is no bias we skip the conversion\n        # since CuDNNGRU always has biases.\n\n        units = weights[1].shape[0]\n        bias_shape = weights[2].shape\n        n_gates = 3\n\n        def convert_weights(weights, from_cudnn=True):\n            kernels = transform_kernels(weights[0],\n                                        transpose_input(from_cudnn),\n                                        n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            biases = np.array(weights[2]).reshape((2, -1) if from_cudnn else -1)\n            return [kernels, recurrent_kernels, biases]\n\n        if bias_shape == (2 * units * n_gates,):\n            source = \'CuDNNGRU\'\n        elif bias_shape == (2, units * n_gates):\n            source = \'GRU(reset_after=True)\'\n        elif bias_shape == (units * n_gates,):\n            source = \'GRU(reset_after=False)\'\n        else:\n            raise ValueError(\'Invalid bias shape: \' + str(bias_shape))\n\n        if target_class == \'CuDNNGRU\':\n            target = \'CuDNNGRU\'\n        elif layer.reset_after:\n            target = \'GRU(reset_after=True)\'\n        else:\n            target = \'GRU(reset_after=False)\'\n\n        # only convert between different types\n        if source != target:\n            types = (source, target)\n            if \'GRU(reset_after=False)\' in types:\n                raise ValueError(\'%s is not compatible with %s\' % types)\n            if source == \'CuDNNGRU\':\n                weights = convert_weights(weights, from_cudnn=True)\n            elif source == \'GRU(reset_after=True)\':\n                weights = convert_weights(weights, from_cudnn=False)\n\n    return weights\n\n\ndef _need_convert_kernel(original_backend):\n    """"""Checks if conversion on kernel matrices is required during weight loading.\n\n    The convolution operation is implemented differently in different backends.\n    While TH implements convolution, TF and CNTK implement the correlation operation.\n    So the channel axis needs to be flipped when TF weights are loaded on a TH model,\n    or vice versa. However, there\'s no conversion required between TF and CNTK.\n\n    # Arguments\n        original_backend: Keras backend the weights were trained with, as a string.\n\n    # Returns\n        `True` if conversion on kernel matrices is required, otherwise `False`.\n    """"""\n    if original_backend is None:\n        # backend information not available\n        return False\n    uses_correlation = {\'tensorflow\': True,\n                        \'theano\': False,\n                        \'cntk\': True}\n    if original_backend not in uses_correlation:\n        # By default, do not convert the kernels if the original backend is unknown\n        return False\n    if K.backend() in uses_correlation:\n        current_uses_correlation = uses_correlation[K.backend()]\n    else:\n        # Assume unknown backends use correlation\n        current_uses_correlation = True\n    return uses_correlation[original_backend] != current_uses_correlation\n\n\ndef load_weights_from_hdf5_group(f, layers, reshape=False):\n    """"""Implements topological (order-based) weight loading.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: a list of target layers.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file.\n    """"""\n    if \'keras_version\' in f.attrs:\n        original_keras_version = f.attrs[\'keras_version\'].decode(\'utf8\')\n    else:\n        original_keras_version = \'1\'\n    if \'backend\' in f.attrs:\n        original_backend = f.attrs[\'backend\'].decode(\'utf8\')\n    else:\n        original_backend = None\n\n    filtered_layers = []\n    for layer in layers:\n        weights = layer.weights\n        if weights:\n            filtered_layers.append(layer)\n\n    layer_names = load_attributes_from_hdf5_group(f, \'layer_names\')\n    filtered_layer_names = []\n    for name in layer_names:\n        g = f[name]\n        weight_names = load_attributes_from_hdf5_group(g, \'weight_names\')\n        if weight_names:\n            filtered_layer_names.append(name)\n    layer_names = filtered_layer_names\n    if len(layer_names) != len(filtered_layers):\n        raise ValueError(\'You are trying to load a weight file \'\n                         \'containing \' + str(len(layer_names)) +\n                         \' layers into a model with \' +\n                         str(len(filtered_layers)) + \' layers.\')\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = load_attributes_from_hdf5_group(g, \'weight_names\')\n        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n        layer = filtered_layers[k]\n        symbolic_weights = layer.weights\n        weight_values = preprocess_weights_for_loading(layer,\n                                                       weight_values,\n                                                       original_keras_version,\n                                                       original_backend,\n                                                       reshape=reshape)\n        if len(weight_values) != len(symbolic_weights):\n            raise ValueError(\'Layer #\' + str(k) +\n                             \' (named ""\' + layer.name +\n                             \'"" in the current model) was found to \'\n                             \'correspond to layer \' + name +\n                             \' in the save file. \'\n                             \'However the new layer \' + layer.name +\n                             \' expects \' + str(len(symbolic_weights)) +\n                             \' weights, but the saved weights have \' +\n                             str(len(weight_values)) +\n                             \' elements.\')\n        weight_value_tuples += zip(symbolic_weights, weight_values)\n    K.batch_set_value(weight_value_tuples)\n\n\ndef load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,\n                                         reshape=False):\n    """"""Implements name-based weight loading.\n\n    (instead of topological weight loading).\n\n    Layers that have no matching name are skipped.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: A list of target layers.\n        skip_mismatch: Boolean, whether to skip loading of layers\n            where there is a mismatch in the number of weights,\n            or a mismatch in the shape of the weights.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file and skip_mismatch=False.\n    """"""\n    if \'keras_version\' in f.attrs:\n        original_keras_version = f.attrs[\'keras_version\'].decode(\'utf8\')\n    else:\n        original_keras_version = \'1\'\n    if \'backend\' in f.attrs:\n        original_backend = f.attrs[\'backend\'].decode(\'utf8\')\n    else:\n        original_backend = None\n\n    # New file format.\n    layer_names = load_attributes_from_hdf5_group(f, \'layer_names\')\n\n    # Reverse index of layer name to list of layers with name.\n    index = {}\n    for layer in layers:\n        if layer.name:\n            index.setdefault(layer.name, []).append(layer)\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = load_attributes_from_hdf5_group(g, \'weight_names\')\n        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n\n        for layer in index.get(name, []):\n            symbolic_weights = layer.weights\n            weight_values = preprocess_weights_for_loading(\n                layer,\n                weight_values,\n                original_keras_version,\n                original_backend,\n                reshape=reshape)\n            if len(weight_values) != len(symbolic_weights):\n                if skip_mismatch:\n                    warnings.warn(\'Skipping loading of weights for \'\n                                  \'layer {}\'.format(layer.name) + \' due to mismatch \'\n                                  \'in number of weights ({} vs {}).\'.format(\n                                      len(symbolic_weights), len(weight_values)))\n                    continue\n                else:\n                    raise ValueError(\'Layer #\' + str(k) +\n                                     \' (named ""\' + layer.name +\n                                     \'"") expects \' +\n                                     str(len(symbolic_weights)) +\n                                     \' weight(s), but the saved weights\' +\n                                     \' have \' + str(len(weight_values)) +\n                                     \' element(s).\')\n            # Set values.\n            for i in range(len(weight_values)):\n                symbolic_shape = K.int_shape(symbolic_weights[i])\n                if symbolic_shape != weight_values[i].shape:\n                    if skip_mismatch:\n                        warnings.warn(\'Skipping loading of weights for \'\n                                      \'layer {}\'.format(layer.name) + \' due to \'\n                                      \'mismatch in shape ({} vs {}).\'.format(\n                                          symbolic_weights[i].shape,\n                                          weight_values[i].shape))\n                        continue\n                    else:\n                        raise ValueError(\'Layer #\' + str(k) +\n                                         \' (named ""\' + layer.name +\n                                         \'""), weight \' +\n                                         str(symbolic_weights[i]) +\n                                         \' has shape {}\'.format(symbolic_shape) +\n                                         \', but the saved weight has shape \' +\n                                         str(weight_values[i].shape) + \'.\')\n                else:\n                    weight_value_tuples.append((symbolic_weights[i],\n                                                weight_values[i]))\n\n    K.batch_set_value(weight_value_tuples)\n'"
keras/engine/sequential.py,0,"b'""""""Sequential model class.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport warnings\nimport copy\n\nfrom . import network\nfrom .training import Model\nfrom .base_layer import Layer\nfrom .input_layer import Input\nfrom .input_layer import InputLayer\nfrom .. import backend as K\nfrom .. import layers as layer_module\n\ntry:\n    import h5py\nexcept ImportError:\n    h5py = None\n\n\nclass Sequential(Model):\n    """"""Linear stack of layers.\n\n    # Arguments\n        layers: list of layers to add to the model.\n        name: Name given to the model\n\n    # Example\n\n    ```python\n    # Optionally, the first layer can receive an `input_shape` argument:\n    model = Sequential()\n    model.add(Dense(32, input_shape=(500,)))\n\n    # Afterwards, we do automatic shape inference:\n    model.add(Dense(32))\n\n    # This is identical to the following:\n    model = Sequential()\n    model.add(Dense(32, input_dim=500))\n\n    # And to the following:\n    model = Sequential()\n    model.add(Dense(32, batch_input_shape=(None, 500)))\n\n    # Note that you can also omit the `input_shape` argument:\n    # In that case the model gets built the first time you call `fit` (or other\n    # training and evaluation methods).\n    model = Sequential()\n    model.add(Dense(32))\n    model.add(Dense(32))\n    model.compile(optimizer=optimizer, loss=loss)\n\n    # This builds the model for the first time:\n    model.fit(x, y, batch_size=32, epochs=10)\n\n    # Note that when using this delayed-build pattern\n    # (no input shape specified),\n    # the model doesn\'t have any weights until the first call\n    # to a training/evaluation method (since it isn\'t yet built):\n    model = Sequential()\n    model.add(Dense(32))\n    model.add(Dense(32))\n    model.weights  # returns []\n\n    # Whereas if you specify the input shape, the model gets built continuously\n    # as you are adding layers:\n    model = Sequential()\n    model.add(Dense(32, input_shape=(500,)))\n    model.add(Dense(32))\n    model.weights  # returns list of length 4\n\n    # When using the delayed-build pattern (no input shape specified), you can\n    # choose to manually build your model by calling\n    # `build(batch_input_shape)`:\n    model = Sequential()\n    model.add(Dense(32))\n    model.add(Dense(32))\n    model.build((None, 500))\n    model.weights  # returns list of length 4\n    ```\n    """"""\n\n    def __init__(self, layers=None, name=None):\n        super(Sequential, self).__init__(name=name)\n        self._build_input_shape = None\n\n        # Add to the model any layers passed to the constructor.\n        if layers:\n            for layer in layers:\n                self.add(layer)\n\n    @property\n    def layers(self):\n        # Historically, `sequential.layers` only returns layers that were added\n        # via `add`, and omits the auto-generated `InputLayer`\n        # that comes at the bottom of the stack.\n        if self._layers and isinstance(self._layers[0], InputLayer):\n            return self._layers[1:]\n        return self._layers\n\n    @property\n    def model(self):\n        # Historically, `Sequential` was once\n        # implemented as a wrapper for `Model` which maintained\n        # its underlying `Model` as the `model` property.\n        # We keep it for compatibility reasons.\n        warnings.warn(\'`Sequential.model` is deprecated. \'\n                      \'`Sequential` is a subclass of `Model`, you can \'\n                      \'just use your `Sequential` instance directly.\')\n        return self\n\n    def add(self, layer):\n        """"""Adds a layer instance on top of the layer stack.\n\n        # Arguments\n            layer: layer instance.\n\n        # Raises\n            TypeError: If `layer` is not a layer instance.\n            ValueError: In case the `layer` argument does not\n                know its input shape.\n            ValueError: In case the `layer` argument has\n                multiple output tensors, or is already connected\n                somewhere else (forbidden in `Sequential` models).\n        """"""\n        if not isinstance(layer, Layer):\n            raise TypeError(\'The added layer must be \'\n                            \'an instance of class Layer. \'\n                            \'Found: \' + str(layer))\n        self.built = False\n        if not self._layers:\n            set_inputs = False\n            # First layer in model: check that it is an input layer.\n            if not isinstance(layer, InputLayer):\n                # Create an input tensor and call `layer` on the input tensor.\n                # First, we need to infer the expected input shape and dtype.\n                first_layer = layer\n                if isinstance(layer, (Model, Sequential)):\n                    # We were passed a model as first layer.\n                    # This requires a specific way to figure out the\n                    # input shape and dtype.\n                    if not layer.layers:\n                        raise ValueError(\'Cannot add an empty model \'\n                                         \'to a `Sequential` model.\')\n                    # In case of nested models: recover the first layer\n                    # of the deepest model to infer input shape and dtype.\n                    first_layer = layer.layers[0]\n                    while isinstance(first_layer, (Model, Sequential)):\n                        first_layer = first_layer.layers[0]\n\n                if hasattr(first_layer, \'batch_input_shape\'):\n                    batch_shape = first_layer.batch_input_shape\n                    dtype = first_layer.dtype\n                    # Instantiate the input layer.\n                    x = Input(\n                        batch_shape=batch_shape,\n                        dtype=dtype,\n                        name=layer.name + \'_input\')\n                    # This will build the current layer\n                    # and create the node connecting the current layer\n                    # to the input layer we just created.\n                    layer(x)\n                    set_inputs = True\n            else:\n                # Corner case where the user passes an InputLayer via `add`.\n                assert len(layer._inbound_nodes[-1].output_tensors) == 1\n                set_inputs = True\n\n            if set_inputs:\n                if len(layer._inbound_nodes[-1].output_tensors) != 1:\n                    raise ValueError(\'All layers in a Sequential model \'\n                                     \'should have a single output tensor. \'\n                                     \'For multi-output layers, \'\n                                     \'use the functional API.\')\n                self.outputs = [layer._inbound_nodes[-1].output_tensors[0]]\n                self.inputs = network.get_source_inputs(self.outputs[0])\n        elif self.outputs:\n            output_tensor = layer(self.outputs[0])\n            if isinstance(output_tensor, list):\n                raise TypeError(\'All layers in a Sequential model \'\n                                \'should have a single output tensor. \'\n                                \'For multi-output layers, \'\n                                \'use the functional API.\')\n            self.outputs = [output_tensor]\n        if self.inputs:\n            self.build()\n        else:\n            self._layers.append(layer)\n\n    def pop(self):\n        """"""Removes the last layer in the model.\n\n        # Raises\n            TypeError: if there are no layers in the model.\n        """"""\n        if not self.layers:\n            raise TypeError(\'There are no layers in the model.\')\n\n        self._layers.pop()\n        self.built = False\n        if not self.layers:\n            self.outputs = None\n            self.inputs = None\n        elif self.outputs:\n            self.layers[-1]._outbound_nodes = []\n            self.outputs = [self.layers[-1].output]\n            self.build()\n\n    def build(self, input_shape=None):\n        if input_shape and not self.inputs:\n            batch_shape = tuple(input_shape)\n            dtype = K.floatx()\n            x = Input(batch_shape=batch_shape,\n                      dtype=dtype,\n                      name=self.name + \'_input\')\n            self.inputs = [x]\n            for layer in self._layers:\n                x = layer(x)\n            self.outputs = [x]\n            self._build_input_shape = input_shape\n\n        if self.inputs:\n            self._init_graph_network(self.inputs,\n                                     self.outputs,\n                                     name=self.name)\n            self.built = True\n\n    def predict_proba(self, x, batch_size=32, verbose=0):\n        """"""Generates class probability predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            batch_size: integer.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A Numpy array of probability predictions.\n        """"""\n        preds = self.predict(x, batch_size, verbose)\n        if preds.min() < 0. or preds.max() > 1.:\n            warnings.warn(\'Network returning invalid probability values. \'\n                          \'The last layer might not normalize predictions \'\n                          \'into probabilities \'\n                          \'(like softmax or sigmoid would).\')\n        return preds\n\n    def predict_classes(self, x, batch_size=32, verbose=0):\n        """"""Generate class predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            batch_size: integer.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A numpy array of class predictions.\n        """"""\n        proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n        if proba.shape[-1] > 1:\n            return proba.argmax(axis=-1)\n        else:\n            return (proba > 0.5).astype(\'int32\')\n\n    def get_config(self):\n        layer_configs = []\n        for layer in self.layers:\n            layer_configs.append({\n                \'class_name\': layer.__class__.__name__,\n                \'config\': layer.get_config()\n            })\n        config = {\n            \'name\': self.name,\n            \'layers\': copy.deepcopy(layer_configs)\n        }\n        if self._build_input_shape:\n            config[\'build_input_shape\'] = self._build_input_shape\n        return config\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        if \'name\' in config:\n            name = config[\'name\']\n            build_input_shape = config.get(\'build_input_shape\')\n            layer_configs = config[\'layers\']\n        else:  # legacy config file\n            name = build_input_shape = None\n            layer_configs = config\n        model = cls(name=name)\n        for conf in layer_configs:\n            layer = layer_module.deserialize(conf,\n                                             custom_objects=custom_objects)\n            model.add(layer)\n        if not model.inputs and build_input_shape:\n            model.build(build_input_shape)\n        return model\n'"
keras/engine/topology.py,0,"b'""""""This module is deprecated, but kept around for backwards compatibility.\n""""""\nfrom .base_layer import Layer, Node, InputSpec\nfrom .input_layer import Input, InputLayer\nfrom .network import Network, get_source_inputs\n'"
keras/engine/training.py,1,"b'""""""Training-related part of the Keras engine.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport warnings\nimport copy\nimport numpy as np\n\nfrom .network import Network\nfrom .base_layer import Layer\nfrom . import training_utils\nfrom . import training_arrays\nfrom . import training_generator\nfrom .. import backend as K\nfrom .. import optimizers\nfrom .. import losses\nfrom .. import metrics as metrics_module\nfrom ..utils.generic_utils import slice_arrays\nfrom ..utils.generic_utils import to_list\nfrom ..utils.generic_utils import unpack_singleton\nfrom ..utils import losses_utils\nfrom ..legacy import interfaces\n\n\nclass Model(Network):\n    """"""The `Model` class adds training & evaluation routines to a `Network`.\n    """"""\n\n    @K.symbolic\n    def compile(self, optimizer,\n                loss=None,\n                metrics=None,\n                loss_weights=None,\n                sample_weight_mode=None,\n                weighted_metrics=None,\n                target_tensors=None,\n                **kwargs):\n        """"""Configures the model for training.\n\n        # Arguments\n            optimizer: String (name of optimizer) or optimizer instance.\n                See [optimizers](/optimizers).\n            loss: String (name of objective function) or objective function or\n                `Loss` instance. See [losses](/losses).\n                If the model has multiple outputs, you can use a different loss\n                on each output by passing a dictionary or a list of losses.\n                The loss value that will be minimized by the model\n                will then be the sum of all individual losses.\n            metrics: List of metrics to be evaluated by the model\n                during training and testing. Typically you will use\n                `metrics=[\'accuracy\']`. To specify different metrics for different\n                outputs of a multi-output model, you could also pass a dictionary,\n                such as\n                `metrics={\'output_a\': \'accuracy\', \'output_b\': [\'accuracy\', \'mse\']}`.\n                You can also pass a list (len = len(outputs)) of lists of metrics\n                such as `metrics=[[\'accuracy\'], [\'accuracy\', \'mse\']]` or\n                `metrics=[\'accuracy\', [\'accuracy\', \'mse\']]`.\n            loss_weights: Optional list or dictionary specifying scalar\n                coefficients (Python floats) to weight the loss contributions\n                of different model outputs.\n                The loss value that will be minimized by the model\n                will then be the *weighted sum* of all individual losses,\n                weighted by the `loss_weights` coefficients.\n                If a list, it is expected to have a 1:1 mapping\n                to the model\'s outputs. If a dict, it is expected to map\n                output names (strings) to scalar coefficients.\n            sample_weight_mode: If you need to do timestep-wise\n                sample weighting (2D weights), set this to `""temporal""`.\n                `None` defaults to sample-wise weights (1D).\n                If the model has multiple outputs, you can use a different\n                `sample_weight_mode` on each output by passing a\n                dictionary or a list of modes.\n            weighted_metrics: List of metrics to be evaluated and weighted\n                by sample_weight or class_weight during training and testing.\n            target_tensors: By default, Keras will create placeholders for the\n                model\'s target, which will be fed with the target data during\n                training. If instead you would like to use your own\n                target tensors (in turn, Keras will not expect external\n                Numpy data for these targets at training time), you\n                can specify them via the `target_tensors` argument. It can be\n                a single tensor (for a single-output model), a list of tensors,\n                or a dict mapping output names to target tensors.\n            **kwargs: When using the Theano/CNTK backends, these arguments\n                are passed into `K.function`.\n                When using the TensorFlow backend,\n                these arguments are passed into `tf.Session.run`.\n\n        # Raises\n            ValueError: In case of invalid arguments for\n                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n        """"""\n        self.optimizer = optimizers.get(optimizer)\n        self.loss = loss or {}\n        self._compile_metrics = metrics or []\n        self.loss_weights = loss_weights\n        self.sample_weight_mode = sample_weight_mode\n        self._compile_weighted_metrics = weighted_metrics\n\n        # List of stateful metric functions. Used for resetting metric state during\n        # training/eval.\n        self._compile_metric_functions = []\n        # List of metric wrappers on output losses.\n        self._output_loss_metrics = None\n\n        if not self.built:\n            # Model is not compilable because\n            # it does not know its number of inputs\n            # and outputs, nor their shapes and names.\n            # We will compile after the first\n            # time the model gets called on training data.\n            return\n        self._is_compiled = True\n\n        # Prepare list of loss functions, same size as model outputs.\n        self.loss_functions = training_utils.prepare_loss_functions(\n            self.loss, self.output_names)\n\n        self._feed_outputs = []\n        self._feed_output_names = []\n        self._feed_output_shapes = []\n        self._feed_loss_fns = []\n\n        # if loss function is None, then this output will be skipped during total\n        # loss calculation and feed targets preparation.\n        self.skip_target_indices = []\n        skip_target_weighing_indices = []\n        for i, loss_function in enumerate(self.loss_functions):\n            if loss_function is None:\n                self.skip_target_indices.append(i)\n                skip_target_weighing_indices.append(i)\n\n        # Prepare output masks.\n        masks = self.compute_mask(self.inputs, mask=None)\n        if masks is None:\n            masks = [None for _ in self.outputs]\n        masks = to_list(masks)\n\n        # Prepare list loss weights, same size of model outputs.\n        self.loss_weights_list = training_utils.prepare_loss_weights(\n            self.output_names, loss_weights)\n\n        # Prepare targets of model.\n        self.targets = []\n        self._feed_targets = []\n        if target_tensors is not None:\n            if isinstance(target_tensors, list):\n                if len(target_tensors) != len(self.outputs):\n                    raise ValueError(\n                        \'When passing a list as `target_tensors`, \'\n                        \'it should have one entry per model output. \'\n                        \'The model has \' + str(len(self.outputs)) +\n                        \' outputs, but you passed target_tensors=\' +\n                        str(target_tensors))\n            elif isinstance(target_tensors, dict):\n                for name in target_tensors:\n                    if name not in self.output_names:\n                        raise ValueError(\'Unknown entry in `target_tensors` \'\n                                         \'dictionary: ""\' + name + \'"". \'\n                                         \'Only expected the following keys: \' +\n                                         str(self.output_names))\n                tmp_target_tensors = []\n                for name in self.output_names:\n                    tmp_target_tensors.append(target_tensors.get(name, None))\n                target_tensors = tmp_target_tensors\n            elif K.is_tensor(target_tensors):\n                if len(self.outputs) != 1:\n                    raise ValueError(\'The model has \' + str(len(self.outputs)) +\n                                     \' outputs, but you passed a single tensor as \'\n                                     \'`target_tensors`. Expected a list or a dict \'\n                                     \'of tensors.\')\n                target_tensors = [target_tensors]\n            else:\n                raise TypeError(\'Expected `target_tensors` to be a tensor, \'\n                                \'a list of tensors, or dict of tensors, but got:\',\n                                target_tensors)\n\n        for i in range(len(self.outputs)):\n            if i in self.skip_target_indices:\n                self.targets.append(None)\n            else:\n                shape = K.int_shape(self.outputs[i])\n                name = self.output_names[i]\n                if target_tensors is not None:\n                    target = target_tensors[i]\n                else:\n                    target = None\n                if target is None or K.is_placeholder(target):\n                    if target is None:\n                        target = K.placeholder(\n                            ndim=len(shape),\n                            name=name + \'_target\',\n                            sparse=K.is_sparse(self.outputs[i]),\n                            dtype=K.dtype(self.outputs[i]))\n                    self._feed_targets.append(target)\n                    self._feed_outputs.append(self.outputs[i])\n                    self._feed_output_names.append(name)\n                    self._feed_output_shapes.append(shape)\n                    self._feed_loss_fns.append(self.loss_functions[i])\n                else:\n                    skip_target_weighing_indices.append(i)\n                self.targets.append(target)\n\n        # Prepare sample weights.\n        self._set_sample_weight_attributes(\n            sample_weight_mode, skip_target_weighing_indices)\n\n        # Save all metric attributes per output of the model.\n        self._cache_output_metric_attributes(metrics, weighted_metrics)\n\n        # Set metric attributes on model.\n        self._set_metric_attributes()\n\n        # Invoke metric functions (unweighted) for all the outputs.\n        self._handle_metrics(\n            self.outputs,\n            targets=self.targets,\n            skip_target_masks=[l is None for l in self.loss_functions],\n            sample_weights=self.sample_weights,\n            masks=masks)\n\n        # Compute total loss.\n        # Used to keep track of the total loss value (stateless).\n        # eg., total_loss = loss_weight_1 * output_1_loss_fn(...) +\n        #                   loss_weight_2 * output_2_loss_fn(...) +\n        #                   layer losses.\n        self.total_loss = self._prepare_total_loss(masks)\n\n        # Functions for train, test and predict will\n        # be compiled lazily when required.\n        # This saves time when the user is not using all functions.\n        self._function_kwargs = kwargs\n\n        self.train_function = None\n        self.test_function = None\n        self.predict_function = None\n\n        # Collected trainable weights, sorted in topological order.\n        trainable_weights = self.trainable_weights\n        self._collected_trainable_weights = trainable_weights\n\n    @property\n    def metrics(self):\n        """"""Returns the model\'s metrics added using `compile`, `add_metric` APIs.""""""\n        metrics = []\n        if self._is_compiled:\n            metrics += self._compile_metric_functions\n        metrics.extend(self._metrics)\n        metrics.extend(_get_metrics_from_layers(self._layers))\n        return metrics\n\n    @property\n    def metrics_names(self):\n        """"""Returns the model\'s display labels for all outputs.""""""\n        metrics_names = [\'loss\']\n        if self._is_compiled:\n            # Add output loss metric names to the metric names list.\n            if len(self.outputs) > 1:\n                metrics_names.extend([\n                    self.output_names[i] + \'_loss\'\n                    for i in range(len(self.outputs))\n                    if i not in self.skip_target_indices\n                ])\n\n            # Add compile metrics/weighted metrics\' names to the metric names list.\n            metrics_names.extend([m.name for m in self._compile_metric_functions])\n\n        # Add metric names from layers.\n        for layer in self.layers:\n            metrics_names += [m.name for m in layer._metrics]\n        metrics_names += [m.name for m in self._metrics]\n        return metrics_names\n\n    def reset_metrics(self):\n        """"""Resets the state of metrics.""""""\n        metrics = self._get_training_eval_metrics()\n        for m in metrics:\n            m.reset_states()\n\n    def _check_trainable_weights_consistency(self):\n        """"""Check trainable weights count consistency.\n\n        This will raise a warning if `trainable_weights` and\n        `_collected_trainable_weights` are inconsistent (i.e. have different\n        number of parameters).\n        Inconsistency will typically arise when one modifies `model.trainable`\n        without calling `model.compile` again.\n        """"""\n        if not hasattr(self, \'_collected_trainable_weights\'):\n            return\n\n        if (len(self.trainable_weights) !=\n                len(self._collected_trainable_weights)):\n            warnings.warn(UserWarning(\n                \'Discrepancy between trainable weights and collected trainable\'\n                \' weights, did you set `model.trainable` without calling\'\n                \' `model.compile` after ?\'))\n\n    def _make_train_function(self):\n        if not hasattr(self, \'train_function\'):\n            raise RuntimeError(\'You must compile your model before using it.\')\n        self._check_trainable_weights_consistency()\n        if self.train_function is None:\n            inputs = (self._feed_inputs +\n                      self._feed_targets +\n                      self._feed_sample_weights)\n            if self._uses_dynamic_learning_phase():\n                inputs += [K.learning_phase()]\n\n            with K.name_scope(\'training\'):\n                with K.name_scope(self.optimizer.__class__.__name__):\n                    training_updates = self.optimizer.get_updates(\n                        params=self._collected_trainable_weights,\n                        loss=self.total_loss)\n                updates = self.updates + training_updates\n\n                metrics = self._get_training_eval_metrics()\n                metrics_tensors = [\n                    m._call_result for m in metrics if hasattr(m, \'_call_result\')\n                ]\n                metrics_updates = []\n                for m in metrics:\n                    metrics_updates.extend(m.updates)\n\n                # Gets loss and metrics. Updates weights at each call.\n                self.train_function = K.function(\n                    inputs,\n                    [self.total_loss] + metrics_tensors,\n                    updates=updates + metrics_updates,\n                    name=\'train_function\',\n                    **self._function_kwargs)\n\n    def _make_test_function(self):\n        if not hasattr(self, \'test_function\'):\n            raise RuntimeError(\'You must compile your model before using it.\')\n        if self.test_function is None:\n            inputs = (self._feed_inputs +\n                      self._feed_targets +\n                      self._feed_sample_weights)\n            if self._uses_dynamic_learning_phase():\n                inputs += [K.learning_phase()]\n\n            metrics = self._get_training_eval_metrics()\n            metrics_tensors = [\n                m._call_result for m in metrics if hasattr(m, \'_call_result\')\n            ]\n\n            metrics_updates = []\n            for m in metrics:\n                metrics_updates.extend(m.updates)\n\n            # Return loss and metrics, no gradient updates.\n            # Does update the network states.\n            self.test_function = K.function(\n                inputs,\n                [self.total_loss] + metrics_tensors,\n                updates=self.state_updates + metrics_updates,\n                name=\'test_function\',\n                **self._function_kwargs)\n\n    def _make_predict_function(self):\n        if not hasattr(self, \'predict_function\'):\n            self.predict_function = None\n        if self.predict_function is None:\n            if self._uses_dynamic_learning_phase():\n                inputs = self._feed_inputs + [K.learning_phase()]\n            else:\n                inputs = self._feed_inputs\n            # Gets network outputs. Does not update weights.\n            # Does update the network states.\n            kwargs = getattr(self, \'_function_kwargs\', {})\n            self.predict_function = K.function(inputs,\n                                               self.outputs,\n                                               updates=self.state_updates,\n                                               name=\'predict_function\',\n                                               **kwargs)\n\n    def _uses_dynamic_learning_phase(self):\n        return (self.uses_learning_phase and\n                not isinstance(K.learning_phase(), int))\n\n    def _set_inputs(self, inputs, outputs=None, training=None):\n        """"""Set model\'s input and output specs based on the input data received.\n\n        This is to be used for Model subclasses, which do not know at instantiation\n        time what their inputs look like.\n\n        # Arguments\n            inputs: Single array, or list of arrays. The arrays could be\n                placeholders, Numpy arrays, or data tensors.\n                - if placeholders: the model is built on top of these\n                  placeholders, and we expect Numpy data to be fed for them\n                  when calling `fit`/etc.\n                - if Numpy data: we create placeholders matching the shape of\n                  the Numpy arrays. We expect Numpy data to be fed for these\n                  placeholders when calling `fit`/etc.\n                - if data tensors: the model is built on top of these tensors.\n                  We do not expect any Numpy data to be provided when calling\n                  `fit`/etc.\n            outputs: Optional output tensors (if already computed by running\n                the model).\n            training: Boolean or None. Only relevant in symbolic mode.\n                Specifies whether to build the model\'s graph in inference\n                mode (False), training mode (True), or using the Keras\n                learning phase (None).\n        """"""\n        if self.__class__.__name__ == \'Sequential\':\n            # Note: we can\'t test whether the model\n            # is `Sequential` via `isinstance`\n            # since `Sequential` depends on `Model`.\n            if isinstance(inputs, list):\n                assert len(inputs) == 1\n                inputs = inputs[0]\n            self.build(input_shape=(None,) + inputs.shape[1:])\n            return\n\n        if self.inputs:\n            raise ValueError(\'Model inputs are already set.\')\n\n        # On-the-fly setting of symbolic model inputs\n        # (either by using the tensor provided,\n        # or by creating a placeholder if Numpy data was provided).\n        self.inputs = []\n        self.input_names = []\n        self._feed_inputs = []\n        self._feed_input_names = []\n        self._feed_input_shapes = []\n        inputs = to_list(inputs, allow_tuple=True)\n\n        for i, v in enumerate(inputs):\n            name = \'input_%d\' % (i + 1)\n            self.input_names.append(name)\n            if isinstance(v, list):\n                v = np.asarray(v)\n                if v.ndim == 1:\n                    v = np.expand_dims(v, 1)\n            if isinstance(v, (np.ndarray)):\n                # We fix the placeholder shape except the batch size.\n                # This is suboptimal, but it is the best we can do with the info\n                # we have. The user should call `model._set_inputs(placeholders)`\n                # to specify custom placeholders if the need arises.\n                shape = (None,) + v.shape[1:]\n                placeholder = K.placeholder(shape=shape, name=name)\n                self.inputs.append(placeholder)\n                self._feed_inputs.append(placeholder)\n                self._feed_input_names.append(name)\n                self._feed_input_shapes.append(shape)\n            else:\n                # Assumed tensor - TODO(fchollet) additional type check?\n                self.inputs.append(v)\n                if K.is_placeholder(v):\n                    self._feed_inputs.append(v)\n                    self._feed_input_names.append(name)\n                    self._feed_input_shapes.append(K.int_shape(v))\n\n        if outputs is None:\n            # Obtain symbolic outputs by calling the model.\n            if self._expects_training_arg:\n                outputs = self.call(unpack_singleton(self.inputs), training=training)\n            else:\n                outputs = self.call(unpack_singleton(self.inputs))\n        outputs = to_list(outputs, allow_tuple=True)\n        self.outputs = outputs\n        self.output_names = [\n            \'output_%d\' % (i + 1) for i in range(len(self.outputs))]\n        self.built = True\n\n    def _standardize_user_data(self, x,\n                               y=None,\n                               sample_weight=None,\n                               class_weight=None,\n                               check_array_lengths=True,\n                               batch_size=None):\n        all_inputs = []\n        if not self.built:\n            # We need to use `x` to set the model inputs.\n            # We type-check that `x` and `y` are either single arrays\n            # or lists of arrays.\n            if isinstance(x, (list, tuple)):\n                if not all(isinstance(v, np.ndarray) or\n                           K.is_tensor(v) for v in x):\n                    raise ValueError(\'Please provide as model inputs \'\n                                     \'either a single \'\n                                     \'array or a list of arrays. \'\n                                     \'You passed: x=\' + str(x))\n                all_inputs += list(x)\n            elif isinstance(x, dict):\n                raise ValueError(\'Please do not pass a dictionary \'\n                                 \'as model inputs.\')\n            else:\n                if not isinstance(x, np.ndarray) and not K.is_tensor(x):\n                    raise ValueError(\'Please provide as model inputs \'\n                                     \'either a single \'\n                                     \'array or a list of arrays. \'\n                                     \'You passed: x=\' + str(x))\n                all_inputs.append(x)\n\n            # Build the model using the retrieved inputs (value or symbolic).\n            # If values, then in symbolic-mode placeholders will be created\n            # to match the value shapes.\n            if not self.inputs:\n                self._set_inputs(x)\n\n        if y is not None:\n            if not self.optimizer:\n                raise RuntimeError(\'You must compile a model before \'\n                                   \'training/testing. \'\n                                   \'Use `model.compile(optimizer, loss)`.\')\n            if not self._is_compiled:\n                # On-the-fly compilation of the model.\n                # We need to use `y` to set the model targets.\n                if isinstance(y, (list, tuple)):\n                    if not all(isinstance(v, np.ndarray) or\n                               K.is_tensor(v) for v in y):\n                        raise ValueError(\'Please provide as model targets \'\n                                         \'either a single \'\n                                         \'array or a list of arrays. \'\n                                         \'You passed: y=\' + str(y))\n                elif isinstance(y, dict):\n                    raise ValueError(\'Please do not pass a dictionary \'\n                                     \'as model targets.\')\n                else:\n                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):\n                        raise ValueError(\'Please provide as model targets \'\n                                         \'either a single \'\n                                         \'array or a list of arrays. \'\n                                         \'You passed: y=\' + str(y))\n                # Typecheck that all inputs are *either* value *or* symbolic.\n                if y is not None:\n                    all_inputs += to_list(y, allow_tuple=True)\n                if any(K.is_tensor(v) for v in all_inputs):\n                    if not all(K.is_tensor(v) for v in all_inputs):\n                        raise ValueError(\'Do not pass inputs that mix Numpy \'\n                                         \'arrays and symbolic tensors. \'\n                                         \'You passed: x=\' + str(x) +\n                                         \'; y=\' + str(y))\n\n                # Handle target tensors if any passed.\n                y = to_list(y, allow_tuple=True)\n                target_tensors = [v for v in y if K.is_tensor(v)]\n                if not target_tensors:\n                    target_tensors = None\n                self.compile(optimizer=self.optimizer,\n                             loss=self.loss,\n                             metrics=self._compile_metrics,\n                             weighted_metrics=self._compile_weighted_metrics,\n                             loss_weights=self.loss_weights,\n                             target_tensors=target_tensors)\n\n        # If `x` and `y` were all symbolic,\n        # then the model should not be fed any inputs and targets.\n        # Note: in this case, `any` and `all` are equivalent since we disallow\n        # mixed symbolic/value inputs.\n        if any(K.is_tensor(v) for v in all_inputs):\n            return [], [], []\n\n        # What follows is input validation and standardization to list format,\n        # in the case where all inputs are value arrays.\n\n        if not self._is_graph_network:\n            # Case: symbolic-mode subclassed network.\n            # Do not do shape validation.\n            feed_input_names = self._feed_input_names\n            feed_input_shapes = None\n        else:\n            # Case: symbolic-mode graph network.\n            # In this case, we run extensive shape validation checks.\n            feed_input_names = self._feed_input_names\n            feed_input_shapes = self._feed_input_shapes\n\n        # Standardize the inputs.\n        x = training_utils.standardize_input_data(\n            x,\n            feed_input_names,\n            feed_input_shapes,\n            check_batch_axis=False,  # Don\'t enforce the batch size.\n            exception_prefix=\'input\')\n\n        if y is not None:\n            if not self._is_graph_network:\n                feed_output_names = self._feed_output_names\n                feed_output_shapes = None\n                # Sample weighting not supported in this case.\n                # TODO: consider supporting it.\n                feed_sample_weight_modes = [None for _ in self.outputs]\n            else:\n                feed_output_names = self._feed_output_names\n                feed_sample_weight_modes = self._feed_sample_weight_modes\n                feed_output_shapes = []\n                for output_shape, loss_fn in zip(self._feed_output_shapes,\n                                                 self._feed_loss_fns):\n                    if ((isinstance(loss_fn, losses.LossFunctionWrapper) and\n                         loss_fn.fn == losses.sparse_categorical_crossentropy)) or (\n                            isinstance(\n                                loss_fn, losses.SparseCategoricalCrossentropy)):\n                        if K.image_data_format() == \'channels_first\' and len(\n                                output_shape) in [4, 5]:\n                            feed_output_shapes.append(\n                                (output_shape[0], 1) + output_shape[2:])\n                        else:\n                            feed_output_shapes.append(output_shape[:-1] + (1,))\n                    elif (not isinstance(loss_fn, losses.Loss) or\n                            (isinstance(loss_fn, losses.LossFunctionWrapper) and\n                             (getattr(losses, loss_fn.fn.__name__, None) is None))):\n                        # If the given loss is not an instance of the `Loss` class\n                        # (custom class) or if the loss function that is wrapped is\n                        # not in the `losses` module, then it is a user-defined loss\n                        # and we make no assumptions about it.\n                        feed_output_shapes.append(None)\n                    else:\n                        feed_output_shapes.append(output_shape)\n\n            # Standardize the outputs.\n            y = training_utils.standardize_input_data(\n                y,\n                feed_output_names,\n                feed_output_shapes,\n                check_batch_axis=False,  # Don\'t enforce the batch size.\n                exception_prefix=\'target\')\n\n            # Generate sample-wise weight values given the `sample_weight` and\n            # `class_weight` arguments.\n            sample_weights = training_utils.standardize_sample_weights(\n                sample_weight, feed_output_names)\n            class_weights = training_utils.standardize_class_weights(\n                class_weight, feed_output_names)\n            sample_weights = [\n                training_utils.standardize_weights(ref, sw, cw, mode)\n                for (ref, sw, cw, mode) in\n                zip(y, sample_weights, class_weights,\n                    feed_sample_weight_modes)\n            ]\n            # Check that all arrays have the same length.\n            if check_array_lengths:\n                training_utils.check_array_length_consistency(x, y, sample_weights)\n            if self._is_graph_network:\n                # Additional checks to avoid users mistakenly\n                # using improper loss fns.\n                training_utils.check_loss_and_target_compatibility(\n                    y, self._feed_loss_fns, feed_output_shapes)\n        else:\n            y = []\n            sample_weights = []\n\n        if self.stateful and batch_size:\n            # Check that for stateful networks, number of samples is a multiple\n            # of the static batch size.\n            if x[0].shape[0] % batch_size != 0:\n                raise ValueError(\'In a stateful network, \'\n                                 \'you should only pass inputs with \'\n                                 \'a number of samples that can be \'\n                                 \'divided by the batch size. Found: \' +\n                                 str(x[0].shape[0]) + \' samples\')\n        return x, y, sample_weights\n\n    def _prepare_total_loss(self, masks=None):\n        """"""Computes total loss from loss functions.\n\n        # Arguments\n            skip_target_indices: A list of indices of model outputs where loss\n                function is None.\n            masks: List of mask values corresponding to each model output.\n\n        # Returns\n            A list of loss weights of python floats.\n        """"""\n        total_loss = None\n        with K.name_scope(\'loss\'):\n            zipped_inputs = zip(self.targets, self.outputs, self.loss_functions,\n                                self.sample_weights, masks, self.loss_weights_list)\n            for i, (y_true, y_pred, loss_fn, sample_weight, mask,\n                    loss_weight) in enumerate(zipped_inputs):\n                if i in self.skip_target_indices:\n                    continue\n                loss_name = self.output_names[i] + \'_loss\'\n                with K.name_scope(loss_name):\n                    if mask is not None:\n                        mask = K.cast(mask, y_pred.dtype)\n                        # Update weights with mask.\n                        if sample_weight is None:\n                            sample_weight = mask\n                        else:\n                            # Update dimensions of weights to match with mask.\n                            mask, _, sample_weight = (\n                                losses_utils.squeeze_or_expand_dimensions(\n                                    mask, None, sample_weight))\n                            sample_weight *= mask\n\n                    output_loss = loss_fn(\n                        y_true, y_pred, sample_weight=sample_weight)\n\n                if len(self.outputs) > 1:\n                    update_ops = self._output_loss_metrics[i].update_state(\n                        output_loss)\n                    with K.control_dependencies(update_ops):  # For TF\n                        self._output_loss_metrics[i].result()\n                if total_loss is None:\n                    total_loss = loss_weight * output_loss\n                else:\n                    total_loss += loss_weight * output_loss\n\n            if total_loss is None:\n                if not self.losses:\n                    raise ValueError(\'The model cannot be compiled \'\n                                     \'because it has no loss to optimize.\')\n                else:\n                    total_loss = 0.\n\n            # Add regularization penalties and other layer-specific losses.\n            for loss_tensor in self.losses:\n                total_loss += loss_tensor\n\n        return K.mean(total_loss)\n\n    def _get_training_eval_metrics(self):\n        """"""Returns all the metrics that are to be reported.\n\n        This includes the output loss metrics, compile metrics/weighted metrics.\n        """"""\n        metrics = []\n        if getattr(self, \'_output_loss_metrics\', None) is not None:\n            metrics.extend(self._output_loss_metrics)\n        if hasattr(self, \'metrics\'):\n            metrics.extend(self.metrics)\n        return metrics\n\n    def _cache_output_metric_attributes(self, metrics, weighted_metrics):\n        """"""Caches metric name and function attributes for every model output.""""""\n        output_shapes = []\n        for output in self.outputs:\n            if output is None:\n                output_shapes.append(None)\n            else:\n                output_shapes.append(list(output.shape))\n        self._per_output_metrics = training_utils.collect_per_output_metric_info(\n            metrics, self.output_names, output_shapes, self.loss_functions)\n        self._per_output_weighted_metrics = (\n            training_utils.collect_per_output_metric_info(\n                weighted_metrics,\n                self.output_names,\n                output_shapes,\n                self.loss_functions,\n                is_weighted=True))\n\n    def _add_unique_metric_name(self, metric_name, output_index):\n        """"""Makes the metric name unique and adds it to the model\'s metric name list.\n\n        If there are multiple outputs for which the metrics are calculated, the\n        metric names have to be made unique by appending an integer.\n\n        # Arguments\n            metric_name: Metric name that corresponds to the metric specified by the\n                user. For example: \'acc\'.\n            output_index: The index of the model output for which the metric name is\n                being added.\n\n        # Returns\n            string, name of the model\'s unique metric name\n        """"""\n        if len(self.output_names) > 1:\n            metric_name = \'%s_%s\' % (self.output_names[output_index], metric_name)\n\n        j = 1\n        base_metric_name = metric_name\n        while metric_name in self.metrics_names:\n            metric_name = \'%s_%d\' % (base_metric_name, j)\n            j += 1\n        return metric_name\n\n    def _set_per_output_metric_attributes(self, metrics_dict, output_index):\n        """"""Sets the metric attributes on the model for the given output.\n\n        # Arguments\n            metrics_dict: A dict with metric names as keys and metric fns as values.\n            output_index: The index of the model output for which the metric\n                attributes are added.\n\n        # Returns\n            Metrics dict updated with unique metric names as keys.\n        """"""\n        updated_metrics_dict = collections.OrderedDict()\n        for metric_name, metric_fn in metrics_dict.items():\n            metric_name = self._add_unique_metric_name(metric_name, output_index)\n\n            # Update the name on the metric class to be the unique generated name.\n            metric_fn.name = metric_name\n            updated_metrics_dict[metric_name] = metric_fn\n            # Keep track of metric function.\n            self._compile_metric_functions.append(metric_fn)\n        return updated_metrics_dict\n\n    def _set_metric_attributes(self):\n        """"""Sets the metric attributes on the model for all the model outputs.""""""\n        updated_per_output_metrics = []\n        updated_per_output_weighted_metrics = []\n        for i in range(len(self.outputs)):\n            if i in self.skip_target_indices:\n                updated_per_output_metrics.append(self._per_output_metrics[i])\n                updated_per_output_weighted_metrics.append(\n                    self._per_output_weighted_metrics[i])\n                continue\n            updated_per_output_metrics.append(\n                self._set_per_output_metric_attributes(\n                    self._per_output_metrics[i], i))\n            updated_per_output_weighted_metrics.append(\n                self._set_per_output_metric_attributes(\n                    self._per_output_weighted_metrics[i], i))\n\n        # Create a metric wrapper for each output loss. This computes mean of an\n        # output loss across mini-batches (irrespective of how we reduce within a\n        # batch).\n        if len(self.outputs) > 1:\n            self._output_loss_metrics = [\n                metrics_module.Mean(name=self.output_names[i] + \'_loss\')\n                for i in range(len(self.loss_functions))\n            ]\n\n        self._per_output_metrics = updated_per_output_metrics\n        self._per_output_weighted_metrics = updated_per_output_weighted_metrics\n\n    def _handle_per_output_metrics(self,\n                                   metrics_dict,\n                                   y_true,\n                                   y_pred,\n                                   mask,\n                                   weights=None):\n        """"""Calls metric functions for a single output.\n\n        # Arguments\n            metrics_dict: A dict with metric names as keys and metric fns as values.\n            y_true: Target output.\n            y_pred: Predicted output.\n            mask: Computed mask value for the current output.\n            weights: Weights to be applied on the current output.\n        """"""\n\n        for metric_name, metric_fn in metrics_dict.items():\n            with K.name_scope(metric_name):\n                training_utils.call_metric_function(\n                    metric_fn, y_true, y_pred, weights=weights, mask=mask)\n\n    def _handle_metrics(self,\n                        outputs,\n                        targets=None,\n                        skip_target_masks=None,\n                        sample_weights=None,\n                        masks=None):\n        """"""Handles calling metric functions.\n\n        # Arguments\n            outputs: List of outputs (predictions).\n            targets: List of targets.\n            skip_target_masks: Optional. List of boolean for whether the\n                corresponding target should be ignored or not.\n            sample_weights: Optional list of sample weight arrays.\n            masks: List of computed output mask values.\n        """"""\n        skip_target_masks = skip_target_masks or [False] * len(outputs)\n        with K.name_scope(\'metrics\'):\n            # Invoke all metrics added using `compile`.\n            for i in range(len(outputs)):\n                if skip_target_masks[i]:\n                    continue\n                output = outputs[i] if outputs else None\n                target = targets[i] if targets else None\n                output_mask = masks[i] if masks else None\n\n                self._handle_per_output_metrics(\n                    self._per_output_metrics[i], target, output, output_mask)\n                self._handle_per_output_metrics(\n                    self._per_output_weighted_metrics[i],\n                    target,\n                    output,\n                    output_mask,\n                    weights=sample_weights[i] if sample_weights else None)\n\n    def _get_callback_model(self):\n        """"""Returns the Callback Model for this Model.""""""\n        if hasattr(self, \'callback_model\') and self.callback_model:\n            return self.callback_model\n        return self\n\n    def _validate_or_infer_batch_size(self, batch_size, steps, x):\n        """"""Validates that the `batch_size` provided is consistent with InputLayer.\n\n        It\'s possible that the user specified a static batch size in their\n        InputLayer. If so, this method checks the provided `batch_size` and `x`\n        arguments are consistent with this static batch size. Also, if\n        `batch_size` is `None`, this method will attempt to infer the batch size\n        from the static batch size of the InputLayer. Lastly, ValueError will be\n        raised if `x` is a generator or `Sequence` instance and `batch_size` is\n        specified as we expect users to provide batched datasets.\n\n        # Arguments\n            batch_size: The batch_size provided as an argument to\n                fit/evaluate/predict.\n            steps: The steps provided as an argument to fit/evaluate/predict.\n            x: The data passed as `x` to fit/evaluate/predict.\n\n        # Returns\n            The validated batch_size, auto-inferred from the first layer if\n            not provided.\n\n        # Raises\n            ValueError: if a batch size is specified and a generator/Sequence\n                is passed, or if the specified batch size does not match the\n                exepected size defined in the Input Layer.\n        """"""\n        if batch_size is not None and training_utils.is_generator_or_sequence(x):\n            raise ValueError(\'The `batch_size` argument must not be specified when\'\n                             \' using a generator or Sequence as an input.\')\n\n        layers = super(Model, self).layers  # Avoids the override in Sequential.\n        if layers:\n            first_layer = layers[0]\n            static_batch_size = training_utils.get_static_batch_size(first_layer)\n            if static_batch_size is not None:\n\n                # Check `batch_size` argument is consistent with InputLayer.\n                if batch_size is not None and batch_size != static_batch_size:\n                    raise ValueError(\'The `batch_size` argument value {} is \'\n                                     \'incompatible with the specified batch \'\n                                     \'size of your Input Layer: {}\'\n                                     .format(batch_size, static_batch_size))\n\n                # Set inferred batch size from the InputLayer.\n                if steps is None:\n                    batch_size = static_batch_size\n\n        if batch_size is None and steps is None:\n            # Backwards compatibility\n            batch_size = 32\n        return batch_size\n\n    def _set_sample_weight_attributes(self, sample_weight_mode,\n                                      skip_target_weighing_indices):\n        """"""Sets sample weight related attributes on the model.""""""\n        sample_weights, sample_weight_modes = training_utils.prepare_sample_weights(\n            self.output_names, sample_weight_mode, skip_target_weighing_indices)\n        self.sample_weights = sample_weights\n        self.sample_weight_modes = sample_weight_modes\n        self._feed_sample_weight_modes = [\n            sample_weight_modes[i]\n            for i in range(len(self.outputs))\n            if i not in skip_target_weighing_indices\n        ]\n        self._feed_sample_weights = [\n            sample_weights[i]\n            for i in range(len(sample_weights))\n            if i not in skip_target_weighing_indices\n        ]\n\n    def fit(self,\n            x=None,\n            y=None,\n            batch_size=None,\n            epochs=1,\n            verbose=1,\n            callbacks=None,\n            validation_split=0.,\n            validation_data=None,\n            shuffle=True,\n            class_weight=None,\n            sample_weight=None,\n            initial_epoch=0,\n            steps_per_epoch=None,\n            validation_steps=None,\n            validation_freq=1,\n            max_queue_size=10,\n            workers=1,\n            use_multiprocessing=False,\n            **kwargs):\n        """"""Trains the model for a fixed number of epochs (iterations on a dataset).\n\n        # Arguments\n            x: Input data. It could be:\n                - A Numpy array (or array-like), or a list of arrays\n                  (in case the model has multiple inputs).\n                - A dict mapping input names to the corresponding\n                  array/tensors, if the model has named inputs.\n                - A generator or `keras.utils.Sequence` returning\n                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n                - None (default) if feeding from framework-native\n                  tensors (e.g. TensorFlow data tensors).\n            y: Target data. Like the input data `x`,\n                it could be either Numpy array(s), framework-native tensor(s),\n                list of Numpy arrays (if the model has multiple outputs) or\n                None (default) if feeding from framework-native tensors\n                (e.g. TensorFlow data tensors).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                If `x` is a generator, or `keras.utils.Sequence` instance,\n                `y` should not be specified (since targets will be obtained\n                from `x`).\n            batch_size: Integer or `None`.\n                Number of samples per gradient update.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` if your data is in the\n                form of symbolic tensors, generators, or `Sequence` instances\n                (since they generate batches).\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire `x` and `y`\n                data provided.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as ""final epoch"".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: Integer. 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training and validation\n                (if ).\n                See [callbacks](/callbacks).\n            validation_split: Float between 0 and 1.\n                Fraction of the training data to be used as validation data.\n                The model will set apart this fraction of the training data,\n                will not train on it, and will evaluate\n                the loss and any model metrics\n                on this data at the end of each epoch.\n                The validation data is selected from the last samples\n                in the `x` and `y` data provided, before shuffling.\n                This argument is not supported when `x` is a generator or\n                `Sequence` instance.\n            validation_data: Data on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n                `validation_data` will override `validation_split`.\n                `validation_data` could be:\n                    - tuple `(x_val, y_val)` of Numpy arrays or tensors\n                    - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n                    - dataset or a dataset iterator\n                For the first two cases, `batch_size` must be provided.\n                For the last case, `validation_steps` must be provided.\n            shuffle: Boolean (whether to shuffle the training data\n                before each epoch) or str (for \'batch\').\n                \'batch\' is a special option for dealing with the\n                limitations of HDF5 data; it shuffles in batch-sized chunks.\n                Has no effect when `steps_per_epoch` is not `None`.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only).\n                This can be useful to tell the model to\n                ""pay more attention"" to samples from\n                an under-represented class.\n            sample_weight: Optional Numpy array of weights for\n                the training samples, used for weighting the loss function\n                (during training only). You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=""temporal""` in `compile()`. This argument\n                is not supported when `x` generator, or `Sequence` instance,\n                instead provide the sample_weights as the third element of `x`.\n            initial_epoch: Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n            steps_per_epoch: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. When training with input tensors such as\n                TensorFlow data tensors, the default `None` is equal to\n                the number of samples in your dataset divided by\n                the batch size, or 1 if that cannot be determined.\n            validation_steps: Only relevant if `steps_per_epoch`\n                is specified. Total number of steps (batches of samples)\n                to validate before stopping.\n            validation_steps: Only relevant if `validation_data` is provided\n                and is a generator. Total number of steps (batches of samples)\n                to draw before stopping when performing validation at the end\n                of every epoch.\n            validation_freq: Only relevant if validation data is provided. Integer\n                or list/tuple/set. If an integer, specifies how many training\n                epochs to run before a new validation run is performed, e.g.\n                `validation_freq=2` runs validation every 2 epochs. If a list,\n                tuple, or set, specifies the epochs on which to run validation,\n                e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n                of the 1st, 2nd, and 10th epochs.\n            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n                input only. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Used for generator or `keras.utils.Sequence` input\n                only. Maximum number of processes to spin up\n                when using process-based threading. If unspecified, `workers`\n                will default to 1. If 0, will execute the generator on the main\n                thread.\n            use_multiprocessing: Boolean. Used for generator or\n                `keras.utils.Sequence` input only. If `True`, use process-based\n                threading. If unspecified, `use_multiprocessing` will default to\n                `False`. Note that because this implementation relies on\n                multiprocessing, you should not pass non-picklable arguments to\n                the generator as they can\'t be passed easily to children processes.\n            **kwargs: Used for backwards compatibility.\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            RuntimeError: If the model was never compiled.\n            ValueError: In case of mismatch between the provided input data\n                and what the model expects.\n        """"""\n        # Legacy support\n        if \'nb_epoch\' in kwargs:\n            warnings.warn(\'The `nb_epoch` argument in `fit` \'\n                          \'has been renamed `epochs`.\', stacklevel=2)\n            epochs = kwargs.pop(\'nb_epoch\')\n        if kwargs:\n            raise TypeError(\'Unrecognized keyword arguments: \' + str(kwargs))\n\n        if x is None and y is None and steps_per_epoch is None:\n            raise ValueError(\'If fitting from data tensors, \'\n                             \'you should specify the `steps_per_epoch` \'\n                             \'argument.\')\n\n        batch_size = self._validate_or_infer_batch_size(\n            batch_size, steps_per_epoch, x)\n\n        # Case 1: generator-like. Input is Python generator,\n        # or Sequence object, or iterator.\n        if training_utils.is_generator_or_sequence(x):\n            training_utils.check_generator_arguments(\n                y, sample_weight, validation_split=validation_split)\n            return self.fit_generator(\n                x,\n                steps_per_epoch=steps_per_epoch,\n                epochs=epochs,\n                verbose=verbose,\n                callbacks=callbacks,\n                validation_data=validation_data,\n                validation_steps=validation_steps,\n                validation_freq=validation_freq,\n                class_weight=class_weight,\n                max_queue_size=max_queue_size,\n                workers=workers,\n                use_multiprocessing=use_multiprocessing,\n                shuffle=shuffle,\n                initial_epoch=initial_epoch)\n\n        # Case 2: Symbolic tensors or Numpy array-like.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight,\n            batch_size=batch_size)\n\n        # Prepare validation data.\n        do_validation = False\n        if validation_data:\n            do_validation = True\n            if len(validation_data) == 2:\n                val_x, val_y = validation_data\n                val_sample_weight = None\n            elif len(validation_data) == 3:\n                val_x, val_y, val_sample_weight = validation_data\n            else:\n                raise ValueError(\'When passing validation_data, \'\n                                 \'it must contain 2 (x_val, y_val) \'\n                                 \'or 3 (x_val, y_val, val_sample_weights) \'\n                                 \'items, however it contains %d items\' %\n                                 len(validation_data))\n\n            val_x, val_y, val_sample_weights = self._standardize_user_data(\n                val_x, val_y,\n                sample_weight=val_sample_weight,\n                batch_size=batch_size)\n            if self._uses_dynamic_learning_phase():\n                val_inputs = val_x + val_y + val_sample_weights + [0]\n            else:\n                val_inputs = val_x + val_y + val_sample_weights\n\n        elif validation_split and 0. < validation_split < 1.:\n            if any(K.is_tensor(t) for t in x):\n                raise ValueError(\n                    \'If your data is in the form of symbolic tensors, \'\n                    \'you cannot use `validation_split`.\')\n            do_validation = True\n            if hasattr(x[0], \'shape\'):\n                split_at = int(int(x[0].shape[0]) * (1. - validation_split))\n            else:\n                split_at = int(len(x[0]) * (1. - validation_split))\n            x, val_x = (slice_arrays(x, 0, split_at),\n                        slice_arrays(x, split_at))\n            y, val_y = (slice_arrays(y, 0, split_at),\n                        slice_arrays(y, split_at))\n            sample_weights, val_sample_weights = (\n                slice_arrays(sample_weights, 0, split_at),\n                slice_arrays(sample_weights, split_at))\n            if self._uses_dynamic_learning_phase():\n                val_inputs = val_x + val_y + val_sample_weights + [0]\n            else:\n                val_inputs = val_x + val_y + val_sample_weights\n\n        elif validation_steps:\n            do_validation = True\n            if self._uses_dynamic_learning_phase():\n                val_inputs = [0]\n\n        # Prepare input arrays and training function.\n        if self._uses_dynamic_learning_phase():\n            fit_inputs = x + y + sample_weights + [1]\n        else:\n            fit_inputs = x + y + sample_weights\n        self._make_train_function()\n        fit_function = self.train_function\n\n        # Prepare display labels.\n        out_labels = self.metrics_names\n\n        if do_validation:\n            self._make_test_function()\n            val_function = self.test_function\n        else:\n            val_function = None\n            val_inputs = []\n\n        # Delegate logic to `fit_loop`.\n        return training_arrays.fit_loop(self, fit_function, fit_inputs,\n                                        out_labels=out_labels,\n                                        batch_size=batch_size,\n                                        epochs=epochs,\n                                        verbose=verbose,\n                                        callbacks=callbacks,\n                                        val_function=val_function,\n                                        val_inputs=val_inputs,\n                                        shuffle=shuffle,\n                                        initial_epoch=initial_epoch,\n                                        steps_per_epoch=steps_per_epoch,\n                                        validation_steps=validation_steps,\n                                        validation_freq=validation_freq)\n\n    def evaluate(self,\n                 x=None,\n                 y=None,\n                 batch_size=None,\n                 verbose=1,\n                 sample_weight=None,\n                 steps=None,\n                 callbacks=None,\n                 max_queue_size=10,\n                 workers=1,\n                 use_multiprocessing=False):\n        """"""Returns the loss value & metrics values for the model in test mode.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: Input data. It could be:\n                - A Numpy array (or array-like), or a list of arrays\n                  (in case the model has multiple inputs).\n                - A dict mapping input names to the corresponding\n                  array/tensors, if the model has named inputs.\n                - A generator or `keras.utils.Sequence` returning\n                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n                - None (default) if feeding from framework-native\n                  tensors (e.g. TensorFlow data tensors).\n            y: Target data. Like the input data `x`,\n                it could be either Numpy array(s), framework-native tensor(s),\n                list of Numpy arrays (if the model has multiple outputs) or\n                None (default) if feeding from framework-native tensors\n                (e.g. TensorFlow data tensors).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                If `x` is a generator, or `keras.utils.Sequence` instance,\n                `y` should not be specified (since targets will be obtained\n                from `x`).\n            batch_size: Integer or `None`.\n                Number of samples per evaluation step.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` if your data is in the\n                form of symbolic tensors, generators, or\n                `keras.utils.Sequence` instances (since they generate batches).\n            verbose: 0 or 1. Verbosity mode.\n                0 = silent, 1 = progress bar.\n            sample_weight: Optional Numpy array of weights for\n                the test samples, used for weighting the loss function.\n                You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=""temporal""` in `compile()`.\n            steps: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring the evaluation round finished.\n                Ignored with the default value of `None`.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during evaluation.\n                See [callbacks](/callbacks).\n            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n                input only. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Used for generator or `keras.utils.Sequence` input\n                only. Maximum number of processes to spin up when using\n                process-based threading. If unspecified, `workers` will default\n                to 1. If 0, will execute the generator on the main thread.\n            use_multiprocessing: Boolean. Used for generator or\n                `keras.utils.Sequence` input only. If `True`, use process-based\n                threading. If unspecified, `use_multiprocessing` will default to\n                `False`. Note that because this implementation relies on\n                multiprocessing, you should not pass non-picklable arguments to\n                the generator as they can\'t be passed easily to children processes.\n\n        # Raises\n            ValueError: in case of invalid arguments.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        """"""\n\n        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\n\n        # Case 1: generator-like. Input is Python generator, or Sequence object.\n        if training_utils.is_generator_or_sequence(x):\n            training_utils.check_generator_arguments(y, sample_weight)\n            return self.evaluate_generator(\n                x,\n                steps=steps,\n                verbose=verbose,\n                callbacks=callbacks,\n                max_queue_size=max_queue_size,\n                workers=workers,\n                use_multiprocessing=use_multiprocessing)\n\n        # Case 2: Symbolic tensors or Numpy array-like.\n        if x is None and y is None and steps is None:\n            raise ValueError(\'If evaluating from data tensors, \'\n                             \'you should specify the `steps` \'\n                             \'argument.\')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            batch_size=batch_size)\n        # Prepare inputs, delegate logic to `test_loop`.\n        if self._uses_dynamic_learning_phase():\n            ins = x + y + sample_weights + [0]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        f = self.test_function\n        return training_arrays.test_loop(self, f, ins,\n                                         batch_size=batch_size,\n                                         verbose=verbose,\n                                         steps=steps,\n                                         callbacks=callbacks)\n\n    def predict(self, x,\n                batch_size=None,\n                verbose=0,\n                steps=None,\n                callbacks=None,\n                max_queue_size=10,\n                workers=1,\n                use_multiprocessing=False):\n        """"""Generates output predictions for the input samples.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: Input data. It could be:\n                - A Numpy array (or array-like), or a list of arrays\n                  (in case the model has multiple inputs).\n                - A dict mapping input names to the corresponding\n                  array/tensors, if the model has named inputs.\n                - A generator or `keras.utils.Sequence` returning\n                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n                - None (default) if feeding from framework-native\n                  tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer or `None`.\n                Number of samples to be predicted at once.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` if your data is in the\n                form of symbolic tensors, generators, or\n                `keras.utils.Sequence` instances (since they generate batches).\n            verbose: Verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during prediction.\n                See [callbacks](/callbacks).\n            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n                input only. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Used for generator or `keras.utils.Sequence` input\n                only. Maximum number of processes to spin up when using\n                process-based threading. If unspecified, `workers` will default\n                to 1. If 0, will execute the generator on the main thread.\n            use_multiprocessing: Boolean. Used for generator or\n                `keras.utils.Sequence` input only. If `True`, use process-based\n                threading. If unspecified, `use_multiprocessing` will default to\n                `False`. Note that because this implementation relies on\n                multiprocessing, you should not pass non-picklable arguments to\n                the generator as they can\'t be passed easily to children processes.\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case of mismatch between the provided\n                input data and the model\'s expectations,\n                or in case a stateful model receives a number of samples\n                that is not a multiple of the batch size.\n        """"""\n\n        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\n\n        # Case 1: generator-like. Input is Python generator, or Sequence object.\n        if training_utils.is_generator_or_sequence(x):\n            return self.predict_generator(\n                x,\n                steps=steps,\n                verbose=verbose,\n                callbacks=callbacks,\n                max_queue_size=max_queue_size,\n                workers=workers,\n                use_multiprocessing=use_multiprocessing)\n\n        if x is None and steps is None:\n            raise ValueError(\'If predicting from data tensors, \'\n                             \'you should specify the `steps` \'\n                             \'argument.\')\n\n        # Case 2: Symbolic tensors or Numpy array-like.\n        x, _, _ = self._standardize_user_data(x)\n        if self.stateful:\n            if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n                raise ValueError(\'In a stateful network, \'\n                                 \'you should only pass inputs with \'\n                                 \'a number of samples that can be \'\n                                 \'divided by the batch size. Found: \' +\n                                 str(x[0].shape[0]) + \' samples. \'\n                                 \'Batch size: \' + str(batch_size) + \'.\')\n\n        # Prepare inputs, delegate logic to `predict_loop`.\n        if self._uses_dynamic_learning_phase():\n            ins = x + [0]\n        else:\n            ins = x\n        self._make_predict_function()\n        f = self.predict_function\n        return training_arrays.predict_loop(self, f, ins,\n                                            batch_size=batch_size,\n                                            verbose=verbose,\n                                            steps=steps,\n                                            callbacks=callbacks)\n\n    def train_on_batch(self, x, y,\n                       sample_weight=None,\n                       class_weight=None,\n                       reset_metrics=True):\n        """"""Runs a single gradient update on a single batch of data.\n\n        # Arguments\n            x: Numpy array of training data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model\'s loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=""temporal"" in compile().\n            class_weight: Optional dictionary mapping\n                class indices (integers) to\n                a weight (float) to apply to the model\'s loss for the samples\n                from this class during training.\n                This can be useful to tell the model to ""pay more attention"" to\n                samples from an under-represented class.\n            reset_metrics: If `True`, the metrics returned will be only for this\n                batch. If `False`, the metrics will be statefully accumulated across\n                batches.\n\n        # Returns\n            Scalar training loss\n            (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        """"""\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight)\n        if self._uses_dynamic_learning_phase():\n            ins = x + y + sample_weights + [1]\n        else:\n            ins = x + y + sample_weights\n        self._make_train_function()\n        outputs = self.train_function(ins)\n\n        if reset_metrics:\n            self.reset_metrics()\n        return unpack_singleton(outputs)\n\n    def test_on_batch(self, x, y, sample_weight=None, reset_metrics=True):\n        """"""Test the model on a single batch of samples.\n\n        # Arguments\n            x: Numpy array of test data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model\'s loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=""temporal"" in compile().\n            reset_metrics: If `True`, the metrics returned will be only for this\n                batch. If `False`, the metrics will be statefully accumulated across\n                batches.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        """"""\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight)\n        if self._uses_dynamic_learning_phase():\n            ins = x + y + sample_weights + [0]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        outputs = self.test_function(ins)\n\n        if reset_metrics:\n            self.reset_metrics()\n        return unpack_singleton(outputs)\n\n    def predict_on_batch(self, x):\n        """"""Returns predictions for a single batch of samples.\n\n        # Arguments\n            x: Input samples, as a Numpy array.\n\n        # Returns\n            Numpy array(s) of predictions.\n        """"""\n        x, _, _ = self._standardize_user_data(x)\n        if self._uses_dynamic_learning_phase():\n            ins = x + [0]\n        else:\n            ins = x\n        self._make_predict_function()\n        outputs = self.predict_function(ins)\n        return unpack_singleton(outputs)\n\n    @interfaces.legacy_generator_methods_support\n    def fit_generator(self, generator,\n                      steps_per_epoch=None,\n                      epochs=1,\n                      verbose=1,\n                      callbacks=None,\n                      validation_data=None,\n                      validation_steps=None,\n                      validation_freq=1,\n                      class_weight=None,\n                      max_queue_size=10,\n                      workers=1,\n                      use_multiprocessing=False,\n                      shuffle=True,\n                      initial_epoch=0):\n        """"""Trains the model on data generated batch-by-batch by a Python generator\n        (or an instance of `Sequence`).\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        The use of `keras.utils.Sequence` guarantees the ordering\n        and guarantees the single use of every input per epoch when\n        using `use_multiprocessing=True`.\n\n        # Arguments\n            generator: A generator or an instance of `Sequence`\n                (`keras.utils.Sequence`) object in order to avoid\n                duplicate data when using multiprocessing.\n                The output of the generator must be either\n                - a tuple `(inputs, targets)`\n                - a tuple `(inputs, targets, sample_weights)`.\n                This tuple (a single output of the generator) makes a single\n                batch. Therefore, all arrays in this tuple must have the same\n                length (equal to the size of this batch). Different batches may\n                have different sizes. For example, the last batch of the epoch\n                is commonly smaller than the others, if the size of the dataset\n                is not divisible by the batch size.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `steps_per_epoch`\n                batches have been seen by the model.\n            steps_per_epoch: Integer.\n                Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to `ceil(num_samples / batch_size)`\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire data provided,\n                as defined by `steps_per_epoch`.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as ""final epoch"".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: Integer. 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See [callbacks](/callbacks).\n            validation_data: This can be either\n                - a generator or a `Sequence` object for the validation data\n                - tuple `(x_val, y_val)`\n                - tuple `(x_val, y_val, val_sample_weights)`\n                on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n            validation_steps: Only relevant if `validation_data`\n                is a generator. Total number of steps (batches of samples)\n                to yield from `validation_data` generator before stopping\n                at the end of every epoch. It should typically\n                be equal to the number of samples of your\n                validation dataset divided by the batch size.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(validation_data)` as a number of steps.\n            validation_freq: Only relevant if validation data is provided. Integer\n                or `collections.Container` instance (e.g. list, tuple, etc.). If an\n                integer, specifies how many training epochs to run before a new\n                validation run is performed, e.g. `validation_freq=2` runs\n                validation every 2 epochs. If a Container, specifies the epochs on\n                which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n                validation at the end of the 1st, 2nd, and 10th epochs.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only). This can be useful to tell the model to\n                ""pay more attention"" to samples\n                from an under-represented class.\n            max_queue_size: Integer. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Maximum number of processes to spin up\n                when using process-based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: Boolean.\n                If `True`, use process-based threading.\n                If unspecified, `use_multiprocessing` will default to `False`.\n                Note that because this implementation\n                relies on multiprocessing,\n                you should not pass non-picklable arguments to the generator\n                as they can\'t be passed easily to children processes.\n            shuffle: Boolean. Whether to shuffle the order of the batches at\n                the beginning of each epoch. Only used with instances\n                of `Sequence` (`keras.utils.Sequence`).\n                Has no effect when `steps_per_epoch` is not `None`.\n            initial_epoch: Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            ValueError: In case the generator yields data in an invalid format.\n\n        # Example\n\n        ```python\n        def generate_arrays_from_file(path):\n            while True:\n                with open(path) as f:\n                    for line in f:\n                        # create numpy arrays of input data\n                        # and labels, from each line in the file\n                        x1, x2, y = process_line(line)\n                        yield ({\'input_1\': x1, \'input_2\': x2}, {\'output\': y})\n\n        model.fit_generator(generate_arrays_from_file(\'/my_file.txt\'),\n                            steps_per_epoch=10000, epochs=10)\n        ```\n        """"""\n        return training_generator.fit_generator(\n            self, generator,\n            steps_per_epoch=steps_per_epoch,\n            epochs=epochs,\n            verbose=verbose,\n            callbacks=callbacks,\n            validation_data=validation_data,\n            validation_steps=validation_steps,\n            validation_freq=validation_freq,\n            class_weight=class_weight,\n            max_queue_size=max_queue_size,\n            workers=workers,\n            use_multiprocessing=use_multiprocessing,\n            shuffle=shuffle,\n            initial_epoch=initial_epoch)\n\n    @interfaces.legacy_generator_methods_support\n    def evaluate_generator(self, generator,\n                           steps=None,\n                           callbacks=None,\n                           max_queue_size=10,\n                           workers=1,\n                           use_multiprocessing=False,\n                           verbose=0):\n        """"""Evaluates the model on a data generator.\n\n        The generator should return the same kind of data\n        as accepted by `test_on_batch`.\n\n        # Arguments\n            generator: Generator yielding tuples (inputs, targets)\n                or (inputs, targets, sample_weights)\n                or an instance of Sequence (keras.utils.Sequence)\n                object in order to avoid duplicate data\n                when using multiprocessing.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during evaluation.\n                See [callbacks](/callbacks).\n            max_queue_size: maximum size for the generator queue\n            workers: Integer. Maximum number of processes to spin up\n                when using process based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: if True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can\'t be passed\n                easily to children processes.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        """"""\n        return training_generator.evaluate_generator(\n            self, generator,\n            steps=steps,\n            callbacks=callbacks,\n            max_queue_size=max_queue_size,\n            workers=workers,\n            use_multiprocessing=use_multiprocessing,\n            verbose=verbose)\n\n    @interfaces.legacy_generator_methods_support\n    def predict_generator(self, generator,\n                          steps=None,\n                          callbacks=None,\n                          max_queue_size=10,\n                          workers=1,\n                          use_multiprocessing=False,\n                          verbose=0):\n        """"""Generates predictions for the input samples from a data generator.\n\n        The generator should return the same kind of data as accepted by\n        `predict_on_batch`.\n\n        # Arguments\n            generator: Generator yielding batches of input samples\n                or an instance of Sequence (keras.utils.Sequence)\n                object in order to avoid duplicate data\n                when using multiprocessing.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during prediction.\n                See [callbacks](/callbacks).\n            max_queue_size: Maximum size for the generator queue.\n            workers: Integer. Maximum number of processes to spin up\n                when using process based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: If `True`, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can\'t be passed\n                easily to children processes.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        """"""\n        return training_generator.predict_generator(\n            self, generator,\n            steps=steps,\n            callbacks=callbacks,\n            max_queue_size=max_queue_size,\n            workers=workers,\n            use_multiprocessing=use_multiprocessing,\n            verbose=verbose)\n\n\ndef _get_metrics_from_layers(layers):\n    """"""Returns list of metrics from the given layers.\n    This will not include the `compile` metrics of a model layer.\n\n    # Arguments\n        layers: List of layers.\n\n    # Returns\n        List of metrics.\n    """"""\n    metrics = []\n    for layer in layers:\n        if isinstance(layer, Model):\n            # We cannot call \'metrics\' on the model because we do not want to\n            # include the metrics that were added in compile API of a nested model.\n            metrics.extend(layer._metrics)\n            metrics.extend(_get_metrics_from_layers(layer.layers))\n        else:\n            metrics.extend(layer.metrics)\n    return metrics\n'"
keras/engine/training_arrays.py,0,"b'""""""Part of the training engine related to plain array data (e.g. Numpy).\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom scipy.sparse import issparse\n\nfrom .training_utils import batch_shuffle\nfrom .training_utils import check_num_samples\nfrom .training_utils import make_batches\nfrom .training_utils import should_run_validation\nfrom .. import backend as K\nfrom .. import callbacks as cbks\nfrom ..utils.generic_utils import Progbar\nfrom ..utils.generic_utils import slice_arrays\nfrom ..utils.generic_utils import to_list\nfrom ..utils.generic_utils import unpack_singleton\n\n\ndef fit_loop(model, fit_function, fit_inputs,\n             out_labels=None,\n             batch_size=None,\n             epochs=100,\n             verbose=1,\n             callbacks=None,\n             val_function=None,\n             val_inputs=None,\n             shuffle=True,\n             initial_epoch=0,\n             steps_per_epoch=None,\n             validation_steps=None,\n             validation_freq=1):\n    """"""Abstract fit function for `fit_function(fit_inputs)`.\n\n    Assumes that fit_function returns a list, labeled by out_labels.\n\n    # Arguments\n        model: Keras model instance.\n        fit_function: Keras function returning a list of tensors\n        fit_inputs: List of tensors to be fed to `fit_function`\n        out_labels: List of strings, display names of\n            the outputs of `fit_function`\n        batch_size: Integer batch size or None if unknown.\n        epochs: Number of times to iterate over the data\n        verbose: Verbosity mode, 0, 1 or 2\n        callbacks: List of callbacks to be called during training and validation\n            (if `val_function` and `val_inputs` are not `None`).\n        val_function: Keras function to call for validation\n        val_inputs: List of tensors to be fed to `val_function`\n        shuffle: Whether to shuffle the data at the beginning of each epoch\n        initial_epoch: Epoch at which to start training\n            (useful for resuming a previous training run)\n        steps_per_epoch: Total number of steps (batches of samples)\n            before declaring one epoch finished and starting the\n            next epoch. Ignored with the default value of `None`.\n        validation_steps: Number of steps to run validation for\n            (only if doing validation from data tensors).\n            Ignored with the default value of `None`.\n        validation_freq: Only relevant if validation data is provided. Integer\n            or list/tuple/set. If an integer, specifies how many training\n            epochs to run before a new validation run is performed, e.g.\n            validation_freq=2` runs validation every 2 epochs. If a list,\n            tuple, or set, specifies the epochs on which to run validation,\n            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n            of the 1st, 2nd, and 10th epochs.\n\n    # Returns\n        `History` object.\n    """"""\n    do_validation = False\n    if val_function and val_inputs:\n        do_validation = True\n        if (verbose and fit_inputs and\n           hasattr(fit_inputs[0], \'shape\') and hasattr(val_inputs[0], \'shape\')):\n            print(\'Train on %d samples, validate on %d samples\' %\n                  (fit_inputs[0].shape[0], val_inputs[0].shape[0]))\n    if validation_steps:\n        do_validation = True\n        if steps_per_epoch is None:\n            raise ValueError(\'Can only use `validation_steps` \'\n                             \'when doing step-wise \'\n                             \'training, i.e. `steps_per_epoch` \'\n                             \'must be set.\')\n    elif do_validation:\n        if steps_per_epoch:\n            raise ValueError(\'Must specify `validation_steps` \'\n                             \'to perform validation \'\n                             \'when doing step-wise training.\')\n\n    num_train_samples = check_num_samples(fit_inputs,\n                                          batch_size=batch_size,\n                                          steps=steps_per_epoch,\n                                          steps_name=\'steps_per_epoch\')\n    if num_train_samples is not None:\n        index_array = np.arange(num_train_samples)\n\n    model.history = cbks.History()\n    _callbacks = [cbks.BaseLogger(stateful_metrics=model.metrics_names[1:])]\n    if verbose:\n        if steps_per_epoch is not None:\n            count_mode = \'steps\'\n        else:\n            count_mode = \'samples\'\n        _callbacks.append(\n            cbks.ProgbarLogger(count_mode, stateful_metrics=model.metrics_names[1:]))\n    _callbacks += (callbacks or []) + [model.history]\n    callbacks = cbks.CallbackList(_callbacks)\n    out_labels = out_labels or []\n\n    # it\'s possible to callback a different model than itself\n    # (used by Sequential models)\n    callback_model = model._get_callback_model()\n    callback_metrics = list(model.metrics_names)\n    if do_validation:\n        callback_metrics += [\'val_\' + n for n in model.metrics_names]\n\n    callbacks.set_model(callback_model)\n    callbacks.set_params({\n        \'batch_size\': batch_size,\n        \'epochs\': epochs,\n        \'steps\': steps_per_epoch,\n        \'samples\': num_train_samples,\n        \'verbose\': verbose,\n        \'do_validation\': do_validation,\n        \'metrics\': callback_metrics,\n    })\n    callbacks._call_begin_hook(\'train\')\n    callbacks.model.stop_training = False\n    for cbk in callbacks:\n        cbk.validation_data = val_inputs\n\n    # To prevent a slowdown,\n    # we find beforehand the arrays that need conversion.\n    feed = (model._feed_inputs +\n            model._feed_targets +\n            model._feed_sample_weights)\n    indices_for_conversion_to_dense = []\n    for i in range(len(feed)):\n        if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):\n            indices_for_conversion_to_dense.append(i)\n\n    for epoch in range(initial_epoch, epochs):\n        model.reset_metrics()\n        callbacks.on_epoch_begin(epoch)\n        epoch_logs = {}\n        if steps_per_epoch is not None:\n            for step_index in range(steps_per_epoch):\n                batch_logs = {\'batch\': step_index, \'size\': 1}\n                callbacks._call_batch_hook(\'train\', \'begin\', step_index, batch_logs)\n                outs = fit_function(fit_inputs)\n\n                outs = to_list(outs)\n                for l, o in zip(out_labels, outs):\n                    batch_logs[l] = o\n\n                callbacks._call_batch_hook(\'train\', \'end\', step_index, batch_logs)\n                if callback_model.stop_training:\n                    break\n\n            if do_validation and should_run_validation(validation_freq, epoch):\n                val_outs = test_loop(model, val_function, val_inputs,\n                                     steps=validation_steps,\n                                     callbacks=callbacks,\n                                     verbose=0)\n                val_outs = to_list(val_outs)\n                # Same labels assumed.\n                for l, o in zip(out_labels, val_outs):\n                    epoch_logs[\'val_\' + l] = o\n        else:\n            if shuffle == \'batch\':\n                index_array = batch_shuffle(index_array, batch_size)\n            elif shuffle:\n                np.random.shuffle(index_array)\n\n            batches = make_batches(num_train_samples, batch_size)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                try:\n                    if isinstance(fit_inputs[-1], int):\n                        # Do not slice the training phase flag.\n                        ins_batch = slice_arrays(\n                            fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n                    else:\n                        ins_batch = slice_arrays(fit_inputs, batch_ids)\n                except TypeError:\n                    raise TypeError(\'TypeError while preparing batch. \'\n                                    \'If using HDF5 input data, \'\n                                    \'pass shuffle=""batch"".\')\n                batch_logs = {\'batch\': batch_index, \'size\': len(batch_ids)}\n                callbacks._call_batch_hook(\'train\', \'begin\', batch_index, batch_logs)\n                for i in indices_for_conversion_to_dense:\n                    ins_batch[i] = ins_batch[i].toarray()\n\n                outs = fit_function(ins_batch)\n                outs = to_list(outs)\n                for l, o in zip(out_labels, outs):\n                    batch_logs[l] = o\n\n                callbacks._call_batch_hook(\'train\', \'end\', batch_index, batch_logs)\n                if callbacks.model.stop_training:\n                    break\n\n            if batch_index == len(batches) - 1:  # Last batch.\n                if do_validation and should_run_validation(validation_freq, epoch):\n                    val_outs = test_loop(model, val_function, val_inputs,\n                                         batch_size=batch_size,\n                                         callbacks=callbacks,\n                                         verbose=0)\n                    val_outs = to_list(val_outs)\n                    # Same labels assumed.\n                    for l, o in zip(out_labels, val_outs):\n                        epoch_logs[\'val_\' + l] = o\n\n        callbacks.on_epoch_end(epoch, epoch_logs)\n        if callbacks.model.stop_training:\n            break\n    callbacks._call_end_hook(\'train\')\n    return model.history\n\n\ndef predict_loop(model, f, ins,\n                 batch_size=32,\n                 verbose=0,\n                 steps=None,\n                 callbacks=None):\n    """"""Abstract method to loop over some data in batches.\n\n    # Arguments\n        model: Keras model instance.\n        f: Keras function returning a list of tensors.\n        ins: list of tensors to be fed to `f`.\n        batch_size: integer batch size.\n        verbose: verbosity mode.\n        steps: Total number of steps (batches of samples)\n            before declaring `predict_loop` finished.\n            Ignored with the default value of `None`.\n        callbacks: List of callbacks or an instance of\n            `keras.callbacks.CallbackList` to be called during prediction.\n\n    # Returns\n        Array of predictions (if the model has a single output)\n        or list of arrays of predictions\n        (if the model has multiple outputs).\n    """"""\n    num_samples = check_num_samples(ins,\n                                    batch_size=batch_size,\n                                    steps=steps,\n                                    steps_name=\'steps\')\n\n    # Check if callbacks have not been already configured\n    if not isinstance(callbacks, cbks.CallbackList):\n        callbacks = cbks.CallbackList(callbacks)\n        callback_model = model._get_callback_model()\n        callbacks.set_model(callback_model)\n        callback_params = {\n            \'batch_size\': batch_size,\n            \'steps\': steps,\n            \'samples\': num_samples,\n            \'verbose\': verbose,\n        }\n        callbacks.set_params(callback_params)\n\n    if verbose == 1:\n        if steps is not None:\n            progbar = Progbar(target=steps)\n        else:\n            progbar = Progbar(target=num_samples)\n\n    indices_for_conversion_to_dense = []\n    for i in range(len(model._feed_inputs)):\n        if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):\n            indices_for_conversion_to_dense.append(i)\n\n    callbacks.model.stop_training = False\n    callbacks._call_begin_hook(\'predict\')\n\n    if steps is not None:\n        # Step-based predictions.\n        # Since we do not know how many samples\n        # we will see, we cannot pre-allocate\n        # the returned Numpy arrays.\n        # Instead, we store one array per batch seen\n        # and concatenate them upon returning.\n        unconcatenated_outs = []\n        for step in range(steps):\n            batch_logs = {\'batch\': step, \'size\': 1}\n            callbacks._call_batch_hook(\'predict\', \'begin\', step, batch_logs)\n            batch_outs = f(ins)\n            batch_outs = to_list(batch_outs)\n            if step == 0:\n                for batch_out in batch_outs:\n                    unconcatenated_outs.append([])\n            for i, batch_out in enumerate(batch_outs):\n                unconcatenated_outs[i].append(batch_out)\n\n            batch_logs[\'outputs\'] = batch_outs\n            callbacks._call_batch_hook(\'predict\', \'end\', step, batch_logs)\n            if verbose == 1:\n                progbar.update(step + 1)\n        callbacks.on_predict_end()\n        if len(unconcatenated_outs) == 1:\n            return np.concatenate(unconcatenated_outs[0], axis=0)\n        return [np.concatenate(unconcatenated_outs[i], axis=0)\n                for i in range(len(unconcatenated_outs))]\n    else:\n        # Sample-based predictions.\n        outs = []\n        batches = make_batches(num_samples, batch_size)\n        index_array = np.arange(num_samples)\n        for batch_index, (batch_start, batch_end) in enumerate(batches):\n            batch_ids = index_array[batch_start:batch_end]\n            if ins and isinstance(ins[-1], int):\n                # Do not slice the training phase flag.\n                ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n            else:\n                ins_batch = slice_arrays(ins, batch_ids)\n            for i in indices_for_conversion_to_dense:\n                ins_batch[i] = ins_batch[i].toarray()\n\n            batch_logs = {\'batch\': batch_index, \'size\': len(batch_ids)}\n            callbacks._call_batch_hook(\'predict\', \'begin\', batch_index, batch_logs)\n            batch_outs = f(ins_batch)\n            batch_outs = to_list(batch_outs)\n            if batch_index == 0:\n                # Pre-allocate the results arrays.\n                for batch_out in batch_outs:\n                    shape = (num_samples,) + batch_out.shape[1:]\n                    outs.append(np.zeros(shape, dtype=batch_out.dtype))\n            for i, batch_out in enumerate(batch_outs):\n                outs[i][batch_start:batch_end] = batch_out\n\n            batch_logs[\'outputs\'] = batch_outs\n            callbacks._call_batch_hook(\'predict\', \'end\', batch_index, batch_logs)\n            if verbose == 1:\n                progbar.update(batch_end)\n        callbacks._call_end_hook(\'predict\')\n        return unpack_singleton(outs)\n\n\ndef test_loop(model, f, ins,\n              batch_size=None,\n              verbose=0,\n              steps=None,\n              callbacks=None):\n    """"""Abstract method to loop over some data in batches.\n\n    # Arguments\n        model: Keras model instance.\n        f: Keras function returning a list of tensors.\n        ins: list of tensors to be fed to `f`.\n        batch_size: integer batch size or `None`.\n        verbose: verbosity mode.\n        steps: Total number of steps (batches of samples)\n            before declaring predictions finished.\n            Ignored with the default value of `None`.\n        callbacks: List of callbacks or an instance of\n            `keras.callbacks.CallbackList` to be called during evaluation.\n\n    # Returns\n        Scalar loss (if the model has a single output and no metrics)\n        or list of scalars (if the model has multiple outputs\n        and/or metrics). The attribute `model.metrics_names` will give you\n        the display labels for the scalar outputs.\n    """"""\n\n    model.reset_metrics()\n    num_samples = check_num_samples(ins,\n                                    batch_size=batch_size,\n                                    steps=steps,\n                                    steps_name=\'steps\')\n\n    # Check if callbacks have not been already configured\n    if not isinstance(callbacks, cbks.CallbackList):\n        callbacks = cbks.CallbackList(callbacks)\n        callback_model = model._get_callback_model()\n        callbacks.set_model(callback_model)\n        callback_metrics = list(model.metrics_names)\n        callback_params = {\n            \'batch_size\': batch_size,\n            \'steps\': steps,\n            \'samples\': num_samples,\n            \'verbose\': verbose,\n            \'metrics\': callback_metrics,\n        }\n        callbacks.set_params(callback_params)\n\n    outs = []\n    if verbose == 1:\n        if steps is not None:\n            progbar = Progbar(target=steps)\n        else:\n            progbar = Progbar(target=num_samples)\n\n    # To prevent a slowdown,\n    # we find beforehand the arrays that need conversion.\n    feed = (model._feed_inputs +\n            model._feed_targets +\n            model._feed_sample_weights)\n    indices_for_conversion_to_dense = []\n    for i in range(len(feed)):\n        if issparse(ins[i]) and not K.is_sparse(feed[i]):\n            indices_for_conversion_to_dense.append(i)\n\n    callbacks.model.stop_training = False\n    callbacks._call_begin_hook(\'test\')\n\n    if steps is not None:\n        for step in range(steps):\n            batch_logs = {\'batch\': step, \'size\': 1}\n            callbacks._call_batch_hook(\'test\', \'begin\', step, batch_logs)\n            batch_outs = f(ins)\n            if isinstance(batch_outs, list):\n                if step == 0:\n                    outs.extend([0.] * len(batch_outs))\n                for i, batch_out in enumerate(batch_outs):\n                    if i == 0:  # Index 0 == `Loss`\n                        outs[i] = float(batch_out)\n                    else:\n                        outs[i] += float(batch_out)\n            else:\n                if step == 0:\n                    outs.append(0.)\n                outs[0] += float(batch_outs)\n\n            for l, o in zip(model.metrics_names, batch_outs):\n                batch_logs[l] = o\n            callbacks._call_batch_hook(\'test\', \'end\', step, batch_logs)\n\n            if verbose == 1:\n                progbar.update(step + 1)\n        outs[0] /= steps  # Index 0 == `Loss`\n    else:\n        batches = make_batches(num_samples, batch_size)\n        index_array = np.arange(num_samples)\n        for batch_index, (batch_start, batch_end) in enumerate(batches):\n            batch_ids = index_array[batch_start:batch_end]\n            if isinstance(ins[-1], int):\n                # Do not slice the training phase flag.\n                ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n            else:\n                ins_batch = slice_arrays(ins, batch_ids)\n            for i in indices_for_conversion_to_dense:\n                ins_batch[i] = ins_batch[i].toarray()\n\n            batch_logs = {\'batch\': batch_index, \'size\': len(batch_ids)}\n            callbacks._call_batch_hook(\'test\', \'begin\', batch_index, batch_logs)\n            batch_outs = f(ins_batch)\n            if isinstance(batch_outs, list):\n                if batch_index == 0:\n                    outs.extend([0.] * len(batch_outs))\n                for i, batch_out in enumerate(batch_outs):\n                    if i == 0:  # Index 0 == `Loss`\n                        outs[i] += float(batch_out) * len(batch_ids)\n                    else:\n                        outs[i] = float(batch_out)\n            else:\n                if batch_index == 0:\n                    outs.append(0.)\n                outs[0] += float(batch_outs) * len(batch_ids)\n\n            for l, o in zip(model.metrics_names, batch_outs):\n                batch_logs[l] = float(o)\n            callbacks._call_batch_hook(\'test\', \'end\', batch_index, batch_logs)\n\n            if verbose == 1:\n                progbar.update(batch_end)\n        outs[0] /= num_samples  # Index 0 == `Loss`\n    callbacks._call_end_hook(\'test\')\n    return unpack_singleton(outs)\n'"
keras/engine/training_generator.py,0,"b'""""""Part of the training engine related to Python generators of array data.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport warnings\nimport numpy as np\n\nfrom .training_utils import is_sequence\nfrom .training_utils import iter_sequence_infinite\nfrom .training_utils import should_run_validation\nfrom .. import backend as K\nfrom ..utils.data_utils import Sequence\nfrom ..utils.data_utils import GeneratorEnqueuer\nfrom ..utils.data_utils import OrderedEnqueuer\nfrom ..utils.generic_utils import Progbar\nfrom ..utils.generic_utils import to_list\nfrom ..utils.generic_utils import unpack_singleton\nfrom .. import callbacks as cbks\n\n\ndef fit_generator(model,\n                  generator,\n                  steps_per_epoch=None,\n                  epochs=1,\n                  verbose=1,\n                  callbacks=None,\n                  validation_data=None,\n                  validation_steps=None,\n                  validation_freq=1,\n                  class_weight=None,\n                  max_queue_size=10,\n                  workers=1,\n                  use_multiprocessing=False,\n                  shuffle=True,\n                  initial_epoch=0):\n    """"""See docstring for `Model.fit_generator`.""""""\n    epoch = initial_epoch\n\n    do_validation = bool(validation_data)\n    model._make_train_function()\n    if do_validation:\n        model._make_test_function()\n\n    use_sequence_api = is_sequence(generator)\n    if not use_sequence_api and use_multiprocessing and workers > 1:\n        warnings.warn(\n            UserWarning(\'Using a generator with `use_multiprocessing=True`\'\n                        \' and multiple workers may duplicate your data.\'\n                        \' Please consider using the `keras.utils.Sequence\'\n                        \' class.\'))\n\n    # if generator is instance of Sequence and steps_per_epoch are not provided -\n    # recompute steps_per_epoch after each epoch\n    recompute_steps_per_epoch = use_sequence_api and steps_per_epoch is None\n\n    if steps_per_epoch is None:\n        if use_sequence_api:\n            steps_per_epoch = len(generator)\n        else:\n            raise ValueError(\'`steps_per_epoch=None` is only valid for a\'\n                             \' generator based on the \'\n                             \'`keras.utils.Sequence`\'\n                             \' class. Please specify `steps_per_epoch` \'\n                             \'or use the `keras.utils.Sequence` class.\')\n\n    # python 2 has \'next\', 3 has \'__next__\'\n    # avoid any explicit version checks\n    val_use_sequence_api = is_sequence(validation_data)\n    val_gen = (hasattr(validation_data, \'next\') or\n               hasattr(validation_data, \'__next__\') or\n               val_use_sequence_api)\n    if (val_gen and not val_use_sequence_api and\n            not validation_steps):\n        raise ValueError(\'`validation_steps=None` is only valid for a\'\n                         \' generator based on the `keras.utils.Sequence`\'\n                         \' class. Please specify `validation_steps` or use\'\n                         \' the `keras.utils.Sequence` class.\')\n\n    # Prepare display labels.\n    out_labels = model.metrics_names\n    callback_metrics = out_labels + [\'val_\' + n for n in out_labels]\n\n    # prepare callbacks\n    model.history = cbks.History()\n    _callbacks = [cbks.BaseLogger(\n        stateful_metrics=model.metrics_names[1:])]\n    if verbose:\n        _callbacks.append(\n            cbks.ProgbarLogger(\n                count_mode=\'steps\',\n                stateful_metrics=model.metrics_names[1:]))\n    _callbacks += (callbacks or []) + [model.history]\n    callbacks = cbks.CallbackList(_callbacks)\n\n    # it\'s possible to callback a different model than self:\n    callback_model = model._get_callback_model()\n\n    callbacks.set_model(callback_model)\n    callbacks.set_params({\n        \'epochs\': epochs,\n        \'steps\': steps_per_epoch,\n        \'verbose\': verbose,\n        \'do_validation\': do_validation,\n        \'metrics\': callback_metrics,\n    })\n    callbacks._call_begin_hook(\'train\')\n\n    enqueuer = None\n    val_enqueuer = None\n\n    try:\n        if do_validation:\n            if val_gen and workers > 0:\n                # Create an Enqueuer that can be reused\n                val_data = validation_data\n                if is_sequence(val_data):\n                    val_enqueuer = OrderedEnqueuer(\n                        val_data,\n                        use_multiprocessing=use_multiprocessing)\n                    validation_steps = validation_steps or len(val_data)\n                else:\n                    val_enqueuer = GeneratorEnqueuer(\n                        val_data,\n                        use_multiprocessing=use_multiprocessing)\n                val_enqueuer.start(workers=workers,\n                                   max_queue_size=max_queue_size)\n                val_enqueuer_gen = val_enqueuer.get()\n            elif val_gen:\n                val_data = validation_data\n                if is_sequence(val_data):\n                    val_enqueuer_gen = iter_sequence_infinite(val_data)\n                    validation_steps = validation_steps or len(val_data)\n                else:\n                    val_enqueuer_gen = val_data\n            else:\n                # Prepare data for validation\n                if len(validation_data) == 2:\n                    val_x, val_y = validation_data\n                    val_sample_weight = None\n                elif len(validation_data) == 3:\n                    val_x, val_y, val_sample_weight = validation_data\n                else:\n                    raise ValueError(\'`validation_data` should be a tuple \'\n                                     \'`(val_x, val_y, val_sample_weight)` \'\n                                     \'or `(val_x, val_y)`. Found: \' +\n                                     str(validation_data))\n                val_x, val_y, val_sample_weights = model._standardize_user_data(\n                    val_x, val_y, val_sample_weight)\n                val_data = val_x + val_y + val_sample_weights\n                if model.uses_learning_phase and not isinstance(K.learning_phase(),\n                                                                int):\n                    val_data += [0.]\n                for cbk in callbacks:\n                    cbk.validation_data = val_data\n\n        if workers > 0:\n            if use_sequence_api:\n                enqueuer = OrderedEnqueuer(\n                    generator,\n                    use_multiprocessing=use_multiprocessing,\n                    shuffle=shuffle)\n            else:\n                enqueuer = GeneratorEnqueuer(\n                    generator,\n                    use_multiprocessing=use_multiprocessing)\n            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n            output_generator = enqueuer.get()\n        else:\n            if use_sequence_api:\n                output_generator = iter_sequence_infinite(generator)\n            else:\n                output_generator = generator\n\n        callbacks.model.stop_training = False\n        # Construct epoch logs.\n        epoch_logs = {}\n        while epoch < epochs:\n            model.reset_metrics()\n            callbacks.on_epoch_begin(epoch)\n            steps_done = 0\n            batch_index = 0\n            while steps_done < steps_per_epoch:\n                generator_output = next(output_generator)\n\n                if not hasattr(generator_output, \'__len__\'):\n                    raise ValueError(\'Output of generator should be \'\n                                     \'a tuple `(x, y, sample_weight)` \'\n                                     \'or `(x, y)`. Found: \' +\n                                     str(generator_output))\n\n                if len(generator_output) == 2:\n                    x, y = generator_output\n                    sample_weight = None\n                elif len(generator_output) == 3:\n                    x, y, sample_weight = generator_output\n                else:\n                    raise ValueError(\'Output of generator should be \'\n                                     \'a tuple `(x, y, sample_weight)` \'\n                                     \'or `(x, y)`. Found: \' +\n                                     str(generator_output))\n                if x is None or len(x) == 0:\n                    # Handle data tensors support when no input given\n                    # step-size = 1 for data tensors\n                    batch_size = 1\n                elif isinstance(x, list):\n                    batch_size = x[0].shape[0]\n                elif isinstance(x, dict):\n                    batch_size = list(x.values())[0].shape[0]\n                else:\n                    batch_size = x.shape[0]\n                # build batch logs\n                batch_logs = {\'batch\': batch_index, \'size\': batch_size}\n                callbacks.on_batch_begin(batch_index, batch_logs)\n\n                outs = model.train_on_batch(x, y,\n                                            sample_weight=sample_weight,\n                                            class_weight=class_weight,\n                                            reset_metrics=False)\n\n                outs = to_list(outs)\n                for l, o in zip(out_labels, outs):\n                    batch_logs[l] = o\n\n                callbacks._call_batch_hook(\'train\', \'end\', batch_index, batch_logs)\n\n                batch_index += 1\n                steps_done += 1\n\n                # Epoch finished.\n                if (steps_done >= steps_per_epoch and\n                        do_validation and\n                        should_run_validation(validation_freq, epoch)):\n                    # Note that `callbacks` here is an instance of\n                    # `keras.callbacks.CallbackList`\n                    if val_gen:\n                        val_outs = model.evaluate_generator(\n                            val_enqueuer_gen,\n                            validation_steps,\n                            callbacks=callbacks,\n                            workers=0)\n                    else:\n                        # No need for try/except because\n                        # data has already been validated.\n                        val_outs = model.evaluate(\n                            val_x, val_y,\n                            batch_size=batch_size,\n                            sample_weight=val_sample_weights,\n                            callbacks=callbacks,\n                            verbose=0)\n                    val_outs = to_list(val_outs)\n                    # Same labels assumed.\n                    for l, o in zip(out_labels, val_outs):\n                        epoch_logs[\'val_\' + l] = o\n\n                if callbacks.model.stop_training:\n                    break\n\n            callbacks.on_epoch_end(epoch, epoch_logs)\n            epoch += 1\n            if callbacks.model.stop_training:\n                break\n\n            if use_sequence_api and workers == 0:\n                generator.on_epoch_end()\n\n            if recompute_steps_per_epoch:\n                if workers > 0:\n                    enqueuer.join_end_of_epoch()\n\n                # recomute steps per epochs in case if Sequence changes it\'s length\n                steps_per_epoch = len(generator)\n\n                # update callbacks to make sure params are valid each epoch\n                callbacks.set_params({\n                    \'epochs\': epochs,\n                    \'steps\': steps_per_epoch,\n                    \'verbose\': verbose,\n                    \'do_validation\': do_validation,\n                    \'metrics\': callback_metrics,\n                })\n\n    finally:\n        try:\n            if enqueuer is not None:\n                enqueuer.stop()\n        finally:\n            if val_enqueuer is not None:\n                val_enqueuer.stop()\n\n    callbacks._call_end_hook(\'train\')\n    return model.history\n\n\ndef evaluate_generator(model, generator,\n                       steps=None,\n                       callbacks=None,\n                       max_queue_size=10,\n                       workers=1,\n                       use_multiprocessing=False,\n                       verbose=0):\n    """"""See docstring for `Model.evaluate_generator`.""""""\n    model._make_test_function()\n    model.reset_metrics()\n\n    steps_done = 0\n    outs_per_batch = []\n    batch_sizes = []\n    use_sequence_api = is_sequence(generator)\n    if not use_sequence_api and use_multiprocessing and workers > 1:\n        warnings.warn(\n            UserWarning(\'Using a generator with `use_multiprocessing=True`\'\n                        \' and multiple workers may duplicate your data.\'\n                        \' Please consider using the `keras.utils.Sequence\'\n                        \' class.\'))\n    if steps is None:\n        if use_sequence_api:\n            steps = len(generator)\n        else:\n            raise ValueError(\'`steps=None` is only valid for a generator\'\n                             \' based on the `keras.utils.Sequence` class.\'\n                             \' Please specify `steps` or use the\'\n                             \' `keras.utils.Sequence` class.\')\n    enqueuer = None\n\n    # Check if callbacks have not been already configured\n    if not isinstance(callbacks, cbks.CallbackList):\n        callbacks = cbks.CallbackList(callbacks)\n        callback_model = model._get_callback_model()\n        callbacks.set_model(callback_model)\n        callback_metrics = list(model.metrics_names)\n        callback_params = {\n            \'steps\': steps,\n            \'verbose\': verbose,\n            \'metrics\': callback_metrics,\n        }\n        callbacks.set_params(callback_params)\n\n    callbacks.model.stop_training = False\n    callbacks._call_begin_hook(\'test\')\n\n    try:\n        if workers > 0:\n            if use_sequence_api:\n                enqueuer = OrderedEnqueuer(\n                    generator,\n                    use_multiprocessing=use_multiprocessing)\n            else:\n                enqueuer = GeneratorEnqueuer(\n                    generator,\n                    use_multiprocessing=use_multiprocessing)\n            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n            output_generator = enqueuer.get()\n        else:\n            if use_sequence_api:\n                output_generator = iter_sequence_infinite(generator)\n            else:\n                output_generator = generator\n\n        if verbose == 1:\n            progbar = Progbar(target=steps)\n\n        while steps_done < steps:\n            generator_output = next(output_generator)\n            if not hasattr(generator_output, \'__len__\'):\n                raise ValueError(\'Output of generator should be a tuple \'\n                                 \'(x, y, sample_weight) \'\n                                 \'or (x, y). Found: \' +\n                                 str(generator_output))\n            if len(generator_output) == 2:\n                x, y = generator_output\n                sample_weight = None\n            elif len(generator_output) == 3:\n                x, y, sample_weight = generator_output\n            else:\n                raise ValueError(\'Output of generator should be a tuple \'\n                                 \'(x, y, sample_weight) \'\n                                 \'or (x, y). Found: \' +\n                                 str(generator_output))\n\n            if x is None or len(x) == 0:\n                # Handle data tensors support when no input given\n                # step-size = 1 for data tensors\n                batch_size = 1\n            elif isinstance(x, list):\n                batch_size = x[0].shape[0]\n            elif isinstance(x, dict):\n                batch_size = list(x.values())[0].shape[0]\n            else:\n                batch_size = x.shape[0]\n            if batch_size == 0:\n                raise ValueError(\'Received an empty batch. \'\n                                 \'Batches should contain \'\n                                 \'at least one item.\')\n\n            batch_logs = {\'batch\': steps_done, \'size\': batch_size}\n            callbacks._call_batch_hook(\'test\', \'begin\', steps_done, batch_logs)\n            outs = model.test_on_batch(x, y,\n                                       sample_weight=sample_weight,\n                                       reset_metrics=False)\n            outs = to_list(outs)\n            outs_per_batch.append(outs)\n\n            for l, o in zip(model.metrics_names, outs):\n                batch_logs[l] = o\n            callbacks._call_batch_hook(\'test\', \'end\', steps_done, batch_logs)\n\n            steps_done += 1\n            batch_sizes.append(batch_size)\n\n            if verbose == 1:\n                progbar.update(steps_done)\n        callbacks._call_end_hook(\'test\')\n\n    finally:\n        if enqueuer is not None:\n            enqueuer.stop()\n\n    averages = [float(outs_per_batch[-1][0])]  # index 0 = \'loss\'\n    for i in range(1, len(outs)):\n        averages.append(np.float64(outs_per_batch[-1][i]))\n    return unpack_singleton(averages)\n\n\ndef predict_generator(model, generator,\n                      steps=None,\n                      callbacks=None,\n                      max_queue_size=10,\n                      workers=1,\n                      use_multiprocessing=False,\n                      verbose=0):\n    """"""See docstring for `Model.predict_generator`.""""""\n    model._make_predict_function()\n\n    steps_done = 0\n    all_outs = []\n    use_sequence_api = is_sequence(generator)\n    if not use_sequence_api and use_multiprocessing and workers > 1:\n        warnings.warn(\n            UserWarning(\'Using a generator with `use_multiprocessing=True`\'\n                        \' and multiple workers may duplicate your data.\'\n                        \' Please consider using the `keras.utils.Sequence\'\n                        \' class.\'))\n    if steps is None:\n        if use_sequence_api:\n            steps = len(generator)\n        else:\n            raise ValueError(\'`steps=None` is only valid for a generator\'\n                             \' based on the `keras.utils.Sequence` class.\'\n                             \' Please specify `steps` or use the\'\n                             \' `keras.utils.Sequence` class.\')\n    enqueuer = None\n\n    # Check if callbacks have not been already configured\n    if not isinstance(callbacks, cbks.CallbackList):\n        callbacks = cbks.CallbackList(callbacks)\n        callback_model = model._get_callback_model()\n        callbacks.set_model(callback_model)\n        callback_params = {\n            \'steps\': steps,\n            \'verbose\': verbose,\n        }\n        callbacks.set_params(callback_params)\n\n    callbacks.model.stop_training = False\n    callbacks._call_begin_hook(\'predict\')\n\n    try:\n        if workers > 0:\n            if use_sequence_api:\n                enqueuer = OrderedEnqueuer(\n                    generator,\n                    use_multiprocessing=use_multiprocessing)\n            else:\n                enqueuer = GeneratorEnqueuer(\n                    generator,\n                    use_multiprocessing=use_multiprocessing)\n            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n            output_generator = enqueuer.get()\n        else:\n            if use_sequence_api:\n                output_generator = iter_sequence_infinite(generator)\n            else:\n                output_generator = generator\n\n        if verbose == 1:\n            progbar = Progbar(target=steps)\n\n        while steps_done < steps:\n            generator_output = next(output_generator)\n            if isinstance(generator_output, tuple):\n                # Compatibility with the generators\n                # used for training.\n                if len(generator_output) == 2:\n                    x, _ = generator_output\n                elif len(generator_output) == 3:\n                    x, _, _ = generator_output\n                else:\n                    raise ValueError(\'Output of generator should be \'\n                                     \'a tuple `(x, y, sample_weight)` \'\n                                     \'or `(x, y)`. Found: \' +\n                                     str(generator_output))\n            else:\n                # Assumes a generator that only\n                # yields inputs (not targets and sample weights).\n                x = generator_output\n\n            if x is None or len(x) == 0:\n                # Handle data tensors support when no input given\n                # step-size = 1 for data tensors\n                batch_size = 1\n            elif isinstance(x, list):\n                batch_size = x[0].shape[0]\n            elif isinstance(x, dict):\n                batch_size = list(x.values())[0].shape[0]\n            else:\n                batch_size = x.shape[0]\n            if batch_size == 0:\n                raise ValueError(\'Received an empty batch. \'\n                                 \'Batches should contain \'\n                                 \'at least one item.\')\n\n            batch_logs = {\'batch\': steps_done, \'size\': batch_size}\n            callbacks._call_batch_hook(\'predict\', \'begin\', steps_done, batch_logs)\n\n            outs = model.predict_on_batch(x)\n            outs = to_list(outs)\n\n            if not all_outs:\n                for out in outs:\n                    all_outs.append([])\n\n            for i, out in enumerate(outs):\n                all_outs[i].append(out)\n\n            batch_logs[\'outputs\'] = outs\n            callbacks._call_batch_hook(\'predict\', \'end\', steps_done, batch_logs)\n\n            steps_done += 1\n            if verbose == 1:\n                progbar.update(steps_done)\n        callbacks._call_end_hook(\'predict\')\n    finally:\n        if enqueuer is not None:\n            enqueuer.stop()\n\n    if len(all_outs) == 1:\n        if steps_done == 1:\n            return all_outs[0][0]\n        else:\n            return np.concatenate(all_outs[0])\n    if steps_done == 1:\n        return [out[0] for out in all_outs]\n    else:\n        return [np.concatenate(out) for out in all_outs]\n'"
keras/engine/training_utils.py,0,"b'""""""Training-related utilities.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport inspect\nimport collections\nimport copy\nimport numpy as np\nimport six\nimport warnings\nfrom collections import OrderedDict\n\nfrom .. import backend as K\nfrom .. import losses\nfrom .. import metrics as metrics_module\nfrom ..utils import Sequence\nfrom ..utils import generic_utils\nfrom ..utils import losses_utils\n\n\ndef standardize_single_array(x):\n    if x is None:\n        return None\n    elif K.is_tensor(x):\n        shape = K.int_shape(x)\n        if shape is None or shape[0] is None:\n            raise ValueError(\n                \'When feeding symbolic tensors to a model, we expect the \'\n                \'tensors to have a static batch size. \'\n                \'Got tensor with shape: %s\' % str(shape))\n        return x\n    elif x.ndim == 1:\n        x = np.expand_dims(x, 1)\n    return x\n\n\ndef standardize_input_data(data,\n                           names,\n                           shapes=None,\n                           check_batch_axis=True,\n                           exception_prefix=\'\'):\n    """"""Normalizes inputs and targets provided by users.\n\n    Users may pass data as a list of arrays, dictionary of arrays,\n    or as a single array. We normalize this to an ordered list of\n    arrays (same order as `names`), while checking that the provided\n    arrays have shapes that match the network\'s expectations.\n\n    # Arguments\n        data: User-provided input data (polymorphic).\n        names: List of expected array names.\n        shapes: Optional list of expected array shapes.\n        check_batch_axis: Boolean; whether to check that\n            the batch axis of the arrays matches the expected\n            value found in `shapes`.\n        exception_prefix: String prefix used for exception formatting.\n\n    # Returns\n        List of standardized input arrays (one array per model input).\n\n    # Raises\n        ValueError: in case of improperly formatted user-provided data.\n    """"""\n    if not names:\n        if data is not None and hasattr(data, \'__len__\') and len(data):\n            raise ValueError(\'Error when checking model \' +\n                             exception_prefix + \': \'\n                             \'expected no data, but got:\', data)\n        return []\n    if data is None:\n        return [None for _ in range(len(names))]\n\n    if isinstance(data, dict):\n        try:\n            data = [\n                data[x].values\n                if data[x].__class__.__name__ == \'DataFrame\' else data[x]\n                for x in names\n            ]\n        except KeyError as e:\n            raise ValueError(\'No data provided for ""\' + e.args[0] +\n                             \'"". Need data \'\n                             \'for each key in: \' + str(names))\n    elif isinstance(data, list):\n        if isinstance(data[0], list):\n            data = [np.asarray(d) for d in data]\n        elif len(names) == 1 and isinstance(data[0], (float, int)):\n            data = [np.asarray(data)]\n        else:\n            data = [\n                x.values if x.__class__.__name__ == \'DataFrame\'\n                else x for x in data\n            ]\n    else:\n        data = data.values if data.__class__.__name__ == \'DataFrame\' else data\n        data = [data]\n    data = [standardize_single_array(x) for x in data]\n\n    if len(data) != len(names):\n        if data and hasattr(data[0], \'shape\'):\n            raise ValueError(\n                \'Error when checking model \' + exception_prefix +\n                \': the list of Numpy arrays that you are passing to \'\n                \'your model is not the size the model expected. \'\n                \'Expected to see \' + str(len(names)) + \' array(s), \'\n                \'but instead got the following list of \' +\n                str(len(data)) + \' arrays: \' + str(data)[:200] + \'...\')\n        elif len(names) > 1:\n            raise ValueError(\n                \'Error when checking model \' + exception_prefix +\n                \': you are passing a list as input to your model, \'\n                \'but the model expects a list of \' + str(len(names)) +\n                \' Numpy arrays instead. \'\n                \'The list you passed was: \' + str(data)[:200])\n        elif len(data) == 1 and not hasattr(data[0], \'shape\'):\n            raise TypeError(\'Error when checking model \' + exception_prefix +\n                            \': data should be a Numpy array, or list/dict of \'\n                            \'Numpy arrays. Found: \' + str(data)[:200] + \'...\')\n        elif len(names) == 1:\n            data = [np.asarray(data)]\n\n    # Check shapes compatibility.\n    if shapes:\n        for i in range(len(names)):\n            if shapes[i] is not None and not K.is_tensor(data[i]):\n                data_shape = data[i].shape\n                shape = shapes[i]\n                if data[i].ndim != len(shape):\n                    raise ValueError(\n                        \'Error when checking \' + exception_prefix +\n                        \': expected \' + names[i] + \' to have \' +\n                        str(len(shape)) + \' dimensions, but got array \'\n                        \'with shape \' + str(data_shape))\n                if not check_batch_axis:\n                    data_shape = data_shape[1:]\n                    shape = shape[1:]\n                for dim, ref_dim in zip(data_shape, shape):\n                    if ref_dim != dim and ref_dim:\n                        raise ValueError(\n                            \'Error when checking \' + exception_prefix +\n                            \': expected \' + names[i] + \' to have shape \' +\n                            str(shape) + \' but got array with shape \' +\n                            str(data_shape))\n    return data\n\n\ndef standardize_sample_or_class_weights(x_weight,\n                                        output_names,\n                                        weight_type):\n    """"""Maps `sample_weight` or `class_weight` to model outputs.\n\n    # Arguments\n        x_weight: User-provided `sample_weight` or `class_weight` argument.\n        output_names: List of output names (strings) in the model.\n        weight_type: A string used purely for exception printing.\n\n    # Returns\n        A list of `sample_weight` or `class_weight` where there are exactly\n            one element per model output.\n\n    # Raises\n        ValueError: In case of invalid user-provided argument.\n    """"""\n    if x_weight is None or len(x_weight) == 0:\n        return [None for _ in output_names]\n    if len(output_names) == 1:\n        if isinstance(x_weight, list) and len(x_weight) == 1:\n            return x_weight\n        if isinstance(x_weight, dict) and output_names[0] in x_weight:\n            return [x_weight[output_names[0]]]\n        else:\n            return [x_weight]\n    if isinstance(x_weight, list):\n        if len(x_weight) != len(output_names):\n            raise ValueError(\'Provided `\' + weight_type + \'` was a list of \' +\n                             str(len(x_weight)) +\n                             \' elements, but the model has \' +\n                             str(len(output_names)) + \' outputs. \'\n                             \'You should provide one `\' + weight_type + \'`\'\n                             \'array per model output.\')\n        return x_weight\n    if isinstance(x_weight, dict):\n        x_weights = []\n        for name in output_names:\n            x_weights.append(x_weight.get(name))\n        return x_weights\n    else:\n        raise TypeError(\'The model has multiple outputs, so `\' +\n                        weight_type + \'` \'\n                        \'should be either a list or a dict. \'\n                        \'Provided `\' + weight_type +\n                        \'` type not understood: \' +\n                        str(x_weight))\n\n\ndef standardize_class_weights(class_weight, output_names):\n    return standardize_sample_or_class_weights(class_weight,\n                                               output_names,\n                                               \'class_weight\')\n\n\ndef standardize_sample_weights(sample_weight, output_names):\n    return standardize_sample_or_class_weights(sample_weight,\n                                               output_names,\n                                               \'sample_weight\')\n\n\ndef check_array_length_consistency(inputs, targets, weights=None):\n    """"""Checks if batch axes are the same for Numpy arrays.\n\n    # Arguments\n        inputs: list of Numpy arrays of inputs.\n        targets: list of Numpy arrays of targets.\n        weights: list of Numpy arrays of sample weights.\n\n    # Raises\n        ValueError: in case of incorrectly formatted data.\n    """"""\n    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else int(y.shape[0]) for y in x])\n\n    set_x = set_of_lengths(inputs)\n    set_y = set_of_lengths(targets)\n    set_w = set_of_lengths(weights)\n    if len(set_x) > 1:\n        raise ValueError(\'All input arrays (x) should have \'\n                         \'the same number of samples. Got array shapes: \' +\n                         str([x.shape for x in inputs]))\n    if len(set_y) > 1:\n        raise ValueError(\'All target arrays (y) should have \'\n                         \'the same number of samples. Got array shapes: \' +\n                         str([y.shape for y in targets]))\n    if set_x and set_y and list(set_x)[0] != list(set_y)[0]:\n        raise ValueError(\'Input arrays should have \'\n                         \'the same number of samples as target arrays. \'\n                         \'Found \' + str(list(set_x)[0]) + \' input samples \'\n                         \'and \' + str(list(set_y)[0]) + \' target samples.\')\n    if len(set_w) > 1:\n        raise ValueError(\'All sample_weight arrays should have \'\n                         \'the same number of samples. Got array shapes: \' +\n                         str([w.shape for w in weights]))\n    if set_y and set_w and list(set_y)[0] != list(set_w)[0]:\n        raise ValueError(\'Sample_weight arrays should have \'\n                         \'the same number of samples as target arrays. Got \' +\n                         str(list(set_y)[0]) + \' input samples and \' +\n                         str(list(set_w)[0]) + \' target samples.\')\n\n\ndef check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n    """"""Does validation on the compatibility of targets and loss functions.\n\n    This helps prevent users from using loss functions incorrectly. This check\n    is purely for UX purposes.\n\n    # Arguments\n        targets: list of Numpy arrays of targets.\n        loss_fns: list of loss functions.\n        output_shapes: list of shapes of model outputs.\n\n    # Raises\n        ValueError: if a loss function or target array\n            is incompatible with an output.\n    """"""\n    key_loss_fns = {\n        losses.mean_squared_error, losses.binary_crossentropy,\n        losses.categorical_crossentropy\n    }\n    key_loss_classes = (losses.MeanSquaredError, losses.BinaryCrossentropy,\n                        losses.CategoricalCrossentropy)\n    for y, loss, shape in zip(targets, loss_fns, output_shapes):\n        if y is None or loss is None:\n            continue\n        if losses.is_categorical_crossentropy(loss):\n            if y.shape[-1] == 1:\n                raise ValueError(\n                    \'You are passing a target array of shape \' + str(y.shape) +\n                    \' while using as loss `categorical_crossentropy`. \'\n                    \'`categorical_crossentropy` expects \'\n                    \'targets to be binary matrices (1s and 0s) \'\n                    \'of shape (samples, classes). \'\n                    \'If your targets are integer classes, \'\n                    \'you can convert them to the expected format via:\\n\'\n                    \'```\\n\'\n                    \'from keras.utils import to_categorical\\n\'\n                    \'y_binary = to_categorical(y_int)\\n\'\n                    \'```\\n\'\n                    \'\\n\'\n                    \'Alternatively, you can use the loss function \'\n                    \'`sparse_categorical_crossentropy` instead, \'\n                    \'which does expect integer targets.\')\n        is_loss_wrapper = isinstance(loss, losses.LossFunctionWrapper)\n        if (isinstance(loss, key_loss_classes) or (is_loss_wrapper and\n                                                   (loss.fn in key_loss_fns))):\n            for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n                if out_dim is not None and target_dim != out_dim:\n                    loss_name = loss.name\n                    if loss_name is None:\n                        loss_type = loss.fn if is_loss_wrapper else type(loss)\n                        loss_name = loss_type.__name__\n                    raise ValueError(\n                        \'A target array with shape \' + str(y.shape) +\n                        \' was passed for an output of shape \' + str(shape) +\n                        \' while using as loss `\' + loss_name + \'`. \'\n                        \'This loss expects targets to have the same shape \'\n                        \'as the output.\')\n\n\ndef check_generator_arguments(y=None, sample_weight=None,\n                              validation_split=None):\n    """"""Validates arguments passed when using a generator.""""""\n    if y is not None:\n        raise ValueError(\'`y` argument is not supported when data is\'\n                         \'a generator or Sequence instance. Instead pass targets\'\n                         \' as the second element of the generator.\')\n    if sample_weight is not None:\n        raise ValueError(\'`sample_weight` argument is not supported when data is\'\n                         \'a generator or Sequence instance. Instead pass sample\'\n                         \' weights as the third element of the generator.\')\n    if validation_split:\n        raise ValueError(\'If your data is in the form of a Python generator, \'\n                         \'you cannot use `validation_split`.\')\n\n\ndef batch_shuffle(index_array, batch_size):\n    """"""Shuffles an array in a batch-wise fashion.\n\n    Useful for shuffling HDF5 arrays\n    (where one cannot access arbitrary indices).\n\n    # Arguments\n        index_array: array of indices to be shuffled.\n        batch_size: integer.\n\n    # Returns\n        The `index_array` array, shuffled in a batch-wise fashion.\n    """"""\n    batch_count = int(len(index_array) / batch_size)\n    # to reshape we need to be cleanly divisible by batch size\n    # we stash extra items and reappend them after shuffling\n    last_batch = index_array[batch_count * batch_size:]\n    index_array = index_array[:batch_count * batch_size]\n    index_array = index_array.reshape((batch_count, batch_size))\n    np.random.shuffle(index_array)\n    index_array = index_array.flatten()\n    return np.append(index_array, last_batch)\n\n\ndef make_batches(size, batch_size):\n    """"""Returns a list of batch indices (tuples of indices).\n\n    # Arguments\n        size: Integer, total size of the data to slice into batches.\n        batch_size: Integer, batch size.\n\n    # Returns\n        A list of tuples of array indices.\n    """"""\n    num_batches = (size + batch_size - 1) // batch_size  # round up\n    return [(i * batch_size, min(size, (i + 1) * batch_size))\n            for i in range(num_batches)]\n\n\ndef weighted_masked_objective(fn):\n    """"""Adds support for masking and sample-weighting to an objective function.\n\n    It transforms an objective function `fn(y_true, y_pred)`\n    into a sample-weighted, cost-masked objective function\n    `fn(y_true, y_pred, weights, mask)`.\n\n    # Arguments\n        fn: The objective function to wrap,\n            with signature `fn(y_true, y_pred)`.\n\n    # Returns\n        A function with signature `fn(y_true, y_pred, weights, mask)`.\n    """"""\n    if fn is None:\n        return None\n\n    def weighted(y_true, y_pred, weights, mask=None):\n        """"""Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        """"""\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in Theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask) + K.epsilon()\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array,\n                                 axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)\n    return weighted\n\n\ndef standardize_weights(y,\n                        sample_weight=None,\n                        class_weight=None,\n                        sample_weight_mode=None):\n    """"""Performs sample weight validation and standardization.\n\n    Everything gets normalized to a single sample-wise (or timestep-wise)\n    weight array. If both `sample_weights` and `class_weights` are provided,\n    the weights are multiplied together.\n\n    # Arguments\n        y: Numpy array of model targets to be weighted.\n        sample_weight: User-provided `sample_weight` argument.\n        class_weight: User-provided `class_weight` argument.\n        sample_weight_mode: One of `None` or `""temporal""`.\n            `""temporal""` indicated that we expect 2D weight data\n            that will be applied to the last 2 dimensions of\n            the targets (i.e. we are weighting timesteps, not samples).\n\n    # Returns\n        A Numpy array of target weights, one entry per sample to weight.\n\n    # Raises\n        ValueError: In case of invalid user-provided arguments.\n    """"""\n    if sample_weight_mode is not None:\n        if sample_weight_mode != \'temporal\':\n            raise ValueError(\'""sample_weight_mode \'\n                             \'should be None or ""temporal"". \'\n                             \'Found: \' + str(sample_weight_mode))\n        if len(y.shape) < 3:\n            raise ValueError(\'Found a sample_weight array for \'\n                             \'an input with shape \' +\n                             str(y.shape) + \'. \'\n                             \'Timestep-wise sample weighting (use of \'\n                             \'sample_weight_mode=""temporal"") is restricted to \'\n                             \'outputs that are at least 3D, i.e. that have \'\n                             \'a time dimension.\')\n        if sample_weight is not None and len(sample_weight.shape) != 2:\n            raise ValueError(\'Found a sample_weight array with shape \' +\n                             str(sample_weight.shape) + \'. \'\n                             \'In order to use timestep-wise sample weighting, \'\n                             \'you should pass a 2D sample_weight array.\')\n    else:\n        if sample_weight is not None and len(sample_weight.shape) != 1:\n            raise ValueError(\'Found a sample_weight array with shape \' +\n                             str(sample_weight.shape) + \'. \'\n                             \'In order to use timestep-wise sample weights, \'\n                             \'you should specify \'\n                             \'sample_weight_mode=""temporal"" \'\n                             \'in compile(). If you just mean to use \'\n                             \'sample-wise weights, make sure your \'\n                             \'sample_weight array is 1D.\')\n\n    if sample_weight is not None:\n        if len(sample_weight.shape) > len(y.shape):\n            raise ValueError(\'Found a sample_weight with shape\' +\n                             str(sample_weight.shape) + \'.\'\n                             \'Expected sample_weight with rank \'\n                             \'less than or equal to \' + str(len(y.shape)))\n\n        if y.shape[:sample_weight.ndim] != sample_weight.shape:\n            raise ValueError(\'Found a sample_weight array with shape \' +\n                             str(sample_weight.shape) +\n                             \' for an input with shape \' +\n                             str(y.shape) + \'. \'\n                             \'sample_weight cannot be broadcast.\')\n\n    class_sample_weight = None\n    if isinstance(class_weight, dict):\n        if len(y.shape) > 2:\n            raise ValueError(\'`class_weight` not supported for \'\n                             \'3+ dimensional targets.\')\n        if len(y.shape) == 2:\n            if y.shape[1] > 1:\n                y_classes = np.argmax(y, axis=1)\n            elif y.shape[1] == 1:\n                y_classes = np.reshape(y, y.shape[0])\n        else:\n            y_classes = y\n\n        class_sample_weight = np.asarray(\n            [class_weight[cls] for cls in y_classes if cls in class_weight])\n\n        if len(class_sample_weight) != len(y_classes):\n            # subtract the sets to pick all missing classes\n            existing_classes = set(y_classes)\n            existing_class_weight = set(class_weight.keys())\n            raise ValueError(\'`class_weight` must contain \'\n                             \'all classes in the data.\'\n                             \' The classes %s exist in the data but not in \'\n                             \'`class_weight`.\'\n                             % (existing_classes - existing_class_weight))\n\n    if sample_weight is not None and class_sample_weight is not None:\n        return sample_weight * class_sample_weight\n    if sample_weight is not None:\n        return sample_weight\n    if class_sample_weight is not None:\n        return class_sample_weight\n\n    # Everything has weight 1 by default.\n    if sample_weight_mode is None:\n        return np.ones((y.shape[0],), dtype=K.floatx())\n    else:\n        return np.ones((y.shape[0], y.shape[1]), dtype=K.floatx())\n\n\ndef check_num_samples(ins,\n                      batch_size=None,\n                      steps=None,\n                      steps_name=\'steps\'):\n    """"""Checks the number of samples provided for training and evaluation.\n\n    The number of samples is not defined when running with `steps`,\n    in which case the number of samples is set to `None`.\n\n    # Arguments\n        ins: List of tensors to be fed to the Keras function.\n        batch_size: Integer batch size or `None` if not defined.\n        steps: Total number of steps (batches of samples)\n            before declaring `predict_loop` finished.\n            Ignored with the default value of `None`.\n        steps_name: The public API\'s parameter name for `steps`.\n\n    # Raises\n        ValueError: when `steps` is `None` and the attribute `ins.shape`\n        does not exist. Also raises ValueError when `steps` is not `None`\n        and `batch_size` is not `None` because they are mutually\n        exclusive.\n\n    # Returns\n        When `steps` is `None`, returns the number of samples to be\n        processed based on the size of the first dimension of the\n        first input Numpy array. When `steps` is not `None` and\n        `batch_size` is `None`, returns `None`.\n\n    # Raises\n        ValueError: In case of invalid arguments.\n    """"""\n    if steps is not None and batch_size is not None:\n        raise ValueError(\n            \'If \' + steps_name + \' is set, the `batch_size` must be None.\')\n\n    if not ins or any(K.is_tensor(x) for x in ins):\n        if steps is None:\n            raise ValueError(\n                \'If your data is in the form of symbolic tensors, \'\n                \'you should specify the `\' + steps_name + \'` argument \'\n                \'(instead of the `batch_size` argument, \'\n                \'because symbolic tensors are expected to produce \'\n                \'batches of input data).\')\n        return None\n\n    if hasattr(ins[0], \'shape\'):\n        return int(ins[0].shape[0])\n    return None  # Edge case where ins == [static_learning_phase]\n\n\ndef iter_sequence_infinite(seq):\n    """"""Iterate indefinitely over a Sequence.\n\n    # Arguments\n        seq: Sequence object\n\n    # Returns\n        Generator yielding batches.\n    """"""\n    while True:\n        for item in seq:\n            yield item\n\n\ndef is_sequence(seq):\n    """"""Determine if an object follows the Sequence API.\n\n    # Arguments\n        seq: a possible Sequence object\n\n    # Returns\n        boolean, whether the object follows the Sequence API.\n    """"""\n    # TODO Dref360: Decide which pattern to follow. First needs a new TF Version.\n    return (getattr(seq, \'use_sequence_api\', False)\n            or set(dir(Sequence())).issubset(set(dir(seq) + [\'use_sequence_api\'])))\n\n\ndef is_generator_or_sequence(x):\n    """"""Check if `x` is a Keras generator type.""""""\n    return inspect.isgenerator(x) or is_sequence(x)\n\n\ndef should_run_validation(validation_freq, epoch):\n    """"""Checks if validation should be run this epoch.\n\n    # Arguments\n        validation_freq: Integer or list. If an integer, specifies how many training\n          epochs to run before a new validation run is performed. If a list,\n          specifies the epochs on which to run validation.\n        epoch: Integer, the number of the training epoch just completed.\n\n    # Returns\n        Bool, True if validation should be run.\n\n    # Raises\n        ValueError: if `validation_freq` is an Integer and less than 1, or if\n        it is neither an Integer nor a Sequence.\n    """"""\n    # `epoch` is 0-indexed internally but 1-indexed in the public API.\n    one_indexed_epoch = epoch + 1\n\n    if isinstance(validation_freq, int):\n        if validation_freq < 1:\n            raise ValueError(\'`validation_freq` can not be less than 1.\')\n        return one_indexed_epoch % validation_freq == 0\n\n    if not isinstance(validation_freq, collections.Container):\n        raise ValueError(\'`validation_freq` must be an Integer or \'\n                         \'`collections.Container` (e.g. list, tuple, etc.)\')\n    return one_indexed_epoch in validation_freq\n\n\ndef get_static_batch_size(layer):\n    """"""Gets the static batch size of a Layer.\n\n    # Arguments\n        layer: a `Layer` instance.\n\n    # Returns\n        The static batch size of a Layer.\n    """"""\n    batch_input_shape, _ = get_input_shape_and_dtype(layer)\n    if batch_input_shape is not None:\n        return batch_input_shape[0]\n    return None\n\n\ndef get_input_shape_and_dtype(layer):\n    """"""Retrieves input shape and input dtype of layer if applicable.\n\n    # Arguments\n        layer: Layer (or model) instance.\n\n    # Returns\n        Tuple (input_shape, input_dtype). Both could be None if the layer\n        does not have a defined input shape.\n\n    # Raises\n      ValueError: in case an empty Sequential or Functional model is passed.\n    """"""\n    def _is_graph_model(layer):\n        return ((hasattr(layer, \'_is_graph_network\') and layer._is_graph_network) or\n                layer.__class__.__name__ == \'Sequential\')\n\n    # In case of nested models: recover the first layer\n    # of the deepest model to infer input shape and dtype.\n    # Subclassed Models may not have been built so can\'t be checked.\n    while _is_graph_model(layer):\n        if not layer.layers:\n            raise ValueError(\'An empty Model cannot be used as a Layer.\')\n        layer = layer.layers[0]\n\n    if hasattr(layer, \'_batch_input_shape\'):\n        return layer._batch_input_shape, layer.dtype\n    return None, None\n\n\ndef get_loss_function(loss):\n    """"""Returns the loss corresponding to the loss input in `compile` API.""""""\n    if loss is None or isinstance(loss, losses.Loss):\n        return loss\n\n    # Deserialize loss configuration, if needed.\n    if isinstance(loss, collections.Mapping):\n        loss = losses.get(loss)\n\n    # Custom callable class.\n    if callable(loss) and not hasattr(loss, \'__name__\'):\n        return loss\n\n    # Wrap loss function with signature `(y_true, y_pred, **kwargs)`\n    # in `LossFunctionWrapper` class.\n    loss_fn = losses.get(loss)\n\n    # For losses which are given as strings/functions in the compile API,\n    # we always set the loss reduction type to be `SUM_OVER_BATCH_SIZE`..\n    return losses.LossFunctionWrapper(\n        loss_fn,\n        name=loss_fn.__name__,\n        reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE)\n\n\ndef get_output_sample_weight_and_mode(skip_target_weighing_indices,\n                                      sample_weight_mode, output_name,\n                                      output_index):\n    """"""Returns the sample weight and weight mode for a single output.""""""\n    if output_index in skip_target_weighing_indices:\n        return None, None\n\n    if sample_weight_mode == \'temporal\':\n        shape = [None, None]\n        mode = \'temporal\'\n    else:\n        shape = [None]\n        mode = None\n    weight = K.placeholder(\n        shape=shape,\n        name=output_name + \'_sample_weights\')\n    return weight, mode\n\n\ndef prepare_sample_weights(output_names, sample_weight_mode,\n                           skip_target_weighing_indices):\n    """"""Prepares sample weights for the model.\n\n    # Arguments\n        output_names: List of model output names.\n        sample_weight_mode: sample weight mode user input passed from compile API.\n        skip_target_weighing_indices: Indices of output for which sample weights\n            should be skipped.\n\n    # Returns\n        A pair of list of sample weights and sample weight modes\n            (one for each output).\n\n    # Raises\n        ValueError: In case of invalid `sample_weight_mode` input.\n    """"""\n    sample_weights = []\n    sample_weight_modes = []\n    if isinstance(sample_weight_mode, dict):\n        unknown_output = set(sample_weight_mode.keys()) - set(output_names)\n        if unknown_output:\n            raise ValueError(\n                \'Unknown entry in \'\n                \'sample_weight_mode dictionary: ""\' + str(unknown_output) +\n                \'"". Only expected the following keys: \' + str(output_names))\n        for i, name in enumerate(output_names):\n            if (i not in skip_target_weighing_indices and\n                    name not in sample_weight_mode):\n                raise ValueError(\n                    \'Output missing from sample_weight_modes dictionary\')\n            weight, mode = get_output_sample_weight_and_mode(\n                skip_target_weighing_indices,\n                sample_weight_mode.get(name),\n                name,\n                i)\n            sample_weights.append(weight)\n            sample_weight_modes.append(mode)\n    elif isinstance(sample_weight_mode, list):\n        if len(sample_weight_mode) != len(output_names):\n            raise ValueError(\'When passing a list as sample_weight_mode, \'\n                             \'it should have one entry per model output. \'\n                             \'The model has \' + str(len(output_names)) +\n                             \' outputs, but you passed \' +\n                             str(len(sample_weight_mode)) + \'sample_weight_modes\')\n        for i, name in enumerate(output_names):\n            weight, mode = get_output_sample_weight_and_mode(\n                skip_target_weighing_indices, sample_weight_mode[i], name, i)\n            sample_weights.append(weight)\n            sample_weight_modes.append(mode)\n    else:\n        for i, name in enumerate(output_names):\n            weight, mode = get_output_sample_weight_and_mode(\n                skip_target_weighing_indices, sample_weight_mode, name, i)\n            sample_weights.append(weight)\n            sample_weight_modes.append(mode)\n    return sample_weights, sample_weight_modes\n\n\ndef prepare_loss_functions(loss, output_names):\n    """"""Converts loss to a list of loss functions.\n\n    # Arguments\n        loss: String (name of objective function), objective function or\n            `Loss` instance. If the model has multiple outputs, you can use\n            a different loss on each output by passing a dictionary or a\n            list of losses. The loss value that will be minimized by the model\n            will then be the sum of all individual losses.\n        output_names: List of model output names.\n\n    # Returns\n        A list of loss objective functions.\n\n    # Raises:\n        ValueError: If loss is a dict with keys not in model output names,\n            or if loss is a list with len not equal to model outputs.\n    """"""\n    if isinstance(loss, collections.Mapping):\n        generic_utils.check_for_unexpected_keys(\'loss\', loss, output_names)\n        loss_functions = []\n        for name in output_names:\n            if name not in loss:\n                warnings.warn(\n                    \'Output {0} missing from loss dictionary. We assume \'\n                    \'this was done on purpose. The fit and evaluate APIs will not \'\n                    \'be expecting any data to be passed to {0}.\'.format(name))\n            loss_functions.append(get_loss_function(loss.get(name, None)))\n    elif isinstance(loss, six.string_types):\n        loss_functions = [get_loss_function(loss) for _ in output_names]\n    elif isinstance(loss, collections.Sequence):\n        if len(loss) != len(output_names):\n            raise ValueError(\'When passing a list as loss, it should have one entry \'\n                             \'per model outputs. The model has {} outputs, but you \'\n                             \'passed loss={}\'.format(len(output_names), loss))\n        loss_functions = [get_loss_function(l) for l in loss]\n    else:\n        loss_functions = [get_loss_function(loss) for _ in range(len(output_names))]\n\n    return loss_functions\n\n\ndef prepare_loss_weights(output_names, loss_weights=None):\n    """"""Converts loss weights to a list of loss weights.\n\n    # Arguments\n        output_names: List of model output names.\n        loss_weights: Optional list or dictionary specifying scalar coefficients\n            (Python floats) to weight the loss contributions of different model\n            outputs. The loss value that will be minimized by the model will then be\n            the *weighted sum* of all individual losses, weighted by the\n            `loss_weights` coefficients. If a list, it is expected to have a 1:1\n            mapping to the model\'s outputs. If a dict, it is expected to map\n            output names (strings) to scalar coefficients.\n\n    # Returns\n        A list of loss weights of python floats.\n\n    # Raises\n        ValueError: If loss weight is a dict with key not in model output names,\n            or if loss is a list with len not equal to model outputs.\n    """"""\n    if loss_weights is None:\n        weights_list = [1.] * len(output_names)\n    elif isinstance(loss_weights, collections.Mapping):\n        generic_utils.check_for_unexpected_keys(\'loss_weights\', loss_weights,\n                                                output_names)\n        weights_list = [loss_weights.get(name, 1.) for name in output_names]\n    elif isinstance(loss_weights, list):\n        if len(loss_weights) != len(output_names):\n            raise ValueError(\'When passing a list as loss_weights, \'\n                             \'it should have one entry per model output. \'\n                             \'The model has \' + str(len(output_names)) +\n                             \' outputs, but you passed loss_weights=\' +\n                             str(loss_weights))\n        weights_list = loss_weights\n    else:\n        raise TypeError(\'Could not interpret loss_weights argument: \' +\n                        str(loss_weights) + \' - expected a list of dicts.\')\n\n    return weights_list\n\n\ndef collect_per_output_metric_info(metrics,\n                                   output_names,\n                                   output_shapes,\n                                   loss_fns,\n                                   is_weighted=False):\n    """"""Maps metric names and functions to model outputs.\n\n    # Arguments\n        metrics: a list or a list of lists or a dict of metric functions.\n        output_names: a list of the names (strings) of model outputs.\n        output_shapes: a list of the shapes (strings) of model outputs.\n        loss_fns: a list of the loss functions corresponding to the model outputs.\n        is_weighted: Boolean indicating whether the given metrics are weighted.\n\n    # Returns\n        A list (one entry per model output) of dicts.\n        For instance, if the model has 2 outputs, and for the first output\n        we want to compute ""binary_accuracy"" and ""binary_crossentropy"",\n        and just ""binary_accuracy"" for the second output,\n        the list would look like: `[{\n            \'acc\': binary_accuracy(),\n            \'ce\': binary_crossentropy(),\n        }, {\n            \'acc\': binary_accuracy(),\n        }]`\n\n    # Raises\n        TypeError: if an incorrect type is passed for the `metrics` argument.\n    """"""\n    if not metrics:\n        return [{} for _ in output_names]\n\n    if isinstance(metrics, list):\n        any_sub_list = any(isinstance(m, list) for m in metrics)\n        if any_sub_list:\n            if len(metrics) != len(output_names):\n                raise ValueError(\'When passing a list of lists as `metrics`, \'\n                                 \'it should have one entry per model output. \'\n                                 \'The model has \' + str(len(output_names)) +\n                                 \' outputs, but you passed metrics=\' + str(metrics))\n            # User has provided a list of len = len(outputs).\n            nested_metrics = [generic_utils.to_list(m) for m in metrics]\n        else:\n            # If it is a single list we then apply all metrics to all outputs.\n            if len(output_names) > 1:\n                nested_metrics = []\n                for _ in output_names:\n                    nested_metrics.append(\n                        [metrics_module.clone_metric(m) for m in metrics])\n            else:\n                nested_metrics = [metrics]\n    elif isinstance(metrics, collections.Mapping):\n        generic_utils.check_for_unexpected_keys(\'metrics\', metrics, output_names)\n        nested_metrics = []\n        for name in output_names:\n            output_metrics = generic_utils.to_list(metrics.get(name, []))\n            nested_metrics.append(output_metrics)\n    else:\n        raise TypeError(\'Type of `metrics` argument not understood. \'\n                        \'Expected a list or dictionary, found: \' + str(metrics))\n\n    per_output_metrics = []\n    for i, metrics in enumerate(nested_metrics):\n        metrics_dict = OrderedDict()\n        for metric in metrics:\n            metric_name = get_metric_name(metric, is_weighted)\n            metric_fn = get_metric_function(\n                metric, output_shape=output_shapes[i], loss_fn=loss_fns[i])\n\n            # If the metric function is not stateful, we create a stateful version.\n            if not isinstance(metric_fn, metrics_module.Metric):\n                metric_fn = metrics_module.MeanMetricWrapper(\n                    metric_fn, name=metric_name)\n            metrics_dict[metric_name] = metric_fn\n        per_output_metrics.append(metrics_dict)\n\n    return per_output_metrics\n\n\ndef get_metric_name(metric, weighted=False):\n    """"""Returns the name corresponding to the given metric input.\n\n    # Arguments\n        metric: Metric function name or reference.\n        weighted: Boolean indicating if the given metric is weighted.\n\n    # Returns\n        The metric name.\n    """"""\n    # We keep the string that the user has set in compile as the metric name.\n    if isinstance(metric, six.string_types):\n        return metric\n\n    metric = metrics_module.get(metric)\n    return metric.name if hasattr(metric, \'name\') else metric.__name__\n\n\ndef get_metric_function(metric, output_shape=None, loss_fn=None):\n    """"""Returns the metric function corresponding to the given metric input.\n\n    # Arguments\n        metric: Metric function name or reference.\n        output_shape: The shape of the output that this metric will be calculated\n            for.\n        loss_fn: The loss function used.\n\n    # Returns\n        The metric function.\n    """"""\n    if metric not in [\'accuracy\', \'acc\', \'crossentropy\', \'ce\']:\n        return metrics_module.get(metric)\n\n    is_sparse_categorical_crossentropy = (\n        isinstance(loss_fn, losses.SparseCategoricalCrossentropy) or\n        (isinstance(loss_fn, losses.LossFunctionWrapper) and\n         loss_fn.fn == losses.sparse_categorical_crossentropy))\n\n    is_binary_crossentropy = (\n        isinstance(loss_fn, losses.BinaryCrossentropy) or\n        (isinstance(loss_fn, losses.LossFunctionWrapper) and\n         loss_fn.fn == losses.binary_crossentropy))\n\n    if metric in [\'accuracy\', \'acc\']:\n        if output_shape[-1] == 1 or is_binary_crossentropy:\n            return metrics_module.binary_accuracy\n        elif is_sparse_categorical_crossentropy:\n            return metrics_module.sparse_categorical_accuracy\n        # If the output_shape[-1] is not 1, then we know output is `categorical`.\n        # We assume it is sparse categorical only if loss is explicitly given\n        # as sparse categorical crossentropy loss.\n        return metrics_module.categorical_accuracy\n    else:\n        if output_shape[-1] == 1 or is_binary_crossentropy:\n            return metrics_module.binary_crossentropy\n        elif is_sparse_categorical_crossentropy:\n            return metrics_module.sparse_categorical_crossentropy\n        return metrics_module.categorical_crossentropy\n\n\ndef call_metric_function(metric_fn,\n                         y_true,\n                         y_pred=None,\n                         weights=None,\n                         mask=None):\n    """"""Invokes metric function and returns the metric result tensor.""""""\n    if mask is not None:\n        mask = K.cast(mask, y_pred.dtype)\n        if weights is None:\n            # Use mask as sample weight.\n            weights = mask\n        else:\n            # Update dimensions of weights to match with mask.\n            mask, _, weights = losses_utils.squeeze_or_expand_dimensions(\n                mask, sample_weight=weights)\n            weights *= mask\n\n    if y_pred is not None:\n        update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)\n        with K.control_dependencies(update_ops):  # For TF\n            metric_fn.result()\n    else:\n        # `Mean` metric only takes a single value.\n        update_ops = metric_fn.update_state(y_true, sample_weight=weights)\n        with K.control_dependencies(update_ops):  # For TF\n            metric_fn.result()\n'"
keras/layers/__init__.py,0,"b'from __future__ import absolute_import\n\nfrom ..utils.generic_utils import deserialize_keras_object\nfrom ..engine.base_layer import Layer\nfrom ..engine import Input\nfrom ..engine import InputLayer\nfrom ..engine.base_layer import InputSpec\n\nfrom .merge import Add\nfrom .merge import Subtract\nfrom .merge import Multiply\nfrom .merge import Average\nfrom .merge import Maximum\nfrom .merge import Minimum\nfrom .merge import Concatenate\nfrom .merge import Dot\nfrom .merge import add\nfrom .merge import subtract\nfrom .merge import multiply\nfrom .merge import average\nfrom .merge import maximum\nfrom .merge import minimum\nfrom .merge import concatenate\nfrom .merge import dot\n\nfrom .core import Dense\nfrom .core import Activation\nfrom .core import Dropout\nfrom .core import Flatten\nfrom .core import Reshape\nfrom .core import Permute\nfrom .core import RepeatVector\nfrom .core import Lambda\nfrom .core import ActivityRegularization\nfrom .core import Masking\nfrom .core import SpatialDropout1D\nfrom .core import SpatialDropout2D\nfrom .core import SpatialDropout3D\n\nfrom .convolutional import Conv1D\nfrom .convolutional import Conv2D\nfrom .convolutional import SeparableConv1D\nfrom .convolutional import SeparableConv2D\nfrom .convolutional import DepthwiseConv2D\nfrom .convolutional import Conv2DTranspose\nfrom .convolutional import Conv3D\nfrom .convolutional import Conv3DTranspose\nfrom .convolutional import Cropping1D\nfrom .convolutional import Cropping2D\nfrom .convolutional import Cropping3D\nfrom .convolutional import UpSampling1D\nfrom .convolutional import UpSampling2D\nfrom .convolutional import UpSampling3D\nfrom .convolutional import ZeroPadding1D\nfrom .convolutional import ZeroPadding2D\nfrom .convolutional import ZeroPadding3D\n\n# Aliases (not in the docs)\nfrom .convolutional import Convolution1D\nfrom .convolutional import Convolution2D\nfrom .convolutional import Convolution3D\nfrom .convolutional import Deconvolution2D\nfrom .convolutional import Deconvolution3D\n\nfrom .pooling import MaxPooling1D\nfrom .pooling import MaxPooling2D\nfrom .pooling import MaxPooling3D\nfrom .pooling import AveragePooling1D\nfrom .pooling import AveragePooling2D\nfrom .pooling import AveragePooling3D\nfrom .pooling import GlobalMaxPooling1D\nfrom .pooling import GlobalMaxPooling2D\nfrom .pooling import GlobalMaxPooling3D\nfrom .pooling import GlobalAveragePooling2D\nfrom .pooling import GlobalAveragePooling1D\nfrom .pooling import GlobalAveragePooling3D\n\n# Aliases (not in the docs)\nfrom .pooling import MaxPool1D\nfrom .pooling import MaxPool2D\nfrom .pooling import MaxPool3D\nfrom .pooling import AvgPool1D\nfrom .pooling import AvgPool2D\nfrom .pooling import AvgPool3D\nfrom .pooling import GlobalMaxPool1D\nfrom .pooling import GlobalMaxPool2D\nfrom .pooling import GlobalMaxPool3D\nfrom .pooling import GlobalAvgPool1D\nfrom .pooling import GlobalAvgPool2D\nfrom .pooling import GlobalAvgPool3D\n\nfrom .local import LocallyConnected1D\nfrom .local import LocallyConnected2D\n\nfrom .recurrent import RNN\nfrom .recurrent import SimpleRNN\nfrom .recurrent import GRU\nfrom .recurrent import LSTM\nfrom .recurrent import SimpleRNNCell\nfrom .recurrent import GRUCell\nfrom .recurrent import LSTMCell\nfrom .recurrent import StackedRNNCells\n\nfrom .cudnn_recurrent import CuDNNGRU\nfrom .cudnn_recurrent import CuDNNLSTM\n\nfrom .normalization import BatchNormalization\n\nfrom .embeddings import Embedding\n\nfrom .noise import GaussianNoise\nfrom .noise import GaussianDropout\nfrom .noise import AlphaDropout\n\nfrom .advanced_activations import LeakyReLU\nfrom .advanced_activations import PReLU\nfrom .advanced_activations import ELU\nfrom .advanced_activations import ThresholdedReLU\nfrom .advanced_activations import Softmax\nfrom .advanced_activations import ReLU\n\nfrom .wrappers import Bidirectional\nfrom .wrappers import TimeDistributed\n\nfrom .convolutional_recurrent import ConvLSTM2D\nfrom .convolutional_recurrent import ConvLSTM2DCell\n\n# Legacy imports\nfrom ..legacy.layers import MaxoutDense\nfrom ..legacy.layers import Highway\nfrom ..legacy.layers import AtrousConvolution1D\nfrom ..legacy.layers import AtrousConvolution2D\nfrom ..legacy.layers import Recurrent\nfrom ..legacy.layers import ConvRecurrent2D\n\n\ndef serialize(layer):\n    """"""Serialize a layer.\n\n    # Arguments\n        layer: a Layer object.\n\n    # Returns\n        dictionary with config.\n    """"""\n    return {\'class_name\': layer.__class__.__name__,\n            \'config\': layer.get_config()}\n\n\ndef deserialize(config, custom_objects=None):\n    """"""Instantiate a layer from a config dictionary.\n\n    # Arguments\n        config: dict of the form {\'class_name\': str, \'config\': dict}\n        custom_objects: dict mapping class names (or function names)\n            of custom (non-Keras) objects to class/functions\n\n    # Returns\n        Layer instance (may be Model, Sequential, Layer...)\n    """"""\n    from .. import models\n    globs = globals()  # All layers.\n    globs[\'Model\'] = models.Model\n    globs[\'Sequential\'] = models.Sequential\n    return deserialize_keras_object(config,\n                                    module_objects=globs,\n                                    custom_objects=custom_objects,\n                                    printable_module_name=\'layer\')\n'"
keras/layers/advanced_activations.py,0,"b'# -*- coding: utf-8 -*-\n""""""Layers that act as activation functions.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import activations\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom ..engine.base_layer import Layer\nfrom ..engine.base_layer import InputSpec\nfrom .. import backend as K\nfrom ..legacy import interfaces\nfrom ..utils.generic_utils import to_list\n\n\nclass LeakyReLU(Layer):\n    """"""Leaky version of a Rectified Linear Unit.\n\n    It allows a small gradient when the unit is not active:\n    `f(x) = alpha * x for x < 0`,\n    `f(x) = x for x >= 0`.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n    # Arguments\n        alpha: float >= 0. Negative slope coefficient.\n\n    # References\n        - [Rectifier Nonlinearities Improve Neural Network Acoustic Models](\n           https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)\n    """"""\n\n    def __init__(self, alpha=0.3, **kwargs):\n        super(LeakyReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha = K.cast_to_floatx(alpha)\n\n    def call(self, inputs):\n        return K.relu(inputs, alpha=self.alpha)\n\n    def get_config(self):\n        config = {\'alpha\': float(self.alpha)}\n        base_config = super(LeakyReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass PReLU(Layer):\n    """"""Parametric Rectified Linear Unit.\n\n    It follows:\n    `f(x) = alpha * x for x < 0`,\n    `f(x) = x for x >= 0`,\n    where `alpha` is a learned array with the same shape as x.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n    # Arguments\n        alpha_initializer: initializer function for the weights.\n        alpha_regularizer: regularizer for the weights.\n        alpha_constraint: constraint for the weights.\n        shared_axes: the axes along which to share learnable\n            parameters for the activation function.\n            For example, if the incoming feature maps\n            are from a 2D convolution\n            with output shape `(batch, height, width, channels)`,\n            and you wish to share parameters across space\n            so that each filter only has one set of parameters,\n            set `shared_axes=[1, 2]`.\n\n    # References\n        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n           ImageNet Classification](https://arxiv.org/abs/1502.01852)\n    """"""\n\n    @interfaces.legacy_prelu_support\n    def __init__(self, alpha_initializer=\'zeros\',\n                 alpha_regularizer=None,\n                 alpha_constraint=None,\n                 shared_axes=None,\n                 **kwargs):\n        super(PReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha_initializer = initializers.get(alpha_initializer)\n        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n        self.alpha_constraint = constraints.get(alpha_constraint)\n        if shared_axes is None:\n            self.shared_axes = None\n        else:\n            self.shared_axes = to_list(shared_axes, allow_tuple=True)\n\n    def build(self, input_shape):\n        param_shape = list(input_shape[1:])\n        self.param_broadcast = [False] * len(param_shape)\n        if self.shared_axes is not None:\n            for i in self.shared_axes:\n                param_shape[i - 1] = 1\n                self.param_broadcast[i - 1] = True\n        self.alpha = self.add_weight(shape=param_shape,\n                                     name=\'alpha\',\n                                     initializer=self.alpha_initializer,\n                                     regularizer=self.alpha_regularizer,\n                                     constraint=self.alpha_constraint)\n        # Set input spec\n        axes = {}\n        if self.shared_axes:\n            for i in range(1, len(input_shape)):\n                if i not in self.shared_axes:\n                    axes[i] = input_shape[i]\n        self.input_spec = InputSpec(ndim=len(input_shape), axes=axes)\n        self.built = True\n\n    def call(self, inputs, mask=None):\n        pos = K.relu(inputs)\n        if K.backend() == \'theano\':\n            neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *\n                   (inputs - K.abs(inputs)) * 0.5)\n        else:\n            neg = -self.alpha * K.relu(-inputs)\n        return pos + neg\n\n    def get_config(self):\n        config = {\n            \'alpha_initializer\': initializers.serialize(self.alpha_initializer),\n            \'alpha_regularizer\': regularizers.serialize(self.alpha_regularizer),\n            \'alpha_constraint\': constraints.serialize(self.alpha_constraint),\n            \'shared_axes\': self.shared_axes\n        }\n        base_config = super(PReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass ELU(Layer):\n    """"""Exponential Linear Unit.\n\n    It follows:\n    `f(x) =  alpha * (exp(x) - 1.) for x < 0`,\n    `f(x) = x for x >= 0`.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n    # Arguments\n        alpha: scale for the negative factor.\n\n    # References\n        - [Fast and Accurate Deep Network Learning by Exponential Linear Units\n           (ELUs)](https://arxiv.org/abs/1511.07289v1)\n    """"""\n\n    def __init__(self, alpha=1.0, **kwargs):\n        super(ELU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha = K.cast_to_floatx(alpha)\n\n    def call(self, inputs):\n        return K.elu(inputs, self.alpha)\n\n    def get_config(self):\n        config = {\'alpha\': float(self.alpha)}\n        base_config = super(ELU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass ThresholdedReLU(Layer):\n    """"""Thresholded Rectified Linear Unit.\n\n    It follows:\n    `f(x) = x for x > theta`,\n    `f(x) = 0 otherwise`.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n    # Arguments\n        theta: float >= 0. Threshold location of activation.\n\n    # References\n        - [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](\n           https://arxiv.org/abs/1402.3337)\n    """"""\n\n    def __init__(self, theta=1.0, **kwargs):\n        super(ThresholdedReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.theta = K.cast_to_floatx(theta)\n\n    def call(self, inputs, mask=None):\n        return inputs * K.cast(K.greater(inputs, self.theta), K.floatx())\n\n    def get_config(self):\n        config = {\'theta\': float(self.theta)}\n        base_config = super(ThresholdedReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass Softmax(Layer):\n    """"""Softmax activation function.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n    # Arguments\n        axis: Integer, axis along which the softmax normalization is applied.\n    """"""\n\n    def __init__(self, axis=-1, **kwargs):\n        super(Softmax, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis\n\n    def call(self, inputs):\n        return activations.softmax(inputs, axis=self.axis)\n\n    def get_config(self):\n        config = {\'axis\': self.axis}\n        base_config = super(Softmax, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass ReLU(Layer):\n    """"""Rectified Linear Unit activation function.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    Otherwise, it follows:\n    `f(x) = max_value` for `x >= max_value`,\n    `f(x) = x` for `threshold <= x < max_value`,\n    `f(x) = negative_slope * (x - threshold)` otherwise.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n    # Arguments\n        max_value: float >= 0. Maximum activation value.\n        negative_slope: float >= 0. Negative slope coefficient.\n        threshold: float. Threshold value for thresholded activation.\n    """"""\n\n    def __init__(self, max_value=None, negative_slope=0.,\n                 threshold=0., **kwargs):\n        super(ReLU, self).__init__(**kwargs)\n        if max_value is not None and max_value < 0.:\n            raise ValueError(\'max_value of ReLU layer \'\n                             \'cannot be negative value: %s\' % str(max_value))\n        if negative_slope < 0.:\n            raise ValueError(\'negative_slope of ReLU layer cannot be \'\n                             \'negative value: %s\' % str(negative_slope))\n        self.supports_masking = True\n        if max_value is not None:\n            max_value = K.cast_to_floatx(max_value)\n        self.max_value = max_value\n        self.negative_slope = K.cast_to_floatx(negative_slope)\n        self.threshold = K.cast_to_floatx(threshold)\n\n    def call(self, inputs):\n        return K.relu(inputs,\n                      alpha=self.negative_slope,\n                      max_value=self.max_value,\n                      threshold=self.threshold)\n\n    def get_config(self):\n        config = {\n            \'max_value\': self.max_value,\n            \'negative_slope\': self.negative_slope,\n            \'threshold\': self.threshold\n        }\n        base_config = super(ReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
keras/layers/convolutional.py,0,"b'# -*- coding: utf-8 -*-\n""""""Convolutional layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend as K\nfrom .. import activations\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom ..engine.base_layer import Layer\nfrom ..engine.base_layer import InputSpec\nfrom ..utils import conv_utils\nfrom ..utils.generic_utils import transpose_shape\nfrom ..legacy import interfaces\n\n# imports for backwards namespace compatibility\nfrom .pooling import AveragePooling1D\nfrom .pooling import AveragePooling2D\nfrom .pooling import AveragePooling3D\nfrom .pooling import MaxPooling1D\nfrom .pooling import MaxPooling2D\nfrom .pooling import MaxPooling3D\n\nfrom ..legacy.layers import AtrousConvolution1D\nfrom ..legacy.layers import AtrousConvolution2D\n\n\nclass _Conv(Layer):\n    """"""Abstract nD convolution layer (private, used as implementation base).\n\n    This layer creates a convolution kernel that is convolved\n    with the layer input to produce a tensor of outputs.\n    If `use_bias` is True, a bias vector is created and added to the outputs.\n    Finally, if `activation` is not `None`,\n    it is applied to the outputs as well.\n\n    # Arguments\n        rank: An integer, the rank of the convolution,\n            e.g. ""2"" for 2D convolution.\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of n integers, specifying the\n            dimensions of the convolution window.\n        strides: An integer or tuple/list of n integers,\n            specifying the strides of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, ..., channels)` while `""channels_first""` corresponds to\n            inputs with shape `(batch, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: An integer or tuple/list of n integers, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n    """"""\n\n    def __init__(self, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_Conv, self).__init__(**kwargs)\n        self.rank = rank\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n                                                      \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, rank, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank,\n                                                        \'dilation_rate\')\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=self.rank + 2)\n\n    def build(self, input_shape):\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.conv1d(\n                inputs,\n                self.kernel,\n                strides=self.strides[0],\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate[0])\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 3:\n            outputs = K.conv3d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            space = input_shape[1:-1]\n        elif self.data_format == \'channels_first\':\n            space = input_shape[2:]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_utils.conv_output_length(\n                space[i],\n                self.kernel_size[i],\n                padding=self.padding,\n                stride=self.strides[i],\n                dilation=self.dilation_rate[i])\n            new_space.append(new_dim)\n        if self.data_format == \'channels_last\':\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n        elif self.data_format == \'channels_first\':\n            return (input_shape[0], self.filters) + tuple(new_space)\n\n    def get_config(self):\n        config = {\n            \'rank\': self.rank,\n            \'filters\': self.filters,\n            \'kernel_size\': self.kernel_size,\n            \'strides\': self.strides,\n            \'padding\': self.padding,\n            \'data_format\': self.data_format,\n            \'dilation_rate\': self.dilation_rate,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\':\n                regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(_Conv, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Conv1D(_Conv):\n    """"""1D convolution layer (e.g. temporal convolution).\n\n    This layer creates a convolution kernel that is convolved\n    with the layer input over a single spatial (or temporal) dimension\n    to produce a tensor of outputs.\n    If `use_bias` is True, a bias vector is created and added to the outputs.\n    Finally, if `activation` is not `None`,\n    it is applied to the outputs as well.\n\n    When using this layer as the first layer in a model,\n    provide an `input_shape` argument (tuple of integers or `None`, does not\n    include the batch axis), e.g. `input_shape=(10, 128)` for time series\n    sequences of 10 time steps with 128 features per step in\n    `data_format=""channels_last""`, or `(None, 128)` for variable-length\n    sequences with 128 features per step.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of a single integer,\n            specifying the length of the 1D convolution window.\n        strides: An integer or tuple/list of a single integer,\n            specifying the stride length of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: One of `""valid""`, `""causal""` or `""same""` (case-insensitive).\n            `""valid""` means ""no padding"".\n            `""same""` results in padding the input such that\n            the output has the same length as the original input.\n            `""causal""` results in causal (dilated) convolutions,\n            e.g. `output[t]` does not depend on `input[t + 1:]`.\n            A zero padding is used such that\n            the output has the same length as the original input.\n            Useful when modeling temporal data where the model\n            should not violate the temporal order. See\n            [WaveNet: A Generative Model for Raw Audio, section 2.1](\n            https://arxiv.org/abs/1609.03499).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, steps, channels)`\n            (default format for temporal data in Keras)\n            while `""channels_first""` corresponds to inputs\n            with shape `(batch, channels, steps)`.\n        dilation_rate: an integer or tuple/list of a single integer, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        3D tensor with shape: `(batch, steps, channels)`\n\n    # Output shape\n        3D tensor with shape: `(batch, new_steps, filters)`\n        `steps` value might have changed due to padding or strides.\n    """"""\n\n    @interfaces.legacy_conv1d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=\'channels_last\',\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if padding == \'causal\':\n            if data_format != \'channels_last\':\n                raise ValueError(\'When using causal padding in `Conv1D`, \'\n                                 \'`data_format` must be ""channels_last"" \'\n                                 \'(temporal data).\')\n        super(Conv1D, self).__init__(\n            rank=1,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def get_config(self):\n        config = super(Conv1D, self).get_config()\n        config.pop(\'rank\')\n        return config\n\n\nclass Conv2D(_Conv):\n    """"""2D convolution layer (e.g. spatial convolution over images).\n\n    This layer creates a convolution kernel that is convolved\n    with the layer input to produce a tensor of\n    outputs. If `use_bias` is True,\n    a bias vector is created and added to the outputs. Finally, if\n    `activation` is not `None`, it is applied to the outputs as well.\n\n    When using this layer as the first layer in a model,\n    provide the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n    in `data_format=""channels_last""`.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution\n            along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n            Note that `""same""` is slightly inconsistent across backends with\n            `strides` != 1, as described\n            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: an integer or tuple/list of 2 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)`\n        if `data_format` is `""channels_last""`.\n        `rows` and `cols` values might have changed due to padding.\n    """"""\n\n    @interfaces.legacy_conv2d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2D, self).__init__(\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def get_config(self):\n        config = super(Conv2D, self).get_config()\n        config.pop(\'rank\')\n        return config\n\n\nclass Conv3D(_Conv):\n    """"""3D convolution layer (e.g. spatial convolution over volumes).\n\n    This layer creates a convolution kernel that is convolved\n    with the layer input to produce a tensor of\n    outputs. If `use_bias` is True,\n    a bias vector is created and added to the outputs. Finally, if\n    `activation` is not `None`, it is applied to the outputs as well.\n\n    When using this layer as the first layer in a model,\n    provide the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis),\n    e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n    with a single channel,\n    in `data_format=""channels_last""`.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 3 integers, specifying the\n            depth, height and width of the 3D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 3 integers,\n            specifying the strides of the convolution along each spatial dimension.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: an integer or tuple/list of 3 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        5D tensor with shape:\n        `(batch, channels, conv_dim1, conv_dim2, conv_dim3)`\n        if `data_format` is `""channels_first""`\n        or 5D tensor with shape:\n        `(batch, conv_dim1, conv_dim2, conv_dim3, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        5D tensor with shape:\n        `(batch, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n        if `data_format` is `""channels_first""`\n        or 5D tensor with shape:\n        `(batch, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n        if `data_format` is `""channels_last""`.\n        `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have\n        changed due to padding.\n    """"""\n\n    @interfaces.legacy_conv3d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv3D, self).__init__(\n            rank=3,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def get_config(self):\n        config = super(Conv3D, self).get_config()\n        config.pop(\'rank\')\n        return config\n\n\nclass Conv2DTranspose(Conv2D):\n    """"""Transposed convolution layer (sometimes called Deconvolution).\n\n    The need for transposed convolutions generally arises\n    from the desire to use a transformation going in the opposite direction\n    of a normal convolution, i.e., from something that has the shape of the\n    output of some convolution to something that has the shape of its input\n    while maintaining a connectivity pattern that is compatible with\n    said convolution.\n\n    When using this layer as the first layer in a model,\n    provide the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n    in `data_format=""channels_last""`.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution\n            along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        output_padding: An integer or tuple/list of 2 integers,\n            specifying the amount of padding along the height and width\n            of the output tensor.\n            Can be a single integer to specify the same value for all\n            spatial dimensions.\n            The amount of output padding along a given dimension must be\n            lower than the stride along that same dimension.\n            If set to `None` (default), the output shape is inferred.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: an integer or tuple/list of 2 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)`\n        if `data_format` is `""channels_last""`.\n        `rows` and `cols` values might have changed due to padding.\n        If `output_padding` is specified:\n\n        ```\n        new_rows = ((rows - 1) * strides[0] + kernel_size[0]\n                    - 2 * padding[0] + output_padding[0])\n        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n                    - 2 * padding[1] + output_padding[1])\n        ```\n\n    # References\n        - [A guide to convolution arithmetic for deep learning](\n           https://arxiv.org/abs/1603.07285v1)\n        - [Deconvolutional Networks](\n           https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n    """"""\n\n    @interfaces.legacy_deconv2d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 output_padding=None,\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n        self.output_padding = output_padding\n        if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n                self.output_padding, 2, \'output_padding\')\n            for stride, out_pad in zip(self.strides, self.output_padding):\n                if out_pad >= stride:\n                    raise ValueError(\'Stride \' + str(self.strides) + \' must be \'\n                                     \'greater than output padding \' +\n                                     str(self.output_padding))\n\n    def build(self, input_shape):\n        if len(input_shape) != 4:\n            raise ValueError(\'Inputs should have rank \' +\n                             str(4) +\n                             \'; Received input shape:\', str(input_shape))\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == \'channels_first\':\n            h_axis, w_axis = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height, width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding is None:\n            out_pad_h = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic output shape:\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding,\n                                              out_pad_h,\n                                              self.dilation_rate[0])\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding,\n                                             out_pad_w,\n                                             self.dilation_rate[1])\n        if self.data_format == \'channels_first\':\n            output_shape = (batch_size, self.filters, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n            inputs,\n            self.kernel,\n            output_shape,\n            self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        if self.data_format == \'channels_first\':\n            c_axis, h_axis, w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1, 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding is None:\n            out_pad_h = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                        stride_h,\n                                                        kernel_h,\n                                                        self.padding,\n                                                        out_pad_h,\n                                                        self.dilation_rate[0])\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                        stride_w,\n                                                        kernel_w,\n                                                        self.padding,\n                                                        out_pad_w,\n                                                        self.dilation_rate[1])\n        return tuple(output_shape)\n\n    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n        config[\'output_padding\'] = self.output_padding\n        return config\n\n\nclass Conv3DTranspose(Conv3D):\n    """"""Transposed convolution layer (sometimes called Deconvolution).\n\n    The need for transposed convolutions generally arises\n    from the desire to use a transformation going in the opposite direction\n    of a normal convolution, i.e., from something that has the shape of the\n    output of some convolution to something that has the shape of its input\n    while maintaining a connectivity pattern that is compatible with\n    said convolution.\n\n    When using this layer as the first layer in a model,\n    provide the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis),\n    e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3 channels\n    if `data_format=""channels_last""`.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 3 integers, specifying the\n            depth, height and width of the 3D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 3 integers,\n            specifying the strides of the convolution\n            along the depth, height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        output_padding: An integer or tuple/list of 3 integers,\n            specifying the amount of padding along the depth, height, and\n            width.\n            Can be a single integer to specify the same value for all\n            spatial dimensions.\n            The amount of output padding along a given dimension must be\n            lower than the stride along that same dimension.\n            If set to `None` (default), the output shape is inferred.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, depth, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, depth, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: an integer or tuple/list of 3 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        5D tensor with shape:\n        `(batch, channels, depth, rows, cols)`\n        if `data_format` is `""channels_first""`\n        or 5D tensor with shape:\n        `(batch, depth, rows, cols, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        5D tensor with shape:\n        `(batch, filters, new_depth, new_rows, new_cols)`\n        if `data_format` is `""channels_first""`\n        or 5D tensor with shape:\n        `(batch, new_depth, new_rows, new_cols, filters)`\n        if `data_format` is `""channels_last""`.\n        `depth` and `rows` and `cols` values might have changed due to padding.\n        If `output_padding` is specified::\n\n        ```\n        new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n                     - 2 * padding[0] + output_padding[0])\n        new_rows = ((rows - 1) * strides[1] + kernel_size[1]\n                    - 2 * padding[1] + output_padding[1])\n        new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n                    - 2 * padding[2] + output_padding[2])\n        ```\n\n    # References\n        - [A guide to convolution arithmetic for deep learning](\n           https://arxiv.org/abs/1603.07285v1)\n        - [Deconvolutional Networks](\n           https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n    """"""\n\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1, 1),\n                 padding=\'valid\',\n                 output_padding=None,\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv3DTranspose, self).__init__(\n            filters,\n            kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n        self.output_padding = output_padding\n        if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n                self.output_padding, 3, \'output_padding\')\n            for stride, out_pad in zip(self.strides, self.output_padding):\n                if out_pad >= stride:\n                    raise ValueError(\'Stride \' + str(self.strides) + \' must be \'\n                                     \'greater than output padding \' +\n                                     str(self.output_padding))\n\n    def build(self, input_shape):\n        if len(input_shape) != 5:\n            raise ValueError(\'Inputs should have rank \' +\n                             str(5) +\n                             \'; Received input shape:\', str(input_shape))\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=5, axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == \'channels_first\':\n            d_axis, h_axis, w_axis = 2, 3, 4\n        else:\n            d_axis, h_axis, w_axis = 1, 2, 3\n\n        depth = input_shape[d_axis]\n        height = input_shape[h_axis]\n        width = input_shape[w_axis]\n\n        kernel_d, kernel_h, kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n        if self.output_padding is None:\n            out_pad_d = out_pad_h = out_pad_w = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic output shape:\n        out_depth = conv_utils.deconv_length(depth,\n                                             stride_d, kernel_d,\n                                             self.padding,\n                                             out_pad_d)\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding,\n                                              out_pad_h)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding,\n                                             out_pad_w)\n\n        if self.data_format == \'channels_first\':\n            output_shape = (batch_size, self.filters,\n                            out_depth, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_depth,\n                            out_height, out_width, self.filters)\n\n        outputs = K.conv3d_transpose(inputs,\n                                     self.kernel,\n                                     output_shape,\n                                     self.strides,\n                                     padding=self.padding,\n                                     data_format=self.data_format)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        if self.data_format == \'channels_first\':\n            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n        else:\n            c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n        kernel_d, kernel_h, kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n        if self.output_padding is None:\n            out_pad_d = out_pad_h = out_pad_w = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\n        output_shape[c_axis] = self.filters\n        output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n                                                        stride_d,\n                                                        kernel_d,\n                                                        self.padding,\n                                                        out_pad_d)\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                        stride_h,\n                                                        kernel_h,\n                                                        self.padding,\n                                                        out_pad_h)\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                        stride_w,\n                                                        kernel_w,\n                                                        self.padding,\n                                                        out_pad_w)\n\n        return tuple(output_shape)\n\n    def get_config(self):\n        config = super(Conv3DTranspose, self).get_config()\n        config.pop(\'dilation_rate\')\n        config[\'output_padding\'] = self.output_padding\n        return config\n\n\nclass _SeparableConv(_Conv):\n    """"""Abstract nD depthwise separable convolution layer (private).\n\n    Separable convolutions consist in first performing\n    a depthwise spatial convolution\n    (which acts on each input channel separately)\n    followed by a pointwise convolution which mixes together the resulting\n    output channels. The `depth_multiplier` argument controls how many\n    output channels are generated per input channel in the depthwise step.\n\n    Intuitively, separable convolutions can be understood as\n    a way to factorize a convolution kernel into two smaller kernels,\n    or as an extreme version of an Inception block.\n\n    # Arguments\n        rank: An integer, the rank of the convolution,\n            e.g. ""2"" for 2D convolution.\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution\n            along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: an integer or tuple/list of n integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        depth_multiplier: The number of depthwise convolution output channels\n            for each input channel.\n            The total number of depthwise convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        depthwise_initializer: Initializer for the depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n        pointwise_initializer: Initializer for the pointwise kernel matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        depthwise_regularizer: Regularizer function applied to\n            the depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        pointwise_regularizer: Regularizer function applied to\n            the pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        depthwise_constraint: Constraint function applied to\n            the depthwise kernel matrix\n            (see [constraints](../constraints.md)).\n        pointwise_constraint: Constraint function applied to\n            the pointwise kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)`\n        if `data_format` is `""channels_last""`.\n        `rows` and `cols` values might have changed due to padding.\n    """"""\n\n    def __init__(self, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=1,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer=\'glorot_uniform\',\n                 pointwise_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_SeparableConv, self).__init__(\n            rank=rank,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            bias_initializer=bias_initializer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.pointwise_initializer = initializers.get(pointwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n        self.pointwise_constraint = constraints.get(pointwise_constraint)\n\n    def build(self, input_shape):\n        if len(input_shape) < self.rank + 2:\n            raise ValueError(\'Inputs to `SeparableConv\' + str(self.rank) + \'D` \'\n                             \'should have rank \' + str(self.rank + 2) + \'. \'\n                             \'Received input shape:\', str(input_shape))\n        channel_axis = 1 if self.data_format == \'channels_first\' else -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = (input_dim, self.depth_multiplier)\n        depthwise_kernel_shape = self.kernel_size + depthwise_kernel_shape\n        pointwise_kernel_shape = (self.depth_multiplier * input_dim, self.filters)\n        pointwise_kernel_shape = (1,) * self.rank + pointwise_kernel_shape\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name=\'depthwise_kernel\',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n        self.pointwise_kernel = self.add_weight(\n            shape=pointwise_kernel_shape,\n            initializer=self.pointwise_initializer,\n            name=\'pointwise_kernel\',\n            regularizer=self.pointwise_regularizer,\n            constraint=self.pointwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.separable_conv1d(\n                inputs,\n                self.depthwise_kernel,\n                self.pointwise_kernel,\n                data_format=self.data_format,\n                strides=self.strides,\n                padding=self.padding,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 2:\n            outputs = K.separable_conv2d(\n                inputs,\n                self.depthwise_kernel,\n                self.pointwise_kernel,\n                data_format=self.data_format,\n                strides=self.strides,\n                padding=self.padding,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def get_config(self):\n        config = super(_SeparableConv, self).get_config()\n        config.pop(\'rank\')\n        config.pop(\'kernel_initializer\')\n        config.pop(\'kernel_regularizer\')\n        config.pop(\'kernel_constraint\')\n        config[\'depth_multiplier\'] = self.depth_multiplier\n        config[\'depthwise_initializer\'] = (\n            initializers.serialize(self.depthwise_initializer))\n        config[\'pointwise_initializer\'] = (\n            initializers.serialize(self.pointwise_initializer))\n        config[\'depthwise_regularizer\'] = (\n            regularizers.serialize(self.depthwise_regularizer))\n        config[\'pointwise_regularizer\'] = (\n            regularizers.serialize(self.pointwise_regularizer))\n        config[\'depthwise_constraint\'] = (\n            constraints.serialize(self.depthwise_constraint))\n        config[\'pointwise_constraint\'] = (\n            constraints.serialize(self.pointwise_constraint))\n        return config\n\n\nclass SeparableConv1D(_SeparableConv):\n    """"""Depthwise separable 1D convolution.\n\n    Separable convolutions consist in first performing\n    a depthwise spatial convolution\n    (which acts on each input channel separately)\n    followed by a pointwise convolution which mixes together the resulting\n    output channels. The `depth_multiplier` argument controls how many\n    output channels are generated per input channel in the depthwise step.\n\n    Intuitively, separable convolutions can be understood as\n    a way to factorize a convolution kernel into two smaller kernels,\n    or as an extreme version of an Inception block.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of single integer,\n            specifying the length of the 1D convolution window.\n        strides: An integer or tuple/list of single integer,\n            specifying the stride length of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, steps, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, steps)`.\n        dilation_rate: An integer or tuple/list of a single integer, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        depth_multiplier: The number of depthwise convolution output channels\n            for each input channel.\n            The total number of depthwise convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        depthwise_initializer: Initializer for the depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n        pointwise_initializer: Initializer for the pointwise kernel matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        depthwise_regularizer: Regularizer function applied to\n            the depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        pointwise_regularizer: Regularizer function applied to\n            the pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        depthwise_constraint: Constraint function applied to\n            the depthwise kernel matrix\n            (see [constraints](../constraints.md)).\n        pointwise_constraint: Constraint function applied to\n            the pointwise kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        3D tensor with shape:\n        `(batch, channels, steps)`\n        if `data_format` is `""channels_first""`\n        or 3D tensor with shape:\n        `(batch, steps, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        3D tensor with shape:\n        `(batch, filters, new_steps)`\n        if `data_format` is `""channels_first""`\n        or 3D tensor with shape:\n        `(batch, new_steps, filters)`\n        if `data_format` is `""channels_last""`.\n        `new_steps` values might have changed due to padding or strides.\n    """"""\n\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=\'channels_last\',\n                 dilation_rate=1,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer=\'glorot_uniform\',\n                 pointwise_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(SeparableConv1D, self).__init__(\n            rank=1,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            depth_multiplier=depth_multiplier,\n            activation=activation,\n            use_bias=use_bias,\n            depthwise_initializer=depthwise_initializer,\n            pointwise_initializer=pointwise_initializer,\n            bias_initializer=bias_initializer,\n            depthwise_regularizer=depthwise_regularizer,\n            pointwise_regularizer=pointwise_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            depthwise_constraint=depthwise_constraint,\n            pointwise_constraint=pointwise_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n\nclass SeparableConv2D(_SeparableConv):\n    """"""Depthwise separable 2D convolution.\n\n    Separable convolution performs first\n    a depthwise spatial convolution\n    (which acts on each input channel separately)\n    followed by a pointwise convolution which mixes together the resulting\n    output channels. The `depth_multiplier` argument controls how many\n    output channels are generated per input channel in the depthwise step.\n\n    Intuitively, separable convolutions can be understood as\n    a way to factorize a convolution kernel into two smaller kernels,\n    or as an extreme version of an Inception block.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution\n            along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: An integer or tuple/list of 2 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        depth_multiplier: The number of depthwise convolution output channels\n            for each input channel.\n            The total number of depthwise convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        depthwise_initializer: Initializer for the depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n        pointwise_initializer: Initializer for the pointwise kernel matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        depthwise_regularizer: Regularizer function applied to\n            the depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        pointwise_regularizer: Regularizer function applied to\n            the pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        depthwise_constraint: Constraint function applied to\n            the depthwise kernel matrix\n            (see [constraints](../constraints.md)).\n        pointwise_constraint: Constraint function applied to\n            the pointwise kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)`\n        if `data_format` is `""channels_last""`.\n        `rows` and `cols` values might have changed due to padding.\n    """"""\n\n    @interfaces.legacy_separable_conv2d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer=\'glorot_uniform\',\n                 pointwise_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(SeparableConv2D, self).__init__(\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            depth_multiplier=depth_multiplier,\n            activation=activation,\n            use_bias=use_bias,\n            depthwise_initializer=depthwise_initializer,\n            pointwise_initializer=pointwise_initializer,\n            bias_initializer=bias_initializer,\n            depthwise_regularizer=depthwise_regularizer,\n            pointwise_regularizer=pointwise_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            depthwise_constraint=depthwise_constraint,\n            pointwise_constraint=pointwise_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n\nclass DepthwiseConv2D(Conv2D):\n    """"""Depthwise 2D convolution.\n\n    Depthwise convolution performs\n    just the first step of a depthwise spatial convolution\n    (which acts on each input channel separately).\n    The `depth_multiplier` argument controls how many\n    output channels are generated per input channel in the depthwise step.\n\n    # Arguments\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution\n            along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `""valid""` or `""same""` (case-insensitive).\n        depth_multiplier: The number of depthwise convolution output channels\n            for each input channel.\n            The total number of depthwise convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \'channels_last\'.\n        dilation_rate: an integer or tuple/list of 2 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. \'linear\' activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        depthwise_initializer: Initializer for the depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        depthwise_regularizer: Regularizer function applied to\n            the depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \'activation\').\n            (see [regularizer](../regularizers.md)).\n        depthwise_constraint: Constraint function applied to\n            the depthwise kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format` is `""channels_last""`.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, channels * depth_multiplier, new_rows, new_cols)`\n        if `data_format` is `""channels_first""`\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols,  channels * depth_multiplier)`\n        if `data_format` is `""channels_last""`.\n        `rows` and `cols` values might have changed due to padding.\n    """"""\n\n    def __init__(self,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 depth_multiplier=1,\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 depthwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(DepthwiseConv2D, self).__init__(\n            filters=None,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n    def build(self, input_shape):\n        if len(input_shape) < 4:\n            raise ValueError(\'Inputs to `DepthwiseConv2D` should have rank 4. \'\n                             \'Received input shape:\', str(input_shape))\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = 3\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs to \'\n                             \'`DepthwiseConv2D` \'\n                             \'should be defined. Found `None`.\')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = (self.kernel_size[0],\n                                  self.kernel_size[1],\n                                  input_dim,\n                                  self.depth_multiplier)\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name=\'depthwise_kernel\',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs, training=None):\n        outputs = K.depthwise_conv2d(\n            inputs,\n            self.depthwise_kernel,\n            strides=self.strides,\n            padding=self.padding,\n            dilation_rate=self.dilation_rate,\n            data_format=self.data_format)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            space = input_shape[1:-1]\n            out_filters = input_shape[3] * self.depth_multiplier\n        elif self.data_format == \'channels_first\':\n            space = input_shape[2:]\n            out_filters = input_shape[1] * self.depth_multiplier\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_utils.conv_output_length(\n                space[i],\n                self.kernel_size[i],\n                padding=self.padding,\n                stride=self.strides[i],\n                dilation=self.dilation_rate[i])\n            new_space.append(new_dim)\n        if self.data_format == \'channels_last\':\n            return (input_shape[0], new_space[0], new_space[1], out_filters)\n        elif self.data_format == \'channels_first\':\n            return (input_shape[0], out_filters, new_space[0], new_space[1])\n\n    def get_config(self):\n        config = super(DepthwiseConv2D, self).get_config()\n        config.pop(\'filters\')\n        config.pop(\'kernel_initializer\')\n        config.pop(\'kernel_regularizer\')\n        config.pop(\'kernel_constraint\')\n        config[\'depth_multiplier\'] = self.depth_multiplier\n        config[\'depthwise_initializer\'] = (\n            initializers.serialize(self.depthwise_initializer))\n        config[\'depthwise_regularizer\'] = (\n            regularizers.serialize(self.depthwise_regularizer))\n        config[\'depthwise_constraint\'] = (\n            constraints.serialize(self.depthwise_constraint))\n        return config\n\n\nclass _UpSampling(Layer):\n    """"""Abstract nD UpSampling layer (private, used as implementation base).\n\n    # Arguments\n        size: Tuple of ints.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, ..., channels)` while `""channels_first""` corresponds to\n            inputs with shape `(batch, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n    """"""\n    def __init__(self, size, data_format=None, **kwargs):\n        # self.rank is 1 for UpSampling1D, 2 for UpSampling2D.\n        self.rank = len(size)\n        self.size = size\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=self.rank + 2)\n        super(_UpSampling, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        raise NotImplementedError\n\n    def compute_output_shape(self, input_shape):\n        size_all_dims = (1,) + self.size + (1,)\n        spatial_axes = list(range(1, 1 + self.rank))\n        size_all_dims = transpose_shape(size_all_dims,\n                                        self.data_format,\n                                        spatial_axes)\n        output_shape = list(input_shape)\n        for dim in range(len(output_shape)):\n            if output_shape[dim] is not None:\n                output_shape[dim] *= size_all_dims[dim]\n        return tuple(output_shape)\n\n    def get_config(self):\n        config = {\'size\': self.size,\n                  \'data_format\': self.data_format}\n        base_config = super(_UpSampling, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass UpSampling1D(_UpSampling):\n    """"""Upsampling layer for 1D inputs.\n\n    Repeats each temporal step `size` times along the time axis.\n\n    # Arguments\n        size: integer. Upsampling factor.\n\n    # Input shape\n        3D tensor with shape: `(batch, steps, features)`.\n\n    # Output shape\n        3D tensor with shape: `(batch, upsampled_steps, features)`.\n    """"""\n\n    @interfaces.legacy_upsampling1d_support\n    def __init__(self, size=2, **kwargs):\n        super(UpSampling1D, self).__init__((int(size),), \'channels_last\', **kwargs)\n\n    def call(self, inputs):\n        output = K.repeat_elements(inputs, self.size[0], axis=1)\n        return output\n\n    def get_config(self):\n        config = super(UpSampling1D, self).get_config()\n        config[\'size\'] = self.size[0]\n        config.pop(\'data_format\')\n        return config\n\n\nclass UpSampling2D(_UpSampling):\n    """"""Upsampling layer for 2D inputs.\n\n    Repeats the rows and columns of the data\n    by size[0] and size[1] respectively.\n\n    # Arguments\n        size: int, or tuple of 2 integers.\n            The upsampling factors for rows and columns.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        interpolation: A string, one of `nearest` or `bilinear`.\n            Note that CNTK does not support yet the `bilinear` upscaling\n            and that with Theano, only `size=(2, 2)` is possible.\n\n    # Input shape\n        4D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, rows, cols, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, rows, cols)`\n\n    # Output shape\n        4D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, upsampled_rows, upsampled_cols, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, upsampled_rows, upsampled_cols)`\n    """"""\n\n    @interfaces.legacy_upsampling2d_support\n    def __init__(self, size=(2, 2), data_format=None, interpolation=\'nearest\',\n                 **kwargs):\n        normalized_size = conv_utils.normalize_tuple(size, 2, \'size\')\n        super(UpSampling2D, self).__init__(normalized_size, data_format, **kwargs)\n        if interpolation not in [\'nearest\', \'bilinear\']:\n            raise ValueError(\'interpolation should be one \'\n                             \'of ""nearest"" or ""bilinear"".\')\n        self.interpolation = interpolation\n\n    def call(self, inputs):\n        return K.resize_images(inputs, self.size[0], self.size[1],\n                               self.data_format, self.interpolation)\n\n    def get_config(self):\n        config = super(UpSampling2D, self).get_config()\n        config[\'interpolation\'] = self.interpolation\n        return config\n\n\nclass UpSampling3D(_UpSampling):\n    """"""Upsampling layer for 3D inputs.\n\n    Repeats the 1st, 2nd and 3rd dimensions\n    of the data by size[0], size[1] and size[2] respectively.\n\n    # Arguments\n        size: int, or tuple of 3 integers.\n            The upsampling factors for dim1, dim2 and dim3.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n\n    # Input shape\n        5D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, dim1, dim2, dim3, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, dim1, dim2, dim3)`\n\n    # Output shape\n        5D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n    """"""\n\n    @interfaces.legacy_upsampling3d_support\n    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n        normalized_size = conv_utils.normalize_tuple(size, 3, \'size\')\n        super(UpSampling3D, self).__init__(normalized_size, data_format, **kwargs)\n\n    def call(self, inputs):\n        return K.resize_volumes(inputs,\n                                self.size[0], self.size[1], self.size[2],\n                                self.data_format)\n\n\nclass _ZeroPadding(Layer):\n    """"""Abstract nD ZeroPadding layer (private, used as implementation base).\n\n    # Arguments\n        padding: Tuple of tuples of two ints. Can be a tuple of ints when\n            rank is 1.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, ..., channels)` while `""channels_first""` corresponds to\n            inputs with shape `(batch, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n    """"""\n    def __init__(self, padding, data_format=None, **kwargs):\n        # self.rank is 1 for ZeroPadding1D, 2 for ZeroPadding2D.\n        self.rank = len(padding)\n        self.padding = padding\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=self.rank + 2)\n        super(_ZeroPadding, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        raise NotImplementedError\n\n    def compute_output_shape(self, input_shape):\n        padding_all_dims = ((0, 0),) + self.padding + ((0, 0),)\n        spatial_axes = list(range(1, 1 + self.rank))\n        padding_all_dims = transpose_shape(padding_all_dims,\n                                           self.data_format,\n                                           spatial_axes)\n        output_shape = list(input_shape)\n        for dim in range(len(output_shape)):\n            if output_shape[dim] is not None:\n                output_shape[dim] += sum(padding_all_dims[dim])\n        return tuple(output_shape)\n\n    def get_config(self):\n        config = {\'padding\': self.padding,\n                  \'data_format\': self.data_format}\n        base_config = super(_ZeroPadding, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass ZeroPadding1D(_ZeroPadding):\n    """"""Zero-padding layer for 1D input (e.g. temporal sequence).\n\n    # Arguments\n        padding: int, or tuple of int (length 2), or dictionary.\n            - If int:\n            How many zeros to add at the beginning and end of\n            the padding dimension (axis 1).\n            - If tuple of int (length 2):\n            How many zeros to add at the beginning and at the end of\n            the padding dimension (`(left_pad, right_pad)`).\n\n    # Input shape\n        3D tensor with shape `(batch, axis_to_pad, features)`\n\n    # Output shape\n        3D tensor with shape `(batch, padded_axis, features)`\n    """"""\n\n    def __init__(self, padding=1, **kwargs):\n        normalized_padding = (conv_utils.normalize_tuple(padding, 2, \'padding\'),)\n        super(ZeroPadding1D, self).__init__(normalized_padding,\n                                            \'channels_last\',\n                                            **kwargs)\n\n    def call(self, inputs):\n        return K.temporal_padding(inputs, padding=self.padding[0])\n\n    def get_config(self):\n        config = super(ZeroPadding1D, self).get_config()\n        config[\'padding\'] = config[\'padding\'][0]\n        config.pop(\'data_format\')\n        return config\n\n\nclass ZeroPadding2D(_ZeroPadding):\n    """"""Zero-padding layer for 2D input (e.g. picture).\n\n    This layer can add rows and columns of zeros\n    at the top, bottom, left and right side of an image tensor.\n\n    # Arguments\n        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n            - If int: the same symmetric padding\n                is applied to height and width.\n            - If tuple of 2 ints:\n                interpreted as two different\n                symmetric padding values for height and width:\n                `(symmetric_height_pad, symmetric_width_pad)`.\n            - If tuple of 2 tuples of 2 ints:\n                interpreted as\n                `((top_pad, bottom_pad), (left_pad, right_pad))`\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n\n    # Input shape\n        4D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, rows, cols, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, rows, cols)`\n\n    # Output shape\n        4D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, padded_rows, padded_cols, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, padded_rows, padded_cols)`\n    """"""\n\n    @interfaces.legacy_zeropadding2d_support\n    def __init__(self,\n                 padding=(1, 1),\n                 data_format=None,\n                 **kwargs):\n        if isinstance(padding, int):\n            normalized_padding = ((padding, padding), (padding, padding))\n        elif hasattr(padding, \'__len__\'):\n            if len(padding) != 2:\n                raise ValueError(\'`padding` should have two elements. \'\n                                 \'Found: \' + str(padding))\n            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                        \'1st entry of padding\')\n            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                       \'2nd entry of padding\')\n            normalized_padding = (height_padding, width_padding)\n        else:\n            raise ValueError(\'`padding` should be either an int, \'\n                             \'a tuple of 2 ints \'\n                             \'(symmetric_height_pad, symmetric_width_pad), \'\n                             \'or a tuple of 2 tuples of 2 ints \'\n                             \'((top_pad, bottom_pad), (left_pad, right_pad)). \'\n                             \'Found: \' + str(padding))\n        super(ZeroPadding2D, self).__init__(normalized_padding,\n                                            data_format,\n                                            **kwargs)\n\n    def call(self, inputs):\n        return K.spatial_2d_padding(inputs,\n                                    padding=self.padding,\n                                    data_format=self.data_format)\n\n\nclass ZeroPadding3D(_ZeroPadding):\n    """"""Zero-padding layer for 3D data (spatial or spatio-temporal).\n\n    # Arguments\n        padding: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n            - If int: the same symmetric padding\n                is applied to height and width.\n            - If tuple of 3 ints:\n                interpreted as three different\n                symmetric padding values for depth, height, and width:\n                `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n            - If tuple of 3 tuples of 2 ints:\n                interpreted as\n                `((left_dim1_pad, right_dim1_pad),\n                  (left_dim2_pad, right_dim2_pad),\n                  (left_dim3_pad, right_dim3_pad))`\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n\n    # Input shape\n        5D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad,\n              depth)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, depth,\n              first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`\n\n    # Output shape\n        5D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, first_padded_axis, second_padded_axis, third_axis_to_pad,\n              depth)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, depth,\n              first_padded_axis, second_padded_axis, third_axis_to_pad)`\n    """"""\n\n    @interfaces.legacy_zeropadding3d_support\n    def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n        if isinstance(padding, int):\n            normalized_padding = 3 * ((padding, padding),)\n        elif hasattr(padding, \'__len__\'):\n            if len(padding) != 3:\n                raise ValueError(\'`padding` should have 3 elements. \'\n                                 \'Found: \' + str(padding))\n            dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                      \'1st entry of padding\')\n            dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                      \'2nd entry of padding\')\n            dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n                                                      \'3rd entry of padding\')\n            normalized_padding = (dim1_padding, dim2_padding, dim3_padding)\n        else:\n            raise ValueError(\n                \'`padding` should be either an int, a tuple of 3 ints \'\n                \'(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad), \'\n                \'or a tuple of 3 tuples of 2 ints \'\n                \'((left_dim1_pad, right_dim1_pad),\'\n                \' (left_dim2_pad, right_dim2_pad),\'\n                \' (left_dim3_pad, right_dim2_pad)). \'\n                \'Found: \' + str(padding))\n        super(ZeroPadding3D, self).__init__(normalized_padding,\n                                            data_format,\n                                            **kwargs)\n\n    def call(self, inputs):\n        return K.spatial_3d_padding(inputs,\n                                    padding=self.padding,\n                                    data_format=self.data_format)\n\n\nclass _Cropping(Layer):\n    """"""Abstract nD copping layer (private, used as implementation base).\n\n    # Arguments\n        cropping: A tuple of tuples of 2 ints.\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, ..., channels)` while `""channels_first""` corresponds to\n            inputs with shape `(batch, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n            For Cropping1D, the data format is always `""channels_last""`.\n    """"""\n\n    def __init__(self, cropping,\n                 data_format=None,\n                 **kwargs):\n        super(_Cropping, self).__init__(**kwargs)\n        # self.rank is 1 for Cropping1D, 2 for Cropping2D...\n        self.rank = len(cropping)\n        self.cropping = cropping\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=2 + self.rank)\n\n    def call(self, inputs):\n        slices_dims = []\n        for start, end in self.cropping:\n            if end == 0:\n                end = None\n            else:\n                end = -end\n            slices_dims.append(slice(start, end))\n\n        slices = [slice(None)] + slices_dims + [slice(None)]\n        slices = tuple(slices)\n        spatial_axes = list(range(1, 1 + self.rank))\n        slices = transpose_shape(slices, self.data_format, spatial_axes)\n        return inputs[slices]\n\n    def compute_output_shape(self, input_shape):\n        cropping_all_dims = ((0, 0),) + self.cropping + ((0, 0),)\n        spatial_axes = list(range(1, 1 + self.rank))\n        cropping_all_dims = transpose_shape(cropping_all_dims,\n                                            self.data_format,\n                                            spatial_axes)\n        output_shape = list(input_shape)\n        for dim in range(len(output_shape)):\n            if output_shape[dim] is not None:\n                output_shape[dim] -= sum(cropping_all_dims[dim])\n        return tuple(output_shape)\n\n    def get_config(self):\n        config = {\'cropping\': self.cropping,\n                  \'data_format\': self.data_format}\n        base_config = super(_Cropping, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Cropping1D(_Cropping):\n    """"""Cropping layer for 1D input (e.g. temporal sequence).\n\n    It crops along the time dimension (axis 1).\n\n    # Arguments\n        cropping: int or tuple of int (length 2)\n            How many units should be trimmed off at the beginning and end of\n            the cropping dimension (axis 1).\n            If a single int is provided,\n            the same value will be used for both.\n\n    # Input shape\n        3D tensor with shape `(batch, axis_to_crop, features)`\n\n    # Output shape\n        3D tensor with shape `(batch, cropped_axis, features)`\n    """"""\n\n    def __init__(self, cropping=(1, 1), **kwargs):\n        normalized_cropping = (conv_utils.normalize_tuple(cropping, 2, \'cropping\'),)\n        super(Cropping1D, self).__init__(normalized_cropping,\n                                         \'channels_last\',\n                                         **kwargs)\n\n    def get_config(self):\n        base_config = super(Cropping1D, self).get_config()\n        base_config.pop(\'data_format\')\n        base_config[\'cropping\'] = base_config[\'cropping\'][0]\n        return base_config\n\n\nclass Cropping2D(_Cropping):\n    """"""Cropping layer for 2D input (e.g. picture).\n\n    It crops along spatial dimensions, i.e. height and width.\n\n    # Arguments\n        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n            - If int: the same symmetric cropping\n                is applied to height and width.\n            - If tuple of 2 ints:\n                interpreted as two different\n                symmetric cropping values for height and width:\n                `(symmetric_height_crop, symmetric_width_crop)`.\n            - If tuple of 2 tuples of 2 ints:\n                interpreted as\n                `((top_crop, bottom_crop), (left_crop, right_crop))`\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n\n    # Input shape\n        4D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, rows, cols, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, rows, cols)`\n\n    # Output shape\n        4D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, cropped_rows, cropped_cols, channels)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, channels, cropped_rows, cropped_cols)`\n\n    # Examples\n\n    ```python\n        # Crop the input 2D images or feature maps\n        model = Sequential()\n        model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n                             input_shape=(28, 28, 3)))\n        # now model.output_shape == (None, 24, 20, 3)\n        model.add(Conv2D(64, (3, 3), padding=\'same\'))\n        model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n        # now model.output_shape == (None, 20, 16, 64)\n    ```\n    """"""\n\n    @interfaces.legacy_cropping2d_support\n    def __init__(self, cropping=((0, 0), (0, 0)),\n                 data_format=None, **kwargs):\n        if isinstance(cropping, int):\n            normalized_cropping = ((cropping, cropping), (cropping, cropping))\n        elif hasattr(cropping, \'__len__\'):\n            if len(cropping) != 2:\n                raise ValueError(\'`cropping` should have two elements. \'\n                                 \'Found: \' + str(cropping))\n            height_cropping = conv_utils.normalize_tuple(\n                cropping[0], 2,\n                \'1st entry of cropping\')\n            width_cropping = conv_utils.normalize_tuple(\n                cropping[1], 2,\n                \'2nd entry of cropping\')\n            normalized_cropping = (height_cropping, width_cropping)\n        else:\n            raise ValueError(\'`cropping` should be either an int, \'\n                             \'a tuple of 2 ints \'\n                             \'(symmetric_height_crop, symmetric_width_crop), \'\n                             \'or a tuple of 2 tuples of 2 ints \'\n                             \'((top_crop, bottom_crop), (left_crop, right_crop)). \'\n                             \'Found: \' + str(cropping))\n        super(Cropping2D, self).__init__(normalized_cropping,\n                                         data_format,\n                                         **kwargs)\n\n\nclass Cropping3D(_Cropping):\n    """"""Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n    # Arguments\n        cropping: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n            - If int: the same symmetric cropping\n                is applied to depth, height, and width.\n            - If tuple of 3 ints:\n                interpreted as three different\n                symmetric cropping values for depth, height, and width:\n                `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n            - If tuple of 3 tuples of 2 ints:\n                interpreted as\n                `((left_dim1_crop, right_dim1_crop),\n                  (left_dim2_crop, right_dim2_crop),\n                  (left_dim3_crop, right_dim3_crop))`\n        data_format: A string,\n            one of `""channels_last""` or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n\n    # Input shape\n        5D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop,\n              depth)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, depth,\n              first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`\n\n    # Output shape\n        5D tensor with shape:\n        - If `data_format` is `""channels_last""`:\n            `(batch, first_cropped_axis, second_cropped_axis, third_cropped_axis,\n              depth)`\n        - If `data_format` is `""channels_first""`:\n            `(batch, depth,\n              first_cropped_axis, second_cropped_axis, third_cropped_axis)`\n    """"""\n\n    @interfaces.legacy_cropping3d_support\n    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n                 data_format=None, **kwargs):\n        self.data_format = K.normalize_data_format(data_format)\n        if isinstance(cropping, int):\n            normalized_cropping = ((cropping, cropping),\n                                   (cropping, cropping),\n                                   (cropping, cropping))\n        elif hasattr(cropping, \'__len__\'):\n            if len(cropping) != 3:\n                raise ValueError(\'`cropping` should have 3 elements. \'\n                                 \'Found: \' + str(cropping))\n            dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n                                                       \'1st entry of cropping\')\n            dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n                                                       \'2nd entry of cropping\')\n            dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n                                                       \'3rd entry of cropping\')\n            normalized_cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n        else:\n            raise ValueError(\n                \'`cropping` should be either an int, a tuple of 3 ints \'\n                \'(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop), \'\n                \'or a tuple of 3 tuples of 2 ints \'\n                \'((left_dim1_crop, right_dim1_crop),\'\n                \' (left_dim2_crop, right_dim2_crop),\'\n                \' (left_dim3_crop, right_dim2_crop)). \'\n                \'Found: \' + str(cropping))\n        super(Cropping3D, self).__init__(normalized_cropping,\n                                         data_format,\n                                         **kwargs)\n\n\n# Aliases\n\nConvolution1D = Conv1D\nConvolution2D = Conv2D\nConvolution3D = Conv3D\nSeparableConvolution1D = SeparableConv1D\nSeparableConvolution2D = SeparableConv2D\nConvolution2DTranspose = Conv2DTranspose\nDeconvolution2D = Deconv2D = Conv2DTranspose\nDeconvolution3D = Deconv3D = Conv3DTranspose\n\n# Legacy aliases\nAtrousConv1D = AtrousConvolution1D\nAtrousConv2D = AtrousConvolution2D\n'"
keras/layers/convolutional_recurrent.py,1,"b'# -*- coding: utf-8 -*-\n""""""Convolutional-recurrent layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend as K\nfrom .. import activations\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom .recurrent import _generate_dropout_mask\nfrom .recurrent import _standardize_args\n\nimport numpy as np\nimport warnings\nfrom ..engine.base_layer import InputSpec, Layer\nfrom ..utils import conv_utils\nfrom ..legacy import interfaces\nfrom ..legacy.layers import Recurrent, ConvRecurrent2D\nfrom .recurrent import RNN\nfrom ..utils.generic_utils import has_arg\nfrom ..utils.generic_utils import to_list\nfrom ..utils.generic_utils import transpose_shape\n\n\nclass ConvRNN2D(RNN):\n    """"""Base class for convolutional-recurrent layers.\n\n    # Arguments\n        cell: A RNN cell instance. A RNN cell is a class that has:\n            - a `call(input_at_t, states_at_t)` method, returning\n              `(output_at_t, states_at_t_plus_1)`. The call method of the\n              cell can also take the optional argument `constants`, see\n              section ""Note on passing external constants"" below.\n            - a `state_size` attribute. This can be a single integer (single state)\n              in which case it is the number of channels of the recurrent state\n              (which should be the same as the number of channels of the cell\n              output). This can also be a list/tuple of integers\n              (one size per state). In this case, the first entry (`state_size[0]`)\n              should be the same as the size of the cell output.\n        return_sequences: Boolean. Whether to return the last output.\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        input_shape: Use this argument to specify the shape of the\n            input when this layer is the first one in a model.\n\n    # Input shape\n        5D tensor with shape:\n        `(samples, timesteps, channels, rows, cols)` if data_format=\'channels_first\'\n        or 5D tensor with shape:\n        `(samples, timesteps, rows, cols, channels)` if data_format=\'channels_last\'.\n\n    # Output shape\n        - if `return_state`: a list of tensors. The first tensor is\n            the output. The remaining tensors are the last states,\n            each 5D tensor with shape:\n            `(samples, timesteps,\n              filters, new_rows, new_cols)` if data_format=\'channels_first\'\n            or 5D tensor with shape:\n            `(samples, timesteps,\n              new_rows, new_cols, filters)` if data_format=\'channels_last\'.\n            `rows` and `cols` values might have changed due to padding.\n        - if `return_sequences`: 5D tensor with shape:\n            `(samples, timesteps,\n              filters, new_rows, new_cols)` if data_format=\'channels_first\'\n            or 5D tensor with shape:\n            `(samples, timesteps,\n              new_rows, new_cols, filters)` if data_format=\'channels_last\'.\n        - else, 4D tensor with shape:\n            `(samples, filters, new_rows, new_cols)` if data_format=\'channels_first\'\n            or 4D tensor with shape:\n            `(samples, new_rows, new_cols, filters)` if data_format=\'channels_last\'.\n\n    # Masking\n        This layer supports masking for input data with a variable number\n        of timesteps. To introduce masks to your data,\n        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n        set to `True`.\n\n    # Note on using statefulness in RNNs\n        You can set RNN layers to be \'stateful\', which means that the states\n        computed for the samples in one batch will be reused as initial states\n        for the samples in the next batch. This assumes a one-to-one mapping\n        between samples in different successive batches.\n\n        To enable statefulness:\n            - specify `stateful=True` in the layer constructor.\n            - specify a fixed batch size for your model, by passing\n                 - if sequential model:\n                    `batch_input_shape=(...)` to the first layer in your model.\n                 - if functional model with 1 or more Input layers:\n                    `batch_shape=(...)` to all the first layers in your model.\n                    This is the expected shape of your inputs\n                    *including the batch size*.\n                    It should be a tuple of integers, e.g. `(32, 10, 100, 100, 32)`.\n                    Note that the number of rows and columns should be specified too.\n            - specify `shuffle=False` when calling fit().\n\n        To reset the states of your model, call `.reset_states()` on either\n        a specific layer, or on your entire model.\n\n    # Note on specifying the initial state of RNNs\n        You can specify the initial state of RNN layers symbolically by\n        calling them with the keyword argument `initial_state`. The value of\n        `initial_state` should be a tensor or list of tensors representing\n        the initial state of the RNN layer.\n\n        You can specify the initial state of RNN layers numerically by\n        calling `reset_states` with the keyword argument `states`. The value of\n        `states` should be a numpy array or list of numpy arrays representing\n        the initial state of the RNN layer.\n\n    # Note on passing external constants to RNNs\n        You can pass ""external"" constants to the cell using the `constants`\n        keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n        requires that the `cell.call` method accepts the same keyword argument\n        `constants`. Such constants can be used to condition the cell\n        transformation on additional static inputs (not changing over time),\n        a.k.a. an attention mechanism.\n    """"""\n\n    def __init__(self, cell,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if unroll:\n            raise TypeError(\'Unrolling isn\\\'t possible with \'\n                            \'convolutional RNNs.\')\n        if isinstance(cell, (list, tuple)):\n            # The StackedConvRNN2DCells isn\'t implemented yet.\n            raise TypeError(\'It is not possible at the moment to\'\n                            \'stack convolutional cells.\')\n        super(ConvRNN2D, self).__init__(cell,\n                                        return_sequences,\n                                        return_state,\n                                        go_backwards,\n                                        stateful,\n                                        unroll,\n                                        **kwargs)\n        self.input_spec = [InputSpec(ndim=5)]\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        cell = self.cell\n        if cell.data_format == \'channels_first\':\n            rows = input_shape[3]\n            cols = input_shape[4]\n        elif cell.data_format == \'channels_last\':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        rows = conv_utils.conv_output_length(rows,\n                                             cell.kernel_size[0],\n                                             padding=cell.padding,\n                                             stride=cell.strides[0],\n                                             dilation=cell.dilation_rate[0])\n        cols = conv_utils.conv_output_length(cols,\n                                             cell.kernel_size[1],\n                                             padding=cell.padding,\n                                             stride=cell.strides[1],\n                                             dilation=cell.dilation_rate[1])\n\n        output_shape = input_shape[:2] + (rows, cols, cell.filters)\n        output_shape = transpose_shape(output_shape, cell.data_format,\n                                       spatial_axes=(2, 3))\n\n        if not self.return_sequences:\n            output_shape = output_shape[:1] + output_shape[2:]\n\n        if self.return_state:\n            output_shape = [output_shape]\n            base = (input_shape[0], rows, cols, cell.filters)\n            base = transpose_shape(base, cell.data_format, spatial_axes=(1, 2))\n            output_shape += [base[:] for _ in range(2)]\n        return output_shape\n\n    def build(self, input_shape):\n        # Note input_shape will be list of shapes of initial states and\n        # constants if these are passed in __call__.\n        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n        else:\n            constants_shape = None\n\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:5])\n\n        # allow cell (if layer) to build before we set or validate state_spec\n        if isinstance(self.cell, Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n            if constants_shape is not None:\n                self.cell.build([step_input_shape] + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\n        # set or validate state_spec\n        if hasattr(self.cell.state_size, \'__len__\'):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        if self.state_spec is not None:\n            # initial_state was passed in call, check compatibility\n            if self.cell.data_format == \'channels_first\':\n                ch_dim = 1\n            elif self.cell.data_format == \'channels_last\':\n                ch_dim = 3\n            if not [spec.shape[ch_dim] for spec in self.state_spec] == state_size:\n                raise ValueError(\n                    \'An initial_state was passed that is not compatible with \'\n                    \'`cell.state_size`. Received `state_spec`={}; \'\n                    \'However `cell.state_size` is \'\n                    \'{}\'.format([spec.shape for spec in self.state_spec],\n                                self.cell.state_size))\n        else:\n            if self.cell.data_format == \'channels_first\':\n                self.state_spec = [InputSpec(shape=(None, dim, None, None))\n                                   for dim in state_size]\n            elif self.cell.data_format == \'channels_last\':\n                self.state_spec = [InputSpec(shape=(None, None, None, dim))\n                                   for dim in state_size]\n        if self.stateful:\n            self.reset_states()\n        self.built = True\n\n    def get_initial_state(self, inputs):\n        # (samples, timesteps, rows, cols, filters)\n        initial_state = K.zeros_like(inputs)\n        # (samples, rows, cols, filters)\n        initial_state = K.sum(initial_state, axis=1)\n        shape = list(self.cell.kernel_shape)\n        shape[-1] = self.cell.filters\n\n        if K.backend() == \'tensorflow\':\n            # We need to force this to be a tensor\n            # and not a variable, to avoid variable initialization\n            # issues.\n            import tensorflow as tf\n            kernel = tf.zeros(tuple(shape))\n        else:\n            kernel = K.zeros(tuple(shape))\n        initial_state = self.cell.input_conv(initial_state,\n                                             kernel,\n                                             padding=self.cell.padding)\n        # Fix for Theano because it needs\n        # K.int_shape to work in call() with initial_state.\n        keras_shape = list(K.int_shape(inputs))\n        keras_shape.pop(1)\n        if K.image_data_format() == \'channels_first\':\n            indices = 2, 3\n        else:\n            indices = 1, 2\n        for i, j in enumerate(indices):\n            keras_shape[j] = conv_utils.conv_output_length(\n                keras_shape[j],\n                shape[i],\n                padding=self.cell.padding,\n                stride=self.cell.strides[i],\n                dilation=self.cell.dilation_rate[i])\n        initial_state._keras_shape = keras_shape\n\n        if hasattr(self.cell.state_size, \'__len__\'):\n            return [initial_state for _ in self.cell.state_size]\n        else:\n            return [initial_state]\n\n    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = _standardize_args(\n            inputs, initial_state, constants, self._num_constants)\n\n        if initial_state is None and constants is None:\n            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n\n        # If any of `initial_state` or `constants` are specified and are Keras\n        # tensors, then add them to the inputs and temporarily modify the\n        # input_spec to include them.\n\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            kwargs[\'initial_state\'] = initial_state\n            additional_inputs += initial_state\n            self.state_spec = []\n            for state in initial_state:\n                try:\n                    shape = K.int_shape(state)\n                # Fix for Theano\n                except TypeError:\n                    shape = tuple(None for _ in range(K.ndim(state)))\n                self.state_spec.append(InputSpec(shape=shape))\n\n            additional_specs += self.state_spec\n        if constants is not None:\n            kwargs[\'constants\'] = constants\n            additional_inputs += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n                                   for constant in constants]\n            self._num_constants = len(constants)\n            additional_specs += self.constants_spec\n        # at this point additional_inputs cannot be empty\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != K.is_keras_tensor(additional_inputs[0]):\n                raise ValueError(\'The initial state or constants of an RNN\'\n                                 \' layer cannot be specified with a mix of\'\n                                 \' Keras tensors and non-Keras tensors\')\n\n        if K.is_keras_tensor(additional_inputs[0]):\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            output = super(ConvRNN2D, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n\n    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            inputs = inputs[0]\n        if initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError(\'Layer has \' + str(len(self.states)) +\n                             \' states but was passed \' +\n                             str(len(initial_state)) +\n                             \' initial states.\')\n        timesteps = K.int_shape(inputs)[1]\n\n        kwargs = {}\n        if has_arg(self.cell.call, \'training\'):\n            kwargs[\'training\'] = training\n\n        if constants:\n            if not has_arg(self.cell.call, \'constants\'):\n                raise ValueError(\'RNN cell does not support constants\')\n\n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)\n        else:\n            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states = K.rnn(step,\n                                             inputs,\n                                             initial_state,\n                                             constants=constants,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        # Properly set learning phase\n        if getattr(last_output, \'_uses_learning_phase\', False):\n            output._uses_learning_phase = True\n\n        if self.return_state:\n            states = to_list(states, allow_tuple=True)\n            return [output] + states\n        else:\n            return output\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError(\'Layer must be stateful.\')\n        input_shape = self.input_spec[0].shape\n        state_shape = self.compute_output_shape(input_shape)\n        if self.return_state:\n            state_shape = state_shape[0]\n        if self.return_sequences:\n            state_shape = state_shape[:1] + state_shape[2:]\n        if None in state_shape:\n            raise ValueError(\'If a RNN is stateful, it needs to know \'\n                             \'its batch size. Specify the batch size \'\n                             \'of your input tensors: \\n\'\n                             \'- If using a Sequential model, \'\n                             \'specify the batch size by passing \'\n                             \'a `batch_input_shape` \'\n                             \'argument to your first layer.\\n\'\n                             \'- If using the functional API, specify \'\n                             \'the time dimension by passing a \'\n                             \'`batch_shape` argument to your Input layer.\\n\'\n                             \'The same thing goes for the number of rows \'\n                             \'and columns.\')\n\n        # helper function\n        def get_tuple_shape(nb_channels):\n            result = list(state_shape)\n            if self.cell.data_format == \'channels_first\':\n                result[1] = nb_channels\n            elif self.cell.data_format == \'channels_last\':\n                result[3] = nb_channels\n            else:\n                raise KeyError\n            return tuple(result)\n\n        # initialize state if None\n        if self.states[0] is None:\n            if hasattr(self.cell.state_size, \'__len__\'):\n                self.states = [K.zeros(get_tuple_shape(dim))\n                               for dim in self.cell.state_size]\n            else:\n                self.states = [K.zeros(get_tuple_shape(self.cell.state_size))]\n        elif states is None:\n            if hasattr(self.cell.state_size, \'__len__\'):\n                for state, dim in zip(self.states, self.cell.state_size):\n                    K.set_value(state, np.zeros(get_tuple_shape(dim)))\n            else:\n                K.set_value(self.states[0],\n                            np.zeros(get_tuple_shape(self.cell.state_size)))\n        else:\n            states = to_list(states, allow_tuple=True)\n            if len(states) != len(self.states):\n                raise ValueError(\'Layer \' + self.name + \' expects \' +\n                                 str(len(self.states)) + \' states, \'\n                                 \'but it received \' + str(len(states)) +\n                                 \' state values. Input received: \' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size, \'__len__\'):\n                    dim = self.cell.state_size[index]\n                else:\n                    dim = self.cell.state_size\n                if value.shape != get_tuple_shape(dim):\n                    raise ValueError(\'State \' + str(index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected shape=\' +\n                                     str(get_tuple_shape(dim)) +\n                                     \', found shape=\' + str(value.shape))\n                # TODO: consider batch calls to `set_value`.\n                K.set_value(state, value)\n\n\nclass ConvLSTM2DCell(Layer):\n    """"""Cell class for the ConvLSTM2D layer.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of n integers, specifying the\n            dimensions of the convolution window.\n        strides: An integer or tuple/list of n integers,\n            specifying the strides of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n        dilation_rate: An integer or tuple/list of n integers, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n        recurrent_activation: Activation function to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs.\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state.\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of the forget gate at initialization.\n            Use in combination with `bias_initializer=""zeros""`.\n            This is recommended in [Jozefowicz et al. (2015)](\n            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n    """"""\n\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=\'tanh\',\n                 recurrent_activation=\'hard_sigmoid\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        super(ConvLSTM2DCell, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 2, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2,\n                                                        \'dilation_rate\')\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        if K.backend() == \'theano\' and (dropout or recurrent_dropout):\n            warnings.warn(\n                \'RNN dropout is no longer supported with the Theano backend \'\n                \'due to technical limitations. \'\n                \'You can either set `dropout` and `recurrent_dropout` to 0, \'\n                \'or use the TensorFlow backend.\')\n            dropout = 0.\n            recurrent_dropout = 0.\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.state_size = (self.filters, self.filters)\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None\n\n    def build(self, input_shape):\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters * 4)\n        self.kernel_shape = kernel_shape\n        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters * 4)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=recurrent_kernel_shape,\n            initializer=self.recurrent_initializer,\n            name=\'recurrent_kernel\',\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n        if self.use_bias:\n            if self.unit_forget_bias:\n                @K.eager\n                def bias_initializer(_, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.filters,), *args, **kwargs),\n                        initializers.Ones()((self.filters,), *args, **kwargs),\n                        self.bias_initializer((self.filters * 2,), *args, **kwargs),\n                    ])\n            else:\n                bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(shape=(self.filters * 4,),\n                                        name=\'bias\',\n                                        initializer=bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :, :, :self.filters]\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :, :, :self.filters]\n        self.kernel_f = self.kernel[:, :, :, self.filters: self.filters * 2]\n        self.recurrent_kernel_f = (\n            self.recurrent_kernel[:, :, :, self.filters: self.filters * 2])\n        self.kernel_c = self.kernel[:, :, :, self.filters * 2: self.filters * 3]\n        self.recurrent_kernel_c = (\n            self.recurrent_kernel[:, :, :, self.filters * 2: self.filters * 3])\n        self.kernel_o = self.kernel[:, :, :, self.filters * 3:]\n        self.recurrent_kernel_o = self.recurrent_kernel[:, :, :, self.filters * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.filters]\n            self.bias_f = self.bias[self.filters: self.filters * 2]\n            self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n            self.bias_o = self.bias[self.filters * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True\n\n    def call(self, inputs, states, training=None):\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training,\n                count=4)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(states[1]),\n                self.recurrent_dropout,\n                training=training,\n                count=4)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        if 0 < self.dropout < 1.:\n            inputs_i = inputs * dp_mask[0]\n            inputs_f = inputs * dp_mask[1]\n            inputs_c = inputs * dp_mask[2]\n            inputs_o = inputs * dp_mask[3]\n        else:\n            inputs_i = inputs\n            inputs_f = inputs\n            inputs_c = inputs\n            inputs_o = inputs\n\n        if 0 < self.recurrent_dropout < 1.:\n            h_tm1_i = h_tm1 * rec_dp_mask[0]\n            h_tm1_f = h_tm1 * rec_dp_mask[1]\n            h_tm1_c = h_tm1 * rec_dp_mask[2]\n            h_tm1_o = h_tm1 * rec_dp_mask[3]\n        else:\n            h_tm1_i = h_tm1\n            h_tm1_f = h_tm1\n            h_tm1_c = h_tm1\n            h_tm1_o = h_tm1\n\n        x_i = self.input_conv(inputs_i, self.kernel_i, self.bias_i,\n                              padding=self.padding)\n        x_f = self.input_conv(inputs_f, self.kernel_f, self.bias_f,\n                              padding=self.padding)\n        x_c = self.input_conv(inputs_c, self.kernel_c, self.bias_c,\n                              padding=self.padding)\n        x_o = self.input_conv(inputs_o, self.kernel_o, self.bias_o,\n                              padding=self.padding)\n        h_i = self.recurrent_conv(h_tm1_i,\n                                  self.recurrent_kernel_i)\n        h_f = self.recurrent_conv(h_tm1_f,\n                                  self.recurrent_kernel_f)\n        h_c = self.recurrent_conv(h_tm1_c,\n                                  self.recurrent_kernel_c)\n        h_o = self.recurrent_conv(h_tm1_o,\n                                  self.recurrent_kernel_o)\n\n        i = self.recurrent_activation(x_i + h_i)\n        f = self.recurrent_activation(x_f + h_f)\n        c = f * c_tm1 + i * self.activation(x_c + h_c)\n        o = self.recurrent_activation(x_o + h_o)\n        h = o * self.activation(c)\n\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n\n        return h, [h, c]\n\n    def input_conv(self, x, w, b=None, padding=\'valid\'):\n        conv_out = K.conv2d(x, w, strides=self.strides,\n                            padding=padding,\n                            data_format=self.data_format,\n                            dilation_rate=self.dilation_rate)\n        if b is not None:\n            conv_out = K.bias_add(conv_out, b,\n                                  data_format=self.data_format)\n        return conv_out\n\n    def recurrent_conv(self, x, w):\n        conv_out = K.conv2d(x, w, strides=(1, 1),\n                            padding=\'same\',\n                            data_format=self.data_format)\n        return conv_out\n\n    def get_config(self):\n        config = {\'filters\': self.filters,\n                  \'kernel_size\': self.kernel_size,\n                  \'strides\': self.strides,\n                  \'padding\': self.padding,\n                  \'data_format\': self.data_format,\n                  \'dilation_rate\': self.dilation_rate,\n                  \'activation\': activations.serialize(self.activation),\n                  \'recurrent_activation\':\n                      activations.serialize(self.recurrent_activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'unit_forget_bias\': self.unit_forget_bias,\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'kernel_constraint\':\n                      constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout}\n        base_config = super(ConvLSTM2DCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass ConvLSTM2D(ConvRNN2D):\n    """"""Convolutional LSTM.\n\n    It is similar to an LSTM layer, but the input transformations\n    and recurrent transformations are both convolutional.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number output of filters in the convolution).\n        kernel_size: An integer or tuple/list of n integers, specifying the\n            dimensions of the convolution window.\n        strides: An integer or tuple/list of n integers,\n            specifying the strides of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, time, ..., channels)`\n            while `""channels_first""` corresponds to\n            inputs with shape `(batch, time, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n        dilation_rate: An integer or tuple/list of n integers, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            tanh is applied by default.\n        recurrent_activation: Activation function to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs.\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state.\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of the forget gate at initialization.\n            Use in combination with `bias_initializer=""zeros""`.\n            This is recommended in [Jozefowicz et al. (2015)](\n            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n\n    # Input shape\n        - if data_format=\'channels_first\'\n            5D tensor with shape:\n            `(samples, time, channels, rows, cols)`\n        - if data_format=\'channels_last\'\n            5D tensor with shape:\n            `(samples, time, rows, cols, channels)`\n\n    # Output shape\n        - if `return_sequences`\n             - if data_format=\'channels_first\'\n                5D tensor with shape:\n                `(samples, time, filters, output_row, output_col)`\n             - if data_format=\'channels_last\'\n                5D tensor with shape:\n                `(samples, time, output_row, output_col, filters)`\n        - else\n            - if data_format=\'channels_first\'\n                4D tensor with shape:\n                `(samples, filters, output_row, output_col)`\n            - if data_format=\'channels_last\'\n                4D tensor with shape:\n                `(samples, output_row, output_col, filters)`\n            where o_row and o_col depend on the shape of the filter and\n            the padding\n\n    # Raises\n        ValueError: in case of invalid constructor arguments.\n\n    # References\n        - [Convolutional LSTM Network: A Machine Learning Approach for\n          Precipitation Nowcasting](http://arxiv.org/abs/1506.04214v1)\n          The current implementation does not include the feedback loop on the\n          cells output\n    """"""\n\n    @interfaces.legacy_convlstm2d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=\'tanh\',\n                 recurrent_activation=\'hard_sigmoid\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 go_backwards=False,\n                 stateful=False,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        cell = ConvLSTM2DCell(filters=filters,\n                              kernel_size=kernel_size,\n                              strides=strides,\n                              padding=padding,\n                              data_format=data_format,\n                              dilation_rate=dilation_rate,\n                              activation=activation,\n                              recurrent_activation=recurrent_activation,\n                              use_bias=use_bias,\n                              kernel_initializer=kernel_initializer,\n                              recurrent_initializer=recurrent_initializer,\n                              bias_initializer=bias_initializer,\n                              unit_forget_bias=unit_forget_bias,\n                              kernel_regularizer=kernel_regularizer,\n                              recurrent_regularizer=recurrent_regularizer,\n                              bias_regularizer=bias_regularizer,\n                              kernel_constraint=kernel_constraint,\n                              recurrent_constraint=recurrent_constraint,\n                              bias_constraint=bias_constraint,\n                              dropout=dropout,\n                              recurrent_dropout=recurrent_dropout)\n        super(ConvLSTM2D, self).__init__(cell,\n                                         return_sequences=return_sequences,\n                                         go_backwards=go_backwards,\n                                         stateful=stateful,\n                                         **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        return super(ConvLSTM2D, self).call(inputs,\n                                            mask=mask,\n                                            training=training,\n                                            initial_state=initial_state)\n\n    @property\n    def filters(self):\n        return self.cell.filters\n\n    @property\n    def kernel_size(self):\n        return self.cell.kernel_size\n\n    @property\n    def strides(self):\n        return self.cell.strides\n\n    @property\n    def padding(self):\n        return self.cell.padding\n\n    @property\n    def data_format(self):\n        return self.cell.data_format\n\n    @property\n    def dilation_rate(self):\n        return self.cell.dilation_rate\n\n    @property\n    def activation(self):\n        return self.cell.activation\n\n    @property\n    def recurrent_activation(self):\n        return self.cell.recurrent_activation\n\n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\n    @property\n    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias\n\n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\n    def get_config(self):\n        config = {\'filters\': self.filters,\n                  \'kernel_size\': self.kernel_size,\n                  \'strides\': self.strides,\n                  \'padding\': self.padding,\n                  \'data_format\': self.data_format,\n                  \'dilation_rate\': self.dilation_rate,\n                  \'activation\': activations.serialize(self.activation),\n                  \'recurrent_activation\':\n                      activations.serialize(self.recurrent_activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'unit_forget_bias\': self.unit_forget_bias,\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'kernel_constraint\':\n                      constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout}\n        base_config = super(ConvLSTM2D, self).get_config()\n        del base_config[\'cell\']\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n'"
keras/layers/core.py,0,"b'# -*- coding: utf-8 -*-\n""""""Core Keras layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nimport copy\nimport types as python_types\nimport warnings\n\nfrom .. import backend as K\nfrom .. import activations\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom ..engine.base_layer import InputSpec\nfrom ..engine.base_layer import Layer\nfrom ..utils.generic_utils import func_dump\nfrom ..utils.generic_utils import func_load\nfrom ..utils.generic_utils import deserialize_keras_object\nfrom ..utils.generic_utils import has_arg\nfrom ..legacy import interfaces\n\n\nclass Masking(Layer):\n    """"""Masks a sequence by using a mask value to skip timesteps.\n\n    If all features for a given sample timestep are equal to `mask_value`,\n    then the sample timestep will be masked (skipped) in all downstream layers\n    (as long as they support masking).\n\n    If any downstream layer does not support masking yet receives such\n    an input mask, an exception will be raised.\n\n    # Example\n\n    Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n    to be fed to an LSTM layer.\n    You want to mask sample #0 at timestep #3, and sample #2 at timestep #5,\n    because you lack features for these sample timesteps. You can do:\n\n        - set `x[0, 3, :] = 0.` and `x[2, 5, :] = 0.`\n        - insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n\n    ```python\n        model = Sequential()\n        model.add(Masking(mask_value=0., input_shape=(timesteps, features)))\n        model.add(LSTM(32))\n    ```\n\n    # Arguments\n        mask_value: Either None or mask value to skip\n    """"""\n\n    def __init__(self, mask_value=0., **kwargs):\n        super(Masking, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.mask_value = mask_value\n\n    def compute_mask(self, inputs, mask=None):\n        output_mask = K.any(K.not_equal(inputs, self.mask_value), axis=-1)\n        return output_mask\n\n    def call(self, inputs):\n        boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n                             axis=-1, keepdims=True)\n        return inputs * K.cast(boolean_mask, K.dtype(inputs))\n\n    def get_config(self):\n        config = {\'mask_value\': self.mask_value}\n        base_config = super(Masking, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass Dropout(Layer):\n    """"""Applies Dropout to the input.\n\n    Dropout consists in randomly setting\n    a fraction `rate` of input units to 0 at each update during training time,\n    which helps prevent overfitting.\n\n    # Arguments\n        rate: float between 0 and 1. Fraction of the input units to drop.\n        noise_shape: 1D integer tensor representing the shape of the\n            binary dropout mask that will be multiplied with the input.\n            For instance, if your inputs have shape\n            `(batch_size, timesteps, features)` and\n            you want the dropout mask to be the same for all timesteps,\n            you can use `noise_shape=(batch_size, 1, features)`.\n        seed: A Python integer to use as random seed.\n\n    # References\n        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n           http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n    """"""\n    @interfaces.legacy_dropout_support\n    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n        super(Dropout, self).__init__(**kwargs)\n        self.rate = min(1., max(0., rate))\n        self.noise_shape = noise_shape\n        self.seed = seed\n        self.supports_masking = True\n\n    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)\n\n    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs():\n                return K.dropout(inputs, self.rate, noise_shape,\n                                 seed=self.seed)\n            return K.in_train_phase(dropped_inputs, inputs,\n                                    training=training)\n        return inputs\n\n    def get_config(self):\n        config = {\'rate\': self.rate,\n                  \'noise_shape\': self.noise_shape,\n                  \'seed\': self.seed}\n        base_config = super(Dropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass SpatialDropout1D(Dropout):\n    """"""Spatial 1D version of Dropout.\n\n    This version performs the same function as Dropout, however it drops\n    entire 1D feature maps instead of individual elements. If adjacent frames\n    within feature maps are strongly correlated (as is normally the case in\n    early convolution layers) then regular dropout will not regularize the\n    activations and will otherwise just result in an effective learning rate\n    decrease. In this case, SpatialDropout1D will help promote independence\n    between feature maps and should be used instead.\n\n    # Arguments\n        rate: float between 0 and 1. Fraction of the input units to drop.\n\n    # Input shape\n        3D tensor with shape:\n        `(samples, timesteps, channels)`\n\n    # Output shape\n        Same as input\n\n    # References\n        - [Efficient Object Localization Using Convolutional Networks](\n           https://arxiv.org/abs/1411.4280)\n    """"""\n\n    @interfaces.legacy_spatialdropout1d_support\n    def __init__(self, rate, **kwargs):\n        super(SpatialDropout1D, self).__init__(rate, **kwargs)\n        self.input_spec = InputSpec(ndim=3)\n\n    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        noise_shape = (input_shape[0], 1, input_shape[2])\n        return noise_shape\n\n\nclass SpatialDropout2D(Dropout):\n    """"""Spatial 2D version of Dropout.\n\n    This version performs the same function as Dropout, however it drops\n    entire 2D feature maps instead of individual elements. If adjacent pixels\n    within feature maps are strongly correlated (as is normally the case in\n    early convolution layers) then regular dropout will not regularize the\n    activations and will otherwise just result in an effective learning rate\n    decrease. In this case, SpatialDropout2D will help promote independence\n    between feature maps and should be used instead.\n\n    # Arguments\n        rate: float between 0 and 1. Fraction of the input units to drop.\n        data_format: `\'channels_first\'` or `\'channels_last\'`.\n            In `\'channels_first\'` mode, the channels dimension\n            (the depth) is at index 1,\n            in `\'channels_last\'` mode is it at index 3.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `\'channels_last\'`.\n\n    # Input shape\n        4D tensor with shape:\n        `(samples, channels, rows, cols)` if `data_format=\'channels_first\'`\n        or 4D tensor with shape:\n        `(samples, rows, cols, channels)` if `data_format=\'channels_last\'`.\n\n    # Output shape\n        Same as input\n\n    # References\n        - [Efficient Object Localization Using Convolutional Networks](\n           https://arxiv.org/abs/1411.4280)\n    """"""\n\n    @interfaces.legacy_spatialdropoutNd_support\n    def __init__(self, rate, data_format=None, **kwargs):\n        super(SpatialDropout2D, self).__init__(rate, **kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)\n\n    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format == \'channels_first\':\n            noise_shape = (input_shape[0], input_shape[1], 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, input_shape[3])\n        return noise_shape\n\n\nclass SpatialDropout3D(Dropout):\n    """"""Spatial 3D version of Dropout.\n\n    This version performs the same function as Dropout, however it drops\n    entire 3D feature maps instead of individual elements. If adjacent voxels\n    within feature maps are strongly correlated (as is normally the case in\n    early convolution layers) then regular dropout will not regularize the\n    activations and will otherwise just result in an effective learning rate\n    decrease. In this case, SpatialDropout3D will help promote independence\n    between feature maps and should be used instead.\n\n    # Arguments\n        rate: float between 0 and 1. Fraction of the input units to drop.\n        data_format: `\'channels_first\'` or `\'channels_last\'`.\n            In `\'channels_first\'` mode, the channels dimension (the depth)\n            is at index 1, in `\'channels_last\'` mode is it at index 4.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `\'channels_last\'`.\n\n    # Input shape\n        5D tensor with shape:\n        `(samples, channels, dim1, dim2, dim3)` if `data_format=\'channels_first\'`\n        or 5D tensor with shape:\n        `(samples, dim1, dim2, dim3, channels)` if `data_format=\'channels_last\'`.\n\n    # Output shape\n        Same as input\n\n    # References\n        - [Efficient Object Localization Using Convolutional Networks](\n           https://arxiv.org/abs/1411.4280)\n    """"""\n\n    @interfaces.legacy_spatialdropoutNd_support\n    def __init__(self, rate, data_format=None, **kwargs):\n        super(SpatialDropout3D, self).__init__(rate, **kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)\n\n    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format == \'channels_first\':\n            noise_shape = (input_shape[0], input_shape[1], 1, 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, 1, input_shape[4])\n        return noise_shape\n\n\nclass Activation(Layer):\n    """"""Applies an activation function to an output.\n\n    # Arguments\n        activation: name of activation function to use\n            (see: [activations](../activations.md)),\n            or alternatively, a Theano or TensorFlow operation.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n    """"""\n\n    def __init__(self, activation, **kwargs):\n        super(Activation, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.activation = activations.get(activation)\n\n    def call(self, inputs):\n        return self.activation(inputs)\n\n    def get_config(self):\n        config = {\'activation\': activations.serialize(self.activation)}\n        base_config = super(Activation, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass Reshape(Layer):\n    """"""Reshapes an output to a certain shape.\n\n    # Arguments\n        target_shape: target shape. Tuple of integers.\n            Does not include the batch axis.\n\n    # Input shape\n        Arbitrary, although all dimensions in the input shaped must be fixed.\n        Use the keyword argument `input_shape`\n        (tuple of integers, does not include the batch axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        `(batch_size,) + target_shape`\n\n    # Example\n\n    ```python\n        # as first layer in a Sequential model\n        model = Sequential()\n        model.add(Reshape((3, 4), input_shape=(12,)))\n        # now: model.output_shape == (None, 3, 4)\n        # note: `None` is the batch dimension\n\n        # as intermediate layer in a Sequential model\n        model.add(Reshape((6, 2)))\n        # now: model.output_shape == (None, 6, 2)\n\n        # also supports shape inference using `-1` as dimension\n        model.add(Reshape((-1, 2, 2)))\n        # now: model.output_shape == (None, 3, 2, 2)\n    ```\n    """"""\n\n    def __init__(self, target_shape, **kwargs):\n        super(Reshape, self).__init__(**kwargs)\n        self.target_shape = tuple(target_shape)\n\n    def _fix_unknown_dimension(self, input_shape, output_shape):\n        """"""Finds and replaces a missing dimension in an output shape.\n\n        This is a near direct port of the internal Numpy function\n        `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`\n\n        # Arguments\n            input_shape: original shape of array being reshaped\n            output_shape: target shape of the array, with at most\n                a single -1 which indicates a dimension that should be\n                derived from the input shape.\n\n        # Returns\n            The new output shape with a `-1` replaced with its computed value.\n\n        # Raises\n            ValueError: if `input_shape` and `output_shape` do not match.\n        """"""\n        output_shape = list(output_shape)\n        msg = \'total size of new array must be unchanged\'\n\n        known, unknown = 1, None\n        for index, dim in enumerate(output_shape):\n            if dim < 0:\n                if unknown is None:\n                    unknown = index\n                else:\n                    raise ValueError(\'Can only specify one unknown dimension.\')\n            else:\n                known *= dim\n\n        original = np.prod(input_shape, dtype=int)\n        if unknown is not None:\n            if known == 0 or original % known != 0:\n                raise ValueError(msg)\n            output_shape[unknown] = original // known\n        elif original != known:\n            raise ValueError(msg)\n\n        return tuple(output_shape)\n\n    def compute_output_shape(self, input_shape):\n        if None in input_shape[1:]:\n            # input shape (partially) unknown? replace -1\'s with None\'s\n            return ((input_shape[0],) +\n                    tuple(s if s != -1 else None for s in self.target_shape))\n        else:\n            # input shape known? then we can compute the output shape\n            return (input_shape[0],) + self._fix_unknown_dimension(\n                input_shape[1:], self.target_shape)\n\n    def call(self, inputs):\n        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)\n\n    def get_config(self):\n        config = {\'target_shape\': self.target_shape}\n        base_config = super(Reshape, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Permute(Layer):\n    """"""Permutes the dimensions of the input according to a given pattern.\n\n    Useful for e.g. connecting RNNs and convnets together.\n\n    # Example\n\n    ```python\n        model = Sequential()\n        model.add(Permute((2, 1), input_shape=(10, 64)))\n        # now: model.output_shape == (None, 64, 10)\n        # note: `None` is the batch dimension\n    ```\n\n    # Arguments\n        dims: Tuple of integers. Permutation pattern, does not include the\n            samples dimension. Indexing starts at 1.\n            For instance, `(2, 1)` permutes the first and second dimension\n            of the input.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same as the input shape, but with the dimensions re-ordered according\n        to the specified pattern.\n    """"""\n\n    def __init__(self, dims, **kwargs):\n        super(Permute, self).__init__(**kwargs)\n        self.dims = tuple(dims)\n        self.input_spec = InputSpec(ndim=len(self.dims) + 1)\n\n    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n        output_shape = copy.copy(input_shape)\n        for i, dim in enumerate(self.dims):\n            target_dim = input_shape[dim]\n            output_shape[i + 1] = target_dim\n        return tuple(output_shape)\n\n    def call(self, inputs):\n        return K.permute_dimensions(inputs, (0,) + self.dims)\n\n    def get_config(self):\n        config = {\'dims\': self.dims}\n        base_config = super(Permute, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Flatten(Layer):\n    """"""Flattens the input. Does not affect the batch size.\n\n    # Arguments\n        data_format: A string,\n            one of `\'channels_last\'` (default) or `\'channels_first\'`.\n            The ordering of the dimensions in the inputs.\n            The purpose of this argument is to preserve weight\n            ordering when switching a model from one data format\n            to another.\n            `\'channels_last\'` corresponds to inputs with shape\n            `(batch, ..., channels)` while `\'channels_first\'` corresponds to\n            inputs with shape `(batch, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `\'channels_last\'`.\n\n    # Example\n\n    ```python\n        model = Sequential()\n        model.add(Conv2D(64, (3, 3),\n                         input_shape=(3, 32, 32), padding=\'same\',))\n        # now: model.output_shape == (None, 64, 32, 32)\n\n        model.add(Flatten())\n        # now: model.output_shape == (None, 65536)\n    ```\n    """"""\n\n    def __init__(self, data_format=None, **kwargs):\n        super(Flatten, self).__init__(**kwargs)\n        self.input_spec = InputSpec(min_ndim=3)\n        self.data_format = K.normalize_data_format(data_format)\n\n    def compute_output_shape(self, input_shape):\n        if not all(input_shape[1:]):\n            raise ValueError(\'The shape of the input to ""Flatten"" \'\n                             \'is not fully defined \'\n                             \'(got \' + str(input_shape[1:]) + \'). \'\n                             \'Make sure to pass a complete ""input_shape"" \'\n                             \'or ""batch_input_shape"" argument to the first \'\n                             \'layer in your model.\')\n        return (input_shape[0], np.prod(input_shape[1:]))\n\n    def call(self, inputs):\n        if self.data_format == \'channels_first\':\n            # Ensure works for any dim\n            permutation = [0]\n            permutation.extend([i for i in\n                                range(2, K.ndim(inputs))])\n            permutation.append(1)\n            inputs = K.permute_dimensions(inputs, permutation)\n\n        return K.batch_flatten(inputs)\n\n    def get_config(self):\n        config = {\'data_format\': self.data_format}\n        base_config = super(Flatten, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass RepeatVector(Layer):\n    """"""Repeats the input n times.\n\n    # Example\n\n    ```python\n        model = Sequential()\n        model.add(Dense(32, input_dim=32))\n        # now: model.output_shape == (None, 32)\n        # note: `None` is the batch dimension\n\n        model.add(RepeatVector(3))\n        # now: model.output_shape == (None, 3, 32)\n    ```\n\n    # Arguments\n        n: integer, repetition factor.\n\n    # Input shape\n        2D tensor of shape `(num_samples, features)`.\n\n    # Output shape\n        3D tensor of shape `(num_samples, n, features)`.\n    """"""\n\n    def __init__(self, n, **kwargs):\n        super(RepeatVector, self).__init__(**kwargs)\n        self.n = n\n        self.input_spec = InputSpec(ndim=2)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.n, input_shape[1])\n\n    def call(self, inputs):\n        return K.repeat(inputs, self.n)\n\n    def get_config(self):\n        config = {\'n\': self.n}\n        base_config = super(RepeatVector, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Lambda(Layer):\n    """"""Wraps arbitrary expression as a `Layer` object.\n\n    # Examples\n\n    ```python\n        # add a x -> x^2 layer\n        model.add(Lambda(lambda x: x ** 2))\n    ```\n    ```python\n        # add a layer that returns the concatenation\n        # of the positive part of the input and\n        # the opposite of the negative part\n\n        def antirectifier(x):\n            x -= K.mean(x, axis=1, keepdims=True)\n            x = K.l2_normalize(x, axis=1)\n            pos = K.relu(x)\n            neg = K.relu(-x)\n            return K.concatenate([pos, neg], axis=1)\n\n        def antirectifier_output_shape(input_shape):\n            shape = list(input_shape)\n            assert len(shape) == 2  # only valid for 2D tensors\n            shape[-1] *= 2\n            return tuple(shape)\n\n        model.add(Lambda(antirectifier,\n                         output_shape=antirectifier_output_shape))\n    ```\n    ```python\n        # add a layer that returns the hadamard product\n        # and sum of it from two input tensors\n\n        def hadamard_product_sum(tensors):\n            out1 = tensors[0] * tensors[1]\n            out2 = K.sum(out1, axis=-1)\n            return [out1, out2]\n\n        def hadamard_product_sum_output_shape(input_shapes):\n            shape1 = list(input_shapes[0])\n            shape2 = list(input_shapes[1])\n            assert shape1 == shape2  # else hadamard product isn\'t possible\n            return [tuple(shape1), tuple(shape2[:-1])]\n\n        x1 = Dense(32)(input_1)\n        x2 = Dense(32)(input_2)\n        layer = Lambda(hadamard_product_sum, hadamard_product_sum_output_shape)\n        x_hadamard, x_sum = layer([x1, x2])\n    ```\n\n    # Arguments\n        function: The function to be evaluated.\n            Takes input tensor or list of tensors as first argument.\n        output_shape: Expected output shape from function.\n            Only relevant when using Theano.\n            Can be a tuple or function.\n            If a tuple, it only specifies the first dimension onward;\n                 sample dimension is assumed either the same as the input:\n                 `output_shape = (input_shape[0], ) + output_shape`\n                 or, the input is `None` and\n                 the sample dimension is also `None`:\n                 `output_shape = (None, ) + output_shape`\n            If a function, it specifies the entire shape as a function of the\n            input shape: `output_shape = f(input_shape)`\n        mask: Either None (indicating no masking) or a Tensor indicating the\n          input mask for Embedding.\n        arguments: optional dictionary of keyword arguments to be passed\n            to the function.\n\n    # Input shape\n        Arbitrary. Use the keyword argument input_shape\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Specified by `output_shape` argument\n        (or auto-inferred when using TensorFlow or CNTK).\n    """"""\n\n    @interfaces.legacy_lambda_support\n    def __init__(self, function, output_shape=None,\n                 mask=None, arguments=None, **kwargs):\n        super(Lambda, self).__init__(**kwargs)\n        self.function = function\n        self._input_dtypes = None\n        self.arguments = arguments if arguments else {}\n        if mask is not None:\n            self.supports_masking = True\n        self.mask = mask\n\n        if output_shape is None:\n            self._output_shape = None\n        elif isinstance(output_shape, (tuple, list)):\n            self._output_shape = tuple(output_shape)\n        else:\n            if not callable(output_shape):\n                raise TypeError(\'In Lambda, `output_shape` \'\n                                \'must be a list, a tuple, or a function.\')\n            self._output_shape = output_shape\n\n    def compute_output_shape(self, input_shape):\n        if self._output_shape is None:\n            # With TensorFlow or CNTK, we can infer the output shape directly:\n            if K.backend() in (\'tensorflow\', \'cntk\'):\n                if isinstance(input_shape, list):\n                    xs = [K.placeholder(shape=shape, dtype=dtype)\n                          for shape, dtype in zip(input_shape, self._input_dtypes)]\n                    x = self.call(xs)\n                else:\n                    x = K.placeholder(shape=input_shape, dtype=self._input_dtypes)\n                    x = self.call(x)\n                if isinstance(x, list):\n                    return [K.int_shape(x_elem) for x_elem in x]\n                else:\n                    return K.int_shape(x)\n            # Otherwise, we default to the input shape.\n            warnings.warn(\'`output_shape` argument not specified for layer {} \'\n                          \'and cannot be automatically inferred \'\n                          \'with the Theano backend. \'\n                          \'Defaulting to output shape `{}` \'\n                          \'(same as input shape). \'\n                          \'If the expected output shape is different, \'\n                          \'specify it via the `output_shape` argument.\'\n                          .format(self.name, input_shape))\n            return input_shape\n        elif isinstance(self._output_shape, (tuple, list)):\n            if isinstance(input_shape, list):\n                num_samples = input_shape[0][0]\n            else:\n                num_samples = input_shape[0] if input_shape else None\n            return (num_samples,) + tuple(self._output_shape)\n        else:\n            shape = self._output_shape(input_shape)\n            if not isinstance(shape, (list, tuple)):\n                raise ValueError(\'`output_shape` function must return a tuple or \'\n                                 \'a list of tuples.\')\n            if isinstance(shape, list):\n                if isinstance(shape[0], int) or shape[0] is None:\n                    shape = tuple(shape)\n            return shape\n\n    def call(self, inputs, mask=None):\n        arguments = self.arguments\n        if has_arg(self.function, \'mask\'):\n            arguments[\'mask\'] = mask\n        if isinstance(inputs, list):\n            self._input_dtypes = [K.dtype(x) for x in inputs]\n        else:\n            self._input_dtypes = K.dtype(inputs)\n        return self.function(inputs, **arguments)\n\n    def compute_mask(self, inputs, mask=None):\n        if callable(self.mask):\n            return self.mask(inputs, mask)\n        return self.mask\n\n    def get_config(self):\n        if isinstance(self.function, python_types.LambdaType):\n            function = func_dump(self.function)\n            function_type = \'lambda\'\n        else:\n            function = self.function.__name__\n            function_type = \'function\'\n\n        if isinstance(self._output_shape, python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n            output_shape_type = \'lambda\'\n        elif callable(self._output_shape):\n            output_shape = self._output_shape.__name__\n            output_shape_type = \'function\'\n        else:\n            output_shape = self._output_shape\n            output_shape_type = \'raw\'\n\n        config = {\'function\': function,\n                  \'function_type\': function_type,\n                  \'output_shape\': output_shape,\n                  \'output_shape_type\': output_shape_type,\n                  \'arguments\': self.arguments}\n        base_config = super(Lambda, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        config = config.copy()\n        globs = globals()\n        if custom_objects:\n            globs = dict(list(globs.items()) + list(custom_objects.items()))\n        function_type = config.pop(\'function_type\')\n        if function_type == \'function\':\n            # Simple lookup in custom objects\n            function = deserialize_keras_object(\n                config[\'function\'],\n                custom_objects=custom_objects,\n                printable_module_name=\'function in Lambda layer\')\n        elif function_type == \'lambda\':\n            # Unsafe deserialization from bytecode\n            function = func_load(config[\'function\'], globs=globs)\n        else:\n            raise TypeError(\'Unknown function type:\', function_type)\n\n        output_shape_type = config.pop(\'output_shape_type\')\n        if output_shape_type == \'function\':\n            # Simple lookup in custom objects\n            output_shape = deserialize_keras_object(\n                config[\'output_shape\'],\n                custom_objects=custom_objects,\n                printable_module_name=\'output_shape function in Lambda layer\')\n        elif output_shape_type == \'lambda\':\n            # Unsafe deserialization from bytecode\n            output_shape = func_load(config[\'output_shape\'], globs=globs)\n        else:\n            output_shape = config[\'output_shape\']\n\n        # If arguments were numpy array, they have been saved as\n        # list. We need to recover the ndarray\n        if \'arguments\' in config:\n            for key in config[\'arguments\']:\n                if isinstance(config[\'arguments\'][key], dict):\n                    arg_dict = config[\'arguments\'][key]\n                    if \'type\' in arg_dict and arg_dict[\'type\'] == \'ndarray\':\n                        # Overwrite the argument with its numpy translation\n                        config[\'arguments\'][key] = np.array(arg_dict[\'value\'])\n\n        config[\'function\'] = function\n        config[\'output_shape\'] = output_shape\n        return cls(**config)\n\n\nclass Dense(Layer):\n    """"""Just your regular densely-connected NN layer.\n\n    `Dense` implements the operation:\n    `output = activation(dot(input, kernel) + bias)`\n    where `activation` is the element-wise activation function\n    passed as the `activation` argument, `kernel` is a weights matrix\n    created by the layer, and `bias` is a bias vector created by the layer\n    (only applicable if `use_bias` is `True`).\n\n    Note: if the input to the layer has a rank greater than 2, then\n    it is flattened prior to the initial dot product with `kernel`.\n\n    # Example\n\n    ```python\n        # as first layer in a sequential model:\n        model = Sequential()\n        model.add(Dense(32, input_shape=(16,)))\n        # now the model will take as input arrays of shape (*, 16)\n        # and output arrays of shape (*, 32)\n\n        # after the first layer, you don\'t need to specify\n        # the size of the input anymore:\n        model.add(Dense(32))\n    ```\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        nD tensor with shape: `(batch_size, ..., input_dim)`.\n        The most common situation would be\n        a 2D input with shape `(batch_size, input_dim)`.\n\n    # Output shape\n        nD tensor with shape: `(batch_size, ..., units)`.\n        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n        the output would have shape `(batch_size, units)`.\n    """"""\n\n    @interfaces.legacy_dense_support\n    def __init__(self, units,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if \'input_shape\' not in kwargs and \'input_dim\' in kwargs:\n            kwargs[\'input_shape\'] = (kwargs.pop(\'input_dim\'),)\n        super(Dense, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(min_ndim=2)\n        self.supports_masking = True\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units),\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        output = K.dot(inputs, self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format=\'channels_last\')\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n        output_shape[-1] = self.units\n        return tuple(output_shape)\n\n    def get_config(self):\n        config = {\n            \'units\': self.units,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\':\n                regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(Dense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass ActivityRegularization(Layer):\n    """"""Layer that applies an update to the cost function based input activity.\n\n    # Arguments\n        l1: L1 regularization factor (positive float).\n        l2: L2 regularization factor (positive float).\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n    """"""\n\n    def __init__(self, l1=0., l2=0., **kwargs):\n        super(ActivityRegularization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.l1 = l1\n        self.l2 = l2\n        self.activity_regularizer = regularizers.L1L2(l1=l1, l2=l2)\n\n    def get_config(self):\n        config = {\'l1\': self.l1,\n                  \'l2\': self.l2}\n        base_config = super(ActivityRegularization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
keras/layers/cudnn_recurrent.py,10,"b'""""""Recurrent layers backed by cuDNN.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend as K\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom .recurrent import RNN\nfrom ..layers import InputSpec\n\nfrom collections import namedtuple\n\n\nclass _CuDNNRNN(RNN):\n    """"""Private base class for CuDNNGRU and CuDNNLSTM.\n\n    # Arguments\n        return_sequences: Boolean. Whether to return the last output.\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n    """"""\n\n    def __init__(self,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 **kwargs):\n        if K.backend() != \'tensorflow\':\n            raise RuntimeError(\'CuDNN RNNs are only available \'\n                               \'with the TensorFlow backend.\')\n        super(RNN, self).__init__(**kwargs)\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.supports_masking = False\n        self.input_spec = [InputSpec(ndim=3)]\n        if hasattr(self.cell.state_size, \'__len__\'):\n            state_size = self.cell.state_size\n        else:\n            state_size = [self.cell.state_size]\n        self.state_spec = [InputSpec(shape=(None, dim))\n                           for dim in state_size]\n        self.constants_spec = None\n        self._states = None\n        self._num_constants = None\n\n    def _canonical_to_params(self, weights, biases):\n        import tensorflow as tf\n        weights = [tf.reshape(x, (-1,)) for x in weights]\n        biases = [tf.reshape(x, (-1,)) for x in biases]\n        return tf.concat(weights + biases, 0)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        if isinstance(mask, list):\n            mask = mask[0]\n        if mask is not None:\n            raise ValueError(\'Masking is not supported for CuDNN RNNs.\')\n\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if len(initial_state) != len(self.states):\n            raise ValueError(\'Layer has \' + str(len(self.states)) +\n                             \' states but was passed \' +\n                             str(len(initial_state)) +\n                             \' initial states.\')\n\n        if self.go_backwards:\n            # Reverse time axis.\n            inputs = K.reverse(inputs, 1)\n        output, states = self._process_batch(inputs, initial_state)\n\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_state:\n            return [output] + states\n        else:\n            return output\n\n    def get_config(self):\n        config = {\'return_sequences\': self.return_sequences,\n                  \'return_state\': self.return_state,\n                  \'go_backwards\': self.go_backwards,\n                  \'stateful\': self.stateful}\n        base_config = super(RNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n    @property\n    def trainable_weights(self):\n        if self.trainable and self.built:\n            return [self.kernel, self.recurrent_kernel, self.bias]\n        return []\n\n    @property\n    def non_trainable_weights(self):\n        if not self.trainable and self.built:\n            return [self.kernel, self.recurrent_kernel, self.bias]\n        return []\n\n    @property\n    def losses(self):\n        return super(RNN, self).losses\n\n    def get_losses_for(self, inputs=None):\n        return super(RNN, self).get_losses_for(inputs=inputs)\n\n\nclass CuDNNGRU(_CuDNNRNN):\n    """"""Fast GRU implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).\n\n    Can only be run on GPU, with the TensorFlow backend.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs.\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state.\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        return_sequences: Boolean. Whether to return the last output.\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n    """"""\n\n    def __init__(self, units,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 return_state=False,\n                 stateful=False,\n                 **kwargs):\n        self.units = units\n        super(CuDNNGRU, self).__init__(\n            return_sequences=return_sequences,\n            return_state=return_state,\n            stateful=stateful,\n            **kwargs)\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n    @property\n    def cell(self):\n        Cell = namedtuple(\'cell\', \'state_size\')\n        cell = Cell(state_size=self.units)\n        return cell\n\n    def build(self, input_shape):\n        super(CuDNNGRU, self).build(input_shape)\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        input_dim = input_shape[-1]\n\n        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n        self._cudnn_gru = cudnn_rnn_ops.CudnnGRU(\n            num_layers=1,\n            num_units=self.units,\n            input_size=input_dim,\n            input_mode=\'linear_input\')\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                      name=\'kernel\',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 3),\n            name=\'recurrent_kernel\',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        self.bias = self.add_weight(shape=(self.units * 6,),\n                                    name=\'bias\',\n                                    initializer=self.bias_initializer,\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n\n        self.kernel_z = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n                                                        self.units:\n                                                        self.units * 2]\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n\n        self.bias_z_i = self.bias[:self.units]\n        self.bias_r_i = self.bias[self.units: self.units * 2]\n        self.bias_h_i = self.bias[self.units * 2: self.units * 3]\n        self.bias_z = self.bias[self.units * 3: self.units * 4]\n        self.bias_r = self.bias[self.units * 4: self.units * 5]\n        self.bias_h = self.bias[self.units * 5:]\n\n        self.built = True\n\n    def _process_batch(self, inputs, initial_state):\n        import tensorflow as tf\n        inputs = tf.transpose(inputs, (1, 0, 2))\n        input_h = initial_state[0]\n        input_h = tf.expand_dims(input_h, axis=0)\n\n        params = self._canonical_to_params(\n            weights=[\n                self.kernel_r,\n                self.kernel_z,\n                self.kernel_h,\n                self.recurrent_kernel_r,\n                self.recurrent_kernel_z,\n                self.recurrent_kernel_h,\n            ],\n            biases=[\n                self.bias_r_i,\n                self.bias_z_i,\n                self.bias_h_i,\n                self.bias_r,\n                self.bias_z,\n                self.bias_h,\n            ],\n        )\n        outputs, h = self._cudnn_gru(\n            inputs,\n            input_h=input_h,\n            params=params,\n            is_training=True)\n\n        if self.stateful or self.return_state:\n            h = h[0]\n        if self.return_sequences:\n            output = tf.transpose(outputs, (1, 0, 2))\n        else:\n            output = outputs[-1]\n        return output, [h]\n\n    def get_config(self):\n        config = {\n            \'units\': self.units,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'recurrent_initializer\':\n                initializers.serialize(self.recurrent_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'recurrent_regularizer\':\n                regularizers.serialize(self.recurrent_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\':\n                regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'recurrent_constraint\':\n                constraints.serialize(self.recurrent_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)}\n        base_config = super(CuDNNGRU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass CuDNNLSTM(_CuDNNRNN):\n    """"""Fast LSTM implementation with [CuDNN](https://developer.nvidia.com/cudnn).\n\n    Can only be run on GPU, with the TensorFlow backend.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs.\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state.\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of the forget gate at initialization.\n            Setting it to true will also force `bias_initializer=""zeros""`.\n            This is recommended in [Jozefowicz et al. (2015)](\n            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        return_sequences: Boolean. Whether to return the last output.\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n    """"""\n    def __init__(self, units,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 return_state=False,\n                 stateful=False,\n                 **kwargs):\n        self.units = units\n        super(CuDNNLSTM, self).__init__(\n            return_sequences=return_sequences,\n            return_state=return_state,\n            stateful=stateful,\n            **kwargs)\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n    @property\n    def cell(self):\n        Cell = namedtuple(\'cell\', \'state_size\')\n        cell = Cell(state_size=(self.units, self.units))\n        return cell\n\n    def build(self, input_shape):\n        super(CuDNNLSTM, self).build(input_shape)\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        input_dim = input_shape[-1]\n\n        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n        self._cudnn_lstm = cudnn_rnn_ops.CudnnLSTM(\n            num_layers=1,\n            num_units=self.units,\n            input_size=input_dim,\n            input_mode=\'linear_input\')\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                      name=\'kernel\',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name=\'recurrent_kernel\',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.unit_forget_bias:\n            def bias_initializer(shape, *args, **kwargs):\n                return K.concatenate([\n                    self.bias_initializer((self.units * 5,), *args, **kwargs),\n                    initializers.Ones()((self.units,), *args, **kwargs),\n                    self.bias_initializer((self.units * 2,), *args, **kwargs),\n                ])\n        else:\n            bias_initializer = self.bias_initializer\n        self.bias = self.add_weight(shape=(self.units * 8,),\n                                    name=\'bias\',\n                                    initializer=bias_initializer,\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n\n        self.kernel_i = self.kernel[:, :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = (\n            self.recurrent_kernel[:, self.units: self.units * 2])\n        self.recurrent_kernel_c = (\n            self.recurrent_kernel[:, self.units * 2: self.units * 3])\n        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\n        self.bias_i_i = self.bias[:self.units]\n        self.bias_f_i = self.bias[self.units: self.units * 2]\n        self.bias_c_i = self.bias[self.units * 2: self.units * 3]\n        self.bias_o_i = self.bias[self.units * 3: self.units * 4]\n        self.bias_i = self.bias[self.units * 4: self.units * 5]\n        self.bias_f = self.bias[self.units * 5: self.units * 6]\n        self.bias_c = self.bias[self.units * 6: self.units * 7]\n        self.bias_o = self.bias[self.units * 7:]\n\n        self.built = True\n\n    def _process_batch(self, inputs, initial_state):\n        import tensorflow as tf\n        inputs = tf.transpose(inputs, (1, 0, 2))\n        input_h = initial_state[0]\n        input_c = initial_state[1]\n        input_h = tf.expand_dims(input_h, axis=0)\n        input_c = tf.expand_dims(input_c, axis=0)\n\n        params = self._canonical_to_params(\n            weights=[\n                self.kernel_i,\n                self.kernel_f,\n                self.kernel_c,\n                self.kernel_o,\n                self.recurrent_kernel_i,\n                self.recurrent_kernel_f,\n                self.recurrent_kernel_c,\n                self.recurrent_kernel_o,\n            ],\n            biases=[\n                self.bias_i_i,\n                self.bias_f_i,\n                self.bias_c_i,\n                self.bias_o_i,\n                self.bias_i,\n                self.bias_f,\n                self.bias_c,\n                self.bias_o,\n            ],\n        )\n        outputs, h, c = self._cudnn_lstm(\n            inputs,\n            input_h=input_h,\n            input_c=input_c,\n            params=params,\n            is_training=True)\n\n        if self.stateful or self.return_state:\n            h = h[0]\n            c = c[0]\n        if self.return_sequences:\n            output = tf.transpose(outputs, (1, 0, 2))\n        else:\n            output = outputs[-1]\n        return output, [h, c]\n\n    def get_config(self):\n        config = {\n            \'units\': self.units,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'recurrent_initializer\':\n                initializers.serialize(self.recurrent_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'unit_forget_bias\': self.unit_forget_bias,\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'recurrent_regularizer\':\n                regularizers.serialize(self.recurrent_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\':\n                regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'recurrent_constraint\': constraints.serialize(self.recurrent_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)}\n        base_config = super(CuDNNLSTM, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n'"
keras/layers/embeddings.py,0,"b'""""""Embedding layer.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend as K\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom ..engine.base_layer import Layer\nfrom ..legacy import interfaces\nfrom ..utils.generic_utils import to_list\n\n\nclass Embedding(Layer):\n    """"""Turns positive integers (indexes) into dense vectors of fixed size.\n    eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n\n    This layer can only be used as the first layer in a model.\n\n    # Example\n\n    ```python\n      model = Sequential()\n      model.add(Embedding(1000, 64, input_length=10))\n      # the model will take as input an integer matrix of size (batch, input_length).\n      # the largest integer (i.e. word index) in the input should be\n      # no larger than 999 (vocabulary size).\n      # now model.output_shape == (None, 10, 64), where None is the batch dimension.\n\n      input_array = np.random.randint(1000, size=(32, 10))\n\n      model.compile(\'rmsprop\', \'mse\')\n      output_array = model.predict(input_array)\n      assert output_array.shape == (32, 10, 64)\n    ```\n\n    # Arguments\n        input_dim: int > 0. Size of the vocabulary,\n            i.e. maximum integer index + 1.\n        output_dim: int >= 0. Dimension of the dense embedding.\n        embeddings_initializer: Initializer for the `embeddings` matrix\n            (see [initializers](../initializers.md)).\n        embeddings_regularizer: Regularizer function applied to\n            the `embeddings` matrix\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        embeddings_constraint: Constraint function applied to\n            the `embeddings` matrix\n            (see [constraints](../constraints.md)).\n        mask_zero: Whether or not the input value 0 is a special ""padding""\n            value that should be masked out.\n            This is useful when using [recurrent layers](recurrent.md)\n            which may take variable length input.\n            If this is `True` then all subsequent layers\n            in the model need to support masking or an exception will be raised.\n            If mask_zero is set to True, as a consequence, index 0 cannot be\n            used in the vocabulary (input_dim should equal size of\n            vocabulary + 1).\n        input_length: Length of input sequences, when it is constant.\n            This argument is required if you are going to connect\n            `Flatten` then `Dense` layers upstream\n            (without it, the shape of the dense outputs cannot be computed).\n\n    # Input shape\n        2D tensor with shape: `(batch_size, sequence_length)`.\n\n    # Output shape\n        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n\n    # References\n        - [A Theoretically Grounded Application of Dropout in\n           Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n    """"""\n\n    @interfaces.legacy_embedding_support\n    def __init__(self, input_dim, output_dim,\n                 embeddings_initializer=\'uniform\',\n                 embeddings_regularizer=None,\n                 activity_regularizer=None,\n                 embeddings_constraint=None,\n                 mask_zero=False,\n                 input_length=None,\n                 **kwargs):\n        if \'input_shape\' not in kwargs:\n            if input_length:\n                kwargs[\'input_shape\'] = (input_length,)\n            else:\n                kwargs[\'input_shape\'] = (None,)\n        super(Embedding, self).__init__(**kwargs)\n\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.embeddings_initializer = initializers.get(embeddings_initializer)\n        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.embeddings_constraint = constraints.get(embeddings_constraint)\n        self.mask_zero = mask_zero\n        self.supports_masking = mask_zero\n        self.input_length = input_length\n\n    def build(self, input_shape):\n        self.embeddings = self.add_weight(\n            shape=(self.input_dim, self.output_dim),\n            initializer=self.embeddings_initializer,\n            name=\'embeddings\',\n            regularizer=self.embeddings_regularizer,\n            constraint=self.embeddings_constraint,\n            dtype=self.dtype)\n        self.built = True\n\n    def compute_mask(self, inputs, mask=None):\n        if not self.mask_zero:\n            return None\n        output_mask = K.not_equal(inputs, 0)\n        return output_mask\n\n    def compute_output_shape(self, input_shape):\n        if self.input_length is None:\n            return input_shape + (self.output_dim,)\n        else:\n            # input_length can be tuple if input is 3D or higher\n            in_lens = to_list(self.input_length, allow_tuple=True)\n            if len(in_lens) != len(input_shape) - 1:\n                raise ValueError(\n                    \'""input_length"" is %s, but received input has shape %s\' %\n                    (str(self.input_length), str(input_shape)))\n            else:\n                for i, (s1, s2) in enumerate(zip(in_lens, input_shape[1:])):\n                    if s1 is not None and s2 is not None and s1 != s2:\n                        raise ValueError(\n                            \'""input_length"" is %s, but received input has shape %s\' %\n                            (str(self.input_length), str(input_shape)))\n                    elif s1 is None:\n                        in_lens[i] = s2\n            return (input_shape[0],) + tuple(in_lens) + (self.output_dim,)\n\n    def call(self, inputs):\n        if K.dtype(inputs) != \'int32\':\n            inputs = K.cast(inputs, \'int32\')\n        out = K.gather(self.embeddings, inputs)\n        return out\n\n    def get_config(self):\n        config = {\'input_dim\': self.input_dim,\n                  \'output_dim\': self.output_dim,\n                  \'embeddings_initializer\':\n                      initializers.serialize(self.embeddings_initializer),\n                  \'embeddings_regularizer\':\n                      regularizers.serialize(self.embeddings_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'embeddings_constraint\':\n                      constraints.serialize(self.embeddings_constraint),\n                  \'mask_zero\': self.mask_zero,\n                  \'input_length\': self.input_length}\n        base_config = super(Embedding, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n'"
keras/layers/local.py,0,"b'# -*- coding: utf-8 -*-\n""""""Locally-connected layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend as K\nfrom .. import activations\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom ..engine.base_layer import Layer\nfrom ..engine.base_layer import InputSpec\nfrom ..utils import conv_utils\nfrom ..legacy import interfaces\n\n\nclass LocallyConnected1D(Layer):\n    """"""Locally-connected layer for 1D inputs.\n\n    The `LocallyConnected1D` layer works similarly to\n    the `Conv1D` layer, except that weights are unshared,\n    that is, a different set of filters is applied at each different patch\n    of the input.\n\n    # Example\n    ```python\n        # apply a unshared weight convolution 1d of length 3 to a sequence with\n        # 10 timesteps, with 64 output filters\n        model = Sequential()\n        model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n        # now model.output_shape == (None, 8, 64)\n        # add a new conv1d on top\n        model.add(LocallyConnected1D(32, 3))\n        # now model.output_shape == (None, 6, 32)\n    ```\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of a single integer,\n            specifying the length of the 1D convolution window.\n        strides: An integer or tuple/list of a single integer,\n            specifying the stride length of the convolution.\n            Specifying any `strides!=1` is incompatible with specifying\n            any `dilation_rate!=1`.\n        padding: Currently only supports `""valid""` (case-insensitive).\n            `""same""` may be supported in the future.\n        data_format: String, one of `channels_first`, `channels_last`.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        3D tensor with shape: `(batch_size, steps, input_dim)`\n\n    # Output shape\n        3D tensor with shape: `(batch_size, new_steps, filters)`\n        `steps` value might have changed due to padding or strides.\n    """"""\n\n    @interfaces.legacy_conv1d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(LocallyConnected1D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 1, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != \'valid\':\n            raise ValueError(\'Invalid border mode for LocallyConnected1D \'\n                             \'(only ""valid"" is supported): \' + padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=3)\n\n    def build(self, input_shape):\n        input_dim = input_shape[2]\n        if input_dim is None:\n            raise ValueError(\'Axis 2 of input should be fully-defined. \'\n                             \'Found shape:\', input_shape)\n        output_length = conv_utils.conv_output_length(input_shape[1],\n                                                      self.kernel_size[0],\n                                                      self.padding,\n                                                      self.strides[0])\n        self.kernel_shape = (output_length,\n                             self.kernel_size[0] * input_dim,\n                             self.filters)\n        self.kernel = self.add_weight(\n            shape=self.kernel_shape,\n            initializer=self.kernel_initializer,\n            name=\'kernel\',\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(\n                shape=(output_length, self.filters),\n                initializer=self.bias_initializer,\n                name=\'bias\',\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(ndim=3, axes={2: input_dim})\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        length = conv_utils.conv_output_length(input_shape[1],\n                                               self.kernel_size[0],\n                                               self.padding,\n                                               self.strides[0])\n        return (input_shape[0], length, self.filters)\n\n    def call(self, inputs):\n        output = K.local_conv1d(inputs, self.kernel, self.kernel_size, self.strides)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def get_config(self):\n        config = {\n            \'filters\': self.filters,\n            \'kernel_size\': self.kernel_size,\n            \'strides\': self.strides,\n            \'padding\': self.padding,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\':\n                regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass LocallyConnected2D(Layer):\n    """"""Locally-connected layer for 2D inputs.\n\n    The `LocallyConnected2D` layer works similarly\n    to the `Conv2D` layer, except that weights are unshared,\n    that is, a different set of filters is applied at each\n    different patch of the input.\n\n    # Examples\n    ```python\n        # apply a 3x3 unshared weights convolution with 64 output filters\n        # on a 32x32 image with `data_format=""channels_last""`:\n        model = Sequential()\n        model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n        # now model.output_shape == (None, 30, 30, 64)\n        # notice that this layer will consume (30*30)*(3*3*3*64)\n        # + (30*30)*64 parameters\n\n        # add a 3x3 unshared weights convolution on top, with 32 output filters:\n        model.add(LocallyConnected2D(32, (3, 3)))\n        # now model.output_shape == (None, 28, 28, 32)\n    ```\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            width and height of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the width and height.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        padding: Currently only support `""valid""` (case-insensitive).\n            `""same""` will be supported in future.\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor with shape:\n        `(samples, channels, rows, cols)` if `data_format=\'channels_first\'`\n        or 4D tensor with shape:\n        `(samples, rows, cols, channels)` if `data_format=\'channels_last\'`.\n\n    # Output shape\n        4D tensor with shape:\n        `(samples, filters, new_rows, new_cols)` if data_format=\'channels_first\'\n        or 4D tensor with shape:\n        `(samples, new_rows, new_cols, filters)` if data_format=\'channels_last\'.\n        `rows` and `cols` values might have changed due to padding.\n    """"""\n\n    @interfaces.legacy_conv2d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(LocallyConnected2D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 2, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != \'valid\':\n            raise ValueError(\'Invalid border mode for LocallyConnected2D \'\n                             \'(only ""valid"" is supported): \' + padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=4)\n\n    def build(self, input_shape):\n        if self.data_format == \'channels_last\':\n            input_row, input_col = input_shape[1:-1]\n            input_filter = input_shape[3]\n        else:\n            input_row, input_col = input_shape[2:]\n            input_filter = input_shape[1]\n        if input_row is None or input_col is None:\n            raise ValueError(\'The spatial dimensions of the inputs to \'\n                             \' a LocallyConnected2D layer \'\n                             \'should be fully-defined, but layer received \'\n                             \'the inputs shape \' + str(input_shape))\n        output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n                                                   self.padding, self.strides[0])\n        output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n                                                   self.padding, self.strides[1])\n        self.output_row = output_row\n        self.output_col = output_col\n        self.kernel_shape = (\n            output_row * output_col,\n            self.kernel_size[0] * self.kernel_size[1] * input_filter,\n            self.filters)\n        self.kernel = self.add_weight(shape=self.kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        if self.data_format == \'channels_first\':\n            self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n        else:\n            self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_first\':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == \'channels_last\':\n            rows = input_shape[1]\n            cols = input_shape[2]\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding, self.strides[1])\n\n        if self.data_format == \'channels_first\':\n            return (input_shape[0], self.filters, rows, cols)\n        elif self.data_format == \'channels_last\':\n            return (input_shape[0], rows, cols, self.filters)\n\n    def call(self, inputs):\n        output = K.local_conv2d(inputs,\n                                self.kernel,\n                                self.kernel_size,\n                                self.strides,\n                                (self.output_row, self.output_col),\n                                self.data_format)\n\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format=self.data_format)\n\n        output = self.activation(output)\n        return output\n\n    def get_config(self):\n        config = {\n            \'filters\': self.filters,\n            \'kernel_size\': self.kernel_size,\n            \'strides\': self.strides,\n            \'padding\': self.padding,\n            \'data_format\': self.data_format,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\':\n                regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n'"
keras/layers/merge.py,0,"b'""""""Layers that can merge several inputs into one.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..engine.base_layer import Layer\nfrom .. import backend as K\n\n\nclass _Merge(Layer):\n    """"""Generic merge layer for elementwise merge functions.\n\n    Used to implement `Sum`, `Average`, etc.\n\n    # Arguments\n        **kwargs: standard layer keyword arguments.\n    """"""\n\n    def __init__(self, **kwargs):\n        super(_Merge, self).__init__(**kwargs)\n        self.supports_masking = True\n\n    def _merge_function(self, inputs):\n        raise NotImplementedError\n\n    def _compute_elemwise_op_output_shape(self, shape1, shape2):\n        """"""Computes the shape of the resultant of an elementwise operation.\n\n        # Arguments\n            shape1: tuple or None. Shape of the first tensor\n            shape2: tuple or None. Shape of the second tensor\n\n        # Returns\n            expected output shape when an element-wise operation is\n            carried out on 2 tensors with shapes shape1 and shape2.\n            tuple or None.\n\n        # Raises\n            ValueError: if shape1 and shape2 are not compatible for\n                element-wise operations.\n        """"""\n        if None in [shape1, shape2]:\n            return None\n        elif len(shape1) < len(shape2):\n            return self._compute_elemwise_op_output_shape(shape2, shape1)\n        elif not shape2:\n            return shape1\n        output_shape = list(shape1[:-len(shape2)])\n        for i, j in zip(shape1[-len(shape2):], shape2):\n            if i is None or j is None:\n                output_shape.append(None)\n            elif i == 1:\n                output_shape.append(j)\n            elif j == 1:\n                output_shape.append(i)\n            else:\n                if i != j:\n                    raise ValueError(\'Operands could not be broadcast \'\n                                     \'together with shapes \' +\n                                     str(shape1) + \' \' + str(shape2))\n                output_shape.append(i)\n        return tuple(output_shape)\n\n    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list):\n            raise ValueError(\'A merge layer should be called \'\n                             \'on a list of inputs.\')\n        if len(input_shape) < 2:\n            raise ValueError(\'A merge layer should be called \'\n                             \'on a list of at least 2 inputs. \'\n                             \'Got \' + str(len(input_shape)) + \' inputs.\')\n        batch_sizes = [s[0] for s in input_shape if s is not None]\n        batch_sizes = set(batch_sizes)\n        batch_sizes -= set([None])\n        if len(batch_sizes) > 1:\n            raise ValueError(\'Can not merge tensors with different \'\n                             \'batch sizes. Got tensors with shapes : \' +\n                             str(input_shape))\n        if input_shape[0] is None:\n            output_shape = None\n        else:\n            output_shape = input_shape[0][1:]\n        for i in range(1, len(input_shape)):\n            if input_shape[i] is None:\n                shape = None\n            else:\n                shape = input_shape[i][1:]\n            output_shape = self._compute_elemwise_op_output_shape(output_shape,\n                                                                  shape)\n        # If the inputs have different ranks, we have to reshape them\n        # to make them broadcastable.\n        if None not in input_shape and len(set(map(len, input_shape))) == 1:\n            self._reshape_required = False\n        else:\n            self._reshape_required = True\n\n    def call(self, inputs):\n        if not isinstance(inputs, list):\n            raise ValueError(\'A merge layer should be called \'\n                             \'on a list of inputs.\')\n        if self._reshape_required:\n            reshaped_inputs = []\n            input_ndims = list(map(K.ndim, inputs))\n            if None not in input_ndims:\n                # If ranks of all inputs are available,\n                # we simply expand each of them at axis=1\n                # until all of them have the same rank.\n                max_ndim = max(input_ndims)\n                for x in inputs:\n                    x_ndim = K.ndim(x)\n                    for _ in range(max_ndim - x_ndim):\n                        x = K.expand_dims(x, 1)\n                    reshaped_inputs.append(x)\n                return self._merge_function(reshaped_inputs)\n            else:\n                # Transpose all inputs so that batch size is the last dimension.\n                # (batch_size, dim1, dim2, ... ) -> (dim1, dim2, ... , batch_size)\n                transposed = False\n                for x in inputs:\n                    x_ndim = K.ndim(x)\n                    if x_ndim is None:\n                        x_shape = K.shape(x)\n                        batch_size = x_shape[0]\n                        new_shape = K.concatenate([x_shape[1:],\n                                                   K.expand_dims(batch_size)])\n                        x_transposed = K.reshape(x, K.stack([batch_size,\n                                                             K.prod(x_shape[1:])]))\n                        x_transposed = K.permute_dimensions(x_transposed, (1, 0))\n                        x_transposed = K.reshape(x_transposed, new_shape)\n                        reshaped_inputs.append(x_transposed)\n                        transposed = True\n                    elif x_ndim > 1:\n                        dims = list(range(1, x_ndim)) + [0]\n                        reshaped_inputs.append(K.permute_dimensions(x, dims))\n                        transposed = True\n                    else:\n                        # We don\'t transpose inputs if they are\n                        # 1D vectors or scalars.\n                        reshaped_inputs.append(x)\n                y = self._merge_function(reshaped_inputs)\n                y_ndim = K.ndim(y)\n                if transposed:\n                    # If inputs have been transposed,\n                    # we have to transpose the output too.\n                    if y_ndim is None:\n                        y_shape = K.shape(y)\n                        y_ndim = K.shape(y_shape)[0]\n                        batch_size = y_shape[y_ndim - 1]\n                        new_shape = K.concatenate([K.expand_dims(batch_size),\n                                                   y_shape[:y_ndim - 1]])\n                        y = K.reshape(y, (-1, batch_size))\n                        y = K.permute_dimensions(y, (1, 0))\n                        y = K.reshape(y, new_shape)\n                    elif y_ndim > 1:\n                        dims = [y_ndim - 1] + list(range(y_ndim - 1))\n                        y = K.permute_dimensions(y, dims)\n                return y\n        else:\n            return self._merge_function(inputs)\n\n    def compute_output_shape(self, input_shape):\n        if input_shape[0] is None:\n            output_shape = None\n        else:\n            output_shape = input_shape[0][1:]\n        for i in range(1, len(input_shape)):\n            if input_shape[i] is None:\n                shape = None\n            else:\n                shape = input_shape[i][1:]\n            output_shape = self._compute_elemwise_op_output_shape(output_shape,\n                                                                  shape)\n        batch_sizes = [s[0] for s in input_shape if s is not None]\n        batch_sizes = set(batch_sizes)\n        batch_sizes -= set([None])\n        if len(batch_sizes) == 1:\n            output_shape = (list(batch_sizes)[0],) + output_shape\n        else:\n            output_shape = (None,) + output_shape\n        return output_shape\n\n    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        if not isinstance(mask, list):\n            raise ValueError(\'`mask` should be a list.\')\n        if not isinstance(inputs, list):\n            raise ValueError(\'`inputs` should be a list.\')\n        if len(mask) != len(inputs):\n            raise ValueError(\'The lists `inputs` and `mask` \'\n                             \'should have the same length.\')\n        if all([m is None for m in mask]):\n            return None\n        masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n        return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n\n\nclass Add(_Merge):\n    """"""Layer that adds a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape, and returns\n    a single tensor (also of the same shape).\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation=\'relu\')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation=\'relu\')(input2)\n        # equivalent to added = keras.layers.add([x1, x2])\n        added = keras.layers.Add()([x1, x2])\n\n        out = keras.layers.Dense(4)(added)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    """"""\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output += inputs[i]\n        return output\n\n\nclass Subtract(_Merge):\n    """"""Layer that subtracts two inputs.\n\n    It takes as input a list of tensors of size 2,\n    both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]),\n    also of the same shape.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation=\'relu\')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation=\'relu\')(input2)\n        # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n        subtracted = keras.layers.Subtract()([x1, x2])\n\n        out = keras.layers.Dense(4)(subtracted)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    """"""\n\n    def build(self, input_shape):\n        super(Subtract, self).build(input_shape)\n        if len(input_shape) != 2:\n            raise ValueError(\'A `Subtract` layer should be called \'\n                             \'on exactly 2 inputs\')\n\n    def _merge_function(self, inputs):\n        if len(inputs) != 2:\n            raise ValueError(\'A `Subtract` layer should be called \'\n                             \'on exactly 2 inputs\')\n        return inputs[0] - inputs[1]\n\n\nclass Multiply(_Merge):\n    """"""Layer that multiplies (element-wise) a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape, and returns\n    a single tensor (also of the same shape).\n    """"""\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output *= inputs[i]\n        return output\n\n\nclass Average(_Merge):\n    """"""Layer that averages a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape, and returns\n    a single tensor (also of the same shape).\n    """"""\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output += inputs[i]\n        return output / len(inputs)\n\n\nclass Maximum(_Merge):\n    """"""Layer that computes the maximum (element-wise) a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape, and returns\n    a single tensor (also of the same shape).\n    """"""\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = K.maximum(output, inputs[i])\n        return output\n\n\nclass Minimum(_Merge):\n    """"""Layer that computes the minimum (element-wise) a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape, and returns\n    a single tensor (also of the same shape).\n    """"""\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = K.minimum(output, inputs[i])\n        return output\n\n\nclass Concatenate(_Merge):\n    """"""Layer that concatenates a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape except for the concatenation axis,\n    and returns a single tensor, the concatenation of all inputs.\n\n    # Arguments\n        axis: Axis along which to concatenate.\n        **kwargs: standard layer keyword arguments.\n    """"""\n\n    def __init__(self, axis=-1, **kwargs):\n        super(Concatenate, self).__init__(**kwargs)\n        self.axis = axis\n        self.supports_masking = True\n        self._reshape_required = False\n\n    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list) or len(input_shape) < 2:\n            raise ValueError(\'A `Concatenate` layer should be called \'\n                             \'on a list of at least 2 inputs\')\n        if all([shape is None for shape in input_shape]):\n            return\n        reduced_inputs_shapes = [list(shape) for shape in input_shape]\n        shape_set = set()\n        for i in range(len(reduced_inputs_shapes)):\n            del reduced_inputs_shapes[i][self.axis]\n            shape_set.add(tuple(reduced_inputs_shapes[i]))\n        if len(shape_set) > 1:\n            raise ValueError(\'A `Concatenate` layer requires \'\n                             \'inputs with matching shapes \'\n                             \'except for the concat axis. \'\n                             \'Got inputs shapes: %s\' % (input_shape))\n\n    def _merge_function(self, inputs):\n        return K.concatenate(inputs, axis=self.axis)\n\n    def compute_output_shape(self, input_shape):\n        if not isinstance(input_shape, list):\n            raise ValueError(\'A `Concatenate` layer should be called \'\n                             \'on a list of inputs.\')\n        input_shapes = input_shape\n        output_shape = list(input_shapes[0])\n        for shape in input_shapes[1:]:\n            if output_shape[self.axis] is None or shape[self.axis] is None:\n                output_shape[self.axis] = None\n                break\n            output_shape[self.axis] += shape[self.axis]\n        return tuple(output_shape)\n\n    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        if not isinstance(mask, list):\n            raise ValueError(\'`mask` should be a list.\')\n        if not isinstance(inputs, list):\n            raise ValueError(\'`inputs` should be a list.\')\n        if len(mask) != len(inputs):\n            raise ValueError(\'The lists `inputs` and `mask` \'\n                             \'should have the same length.\')\n        if all([m is None for m in mask]):\n            return None\n        # Make a list of masks while making sure\n        # the dimensionality of each mask\n        # is the same as the corresponding input.\n        masks = []\n        for input_i, mask_i in zip(inputs, mask):\n            if mask_i is None:\n                # Input is unmasked. Append all 1s to masks,\n                masks.append(K.ones_like(input_i, dtype=\'bool\'))\n            elif K.ndim(mask_i) < K.ndim(input_i):\n                # Mask is smaller than the input, expand it\n                masks.append(K.expand_dims(mask_i))\n            else:\n                masks.append(mask_i)\n        concatenated = K.concatenate(masks, axis=self.axis)\n        return K.all(concatenated, axis=-1, keepdims=False)\n\n    def get_config(self):\n        config = {\n            \'axis\': self.axis,\n        }\n        base_config = super(Concatenate, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Dot(_Merge):\n    """"""Layer that computes a dot product between samples in two tensors.\n\n    E.g. if applied to a list of two tensors `a` and `b` of shape `(batch_size, n)`,\n    the output will be a tensor of shape `(batch_size, 1)`\n    where each entry `i` will be the dot product between\n    `a[i]` and `b[i]`.\n\n    # Arguments\n        axes: Integer or tuple of integers,\n            axis or axes along which to take the dot product.\n        normalize: Whether to L2-normalize samples along the\n            dot product axis before taking the dot product.\n            If set to True, then the output of the dot product\n            is the cosine proximity between the two samples.\n        **kwargs: Standard layer keyword arguments.\n    """"""\n\n    def __init__(self, axes, normalize=False, **kwargs):\n        super(Dot, self).__init__(**kwargs)\n        if not isinstance(axes, int):\n            if not isinstance(axes, (list, tuple)):\n                raise TypeError(\'Invalid type for `axes` - \'\n                                \'should be a list or an int.\')\n            if len(axes) != 2:\n                raise ValueError(\'Invalid format for `axes` - \'\n                                 \'should contain two elements.\')\n            if not isinstance(axes[0], int) or not isinstance(axes[1], int):\n                raise ValueError(\'Invalid format for `axes` - \'\n                                 \'list elements should be ""int"".\')\n        self.axes = axes\n        self.normalize = normalize\n        self.supports_masking = True\n        self._reshape_required = False\n\n    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list) or len(input_shape) != 2:\n            raise ValueError(\'A `Dot` layer should be called \'\n                             \'on a list of 2 inputs.\')\n        shape1 = input_shape[0]\n        shape2 = input_shape[1]\n        if shape1 is None or shape2 is None:\n            return\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = self.axes\n        if shape1[axes[0]] != shape2[axes[1]]:\n            raise ValueError(\n                \'Dimension incompatibility \'\n                \'%s != %s. \' % (shape1[axes[0]], shape2[axes[1]]) +\n                \'Layer shapes: %s, %s\' % (shape1, shape2))\n\n    def _merge_function(self, inputs):\n        if len(inputs) != 2:\n            raise ValueError(\'A `Dot` layer should be called \'\n                             \'on exactly 2 inputs\')\n        x1 = inputs[0]\n        x2 = inputs[1]\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % K.ndim(x1), self.axes % K.ndim(x2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = []\n            for i in range(len(self.axes)):\n                if self.axes[i] < 0:\n                    axes.append(self.axes[i] % K.ndim(inputs[i]))\n                else:\n                    axes.append(self.axes[i])\n        if self.normalize:\n            x1 = K.l2_normalize(x1, axis=axes[0])\n            x2 = K.l2_normalize(x2, axis=axes[1])\n        output = K.batch_dot(x1, x2, axes)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        if not isinstance(input_shape, list) or len(input_shape) != 2:\n            raise ValueError(\'A `Dot` layer should be called \'\n                             \'on a list of 2 inputs.\')\n        shape1 = list(input_shape[0])\n        shape2 = list(input_shape[1])\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = self.axes\n        shape1.pop(axes[0])\n        shape2.pop(axes[1])\n        shape2.pop(0)\n        output_shape = shape1 + shape2\n        if len(output_shape) == 1:\n            output_shape += [1]\n        return tuple(output_shape)\n\n    def compute_mask(self, inputs, mask=None):\n        return None\n\n    def get_config(self):\n        config = {\n            \'axes\': self.axes,\n            \'normalize\': self.normalize,\n        }\n        base_config = super(Dot, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\ndef add(inputs, **kwargs):\n    """"""Functional interface to the `Add` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the sum of the inputs.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation=\'relu\')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation=\'relu\')(input2)\n        added = keras.layers.add([x1, x2])\n\n        out = keras.layers.Dense(4)(added)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    """"""\n    return Add(**kwargs)(inputs)\n\n\ndef subtract(inputs, **kwargs):\n    """"""Functional interface to the `Subtract` layer.\n\n    # Arguments\n        inputs: A list of input tensors (exactly 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the difference of the inputs.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation=\'relu\')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation=\'relu\')(input2)\n        subtracted = keras.layers.subtract([x1, x2])\n\n        out = keras.layers.Dense(4)(subtracted)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    """"""\n    return Subtract(**kwargs)(inputs)\n\n\ndef multiply(inputs, **kwargs):\n    """"""Functional interface to the `Multiply` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise product of the inputs.\n    """"""\n    return Multiply(**kwargs)(inputs)\n\n\ndef average(inputs, **kwargs):\n    """"""Functional interface to the `Average` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the average of the inputs.\n    """"""\n    return Average(**kwargs)(inputs)\n\n\ndef maximum(inputs, **kwargs):\n    """"""Functional interface to the `Maximum` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise maximum of the inputs.\n    """"""\n    return Maximum(**kwargs)(inputs)\n\n\ndef minimum(inputs, **kwargs):\n    """"""Functional interface to the `Minimum` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise minimum of the inputs.\n    """"""\n    return Minimum(**kwargs)(inputs)\n\n\ndef concatenate(inputs, axis=-1, **kwargs):\n    """"""Functional interface to the `Concatenate` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        axis: Concatenation axis.\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the concatenation of the inputs alongside axis `axis`.\n    """"""\n    return Concatenate(axis=axis, **kwargs)(inputs)\n\n\ndef dot(inputs, axes, normalize=False, **kwargs):\n    """"""Functional interface to the `Dot` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        axes: Integer or tuple of integers,\n            axis or axes along which to take the dot product.\n        normalize: Whether to L2-normalize samples along the\n            dot product axis before taking the dot product.\n            If set to True, then the output of the dot product\n            is the cosine proximity between the two samples.\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the dot product of the samples from the inputs.\n    """"""\n    return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)\n'"
keras/layers/noise.py,0,"b'# -*- coding: utf-8 -*-\n""""""Layers that operate regularization via the addition of noise.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..engine.base_layer import Layer\nfrom .. import backend as K\nimport numpy as np\nfrom ..legacy import interfaces\n\n\nclass GaussianNoise(Layer):\n    """"""Apply additive zero-centered Gaussian noise.\n\n    This is useful to mitigate overfitting\n    (you could see it as a form of random data augmentation).\n    Gaussian Noise (GS) is a natural choice as corruption process\n    for real valued inputs.\n\n    As it is a regularization layer, it is only active at training time.\n\n    # Arguments\n        stddev: float, standard deviation of the noise distribution.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n    """"""\n\n    @interfaces.legacy_gaussiannoise_support\n    def __init__(self, stddev, **kwargs):\n        super(GaussianNoise, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.stddev = stddev\n\n    def call(self, inputs, training=None):\n        def noised():\n            return inputs + K.random_normal(shape=K.shape(inputs),\n                                            mean=0.,\n                                            stddev=self.stddev)\n        return K.in_train_phase(noised, inputs, training=training)\n\n    def get_config(self):\n        config = {\'stddev\': self.stddev}\n        base_config = super(GaussianNoise, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass GaussianDropout(Layer):\n    """"""Apply multiplicative 1-centered Gaussian noise.\n\n    As it is a regularization layer, it is only active at training time.\n\n    # Arguments\n        rate: float, drop probability (as with `Dropout`).\n            The multiplicative noise will have\n            standard deviation `sqrt(rate / (1 - rate))`.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n\n    # References\n        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n           http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n    """"""\n\n    @interfaces.legacy_gaussiandropout_support\n    def __init__(self, rate, **kwargs):\n        super(GaussianDropout, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.rate = rate\n\n    def call(self, inputs, training=None):\n        if 0 < self.rate < 1:\n            def noised():\n                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                mean=1.0,\n                                                stddev=stddev)\n            return K.in_train_phase(noised, inputs, training=training)\n        return inputs\n\n    def get_config(self):\n        config = {\'rate\': self.rate}\n        base_config = super(GaussianDropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n\nclass AlphaDropout(Layer):\n    """"""Applies Alpha Dropout to the input.\n\n    Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n    to their original values, in order to ensure the self-normalizing property\n    even after this dropout.\n    Alpha Dropout fits well to Scaled Exponential Linear Units\n    by randomly setting activations to the negative saturation value.\n\n    # Arguments\n        rate: float, drop probability (as with `Dropout`).\n            The multiplicative noise will have\n            standard deviation `sqrt(rate / (1 - rate))`.\n        noise_shape: A 1-D `Tensor` of type `int32`, representing the\n            shape for randomly generated keep/drop flags.\n        seed: A Python integer to use as random seed.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n    """"""\n    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n        super(AlphaDropout, self).__init__(**kwargs)\n        self.rate = rate\n        self.noise_shape = noise_shape\n        self.seed = seed\n        self.supports_masking = True\n\n    def _get_noise_shape(self, inputs):\n        return self.noise_shape if self.noise_shape else K.shape(inputs)\n\n    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed):\n                alpha = 1.6732632423543772848170429916717\n                scale = 1.0507009873554804934193349852946\n                alpha_p = -alpha * scale\n\n                kept_idx = K.greater_equal(K.random_uniform(noise_shape,\n                                                            seed=seed), rate)\n                kept_idx = K.cast(kept_idx, K.floatx())\n\n                # Get affine transformation params\n                a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5\n                b = -a * alpha_p * rate\n\n                # Apply mask\n                x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n\n                # Do affine transformation\n                return a * x + b\n\n            return K.in_train_phase(dropped_inputs, inputs, training=training)\n        return inputs\n\n    def get_config(self):\n        config = {\'rate\': self.rate}\n        base_config = super(AlphaDropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
keras/layers/normalization.py,0,"b'# -*- coding: utf-8 -*-\n""""""Normalization layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..engine.base_layer import Layer, InputSpec\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom .. import backend as K\nfrom ..legacy import interfaces\n\n\nclass BatchNormalization(Layer):\n    """"""Batch normalization layer (Ioffe and Szegedy, 2014).\n\n    Normalize the activations of the previous layer at each batch,\n    i.e. applies a transformation that maintains the mean activation\n    close to 0 and the activation standard deviation close to 1.\n\n    # Arguments\n        axis: Integer, the axis that should be normalized\n            (typically the features axis).\n            For instance, after a `Conv2D` layer with\n            `data_format=""channels_first""`,\n            set `axis=1` in `BatchNormalization`.\n        momentum: Momentum for the moving mean and the moving variance.\n        epsilon: Small float added to variance to avoid dividing by zero.\n        center: If True, add offset of `beta` to normalized tensor.\n            If False, `beta` is ignored.\n        scale: If True, multiply by `gamma`.\n            If False, `gamma` is not used.\n            When the next layer is linear (also e.g. `nn.relu`),\n            this can be disabled since the scaling\n            will be done by the next layer.\n        beta_initializer: Initializer for the beta weight.\n        gamma_initializer: Initializer for the gamma weight.\n        moving_mean_initializer: Initializer for the moving mean.\n        moving_variance_initializer: Initializer for the moving variance.\n        beta_regularizer: Optional regularizer for the beta weight.\n        gamma_regularizer: Optional regularizer for the gamma weight.\n        beta_constraint: Optional constraint for the beta weight.\n        gamma_constraint: Optional constraint for the gamma weight.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n\n    # References\n        - [Batch Normalization: Accelerating Deep Network Training by\n           Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n    """"""\n\n    @interfaces.legacy_batchnorm_support\n    def __init__(self,\n                 axis=-1,\n                 momentum=0.99,\n                 epsilon=1e-3,\n                 center=True,\n                 scale=True,\n                 beta_initializer=\'zeros\',\n                 gamma_initializer=\'ones\',\n                 moving_mean_initializer=\'zeros\',\n                 moving_variance_initializer=\'ones\',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(BatchNormalization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis\n        self.momentum = momentum\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n        self.moving_variance_initializer = (\n            initializers.get(moving_variance_initializer))\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError(\'Axis \' + str(self.axis) + \' of \'\n                             \'input tensor should have a defined dimension \'\n                             \'but the layer received an input with shape \' +\n                             str(input_shape) + \'.\')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name=\'gamma\',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name=\'beta\',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.moving_mean = self.add_weight(\n            shape=shape,\n            name=\'moving_mean\',\n            initializer=self.moving_mean_initializer,\n            trainable=False)\n        self.moving_variance = self.add_weight(\n            shape=shape,\n            name=\'moving_variance\',\n            initializer=self.moving_variance_initializer,\n            trainable=False)\n        self.built = True\n\n    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n\n        # Determines whether broadcasting is needed.\n        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n\n        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    axis=self.axis,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    axis=self.axis,\n                    epsilon=self.epsilon)\n\n        # If the learning phase is *static* and set to inference:\n        if training in {0, False}:\n            return normalize_inference()\n\n        # If the learning is either dynamic, or set to training:\n        normed_training, mean, variance = K.normalize_batch_in_training(\n            inputs, self.gamma, self.beta, reduction_axes,\n            epsilon=self.epsilon)\n\n        if K.backend() != \'cntk\':\n            sample_size = K.prod([K.shape(inputs)[axis]\n                                  for axis in reduction_axes])\n            sample_size = K.cast(sample_size, dtype=K.dtype(inputs))\n            if K.backend() == \'tensorflow\' and sample_size.dtype != \'float32\':\n                sample_size = K.cast(sample_size, dtype=\'float32\')\n\n            # sample variance - unbiased estimator of population variance\n            variance *= sample_size / (sample_size - (1.0 + self.epsilon))\n\n        self.add_update([K.moving_average_update(self.moving_mean,\n                                                 mean,\n                                                 self.momentum),\n                         K.moving_average_update(self.moving_variance,\n                                                 variance,\n                                                 self.momentum)],\n                        inputs)\n\n        # Pick the normalized form corresponding to the training phase.\n        return K.in_train_phase(normed_training,\n                                normalize_inference,\n                                training=training)\n\n    def get_config(self):\n        config = {\n            \'axis\': self.axis,\n            \'momentum\': self.momentum,\n            \'epsilon\': self.epsilon,\n            \'center\': self.center,\n            \'scale\': self.scale,\n            \'beta_initializer\': initializers.serialize(self.beta_initializer),\n            \'gamma_initializer\': initializers.serialize(self.gamma_initializer),\n            \'moving_mean_initializer\':\n                initializers.serialize(self.moving_mean_initializer),\n            \'moving_variance_initializer\':\n                initializers.serialize(self.moving_variance_initializer),\n            \'beta_regularizer\': regularizers.serialize(self.beta_regularizer),\n            \'gamma_regularizer\': regularizers.serialize(self.gamma_regularizer),\n            \'beta_constraint\': constraints.serialize(self.beta_constraint),\n            \'gamma_constraint\': constraints.serialize(self.gamma_constraint)\n        }\n        base_config = super(BatchNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
keras/layers/pooling.py,0,"b'# -*- coding: utf-8 -*-\n""""""Pooling layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend as K\nfrom ..engine.base_layer import Layer\nfrom ..engine.base_layer import InputSpec\nfrom ..utils import conv_utils\nfrom ..legacy import interfaces\n\n\nclass _Pooling1D(Layer):\n    """"""Abstract class for different pooling 1D layers.\n    """"""\n\n    def __init__(self, pool_size=2, strides=None,\n                 padding=\'valid\', data_format=\'channels_last\', **kwargs):\n        super(_Pooling1D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 1, \'pool_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 1, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=3)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_first\':\n            steps = input_shape[2]\n            features = input_shape[1]\n        else:\n            steps = input_shape[1]\n            features = input_shape[2]\n        length = conv_utils.conv_output_length(steps,\n                                               self.pool_size[0],\n                                               self.padding,\n                                               self.strides[0])\n        if self.data_format == \'channels_first\':\n            return (input_shape[0], features, length)\n        else:\n            return (input_shape[0], length, features)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        raise NotImplementedError\n\n    def call(self, inputs):\n        dummy_axis = 2 if self.data_format == \'channels_last\' else 3\n        inputs = K.expand_dims(inputs, dummy_axis)   # add dummy last dimension\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size + (1,),\n                                        strides=self.strides + (1,),\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return K.squeeze(output, dummy_axis)  # remove dummy last dimension\n\n    def get_config(self):\n        config = {\'strides\': self.strides,\n                  \'pool_size\': self.pool_size,\n                  \'padding\': self.padding,\n                  \'data_format\': self.data_format}\n        base_config = super(_Pooling1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass MaxPooling1D(_Pooling1D):\n    """"""Max pooling operation for temporal data.\n\n    # Arguments\n        pool_size: Integer, size of the max pooling windows.\n        strides: Integer, or None. Factor by which to downscale.\n            E.g. 2 will halve the input.\n            If None, it will default to `pool_size`.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, steps, features)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            3D tensor with shape:\n            `(batch_size, steps, features)`\n        - If `data_format=\'channels_first\'`:\n            3D tensor with shape:\n            `(batch_size, features, steps)`\n\n    # Output shape\n        - If `data_format=\'channels_last\'`:\n            3D tensor with shape:\n            `(batch_size, downsampled_steps, features)`\n        - If `data_format=\'channels_first\'`:\n            3D tensor with shape:\n            `(batch_size, features, downsampled_steps)`\n    """"""\n\n    @interfaces.legacy_pooling1d_support\n    def __init__(self, pool_size=2, strides=None,\n                 padding=\'valid\', data_format=\'channels_last\', **kwargs):\n        super(MaxPooling1D, self).__init__(pool_size, strides,\n                                           padding, data_format,\n                                           **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode=\'max\')\n        return output\n\n\nclass AveragePooling1D(_Pooling1D):\n    """"""Average pooling for temporal data.\n\n    # Arguments\n        pool_size: Integer, size of the average pooling windows.\n        strides: Integer, or None. Factor by which to downscale.\n            E.g. 2 will halve the input.\n            If None, it will default to `pool_size`.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, steps, features)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            3D tensor with shape:\n            `(batch_size, steps, features)`\n        - If `data_format=\'channels_first\'`:\n            3D tensor with shape:\n            `(batch_size, features, steps)`\n\n    # Output shape\n        - If `data_format=\'channels_last\'`:\n            3D tensor with shape:\n            `(batch_size, downsampled_steps, features)`\n        - If `data_format=\'channels_first\'`:\n            3D tensor with shape:\n            `(batch_size, features, downsampled_steps)`\n    """"""\n\n    @interfaces.legacy_pooling1d_support\n    def __init__(self, pool_size=2, strides=None,\n                 padding=\'valid\', data_format=\'channels_last\', **kwargs):\n        super(AveragePooling1D, self).__init__(pool_size, strides,\n                                               padding, data_format,\n                                               **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode=\'avg\')\n        return output\n\n\nclass _Pooling2D(Layer):\n    """"""Abstract class for different pooling 2D layers.\n    """"""\n\n    def __init__(self, pool_size=(2, 2), strides=None, padding=\'valid\',\n                 data_format=None, **kwargs):\n        super(_Pooling2D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, \'pool_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 2, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_first\':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == \'channels_last\':\n            rows = input_shape[1]\n            cols = input_shape[2]\n        rows = conv_utils.conv_output_length(rows, self.pool_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.pool_size[1],\n                                             self.padding, self.strides[1])\n        if self.data_format == \'channels_first\':\n            return (input_shape[0], input_shape[1], rows, cols)\n        elif self.data_format == \'channels_last\':\n            return (input_shape[0], rows, cols, input_shape[3])\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        raise NotImplementedError\n\n    def call(self, inputs):\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size,\n                                        strides=self.strides,\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return output\n\n    def get_config(self):\n        config = {\'pool_size\': self.pool_size,\n                  \'padding\': self.padding,\n                  \'strides\': self.strides,\n                  \'data_format\': self.data_format}\n        base_config = super(_Pooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass MaxPooling2D(_Pooling2D):\n    """"""Max pooling operation for spatial data.\n\n    # Arguments\n        pool_size: integer or tuple of 2 integers,\n            factors by which to downscale (vertical, horizontal).\n            (2, 2) will halve the input in both spatial dimension.\n            If only one integer is specified, the same window length\n            will be used for both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n            Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            4D tensor with shape:\n            `(batch_size, rows, cols, channels)`\n        - If `data_format=\'channels_first\'`:\n            4D tensor with shape:\n            `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        - If `data_format=\'channels_last\'`:\n            4D tensor with shape:\n            `(batch_size, pooled_rows, pooled_cols, channels)`\n        - If `data_format=\'channels_first\'`:\n            4D tensor with shape:\n            `(batch_size, channels, pooled_rows, pooled_cols)`\n    """"""\n\n    @interfaces.legacy_pooling2d_support\n    def __init__(self, pool_size=(2, 2), strides=None, padding=\'valid\',\n                 data_format=None, **kwargs):\n        super(MaxPooling2D, self).__init__(pool_size, strides, padding,\n                                           data_format, **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format,\n                          pool_mode=\'max\')\n        return output\n\n\nclass AveragePooling2D(_Pooling2D):\n    """"""Average pooling operation for spatial data.\n\n    # Arguments\n        pool_size: Integer or tuple of 2 integers,\n            factors by which to downscale (vertical, horizontal).\n            (2, 2) will halve the input in both spatial dimension.\n            If only one integer is specified, the same window length\n            will be used for both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n            Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            4D tensor with shape:\n            `(batch_size, rows, cols, channels)`\n        - If `data_format=\'channels_first\'`:\n            4D tensor with shape:\n            `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        - If `data_format=\'channels_last\'`:\n            4D tensor with shape:\n            `(batch_size, pooled_rows, pooled_cols, channels)`\n        - If `data_format=\'channels_first\'`:\n            4D tensor with shape:\n            `(batch_size, channels, pooled_rows, pooled_cols)`\n    """"""\n\n    @interfaces.legacy_pooling2d_support\n    def __init__(self, pool_size=(2, 2), strides=None, padding=\'valid\',\n                 data_format=None, **kwargs):\n        super(AveragePooling2D, self).__init__(pool_size, strides, padding,\n                                               data_format, **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode=\'avg\')\n        return output\n\n\nclass _Pooling3D(Layer):\n    """"""Abstract class for different pooling 3D layers.\n    """"""\n\n    def __init__(self, pool_size=(2, 2, 2), strides=None, padding=\'valid\',\n                 data_format=None, **kwargs):\n        super(_Pooling3D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 3, \'pool_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 3, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_first\':\n            len_dim1 = input_shape[2]\n            len_dim2 = input_shape[3]\n            len_dim3 = input_shape[4]\n        elif self.data_format == \'channels_last\':\n            len_dim1 = input_shape[1]\n            len_dim2 = input_shape[2]\n            len_dim3 = input_shape[3]\n        len_dim1 = conv_utils.conv_output_length(len_dim1, self.pool_size[0],\n                                                 self.padding, self.strides[0])\n        len_dim2 = conv_utils.conv_output_length(len_dim2, self.pool_size[1],\n                                                 self.padding, self.strides[1])\n        len_dim3 = conv_utils.conv_output_length(len_dim3, self.pool_size[2],\n                                                 self.padding, self.strides[2])\n        if self.data_format == \'channels_first\':\n            return (input_shape[0],\n                    input_shape[1],\n                    len_dim1, len_dim2, len_dim3)\n        elif self.data_format == \'channels_last\':\n            return (input_shape[0],\n                    len_dim1, len_dim2, len_dim3,\n                    input_shape[4])\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        raise NotImplementedError\n\n    def call(self, inputs):\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size,\n                                        strides=self.strides,\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return output\n\n    def get_config(self):\n        config = {\'pool_size\': self.pool_size,\n                  \'padding\': self.padding,\n                  \'strides\': self.strides,\n                  \'data_format\': self.data_format}\n        base_config = super(_Pooling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass MaxPooling3D(_Pooling3D):\n    """"""Max pooling operation for 3D data (spatial or spatio-temporal).\n\n    # Arguments\n        pool_size: Integer or tuple of 3 integers,\n            factors by which to downscale (dim1, dim2, dim3).\n            (2, 2, 2) will halve the size of the 3D input in each dimension.\n        strides: Integer, tuple of 3 integers, or None. Strides values.\n                If None, it will default to `pool_size`.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            5D tensor with shape:\n            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        - If `data_format=\'channels_first\'`:\n            5D tensor with shape:\n            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n    # Output shape\n        - If `data_format=\'channels_last\'`:\n            5D tensor with shape:\n            `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n        - If `data_format=\'channels_first\'`:\n            5D tensor with shape:\n            `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n    """"""\n\n    @interfaces.legacy_pooling3d_support\n    def __init__(self, pool_size=(2, 2, 2), strides=None, padding=\'valid\',\n                 data_format=None, **kwargs):\n        super(MaxPooling3D, self).__init__(pool_size, strides, padding,\n                                           data_format, **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool3d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode=\'max\')\n        return output\n\n\nclass AveragePooling3D(_Pooling3D):\n    """"""Average pooling operation for 3D data (spatial or spatio-temporal).\n\n    # Arguments\n        pool_size: Integer or tuple of 3 integers,\n            factors by which to downscale (dim1, dim2, dim3).\n            (2, 2, 2) will halve the size of the 3D input in each dimension.\n        strides: Integer, tuple of 3 integers, or None. Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            5D tensor with shape:\n            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        - If `data_format=\'channels_first\'`:\n            5D tensor with shape:\n            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n    # Output shape\n        - If `data_format=\'channels_last\'`:\n            5D tensor with shape:\n            `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n        - If `data_format=\'channels_first\'`:\n            5D tensor with shape:\n            `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n    """"""\n\n    @interfaces.legacy_pooling3d_support\n    def __init__(self, pool_size=(2, 2, 2), strides=None, padding=\'valid\',\n                 data_format=None, **kwargs):\n        super(AveragePooling3D, self).__init__(pool_size, strides, padding,\n                                               data_format, **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool3d(inputs, pool_size, strides,\n                          padding, data_format,\n                          pool_mode=\'avg\')\n        return output\n\n\nclass _GlobalPooling1D(Layer):\n    """"""Abstract class for different global pooling 1D layers.\n    """"""\n\n    def __init__(self, data_format=\'channels_last\', **kwargs):\n        super(_GlobalPooling1D, self).__init__(**kwargs)\n        self.input_spec = InputSpec(ndim=3)\n        self.data_format = K.normalize_data_format(data_format)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_first\':\n            return (input_shape[0], input_shape[1])\n        else:\n            return (input_shape[0], input_shape[2])\n\n    def call(self, inputs):\n        raise NotImplementedError\n\n    def get_config(self):\n        config = {\'data_format\': self.data_format}\n        base_config = super(_GlobalPooling1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass GlobalAveragePooling1D(_GlobalPooling1D):\n    """"""Global average pooling operation for temporal data.\n\n    # Arguments\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, steps, features)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            3D tensor with shape:\n            `(batch_size, steps, features)`\n        - If `data_format=\'channels_first\'`:\n            3D tensor with shape:\n            `(batch_size, features, steps)`\n\n    # Output shape\n        2D tensor with shape:\n        `(batch_size, features)`\n    """"""\n\n    def __init__(self, data_format=\'channels_last\', **kwargs):\n        super(GlobalAveragePooling1D, self).__init__(data_format,\n                                                     **kwargs)\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        steps_axis = 1 if self.data_format == \'channels_last\' else 2\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            input_shape = K.int_shape(inputs)\n            broadcast_shape = [-1, input_shape[steps_axis], 1]\n            mask = K.reshape(mask, broadcast_shape)\n            inputs *= mask\n            return K.sum(inputs, axis=steps_axis) / K.sum(mask, axis=steps_axis)\n        else:\n            return K.mean(inputs, axis=steps_axis)\n\n    def compute_mask(self, inputs, mask=None):\n        return None\n\n\nclass GlobalMaxPooling1D(_GlobalPooling1D):\n    """"""Global max pooling operation for temporal data.\n\n    # Arguments\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, steps, features)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            3D tensor with shape:\n            `(batch_size, steps, features)`\n        - If `data_format=\'channels_first\'`:\n            3D tensor with shape:\n            `(batch_size, features, steps)`\n\n    # Output shape\n        2D tensor with shape:\n        `(batch_size, features)`\n    """"""\n\n    def call(self, inputs):\n        steps_axis = 1 if self.data_format == \'channels_last\' else 2\n        return K.max(inputs, axis=steps_axis)\n\n\nclass _GlobalPooling2D(Layer):\n    """"""Abstract class for different global pooling 2D layers.\n    """"""\n\n    @interfaces.legacy_global_pooling_support\n    def __init__(self, data_format=None, **kwargs):\n        super(_GlobalPooling2D, self).__init__(**kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            return (input_shape[0], input_shape[3])\n        else:\n            return (input_shape[0], input_shape[1])\n\n    def call(self, inputs):\n        raise NotImplementedError\n\n    def get_config(self):\n        config = {\'data_format\': self.data_format}\n        base_config = super(_GlobalPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass GlobalAveragePooling2D(_GlobalPooling2D):\n    """"""Global average pooling operation for spatial data.\n\n    # Arguments\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            4D tensor with shape:\n            `(batch_size, rows, cols, channels)`\n        - If `data_format=\'channels_first\'`:\n            4D tensor with shape:\n            `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n    """"""\n\n    def call(self, inputs):\n        if self.data_format == \'channels_last\':\n            return K.mean(inputs, axis=[1, 2])\n        else:\n            return K.mean(inputs, axis=[2, 3])\n\n\nclass GlobalMaxPooling2D(_GlobalPooling2D):\n    """"""Global max pooling operation for spatial data.\n\n    # Arguments\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `""channels_first""`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            4D tensor with shape:\n            `(batch_size, rows, cols, channels)`\n        - If `data_format=\'channels_first\'`:\n            4D tensor with shape:\n            `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n    """"""\n\n    def call(self, inputs):\n        if self.data_format == \'channels_last\':\n            return K.max(inputs, axis=[1, 2])\n        else:\n            return K.max(inputs, axis=[2, 3])\n\n\nclass _GlobalPooling3D(Layer):\n    """"""Abstract class for different global pooling 3D layers.\n    """"""\n\n    @interfaces.legacy_global_pooling_support\n    def __init__(self, data_format=None, **kwargs):\n        super(_GlobalPooling3D, self).__init__(**kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            return (input_shape[0], input_shape[4])\n        else:\n            return (input_shape[0], input_shape[1])\n\n    def call(self, inputs):\n        raise NotImplementedError\n\n    def get_config(self):\n        config = {\'data_format\': self.data_format}\n        base_config = super(_GlobalPooling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass GlobalAveragePooling3D(_GlobalPooling3D):\n    """"""Global Average pooling operation for 3D data.\n\n    # Arguments\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            5D tensor with shape:\n            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        - If `data_format=\'channels_first\'`:\n            5D tensor with shape:\n            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n    """"""\n\n    def call(self, inputs):\n        if self.data_format == \'channels_last\':\n            return K.mean(inputs, axis=[1, 2, 3])\n        else:\n            return K.mean(inputs, axis=[2, 3, 4])\n\n\nclass GlobalMaxPooling3D(_GlobalPooling3D):\n    """"""Global Max pooling operation for 3D data.\n\n    # Arguments\n        data_format: A string,\n            one of `""channels_last""` (default) or `""channels_first""`.\n            The ordering of the dimensions in the inputs.\n            `""channels_last""` corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n            while `""channels_first""` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be `""channels_last""`.\n\n    # Input shape\n        - If `data_format=\'channels_last\'`:\n            5D tensor with shape:\n            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        - If `data_format=\'channels_first\'`:\n            5D tensor with shape:\n            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n    """"""\n\n    def call(self, inputs):\n        if self.data_format == \'channels_last\':\n            return K.max(inputs, axis=[1, 2, 3])\n        else:\n            return K.max(inputs, axis=[2, 3, 4])\n\n\n# Aliases\n\nAvgPool1D = AveragePooling1D\nMaxPool1D = MaxPooling1D\nAvgPool2D = AveragePooling2D\nMaxPool2D = MaxPooling2D\nAvgPool3D = AveragePooling3D\nMaxPool3D = MaxPooling3D\nGlobalMaxPool1D = GlobalMaxPooling1D\nGlobalMaxPool2D = GlobalMaxPooling2D\nGlobalMaxPool3D = GlobalMaxPooling3D\nGlobalAvgPool1D = GlobalAveragePooling1D\nGlobalAvgPool2D = GlobalAveragePooling2D\nGlobalAvgPool3D = GlobalAveragePooling3D\n'"
keras/layers/recurrent.py,0,"b'# -*- coding: utf-8 -*-\n""""""Recurrent layers and their base classes.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport warnings\n\nfrom .. import backend as K\nfrom .. import activations\nfrom .. import initializers\nfrom .. import regularizers\nfrom .. import constraints\nfrom ..engine.base_layer import Layer\nfrom ..engine.base_layer import disable_tracking\nfrom ..engine.base_layer import InputSpec\nfrom ..utils.generic_utils import has_arg\nfrom ..utils.generic_utils import to_list\n\n# Legacy support.\nfrom ..legacy.layers import Recurrent\nfrom ..legacy import interfaces\n\n\nclass StackedRNNCells(Layer):\n    """"""Wrapper allowing a stack of RNN cells to behave as a single cell.\n\n    Used to implement efficient stacked RNNs.\n\n    # Arguments\n        cells: List of RNN cell instances.\n\n    # Examples\n\n    ```python\n        cells = [\n            keras.layers.LSTMCell(output_dim),\n            keras.layers.LSTMCell(output_dim),\n            keras.layers.LSTMCell(output_dim),\n        ]\n\n        inputs = keras.Input((timesteps, input_dim))\n        x = keras.layers.RNN(cells)(inputs)\n    ```\n    """"""\n\n    def __init__(self, cells, **kwargs):\n        for cell in cells:\n            if not hasattr(cell, \'call\'):\n                raise ValueError(\'All cells must have a `call` method. \'\n                                 \'received cells:\', cells)\n            if not hasattr(cell, \'state_size\'):\n                raise ValueError(\'All cells must have a \'\n                                 \'`state_size` attribute. \'\n                                 \'received cells:\', cells)\n        self.cells = cells\n        # reverse_state_order determines whether the state size will be in a\n        # reverse order of the cells\' state. User might want to set this to True\n        # to keep the existing behavior. This is only useful when use\n        # `RNN(return_state=True)` since the state will be returned as the same\n        # order of state_size.\n        self.reverse_state_order = kwargs.pop(\'reverse_state_order\', False)\n        if self.reverse_state_order:\n            warnings.warn(\'`reverse_state_order=True` in `StackedRNNCells` \'\n                          \'will soon be deprecated. Please update the code to \'\n                          \'work with the natural order of states if you \'\n                          \'reply on the RNN states, \'\n                          \'eg `RNN(return_state=True)`.\')\n        super(StackedRNNCells, self).__init__(**kwargs)\n\n    @property\n    def state_size(self):\n        # States are a flat list of the individual cell state size.\n        # e.g. states of a 2-layer LSTM would be `[h1, c1, h2, c2]`.\n        # (assuming one LSTM has states [h, c])\n        # In the case of reverse_state_order=True, the state_size will be\n        # `[h2, c2, h1, c1]`.\n        state_size = []\n        for cell in self.cells[::-1] if self.reverse_state_order else self.cells:\n            if hasattr(cell.state_size, \'__len__\'):\n                state_size += list(cell.state_size)\n            else:\n                state_size.append(cell.state_size)\n        return tuple(state_size)\n\n    @property\n    def output_size(self):\n        if getattr(self.cells[-1], \'output_size\', None) is not None:\n            return self.cells[-1].output_size\n        if hasattr(self.cells[-1].state_size, \'__len__\'):\n            return self.cells[-1].state_size[0]\n        else:\n            return self.cells[-1].state_size\n\n    def call(self, inputs, states, constants=None, **kwargs):\n        # Recover per-cell states.\n        nested_states = []\n        for cell in self.cells[::-1] if self.reverse_state_order else self.cells:\n            if hasattr(cell.state_size, \'__len__\'):\n                nested_states.append(states[:len(cell.state_size)])\n                states = states[len(cell.state_size):]\n            else:\n                nested_states.append([states[0]])\n                states = states[1:]\n        if self.reverse_state_order:\n            nested_states = nested_states[::-1]\n\n        # Call the cells in order and store the returned states.\n        new_nested_states = []\n        for cell, states in zip(self.cells, nested_states):\n            if has_arg(cell.call, \'constants\'):\n                inputs, states = cell.call(inputs, states,\n                                           constants=constants,\n                                           **kwargs)\n            else:\n                inputs, states = cell.call(inputs, states, **kwargs)\n            new_nested_states.append(states)\n\n        # Format the new states as a flat list\n        # in reverse cell order.\n        new_states = []\n        if self.reverse_state_order:\n            new_nested_states = new_nested_states[::-1]\n        for cell_states in new_nested_states:\n            new_states += cell_states\n        return inputs, new_states\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            constants_shape = input_shape[1:]\n            input_shape = input_shape[0]\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                if has_arg(cell.call, \'constants\'):\n                    cell.build([input_shape] + constants_shape)\n                else:\n                    cell.build(input_shape)\n            if getattr(cell, \'output_size\', None) is not None:\n                output_dim = cell.output_size\n            elif hasattr(cell.state_size, \'__len__\'):\n                output_dim = cell.state_size[0]\n            else:\n                output_dim = cell.state_size\n            input_shape = (input_shape[0], output_dim)\n        self.built = True\n\n    def get_config(self):\n        cells = []\n        for cell in self.cells:\n            cells.append({\'class_name\': cell.__class__.__name__,\n                          \'config\': cell.get_config()})\n        config = {\'cells\': cells}\n        base_config = super(StackedRNNCells, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        cells = []\n        for cell_config in config.pop(\'cells\'):\n            cells.append(deserialize_layer(cell_config,\n                                           custom_objects=custom_objects))\n        return cls(cells, **config)\n\n    @property\n    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.trainable_weights\n        return weights\n\n    @property\n    def non_trainable_weights(self):\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = []\n            for cell in self.cells:\n                if isinstance(cell, Layer):\n                    trainable_weights += cell.trainable_weights\n            return trainable_weights + weights\n        return weights\n\n    def get_weights(self):\n        """"""Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays.\n        """"""\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.weights\n        return K.batch_get_value(weights)\n\n    def set_weights(self, weights):\n        """"""Sets the weights of the model.\n\n        # Arguments\n            weights: A list of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        """"""\n        tuples = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                num_param = len(cell.weights)\n                weights = weights[:num_param]\n                for sw, w in zip(cell.weights, weights):\n                    tuples.append((sw, w))\n                weights = weights[num_param:]\n        K.batch_set_value(tuples)\n\n    @property\n    def losses(self):\n        losses = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell_losses = cell.losses\n                losses += cell_losses\n        return losses\n\n    def get_losses_for(self, inputs=None):\n        losses = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell_losses = cell.get_losses_for(inputs)\n                losses += cell_losses\n        return losses\n\n\nclass RNN(Layer):\n    """"""Base class for recurrent layers.\n\n    # Arguments\n        cell: A RNN cell instance. A RNN cell is a class that has:\n            - a `call(input_at_t, states_at_t)` method, returning\n                `(output_at_t, states_at_t_plus_1)`. The call method of the\n                cell can also take the optional argument `constants`, see\n                section ""Note on passing external constants"" below.\n            - a `state_size` attribute. This can be a single integer\n                (single state) in which case it is\n                the size of the recurrent state\n                (which should be the same as the size of the cell output).\n                This can also be a list/tuple of integers\n                (one size per state).\n            - a `output_size` attribute. This can be a single integer or a\n                TensorShape, which represent the shape of the output. For\n                backward compatible reason, if this attribute is not available\n                for the cell, the value will be inferred by the first element\n                of the `state_size`.\n            It is also possible for `cell` to be a list of RNN cell instances,\n            in which cases the cells get stacked one after the other in the RNN,\n            implementing an efficient stacked RNN.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        unroll: Boolean (default False).\n            If True, the network will be unrolled,\n            else a symbolic loop will be used.\n            Unrolling can speed-up a RNN,\n            although it tends to be more memory-intensive.\n            Unrolling is only suitable for short sequences.\n        input_dim: dimensionality of the input (integer).\n            This argument (or alternatively,\n            the keyword argument `input_shape`)\n            is required when using this layer as the first layer in a model.\n        input_length: Length of input sequences, to be specified\n            when it is constant.\n            This argument is required if you are going to connect\n            `Flatten` then `Dense` layers upstream\n            (without it, the shape of the dense outputs cannot be computed).\n            Note that if the recurrent layer is not the first layer\n            in your model, you would need to specify the input length\n            at the level of the first layer\n            (e.g. via the `input_shape` argument)\n\n    # Input shape\n        3D tensor with shape `(batch_size, timesteps, input_dim)`.\n\n    # Output shape\n        - if `return_state`: a list of tensors. The first tensor is\n            the output. The remaining tensors are the last states,\n            each with shape `(batch_size, units)`. For example, the number of\n            state tensors is 1 (for RNN and GRU) or 2 (for LSTM).\n        - if `return_sequences`: 3D tensor with shape\n            `(batch_size, timesteps, units)`.\n        - else, 2D tensor with shape `(batch_size, units)`.\n\n    # Masking\n        This layer supports masking for input data with a variable number\n        of timesteps. To introduce masks to your data,\n        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n        set to `True`.\n\n    # Note on using statefulness in RNNs\n        You can set RNN layers to be \'stateful\', which means that the states\n        computed for the samples in one batch will be reused as initial states\n        for the samples in the next batch. This assumes a one-to-one mapping\n        between samples in different successive batches.\n\n        To enable statefulness:\n            - specify `stateful=True` in the layer constructor.\n            - specify a fixed batch size for your model, by passing\n                if sequential model:\n                  `batch_input_shape=(...)` to the first layer in your model.\n                else for functional model with 1 or more Input layers:\n                  `batch_shape=(...)` to all the first layers in your model.\n                This is the expected shape of your inputs\n                *including the batch size*.\n                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n            - specify `shuffle=False` when calling fit().\n\n        To reset the states of your model, call `.reset_states()` on either\n        a specific layer, or on your entire model.\n\n    # Note on specifying the initial state of RNNs\n        You can specify the initial state of RNN layers symbolically by\n        calling them with the keyword argument `initial_state`. The value of\n        `initial_state` should be a tensor or list of tensors representing\n        the initial state of the RNN layer.\n\n        You can specify the initial state of RNN layers numerically by\n        calling `reset_states` with the keyword argument `states`. The value of\n        `states` should be a numpy array or list of numpy arrays representing\n        the initial state of the RNN layer.\n\n    # Note on passing external constants to RNNs\n        You can pass ""external"" constants to the cell using the `constants`\n        keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n        requires that the `cell.call` method accepts the same keyword argument\n        `constants`. Such constants can be used to condition the cell\n        transformation on additional static inputs (not changing over time),\n        a.k.a. an attention mechanism.\n\n    # Examples\n\n    ```python\n        # First, let\'s define a RNN Cell, as a layer subclass.\n\n        class MinimalRNNCell(keras.layers.Layer):\n\n            def __init__(self, units, **kwargs):\n                self.units = units\n                self.state_size = units\n                super(MinimalRNNCell, self).__init__(**kwargs)\n\n            def build(self, input_shape):\n                self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                              initializer=\'uniform\',\n                                              name=\'kernel\')\n                self.recurrent_kernel = self.add_weight(\n                    shape=(self.units, self.units),\n                    initializer=\'uniform\',\n                    name=\'recurrent_kernel\')\n                self.built = True\n\n            def call(self, inputs, states):\n                prev_output = states[0]\n                h = K.dot(inputs, self.kernel)\n                output = h + K.dot(prev_output, self.recurrent_kernel)\n                return output, [output]\n\n        # Let\'s use this cell in a RNN layer:\n\n        cell = MinimalRNNCell(32)\n        x = keras.Input((None, 5))\n        layer = RNN(cell)\n        y = layer(x)\n\n        # Here\'s how to use the cell to build a stacked RNN:\n\n        cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n        x = keras.Input((None, 5))\n        layer = RNN(cells)\n        y = layer(x)\n    ```\n    """"""\n\n    def __init__(self, cell,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if isinstance(cell, (list, tuple)):\n            cell = StackedRNNCells(cell)\n        if not hasattr(cell, \'call\'):\n            raise ValueError(\'`cell` should have a `call` method. \'\n                             \'The RNN was passed:\', cell)\n        if not hasattr(cell, \'state_size\'):\n            raise ValueError(\'The RNN cell should have \'\n                             \'an attribute `state_size` \'\n                             \'(tuple of integers, \'\n                             \'one integer per RNN state).\')\n        super(RNN, self).__init__(**kwargs)\n        self._set_cell(cell)\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self._states = None\n        self.constants_spec = None\n        self._num_constants = None\n\n    @disable_tracking\n    def _set_cell(self, cell):\n        # This is isolated in its own method in order to use\n        # the disable_tracking decorator without altering the\n        # visible signature of __init__.\n        self.cell = cell\n\n    @property\n    def states(self):\n        if self._states is None:\n            if isinstance(self.cell.state_size, int):\n                num_states = 1\n            else:\n                num_states = len(self.cell.state_size)\n            return [None for _ in range(num_states)]\n        return self._states\n\n    @states.setter\n    def states(self, states):\n        self._states = states\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        if hasattr(self.cell.state_size, \'__len__\'):\n            state_size = self.cell.state_size\n        else:\n            state_size = [self.cell.state_size]\n\n        if getattr(self.cell, \'output_size\', None) is not None:\n            output_dim = self.cell.output_size\n        else:\n            output_dim = state_size[0]\n\n        if self.return_sequences:\n            output_shape = (input_shape[0], input_shape[1], output_dim)\n        else:\n            output_shape = (input_shape[0], output_dim)\n\n        if self.return_state:\n            state_shape = [(input_shape[0], dim) for dim in state_size]\n            return [output_shape] + state_shape\n        else:\n            return output_shape\n\n    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask\n\n    def build(self, input_shape):\n        # Note input_shape will be list of shapes of initial states and\n        # constants if these are passed in __call__.\n        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n        else:\n            constants_shape = None\n\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        input_dim = input_shape[-1]\n        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n\n        # allow cell (if layer) to build before we set or validate state_spec\n        if isinstance(self.cell, Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n            if constants_shape is not None:\n                self.cell.build([step_input_shape] + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\n        # set or validate state_spec\n        if hasattr(self.cell.state_size, \'__len__\'):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        if self.state_spec is not None:\n            # initial_state was passed in call, check compatibility\n            if [spec.shape[-1] for spec in self.state_spec] != state_size:\n                raise ValueError(\n                    \'An `initial_state` was passed that is not compatible with \'\n                    \'`cell.state_size`. Received `state_spec`={}; \'\n                    \'however `cell.state_size` is \'\n                    \'{}\'.format(self.state_spec, self.cell.state_size))\n        else:\n            self.state_spec = [InputSpec(shape=(None, dim))\n                               for dim in state_size]\n        if self.stateful:\n            self.reset_states()\n        self.built = True\n\n    def get_initial_state(self, inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        if hasattr(self.cell.state_size, \'__len__\'):\n            return [K.tile(initial_state, [1, dim])\n                    for dim in self.cell.state_size]\n        else:\n            return [K.tile(initial_state, [1, self.cell.state_size])]\n\n    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = _standardize_args(\n            inputs, initial_state, constants, self._num_constants)\n\n        if initial_state is None and constants is None:\n            return super(RNN, self).__call__(inputs, **kwargs)\n\n        # If any of `initial_state` or `constants` are specified and are Keras\n        # tensors, then add them to the inputs and temporarily modify the\n        # input_spec to include them.\n\n        additional_inputs = []\n        additional_specs = []\n\n        if initial_state is not None:\n            kwargs[\'initial_state\'] = initial_state\n            additional_inputs += initial_state\n            self.state_spec = [InputSpec(shape=K.int_shape(state))\n                               for state in initial_state]\n            additional_specs += self.state_spec\n        if constants is not None:\n            kwargs[\'constants\'] = constants\n            additional_inputs += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n                                   for constant in constants]\n            self._num_constants = len(constants)\n            additional_specs += self.constants_spec\n        # at this point additional_inputs cannot be empty\n        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != is_keras_tensor:\n                raise ValueError(\'The initial state or constants of an RNN\'\n                                 \' layer cannot be specified with a mix of\'\n                                 \' Keras tensors and non-Keras tensors\'\n                                 \' (a ""Keras tensor"" is a tensor that was\'\n                                 \' returned by a Keras layer, or by `Input`)\')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            if \'initial_state\' in kwargs:\n                kwargs.pop(\'initial_state\')\n            if \'constants\' in kwargs:\n                kwargs.pop(\'constants\')\n            output = super(RNN, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(RNN, self).__call__(inputs, **kwargs)\n\n    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        if not isinstance(initial_state, (list, tuple, type(None))):\n            initial_state = [initial_state]\n        if not isinstance(constants, (list, tuple, type(None))):\n            constants = [constants]\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            if len(inputs) == 1:\n                inputs = inputs[0]\n            else:\n                # get initial_state from full input spec\n                # as they could be copied to multiple GPU.\n                if self._num_constants is None:\n                    if initial_state is not None:\n                        raise ValueError(\'Layer was passed initial state \' +\n                                         \'via both kwarg and inputs list)\')\n                    initial_state = inputs[1:]\n                else:\n                    if initial_state is not None and inputs[1:-self._num_constants]:\n                        raise ValueError(\'Layer was passed initial state \' +\n                                         \'via both kwarg and inputs list\')\n                    initial_state = inputs[1:-self._num_constants]\n                    if constants is None:\n                        constants = inputs[-self._num_constants:]\n                    elif len(inputs) > 1 + len(initial_state):\n                        raise ValueError(\'Layer was passed constants \' +\n                                         \'via both kwarg and inputs list)\')\n                if len(initial_state) == 0:\n                    initial_state = None\n                inputs = inputs[0]\n        if initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError(\'Layer has \' + str(len(self.states)) +\n                             \' states but was passed \' +\n                             str(len(initial_state)) +\n                             \' initial states.\')\n\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps is None:\n            raise ValueError(\'Cannot unroll a RNN if the \'\n                             \'time dimension is undefined. \\n\'\n                             \'- If using a Sequential model, \'\n                             \'specify the time dimension by passing \'\n                             \'an `input_shape` or `batch_input_shape` \'\n                             \'argument to your first layer. If your \'\n                             \'first layer is an Embedding, you can \'\n                             \'also use the `input_length` argument.\\n\'\n                             \'- If using the functional API, specify \'\n                             \'the time dimension by passing a `shape` \'\n                             \'or `batch_shape` argument to your Input layer.\')\n\n        kwargs = {}\n        if has_arg(self.cell.call, \'training\'):\n            kwargs[\'training\'] = training\n\n        if constants:\n            if not has_arg(self.cell.call, \'constants\'):\n                raise ValueError(\'RNN cell does not support constants\')\n\n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)\n        else:\n            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states = K.rnn(step,\n                                             inputs,\n                                             initial_state,\n                                             constants=constants,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        # Properly set learning phase\n        if getattr(last_output, \'_uses_learning_phase\', False):\n            output._uses_learning_phase = True\n            for state in states:\n                state._uses_learning_phase = True\n\n        if self.return_state:\n            states = to_list(states, allow_tuple=True)\n            return [output] + states\n        else:\n            return output\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError(\'Layer must be stateful.\')\n        batch_size = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise ValueError(\'If a RNN is stateful, it needs to know \'\n                             \'its batch size. Specify the batch size \'\n                             \'of your input tensors: \\n\'\n                             \'- If using a Sequential model, \'\n                             \'specify the batch size by passing \'\n                             \'a `batch_input_shape` \'\n                             \'argument to your first layer.\\n\'\n                             \'- If using the functional API, specify \'\n                             \'the batch size by passing a \'\n                             \'`batch_shape` argument to your Input layer.\')\n        # initialize state if None\n        if self.states[0] is None:\n            if hasattr(self.cell.state_size, \'__len__\'):\n                self.states = [K.zeros((batch_size, dim))\n                               for dim in self.cell.state_size]\n            else:\n                self.states = [K.zeros((batch_size, self.cell.state_size))]\n        elif states is None:\n            if hasattr(self.cell.state_size, \'__len__\'):\n                for state, dim in zip(self.states, self.cell.state_size):\n                    K.set_value(state, np.zeros((batch_size, dim)))\n            else:\n                K.set_value(self.states[0],\n                            np.zeros((batch_size, self.cell.state_size)))\n        else:\n            states = to_list(states, allow_tuple=True)\n            if len(states) != len(self.states):\n                raise ValueError(\'Layer \' + self.name + \' expects \' +\n                                 str(len(self.states)) + \' states, \'\n                                 \'but it received \' + str(len(states)) +\n                                 \' state values. Input received: \' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size, \'__len__\'):\n                    dim = self.cell.state_size[index]\n                else:\n                    dim = self.cell.state_size\n                if value.shape != (batch_size, dim):\n                    raise ValueError(\'State \' + str(index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected shape=\' +\n                                     str((batch_size, dim)) +\n                                     \', found shape=\' + str(value.shape))\n                # TODO: consider batch calls to `set_value`.\n                K.set_value(state, value)\n\n    def get_config(self):\n        config = {\'return_sequences\': self.return_sequences,\n                  \'return_state\': self.return_state,\n                  \'go_backwards\': self.go_backwards,\n                  \'stateful\': self.stateful,\n                  \'unroll\': self.unroll}\n        if self._num_constants is not None:\n            config[\'num_constants\'] = self._num_constants\n\n        cell_config = self.cell.get_config()\n        config[\'cell\'] = {\'class_name\': self.cell.__class__.__name__,\n                          \'config\': cell_config}\n        base_config = super(RNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        cell = deserialize_layer(config.pop(\'cell\'),\n                                 custom_objects=custom_objects)\n        num_constants = config.pop(\'num_constants\', None)\n        layer = cls(cell, **config)\n        layer._num_constants = num_constants\n        return layer\n\n    @property\n    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        if isinstance(self.cell, Layer):\n            return self.cell.trainable_weights\n        return []\n\n    @property\n    def non_trainable_weights(self):\n        if isinstance(self.cell, Layer):\n            if not self.trainable:\n                return self.cell.weights\n            return self.cell.non_trainable_weights\n        return []\n\n    @property\n    def losses(self):\n        layer_losses = super(RNN, self).losses\n        if isinstance(self.cell, Layer):\n            return self.cell.losses + layer_losses\n        return layer_losses\n\n    def get_losses_for(self, inputs=None):\n        if isinstance(self.cell, Layer):\n            cell_losses = self.cell.get_losses_for(inputs)\n            return cell_losses + super(RNN, self).get_losses_for(inputs)\n        return super(RNN, self).get_losses_for(inputs)\n\n\nclass SimpleRNNCell(Layer):\n    """"""Cell class for SimpleRNN.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n    """"""\n\n    def __init__(self, units,\n                 activation=\'tanh\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        super(SimpleRNNCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.state_size = self.units\n        self.output_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None\n\n    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      name=\'kernel\',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            name=\'recurrent_kernel\',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        name=\'bias\',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.built = True\n\n    def call(self, inputs, states, training=None):\n        prev_output = states[0]\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(prev_output),\n                self.recurrent_dropout,\n                training=training)\n\n        dp_mask = self._dropout_mask\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if dp_mask is not None:\n            h = K.dot(inputs * dp_mask, self.kernel)\n        else:\n            h = K.dot(inputs, self.kernel)\n        if self.bias is not None:\n            h = K.bias_add(h, self.bias)\n\n        if rec_dp_mask is not None:\n            prev_output *= rec_dp_mask\n        output = h + K.dot(prev_output, self.recurrent_kernel)\n        if self.activation is not None:\n            output = self.activation(output)\n\n        # Properly set learning phase on output tensor.\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                output._uses_learning_phase = True\n        return output, [output]\n\n    def get_config(self):\n        config = {\'units\': self.units,\n                  \'activation\': activations.serialize(self.activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout}\n        base_config = super(SimpleRNNCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass SimpleRNN(RNN):\n    """"""Fully-connected RNN where the output is to be fed back to input.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        unroll: Boolean (default False).\n            If True, the network will be unrolled,\n            else a symbolic loop will be used.\n            Unrolling can speed-up a RNN,\n            although it tends to be more memory-intensive.\n            Unrolling is only suitable for short sequences.\n    """"""\n\n    @interfaces.legacy_recurrent_support\n    def __init__(self, units,\n                 activation=\'tanh\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if \'implementation\' in kwargs:\n            kwargs.pop(\'implementation\')\n            warnings.warn(\'The `implementation` argument \'\n                          \'in `SimpleRNN` has been deprecated. \'\n                          \'Please remove it from your layer call.\')\n        if K.backend() == \'theano\' and (dropout or recurrent_dropout):\n            warnings.warn(\n                \'RNN dropout is no longer supported with the Theano backend \'\n                \'due to technical limitations. \'\n                \'You can either set `dropout` and `recurrent_dropout` to 0, \'\n                \'or use the TensorFlow backend.\')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = SimpleRNNCell(units,\n                             activation=activation,\n                             use_bias=use_bias,\n                             kernel_initializer=kernel_initializer,\n                             recurrent_initializer=recurrent_initializer,\n                             bias_initializer=bias_initializer,\n                             kernel_regularizer=kernel_regularizer,\n                             recurrent_regularizer=recurrent_regularizer,\n                             bias_regularizer=bias_regularizer,\n                             kernel_constraint=kernel_constraint,\n                             recurrent_constraint=recurrent_constraint,\n                             bias_constraint=bias_constraint,\n                             dropout=dropout,\n                             recurrent_dropout=recurrent_dropout)\n        super(SimpleRNN, self).__init__(cell,\n                                        return_sequences=return_sequences,\n                                        return_state=return_state,\n                                        go_backwards=go_backwards,\n                                        stateful=stateful,\n                                        unroll=unroll,\n                                        **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(SimpleRNN, self).call(inputs,\n                                           mask=mask,\n                                           training=training,\n                                           initial_state=initial_state)\n\n    @property\n    def units(self):\n        return self.cell.units\n\n    @property\n    def activation(self):\n        return self.cell.activation\n\n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\n    def get_config(self):\n        config = {\'units\': self.units,\n                  \'activation\': activations.serialize(self.activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout}\n        base_config = super(SimpleRNN, self).get_config()\n        del base_config[\'cell\']\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n        if \'implementation\' in config:\n            config.pop(\'implementation\')\n        return cls(**config)\n\n\nclass GRUCell(Layer):\n    """"""Cell class for the GRU layer.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        recurrent_activation: Activation function to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n            Default: sigmoid (`sigmoid`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n        implementation: Implementation mode, either 1 or 2.\n            Mode 1 will structure its operations as a larger number of\n            smaller dot products and additions, whereas mode 2 will\n            batch them into fewer, larger operations. These modes will\n            have different performance profiles on different hardware and\n            for different applications.\n        reset_after: GRU convention (whether to apply reset gate after or\n            before matrix multiplication). False = ""before"" (default),\n            True = ""after"" (CuDNN compatible).\n    """"""\n\n    def __init__(self, units,\n                 activation=\'tanh\',\n                 recurrent_activation=\'sigmoid\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=2,\n                 reset_after=False,\n                 **kwargs):\n        super(GRUCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.reset_after = reset_after\n        self.state_size = self.units\n        self.output_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\n        if isinstance(self.recurrent_initializer, initializers.Identity):\n            def recurrent_identity(shape, gain=1., dtype=None):\n                del dtype\n                return gain * np.concatenate(\n                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n\n            self.recurrent_initializer = recurrent_identity\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                      name=\'kernel\',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 3),\n            name=\'recurrent_kernel\',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if not self.reset_after:\n                bias_shape = (3 * self.units,)\n            else:\n                # separate biases for input and recurrent kernels\n                # Note: the shape is intentionally different from CuDNNGRU biases\n                # `(2 * 3 * self.units,)`, so that we can distinguish the classes\n                # when loading and converting saved weights.\n                bias_shape = (2, 3 * self.units)\n            self.bias = self.add_weight(shape=bias_shape,\n                                        name=\'bias\',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n            if not self.reset_after:\n                self.input_bias, self.recurrent_bias = self.bias, None\n            else:\n                # NOTE: need to flatten, since slicing in CNTK gives 2D array\n                self.input_bias = K.flatten(self.bias[0])\n                self.recurrent_bias = K.flatten(self.bias[1])\n        else:\n            self.bias = None\n\n        # update gate\n        self.kernel_z = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n        # reset gate\n        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n                                                        self.units:\n                                                        self.units * 2]\n        # new gate\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n\n        if self.use_bias:\n            # bias for inputs\n            self.input_bias_z = self.input_bias[:self.units]\n            self.input_bias_r = self.input_bias[self.units: self.units * 2]\n            self.input_bias_h = self.input_bias[self.units * 2:]\n            # bias for hidden state - just for compatibility with CuDNN\n            if self.reset_after:\n                self.recurrent_bias_z = self.recurrent_bias[:self.units]\n                self.recurrent_bias_r = (\n                    self.recurrent_bias[self.units: self.units * 2])\n                self.recurrent_bias_h = self.recurrent_bias[self.units * 2:]\n        else:\n            self.input_bias_z = None\n            self.input_bias_r = None\n            self.input_bias_h = None\n            if self.reset_after:\n                self.recurrent_bias_z = None\n                self.recurrent_bias_r = None\n                self.recurrent_bias_h = None\n        self.built = True\n\n    def call(self, inputs, states, training=None):\n        h_tm1 = states[0]  # previous memory\n\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training,\n                count=3)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(h_tm1),\n                self.recurrent_dropout,\n                training=training,\n                count=3)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if self.implementation == 1:\n            if 0. < self.dropout < 1.:\n                inputs_z = inputs * dp_mask[0]\n                inputs_r = inputs * dp_mask[1]\n                inputs_h = inputs * dp_mask[2]\n            else:\n                inputs_z = inputs\n                inputs_r = inputs\n                inputs_h = inputs\n\n            x_z = K.dot(inputs_z, self.kernel_z)\n            x_r = K.dot(inputs_r, self.kernel_r)\n            x_h = K.dot(inputs_h, self.kernel_h)\n            if self.use_bias:\n                x_z = K.bias_add(x_z, self.input_bias_z)\n                x_r = K.bias_add(x_r, self.input_bias_r)\n                x_h = K.bias_add(x_h, self.input_bias_h)\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1_z = h_tm1 * rec_dp_mask[0]\n                h_tm1_r = h_tm1 * rec_dp_mask[1]\n                h_tm1_h = h_tm1 * rec_dp_mask[2]\n            else:\n                h_tm1_z = h_tm1\n                h_tm1_r = h_tm1\n                h_tm1_h = h_tm1\n\n            recurrent_z = K.dot(h_tm1_z, self.recurrent_kernel_z)\n            recurrent_r = K.dot(h_tm1_r, self.recurrent_kernel_r)\n            if self.reset_after and self.use_bias:\n                recurrent_z = K.bias_add(recurrent_z, self.recurrent_bias_z)\n                recurrent_r = K.bias_add(recurrent_r, self.recurrent_bias_r)\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            # reset gate applied after/before matrix multiplication\n            if self.reset_after:\n                recurrent_h = K.dot(h_tm1_h, self.recurrent_kernel_h)\n                if self.use_bias:\n                    recurrent_h = K.bias_add(recurrent_h, self.recurrent_bias_h)\n                recurrent_h = r * recurrent_h\n            else:\n                recurrent_h = K.dot(r * h_tm1_h, self.recurrent_kernel_h)\n\n            hh = self.activation(x_h + recurrent_h)\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n\n            # inputs projected by all gate matrices at once\n            matrix_x = K.dot(inputs, self.kernel)\n            if self.use_bias:\n                # biases: bias_z_i, bias_r_i, bias_h_i\n                matrix_x = K.bias_add(matrix_x, self.input_bias)\n            x_z = matrix_x[:, :self.units]\n            x_r = matrix_x[:, self.units: 2 * self.units]\n            x_h = matrix_x[:, 2 * self.units:]\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n\n            if self.reset_after:\n                # hidden state projected by all gate matrices at once\n                matrix_inner = K.dot(h_tm1, self.recurrent_kernel)\n                if self.use_bias:\n                    matrix_inner = K.bias_add(matrix_inner, self.recurrent_bias)\n            else:\n                # hidden state projected separately for update/reset and new\n                matrix_inner = K.dot(h_tm1,\n                                     self.recurrent_kernel[:, :2 * self.units])\n\n            recurrent_z = matrix_inner[:, :self.units]\n            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            if self.reset_after:\n                recurrent_h = r * matrix_inner[:, 2 * self.units:]\n            else:\n                recurrent_h = K.dot(r * h_tm1,\n                                    self.recurrent_kernel[:, 2 * self.units:])\n\n            hh = self.activation(x_h + recurrent_h)\n\n        # previous and candidate state mixed by update gate\n        h = z * h_tm1 + (1 - z) * hh\n\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n\n        return h, [h]\n\n    def get_config(self):\n        config = {\'units\': self.units,\n                  \'activation\': activations.serialize(self.activation),\n                  \'recurrent_activation\':\n                      activations.serialize(self.recurrent_activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout,\n                  \'implementation\': self.implementation,\n                  \'reset_after\': self.reset_after}\n        base_config = super(GRUCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass GRU(RNN):\n    """"""Gated Recurrent Unit - Cho et al. 2014.\n\n    There are two variants. The default one is based on 1406.1078v3 and\n    has reset gate applied to hidden state before matrix multiplication. The\n    other one is based on original 1406.1078v1 and has the order reversed.\n\n    The second variant is compatible with CuDNNGRU (GPU-only) and allows\n    inference on CPU. Thus it has separate biases for `kernel` and\n    `recurrent_kernel`. Use `\'reset_after\'=True` and\n    `recurrent_activation=\'sigmoid\'`.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        recurrent_activation: Activation function to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n            Default: sigmoid (`sigmoid`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n        implementation: Implementation mode, either 1 or 2.\n            Mode 1 will structure its operations as a larger number of\n            smaller dot products and additions, whereas mode 2 will\n            batch them into fewer, larger operations. These modes will\n            have different performance profiles on different hardware and\n            for different applications.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        unroll: Boolean (default False).\n            If True, the network will be unrolled,\n            else a symbolic loop will be used.\n            Unrolling can speed-up a RNN,\n            although it tends to be more memory-intensive.\n            Unrolling is only suitable for short sequences.\n        reset_after: GRU convention (whether to apply reset gate after or\n            before matrix multiplication). False = ""before"" (default),\n            True = ""after"" (CuDNN compatible).\n\n    # References\n        - [Learning Phrase Representations using RNN Encoder-Decoder for\n           Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n        - [On the Properties of Neural Machine Translation:\n           Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)\n        - [Empirical Evaluation of Gated Recurrent Neural Networks on\n           Sequence Modeling](https://arxiv.org/abs/1412.3555v1)\n        - [A Theoretically Grounded Application of Dropout in\n           Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n    """"""\n\n    @interfaces.legacy_recurrent_support\n    def __init__(self, units,\n                 activation=\'tanh\',\n                 recurrent_activation=\'sigmoid\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=2,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 reset_after=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn(\'`implementation=0` has been deprecated, \'\n                          \'and now defaults to `implementation=1`.\'\n                          \'Please update your layer call.\')\n        if K.backend() == \'theano\' and (dropout or recurrent_dropout):\n            warnings.warn(\n                \'RNN dropout is no longer supported with the Theano backend \'\n                \'due to technical limitations. \'\n                \'You can either set `dropout` and `recurrent_dropout` to 0, \'\n                \'or use the TensorFlow backend.\')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = GRUCell(units,\n                       activation=activation,\n                       recurrent_activation=recurrent_activation,\n                       use_bias=use_bias,\n                       kernel_initializer=kernel_initializer,\n                       recurrent_initializer=recurrent_initializer,\n                       bias_initializer=bias_initializer,\n                       kernel_regularizer=kernel_regularizer,\n                       recurrent_regularizer=recurrent_regularizer,\n                       bias_regularizer=bias_regularizer,\n                       kernel_constraint=kernel_constraint,\n                       recurrent_constraint=recurrent_constraint,\n                       bias_constraint=bias_constraint,\n                       dropout=dropout,\n                       recurrent_dropout=recurrent_dropout,\n                       implementation=implementation,\n                       reset_after=reset_after)\n        super(GRU, self).__init__(cell,\n                                  return_sequences=return_sequences,\n                                  return_state=return_state,\n                                  go_backwards=go_backwards,\n                                  stateful=stateful,\n                                  unroll=unroll,\n                                  **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(GRU, self).call(inputs,\n                                     mask=mask,\n                                     training=training,\n                                     initial_state=initial_state)\n\n    @property\n    def units(self):\n        return self.cell.units\n\n    @property\n    def activation(self):\n        return self.cell.activation\n\n    @property\n    def recurrent_activation(self):\n        return self.cell.recurrent_activation\n\n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\n    @property\n    def implementation(self):\n        return self.cell.implementation\n\n    @property\n    def reset_after(self):\n        return self.cell.reset_after\n\n    def get_config(self):\n        config = {\'units\': self.units,\n                  \'activation\': activations.serialize(self.activation),\n                  \'recurrent_activation\':\n                      activations.serialize(self.recurrent_activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout,\n                  \'implementation\': self.implementation,\n                  \'reset_after\': self.reset_after}\n        base_config = super(GRU, self).get_config()\n        del base_config[\'cell\']\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n        if \'implementation\' in config and config[\'implementation\'] == 0:\n            config[\'implementation\'] = 1\n        return cls(**config)\n\n\nclass LSTMCell(Layer):\n    """"""Cell class for the LSTM layer.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        recurrent_activation: Activation function to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n            Default: sigmoid (`sigmoid`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).x\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of the forget gate at initialization.\n            Setting it to true will also force `bias_initializer=""zeros""`.\n            This is recommended in [Jozefowicz et al. (2015)](\n            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n        implementation: Implementation mode, either 1 or 2.\n            Mode 1 will structure its operations as a larger number of\n            smaller dot products and additions, whereas mode 2 will\n            batch them into fewer, larger operations. These modes will\n            have different performance profiles on different hardware and\n            for different applications.\n    """"""\n\n    def __init__(self, units,\n                 activation=\'tanh\',\n                 recurrent_activation=\'sigmoid\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=2,\n                 **kwargs):\n        super(LSTMCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.state_size = (self.units, self.units)\n        self.output_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\n        if type(self.recurrent_initializer).__name__ == \'Identity\':\n            def recurrent_identity(shape, gain=1., dtype=None):\n                del dtype\n                return gain * np.concatenate(\n                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n\n            self.recurrent_initializer = recurrent_identity\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                      name=\'kernel\',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name=\'recurrent_kernel\',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if self.unit_forget_bias:\n                @K.eager\n                def bias_initializer(_, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])\n            else:\n                bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(shape=(self.units * 4,),\n                                        name=\'bias\',\n                                        initializer=bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = (\n            self.recurrent_kernel[:, self.units: self.units * 2])\n        self.recurrent_kernel_c = (\n            self.recurrent_kernel[:, self.units * 2: self.units * 3])\n        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.units]\n            self.bias_f = self.bias[self.units: self.units * 2]\n            self.bias_c = self.bias[self.units * 2: self.units * 3]\n            self.bias_o = self.bias[self.units * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True\n\n    def call(self, inputs, states, training=None):\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training,\n                count=4)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(states[0]),\n                self.recurrent_dropout,\n                training=training,\n                count=4)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        if self.implementation == 1:\n            if 0 < self.dropout < 1.:\n                inputs_i = inputs * dp_mask[0]\n                inputs_f = inputs * dp_mask[1]\n                inputs_c = inputs * dp_mask[2]\n                inputs_o = inputs * dp_mask[3]\n            else:\n                inputs_i = inputs\n                inputs_f = inputs\n                inputs_c = inputs\n                inputs_o = inputs\n            x_i = K.dot(inputs_i, self.kernel_i)\n            x_f = K.dot(inputs_f, self.kernel_f)\n            x_c = K.dot(inputs_c, self.kernel_c)\n            x_o = K.dot(inputs_o, self.kernel_o)\n            if self.use_bias:\n                x_i = K.bias_add(x_i, self.bias_i)\n                x_f = K.bias_add(x_f, self.bias_f)\n                x_c = K.bias_add(x_c, self.bias_c)\n                x_o = K.bias_add(x_o, self.bias_o)\n\n            if 0 < self.recurrent_dropout < 1.:\n                h_tm1_i = h_tm1 * rec_dp_mask[0]\n                h_tm1_f = h_tm1 * rec_dp_mask[1]\n                h_tm1_c = h_tm1 * rec_dp_mask[2]\n                h_tm1_o = h_tm1 * rec_dp_mask[3]\n            else:\n                h_tm1_i = h_tm1\n                h_tm1_f = h_tm1\n                h_tm1_c = h_tm1\n                h_tm1_o = h_tm1\n            i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n                                                      self.recurrent_kernel_i))\n            f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n                                                      self.recurrent_kernel_f))\n            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n                                                            self.recurrent_kernel_c))\n            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n                                                      self.recurrent_kernel_o))\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n            z = K.dot(inputs, self.kernel)\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n            z += K.dot(h_tm1, self.recurrent_kernel)\n            if self.use_bias:\n                z = K.bias_add(z, self.bias)\n\n            z0 = z[:, :self.units]\n            z1 = z[:, self.units: 2 * self.units]\n            z2 = z[:, 2 * self.units: 3 * self.units]\n            z3 = z[:, 3 * self.units:]\n\n            i = self.recurrent_activation(z0)\n            f = self.recurrent_activation(z1)\n            c = f * c_tm1 + i * self.activation(z2)\n            o = self.recurrent_activation(z3)\n\n        h = o * self.activation(c)\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n        return h, [h, c]\n\n    def get_config(self):\n        config = {\'units\': self.units,\n                  \'activation\': activations.serialize(self.activation),\n                  \'recurrent_activation\':\n                      activations.serialize(self.recurrent_activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'unit_forget_bias\': self.unit_forget_bias,\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout,\n                  \'implementation\': self.implementation}\n        base_config = super(LSTMCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass LSTM(RNN):\n    """"""Long Short-Term Memory layer - Hochreiter 1997.\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        recurrent_activation: Activation function to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n            Default: sigmoid (`sigmoid`).\n            If you pass `None`, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs.\n            (see [initializers](../initializers.md)).\n        recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights matrix,\n            used for the linear transformation of the recurrent state.\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of the forget gate at initialization.\n            Setting it to true will also force `bias_initializer=""zeros""`.\n            This is recommended in [Jozefowicz et al. (2015)](\n            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        recurrent_regularizer: Regularizer function applied to\n            the `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n        dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the inputs.\n        recurrent_dropout: Float between 0 and 1.\n            Fraction of the units to drop for\n            the linear transformation of the recurrent state.\n        implementation: Implementation mode, either 1 or 2.\n            Mode 1 will structure its operations as a larger number of\n            smaller dot products and additions, whereas mode 2 will\n            batch them into fewer, larger operations. These modes will\n            have different performance profiles on different hardware and\n            for different applications.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output. The returned elements of the\n            states list are the hidden state and the cell state, respectively.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        unroll: Boolean (default False).\n            If True, the network will be unrolled,\n            else a symbolic loop will be used.\n            Unrolling can speed-up a RNN,\n            although it tends to be more memory-intensive.\n            Unrolling is only suitable for short sequences.\n\n    # References\n        - [Long short-term memory](\n          http://www.bioinf.jku.at/publications/older/2604.pdf)\n        - [Learning to forget: Continual prediction with LSTM](\n          http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n        - [Supervised sequence labeling with recurrent neural networks](\n          http://www.cs.toronto.edu/~graves/preprint.pdf)\n        - [A Theoretically Grounded Application of Dropout in\n           Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n    """"""\n\n    @interfaces.legacy_recurrent_support\n    def __init__(self, units,\n                 activation=\'tanh\',\n                 recurrent_activation=\'sigmoid\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 recurrent_initializer=\'orthogonal\',\n                 bias_initializer=\'zeros\',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=2,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn(\'`implementation=0` has been deprecated, \'\n                          \'and now defaults to `implementation=1`.\'\n                          \'Please update your layer call.\')\n        if K.backend() == \'theano\' and (dropout or recurrent_dropout):\n            warnings.warn(\n                \'RNN dropout is no longer supported with the Theano backend \'\n                \'due to technical limitations. \'\n                \'You can either set `dropout` and `recurrent_dropout` to 0, \'\n                \'or use the TensorFlow backend.\')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = LSTMCell(units,\n                        activation=activation,\n                        recurrent_activation=recurrent_activation,\n                        use_bias=use_bias,\n                        kernel_initializer=kernel_initializer,\n                        recurrent_initializer=recurrent_initializer,\n                        unit_forget_bias=unit_forget_bias,\n                        bias_initializer=bias_initializer,\n                        kernel_regularizer=kernel_regularizer,\n                        recurrent_regularizer=recurrent_regularizer,\n                        bias_regularizer=bias_regularizer,\n                        kernel_constraint=kernel_constraint,\n                        recurrent_constraint=recurrent_constraint,\n                        bias_constraint=bias_constraint,\n                        dropout=dropout,\n                        recurrent_dropout=recurrent_dropout,\n                        implementation=implementation)\n        super(LSTM, self).__init__(cell,\n                                   return_sequences=return_sequences,\n                                   return_state=return_state,\n                                   go_backwards=go_backwards,\n                                   stateful=stateful,\n                                   unroll=unroll,\n                                   **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(LSTM, self).call(inputs,\n                                      mask=mask,\n                                      training=training,\n                                      initial_state=initial_state)\n\n    @property\n    def units(self):\n        return self.cell.units\n\n    @property\n    def activation(self):\n        return self.cell.activation\n\n    @property\n    def recurrent_activation(self):\n        return self.cell.recurrent_activation\n\n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\n    @property\n    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias\n\n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\n    @property\n    def implementation(self):\n        return self.cell.implementation\n\n    def get_config(self):\n        config = {\'units\': self.units,\n                  \'activation\': activations.serialize(self.activation),\n                  \'recurrent_activation\':\n                      activations.serialize(self.recurrent_activation),\n                  \'use_bias\': self.use_bias,\n                  \'kernel_initializer\':\n                      initializers.serialize(self.kernel_initializer),\n                  \'recurrent_initializer\':\n                      initializers.serialize(self.recurrent_initializer),\n                  \'bias_initializer\': initializers.serialize(self.bias_initializer),\n                  \'unit_forget_bias\': self.unit_forget_bias,\n                  \'kernel_regularizer\':\n                      regularizers.serialize(self.kernel_regularizer),\n                  \'recurrent_regularizer\':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n                  \'recurrent_constraint\':\n                      constraints.serialize(self.recurrent_constraint),\n                  \'bias_constraint\': constraints.serialize(self.bias_constraint),\n                  \'dropout\': self.dropout,\n                  \'recurrent_dropout\': self.recurrent_dropout,\n                  \'implementation\': self.implementation}\n        base_config = super(LSTM, self).get_config()\n        del base_config[\'cell\']\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n        if \'implementation\' in config and config[\'implementation\'] == 0:\n            config[\'implementation\'] = 1\n        return cls(**config)\n\n\ndef _generate_dropout_mask(ones, rate, training=None, count=1):\n    def dropped_inputs():\n        return K.dropout(ones, rate)\n\n    if count > 1:\n        return [K.in_train_phase(\n            dropped_inputs,\n            ones,\n            training=training) for _ in range(count)]\n    return K.in_train_phase(\n        dropped_inputs,\n        ones,\n        training=training)\n\n\ndef _standardize_args(inputs, initial_state, constants, num_constants):\n    """"""Standardize `__call__` to a single list of tensor inputs.\n\n    When running a model loaded from file, the input tensors\n    `initial_state` and `constants` can be passed to `RNN.__call__` as part\n    of `inputs` instead of by the dedicated keyword arguments. This method\n    makes sure the arguments are separated and that `initial_state` and\n    `constants` are lists of tensors (or None).\n\n    # Arguments\n        inputs: tensor or list/tuple of tensors\n        initial_state: tensor or list of tensors or None\n        constants: tensor or list of tensors or None\n\n    # Returns\n        inputs: tensor\n        initial_state: list of tensors or None\n        constants: list of tensors or None\n    """"""\n    if isinstance(inputs, list):\n        assert initial_state is None and constants is None\n        if num_constants is not None:\n            constants = inputs[-num_constants:]\n            inputs = inputs[:-num_constants]\n        if len(inputs) > 1:\n            initial_state = inputs[1:]\n        inputs = inputs[0]\n\n    def to_list_or_none(x):\n        if x is None or isinstance(x, list):\n            return x\n        if isinstance(x, tuple):\n            return list(x)\n        return [x]\n\n    initial_state = to_list_or_none(initial_state)\n    constants = to_list_or_none(constants)\n\n    return inputs, initial_state, constants\n'"
keras/layers/wrappers.py,0,"b'# -*- coding: utf-8 -*-\n""""""Layers that augment the functionality of a base layer.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nfrom ..engine.base_layer import Layer\nfrom ..engine.base_layer import disable_tracking\nfrom ..engine.base_layer import InputSpec\nfrom ..utils.generic_utils import has_arg\nfrom ..utils.generic_utils import object_list_uid\nfrom .. import backend as K\n\nfrom . import recurrent\n\n\nclass Wrapper(Layer):\n    """"""Abstract wrapper base class.\n\n    Wrappers take another layer and augment it in various ways.\n    Do not use this class as a layer, it is only an abstract base class.\n    Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n\n    # Arguments\n        layer: The layer to be wrapped.\n    """"""\n\n    @disable_tracking\n    def __init__(self, layer, **kwargs):\n        self.layer = layer\n        # Tracks mapping of Wrapper inputs to inner layer inputs. Useful when\n        # the inner layer has update ops that depend on its inputs (as opposed\n        # to the inputs to the Wrapper layer).\n        self._input_map = {}\n        super(Wrapper, self).__init__(**kwargs)\n\n    def build(self, input_shape=None):\n        self.built = True\n\n    @property\n    def activity_regularizer(self):\n        if hasattr(self.layer, \'activity_regularizer\'):\n            return self.layer.activity_regularizer\n        else:\n            return None\n\n    @property\n    def trainable(self):\n        return self.layer.trainable\n\n    @trainable.setter\n    def trainable(self, value):\n        self.layer.trainable = value\n\n    @property\n    def trainable_weights(self):\n        return self.layer.trainable_weights\n\n    @property\n    def non_trainable_weights(self):\n        return self.layer.non_trainable_weights\n\n    @property\n    def updates(self):\n        if hasattr(self.layer, \'updates\'):\n            return self.layer.updates\n        return []\n\n    def get_updates_for(self, inputs=None):\n        # If the wrapper modifies the inputs, use the modified inputs to\n        # get the updates from the inner layer.\n        inner_inputs = inputs\n        if inputs is not None:\n            uid = object_list_uid(inputs)\n            if uid in self._input_map:\n                inner_inputs = self._input_map[uid]\n\n        updates = self.layer.get_updates_for(inner_inputs)\n        updates += super(Wrapper, self).get_updates_for(inputs)\n        return updates\n\n    @property\n    def losses(self):\n        if hasattr(self.layer, \'losses\'):\n            return self.layer.losses\n        return []\n\n    def get_losses_for(self, inputs=None):\n        if inputs is None:\n            losses = self.layer.get_losses_for(None)\n            return losses + super(Wrapper, self).get_losses_for(None)\n        return super(Wrapper, self).get_losses_for(inputs)\n\n    def get_weights(self):\n        return self.layer.get_weights()\n\n    def set_weights(self, weights):\n        self.layer.set_weights(weights)\n\n    def get_config(self):\n        config = {\'layer\': {\'class_name\': self.layer.__class__.__name__,\n                            \'config\': self.layer.get_config()}}\n        base_config = super(Wrapper, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        layer = deserialize_layer(config.pop(\'layer\'),\n                                  custom_objects=custom_objects)\n        return cls(layer, **config)\n\n\nclass TimeDistributed(Wrapper):\n    """"""This wrapper applies a layer to every temporal slice of an input.\n\n    The input should be at least 3D, and the dimension of index one\n    will be considered to be the temporal dimension.\n\n    Consider a batch of 32 samples,\n    where each sample is a sequence of 10 vectors of 16 dimensions.\n    The batch input shape of the layer is then `(32, 10, 16)`,\n    and the `input_shape`, not including the samples dimension, is `(10, 16)`.\n\n    You can then use `TimeDistributed` to apply a `Dense` layer\n    to each of the 10 timesteps, independently:\n\n    ```python\n        # as the first layer in a model\n        model = Sequential()\n        model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n        # now model.output_shape == (None, 10, 8)\n    ```\n\n    The output will then have shape `(32, 10, 8)`.\n\n    In subsequent layers, there is no need for the `input_shape`:\n\n    ```python\n        model.add(TimeDistributed(Dense(32)))\n        # now model.output_shape == (None, 10, 32)\n    ```\n\n    The output will then have shape `(32, 10, 32)`.\n\n    `TimeDistributed` can be used with arbitrary layers, not just `Dense`,\n    for instance with a `Conv2D` layer:\n\n    ```python\n        model = Sequential()\n        model.add(TimeDistributed(Conv2D(64, (3, 3)),\n                                  input_shape=(10, 299, 299, 3)))\n    ```\n\n    # Arguments\n        layer: a layer instance.\n    """"""\n\n    def __init__(self, layer, **kwargs):\n        super(TimeDistributed, self).__init__(layer, **kwargs)\n        self.supports_masking = True\n\n    def _get_shape_tuple(self, init_tuple, tensor, start_idx, int_shape=None):\n        """"""Finds non-specific dimensions in the static shapes\n        and replaces them by the corresponding dynamic shapes of the tensor.\n\n        # Arguments\n            init_tuple: a tuple, the first part of the output shape\n            tensor: the tensor from which to get the (static and dynamic) shapes\n                as the last part of the output shape\n            start_idx: int, which indicate the first dimension to take from\n                the static shape of the tensor\n            int_shape: an alternative static shape to take as the last part\n                of the output shape\n\n        # Returns\n            The new int_shape with the first part from init_tuple\n            and the last part from either `int_shape` (if provided)\n            or K.int_shape(tensor), where every `None` is replaced by\n            the corresponding dimension from K.shape(tensor)\n        """"""\n        # replace all None in int_shape by K.shape\n        if int_shape is None:\n            int_shape = K.int_shape(tensor)[start_idx:]\n        if not any(not s for s in int_shape):\n            return init_tuple + int_shape\n        tensor_shape = K.shape(tensor)\n        int_shape = list(int_shape)\n        for i, s in enumerate(int_shape):\n            if not s:\n                int_shape[i] = tensor_shape[start_idx + i]\n        return init_tuple + tuple(int_shape)\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 3\n        self.input_spec = InputSpec(shape=input_shape)\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        if not self.layer.built:\n            self.layer.build(child_input_shape)\n            self.layer.built = True\n        super(TimeDistributed, self).build()\n\n    def compute_output_shape(self, input_shape):\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n        timesteps = input_shape[1]\n        return (child_output_shape[0], timesteps) + child_output_shape[1:]\n\n    def call(self, inputs, training=None, mask=None):\n        kwargs = {}\n        if has_arg(self.layer.call, \'training\'):\n            kwargs[\'training\'] = training\n        uses_learning_phase = False\n\n        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n            # batch size matters, use rnn-based implementation\n            def step(x, _):\n                global uses_learning_phase\n                output = self.layer.call(x, **kwargs)\n                if hasattr(output, \'_uses_learning_phase\'):\n                    uses_learning_phase = (output._uses_learning_phase or\n                                           uses_learning_phase)\n                return output, []\n\n            _, outputs, _ = K.rnn(step, inputs,\n                                  initial_states=[],\n                                  input_length=input_shape[1],\n                                  unroll=False)\n            y = outputs\n        else:\n            # No batch size specified, therefore the layer will be able\n            # to process batches of any size.\n            # We can go with reshape-based implementation for performance.\n            input_length = input_shape[1]\n            if not input_length:\n                input_length = K.shape(inputs)[1]\n            inner_input_shape = self._get_shape_tuple((-1,), inputs, 2)\n            # Shape: (num_samples * timesteps, ...). And track the\n            # transformation in self._input_map.\n            input_uid = object_list_uid(inputs)\n            inputs = K.reshape(inputs, inner_input_shape)\n            self._input_map[input_uid] = inputs\n            # (num_samples * timesteps, ...)\n            if has_arg(self.layer.call, \'mask\') and mask is not None:\n                inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n                kwargs[\'mask\'] = K.reshape(mask, inner_mask_shape)\n            y = self.layer.call(inputs, **kwargs)\n            if hasattr(y, \'_uses_learning_phase\'):\n                uses_learning_phase = y._uses_learning_phase\n            # Shape: (num_samples, timesteps, ...)\n            output_shape = self.compute_output_shape(input_shape)\n            output_shape = self._get_shape_tuple(\n                (-1, input_length), y, 1, output_shape[2:])\n            y = K.reshape(y, output_shape)\n\n        # Apply activity regularizer if any:\n        if (hasattr(self.layer, \'activity_regularizer\') and\n           self.layer.activity_regularizer is not None):\n            regularization_loss = self.layer.activity_regularizer(y)\n            self.add_loss(regularization_loss, inputs)\n\n        if uses_learning_phase:\n            y._uses_learning_phase = True\n        return y\n\n    def compute_mask(self, inputs, mask=None):\n        """"""Computes an output mask tensor for Embedding layer\n        based on the inputs, mask, and the inner layer.\n\n        If batch size is specified:\n        Simply return the input `mask`. (An rnn-based implementation with\n        more than one rnn inputs is required but not supported in Keras yet.)\n\n        Otherwise we call `compute_mask` of the inner layer at each time step.\n        If the output mask at each time step is not `None`:\n        (E.g., inner layer is Masking or RNN)\n        Concatenate all of them and return the concatenation.\n        If the output mask at each time step is `None` and\n        the input mask is not `None`:\n        (E.g., inner layer is Dense)\n        Reduce the input_mask to 2 dimensions and return it.\n        Otherwise (both the output mask and the input mask are `None`):\n        (E.g., `mask` is not used at all)\n        Return `None`.\n\n        # Arguments\n            inputs: Tensor\n            mask: Tensor\n        # Returns\n            None or a tensor\n        """"""\n        # cases need to call the layer.compute_mask when input_mask is None:\n        # Masking layer and Embedding layer with mask_zero\n        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n            # batch size matters, we currently do not handle mask explicitly\n            return mask\n        inner_mask = mask\n        if inner_mask is not None:\n            inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n            inner_mask = K.reshape(inner_mask, inner_mask_shape)\n        input_uid = object_list_uid(inputs)\n        inner_inputs = self._input_map[input_uid]\n        output_mask = self.layer.compute_mask(inner_inputs, inner_mask)\n        if output_mask is None:\n            if mask is None:\n                return None\n            # input_mask is not None, and output_mask is None:\n            # we should return a not-None mask\n            output_mask = mask\n            for _ in range(2, len(K.int_shape(mask))):\n                output_mask = K.any(output_mask, axis=-1)\n        else:\n            # output_mask is not None. We need to reshape it\n            input_length = input_shape[1]\n            if not input_length:\n                input_length = K.shape(inputs)[1]\n            output_mask_int_shape = K.int_shape(output_mask)\n            if output_mask_int_shape is None:\n                # if the output_mask does not have a static shape,\n                # its shape must be the same as mask\'s\n                if mask is not None:\n                    output_mask_int_shape = K.int_shape(mask)\n                else:\n                    output_mask_int_shape = K.compute_output_shape(input_shape)[:-1]\n            output_mask_shape = self._get_shape_tuple(\n                (-1, input_length), output_mask, 1, output_mask_int_shape[1:])\n            output_mask = K.reshape(output_mask, output_mask_shape)\n        return output_mask\n\n\nclass Bidirectional(Wrapper):\n    """"""Bidirectional wrapper for RNNs.\n\n    # Arguments\n        layer: `Recurrent` instance.\n        merge_mode: Mode by which outputs of the\n            forward and backward RNNs will be combined.\n            One of {\'sum\', \'mul\', \'concat\', \'ave\', None}.\n            If None, the outputs will not be combined,\n            they will be returned as a list.\n        weights: Initial weights to load in the Bidirectional model\n\n    # Raises\n        ValueError: In case of invalid `merge_mode` argument.\n\n    # Examples\n\n    ```python\n        model = Sequential()\n        model.add(Bidirectional(LSTM(10, return_sequences=True),\n                                input_shape=(5, 10)))\n        model.add(Bidirectional(LSTM(10)))\n        model.add(Dense(5))\n        model.add(Activation(\'softmax\'))\n        model.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\')\n    ```\n    """"""\n\n    def __init__(self, layer, merge_mode=\'concat\', weights=None, **kwargs):\n        if merge_mode not in [\'sum\', \'mul\', \'ave\', \'concat\', None]:\n            raise ValueError(\'Invalid merge mode. \'\n                             \'Merge mode should be one of \'\n                             \'{""sum"", ""mul"", ""ave"", ""concat"", None}\')\n        self._set_sublayers(layer)\n        self.merge_mode = merge_mode\n        if weights:\n            nw = len(weights)\n            self.forward_layer.initial_weights = weights[:nw // 2]\n            self.backward_layer.initial_weights = weights[nw // 2:]\n        self.stateful = layer.stateful\n        self.return_sequences = layer.return_sequences\n        self.return_state = layer.return_state\n        self.supports_masking = True\n        self._trainable = True\n        super(Bidirectional, self).__init__(layer, **kwargs)\n        self.input_spec = layer.input_spec\n        self._num_constants = None\n\n    @disable_tracking\n    def _set_sublayers(self, layer):\n        # This is isolated in its own method in order to use\n        # the disable_tracking decorator without altering the\n        # visible signature of __init__.\n        self.forward_layer = copy.copy(layer)\n        config = layer.get_config()\n        config[\'go_backwards\'] = not config[\'go_backwards\']\n        self.backward_layer = layer.__class__.from_config(config)\n        self.forward_layer.name = \'forward_\' + self.forward_layer.name\n        self.backward_layer.name = \'backward_\' + self.backward_layer.name\n\n    @property\n    def trainable(self):\n        return self._trainable\n\n    @trainable.setter\n    def trainable(self, value):\n        self._trainable = value\n        self.forward_layer.trainable = value\n        self.backward_layer.trainable = value\n\n    def get_weights(self):\n        return self.forward_layer.get_weights() + self.backward_layer.get_weights()\n\n    def set_weights(self, weights):\n        nw = len(weights)\n        self.forward_layer.set_weights(weights[:nw // 2])\n        self.backward_layer.set_weights(weights[nw // 2:])\n\n    def compute_output_shape(self, input_shape):\n        output_shape = self.forward_layer.compute_output_shape(input_shape)\n        if self.return_state:\n            state_shape = output_shape[1:]\n            output_shape = output_shape[0]\n\n        if self.merge_mode == \'concat\':\n            output_shape = list(output_shape)\n            output_shape[-1] *= 2\n            output_shape = tuple(output_shape)\n        elif self.merge_mode is None:\n            output_shape = [output_shape, copy.copy(output_shape)]\n\n        if self.return_state:\n            if self.merge_mode is None:\n                return output_shape + state_shape + copy.copy(state_shape)\n            return [output_shape] + state_shape + copy.copy(state_shape)\n        return output_shape\n\n    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = recurrent._standardize_args(\n            inputs, initial_state, constants, self._num_constants)\n\n        if initial_state is None and constants is None:\n            return super(Bidirectional, self).__call__(inputs, **kwargs)\n\n        # Applies the same workaround as in `RNN.__call__`\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            # Check if `initial_state` can be splitted into half\n            num_states = len(initial_state)\n            if num_states % 2 > 0:\n                raise ValueError(\n                    \'When passing `initial_state` to a Bidirectional RNN, \'\n                    \'the state should be a list containing the states of \'\n                    \'the underlying RNNs. \'\n                    \'Found: \' + str(initial_state))\n\n            kwargs[\'initial_state\'] = initial_state\n            additional_inputs += initial_state\n            state_specs = [InputSpec(shape=K.int_shape(state))\n                           for state in initial_state]\n            self.forward_layer.state_spec = state_specs[:num_states // 2]\n            self.backward_layer.state_spec = state_specs[num_states // 2:]\n            additional_specs += state_specs\n        if constants is not None:\n            kwargs[\'constants\'] = constants\n            additional_inputs += constants\n            constants_spec = [InputSpec(shape=K.int_shape(constant))\n                              for constant in constants]\n            self.forward_layer.constants_spec = constants_spec\n            self.backward_layer.constants_spec = constants_spec\n            additional_specs += constants_spec\n\n            self._num_constants = len(constants)\n            self.forward_layer._num_constants = self._num_constants\n            self.backward_layer._num_constants = self._num_constants\n\n        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != is_keras_tensor:\n                raise ValueError(\'The initial state of a Bidirectional\'\n                                 \' layer cannot be specified with a mix of\'\n                                 \' Keras tensors and non-Keras tensors\'\n                                 \' (a ""Keras tensor"" is a tensor that was\'\n                                 \' returned by a Keras layer, or by `Input`)\')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            if \'initial_state\' in kwargs:\n                kwargs.pop(\'initial_state\')\n            if \'constants\' in kwargs:\n                kwargs.pop(\'constants\')\n            output = super(Bidirectional, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(Bidirectional, self).__call__(inputs, **kwargs)\n\n    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        kwargs = {}\n        if has_arg(self.layer.call, \'training\'):\n            kwargs[\'training\'] = training\n        if has_arg(self.layer.call, \'mask\'):\n            kwargs[\'mask\'] = mask\n        if has_arg(self.layer.call, \'constants\'):\n            if self._num_constants is not None and constants is None:\n                    constants = inputs[-self._num_constants:]\n                    inputs = inputs[:-self._num_constants]\n            kwargs[\'constants\'] = constants\n        if has_arg(self.layer.call, \'initial_state\'):\n            if isinstance(inputs, list) and len(inputs) > 1:\n                if initial_state is not None:\n                    raise ValueError(\'Layer was passed initial state \' +\n                                     \'via both kwarg and inputs list)\')\n                initial_state = inputs[1:]\n                inputs = [inputs[0]]\n            if initial_state is None:\n                forward_state = None\n                backward_state = None\n            else:\n                pivot = len(initial_state) // 2\n                forward_state = initial_state[:pivot]\n                backward_state = initial_state[pivot:]\n            y = self.forward_layer.call(inputs,\n                                        initial_state=forward_state, **kwargs)\n            y_rev = self.backward_layer.call(inputs,\n                                             initial_state=backward_state, **kwargs)\n        else:\n            if isinstance(inputs, list) and len(inputs) > 1 or initial_state:\n                raise ValueError(\'Layer does not accept initial_state argument.\')\n            y = self.forward_layer.call(inputs, **kwargs)\n            y_rev = self.backward_layer.call(inputs, **kwargs)\n\n        if self.return_state:\n            states = y[1:] + y_rev[1:]\n            y = y[0]\n            y_rev = y_rev[0]\n\n        if self.return_sequences:\n            y_rev = K.reverse(y_rev, 1)\n        if self.merge_mode == \'concat\':\n            output = K.concatenate([y, y_rev])\n        elif self.merge_mode == \'sum\':\n            output = y + y_rev\n        elif self.merge_mode == \'ave\':\n            output = (y + y_rev) / 2\n        elif self.merge_mode == \'mul\':\n            output = y * y_rev\n        elif self.merge_mode is None:\n            output = [y, y_rev]\n        else:\n            raise ValueError(\'Unrecognized value for argument \'\n                             \'merge_mode: %s\' % (self.merge_mode))\n\n        # Properly set learning phase\n        if (getattr(y, \'_uses_learning_phase\', False) or\n           getattr(y_rev, \'_uses_learning_phase\', False)):\n            if self.merge_mode is None:\n                for out in output:\n                    out._uses_learning_phase = True\n            else:\n                output._uses_learning_phase = True\n\n        if self.return_state:\n            if self.merge_mode is None:\n                return output + states\n            return [output] + states\n        return output\n\n    def reset_states(self):\n        self.forward_layer.reset_states()\n        self.backward_layer.reset_states()\n\n    def build(self, input_shape):\n        with K.name_scope(self.forward_layer.name):\n            self.forward_layer.build(input_shape)\n        with K.name_scope(self.backward_layer.name):\n            self.backward_layer.build(input_shape)\n        self.built = True\n\n    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        if self.return_sequences:\n            if not self.merge_mode:\n                output_mask = [mask, mask]\n            else:\n                output_mask = mask\n        else:\n            output_mask = [None, None] if not self.merge_mode else None\n\n        if self.return_state:\n            states = self.forward_layer.states\n            state_mask = [None for _ in states]\n            if isinstance(output_mask, list):\n                return output_mask + state_mask * 2\n            return [output_mask] + state_mask * 2\n\n        return output_mask\n\n    @property\n    def trainable_weights(self):\n        if hasattr(self.forward_layer, \'trainable_weights\'):\n            return (self.forward_layer.trainable_weights +\n                    self.backward_layer.trainable_weights)\n        return []\n\n    @property\n    def non_trainable_weights(self):\n        if hasattr(self.forward_layer, \'non_trainable_weights\'):\n            return (self.forward_layer.non_trainable_weights +\n                    self.backward_layer.non_trainable_weights)\n        return []\n\n    @property\n    def updates(self):\n        if hasattr(self.forward_layer, \'updates\'):\n            return self.forward_layer.updates + self.backward_layer.updates\n        return []\n\n    def get_updates_for(self, inputs=None):\n        forward_updates = self.forward_layer.get_updates_for(inputs)\n        backward_updates = self.backward_layer.get_updates_for(inputs)\n        return (super(Wrapper, self).get_updates_for(inputs) +\n                forward_updates + backward_updates)\n\n    @property\n    def losses(self):\n        if hasattr(self.forward_layer, \'losses\'):\n            return self.forward_layer.losses + self.backward_layer.losses\n        return []\n\n    def get_losses_for(self, inputs=None):\n        forward_losses = self.forward_layer.get_losses_for(inputs)\n        backward_losses = self.backward_layer.get_losses_for(inputs)\n        return (super(Wrapper, self).get_losses_for(inputs) +\n                forward_losses + backward_losses)\n\n    @property\n    def constraints(self):\n        constraints = {}\n        if hasattr(self.forward_layer, \'constraints\'):\n            constraints.update(self.forward_layer.constraints)\n            constraints.update(self.backward_layer.constraints)\n        return constraints\n\n    def get_config(self):\n        config = {\'merge_mode\': self.merge_mode}\n        if self._num_constants is not None:\n            config[\'num_constants\'] = self._num_constants\n\n        base_config = super(Bidirectional, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        rnn_layer = deserialize_layer(config.pop(\'layer\'),\n                                      custom_objects=custom_objects)\n        num_constants = config.pop(\'num_constants\', None)\n        layer = cls(rnn_layer, **config)\n        layer._num_constants = num_constants\n        return layer\n'"
keras/legacy/__init__.py,0,b''
keras/legacy/interfaces.py,0,"b'""""""Interface converters for Keras 1 support in Keras 2.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport warnings\nimport functools\nimport numpy as np\n\n\ndef generate_legacy_interface(allowed_positional_args=None,\n                              conversions=None,\n                              preprocessor=None,\n                              value_conversions=None,\n                              object_type=\'class\'):\n    if allowed_positional_args is None:\n        check_positional_args = False\n    else:\n        check_positional_args = True\n    allowed_positional_args = allowed_positional_args or []\n    conversions = conversions or []\n    value_conversions = value_conversions or []\n\n    def legacy_support(func):\n        @six.wraps(func)\n        def wrapper(*args, **kwargs):\n            if object_type == \'class\':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError(\'`\' + object_name +\n                                    \'` can accept only \' +\n                                    str(len(allowed_positional_args)) +\n                                    \' positional arguments \' +\n                                    str(tuple(allowed_positional_args)) +\n                                    \', but you passed the following \'\n                                    \'positional arguments: \' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = \'`\' + object_name + \'(\'\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += \'""\' + value + \'""\'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = \'array\'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + \'...\'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += \', \'\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + \'=\'\n                    if isinstance(value, six.string_types):\n                        signature += \'""\' + value + \'""\'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = \'array\'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + \'...\'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += \', \'\n                signature += \')`\'\n                warnings.warn(\'Update your `\' + object_name + \'` call to the \' +\n                              \'Keras 2 API: \' + signature, stacklevel=2)\n            return func(*args, **kwargs)\n        wrapper._original_function = func\n        return wrapper\n    return legacy_support\n\n\ngenerate_legacy_method_interface = functools.partial(generate_legacy_interface,\n                                                     object_type=\'method\')\n\n\ndef raise_duplicate_arg_error(old_arg, new_arg):\n    raise TypeError(\'For the `\' + new_arg + \'` argument, \'\n                    \'the layer received both \'\n                    \'the legacy keyword argument \'\n                    \'`\' + old_arg + \'` and the Keras 2 keyword argument \'\n                    \'`\' + new_arg + \'`. Stick to the latter!\')\n\n\nlegacy_dense_support = generate_legacy_interface(\n    allowed_positional_args=[\'units\'],\n    conversions=[(\'output_dim\', \'units\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'W_constraint\', \'kernel_constraint\'),\n                 (\'b_constraint\', \'bias_constraint\'),\n                 (\'bias\', \'use_bias\')])\n\nlegacy_dropout_support = generate_legacy_interface(\n    allowed_positional_args=[\'rate\', \'noise_shape\', \'seed\'],\n    conversions=[(\'p\', \'rate\')])\n\n\ndef embedding_kwargs_preprocessor(args, kwargs):\n    converted = []\n    if \'dropout\' in kwargs:\n        kwargs.pop(\'dropout\')\n        warnings.warn(\'The `dropout` argument is no longer support in `Embedding`. \'\n                      \'You can apply a `keras.layers.SpatialDropout1D` layer \'\n                      \'right after the `Embedding` layer to get the same behavior.\',\n                      stacklevel=3)\n    return args, kwargs, converted\n\nlegacy_embedding_support = generate_legacy_interface(\n    allowed_positional_args=[\'input_dim\', \'output_dim\'],\n    conversions=[(\'init\', \'embeddings_initializer\'),\n                 (\'W_regularizer\', \'embeddings_regularizer\'),\n                 (\'W_constraint\', \'embeddings_constraint\')],\n    preprocessor=embedding_kwargs_preprocessor)\n\nlegacy_pooling1d_support = generate_legacy_interface(\n    allowed_positional_args=[\'pool_size\', \'strides\', \'padding\'],\n    conversions=[(\'pool_length\', \'pool_size\'),\n                 (\'stride\', \'strides\'),\n                 (\'border_mode\', \'padding\')])\n\nlegacy_prelu_support = generate_legacy_interface(\n    allowed_positional_args=[\'alpha_initializer\'],\n    conversions=[(\'init\', \'alpha_initializer\')])\n\n\nlegacy_gaussiannoise_support = generate_legacy_interface(\n    allowed_positional_args=[\'stddev\'],\n    conversions=[(\'sigma\', \'stddev\')])\n\n\ndef recurrent_args_preprocessor(args, kwargs):\n    converted = []\n    if \'forget_bias_init\' in kwargs:\n        if kwargs[\'forget_bias_init\'] == \'one\':\n            kwargs.pop(\'forget_bias_init\')\n            kwargs[\'unit_forget_bias\'] = True\n            converted.append((\'forget_bias_init\', \'unit_forget_bias\'))\n        else:\n            kwargs.pop(\'forget_bias_init\')\n            warnings.warn(\'The `forget_bias_init` argument \'\n                          \'has been ignored. Use `unit_forget_bias=True` \'\n                          \'instead to initialize with ones.\', stacklevel=3)\n    if \'input_dim\' in kwargs:\n        input_length = kwargs.pop(\'input_length\', None)\n        input_dim = kwargs.pop(\'input_dim\')\n        input_shape = (input_length, input_dim)\n        kwargs[\'input_shape\'] = input_shape\n        converted.append((\'input_dim\', \'input_shape\'))\n        warnings.warn(\'The `input_dim` and `input_length` arguments \'\n                      \'in recurrent layers are deprecated. \'\n                      \'Use `input_shape` instead.\', stacklevel=3)\n    return args, kwargs, converted\n\nlegacy_recurrent_support = generate_legacy_interface(\n    allowed_positional_args=[\'units\'],\n    conversions=[(\'output_dim\', \'units\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'inner_init\', \'recurrent_initializer\'),\n                 (\'inner_activation\', \'recurrent_activation\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'U_regularizer\', \'recurrent_regularizer\'),\n                 (\'dropout_W\', \'dropout\'),\n                 (\'dropout_U\', \'recurrent_dropout\'),\n                 (\'consume_less\', \'implementation\')],\n    value_conversions={\'consume_less\': {\'cpu\': 0,\n                                        \'mem\': 1,\n                                        \'gpu\': 2}},\n    preprocessor=recurrent_args_preprocessor)\n\nlegacy_gaussiandropout_support = generate_legacy_interface(\n    allowed_positional_args=[\'rate\'],\n    conversions=[(\'p\', \'rate\')])\n\nlegacy_pooling2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'pool_size\', \'strides\', \'padding\'],\n    conversions=[(\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_pooling3d_support = generate_legacy_interface(\n    allowed_positional_args=[\'pool_size\', \'strides\', \'padding\'],\n    conversions=[(\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_global_pooling_support = generate_legacy_interface(\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_upsampling1d_support = generate_legacy_interface(\n    allowed_positional_args=[\'size\'],\n    conversions=[(\'length\', \'size\')])\n\nlegacy_upsampling2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'size\'],\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_upsampling3d_support = generate_legacy_interface(\n    allowed_positional_args=[\'size\'],\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\n\ndef conv1d_args_preprocessor(args, kwargs):\n    converted = []\n    if \'input_dim\' in kwargs:\n        if \'input_length\' in kwargs:\n            length = kwargs.pop(\'input_length\')\n        else:\n            length = None\n        input_shape = (length, kwargs.pop(\'input_dim\'))\n        kwargs[\'input_shape\'] = input_shape\n        converted.append((\'input_shape\', \'input_dim\'))\n    return args, kwargs, converted\n\nlegacy_conv1d_support = generate_legacy_interface(\n    allowed_positional_args=[\'filters\', \'kernel_size\'],\n    conversions=[(\'nb_filter\', \'filters\'),\n                 (\'filter_length\', \'kernel_size\'),\n                 (\'subsample_length\', \'strides\'),\n                 (\'border_mode\', \'padding\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'W_constraint\', \'kernel_constraint\'),\n                 (\'b_constraint\', \'bias_constraint\'),\n                 (\'bias\', \'use_bias\')],\n    preprocessor=conv1d_args_preprocessor)\n\n\ndef conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 4:\n        raise TypeError(\'Layer can receive at most 3 positional arguments.\')\n    elif len(args) == 4:\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = [\'padding\', \'strides\', \'data_format\']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        \'It seems that you are using the Keras 2 \'\n                        \'and you are passing both `kernel_size` and `strides` \'\n                        \'as integer positional arguments. For safety reasons, \'\n                        \'this is disallowed. Pass `strides` \'\n                        \'as a keyword argument instead.\')\n            kernel_size = (args[2], args[3])\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'nb_row/nb_col\'))\n    elif len(args) == 3 and isinstance(args[2], int):\n        if \'nb_col\' in kwargs:\n            kernel_size = (args[2], kwargs.pop(\'nb_col\'))\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'nb_row/nb_col\'))\n    elif len(args) == 2:\n        if \'nb_row\' in kwargs and \'nb_col\' in kwargs:\n            kernel_size = (kwargs.pop(\'nb_row\'), kwargs.pop(\'nb_col\'))\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'nb_row/nb_col\'))\n    elif len(args) == 1:\n        if \'nb_row\' in kwargs and \'nb_col\' in kwargs:\n            kernel_size = (kwargs.pop(\'nb_row\'), kwargs.pop(\'nb_col\'))\n            kwargs[\'kernel_size\'] = kernel_size\n            converted.append((\'kernel_size\', \'nb_row/nb_col\'))\n    return args, kwargs, converted\n\nlegacy_conv2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'filters\', \'kernel_size\'],\n    conversions=[(\'nb_filter\', \'filters\'),\n                 (\'subsample\', \'strides\'),\n                 (\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'W_constraint\', \'kernel_constraint\'),\n                 (\'b_constraint\', \'bias_constraint\'),\n                 (\'bias\', \'use_bias\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}},\n    preprocessor=conv2d_args_preprocessor)\n\n\ndef separable_conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if \'init\' in kwargs:\n        init = kwargs.pop(\'init\')\n        kwargs[\'depthwise_initializer\'] = init\n        kwargs[\'pointwise_initializer\'] = init\n        converted.append((\'init\', \'depthwise_initializer/pointwise_initializer\'))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted\n\nlegacy_separable_conv2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'filters\', \'kernel_size\'],\n    conversions=[(\'nb_filter\', \'filters\'),\n                 (\'subsample\', \'strides\'),\n                 (\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'b_constraint\', \'bias_constraint\'),\n                 (\'bias\', \'use_bias\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}},\n    preprocessor=separable_conv2d_args_preprocessor)\n\n\ndef deconv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) == 5:\n        if isinstance(args[4], tuple):\n            args = args[:-1]\n            converted.append((\'output_shape\', None))\n    if \'output_shape\' in kwargs:\n        kwargs.pop(\'output_shape\')\n        converted.append((\'output_shape\', None))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted\n\nlegacy_deconv2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'filters\', \'kernel_size\'],\n    conversions=[(\'nb_filter\', \'filters\'),\n                 (\'subsample\', \'strides\'),\n                 (\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'W_constraint\', \'kernel_constraint\'),\n                 (\'b_constraint\', \'bias_constraint\'),\n                 (\'bias\', \'use_bias\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}},\n    preprocessor=deconv2d_args_preprocessor)\n\n\ndef conv3d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 5:\n        raise TypeError(\'Layer can receive at most 4 positional arguments.\')\n    if len(args) == 5:\n        if all([isinstance(x, int) for x in args[2:5]]):\n            kernel_size = (args[2], args[3], args[4])\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'kernel_dim*\'))\n    elif len(args) == 4 and isinstance(args[3], int):\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = [\'padding\', \'strides\', \'data_format\']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        \'It seems that you are using the Keras 2 \'\n                        \'and you are passing both `kernel_size` and `strides` \'\n                        \'as integer positional arguments. For safety reasons, \'\n                        \'this is disallowed. Pass `strides` \'\n                        \'as a keyword argument instead.\')\n        if \'kernel_dim3\' in kwargs:\n            kernel_size = (args[2], args[3], kwargs.pop(\'kernel_dim3\'))\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'kernel_dim*\'))\n    elif len(args) == 3:\n        if all([x in kwargs for x in [\'kernel_dim2\', \'kernel_dim3\']]):\n            kernel_size = (args[2],\n                           kwargs.pop(\'kernel_dim2\'),\n                           kwargs.pop(\'kernel_dim3\'))\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'kernel_dim*\'))\n    elif len(args) == 2:\n        if all([x in kwargs for x in [\'kernel_dim1\', \'kernel_dim2\', \'kernel_dim3\']]):\n            kernel_size = (kwargs.pop(\'kernel_dim1\'),\n                           kwargs.pop(\'kernel_dim2\'),\n                           kwargs.pop(\'kernel_dim3\'))\n            args = [args[0], args[1], kernel_size]\n            converted.append((\'kernel_size\', \'kernel_dim*\'))\n    elif len(args) == 1:\n        if all([x in kwargs for x in [\'kernel_dim1\', \'kernel_dim2\', \'kernel_dim3\']]):\n            kernel_size = (kwargs.pop(\'kernel_dim1\'),\n                           kwargs.pop(\'kernel_dim2\'),\n                           kwargs.pop(\'kernel_dim3\'))\n            kwargs[\'kernel_size\'] = kernel_size\n            converted.append((\'kernel_size\', \'nb_row/nb_col\'))\n    return args, kwargs, converted\n\nlegacy_conv3d_support = generate_legacy_interface(\n    allowed_positional_args=[\'filters\', \'kernel_size\'],\n    conversions=[(\'nb_filter\', \'filters\'),\n                 (\'subsample\', \'strides\'),\n                 (\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'W_constraint\', \'kernel_constraint\'),\n                 (\'b_constraint\', \'bias_constraint\'),\n                 (\'bias\', \'use_bias\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}},\n    preprocessor=conv3d_args_preprocessor)\n\n\ndef batchnorm_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 1:\n        raise TypeError(\'The `BatchNormalization` layer \'\n                        \'does not accept positional arguments. \'\n                        \'Use keyword arguments instead.\')\n    if \'mode\' in kwargs:\n        value = kwargs.pop(\'mode\')\n        if value != 0:\n            raise TypeError(\'The `mode` argument of `BatchNormalization` \'\n                            \'no longer exists. `mode=1` and `mode=2` \'\n                            \'are no longer supported.\')\n        converted.append((\'mode\', None))\n    return args, kwargs, converted\n\n\ndef convlstm2d_args_preprocessor(args, kwargs):\n    converted = []\n    if \'forget_bias_init\' in kwargs:\n        value = kwargs.pop(\'forget_bias_init\')\n        if value == \'one\':\n            kwargs[\'unit_forget_bias\'] = True\n            converted.append((\'forget_bias_init\', \'unit_forget_bias\'))\n        else:\n            warnings.warn(\'The `forget_bias_init` argument \'\n                          \'has been ignored. Use `unit_forget_bias=True` \'\n                          \'instead to initialize with ones.\', stacklevel=3)\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted\n\nlegacy_convlstm2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'filters\', \'kernel_size\'],\n    conversions=[(\'nb_filter\', \'filters\'),\n                 (\'subsample\', \'strides\'),\n                 (\'border_mode\', \'padding\'),\n                 (\'dim_ordering\', \'data_format\'),\n                 (\'init\', \'kernel_initializer\'),\n                 (\'inner_init\', \'recurrent_initializer\'),\n                 (\'W_regularizer\', \'kernel_regularizer\'),\n                 (\'U_regularizer\', \'recurrent_regularizer\'),\n                 (\'b_regularizer\', \'bias_regularizer\'),\n                 (\'inner_activation\', \'recurrent_activation\'),\n                 (\'dropout_W\', \'dropout\'),\n                 (\'dropout_U\', \'recurrent_dropout\'),\n                 (\'bias\', \'use_bias\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}},\n    preprocessor=convlstm2d_args_preprocessor)\n\nlegacy_batchnorm_support = generate_legacy_interface(\n    allowed_positional_args=[],\n    conversions=[(\'beta_init\', \'beta_initializer\'),\n                 (\'gamma_init\', \'gamma_initializer\')],\n    preprocessor=batchnorm_args_preprocessor)\n\n\ndef zeropadding2d_args_preprocessor(args, kwargs):\n    converted = []\n    if \'padding\' in kwargs and isinstance(kwargs[\'padding\'], dict):\n        if set(kwargs[\'padding\'].keys()) <= {\'top_pad\', \'bottom_pad\',\n                                             \'left_pad\', \'right_pad\'}:\n            top_pad = kwargs[\'padding\'].get(\'top_pad\', 0)\n            bottom_pad = kwargs[\'padding\'].get(\'bottom_pad\', 0)\n            left_pad = kwargs[\'padding\'].get(\'left_pad\', 0)\n            right_pad = kwargs[\'padding\'].get(\'right_pad\', 0)\n            kwargs[\'padding\'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n            warnings.warn(\'The `padding` argument in the Keras 2 API no longer\'\n                          \'accepts dict types. You can now input argument as: \'\n                          \'`padding=(top_pad, bottom_pad, left_pad, right_pad)`.\',\n                          stacklevel=3)\n    elif len(args) == 2 and isinstance(args[1], dict):\n        if set(args[1].keys()) <= {\'top_pad\', \'bottom_pad\',\n                                   \'left_pad\', \'right_pad\'}:\n            top_pad = args[1].get(\'top_pad\', 0)\n            bottom_pad = args[1].get(\'bottom_pad\', 0)\n            left_pad = args[1].get(\'left_pad\', 0)\n            right_pad = args[1].get(\'right_pad\', 0)\n            args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n            warnings.warn(\'The `padding` argument in the Keras 2 API no longer\'\n                          \'accepts dict types. You can now input argument as: \'\n                          \'`padding=((top_pad, bottom_pad), (left_pad, right_pad))`\',\n                          stacklevel=3)\n    return args, kwargs, converted\n\nlegacy_zeropadding2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'padding\'],\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}},\n    preprocessor=zeropadding2d_args_preprocessor)\n\nlegacy_zeropadding3d_support = generate_legacy_interface(\n    allowed_positional_args=[\'padding\'],\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_cropping2d_support = generate_legacy_interface(\n    allowed_positional_args=[\'cropping\'],\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_cropping3d_support = generate_legacy_interface(\n    allowed_positional_args=[\'cropping\'],\n    conversions=[(\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_spatialdropout1d_support = generate_legacy_interface(\n    allowed_positional_args=[\'rate\'],\n    conversions=[(\'p\', \'rate\')])\n\nlegacy_spatialdropoutNd_support = generate_legacy_interface(\n    allowed_positional_args=[\'rate\'],\n    conversions=[(\'p\', \'rate\'),\n                 (\'dim_ordering\', \'data_format\')],\n    value_conversions={\'dim_ordering\': {\'tf\': \'channels_last\',\n                                        \'th\': \'channels_first\',\n                                        \'default\': None}})\n\nlegacy_lambda_support = generate_legacy_interface(\n    allowed_positional_args=[\'function\', \'output_shape\'])\n\n\n# Model methods\n\ndef generator_methods_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) < 3:\n        if \'samples_per_epoch\' in kwargs:\n            samples_per_epoch = kwargs.pop(\'samples_per_epoch\')\n            if len(args) > 1:\n                generator = args[1]\n            else:\n                generator = kwargs[\'generator\']\n            if hasattr(generator, \'batch_size\'):\n                kwargs[\'steps_per_epoch\'] = samples_per_epoch // generator.batch_size\n            else:\n                kwargs[\'steps_per_epoch\'] = samples_per_epoch\n            converted.append((\'samples_per_epoch\', \'steps_per_epoch\'))\n\n    keras1_args = {\'samples_per_epoch\', \'val_samples\',\n                   \'nb_epoch\', \'nb_val_samples\', \'nb_worker\'}\n    if keras1_args.intersection(kwargs.keys()):\n        warnings.warn(\'The semantics of the Keras 2 argument \'\n                      \'`steps_per_epoch` is not the same as the \'\n                      \'Keras 1 argument `samples_per_epoch`. \'\n                      \'`steps_per_epoch` is the number of batches \'\n                      \'to draw from the generator at each epoch. \'\n                      \'Basically steps_per_epoch = samples_per_epoch/batch_size. \'\n                      \'Similarly `nb_val_samples`->`validation_steps` and \'\n                      \'`val_samples`->`steps` arguments have changed. \'\n                      \'Update your method calls accordingly.\', stacklevel=3)\n\n    return args, kwargs, converted\n\n\nlegacy_generator_methods_support = generate_legacy_method_interface(\n    allowed_positional_args=[\'generator\', \'steps_per_epoch\', \'epochs\'],\n    conversions=[(\'samples_per_epoch\', \'steps_per_epoch\'),\n                 (\'val_samples\', \'steps\'),\n                 (\'nb_epoch\', \'epochs\'),\n                 (\'nb_val_samples\', \'validation_steps\'),\n                 (\'nb_worker\', \'workers\'),\n                 (\'pickle_safe\', \'use_multiprocessing\'),\n                 (\'max_q_size\', \'max_queue_size\')],\n    preprocessor=generator_methods_args_preprocessor)\n\n\nlegacy_model_constructor_support = generate_legacy_interface(\n    allowed_positional_args=None,\n    conversions=[(\'input\', \'inputs\'),\n                 (\'output\', \'outputs\')])\n\nlegacy_input_support = generate_legacy_interface(\n    allowed_positional_args=None,\n    conversions=[(\'input_dtype\', \'dtype\')])\n\n\ndef add_weight_args_preprocessing(args, kwargs):\n    if len(args) > 1:\n        if isinstance(args[1], (tuple, list)):\n            kwargs[\'shape\'] = args[1]\n            args = (args[0],) + args[2:]\n            if len(args) > 1:\n                if isinstance(args[1], six.string_types):\n                    kwargs[\'name\'] = args[1]\n                    args = (args[0],) + args[2:]\n    return args, kwargs, []\n\n\nlegacy_add_weight_support = generate_legacy_interface(\n    allowed_positional_args=[\'name\', \'shape\'],\n    preprocessor=add_weight_args_preprocessing)\n\n\ndef get_updates_arg_preprocessing(args, kwargs):\n    # Old interface: (params, constraints, loss)\n    # New interface: (loss, params)\n    if len(args) > 4:\n        raise TypeError(\'`get_update` call received more arguments \'\n                        \'than expected.\')\n    elif len(args) == 4:\n        # Assuming old interface.\n        opt, params, _, loss = args\n        kwargs[\'loss\'] = loss\n        kwargs[\'params\'] = params\n        return [opt], kwargs, []\n    elif len(args) == 3:\n        if isinstance(args[1], (list, tuple)):\n            assert isinstance(args[2], dict)\n            assert \'loss\' in kwargs\n            opt, params, _ = args\n            kwargs[\'params\'] = params\n            return [opt], kwargs, []\n    return args, kwargs, []\n\nlegacy_get_updates_support = generate_legacy_interface(\n    allowed_positional_args=None,\n    conversions=[],\n    preprocessor=get_updates_arg_preprocessing)\n'"
keras/legacy/layers.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport warnings\n\nfrom ..engine import Layer, InputSpec\nfrom .. import backend as K\nfrom ..utils import conv_utils\nfrom ..utils.generic_utils import to_list\nfrom .. import regularizers\nfrom .. import constraints\nfrom .. import activations\nfrom .. import initializers\n\n\nclass MaxoutDense(Layer):\n    """"""A dense maxout layer.\n    A `MaxoutDense` layer takes the element-wise maximum of\n    `nb_feature` `Dense(input_dim, output_dim)` linear layers.\n    This allows the layer to learn a convex,\n    piecewise linear activation function over the inputs.\n    Note that this is a *linear* layer;\n    if you wish to apply activation function\n    (you shouldn\'t need to --they are universal function approximators),\n    an `Activation` layer must be added after.\n    # Arguments\n        output_dim: int > 0.\n        nb_feature: number of Dense layers to use internally.\n        init: name of initialization function for the weights of the layer\n            (see [initializations](../initializations.md)),\n            or alternatively, Theano function to use for weights\n            initialization. This parameter is only relevant\n            if you don\'t pass a `weights` argument.\n        weights: list of Numpy arrays to set as initial weights.\n            The list should have 2 elements, of shape `(input_dim, output_dim)`\n            and (output_dim,) for weights and biases respectively.\n        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n            (eg. L1 or L2 regularization), applied to the main weights matrix.\n        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n            applied to the bias.\n        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n            applied to the network output.\n        W_constraint: instance of the [constraints](../constraints.md) module\n            (eg. maxnorm, nonneg), applied to the main weights matrix.\n        b_constraint: instance of the [constraints](../constraints.md) module,\n            applied to the bias.\n        bias: whether to include a bias\n            (i.e. make the layer affine rather than linear).\n        input_dim: dimensionality of the input (integer). This argument\n            (or alternatively, the keyword argument `input_shape`)\n            is required when using this layer as the first layer in a model.\n    # Input shape\n        2D tensor with shape: `(nb_samples, input_dim)`.\n    # Output shape\n        2D tensor with shape: `(nb_samples, output_dim)`.\n    # References\n        - [Maxout Networks](http://arxiv.org/abs/1302.4389)\n    """"""\n\n    def __init__(self, output_dim,\n                 nb_feature=4,\n                 init=\'glorot_uniform\',\n                 weights=None,\n                 W_regularizer=None,\n                 b_regularizer=None,\n                 activity_regularizer=None,\n                 W_constraint=None,\n                 b_constraint=None,\n                 bias=True,\n                 input_dim=None,\n                 **kwargs):\n        warnings.warn(\'The `MaxoutDense` layer is deprecated \'\n                      \'and will be removed after 06/2017.\')\n        self.output_dim = output_dim\n        self.nb_feature = nb_feature\n        self.init = initializers.get(init)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim = input_dim\n        if self.input_dim:\n            kwargs[\'input_shape\'] = (self.input_dim,)\n        super(MaxoutDense, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(),\n                                    shape=(None, input_dim))\n\n        self.W = self.add_weight(shape=(self.nb_feature, input_dim, self.output_dim),\n                                 initializer=self.init,\n                                 name=\'W\',\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight(shape=(self.nb_feature, self.output_dim,),\n                                     initializer=\'zero\',\n                                     name=\'b\',\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) == 2\n        return (input_shape[0], self.output_dim)\n\n    def call(self, x):\n        # no activation, this layer is only linear.\n        output = K.dot(x, self.W)\n        if self.bias:\n            output += self.b\n        output = K.max(output, axis=1)\n        return output\n\n    def get_config(self):\n        config = {\'output_dim\': self.output_dim,\n                  \'init\': initializers.serialize(self.init),\n                  \'nb_feature\': self.nb_feature,\n                  \'W_regularizer\': regularizers.serialize(self.W_regularizer),\n                  \'b_regularizer\': regularizers.serialize(self.b_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'W_constraint\': constraints.serialize(self.W_constraint),\n                  \'b_constraint\': constraints.serialize(self.b_constraint),\n                  \'bias\': self.bias,\n                  \'input_dim\': self.input_dim}\n        base_config = super(MaxoutDense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Highway(Layer):\n    """"""Densely connected highway network.\n    Highway layers are a natural extension of LSTMs to feedforward networks.\n    # Arguments\n        init: name of initialization function for the weights of the layer\n            (see [initializations](../initializations.md)),\n            or alternatively, Theano function to use for weights\n            initialization. This parameter is only relevant\n            if you don\'t pass a `weights` argument.\n        activation: name of activation function to use\n            (see [activations](../activations.md)),\n            or alternatively, elementwise Theano function.\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: a(x) = x).\n        weights: list of Numpy arrays to set as initial weights.\n            The list should have 2 elements, of shape `(input_dim, output_dim)`\n            and (output_dim,) for weights and biases respectively.\n        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n            (eg. L1 or L2 regularization), applied to the main weights matrix.\n        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n            applied to the bias.\n        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n            applied to the network output.\n        W_constraint: instance of the [constraints](../constraints.md) module\n            (eg. maxnorm, nonneg), applied to the main weights matrix.\n        b_constraint: instance of the [constraints](../constraints.md) module,\n            applied to the bias.\n        bias: whether to include a bias\n            (i.e. make the layer affine rather than linear).\n        input_dim: dimensionality of the input (integer). This argument\n            (or alternatively, the keyword argument `input_shape`)\n            is required when using this layer as the first layer in a model.\n    # Input shape\n        2D tensor with shape: `(nb_samples, input_dim)`.\n    # Output shape\n        2D tensor with shape: `(nb_samples, input_dim)`.\n    # References\n        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)\n    """"""\n\n    def __init__(self,\n                 init=\'glorot_uniform\',\n                 activation=None,\n                 weights=None,\n                 W_regularizer=None,\n                 b_regularizer=None,\n                 activity_regularizer=None,\n                 W_constraint=None,\n                 b_constraint=None,\n                 bias=True,\n                 input_dim=None,\n                 **kwargs):\n        warnings.warn(\'The `Highway` layer is deprecated \'\n                      \'and will be removed after 06/2017.\')\n        if \'transform_bias\' in kwargs:\n            kwargs.pop(\'transform_bias\')\n            warnings.warn(\'`transform_bias` argument is deprecated and \'\n                          \'has been removed.\')\n        self.init = initializers.get(init)\n        self.activation = activations.get(activation)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim = input_dim\n        if self.input_dim:\n            kwargs[\'input_shape\'] = (self.input_dim,)\n        super(Highway, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(),\n                                    shape=(None, input_dim))\n\n        self.W = self.add_weight(shape=(input_dim, input_dim),\n                                 initializer=self.init,\n                                 name=\'W\',\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.W_carry = self.add_weight(shape=(input_dim, input_dim),\n                                       initializer=self.init,\n                                       name=\'W_carry\')\n        if self.bias:\n            self.b = self.add_weight(shape=(input_dim,),\n                                     initializer=\'zero\',\n                                     name=\'b\',\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n            self.b_carry = self.add_weight(shape=(input_dim,),\n                                           initializer=\'one\',\n                                           name=\'b_carry\')\n        else:\n            self.b_carry = None\n\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True\n\n    def call(self, x):\n        y = K.dot(x, self.W_carry)\n        if self.bias:\n            y += self.b_carry\n        transform_weight = activations.sigmoid(y)\n        y = K.dot(x, self.W)\n        if self.bias:\n            y += self.b\n        act = self.activation(y)\n        act *= transform_weight\n        output = act + (1 - transform_weight) * x\n        return output\n\n    def get_config(self):\n        config = {\'init\': initializers.serialize(self.init),\n                  \'activation\': activations.serialize(self.activation),\n                  \'W_regularizer\': regularizers.serialize(self.W_regularizer),\n                  \'b_regularizer\': regularizers.serialize(self.b_regularizer),\n                  \'activity_regularizer\':\n                      regularizers.serialize(self.activity_regularizer),\n                  \'W_constraint\': constraints.serialize(self.W_constraint),\n                  \'b_constraint\': constraints.serialize(self.b_constraint),\n                  \'bias\': self.bias,\n                  \'input_dim\': self.input_dim}\n        base_config = super(Highway, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\ndef AtrousConvolution1D(*args, **kwargs):\n    from ..layers import Conv1D\n    if \'atrous_rate\' in kwargs:\n        rate = kwargs.pop(\'atrous_rate\')\n    else:\n        rate = 1\n    kwargs[\'dilation_rate\'] = rate\n    warnings.warn(\'The `AtrousConvolution1D` layer \'\n                  \' has been deprecated. Use instead \'\n                  \'the `Conv1D` layer with the `dilation_rate` \'\n                  \'argument.\')\n    return Conv1D(*args, **kwargs)\n\n\ndef AtrousConvolution2D(*args, **kwargs):\n    from ..layers import Conv2D\n    if \'atrous_rate\' in kwargs:\n        rate = kwargs.pop(\'atrous_rate\')\n    else:\n        rate = 1\n    kwargs[\'dilation_rate\'] = rate\n    warnings.warn(\'The `AtrousConvolution2D` layer \'\n                  \' has been deprecated. Use instead \'\n                  \'the `Conv2D` layer with the `dilation_rate` \'\n                  \'argument.\')\n    return Conv2D(*args, **kwargs)\n\n\nclass Recurrent(Layer):\n    """"""Abstract base class for recurrent layers.\n\n    Do not use in a model -- it\'s not a valid layer!\n    Use its children classes `LSTM`, `GRU` and `SimpleRNN` instead.\n    All recurrent layers (`LSTM`, `GRU`, `SimpleRNN`) also\n    follow the specifications of this class and accept\n    the keyword arguments listed below.\n\n    # Example\n\n    ```python\n        # as the first layer in a Sequential model\n        model = Sequential()\n        model.add(LSTM(32, input_shape=(10, 64)))\n        # now model.output_shape == (None, 32)\n        # note: `None` is the batch dimension.\n        # for subsequent layers, no need to specify the input size:\n        model.add(LSTM(16))\n        # to stack recurrent layers, you must use return_sequences=True\n        # on any recurrent layer that feeds into another recurrent layer.\n        # note that you only need to specify the input size on the first layer.\n        model = Sequential()\n        model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n        model.add(LSTM(32, return_sequences=True))\n        model.add(LSTM(10))\n    ```\n\n    # Arguments\n        weights: list of Numpy arrays to set as initial weights.\n            The list should have 3 elements, of shapes:\n            `[(input_dim, output_dim), (output_dim, output_dim), (output_dim,)]`.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        unroll: Boolean (default False).\n            If True, the network will be unrolled,\n            else a symbolic loop will be used.\n            Unrolling can speed-up a RNN,\n            although it tends to be more memory-intensive.\n            Unrolling is only suitable for short sequences.\n        implementation: one of {0, 1, or 2}.\n            If set to 0, the RNN will use\n            an implementation that uses fewer, larger matrix products,\n            thus running faster on CPU but consuming more memory.\n            If set to 1, the RNN will use more matrix products,\n            but smaller ones, thus running slower\n            (may actually be faster on GPU) while consuming less memory.\n            If set to 2 (LSTM/GRU only),\n            the RNN will combine the input gate,\n            the forget gate and the output gate into a single matrix,\n            enabling more time-efficient parallelization on the GPU.\n            Note: RNN dropout must be shared for all gates,\n            resulting in a slightly reduced regularization.\n        input_dim: dimensionality of the input (integer).\n            This argument (or alternatively, the keyword argument `input_shape`)\n            is required when using this layer as the first layer in a model.\n        input_length: Length of input sequences, to be specified\n            when it is constant.\n            This argument is required if you are going to connect\n            `Flatten` then `Dense` layers upstream\n            (without it, the shape of the dense outputs cannot be computed).\n            Note that if the recurrent layer is not the first layer\n            in your model, you would need to specify the input length\n            at the level of the first layer\n            (e.g. via the `input_shape` argument)\n\n    # Input shapes\n        3D tensor with shape `(batch_size, timesteps, input_dim)`,\n        (Optional) 2D tensors with shape `(batch_size, output_dim)`.\n\n    # Output shape\n        - if `return_state`: a list of tensors. The first tensor is\n            the output. The remaining tensors are the last states,\n            each with shape `(batch_size, units)`.\n        - if `return_sequences`: 3D tensor with shape\n            `(batch_size, timesteps, units)`.\n        - else, 2D tensor with shape `(batch_size, units)`.\n\n    # Masking\n        This layer supports masking for input data with a variable number\n        of timesteps. To introduce masks to your data,\n        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n        set to `True`.\n\n    # Note on using statefulness in RNNs\n        You can set RNN layers to be \'stateful\', which means that the states\n        computed for the samples in one batch will be reused as initial states\n        for the samples in the next batch. This assumes a one-to-one mapping\n        between samples in different successive batches.\n        To enable statefulness:\n            - specify `stateful=True` in the layer constructor.\n            - specify a fixed batch size for your model, by passing\n                if sequential model:\n                  `batch_input_shape=(...)` to the first layer in your model.\n                else for functional model with 1 or more Input layers:\n                  `batch_shape=(...)` to all the first layers in your model.\n                This is the expected shape of your inputs\n                *including the batch size*.\n                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n            - specify `shuffle=False` when calling fit().\n        To reset the states of your model, call `.reset_states()` on either\n        a specific layer, or on your entire model.\n\n    # Note on specifying the initial state of RNNs\n        You can specify the initial state of RNN layers symbolically by\n        calling them with the keyword argument `initial_state`. The value of\n        `initial_state` should be a tensor or list of tensors representing\n        the initial state of the RNN layer.\n        You can specify the initial state of RNN layers numerically by\n        calling `reset_states` with the keyword argument `states`. The value of\n        `states` should be a numpy array or list of numpy arrays representing\n        the initial state of the RNN layer.\n    """"""\n\n    def __init__(self, return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 implementation=0,\n                 **kwargs):\n        super(Recurrent, self).__init__(**kwargs)\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n\n        self.stateful = stateful\n        self.unroll = unroll\n        self.implementation = implementation\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self.dropout = 0\n        self.recurrent_dropout = 0\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        if self.return_sequences:\n            output_shape = (input_shape[0], input_shape[1], self.units)\n        else:\n            output_shape = (input_shape[0], self.units)\n\n        if self.return_state:\n            state_shape = [(input_shape[0], self.units) for _ in self.states]\n            return [output_shape] + state_shape\n        else:\n            return output_shape\n\n    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask\n\n    def step(self, inputs, states):\n        raise NotImplementedError\n\n    def get_constants(self, inputs, training=None):\n        return []\n\n    def get_initial_state(self, inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        # (samples, output_dim)\n        initial_state = K.tile(initial_state, [1, self.units])\n        initial_state = [initial_state for _ in range(len(self.states))]\n        return initial_state\n\n    def preprocess_input(self, inputs, training=None):\n        return inputs\n\n    def __call__(self, inputs, initial_state=None, **kwargs):\n\n        # If there are multiple inputs, then\n        # they should be the main input and `initial_state`\n        # e.g. when loading model from file\n        if (isinstance(inputs, (list, tuple))\n                and len(inputs) > 1 and initial_state is None):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is None:\n            return super(Recurrent, self).__call__(inputs, **kwargs)\n\n        initial_state = to_list(initial_state, allow_tuple=True)\n\n        is_keras_tensor = hasattr(initial_state[0], \'_keras_history\')\n        for tensor in initial_state:\n            if hasattr(tensor, \'_keras_history\') != is_keras_tensor:\n                raise ValueError(\'The initial state of an RNN layer cannot be\'\n                                 \' specified with a mix of Keras tensors and\'\n                                 \' non-Keras tensors\')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state\n            input_spec = self.input_spec\n            state_spec = self.state_spec\n            input_spec = to_list(input_spec)\n            state_spec = to_list(state_spec)\n            self.input_spec = input_spec + state_spec\n\n            # Compute the full inputs, including state\n            inputs = [inputs] + list(initial_state)\n\n            # Perform the call\n            output = super(Recurrent, self).__call__(inputs, **kwargs)\n\n            # Restore original input spec\n            self.input_spec = input_spec\n            return output\n        else:\n            kwargs[\'initial_state\'] = initial_state\n            return super(Recurrent, self).__call__(inputs, **kwargs)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError(\'Layer has \' + str(len(self.states)) +\n                             \' states but was passed \' +\n                             str(len(initial_state)) +\n                             \' initial states.\')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps in [None, 1]:\n            raise ValueError(\'Cannot unroll a RNN if the \'\n                             \'time dimension is undefined or equal to 1. \\n\'\n                             \'- If using a Sequential model, \'\n                             \'specify the time dimension by passing \'\n                             \'an `input_shape` or `batch_input_shape` \'\n                             \'argument to your first layer. If your \'\n                             \'first layer is an Embedding, you can \'\n                             \'also use the `input_length` argument.\\n\'\n                             \'- If using the functional API, specify \'\n                             \'the time dimension by passing a `shape` \'\n                             \'or `batch_shape` argument to your Input layer.\')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n        last_output, outputs, states = K.rnn(self.step,\n                                             preprocessed_input,\n                                             initial_state,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             constants=constants,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout + self.recurrent_dropout:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        if self.return_state:\n            states = to_list(states, allow_tuple=True)\n            return [output] + states\n        else:\n            return output\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError(\'Layer must be stateful.\')\n        batch_size = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise ValueError(\'If a RNN is stateful, it needs to know \'\n                             \'its batch size. Specify the batch size \'\n                             \'of your input tensors: \\n\'\n                             \'- If using a Sequential model, \'\n                             \'specify the batch size by passing \'\n                             \'a `batch_input_shape` \'\n                             \'argument to your first layer.\\n\'\n                             \'- If using the functional API, specify \'\n                             \'the time dimension by passing a \'\n                             \'`batch_shape` argument to your Input layer.\')\n        # initialize state if None\n        if self.states[0] is None:\n            self.states = [K.zeros((batch_size, self.units))\n                           for _ in self.states]\n        elif states is None:\n            for state in self.states:\n                K.set_value(state, np.zeros((batch_size, self.units)))\n        else:\n            states = to_list(states, allow_tuple=True)\n            if len(states) != len(self.states):\n                raise ValueError(\'Layer \' + self.name + \' expects \' +\n                                 str(len(self.states)) + \' states, \'\n                                 \'but it received \' + str(len(states)) +\n                                 \' state values. Input received: \' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if value.shape != (batch_size, self.units):\n                    raise ValueError(\'State \' + str(index) +\n                                     \' is incompatible with layer \' +\n                                     self.name + \': expected shape=\' +\n                                     str((batch_size, self.units)) +\n                                     \', found shape=\' + str(value.shape))\n                K.set_value(state, value)\n\n    def get_config(self):\n        config = {\'return_sequences\': self.return_sequences,\n                  \'return_state\': self.return_state,\n                  \'go_backwards\': self.go_backwards,\n                  \'stateful\': self.stateful,\n                  \'unroll\': self.unroll,\n                  \'implementation\': self.implementation}\n        base_config = super(Recurrent, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass ConvRecurrent2D(Recurrent):\n    """"""Abstract base class for convolutional recurrent layers.\n\n    Do not use in a model -- it\'s not a functional layer!\n\n    # Arguments\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number output of filters in the convolution).\n        kernel_size: An integer or tuple/list of n integers, specifying the\n            dimensions of the convolution window.\n        strides: An integer or tuple/list of n integers,\n            specifying the strides of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, time, ..., channels)`\n            while `channels_first` corresponds to\n            inputs with shape `(batch, time, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: An integer or tuple/list of n integers, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n\n    # Input shape\n        5D tensor with shape `(num_samples, timesteps, channels, rows, cols)`.\n\n    # Output shape\n        - if `return_sequences`: 5D tensor with shape\n            `(num_samples, timesteps, channels, rows, cols)`.\n        - else, 4D tensor with shape `(num_samples, channels, rows, cols)`.\n\n    # Masking\n        This layer supports masking for input data with a variable number\n        of timesteps. To introduce masks to your data,\n        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n        set to `True`.\n        **Note:** for the time being, masking is only supported with Theano.\n\n    # Note on using statefulness in RNNs\n        You can set RNN layers to be \'stateful\', which means that the states\n        computed for the samples in one batch will be reused as initial states\n        for the samples in the next batch.\n        This assumes a one-to-one mapping between\n        samples in different successive batches.\n\n        To enable statefulness:\n            - specify `stateful=True` in the layer constructor.\n            - specify a fixed batch size for your model, by passing\n                a `batch_input_size=(...)` to the first layer in your model.\n                This is the expected shape of your inputs *including the batch\n                size*.\n                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n\n        To reset the states of your model, call `.reset_states()` on either\n        a specific layer, or on your entire model.\n    """"""\n\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 return_sequences=False,\n                 go_backwards=False,\n                 stateful=False,\n                 **kwargs):\n        super(ConvRecurrent2D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 2, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2,\n                                                        \'dilation_rate\')\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.input_spec = [InputSpec(ndim=5)]\n        self.state_spec = None\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        if self.data_format == \'channels_first\':\n            rows = input_shape[3]\n            cols = input_shape[4]\n        elif self.data_format == \'channels_last\':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        rows = conv_utils.conv_output_length(rows,\n                                             self.kernel_size[0],\n                                             padding=self.padding,\n                                             stride=self.strides[0],\n                                             dilation=self.dilation_rate[0])\n        cols = conv_utils.conv_output_length(cols,\n                                             self.kernel_size[1],\n                                             padding=self.padding,\n                                             stride=self.strides[1],\n                                             dilation=self.dilation_rate[1])\n        if self.return_sequences:\n            if self.data_format == \'channels_first\':\n                output_shape = (input_shape[0], input_shape[1],\n                                self.filters, rows, cols)\n            elif self.data_format == \'channels_last\':\n                output_shape = (input_shape[0], input_shape[1],\n                                rows, cols, self.filters)\n        else:\n            if self.data_format == \'channels_first\':\n                output_shape = (input_shape[0], self.filters, rows, cols)\n            elif self.data_format == \'channels_last\':\n                output_shape = (input_shape[0], rows, cols, self.filters)\n\n        if self.return_state:\n            if self.data_format == \'channels_first\':\n                state_shape = (input_shape[0], self.filters, rows, cols)\n            elif self.data_format == \'channels_last\':\n                state_shape = (input_shape[0], rows, cols, self.filters)\n            output_shape = [output_shape, state_shape, state_shape]\n\n        return output_shape\n\n    def get_config(self):\n        config = {\'filters\': self.filters,\n                  \'kernel_size\': self.kernel_size,\n                  \'strides\': self.strides,\n                  \'padding\': self.padding,\n                  \'data_format\': self.data_format,\n                  \'dilation_rate\': self.dilation_rate,\n                  \'return_sequences\': self.return_sequences,\n                  \'go_backwards\': self.go_backwards,\n                  \'stateful\': self.stateful}\n        base_config = super(ConvRecurrent2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n'"
keras/preprocessing/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend\nfrom .. import utils\n\nimport keras_preprocessing\n\nfrom . import image\nfrom . import sequence\nfrom . import text\n'
keras/preprocessing/image.py,0,"b'""""""Utilities for real-time data augmentation on image data.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .. import backend\nfrom .. import utils\nfrom ..utils import generic_utils\n\nfrom keras_preprocessing import image\n\nrandom_rotation = image.random_rotation\nrandom_shift = image.random_shift\nrandom_shear = image.random_shear\nrandom_zoom = image.random_zoom\napply_channel_shift = image.apply_channel_shift\nrandom_channel_shift = image.random_channel_shift\napply_brightness_shift = image.apply_brightness_shift\nrandom_brightness = image.random_brightness\napply_affine_transform = image.apply_affine_transform\nload_img = image.load_img\n\n\ndef array_to_img(x, data_format=None, scale=True, dtype=None):\n    """"""Converts a 3D Numpy array to a PIL Image instance.\n\n    # Arguments\n        x: Input Numpy array.\n        data_format: Image data format.\n            either ""channels_first"" or ""channels_last"".\n            If omitted (`None`), then `backend.image_data_format()` is used.\n        scale: Whether to rescale image values\n            to be within `[0, 255]`.\n        dtype: Dtype to use.\n            If omitted (`None`), then `backend.floatx()` or `float32` are used.\n\n    # Returns\n        A PIL Image instance.\n\n    # Raises\n        ImportError: if PIL is not available.\n        ValueError: if invalid `x` or `data_format` is passed.\n    """"""\n    if data_format is None:\n        data_format = backend.image_data_format()\n    if dtype is None:\n        dtype = backend.floatx()\n    return image.array_to_img(x,\n                              data_format=data_format,\n                              scale=scale,\n                              dtype=dtype)\n\n\ndef img_to_array(img, data_format=None, dtype=None):\n    """"""Converts a PIL Image instance to a Numpy array.\n\n    # Arguments\n        img: PIL Image instance.\n        data_format: Image data format, either ""channels_first"" or ""channels_last"".\n            If omitted (`None`), then `backend.image_data_format()` is used.\n        dtype: Dtype to use for the returned array.\n            If omitted (`None`), then `backend.floatx()` or `float32` are used.\n\n    # Returns\n        A 3D Numpy array.\n\n    # Raises\n        ValueError: if invalid `img` or `data_format` is passed.\n    """"""\n    if data_format is None:\n        data_format = backend.image_data_format()\n    if dtype is None:\n        dtype = backend.floatx()\n    return image.img_to_array(img, data_format=data_format, dtype=dtype)\n\n\ndef save_img(path,\n             x,\n             data_format=None,\n             file_format=None,\n             scale=True, **kwargs):\n    """"""Saves an image stored as a Numpy array to a path or file object.\n\n    # Arguments\n        path: Path or file object.\n        x: Numpy array.\n        data_format: Image data format,\n            either ""channels_first"" or ""channels_last"".\n            If omitted (`None`), then `backend.image_data_format()` is used.\n        file_format: Optional file format override. If omitted, the\n            format to use is determined from the filename extension.\n            If a file object was used instead of a filename, this\n            parameter should always be used.\n        scale: Whether to rescale image values to be within `[0, 255]`.\n        **kwargs: Additional keyword arguments passed to `PIL.Image.save()`.\n    """"""\n    if data_format is None:\n        data_format = backend.image_data_format()\n    return image.save_img(path,\n                          x,\n                          data_format=data_format,\n                          file_format=file_format,\n                          scale=scale, **kwargs)\n\n\nclass Iterator(image.Iterator, utils.Sequence):\n    pass\n\n\nclass DirectoryIterator(image.DirectoryIterator, Iterator):\n    __doc__ = image.DirectoryIterator.__doc__\n\n    def __init__(self, directory, image_data_generator,\n                 target_size=(256, 256),\n                 color_mode=\'rgb\',\n                 classes=None,\n                 class_mode=\'categorical\',\n                 batch_size=32,\n                 shuffle=True,\n                 seed=None,\n                 data_format=None,\n                 save_to_dir=None,\n                 save_prefix=\'\',\n                 save_format=\'png\',\n                 follow_links=False,\n                 subset=None,\n                 interpolation=\'nearest\',\n                 dtype=None):\n        if data_format is None:\n            data_format = backend.image_data_format()\n        if dtype is None:\n            dtype = backend.floatx()\n        super(DirectoryIterator, self).__init__(\n            directory, image_data_generator,\n            target_size=target_size,\n            color_mode=color_mode,\n            classes=classes,\n            class_mode=class_mode,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            data_format=data_format,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            follow_links=follow_links,\n            subset=subset,\n            interpolation=interpolation,\n            dtype=dtype)\n\n\nclass NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n    __doc__ = image.NumpyArrayIterator.__doc__\n\n    def __init__(self, x, y, image_data_generator,\n                 batch_size=32,\n                 shuffle=False,\n                 sample_weight=None,\n                 seed=None,\n                 data_format=None,\n                 save_to_dir=None,\n                 save_prefix=\'\',\n                 save_format=\'png\',\n                 subset=None,\n                 dtype=None):\n        if data_format is None:\n            data_format = backend.image_data_format()\n        if dtype is None:\n            dtype = backend.floatx()\n        super(NumpyArrayIterator, self).__init__(\n            x, y, image_data_generator,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            sample_weight=sample_weight,\n            seed=seed,\n            data_format=data_format,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            subset=subset,\n            dtype=dtype)\n\n\nclass DataFrameIterator(image.DataFrameIterator, Iterator):\n    __doc__ = image.DataFrameIterator.__doc__\n\n    def __init__(self,\n                 dataframe,\n                 directory=None,\n                 image_data_generator=None,\n                 x_col=\'filename\',\n                 y_col=\'class\',\n                 weight_col=None,\n                 target_size=(256, 256),\n                 color_mode=\'rgb\',\n                 classes=None,\n                 class_mode=\'categorical\',\n                 batch_size=32,\n                 shuffle=True,\n                 seed=None,\n                 data_format=\'channels_last\',\n                 save_to_dir=None,\n                 save_prefix=\'\',\n                 save_format=\'png\',\n                 subset=None,\n                 interpolation=\'nearest\',\n                 dtype=\'float32\',\n                 validate_filenames=True):\n        if data_format is None:\n            data_format = backend.image_data_format()\n        if dtype is None:\n            dtype = backend.floatx()\n        super(DataFrameIterator, self).__init__(\n            dataframe,\n            directory=directory,\n            image_data_generator=image_data_generator,\n            x_col=x_col,\n            y_col=y_col,\n            weight_col=weight_col,\n            target_size=target_size,\n            color_mode=color_mode,\n            classes=classes,\n            class_mode=class_mode,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            data_format=data_format,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            subset=subset,\n            interpolation=interpolation,\n            dtype=dtype,\n            validate_filenames=validate_filenames)\n\n\nclass ImageDataGenerator(image.ImageDataGenerator):\n    __doc__ = image.ImageDataGenerator.__doc__\n\n    def __init__(self,\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 zca_whitening=False,\n                 zca_epsilon=1e-6,\n                 rotation_range=0,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 brightness_range=None,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode=\'nearest\',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 preprocessing_function=None,\n                 data_format=\'channels_last\',\n                 validation_split=0.0,\n                 interpolation_order=1,\n                 dtype=\'float32\'):\n        if data_format is None:\n            data_format = backend.image_data_format()\n        if dtype is None:\n            dtype = backend.floatx()\n        super(ImageDataGenerator, self).__init__(\n            featurewise_center=featurewise_center,\n            samplewise_center=samplewise_center,\n            featurewise_std_normalization=featurewise_std_normalization,\n            samplewise_std_normalization=samplewise_std_normalization,\n            zca_whitening=zca_whitening,\n            zca_epsilon=zca_epsilon,\n            rotation_range=rotation_range,\n            width_shift_range=width_shift_range,\n            height_shift_range=height_shift_range,\n            brightness_range=brightness_range,\n            shear_range=shear_range,\n            zoom_range=zoom_range,\n            channel_shift_range=channel_shift_range,\n            fill_mode=fill_mode,\n            cval=cval,\n            horizontal_flip=horizontal_flip,\n            vertical_flip=vertical_flip,\n            rescale=rescale,\n            preprocessing_function=preprocessing_function,\n            data_format=data_format,\n            validation_split=validation_split,\n            interpolation_order=interpolation_order,\n            dtype=dtype)\n\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32,\n             shuffle=True,\n             sample_weight=None,\n             seed=None,\n             save_to_dir=None,\n             save_prefix=\'\',\n             save_format=\'png\',\n             subset=None):\n        """"""Takes data & label arrays, generates batches of augmented data.\n\n        # Arguments\n            x: Input data. Numpy array of rank 4 or a tuple.\n                If tuple, the first element\n                should contain the images and the second element\n                another numpy array or a list of numpy arrays\n                that gets passed to the output\n                without any modifications.\n                Can be used to feed the model miscellaneous data\n                along with the images.\n                In case of grayscale data, the channels axis of the image array\n                should have value 1, in case\n                of RGB data, it should have value 3, and in case\n                of RGBA data, it should have value 4.\n            y: Labels.\n            batch_size: Int (default: 32).\n            shuffle: Boolean (default: True).\n            sample_weight: Sample weights.\n            seed: Int (default: None).\n            save_to_dir: None or str (default: None).\n                This allows you to optionally specify a directory\n                to which to save the augmented pictures being generated\n                (useful for visualizing what you are doing).\n            save_prefix: Str (default: `\'\'`).\n                Prefix to use for filenames of saved pictures\n                (only relevant if `save_to_dir` is set).\n            save_format: one of ""png"", ""jpeg""\n                (only relevant if `save_to_dir` is set). Default: ""png"".\n            subset: Subset of data (`""training""` or `""validation""`) if\n                `validation_split` is set in `ImageDataGenerator`.\n\n        # Returns\n            An `Iterator` yielding tuples of `(x, y)`\n                where `x` is a numpy array of image data\n                (in the case of a single image input) or a list\n                of numpy arrays (in the case with\n                additional inputs) and `y` is a numpy array\n                of corresponding labels. If \'sample_weight\' is not None,\n                the yielded tuples are of the form `(x, y, sample_weight)`.\n                If `y` is None, only the numpy array `x` is returned.\n        """"""\n        return NumpyArrayIterator(\n            x,\n            y,\n            self,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            sample_weight=sample_weight,\n            seed=seed,\n            data_format=self.data_format,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            subset=subset\n        )\n\n    def flow_from_directory(self,\n                            directory,\n                            target_size=(256, 256),\n                            color_mode=\'rgb\',\n                            classes=None,\n                            class_mode=\'categorical\',\n                            batch_size=32,\n                            shuffle=True,\n                            seed=None,\n                            save_to_dir=None,\n                            save_prefix=\'\',\n                            save_format=\'png\',\n                            follow_links=False,\n                            subset=None,\n                            interpolation=\'nearest\'):\n        """"""Takes the path to a directory & generates batches of augmented data.\n\n        # Arguments\n            directory: string, path to the target directory.\n                It should contain one subdirectory per class.\n                Any PNG, JPG, BMP, PPM or TIF images\n                inside each of the subdirectories directory tree\n                will be included in the generator.\n                See [this script](\n                https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n                for more details.\n            target_size: Tuple of integers `(height, width)`,\n                default: `(256, 256)`.\n                The dimensions to which all images found will be resized.\n            color_mode: One of ""grayscale"", ""rgb"", ""rgba"". Default: ""rgb"".\n                Whether the images will be converted to\n                have 1, 3, or 4 channels.\n            classes: Optional list of class subdirectories\n                (e.g. `[\'dogs\', \'cats\']`). Default: None.\n                If not provided, the list of classes will be automatically\n                inferred from the subdirectory names/structure\n                under `directory`, where each subdirectory will\n                be treated as a different class\n                (and the order of the classes, which will map to the label\n                indices, will be alphanumeric).\n                The dictionary containing the mapping from class names to class\n                indices can be obtained via the attribute `class_indices`.\n            class_mode: One of ""categorical"", ""binary"", ""sparse"",\n                ""input"", or None. Default: ""categorical"".\n                Determines the type of label arrays that are returned:\n                - ""categorical"" will be 2D one-hot encoded labels,\n                - ""binary"" will be 1D binary labels,\n                    ""sparse"" will be 1D integer labels,\n                - ""input"" will be images identical\n                    to input images (mainly used to work with autoencoders).\n                - If None, no labels are returned\n                  (the generator will only yield batches of image data,\n                  which is useful to use with `model.predict_generator()`).\n                  Please note that in case of class_mode None,\n                  the data still needs to reside in a subdirectory\n                  of `directory` for it to work correctly.\n            batch_size: Size of the batches of data (default: 32).\n            shuffle: Whether to shuffle the data (default: True)\n                If set to False, sorts the data in alphanumeric order.\n            seed: Optional random seed for shuffling and transformations.\n            save_to_dir: None or str (default: None).\n                This allows you to optionally specify\n                a directory to which to save\n                the augmented pictures being generated\n                (useful for visualizing what you are doing).\n            save_prefix: Str. Prefix to use for filenames of saved pictures\n                (only relevant if `save_to_dir` is set).\n            save_format: One of ""png"", ""jpeg""\n                (only relevant if `save_to_dir` is set). Default: ""png"".\n            follow_links: Whether to follow symlinks inside\n                class subdirectories (default: False).\n            subset: Subset of data (`""training""` or `""validation""`) if\n                `validation_split` is set in `ImageDataGenerator`.\n            interpolation: Interpolation method used to\n                resample the image if the\n                target size is different from that of the loaded image.\n                Supported methods are `""nearest""`, `""bilinear""`,\n                and `""bicubic""`.\n                If PIL version 1.1.3 or newer is installed, `""lanczos""` is also\n                supported. If PIL version 3.4.0 or newer is installed,\n                `""box""` and `""hamming""` are also supported.\n                By default, `""nearest""` is used.\n\n        # Returns\n            A `DirectoryIterator` yielding tuples of `(x, y)`\n                where `x` is a numpy array containing a batch\n                of images with shape `(batch_size, *target_size, channels)`\n                and `y` is a numpy array of corresponding labels.\n        """"""\n        return DirectoryIterator(\n            directory,\n            self,\n            target_size=target_size,\n            color_mode=color_mode,\n            classes=classes,\n            class_mode=class_mode,\n            data_format=self.data_format,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            follow_links=follow_links,\n            subset=subset,\n            interpolation=interpolation\n        )\n\n    def flow_from_dataframe(self,\n                            dataframe,\n                            directory=None,\n                            x_col=""filename"",\n                            y_col=""class"",\n                            weight_col=None,\n                            target_size=(256, 256),\n                            color_mode=\'rgb\',\n                            classes=None,\n                            class_mode=\'categorical\',\n                            batch_size=32,\n                            shuffle=True,\n                            seed=None,\n                            save_to_dir=None,\n                            save_prefix=\'\',\n                            save_format=\'png\',\n                            subset=None,\n                            interpolation=\'nearest\',\n                            validate_filenames=True,\n                            **kwargs):\n        """"""Takes the dataframe and the path to a directory\n         and generates batches of augmented/normalized data.\n\n        **A simple tutorial can be found **[here](\n                                    http://bit.ly/keras_flow_from_dataframe).\n\n        # Arguments\n            dataframe: Pandas dataframe containing the filepaths relative to\n                `directory` (or absolute paths if `directory` is None) of the\n                images in a string column. It should include other column/s\n                depending on the `class_mode`:\n                - if `class_mode` is `""categorical""` (default value) it must\n                    include the `y_col` column with the class/es of each image.\n                    Values in column can be string/list/tuple if a single class\n                    or list/tuple if multiple classes.\n                - if `class_mode` is `""binary""` or `""sparse""` it must include\n                    the given `y_col` column with class values as strings.\n                - if `class_mode` is `""raw""` or `""multi_output""` it should contain\n                the columns specified in `y_col`.\n                - if `class_mode` is `""input""` or `None` no extra column is needed.\n            directory: string, path to the directory to read images from. If `None`,\n                data in `x_col` column should be absolute paths.\n            x_col: string, column in `dataframe` that contains the filenames (or\n                absolute paths if `directory` is `None`).\n            y_col: string or list, column/s in `dataframe` that has the target data.\n            weight_col: string, column in `dataframe` that contains the sample\n                weights. Default: `None`.\n            target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n                The dimensions to which all images found will be resized.\n            color_mode: one of ""grayscale"", ""rgb"", ""rgba"". Default: ""rgb"".\n                Whether the images will be converted to have 1 or 3 color channels.\n            classes: optional list of classes (e.g. `[\'dogs\', \'cats\']`).\n                Default: None. If not provided, the list of classes will be\n                automatically inferred from the `y_col`,\n                which will map to the label indices, will be alphanumeric).\n                The dictionary containing the mapping from class names to class\n                indices can be obtained via the attribute `class_indices`.\n            class_mode: one of ""binary"", ""categorical"", ""input"", ""multi_output"",\n                ""raw"", sparse"" or None. Default: ""categorical"".\n                Mode for yielding the targets:\n                - `""binary""`: 1D numpy array of binary labels,\n                - `""categorical""`: 2D numpy array of one-hot encoded labels.\n                    Supports multi-label output.\n                - `""input""`: images identical to input images (mainly used to\n                    work with autoencoders),\n                - `""multi_output""`: list with the values of the different columns,\n                - `""raw""`: numpy array of values in `y_col` column(s),\n                - `""sparse""`: 1D numpy array of integer labels,\n                - `None`, no targets are returned (the generator will only yield\n                    batches of image data, which is useful to use in\n                    `model.predict_generator()`).\n            batch_size: size of the batches of data (default: 32).\n            shuffle: whether to shuffle the data (default: True)\n            seed: optional random seed for shuffling and transformations.\n            save_to_dir: None or str (default: None).\n                This allows you to optionally specify a directory\n                to which to save the augmented pictures being generated\n                (useful for visualizing what you are doing).\n            save_prefix: str. Prefix to use for filenames of saved pictures\n                (only relevant if `save_to_dir` is set).\n            save_format: one of ""png"", ""jpeg""\n                (only relevant if `save_to_dir` is set). Default: ""png"".\n            follow_links: whether to follow symlinks inside class subdirectories\n                (default: False).\n            subset: Subset of data (`""training""` or `""validation""`) if\n                `validation_split` is set in `ImageDataGenerator`.\n            interpolation: Interpolation method used to resample the image if the\n                target size is different from that of the loaded image.\n                Supported methods are `""nearest""`, `""bilinear""`, and `""bicubic""`.\n                If PIL version 1.1.3 or newer is installed, `""lanczos""` is also\n                supported. If PIL version 3.4.0 or newer is installed, `""box""` and\n                `""hamming""` are also supported. By default, `""nearest""` is used.\n            validate_filenames: Boolean, whether to validate image filenames in\n                `x_col`. If `True`, invalid images will be ignored. Disabling this\n                option can lead to speed-up in the execution of this function.\n                Default: `True`.\n\n        # Returns\n            A `DataFrameIterator` yielding tuples of `(x, y)`\n            where `x` is a numpy array containing a batch\n            of images with shape `(batch_size, *target_size, channels)`\n            and `y` is a numpy array of corresponding labels.\n        """"""\n        return DataFrameIterator(\n            dataframe,\n            directory,\n            self,\n            x_col=x_col,\n            y_col=y_col,\n            weight_col=weight_col,\n            target_size=target_size,\n            color_mode=color_mode,\n            classes=classes,\n            class_mode=class_mode,\n            data_format=self.data_format,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            subset=subset,\n            interpolation=interpolation,\n            validate_filenames=validate_filenames,\n            **kwargs\n        )\n\n\narray_to_img.__doc__ = image.array_to_img.__doc__\nimg_to_array.__doc__ = image.img_to_array.__doc__\nsave_img.__doc__ = image.save_img.__doc__\n'"
keras/preprocessing/sequence.py,0,"b'""""""Utilities for preprocessing sequence data.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_preprocessing import sequence\nfrom .. import utils\n\npad_sequences = sequence.pad_sequences\nmake_sampling_table = sequence.make_sampling_table\nskipgrams = sequence.skipgrams\n_remove_long_seq = sequence._remove_long_seq  # TODO: make it public?\n\n\nclass TimeseriesGenerator(sequence.TimeseriesGenerator, utils.Sequence):\n    """"""Utility class for generating batches of temporal data.\n\n    This class takes in a sequence of data-points gathered at\n    equal intervals, along with time series parameters such as\n    stride, length of history, etc., to produce batches for\n    training/validation.\n\n    # Arguments\n        data: Indexable generator (such as list or Numpy array)\n            containing consecutive data points (timesteps).\n            The data should be at 2D, and axis 0 is expected\n            to be the time dimension.\n        targets: Targets corresponding to timesteps in `data`.\n            It should have same length as `data`.\n        length: Length of the output sequences (in number of timesteps).\n        sampling_rate: Period between successive individual timesteps\n            within sequences. For rate `r`, timesteps\n            `data[i]`, `data[i-r]`, ... `data[i - length]`\n            are used for create a sample sequence.\n        stride: Period between successive output sequences.\n            For stride `s`, consecutive output samples would\n            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n        start_index: Data points earlier than `start_index` will not be used\n            in the output sequences. This is useful to reserve part of the\n            data for test or validation.\n        end_index: Data points later than `end_index` will not be used\n            in the output sequences. This is useful to reserve part of the\n            data for test or validation.\n        shuffle: Whether to shuffle output samples,\n            or instead draw them in chronological order.\n        reverse: Boolean: if `true`, timesteps in each output sample will be\n            in reverse chronological order.\n        batch_size: Number of timeseries samples in each batch\n            (except maybe the last one).\n\n    # Returns\n        A [Sequence](/utils/#sequence) instance.\n\n    # Examples\n\n    ```python\n    from keras.preprocessing.sequence import TimeseriesGenerator\n    import numpy as np\n\n    data = np.array([[i] for i in range(50)])\n    targets = np.array([[i] for i in range(50)])\n\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2,\n                                   batch_size=2)\n    assert len(data_gen) == 20\n\n    batch_0 = data_gen[0]\n    x, y = batch_0\n    assert np.array_equal(x,\n                          np.array([[[0], [2], [4], [6], [8]],\n                                    [[1], [3], [5], [7], [9]]]))\n    assert np.array_equal(y,\n                          np.array([[10], [11]]))\n    ```\n    """"""\n    pass\n'"
keras/preprocessing/text.py,0,"b'""""""Utilities for text input preprocessing.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras_preprocessing import text\n\ntext_to_word_sequence = text.text_to_word_sequence\none_hot = text.one_hot\nhashing_trick = text.hashing_trick\nTokenizer = text.Tokenizer\ntokenizer_from_json = text.tokenizer_from_json\n'"
keras/utils/__init__.py,0,b'from __future__ import absolute_import\nfrom . import np_utils\nfrom . import generic_utils\nfrom . import data_utils\nfrom . import io_utils\nfrom . import conv_utils\nfrom . import losses_utils\nfrom . import metrics_utils\n\n# Globally-importable utils.\nfrom .io_utils import HDF5Matrix\nfrom .io_utils import H5Dict\nfrom .data_utils import get_file\nfrom .data_utils import Sequence\nfrom .data_utils import GeneratorEnqueuer\nfrom .data_utils import OrderedEnqueuer\nfrom .generic_utils import CustomObjectScope\nfrom .generic_utils import custom_object_scope\nfrom .generic_utils import get_custom_objects\nfrom .generic_utils import serialize_keras_object\nfrom .generic_utils import deserialize_keras_object\nfrom .generic_utils import Progbar\nfrom .layer_utils import convert_all_kernels_in_model\nfrom .layer_utils import get_source_inputs\nfrom .layer_utils import print_summary\nfrom .vis_utils import model_to_dot\nfrom .vis_utils import plot_model\nfrom .np_utils import to_categorical\nfrom .np_utils import normalize\nfrom .multi_gpu_utils import multi_gpu_model\n'
keras/utils/conv_utils.py,0,"b'""""""Utilities used in convolutional layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom six.moves import range\nimport numpy as np\nfrom .. import backend as K\n\n\ndef normalize_tuple(value, n, name):\n    """"""Transforms a single int or iterable of ints into an int tuple.\n\n    # Arguments\n        value: The value to validate and convert. Could be an int, or any iterable\n          of ints.\n        n: The size of the tuple to be returned.\n        name: The name of the argument being validated, e.g. `strides` or\n          `kernel_size`. This is only used to format error messages.\n\n    # Returns\n        A tuple of n integers.\n\n    # Raises\n        ValueError: If something else than an int/long or iterable thereof was\n        passed.\n    """"""\n    if isinstance(value, int):\n        return (value,) * n\n    else:\n        try:\n            value_tuple = tuple(value)\n        except TypeError:\n            raise ValueError(\'The `{}` argument must be a tuple of {} \'\n                             \'integers. Received: {}\'.format(name, n, value))\n        if len(value_tuple) != n:\n            raise ValueError(\'The `{}` argument must be a tuple of {} \'\n                             \'integers. Received: {}\'.format(name, n, value))\n        for single_value in value_tuple:\n            try:\n                int(single_value)\n            except ValueError:\n                raise ValueError(\'The `{}` argument must be a tuple of {} \'\n                                 \'integers. Received: {} including element {} \'\n                                 \'of type {}\'.format(name, n, value, single_value,\n                                                     type(single_value)))\n    return value_tuple\n\n\ndef normalize_padding(value):\n    padding = value.lower()\n    allowed = {\'valid\', \'same\', \'causal\'}\n    if K.backend() == \'theano\':\n        allowed.add(\'full\')\n    if padding not in allowed:\n        raise ValueError(\'The `padding` argument must be one of ""valid"", ""same"" \'\n                         \'(or ""causal"" for Conv1D). Received: {}\'.format(padding))\n    return padding\n\n\ndef convert_kernel(kernel):\n    """"""Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n\n    Also works reciprocally, since the transformation is its own inverse.\n\n    # Arguments\n        kernel: Numpy array (3D, 4D or 5D).\n\n    # Returns\n        The converted kernel.\n\n    # Raises\n        ValueError: in case of invalid kernel shape or invalid data_format.\n    """"""\n    kernel = np.asarray(kernel)\n    if not 3 <= kernel.ndim <= 5:\n        raise ValueError(\'Invalid kernel shape:\', kernel.shape)\n    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n    no_flip = (slice(None, None), slice(None, None))\n    slices[-2:] = no_flip\n    return np.copy(kernel[tuple(slices)])\n\n\ndef conv_output_length(input_length, filter_size,\n                       padding, stride, dilation=1):\n    """"""Determines output length of a convolution given input length.\n\n    # Arguments\n        input_length: integer.\n        filter_size: integer.\n        padding: one of `""same""`, `""valid""`, `""full""`.\n        stride: integer.\n        dilation: dilation rate, integer.\n\n    # Returns\n        The output length (integer).\n    """"""\n    if input_length is None:\n        return None\n    assert padding in {\'same\', \'valid\', \'full\', \'causal\'}\n    dilated_filter_size = (filter_size - 1) * dilation + 1\n    if padding == \'same\':\n        output_length = input_length\n    elif padding == \'valid\':\n        output_length = input_length - dilated_filter_size + 1\n    elif padding == \'causal\':\n        output_length = input_length\n    elif padding == \'full\':\n        output_length = input_length + dilated_filter_size - 1\n    return (output_length + stride - 1) // stride\n\n\ndef conv_input_length(output_length, filter_size, padding, stride):\n    """"""Determines input length of a convolution given output length.\n\n    # Arguments\n        output_length: integer.\n        filter_size: integer.\n        padding: one of `""same""`, `""valid""`, `""full""`.\n        stride: integer.\n\n    # Returns\n        The input length (integer).\n    """"""\n    if output_length is None:\n        return None\n    assert padding in {\'same\', \'valid\', \'full\'}\n    if padding == \'same\':\n        pad = filter_size // 2\n    elif padding == \'valid\':\n        pad = 0\n    elif padding == \'full\':\n        pad = filter_size - 1\n    return (output_length - 1) * stride - 2 * pad + filter_size\n\n\ndef deconv_length(dim_size, stride_size, kernel_size, padding,\n                  output_padding, dilation=1):\n    """"""Determines output length of a transposed convolution given input length.\n\n    # Arguments\n        dim_size: Integer, the input length.\n        stride_size: Integer, the stride along the dimension of `dim_size`.\n        kernel_size: Integer, the kernel size along the dimension of\n            `dim_size`.\n        padding: One of `""same""`, `""valid""`, `""full""`.\n        output_padding: Integer, amount of padding along the output dimension,\n            Can be set to `None` in which case the output length is inferred.\n        dilation: dilation rate, integer.\n\n    # Returns\n        The output length (integer).\n    """"""\n    assert padding in {\'same\', \'valid\', \'full\'}\n    if dim_size is None:\n        return None\n\n    # Get the dilated kernel size\n    kernel_size = (kernel_size - 1) * dilation + 1\n\n    # Infer length if output padding is None, else compute the exact length\n    if output_padding is None:\n        if padding == \'valid\':\n            dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n        elif padding == \'full\':\n            dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n        elif padding == \'same\':\n            dim_size = dim_size * stride_size\n    else:\n        if padding == \'same\':\n            pad = kernel_size // 2\n        elif padding == \'valid\':\n            pad = 0\n        elif padding == \'full\':\n            pad = kernel_size - 1\n\n        dim_size = ((dim_size - 1) * stride_size + kernel_size - 2 * pad +\n                    output_padding)\n\n    return dim_size\n'"
keras/utils/data_utils.py,0,"b'""""""Utilities for file download and caching.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport hashlib\nimport multiprocessing as mp\nimport os\nimport random\nimport shutil\nimport sys\nimport tarfile\nimport threading\nimport time\nimport warnings\nimport zipfile\nfrom abc import abstractmethod\nfrom contextlib import closing\nfrom multiprocessing.pool import ThreadPool\n\nimport numpy as np\nimport six\nfrom six.moves.urllib.error import HTTPError\nfrom six.moves.urllib.error import URLError\nfrom six.moves.urllib.request import urlopen\n\ntry:\n    import queue\nexcept ImportError:\n    import Queue as queue\n\nfrom ..utils.generic_utils import Progbar\n\nif sys.version_info[0] == 2:\n    def urlretrieve(url, filename, reporthook=None, data=None):\n        """"""Replacement for `urlretrieve` for Python 2.\n\n        Under Python 2, `urlretrieve` relies on `FancyURLopener` from legacy\n        `urllib` module, known to have issues with proxy management.\n\n        # Arguments\n            url: url to retrieve.\n            filename: where to store the retrieved data locally.\n            reporthook: a hook function that will be called once\n                on establishment of the network connection and once\n                after each block read thereafter.\n                The hook will be passed three arguments;\n                a count of blocks transferred so far,\n                a block size in bytes, and the total size of the file.\n            data: `data` argument passed to `urlopen`.\n        """"""\n\n        def chunk_read(response, chunk_size=8192, reporthook=None):\n            content_type = response.info().get(\'Content-Length\')\n            total_size = -1\n            if content_type is not None:\n                total_size = int(content_type.strip())\n            count = 0\n            while True:\n                chunk = response.read(chunk_size)\n                count += 1\n                if reporthook is not None:\n                    reporthook(count, chunk_size, total_size)\n                if chunk:\n                    yield chunk\n                else:\n                    break\n\n        with closing(urlopen(url, data)) as response, open(filename, \'wb\') as fd:\n            for chunk in chunk_read(response, reporthook=reporthook):\n                fd.write(chunk)\nelse:\n    from six.moves.urllib.request import urlretrieve\n\n\ndef _extract_archive(file_path, path=\'.\', archive_format=\'auto\'):\n    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n\n    # Arguments\n        file_path: path to the archive file\n        path: path to extract the archive file\n        archive_format: Archive format to try for extracting the file.\n            Options are \'auto\', \'tar\', \'zip\', and None.\n            \'tar\' includes tar, tar.gz, and tar.bz files.\n            The default \'auto\' is [\'tar\', \'zip\'].\n            None or an empty list will return no matches found.\n\n    # Returns\n        True if a match was found and an archive extraction was completed,\n        False otherwise.\n    """"""\n    if archive_format is None:\n        return False\n    if archive_format == \'auto\':\n        archive_format = [\'tar\', \'zip\']\n    if isinstance(archive_format, six.string_types):\n        archive_format = [archive_format]\n\n    for archive_type in archive_format:\n        if archive_type == \'tar\':\n            open_fn = tarfile.open\n            is_match_fn = tarfile.is_tarfile\n        if archive_type == \'zip\':\n            open_fn = zipfile.ZipFile\n            is_match_fn = zipfile.is_zipfile\n\n        if is_match_fn(file_path):\n            with open_fn(file_path) as archive:\n                try:\n                    archive.extractall(path)\n                except (tarfile.TarError, RuntimeError,\n                        KeyboardInterrupt):\n                    if os.path.exists(path):\n                        if os.path.isfile(path):\n                            os.remove(path)\n                        else:\n                            shutil.rmtree(path)\n                    raise\n            return True\n    return False\n\n\ndef get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir=\'datasets\',\n             hash_algorithm=\'auto\',\n             extract=False,\n             archive_format=\'auto\',\n             cache_dir=None):\n    """"""Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of \'extract\'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of \'file_hash\'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are \'md5\', \'sha256\', and \'auto\'.\n            The default \'auto\' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are \'auto\', \'tar\', \'zip\', and None.\n            \'tar\' includes tar, tar.gz, and tar.bz files.\n            The default \'auto\' is [\'tar\', \'zip\'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    """"""  # noqa\n    if cache_dir is None:\n        if \'KERAS_HOME\' in os.environ:\n            cache_dir = os.environ.get(\'KERAS_HOME\')\n        else:\n            cache_dir = os.path.join(os.path.expanduser(\'~\'), \'.keras\')\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = \'md5\'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join(\'/tmp\', \'.keras\')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + \'.tar.gz\'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print(\'A local file was found, but it seems to be incomplete\'\n                      \' or outdated because the {} file hash does not match \'\n                      \'the original value of {} so we will re-download the \'\n                      \'data.\'.format(hash_algorithm, file_hash))\n                download = True\n    else:\n        download = True\n\n    if download:\n        print(\'Downloading data from\', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size == -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = \'URL fetch failure on {} : {} -- {}\'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n        except (Exception, KeyboardInterrupt):\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format=\'tar\')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath\n\n\ndef _hash_file(fpath, algorithm=\'sha256\', chunk_size=65535):\n    """"""Calculates a file sha256 or md5 hash.\n\n    # Example\n\n    ```python\n        >>> from keras.utils.data_utils import _hash_file\n        >>> _hash_file(\'/path/to/file.zip\')\n        \'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\'\n    ```\n\n    # Arguments\n        fpath: path to the file being validated\n        algorithm: hash algorithm, one of \'auto\', \'sha256\', or \'md5\'.\n            The default \'auto\' detects the hash algorithm in use.\n        chunk_size: Bytes to read at a time, important for large files.\n\n    # Returns\n        The file hash\n    """"""\n    if (algorithm == \'sha256\') or (algorithm == \'auto\' and len(hash) == 64):\n        hasher = hashlib.sha256()\n    else:\n        hasher = hashlib.md5()\n\n    with open(fpath, \'rb\') as fpath_file:\n        for chunk in iter(lambda: fpath_file.read(chunk_size), b\'\'):\n            hasher.update(chunk)\n\n    return hasher.hexdigest()\n\n\ndef validate_file(fpath, file_hash, algorithm=\'auto\', chunk_size=65535):\n    """"""Validates a file against a sha256 or md5 hash.\n\n    # Arguments\n        fpath: path to the file being validated\n        file_hash:  The expected hash string of the file.\n            The sha256 and md5 hash algorithms are both supported.\n        algorithm: Hash algorithm, one of \'auto\', \'sha256\', or \'md5\'.\n            The default \'auto\' detects the hash algorithm in use.\n        chunk_size: Bytes to read at a time, important for large files.\n\n    # Returns\n        Whether the file is valid\n    """"""\n    if ((algorithm == \'sha256\') or\n            (algorithm == \'auto\' and len(file_hash) == 64)):\n        hasher = \'sha256\'\n    else:\n        hasher = \'md5\'\n\n    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):\n        return True\n    else:\n        return False\n\n\nclass Sequence(object):\n    """"""Base object for fitting to a sequence of data, such as a dataset.\n\n    Every `Sequence` must implement the `__getitem__` and the `__len__` methods.\n    If you want to modify your dataset between epochs you may implement\n    `on_epoch_end`. The method `__getitem__` should return a complete batch.\n\n    # Notes\n\n    `Sequence` are a safer way to do multiprocessing. This structure guarantees\n    that the network will only train once on each sample per epoch which is not\n    the case with generators.\n\n    # Examples\n\n    ```python\n        from skimage.io import imread\n        from skimage.transform import resize\n        import numpy as np\n\n        # Here, `x_set` is list of path to the images\n        # and `y_set` are the associated classes.\n\n        class CIFAR10Sequence(Sequence):\n\n            def __init__(self, x_set, y_set, batch_size):\n                self.x, self.y = x_set, y_set\n                self.batch_size = batch_size\n\n            def __len__(self):\n                return int(np.ceil(len(self.x) / float(self.batch_size)))\n\n            def __getitem__(self, idx):\n                batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n                batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n                return np.array([\n                    resize(imread(file_name), (200, 200))\n                       for file_name in batch_x]), np.array(batch_y)\n    ```\n    """"""\n\n    use_sequence_api = True\n\n    @abstractmethod\n    def __getitem__(self, index):\n        """"""Gets batch at position `index`.\n\n        # Arguments\n            index: position of the batch in the Sequence.\n\n        # Returns\n            A batch\n        """"""\n        raise NotImplementedError\n\n    @abstractmethod\n    def __len__(self):\n        """"""Number of batch in the Sequence.\n\n        # Returns\n            The number of batches in the Sequence.\n        """"""\n        raise NotImplementedError\n\n    def on_epoch_end(self):\n        """"""Method called at the end of every epoch.\n        """"""\n        pass\n\n    def __iter__(self):\n        """"""Create a generator that iterate over the Sequence.""""""\n        for item in (self[i] for i in range(len(self))):\n            yield item\n\n\n# Global variables to be shared across processes\n_SHARED_SEQUENCES = {}\n# We use a Value to provide unique id to different processes.\n_SEQUENCE_COUNTER = None\n\n\ndef init_pool(seqs):\n    global _SHARED_SEQUENCES\n    _SHARED_SEQUENCES = seqs\n\n\ndef get_index(uid, i):\n    """"""Get the value from the Sequence `uid` at index `i`.\n\n    To allow multiple Sequences to be used at the same time, we use `uid` to\n    get a specific one. A single Sequence would cause the validation to\n    overwrite the training Sequence.\n\n    # Arguments\n        uid: int, Sequence identifier\n        i: index\n\n    # Returns\n        The value at index `i`.\n    """"""\n    return _SHARED_SEQUENCES[uid][i]\n\n\nclass SequenceEnqueuer(object):\n    """"""Base class to enqueue inputs.\n\n    The task of an Enqueuer is to use parallelism to speed up preprocessing.\n    This is done with processes or threads.\n\n    # Examples\n\n    ```python\n        enqueuer = SequenceEnqueuer(...)\n        enqueuer.start()\n        datas = enqueuer.get()\n        for data in datas:\n            # Use the inputs; training, evaluating, predicting.\n            # ... stop sometime.\n        enqueuer.close()\n    ```\n\n    The `enqueuer.get()` should be an infinite stream of datas.\n\n    """"""\n    def __init__(self, sequence,\n                 use_multiprocessing=False):\n        self.sequence = sequence\n        self.use_multiprocessing = use_multiprocessing\n\n        global _SEQUENCE_COUNTER\n        if _SEQUENCE_COUNTER is None:\n            try:\n                _SEQUENCE_COUNTER = mp.Value(\'i\', 0)\n            except OSError:\n                # In this case the OS does not allow us to use\n                # multiprocessing. We resort to an int\n                # for enqueuer indexing.\n                _SEQUENCE_COUNTER = 0\n\n        if isinstance(_SEQUENCE_COUNTER, int):\n            self.uid = _SEQUENCE_COUNTER\n            _SEQUENCE_COUNTER += 1\n        else:\n            # Doing Multiprocessing.Value += x is not process-safe.\n            with _SEQUENCE_COUNTER.get_lock():\n                self.uid = _SEQUENCE_COUNTER.value\n                _SEQUENCE_COUNTER.value += 1\n\n        self.workers = 0\n        self.executor_fn = None\n        self.queue = None\n        self.run_thread = None\n        self.stop_signal = None\n\n    def is_running(self):\n        return self.stop_signal is not None and not self.stop_signal.is_set()\n\n    def start(self, workers=1, max_queue_size=10):\n        """"""Start the handler\'s workers.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, workers could block on `put()`)\n        """"""\n        if self.use_multiprocessing:\n            self.executor_fn = self._get_executor_init(workers)\n        else:\n            # We do not need the init since it\'s threads.\n            self.executor_fn = lambda _: ThreadPool(workers)\n        self.workers = workers\n        self.queue = queue.Queue(max_queue_size)\n        self.stop_signal = threading.Event()\n        self.run_thread = threading.Thread(target=self._run)\n        self.run_thread.daemon = True\n        self.run_thread.start()\n\n    def _send_sequence(self):\n        """"""Send current Iterable to all workers.""""""\n        # For new processes that may spawn\n        _SHARED_SEQUENCES[self.uid] = self.sequence\n\n    def stop(self, timeout=None):\n        """"""Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`\n        """"""\n        self.stop_signal.set()\n        with self.queue.mutex:\n            self.queue.queue.clear()\n            self.queue.unfinished_tasks = 0\n            self.queue.not_full.notify()\n        self.run_thread.join(timeout)\n        _SHARED_SEQUENCES[self.uid] = None\n\n    @abstractmethod\n    def _run(self):\n        """"""Submits request to the executor and queue the `Future` objects.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def _get_executor_init(self, workers):\n        """"""Get the Pool initializer for multiprocessing.\n\n        # Returns\n            Function, a Function to initialize the pool\n        """"""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get(self):\n        """"""Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Returns\n            Generator yielding tuples `(inputs, targets)`\n                or `(inputs, targets, sample_weights)`.\n        """"""\n        raise NotImplementedError\n\n\nclass OrderedEnqueuer(SequenceEnqueuer):\n    """"""Builds a Enqueuer from a Sequence.\n\n    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n\n    # Arguments\n        sequence: A `keras.utils.data_utils.Sequence` object.\n        use_multiprocessing: use multiprocessing if True, otherwise threading\n        shuffle: whether to shuffle the data at the beginning of each epoch\n    """"""\n    def __init__(self, sequence, use_multiprocessing=False, shuffle=False):\n        super(OrderedEnqueuer, self).__init__(sequence, use_multiprocessing)\n        self.shuffle = shuffle\n        self.end_of_epoch_signal = threading.Event()\n\n    def _get_executor_init(self, workers):\n        """"""Get the Pool initializer for multiprocessing.\n\n        # Returns\n            Function, a Function to initialize the pool\n        """"""\n        return lambda seqs: mp.Pool(workers,\n                                    initializer=init_pool,\n                                    initargs=(seqs,))\n\n    def _wait_queue(self):\n        """"""Wait for the queue to be empty.""""""\n        while True:\n            time.sleep(0.1)\n            if self.queue.unfinished_tasks == 0 or self.stop_signal.is_set():\n                return\n\n    def _run(self):\n        """"""Submits request to the executor and queue the `Future` objects.""""""\n        while True:\n            sequence = list(range(len(self.sequence)))\n            self._send_sequence()  # Share the initial sequence\n\n            if self.shuffle:\n                random.shuffle(sequence)\n\n            with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n                for i in sequence:\n                    if self.stop_signal.is_set():\n                        return\n                    future = executor.apply_async(get_index, (self.uid, i))\n                    future.idx = i\n                    self.queue.put(future, block=True)\n\n                # Done with the current epoch, waiting for the final batches\n                self._wait_queue()\n\n                if self.stop_signal.is_set():\n                    # We\'re done\n                    return\n\n            # Call the internal on epoch end.\n            self.sequence.on_epoch_end()\n            # communicate on_epoch_end to the main thread\n            self.end_of_epoch_signal.set()\n\n    def join_end_of_epoch(self):\n        self.end_of_epoch_signal.wait(timeout=30)\n        self.end_of_epoch_signal.clear()\n\n    def get(self):\n        """"""Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Yields\n            The next element in the queue, i.e. a tuple\n            `(inputs, targets)` or\n            `(inputs, targets, sample_weights)`.\n        """"""\n        try:\n            while self.is_running():\n                try:\n                    future = self.queue.get(block=True)\n                    inputs = future.get(timeout=30)\n                except mp.TimeoutError:\n                    idx = future.idx\n                    warnings.warn(\n                        \'The input {} could not be retrieved.\'\n                        \' It could be because a worker has died.\'.format(idx),\n                        UserWarning)\n                    inputs = self.sequence[idx]\n                finally:\n                    self.queue.task_done()\n\n                if inputs is not None:\n                    yield inputs\n        except Exception:\n            self.stop()\n            six.reraise(*sys.exc_info())\n\n\ndef init_pool_generator(gens, random_seed=None):\n    global _SHARED_SEQUENCES\n    _SHARED_SEQUENCES = gens\n\n    if random_seed is not None:\n        ident = mp.current_process().ident\n        np.random.seed(random_seed + ident)\n\n\ndef next_sample(uid):\n    """"""Get the next value from the generator `uid`.\n\n    To allow multiple generators to be used at the same time, we use `uid` to\n    get a specific one. A single generator would cause the validation to\n    overwrite the training generator.\n\n    # Arguments\n        uid: int, generator identifier\n\n    # Returns\n        The next value of generator `uid`.\n    """"""\n    return six.next(_SHARED_SEQUENCES[uid])\n\n\nclass GeneratorEnqueuer(SequenceEnqueuer):\n    """"""Builds a queue out of a data generator.\n\n    The provided generator can be finite in which case the class will throw\n    a `StopIteration` exception.\n\n    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n\n    # Arguments\n        sequence: a sequence function which yields data\n        use_multiprocessing: use multiprocessing if True, otherwise threading\n        wait_time: time to sleep in-between calls to `put()`\n        random_seed: Initial seed for workers,\n            will be incremented by one for each worker.\n    """"""\n\n    def __init__(self, sequence, use_multiprocessing=False, wait_time=None,\n                 random_seed=None):\n        super(GeneratorEnqueuer, self).__init__(sequence, use_multiprocessing)\n        self.random_seed = random_seed\n        if wait_time is not None:\n            warnings.warn(\'`wait_time` is not used anymore.\',\n                          DeprecationWarning)\n\n    def _get_executor_init(self, workers):\n        """"""Get the Pool initializer for multiprocessing.\n\n        # Returns\n            Function, a Function to initialize the pool\n        """"""\n        return lambda seqs: mp.Pool(workers,\n                                    initializer=init_pool_generator,\n                                    initargs=(seqs, self.random_seed))\n\n    def _run(self):\n        """"""Submits request to the executor and queue the `Future` objects.""""""\n        self._send_sequence()  # Share the initial generator\n        with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n            while True:\n                if self.stop_signal.is_set():\n                    return\n                self.queue.put(\n                    executor.apply_async(next_sample, (self.uid,)), block=True)\n\n    def get(self):\n        """"""Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Yields\n            The next element in the queue, i.e. a tuple\n            `(inputs, targets)` or\n            `(inputs, targets, sample_weights)`.\n        """"""\n        try:\n            while self.is_running():\n                try:\n                    future = self.queue.get(block=True)\n                    inputs = future.get(timeout=30)\n                    self.queue.task_done()\n                except mp.TimeoutError:\n                    warnings.warn(\n                        \'An input could not be retrieved.\'\n                        \' It could be because a worker has died.\'\n                        \'We do not have any information on the lost sample.\',\n                        UserWarning)\n                    continue\n                if inputs is not None:\n                    yield inputs\n        except StopIteration:\n            # Special case for finite generators\n            last_ones = []\n            while self.queue.qsize() > 0:\n                last_ones.append(self.queue.get(block=True))\n            # Wait for them to complete\n            [f.wait() for f in last_ones]\n            # Keep the good ones\n            last_ones = (future.get() for future in last_ones if future.successful())\n            for inputs in last_ones:\n                if inputs is not None:\n                    yield inputs\n        except Exception as e:\n            self.stop()\n            if \'generator already executing\' in str(e):\n                raise RuntimeError(\n                    ""Your generator is NOT thread-safe.""\n                    ""Keras requires a thread-safe generator when""\n                    ""`use_multiprocessing=False, workers > 1`.""\n                    ""For more information see issue #1638."")\n            six.reraise(*sys.exc_info())\n'"
keras/utils/generic_utils.py,0,"b'""""""Python utilities required by Keras.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport binascii\nimport numpy as np\n\nimport time\nimport sys\nimport six\nimport marshal\nimport types as python_types\nimport inspect\nimport codecs\nimport collections\n\n_GLOBAL_CUSTOM_OBJECTS = {}\n\n\nclass CustomObjectScope(object):\n    """"""Provides a scope that changes to `_GLOBAL_CUSTOM_OBJECTS` cannot escape.\n\n    Code within a `with` statement will be able to access custom objects\n    by name. Changes to global custom objects persist\n    within the enclosing `with` statement. At end of the `with` statement,\n    global custom objects are reverted to state\n    at beginning of the `with` statement.\n\n    # Example\n\n    Consider a custom object `MyObject` (e.g. a class):\n\n    ```python\n        with CustomObjectScope({\'MyObject\':MyObject}):\n            layer = Dense(..., kernel_regularizer=\'MyObject\')\n            # save, load, etc. will recognize custom object by name\n    ```\n    """"""\n\n    def __init__(self, *args):\n        self.custom_objects = args\n        self.backup = None\n\n    def __enter__(self):\n        self.backup = _GLOBAL_CUSTOM_OBJECTS.copy()\n        for objects in self.custom_objects:\n            _GLOBAL_CUSTOM_OBJECTS.update(objects)\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        _GLOBAL_CUSTOM_OBJECTS.clear()\n        _GLOBAL_CUSTOM_OBJECTS.update(self.backup)\n\n\ndef custom_object_scope(*args):\n    """"""Provides a scope that changes to `_GLOBAL_CUSTOM_OBJECTS` cannot escape.\n\n    Convenience wrapper for `CustomObjectScope`.\n    Code within a `with` statement will be able to access custom objects\n    by name. Changes to global custom objects persist\n    within the enclosing `with` statement. At end of the `with` statement,\n    global custom objects are reverted to state\n    at beginning of the `with` statement.\n\n    # Example\n\n    Consider a custom object `MyObject`\n\n    ```python\n        with custom_object_scope({\'MyObject\':MyObject}):\n            layer = Dense(..., kernel_regularizer=\'MyObject\')\n            # save, load, etc. will recognize custom object by name\n    ```\n\n    # Arguments\n        *args: Variable length list of dictionaries of name,\n            class pairs to add to custom objects.\n\n    # Returns\n        Object of type `CustomObjectScope`.\n    """"""\n    return CustomObjectScope(*args)\n\n\ndef get_custom_objects():\n    """"""Retrieves a live reference to the global dictionary of custom objects.\n\n    Updating and clearing custom objects using `custom_object_scope`\n    is preferred, but `get_custom_objects` can\n    be used to directly access `_GLOBAL_CUSTOM_OBJECTS`.\n\n    # Example\n\n    ```python\n        get_custom_objects().clear()\n        get_custom_objects()[\'MyObject\'] = MyObject\n    ```\n\n    # Returns\n        Global dictionary of names to classes (`_GLOBAL_CUSTOM_OBJECTS`).\n    """"""\n    return _GLOBAL_CUSTOM_OBJECTS\n\n\ndef serialize_keras_object(instance):\n    if instance is None:\n        return None\n    if hasattr(instance, \'get_config\'):\n        return {\n            \'class_name\': instance.__class__.__name__,\n            \'config\': instance.get_config()\n        }\n    if hasattr(instance, \'__name__\'):\n        return instance.__name__\n    else:\n        raise ValueError(\'Cannot serialize\', instance)\n\n\ndef deserialize_keras_object(identifier, module_objects=None,\n                             custom_objects=None,\n                             printable_module_name=\'object\'):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        # In this case we are dealing with a Keras config dictionary.\n        config = identifier\n        if \'class_name\' not in config or \'config\' not in config:\n            raise ValueError(\'Improper config format: {}\'.format(config))\n        class_name = config[\'class_name\']\n        if custom_objects and class_name in custom_objects:\n            cls = custom_objects[class_name]\n        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n        else:\n            module_objects = module_objects or {}\n            cls = module_objects.get(class_name)\n            if cls is None:\n                raise ValueError(\'Unknown {}: {}\'.format(printable_module_name,\n                                                         class_name))\n        if hasattr(cls, \'from_config\'):\n            custom_objects = custom_objects or {}\n            if has_arg(cls.from_config, \'custom_objects\'):\n                return cls.from_config(\n                    config[\'config\'],\n                    custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                                        list(custom_objects.items())))\n            with CustomObjectScope(custom_objects):\n                return cls.from_config(config[\'config\'])\n        else:\n            # Then `cls` may be a function returning a class.\n            # in this case by convention `config` holds\n            # the kwargs of the function.\n            custom_objects = custom_objects or {}\n            with CustomObjectScope(custom_objects):\n                return cls(**config[\'config\'])\n    elif isinstance(identifier, six.string_types):\n        function_name = identifier\n        if custom_objects and function_name in custom_objects:\n            fn = custom_objects.get(function_name)\n        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n        else:\n            fn = module_objects.get(function_name)\n            if fn is None:\n                raise ValueError(\'Unknown {}: {}\'.format(printable_module_name,\n                                                         function_name))\n        return fn\n    else:\n        raise ValueError(\'Could not interpret serialized \'\n                         \'{}: {}\'.format(printable_module_name, identifier))\n\n\ndef func_dump(func):\n    """"""Serializes a user defined function.\n\n    # Arguments\n        func: the function to serialize.\n\n    # Returns\n        A tuple `(code, defaults, closure)`.\n    """"""\n    raw_code = marshal.dumps(func.__code__)\n    code = codecs.encode(raw_code, \'base64\').decode(\'ascii\')\n    defaults = func.__defaults__\n    if func.__closure__:\n        closure = tuple(c.cell_contents for c in func.__closure__)\n    else:\n        closure = None\n    return code, defaults, closure\n\n\ndef func_load(code, defaults=None, closure=None, globs=None):\n    """"""Deserializes a user defined function.\n\n    # Arguments\n        code: bytecode of the function.\n        defaults: defaults of the function.\n        closure: closure of the function.\n        globs: dictionary of global objects.\n\n    # Returns\n        A function object.\n    """"""\n    if isinstance(code, (tuple, list)):  # unpack previous dump\n        code, defaults, closure = code\n        if isinstance(defaults, list):\n            defaults = tuple(defaults)\n\n    def ensure_value_to_cell(value):\n        """"""Ensures that a value is converted to a python cell object.\n\n        # Arguments\n            value: Any value that needs to be casted to the cell type\n\n        # Returns\n            A value wrapped as a cell object (see function ""func_load"")\n\n        """"""\n        def dummy_fn():\n            value  # just access it so it gets captured in .__closure__\n\n        cell_value = dummy_fn.__closure__[0]\n        if not isinstance(value, type(cell_value)):\n            return cell_value\n        else:\n            return value\n\n    if closure is not None:\n        closure = tuple(ensure_value_to_cell(_) for _ in closure)\n    try:\n        raw_code = codecs.decode(code.encode(\'ascii\'), \'base64\')\n        code = marshal.loads(raw_code)\n    except (UnicodeEncodeError, binascii.Error, ValueError):\n        # backwards compatibility for models serialized prior to 2.1.2\n        raw_code = code.encode(\'raw_unicode_escape\')\n        code = marshal.loads(raw_code)\n    if globs is None:\n        globs = globals()\n    return python_types.FunctionType(code, globs,\n                                     name=code.co_name,\n                                     argdefs=defaults,\n                                     closure=closure)\n\n\ndef getargspec(fn):\n    """"""Python 2/3 compatible `getargspec`.\n\n    Calls `getfullargspec` and assigns args, varargs,\n    varkw, and defaults to a python 2/3 compatible `ArgSpec`.\n    The parameter name \'varkw\' is changed to \'keywords\' to fit the\n    `ArgSpec` struct.\n\n    # Arguments\n        fn: the target function to inspect.\n\n    # Returns\n        An ArgSpec with args, varargs, keywords, and defaults parameters\n        from FullArgSpec.\n    """"""\n    if sys.version_info < (3,):\n        arg_spec = inspect.getargspec(fn)\n    else:\n        full_arg_spec = inspect.getfullargspec(fn)\n        arg_spec = inspect.ArgSpec(\n            args=full_arg_spec.args,\n            varargs=full_arg_spec.varargs,\n            keywords=full_arg_spec.varkw,\n            defaults=full_arg_spec.defaults)\n    return arg_spec\n\n\ndef has_arg(fn, name, accept_all=False):\n    """"""Checks if a callable accepts a given keyword argument.\n\n    For Python 2, checks if there is an argument with the given name.\n\n    For Python 3, checks if there is an argument with the given name, and\n    also whether this argument can be called with a keyword (i.e. if it is\n    not a positional-only argument).\n\n    # Arguments\n        fn: Callable to inspect.\n        name: Check if `fn` can be called with `name` as a keyword argument.\n        accept_all: What to return if there is no parameter called `name`\n                    but the function accepts a `**kwargs` argument.\n\n    # Returns\n        bool, whether `fn` accepts a `name` keyword argument.\n    """"""\n    if sys.version_info < (3,):\n        arg_spec = inspect.getargspec(fn)\n        if accept_all and arg_spec.keywords is not None:\n            return True\n        return (name in arg_spec.args)\n    elif sys.version_info < (3, 3):\n        arg_spec = inspect.getfullargspec(fn)\n        if accept_all and arg_spec.varkw is not None:\n            return True\n        return (name in arg_spec.args or\n                name in arg_spec.kwonlyargs)\n    else:\n        signature = inspect.signature(fn)\n        parameter = signature.parameters.get(name)\n        if parameter is None:\n            if accept_all:\n                for param in signature.parameters.values():\n                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n                        return True\n            return False\n        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                   inspect.Parameter.KEYWORD_ONLY))\n\n\nclass Progbar(object):\n    """"""Displays a progress bar.\n\n    # Arguments\n        target: Total number of steps expected, None if unknown.\n        width: Progress bar width on screen.\n        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n        stateful_metrics: Iterable of string names of metrics that\n            should *not* be averaged over time. Metrics in this list\n            will be displayed as-is. All others will be averaged\n            by the progbar before display.\n        interval: Minimum visual progress update interval (in seconds).\n    """"""\n\n    def __init__(self, target, width=30, verbose=1, interval=0.05,\n                 stateful_metrics=None):\n        self.target = target\n        self.width = width\n        self.verbose = verbose\n        self.interval = interval\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n        self._dynamic_display = ((hasattr(sys.stdout, \'isatty\') and\n                                  sys.stdout.isatty()) or\n                                 \'ipykernel\' in sys.modules)\n        self._total_width = 0\n        self._seen_so_far = 0\n        self._values = collections.OrderedDict()\n        self._start = time.time()\n        self._last_update = 0\n\n    def update(self, current, values=None):\n        """"""Updates the progress bar.\n\n        # Arguments\n            current: Index of current step.\n            values: List of tuples:\n                `(name, value_for_last_step)`.\n                If `name` is in `stateful_metrics`,\n                `value_for_last_step` will be displayed as-is.\n                Else, an average of the metric over time will be displayed.\n        """"""\n        values = values or []\n        for k, v in values:\n            if k not in self.stateful_metrics:\n                if k not in self._values:\n                    self._values[k] = [v * (current - self._seen_so_far),\n                                       current - self._seen_so_far]\n                else:\n                    self._values[k][0] += v * (current - self._seen_so_far)\n                    self._values[k][1] += (current - self._seen_so_far)\n            else:\n                # Stateful metrics output a numeric value.  This representation\n                # means ""take an average from a single value"" but keeps the\n                # numeric formatting.\n                self._values[k] = [v, 1]\n        self._seen_so_far = current\n\n        now = time.time()\n        info = \' - %.0fs\' % (now - self._start)\n        if self.verbose == 1:\n            if (now - self._last_update < self.interval and\n                    self.target is not None and current < self.target):\n                return\n\n            prev_total_width = self._total_width\n            if self._dynamic_display:\n                sys.stdout.write(\'\\b\' * prev_total_width)\n                sys.stdout.write(\'\\r\')\n            else:\n                sys.stdout.write(\'\\n\')\n\n            if self.target is not None:\n                numdigits = int(np.floor(np.log10(self.target))) + 1\n                barstr = \'%%%dd/%d [\' % (numdigits, self.target)\n                bar = barstr % current\n                prog = float(current) / self.target\n                prog_width = int(self.width * prog)\n                if prog_width > 0:\n                    bar += (\'=\' * (prog_width - 1))\n                    if current < self.target:\n                        bar += \'>\'\n                    else:\n                        bar += \'=\'\n                bar += (\'.\' * (self.width - prog_width))\n                bar += \']\'\n            else:\n                bar = \'%7d/Unknown\' % current\n\n            self._total_width = len(bar)\n            sys.stdout.write(bar)\n\n            if current:\n                time_per_unit = (now - self._start) / current\n            else:\n                time_per_unit = 0\n            if self.target is not None and current < self.target:\n                eta = time_per_unit * (self.target - current)\n                if eta > 3600:\n                    eta_format = (\'%d:%02d:%02d\' %\n                                  (eta // 3600, (eta % 3600) // 60, eta % 60))\n                elif eta > 60:\n                    eta_format = \'%d:%02d\' % (eta // 60, eta % 60)\n                else:\n                    eta_format = \'%ds\' % eta\n\n                info = \' - ETA: %s\' % eta_format\n            else:\n                if time_per_unit >= 1:\n                    info += \' %.0fs/step\' % time_per_unit\n                elif time_per_unit >= 1e-3:\n                    info += \' %.0fms/step\' % (time_per_unit * 1e3)\n                else:\n                    info += \' %.0fus/step\' % (time_per_unit * 1e6)\n\n            for k in self._values:\n                info += \' - %s:\' % k\n                if isinstance(self._values[k], list):\n                    avg = np.mean(\n                        self._values[k][0] / max(1, self._values[k][1]))\n                    if abs(avg) > 1e-3:\n                        info += \' %.4f\' % avg\n                    else:\n                        info += \' %.4e\' % avg\n                else:\n                    info += \' %s\' % self._values[k]\n\n            self._total_width += len(info)\n            if prev_total_width > self._total_width:\n                info += (\' \' * (prev_total_width - self._total_width))\n\n            if self.target is not None and current >= self.target:\n                info += \'\\n\'\n\n            sys.stdout.write(info)\n            sys.stdout.flush()\n\n        elif self.verbose == 2:\n            if self.target is None or current >= self.target:\n                for k in self._values:\n                    info += \' - %s:\' % k\n                    avg = np.mean(\n                        self._values[k][0] / max(1, self._values[k][1]))\n                    if avg > 1e-3:\n                        info += \' %.4f\' % avg\n                    else:\n                        info += \' %.4e\' % avg\n                info += \'\\n\'\n\n                sys.stdout.write(info)\n                sys.stdout.flush()\n\n        self._last_update = now\n\n    def add(self, n, values=None):\n        self.update(self._seen_so_far + n, values)\n\n\ndef to_list(x, allow_tuple=False):\n    """"""Normalizes a list/tensor into a list.\n\n    If a tensor is passed, we return\n    a list of size 1 containing the tensor.\n\n    # Arguments\n        x: target object to be normalized.\n        allow_tuple: If False and x is a tuple,\n            it will be converted into a list\n            with a single element (the tuple).\n            Else converts the tuple to a list.\n\n    # Returns\n        A list.\n    """"""\n    if isinstance(x, list):\n        return x\n    if allow_tuple and isinstance(x, tuple):\n        return list(x)\n    return [x]\n\n\ndef unpack_singleton(x):\n    """"""Gets the first element if the iterable has only one value.\n\n    Otherwise return the iterable.\n\n    # Argument\n        x: A list or tuple.\n\n    # Returns\n        The same iterable or the first element.\n    """"""\n    if len(x) == 1:\n        return x[0]\n    return x\n\n\ndef object_list_uid(object_list):\n    object_list = to_list(object_list)\n    return \', \'.join((str(abs(id(x))) for x in object_list))\n\n\ndef is_all_none(iterable_or_element):\n    iterable = to_list(iterable_or_element, allow_tuple=True)\n    for element in iterable:\n        if element is not None:\n            return False\n    return True\n\n\ndef slice_arrays(arrays, start=None, stop=None):\n    """"""Slices an array or list of arrays.\n\n    This takes an array-like, or a list of\n    array-likes, and outputs:\n        - arrays[start:stop] if `arrays` is an array-like\n        - [x[start:stop] for x in arrays] if `arrays` is a list\n\n    Can also work on list/array of indices: `_slice_arrays(x, indices)`\n\n    # Arguments\n        arrays: Single array or list of arrays.\n        start: can be an integer index (start index)\n            or a list/array of indices\n        stop: integer (stop index); should be None if\n            `start` was a list.\n\n    # Returns\n        A slice of the array(s).\n    """"""\n    if arrays is None:\n        return [None]\n    elif isinstance(arrays, list):\n        if hasattr(start, \'__len__\'):\n            # hdf5 datasets only support list objects as indices\n            if hasattr(start, \'shape\'):\n                start = start.tolist()\n            return [None if x is None else x[start] for x in arrays]\n        else:\n            return [None if x is None else x[start:stop] for x in arrays]\n    else:\n        if hasattr(start, \'__len__\'):\n            if hasattr(start, \'shape\'):\n                start = start.tolist()\n            return arrays[start]\n        elif hasattr(start, \'__getitem__\'):\n            return arrays[start:stop]\n        else:\n            return [None]\n\n\ndef transpose_shape(shape, target_format, spatial_axes):\n    """"""Converts a tuple or a list to the correct `data_format`.\n\n    It does so by switching the positions of its elements.\n\n    # Arguments\n        shape: Tuple or list, often representing shape,\n            corresponding to `\'channels_last\'`.\n        target_format: A string, either `\'channels_first\'` or `\'channels_last\'`.\n        spatial_axes: A tuple of integers.\n            Correspond to the indexes of the spatial axes.\n            For example, if you pass a shape\n            representing (batch_size, timesteps, rows, cols, channels),\n            then `spatial_axes=(2, 3)`.\n\n    # Returns\n        A tuple or list, with the elements permuted according\n        to `target_format`.\n\n    # Example\n    ```python\n        >>> from keras.utils.generic_utils import transpose_shape\n        >>> transpose_shape((16, 128, 128, 32),\'channels_first\', spatial_axes=(1, 2))\n        (16, 32, 128, 128)\n        >>> transpose_shape((16, 128, 128, 32), \'channels_last\', spatial_axes=(1, 2))\n        (16, 128, 128, 32)\n        >>> transpose_shape((128, 128, 32), \'channels_first\', spatial_axes=(0, 1))\n        (32, 128, 128)\n    ```\n\n    # Raises\n        ValueError: if `value` or the global `data_format` invalid.\n    """"""\n    if target_format == \'channels_first\':\n        new_values = shape[:spatial_axes[0]]\n        new_values += (shape[-1],)\n        new_values += tuple(shape[x] for x in spatial_axes)\n\n        if isinstance(shape, list):\n            return list(new_values)\n        return new_values\n    elif target_format == \'channels_last\':\n        return shape\n    else:\n        raise ValueError(\'The `data_format` argument must be one of \'\n                         \'""channels_first"", ""channels_last"". Received: \' +\n                         str(target_format))\n\n\ndef check_for_unexpected_keys(name, input_dict, expected_values):\n    unknown = set(input_dict.keys()).difference(expected_values)\n    if unknown:\n        raise ValueError(\'Unknown entries in {} dictionary: {}. Only expected \'\n                         \'following keys: {}\'.format(name, list(unknown),\n                                                     expected_values))\n'"
keras/utils/io_utils.py,0,"b'""""""Utilities related to disk I/O.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom collections import defaultdict\nimport sys\nimport contextlib\n\n\nimport six\ntry:\n    import h5py\n    HDF5_OBJECT_HEADER_LIMIT = 64512\nexcept ImportError:\n    h5py = None\n\n\nif sys.version_info[0] == 3:\n    import pickle\nelse:\n    import cPickle as pickle\n\n\nclass HDF5Matrix(object):\n    """"""Representation of HDF5 dataset to be used instead of a NumPy array.\n\n    # Example\n\n    ```python\n        x_data = HDF5Matrix(\'input/file.hdf5\', \'data\')\n        model.predict(x_data)\n    ```\n\n    Providing `start` and `end` allows use of a slice of the dataset.\n\n    Optionally, a normalizer function (or lambda) can be given. This will\n    be called on every slice of data retrieved.\n\n    # Arguments\n        datapath: string, path to a HDF5 file\n        dataset: string, name of the HDF5 dataset in the file specified\n            in datapath\n        start: int, start of desired slice of the specified dataset\n        end: int, end of desired slice of the specified dataset\n        normalizer: function to be called on data when retrieved\n\n    # Returns\n        An array-like HDF5 dataset.\n    """"""\n    refs = defaultdict(int)\n\n    def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):\n        if h5py is None:\n            raise ImportError(\'The use of HDF5Matrix requires \'\n                              \'HDF5 and h5py installed.\')\n\n        if datapath not in list(self.refs.keys()):\n            f = h5py.File(datapath)\n            self.refs[datapath] = f\n        else:\n            f = self.refs[datapath]\n        self.data = f[dataset]\n        self.start = start\n        if end is None:\n            self.end = self.data.shape[0]\n        else:\n            self.end = end\n        self.normalizer = normalizer\n        if self.normalizer is not None:\n            first_val = self.normalizer(self.data[0:1])\n        else:\n            first_val = self.data[0:1]\n        self._base_shape = first_val.shape[1:]\n        self._base_dtype = first_val.dtype\n\n    def __len__(self):\n        return self.end - self.start\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            start, stop = key.start, key.stop\n            if start is None:\n                start = 0\n            if stop is None:\n                stop = self.shape[0]\n            if stop + self.start <= self.end:\n                idx = slice(start + self.start, stop + self.start)\n            else:\n                raise IndexError\n        elif isinstance(key, (int, np.integer)):\n            if key + self.start < self.end:\n                idx = key + self.start\n            else:\n                raise IndexError\n        elif isinstance(key, np.ndarray):\n            if np.max(key) + self.start < self.end:\n                idx = (self.start + key).tolist()\n            else:\n                raise IndexError\n        else:\n            # Assume list/iterable\n            if max(key) + self.start < self.end:\n                idx = [x + self.start for x in key]\n            else:\n                raise IndexError\n        if self.normalizer is not None:\n            return self.normalizer(self.data[idx])\n        else:\n            return self.data[idx]\n\n    @property\n    def shape(self):\n        """"""Gets a numpy-style shape tuple giving the dataset dimensions.\n\n        # Returns\n            A numpy-style shape tuple.\n        """"""\n        return (self.end - self.start,) + self._base_shape\n\n    @property\n    def dtype(self):\n        """"""Gets the datatype of the dataset.\n\n        # Returns\n            A numpy dtype string.\n        """"""\n        return self._base_dtype\n\n    @property\n    def ndim(self):\n        """"""Gets the number of dimensions (rank) of the dataset.\n\n        # Returns\n            An integer denoting the number of dimensions (rank) of the dataset.\n        """"""\n        return self.data.ndim\n\n    @property\n    def size(self):\n        """"""Gets the total dataset size (number of elements).\n\n        # Returns\n            An integer denoting the number of elements in the dataset.\n        """"""\n        return np.prod(self.shape)\n\n\ndef ask_to_proceed_with_overwrite(filepath):\n    """"""Produces a prompt asking about overwriting a file.\n\n    # Arguments\n        filepath: the path to the file to be overwritten.\n\n    # Returns\n        True if we can proceed with overwrite, False otherwise.\n    """"""\n    overwrite = six.moves.input(\'[WARNING] %s already exists - overwrite? \'\n                                \'[y/n]\' % (filepath)).strip().lower()\n    while overwrite not in (\'y\', \'n\'):\n        overwrite = six.moves.input(\'Enter ""y"" (overwrite) or ""n"" \'\n                                    \'(cancel).\').strip().lower()\n    if overwrite == \'n\':\n        return False\n    print(\'[TIP] Next time specify overwrite=True!\')\n    return True\n\n\nclass H5Dict(object):\n    """""" A dict-like wrapper around h5py groups (or dicts).\n\n    This allows us to have a single serialization logic\n    for both pickling and saving to disk.\n\n    Note: This is not intended to be a generic wrapper.\n    There are lot of edge cases which have been hardcoded,\n    and makes sense only in the context of model serialization/\n    deserialization.\n\n    # Arguments\n        path: Either a string (path on disk), a Path, a dict, or a HDF5 Group.\n        mode: File open mode (one of `{""a"", ""r"", ""w""}`).\n    """"""\n\n    def __init__(self, path, mode=\'a\'):\n        if isinstance(path, h5py.Group):\n            self.data = path\n            self._is_file = False\n        elif isinstance(path, six.string_types) or _is_path_instance(path):\n            self.data = h5py.File(path, mode=mode)\n            self._is_file = True\n        elif isinstance(path, dict):\n            self.data = path\n            self._is_file = False\n            if mode == \'w\':\n                self.data.clear()\n            # Flag to check if a dict is user defined data or a sub group:\n            self.data[\'_is_group\'] = True\n        else:\n            raise TypeError(\'Required Group, str, Path or dict. \'\n                            \'Received: {}.\'.format(type(path)))\n        self.read_only = mode == \'r\'\n\n    @staticmethod\n    def is_supported_type(path):\n        """"""Check if `path` is of supported type for instantiating a `H5Dict`""""""\n        return (\n            isinstance(path, h5py.Group) or\n            isinstance(path, dict) or\n            isinstance(path, six.string_types) or\n            _is_path_instance(path)\n        )\n\n    def __setitem__(self, attr, val):\n        if self.read_only:\n            raise ValueError(\'Cannot set item in read-only mode.\')\n        is_np = type(val).__module__ == np.__name__\n        if isinstance(self.data, dict):\n            if isinstance(attr, bytes):\n                attr = attr.decode(\'utf-8\')\n            if is_np:\n                self.data[attr] = pickle.dumps(val)\n                # We have to remember to unpickle in __getitem__\n                self.data[\'_{}_pickled\'.format(attr)] = True\n            else:\n                self.data[attr] = val\n            return\n        if isinstance(self.data, h5py.Group) and attr in self.data:\n            raise KeyError(\'Cannot set attribute. \'\n                           \'Group with name ""{}"" exists.\'.format(attr))\n        if is_np:\n            dataset = self.data.create_dataset(attr, val.shape, dtype=val.dtype)\n            if not val.shape:\n                # scalar\n                dataset[()] = val\n            else:\n                dataset[:] = val\n        elif isinstance(val, (list, tuple)):\n            # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n            # because in that case even chunking the array would not make the saving\n            # possible.\n            bad_attributes = [x for x in val if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n\n            # Expecting this to never be true.\n            if bad_attributes:\n                raise RuntimeError(\'The following attributes cannot be saved to \'\n                                   \'HDF5 file because they are larger than \'\n                                   \'%d bytes: %s\' % (HDF5_OBJECT_HEADER_LIMIT,\n                                                     \', \'.join(bad_attributes)))\n\n            if (val and sys.version_info[0] == 3 and isinstance(\n                    val[0], six.string_types)):\n                # convert to bytes\n                val = [x.encode(\'utf-8\') for x in val]\n\n            data_npy = np.asarray(val)\n\n            num_chunks = 1\n            chunked_data = np.array_split(data_npy, num_chunks)\n\n            # This will never loop forever thanks to the test above.\n            is_too_big = lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT\n            while any(map(is_too_big, chunked_data)):\n                num_chunks += 1\n                chunked_data = np.array_split(data_npy, num_chunks)\n\n            if num_chunks > 1:\n                for chunk_id, chunk_data in enumerate(chunked_data):\n                    self.data.attrs[\'%s%d\' % (attr, chunk_id)] = chunk_data\n            else:\n                self.data.attrs[attr] = val\n        else:\n            self.data.attrs[attr] = val\n\n    def __getitem__(self, attr):\n        if isinstance(self.data, dict):\n            if isinstance(attr, bytes):\n                attr = attr.decode(\'utf-8\')\n            if attr in self.data:\n                val = self.data[attr]\n                if isinstance(val, dict) and val.get(\'_is_group\'):\n                    val = H5Dict(val)\n                elif \'_{}_pickled\'.format(attr) in self.data:\n                    val = pickle.loads(val)\n                return val\n            else:\n                if self.read_only:\n                    raise ValueError(\'Cannot create group in read-only mode.\')\n                val = {\'_is_group\': True}\n                self.data[attr] = val\n                return H5Dict(val)\n        if attr in self.data.attrs:\n            val = self.data.attrs[attr]\n            if type(val).__module__ == np.__name__:\n                if val.dtype.type == np.string_:\n                    val = val.tolist()\n        elif attr in self.data:\n            val = self.data[attr]\n            if isinstance(val, h5py.Dataset):\n                val = np.asarray(val)\n            else:\n                val = H5Dict(val)\n        else:\n            # could be chunked\n            chunk_attr = \'%s%d\' % (attr, 0)\n            is_chunked = chunk_attr in self.data.attrs\n            if is_chunked:\n                val = []\n                chunk_id = 0\n                while chunk_attr in self.data.attrs:\n                    chunk = self.data.attrs[chunk_attr]\n                    val.extend([x.decode(\'utf8\') for x in chunk])\n                    chunk_id += 1\n                    chunk_attr = \'%s%d\' % (attr, chunk_id)\n            else:\n                if self.read_only:\n                    raise ValueError(\'Cannot create group in read-only mode.\')\n                val = H5Dict(self.data.create_group(attr))\n        return val\n\n    def __len__(self):\n        return len(self.data)\n\n    def __iter__(self):\n        return iter(self.data)\n\n    def iter(self):\n        return iter(self.data)\n\n    def __getattr__(self, attr):\n\n        def wrapper(f):\n            def h5wrapper(*args, **kwargs):\n                out = f(*args, **kwargs)\n                if isinstance(self.data, type(out)):\n                    return H5Dict(out)\n                else:\n                    return out\n            return h5wrapper\n\n        return wrapper(getattr(self.data, attr))\n\n    def close(self):\n        if isinstance(self.data, h5py.Group):\n            self.data.file.flush()\n            if self._is_file:\n                self.data.close()\n\n    def update(self, *args):\n        if isinstance(self.data, dict):\n            self.data.update(*args)\n        raise NotImplementedError\n\n    def __contains__(self, key):\n        if isinstance(self.data, dict):\n            return key in self.data\n        else:\n            return (key in self.data) or (key in self.data.attrs)\n\n    def get(self, key, default=None):\n        if key in self:\n            return self[key]\n        return default\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n\n\nh5dict = H5Dict\n\n\ndef load_from_binary_h5py(load_function, stream):\n    """"""Calls `load_function` on a `h5py.File` read from the binary `stream`.\n\n    # Arguments\n        load_function: A function that takes a `h5py.File`, reads from it, and\n            returns any object.\n        stream: Any file-like object implementing the method `read` that returns\n            `bytes` data (e.g. `io.BytesIO`) that represents a valid h5py file image.\n\n    # Returns\n        The object returned by `load_function`.\n    """"""\n    # Implementation based on suggestion solution here:\n    #   https://github.com/keras-team/keras/issues/9343#issuecomment-440903847\n    binary_data = stream.read()\n    file_access_property_list = h5py.h5p.create(h5py.h5p.FILE_ACCESS)\n    file_access_property_list.set_fapl_core(backing_store=False)\n    file_access_property_list.set_file_image(binary_data)\n    file_id_args = {\'fapl\': file_access_property_list,\n                    \'flags\': h5py.h5f.ACC_RDONLY,\n                    \'name\': b\'in-memory-h5py\'}  # name does not matter\n    h5_file_args = {\'backing_store\': False,\n                    \'driver\': \'core\',\n                    \'mode\': \'r\'}\n    with contextlib.closing(h5py.h5f.open(**file_id_args)) as file_id:\n        with h5py.File(file_id, **h5_file_args) as h5_file:\n            return load_function(h5_file)\n\n\ndef save_to_binary_h5py(save_function, stream):\n    """"""Calls `save_function` on an in memory `h5py.File`.\n\n    The file is subsequently written to the binary `stream`.\n\n     # Arguments\n        save_function: A function that takes a `h5py.File`, writes to it and\n            (optionally) returns any object.\n        stream: Any file-like object implementing the method `write` that accepts\n            `bytes` data (e.g. `io.BytesIO`).\n     """"""\n    with h5py.File(\'in-memory-h5py\', driver=\'core\', backing_store=False) as h5file:\n        # note that filename does not matter here.\n        return_value = save_function(h5file)\n        h5file.flush()\n        binary_data = h5file.fid.get_file_image()\n    stream.write(binary_data)\n\n    return return_value\n\n\ndef _is_path_instance(path):\n    # We can\'t use isinstance here because it would require\n    # us to add pathlib2 to the Python 2 dependencies.\n    class_name = type(path).__name__\n    return class_name == \'PosixPath\' or class_name == \'WindowsPath\'\n'"
keras/utils/layer_utils.py,0,"b'""""""Utilities related to layer/model functionality.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .conv_utils import convert_kernel\nfrom .. import backend as K\nimport numpy as np\n\n\ndef count_params(weights):\n    """"""Count the total number of scalars composing the weights.\n\n    # Arguments\n        weights: An iterable containing the weights on which to compute params\n\n    # Returns\n        The total number of scalars composing the weights\n    """"""\n    weight_ids = set()\n    total = 0\n    for w in weights:\n        if id(w) not in weight_ids:\n            weight_ids.add(id(w))\n            total += int(K.count_params(w))\n    return total\n\n\ndef print_summary(model, line_length=None, positions=None, print_fn=None):\n    """"""Prints a summary of a model.\n\n    # Arguments\n        model: Keras model instance.\n        line_length: Total length of printed lines\n            (e.g. set this to adapt the display to different\n            terminal window sizes).\n        positions: Relative or absolute positions of log elements in each line.\n            If not provided, defaults to `[.33, .55, .67, 1.]`.\n        print_fn: Print function to use.\n            It will be called on each line of the summary.\n            You can set it to a custom function\n            in order to capture the string summary.\n            It defaults to `print` (prints to stdout).\n    """"""\n    if print_fn is None:\n        print_fn = print\n\n    if model.__class__.__name__ == \'Sequential\':\n        sequential_like = True\n    elif not model._is_graph_network:\n        # We treat subclassed models as a simple sequence of layers,\n        # for logging purposes.\n        sequential_like = True\n    else:\n        sequential_like = True\n        nodes_by_depth = model._nodes_by_depth.values()\n        nodes = []\n        for v in nodes_by_depth:\n            if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n                # if the model has multiple nodes\n                # or if the nodes have multiple inbound_layers\n                # the model is no longer sequential\n                sequential_like = False\n                break\n            nodes += v\n        if sequential_like:\n            # search for shared layers\n            for layer in model.layers:\n                flag = False\n                for node in layer._inbound_nodes:\n                    if node in nodes:\n                        if flag:\n                            sequential_like = False\n                            break\n                        else:\n                            flag = True\n                if not sequential_like:\n                    break\n\n    if sequential_like:\n        line_length = line_length or 65\n        positions = positions or [.45, .85, 1.]\n        if positions[-1] <= 1:\n            positions = [int(line_length * p) for p in positions]\n        # header names for the different log elements\n        to_display = [\'Layer (type)\', \'Output Shape\', \'Param #\']\n    else:\n        line_length = line_length or 98\n        positions = positions or [.33, .55, .67, 1.]\n        if positions[-1] <= 1:\n            positions = [int(line_length * p) for p in positions]\n        # header names for the different log elements\n        to_display = [\'Layer (type)\',\n                      \'Output Shape\',\n                      \'Param #\',\n                      \'Connected to\']\n        relevant_nodes = []\n        for v in model._nodes_by_depth.values():\n            relevant_nodes += v\n\n    def print_row(fields, positions):\n        line = \'\'\n        for i in range(len(fields)):\n            if i > 0:\n                line = line[:-1] + \' \'\n            line += str(fields[i])\n            line = line[:positions[i]]\n            line += \' \' * (positions[i] - len(line))\n        print_fn(line)\n\n    print_fn(\'Model: ""{}""\'.format(model.name))\n    print_fn(\'_\' * line_length)\n    print_row(to_display, positions)\n    print_fn(\'=\' * line_length)\n\n    def print_layer_summary(layer):\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = \'multiple\'\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        fields = [name + \' (\' + cls_name + \')\',\n                  output_shape, layer.count_params()]\n        print_row(fields, positions)\n\n    def print_layer_summary_with_connections(layer):\n        """"""Prints a summary for a single layer.\n\n        # Arguments\n            layer: target layer.\n        """"""\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = \'multiple\'\n        connections = []\n        for node in layer._inbound_nodes:\n            if relevant_nodes and node not in relevant_nodes:\n                # node is not part of the current network\n                continue\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i].name\n                inbound_node_index = node.node_indices[i]\n                inbound_tensor_index = node.tensor_indices[i]\n                connections.append(inbound_layer +\n                                   \'[\' + str(inbound_node_index) + \'][\' +\n                                   str(inbound_tensor_index) + \']\')\n\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        if not connections:\n            first_connection = \'\'\n        else:\n            first_connection = connections[0]\n        fields = [name +\n                  \' (\' + cls_name + \')\',\n                  output_shape,\n                  layer.count_params(),\n                  first_connection]\n        print_row(fields, positions)\n        if len(connections) > 1:\n            for i in range(1, len(connections)):\n                fields = [\'\', \'\', \'\', connections[i]]\n                print_row(fields, positions)\n\n    layers = model.layers\n    for i in range(len(layers)):\n        if sequential_like:\n            print_layer_summary(layers[i])\n        else:\n            print_layer_summary_with_connections(layers[i])\n        if i == len(layers) - 1:\n            print_fn(\'=\' * line_length)\n        else:\n            print_fn(\'_\' * line_length)\n\n    model._check_trainable_weights_consistency()\n    if hasattr(model, \'_collected_trainable_weights\'):\n        trainable_count = count_params(model._collected_trainable_weights)\n    else:\n        trainable_count = count_params(model.trainable_weights)\n\n    non_trainable_count = count_params(model.non_trainable_weights)\n\n    print_fn(\n        \'Total params: {:,}\'.format(trainable_count + non_trainable_count))\n    print_fn(\'Trainable params: {:,}\'.format(trainable_count))\n    print_fn(\'Non-trainable params: {:,}\'.format(non_trainable_count))\n    print_fn(\'_\' * line_length)\n\n\ndef convert_all_kernels_in_model(model):\n    """"""Converts all convolution kernels in a model from Theano to TensorFlow.\n\n    Also works from TensorFlow to Theano.\n\n    # Arguments\n        model: target model for the conversion.\n    """"""\n    # Note: SeparableConvolution not included\n    # since only supported by TF.\n    conv_classes = {\n        \'Conv1D\',\n        \'Conv2D\',\n        \'Conv3D\',\n        \'Conv2DTranspose\',\n    }\n    to_assign = []\n    for layer in model.layers:\n        if layer.__class__.__name__ in conv_classes:\n            original_kernel = K.get_value(layer.kernel)\n            converted_kernel = convert_kernel(original_kernel)\n            to_assign.append((layer.kernel, converted_kernel))\n    K.batch_set_value(to_assign)\n\n\ndef convert_dense_weights_data_format(dense,\n                                      previous_feature_map_shape,\n                                      target_data_format=\'channels_first\'):\n    """"""Utility useful when changing a convnet\'s `data_format`.\n\n    When porting the weights of a convnet from one data format to the other,\n    if the convnet includes a `Flatten` layer\n    (applied to the last convolutional feature map)\n    followed by a `Dense` layer, the weights of that `Dense` layer\n    should be updated to reflect the new dimension ordering.\n\n    # Arguments\n        dense: The target `Dense` layer.\n        previous_feature_map_shape: A shape tuple of 3 integers,\n            e.g. `(512, 7, 7)`. The shape of the convolutional\n            feature map right before the `Flatten` layer that\n            came before the target `Dense` layer.\n        target_data_format: One of ""channels_last"", ""channels_first"".\n            Set it ""channels_last""\n            if converting a ""channels_first"" model to ""channels_last"",\n            or reciprocally.\n    """"""\n    assert target_data_format in {\'channels_last\', \'channels_first\'}\n    kernel, bias = dense.get_weights()\n    for i in range(kernel.shape[1]):\n        if target_data_format == \'channels_first\':\n            c, h, w = previous_feature_map_shape\n            original_fm_shape = (h, w, c)\n            ki = kernel[:, i].reshape(original_fm_shape)\n            ki = np.transpose(ki, (2, 0, 1))  # last -> first\n        else:\n            h, w, c = previous_feature_map_shape\n            original_fm_shape = (c, h, w)\n            ki = kernel[:, i].reshape(original_fm_shape)\n            ki = np.transpose(ki, (1, 2, 0))  # first -> last\n        kernel[:, i] = np.reshape(ki, (np.prod(previous_feature_map_shape),))\n    dense.set_weights([kernel, bias])\n\n\ndef get_source_inputs(tensor, layer=None, node_index=None):\n    """"""Returns the list of input tensors necessary to compute `tensor`.\n\n    Output will always be a list of tensors\n    (potentially with 1 element).\n\n    # Arguments\n        tensor: The tensor to start from.\n        layer: Origin layer of the tensor. Will be\n            determined via tensor._keras_history if not provided.\n        node_index: Origin node index of the tensor.\n\n    # Returns\n        List of input tensors.\n    """"""\n    if not hasattr(tensor, \'_keras_history\'):\n        return tensor\n\n    if layer is None or node_index:\n        layer, node_index, _ = tensor._keras_history\n    if not layer._inbound_nodes:\n        return [tensor]\n    else:\n        node = layer._inbound_nodes[node_index]\n        if not node.inbound_layers:\n            # Reached an Input layer, stop recursion.\n            return node.input_tensors\n        else:\n            source_tensors = []\n            source_tensors_ids = set()\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                previous_sources = get_source_inputs(x,\n                                                     layer,\n                                                     node_index)\n                # Avoid input redundancy.\n                for x in previous_sources:\n                    if id(x) not in source_tensors_ids:\n                        source_tensors.append(x)\n                        source_tensors_ids.add(id(x))\n            return source_tensors\n'"
keras/utils/losses_utils.py,0,"b'""""""Utilities related to losses.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom .. import backend as K\n\n\nclass Reduction(object):\n    """"""Types of loss reduction.\n\n    Contains the following values:\n\n    * `NONE`: Un-reduced weighted losses with the same shape as input. When this\n        reduction type used with built-in Keras training loops like\n        `fit`/`evaluate`, the unreduced vector loss is passed to the optimizer but\n        the reported loss will be a scalar value.\n    * `SUM`: Scalar sum of weighted losses.\n    * `SUM_OVER_BATCH_SIZE`: Scalar `SUM` divided by number of elements in losses.\n    """"""\n\n    NONE = \'none\'\n    SUM = \'sum\'\n    SUM_OVER_BATCH_SIZE = \'sum_over_batch_size\'\n\n    @classmethod\n    def all(cls):\n        return (cls.NONE, cls.SUM, cls.SUM_OVER_BATCH_SIZE)\n\n    @classmethod\n    def validate(cls, key):\n        if key not in cls.all():\n            raise ValueError(\'Invalid Reduction Key %s.\' % key)\n\n\ndef squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n    """"""Squeeze or expand last dimension if needed.\n\n    1. Squeezes last dim of `y_pred` or `y_true` if their rank differs by 1.\n    2. Squeezes or expands last dim of `sample_weight` if its rank differs by 1\n    from the new rank of `y_pred`.\n    If `sample_weight` is scalar, it is kept scalar.\n\n    # Arguments\n        y_pred: Predicted values, a `Tensor` of arbitrary dimensions.\n        y_true: Optional label `Tensor` whose dimensions match `y_pred`.\n        sample_weight: Optional weight scalar or `Tensor` whose dimensions match\n            `y_pred`.\n\n    # Returns\n        Tuple of `y_pred`, `y_true` and `sample_weight`. Each of them possibly has\n        the last dimension squeezed, `sample_weight` could be extended by one\n        dimension.\n    """"""\n    if y_true is not None:\n        y_pred_rank = K.ndim(y_pred)\n        y_pred_shape = K.int_shape(y_pred)\n        y_true_rank = K.ndim(y_true)\n        y_true_shape = K.int_shape(y_true)\n\n        if (y_pred_rank - y_true_rank == 1) and (y_pred_shape[-1] == 1):\n            y_pred = K.squeeze(y_pred, -1)\n        elif (y_true_rank - y_pred_rank == 1) and (y_true_shape[-1] == 1):\n            y_true = K.squeeze(y_true, -1)\n\n    if sample_weight is None:\n        return y_pred, y_true\n\n    y_pred_rank = K.ndim(y_pred)\n    weights_rank = K.ndim(sample_weight)\n    if weights_rank != 0:\n        if y_pred_rank == 0 and weights_rank == 1:\n            y_pred = K.expand_dims(y_pred, -1)\n        elif weights_rank - y_pred_rank == 1:\n            sample_weight = K.squeeze(sample_weight, -1)\n        elif y_pred_rank - weights_rank == 1:\n            sample_weight = K.expand_dims(sample_weight, -1)\n    return y_pred, y_true, sample_weight\n\n\ndef _num_elements(losses):\n    """"""Computes the number of elements in `losses` tensor.""""""\n    with K.name_scope(\'num_elements\') as scope:\n        return K.cast(K.size(losses, name=scope), losses.dtype)\n\n\ndef reduce_weighted_loss(weighted_losses, reduction=Reduction.SUM_OVER_BATCH_SIZE):\n    """"""Reduces the individual weighted loss measurements.""""""\n    if reduction == Reduction.NONE:\n        loss = weighted_losses\n    else:\n        loss = K.sum(weighted_losses)\n        if reduction == Reduction.SUM_OVER_BATCH_SIZE:\n            loss = loss / _num_elements(weighted_losses)\n    return loss\n\n\ndef broadcast_weights(values, sample_weight):\n    # Broadcast weights if possible.\n    weights_shape = K.int_shape(sample_weight)\n    values_shape = K.int_shape(values)\n\n    if values_shape != weights_shape:\n        weights_rank = K.ndim(sample_weight)\n        values_rank = K.ndim(values)\n\n        # Raise error if ndim of weights is > values.\n        if weights_rank > values_rank:\n            raise ValueError(\n                \'Incompatible shapes: `values` {} vs `sample_weight` {}\'.format(\n                    values_shape, weights_shape))\n\n        # Expand dim of weights to match ndim of values, if required.\n        for i in range(weights_rank, values_rank):\n            sample_weight = K.expand_dims(sample_weight, axis=i)\n\n        if weights_shape is not None and values_shape is not None:\n            for i in range(weights_rank):\n                if (weights_shape[i] is not None and\n                    values_shape[i] is not None and\n                        weights_shape[i] != values_shape[i]):\n                    # Cannot be broadcasted.\n                    if weights_shape[i] != 1:\n                        raise ValueError(\n                            \'Incompatible shapes: `values` {} vs \'\n                            \'`sample_weight` {}\'.format(\n                                values_shape, weights_shape))\n                    sample_weight = K.repeat_elements(\n                        sample_weight, values_shape[i], axis=i)\n    return sample_weight\n\n\ndef compute_weighted_loss(losses,\n                          sample_weight=None,\n                          reduction=Reduction.SUM_OVER_BATCH_SIZE,\n                          name=None):\n    """"""Computes the weighted loss.\n\n    # Arguments\n        losses: `Tensor` of shape `[batch_size, d1, ... dN]`.\n        sample_weight: Optional `Tensor` whose rank is either 0, or the same rank as\n        `   losses`, or be broadcastable to `losses`.\n        reduction: (Optional) Type of Reduction to apply to loss.\n            Default value is `SUM_OVER_BATCH_SIZE`.\n        name: Optional name for the op.\n\n    # Raises\n        ValueError: If the shape of `sample_weight` is not compatible with `losses`.\n\n    # Returns\n        Weighted loss `Tensor` of the same type as `losses`. If `reduction` is\n            `NONE`, this has the same shape as `losses`; otherwise, it is scalar.\n    """"""\n    Reduction.validate(reduction)\n    if sample_weight is None:\n        sample_weight = 1.0\n    with K.name_scope(name or \'weighted_loss\'):\n        input_dtype = K.dtype(losses)\n        losses = K.cast(losses, K.floatx())\n        sample_weight = K.cast(sample_weight, K.floatx())\n\n        # Update dimensions of `sample_weight` to match with `losses` if possible.\n        losses, _, sample_weight = squeeze_or_expand_dimensions(\n            losses, None, sample_weight)\n\n        # Broadcast weights if possible.\n        sample_weight = broadcast_weights(losses, sample_weight)\n\n        # Apply weights to losses.\n        weighted_losses = sample_weight * losses\n\n        # Apply reduction function to the individual weighted losses.\n        loss = reduce_weighted_loss(weighted_losses, reduction)\n        # Convert the result back to the input type.\n        loss = K.cast(loss, input_dtype)\n        return loss\n'"
keras/utils/metrics_utils.py,1,"b'""""""Utilities related to metrics.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom enum import Enum\n\nfrom .. import backend as K\nfrom . import losses_utils\n\n\nNEG_INF = -1e10\n\n\nclass Reduction(object):\n    """"""Types of metrics reduction.\n\n    Contains the following values:\n    * `SUM`: Scalar sum of weighted values.\n    * `SUM_OVER_BATCH_SIZE`: Scalar `SUM` of weighted values divided by\n        number of elements in values.\n    * `WEIGHTED_MEAN`: Scalar sum of weighted values divided by sum of weights.\n    """"""\n\n    SUM = \'sum\'\n    SUM_OVER_BATCH_SIZE = \'sum_over_batch_size\'\n    WEIGHTED_MEAN = \'weighted_mean\'\n\n\ndef update_state_wrapper(update_state_fn):\n    """"""Decorator to wrap metric `update_state()` with `add_update()`.\n\n    # Arguments\n        update_state_fn: function that accumulates metric statistics.\n\n    # Returns\n        Decorated function that wraps `update_state_fn()` with `add_update()`.\n    """"""\n    def decorated(metric_obj, *args, **kwargs):\n        """"""Decorated function with `add_update()`.""""""\n\n        update_op = update_state_fn(*args, **kwargs)\n        metric_obj.add_update(update_op)\n        return update_op\n\n    return decorated\n\n\ndef result_wrapper(result_fn):\n    """"""Decorator to wrap metric `result()` with identity op.\n\n    Wrapping result in identity so that control dependency between\n    update_op from `update_state` and result works in case result returns\n    a tensor.\n\n    # Arguments\n        result_fn: function that computes the metric result.\n\n    # Returns\n        Decorated function that wraps `result()` with identity op.\n    """"""\n    def decorated(metric_obj, *args, **kwargs):\n        result_t = K.identity(result_fn(*args, **kwargs))\n        metric_obj._call_result = result_t\n        result_t._is_metric = True\n        return result_t\n\n    return decorated\n\n\ndef filter_top_k(x, k):\n    """"""Filters top-k values in the last dim of x and set the rest to NEG_INF.\n    Used for computing top-k prediction values in dense labels (which has the same\n    shape as predictions) for recall and precision top-k metrics.\n\n    # Arguments\n        x: tensor with any dimensions.\n        k: the number of values to keep.\n\n    # Returns\n        tensor with same shape and dtype as x.\n    """"""\n    import tensorflow as tf\n    _, top_k_idx = tf.nn.top_k(x, k, sorted=False)\n    top_k_mask = K.sum(\n        K.one_hot(top_k_idx, x.shape[-1]), axis=-2)\n    return x * top_k_mask + NEG_INF * (1 - top_k_mask)\n\n\ndef to_list(x):\n    if isinstance(x, list):\n        return x\n    return [x]\n\n\ndef assert_thresholds_range(thresholds):\n    if thresholds is not None:\n        invalid_thresholds = [t for t in thresholds if t is None or t < 0 or t > 1]\n    if invalid_thresholds:\n        raise ValueError(\n            \'Threshold values must be in [0, 1]. Invalid values: {}\'.format(\n                invalid_thresholds))\n\n\ndef parse_init_thresholds(thresholds, default_threshold=0.5):\n    if thresholds is not None:\n        assert_thresholds_range(to_list(thresholds))\n    thresholds = to_list(default_threshold if thresholds is None else thresholds)\n    return thresholds\n\n\nclass ConfusionMatrix(Enum):\n    TRUE_POSITIVES = \'tp\'\n    FALSE_POSITIVES = \'fp\'\n    TRUE_NEGATIVES = \'tn\'\n    FALSE_NEGATIVES = \'fn\'\n\n\nclass AUCCurve(Enum):\n    """"""Type of AUC Curve (ROC or PR).""""""\n    ROC = \'ROC\'\n    PR = \'PR\'\n\n    @staticmethod\n    def from_str(key):\n        if key in (\'pr\', \'PR\'):\n            return AUCCurve.PR\n        elif key in (\'roc\', \'ROC\'):\n            return AUCCurve.ROC\n        else:\n            raise ValueError(\'Invalid AUC curve value ""%s"".\' % key)\n\n\nclass AUCSummationMethod(Enum):\n    """"""Type of AUC summation method.\n\n    https://en.wikipedia.org/wiki/Riemann_sum)\n\n    Contains the following values:\n    * \'interpolation\': Applies mid-point summation scheme for `ROC` curve. For\n    `PR` curve, interpolates (true/false) positives but not the ratio that is\n    precision (see Davis & Goadrich 2006 for details).\n    * \'minoring\': Applies left summation for increasing intervals and right\n    summation for decreasing intervals.\n    * \'majoring\': Applies right summation for increasing intervals and left\n    summation for decreasing intervals.\n    """"""\n    INTERPOLATION = \'interpolation\'\n    MAJORING = \'majoring\'\n    MINORING = \'minoring\'\n\n    @staticmethod\n    def from_str(key):\n        if key in (\'interpolation\', \'Interpolation\'):\n            return AUCSummationMethod.INTERPOLATION\n        elif key in (\'majoring\', \'Majoring\'):\n            return AUCSummationMethod.MAJORING\n        elif key in (\'minoring\', \'Minoring\'):\n            return AUCSummationMethod.MINORING\n        else:\n            raise ValueError(\'Invalid AUC summation method value ""%s"".\' % key)\n\n\ndef weighted_assign_add(label, pred, weights, var):\n    # Logical and\n    label = K.expand_dims(label, 0)\n    pred = K.expand_dims(pred, 0)\n    are_different = K.concatenate([label, pred], axis=0)\n    label_and_pred = K.all(are_different, axis=0)\n\n    label_and_pred = K.cast(label_and_pred, dtype=K.floatx())\n    if weights is not None:\n        label_and_pred *= weights\n    return K.update_add(var, K.sum(label_and_pred, 1))\n\n\ndef update_confusion_matrix_variables(variables_to_update,\n                                      y_true,\n                                      y_pred,\n                                      thresholds=0.5,\n                                      top_k=None,\n                                      class_id=None,\n                                      sample_weight=None):\n    """"""Returns op to update the given confusion matrix variables.\n\n    For every pair of values in y_true and y_pred:\n\n    true_positive: y_true == True and y_pred > thresholds\n    false_negatives: y_true == True and y_pred <= thresholds\n    true_negatives: y_true == False and y_pred <= thresholds\n    false_positive: y_true == False and y_pred > thresholds\n\n    The results will be weighted and added together. When multiple thresholds are\n    provided, we will repeat the same for every threshold.\n\n    For estimation of these metrics over a stream of data, the function creates an\n    `update_op` operation that updates the given variables.\n\n    If `sample_weight` is `None`, weights default to 1.\n    Use weights of 0 to mask values.\n\n    # Arguments\n    variables_to_update: Dictionary with \'tp\', \'fn\', \'tn\', \'fp\' as valid keys\n      and corresponding variables to update as values.\n    y_true: A `Tensor` whose shape matches `y_pred`. Will be cast to `bool`.\n    y_pred: A floating point `Tensor` of arbitrary shape and whose values are in\n      the range `[0, 1]`.\n    thresholds: A float value or a python list or tuple of float thresholds in\n      `[0, 1]`, or NEG_INF (used when top_k is set).\n    top_k: Optional int, indicates that the positive labels should be limited to\n      the top k predictions.\n    class_id: Optional int, limits the prediction and labels to the class\n      specified by this argument.\n    sample_weight: Optional `Tensor` whose rank is either 0, or the same rank as\n      `y_true`, and must be broadcastable to `y_true` (i.e., all dimensions must\n      be either `1`, or the same as the corresponding `y_true` dimension).\n\n    # Returns\n        Update ops.\n\n    # Raises\n        ValueError: If `y_pred` and `y_true` have mismatched shapes, or if\n            `sample_weight` is not `None` and its shape doesn\'t match `y_pred`, or if\n            `variables_to_update` contains invalid keys.\n    """"""\n    if variables_to_update is None:\n        return\n    y_true = K.cast(y_true, dtype=K.floatx())\n    y_pred = K.cast(y_pred, dtype=K.floatx())\n    if sample_weight is not None:\n        sample_weight = K.cast(sample_weight, dtype=K.floatx())\n\n    if not any(key\n               for key in variables_to_update\n               if key in list(ConfusionMatrix)):\n        raise ValueError(\n            \'Please provide at least one valid confusion matrix \'\n            \'variable to update. Valid variable key options are: ""{}"". \'\n            \'Received: ""{}""\'.format(\n                list(ConfusionMatrix), variables_to_update.keys()))\n\n    invalid_keys = [\n        key for key in variables_to_update if key not in list(ConfusionMatrix)\n    ]\n    if invalid_keys:\n        raise ValueError(\n            \'Invalid keys: {}. Valid variable key options are: ""{}""\'.format(\n                invalid_keys, list(ConfusionMatrix)))\n\n    if sample_weight is None:\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(\n            y_pred, y_true=y_true)\n    else:\n        y_pred, y_true, sample_weight = (\n            losses_utils.squeeze_or_expand_dimensions(\n                y_pred, y_true=y_true, sample_weight=sample_weight))\n\n    if top_k is not None:\n        y_pred = filter_top_k(y_pred, top_k)\n    if class_id is not None:\n        y_true = y_true[..., class_id]\n        y_pred = y_pred[..., class_id]\n\n    thresholds = to_list(thresholds)\n    num_thresholds = len(thresholds)\n    num_predictions = K.size(y_pred)\n\n    # Reshape predictions and labels.\n    predictions_2d = K.reshape(y_pred, [1, -1])\n    labels_2d = K.reshape(\n        K.cast(y_true, dtype=\'bool\'), [1, -1])\n\n    # Tile the thresholds for every prediction.\n    thresh_tiled = K.tile(\n        K.expand_dims(K.constant(thresholds), 1),\n        K.cast(\n            K.stack([1, num_predictions]),\n            dtype=\'int32\',\n        )\n    )\n\n    # Tile the predictions for every threshold.\n    preds_tiled = K.tile(predictions_2d, [num_thresholds, 1])\n\n    # Compare predictions and threshold.\n    pred_is_pos = K.greater(preds_tiled, thresh_tiled)\n\n    # Tile labels by number of thresholds\n    label_is_pos = K.tile(labels_2d, [num_thresholds, 1])\n\n    if sample_weight is not None:\n        weights = losses_utils.broadcast_weights(\n            y_pred, K.cast(sample_weight, dtype=K.floatx()))\n        weights_tiled = K.tile(\n            K.reshape(weights, [1, -1]), [num_thresholds, 1])\n    else:\n        weights_tiled = None\n\n    update_ops = []\n    loop_vars = {\n        ConfusionMatrix.TRUE_POSITIVES: (label_is_pos, pred_is_pos),\n    }\n    update_tn = ConfusionMatrix.TRUE_NEGATIVES in variables_to_update\n    update_fp = ConfusionMatrix.FALSE_POSITIVES in variables_to_update\n    update_fn = ConfusionMatrix.FALSE_NEGATIVES in variables_to_update\n\n    if update_fn or update_tn:\n        pred_is_neg = K.equal(\n            pred_is_pos, K.zeros_like(pred_is_pos, dtype=pred_is_pos.dtype))\n        loop_vars[ConfusionMatrix.FALSE_NEGATIVES] = (label_is_pos, pred_is_neg)\n\n    if update_fp or update_tn:\n        label_is_neg = K.equal(\n            label_is_pos, K.zeros_like(label_is_pos, dtype=label_is_pos.dtype))\n        loop_vars[ConfusionMatrix.FALSE_POSITIVES] = (label_is_neg, pred_is_pos)\n        if update_tn:\n            loop_vars[ConfusionMatrix.TRUE_NEGATIVES] = (label_is_neg, pred_is_neg)\n\n    for matrix_cond, (label, pred) in loop_vars.items():\n        if matrix_cond in variables_to_update:\n            update_ops.append(\n                weighted_assign_add(label, pred, weights_tiled,\n                                    variables_to_update[matrix_cond]))\n    return update_ops\n'"
keras/utils/multi_gpu_utils.py,6,"b'""""""Multi-GPU training utilities.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom ..layers.merge import concatenate\nfrom .. import backend as K\nfrom ..layers.core import Lambda\nfrom ..engine.training import Model\nfrom ..models import clone_model\nfrom ..utils.generic_utils import to_list\n\n\ndef _get_available_devices():\n    return K.tensorflow_backend._get_available_gpus() + [\'/cpu:0\']\n\n\ndef _normalize_device_name(name):\n    name = \'/\' + \':\'.join(name.lower().replace(\'/\', \'\').split(\':\')[-2:])\n    return name\n\n\ndef multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n    """"""Replicates a model on different GPUs.\n\n    Specifically, this function implements single-machine\n    multi-GPU data parallelism. It works in the following way:\n\n    - Divide the model\'s input(s) into multiple sub-batches.\n    - Apply a model copy on each sub-batch. Every model copy\n        is executed on a dedicated GPU.\n    - Concatenate the results (on CPU) into one big batch.\n\n    E.g. if your `batch_size` is 64 and you use `gpus=2`,\n    then we will divide the input into 2 sub-batches of 32 samples,\n    process each sub-batch on one GPU, then return the full\n    batch of 64 processed samples.\n\n    This induces quasi-linear speedup on up to 8 GPUs.\n\n    This function is only available with the TensorFlow backend\n    for the time being.\n\n    # Arguments\n        model: A Keras model instance. To avoid OOM errors,\n            this model could have been built on CPU, for instance\n            (see usage example below).\n        gpus: Integer >= 2 or list of integers, number of GPUs or\n            list of GPU IDs on which to create model replicas.\n        cpu_merge: A boolean value to identify whether to force\n            merging model weights under the scope of the CPU or not.\n        cpu_relocation: A boolean value to identify whether to\n            create the model\'s weights under the scope of the CPU.\n            If the model is not defined under any preceding device\n            scope, you can still rescue it by activating this option.\n\n    # Returns\n        A Keras `Model` instance which can be used just like the initial\n        `model` argument, but which distributes its workload on multiple GPUs.\n\n    # Examples\n\n    Example 1 - Training models with weights merge on CPU\n\n    ```python\n        import tensorflow as tf\n        from keras.applications import Xception\n        from keras.utils import multi_gpu_model\n        import numpy as np\n\n        num_samples = 1000\n        height = 224\n        width = 224\n        num_classes = 1000\n\n        # Instantiate the base model (or ""template"" model).\n        # We recommend doing this with under a CPU device scope,\n        # so that the model\'s weights are hosted on CPU memory.\n        # Otherwise they may end up hosted on a GPU, which would\n        # complicate weight sharing.\n        with tf.device(\'/cpu:0\'):\n            model = Xception(weights=None,\n                             input_shape=(height, width, 3),\n                             classes=num_classes)\n\n        # Replicates the model on 8 GPUs.\n        # This assumes that your machine has 8 available GPUs.\n        parallel_model = multi_gpu_model(model, gpus=8)\n        parallel_model.compile(loss=\'categorical_crossentropy\',\n                               optimizer=\'rmsprop\')\n\n        # Generate dummy data.\n        x = np.random.random((num_samples, height, width, 3))\n        y = np.random.random((num_samples, num_classes))\n\n        # This `fit` call will be distributed on 8 GPUs.\n        # Since the batch size is 256, each GPU will process 32 samples.\n        parallel_model.fit(x, y, epochs=20, batch_size=256)\n\n        # Save model via the template model (which shares the same weights):\n        model.save(\'my_model.h5\')\n    ```\n\n    Example 2 - Training models with weights merge on CPU using cpu_relocation\n\n    ```python\n         ..\n         # Not needed to change the device scope for model definition:\n         model = Xception(weights=None, ..)\n\n         try:\n             parallel_model = multi_gpu_model(model, cpu_relocation=True)\n             print(""Training using multiple GPUs.."")\n         except ValueError:\n             parallel_model = model\n             print(""Training using single GPU or CPU.."")\n         parallel_model.compile(..)\n         ..\n    ```\n\n    Example 3 - Training models with weights merge on GPU (recommended for NV-link)\n\n    ```python\n         ..\n         # Not needed to change the device scope for model definition:\n         model = Xception(weights=None, ..)\n\n         try:\n             parallel_model = multi_gpu_model(model, cpu_merge=False)\n             print(""Training using multiple GPUs.."")\n         except:\n             parallel_model = model\n             print(""Training using single GPU or CPU.."")\n\n         parallel_model.compile(..)\n         ..\n    ```\n\n    # On model saving\n\n    To save the multi-gpu model, use `.save(fname)` or `.save_weights(fname)`\n    with the template model (the argument you passed to `multi_gpu_model`),\n    rather than the model returned by `multi_gpu_model`.\n    """"""\n    if K.backend() != \'tensorflow\':\n        raise ValueError(\'`multi_gpu_model` is only available \'\n                         \'with the TensorFlow backend.\')\n\n    available_devices = _get_available_devices()\n    available_devices = [_normalize_device_name(name)\n                         for name in available_devices]\n    if not gpus:\n        # Using all visible GPUs when not specifying `gpus`\n        # e.g. CUDA_VISIBLE_DEVICES=0,2 python keras_mgpu.py\n        gpus = len((x for x in available_devices if \'/gpu:\' in x))\n\n    if isinstance(gpus, (list, tuple)):\n        if len(gpus) <= 1:\n            raise ValueError(\'For multi-gpu usage to be effective, \'\n                             \'call `multi_gpu_model` with `len(gpus) >= 2`. \'\n                             \'Received: `gpus=%s`\' % gpus)\n        num_gpus = len(gpus)\n        target_gpu_ids = gpus\n    else:\n        if gpus <= 1:\n            raise ValueError(\'For multi-gpu usage to be effective, \'\n                             \'call `multi_gpu_model` with `gpus >= 2`. \'\n                             \'Received: `gpus=%d`\' % gpus)\n        num_gpus = gpus\n        target_gpu_ids = range(num_gpus)\n\n    import tensorflow as tf\n\n    target_devices = [\'/cpu:0\'] + [\'/gpu:%d\' % i for i in target_gpu_ids]\n    for device in target_devices:\n        if device not in available_devices:\n            raise ValueError(\n                \'To call `multi_gpu_model` with `gpus=%s`, \'\n                \'we expect the following devices to be available: %s. \'\n                \'However this machine only has: %s. \'\n                \'Try reducing `gpus`.\' % (gpus,\n                                          target_devices,\n                                          available_devices))\n\n    def get_slice(data, i, parts):\n        shape = K.shape(data)\n        batch_size = shape[:1]\n        input_shape = shape[1:]\n        step = batch_size // parts\n        if i == parts - 1:\n            size = batch_size - step * i\n        else:\n            size = step\n        size = K.concatenate([size, input_shape], axis=0)\n        stride = K.concatenate([step, input_shape * 0], axis=0)\n        start = stride * i\n        return K.slice(data, start, size)\n\n    # Relocate the model definition under CPU device scope if needed\n    if cpu_relocation:\n        with tf.device(\'/cpu:0\'):\n            model = clone_model(model)\n\n    all_outputs = []\n    for i in range(len(model.outputs)):\n        all_outputs.append([])\n\n    # Place a copy of the model on each GPU,\n    # each getting a slice of the inputs.\n    for i, gpu_id in enumerate(target_gpu_ids):\n        with tf.device(\'/gpu:%d\' % gpu_id):\n            with tf.name_scope(\'replica_%d\' % gpu_id):\n                inputs = []\n                # Retrieve a slice of the input.\n                for x in model.inputs:\n                    # In-place input splitting which is not only\n                    # 5% ~ 12% faster but also less GPU memory\n                    # duplication.\n                    with tf.device(x.device):\n                        input_shape = K.int_shape(x)[1:]\n                        slice_i = Lambda(get_slice,\n                                         output_shape=input_shape,\n                                         arguments={\'i\': i,\n                                                    \'parts\': num_gpus})(x)\n                        inputs.append(slice_i)\n\n                # Apply model on slice\n                # (creating a model replica on the target device).\n                outputs = model(inputs)\n                outputs = to_list(outputs)\n\n                # Save the outputs for merging back together later.\n                for o in range(len(outputs)):\n                    all_outputs[o].append(outputs[o])\n\n    # Deduplicate output names to handle Siamese networks.\n    occurrences = {}\n    for n in model.output_names:\n        if n not in occurrences:\n            occurrences[n] = 1\n        else:\n            occurrences[n] += 1\n    conflict_counter = {n: 0 for n, count in occurrences.items() if count > 1}\n    output_names = []\n    for n in model.output_names:\n        if n in conflict_counter:\n            conflict_counter[n] += 1\n            n += \'_%d\' % conflict_counter[n]\n        output_names.append(n)\n\n    # Merge outputs under expected scope.\n    with tf.device(\'/cpu:0\' if cpu_merge else \'/gpu:%d\' % target_gpu_ids[0]):\n        merged = []\n        for name, outputs in zip(output_names, all_outputs):\n            merged.append(concatenate(outputs,\n                                      axis=0, name=name))\n        return Model(model.inputs, merged)\n'"
keras/utils/np_utils.py,0,"b'""""""Numpy-related utilities.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\n\ndef to_categorical(y, num_classes=None, dtype=\'float32\'):\n    """"""Converts a class vector (integers) to binary class matrix.\n\n    E.g. for use with categorical_crossentropy.\n\n    # Arguments\n        y: class vector to be converted into a matrix\n            (integers from 0 to num_classes).\n        num_classes: total number of classes.\n        dtype: The data type expected by the input, as a string\n            (`float32`, `float64`, `int32`...)\n\n    # Returns\n        A binary matrix representation of the input. The classes axis\n        is placed last.\n\n    # Example\n\n    ```python\n    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n    > labels\n    array([0, 2, 1, 2, 0])\n    # `to_categorical` converts this into a matrix with as many\n    # columns as there are classes. The number of rows\n    # stays the same.\n    > to_categorical(labels)\n    array([[ 1.,  0.,  0.],\n           [ 0.,  0.,  1.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  1.],\n           [ 1.,  0.,  0.]], dtype=float32)\n    ```\n    """"""\n\n    y = np.array(y, dtype=\'int\')\n    input_shape = y.shape\n    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n        input_shape = tuple(input_shape[:-1])\n    y = y.ravel()\n    if not num_classes:\n        num_classes = np.max(y) + 1\n    n = y.shape[0]\n    categorical = np.zeros((n, num_classes), dtype=dtype)\n    categorical[np.arange(n), y] = 1\n    output_shape = input_shape + (num_classes,)\n    categorical = np.reshape(categorical, output_shape)\n    return categorical\n\n\ndef normalize(x, axis=-1, order=2):\n    """"""Normalizes a NumPy array.\n\n    # Arguments\n        x: NumPy array to normalize.\n        axis: axis along which to normalize.\n        order: Normalization order (e.g. 2 for L2 norm).\n\n    # Returns\n        A normalized copy of the array.\n    """"""\n    l2 = np.atleast_1d(np.linalg.norm(x, order, axis))\n    l2[l2 == 0] = 1\n    return x / np.expand_dims(l2, axis)\n'"
keras/utils/test_utils.py,0,"b'""""""Utilities related to Keras unit tests.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom io import BytesIO\n\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom .generic_utils import has_arg\nfrom ..engine import Model, Input\nfrom .. import backend as K\n\ntry:\n    from tensorflow.python.lib.io import file_io as tf_file_io\nexcept ImportError:\n    tf_file_io = None\n\ntry:\n    from unittest.mock import patch, Mock, MagicMock\nexcept:\n    from mock import patch, Mock, MagicMock\n\n\ndef get_test_data(num_train=1000, num_test=500, input_shape=(10,),\n                  output_shape=(2,),\n                  classification=True, num_classes=2):\n    """"""Generates test data to train a model on.\n\n    classification=True overrides output_shape\n    (i.e. output_shape is set to (1,)) and the output\n    consists in integers in [0, num_classes-1].\n\n    Otherwise: float output with shape output_shape.\n    """"""\n    samples = num_train + num_test\n    if classification:\n        y = np.random.randint(0, num_classes, size=(samples,))\n        X = np.zeros((samples,) + input_shape, dtype=np.float32)\n        for i in range(samples):\n            X[i] = np.random.normal(loc=y[i], scale=0.7, size=input_shape)\n    else:\n        y_loc = np.random.random((samples,))\n        X = np.zeros((samples,) + input_shape, dtype=np.float32)\n        y = np.zeros((samples,) + output_shape, dtype=np.float32)\n        for i in range(samples):\n            X[i] = np.random.normal(loc=y_loc[i], scale=0.7, size=input_shape)\n            y[i] = np.random.normal(loc=y_loc[i], scale=0.7, size=output_shape)\n\n    return (X[:num_train], y[:num_train]), (X[num_train:], y[num_train:])\n\n\ndef layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n               input_data=None, expected_output=None,\n               expected_output_dtype=None, fixed_batch_size=False):\n    """"""Test routine for a layer with a single input tensor\n    and single output tensor.\n    """"""\n    # generate input data\n    if input_data is None:\n        assert input_shape\n        if not input_dtype:\n            input_dtype = K.floatx()\n        input_data_shape = list(input_shape)\n        for i, e in enumerate(input_data_shape):\n            if e is None:\n                input_data_shape[i] = np.random.randint(1, 4)\n        input_data = (10 * np.random.random(input_data_shape))\n        input_data = input_data.astype(input_dtype)\n    else:\n        if input_shape is None:\n            input_shape = input_data.shape\n        if input_dtype is None:\n            input_dtype = input_data.dtype\n    if expected_output_dtype is None:\n        expected_output_dtype = input_dtype\n\n    # instantiation\n    layer = layer_cls(**kwargs)\n\n    # test get_weights , set_weights at layer level\n    weights = layer.get_weights()\n    layer.set_weights(weights)\n\n    expected_output_shape = layer.compute_output_shape(input_shape)\n\n    # test in functional API\n    if fixed_batch_size:\n        x = Input(batch_shape=input_shape, dtype=input_dtype)\n    else:\n        x = Input(shape=input_shape[1:], dtype=input_dtype)\n    y = layer(x)\n    assert K.dtype(y) == expected_output_dtype\n\n    # check with the functional API\n    model = Model(x, y)\n\n    actual_output = model.predict(input_data)\n    actual_output_shape = actual_output.shape\n    for expected_dim, actual_dim in zip(expected_output_shape,\n                                        actual_output_shape):\n        if expected_dim is not None:\n            assert expected_dim == actual_dim\n\n    if expected_output is not None:\n        assert_allclose(actual_output, expected_output, rtol=1e-3)\n\n    # test serialization, weight setting at model level\n    model_config = model.get_config()\n    recovered_model = model.__class__.from_config(model_config)\n    if model.weights:\n        weights = model.get_weights()\n        recovered_model.set_weights(weights)\n        _output = recovered_model.predict(input_data)\n        assert_allclose(_output, actual_output, rtol=1e-3)\n\n    # test training mode (e.g. useful when the layer has a\n    # different behavior at training and testing time).\n    if has_arg(layer.call, \'training\'):\n        model.compile(\'rmsprop\', \'mse\')\n        model.train_on_batch(input_data, actual_output)\n\n    # test instantiation from layer config\n    layer_config = layer.get_config()\n    layer_config[\'batch_input_shape\'] = input_shape\n    layer = layer.__class__.from_config(layer_config)\n\n    # for further checks in the caller function\n    return actual_output\n\n\nclass tf_file_io_proxy(object):\n    """"""Context manager for mock patching `tensorflow.python.lib.io.file_io` in tests.\n\n    The purpose of this class is to be able to tests model saving/loading to/from\n    Google Cloud Storage, for witch the tensorflow `file_io` package is used.\n\n    If a `bucket_name` is provided, either as an input argument or by setting the\n    environment variable GCS_TEST_BUCKET, *NO mocking* will be done and files will be\n    transferred to the real GCS bucket. For this to work, valid Google application\n    credentials must be available, see:\n        https://cloud.google.com/video-intelligence/docs/common/auth\n    for further details.\n\n    If a `bucket_name` is not provided, an identifier of the import of the file_io\n    module to mock must be provided, using the `file_io_module` argument.\n    NOTE that only part of the module is mocked and that the same Exceptions\n    are not raised in mock implementation.\n\n    Since the bucket name can be provided using an environment variable, it is\n    recommended to use method `get_filepath(filename)` in tests to make them\n    pass with and without a real GCS bucket during testing. See example below.\n\n    # Arguments\n        file_io_module: String identifier of the file_io module import to patch. E.g\n            \'keras.engine.saving.tf_file_io\'\n        bucket_name: String identifier of *a real* GCS bucket (with or without the\n            \'gs://\' prefix). A bucket name provided with argument precedes what is\n            specified using the GCS_TEST_BUCKET environment variable.\n\n    # Example\n    ```python\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,)))\n\n    with tf_file_io_proxy(\'keras.engine.saving.tf_file_io\') as file_io_proxy:\n        gcs_filepath = file_io_proxy.get_filepath(filename=\'model.h5\')\n        save_model(model, gcs_filepath)\n        file_io_proxy.assert_exists(gcs_filepath)\n        new_model_gcs = load_model(gcs_filepath)\n        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n    ```\n    """"""\n    _gcs_prefix = \'gs://\'\n    _test_bucket_env_key = \'GCS_TEST_BUCKET\'\n\n    def __init__(self, file_io_module=None, bucket_name=None):\n        if bucket_name is None:\n            bucket_name = os.environ.get(self._test_bucket_env_key, None)\n        if bucket_name is None:\n            # will mock gcs locally for tests\n            if file_io_module is None:\n                raise ValueError(\'`file_io_module` must be provided for mocking\')\n            self.mock_gcs = True\n            self.file_io_module = file_io_module\n            self.local_objects = {}\n            self.bucket_name = \'mock-bucket\'\n        else:\n            # will use real bucket for tests\n            if bucket_name.startswith(self._gcs_prefix):\n                bucket_name = bucket_name[len(self._gcs_prefix):]\n            self.bucket_name = bucket_name\n            if tf_file_io is None:\n                raise ImportError(\n                    \'tensorflow must be installed to read/write to GCS\')\n            try:\n                # check that bucket exists and is accessible\n                tf_file_io.is_directory(self.bucket_path)\n            except:\n                raise IOError(\n                    \'could not access provided bucket {}\'.format(self.bucket_path))\n            self.mock_gcs = False\n            self.file_io_module = None\n            self.local_objects = None\n\n        self.patched_file_io = None\n        self._is_started = False\n\n    @property\n    def bucket_path(self):\n        """"""Returns the full GCS bucket path""""""\n        return self._gcs_prefix + self.bucket_name\n\n    def get_filepath(self, filename):\n        """"""Returns filename appended to bucketpath""""""\n        return os.path.join(self.bucket_path, filename)\n\n    def FileIO(self, name, mode):\n        """"""Proxy for tensorflow.python.lib.io.file_io.FileIO class. Mocks the class\n        if a real GCS bucket is not available for testing.\n        """"""\n        self._check_started()\n        if not self.mock_gcs:\n            return tf_file_io.FileIO(name, mode)\n\n        filepath = name\n        if filepath.startswith(self._gcs_prefix):\n            mock_fio = MagicMock()\n            mock_fio.__enter__ = Mock(return_value=mock_fio)\n            if mode == \'rb\':\n                if filepath not in self.local_objects:\n                    raise IOError(\'{} does not exist\'.format(filepath))\n                self.local_objects[filepath].seek(0)\n                mock_fio.read = self.local_objects[filepath].read\n            elif mode == \'wb\':\n                self.local_objects[filepath] = BytesIO()\n                mock_fio.write = self.local_objects[filepath].write\n            else:\n                raise ValueError(\n                    \'{} only supports wrapping of FileIO for `mode` ""rb"" or ""wb""\')\n            return mock_fio\n\n        return open(filepath, mode)\n\n    def file_exists(self, filename):\n        """"""Proxy for tensorflow.python.lib.io.file_io.file_exists class. Mocks the\n        function if a real GCS bucket is not available for testing.\n        """"""\n        self._check_started()\n        if not self.mock_gcs:\n            return tf_file_io.file_exists(filename)\n\n        if filename.startswith(self._gcs_prefix):\n            return filename in self.local_objects\n\n        return os.path.exists(filename)\n\n    def delete_file(self, filename):\n        """"""Proxy for tensorflow.python.lib.io.file_io.delete_file function. Mocks\n        the function if a real GCS bucket is not available for testing.\n        """"""\n        if not self.mock_gcs:\n            tf_file_io.delete_file(filename)\n        elif filename.startswith(self._gcs_prefix):\n            self.local_objects.pop(filename)\n        else:\n            os.remove(filename)\n\n    def assert_exists(self, filepath):\n        """"""Convenience method for verifying that a file exists after writing.""""""\n        self._check_started()\n        if not self.file_exists(filepath):\n            raise AssertionError(\'{} does not exist\'.format(filepath))\n\n    def _check_started(self):\n        if not self._is_started:\n            raise RuntimeError(\'tf_file_io_proxy is not started\')\n\n    def start(self):\n        """"""Start mocking of `self.file_io_module` if real bucket not\n        available for testing""""""\n        if self._is_started:\n            raise RuntimeError(\'start called on already started tf_file_io_proxy\')\n        if self.mock_gcs:\n            mock_module = Mock()\n            mock_module.FileIO = self.FileIO\n            mock_module.file_exists = self.file_exists\n            mock_module.delete_file = self.delete_file\n            patched_file_io = patch(self.file_io_module, new=mock_module)\n            self.patched_file_io = patched_file_io\n            self.patched_file_io.start()\n        self._is_started = True\n\n    def stop(self):\n        """"""Stop mocking of `self.file_io_module` if real bucket not\n        available for testing""""""\n        if not self._is_started:\n            raise RuntimeError(\'stop called on unstarted tf_file_io_proxy\')\n        if self.mock_gcs:\n            self.patched_file_io.stop()\n        self._is_started = False\n\n    def __enter__(self):\n        self.start()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.stop()\n'"
keras/utils/vis_utils.py,0,"b'""""""Utilities related to model visualization.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom ..models import Model\nfrom ..layers.wrappers import Wrapper\n\n# `pydot` is an optional dependency,\n# see `extras_require` in `setup.py`.\ntry:\n    import pydot\nexcept ImportError:\n    pydot = None\n\n\ndef _check_pydot():\n    """"""Raise errors if `pydot` or GraphViz unavailable.""""""\n    if pydot is None:\n        raise ImportError(\n            \'Failed to import `pydot`. \'\n            \'Please install `pydot`. \'\n            \'For example with `pip install pydot`.\')\n    try:\n        # Attempt to create an image of a blank graph\n        # to check the pydot/graphviz installation.\n        pydot.Dot.create(pydot.Dot())\n    except OSError:\n        raise OSError(\n            \'`pydot` failed to call GraphViz.\'\n            \'Please install GraphViz (https://www.graphviz.org/) \'\n            \'and ensure that its executables are in the $PATH.\')\n\n\ndef is_model(layer):\n    return isinstance(layer, Model)\n\n\ndef is_wrapped_model(layer):\n    return isinstance(layer, Wrapper) and isinstance(layer.layer, Model)\n\n\ndef add_edge(dot, src, dst):\n    if not dot.get_edge(src, dst):\n        dot.add_edge(pydot.Edge(src, dst))\n\n\ndef model_to_dot(model,\n                 show_shapes=False,\n                 show_layer_names=True,\n                 rankdir=\'TB\',\n                 expand_nested=False,\n                 dpi=96,\n                 subgraph=False):\n    """"""Convert a Keras model to dot format.\n\n    # Arguments\n        model: A Keras model instance.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            \'TB\' creates a vertical plot;\n            \'LR\' creates a horizontal plot.\n        expand_nested: whether to expand nested models into clusters.\n        dpi: dot DPI.\n        subgraph: whether to return a pydot.Cluster instance.\n\n    # Returns\n        A `pydot.Dot` instance representing the Keras model or\n        a `pydot.Cluster` instance representing nested model if\n        `subgraph=True`.\n    """"""\n    from ..layers.wrappers import Wrapper\n    from ..models import Model\n    from ..models import Sequential\n\n    _check_pydot()\n    if subgraph:\n        dot = pydot.Cluster(style=\'dashed\', graph_name=model.name)\n        dot.set(\'label\', model.name)\n        dot.set(\'labeljust\', \'l\')\n    else:\n        dot = pydot.Dot()\n        dot.set(\'rankdir\', rankdir)\n        dot.set(\'concentrate\', True)\n        dot.set(\'dpi\', dpi)\n        dot.set_node_defaults(shape=\'record\')\n\n    sub_n_first_node = {}\n    sub_n_last_node = {}\n    sub_w_first_node = {}\n    sub_w_last_node = {}\n\n    if isinstance(model, Sequential):\n        if not model.built:\n            model.build()\n    layers = model._layers\n\n    # Create graph nodes.\n    for i, layer in enumerate(layers):\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer\'s label to node\'s label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n\n        if isinstance(layer, Wrapper):\n            if expand_nested and isinstance(layer.layer, Model):\n                submodel_wrapper = model_to_dot(layer.layer, show_shapes,\n                                                show_layer_names, rankdir,\n                                                expand_nested,\n                                                subgraph=True)\n                # sub_w : submodel_wrapper\n                sub_w_nodes = submodel_wrapper.get_nodes()\n                sub_w_first_node[layer.layer.name] = sub_w_nodes[0]\n                sub_w_last_node[layer.layer.name] = sub_w_nodes[-1]\n                dot.add_subgraph(submodel_wrapper)\n            else:\n                layer_name = \'{}({})\'.format(layer_name, layer.layer.name)\n                child_class_name = layer.layer.__class__.__name__\n                class_name = \'{}({})\'.format(class_name, child_class_name)\n\n        if expand_nested and isinstance(layer, Model):\n            submodel_not_wrapper = model_to_dot(layer, show_shapes,\n                                                show_layer_names, rankdir,\n                                                expand_nested,\n                                                subgraph=True)\n            # sub_n : submodel_not_wrapper\n            sub_n_nodes = submodel_not_wrapper.get_nodes()\n            sub_n_first_node[layer.name] = sub_n_nodes[0]\n            sub_n_last_node[layer.name] = sub_n_nodes[-1]\n            dot.add_subgraph(submodel_not_wrapper)\n\n        # Create node\'s label.\n        if show_layer_names:\n            label = \'{}: {}\'.format(layer_name, class_name)\n        else:\n            label = class_name\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n            try:\n                outputlabels = str(layer.output_shape)\n            except AttributeError:\n                outputlabels = \'multiple\'\n            if hasattr(layer, \'input_shape\'):\n                inputlabels = str(layer.input_shape)\n            elif hasattr(layer, \'input_shapes\'):\n                inputlabels = \', \'.join(\n                    (str(ishape) for ishape in layer.input_shapes))\n            else:\n                inputlabels = \'multiple\'\n            label = \'%s\\n|{input:|output:}|{{%s}|{%s}}\' % (label,\n                                                           inputlabels,\n                                                           outputlabels)\n\n        if not expand_nested or not isinstance(layer, Model):\n            node = pydot.Node(layer_id, label=label)\n            dot.add_node(node)\n\n    # Connect nodes with edges.\n    for layer in layers:\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + \'_ib-\' + str(i)\n            if node_key in model._network_nodes:\n                for inbound_layer in node.inbound_layers:\n                    inbound_layer_id = str(id(inbound_layer))\n                    if not expand_nested:\n                        assert dot.get_node(inbound_layer_id)\n                        assert dot.get_node(layer_id)\n                        dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n                    else:\n                        # if inbound_layer is not Model or wrapped Model\n                        if not is_model(inbound_layer) and (\n                                not is_wrapped_model(inbound_layer)):\n                            # if current layer is not Model or wrapped Model\n                            if not is_model(layer) and (\n                                    not is_wrapped_model(layer)):\n                                assert dot.get_node(inbound_layer_id)\n                                assert dot.get_node(layer_id)\n                                dot.add_edge(pydot.Edge(inbound_layer_id,\n                                                        layer_id))\n                            # if current layer is Model\n                            elif is_model(layer):\n                                add_edge(dot, inbound_layer_id,\n                                         sub_n_first_node[layer.name].get_name())\n                            # if current layer is wrapped Model\n                            elif is_wrapped_model(layer):\n                                dot.add_edge(pydot.Edge(inbound_layer_id,\n                                                        layer_id))\n                                name = sub_w_first_node[layer.layer.name].get_name()\n                                dot.add_edge(pydot.Edge(layer_id,\n                                                        name))\n                        # if inbound_layer is Model\n                        elif is_model(inbound_layer):\n                            name = sub_n_last_node[inbound_layer.name].get_name()\n                            if is_model(layer):\n                                output_name = sub_n_first_node[layer.name].get_name()\n                                add_edge(dot, name, output_name)\n                            else:\n                                add_edge(dot, name, layer_id)\n                        # if inbound_layer is wrapped Model\n                        elif is_wrapped_model(inbound_layer):\n                            inbound_layer_name = inbound_layer.layer.name\n                            add_edge(dot,\n                                     sub_w_last_node[inbound_layer_name].get_name(),\n                                     layer_id)\n    return dot\n\n\ndef plot_model(model,\n               to_file=\'model.png\',\n               show_shapes=False,\n               show_layer_names=True,\n               rankdir=\'TB\',\n               expand_nested=False,\n               dpi=96):\n    """"""Converts a Keras model to dot format and save to a file.\n\n    # Arguments\n        model: A Keras model instance\n        to_file: File name of the plot image.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            \'TB\' creates a vertical plot;\n            \'LR\' creates a horizontal plot.\n        expand_nested: whether to expand nested models into clusters.\n        dpi: dot DPI.\n\n    # Returns\n        A Jupyter notebook Image object if Jupyter is installed.\n        This enables in-line display of the model plots in notebooks.\n    """"""\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n                       expand_nested, dpi)\n    _, extension = os.path.splitext(to_file)\n    if not extension:\n        extension = \'png\'\n    else:\n        extension = extension[1:]\n    dot.write(to_file, format=extension)\n    # Return the image as a Jupyter Image object, to be displayed in-line.\n    if extension != \'pdf\':\n        try:\n            from IPython import display\n            return display.Image(filename=to_file)\n        except ImportError:\n            pass\n'"
keras/wrappers/__init__.py,0,b'from __future__ import absolute_import\r\n\r\nfrom . import scikit_learn\r\n'
keras/wrappers/scikit_learn.py,0,"b'""""""Wrapper for using the Scikit-Learn API with Keras models.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport types\n\nimport numpy as np\n\nfrom .. import losses\nfrom ..utils.np_utils import to_categorical\nfrom ..utils.generic_utils import has_arg\nfrom ..utils.generic_utils import to_list\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    """"""Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        **sk_params: model parameters & fitting parameters\n\n    The `build_fn` should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to `build_fn`:\n    1. A function\n    2. An instance of a class that implements the `__call__` method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the\n    present class will then be treated as the default `build_fn`.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, `build_fn` should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `epochs`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn\'s `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `epochs` as well as the model parameters.\n    """"""\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        """"""Checks for user typos in `params`.\n\n        # Arguments\n            params: dictionary; the parameters to be checked\n\n        # Raises\n            ValueError: if any member of `params` is not a valid argument.\n        """"""\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        for params_name in params:\n            for fn in legal_params_fns:\n                if has_arg(fn, params_name):\n                    break\n            else:\n                if params_name != \'nb_epoch\':\n                    raise ValueError(\n                        \'{} is not a legal parameter\'.format(params_name))\n\n    def get_params(self, **params):\n        """"""Gets parameters for this estimator.\n\n        # Arguments\n            **params: ignored (exists for API compatibility).\n\n        # Returns\n            Dictionary of parameter names mapped to their values.\n        """"""\n        res = copy.deepcopy(self.sk_params)\n        res.update({\'build_fn\': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        """"""Sets the parameters of this estimator.\n\n        # Arguments\n            **params: Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        """"""\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, x, y, **kwargs):\n        """"""Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        """"""\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        if (losses.is_categorical_crossentropy(self.model.loss) and\n                len(y.shape) != 2):\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(x, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override=None):\n        """"""Filters `sk_params` and returns those in `fn`\'s arguments.\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override `sk_params`\n\n        # Returns\n            res : dictionary containing variables\n                in both `sk_params` and `fn`\'s arguments.\n        """"""\n        override = override or {}\n        res = {}\n        for name, value in self.sk_params.items():\n            if has_arg(fn, name):\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    """"""Implementation of the scikit-learn classifier API for Keras.\n    """"""\n\n    def fit(self, x, y, sample_weight=None, **kwargs):\n        """"""Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n\n        # Raises\n            ValueError: In case of invalid shape for `y` argument.\n        """"""\n        y = np.array(y)\n        if len(y.shape) == 2 and y.shape[1] > 1:\n            self.classes_ = np.arange(y.shape[1])\n        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n            self.classes_ = np.unique(y)\n            y = np.searchsorted(self.classes_, y)\n        else:\n            raise ValueError(\'Invalid shape for y: \' + str(y.shape))\n        self.n_classes_ = len(self.classes_)\n        if sample_weight is not None:\n            kwargs[\'sample_weight\'] = sample_weight\n        return super(KerasClassifier, self).fit(x, y, **kwargs)\n\n    def predict(self, x, **kwargs):\n        """"""Returns the class predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        """"""\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n\n        proba = self.model.predict(x, **kwargs)\n        if proba.shape[-1] > 1:\n            classes = proba.argmax(axis=-1)\n        else:\n            classes = (proba > 0.5).astype(\'int32\')\n        return self.classes_[classes]\n\n    def predict_proba(self, x, **kwargs):\n        """"""Returns class probability estimates for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                to match the scikit-learn API,\n                will return an array of shape `(n_samples, 2)`\n                (instead of `(n_sample, 1)` as in Keras).\n        """"""\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict(x, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, x, y, **kwargs):\n        """"""Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on `x` wrt. `y`.\n\n        # Raises\n            ValueError: If the underlying model isn\'t configured to\n                compute accuracy. You should pass `metrics=[""accuracy""]` to\n                the `.compile()` method of the model.\n        """"""\n        y = np.searchsorted(self.classes_, y)\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, \'__name__\'):\n            loss_name = loss_name.__name__\n        if loss_name == \'categorical_crossentropy\' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(x, y, **kwargs)\n        outputs = to_list(outputs)\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name in [\'accuracy\', \'acc\']:\n                return output\n        raise ValueError(\'The model is not configured to compute accuracy. \'\n                         \'You should pass `metrics=[""accuracy""]` to \'\n                         \'the `model.compile()` method.\')\n\n\nclass KerasRegressor(BaseWrapper):\n    """"""Implementation of the scikit-learn regressor API for Keras.\n    """"""\n\n    def predict(self, x, **kwargs):\n        """"""Returns predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        """"""\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        preds = np.array(self.model.predict(x, **kwargs))\n        if preds.shape[-1] == 1:\n            return np.squeeze(preds, axis=-1)\n        return preds\n\n    def score(self, x, y, **kwargs):\n        """"""Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on `x` wrt. `y`.\n        """"""\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(x, y, **kwargs)\n        if isinstance(loss, list):\n            return -loss[0]\n        return -loss\n'"
tests/docs/test_doc_auto_generation.py,0,"b'import os\nfrom markdown import markdown\nfrom docs import autogen\nimport pytest\nfrom keras import backend as K\n\n\nif K.backend() != \'tensorflow\':\n    pytestmark = pytest.mark.skip\n\n\ntest_doc1 = {\n    \'doc\': """"""Base class for recurrent layers.\n\n    # Arguments\n        cell: A RNN cell instance. A RNN cell is a class that has:\n            - a `call(input_at_t, states_at_t)` method, returning\n                `(output_at_t, states_at_t_plus_1)`. The call method of the\n                cell can also take the optional argument `constants`, see\n                section ""Note on passing external constants"" below.\n            - a `state_size` attribute. This can be a single integer\n                (single state) in which case it is\n                the size of the recurrent state\n                (which should be the same as the size of the cell output).\n                This can also be a list/tuple of integers\n                (one size per state). In this case, the first entry\n                (`state_size[0]`) should be the same as\n                the size of the cell output.\n            It is also possible for `cell` to be a list of RNN cell instances,\n            in which cases the cells get stacked on after the other in the RNN,\n            implementing an efficient stacked RNN.\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n        go_backwards: Boolean (default False).\n            If True, process the input sequence backwards and return the\n            reversed sequence.\n        stateful: Boolean (default False). If True, the last state\n            for each sample at index i in a batch will be used as initial\n            state for the sample of index i in the following batch.\n        unroll: Boolean (default False).\n            If True, the network will be unrolled,\n            else a symbolic loop will be used.\n            Unrolling can speed-up a RNN,\n            although it tends to be more memory-intensive.\n            Unrolling is only suitable for short sequences.\n        input_dim: dimensionality of the input (integer).\n            This argument (or alternatively,\n            the keyword argument `input_shape`)\n            is required when using this layer as the first layer in a model.\n        input_length: Length of input sequences, to be specified\n            when it is constant.\n            This argument is required if you are going to connect\n            `Flatten` then `Dense` layers upstream\n            (without it, the shape of the dense outputs cannot be computed).\n            Note that if the recurrent layer is not the first layer\n            in your model, you would need to specify the input length\n            at the level of the first layer\n            (e.g. via the `input_shape` argument)\n\n    # Input shape\n        3D tensor with shape `(batch_size, timesteps, input_dim)`.\n\n    # Output shape\n        - if `return_state`: a list of tensors. The first tensor is\n            the output. The remaining tensors are the last states,\n            each with shape `(batch_size, units)`.\n        - if `return_sequences`: 3D tensor with shape\n            `(batch_size, timesteps, units)`.\n        - else, 2D tensor with shape `(batch_size, units)`.\n\n    # Masking\n        This layer supports masking for input data with a variable number\n        of timesteps. To introduce masks to your data,\n        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n        set to `True`.\n\n    # Note on using statefulness in RNNs\n        You can set RNN layers to be \'stateful\', which means that the states\n        computed for the samples in one batch will be reused as initial states\n        for the samples in the next batch. This assumes a one-to-one mapping\n        between samples in different successive batches.\n\n        To enable statefulness:\n            - specify `stateful=True` in the layer constructor.\n            - specify a fixed batch size for your model, by passing\n                if sequential model:\n                  `batch_input_shape=(...)` to the first layer in your model.\n                else for functional model with 1 or more Input layers:\n                  `batch_shape=(...)` to all the first layers in your model.\n                This is the expected shape of your inputs\n                *including the batch size*.\n                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n            - specify `shuffle=False` when calling fit().\n\n        To reset the states of your model, call `.reset_states()` on either\n        a specific layer, or on your entire model.\n\n    # Note on specifying the initial state of RNNs\n    Note: that\n        One: You can specify the initial state of RNN layers symbolically by\n            calling them with the keyword argument `initial_state`.\n        Two: The value of `initial_state` should be a tensor or list of\n            tensors representing\n            the initial state of the RNN layer.\n        You can specify the initial state of RNN layers numerically by:\n        One: calling `reset_states`\n            - With the keyword argument `states`.\n                - The value of\n            `states` should be a numpy array or\n            list of numpy arrays representing\n        the initial state of the RNN layer.\n\n    # Note on passing external constants to RNNs\n        You can pass ""external"" constants to the cell using the `constants`\n        keyword: argument of `RNN.__call__` (as well as `RNN.call`) method.\n        This: requires that the `cell.call` method accepts the same keyword argument\n        `constants`. Such constants can be used to condition the cell\n        transformation on additional static inputs (not changing over time),\n        a.k.a. an attention mechanism.\n\n    # Examples\n\n    ```python\n        # First, let\'s define a RNN Cell, as a layer subclass.\n\n        class MinimalRNNCell(keras.layers.Layer):\n\n            def __init__(self, units, **kwargs):\n                self.units = units\n                self.state_size = units\n                super(MinimalRNNCell, self).__init__(**kwargs)\n\n            def build(self, input_shape):\n                self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                              initializer=\'uniform\',\n                                              name=\'kernel\')\n                self.recurrent_kernel = self.add_weight(\n                    shape=(self.units, self.units),\n                    initializer=\'uniform\',\n                    name=\'recurrent_kernel\')\n                self.built = True\n\n            def call(self, inputs, states):\n                prev_output = states[0]\n                h = K.dot(inputs, self.kernel)\n                output = h + K.dot(prev_output, self.recurrent_kernel)\n                return output, [output]\n\n        # Let\'s use this cell in a RNN layer:\n\n        cell = MinimalRNNCell(32)\n        x = keras.Input((None, 5))\n        layer = RNN(cell)\n        y = layer(x)\n\n        # Here\'s how to use the cell to build a stacked RNN:\n\n        cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n        x = keras.Input((None, 5))\n        layer = RNN(cells)\n        y = layer(x)\n    ```\n    """""",\n    \'result\': \'\'\'Base class for recurrent layers.\n\n__Arguments__\n\n- __cell__: A RNN cell instance. A RNN cell is a class that has:\n    - a `call(input_at_t, states_at_t)` method, returning\n        `(output_at_t, states_at_t_plus_1)`. The call method of the\n        cell can also take the optional argument `constants`, see\n        section ""Note on passing external constants"" below.\n    - a `state_size` attribute. This can be a single integer\n        (single state) in which case it is\n        the size of the recurrent state\n        (which should be the same as the size of the cell output).\n        This can also be a list/tuple of integers\n        (one size per state). In this case, the first entry\n        (`state_size[0]`) should be the same as\n        the size of the cell output.\n\n    It is also possible for `cell` to be a list of RNN cell instances,\n    in which cases the cells get stacked on after the other in the RNN,\n    implementing an efficient stacked RNN.\n\n- __return_sequences__: Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.\n- __return_state__: Boolean. Whether to return the last state\n    in addition to the output.\n- __go_backwards__: Boolean (default False).\n    If True, process the input sequence backwards and return the\n    reversed sequence.\n- __stateful__: Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.\n- __unroll__: Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.\n- __input_dim__: dimensionality of the input (integer).\n    This argument (or alternatively,\n    the keyword argument `input_shape`)\n    is required when using this layer as the first layer in a model.\n- __input_length__: Length of input sequences, to be specified\n    when it is constant.\n    This argument is required if you are going to connect\n    `Flatten` then `Dense` layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n    Note that if the recurrent layer is not the first layer\n    in your model, you would need to specify the input length\n    at the level of the first layer\n    (e.g. via the `input_shape` argument)\n\n__Input shape__\n\n3D tensor with shape `(batch_size, timesteps, input_dim)`.\n\n__Output shape__\n\n- if `return_state`: a list of tensors. The first tensor is\n    the output. The remaining tensors are the last states,\n    each with shape `(batch_size, units)`.\n- if `return_sequences`: 3D tensor with shape\n    `(batch_size, timesteps, units)`.\n- else, 2D tensor with shape `(batch_size, units)`.\n\n__Masking__\n\nThis layer supports masking for input data with a variable number\nof timesteps. To introduce masks to your data,\nuse an [Embedding](embeddings.md) layer with the `mask_zero` parameter\nset to `True`.\n\n__Note on using statefulness in RNNs__\n\nYou can set RNN layers to be \'stateful\', which means that the states\ncomputed for the samples in one batch will be reused as initial states\nfor the samples in the next batch. This assumes a one-to-one mapping\nbetween samples in different successive batches.\n\nTo enable statefulness:\n- specify `stateful=True` in the layer constructor.\n- specify a fixed batch size for your model, by passing\nif sequential model:\n`batch_input_shape=(...)` to the first layer in your model.\nelse for functional model with 1 or more Input layers:\n`batch_shape=(...)` to all the first layers in your model.\nThis is the expected shape of your inputs\n*including the batch size*.\nIt should be a tuple of integers, e.g. `(32, 10, 100)`.\n- specify `shuffle=False` when calling fit().\n\nTo reset the states of your model, call `.reset_states()` on either\na specific layer, or on your entire model.\n\n__Note on specifying the initial state of RNNs__\n\nNote: that\n- __One__: You can specify the initial state of RNN layers symbolically by\n    calling them with the keyword argument `initial_state`.\n- __Two__: The value of `initial_state` should be a tensor or list of\n    tensors representing\n    the initial state of the RNN layer.\n\nYou can specify the initial state of RNN layers numerically by:\n\n- __One__: calling `reset_states`\n    - With the keyword argument `states`.\n        - The value of\n\n    `states` should be a numpy array or\n    list of numpy arrays representing\n\nthe initial state of the RNN layer.\n\n__Note on passing external constants to RNNs__\n\nYou can pass ""external"" constants to the cell using the `constants`\n- __keyword__: argument of `RNN.__call__` (as well as `RNN.call`) method.\n- __This__: requires that the `cell.call` method accepts the same keyword argument\n\n`constants`. Such constants can be used to condition the cell\ntransformation on additional static inputs (not changing over time),\na.k.a. an attention mechanism.\n\n__Examples__\n\n\n```python\n# First, let\'s define a RNN Cell, as a layer subclass.\n\nclass MinimalRNNCell(keras.layers.Layer):\n\n    def __init__(self, units, **kwargs):\n        self.units = units\n        self.state_size = units\n        super(MinimalRNNCell, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer=\'uniform\',\n                                      name=\'kernel\')\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            initializer=\'uniform\',\n            name=\'recurrent_kernel\')\n        self.built = True\n\n    def call(self, inputs, states):\n        prev_output = states[0]\n        h = K.dot(inputs, self.kernel)\n        output = h + K.dot(prev_output, self.recurrent_kernel)\n        return output, [output]\n\n# Let\'s use this cell in a RNN layer:\n\ncell = MinimalRNNCell(32)\nx = keras.Input((None, 5))\nlayer = RNN(cell)\ny = layer(x)\n\n# Here\'s how to use the cell to build a stacked RNN:\n\ncells = [MinimalRNNCell(32), MinimalRNNCell(64)]\nx = keras.Input((None, 5))\nlayer = RNN(cells)\ny = layer(x)\n```\n\'\'\'}\n\n\ntest_doc_with_arguments_as_last_block = {\n    \'doc\': """"""Base class for recurrent layers.\n\n    # Arguments\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n    """""",\n    \'result\': \'\'\'Base class for recurrent layers.\n\n__Arguments__\n\n- __return_sequences__: Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.\n- __return_state__: Boolean. Whether to return the last state\n    in addition to the output.\n\'\'\'}\n\n\n@pytest.mark.parametrize(\'docs_descriptor\', [\n    test_doc1,\n    test_doc_with_arguments_as_last_block,\n])\ndef test_doc_lists(docs_descriptor):\n    docstring = autogen.process_docstring(docs_descriptor[\'doc\'])\n    assert markdown(docstring) == markdown(docs_descriptor[\'result\'])\n\n\ndummy_docstring = """"""Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Examples\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n\n    # Numpy implementation\n    ```python\n        def dot(x, y):\n            return dot(x, y)\n    ```\n    """"""\n\n\ndef test_doc_multiple_sections_code():\n    """""" Checks that we can have code blocks in multiple sections.""""""\n    generated = autogen.process_docstring(dummy_docstring)\n    assert \'# Theano-like behavior example\' in generated\n    assert \'def dot(x, y):\' in generated\n\n\ndef test_docs_in_custom_destination_dir(tmpdir):\n    autogen.generate(tmpdir)\n    assert os.path.isdir(os.path.join(tmpdir, \'layers\'))\n    assert os.path.isdir(os.path.join(tmpdir, \'models\'))\n    assert os.path.isdir(os.path.join(tmpdir, \'examples\'))\n    assert os.listdir(os.path.join(tmpdir, \'examples\'))\n\n\ndef test_module_name():\n    for page in autogen.PAGES:\n        list_of_classes = autogen.read_page_data(page, \'classes\')\n        for element in list_of_classes:\n            if isinstance(element, (list, tuple)):\n                cls = element[0]\n            else:\n                cls = element\n            signature = autogen.get_class_signature(cls)\n            assert signature.startswith(\'keras.\')\n\n        list_of_functions = autogen.read_page_data(page, \'functions\')\n        for function_ in list_of_functions:\n            signature = autogen.get_function_signature(function_)\n            assert signature.startswith(\'keras.\')\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/docs/test_documentation.py,0,"b'import importlib\nimport inspect\nimport re\nimport sys\nfrom itertools import compress\nfrom keras import backend as K\n\nimport pytest\n\nif K.backend() != \'tensorflow\':\n    pytestmark = pytest.mark.skip\n\nmodules = [\'keras.layers\', \'keras.models\', \'keras\',\n           \'keras.backend\', \'keras.engine\',\n           \'keras.wrappers\', \'keras.utils\',\n           \'keras.callbacks\', \'keras.activations\',\n           \'keras.losses\', \'keras.models\', \'keras.optimizers\']\naccepted_name = [\'from_config\']\naccepted_module = [\'keras.legacy.layers\', \'keras.utils.generic_utils\']\n\n# Functions or classes with less than \'MIN_CODE_SIZE\' lines can be ignored\nMIN_CODE_SIZE = 15\n\n\ndef handle_class_init(name, member):\n    init_args = [\n        arg for arg in list(inspect.signature(member.__init__).parameters.keys())\n        if arg not in [\'self\', \'args\', \'kwargs\']\n    ]\n    assert_args_presence(init_args, member.__doc__, member, name)\n\n\ndef handle_class(name, member):\n    if is_accepted(name, member):\n        return\n\n    if member.__doc__ is None and not member_too_small(member):\n        raise ValueError(""{} class doesn\'t have any documentation"".format(name),\n                         member.__module__, inspect.getmodule(member).__file__)\n\n    handle_class_init(name, member)\n\n    for n, met in inspect.getmembers(member):\n        if inspect.ismethod(met):\n            handle_method(n, met)\n\n\ndef handle_function(name, member):\n    if name.startswith(\'_\'):\n        return\n    if is_accepted(name, member) or member_too_small(member):\n        # We don\'t need to check this one.\n        return\n    doc = member.__doc__\n    if doc is None:\n        raise ValueError(""{} function doesn\'t have any documentation"".format(name),\n                         member.__module__, inspect.getmodule(member).__file__)\n\n    args = list(inspect.signature(member).parameters.keys())\n    assert_args_presence(args, doc, member, name)\n    assert_function_style(name, member, doc, args)\n    assert_doc_style(name, member, doc)\n\n\ndef assert_doc_style(name, member, doc):\n    lines = doc.split(""\\n"")\n    first_line = lines[0]\n    if len(first_line.strip()) == 0:\n        raise ValueError(\n            ""{} the documentation should be on the first line."".format(name),\n            member.__module__)\n    if first_line.strip()[-1] != \'.\':\n        raise ValueError(""{} first line should end with a \'.\'"".format(name),\n                         member.__module__)\n\n\ndef assert_function_style(name, member, doc, args):\n    code = inspect.getsource(member)\n    has_return = re.findall(r""\\s*return \\S+"", code, re.MULTILINE)\n    if has_return and ""# Returns"" not in doc:\n        innerfunction = [inspect.getsource(x) for x in member.__code__.co_consts if\n                         inspect.iscode(x)]\n        return_in_sub = [ret for code_inner in innerfunction for ret in\n                         re.findall(r""\\s*return \\S+"", code_inner, re.MULTILINE)]\n        if len(return_in_sub) < len(has_return):\n            raise ValueError(""{} needs a \'# Returns\' section"".format(name),\n                             member.__module__)\n\n    has_raise = re.findall(r""^\\s*raise \\S+"", code, re.MULTILINE)\n    if has_raise and ""# Raises"" not in doc:\n        innerfunction = [inspect.getsource(x) for x in member.__code__.co_consts if\n                         inspect.iscode(x)]\n        raise_in_sub = [ret for code_inner in innerfunction for ret in\n                        re.findall(r""\\s*raise \\S+"", code_inner, re.MULTILINE)]\n        if len(raise_in_sub) < len(has_raise):\n            raise ValueError(""{} needs a \'# Raises\' section"".format(name),\n                             member.__module__)\n\n    if len(args) > 0 and ""# Arguments"" not in doc:\n        raise ValueError(""{} needs a \'# Arguments\' section"".format(name),\n                         member.__module__)\n\n    assert_blank_before(name, member, doc, [\'# Arguments\', \'# Raises\', \'# Returns\'])\n\n\ndef assert_blank_before(name, member, doc, keywords):\n    doc_lines = [x.strip() for x in doc.split(\'\\n\')]\n    for keyword in keywords:\n        if keyword in doc_lines:\n            index = doc_lines.index(keyword)\n            if doc_lines[index - 1] != \'\':\n                raise ValueError(\n                    ""{} \'{}\' should have a blank line above."".format(name, keyword),\n                    member.__module__)\n\n\ndef is_accepted(name, member):\n    if \'keras\' not in str(member.__module__):\n        return True\n    return name in accepted_name or member.__module__ in accepted_module\n\n\ndef member_too_small(member):\n    code = inspect.getsource(member).split(\'\\n\')\n    return len(code) < MIN_CODE_SIZE\n\n\ndef assert_args_presence(args, doc, member, name):\n    if not doc:\n        raise ValueError(\'{} needs a docstring.\'.format(name),\n                         member.__module__)\n    args_not_in_doc = [arg not in doc for arg in args]\n    if any(args_not_in_doc):\n        raise ValueError(\n            ""{} {} arguments are not present in documentation "".format(name, list(\n                compress(args, args_not_in_doc))), member.__module__)\n    words = doc.replace(\'*\', \'\').split()\n    # Check arguments styling\n    styles = [arg + "":"" not in words for arg in args]\n    if any(styles):\n        raise ValueError(\n            ""{} {} are not style properly \'argument\': documentation"".format(\n                name,\n                list(compress(args, styles))),\n            member.__module__)\n\n    # Check arguments order\n    indexes = [words.index(arg + "":"") for arg in args]\n    if indexes != sorted(indexes):\n        raise ValueError(\n            ""{} arguments order is different from the documentation"".format(name),\n            member.__module__)\n\n\ndef handle_method(name, member):\n    if name in accepted_name or member.__module__ in accepted_module:\n        return\n    handle_function(name, member)\n\n\ndef handle_module(mod):\n    for name, mem in inspect.getmembers(mod):\n        if inspect.isclass(mem):\n            handle_class(name, mem)\n        elif inspect.isfunction(mem):\n            handle_function(name, mem)\n        elif \'keras\' in name and inspect.ismodule(mem):\n            # Only test keras\' modules\n            handle_module(mem)\n\n\n@pytest.mark.skipif(sys.version_info < (3, 3), reason=""requires python3.3"")\ndef test_doc():\n    for module in modules:\n        mod = importlib.import_module(module)\n        handle_module(mod)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/integration_tests/applications_test.py,0,"b""import pytest\nimport random\nimport os\nfrom multiprocessing import Process, Queue\nfrom keras import applications\nfrom keras import backend as K\n\n\nMODEL_LIST = [\n    (applications.ResNet50, 2048),\n    (applications.ResNet101, 2048),\n    (applications.ResNet152, 2048),\n    (applications.ResNet50V2, 2048),\n    (applications.ResNet101V2, 2048),\n    (applications.ResNet152V2, 2048),\n    (applications.VGG16, 512),\n    (applications.VGG19, 512),\n    (applications.Xception, 2048),\n    (applications.InceptionV3, 2048),\n    (applications.InceptionResNetV2, 1536),\n    (applications.MobileNet, 1024),\n    (applications.MobileNetV2, 1280),\n    (applications.DenseNet121, 1024),\n    (applications.DenseNet169, 1664),\n    (applications.DenseNet201, 1920),\n    # Note that NASNetLarge is too heavy to test on Travis.\n    (applications.NASNetMobile, 1056)\n]\n\n\ndef _get_output_shape(model_fn):\n    if K.backend() == 'cntk':\n        # Create model in a subprocess so that\n        # the memory consumed by InceptionResNetV2 will be\n        # released back to the system after this test\n        # (to deal with OOM error on CNTK backend).\n        # TODO: remove the use of multiprocessing from these tests\n        # once a memory clearing mechanism\n        # is implemented in the CNTK backend.\n        def target(queue):\n            model = model_fn()\n            queue.put(model.output_shape)\n        queue = Queue()\n        p = Process(target=target, args=(queue,))\n        p.start()\n        p.join()\n        # The error in a subprocess won't propagate\n        # to the main process, so we check if the model\n        # is successfully created by checking if the output shape\n        # has been put into the queue\n        assert not queue.empty(), 'Model creation failed.'\n        return queue.get_nowait()\n    else:\n        model = model_fn()\n        return model.output_shape\n\n\ndef _test_application_basic(app, last_dim=1000):\n    output_shape = _get_output_shape(lambda: app(weights=None))\n    assert output_shape == (None, last_dim)\n\n\ndef _test_application_notop(app, last_dim):\n    output_shape = _get_output_shape(\n        lambda: app(weights=None, include_top=False))\n    assert len(output_shape) == 4\n    assert output_shape[-1] == last_dim\n\n\ndef test_applications():\n    for _ in range(3):\n        app, last_dim = random.choice(MODEL_LIST)\n        _test_application_basic(app)\n        _test_application_notop(app, last_dim)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/imagenet_utils_test.py,0,"b""import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras.applications import imagenet_utils as utils\nfrom keras.models import Model\nfrom keras.layers import Input, Lambda\n\n\ndef test_preprocess_input():\n    # Test image batch with float and int image input\n    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n    xint = x.astype('int32')\n    assert utils.preprocess_input(x).shape == x.shape\n    assert utils.preprocess_input(xint).shape == xint.shape\n\n    out1 = utils.preprocess_input(x, 'channels_last')\n    out1int = utils.preprocess_input(xint, 'channels_last')\n    out2 = utils.preprocess_input(np.transpose(x, (0, 3, 1, 2)),\n                                  'channels_first')\n    out2int = utils.preprocess_input(np.transpose(xint, (0, 3, 1, 2)),\n                                     'channels_first')\n    assert_allclose(out1, out2.transpose(0, 2, 3, 1))\n    assert_allclose(out1int, out2int.transpose(0, 2, 3, 1))\n\n    # Test single image\n    x = np.random.uniform(0, 255, (10, 10, 3))\n    xint = x.astype('int32')\n    assert utils.preprocess_input(x).shape == x.shape\n    assert utils.preprocess_input(xint).shape == xint.shape\n\n    out1 = utils.preprocess_input(x, 'channels_last')\n    out1int = utils.preprocess_input(xint, 'channels_last')\n    out2 = utils.preprocess_input(np.transpose(x, (2, 0, 1)),\n                                  'channels_first')\n    out2int = utils.preprocess_input(np.transpose(xint, (2, 0, 1)),\n                                     'channels_first')\n    assert_allclose(out1, out2.transpose(1, 2, 0))\n    assert_allclose(out1int, out2int.transpose(1, 2, 0))\n\n    # Test that writing over the input data works predictably\n    for mode in ['torch', 'tf']:\n        x = np.random.uniform(0, 255, (2, 10, 10, 3))\n        xint = x.astype('int')\n        x2 = utils.preprocess_input(x, mode=mode)\n        xint2 = utils.preprocess_input(xint)\n        assert_allclose(x, x2)\n        assert xint.astype('float').max() != xint2.max()\n    # Caffe mode works differently from the others\n    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n    xint = x.astype('int')\n    x2 = utils.preprocess_input(x, data_format='channels_last', mode='caffe')\n    xint2 = utils.preprocess_input(xint)\n    assert_allclose(x, x2[..., ::-1])\n    assert xint.astype('float').max() != xint2.max()\n\n\ndef test_preprocess_input_symbolic():\n    # Test image batch\n    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n    inputs = Input(shape=x.shape[1:])\n    outputs = Lambda(utils.preprocess_input, output_shape=x.shape[1:])(inputs)\n    model = Model(inputs, outputs)\n    assert model.predict(x).shape == x.shape\n\n    outputs1 = Lambda(lambda x: utils.preprocess_input(x, 'channels_last'),\n                      output_shape=x.shape[1:])(inputs)\n    model1 = Model(inputs, outputs1)\n    out1 = model1.predict(x)\n    x2 = np.transpose(x, (0, 3, 1, 2))\n    inputs2 = Input(shape=x2.shape[1:])\n    outputs2 = Lambda(lambda x: utils.preprocess_input(x, 'channels_first'),\n                      output_shape=x2.shape[1:])(inputs2)\n    model2 = Model(inputs2, outputs2)\n    out2 = model2.predict(x2)\n    assert_allclose(out1, out2.transpose(0, 2, 3, 1))\n\n    # Test single image\n    x = np.random.uniform(0, 255, (10, 10, 3))\n    inputs = Input(shape=x.shape)\n    outputs = Lambda(utils.preprocess_input, output_shape=x.shape)(inputs)\n    model = Model(inputs, outputs)\n    assert model.predict(x[np.newaxis])[0].shape == x.shape\n\n    outputs1 = Lambda(lambda x: utils.preprocess_input(x, 'channels_last'),\n                      output_shape=x.shape)(inputs)\n    model1 = Model(inputs, outputs1)\n    out1 = model1.predict(x[np.newaxis])[0]\n    x2 = np.transpose(x, (2, 0, 1))\n    inputs2 = Input(shape=x2.shape)\n    outputs2 = Lambda(lambda x: utils.preprocess_input(x, 'channels_first'),\n                      output_shape=x2.shape)(inputs2)\n    model2 = Model(inputs2, outputs2)\n    out2 = model2.predict(x2[np.newaxis])[0]\n    assert_allclose(out1, out2.transpose(1, 2, 0))\n\n\ndef DISABLED_test_decode_predictions():\n    # Disabled due to SSL issues on Travis.\n    x = np.zeros((2, 1000))\n    x[0, 372] = 1.0\n    x[1, 549] = 1.0\n    outs = utils.decode_predictions(x, top=1)\n    scores = [out[0][2] for out in outs]\n    assert scores[0] == scores[1]\n\n    # the numbers of columns and ImageNet classes are not identical.\n    with pytest.raises(ValueError):\n        utils.decode_predictions(np.ones((2, 100)))\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/test_datasets.py,0,"b""from __future__ import print_function\nimport pytest\nimport time\nimport random\nfrom keras.datasets import cifar10\nfrom keras.datasets import cifar100\nfrom keras.datasets import reuters\nfrom keras.datasets import imdb\nfrom keras.datasets import mnist\nfrom keras.datasets import boston_housing\nfrom keras.datasets import fashion_mnist\n\n\ndef test_cifar():\n    # only run data download tests 20% of the time\n    # to speed up frequent testing\n    random.seed(time.time())\n    if random.random() > 0.8:\n        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n        assert len(x_train) == len(y_train) == 50000\n        assert len(x_test) == len(y_test) == 10000\n        (x_train, y_train), (x_test, y_test) = cifar100.load_data('fine')\n        assert len(x_train) == len(y_train) == 50000\n        assert len(x_test) == len(y_test) == 10000\n        (x_train, y_train), (x_test, y_test) = cifar100.load_data('coarse')\n        assert len(x_train) == len(y_train) == 50000\n        assert len(x_test) == len(y_test) == 10000\n\n\ndef test_reuters():\n    # only run data download tests 20% of the time\n    # to speed up frequent testing\n    random.seed(time.time())\n    if random.random() > 0.8:\n        (x_train, y_train), (x_test, y_test) = reuters.load_data()\n        assert len(x_train) == len(y_train)\n        assert len(x_test) == len(y_test)\n        assert len(x_train) + len(x_test) == 11228\n        (x_train, y_train), (x_test, y_test) = reuters.load_data(maxlen=10)\n        assert len(x_train) == len(y_train)\n        assert len(x_test) == len(y_test)\n        word_index = reuters.get_word_index()\n        assert isinstance(word_index, dict)\n\n\ndef test_mnist():\n    # only run data download tests 20% of the time\n    # to speed up frequent testing\n    random.seed(time.time())\n    if random.random() > 0.8:\n        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n        assert len(x_train) == len(y_train) == 60000\n        assert len(x_test) == len(y_test) == 10000\n\n\ndef test_imdb():\n    # only run data download tests 20% of the time\n    # to speed up frequent testing\n    random.seed(time.time())\n    if random.random() > 0.8:\n        (x_train, y_train), (x_test, y_test) = imdb.load_data()\n        (x_train, y_train), (x_test, y_test) = imdb.load_data(maxlen=40)\n        assert len(x_train) == len(y_train)\n        assert len(x_test) == len(y_test)\n        word_index = imdb.get_word_index()\n        assert isinstance(word_index, dict)\n\n\ndef test_boston_housing():\n    # only run data download tests 20% of the time\n    # to speed up frequent testing\n    random.seed(time.time())\n    if random.random() > 0.8:\n        (x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n        assert len(x_train) == len(y_train)\n        assert len(x_test) == len(y_test)\n\n\ndef test_fashion_mnist():\n    # only run data download tests 20% of the time\n    # to speed up frequent testing\n    random.seed(time.time())\n    if random.random() > 0.8:\n        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n        assert len(x_train) == len(y_train) == 60000\n        assert len(x_test) == len(y_test) == 10000\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/test_image_data_tasks.py,0,"b""from __future__ import print_function\nimport numpy as np\nimport pytest\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.test_utils import get_test_data\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.utils.np_utils import to_categorical\n\n\ndef test_image_classification():\n    np.random.seed(1337)\n    input_shape = (16, 16, 3)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n                                                         num_test=200,\n                                                         input_shape=input_shape,\n                                                         classification=True,\n                                                         num_classes=4)\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n    model = Sequential([\n        layers.Conv2D(filters=8, kernel_size=3,\n                      activation='relu',\n                      input_shape=input_shape),\n        layers.MaxPooling2D(pool_size=2),\n        layers.Conv2D(filters=4, kernel_size=(3, 3),\n                      activation='relu', padding='same'),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(y_test.shape[-1], activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    model.summary()\n    history = model.fit(x_train, y_train, epochs=12, batch_size=16,\n                        validation_data=(x_test, y_test),\n                        verbose=0)\n    assert history.history['val_accuracy'][-1] > 0.75\n    config = model.get_config()\n    model = Sequential.from_config(config)\n\n\ndef test_image_data_generator_training():\n    np.random.seed(1337)\n    img_gen = ImageDataGenerator(rescale=1.)  # Dummy ImageDataGenerator\n    input_shape = (16, 16, 3)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n                                                         num_test=200,\n                                                         input_shape=input_shape,\n                                                         classification=True,\n                                                         num_classes=4)\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n    model = Sequential([\n        layers.Conv2D(filters=8, kernel_size=3,\n                      activation='relu',\n                      input_shape=input_shape),\n        layers.MaxPooling2D(pool_size=2),\n        layers.Conv2D(filters=4, kernel_size=(3, 3),\n                      activation='relu', padding='same'),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(y_test.shape[-1], activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    history = model.fit_generator(img_gen.flow(x_train, y_train, batch_size=16),\n                                  epochs=15,\n                                  validation_data=img_gen.flow(x_test, y_test,\n                                                               batch_size=16),\n                                  verbose=0)\n    assert history.history['val_accuracy'][-1] > 0.70\n    model.evaluate_generator(img_gen.flow(x_train, y_train, batch_size=16))\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/test_temporal_data_tasks.py,0,"b""from __future__ import print_function\nimport numpy as np\nimport pytest\nimport string\n\nfrom keras.utils.test_utils import get_test_data\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras import layers, optimizers\nimport keras.backend as K\nimport keras\n\n\ndef test_temporal_classification():\n    '''\n    Classify temporal sequences of float numbers\n    of length 3 into 2 classes using\n    single layer of GRU units and softmax applied\n    to the last activations of the units\n    '''\n    np.random.seed(1337)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=200,\n                                                         num_test=20,\n                                                         input_shape=(3, 4),\n                                                         classification=True,\n                                                         num_classes=2)\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n    model = Sequential()\n    model.add(layers.GRU(8,\n                         input_shape=(x_train.shape[1], x_train.shape[2])))\n    model.add(layers.Dense(y_train.shape[-1], activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    model.summary()\n    history = model.fit(x_train, y_train, epochs=5, batch_size=10,\n                        validation_data=(x_test, y_test),\n                        verbose=0)\n    assert(history.history['accuracy'][-1] >= 0.8)\n    config = model.get_config()\n    model = Sequential.from_config(config)\n\n\ndef test_temporal_classification_functional():\n    '''\n    Classify temporal sequences of float numbers\n    of length 3 into 2 classes using\n    single layer of GRU units and softmax applied\n    to the last activations of the units\n    '''\n    np.random.seed(1337)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=200,\n                                                         num_test=20,\n                                                         input_shape=(3, 4),\n                                                         classification=True,\n                                                         num_classes=2)\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n    inputs = layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n    x = layers.SimpleRNN(8)(inputs)\n    outputs = layers.Dense(y_train.shape[-1], activation='softmax')(x)\n    model = keras.models.Model(inputs, outputs)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    history = model.fit(x_train, y_train, epochs=5, batch_size=10,\n                        validation_data=(x_test, y_test),\n                        verbose=0)\n    assert(history.history['accuracy'][-1] >= 0.75)\n\n\ndef test_temporal_regression():\n    '''\n    Predict float numbers (regression) based on sequences\n    of float numbers of length 3 using a single layer of GRU units\n    '''\n    np.random.seed(1337)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=200,\n                                                         num_test=20,\n                                                         input_shape=(3, 5),\n                                                         output_shape=(2,),\n                                                         classification=False)\n    model = Sequential()\n    model.add(layers.LSTM(y_train.shape[-1],\n                          input_shape=(x_train.shape[1], x_train.shape[2])))\n    model.compile(loss='hinge', optimizer='adam')\n    history = model.fit(x_train, y_train, epochs=5, batch_size=16,\n                        validation_data=(x_test, y_test), verbose=0)\n    assert(history.history['loss'][-1] < 1.)\n\n\ndef test_3d_to_3d():\n    '''\n    Apply a same Dense layer for each element of time dimension of the input\n    and make predictions of the output sequence elements.\n    This does not make use of the temporal structure of the sequence\n    (see TimeDistributedDense for more details)\n    '''\n    np.random.seed(1337)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=100,\n                                                         num_test=20,\n                                                         input_shape=(3, 5),\n                                                         output_shape=(3, 5),\n                                                         classification=False)\n\n    model = Sequential()\n    model.add(layers.TimeDistributed(\n        layers.Dense(y_train.shape[-1]), input_shape=x_train.shape[1:3]))\n    model.compile(loss='hinge', optimizer='rmsprop')\n    history = model.fit(x_train, y_train, epochs=20, batch_size=16,\n                        validation_data=(x_test, y_test), verbose=0)\n    assert(history.history['loss'][-1] < 1.)\n\n\ndef test_stacked_lstm_char_prediction():\n    '''\n    Learn alphabetical char sequence with stacked LSTM.\n    Predict the whole alphabet based on the first two letters ('ab' -> 'ab...z')\n    See non-toy example in examples/lstm_text_generation.py\n    '''\n    # generate alphabet:\n    # http://stackoverflow.com/questions/16060899/alphabet-range-python\n    alphabet = string.ascii_lowercase\n    number_of_chars = len(alphabet)\n\n    # generate char sequences of length 'sequence_length' out of alphabet and\n    # store the next char as label (e.g. 'ab'->'c')\n    sequence_length = 2\n    sentences = [alphabet[i: i + sequence_length]\n                 for i in range(len(alphabet) - sequence_length)]\n    next_chars = [alphabet[i + sequence_length]\n                  for i in range(len(alphabet) - sequence_length)]\n\n    # Transform sequences and labels into 'one-hot' encoding\n    x = np.zeros((len(sentences), sequence_length, number_of_chars), dtype=np.bool)\n    y = np.zeros((len(sentences), number_of_chars), dtype=np.bool)\n    for i, sentence in enumerate(sentences):\n        for t, char in enumerate(sentence):\n            x[i, t, ord(char) - ord('a')] = 1\n        y[i, ord(next_chars[i]) - ord('a')] = 1\n\n    # learn the alphabet with stacked LSTM\n    model = Sequential([\n        layers.LSTM(16, return_sequences=True,\n                    input_shape=(sequence_length, number_of_chars)),\n        layers.LSTM(16, return_sequences=False),\n        layers.Dense(number_of_chars, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    model.fit(x, y, batch_size=1, epochs=60, verbose=1)\n\n    # prime the model with 'ab' sequence and let it generate the learned alphabet\n    sentence = alphabet[:sequence_length]\n    generated = sentence\n    for iteration in range(number_of_chars - sequence_length):\n        x = np.zeros((1, sequence_length, number_of_chars))\n        for t, char in enumerate(sentence):\n            x[0, t, ord(char) - ord('a')] = 1.\n        preds = model.predict(x, verbose=0)[0]\n        next_char = chr(np.argmax(preds) + ord('a'))\n        generated += next_char\n        sentence = sentence[1:] + next_char\n\n    # check that it did generate the alphabet correctly\n    assert(generated == alphabet)\n\n\n@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\ndef test_embedding_with_clipnorm():\n    model = Sequential()\n    model.add(layers.Embedding(input_dim=1, output_dim=1))\n    model.compile(optimizer=optimizers.SGD(clipnorm=0.1), loss='mse')\n    model.fit(np.array([[0]]), np.array([[[0.5]]]), epochs=1)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/test_tensorflow_integration.py,3,"b""from __future__ import print_function\n\nimport os\nimport tempfile\nimport pytest\nimport keras\nfrom keras import layers\nfrom keras.utils.test_utils import get_test_data\n\n\n@pytest.mark.skipif(keras.backend.backend() != 'tensorflow',\n                    reason='Requires TF backend')\ndef test_tf_optimizer():\n    import tensorflow as tf\n\n    num_hidden = 10\n    output_dim = 2\n    input_dim = 10\n    target = 0.8\n\n    if tf.__version__.startswith('1.'):\n        optimizer = tf.train.AdadeltaOptimizer(\n            learning_rate=1., rho=0.95, epsilon=1e-08)\n    else:\n        optimizer = tf.keras.optimizers.Adadelta(\n            learning_rate=1., rho=0.95, epsilon=1e-08)\n\n    (x_train, y_train), (x_test, y_test) = get_test_data(\n        num_train=1000, num_test=200,\n        input_shape=(input_dim,),\n        classification=True, num_classes=output_dim)\n\n    model = keras.Sequential()\n    model.add(layers.Dense(num_hidden,\n                           activation='relu',\n                           input_shape=(input_dim,)))\n    model.add(layers.Dense(output_dim, activation='softmax'))\n\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n    history = model.fit(x_train, y_train, epochs=8, batch_size=16,\n                        validation_data=(x_test, y_test), verbose=2)\n    assert history.history['val_accuracy'][-1] >= target\n\n    # Test saving.\n    _, fname = tempfile.mkstemp('.h5')\n    model.save(fname)\n    model = keras.models.load_model(fname)\n    assert len(model.weights) == 4\n    os.remove(fname)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/test_vector_data_tasks.py,0,"b""from __future__ import print_function\nimport pytest\n\nfrom keras.utils.test_utils import get_test_data\nfrom keras.models import Sequential\nfrom keras import layers\nimport keras\nfrom keras.utils.np_utils import to_categorical\n\nnum_classes = 2\n\n\ndef test_vector_classification():\n    '''\n    Classify random float vectors into 2 classes with logistic regression\n    using 2 layer neural network with ReLU hidden units.\n    '''\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n                                                         num_test=200,\n                                                         input_shape=(20,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n    # Test with Sequential API\n    model = Sequential([\n        layers.Dense(16, input_shape=(x_train.shape[-1],), activation='relu'),\n        layers.Dense(8),\n        layers.Activation('relu'),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=keras.optimizers.Adam(1e-3),\n                  metrics=['accuracy'])\n    model.summary()\n    history = model.fit(x_train, y_train, epochs=15, batch_size=16,\n                        validation_data=(x_test, y_test),\n                        verbose=0)\n    assert(history.history['val_accuracy'][-1] > 0.8)\n    config = model.get_config()\n    model = Sequential.from_config(config)\n\n\ndef test_vector_classification_functional():\n    (x_train, y_train), _ = get_test_data(num_train=500,\n                                          num_test=200,\n                                          input_shape=(20,),\n                                          classification=True,\n                                          num_classes=num_classes)\n    # Test with functional API\n    inputs = layers.Input(shape=(x_train.shape[-1],))\n    x = layers.Dense(16, activation=keras.activations.relu)(inputs)\n    x = layers.Dense(8)(x)\n    x = layers.Activation('relu')(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    model = keras.models.Model(inputs, outputs)\n    model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n                  optimizer=keras.optimizers.Adam(1e-3),\n                  metrics=['accuracy'])\n    history = model.fit(x_train, y_train, epochs=15, batch_size=16,\n                        validation_data=(x_train, y_train),\n                        verbose=0)\n    assert(history.history['val_accuracy'][-1] > 0.8)\n\n\ndef test_vector_regression():\n    '''\n    Perform float data prediction (regression) using 2 layer MLP\n    with tanh and sigmoid activations.\n    '''\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n                                                         num_test=200,\n                                                         input_shape=(20,),\n                                                         output_shape=(num_classes,),\n                                                         classification=False)\n\n    model = Sequential([\n        layers.Dense(16, input_shape=(x_train.shape[-1],), activation='tanh'),\n        layers.Dense(num_classes)\n    ])\n\n    model.compile(loss='hinge', optimizer=keras.optimizers.Adam(1e-3))\n    history = model.fit(x_train, y_train, epochs=20, batch_size=16,\n                        validation_data=(x_test, y_test), verbose=0)\n    assert (history.history['val_loss'][-1] < 0.9)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/activations_test.py,0,"b'import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras import backend as K\nfrom keras import activations\n\nfrom keras.layers.core import Dense\n\n\ndef get_standard_values():\n    """"""A set of floats used for testing the activations.\n    """"""\n    return np.array([[0, 0.1, 0.5, 0.9, 1.0]], dtype=K.floatx())\n\n\ndef test_serialization():\n    all_activations = [\'softmax\', \'relu\', \'elu\', \'tanh\',\n                       \'sigmoid\', \'hard_sigmoid\', \'linear\',\n                       \'softplus\', \'softsign\', \'selu\']\n    for name in all_activations:\n        fn = activations.get(name)\n        ref_fn = getattr(activations, name)\n        assert fn == ref_fn\n        config = activations.serialize(fn)\n        fn = activations.deserialize(config)\n        assert fn == ref_fn\n\n\ndef test_get_fn():\n    """"""Activations has a convenience ""get"" function. All paths of this\n    function are tested here, although the behaviour in some instances\n    seems potentially surprising (e.g. situation 3)\n    """"""\n\n    # 1. Default returns linear\n    a = activations.get(None)\n    assert a == activations.linear\n\n    # 2. Passing in a layer raises a warning\n    layer = Dense(32)\n    with pytest.warns(UserWarning):\n        a = activations.get(layer)\n\n    # 3. Callables return themselves for some reason\n    a = activations.get(lambda x: 5)\n    assert a(None) == 5\n\n    # 4. Anything else is not a valid argument\n    with pytest.raises(ValueError):\n        a = activations.get(6)\n\n\ndef test_softmax_valid():\n    """"""Test using a reference implementation of softmax.\n    """"""\n    def softmax(values):\n        m = np.max(values)\n        e = np.exp(values - m)\n        return e / np.sum(e)\n\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.softmax(x)])\n    test_values = get_standard_values()\n\n    result = f([test_values])[0]\n    expected = softmax(test_values)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_softmax_invalid():\n    """"""Test for the expected exception behaviour on invalid input\n    """"""\n\n    x = K.placeholder(ndim=1)\n\n    # One dimensional arrays are supposed to raise a value error\n    with pytest.raises(ValueError):\n        f = K.function([x], [activations.softmax(x)])\n\n\ndef test_softmax_3d():\n    """"""Test using a reference implementation of softmax.\n    """"""\n    def softmax(values, axis):\n        m = np.max(values, axis=axis, keepdims=True)\n        e = np.exp(values - m)\n        return e / np.sum(e, axis=axis, keepdims=True)\n\n    x = K.placeholder(ndim=3)\n    f = K.function([x], [activations.softmax(x, axis=1)])\n    test_values = get_standard_values()[:, :, np.newaxis].copy()\n\n    result = f([test_values])[0]\n    expected = softmax(test_values, axis=1)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_time_distributed_softmax():\n    x = K.placeholder(shape=(1, 1, 5))\n    f = K.function([x], [activations.softmax(x)])\n    test_values = get_standard_values()\n    test_values = np.reshape(test_values, (1, 1, np.size(test_values)))\n    f([test_values])[0]\n\n\ndef test_softplus():\n    """"""Test using a reference softplus implementation.\n    """"""\n    def softplus(x):\n        return np.log(np.ones_like(x) + np.exp(x))\n\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.softplus(x)])\n    test_values = get_standard_values()\n\n    result = f([test_values])[0]\n    expected = softplus(test_values)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_softsign():\n    """"""Test using a reference softsign implementation.\n    """"""\n    def softsign(x):\n        return np.divide(x, np.ones_like(x) + np.absolute(x))\n\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.softsign(x)])\n    test_values = get_standard_values()\n\n    result = f([test_values])[0]\n    expected = softsign(test_values)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_sigmoid():\n    """"""Test using a numerically stable reference sigmoid implementation.\n    """"""\n    def ref_sigmoid(x):\n        if x >= 0:\n            return 1 / (1 + np.exp(-x))\n        else:\n            z = np.exp(x)\n            return z / (1 + z)\n    sigmoid = np.vectorize(ref_sigmoid)\n\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.sigmoid(x)])\n    test_values = get_standard_values()\n\n    result = f([test_values])[0]\n    expected = sigmoid(test_values)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_hard_sigmoid():\n    """"""Test using a reference hard sigmoid implementation.\n    """"""\n    def ref_hard_sigmoid(x):\n        x = (x * 0.2) + 0.5\n        z = 0.0 if x <= 0 else (1.0 if x >= 1 else x)\n        return z\n    hard_sigmoid = np.vectorize(ref_hard_sigmoid)\n\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.hard_sigmoid(x)])\n    test_values = get_standard_values()\n\n    result = f([test_values])[0]\n    expected = hard_sigmoid(test_values)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_relu():\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.relu(x)])\n\n    test_values = get_standard_values()\n    result = f([test_values])[0]\n    assert_allclose(result, test_values, rtol=1e-05)\n\n    # Test max_value\n    test_values = np.array([[0.5, 1.5]], dtype=K.floatx())\n    f = K.function([x], [activations.relu(x, max_value=1.)])\n    result = f([test_values])[0]\n    assert np.max(result) <= 1.\n\n    # Test max_value == 6.\n    test_values = np.array([[0.5, 6.]], dtype=K.floatx())\n    f = K.function([x], [activations.relu(x, max_value=1.)])\n    result = f([test_values])[0]\n    assert np.max(result) <= 6.\n\n\ndef test_elu():\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.elu(x, 0.5)])\n\n    test_values = get_standard_values()\n    result = f([test_values])[0]\n    assert_allclose(result, test_values, rtol=1e-05)\n\n    negative_values = np.array([[-1, -2]], dtype=K.floatx())\n    result = f([negative_values])[0]\n    true_result = (np.exp(negative_values) - 1) / 2\n\n    assert_allclose(result, true_result)\n\n\ndef test_selu():\n    x = K.placeholder(ndim=2)\n    f = K.function([x], [activations.selu(x)])\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n\n    positive_values = get_standard_values()\n    result = f([positive_values])[0]\n    assert_allclose(result, positive_values * scale, rtol=1e-05)\n\n    negative_values = np.array([[-1, -2]], dtype=K.floatx())\n\n    result = f([negative_values])[0]\n    true_result = (np.exp(negative_values) - 1) * scale * alpha\n\n    assert_allclose(result, true_result)\n\n\ndef test_tanh():\n    test_values = get_standard_values()\n\n    x = K.placeholder(ndim=2)\n    exp = activations.tanh(x)\n    f = K.function([x], [exp])\n\n    result = f([test_values])[0]\n    expected = np.tanh(test_values)\n    assert_allclose(result, expected, rtol=1e-05)\n\n\ndef test_linear():\n    xs = [1, 5, True, None]\n    for x in xs:\n        assert(x == activations.linear(x))\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/constraints_test.py,0,"b""import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras import backend as K\nfrom keras import constraints\n\n\ndef get_test_values():\n    return [0.1, 0.5, 3, 8, 1e-7]\n\n\ndef get_example_array():\n    np.random.seed(3537)\n    example_array = np.random.random((100, 100)) * 100. - 50.\n    example_array[0, 0] = 0.  # 0 could possibly cause trouble\n    return example_array\n\n\ndef test_serialization():\n    all_activations = ['max_norm', 'non_neg',\n                       'unit_norm', 'min_max_norm']\n    for name in all_activations:\n        fn = constraints.get(name)\n        ref_fn = getattr(constraints, name)()\n        assert fn.__class__ == ref_fn.__class__\n        config = constraints.serialize(fn)\n        fn = constraints.deserialize(config)\n        assert fn.__class__ == ref_fn.__class__\n\n\ndef test_max_norm():\n    array = get_example_array()\n    for m in get_test_values():\n        norm_instance = constraints.max_norm(m)\n        normed = norm_instance(K.variable(array))\n        assert(np.all(K.eval(normed) < m))\n\n    # a more explicit example\n    norm_instance = constraints.max_norm(2.0)\n    x = np.array([[0, 0, 0], [1.0, 0, 0], [3, 0, 0], [3, 3, 3]]).T\n    x_normed_target = np.array([[0, 0, 0], [1.0, 0, 0],\n                                [2.0, 0, 0],\n                                [2. / np.sqrt(3),\n                                 2. / np.sqrt(3),\n                                 2. / np.sqrt(3)]]).T\n    x_normed_actual = K.eval(norm_instance(K.variable(x)))\n    assert_allclose(x_normed_actual, x_normed_target, rtol=1e-05)\n\n\ndef test_non_neg():\n    non_neg_instance = constraints.non_neg()\n    normed = non_neg_instance(K.variable(get_example_array()))\n    assert(np.all(np.min(K.eval(normed), axis=1) == 0.))\n\n\ndef test_unit_norm():\n    unit_norm_instance = constraints.unit_norm()\n    normalized = unit_norm_instance(K.variable(get_example_array()))\n    norm_of_normalized = np.sqrt(np.sum(K.eval(normalized) ** 2, axis=0))\n    # In the unit norm constraint, it should be equal to 1.\n    difference = norm_of_normalized - 1.\n    largest_difference = np.max(np.abs(difference))\n    assert(np.abs(largest_difference) < 10e-5)\n\n\ndef test_min_max_norm():\n    array = get_example_array()\n    for m in get_test_values():\n        norm_instance = constraints.min_max_norm(min_value=m, max_value=m * 2)\n        normed = norm_instance(K.variable(array))\n        value = K.eval(normed)\n        l2 = np.sqrt(np.sum(np.square(value), axis=0))\n        assert l2[l2 < m].size == 0\n        assert l2[l2 > m * 2 + 1e-5].size == 0\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/initializers_test.py,0,"b""import pytest\nimport numpy as np\n\nfrom keras import initializers\nfrom keras import backend as K\n\n# 2D tensor test fixture\nFC_SHAPE = (200, 100)\n\n# 4D convolution in th order. This shape has the same effective shape as FC_SHAPE\nCONV_SHAPE = (25, 25, 20, 20)\n\n\ndef _runner(init, shape, target_mean=None, target_std=None,\n            target_max=None, target_min=None):\n    variable = K.variable(init(shape))\n    output = K.get_value(variable)\n    lim = 3e-2\n    if target_std is not None:\n        assert abs(output.std() - target_std) < lim\n    if target_mean is not None:\n        assert abs(output.mean() - target_mean) < lim\n    if target_max is not None:\n        assert abs(output.max() - target_max) < lim\n    if target_min is not None:\n        assert abs(output.min() - target_min) < lim\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_uniform(tensor_shape):\n    _runner(initializers.RandomUniform(minval=-1, maxval=1), tensor_shape,\n            target_mean=0., target_max=1, target_min=-1)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_normal(tensor_shape):\n    _runner(initializers.RandomNormal(mean=0, stddev=1), tensor_shape,\n            target_mean=0., target_std=1)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_truncated_normal(tensor_shape):\n    _runner(initializers.TruncatedNormal(mean=0, stddev=1), tensor_shape,\n            target_mean=0., target_max=2, target_min=-2)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_constant(tensor_shape):\n    _runner(initializers.Constant(2), tensor_shape,\n            target_mean=2, target_max=2, target_min=2)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_lecun_uniform(tensor_shape):\n    fan_in, _ = initializers._compute_fans(tensor_shape)\n    std = np.sqrt(1. / fan_in)\n    _runner(initializers.lecun_uniform(), tensor_shape,\n            target_mean=0., target_std=std)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_glorot_uniform(tensor_shape):\n    fan_in, fan_out = initializers._compute_fans(tensor_shape)\n    std = np.sqrt(2. / (fan_in + fan_out))\n    _runner(initializers.glorot_uniform(), tensor_shape,\n            target_mean=0., target_std=std)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_he_uniform(tensor_shape):\n    fan_in, _ = initializers._compute_fans(tensor_shape)\n    std = np.sqrt(2. / fan_in)\n    _runner(initializers.he_uniform(), tensor_shape,\n            target_mean=0., target_std=std)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_lecun_normal(tensor_shape):\n    fan_in, _ = initializers._compute_fans(tensor_shape)\n    std = np.sqrt(1. / fan_in)\n    _runner(initializers.lecun_normal(), tensor_shape,\n            target_mean=0., target_std=std)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_glorot_normal(tensor_shape):\n    fan_in, fan_out = initializers._compute_fans(tensor_shape)\n    std = np.sqrt(2. / (fan_in + fan_out))\n    _runner(initializers.glorot_normal(), tensor_shape,\n            target_mean=0., target_std=std)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_he_normal(tensor_shape):\n    fan_in, _ = initializers._compute_fans(tensor_shape)\n    std = np.sqrt(2. / fan_in)\n    _runner(initializers.he_normal(), tensor_shape,\n            target_mean=0., target_std=std)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_orthogonal(tensor_shape):\n    _runner(initializers.orthogonal(), tensor_shape,\n            target_mean=0.)\n\n\ndef test_orthogonal_init_does_not_affect_global_rng():\n    np.random.seed(1337)\n    before = np.random.randint(0, 100, size=10)\n\n    np.random.seed(1337)\n    init = initializers.orthogonal(seed=9876)\n    init(shape=(10, 5))\n    after = np.random.randint(0, 100, size=10)\n\n    assert np.array_equal(before, after)\n\n\n@pytest.mark.parametrize('tensor_shape',\n                         [(100, 100), (10, 20), (30, 80), (1, 2, 3, 4)],\n                         ids=['FC', 'RNN', 'RNN_INVALID', 'CONV'])\ndef test_identity(tensor_shape):\n    target_mean = (1. * min(tensor_shape)) / (tensor_shape[0] * tensor_shape[1])\n    if len(tensor_shape) > 2:\n        with pytest.raises(ValueError):\n            _runner(initializers.identity(), tensor_shape,\n                    target_mean=target_mean, target_max=1.)\n    else:\n        _runner(initializers.identity(), tensor_shape,\n                target_mean=target_mean, target_max=1.)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_zero(tensor_shape):\n    _runner(initializers.zeros(), tensor_shape,\n            target_mean=0., target_max=0.)\n\n\n@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\ndef test_one(tensor_shape):\n    _runner(initializers.ones(), tensor_shape,\n            target_mean=1., target_max=1.)\n\n\n@pytest.mark.parametrize('initializer',\n                         [initializers.orthogonal,\n                          initializers.uniform,\n                          initializers.normal,\n                          initializers.truncated_normal,\n                          initializers.VarianceScaling],\n                         ids=['orthogonal',\n                              'uniform',\n                              'normal',\n                              'truncated_normal',\n                              'variance_scaling'])\ndef test_statefulness(initializer):\n    # Test that calling a same seeded random initializer\n    # in succession results in different values.\n    init = initializer(seed=1337)\n    samples = [init((2, 2)) for _ in range(2)]\n    samples = [K.get_value(K.variable(x)) for x in samples]\n    assert np.mean(np.abs(samples[0] - samples[1])) > 0.\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/losses_test.py,0,"b'import pytest\nimport numpy as np\n\nimport keras\nfrom keras import losses\nfrom keras import backend as K\nfrom keras.utils import losses_utils\nfrom keras.utils.generic_utils import custom_object_scope\n\n\nall_functions = [losses.mean_squared_error,\n                 losses.mean_absolute_error,\n                 losses.mean_absolute_percentage_error,\n                 losses.mean_squared_logarithmic_error,\n                 losses.squared_hinge,\n                 losses.hinge,\n                 losses.categorical_crossentropy,\n                 losses.binary_crossentropy,\n                 losses.kullback_leibler_divergence,\n                 losses.poisson,\n                 losses.cosine_proximity,\n                 losses.logcosh,\n                 losses.categorical_hinge]\nall_classes = [\n    losses.Hinge,\n    losses.SquaredHinge,\n    losses.CategoricalHinge,\n    losses.Poisson,\n    losses.LogCosh,\n    losses.KLDivergence,\n    losses.Huber,\n    # losses.SparseCategoricalCrossentropy,\n    losses.BinaryCrossentropy,\n    losses.MeanSquaredLogarithmicError,\n    losses.MeanAbsolutePercentageError,\n    losses.MeanAbsoluteError,\n    losses.MeanSquaredError,\n]\n\n\nclass MSE_MAE_loss(object):\n    """"""Loss function with internal state, for testing serialization code.""""""\n\n    def __init__(self, mse_fraction):\n        self.mse_fraction = mse_fraction\n\n    def __call__(self, y_true, y_pred, sample_weight=None):\n        return (self.mse_fraction * losses.mse(y_true, y_pred) +\n                (1 - self.mse_fraction) * losses.mae(y_true, y_pred))\n\n    def get_config(self):\n        return {\'mse_fraction\': self.mse_fraction}\n\n\nclass TestLossFunctions(object):\n\n    @pytest.mark.parametrize(\'loss_fn\', all_functions)\n    def test_objective_shapes_3d(self, loss_fn):\n        y_a = K.variable(np.random.random((5, 6, 7)))\n        y_b = K.variable(np.random.random((5, 6, 7)))\n        objective_output = loss_fn(y_a, y_b)\n        assert K.eval(objective_output).shape == (5, 6)\n\n    @pytest.mark.parametrize(\'loss_fn\', all_functions)\n    def test_objective_shapes_2d(self, loss_fn):\n        y_a = K.variable(np.random.random((6, 7)))\n        y_b = K.variable(np.random.random((6, 7)))\n        objective_output = loss_fn(y_a, y_b)\n        assert K.eval(objective_output).shape == (6,)\n\n    def test_cce_one_hot(self):\n        y_a = K.variable(np.random.randint(0, 7, (5, 6)))\n        y_b = K.variable(np.random.random((5, 6, 7)))\n        objective_output = losses.sparse_categorical_crossentropy(y_a, y_b)\n        assert K.eval(objective_output).shape == (5, 6)\n\n        y_a = K.variable(np.random.randint(0, 7, (6,)))\n        y_b = K.variable(np.random.random((6, 7)))\n        assert K.eval(losses.sparse_categorical_crossentropy(y_a, y_b)).shape == (6,)\n\n    def test_categorical_hinge(self):\n        y_pred = K.variable(np.array([[0.3, 0.2, 0.1],\n                                      [0.1, 0.2, 0.7]]))\n        y_true = K.variable(np.array([[0, 1, 0],\n                                      [1, 0, 0]]))\n        expected_loss = ((0.3 - 0.2 + 1) + (0.7 - 0.1 + 1)) / 2.0\n        loss = K.eval(losses.categorical_hinge(y_true, y_pred))\n        assert np.isclose(expected_loss, np.mean(loss))\n\n    def test_sparse_categorical_crossentropy(self):\n        y_pred = K.variable(np.array([[0.3, 0.6, 0.1],\n                                      [0.1, 0.2, 0.7]]))\n        y_true = K.variable(np.array([1, 2]))\n        expected_loss = - (np.log(0.6) + np.log(0.7)) / 2\n        loss = K.eval(losses.sparse_categorical_crossentropy(y_true, y_pred))\n        assert np.isclose(expected_loss, np.mean(loss))\n\n    def test_sparse_categorical_crossentropy_4d(self):\n        y_pred = K.variable(np.array([[[[0.7, 0.1, 0.2],\n                                        [0.0, 0.3, 0.7],\n                                        [0.1, 0.1, 0.8]],\n                                       [[0.3, 0.7, 0.0],\n                                        [0.3, 0.4, 0.3],\n                                        [0.2, 0.5, 0.3]],\n                                       [[0.8, 0.1, 0.1],\n                                        [1.0, 0.0, 0.0],\n                                        [0.4, 0.3, 0.3]]]]))\n        y_true = K.variable(np.array([[[0, 1, 0],\n                                       [2, 1, 0],\n                                       [2, 2, 1]]]))\n        expected_loss = - (np.log(0.7) + np.log(0.3) + np.log(0.1) +\n                           np.log(K.epsilon()) + np.log(0.4) + np.log(0.2) +\n                           np.log(0.1) + np.log(K.epsilon()) + np.log(0.3)) / 9\n        loss = K.eval(losses.sparse_categorical_crossentropy(y_true, y_pred))\n        assert np.isclose(expected_loss, np.mean(loss))\n\n    def test_serializing_loss_class(self):\n        orig_loss_class = MSE_MAE_loss(0.3)\n        with custom_object_scope({\'MSE_MAE_loss\': MSE_MAE_loss}):\n            serialized = losses.serialize(orig_loss_class)\n\n        with custom_object_scope({\'MSE_MAE_loss\': MSE_MAE_loss}):\n            deserialized = losses.deserialize(serialized)\n        assert isinstance(deserialized, MSE_MAE_loss)\n        assert deserialized.mse_fraction == 0.3\n\n    def test_serializing_model_with_loss_class(self, tmpdir):\n        model_filename = str(tmpdir / \'custom_loss.hdf\')\n\n        with custom_object_scope({\'MSE_MAE_loss\': MSE_MAE_loss}):\n            loss = MSE_MAE_loss(0.3)\n            inputs = keras.layers.Input((2,))\n            outputs = keras.layers.Dense(1, name=\'model_output\')(inputs)\n            model = keras.models.Model(inputs, outputs)\n            model.compile(optimizer=\'sgd\', loss={\'model_output\': loss})\n            model.fit(np.random.rand(256, 2), np.random.rand(256, 1))\n            model.save(model_filename)\n\n        with custom_object_scope({\'MSE_MAE_loss\': MSE_MAE_loss}):\n            loaded_model = keras.models.load_model(model_filename)\n            loaded_model.predict(np.random.rand(128, 2))\n\n    def test_loss_wrapper(self):\n        loss_fn = losses.get(\'mse\')\n        mse_obj = losses.LossFunctionWrapper(loss_fn, name=loss_fn.__name__)\n\n        assert mse_obj.name == \'mean_squared_error\'\n        assert (mse_obj.reduction == losses_utils.Reduction.SUM_OVER_BATCH_SIZE)\n\n        y_true = K.constant([[1., 9.], [2., 5.]])\n        y_pred = K.constant([[4., 8.], [12., 3.]])\n        sample_weight = K.constant([1.2, 0.5])\n        loss = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        # mse = [((4 - 1)^2 + (8 - 9)^2) / 2, ((12 - 2)^2 + (3 - 5)^2) / 2]\n        # mse = [5, 52]\n        # weighted_mse = [5 * 1.2, 52 * 0.5] = [6, 26]\n        # reduced_weighted_mse = (6 + 26) / 2 =\n        np.allclose(K.eval(loss), 16, atol=1e-2)\n\n\nskipif_not_tf = pytest.mark.skipif(\n    K.backend() != \'tensorflow\',\n    reason=\'Need TensorFlow to __call__ a loss\')\n\n\nclass TestLossClasses(object):\n\n    @pytest.mark.parametrize(\'cls\', all_classes)\n    def test_objective_shapes_3d(self, cls):\n        y_a = K.variable(np.random.random((5, 6, 7)))\n        y_b = K.variable(np.random.random((5, 6, 7)))\n        sw = K.variable(np.random.random((5, 6)))\n        obj_fn = cls(name=\'test\')\n        objective_output = obj_fn(y_a, y_b, sample_weight=sw)\n        assert K.eval(objective_output).shape == ()\n\n    @pytest.mark.parametrize(\'cls\', all_classes)\n    def test_objective_shapes_2d(self, cls):\n        y_a = K.variable(np.random.random((6, 7)))\n        y_b = K.variable(np.random.random((6, 7)))\n        sw = K.variable(np.random.random((6,)))\n        obj_fn = cls(name=\'test\')\n        objective_output = obj_fn(y_a, y_b, sample_weight=sw)\n        assert K.eval(objective_output).shape == ()\n\n\n@skipif_not_tf\nclass TestMeanSquaredError:\n\n    def test_config(self):\n        mse_obj = losses.MeanSquaredError(\n            reduction=losses_utils.Reduction.SUM, name=\'mse_1\')\n        assert mse_obj.name == \'mse_1\'\n        assert mse_obj.reduction == losses_utils.Reduction.SUM\n\n    def test_all_correct_unweighted(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mse_obj(y_true, y_true)\n        assert np.isclose(K.eval(loss), 0.0)\n\n    def test_unweighted(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mse_obj(y_true, y_pred)\n        assert np.isclose(K.eval(loss), 49.5, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mse_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), 113.85, atol=1e-3)\n\n    def test_sample_weighted(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        sample_weight = K.constant([1.2, 3.4], shape=(2, 1))\n        loss = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 767.8 / 6, atol=1e-3)\n\n    def test_timestep_weighted(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3, 1))\n        sample_weight = K.constant([3, 6, 5, 0, 4, 2], shape=(2, 3))\n        loss = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 97.833, atol=1e-3)\n\n    def test_zero_weighted(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mse_obj(y_true, y_pred, sample_weight=0)\n        assert np.isclose(K.eval(loss), 0.0)\n\n    def test_invalid_sample_weight(self):\n        mse_obj = losses.MeanSquaredError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3, 1))\n        sample_weight = K.constant([3, 6, 5, 0], shape=(2, 2))\n        with pytest.raises(Exception):\n            mse_obj(y_true, y_pred, sample_weight=sample_weight)\n\n    def test_no_reduction(self):\n        mse_obj = losses.MeanSquaredError(\n            reduction=losses_utils.Reduction.NONE)\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mse_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.allclose(K.eval(loss), [84.3333, 143.3666], atol=1e-3)\n\n    def test_sum_reduction(self):\n        mse_obj = losses.MeanSquaredError(\n            reduction=losses_utils.Reduction.SUM)\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mse_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), 227.69998, atol=1e-3)\n\n\n@skipif_not_tf\nclass TestMeanAbsoluteError(object):\n\n    def test_config(self):\n        mae_obj = losses.MeanAbsoluteError(\n            reduction=losses_utils.Reduction.SUM, name=\'mae_1\')\n        assert mae_obj.name == \'mae_1\'\n        assert mae_obj.reduction == losses_utils.Reduction.SUM\n\n    def test_all_correct_unweighted(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mae_obj(y_true, y_true)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n    def test_unweighted(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mae_obj(y_true, y_pred)\n        assert np.isclose(K.eval(loss), 5.5, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mae_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), 12.65, atol=1e-3)\n\n    def test_sample_weighted(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        sample_weight = K.constant([1.2, 3.4], shape=(2, 1))\n        loss = mae_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 81.4 / 6, atol=1e-3)\n\n    def test_timestep_weighted(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3, 1))\n        sample_weight = K.constant([3, 6, 5, 0, 4, 2], shape=(2, 3))\n        loss = mae_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 13.833, atol=1e-3)\n\n    def test_zero_weighted(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mae_obj(y_true, y_pred, sample_weight=0)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n    def test_invalid_sample_weight(self):\n        mae_obj = losses.MeanAbsoluteError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3, 1))\n        sample_weight = K.constant([3, 6, 5, 0], shape=(2, 2))\n        with pytest.raises(Exception):\n            mae_obj(y_true, y_pred, sample_weight=sample_weight)\n\n    def test_no_reduction(self):\n        mae_obj = losses.MeanAbsoluteError(\n            reduction=losses_utils.Reduction.NONE)\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mae_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.allclose(K.eval(loss), [10.7333, 14.5666], atol=1e-3)\n\n    def test_sum_reduction(self):\n        mae_obj = losses.MeanAbsoluteError(\n            reduction=losses_utils.Reduction.SUM)\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mae_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), 25.29999, atol=1e-3)\n\n\n@skipif_not_tf\nclass TestMeanAbsolutePercentageError(object):\n\n    def test_config(self):\n        mape_obj = losses.MeanAbsolutePercentageError(\n            reduction=losses_utils.Reduction.SUM, name=\'mape_1\')\n        assert mape_obj.name == \'mape_1\'\n        assert mape_obj.reduction == losses_utils.Reduction.SUM\n\n    def test_all_correct_unweighted(self):\n        mape_obj = losses.MeanAbsolutePercentageError()\n        y_true = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mape_obj(y_true, y_true)\n        assert np.allclose(K.eval(loss), 0.0, atol=1e-3)\n\n    def test_unweighted(self):\n        mape_obj = losses.MeanAbsolutePercentageError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mape_obj(y_true, y_pred)\n        assert np.allclose(K.eval(loss), 211.8518, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        mape_obj = losses.MeanAbsolutePercentageError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mape_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.allclose(K.eval(loss), 487.259, atol=1e-3)\n\n    def test_sample_weighted(self):\n        mape_obj = losses.MeanAbsolutePercentageError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        sample_weight = K.constant([1.2, 3.4], shape=(2, 1))\n        loss = mape_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(K.eval(loss), 422.8888, atol=1e-3)\n\n    def test_timestep_weighted(self):\n        mape_obj = losses.MeanAbsolutePercentageError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3, 1))\n        sample_weight = K.constant([3, 6, 5, 0, 4, 2], shape=(2, 3))\n        loss = mape_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(K.eval(loss), 694.4445, atol=1e-3)\n\n    def test_zero_weighted(self):\n        mape_obj = losses.MeanAbsolutePercentageError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mape_obj(y_true, y_pred, sample_weight=0)\n        assert np.allclose(K.eval(loss), 0.0, atol=1e-3)\n\n    def test_no_reduction(self):\n        mape_obj = losses.MeanAbsolutePercentageError(\n            reduction=losses_utils.Reduction.NONE)\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = mape_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.allclose(K.eval(loss), [621.8518, 352.6666], atol=1e-3)\n\n\n@skipif_not_tf\nclass TestMeanSquaredLogarithmicError(object):\n\n    def test_config(self):\n        msle_obj = losses.MeanSquaredLogarithmicError(\n            reduction=losses_utils.Reduction .SUM, name=\'mape_1\')\n        assert msle_obj.name == \'mape_1\'\n        assert msle_obj.reduction == losses_utils.Reduction .SUM\n\n    def test_unweighted(self):\n        msle_obj = losses.MeanSquaredLogarithmicError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = msle_obj(y_true, y_pred)\n        assert np.allclose(K.eval(loss), 1.4370, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        msle_obj = losses.MeanSquaredLogarithmicError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = msle_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.allclose(K.eval(loss), 3.3051, atol=1e-3)\n\n    def test_sample_weighted(self):\n        msle_obj = losses.MeanSquaredLogarithmicError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        sample_weight = K.constant([1.2, 3.4], shape=(2, 1))\n        loss = msle_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(K.eval(loss), 3.7856, atol=1e-3)\n\n    def test_timestep_weighted(self):\n        msle_obj = losses.MeanSquaredLogarithmicError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3, 1))\n        sample_weight = K.constant([3, 6, 5, 0, 4, 2], shape=(2, 3))\n        loss = msle_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(K.eval(loss), 2.6473, atol=1e-3)\n\n    def test_zero_weighted(self):\n        msle_obj = losses.MeanSquaredLogarithmicError()\n        y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n        y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n        loss = msle_obj(y_true, y_pred, sample_weight=0)\n        assert np.allclose(K.eval(loss), 0.0, atol=1e-3)\n\n\n@skipif_not_tf\nclass TestBinaryCrossentropy(object):\n\n    def test_config(self):\n        bce_obj = losses.BinaryCrossentropy(\n            reduction=losses_utils.Reduction.SUM, name=\'bce_1\')\n        assert bce_obj.name == \'bce_1\'\n        assert bce_obj.reduction == losses_utils.Reduction.SUM\n\n    def test_all_correct_unweighted(self):\n        y_true = K.constant([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n        bce_obj = losses.BinaryCrossentropy()\n        loss = bce_obj(y_true, y_true)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[100.0, -100.0, -100.0],\n                             [-100.0, 100.0, -100.0],\n                             [-100.0, -100.0, 100.0]])\n        bce_obj = losses.BinaryCrossentropy(from_logits=True)\n        loss = bce_obj(y_true, logits)\n        assert np.isclose(K.eval(loss), 0.0, 3)\n\n    def test_unweighted(self):\n        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n        bce_obj = losses.BinaryCrossentropy()\n        loss = bce_obj(y_true, y_pred)\n\n        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n        # y` = clip(output, EPSILON, 1. - EPSILON)\n        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n\n        # Loss = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n        #      = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n        #         -log(Y_MAX + EPSILON), -log(1)]\n        #      = [0, 15.33, 0, 0]\n        # Reduced loss = 15.33 / 4\n\n        assert np.isclose(K.eval(loss), 3.833, atol=1e-3)\n\n        # Test with logits.\n        y_true = K.constant([[1., 0., 1.], [0., 1., 1.]])\n        logits = K.constant([[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]])\n        bce_obj = losses.BinaryCrossentropy(from_logits=True)\n        loss = bce_obj(y_true, logits)\n\n        # Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n        #            (where x = logits and z = y_true)\n        #      = [((100 - 100 * 1 + log(1 + exp(-100))) +\n        #          (0 + 100 * 0 + log(1 + exp(-100))) +\n        #          (100 - 100 * 1 + log(1 + exp(-100))),\n        #         ((100 - 100 * 0 + log(1 + exp(-100))) +\n        #          (100 - 100 * 1 + log(1 + exp(-100))) +\n        #          (0 + 100 * 1 + log(1 + exp(-100))))]\n        #      = [(0 + 0 + 0) / 3, 200 / 3]\n        # Reduced loss = (0 + 66.666) / 2\n\n        assert np.isclose(K.eval(loss), 33.333, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        bce_obj = losses.BinaryCrossentropy()\n        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n        loss = bce_obj(y_true, y_pred, sample_weight=2.3)\n\n        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n        # y` = clip(output, EPSILON, 1. - EPSILON)\n        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n\n        # Loss = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n        #      = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n        #         -log(Y_MAX + EPSILON), -log(1)]\n        #      = [0, 15.33, 0, 0]\n        # Weighted loss = [0, 15.33 * 2.3, 0, 0]\n        # Reduced loss = 15.33 * 2.3 / 4\n\n        assert np.isclose(K.eval(loss), 8.817, atol=1e-3)\n\n        # Test with logits.\n        y_true = K.constant([[1, 0, 1], [0, 1, 1]])\n        logits = K.constant([[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]])\n        bce_obj = losses.BinaryCrossentropy(from_logits=True)\n        loss = bce_obj(y_true, logits, sample_weight=2.3)\n\n        # Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n        #            (where x = logits and z = y_true)\n        # Loss = [(0 + 0 + 0) / 3, 200 / 3]\n        # Weighted loss = [0 * 2.3, 66.666 * 2.3]\n        # Reduced loss = (0 + 66.666 * 2.3) / 2\n\n        assert np.isclose(K.eval(loss), 76.667, atol=1e-3)\n\n    def test_sample_weighted(self):\n        bce_obj = losses.BinaryCrossentropy()\n        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n        sample_weight = K.constant([1.2, 3.4], shape=(2, 1))\n        loss = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n        # y` = clip(output, EPSILON, 1. - EPSILON)\n        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n\n        # Loss = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n        #      = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n        #         -log(Y_MAX + EPSILON), -log(1)]\n        #      = [0, 15.33, 0, 0]\n        # Reduced loss = 15.33 * 1.2 / 4\n\n        assert np.isclose(K.eval(loss), 4.6, atol=1e-3)\n\n        # Test with logits.\n        y_true = K.constant([[1, 0, 1], [0, 1, 1]])\n        logits = K.constant([[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]])\n        weights = K.constant([4, 3])\n        bce_obj = losses.BinaryCrossentropy(from_logits=True)\n        loss = bce_obj(y_true, logits, sample_weight=weights)\n\n        # Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n        #            (where x = logits and z = y_true)\n        # Loss = [(0 + 0 + 0)/3, 200 / 3]\n        # Weighted loss = [0 * 4, 66.666 * 3]\n        # Reduced loss = (0 + 66.666 * 3) / 2\n\n        assert np.isclose(K.eval(loss), 100, atol=1e-3)\n\n    def test_no_reduction(self):\n        y_true = K.constant([[1, 0, 1], [0, 1, 1]])\n        logits = K.constant([[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]])\n        bce_obj = losses.BinaryCrossentropy(\n            from_logits=True, reduction=losses_utils.Reduction.NONE)\n        loss = bce_obj(y_true, logits)\n\n        # Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n        #            (where x = logits and z = y_true)\n        # Loss = [(0 + 0 + 0)/3, (200)/3]\n\n        assert np.allclose(K.eval(loss), (0., 66.6666), atol=1e-3)\n\n    def test_label_smoothing(self):\n        logits = K.constant([[100.0, -100.0, -100.0]])\n        y_true = K.constant([[1, 0, 1]])\n        label_smoothing = 0.1\n        # Loss: max(x, 0) - x * z + log(1 + exp(-abs(x)))\n        #            (where x = logits and z = y_true)\n        # Label smoothing: z\' = z * (1 - L) + 0.5L\n        #                  1  = 1 - 0.5L\n        #                  0  = 0.5L\n        # Applying the above two fns to the given input:\n        # (100 - 100 * (1 - 0.5 L)  + 0 +\n        #  0   + 100 * (0.5 L)      + 0 +\n        #  0   + 100 * (1 - 0.5 L)  + 0) * (1/3)\n        #  = (100 + 50L) * 1/3\n        bce_obj = losses.BinaryCrossentropy(\n            from_logits=True, label_smoothing=label_smoothing)\n        loss = bce_obj(y_true, logits)\n        expected_value = (100.0 + 50.0 * label_smoothing) / 3.0\n        assert np.isclose(K.eval(loss), expected_value, atol=1e-3)\n\n\n@skipif_not_tf\nclass TestCategoricalCrossentropy(object):\n\n    def test_config(self):\n        cce_obj = losses.CategoricalCrossentropy(\n            reduction=losses_utils.Reduction.SUM, name=\'bce_1\')\n        assert cce_obj.name == \'bce_1\'\n        assert cce_obj.reduction == losses_utils.Reduction.SUM\n\n    def test_all_correct_unweighted(self):\n        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        y_pred = K.constant([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n        cce_obj = losses.CategoricalCrossentropy()\n        loss = cce_obj(y_true, y_pred)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[10., 0., 0.], [0., 10., 0.], [0., 0., 10.]])\n        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n    def test_unweighted(self):\n        cce_obj = losses.CategoricalCrossentropy()\n        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        y_pred = K.constant(\n            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n        loss = cce_obj(y_true, y_pred)\n        assert np.isclose(K.eval(loss), .3239, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits)\n        assert np.isclose(K.eval(loss), .05737, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        cce_obj = losses.CategoricalCrossentropy()\n        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        y_pred = K.constant(\n            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n        loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), .7449, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), .132, atol=1e-3)\n\n    def test_sample_weighted(self):\n        cce_obj = losses.CategoricalCrossentropy()\n        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        y_pred = K.constant(\n            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n        sample_weight = K.constant([[1.2], [3.4], [5.6]], shape=(3, 1))\n        loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 1.0696, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 0.31829, atol=1e-3)\n\n    def test_no_reduction(self):\n        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.CategoricalCrossentropy(\n            from_logits=True, reduction=losses_utils.Reduction.NONE)\n        loss = cce_obj(y_true, logits)\n        assert np.allclose(K.eval(loss), (0.001822, 0.000459, 0.169846), atol=1e-3)\n\n    def test_label_smoothing(self):\n        logits = K.constant([[100.0, -100.0, -100.0]])\n        y_true = K.constant([[1, 0, 0]])\n        label_smoothing = 0.1\n        # Softmax Cross Entropy Loss: -\\sum_i p_i \\log q_i\n        # where for a softmax activation\n        # \\log q_i = x_i - \\log \\sum_j \\exp x_j\n        #          = x_i - x_max - \\log \\sum_j \\exp (x_j - x_max)\n        # For our activations, [100, -100, -100]\n        # \\log ( exp(0) + exp(-200) + exp(-200) ) = 0\n        # so our log softmaxes become: [0, -200, -200]\n        # Label smoothing: z\' = z * (1 - L) + L/n\n        #                  1  = 1 - L + L/n\n        #                  0  = L/n\n        # Applying the above two fns to the given input:\n        # -0 * (1 - L + L/n) + 200 * L/n + 200 * L/n = 400 L/n\n        cce_obj = losses.CategoricalCrossentropy(\n            from_logits=True, label_smoothing=label_smoothing)\n        loss = cce_obj(y_true, logits)\n        expected_value = 400.0 * label_smoothing / 3.0\n        assert np.isclose(K.eval(loss), expected_value, atol=1e-3)\n\n\n@skipif_not_tf\nclass TestSparseCategoricalCrossentropy(object):\n\n    def test_config(self):\n        cce_obj = losses.SparseCategoricalCrossentropy(\n            reduction=losses_utils.Reduction.SUM, name=\'scc\')\n        assert cce_obj.name == \'scc\'\n        assert cce_obj.reduction == losses_utils.Reduction.SUM\n\n    def test_all_correct_unweighted(self):\n        y_true = K.constant([[0], [1], [2]])\n        y_pred = K.constant([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n        cce_obj = losses.SparseCategoricalCrossentropy()\n        loss = cce_obj(y_true, y_pred)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[10., 0., 0.], [0., 10., 0.], [0., 0., 10.]])\n        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits)\n        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n\n    def test_unweighted(self):\n        cce_obj = losses.SparseCategoricalCrossentropy()\n        y_true = K.constant([0, 1, 2])\n        y_pred = K.constant(\n            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n        loss = cce_obj(y_true, y_pred)\n        assert np.isclose(K.eval(loss), .3239, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits)\n        assert np.isclose(K.eval(loss), .0573, atol=1e-3)\n\n    def test_scalar_weighted(self):\n        cce_obj = losses.SparseCategoricalCrossentropy()\n        y_true = K.constant([[0], [1], [2]])\n        y_pred = K.constant(\n            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n        loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), .7449, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits, sample_weight=2.3)\n        assert np.isclose(K.eval(loss), .1317, atol=1e-3)\n\n    def test_sample_weighted(self):\n        cce_obj = losses.SparseCategoricalCrossentropy()\n        y_true = K.constant([[0], [1], [2]])\n        y_pred = K.constant(\n            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n        sample_weight = K.constant([[1.2], [3.4], [5.6]], shape=(3, 1))\n        loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 1.0696, atol=1e-3)\n\n        # Test with logits.\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n        loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n        assert np.isclose(K.eval(loss), 0.31829, atol=1e-3)\n\n    def test_no_reduction(self):\n        y_true = K.constant([[0], [1], [2]])\n        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n        cce_obj = losses.SparseCategoricalCrossentropy(\n            from_logits=True, reduction=losses_utils.Reduction.NONE)\n        loss = cce_obj(y_true, logits)\n        assert np.allclose(K.eval(loss), (0.001822, 0.000459, 0.169846), atol=1e-3)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/metrics_confusion_matrix_test.py,1,"b'""""""Tests for Keras confusion matrix metrics classes.""""""\nimport pytest\nimport numpy as np\n\nfrom keras import metrics\nfrom keras import backend as K\nfrom keras.utils import metrics_utils\n\nif K.backend() != \'tensorflow\':\n    # Need TensorFlow to use metric.__call__\n    pytestmark = pytest.mark.skip\n\nimport tensorflow as tf\n\n\nclass TestFalsePositives(object):\n\n    def test_config(self):\n        fp_obj = metrics.FalsePositives(name=\'my_fp\', thresholds=[0.4, 0.9])\n        assert fp_obj.name == \'my_fp\'\n        assert len(fp_obj.weights) == 1\n        assert fp_obj.thresholds == [0.4, 0.9]\n\n        # Check save and restore config\n        fp_obj2 = metrics.FalsePositives.from_config(fp_obj.get_config())\n        assert fp_obj2.name == \'my_fp\'\n        assert len(fp_obj2.weights) == 1\n        assert fp_obj2.thresholds == [.4, 0.9]\n\n    def test_unweighted(self):\n        fp_obj = metrics.FalsePositives()\n\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1), (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1), (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n\n        result = fp_obj(y_true, y_pred)\n        assert np.allclose(7., K.eval(result))\n\n    def test_weighted(self):\n        fp_obj = metrics.FalsePositives()\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1), (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1), (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n        sample_weight = (1., 1.5, 2., 2.5)\n        result = fp_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(14., K.eval(result))\n\n    def test_unweighted_with_thresholds(self):\n        fp_obj = metrics.FalsePositives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0), (1, 1, 1, 1))\n\n        result = fp_obj(y_true, y_pred)\n        assert np.allclose([7., 4., 2.], K.eval(result))\n\n    def test_weighted_with_thresholds(self):\n        fp_obj = metrics.FalsePositives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0), (1, 1, 1, 1))\n        sample_weight = ((1.0, 2.0, 3.0, 5.0), (7.0, 11.0, 13.0, 17.0),\n                         (19.0, 23.0, 29.0, 31.0), (5.0, 15.0, 10.0, 0))\n\n        result = fp_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose([125., 42., 12.], K.eval(result))\n\n    def test_threshold_limit(self):\n        with pytest.raises(Exception):\n            metrics.FalsePositives(thresholds=[-1, 0.5, 2])\n\n        with pytest.raises(Exception):\n            metrics.FalsePositives(thresholds=[None])\n\n\nclass TestTruePositives(object):\n\n    def test_config(self):\n        tp_obj = metrics.TruePositives(name=\'my_tp\', thresholds=[0.4, 0.9])\n        assert tp_obj.name == \'my_tp\'\n        assert len(tp_obj.weights) == 1\n        assert tp_obj.thresholds == [0.4, 0.9]\n\n        # Check save and restore config\n        tp_obj2 = metrics.TruePositives.from_config(tp_obj.get_config())\n        assert tp_obj2.name == \'my_tp\'\n        assert len(tp_obj2.weights) == 1\n        assert tp_obj2.thresholds == [0.4, 0.9]\n\n    def test_unweighted(self):\n        tp_obj = metrics.TruePositives()\n\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n\n        result = tp_obj(y_true, y_pred)\n        assert np.allclose(7., K.eval(result))\n\n    def test_weighted(self):\n        tp_obj = metrics.TruePositives()\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n        sample_weight = (1., 1.5, 2., 2.5)\n        result = tp_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(12., K.eval(result))\n\n    def test_unweighted_with_thresholds(self):\n        tp_obj = metrics.TruePositives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0),\n                  (1, 1, 1, 1))\n\n        result = tp_obj(y_true, y_pred)\n        assert np.allclose([6., 3., 1.], K.eval(result))\n\n    def test_weighted_with_thresholds(self):\n        tp_obj = metrics.TruePositives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0),\n                  (1, 1, 1, 1))\n\n        result = tp_obj(y_true, y_pred, sample_weight=37.)\n        assert np.allclose([222., 111., 37.], K.eval(result))\n\n\nclass TestTrueNegatives(object):\n\n    def test_config(self):\n        tn_obj = metrics.TrueNegatives(name=\'my_tn\', thresholds=[0.4, 0.9])\n        assert tn_obj.name == \'my_tn\'\n        assert len(tn_obj.weights) == 1\n        assert tn_obj.thresholds == [0.4, 0.9]\n\n        # Check save and restore config\n        tn_obj2 = metrics.TrueNegatives.from_config(tn_obj.get_config())\n        assert tn_obj2.name == \'my_tn\'\n        assert len(tn_obj2.weights) == 1\n        assert tn_obj2.thresholds == [0.4, 0.9]\n\n    def test_unweighted(self):\n        tn_obj = metrics.TrueNegatives()\n\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n\n        result = tn_obj(y_true, y_pred)\n        assert np.allclose(3., K.eval(result))\n\n    def test_weighted(self):\n        tn_obj = metrics.TrueNegatives()\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n        sample_weight = (1., 1.5, 2., 2.5)\n        result = tn_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(4., K.eval(result))\n\n    def test_unweighted_with_thresholds(self):\n        tn_obj = metrics.TrueNegatives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0), (1, 1, 1, 1))\n\n        result = tn_obj(y_true, y_pred)\n        assert np.allclose([2., 5., 7.], K.eval(result))\n\n    def test_weighted_with_thresholds(self):\n        tn_obj = metrics.TrueNegatives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0), (1, 1, 1, 1))\n        sample_weight = ((0.0, 2.0, 3.0, 5.0),)\n\n        result = tn_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose([5., 15., 23.], K.eval(result))\n\n\nclass TestFalseNegatives(object):\n\n    def test_config(self):\n        fn_obj = metrics.FalseNegatives(name=\'my_fn\', thresholds=[0.4, 0.9])\n        assert fn_obj.name == \'my_fn\'\n        assert len(fn_obj.weights) == 1\n        assert fn_obj.thresholds == [0.4, 0.9]\n\n        # Check save and restore config\n        fn_obj2 = metrics.FalseNegatives.from_config(fn_obj.get_config())\n        assert fn_obj2.name == \'my_fn\'\n        assert len(fn_obj2.weights) == 1\n        assert fn_obj2.thresholds == [0.4, 0.9]\n\n    def test_unweighted(self):\n        fn_obj = metrics.FalseNegatives()\n\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n\n        result = fn_obj(y_true, y_pred)\n        assert np.allclose(3., K.eval(result))\n\n    def test_weighted(self):\n        fn_obj = metrics.FalseNegatives()\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n        sample_weight = (1., 1.5, 2., 2.5)\n        result = fn_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(5., K.eval(result))\n\n    def test_unweighted_with_thresholds(self):\n        fn_obj = metrics.FalseNegatives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0), (1, 1, 1, 1))\n\n        result = fn_obj(y_true, y_pred)\n        assert np.allclose([1., 4., 6.], K.eval(result))\n\n    def test_weighted_with_thresholds(self):\n        fn_obj = metrics.FalseNegatives(thresholds=[0.15, 0.5, 0.85])\n\n        y_pred = ((0.9, 0.2, 0.8, 0.1), (0.2, 0.9, 0.7, 0.6),\n                  (0.1, 0.2, 0.4, 0.3), (0, 1, 0.7, 0.3))\n        y_true = ((0, 1, 1, 0), (1, 0, 0, 0), (0, 0, 0, 0), (1, 1, 1, 1))\n        sample_weight = ((3.0,), (5.0,), (7.0,), (4.0,))\n\n        result = fn_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose([4., 16., 23.], K.eval(result))\n\n\nclass TestSensitivityAtSpecificity(object):\n\n    def test_config(self):\n        s_obj = metrics.SensitivityAtSpecificity(\n            0.4, num_thresholds=100, name=\'sensitivity_at_specificity_1\')\n        assert s_obj.name == \'sensitivity_at_specificity_1\'\n        assert len(s_obj.weights) == 4\n        assert s_obj.specificity == 0.4\n        assert s_obj.num_thresholds == 100\n\n        # Check save and restore config\n        s_obj2 = metrics.SensitivityAtSpecificity.from_config(s_obj.get_config())\n        assert s_obj2.name == \'sensitivity_at_specificity_1\'\n        assert len(s_obj2.weights) == 4\n        assert s_obj2.specificity == 0.4\n        assert s_obj2.num_thresholds == 100\n\n    def test_unweighted_all_correct(self):\n        s_obj = metrics.SensitivityAtSpecificity(0.7, num_thresholds=1)\n        inputs = np.random.randint(0, 2, size=(100, 1))\n        y_pred = K.constant(inputs, dtype=\'float32\')\n        y_true = K.constant(inputs)\n        result = s_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n\n    def test_unweighted_high_specificity(self):\n        s_obj = metrics.SensitivityAtSpecificity(0.8)\n        pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.1, 0.45, 0.5, 0.8, 0.9]\n        label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n        y_pred = K.constant(pred_values, dtype=\'float32\')\n        y_true = K.constant(label_values)\n        result = s_obj(y_true, y_pred)\n        assert np.isclose(0.8, K.eval(result))\n\n    def test_unweighted_low_specificity(self):\n        s_obj = metrics.SensitivityAtSpecificity(0.4)\n        pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.25, 0.26, 0.26]\n        label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n        y_pred = K.constant(pred_values, dtype=\'float32\')\n        y_true = K.constant(label_values)\n        result = s_obj(y_true, y_pred)\n        assert np.isclose(0.6, K.eval(result))\n\n    def test_weighted(self):\n        s_obj = metrics.SensitivityAtSpecificity(0.4)\n        pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.25, 0.26, 0.26]\n        label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n        weight_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n        y_pred = K.constant(pred_values, dtype=\'float32\')\n        y_true = K.constant(label_values, dtype=\'float32\')\n        weights = K.constant(weight_values)\n        result = s_obj(y_true, y_pred, sample_weight=weights)\n        assert np.isclose(0.675, K.eval(result))\n\n    def test_invalid_specificity(self):\n        with pytest.raises(Exception):\n            metrics.SensitivityAtSpecificity(-1)\n\n    def test_invalid_num_thresholds(self):\n        with pytest.raises(Exception):\n            metrics.SensitivityAtSpecificity(0.4, num_thresholds=-1)\n\n\nclass TestSpecificityAtSensitivity(object):\n\n    def test_config(self):\n        s_obj = metrics.SpecificityAtSensitivity(\n            0.4, num_thresholds=100, name=\'specificity_at_sensitivity_1\')\n        assert s_obj.name == \'specificity_at_sensitivity_1\'\n        assert len(s_obj.weights) == 4\n        assert s_obj.sensitivity == 0.4\n        assert s_obj.num_thresholds == 100\n\n        # Check save and restore config\n        s_obj2 = metrics.SpecificityAtSensitivity.from_config(s_obj.get_config())\n        assert s_obj2.name == \'specificity_at_sensitivity_1\'\n        assert len(s_obj2.weights) == 4\n        assert s_obj2.sensitivity == 0.4\n        assert s_obj2.num_thresholds == 100\n\n    def test_unweighted_all_correct(self):\n        s_obj = metrics.SpecificityAtSensitivity(0.7, num_thresholds=1)\n        inputs = np.random.randint(0, 2, size=(100, 1))\n        y_pred = K.constant(inputs, dtype=\'float32\')\n        y_true = K.constant(inputs)\n        result = s_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n\n    def test_unweighted_high_sensitivity(self):\n        s_obj = metrics.SpecificityAtSensitivity(0.8)\n        pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.1, 0.45, 0.5, 0.8, 0.9]\n        label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n        y_pred = K.constant(pred_values, dtype=\'float32\')\n        y_true = K.constant(label_values)\n        result = s_obj(y_true, y_pred)\n        assert np.isclose(0.4, K.eval(result))\n\n    def test_unweighted_low_sensitivity(self):\n        s_obj = metrics.SpecificityAtSensitivity(0.4)\n        pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.25, 0.26, 0.26]\n        label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n        y_pred = K.constant(pred_values, dtype=\'float32\')\n        y_true = K.constant(label_values)\n        result = s_obj(y_true, y_pred)\n        assert np.isclose(0.6, K.eval(result))\n\n    def test_weighted(self):\n        s_obj = metrics.SpecificityAtSensitivity(0.4)\n        pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.25, 0.26, 0.26]\n        label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n        weight_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n        y_pred = K.constant(pred_values, dtype=\'float32\')\n        y_true = K.constant(label_values, dtype=\'float32\')\n        weights = K.constant(weight_values)\n        result = s_obj(y_true, y_pred, sample_weight=weights)\n        assert np.isclose(0.4, K.eval(result))\n\n    def test_invalid_sensitivity(self):\n        with pytest.raises(Exception):\n            metrics.SpecificityAtSensitivity(-1)\n\n    def test_invalid_num_thresholds(self):\n        with pytest.raises(Exception):\n            metrics.SpecificityAtSensitivity(0.4, num_thresholds=-1)\n\n\nclass TestAUC(object):\n\n    def setup(self):\n        self.num_thresholds = 3\n        self.y_pred = K.constant([0, 0.5, 0.3, 0.9], dtype=\'float32\')\n        self.y_true = K.constant([0, 0, 1, 1])\n        self.sample_weight = [1, 2, 3, 4]\n\n        # threshold values are [0 - 1e-7, 0.5, 1 + 1e-7]\n        # y_pred when threshold = 0 - 1e-7  : [1, 1, 1, 1]\n        # y_pred when threshold = 0.5       : [0, 0, 0, 1]\n        # y_pred when threshold = 1 + 1e-7  : [0, 0, 0, 0]\n\n        # without sample_weight:\n        # tp = np.sum([[0, 0, 1, 1], [0, 0, 0, 1], [0, 0, 0, 0]], axis=1)\n        # fp = np.sum([[1, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], axis=1)\n        # fn = np.sum([[0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 1]], axis=1)\n        # tn = np.sum([[0, 0, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0]], axis=1)\n\n        # tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]\n\n        # with sample_weight:\n        # tp = np.sum([[0, 0, 3, 4], [0, 0, 0, 4], [0, 0, 0, 0]], axis=1)\n        # fp = np.sum([[1, 2, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], axis=1)\n        # fn = np.sum([[0, 0, 0, 0], [0, 0, 3, 0], [0, 0, 3, 4]], axis=1)\n        # tn = np.sum([[0, 0, 0, 0], [1, 2, 0, 0], [1, 2, 0, 0]], axis=1)\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n\n    def test_config(self):\n        auc_obj = metrics.AUC(\n            num_thresholds=100,\n            curve=\'PR\',\n            summation_method=\'majoring\',\n            name=\'auc_1\')\n        assert auc_obj.name == \'auc_1\'\n        assert len(auc_obj.weights) == 4\n        assert auc_obj.num_thresholds == 100\n        assert auc_obj.curve == metrics_utils.AUCCurve.PR\n        assert auc_obj.summation_method == metrics_utils.AUCSummationMethod.MAJORING\n\n        # Check save and restore config.\n        auc_obj2 = metrics.AUC.from_config(auc_obj.get_config())\n        assert auc_obj2.name == \'auc_1\'\n        assert len(auc_obj2.weights) == 4\n        assert auc_obj2.num_thresholds == 100\n        assert auc_obj2.curve == metrics_utils.AUCCurve.PR\n        assert auc_obj2.summation_method == metrics_utils.AUCSummationMethod.MAJORING\n\n    def test_config_manual_thresholds(self):\n        auc_obj = metrics.AUC(\n            num_thresholds=None,\n            curve=\'PR\',\n            summation_method=\'majoring\',\n            name=\'auc_1\',\n            thresholds=[0.3, 0.5])\n        assert auc_obj.name == \'auc_1\'\n        assert len(auc_obj.weights) == 4\n        assert auc_obj.num_thresholds == 4\n        assert np.allclose(auc_obj.thresholds, [0.0, 0.3, 0.5, 1.0], atol=1e-3)\n        assert auc_obj.curve == metrics_utils.AUCCurve.PR\n        assert auc_obj.summation_method == metrics_utils.AUCSummationMethod.MAJORING\n\n        # Check save and restore config.\n        auc_obj2 = metrics.AUC.from_config(auc_obj.get_config())\n        assert auc_obj2.name == \'auc_1\'\n        assert len(auc_obj2.weights) == 4\n        assert auc_obj2.num_thresholds == 4\n        assert auc_obj2.curve == metrics_utils.AUCCurve.PR\n        assert auc_obj2.summation_method == metrics_utils.AUCSummationMethod.MAJORING\n\n    def test_unweighted_all_correct(self):\n        self.setup()\n        auc_obj = metrics.AUC()\n        result = auc_obj(self.y_true, self.y_true)\n        assert K.eval(result) == 1\n\n    def test_unweighted(self):\n        self.setup()\n        auc_obj = metrics.AUC(num_thresholds=self.num_thresholds)\n        result = auc_obj(self.y_true, self.y_pred)\n\n        # tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]\n        # recall = [2/2, 1/(1+1), 0] = [1, 0.5, 0]\n        # fp_rate = [2/2, 0, 0] = [1, 0, 0]\n        # heights = [(1 + 0.5)/2, (0.5 + 0)/2] = [0.75, 0.25]\n        # widths = [(1 - 0), (0 - 0)] = [1, 0]\n        expected_result = (0.75 * 1 + 0.25 * 0)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_manual_thresholds(self):\n        self.setup()\n        # Verify that when specified, thresholds are used instead of num_thresholds.\n        auc_obj = metrics.AUC(num_thresholds=2, thresholds=[0.5])\n        assert auc_obj.num_thresholds == 3\n        assert np.allclose(auc_obj.thresholds, [0.0, 0.5, 1.0], atol=1e-3)\n        result = auc_obj(self.y_true, self.y_pred)\n\n        # tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]\n        # recall = [2/2, 1/(1+1), 0] = [1, 0.5, 0]\n        # fp_rate = [2/2, 0, 0] = [1, 0, 0]\n        # heights = [(1 + 0.5)/2, (0.5 + 0)/2] = [0.75, 0.25]\n        # widths = [(1 - 0), (0 - 0)] = [1, 0]\n        expected_result = (0.75 * 1 + 0.25 * 0)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted_roc_interpolation(self):\n        self.setup()\n        auc_obj = metrics.AUC(num_thresholds=self.num_thresholds)\n        result = auc_obj(self.y_true, self.y_pred, sample_weight=self.sample_weight)\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n        # recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]\n        # fp_rate = [3/3, 0, 0] = [1, 0, 0]\n        # heights = [(1 + 0.571)/2, (0.571 + 0)/2] = [0.7855, 0.2855]\n        # widths = [(1 - 0), (0 - 0)] = [1, 0]\n        expected_result = (0.7855 * 1 + 0.2855 * 0)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted_roc_majoring(self):\n        self.setup()\n        auc_obj = metrics.AUC(\n            num_thresholds=self.num_thresholds, summation_method=\'majoring\')\n        result = auc_obj(self.y_true, self.y_pred, sample_weight=self.sample_weight)\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n        # recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]\n        # fp_rate = [3/3, 0, 0] = [1, 0, 0]\n        # heights = [max(1, 0.571), max(0.571, 0)] = [1, 0.571]\n        # widths = [(1 - 0), (0 - 0)] = [1, 0]\n        expected_result = (1 * 1 + 0.571 * 0)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted_roc_minoring(self):\n        self.setup()\n        auc_obj = metrics.AUC(\n            num_thresholds=self.num_thresholds, summation_method=\'minoring\')\n        result = auc_obj(self.y_true, self.y_pred, sample_weight=self.sample_weight)\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n        # recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]\n        # fp_rate = [3/3, 0, 0] = [1, 0, 0]\n        # heights = [min(1, 0.571), min(0.571, 0)] = [0.571, 0]\n        # widths = [(1 - 0), (0 - 0)] = [1, 0]\n        expected_result = (0.571 * 1 + 0 * 0)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted_pr_majoring(self):\n        self.setup()\n        auc_obj = metrics.AUC(\n            num_thresholds=self.num_thresholds,\n            curve=\'PR\',\n            summation_method=\'majoring\')\n        result = auc_obj(self.y_true, self.y_pred, sample_weight=self.sample_weight)\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n        # precision = [7/(7+3), 4/4, 0] = [0.7, 1, 0]\n        # recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]\n        # heights = [max(0.7, 1), max(1, 0)] = [1, 1]\n        # widths = [(1 - 0.571), (0.571 - 0)] = [0.429, 0.571]\n        expected_result = (1 * 0.429 + 1 * 0.571)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted_pr_minoring(self):\n        self.setup()\n        auc_obj = metrics.AUC(\n            num_thresholds=self.num_thresholds,\n            curve=\'PR\',\n            summation_method=\'minoring\')\n        result = auc_obj(self.y_true, self.y_pred, sample_weight=self.sample_weight)\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n        # precision = [7/(7+3), 4/4, 0] = [0.7, 1, 0]\n        # recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]\n        # heights = [min(0.7, 1), min(1, 0)] = [0.7, 0]\n        # widths = [(1 - 0.571), (0.571 - 0)] = [0.429, 0.571]\n        expected_result = (0.7 * 0.429 + 0 * 0.571)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted_pr_interpolation(self):\n        self.setup()\n        auc_obj = metrics.AUC(num_thresholds=self.num_thresholds, curve=\'PR\')\n        result = auc_obj(self.y_true, self.y_pred, sample_weight=self.sample_weight)\n\n        # auc = (slope / Total Pos) * [dTP - intercept * log(Pb/Pa)]\n\n        # tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]\n        # P = tp + fp = [10, 4, 0]\n        # dTP = [7-4, 4-0] = [3, 4]\n        # dP = [10-4, 4-0] = [6, 4]\n        # slope = dTP/dP = [0.5, 1]\n        # intercept = (TPa+(slope*Pa) = [(4 - 0.5*4), (0 - 1*0)] = [2, 0]\n        # (Pb/Pa) = (Pb/Pa) if Pb > 0 AND Pa > 0 else 1 = [10/4, 4/0] = [2.5, 1]\n        # auc * TotalPos = [(0.5 * (3 + 2 * log(2.5))), (1 * (4 + 0))]\n        #                = [2.416, 4]\n        # auc = [2.416, 4]/(tp[1:]+fn[1:])\n        # expected_result = (2.416 / 7 + 4 / 7)\n        expected_result = 0.345 + 0.571\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_invalid_num_thresholds(self):\n        with pytest.raises(Exception):\n            metrics.AUC(num_thresholds=-1)\n\n        with pytest.raises(Exception):\n            metrics.AUC(num_thresholds=1)\n\n    def test_invalid_curve(self):\n        with pytest.raises(Exception):\n            metrics.AUC(curve=\'Invalid\')\n\n    def test_invalid_summation_method(self):\n        with pytest.raises(Exception):\n            metrics.AUC(summation_method=\'Invalid\')\n\n\nclass TestPrecisionTest(object):\n\n    def test_config(self):\n        p_obj = metrics.Precision(\n            name=\'my_precision\', thresholds=[0.4, 0.9], top_k=15, class_id=12)\n        assert p_obj.name == \'my_precision\'\n        assert len(p_obj.weights) == 2\n        assert ([v.name for v in p_obj.weights] ==\n                [\'true_positives:0\', \'false_positives:0\'])\n        assert p_obj.thresholds == [0.4, 0.9]\n        assert p_obj.top_k == 15\n        assert p_obj.class_id == 12\n\n        # Check save and restore config\n        p_obj2 = metrics.Precision.from_config(p_obj.get_config())\n        assert p_obj2.name == \'my_precision\'\n        assert len(p_obj2.weights) == 2\n        assert p_obj2.thresholds == [0.4, 0.9]\n        assert p_obj2.top_k == 15\n        assert p_obj2.class_id == 12\n\n    def test_unweighted(self):\n        p_obj = metrics.Precision()\n        y_pred = K.constant([1, 0, 1, 0], shape=(1, 4))\n        y_true = K.constant([0, 1, 1, 0], shape=(1, 4))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n\n    def test_unweighted_all_incorrect(self):\n        p_obj = metrics.Precision(thresholds=[0.5])\n        inputs = np.random.randint(0, 2, size=(100, 1))\n        y_pred = K.constant(inputs)\n        y_true = K.constant(1 - inputs)\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(0, K.eval(result))\n\n    def test_weighted(self):\n        p_obj = metrics.Precision()\n        y_pred = K.constant([[1, 0, 1, 0], [1, 0, 1, 0]])\n        y_true = K.constant([[0, 1, 1, 0], [1, 0, 0, 1]])\n        result = p_obj(\n            y_true,\n            y_pred,\n            sample_weight=K.constant([[1, 2, 3, 4], [4, 3, 2, 1]]))\n        weighted_tp = 3.0 + 4.0\n        weighted_positives = (1.0 + 3.0) + (4.0 + 2.0)\n        expected_precision = weighted_tp / weighted_positives\n        assert np.isclose(expected_precision, K.eval(result))\n\n    def test_unweighted_with_threshold(self):\n        p_obj = metrics.Precision(thresholds=[0.5, 0.7])\n        y_pred = K.constant([1, 0, 0.6, 0], shape=(1, 4))\n        y_true = K.constant([0, 1, 1, 0], shape=(1, 4))\n        result = p_obj(y_true, y_pred)\n        assert np.allclose([0.5, 0.], K.eval(result), 0)\n\n    def test_weighted_with_threshold(self):\n        p_obj = metrics.Precision(thresholds=[0.5, 1.])\n        y_true = K.constant([[0, 1], [1, 0]], shape=(2, 2))\n        y_pred = K.constant([[1, 0], [0.6, 0]],\n                            shape=(2, 2),\n                            dtype=\'float32\')\n        weights = K.constant([[4, 0], [3, 1]],\n                             shape=(2, 2),\n                             dtype=\'float32\')\n        result = p_obj(y_true, y_pred, sample_weight=weights)\n        weighted_tp = 0 + 3.\n        weighted_positives = (0 + 3.) + (4. + 0.)\n        expected_precision = weighted_tp / weighted_positives\n        assert np.allclose([expected_precision, 0], K.eval(result), 1e-3)\n\n    def test_unweighted_top_k(self):\n        p_obj = metrics.Precision(top_k=3)\n        y_pred = K.constant([0.2, 0.1, 0.5, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(1. / 3, K.eval(result))\n\n    def test_weighted_top_k(self):\n        p_obj = metrics.Precision(top_k=3)\n        y_pred1 = K.constant([0.2, 0.1, 0.4, 0, 0.2], shape=(1, 5))\n        y_true1 = K.constant([0, 1, 1, 0, 1], shape=(1, 5))\n        K.eval(\n            p_obj(\n                y_true1,\n                y_pred1,\n                sample_weight=K.constant([[1, 4, 2, 3, 5]])))\n\n        y_pred2 = K.constant([0.2, 0.6, 0.4, 0.2, 0.2], shape=(1, 5))\n        y_true2 = K.constant([1, 0, 1, 1, 1], shape=(1, 5))\n        result = p_obj(y_true2, y_pred2, sample_weight=K.constant(3))\n\n        tp = (2 + 5) + (3 + 3)\n        predicted_positives = (1 + 2 + 5) + (3 + 3 + 3)\n        expected_precision = float(tp) / predicted_positives\n        assert np.isclose(expected_precision, K.eval(result))\n\n    def test_unweighted_class_id(self):\n        p_obj = metrics.Precision(class_id=2)\n\n        y_pred = K.constant([0.2, 0.1, 0.6, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(p_obj.true_positives))\n        assert np.isclose(0, K.eval(p_obj.false_positives))\n\n        y_pred = K.constant([0.2, 0.1, 0, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(p_obj.true_positives))\n        assert np.isclose(0, K.eval(p_obj.false_positives))\n\n        y_pred = K.constant([0.2, 0.1, 0.6, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 0, 0, 0], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n        assert np.isclose(1, K.eval(p_obj.true_positives))\n        assert np.isclose(1, K.eval(p_obj.false_positives))\n\n    def test_unweighted_top_k_and_class_id(self):\n        p_obj = metrics.Precision(class_id=2, top_k=2)\n\n        y_pred = K.constant([0.2, 0.6, 0.3, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(p_obj.true_positives))\n        assert np.isclose(0, K.eval(p_obj.false_positives))\n\n        y_pred = K.constant([1, 1, 0.9, 1, 1], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(p_obj.true_positives))\n        assert np.isclose(0, K.eval(p_obj.false_positives))\n\n    def test_unweighted_top_k_and_threshold(self):\n        p_obj = metrics.Precision(thresholds=.7, top_k=2)\n\n        y_pred = K.constant([0.2, 0.8, 0.6, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 1], shape=(1, 5))\n        result = p_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(p_obj.true_positives))\n        assert np.isclose(0, K.eval(p_obj.false_positives))\n\n\nclass TestRecall(object):\n\n    def test_config(self):\n        r_obj = metrics.Recall(\n            name=\'my_recall\', thresholds=[0.4, 0.9], top_k=15, class_id=12)\n        assert r_obj.name == \'my_recall\'\n        assert len(r_obj.weights) == 2\n        assert ([v.name for v in r_obj.weights] ==\n                [\'true_positives:0\', \'false_negatives:0\'])\n        assert r_obj.thresholds == [0.4, 0.9]\n        assert r_obj.top_k == 15\n        assert r_obj.class_id == 12\n\n        # Check save and restore config\n        r_obj2 = metrics.Recall.from_config(r_obj.get_config())\n        assert r_obj2.name == \'my_recall\'\n        assert len(r_obj2.weights) == 2\n        assert r_obj2.thresholds == [0.4, 0.9]\n        assert r_obj2.top_k == 15\n        assert r_obj2.class_id == 12\n\n    def test_unweighted(self):\n        r_obj = metrics.Recall()\n        y_pred = K.constant([1, 0, 1, 0], shape=(1, 4))\n        y_true = K.constant([0, 1, 1, 0], shape=(1, 4))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n\n    def test_unweighted_all_incorrect(self):\n        r_obj = metrics.Recall(thresholds=[0.5])\n        inputs = np.random.randint(0, 2, size=(100, 1))\n        y_pred = K.constant(inputs)\n        y_true = K.constant(1 - inputs)\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0, K.eval(result))\n\n    def test_weighted(self):\n        r_obj = metrics.Recall()\n        y_pred = K.constant([[1, 0, 1, 0], [0, 1, 0, 1]])\n        y_true = K.constant([[0, 1, 1, 0], [1, 0, 0, 1]])\n        result = r_obj(\n            y_true,\n            y_pred,\n            sample_weight=K.constant([[1, 2, 3, 4], [4, 3, 2, 1]]))\n        weighted_tp = 3.0 + 1.0\n        weighted_t = (2.0 + 3.0) + (4.0 + 1.0)\n        expected_recall = weighted_tp / weighted_t\n        assert np.isclose(expected_recall, K.eval(result))\n\n    def test_unweighted_with_threshold(self):\n        r_obj = metrics.Recall(thresholds=[0.5, 0.7])\n        y_pred = K.constant([1, 0, 0.6, 0], shape=(1, 4))\n        y_true = K.constant([0, 1, 1, 0], shape=(1, 4))\n        result = r_obj(y_true, y_pred)\n        assert np.allclose([0.5, 0.], K.eval(result), 0)\n\n    def test_weighted_with_threshold(self):\n        r_obj = metrics.Recall(thresholds=[0.5, 1.])\n        y_true = K.constant([[0, 1], [1, 0]], shape=(2, 2))\n        y_pred = K.constant([[1, 0], [0.6, 0]],\n                            shape=(2, 2),\n                            dtype=\'float32\')\n        weights = K.constant([[1, 4], [3, 2]],\n                             shape=(2, 2),\n                             dtype=\'float32\')\n        result = r_obj(y_true, y_pred, sample_weight=weights)\n        weighted_tp = 0 + 3.\n        weighted_positives = (0 + 3.) + (4. + 0.)\n        expected_recall = weighted_tp / weighted_positives\n        assert np.allclose([expected_recall, 0], K.eval(result), 1e-3)\n\n    def test_unweighted_top_k(self):\n        r_obj = metrics.Recall(top_k=3)\n        y_pred = K.constant([0.2, 0.1, 0.5, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n\n    def test_weighted_top_k(self):\n        r_obj = metrics.Recall(top_k=3)\n        y_pred1 = K.constant([0.2, 0.1, 0.4, 0, 0.2], shape=(1, 5))\n        y_true1 = K.constant([0, 1, 1, 0, 1], shape=(1, 5))\n        K.eval(\n            r_obj(\n                y_true1,\n                y_pred1,\n                sample_weight=K.constant([[1, 4, 2, 3, 5]])))\n\n        y_pred2 = K.constant([0.2, 0.6, 0.4, 0.2, 0.2], shape=(1, 5))\n        y_true2 = K.constant([1, 0, 1, 1, 1], shape=(1, 5))\n        result = r_obj(y_true2, y_pred2, sample_weight=K.constant(3))\n\n        tp = (2 + 5) + (3 + 3)\n        positives = (4 + 2 + 5) + (3 + 3 + 3 + 3)\n        expected_recall = float(tp) / positives\n        assert np.isclose(expected_recall, K.eval(result))\n\n    def test_unweighted_class_id(self):\n        r_obj = metrics.Recall(class_id=2)\n\n        y_pred = K.constant([0.2, 0.1, 0.6, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(r_obj.true_positives))\n        assert np.isclose(0, K.eval(r_obj.false_negatives))\n\n        y_pred = K.constant([0.2, 0.1, 0, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n        assert np.isclose(1, K.eval(r_obj.true_positives))\n        assert np.isclose(1, K.eval(r_obj.false_negatives))\n\n        y_pred = K.constant([0.2, 0.1, 0.6, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 0, 0, 0], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n        assert np.isclose(1, K.eval(r_obj.true_positives))\n        assert np.isclose(1, K.eval(r_obj.false_negatives))\n\n    def test_unweighted_top_k_and_class_id(self):\n        r_obj = metrics.Recall(class_id=2, top_k=2)\n\n        y_pred = K.constant([0.2, 0.6, 0.3, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(1, K.eval(result))\n        assert np.isclose(1, K.eval(r_obj.true_positives))\n        assert np.isclose(0, K.eval(r_obj.false_negatives))\n\n        y_pred = K.constant([1, 1, 0.9, 1, 1], shape=(1, 5))\n        y_true = K.constant([0, 1, 1, 0, 0], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0.5, K.eval(result))\n        assert np.isclose(1, K.eval(r_obj.true_positives))\n        assert np.isclose(1, K.eval(r_obj.false_negatives))\n\n    def test_unweighted_top_k_and_threshold(self):\n        r_obj = metrics.Recall(thresholds=.7, top_k=2)\n\n        y_pred = K.constant([0.2, 0.8, 0.6, 0, 0.2], shape=(1, 5))\n        y_true = K.constant([1, 1, 1, 0, 1], shape=(1, 5))\n        result = r_obj(y_true, y_pred)\n        assert np.isclose(0.25, K.eval(result))\n        assert np.isclose(1, K.eval(r_obj.true_positives))\n        assert np.isclose(3, K.eval(r_obj.false_negatives))\n\n\n@pytest.mark.skipif(not tf.__version__.startswith(\'2.\'),\n                    reason=\'Requires TF 2\')\nclass TestMeanIoU(object):\n\n    def test_config(self):\n        m_obj = metrics.MeanIoU(num_classes=2, name=\'mean_iou\')\n        assert m_obj.name == \'mean_iou\'\n        assert m_obj.num_classes == 2\n\n        m_obj2 = metrics.MeanIoU.from_config(m_obj.get_config())\n        assert m_obj2.name == \'mean_iou\'\n        assert m_obj2.num_classes == 2\n\n    def test_unweighted(self):\n        y_pred = K.constant([0, 1, 0, 1], shape=(1, 4))\n        y_true = K.constant([0, 0, 1, 1], shape=(1, 4))\n\n        m_obj = metrics.MeanIoU(num_classes=2)\n        result = m_obj(y_true, y_pred)\n\n        # cm = [[1, 1],\n        #       [1, 1]]\n        # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n        # iou = true_positives / (sum_row + sum_col - true_positives))\n        expected_result = (1. / (2 + 2 - 1) + 1. / (2 + 2 - 1)) / 2\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted(self):\n        y_pred = K.constant([0, 1, 0, 1], dtype=\'float32\')\n        y_true = K.constant([0, 0, 1, 1])\n        sample_weight = K.constant([0.2, 0.3, 0.4, 0.1])\n\n        m_obj = metrics.MeanIoU(num_classes=2)\n        result = m_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        # cm = [[0.2, 0.3],\n        #       [0.4, 0.1]]\n        # sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], true_positives = [0.2, 0.1]\n        # iou = true_positives / (sum_row + sum_col - true_positives))\n        expected_result = (0.2 / (0.6 + 0.5 - 0.2) + 0.1 / (0.4 + 0.5 - 0.1)) / 2\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_multi_dim_input(self):\n        y_pred = K.constant([[0, 1], [0, 1]], dtype=\'float32\')\n        y_true = K.constant([[0, 0], [1, 1]])\n        sample_weight = K.constant([[0.2, 0.3], [0.4, 0.1]])\n\n        m_obj = metrics.MeanIoU(num_classes=2)\n        result = m_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        # cm = [[0.2, 0.3],\n        #       [0.4, 0.1]]\n        # sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], true_positives = [0.2, 0.1]\n        # iou = true_positives / (sum_row + sum_col - true_positives))\n        expected_result = (0.2 / (0.6 + 0.5 - 0.2) + 0.1 / (0.4 + 0.5 - 0.1)) / 2\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_zero_valid_entries(self):\n        m_obj = metrics.MeanIoU(num_classes=2)\n        assert np.allclose(K.eval(m_obj.result()), 0, atol=1e-3)\n\n    def test_zero_and_non_zero_entries(self):\n        y_pred = K.constant([1], dtype=\'float32\')\n        y_true = K.constant([1])\n\n        m_obj = metrics.MeanIoU(num_classes=2)\n        result = m_obj(y_true, y_pred)\n\n        # cm = [[0, 0],\n        #       [0, 1]]\n        # sum_row = [0, 1], sum_col = [0, 1], true_positives = [0, 1]\n        # iou = true_positives / (sum_row + sum_col - true_positives))\n        expected_result = (0. + 1. / (1 + 1 - 1)) / 1\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n'"
tests/keras/metrics_correctness_test.py,0,"b'""""""Tests for Keras metrics correctness.""""""\n\nimport numpy as np\n\nimport keras\nfrom keras import layers\nfrom keras import losses\nfrom keras import metrics\nfrom keras import backend as K\n\n\ndef get_multi_io_model():\n    inp_1 = layers.Input(shape=(1,), name=\'input_1\')\n    inp_2 = layers.Input(shape=(1,), name=\'input_2\')\n    dense = layers.Dense(3, kernel_initializer=\'ones\', trainable=False)\n    x_1 = dense(inp_1)\n    x_2 = dense(inp_2)\n    out_1 = layers.Dense(\n        1, kernel_initializer=\'ones\', name=\'output_1\', trainable=False)(x_1)\n    out_2 = layers.Dense(\n        1, kernel_initializer=\'ones\', name=\'output_2\', trainable=False)(x_2)\n    return keras.Model([inp_1, inp_2], [out_1, out_2])\n\n\ndef custom_generator_multi_io(sample_weights=None):\n    batch_size = 2\n    num_samples = 4\n    inputs = np.asarray([[1.], [2.], [3.], [4.]])\n    targets_1 = np.asarray([[2.], [4.], [6.], [8.]])\n    targets_2 = np.asarray([[1.], [2.], [3.], [4.]])\n    w1 = sample_weights[0] if sample_weights else None\n    w2 = sample_weights[1] if sample_weights else None\n    i = 0\n    while True:\n        batch_index = i * batch_size % num_samples\n        i += 1\n        start = batch_index\n        end = start + batch_size\n        x = [inputs[start:end], inputs[start:end]]\n        y = [targets_1[start:end], targets_2[start:end]]\n        if sample_weights:\n            w = [\n                None if w1 is None else w1[start:end],\n                None if w2 is None else w2[start:end]\n            ]\n        else:\n            w = None\n        yield x, y, w\n\n\nclass TestMetricsCorrectnessMultiIO(object):\n\n    def _get_compiled_multi_io_model(self):\n        model = get_multi_io_model()\n        model.compile(\n            optimizer=\'rmsprop\',\n            loss=losses.MeanSquaredError(),\n            metrics=[metrics.MeanSquaredError(name=\'mean_squared_error\')],\n            weighted_metrics=[\n                metrics.MeanSquaredError(name=\'mean_squared_error_2\')\n            ])\n        return model\n\n    def setUp(self):\n        self.x = np.asarray([[1.], [2.], [3.], [4.]])\n        self.y1 = np.asarray([[2.], [4.], [6.], [8.]])\n        self.y2 = np.asarray([[1.], [2.], [3.], [4.]])\n        self.sample_weight_1 = np.asarray([2., 3., 4., 5.])\n        self.sample_weight_2 = np.asarray([3.5, 2.5, 1.5, 0.5])\n        self.class_weight_1 = {2: 2, 4: 3, 6: 4, 8: 5}\n        self.class_weight_2 = {1: 3.5, 2: 2.5, 3: 1.5, 4: 0.5}\n\n        # y_true_1 = [[2.], [4.], [6.], [8.]], y_pred = [[3.], [6.], [9.], [12.]]\n        # y_true_2 = [[1.], [2.], [3.], [4.]], y_pred = [[3.], [6.], [9.], [12.]]\n\n        # Weighted metric `output_1`:\n        #   Total = ((3 - 2)^2 * 2  + (6 - 4)^2 * 3) +\n        #           ((9 - 6)^2 * 4 + (12 - 8)^2 * 5)\n        #         = 130\n        #   Count = (2 + 3) + (4 + 5)\n        #   Result = 9.2857141\n\n        # Weighted metric `output_2`:\n        #   Total = ((3 - 1)^2 * 3.5 + (6 - 2)^2 * 2.5) +\n        #           ((9 - 3)^2 * 1.5 + (12 - 4)^2 * 0.5)\n        #         = 140\n        #   Count = (3.5 + 2.5) + (1.5 + 0.5)\n        #   Result = 17.5\n\n        # Loss `output_1` with weights:\n        #   Total = ((3 - 2)^2 * 2  + (6 - 4)^2 * 3) +\n        #           ((9 - 6)^2 * 4 + (12 - 8)^2 * 5)\n        #         = 130\n        #   Count = 2 + 2\n        #   Result = 32.5\n\n        # Loss `output_1` without weights/Metric `output_1`:\n        #   Total = ((3 - 2)^2 + (6 - 4)^2) + ((9 - 6)^2 + (12 - 8)^2) = 30\n        #   Count = 2 + 2\n        #   Result = 7.5\n\n        # Loss `output_2` with weights:\n        #   Total = ((3 - 1)^2 * 3.5 + (6 - 2)^2 * 2.5) +\n        #           ((9 - 3)^2 * 1.5 + (12 - 4)^2 * 0.5)\n        #         = 140\n        #   Count = 2 + 2\n        #   Result = 35\n\n        # Loss `output_2` without weights/Metric `output_2`:\n        #   Total = ((3 - 1)^2 + (6 - 2)^2) + ((9 - 3)^2 + (12 - 4)^2) = 120\n        #   Count = 2 + 2\n        #   Result = 30\n\n        # Total loss with weights = 32.5 + 35 = 67.5\n        # Total loss without weights = 7.5 + 30 = 37.5\n\n        self.expected_fit_result_with_weights = {\n            \'output_1_mean_squared_error\': [7.5, 7.5],\n            \'output_2_mean_squared_error\': [30, 30],\n            \'output_1_mean_squared_error_2\': [9.286, 9.286],\n            \'output_2_mean_squared_error_2\': [17.5, 17.5],\n            \'loss\': [67.5, 67.5],\n            \'output_1_loss\': [32.5, 32.5],\n            \'output_2_loss\': [35, 35],\n        }\n\n        self.expected_fit_result_with_weights_output_2 = {\n            \'output_1_mean_squared_error\': [7.5, 7.5],\n            \'output_2_mean_squared_error\': [30, 30],\n            \'output_1_mean_squared_error_2\': [7.5, 7.5],\n            \'output_2_mean_squared_error_2\': [17.5, 17.5],\n            \'loss\': [42.5, 42.5],\n            \'output_1_loss\': [7.5, 7.5],\n            \'output_2_loss\': [35, 35],\n        }\n\n        self.expected_fit_result = {\n            \'output_1_mean_squared_error\': [7.5, 7.5],\n            \'output_2_mean_squared_error\': [30, 30],\n            \'output_1_mean_squared_error_2\': [7.5, 7.5],\n            \'output_2_mean_squared_error_2\': [30, 30],\n            \'loss\': [37.5, 37.5],\n            \'output_1_loss\': [7.5, 7.5],\n            \'output_2_loss\': [30, 30],\n        }\n\n        # In the order: \'loss\', \'output_1_loss\', \'output_2_loss\',\n        # \'output_1_mean_squared_error\', \'output_1_mean_squared_error_2\',\n        # \'output_2_mean_squared_error\', \'output_2_mean_squared_error_2\'\n        self.expected_batch_result_with_weights = [\n            67.5, 32.5, 35, 7.5, 9.286, 30, 17.5\n        ]\n        self.expected_batch_result_with_weights_output_2 = [\n            42.5, 7.5, 35, 7.5, 7.5, 30, 17.5\n        ]\n        self.expected_batch_result = [37.5, 7.5, 30, 7.5, 7.5, 30, 30]\n\n    def test_fit(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        history = model.fit([self.x, self.x], [self.y1, self.y2],\n                            batch_size=2,\n                            epochs=2,\n                            shuffle=False)\n        for key, value in self.expected_fit_result.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n    def test_fit_with_sample_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        history = model.fit([self.x, self.x], [self.y1, self.y2],\n                            sample_weight={\n                                \'output_1\': self.sample_weight_1,\n                                \'output_2\': self.sample_weight_2},\n                            batch_size=2,\n                            epochs=2,\n                            shuffle=False)\n        for key, value in self.expected_fit_result_with_weights.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n        # Set weights for one output (use batch size).\n        history = model.fit([self.x, self.x], [self.y1, self.y2],\n                            sample_weight={\'output_2\': self.sample_weight_2},\n                            batch_size=2,\n                            epochs=2,\n                            shuffle=False)\n\n        for key, value in self.expected_fit_result_with_weights_output_2.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n    def test_fit_with_class_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        history = model.fit([self.x, self.x], [self.y1, self.y2],\n                            class_weight={\n                                \'output_1\': self.class_weight_1,\n                                \'output_2\': self.class_weight_2},\n                            batch_size=2,\n                            epochs=2,\n                            shuffle=False)\n        for key, value in self.expected_fit_result_with_weights.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n        # Set weights for one output.\n        history = model.fit([self.x, self.x], [self.y1, self.y2],\n                            class_weight={\'output_2\': self.class_weight_2},\n                            batch_size=2,\n                            epochs=2,\n                            shuffle=False)\n\n        for key, value in self.expected_fit_result_with_weights_output_2.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n    def test_eval(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        eval_result = model.evaluate([self.x, self.x], [self.y1, self.y2],\n                                     batch_size=2)\n        np.allclose(eval_result, self.expected_batch_result, 1e-3)\n\n    def test_eval_with_sample_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        eval_result = model.evaluate([self.x, self.x], [self.y1, self.y2],\n                                     batch_size=2,\n                                     sample_weight={\n                                         \'output_1\': self.sample_weight_1,\n                                         \'output_2\': self.sample_weight_2})\n        np.allclose(eval_result, self.expected_batch_result_with_weights,\n                    1e-3)\n\n        # Set weights for one output.\n        model = self._get_compiled_multi_io_model()\n        eval_result = model.evaluate([self.x, self.x], [self.y1, self.y2],\n                                     batch_size=2,\n                                     sample_weight={\n                                         \'output_2\': self.sample_weight_2})\n        np.allclose(eval_result,\n                    self.expected_batch_result_with_weights_output_2, 1e-3)\n\n        # Verify that metric value is same with arbitrary weights and batch size.\n        x = np.random.random((50, 1))\n        y = np.random.random((50, 1))\n        w = np.random.random((50,))\n        mse1 = model.evaluate([x, x], [y, y], sample_weight=[w, w], batch_size=5)[3]\n        mse2 = model.evaluate([x, x], [y, y], sample_weight=[w, w],\n                              batch_size=10)[3]\n        np.allclose(mse1, mse2, 1e-3)\n\n    def test_train_on_batch(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        result = model.train_on_batch([self.x, self.x], [self.y1, self.y2])\n        np.allclose(result, self.expected_batch_result, 1e-3)\n\n    def test_train_on_batch_with_sample_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        result = model.train_on_batch([self.x, self.x], [self.y1, self.y2],\n                                      sample_weight={\n                                          \'output_1\': self.sample_weight_1,\n                                          \'output_2\': self.sample_weight_2})\n        np.allclose(result, self.expected_batch_result_with_weights, 1e-3)\n\n        # Set weights for one output.\n        result = model.train_on_batch([self.x, self.x], [self.y1, self.y2],\n                                      sample_weight={\n                                          \'output_2\': self.sample_weight_2})\n        np.allclose(result, self.expected_batch_result_with_weights_output_2, 1e-3)\n\n    def test_train_on_batch_with_class_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        result = model.train_on_batch([self.x, self.x], [self.y1, self.y2],\n                                      class_weight={\n                                          \'output_1\': self.class_weight_1,\n                                          \'output_2\': self.class_weight_2})\n        np.allclose(result, self.expected_batch_result_with_weights, 1e-3)\n\n        # Set weights for one output.\n        result = model.train_on_batch([self.x, self.x], [self.y1, self.y2],\n                                      class_weight={\n                                          \'output_2\': self.class_weight_2})\n        np.allclose(result,\n                    self.expected_batch_result_with_weights_output_2, 1e-3)\n\n    def test_test_on_batch(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        result = model.test_on_batch([self.x, self.x], [self.y1, self.y2])\n        np.allclose(result, self.expected_batch_result, 1e-3)\n\n    def test_test_on_batch_with_sample_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        result = model.test_on_batch([self.x, self.x], [self.y1, self.y2],\n                                     sample_weight={\n                                         \'output_1\': self.sample_weight_1,\n                                         \'output_2\': self.sample_weight_2})\n        np.allclose(result, self.expected_batch_result_with_weights, 1e-3)\n\n        # Set weights for one output.\n        result = model.test_on_batch([self.x, self.x], [self.y1, self.y2],\n                                     sample_weight={\n                                         \'output_2\': self.sample_weight_2})\n        np.allclose(result,\n                    self.expected_batch_result_with_weights_output_2, 1e-3)\n\n    def test_fit_generator(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        history = model.fit_generator(\n            custom_generator_multi_io(), steps_per_epoch=2, epochs=2)\n        for key, value in self.expected_fit_result.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n    def test_fit_generator_with_sample_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        history = model.fit_generator(\n            custom_generator_multi_io(\n                sample_weights=[self.sample_weight_1, self.sample_weight_2]),\n            steps_per_epoch=2,\n            epochs=2)\n        for key, value in self.expected_fit_result_with_weights.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n        # Set weights for one output.\n        history = model.fit_generator(\n            custom_generator_multi_io(sample_weights=[None, self.sample_weight_2]),\n            steps_per_epoch=2,\n            epochs=2)\n        for key, value in self.expected_fit_result_with_weights_output_2.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n    def test_fit_generator_with_class_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        history = model.fit_generator(\n            custom_generator_multi_io(),\n            class_weight={\n                \'output_1\': self.class_weight_1,\n                \'output_2\': self.class_weight_2,\n            },\n            steps_per_epoch=2,\n            epochs=2)\n        for key, value in self.expected_fit_result_with_weights.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n        # Set weights for one output.\n        history = model.fit_generator(\n            custom_generator_multi_io(),\n            class_weight={\'output_2\': self.class_weight_2},\n            steps_per_epoch=2,\n            epochs=2)\n        for key, value in self.expected_fit_result_with_weights_output_2.items():\n            np.allclose(history.history[key], value, 1e-3)\n\n    def test_eval_generator(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        eval_result = model.evaluate_generator(custom_generator_multi_io(), steps=2)\n        np.allclose(eval_result, self.expected_batch_result, 1e-3)\n\n    def test_eval_generator_with_sample_weight(self):\n        self.setUp()\n        model = self._get_compiled_multi_io_model()\n        eval_result = model.evaluate_generator(\n            custom_generator_multi_io(\n                sample_weights=[self.sample_weight_1, self.sample_weight_2]),\n            steps=2)\n        np.allclose(eval_result, self.expected_batch_result_with_weights, 1e-3)\n\n        # Set weights for one output.\n        eval_result = model.evaluate_generator(\n            custom_generator_multi_io(sample_weights=[None, self.sample_weight_2]),\n            steps=2)\n        np.allclose(eval_result,\n                    self.expected_batch_result_with_weights_output_2, 1e-3)\n'"
tests/keras/metrics_functional_test.py,0,"b'import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom flaky import flaky\n\nimport keras\nfrom keras import metrics\nfrom keras import backend as K\n\nall_metrics = [\n    metrics.binary_accuracy,\n    metrics.categorical_accuracy,\n    metrics.mean_squared_error,\n    metrics.mean_absolute_error,\n    metrics.mean_absolute_percentage_error,\n    metrics.mean_squared_logarithmic_error,\n    metrics.squared_hinge,\n    metrics.hinge,\n    metrics.categorical_crossentropy,\n    metrics.binary_crossentropy,\n    metrics.poisson,\n    metrics.cosine_proximity,\n    metrics.logcosh,\n]\n\nall_sparse_metrics = [\n    metrics.sparse_categorical_accuracy,\n    metrics.sparse_categorical_crossentropy,\n]\n\n\n@pytest.mark.parametrize(\'metric\', all_metrics)\ndef test_metrics(metric):\n    y_a = K.variable(np.random.random((6, 7)))\n    y_b = K.variable(np.random.random((6, 7)))\n    output = metric(y_a, y_b)\n    assert K.eval(output).shape == (6,)\n\n\n@pytest.mark.parametrize(\'metric\', all_sparse_metrics)\ndef test_sparse_metrics(metric):\n    y_a = K.variable(np.random.randint(0, 7, (6,)), dtype=K.floatx())\n    y_b = K.variable(np.random.random((6, 7)), dtype=K.floatx())\n    assert K.eval(metric(y_a, y_b)).shape == (6,)\n\n\n@pytest.mark.parametrize(\'shape\', [(6,), (6, 3), (6, 3, 1)])\ndef test_sparse_categorical_accuracy_correctness(shape):\n    y_a = K.variable(np.random.randint(0, 7, shape), dtype=K.floatx())\n    y_b_shape = shape + (7,)\n    y_b = K.variable(np.random.random(y_b_shape), dtype=K.floatx())\n    # use one_hot embedding to convert sparse labels to equivalent dense labels\n    y_a_dense_labels = K.cast(K.one_hot(K.cast(y_a, dtype=\'int32\'), 7),\n                              dtype=K.floatx())\n    sparse_categorical_acc = metrics.sparse_categorical_accuracy(y_a, y_b)\n    categorical_acc = metrics.categorical_accuracy(y_a_dense_labels, y_b)\n    assert np.allclose(K.eval(sparse_categorical_acc), K.eval(categorical_acc))\n\n\ndef test_serialize():\n    \'\'\'This is a mock \'round trip\' of serialize and deserialize.\n    \'\'\'\n\n    class MockMetric:\n        def __init__(self):\n            self.__name__ = ""mock_metric""\n\n    mock = MockMetric()\n    found = metrics.serialize(mock)\n    assert found == ""mock_metric""\n\n    found = metrics.deserialize(\'mock_metric\',\n                                custom_objects={\'mock_metric\': True})\n    assert found is True\n\n\ndef test_invalid_get():\n\n    with pytest.raises(ValueError):\n        metrics.get(5)\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=\'CNTK backend does not support top_k yet\')\ndef test_top_k_categorical_accuracy():\n    y_pred = K.variable(np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]))\n    y_true = K.variable(np.array([[0, 1, 0], [1, 0, 0]]))\n    success_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n                                                               k=3))\n    assert np.mean(success_result) == 1\n    partial_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n                                                               k=2))\n    assert np.mean(partial_result) == 0.5\n    failure_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n                                                               k=1))\n    assert np.mean(failure_result) == 0\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=\'CNTK backend does not support top_k yet\')\n@pytest.mark.parametrize(\'y_pred, y_true\', [\n    # Test correctness if the shape of y_true is (num_samples, 1)\n    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n    # Test correctness if the shape of y_true is (num_samples,)\n    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n])\ndef test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n    y_pred = K.variable(y_pred)\n    y_true = K.variable(y_true)\n    success_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n\n    assert np.mean(success_result) == 1\n    partial_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2))\n\n    assert np.mean(partial_result) == 0.5\n    failure_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1))\n\n    assert np.mean(failure_result) == 0\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/metrics_test.py,0,"b'""""""Tests for Keras metrics classes.""""""\nimport pytest\nimport numpy as np\nimport math\n\nfrom keras import metrics\nfrom keras import backend as K\n\n\nif K.backend() != \'tensorflow\':\n    # Need TensorFlow to use metric.__call__\n    pytestmark = pytest.mark.skip\n\n\nclass TestSum(object):\n\n    def test_sum(self):\n        m = metrics.Sum(name=\'my_sum\', dtype=\'float32\')\n\n        # check config\n        assert m.name == \'my_sum\'\n        assert m.stateful\n        assert m.dtype == \'float32\'\n        assert len(m.weights) == 1\n\n        # check initial state\n        assert K.eval(m.total) == 0\n\n        # check __call__\n        assert K.eval(m(100.0)) == 100\n        assert K.eval(m.total) == 100\n\n        # check update_state() and result() + state accumulation + tensor input\n        result = m([1, 5])\n        assert np.isclose(K.eval(result), 106)\n        assert K.eval(m.total) == 106  # 100 + 1 + 5\n\n        # check reset_states()\n        m.reset_states()\n        assert K.eval(m.total) == 0\n\n    def test_sum_with_sample_weight(self):\n        m = metrics.Sum(dtype=\'float64\')\n        assert m.dtype == \'float64\'\n\n        # check scalar weight\n        result_t = m(100, sample_weight=0.5)\n        assert K.eval(result_t) == 50\n        assert K.eval(m.total) == 50\n\n        # check weights not scalar and weights rank matches values rank\n        result_t = m([1, 5], sample_weight=[1, 0.2])\n        result = K.eval(result_t)\n        assert np.isclose(result, 52.)  # 50 + 1 + 5 * 0.2\n        assert np.isclose(K.eval(m.total), 52.)\n\n        # check weights broadcast\n        result_t = m([1, 2], sample_weight=0.5)\n        assert np.isclose(K.eval(result_t), 53.5)  # 52 + 0.5 + 1\n        assert np.isclose(K.eval(m.total), 53.5)\n\n        # check weights squeeze\n        result_t = m([1, 5], sample_weight=[[1], [0.2]])\n        assert np.isclose(K.eval(result_t), 55.5)  # 53.5 + 1 + 1\n        assert np.isclose(K.eval(m.total), 55.5)\n\n        # check weights expand\n        result_t = m([[1], [5]], sample_weight=[1, 0.2])\n        assert np.isclose(K.eval(result_t), 57.5, 2)  # 55.5 + 1 + 1\n        assert np.isclose(K.eval(m.total), 57.5, 1)\n\n        # check values reduced to the dimensions of weight\n        result_t = m([[[1., 2.], [3., 2.], [0.5, 4.]]], sample_weight=[0.5])\n        result = np.round(K.eval(result_t), decimals=2)\n        # result = (prev: 57.5) + 0.5 + 1 + 1.5 + 1 + 0.25 + 2\n        assert np.isclose(result, 63.75, 2)\n        assert np.isclose(K.eval(m.total), 63.75, 2)\n\n\nclass TestMean(object):\n\n    def test_mean(self):\n        m = metrics.Mean(name=\'my_mean\')\n\n        # check config\n        assert m.name == \'my_mean\'\n        assert m.stateful\n        assert m.dtype == \'float32\'\n        assert len(m.weights) == 2\n\n        # check initial state\n        assert K.eval(m.total) == 0\n        assert K.eval(m.count) == 0\n\n        # check __call__()\n        assert K.eval(m(100)) == 100\n        assert K.eval(m.total) == 100\n        assert K.eval(m.count) == 1\n\n        # check update_state() and result()\n        result = m([1, 5])\n        assert np.isclose(K.eval(result), 106. / 3)\n        assert K.eval(m.total) == 106  # 100 + 1 + 5\n        assert K.eval(m.count) == 3\n\n        # check reset_states()\n        m.reset_states()\n        assert K.eval(m.total) == 0\n        assert K.eval(m.count) == 0\n\n        # Check save and restore config\n        m2 = metrics.Mean.from_config(m.get_config())\n        assert m2.name == \'my_mean\'\n        assert m2.stateful\n        assert m2.dtype == \'float32\'\n        assert len(m2.weights) == 2\n\n    def test_mean_with_sample_weight(self):\n        m = metrics.Mean(dtype=\'float64\')\n        assert m.dtype == \'float64\'\n\n        # check scalar weight\n        result_t = m(100, sample_weight=0.5)\n        assert K.eval(result_t) == 50. / 0.5\n        assert K.eval(m.total) == 50\n        assert K.eval(m.count) == 0.5\n\n        # check weights not scalar and weights rank matches values rank\n        result_t = m([1, 5], sample_weight=[1, 0.2])\n        result = K.eval(result_t)\n        assert np.isclose(result, 52. / 1.7)\n        assert np.isclose(K.eval(m.total), 52)  # 50 + 1 + 5 * 0.2\n        assert np.isclose(K.eval(m.count), 1.7)  # 0.5 + 1.2\n\n        # check weights broadcast\n        result_t = m([1, 2], sample_weight=0.5)\n        assert np.isclose(K.eval(result_t), 53.5 / 2.7, rtol=3)\n        assert np.isclose(K.eval(m.total), 53.5, rtol=3)  # 52 + 0.5 + 1\n        assert np.isclose(K.eval(m.count), 2.7, rtol=3)  # 1.7 + 0.5 + 0.5\n\n        # check weights squeeze\n        result_t = m([1, 5], sample_weight=[[1], [0.2]])\n        assert np.isclose(K.eval(result_t), 55.5 / 3.9, rtol=3)\n        assert np.isclose(K.eval(m.total), 55.5, rtol=3)  # 53.5 + 1 + 1\n        assert np.isclose(K.eval(m.count), 3.9, rtol=3)  # 2.7 + 1.2\n\n        # check weights expand\n        result_t = m([[1], [5]], sample_weight=[1, 0.2])\n        assert np.isclose(K.eval(result_t), 57.5 / 5.1, rtol=3)\n        assert np.isclose(K.eval(m.total), 57.5, rtol=3)  # 55.5 + 1 + 1\n        assert np.isclose(K.eval(m.count), 5.1, rtol=3)  # 3.9 + 1.2\n\n    def test_multiple_instances(self):\n        m = metrics.Mean()\n        m2 = metrics.Mean()\n\n        assert m.name == \'mean\'\n        assert m2.name == \'mean\'\n\n        # check initial state\n        assert K.eval(m.total) == 0\n        assert K.eval(m.count) == 0\n        assert K.eval(m2.total) == 0\n        assert K.eval(m2.count) == 0\n\n        # check __call__()\n        assert K.eval(m(100)) == 100\n        assert K.eval(m.total) == 100\n        assert K.eval(m.count) == 1\n        assert K.eval(m2.total) == 0\n        assert K.eval(m2.count) == 0\n\n        assert K.eval(m2([63, 10])) == 36.5\n        assert K.eval(m2.total) == 73\n        assert K.eval(m2.count) == 2\n        assert K.eval(m.result()) == 100\n        assert K.eval(m.total) == 100\n        assert K.eval(m.count) == 1\n\n\nclass TestAccuracy(object):\n\n    def test_accuracy(self):\n        acc_obj = metrics.Accuracy(name=\'my_acc\')\n\n        # check config\n        assert acc_obj.name == \'my_acc\'\n        assert acc_obj.stateful\n        assert len(acc_obj.weights) == 2\n        assert acc_obj.dtype == \'float32\'\n\n        # verify that correct value is returned\n        result = K.eval(acc_obj([[1], [2], [3], [4]], [[1], [2], [3], [4]]))\n        assert result == 1  # 2/2\n\n        # Check save and restore config\n        a2 = metrics.Accuracy.from_config(acc_obj.get_config())\n        assert a2.name == \'my_acc\'\n        assert a2.stateful\n        assert len(a2.weights) == 2\n        assert a2.dtype, \'float32\'\n\n        # check with sample_weight\n        result_t = acc_obj([[2], [1]], [[2], [0]], sample_weight=[[0.5], [0.2]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 4.5 / 4.7, atol=1e-3)\n\n    def test_binary_accuracy(self):\n        acc_obj = metrics.BinaryAccuracy(name=\'my_acc\')\n\n        # check config\n        assert acc_obj.name == \'my_acc\'\n        assert acc_obj.stateful\n        assert len(acc_obj.weights) == 2\n        assert acc_obj.dtype == \'float32\'\n\n        # verify that correct value is returned\n        result_t = acc_obj([[1], [0]], [[1], [0]])\n        result = K.eval(result_t)\n        assert result == 1  # 2/2\n\n        # check y_pred squeeze\n        result_t = acc_obj([[1], [1]], [[[1]], [[0]]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 3. / 4., atol=1e-3)\n\n        # check y_true squeeze\n        result_t = acc_obj([[[1]], [[1]]], [[1], [0]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 4. / 6., atol=1e-3)\n\n        # check with sample_weight\n        result_t = acc_obj([[1], [1]], [[1], [0]], [[0.5], [0.2]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 4.5 / 6.7, atol=1e-3)\n\n    def test_binary_accuracy_threshold(self):\n        acc_obj = metrics.BinaryAccuracy(threshold=0.7)\n        result_t = acc_obj([[1], [1], [0], [0]], [[0.9], [0.6], [0.4], [0.8]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 0.5, atol=1e-3)\n\n    def test_categorical_accuracy(self):\n        acc_obj = metrics.CategoricalAccuracy(name=\'my_acc\')\n\n        # check config\n        assert acc_obj.name == \'my_acc\'\n        assert acc_obj.stateful\n        assert len(acc_obj.weights) == 2\n        assert acc_obj.dtype == \'float32\'\n\n        # verify that correct value is returned\n        result_t = acc_obj([[0, 0, 1], [0, 1, 0]],\n                           [[0.1, 0.1, 0.8], [0.05, 0.95, 0]])\n        result = K.eval(result_t)\n        assert result == 1  # 2/2\n\n        # check with sample_weight\n        result_t = acc_obj([[0, 0, 1], [0, 1, 0]],\n                           [[0.1, 0.1, 0.8], [0.05, 0, 0.95]],\n                           [[0.5], [0.2]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 2.5 / 2.7, atol=1e-3)  # 2.5/2.7\n\n    def test_sparse_categorical_accuracy(self):\n        acc_obj = metrics.SparseCategoricalAccuracy(name=\'my_acc\')\n\n        # check config\n        assert acc_obj.name == \'my_acc\'\n        assert acc_obj.stateful\n        assert len(acc_obj.weights) == 2\n        assert acc_obj.dtype == \'float32\'\n\n        # verify that correct value is returned\n        result_t = acc_obj([[2], [1]],\n                           [[0.1, 0.1, 0.8],\n                           [0.05, 0.95, 0]])\n        result = K.eval(result_t)\n        assert result == 1  # 2/2\n\n        # check with sample_weight\n        result_t = acc_obj([[2], [1]],\n                           [[0.1, 0.1, 0.8], [0.05, 0, 0.95]],\n                           [[0.5], [0.2]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 2.5 / 2.7, atol=1e-3)\n\n    def test_sparse_categorical_accuracy_mismatched_dims(self):\n        acc_obj = metrics.SparseCategoricalAccuracy(name=\'my_acc\')\n\n        # check config\n        assert acc_obj.name == \'my_acc\'\n        assert acc_obj.stateful\n        assert len(acc_obj.weights) == 2\n        assert acc_obj.dtype == \'float32\'\n\n        # verify that correct value is returned\n        result_t = acc_obj([2, 1], [[0.1, 0.1, 0.8], [0.05, 0.95, 0]])\n        result = K.eval(result_t)\n        assert result == 1  # 2/2\n\n        # check with sample_weight\n        result_t = acc_obj([2, 1], [[0.1, 0.1, 0.8], [0.05, 0, 0.95]],\n                           [[0.5], [0.2]])\n        result = K.eval(result_t)\n        assert np.isclose(result, 2.5 / 2.7, atol=1e-3)\n\n\nclass TestMeanSquaredErrorTest(object):\n\n    def test_config(self):\n        mse_obj = metrics.MeanSquaredError(name=\'my_mse\', dtype=\'int32\')\n        assert mse_obj.name == \'my_mse\'\n        assert mse_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        mse_obj2 = metrics.MeanSquaredError.from_config(mse_obj.get_config())\n        assert mse_obj2.name == \'my_mse\'\n        assert mse_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        mse_obj = metrics.MeanSquaredError()\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n\n        result = mse_obj(y_true, y_pred)\n        np.isclose(0.5, K.eval(result), atol=1e-5)\n\n    def test_weighted(self):\n        mse_obj = metrics.MeanSquaredError()\n        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n        sample_weight = (1., 1.5, 2., 2.5)\n        result = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n        np.isclose(0.54285, K.eval(result), atol=1e-5)\n\n\nclass TestHinge(object):\n\n    def test_config(self):\n        hinge_obj = metrics.Hinge(name=\'hinge\', dtype=\'int32\')\n        assert hinge_obj.name == \'hinge\'\n        assert hinge_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        hinge_obj2 = metrics.Hinge.from_config(hinge_obj.get_config())\n        assert hinge_obj2.name == \'hinge\'\n        assert hinge_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        hinge_obj = metrics.Hinge()\n        y_true = K.constant([[0, 1, 0, 1], [0, 0, 1, 1]])\n        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n                             [-0.25, -1., 0.5, 0.6]])\n\n        result = hinge_obj(y_true, y_pred)\n        assert np.allclose(0.506, K.eval(result), atol=1e-3)\n\n    def test_weighted(self):\n        hinge_obj = metrics.Hinge()\n        y_true = K.constant([[-1, 1, -1, 1], [-1, -1, 1, 1]])\n        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n                             [-0.25, -1., 0.5, 0.6]])\n        sample_weight = K.constant([1.5, 2.])\n\n        result = hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(0.493, K.eval(result), atol=1e-3)\n\n\nclass TestSquaredHinge(object):\n\n    def test_config(self):\n        sq_hinge_obj = metrics.SquaredHinge(name=\'sq_hinge\', dtype=\'int32\')\n        assert sq_hinge_obj.name == \'sq_hinge\'\n        assert sq_hinge_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        sq_hinge_obj2 = metrics.SquaredHinge.from_config(\n            sq_hinge_obj.get_config())\n        assert sq_hinge_obj2.name == \'sq_hinge\'\n        assert sq_hinge_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        sq_hinge_obj = metrics.SquaredHinge()\n        y_true = K.constant([[0, 1, 0, 1], [0, 0, 1, 1]])\n        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n                             [-0.25, -1., 0.5, 0.6]])\n\n        result = sq_hinge_obj(y_true, y_pred)\n        assert np.allclose(0.364, K.eval(result), atol=1e-3)\n\n    def test_weighted(self):\n        sq_hinge_obj = metrics.SquaredHinge()\n        y_true = K.constant([[-1, 1, -1, 1], [-1, -1, 1, 1]])\n        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n                             [-0.25, -1., 0.5, 0.6]])\n        sample_weight = K.constant([1.5, 2.])\n\n        result = sq_hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(0.347, K.eval(result), atol=1e-3)\n\n\nclass TestCategoricalHinge(object):\n\n    def test_config(self):\n        cat_hinge_obj = metrics.CategoricalHinge(\n            name=\'cat_hinge\', dtype=\'int32\')\n        assert cat_hinge_obj.name == \'cat_hinge\'\n        assert cat_hinge_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        cat_hinge_obj2 = metrics.CategoricalHinge.from_config(\n            cat_hinge_obj.get_config())\n        assert cat_hinge_obj2.name == \'cat_hinge\'\n        assert cat_hinge_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        cat_hinge_obj = metrics.CategoricalHinge()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n\n        result = cat_hinge_obj(y_true, y_pred)\n        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n\n    def test_weighted(self):\n        cat_hinge_obj = metrics.CategoricalHinge()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n        sample_weight = K.constant((1., 1.5, 2., 2.5))\n        result = cat_hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n\n\nclass TestTopKCategoricalAccuracy(object):\n\n    def test_config(self):\n        a_obj = metrics.TopKCategoricalAccuracy(name=\'topkca\', dtype=\'int32\')\n        assert a_obj.name == \'topkca\'\n        assert a_obj.dtype == \'int32\'\n\n        a_obj2 = metrics.TopKCategoricalAccuracy.from_config(a_obj.get_config())\n        assert a_obj2.name == \'topkca\'\n        assert a_obj2.dtype == \'int32\'\n\n    def test_correctness(self):\n        a_obj = metrics.TopKCategoricalAccuracy()\n        y_true = [[0, 0, 1], [0, 1, 0]]\n        y_pred = [[0.1, 0.9, 0.8], [0.05, 0.95, 0]]\n\n        result = a_obj(y_true, y_pred)\n        assert 1 == K.eval(result)  # both the samples match\n\n        # With `k` < 5.\n        a_obj = metrics.TopKCategoricalAccuracy(k=1)\n        result = a_obj(y_true, y_pred)\n        assert 0.5 == K.eval(result)  # only sample #2 matches\n\n        # With `k` > 5.\n        y_true = ([[0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0]])\n        y_pred = [[0.5, 0.9, 0.1, 0.7, 0.6, 0.5, 0.4],\n                  [0.05, 0.95, 0, 0, 0, 0, 0]]\n        a_obj = metrics.TopKCategoricalAccuracy(k=6)\n        result = a_obj(y_true, y_pred)\n        assert 0.5 == K.eval(result)  # only 1 sample matches.\n\n    def test_weighted(self):\n        a_obj = metrics.TopKCategoricalAccuracy(k=2)\n        y_true = [[0, 1, 0], [1, 0, 0], [0, 0, 1]]\n        y_pred = [[0, 0.9, 0.1], [0, 0.9, 0.1], [0, 0.9, 0.1]]\n        sample_weight = (1.0, 0.0, 1.0)\n        result = a_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(1.0, K.eval(result), atol=1e-5)\n\n\nclass TestSparseTopKCategoricalAccuracy(object):\n\n    def test_config(self):\n        a_obj = metrics.SparseTopKCategoricalAccuracy(\n            name=\'stopkca\', dtype=\'int32\')\n        assert a_obj.name == \'stopkca\'\n        assert a_obj.dtype == \'int32\'\n\n        a_obj2 = metrics.SparseTopKCategoricalAccuracy.from_config(\n            a_obj.get_config())\n        assert a_obj2.name == \'stopkca\'\n        assert a_obj2.dtype == \'int32\'\n\n    def test_correctness(self):\n        a_obj = metrics.SparseTopKCategoricalAccuracy()\n        y_true = [2, 1]\n        y_pred = [[0.1, 0.9, 0.8], [0.05, 0.95, 0]]\n\n        result = a_obj(y_true, y_pred)\n        assert 1 == K.eval(result)  # both the samples match\n\n        # With `k` < 5.\n        a_obj = metrics.SparseTopKCategoricalAccuracy(k=1)\n        result = a_obj(y_true, y_pred)\n        assert 0.5 == K.eval(result)  # only sample #2 matches\n\n        # With `k` > 5.\n        y_pred = [[0.5, 0.9, 0.1, 0.7, 0.6, 0.5, 0.4],\n                  [0.05, 0.95, 0, 0, 0, 0, 0]]\n        a_obj = metrics.SparseTopKCategoricalAccuracy(k=6)\n        result = a_obj(y_true, y_pred)\n        assert 0.5 == K.eval(result)  # only 1 sample matches.\n\n    def test_weighted(self):\n        a_obj = metrics.SparseTopKCategoricalAccuracy(k=2)\n        y_true = [1, 0, 2]\n        y_pred = [[0, 0.9, 0.1], [0, 0.9, 0.1], [0, 0.9, 0.1]]\n        sample_weight = (1.0, 0.0, 1.0)\n        result = a_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(1.0, K.eval(result), atol=1e-5)\n\n\nclass TestLogCoshError(object):\n\n    def setup(self):\n        self.y_pred = np.asarray([1, 9, 2, -5, -2, 6]).reshape((2, 3))\n        self.y_true = np.asarray([4, 8, 12, 8, 1, 3]).reshape((2, 3))\n        self.batch_size = 6\n        error = self.y_pred - self.y_true\n        self.expected_results = np.log((np.exp(error) + np.exp(-error)) / 2)\n\n    def test_config(self):\n        logcosh_obj = metrics.LogCoshError(name=\'logcosh\', dtype=\'int32\')\n        assert logcosh_obj.name == \'logcosh\'\n        assert logcosh_obj.dtype == \'int32\'\n\n    def test_unweighted(self):\n        self.setup()\n        logcosh_obj = metrics.LogCoshError()\n\n        result = logcosh_obj(self.y_true, self.y_pred)\n        expected_result = np.sum(self.expected_results) / self.batch_size\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted(self):\n        self.setup()\n        logcosh_obj = metrics.LogCoshError()\n        sample_weight = [[1.2], [3.4]]\n        result = logcosh_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n\n        sample_weight = np.asarray([1.2, 1.2, 1.2, 3.4, 3.4, 3.4]).reshape((2, 3))\n        expected_result = np.multiply(self.expected_results, sample_weight)\n        expected_result = np.sum(expected_result) / np.sum(sample_weight)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n\nclass TestPoisson(object):\n\n    def setup(self):\n        self.y_pred = np.asarray([1, 9, 2, 5, 2, 6]).reshape((2, 3))\n        self.y_true = np.asarray([4, 8, 12, 8, 1, 3]).reshape((2, 3))\n        self.batch_size = 6\n        self.expected_results = self.y_pred - np.multiply(\n            self.y_true, np.log(self.y_pred))\n\n    def test_config(self):\n        poisson_obj = metrics.Poisson(name=\'poisson\', dtype=\'int32\')\n        assert poisson_obj.name == \'poisson\'\n        assert poisson_obj.dtype == \'int32\'\n\n        poisson_obj2 = metrics.Poisson.from_config(poisson_obj.get_config())\n        assert poisson_obj2.name == \'poisson\'\n        assert poisson_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        self.setup()\n        poisson_obj = metrics.Poisson()\n\n        result = poisson_obj(self.y_true, self.y_pred)\n        expected_result = np.sum(self.expected_results) / self.batch_size\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted(self):\n        self.setup()\n        poisson_obj = metrics.Poisson()\n        sample_weight = [[1.2], [3.4]]\n\n        result = poisson_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n        sample_weight = np.asarray([1.2, 1.2, 1.2, 3.4, 3.4, 3.4]).reshape((2, 3))\n        expected_result = np.multiply(self.expected_results, sample_weight)\n        expected_result = np.sum(expected_result) / np.sum(sample_weight)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n\nclass TestKLDivergence(object):\n\n    def setup(self):\n        self.y_pred = np.asarray([.4, .9, .12, .36, .3, .4]).reshape((2, 3))\n        self.y_true = np.asarray([.5, .8, .12, .7, .43, .8]).reshape((2, 3))\n        self.batch_size = 2\n        self.expected_results = np.multiply(\n            self.y_true, np.log(self.y_true / self.y_pred))\n\n    def test_config(self):\n        k_obj = metrics.KLDivergence(name=\'kld\', dtype=\'int32\')\n        assert k_obj.name == \'kld\'\n        assert k_obj.dtype == \'int32\'\n\n        k_obj2 = metrics.KLDivergence.from_config(k_obj.get_config())\n        assert k_obj2.name == \'kld\'\n        assert k_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        self.setup()\n        k_obj = metrics.KLDivergence()\n\n        result = k_obj(self.y_true, self.y_pred)\n        expected_result = np.sum(self.expected_results) / self.batch_size\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n    def test_weighted(self):\n        self.setup()\n        k_obj = metrics.KLDivergence()\n        sample_weight = [[1.2], [3.4]]\n        result = k_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n\n        sample_weight = np.asarray([1.2, 1.2, 1.2, 3.4, 3.4, 3.4]).reshape((2, 3))\n        expected_result = np.multiply(self.expected_results, sample_weight)\n        expected_result = np.sum(expected_result) / (1.2 + 3.4)\n        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n\nclass TestCosineSimilarity(object):\n\n    def l2_norm(self, x, axis):\n        epsilon = 1e-12\n        square_sum = np.sum(np.square(x), axis=axis, keepdims=True)\n        x_inv_norm = 1 / np.sqrt(np.maximum(square_sum, epsilon))\n        return np.multiply(x, x_inv_norm)\n\n    def setup(self, axis=1):\n        self.np_y_true = np.asarray([[1, 9, 2], [-5, -2, 6]], dtype=np.float32)\n        self.np_y_pred = np.asarray([[4, 8, 12], [8, 1, 3]], dtype=np.float32)\n\n        y_true = self.l2_norm(self.np_y_true, axis)\n        y_pred = self.l2_norm(self.np_y_pred, axis)\n        self.expected_loss = np.sum(np.multiply(y_true, y_pred), axis=(axis,))\n\n        self.y_true = K.constant(self.np_y_true)\n        self.y_pred = K.constant(self.np_y_pred)\n\n    def test_config(self):\n        cosine_obj = metrics.CosineSimilarity(\n            axis=2, name=\'my_cos\', dtype=\'int32\')\n        assert cosine_obj.name == \'my_cos\'\n        assert cosine_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        cosine_obj2 = metrics.CosineSimilarity.from_config(cosine_obj.get_config())\n        assert cosine_obj2.name == \'my_cos\'\n        assert cosine_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        self.setup()\n        cosine_obj = metrics.CosineSimilarity()\n        loss = cosine_obj(self.y_true, self.y_pred)\n        expected_loss = np.mean(self.expected_loss)\n        assert np.allclose(K.eval(loss), expected_loss, 3)\n\n    def test_weighted(self):\n        self.setup()\n        cosine_obj = metrics.CosineSimilarity()\n        sample_weight = np.asarray([1.2, 3.4])\n        loss = cosine_obj(\n            self.y_true,\n            self.y_pred,\n            sample_weight=K.constant(sample_weight))\n        expected_loss = np.sum(\n            self.expected_loss * sample_weight) / np.sum(sample_weight)\n        assert np.allclose(K.eval(loss), expected_loss, 3)\n\n    def test_axis(self):\n        self.setup(axis=1)\n        cosine_obj = metrics.CosineSimilarity(axis=1)\n        loss = cosine_obj(self.y_true, self.y_pred)\n        expected_loss = np.mean(self.expected_loss)\n        assert np.allclose(K.eval(loss), expected_loss, 3)\n\n\nclass TestMeanAbsoluteError(object):\n\n    def test_config(self):\n        mae_obj = metrics.MeanAbsoluteError(name=\'my_mae\', dtype=\'int32\')\n        assert mae_obj.name == \'my_mae\'\n        assert mae_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        mae_obj2 = metrics.MeanAbsoluteError.from_config(mae_obj.get_config())\n        assert mae_obj2.name == \'my_mae\'\n        assert mae_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        mae_obj = metrics.MeanAbsoluteError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n\n        result = mae_obj(y_true, y_pred)\n        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n\n    def test_weighted(self):\n        mae_obj = metrics.MeanAbsoluteError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n        sample_weight = K.constant((1., 1.5, 2., 2.5))\n        result = mae_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(0.54285, K.eval(result), atol=1e-5)\n\n\nclass TestMeanAbsolutePercentageError(object):\n\n    def test_config(self):\n        mape_obj = metrics.MeanAbsolutePercentageError(\n            name=\'my_mape\', dtype=\'int32\')\n        assert mape_obj.name == \'my_mape\'\n        assert mape_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        mape_obj2 = metrics.MeanAbsolutePercentageError.from_config(\n            mape_obj.get_config())\n        assert mape_obj2.name == \'my_mape\'\n        assert mape_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        mape_obj = metrics.MeanAbsolutePercentageError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n\n        result = mape_obj(y_true, y_pred)\n        assert np.allclose(35e7, K.eval(result), atol=1e-5)\n\n    def test_weighted(self):\n        mape_obj = metrics.MeanAbsolutePercentageError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n        sample_weight = K.constant((1., 1.5, 2., 2.5))\n        result = mape_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(40e7, K.eval(result), atol=1e-5)\n\n\nclass TestMeanSquaredError(object):\n\n    def test_config(self):\n        mse_obj = metrics.MeanSquaredError(name=\'my_mse\', dtype=\'int32\')\n        assert mse_obj.name == \'my_mse\'\n        assert mse_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        mse_obj2 = metrics.MeanSquaredError.from_config(mse_obj.get_config())\n        assert mse_obj2.name == \'my_mse\'\n        assert mse_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        mse_obj = metrics.MeanSquaredError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n\n        result = mse_obj(y_true, y_pred)\n        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n\n    def test_weighted(self):\n        mse_obj = metrics.MeanSquaredError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n        sample_weight = K.constant((1., 1.5, 2., 2.5))\n        result = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(0.54285, K.eval(result), atol=1e-5)\n\n\nclass TestMeanSquaredLogarithmicError(object):\n\n    def test_config(self):\n        msle_obj = metrics.MeanSquaredLogarithmicError(\n            name=\'my_msle\', dtype=\'int32\')\n        assert msle_obj.name == \'my_msle\'\n        assert msle_obj.dtype == \'int32\'\n\n        # Check save and restore config\n        msle_obj2 = metrics.MeanSquaredLogarithmicError.from_config(\n            msle_obj.get_config())\n        assert msle_obj2.name == \'my_msle\'\n        assert msle_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        msle_obj = metrics.MeanSquaredLogarithmicError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n\n        result = msle_obj(y_true, y_pred)\n        assert np.allclose(0.24022, K.eval(result), atol=1e-5)\n\n    def test_weighted(self):\n        msle_obj = metrics.MeanSquaredLogarithmicError()\n        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n        sample_weight = K.constant((1., 1.5, 2., 2.5))\n        result = msle_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(0.26082, K.eval(result), atol=1e-5)\n\n\nclass TestRootMeanSquaredError(object):\n\n    def test_config(self):\n        rmse_obj = metrics.RootMeanSquaredError(name=\'rmse\', dtype=\'int32\')\n        assert rmse_obj.name == \'rmse\'\n        assert rmse_obj.dtype == \'int32\'\n\n        rmse_obj2 = metrics.RootMeanSquaredError.from_config(rmse_obj.get_config())\n        assert rmse_obj2.name == \'rmse\'\n        assert rmse_obj2.dtype == \'int32\'\n\n    def test_unweighted(self):\n        rmse_obj = metrics.RootMeanSquaredError()\n        y_true = K.constant((2, 4, 6))\n        y_pred = K.constant((1, 3, 2))\n\n        update_op = rmse_obj(y_true, y_pred)\n        K.eval(update_op)\n        result = rmse_obj(y_true, y_pred)\n        # error = [-1, -1, -4], square(error) = [1, 1, 16], mean = 18/3 = 6\n        assert np.allclose(math.sqrt(6), K.eval(result), atol=1e-3)\n\n    def test_weighted(self):\n        rmse_obj = metrics.RootMeanSquaredError()\n        y_true = K.constant((2, 4, 6, 8))\n        y_pred = K.constant((1, 3, 2, 3))\n        sample_weight = K.constant((0, 1, 0, 1))\n        result = rmse_obj(y_true, y_pred, sample_weight=sample_weight)\n        assert np.allclose(math.sqrt(13), K.eval(result), atol=1e-3)\n\n\nclass TestBinaryCrossentropy(object):\n\n    def test_config(self):\n        bce_obj = metrics.BinaryCrossentropy(\n            name=\'bce\', dtype=\'int32\', label_smoothing=0.2)\n        assert bce_obj.name == \'bce\'\n        assert bce_obj.dtype == \'int32\'\n\n        old_config = bce_obj.get_config()\n        assert np.allclose(old_config[\'label_smoothing\'], 0.2, atol=1e-3)\n\n    def test_unweighted(self):\n        bce_obj = metrics.BinaryCrossentropy()\n        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n        result = bce_obj(y_true, y_pred)\n\n        assert np.allclose(K.eval(result), 3.833, atol=1e-3)\n\n    def test_unweighted_with_logits(self):\n        bce_obj = metrics.BinaryCrossentropy(from_logits=True)\n\n        y_true = [[1, 0, 1], [0, 1, 1]]\n        y_pred = [[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]]\n        result = bce_obj(y_true, y_pred)\n\n        assert np.allclose(K.eval(result), 33.333, atol=1e-3)\n\n    def test_weighted(self):\n        bce_obj = metrics.BinaryCrossentropy()\n        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n        sample_weight = [1.5, 2.]\n        result = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        assert np.allclose(K.eval(result), 3.285, atol=1e-3)\n\n    def test_weighted_from_logits(self):\n        bce_obj = metrics.BinaryCrossentropy(from_logits=True)\n        y_true = [[1, 0, 1], [0, 1, 1]]\n        y_pred = [[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]]\n        sample_weight = [2., 2.5]\n        result = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        assert np.allclose(K.eval(result), 37.037, atol=1e-3)\n\n    def test_label_smoothing(self):\n        logits = ((100., -100., -100.))\n        y_true = ((1, 0, 1))\n        label_smoothing = 0.1\n        bce_obj = metrics.BinaryCrossentropy(\n            from_logits=True, label_smoothing=label_smoothing)\n        result = bce_obj(y_true, logits)\n        expected_value = (100.0 + 50.0 * label_smoothing) / 3.0\n        assert np.allclose(expected_value, K.eval(result), atol=1e-3)\n\n\nclass TestCategoricalCrossentropy(object):\n\n    def test_config(self):\n        cce_obj = metrics.CategoricalCrossentropy(\n            name=\'cce\', dtype=\'int32\', label_smoothing=0.2)\n        assert cce_obj.name == \'cce\'\n        assert cce_obj.dtype == \'int32\'\n\n        old_config = cce_obj.get_config()\n        assert np.allclose(old_config[\'label_smoothing\'], 0.2, 1e-3)\n\n    def test_unweighted(self):\n        cce_obj = metrics.CategoricalCrossentropy()\n\n        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n        result = cce_obj(y_true, y_pred)\n\n        assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n\n    def test_unweighted_from_logits(self):\n        cce_obj = metrics.CategoricalCrossentropy(from_logits=True)\n\n        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n        result = cce_obj(y_true, logits)\n\n        assert np.allclose(K.eval(result), 3.5011, atol=1e-3)\n\n    def test_weighted(self):\n        cce_obj = metrics.CategoricalCrossentropy()\n\n        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n        sample_weight = [1.5, 2.]\n        result = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        assert np.allclose(K.eval(result), 1.338, atol=1e-3)\n\n    def test_weighted_from_logits(self):\n        cce_obj = metrics.CategoricalCrossentropy(from_logits=True)\n\n        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n        sample_weight = [1.5, 2.]\n        result = cce_obj(y_true, logits, sample_weight=sample_weight)\n\n        assert np.allclose(K.eval(result), 4.0012, atol=1e-3)\n\n    def test_label_smoothing(self):\n        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n        label_smoothing = 0.1\n\n        cce_obj = metrics.CategoricalCrossentropy(\n            from_logits=True, label_smoothing=label_smoothing)\n        loss = cce_obj(y_true, logits)\n        assert np.allclose(K.eval(loss), 3.667, atol=1e-3)\n\n\nclass TestSparseCategoricalCrossentropy(object):\n\n    def test_config(self):\n        scce_obj = metrics.SparseCategoricalCrossentropy(\n            name=\'scce\', dtype=\'int32\')\n        assert scce_obj.name == \'scce\'\n        assert scce_obj.dtype == \'int32\'\n\n    def test_unweighted(self):\n        scce_obj = metrics.SparseCategoricalCrossentropy()\n\n        y_true = np.asarray([1, 2])\n        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n        result = scce_obj(y_true, y_pred)\n\n        assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n\n    def test_unweighted_from_logits(self):\n        scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n\n        y_true = np.asarray([1, 2])\n        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n        result = scce_obj(y_true, logits)\n\n        assert np.allclose(K.eval(result), 3.5011, atol=1e-3)\n\n    def test_weighted(self):\n        scce_obj = metrics.SparseCategoricalCrossentropy()\n\n        y_true = np.asarray([1, 2])\n        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n        sample_weight = [1.5, 2.]\n        result = scce_obj(y_true, y_pred, sample_weight=sample_weight)\n\n        assert np.allclose(K.eval(result), 1.338, atol=1e-3)\n\n    def test_weighted_from_logits(self):\n        scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n        y_true = np.asarray([1, 2])\n        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n        sample_weight = [1.5, 2.]\n        result = scce_obj(y_true, logits, sample_weight=sample_weight)\n\n        assert np.allclose(K.eval(result), 4.0012, atol=1e-3)\n\n    def test_axis(self):\n        scce_obj = metrics.SparseCategoricalCrossentropy(axis=0)\n\n        y_true = np.asarray([1, 2])\n        y_pred = np.asarray([[0.05, 0.1], [0.95, 0.8], [0, 0.1]])\n        result = scce_obj(y_true, y_pred)\n\n        assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n'"
tests/keras/metrics_training_test.py,1,"b'""""""Tests for metric objects training and evaluation.""""""\nimport pytest\nimport numpy as np\n\nfrom keras import metrics\nfrom keras import backend as K\nfrom keras.layers import Dense\nfrom keras.models import Sequential\n\n\nif K.backend() == \'cntk\':\n    pytestmark = pytest.mark.skip\n\n\nMETRICS = [\n    metrics.Accuracy,\n    metrics.MeanSquaredError,\n    metrics.Hinge,\n    metrics.CategoricalHinge,\n    metrics.SquaredHinge,\n    metrics.FalsePositives,\n    metrics.TruePositives,\n    metrics.FalseNegatives,\n    metrics.TrueNegatives,\n    metrics.BinaryAccuracy,\n    metrics.CategoricalAccuracy,\n    metrics.TopKCategoricalAccuracy,\n    metrics.LogCoshError,\n    metrics.Poisson,\n    metrics.KLDivergence,\n    metrics.CosineSimilarity,\n    metrics.MeanAbsoluteError,\n    metrics.MeanAbsolutePercentageError,\n    metrics.MeanSquaredError,\n    metrics.MeanSquaredLogarithmicError,\n    metrics.RootMeanSquaredError,\n    metrics.BinaryCrossentropy,\n    metrics.CategoricalCrossentropy,\n    metrics.Precision,\n    metrics.Recall,\n    metrics.AUC,\n]\nSPARSE_METRICS = [\n    metrics.SparseCategoricalAccuracy,\n    metrics.SparseTopKCategoricalAccuracy,\n    metrics.SparseCategoricalCrossentropy\n]\n\n\n@pytest.mark.parametrize(\'metric_cls\', METRICS)\ndef test_training_and_eval(metric_cls):\n    model = Sequential([Dense(2, input_shape=(3,))])\n    model.compile(\'rmsprop\', \'mse\', metrics=[metric_cls()])\n    x = np.random.random((10, 3))\n    y = np.random.random((10, 2))\n    model.fit(x, y)\n    model.evaluate(x, y)\n\n\n@pytest.mark.parametrize(\'metric_cls\', SPARSE_METRICS)\ndef test_sparse_metrics(metric_cls):\n    model = Sequential([Dense(1, input_shape=(3,))])\n    model.compile(\'rmsprop\', \'mse\', metrics=[metric_cls()])\n    x = np.random.random((10, 3))\n    y = np.random.random((10,))\n    model.fit(x, y)\n    model.evaluate(x, y)\n\n\ndef test_sensitivity_metrics():\n    metrics_list = [\n        metrics.SensitivityAtSpecificity(0.5),\n        metrics.SpecificityAtSensitivity(0.5),\n    ]\n    model = Sequential([Dense(2, input_shape=(3,))])\n    model.compile(\'rmsprop\', \'mse\', metrics=metrics_list)\n    x = np.random.random((10, 3))\n    y = np.random.random((10, 2))\n    model.fit(x, y)\n    model.evaluate(x, y)\n\n\n@pytest.mark.skipif(True, reason=\'It is a flaky test, see #13477 for more context.\')\ndef test_mean_iou():\n    import tensorflow as tf\n    if not tf.__version__.startswith(\'2.\'):\n        return\n\n    model = Sequential([Dense(1, input_shape=(3,))])\n    model.compile(\'rmsprop\', \'mse\', metrics=[metrics.MeanIoU(2)])\n    x = np.random.random((10, 3))\n    y = np.random.random((10,))\n    model.fit(x, y)\n    model.evaluate(x, y)\n'"
tests/keras/optimizers_test.py,4,"b""from __future__ import print_function\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras.utils import test_utils\nfrom keras import optimizers, Input\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers.core import Dense, Activation, Lambda\nfrom keras.utils.np_utils import to_categorical\nfrom keras import backend as K\nimport tempfile\n\n\nnum_classes = 2\n\n\ndef get_test_data():\n    np.random.seed(1337)\n    (x_train, y_train), _ = test_utils.get_test_data(num_train=1000,\n                                                     num_test=200,\n                                                     input_shape=(10,),\n                                                     classification=True,\n                                                     num_classes=num_classes)\n    y_train = to_categorical(y_train)\n    return x_train, y_train\n\n\ndef _test_optimizer(optimizer, target=0.75):\n    x_train, y_train = get_test_data()\n\n    model = Sequential()\n    model.add(Dense(10, input_shape=(x_train.shape[1],)))\n    model.add(Activation('relu'))\n    model.add(Dense(y_train.shape[1]))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n\n    history = model.fit(x_train, y_train, epochs=3, batch_size=16, verbose=0)\n    assert history.history['accuracy'][-1] >= target\n    config = optimizers.serialize(optimizer)\n    optim = optimizers.deserialize(config)\n    new_config = optimizers.serialize(optim)\n    new_config['class_name'] = new_config['class_name'].lower()\n    assert config == new_config\n\n    # Test constraints.\n    model = Sequential()\n    dense = Dense(10,\n                  input_shape=(x_train.shape[1],),\n                  kernel_constraint=lambda x: 0. * x + 1.,\n                  bias_constraint=lambda x: 0. * x + 2.,)\n    model.add(dense)\n    model.add(Activation('relu'))\n    model.add(Dense(y_train.shape[1]))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n    model.train_on_batch(x_train[:10], y_train[:10])\n    kernel, bias = dense.get_weights()\n    assert_allclose(kernel, 1.)\n    assert_allclose(bias, 2.)\n\n    # Test saving.\n    model = Sequential()\n    model.add(Dense(1, input_dim=1))\n    model.compile(loss='mse', optimizer=optimizer)\n    model.fit(np.zeros((1, 1)), np.zeros((1, 1)))\n\n    _, fname = tempfile.mkstemp('.h5')\n    model.save(fname)\n    model2 = load_model(fname)\n\n    for w1, w2 in zip(model.get_weights(), model2.get_weights()):\n        assert_allclose(w1, w2)\n\n\n@pytest.mark.skipif((K.backend() != 'tensorflow'),\n                    reason='Only Tensorflow raises a '\n                           'ValueError if the gradient is null.')\ndef test_no_grad():\n    inp = Input([3])\n    x = Dense(10)(inp)\n    x = Lambda(\n        lambda l: 1.0 * K.reshape(K.cast(K.argmax(l), 'float32'), [-1, 1]),\n        output_shape=lambda x: [x[0], 1])(x)\n    mod = Model(inp, x)\n    mod.compile('sgd', 'mse')\n    with pytest.raises(ValueError):\n        mod.fit(np.zeros([10, 3]), np.zeros([10, 1], np.float32),\n                batch_size=10, epochs=10)\n\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='Flaky with CNTK')\ndef test_sgd():\n    sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n    _test_optimizer(sgd)\n\n\ndef test_rmsprop():\n    _test_optimizer(optimizers.RMSprop())\n    _test_optimizer(optimizers.RMSprop(decay=1e-3))\n\n\ndef test_adagrad():\n    _test_optimizer(optimizers.Adagrad())\n    _test_optimizer(optimizers.Adagrad(decay=1e-3))\n\n\ndef test_adadelta():\n    _test_optimizer(optimizers.Adadelta(), target=0.6)\n    _test_optimizer(optimizers.Adadelta(decay=1e-3), target=0.6)\n\n\ndef test_adam():\n    _test_optimizer(optimizers.Adam())\n    _test_optimizer(optimizers.Adam(decay=1e-3))\n\n\ndef test_adamax():\n    _test_optimizer(optimizers.Adamax())\n    _test_optimizer(optimizers.Adamax(decay=1e-3))\n\n\ndef test_nadam():\n    _test_optimizer(optimizers.Nadam())\n\n\ndef test_adam_amsgrad():\n    _test_optimizer(optimizers.Adam(amsgrad=True))\n    _test_optimizer(optimizers.Adam(amsgrad=True, decay=1e-3))\n\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='Flaky with CNTK')\ndef test_clipnorm():\n    sgd = optimizers.SGD(lr=0.01, momentum=0.9, clipnorm=0.5)\n    _test_optimizer(sgd)\n\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='Flaky with CNTK')\ndef test_clipvalue():\n    sgd = optimizers.SGD(lr=0.01, momentum=0.9, clipvalue=0.5)\n    _test_optimizer(sgd)\n\n\n@pytest.mark.skipif((K.backend() != 'tensorflow'),\n                    reason='Requires TensorFlow backend')\ndef test_tfoptimizer():\n    from keras import constraints\n    import tensorflow as tf\n    if tf.__version__.startswith('1.'):\n        optimizer = optimizers.TFOptimizer(tf.train.AdamOptimizer())\n    else:\n        optimizer = tf.keras.optimizers.Adam()\n\n    model = Sequential()\n    model.add(Dense(num_classes, input_shape=(3,),\n                    kernel_constraint=constraints.MaxNorm(1)))\n    model.compile(loss='mean_squared_error', optimizer=optimizer)\n    model.fit(np.random.random((5, 3)), np.random.random((5, num_classes)),\n              epochs=1, batch_size=5, verbose=0)\n\n    if tf.__version__.startswith('1.'):\n        with pytest.raises(NotImplementedError):\n            optimizer.weights\n        with pytest.raises(NotImplementedError):\n            optimizer.get_config()\n        with pytest.raises(NotImplementedError):\n            optimizer.from_config(None)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/regularizers_test.py,0,"b""import pytest\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Input, Average\nfrom keras.utils import np_utils\nfrom keras.utils import test_utils\nfrom keras import regularizers\nfrom keras import backend as K\n\ndata_dim = 5\nnum_classes = 2\nbatch_size = 10\n\n\ndef get_data():\n    (x_train, y_train), _ = test_utils.get_test_data(\n        num_train=batch_size,\n        num_test=batch_size,\n        input_shape=(data_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_train = np_utils.to_categorical(y_train, num_classes)\n\n    return x_train, y_train\n\n\ndef create_model(kernel_regularizer=None, activity_regularizer=None):\n    model = Sequential()\n    model.add(Dense(num_classes,\n                    kernel_regularizer=kernel_regularizer,\n                    activity_regularizer=activity_regularizer,\n                    input_shape=(data_dim,)))\n    return model\n\n\ndef create_multi_input_model_from(layer1, layer2):\n    input_1 = Input(shape=(data_dim,))\n    input_2 = Input(shape=(data_dim,))\n    out1 = layer1(input_1)\n    out2 = layer2(input_2)\n    out = Average()([out1, out2])\n    model = Model([input_1, input_2], out)\n    model.add_loss(K.mean(out2))\n    model.add_loss(1)\n    model.add_loss(1)\n    return model\n\n\ndef test_kernel_regularization():\n    x_train, y_train = get_data()\n    for reg in [regularizers.l1(),\n                regularizers.l2(),\n                regularizers.l1_l2()]:\n        model = create_model(kernel_regularizer=reg)\n        model.compile(loss='categorical_crossentropy', optimizer='sgd')\n        assert len(model.losses) == 1\n        model.train_on_batch(x_train, y_train)\n\n\ndef test_activity_regularization():\n    x_train, y_train = get_data()\n    for reg in [regularizers.l1(), regularizers.l2()]:\n        model = create_model(activity_regularizer=reg)\n        model.compile(loss='categorical_crossentropy', optimizer='sgd')\n        assert len(model.losses) == 1\n        model.train_on_batch(x_train, y_train)\n\n\ndef test_regularization_shared_layer():\n    dense_layer = Dense(num_classes,\n                        kernel_regularizer=regularizers.l1(),\n                        activity_regularizer=regularizers.l1())\n\n    model = create_multi_input_model_from(dense_layer, dense_layer)\n    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n    assert len(model.losses) == 6\n\n\ndef test_regularization_shared_model():\n    dense_layer = Dense(num_classes,\n                        kernel_regularizer=regularizers.l1(),\n                        activity_regularizer=regularizers.l1())\n\n    input_tensor = Input(shape=(data_dim,))\n    dummy_model = Model(input_tensor, dense_layer(input_tensor))\n\n    model = create_multi_input_model_from(dummy_model, dummy_model)\n    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n    assert len(model.losses) == 6\n\n\ndef test_regularization_shared_layer_in_different_models():\n    shared_dense = Dense(num_classes,\n                         kernel_regularizer=regularizers.l1(),\n                         activity_regularizer=regularizers.l1())\n    models = []\n    for _ in range(2):\n        input_tensor = Input(shape=(data_dim,))\n        unshared_dense = Dense(num_classes, kernel_regularizer=regularizers.l1())\n        out = unshared_dense(shared_dense(input_tensor))\n        models.append(Model(input_tensor, out))\n\n    model = create_multi_input_model_from(*models)\n    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n    assert len(model.losses) == 8\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/test_sequential_model.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\nimport pytest\nimport os\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras import backend as K\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.utils import np_utils\nfrom keras.utils.test_utils import get_test_data\nfrom keras.models import model_from_json, model_from_yaml\nfrom keras import losses\nfrom keras.engine.training_utils import make_batches\n\n\ninput_dim = 16\nnum_hidden = 8\nnum_classes = 4\nbatch_size = 32\nepochs = 1\n\n\n@pytest.fixture\ndef in_tmpdir(tmpdir):\n    """"""Runs a function in a temporary directory.\n\n    Checks that the directory is empty afterwards.\n    """"""\n    with tmpdir.as_cwd():\n        yield None\n    assert not tmpdir.listdir()\n\n\ndef test_sequential_pop():\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim))\n    model.add(Dense(num_classes))\n    model.compile(loss=\'mse\', optimizer=\'sgd\')\n    x = np.random.random((batch_size, input_dim))\n    y = np.random.random((batch_size, num_classes))\n    model.fit(x, y, epochs=1)\n    model.pop()\n    assert len(model.layers) == 1\n    assert model.output_shape == (None, num_hidden)\n    model.compile(loss=\'mse\', optimizer=\'sgd\')\n    y = np.random.random((batch_size, num_hidden))\n    model.fit(x, y, epochs=1)\n\n\ndef _get_test_data():\n    np.random.seed(1234)\n\n    train_samples = 100\n    test_samples = 50\n\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    return (x_train, y_train), (x_test, y_test)\n\n\ndef test_sequential_fit_generator():\n    (x_train, y_train), (x_test, y_test) = _get_test_data()\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(x_train) // batch_size\n        else:\n            max_batch_index = len(x_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                yield (x_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (x_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_shape=(input_dim,)))\n    model.add(Activation(\'relu\'))\n    model.add(Dense(num_classes))\n    model.pop()\n    model.add(Dense(num_classes))\n    model.add(Activation(\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\')\n\n    model.fit_generator(data_generator(True), 5, epochs)\n    model.fit_generator(data_generator(True), 5, epochs,\n                        validation_data=(x_test, y_test))\n    model.fit_generator(data_generator(True), 5, epochs,\n                        validation_data=data_generator(False),\n                        validation_steps=3)\n    model.fit_generator(data_generator(True), 5, epochs, max_queue_size=2)\n    model.evaluate(x_train, y_train)\n\n\ndef test_sequential(in_tmpdir):\n    (x_train, y_train), (x_test, y_test) = _get_test_data()\n\n    # TODO: factor out\n    def data_generator(x, y, batch_size=50):\n        index_array = np.arange(len(x))\n        while 1:\n            batches = make_batches(len(x_test), batch_size)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                x_batch = x[batch_ids]\n                y_batch = y[batch_ids]\n                yield (x_batch, y_batch)\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_shape=(input_dim,)))\n    model.add(Activation(\'relu\'))\n    model.add(Dense(num_classes))\n    model.add(Activation(\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\')\n\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n              validation_data=(x_test, y_test))\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2,\n              validation_split=0.1)\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n              shuffle=False)\n\n    model.train_on_batch(x_train[:32], y_train[:32])\n\n    loss_np = model.evaluate(x_test, y_test)\n    predict_np = model.predict(x_test)\n\n    generator_pred_np = model.predict_generator(\n        data_generator(x_test, y_test), 1,\n        max_queue_size=2, verbose=1)\n    generator_loss_np = model.evaluate_generator(\n        data_generator(x_test, y_test, 50), 1,\n        max_queue_size=2)\n\n    assert_allclose(loss_np, generator_loss_np, atol=1e-5)\n    assert_allclose(predict_np, generator_pred_np, atol=1e-5)\n\n    model.predict(x_test, verbose=0)\n    model.predict_classes(x_test, verbose=0)\n    model.predict_proba(x_test, verbose=0)\n\n    fname = \'test_sequential_temp.h5\'\n    model.save_weights(fname, overwrite=True)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_shape=(input_dim,)))\n    model.add(Activation(\'relu\'))\n    model.add(Dense(num_classes))\n    model.add(Activation(\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\')\n    model.load_weights(fname)\n    os.remove(fname)\n\n    nloss = model.evaluate(x_test, y_test, verbose=0)\n    assert(loss_np == nloss)\n\n    # Test serialization\n    config = model.get_config()\n    assert \'name\' in config\n    new_model = Sequential.from_config(config)\n    assert new_model.weights  # Model should be built.\n\n    model.summary()\n    json_str = model.to_json()\n    model_from_json(json_str)\n\n    yaml_str = model.to_yaml()\n    model_from_yaml(yaml_str)\n\n\ndef test_nested_sequential(in_tmpdir):\n    (x_train, y_train), (x_test, y_test) = _get_test_data()\n\n    inner = Sequential()\n    inner.add(Dense(num_hidden, input_shape=(input_dim,)))\n    inner.add(Activation(\'relu\'))\n    inner.add(Dense(num_classes))\n\n    middle = Sequential()\n    middle.add(inner)\n\n    model = Sequential()\n    model.add(middle)\n    model.add(Activation(\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\')\n\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n              validation_data=(x_test, y_test))\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2,\n              validation_split=0.1)\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n              shuffle=False)\n\n    model.train_on_batch(x_train[:32], y_train[:32])\n\n    loss = model.evaluate(x_test, y_test, verbose=0)\n\n    model.predict(x_test, verbose=0)\n    model.predict_classes(x_test, verbose=0)\n    model.predict_proba(x_test, verbose=0)\n\n    fname = \'test_nested_sequential_temp.h5\'\n    model.save_weights(fname, overwrite=True)\n\n    inner = Sequential()\n    inner.add(Dense(num_hidden, input_shape=(input_dim,)))\n    inner.add(Activation(\'relu\'))\n    inner.add(Dense(num_classes))\n\n    middle = Sequential()\n    middle.add(inner)\n\n    model = Sequential()\n    model.add(middle)\n    model.add(Activation(\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\')\n    model.load_weights(fname)\n    os.remove(fname)\n\n    nloss = model.evaluate(x_test, y_test, verbose=0)\n    assert(loss == nloss)\n\n    # Test serialization\n    config = model.get_config()\n    Sequential.from_config(config)\n\n    model.summary()\n    json_str = model.to_json()\n    model_from_json(json_str)\n\n    yaml_str = model.to_yaml()\n    model_from_yaml(yaml_str)\n\n\ndef test_sequential_count_params():\n    input_dim = 20\n    num_units = 10\n    num_classes = 2\n\n    n = input_dim * num_units + num_units\n    n += num_units * num_units + num_units\n    n += num_units * num_classes + num_classes\n\n    model = Sequential()\n    model.add(Dense(num_units, input_shape=(input_dim,)))\n    model.add(Dense(num_units))\n    model.add(Dense(num_classes))\n    model.add(Activation(\'softmax\'))\n    model.build()\n\n    assert(n == model.count_params())\n\n    model.compile(\'sgd\', \'binary_crossentropy\')\n    assert(n == model.count_params())\n\n\ndef test_nested_sequential_trainability():\n    input_dim = 20\n    num_units = 10\n    num_classes = 2\n\n    inner_model = Sequential()\n    inner_model.add(Dense(num_units, input_shape=(input_dim,)))\n\n    model = Sequential()\n    model.add(inner_model)\n    model.add(Dense(num_classes))\n\n    assert len(model.trainable_weights) == 4\n    inner_model.trainable = False\n    assert len(model.trainable_weights) == 2\n    inner_model.trainable = True\n    assert len(model.trainable_weights) == 4\n\n\ndef test_rebuild_model():\n    model = Sequential()\n    model.add(Dense(128, input_shape=(784,)))\n    model.add(Dense(64))\n    assert(model.get_layer(index=-1).output_shape == (None, 64))\n\n    model.add(Dense(32))\n    assert(model.get_layer(index=-1).output_shape == (None, 32))\n\n\ndef test_clone_functional_model():\n    val_a = np.random.random((10, 4))\n    val_b = np.random.random((10, 4))\n    val_out = np.random.random((10, 4))\n\n    input_a = keras.Input(shape=(4,))\n    input_b = keras.Input(shape=(4,))\n    dense_1 = keras.layers.Dense(4)\n    dense_2 = keras.layers.Dense(4)\n\n    x_a = dense_1(input_a)\n    x_a = keras.layers.Dropout(0.5)(x_a)\n    x_a = keras.layers.BatchNormalization()(x_a)\n    x_b = dense_1(input_b)\n    x_a = dense_2(x_a)\n    outputs = keras.layers.add([x_a, x_b])\n    model = keras.models.Model([input_a, input_b], outputs)\n\n    if K.backend() == \'tensorflow\':\n        # Everything should work in a new session.\n        K.clear_session()\n\n    # With placeholder creation\n    new_model = keras.models.clone_model(model)\n    new_model.compile(\'rmsprop\', \'mse\')\n    new_model.train_on_batch([val_a, val_b], val_out)\n\n    # On top of new tensors\n    input_a = keras.Input(shape=(4,), name=\'a\')\n    input_b = keras.Input(shape=(4,), name=\'b\')\n    new_model = keras.models.clone_model(\n        model, input_tensors=[input_a, input_b])\n    new_model.compile(\'rmsprop\', \'mse\')\n    new_model.train_on_batch([val_a, val_b], val_out)\n\n    # On top of new, non-Keras tensors\n    input_a = keras.backend.variable(val_a)\n    input_b = keras.backend.variable(val_b)\n    new_model = keras.models.clone_model(\n        model, input_tensors=[input_a, input_b])\n    new_model.compile(\'rmsprop\', \'mse\')\n    new_model.train_on_batch(None, val_out)\n\n\ndef test_clone_functional_model_with_multi_outputs():\n    input_layer = keras.Input(shape=(4,))\n\n    # Layer with single input and multiple outputs\n    layer1 = keras.layers.Lambda(lambda x: [x + 1, x],\n                                 lambda shapes: [shapes, shapes])\n    x_a, x_b = layer1(input_layer)\n\n    class SwapLayer(keras.layers.Layer):\n        def call(self, inputs, **kwargs):\n            return [inputs[1], inputs[0]]\n\n        def compute_output_shape(self, input_shape):\n            return [input_shape[1], input_shape[0]]\n\n    # Layer with multiple inputs and outputs\n    x_a, x_b = SwapLayer()([x_a, x_b])\n    model = keras.Model(inputs=[input_layer], outputs=[x_a, x_b])\n    new_model = keras.models.clone_model(model)\n\n    x_test = np.random.random((10, 4))\n    pred_a, pred_b = model.predict(x_test)\n    pred_new_a, pred_new_b = new_model.predict(x_test)\n    assert(pred_a.all() == pred_new_a.all())\n    assert(pred_b.all() == pred_new_b.all())\n\n\ndef test_clone_sequential_model():\n    val_a = np.random.random((10, 4))\n    val_out = np.random.random((10, 4))\n\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(4, input_shape=(4,)))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dense(4))\n\n    if K.backend() == \'tensorflow\':\n        # Everything should work in a new session.\n        K.clear_session()\n\n    # With placeholder creation\n    new_model = keras.models.clone_model(model)\n    new_model.compile(\'rmsprop\', \'mse\')\n    new_model.train_on_batch(val_a, val_out)\n\n    # On top of new tensor\n    input_a = keras.Input(shape=(4,))\n    new_model = keras.models.clone_model(\n        model, input_tensors=input_a)\n    new_model.compile(\'rmsprop\', \'mse\')\n    new_model.train_on_batch(val_a, val_out)\n\n    # On top of new, non-Keras tensor\n    input_a = keras.backend.variable(val_a)\n    new_model = keras.models.clone_model(\n        model, input_tensors=input_a)\n    new_model.compile(\'rmsprop\', \'mse\')\n    new_model.train_on_batch(None, val_out)\n\n\ndef test_sequential_update_disabling():\n    val_a = np.random.random((10, 4))\n    val_out = np.random.random((10, 4))\n\n    model = keras.models.Sequential()\n    model.add(keras.layers.BatchNormalization(input_shape=(4,)))\n\n    model.trainable = False\n    assert not model.updates\n\n    model.compile(\'sgd\', \'mse\')\n    assert not model.updates\n\n    x1 = model.predict(val_a)\n    model.train_on_batch(val_a, val_out)\n    x2 = model.predict(val_a)\n    assert_allclose(x1, x2, atol=1e-7)\n\n    model.trainable = True\n    model.compile(\'sgd\', \'mse\')\n    assert model.updates\n\n    model.train_on_batch(val_a, val_out)\n    x2 = model.predict(val_a)\n    assert np.abs(np.sum(x1 - x2)) > 1e-5\n\n\ndef test_sequential_deferred_build():\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(3))\n    model.add(keras.layers.Dense(3))\n    model.compile(\'sgd\', \'mse\')\n\n    assert model.built is False\n    assert len(model.layers) == 2\n    assert len(model.weights) == 0\n\n    model.train_on_batch(\n        np.random.random((2, 4)), np.random.random((2, 3)))\n\n    assert model.built is True\n    assert len(model.layers) == 2\n    assert len(model.weights) == 4\n\n    # Test serialization\n    config = model.get_config()\n    assert \'name\' in config\n    new_model = Sequential.from_config(config)\n    assert new_model.built is True\n    assert len(new_model.layers) == 2\n    assert len(new_model.weights) == 4\n\n\ndef test_nested_sequential_deferred_build():\n    inner_model = keras.models.Sequential()\n    inner_model.add(keras.layers.Dense(3))\n    inner_model.add(keras.layers.Dense(3))\n\n    model = keras.models.Sequential()\n    model.add(inner_model)\n    model.add(keras.layers.Dense(5))\n    model.compile(\'sgd\', \'mse\')\n\n    assert inner_model.built is False\n    assert len(inner_model.layers) == 2\n    assert len(inner_model.weights) == 0\n    assert model.built is False\n    assert len(model.layers) == 2\n    assert len(model.weights) == 0\n\n    model.train_on_batch(\n        np.random.random((2, 4)), np.random.random((2, 5)))\n\n    assert inner_model.built is True\n    assert len(inner_model.layers) == 2\n    assert len(inner_model.weights) == 4\n    assert model.built is True\n    assert len(model.layers) == 2\n    assert len(model.weights) == 6\n\n    config = model.get_config()\n    new_model = keras.models.Sequential.from_config(config)\n    assert new_model.built is True\n    assert len(new_model.layers) == 2\n    assert len(new_model.weights) == 6\n\n    new_inner_model = new_model.layers[0]\n    assert new_inner_model.built is True\n    assert len(new_inner_model.layers) == 2\n    assert len(new_inner_model.weights) == 4\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/integration_tests/preprocessing/image_test.py,0,"b'import pytest\nfrom keras.preprocessing import image\nfrom PIL import Image\nimport numpy as np\nimport os\nimport tempfile\nimport shutil\n\n\nclass TestImage(object):\n\n    def setup_class(cls):\n        cls.img_w = cls.img_h = 20\n        rgb_images = []\n        gray_images = []\n        for n in range(8):\n            bias = np.random.rand(cls.img_w, cls.img_h, 1) * 64\n            variance = np.random.rand(cls.img_w, cls.img_h, 1) * (255 - 64)\n            imarray = np.random.rand(cls.img_w, cls.img_h, 3) * variance + bias\n            im = Image.fromarray(imarray.astype(\'uint8\')).convert(\'RGB\')\n            rgb_images.append(im)\n\n            imarray = np.random.rand(cls.img_w, cls.img_h, 1) * variance + bias\n            im = Image.fromarray(imarray.astype(\'uint8\').squeeze()).convert(\'L\')\n            gray_images.append(im)\n\n        cls.all_test_images = [rgb_images, gray_images]\n\n    def teardown_class(cls):\n        del cls.all_test_images\n\n    def test_image_data_generator(self, tmpdir):\n        for test_images in self.all_test_images:\n            img_list = []\n            for im in test_images:\n                img_list.append(image.img_to_array(im)[None, ...])\n\n            images = np.vstack(img_list)\n            generator = image.ImageDataGenerator(\n                featurewise_center=True,\n                samplewise_center=True,\n                featurewise_std_normalization=True,\n                samplewise_std_normalization=True,\n                zca_whitening=True,\n                rotation_range=90.,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                shear_range=0.5,\n                zoom_range=0.2,\n                channel_shift_range=0.,\n                brightness_range=(1, 5),\n                fill_mode=\'nearest\',\n                cval=0.5,\n                horizontal_flip=True,\n                vertical_flip=True)\n            generator.fit(images, augment=True)\n\n            num_samples = images.shape[0]\n            for x, y in generator.flow(images, np.arange(num_samples),\n                                       shuffle=False, save_to_dir=str(tmpdir),\n                                       batch_size=3):\n                assert x.shape == images[:3].shape\n                assert list(y) == [0, 1, 2]\n                break\n\n            # Test with sample weights\n            for x, y, w in generator.flow(images, np.arange(num_samples),\n                                          shuffle=False,\n                                          sample_weight=np.arange(num_samples) + 1,\n                                          save_to_dir=str(tmpdir),\n                                          batch_size=3):\n                assert x.shape == images[:3].shape\n                assert list(y) == [0, 1, 2]\n                assert list(w) == [1, 2, 3]\n                break\n\n            # Test with `shuffle=True`\n            for x, y in generator.flow(images, np.arange(num_samples),\n                                       shuffle=True, save_to_dir=str(tmpdir),\n                                       batch_size=3):\n                assert x.shape == images[:3].shape\n                # Check that the sequence is shuffled.\n                assert list(y) != [0, 1, 2]\n                break\n\n            # Test without y\n            for x in generator.flow(images, None,\n                                    shuffle=True, save_to_dir=str(tmpdir),\n                                    batch_size=3):\n                assert type(x) is np.ndarray\n                assert x.shape == images[:3].shape\n                # Check that the sequence is shuffled.\n                break\n\n            # Test with a single miscellaneous input data array\n            dsize = images.shape[0]\n            x_misc1 = np.random.random(dsize)\n\n            for i, (x, y) in enumerate(generator.flow((images, x_misc1),\n                                                      np.arange(dsize),\n                                                      shuffle=False, batch_size=2)):\n                assert x[0].shape == images[:2].shape\n                assert (x[1] == x_misc1[(i * 2):((i + 1) * 2)]).all()\n                if i == 2:\n                    break\n\n            # Test with two miscellaneous inputs\n            x_misc2 = np.random.random((dsize, 3, 3))\n\n            for i, (x, y) in enumerate(generator.flow((images, [x_misc1, x_misc2]),\n                                                      np.arange(dsize),\n                                                      shuffle=False, batch_size=2)):\n                assert x[0].shape == images[:2].shape\n                assert (x[1] == x_misc1[(i * 2):((i + 1) * 2)]).all()\n                assert (x[2] == x_misc2[(i * 2):((i + 1) * 2)]).all()\n                if i == 2:\n                    break\n\n            # Test cases with `y = None`\n            x = generator.flow(images, None, batch_size=3).next()\n            assert type(x) is np.ndarray\n            assert x.shape == images[:3].shape\n            x = generator.flow((images, x_misc1), None,\n                               batch_size=3, shuffle=False).next()\n            assert type(x) is list\n            assert x[0].shape == images[:3].shape\n            assert (x[1] == x_misc1[:3]).all()\n            x = generator.flow((images, [x_misc1, x_misc2]), None,\n                               batch_size=3, shuffle=False).next()\n            assert type(x) is list\n            assert x[0].shape == images[:3].shape\n            assert (x[1] == x_misc1[:3]).all()\n            assert (x[2] == x_misc2[:3]).all()\n\n            # Test some failure cases:\n            x_misc_err = np.random.random((dsize + 1, 3, 3))\n\n            with pytest.raises(ValueError) as e_info:\n                generator.flow((images, x_misc_err), np.arange(dsize), batch_size=3)\n            assert \'All of the arrays in\' in str(e_info.value)\n\n            with pytest.raises(ValueError) as e_info:\n                generator.flow((images, x_misc1),\n                               np.arange(dsize + 1),\n                               batch_size=3)\n            assert \'`x` (images tensor) and `y` (labels) \' in str(e_info.value)\n\n            # Test `flow` behavior as Sequence\n            seq = generator.flow(images, np.arange(images.shape[0]),\n                                 shuffle=False, save_to_dir=str(tmpdir),\n                                 batch_size=3)\n            assert len(seq) == images.shape[0] // 3 + 1\n            x, y = seq[0]\n            assert x.shape == images[:3].shape\n            assert list(y) == [0, 1, 2]\n\n            # Test with `shuffle=True`\n            seq = generator.flow(images, np.arange(images.shape[0]),\n                                 shuffle=True, save_to_dir=str(tmpdir),\n                                 batch_size=3, seed=123)\n            x, y = seq[0]\n            # Check that the sequence is shuffled.\n            assert list(y) != [0, 1, 2]\n\n            # `on_epoch_end` should reshuffle the sequence.\n            seq.on_epoch_end()\n            x2, y2 = seq[0]\n            assert list(y) != list(y2)\n\n    def test_image_data_generator_with_split_value_error(self):\n        with pytest.raises(ValueError):\n            generator = image.ImageDataGenerator(validation_split=5)\n\n    def test_image_data_generator_invalid_data(self):\n        generator = image.ImageDataGenerator(\n            featurewise_center=True,\n            samplewise_center=True,\n            featurewise_std_normalization=True,\n            samplewise_std_normalization=True,\n            zca_whitening=True,\n            data_format=\'channels_last\')\n        # Test fit with invalid data\n        with pytest.raises(ValueError):\n            x = np.random.random((3, 10, 10))\n            generator.fit(x)\n\n        # Test flow with invalid data\n        with pytest.raises(ValueError):\n            x = np.random.random((32, 10, 10))\n            generator.flow(np.arange(x.shape[0]))\n\n    def test_image_data_generator_fit(self):\n        generator = image.ImageDataGenerator(\n            featurewise_center=True,\n            samplewise_center=True,\n            featurewise_std_normalization=True,\n            samplewise_std_normalization=True,\n            zca_whitening=True,\n            zoom_range=(0.2, 0.2),\n            data_format=\'channels_last\')\n        # Test grayscale\n        x = np.random.random((32, 10, 10, 1))\n        generator.fit(x)\n        # Test RBG\n        x = np.random.random((32, 10, 10, 3))\n        generator.fit(x)\n        # Test more samples than dims\n        x = np.random.random((32, 4, 4, 1))\n        generator.fit(x)\n        generator = image.ImageDataGenerator(\n            featurewise_center=True,\n            samplewise_center=True,\n            featurewise_std_normalization=True,\n            samplewise_std_normalization=True,\n            zca_whitening=True,\n            data_format=\'channels_first\')\n        # Test grayscale\n        x = np.random.random((32, 1, 10, 10))\n        generator.fit(x)\n        # Test RBG\n        x = np.random.random((32, 3, 10, 10))\n        generator.fit(x)\n        # Test more samples than dims\n        x = np.random.random((32, 1, 4, 4))\n        generator.fit(x)\n\n    def test_directory_iterator(self, tmpdir):\n        num_classes = 2\n\n        # create folders and subfolders\n        paths = []\n        for cl in range(num_classes):\n            class_directory = \'class-{}\'.format(cl)\n            classpaths = [\n                class_directory,\n                os.path.join(class_directory, \'subfolder-1\'),\n                os.path.join(class_directory, \'subfolder-2\'),\n                os.path.join(class_directory, \'subfolder-1\', \'sub-subfolder\')\n            ]\n            for path in classpaths:\n                tmpdir.join(path).mkdir()\n            paths.append(classpaths)\n\n        # save the images in the paths\n        count = 0\n        filenames = []\n        for test_images in self.all_test_images:\n            for im in test_images:\n                # rotate image class\n                im_class = count % num_classes\n                # rotate subfolders\n                classpaths = paths[im_class]\n                filename = os.path.join(classpaths[count % len(classpaths)],\n                                        \'image-{}.jpg\'.format(count))\n                filenames.append(filename)\n                im.save(str(tmpdir / filename))\n                count += 1\n\n        # create iterator\n        generator = image.ImageDataGenerator()\n        dir_iterator = generator.flow_from_directory(str(tmpdir))\n\n        # check number of classes and images\n        assert len(dir_iterator.class_indices) == num_classes\n        assert len(dir_iterator.classes) == count\n        assert set(dir_iterator.filenames) == set(filenames)\n\n        # Test invalid use cases\n        with pytest.raises(ValueError):\n            generator.flow_from_directory(str(tmpdir), color_mode=\'cmyk\')\n        with pytest.raises(ValueError):\n            generator.flow_from_directory(str(tmpdir), class_mode=\'output\')\n\n        def preprocessing_function(x):\n            """"""This will fail if not provided by a Numpy array.\n            Note: This is made to enforce backward compatibility.\n            """"""\n\n            assert x.shape == (26, 26, 3)\n            assert type(x) is np.ndarray\n\n            return np.zeros_like(x)\n\n        # Test usage as Sequence\n        generator = image.ImageDataGenerator(\n            preprocessing_function=preprocessing_function)\n        dir_seq = generator.flow_from_directory(str(tmpdir),\n                                                target_size=(26, 26),\n                                                color_mode=\'rgb\',\n                                                batch_size=3,\n                                                class_mode=\'categorical\')\n        assert len(dir_seq) == count // 3 + 1\n        x1, y1 = dir_seq[1]\n        assert x1.shape == (3, 26, 26, 3)\n        assert y1.shape == (3, num_classes)\n        x1, y1 = dir_seq[5]\n        assert (x1 == 0).all()\n\n        with pytest.raises(ValueError):\n            x1, y1 = dir_seq[9]\n\n    def test_directory_iterator_class_mode_input(self, tmpdir):\n        tmpdir.join(\'class-1\').mkdir()\n\n        # save the images in the paths\n        count = 0\n        for test_images in self.all_test_images:\n            for im in test_images:\n                filename = str(tmpdir / \'class-1\' / \'image-{}.jpg\'.format(count))\n                im.save(filename)\n                count += 1\n\n        # create iterator\n        generator = image.ImageDataGenerator()\n        dir_iterator = generator.flow_from_directory(str(tmpdir),\n                                                     class_mode=\'input\')\n        batch = next(dir_iterator)\n\n        # check if input and output have the same shape\n        assert(batch[0].shape == batch[1].shape)\n        # check if the input and output images are not the same numpy array\n        input_img = batch[0][0]\n        output_img = batch[1][0]\n        output_img[0][0][0] += 1\n        assert(input_img[0][0][0] != output_img[0][0][0])\n\n    @pytest.mark.parametrize(\'validation_split,num_training\', [\n        (0.25, 12),\n        (0.40, 10),\n        (0.50, 8),\n    ])\n    def test_directory_iterator_with_validation_split(self, validation_split,\n                                                      num_training):\n        num_classes = 2\n        tmp_folder = tempfile.mkdtemp(prefix=\'test_images\')\n\n        # create folders and subfolders\n        paths = []\n        for cl in range(num_classes):\n            class_directory = \'class-{}\'.format(cl)\n            classpaths = [\n                class_directory,\n                os.path.join(class_directory, \'subfolder-1\'),\n                os.path.join(class_directory, \'subfolder-2\'),\n                os.path.join(class_directory, \'subfolder-1\', \'sub-subfolder\')\n            ]\n            for path in classpaths:\n                os.mkdir(os.path.join(tmp_folder, path))\n            paths.append(classpaths)\n\n        # save the images in the paths\n        count = 0\n        filenames = []\n        for test_images in self.all_test_images:\n            for im in test_images:\n                # rotate image class\n                im_class = count % num_classes\n                # rotate subfolders\n                classpaths = paths[im_class]\n                filename = os.path.join(classpaths[count % len(classpaths)],\n                                        \'image-{}.jpg\'.format(count))\n                filenames.append(filename)\n                im.save(os.path.join(tmp_folder, filename))\n                count += 1\n\n        # create iterator\n        generator = image.ImageDataGenerator(validation_split=validation_split)\n\n        with pytest.raises(ValueError):\n            generator.flow_from_directory(tmp_folder, subset=\'foo\')\n\n        train_iterator = generator.flow_from_directory(tmp_folder,\n                                                       subset=\'training\')\n        assert train_iterator.samples == num_training\n\n        valid_iterator = generator.flow_from_directory(tmp_folder,\n                                                       subset=\'validation\')\n        assert valid_iterator.samples == count - num_training\n\n        # check number of classes and images\n        assert len(train_iterator.class_indices) == num_classes\n        assert len(train_iterator.classes) == num_training\n        assert len(set(train_iterator.filenames) & set(filenames)) == num_training\n\n        shutil.rmtree(tmp_folder)\n\n    def test_img_utils(self):\n        height, width = 10, 8\n\n        # Test th data format\n        x = np.random.random((3, height, width))\n        img = image.array_to_img(x, data_format=\'channels_first\')\n        assert img.size == (width, height)\n        x = image.img_to_array(img, data_format=\'channels_first\')\n        assert x.shape == (3, height, width)\n        # Test 2D\n        x = np.random.random((1, height, width))\n        img = image.array_to_img(x, data_format=\'channels_first\')\n        assert img.size == (width, height)\n        x = image.img_to_array(img, data_format=\'channels_first\')\n        assert x.shape == (1, height, width)\n\n        # Test tf data format\n        x = np.random.random((height, width, 3))\n        img = image.array_to_img(x, data_format=\'channels_last\')\n        assert img.size == (width, height)\n        x = image.img_to_array(img, data_format=\'channels_last\')\n        assert x.shape == (height, width, 3)\n        # Test 2D\n        x = np.random.random((height, width, 1))\n        img = image.array_to_img(x, data_format=\'channels_last\')\n        assert img.size == (width, height)\n        x = image.img_to_array(img, data_format=\'channels_last\')\n        assert x.shape == (height, width, 1)\n\n        # Test invalid use case\n        with pytest.raises(ValueError):\n            x = np.random.random((height, width))  # not 3D\n            img = image.array_to_img(x, data_format=\'channels_first\')\n        with pytest.raises(ValueError):  # unknown data_format\n            x = np.random.random((height, width, 3))\n            img = image.array_to_img(x, data_format=\'channels\')\n        with pytest.raises(ValueError):  # neither RGB nor gray-scale\n            x = np.random.random((height, width, 5))\n            img = image.array_to_img(x, data_format=\'channels_last\')\n        with pytest.raises(ValueError):  # unknown data_format\n            x = np.random.random((height, width, 3))\n            img = image.img_to_array(x, data_format=\'channels\')\n        with pytest.raises(ValueError):  # neither RGB nor gray-scale\n            x = np.random.random((height, width, 5, 3))\n            img = image.img_to_array(x, data_format=\'channels_last\')\n\n    def test_random_transforms(self):\n        x = np.random.random((2, 28, 28))\n        assert image.random_rotation(x, 45).shape == (2, 28, 28)\n        assert image.random_shift(x, 1, 1).shape == (2, 28, 28)\n        assert image.random_shear(x, 20).shape == (2, 28, 28)\n        assert image.random_zoom(x, (5, 5)).shape == (2, 28, 28)\n        assert image.random_channel_shift(x, 20).shape == (2, 28, 28)\n\n        # Test get_random_transform with predefined seed\n        seed = 1\n        generator = image.ImageDataGenerator(\n            rotation_range=90.,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            shear_range=0.5,\n            zoom_range=0.2,\n            channel_shift_range=0.1,\n            brightness_range=(1, 5),\n            horizontal_flip=True,\n            vertical_flip=True)\n        transform_dict = generator.get_random_transform(x.shape, seed)\n        transform_dict2 = generator.get_random_transform(x.shape, seed * 2)\n        assert transform_dict[\'theta\'] != 0\n        assert transform_dict[\'theta\'] != transform_dict2[\'theta\']\n        assert transform_dict[\'tx\'] != 0\n        assert transform_dict[\'tx\'] != transform_dict2[\'tx\']\n        assert transform_dict[\'ty\'] != 0\n        assert transform_dict[\'ty\'] != transform_dict2[\'ty\']\n        assert transform_dict[\'shear\'] != 0\n        assert transform_dict[\'shear\'] != transform_dict2[\'shear\']\n        assert transform_dict[\'zx\'] != 0\n        assert transform_dict[\'zx\'] != transform_dict2[\'zx\']\n        assert transform_dict[\'zy\'] != 0\n        assert transform_dict[\'zy\'] != transform_dict2[\'zy\']\n        assert transform_dict[\'channel_shift_intensity\'] != 0\n        assert (transform_dict[\'channel_shift_intensity\'] !=\n                transform_dict2[\'channel_shift_intensity\'])\n        assert transform_dict[\'brightness\'] != 0\n        assert transform_dict[\'brightness\'] != transform_dict2[\'brightness\']\n\n        # Test get_random_transform without any randomness\n        generator = image.ImageDataGenerator()\n        transform_dict = generator.get_random_transform(x.shape, seed)\n        assert transform_dict[\'theta\'] == 0\n        assert transform_dict[\'tx\'] == 0\n        assert transform_dict[\'ty\'] == 0\n        assert transform_dict[\'shear\'] == 0\n        assert transform_dict[\'zx\'] == 1\n        assert transform_dict[\'zy\'] == 1\n        assert transform_dict[\'channel_shift_intensity\'] is None\n        assert transform_dict[\'brightness\'] is None\n\n    def test_deterministic_transform(self):\n        x = np.ones((32, 32, 3))\n        generator = image.ImageDataGenerator(\n            rotation_range=90,\n            fill_mode=\'constant\')\n        x = np.random.random((32, 32, 3))\n        assert np.allclose(generator.apply_transform(x, {\'flip_vertical\': True}),\n                           x[::-1, :, :])\n        assert np.allclose(generator.apply_transform(x, {\'flip_horizontal\': True}),\n                           x[:, ::-1, :])\n        x = np.ones((3, 3, 3))\n        x_rotated = np.array([[[0., 0., 0.],\n                               [0., 0., 0.],\n                               [1., 1., 1.]],\n                              [[0., 0., 0.],\n                               [1., 1., 1.],\n                               [1., 1., 1.]],\n                              [[0., 0., 0.],\n                               [0., 0., 0.],\n                               [1., 1., 1.]]])\n        assert np.allclose(generator.apply_transform(x, {\'theta\': 45}),\n                           x_rotated)\n        assert np.allclose(image.apply_affine_transform(\n            x, theta=45, channel_axis=2, fill_mode=\'constant\'), x_rotated)\n\n    def test_batch_standardize(self):\n        # ImageDataGenerator.standardize should work on batches\n        for test_images in self.all_test_images:\n            img_list = []\n            for im in test_images:\n                img_list.append(image.img_to_array(im)[None, ...])\n\n            images = np.vstack(img_list)\n            generator = image.ImageDataGenerator(\n                featurewise_center=True,\n                samplewise_center=True,\n                featurewise_std_normalization=True,\n                samplewise_std_normalization=True,\n                zca_whitening=True,\n                rotation_range=90.,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                shear_range=0.5,\n                zoom_range=0.2,\n                channel_shift_range=0.,\n                brightness_range=(1, 5),\n                fill_mode=\'nearest\',\n                cval=0.5,\n                horizontal_flip=True,\n                vertical_flip=True)\n            generator.fit(images, augment=True)\n\n            transformed = np.copy(images)\n            for i, im in enumerate(transformed):\n                transformed[i] = generator.random_transform(im)\n            transformed = generator.standardize(transformed)\n\n    def test_load_img(self, tmpdir):\n        filename = str(tmpdir / \'image.png\')\n\n        original_im_array = np.array(255 * np.random.rand(100, 100, 3),\n                                     dtype=np.uint8)\n        original_im = image.array_to_img(original_im_array, scale=False)\n        original_im.save(filename)\n\n        # Test that loaded image is exactly equal to original.\n\n        loaded_im = image.load_img(filename)\n        loaded_im_array = image.img_to_array(loaded_im)\n        assert loaded_im_array.shape == original_im_array.shape\n        assert np.all(loaded_im_array == original_im_array)\n\n        loaded_im = image.load_img(filename, grayscale=True)\n        loaded_im_array = image.img_to_array(loaded_im)\n        assert loaded_im_array.shape == (original_im_array.shape[0],\n                                         original_im_array.shape[1], 1)\n\n        # Test that nothing is changed when target size is equal to original.\n\n        loaded_im = image.load_img(filename, target_size=(100, 100))\n        loaded_im_array = image.img_to_array(loaded_im)\n        assert loaded_im_array.shape == original_im_array.shape\n        assert np.all(loaded_im_array == original_im_array)\n\n        loaded_im = image.load_img(filename, grayscale=True,\n                                   target_size=(100, 100))\n        loaded_im_array = image.img_to_array(loaded_im)\n        assert loaded_im_array.shape == (original_im_array.shape[0],\n                                         original_im_array.shape[1], 1)\n\n        # Test down-sampling with bilinear interpolation.\n\n        loaded_im = image.load_img(filename, target_size=(25, 25))\n        loaded_im_array = image.img_to_array(loaded_im)\n        assert loaded_im_array.shape == (25, 25, 3)\n\n        loaded_im = image.load_img(filename, grayscale=True,\n                                   target_size=(25, 25))\n        loaded_im_array = image.img_to_array(loaded_im)\n        assert loaded_im_array.shape == (25, 25, 1)\n\n        # Test down-sampling with nearest neighbor interpolation.\n\n        loaded_im_nearest = image.load_img(filename, target_size=(25, 25),\n                                           interpolation=""nearest"")\n        loaded_im_array_nearest = image.img_to_array(loaded_im_nearest)\n        assert loaded_im_array_nearest.shape == (25, 25, 3)\n        assert np.any(loaded_im_array_nearest != loaded_im_array)\n\n        # Check that exception is raised if interpolation not supported.\n\n        loaded_im = image.load_img(filename, interpolation=""unsupported"")\n        with pytest.raises(ValueError):\n            loaded_im = image.load_img(filename, target_size=(25, 25),\n                                       interpolation=""unsupported"")\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/integration_tests/preprocessing/sequence_test.py,0,"b""from math import ceil\n\nimport numpy as np\nfrom numpy.testing import assert_allclose, assert_raises\n\nimport pytest\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.sequence import make_sampling_table\nfrom keras.preprocessing.sequence import skipgrams\nfrom keras.preprocessing.sequence import _remove_long_seq\nfrom keras.preprocessing.sequence import TimeseriesGenerator\n\n\ndef test_pad_sequences():\n    a = [[1], [1, 2], [1, 2, 3]]\n\n    # test padding\n    b = pad_sequences(a, maxlen=3, padding='pre')\n    assert_allclose(b, [[0, 0, 1], [0, 1, 2], [1, 2, 3]])\n    b = pad_sequences(a, maxlen=3, padding='post')\n    assert_allclose(b, [[1, 0, 0], [1, 2, 0], [1, 2, 3]])\n\n    # test truncating\n    b = pad_sequences(a, maxlen=2, truncating='pre')\n    assert_allclose(b, [[0, 1], [1, 2], [2, 3]])\n    b = pad_sequences(a, maxlen=2, truncating='post')\n    assert_allclose(b, [[0, 1], [1, 2], [1, 2]])\n\n    # test value\n    b = pad_sequences(a, maxlen=3, value=1)\n    assert_allclose(b, [[1, 1, 1], [1, 1, 2], [1, 2, 3]])\n\n\ndef test_pad_sequences_vector():\n    a = [[[1, 1]],\n         [[2, 1], [2, 2]],\n         [[3, 1], [3, 2], [3, 3]]]\n\n    # test padding\n    b = pad_sequences(a, maxlen=3, padding='pre')\n    assert_allclose(b, [[[0, 0], [0, 0], [1, 1]],\n                        [[0, 0], [2, 1], [2, 2]],\n                        [[3, 1], [3, 2], [3, 3]]])\n    b = pad_sequences(a, maxlen=3, padding='post')\n    assert_allclose(b, [[[1, 1], [0, 0], [0, 0]],\n                        [[2, 1], [2, 2], [0, 0]],\n                        [[3, 1], [3, 2], [3, 3]]])\n\n    # test truncating\n    b = pad_sequences(a, maxlen=2, truncating='pre')\n    assert_allclose(b, [[[0, 0], [1, 1]],\n                        [[2, 1], [2, 2]],\n                        [[3, 2], [3, 3]]])\n\n    b = pad_sequences(a, maxlen=2, truncating='post')\n    assert_allclose(b, [[[0, 0], [1, 1]],\n                        [[2, 1], [2, 2]],\n                        [[3, 1], [3, 2]]])\n\n    # test value\n    b = pad_sequences(a, maxlen=3, value=1)\n    assert_allclose(b, [[[1, 1], [1, 1], [1, 1]],\n                        [[1, 1], [2, 1], [2, 2]],\n                        [[3, 1], [3, 2], [3, 3]]])\n\n\ndef test_make_sampling_table():\n    a = make_sampling_table(3)\n    assert_allclose(a, np.asarray([0.00315225, 0.00315225, 0.00547597]),\n                    rtol=.1)\n\n\ndef test_skipgrams():\n    # test with no window size and binary labels\n    couples, labels = skipgrams(np.arange(3), vocabulary_size=3)\n    for couple in couples:\n        assert couple[0] in [0, 1, 2] and couple[1] in [0, 1, 2]\n\n    # test window size and categorical labels\n    couples, labels = skipgrams(np.arange(5), vocabulary_size=5, window_size=1,\n                                categorical=True)\n    for couple in couples:\n        assert couple[0] - couple[1] <= 3\n    for l in labels:\n        assert len(l) == 2\n\n\ndef test_remove_long_seq():\n    maxlen = 5\n    seq = [\n        [1, 2, 3],\n        [1, 2, 3, 4, 5, 6],\n    ]\n    label = ['a', 'b']\n    new_seq, new_label = _remove_long_seq(maxlen, seq, label)\n    assert new_seq == [[1, 2, 3]]\n    assert new_label == ['a']\n\n\ndef test_TimeseriesGenerator():\n    data = np.array([[i] for i in range(50)])\n    targets = np.array([[i] for i in range(50)])\n\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2,\n                                   batch_size=2)\n    assert len(data_gen) == 20\n    assert (np.allclose(data_gen[0][0],\n                        np.array([[[0], [2], [4], [6], [8]],\n                                  [[1], [3], [5], [7], [9]]])))\n    assert (np.allclose(data_gen[0][1],\n                        np.array([[10], [11]])))\n    assert (np.allclose(data_gen[1][0],\n                        np.array([[[2], [4], [6], [8], [10]],\n                                  [[3], [5], [7], [9], [11]]])))\n    assert (np.allclose(data_gen[1][1],\n                        np.array([[12], [13]])))\n\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2, reverse=True,\n                                   batch_size=2)\n    assert len(data_gen) == 20\n    assert (np.allclose(data_gen[0][0],\n                        np.array([[[8], [6], [4], [2], [0]],\n                                  [[9], [7], [5], [3], [1]]])))\n    assert (np.allclose(data_gen[0][1],\n                        np.array([[10], [11]])))\n\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2, shuffle=True,\n                                   batch_size=1)\n    batch = data_gen[0]\n    r = batch[1][0][0]\n    assert (np.allclose(batch[0],\n                        np.array([[[r - 10],\n                                   [r - 8],\n                                   [r - 6],\n                                   [r - 4],\n                                   [r - 2]]])))\n    assert (np.allclose(batch[1], np.array([[r], ])))\n\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2, stride=2,\n                                   batch_size=2)\n    assert len(data_gen) == 10\n    assert (np.allclose(data_gen[1][0],\n                        np.array([[[4], [6], [8], [10], [12]],\n                                  [[6], [8], [10], [12], [14]]])))\n    assert (np.allclose(data_gen[1][1],\n                        np.array([[14], [16]])))\n\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2,\n                                   start_index=10, end_index=30,\n                                   batch_size=2)\n    assert len(data_gen) == 6\n    assert (np.allclose(data_gen[0][0],\n                        np.array([[[10], [12], [14], [16], [18]],\n                                  [[11], [13], [15], [17], [19]]])))\n    assert (np.allclose(data_gen[0][1],\n                        np.array([[20], [21]])))\n\n    data = np.array([np.random.random_sample((1, 2, 3, 4)) for i in range(50)])\n    targets = np.array([np.random.random_sample((3, 2, 1)) for i in range(50)])\n    data_gen = TimeseriesGenerator(data, targets,\n                                   length=10, sampling_rate=2,\n                                   start_index=10, end_index=30,\n                                   batch_size=2)\n    assert len(data_gen) == 6\n    assert np.allclose(data_gen[0][0], np.array(\n        [np.array(data[10:19:2]), np.array(data[11:20:2])]))\n    assert (np.allclose(data_gen[0][1],\n                        np.array([targets[20], targets[21]])))\n\n    with assert_raises(ValueError) as context:\n        TimeseriesGenerator(data, targets, length=50)\n    error = str(context.exception)\n    assert '`start_index+length=50 > end_index=49` is disallowed' in error\n\n\ndef test_TimeSeriesGenerator_doesnt_miss_any_sample():\n    x = np.array([[i] for i in range(10)])\n\n    for length in range(3, 10):\n        g = TimeseriesGenerator(x, x,\n                                length=length,\n                                batch_size=1)\n        expected = max(0, len(x) - length)\n        actual = len(g)\n\n        assert expected == actual\n\n        if len(g) > 0:\n            # All elements in range(length, 10) should be used as current step\n            expected = np.arange(length, 10).reshape(-1, 1)\n\n            y = np.concatenate([g[ix][1] for ix in range(len(g))], axis=0)\n            assert_allclose(y, expected)\n\n    x = np.array([[i] for i in range(23)])\n\n    strides = (1, 1, 5, 7, 3, 5, 3)\n    lengths = (3, 3, 4, 3, 1, 3, 7)\n    batch_sizes = (6, 6, 6, 5, 6, 6, 6)\n    shuffles = (False, True, True, False, False, False, False)\n\n    for stride, length, batch_size, shuffle in zip(strides,\n                                                   lengths,\n                                                   batch_sizes,\n                                                   shuffles):\n        g = TimeseriesGenerator(x, x,\n                                length=length,\n                                sampling_rate=1,\n                                stride=stride,\n                                start_index=0,\n                                end_index=None,\n                                shuffle=shuffle,\n                                reverse=False,\n                                batch_size=batch_size)\n        if shuffle:\n            # all batches have the same size when shuffle is True.\n            expected_sequences = ceil(\n                (23 - length) / float(batch_size * stride)) * batch_size\n        else:\n            # last batch will be different if `(samples - length) / stride`\n            # is not a multiple of `batch_size`.\n            expected_sequences = ceil((23 - length) / float(stride))\n\n        expected_batches = ceil(expected_sequences / float(batch_size))\n\n        y = [g[ix][1] for ix in range(len(g))]\n\n        actual_sequences = sum(len(_y) for _y in y)\n        actual_batches = len(y)\n\n        assert expected_sequences == actual_sequences\n        assert expected_batches == actual_batches\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/integration_tests/preprocessing/text_test.py,0,"b'# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport pytest\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.text import hashing_trick\nfrom keras.preprocessing.text import text_to_word_sequence\n\n\ndef test_one_hot():\n    text = \'The cat sat on the mat.\'\n    encoded = one_hot(text, 5)\n    assert len(encoded) == 6\n    assert np.max(encoded) <= 4\n    assert np.min(encoded) >= 0\n\n\ndef test_hashing_trick_hash():\n    text = \'The cat sat on the mat.\'\n    encoded = hashing_trick(text, 5)\n    assert len(encoded) == 6\n    assert np.max(encoded) <= 4\n    assert np.min(encoded) >= 1\n\n\ndef test_hashing_trick_md5():\n    text = \'The cat sat on the mat.\'\n    encoded = hashing_trick(text, 5, hash_function=\'md5\')\n    assert len(encoded) == 6\n    assert np.max(encoded) <= 4\n    assert np.min(encoded) >= 1\n\n\ndef test_tokenizer():\n    texts = [\'The cat sat on the mat.\',\n             \'The dog sat on the log.\',\n             \'Dogs and cats living together.\']\n    tokenizer = Tokenizer(num_words=10)\n    tokenizer.fit_on_texts(texts)\n\n    sequences = []\n    for seq in tokenizer.texts_to_sequences_generator(texts):\n        sequences.append(seq)\n    assert np.max(np.max(sequences)) < 10\n    assert np.min(np.min(sequences)) == 1\n\n    tokenizer.fit_on_sequences(sequences)\n\n    for mode in [\'binary\', \'count\', \'tfidf\', \'freq\']:\n        matrix = tokenizer.texts_to_matrix(texts, mode)\n\n\ndef test_sequential_fit():\n    texts = [\'The cat sat on the mat.\',\n             \'The dog sat on the log.\',\n             \'Dogs and cats living together.\']\n    word_sequences = [\n        [\'The\', \'cat\', \'is\', \'sitting\'],\n        [\'The\', \'dog\', \'is\', \'standing\']\n    ]\n\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(texts)\n    tokenizer.fit_on_texts(word_sequences)\n\n    assert tokenizer.document_count == 5\n\n    tokenizer.texts_to_matrix(texts)\n    tokenizer.texts_to_matrix(word_sequences)\n\n\ndef test_text_to_word_sequence():\n    text = \'hello! ? world!\'\n    assert text_to_word_sequence(text) == [\'hello\', \'world\']\n\n\ndef test_text_to_word_sequence_multichar_split():\n    text = \'hello!stop?world!\'\n    assert text_to_word_sequence(text, split=\'stop\') == [\'hello\', \'world\']\n\n\ndef test_text_to_word_sequence_unicode():\n    text = u\'ali! veli? k\xc4\xb1rk dokuz elli\'\n    assert (text_to_word_sequence(text) ==\n            [u\'ali\', u\'veli\', u\'k\xc4\xb1rk\', u\'dokuz\', u\'elli\'])\n\n\ndef test_text_to_word_sequence_unicode_multichar_split():\n    text = u\'ali!stopveli?stopk\xc4\xb1rkstopdokuzstopelli\'\n    assert (text_to_word_sequence(text, split=\'stop\') ==\n            [u\'ali\', u\'veli\', u\'k\xc4\xb1rk\', u\'dokuz\', u\'elli\'])\n\n\ndef test_tokenizer_unicode():\n    texts = [u\'ali veli k\xc4\xb1rk dokuz elli\',\n             u\'ali veli k\xc4\xb1rk dokuz elli veli k\xc4\xb1rk dokuz\']\n    tokenizer = Tokenizer(num_words=5)\n    tokenizer.fit_on_texts(texts)\n\n    assert len(tokenizer.word_counts) == 5\n\n\ndef test_tokenizer_oov_flag():\n    """"""\n    Test of Out of Vocabulary (OOV) flag in Tokenizer\n    """"""\n    x_train = [\'This text has only known words\']\n    x_test = [\'This text has some unknown words\']  # 2 OOVs: some, unknown\n\n    # Default, without OOV flag\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(x_train)\n    x_test_seq = tokenizer.texts_to_sequences(x_test)\n    assert len(x_test_seq[0]) == 4  # discards 2 OOVs\n\n    # With OOV feature\n    tokenizer = Tokenizer(oov_token=\'<unk>\')\n    tokenizer.fit_on_texts(x_train)\n    x_test_seq = tokenizer.texts_to_sequences(x_test)\n    assert len(x_test_seq[0]) == 6  # OOVs marked in place\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/backend/backend_test.py,4,"b'import pytest\nfrom numpy.testing import assert_allclose\nimport numpy as np\nimport scipy.sparse as sparse\nimport warnings\n\nfrom keras import backend as K\nfrom keras.utils.conv_utils import convert_kernel\nfrom keras.backend import numpy_backend as KNP\n\n\ntry:\n    from keras.backend import cntk_backend as KC\nexcept ImportError:\n    KC = None\n    warnings.warn(\'Could not import the CNTK backend\')\n\ntry:\n    from keras.backend import tensorflow_backend as KTF\nexcept ImportError:\n    KTF = None\n    warnings.warn(\'Could not import the TensorFlow backend.\')\n\ntry:\n    from keras.backend import theano_backend as KTH\nexcept ImportError:\n    KTH = None\n    warnings.warn(\'Could not import the Theano backend\')\n\nif K.backend() == \'theano\':\n    WITH_NP = [KTH, KNP]\nelif K.backend() == \'cntk\':\n    WITH_NP = [KC, KNP]\nelse:\n    WITH_NP = [KTF, KNP]\n\nif K.backend() == \'cntk\':\n    supports_sparse = False\nelif K.backend() == \'theano\' and not KTH.th_sparse_module:\n    supports_sparse = False\nelif K.backend() == \'tensorflow\':\n    # Must wait for tf.keras to support sparse ops.\n    supports_sparse = False\nelse:\n    supports_sparse = True\n\n\ndef check_dtype(var, dtype):\n    if K.backend() == \'tensorflow\':\n        assert dtype in str(var.dtype.name)\n    else:\n        assert dtype in str(var.dtype)\n\n\ndef cntk_func_tensors(function_name, shapes_or_vals, **kwargs):\n    placeholders = []\n    variables = []\n    for shape_or_val in shapes_or_vals:\n        if isinstance(shape_or_val, tuple):\n            shape = shape_or_val\n            placeholders.append(KC.placeholder(shape))\n        else:\n            value = shape_or_val\n            variables.append(KC.variable(value))\n\n    output_cntk = getattr(KC, function_name)(*(placeholders + variables), **kwargs)\n    cntk_func = KC.function(placeholders, [output_cntk])\n    return output_cntk, cntk_func\n\n\ndef parse_shape_or_val(shape_or_val):\n    if isinstance(shape_or_val, np.ndarray):\n        return shape_or_val.shape, shape_or_val\n    else:\n        return shape_or_val, np.random.random(shape_or_val).astype(np.float32) - 0.5\n\n\ndef assert_list_pairwise(z_list,\n                         shape=True,\n                         allclose=True,\n                         itself=False,\n                         atol=1e-05):\n    for (z1, z2) in zip(z_list[1:], z_list[:-1]):\n        if shape:\n            assert z1.shape == z2.shape\n        if allclose:\n            assert_allclose(z1, z2, atol=atol)\n        if itself:\n            assert z1 == z2\n\n\ndef assert_list_keras_shape(t_list, z_list):\n    for t, z in zip(t_list, z_list):\n        if hasattr(t, \'_keras_shape\') and len(t._keras_shape) > 1:\n            for i, s in enumerate(t._keras_shape):\n                if s:\n                    assert t._keras_shape[i] == z.shape[i]\n\n\ndef check_single_tensor_operation(function_name,\n                                  x_shape_or_val,\n                                  backend_list,\n                                  **kwargs):\n    shape_or_val = kwargs.pop(\'shape_or_val\', True)\n    assert_value_equality = kwargs.pop(\'assert_value_equality\', True)\n    cntk_dynamicity = kwargs.pop(\'cntk_dynamicity\', False)\n\n    if shape_or_val:\n        x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n\n    t_list = []\n    z_list = []\n    for k in backend_list:\n        if shape_or_val:\n            if (k == KC) & (cntk_dynamicity):\n                t, f = cntk_func_tensors(function_name, [x_shape], **kwargs)\n                z = f([x_val])[0]\n            else:\n                t = getattr(k, function_name)(k.variable(x_val), **kwargs)\n                z = k.eval(t)\n        else:\n            t = getattr(k, function_name)(x_shape_or_val, **kwargs)\n            z = k.eval(t)\n        t_list += [t]\n        z_list += [z]\n\n    assert_list_pairwise(z_list, allclose=assert_value_equality)\n    assert_list_keras_shape(t_list, z_list)\n\n\ndef check_two_tensor_operation(function_name,\n                               x_shape_or_val,\n                               y_shape_or_val,\n                               backend_list,\n                               **kwargs):\n    concat_args = kwargs.pop(\'concat_args\', False)\n    cntk_dynamicity = kwargs.pop(\'cntk_dynamicity\', False)\n    cntk_two_dynamicity = kwargs.pop(\'cntk_two_dynamicity\', False)\n\n    x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n    y_shape, y_val = parse_shape_or_val(y_shape_or_val)\n\n    t_list = []\n    z_list = []\n    for k in backend_list:\n        if (k == KC) & (cntk_dynamicity):\n            t, f = cntk_func_tensors(function_name, [x_shape, y_val], **kwargs)\n            z = f([x_val])[0]\n        elif (k == KC) & (cntk_two_dynamicity):\n            t, f = cntk_func_tensors(function_name, [x_shape, y_shape], **kwargs)\n            z = f([x_val, y_val])[0]\n        elif (k == KTH) & (function_name[:4] == \'conv\'):\n            t = getattr(k, function_name)(\n                k.variable(x_val), k.variable(convert_kernel(y_val)), **kwargs)\n            z = k.eval(t)\n        elif concat_args:\n            t = getattr(k, function_name)(\n                [k.variable(x_val), k.variable(y_val)], **kwargs)\n            z = k.eval(t)\n        else:\n            t = getattr(k, function_name)(\n                k.variable(x_val), k.variable(y_val), **kwargs)\n            z = k.eval(t)\n        t_list += [t]\n        z_list += [z]\n\n    assert_list_pairwise(z_list)\n    assert_list_keras_shape(t_list, z_list)\n\n\ndef check_composed_tensor_operations(first_function_name,\n                                     first_function_args,\n                                     second_function_name,\n                                     second_function_args,\n                                     input_shape,\n                                     backend_list):\n    val = np.random.random(input_shape) - 0.5\n\n    z_list = []\n    for k in backend_list:\n        x = k.variable(val)\n        y = getattr(k, first_function_name)(x, **first_function_args)\n        z = k.eval(getattr(k, second_function_name)(y, **second_function_args))\n        z_list += [z]\n\n    assert_list_pairwise(z_list)\n\n\ndef check_rnn_operation(step_function_k,\n                        step_function_np,\n                        inputs_np,\n                        initial_states_np,\n                        mask_np=None,\n                        constants_np=None,\n                        **kwargs):\n    inputs_k = K.variable(inputs_np)\n    initial_states_k = [K.variable(s) for s in initial_states_np]\n    if mask_np is not None:\n        mask_k = K.variable(mask_np)\n    else:\n        mask_k = None\n    if constants_np is not None:\n        constants_k = [K.variable(c) for c in constants_np]\n    else:\n        constants_k = None\n\n    last_output_np, output_np, last_states_np = KNP.rnn(\n        step_function_np,\n        inputs_np,\n        initial_states_np,\n        mask=mask_np,\n        constants=constants_np,\n        **kwargs)\n    # note that numpy reference implementation is independent of `unroll` argument\n    if \'unroll\' in kwargs:\n        unroll_options = [kwargs.pop(\'unroll\')]\n    else:\n        unroll_options = [True, False]\n    for unroll in unroll_options:\n        last_output_k, output_k, last_states_k = K.rnn(\n            step_function_k,\n            inputs_k,\n            initial_states_k,\n            mask=mask_k,\n            constants=constants_k,\n            unroll=unroll,\n            input_length=inputs_np.shape[1] if unroll else None,\n            **kwargs)\n\n        last_states_k = [K.eval(s) for s in last_states_k]\n        last_output_k = K.eval(last_output_k)\n        output_k = K.eval(output_k)\n\n        assert_allclose(last_output_k, last_output_np, atol=1e-05)\n        assert_allclose(output_k, output_np, atol=1e-05)\n        assert len(last_states_k) == len(last_states_np)\n        for s_k, s_np in zip(last_states_k, last_states_np):\n            assert_allclose(s_k, s_np, atol=1e-05)\n\n\nclass TestBackend(object):\n\n    def test_is_keras_tensor(self):\n        np_var = np.array([1, 2])\n        with pytest.raises(ValueError):\n            K.is_keras_tensor(np_var)\n\n        keras_var = K.variable(np_var)\n        assert K.is_keras_tensor(keras_var) is False\n        keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        assert K.is_keras_tensor(keras_placeholder) is False\n\n    def test_set_learning_phase(self):\n        # not supported learning_phase\n        with pytest.raises(ValueError):\n            K.set_learning_phase(2)\n\n    def test_creation_operations(self):\n        check_single_tensor_operation(\'eye\', 3, WITH_NP, shape_or_val=False)\n        check_single_tensor_operation(\'eye\', (3, 2), WITH_NP, shape_or_val=False)\n        check_single_tensor_operation(\'eye\', (3, 4), WITH_NP, shape_or_val=False)\n\n        check_single_tensor_operation(\'ones\', (3, 5, 10, 8),\n                                      WITH_NP, shape_or_val=False)\n        check_single_tensor_operation(\'zeros\', (3, 5, 10, 8),\n                                      WITH_NP, shape_or_val=False)\n\n        check_single_tensor_operation(\'ones_like\', (3, 5, 10, 8), WITH_NP)\n        check_single_tensor_operation(\'zeros_like\', (3, 5, 10, 8), WITH_NP)\n\n    def test_linear_operations(self):\n        check_two_tensor_operation(\'dot\', (4, 2), (2, 4), WITH_NP)\n        check_two_tensor_operation(\'dot\', (4, 2), (5, 2, 3), WITH_NP)\n\n        check_two_tensor_operation(\'batch_dot\', (4, 2, 3), (4, 5, 3),\n                                   WITH_NP, cntk_two_dynamicity=True, axes=(2, 2))\n        check_two_tensor_operation(\'batch_dot\', (4, 2, 3), (4, 3),\n                                   WITH_NP, cntk_two_dynamicity=True, axes=(2, 1))\n        check_two_tensor_operation(\'batch_dot\', (4, 2), (4, 2, 3),\n                                   WITH_NP, cntk_two_dynamicity=True, axes=(1, 1))\n        check_two_tensor_operation(\'batch_dot\', (32, 20), (32, 20),\n                                   WITH_NP, cntk_two_dynamicity=True, axes=1)\n        check_two_tensor_operation(\'batch_dot\', (32, 20), (32, 20),\n                                   WITH_NP, cntk_two_dynamicity=True, axes=(1, 1))\n        check_two_tensor_operation(\'batch_dot\', (4, 2, 3), (4, 5, 3),\n                                   WITH_NP, axes=(2, 2))\n        check_two_tensor_operation(\'batch_dot\', (4, 2, 3), (4, 3),\n                                   WITH_NP, axes=(2, 1))\n        check_two_tensor_operation(\'batch_dot\', (4, 2), (4, 2, 3),\n                                   WITH_NP, axes=(1, 1))\n        check_two_tensor_operation(\'batch_dot\', (32, 20), (32, 20),\n                                   WITH_NP, axes=1)\n        check_two_tensor_operation(\'batch_dot\', (32, 20), (32, 20),\n                                   WITH_NP, axes=(1, 1))\n\n        check_single_tensor_operation(\'transpose\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'reverse\', (4, 3, 2), WITH_NP, axes=1)\n        check_single_tensor_operation(\'reverse\', (4, 3, 2), WITH_NP, axes=(1, 2))\n        check_single_tensor_operation(\'reverse\', (4, 3, 2), WITH_NP, axes=(0, -1))\n\n    def test_random_variables(self):\n        check_single_tensor_operation(\'random_uniform_variable\', (2, 3), WITH_NP,\n                                      low=0., high=1.,\n                                      shape_or_val=False,\n                                      assert_value_equality=False)\n        check_single_tensor_operation(\'random_normal_variable\', (2, 3), WITH_NP,\n                                      mean=0., scale=1.,\n                                      shape_or_val=False,\n                                      assert_value_equality=False)\n\n    def test_batch_dot_shape(self):\n        # Note : batch_dot implementation is different for\n        # placeholders and variables in CNTK backend\n\n        test_cases = []\n        test_cases.append([(None, 3, 4, 5), (None, 2, 3, 4), (2, 3)])\n        test_cases.append([(None, 3, 4, 5), (None, 2, 4), 2])\n        test_cases.append([(None, 3, 4), (None, 2, 3, 4), (2, 3)])\n        test_cases.append([(None, 4, 3), (None, 3, 5), (2, 1)])\n        test_cases.append([(None, 4), (None, 3, 4), (1, 2)])\n        test_cases.append([(None, 4), (None, 4), None])\n\n        batch_size = 7\n\n        def batch_shape(shape):\n            return (batch_size, ) + shape[1:]\n\n        def random(shape):\n            return np.random.random(batch_shape(shape))\n\n        for x_shape, y_shape, axes in test_cases:\n            x_np = random(x_shape)\n            y_np = random(y_shape)\n            z_np = KNP.batch_dot(x_np, y_np, axes)\n\n            # test with placeholders\n            x = K.placeholder(shape=x_shape)\n            y = K.placeholder(shape=y_shape)\n            z = K.batch_dot(x, y, axes)\n\n            z_shape = K.int_shape(z)\n            if z_shape is not None:\n                assert z_shape[1:] == z_np.shape[1:]\n\n            f = K.function([x, y], [z])\n\n            assert_allclose(f([x_np, y_np])[0], z_np, atol=1e-05)\n\n            # test with placeholders (no shape info)\n            if K.backend() != \'cntk\':\n                x = K.placeholder(ndim=len(x_shape))\n                y = K.placeholder(ndim=len(y_shape))\n                z = K.batch_dot(x, y, axes)\n\n                z_shape = K.int_shape(z)\n                if z_shape is not None:\n                    assert len(z_shape) == z_np.ndim\n                    assert set(z_shape) <= set((None, 1))\n\n                f = K.function([x, y], [z])\n\n                assert_allclose(f([x_np, y_np])[0], z_np, atol=1e-05)\n\n            # test with variables\n            x = K.variable(x_np)\n            y = K.variable(y_np)\n            z = K.batch_dot(x, y, axes)\n\n            z_shape = K.int_shape(z)\n            if z_shape is not None:\n                assert z_shape[1:] == z_np.shape[1:]\n\n            z = K.eval(z)\n            assert_allclose(z, z_np, atol=1e-05)\n\n    def test_shape_operations(self):\n        check_single_tensor_operation(\'reshape\', (4, 2), WITH_NP, shape=(8, 1))\n        check_single_tensor_operation(\'permute_dimensions\', (4, 2, 3), WITH_NP,\n                                      pattern=(2, 0, 1))\n        check_single_tensor_operation(\'repeat\', (4, 1), WITH_NP, n=3)\n        check_single_tensor_operation(\'flatten\', (4, 1), WITH_NP)\n        check_single_tensor_operation(\'batch_flatten\', (20, 2, 5), WITH_NP,\n                                      cntk_dynamicity=True)\n        check_single_tensor_operation(\'expand_dims\', (4, 3), WITH_NP, axis=-1)\n        check_single_tensor_operation(\'expand_dims\', (4, 3, 2), WITH_NP, axis=1)\n        check_single_tensor_operation(\'squeeze\', (4, 3, 1), WITH_NP, axis=2)\n        check_single_tensor_operation(\'squeeze\', (4, 1, 1), WITH_NP, axis=1)\n        check_composed_tensor_operations(\'reshape\', {\'shape\': (4, 3, 1, 1)},\n                                         \'squeeze\', {\'axis\': 2},\n                                         (4, 3, 1, 1), WITH_NP)\n\n    @pytest.mark.skipif(K.backend() != \'theano\',\n                        reason=\'We only test the shape inference of the \'\n                               \'theano backend.\')\n    def test_none_shape_operations(self):\n        # Test shape inference when input\n        # shape has `None` entries\n        x = K.placeholder((3, None, 4))\n\n        y = K.batch_flatten(x)\n        if hasattr(y, \'_keras_shape\'):\n            assert y._keras_shape == (3, None)\n\n        y = K.flatten(x)\n        if hasattr(y, \'_keras_shape\'):\n            assert y._keras_shape == (None,)\n\n    def test_repeat_elements(self):\n        reps = 3\n        for ndims in [1, 2, 3]:\n            shape = np.arange(2, 2 + ndims)\n            arr = np.arange(np.prod(shape)).reshape(shape)\n\n            for rep_axis in range(ndims):\n                check_single_tensor_operation(\'repeat_elements\', arr, WITH_NP,\n                                              rep=reps, axis=rep_axis)\n\n                if K.backend() != \'cntk\':\n                    shape = list(shape)\n                    shape[rep_axis] = None\n                    x = K.placeholder(shape=shape)\n                    y = K.repeat_elements(x, reps, axis=rep_axis)\n                    assert y._keras_shape == tuple(shape)\n                    assert y._keras_shape == K.int_shape(y)\n\n    def test_tile(self):\n        check_single_tensor_operation(\'tile\', (3, 4), WITH_NP, n=2)\n        check_single_tensor_operation(\'tile\', (3, 4), WITH_NP, n=(2, 1))\n        check_single_tensor_operation(\'tile\', (3, 4, 5), WITH_NP, n=2)\n        check_single_tensor_operation(\'tile\', (3, 4, 5), WITH_NP, n=(1, 2))\n        check_single_tensor_operation(\'tile\', (3, 4, 5), WITH_NP, n=(3, 1, 2))\n\n        # test theano shape inference when\n        # input shape has None entries\n        if K.backend() == \'theano\':\n            x = K.placeholder(shape=(None, 4))\n            n = 2\n            y = K.tile(x, n)\n            assert y._keras_shape == (None, 8)\n            n = (4, 3)\n            y = K.tile(x, n)\n            assert y._keras_shape == (None, 12)\n\n    def test_gather(self):\n        shape = (10, 2, 3)\n        ref = np.arange(np.prod(shape)).reshape(shape)\n        inds = [1, 3, 7, 9]\n        t_list = [k.gather(k.variable(ref), k.variable(inds, dtype=\'int32\'))\n                  for k in WITH_NP]\n        z_list = [k.eval(k.gather(k.variable(ref), k.variable(inds, dtype=\'int32\')))\n                  for k in WITH_NP]\n\n        assert_list_pairwise(z_list)\n        assert_list_keras_shape(t_list, z_list)\n\n        # test theano shape inference when\n        # input shape has None entries\n        if K.backend() == \'theano\':\n            x = K.placeholder(shape=(None, 3, 4))\n            indices = K.placeholder(shape=(5, 6), dtype=\'int32\')\n            y = K.gather(x, indices)\n            assert y._keras_shape == (5, 6, 3, 4)\n\n    @pytest.mark.parametrize(\'function_name\',\n                             [\'get_value\', \'count_params\',\n                              \'int_shape\', \'get_variable_shape\'])\n    def test_value_manipulation(self, function_name):\n        val = np.random.random((4, 2))\n        v_list = [getattr(k, function_name)(k.variable(val))\n                  for k in WITH_NP]\n\n        if function_name == \'get_value\':\n            assert_list_pairwise(v_list)\n        else:\n            assert_list_pairwise(v_list,\n                                 shape=False,\n                                 allclose=False,\n                                 itself=True)\n\n    def test_print_tensor(self, capsys):\n        # TODO: somehow this capture mechanism doesn\'t work for TF\n        # even though the TF op does print to stdout.\n        for k in [KTH]:\n            x = k.placeholder((1, 1))\n            y = k.print_tensor(x, \'msg\')\n            fn = k.function([x], [y])\n            _ = fn([np.ones((1, 1))])\n            out, err = capsys.readouterr()\n            # Theano inserts ""__str__ = "" for no good reason\n            assert out.replace(\'__str__ = \', \'\') == \'msg [[1.]]\\n\'\n\n    def test_elementwise_operations(self):\n        check_single_tensor_operation(\'max\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'max\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'max\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'min\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'min\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'min\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'mean\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'mean\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'mean\', (4, 2, 3),\n                                      WITH_NP, axis=-1, keepdims=True)\n        check_single_tensor_operation(\'mean\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'var\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'var\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'var\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'std\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'std\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'std\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'prod\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'prod\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'prod\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'any\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'any\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'any\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'all\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'all\', (4, 2), WITH_NP, axis=1, keepdims=True)\n        check_single_tensor_operation(\'all\', (4, 2, 3), WITH_NP, axis=[1, -1])\n\n        check_single_tensor_operation(\'argmax\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'argmax\', (4, 2), WITH_NP, axis=1)\n\n        check_single_tensor_operation(\'argmin\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'argmin\', (4, 2), WITH_NP, axis=1)\n\n        check_single_tensor_operation(\'square\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'abs\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'sqrt\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'exp\', (4, 2), WITH_NP)\n\n        check_single_tensor_operation(\'round\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'sign\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'pow\', (4, 2), WITH_NP, a=3)\n        check_single_tensor_operation(\'clip\', (4, 2), WITH_NP, min_value=0.4,\n                                      max_value=0.6)\n\n        check_single_tensor_operation(\'cos\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'sin\', (4, 2), WITH_NP)\n\n        # two-tensor ops\n        check_two_tensor_operation(\'equal\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'not_equal\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'greater\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'greater_equal\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'less\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'less_equal\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'maximum\', (4, 2), (4, 2), WITH_NP)\n        check_two_tensor_operation(\'minimum\', (4, 2), (4, 2), WITH_NP)\n\n    # assumes first uid will always be the same\n    def test_reset_uids(self):\n        first = K.get_uid()\n        K.get_uid()\n        K.reset_uids()\n        assert K.get_uid() == first\n\n    def test_cumsum(self):\n        check_single_tensor_operation(\'cumsum\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'cumsum\', (4, 2), WITH_NP, axis=1)\n\n    def test_cumprod(self):\n        check_single_tensor_operation(\'cumprod\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'cumprod\', (4, 2), WITH_NP, axis=1)\n\n    @pytest.mark.skipif(K.backend() == \'cntk\',\n                        reason=\'cntk return -85.1 for zero or \'\n                               \'negative number, not nan, so can\\\'t \'\n                               \'compare with other backend.\')\n    def test_log(self):\n        check_single_tensor_operation(\'log\', (4, 2), WITH_NP)\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'theano returns tuples for updates; cntk buggy\')\n    def test_update(self):\n        x = np.ones((3, 4))\n        x_var = K.variable(x)\n        new_x = np.random.random((3, 4))\n\n        op = K.update(x_var, new_x)\n        K.eval(op)\n\n        assert_allclose(new_x, K.eval(x_var), atol=1e-05)\n\n    @pytest.mark.skipif(K.backend() == \'theano\',\n                        reason=\'theano returns tuples for update ops\')\n    def test_update_add(self):\n        x = np.ones((3, 4))\n        x_var = K.variable(x)\n        increment = np.random.random((3, 4))\n\n        op = K.update_add(x_var, increment)\n        K.eval(op)\n\n        assert_allclose(x + increment, K.eval(x_var), atol=1e-05)\n\n    @pytest.mark.skipif(K.backend() == \'theano\',\n                        reason=\'theano returns tuples for update ops\')\n    def test_update_sub(self):\n        x = np.ones((3, 4))\n        x_var = K.variable(x)\n        decrement = np.random.random((3, 4))\n\n        op = K.update_sub(x_var, decrement)\n        K.eval(op)\n\n        assert_allclose(x - decrement, K.eval(x_var), atol=1e-05)\n\n    @pytest.mark.skipif(K.backend() == \'cntk\',\n                        reason=\'cntk doesn\\\'t support gradient in this way.\')\n    def test_gradient(self):\n        val = np.random.random((4, 2))\n        x_list = [k.placeholder(shape=(4, 2)) for k in [KTH, KTF]]\n        z_list = []\n        zero_list = []\n        for x, k in zip(x_list, [KTH, KTF]):\n            exp = x * k.exp(x)\n            loss = k.sum(exp)\n            zero_loss = k.stop_gradient(loss)\n            grad = k.gradients(loss, [exp])\n\n            zero_grad = k.gradients(loss + zero_loss, [exp])\n            grad_eval_fn = k.function([x], [grad[0]])\n            zero_grad_eval_fn = k.function([x], [zero_grad[0]])\n            z_list.append(grad_eval_fn([val])[0])\n            zero_list.append(zero_grad_eval_fn([val])[0])\n\n        assert_list_pairwise(z_list)\n        assert_list_pairwise(zero_list)\n        for i in range(len(z_list)):\n            assert_allclose(zero_list[i], z_list[i], atol=1e-05)\n\n    def test_stop_gradient(self):\n        # This test checks the consistency of the stop_gradient backend API.\n        # It doesn\'t check the functionality (which is checked at the\n        # test_gradient test).\n        val = np.random.random((4, 2))\n        a = K.variable(val)\n        b = K.square(a)\n        c, d = K.stop_gradient([a, b])\n        e = K.stop_gradient(b)\n\n    @pytest.mark.skipif(K.backend() == \'cntk\',\n                        reason=\'cntk currently not support function in this \'\n                               \'way, so can\\\'t test as this.\')\n    def test_function(self):\n        test_backend = [KTH, KTF]\n        val = np.random.random((4, 2))\n        input_val = np.random.random((4, 2))\n\n        f_list = []\n        x_list = []\n        for k in test_backend:\n            x = k.variable(val)\n            x_list.append(x)\n            y = k.placeholder(ndim=2)\n            exp = k.square(x) + y\n            # Need to use `identity` to make this symbolic\n            # (TODO: fix in tf.keras)\n            update = k.identity(x) * 2\n            f = k.function([y], [exp], updates=[(x, update)])\n            f_list.append(f)\n\n        function_outputs_list = [f([input_val])[0] for f in f_list]\n        assert_list_pairwise(function_outputs_list)\n\n        new_val_list = [k.get_value(x) for x, k in zip(x_list, test_backend)]\n        assert_list_pairwise(new_val_list)\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\' or not KTF._is_tf_1(),\n                        reason=\'Uses the `fetches` argument.\')\n    def test_function_tf_fetches(self):\n        # Additional operations can be passed to tf.Session().run() via its\n        # `fetches` arguments. In contrast to `updates` argument of\n        # KTF.function() these do not have control dependency on `outputs`, so\n        # they can run in parallel. Also they should not contribute to output of\n        # KTF.function().\n\n        x = K.variable(0.)\n        y = K.variable(0.)\n        x_placeholder = K.placeholder(shape=())\n        y_placeholder = K.placeholder(shape=())\n\n        f = K.function(inputs=[x_placeholder, y_placeholder],\n                       outputs=[x_placeholder + y_placeholder],\n                       updates=[(x, x_placeholder + 1.)],\n                       fetches=[K.update(y, 5.)])\n        output = f([10., 20.])\n        assert output == [30.]\n        assert K.get_session().run(fetches=[x, y]) == [11., 5.]\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\' or not KTF._is_tf_1(),\n                        reason=\'Uses the `feed_dict` argument.\')\n    def test_function_tf_feed_dict(self):\n        # Additional substitutions can be passed to `tf.Session().run()` via its\n        # `feed_dict` arguments. Note that the feed_dict is passed once in the\n        # constructor but we can modify the values in the dictionary. Through\n        # this feed_dict we can provide additional substitutions besides Keras\n        # inputs.\n\n        x = K.variable(0.)\n        y = K.variable(0.)\n        x_placeholder = K.placeholder(shape=())\n        y_placeholder = K.placeholder(shape=())\n\n        feed_dict = {y_placeholder: 3.}\n\n        f = K.function(inputs=[x_placeholder],\n                       outputs=[x_placeholder + 1.],\n                       updates=[(x, x_placeholder + 10.)],\n                       feed_dict=feed_dict,\n                       fetches=[K.update(y, y_placeholder * 10.)])\n        output = f([10.])\n        assert output == [11.]\n        assert K.get_session().run(fetches=[x, y]) == [20., 30.]\n\n        # updated value in feed_dict will be modified within the K.function()\n        feed_dict[y_placeholder] = 4.\n        output = f([20.])\n        assert output == [21.]\n        assert K.get_session().run(fetches=[x, y]) == [30., 40.]\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\' or not KTF._is_tf_1(),\n                        reason=\'Uses the `options` and `run_metadata` arguments.\')\n    def test_function_tf_run_options_with_run_metadata(self):\n        from tensorflow.core.protobuf import config_pb2\n        x_placeholder = K.placeholder(shape=())\n        y_placeholder = K.placeholder(shape=())\n\n        run_options = config_pb2.RunOptions(output_partition_graphs=True)\n        run_metadata = config_pb2.RunMetadata()\n        # enable run_options.\n        f = K.function(inputs=[x_placeholder, y_placeholder],\n                       outputs=[x_placeholder + y_placeholder],\n                       options=run_options,\n                       run_metadata=run_metadata)\n        output = f([10., 20.])\n        assert output == [30.]\n        assert len(run_metadata.partition_graphs) > 0\n        # disable run_options.\n        f = K.function(inputs=[x_placeholder, y_placeholder],\n                       outputs=[x_placeholder + y_placeholder],\n                       run_metadata=run_metadata)\n        output = f([10., 20.])\n        assert output == [30.]\n        assert len(run_metadata.partition_graphs) == 0\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'Uses the `string` type for a tensor.\')\n    def test_function_tf_string_input(self):\n        # Test functions with string inputs.\n\n        x_placeholder = K.placeholder(shape=(), dtype=""string"")\n        x_identity = K.identity(x_placeholder)\n\n        f = K.function(inputs=[x_placeholder], outputs=[x_identity])\n        output = f([b\'test\'])\n        assert output == [b\'test\']\n\n    def test_rnn(self):\n        # implement a simple RNN\n        num_samples = 4\n        input_dim = 5\n        output_dim = 3\n        timesteps = 6\n\n        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n        _, h0 = parse_shape_or_val((num_samples, output_dim))\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        _, wh = parse_shape_or_val((output_dim, output_dim))\n        mask = np.random.randint(2, size=(num_samples, timesteps))\n\n        wi_k = K.variable(wi)\n        wh_k = K.variable(wh)\n\n        def get_step_function(backend, w_i, w_h):\n\n            def simple_rnn(inputs, states):\n                assert len(states) == 1\n                h = states[0]\n                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n                return y, [y]\n\n            return simple_rnn\n\n        kwargs_list = [\n            {\'go_backwards\': False, \'mask\': None},\n            {\'go_backwards\': True, \'mask\': None},\n            {\'go_backwards\': False, \'mask\': mask},\n            {\'go_backwards\': True, \'mask\': mask},\n        ]\n        for kwargs in kwargs_list:\n            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n                                step_function_np=get_step_function(KNP, wi, wh),\n                                inputs_np=x,\n                                initial_states_np=[h0],\n                                mask_np=kwargs.pop(\'mask\', None),\n                                **kwargs)\n\n    @pytest.mark.skipif(K.backend() == \'theano\', reason=\'Not supported\')\n    def test_rnn_unroll_with_len_1(self):\n        num_samples = 4\n        input_dim = 5\n        output_dim = 3\n\n        _, x = parse_shape_or_val((num_samples, 1, input_dim))\n        _, h0 = parse_shape_or_val((num_samples, output_dim))\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        _, wh = parse_shape_or_val((output_dim, output_dim))\n\n        wi_k = K.variable(wi)\n        wh_k = K.variable(wh)\n\n        def get_step_function(backend, w_i, w_h):\n\n            def simple_rnn(inputs, states):\n                assert len(states) == 1\n                h = states[0]\n                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n                return y, [y]\n\n            return simple_rnn\n\n        kwargs_list = [\n            {\'go_backwards\': False},\n            {\'go_backwards\': True},\n        ]\n        for kwargs in kwargs_list:\n            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n                                step_function_np=get_step_function(KNP, wi, wh),\n                                inputs_np=x,\n                                initial_states_np=[h0],\n                                unroll=True,\n                                **kwargs)\n\n    def test_rnn_additional_states(self):\n        # implement a simple RNN with an additional state\n        # whose shape is different from that of the output\n        num_samples = 4\n        input_dim = 5\n        output_dim = 3\n        timesteps = 6\n\n        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n        _, h0 = parse_shape_or_val((num_samples, output_dim))\n        h1 = np.concatenate([h0, h0], axis=-1)\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        _, wh = parse_shape_or_val((output_dim, output_dim))\n        mask = np.random.randint(2, size=(num_samples, timesteps))\n\n        wi_k = K.variable(wi)\n        wh_k = K.variable(wh)\n\n        def get_step_function(backend, w_i, w_h):\n\n            def simple_rnn_with_extra_mock_state(inputs, states):\n                assert len(states) == 2\n                h = states[0]\n                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n                return y, [y, backend.concatenate([y, y], axis=-1)]\n\n            return simple_rnn_with_extra_mock_state\n\n        kwargs_list = [\n            {\'go_backwards\': False, \'mask\': None},\n            {\'go_backwards\': True, \'mask\': None},\n            {\'go_backwards\': False, \'mask\': mask},\n            {\'go_backwards\': True, \'mask\': mask},\n        ]\n        for kwargs in kwargs_list:\n            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n                                step_function_np=get_step_function(KNP, wi, wh),\n                                inputs_np=x,\n                                initial_states_np=[h0, h1],\n                                mask_np=kwargs.pop(\'mask\', None),\n                                **kwargs)\n\n    def test_rnn_no_states(self):\n        # implement a simple RNN without states\n        num_samples = 3\n        input_dim = 8\n        output_dim = 4\n        timesteps = 5\n\n        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        mask = np.random.randint(2, size=(num_samples, timesteps))\n\n        wi_k = K.variable(wi)\n\n        def get_step_function(backend, w_i):\n\n            def simple_no_states(inputs, states):\n                assert len(states) == 0\n                y = backend.dot(inputs, w_i)\n                return y, []\n\n            return simple_no_states\n\n        kwargs_list = [\n            {\'go_backwards\': False},\n            {\'go_backwards\': True},\n        ]\n        for kwargs in kwargs_list:\n            check_rnn_operation(step_function_k=get_step_function(K, wi_k),\n                                step_function_np=get_step_function(KNP, wi),\n                                inputs_np=x,\n                                initial_states_np=[],\n                                mask_np=None,\n                                **kwargs)\n\n    def test_rnn_constants(self):\n        # implement a simple RNN\n        num_samples = 4\n        input_dim = 5\n        output_dim = 3\n        timesteps = 6\n\n        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n        _, h0 = parse_shape_or_val((num_samples, output_dim))\n        _, c = parse_shape_or_val((num_samples, output_dim))\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        _, wh = parse_shape_or_val((output_dim, output_dim))\n        mask = np.random.randint(2, size=(num_samples, timesteps))\n\n        wi_k = K.variable(wi)\n        wh_k = K.variable(wh)\n\n        def get_step_function(backend, w_i, w_h):\n\n            def simple_rnn_add_constant(inputs, states_and_constants):\n                # constants are appended to states in K.rnn\n                [h, c] = states_and_constants\n                y = backend.dot(inputs, w_i) + backend.dot(h, w_h) + c\n                return y, [y]\n\n            return simple_rnn_add_constant\n\n        kwargs_list = [\n            {\'go_backwards\': False, \'mask\': None},\n            {\'go_backwards\': True, \'mask\': None},\n            {\'go_backwards\': False, \'mask\': mask},\n            {\'go_backwards\': True, \'mask\': mask},\n        ]\n        for kwargs in kwargs_list:\n            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n                                step_function_np=get_step_function(KNP, wi, wh),\n                                inputs_np=x,\n                                initial_states_np=[h0],\n                                mask_np=kwargs.pop(\'mask\', None),\n                                constants_np=[c],\n                                **kwargs)\n\n    def test_rnn_output_and_state_masking_independent(self):\n        num_samples = 2\n        num_timesteps = 4\n        state_and_io_size = 5\n        mask_last_num_timesteps = 2  # for second sample only\n\n        # a step function that just outputs inputs,\n        # but increments states +1 per timestep\n        def step_function(inputs, states):\n            return inputs, [s + 1 for s in states]\n\n        inputs_vals = np.random.random(\n            (num_samples, num_timesteps, state_and_io_size))\n        initial_state_vals = np.random.random((num_samples, state_and_io_size))\n        # masking of two last timesteps for second sample only\n        mask_vals = np.ones((num_samples, num_timesteps))\n        mask_vals[1, -mask_last_num_timesteps:] = 0\n\n        # outputs expected to be same as inputs for the first sample\n        expected_outputs = inputs_vals.copy()\n        # but for the second sample all outputs in masked region should be the same\n        # as last output before masked region\n        expected_outputs[1, -mask_last_num_timesteps:] = expected_outputs[\n            1, -(mask_last_num_timesteps + 1)]\n\n        expected_state = initial_state_vals.copy()\n        # first state should be incremented for every timestep (no masking)\n        expected_state[0] += num_timesteps\n        # second state should not be incremented for last two timesteps\n        expected_state[1] += (num_timesteps - mask_last_num_timesteps)\n\n        # verify same expected output for `unroll=true/false`\n        inputs = K.constant(inputs_vals)\n        initial_states = [K.constant(initial_state_vals)]\n        mask = K.constant(mask_vals)\n        for unroll in [True, False]:\n            last_output, outputs, last_states = K.rnn(\n                step_function,\n                inputs,\n                initial_states,\n                mask=mask,\n                unroll=unroll,\n                input_length=num_timesteps if unroll else None)\n\n            assert_allclose(K.eval(outputs), expected_outputs)\n            assert_allclose(K.eval(last_states[0]), expected_state)\n\n    @pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported\')\n    def test_rnn_output_num_dim_larger_than_2_masking(self):\n        num_samples = 3\n        num_timesteps = 4\n        num_features = 5\n\n        def step_function(inputs, states):\n            outputs = K.tile(K.expand_dims(inputs), [1, 1, 2])\n            return outputs, states\n\n        inputs_vals = np.random.random((num_samples, num_timesteps, num_features))\n        initial_state_vals = np.random.random((num_samples, 6))\n        mask_vals = np.ones((num_samples, num_timesteps))\n        mask_vals[-1, -1] = 0  # final timestep masked for last sample\n\n        expected_outputs = np.repeat(inputs_vals[..., None], repeats=2, axis=-1)\n        # for the last sample, the final timestep (in masked region) should be the\n        # same as the second to final output (before masked region)\n        expected_outputs[-1, -1] = expected_outputs[-1, -2]\n\n        inputs = K.constant(inputs_vals)\n        initial_states = [K.constant(initial_state_vals)]\n        mask = K.constant(mask_vals)\n        for unroll in [True, False]:\n            last_output, outputs, last_states = K.rnn(\n                step_function,\n                inputs,\n                initial_states,\n                mask=mask,\n                unroll=unroll,\n                input_length=num_timesteps if unroll else None)\n\n            assert_allclose(K.eval(outputs), expected_outputs)\n\n    @pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported\')\n    def test_rnn_state_num_dim_larger_than_2_masking(self):\n        num_samples = 3\n        num_timesteps = 4\n\n        def step_function(inputs, states):\n            return inputs, [s + 1 for s in states]\n\n        inputs_vals = np.random.random((num_samples, num_timesteps, 5))\n        initial_state_vals = np.random.random((num_samples, 6, 7))\n        mask_vals = np.ones((num_samples, num_timesteps))\n        mask_vals[0, -2:] = 0  # final two timesteps masked for first sample\n\n        expected_last_state = initial_state_vals.copy()\n        expected_last_state[0] += (num_timesteps - 2)\n        expected_last_state[1:] += num_timesteps\n\n        inputs = K.variable(inputs_vals)\n        initial_states = [K.variable(initial_state_vals)]\n        mask = K.variable(mask_vals)\n        for unroll in [True, False]:\n            last_output, outputs, last_states = K.rnn(\n                step_function,\n                inputs,\n                initial_states,\n                mask=mask,\n                unroll=unroll,\n                input_length=num_timesteps if unroll else None)\n\n            # not updated last timestep:\n            assert_allclose(K.eval(last_states[0]), expected_last_state)\n\n    @pytest.mark.parametrize(\'shape\', [(3, ), (1, 3), (2, 1), (4, 2), (4, 2, 3)])\n    def test_logsumexp(self, shape):\n        check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=None)\n        check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=0)\n        check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=-1)\n        check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=-1,\n                                      keepdims=True)\n        if len(shape) > 1:\n            check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=1)\n            check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=1,\n                                          keepdims=True)\n        if len(shape) > 2:\n            check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=[1, -1])\n            check_single_tensor_operation(\'logsumexp\', shape, WITH_NP, axis=[1, -1],\n                                          keepdims=True)\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'The optimization is applied only with TensorFlow.\')\n    def test_logsumexp_optim(self):\n        \'\'\'\n        Check if optimization works.\n        \'\'\'\n        x_np = np.array([1e+4, 1e-4])\n        result = K.eval(K.logsumexp(K.variable(x_np), axis=0))\n        assert_allclose(result, 1e4, rtol=1e-5)\n\n    def test_switch(self):\n        # scalar\n        val = np.random.random()\n        z_list = []\n        for k in WITH_NP:\n            x = k.variable(val)\n            x = k.switch(k.greater_equal(x, 0.5), x * 0.1, x * 0.2)\n            z_list.append(k.eval(x))\n        assert_list_pairwise(z_list)\n        # non scalar\n        shapes = []\n        shapes.append([(4, 3, 2), (4, 3, 2), (4, 3, 2)])\n        for s in shapes:\n            z_list = []\n            arrays = list(map(np.random.random, s))\n            for k in WITH_NP:\n                x, then_expr, else_expr = map(k.variable, arrays)\n                cond = k.greater_equal(x, 0.5)\n                z_list.append(k.eval(k.switch(cond, then_expr, else_expr)))\n            assert_list_pairwise(z_list)\n\n    def test_dropout(self):\n        val = np.random.random((100, 100))\n        z_list = [k.eval(k.dropout(k.variable(val), level=0.2))\n                  for k in WITH_NP]\n        assert_list_pairwise(z_list, allclose=False)\n        # dropout patterns are different, only check mean\n        for i in range(len(z_list) - 1):\n            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) < 0.05\n\n        z_list = [k.eval(k.dropout(k.variable(val), level=0.2,\n                                   noise_shape=list(val.shape)))\n                  for k in WITH_NP]\n        assert_list_pairwise(z_list, allclose=False)\n        # dropout patterns are different, only check mean\n        for i in range(len(z_list) - 1):\n            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) < 0.05\n\n        # Test invalid use cases\n        with pytest.raises(ValueError):\n            z = K.dropout(K.variable(val), level=-0.5)\n\n    @pytest.mark.parametrize(\'alpha,max_value,threshold\', [\n        (0.0, None, 0.0),  # standard relu\n        (0.1, None, 0.0),  # set alpha only\n        (0.0, 5.0, 0.0),   # set max_value only\n        (0.0, None, 0.8),  # set threshold only\n        (0.1, 5.0, 0.0),   # set alpha and max_value\n        (0.1, None, 0.8),  # set alpha and threshold\n        (0.0, 5.0, 0.8),   # set max_value and threshold\n        (0.1, 5.0, 0.8),   # set all\n        (0.1, 0.0, 0.8),   # max_value is zero\n        (0.1, 5.0, -2.8),  # threshold is negative\n        (0.1, 9.0, 0.8),   # max_value > 6\n    ])\n    def test_relu(self, alpha, max_value, threshold):\n        check_single_tensor_operation(\'relu\', (4, 2), WITH_NP, alpha=alpha,\n                                      max_value=max_value, threshold=threshold)\n\n    def test_nn_operations(self):\n        check_single_tensor_operation(\'softsign\', (4, 10), WITH_NP)\n        check_single_tensor_operation(\'softplus\', (4, 10), WITH_NP)\n        check_single_tensor_operation(\'elu\', (4, 10), WITH_NP, alpha=0.5)\n\n        check_single_tensor_operation(\'sigmoid\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'hard_sigmoid\', (4, 2), WITH_NP)\n        check_single_tensor_operation(\'tanh\', (4, 2), WITH_NP)\n\n        check_single_tensor_operation(\'softmax\', (4, 10), WITH_NP)\n        check_single_tensor_operation(\'softmax\', (4, 5, 3), WITH_NP, axis=1)\n        check_single_tensor_operation(\'softmax\', (4, 5, 3, 10), WITH_NP, axis=2)\n\n        check_single_tensor_operation(\'l2_normalize\', (4, 3), WITH_NP, axis=-1)\n        check_single_tensor_operation(\'l2_normalize\', (4, 3), WITH_NP, axis=1)\n\n    def test_crossentropy(self):\n        # toy label matrix (4 samples, 2 classes)\n        label = np.array([[.4, .6], [.3, .7], [.1, .9], [.2, .8]], dtype=np.float32)\n        binary_targets = np.array([[.3, .7], [.2, .8], [.4, .6], [.1, .9]],\n                                  dtype=np.float32)\n        categorical_targets = np.array([[1, 0], [1, 0], [0, 1], [0, 1]],\n                                       dtype=np.float32)\n        check_two_tensor_operation(\n            \'binary_crossentropy\', label, binary_targets, WITH_NP)\n        check_two_tensor_operation(\'binary_crossentropy\', label, (4, 2),\n                                   WITH_NP, from_logits=True)\n        check_two_tensor_operation(\n            \'categorical_crossentropy\', label, categorical_targets,\n            WITH_NP, cntk_two_dynamicity=True)\n        check_two_tensor_operation(\'categorical_crossentropy\', label, (4, 2),\n                                   WITH_NP, cntk_two_dynamicity=True,\n                                   from_logits=True)\n\n        # toy label matrix (2 samples, 3 classes)\n        label = np.array([[.4, .1, .5], [.2, .6, .2]], dtype=np.float32)\n        categorical_targets = np.array([[0, 1, 0], [1, 0, 0]], dtype=np.float32)\n        check_two_tensor_operation(\n            \'categorical_crossentropy\', label, categorical_targets,\n            WITH_NP, cntk_two_dynamicity=True)\n        check_two_tensor_operation(\'categorical_crossentropy\', label, (2, 3),\n                                   WITH_NP, cntk_two_dynamicity=True,\n                                   from_logits=True)\n\n    def test_in_top_k(self):\n        batch_size = 20\n        num_classes = 10\n\n        # Random prediction test case\n        predictions = np.random.random((batch_size, num_classes)).astype(\'float32\')\n        targets = np.random.randint(num_classes, size=batch_size, dtype=\'int32\')\n\n        # (k == 0 or k > num_classes) does not raise an error\n        # but just return an unmeaningful tensor.\n        for k in range(1, 2 if K.backend() == \'cntk\' else (num_classes + 1)):\n            z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype=\'float32\'),\n                                        b.variable(targets, dtype=\'int32\'), k))\n                      for b in WITH_NP]\n            assert_list_pairwise(z_list)\n\n        # Identical prediction test case:\n        # randomly set half of the predictions to an identical value\n        num_identical = num_classes // 2\n        for i in range(batch_size):\n            idx_identical = np.random.choice(num_classes,\n                                             size=num_identical, replace=False)\n            predictions[i, idx_identical] = predictions[i, 0]\n        targets = np.zeros(batch_size, dtype=\'int32\')\n\n        for k in range(1, 2 if K.backend() == \'cntk\' else (num_classes + 1)):\n            z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype=\'float32\'),\n                                        b.variable(targets, dtype=\'int32\'), k))\n                      for b in WITH_NP]\n            assert_list_pairwise(z_list)\n\n    @pytest.mark.parametrize(\'op,input_shape,kernel_shape,padding,data_format\', [\n        (\'conv1d\', (2, 8, 2), (3, 2, 3), \'same\', \'channels_last\'),\n        (\'conv1d\', (1, 8, 2), (3, 2, 3), \'valid\', \'channels_last\'),\n        (\'conv1d\', (1, 2, 8), (3, 2, 3), \'valid\', \'channels_first\'),\n        (\'conv2d\', (2, 3, 4, 5), (3, 3, 3, 2), \'same\', \'channels_first\'),\n        (\'conv2d\', (2, 3, 5, 6), (4, 3, 3, 4), \'valid\', \'channels_first\'),\n        (\'conv2d\', (1, 6, 5, 3), (3, 4, 3, 2), \'valid\', \'channels_last\'),\n        (\'conv2d\', (1, 7, 6, 3), (3, 3, 3, 4), \'same\', \'channels_last\'),\n        (\'conv3d\', (2, 3, 4, 5, 4), (3, 3, 3, 3, 4), \'same\', \'channels_first\'),\n        (\'conv3d\', (2, 3, 5, 4, 6), (3, 2, 4, 3, 4), \'valid\', \'channels_first\'),\n        (\'conv3d\', (1, 2, 2, 2, 1), (2, 2, 2, 1, 1), \'valid\', \'channels_last\'),\n        (\'conv3d\', (1, 3, 5, 4, 2), (3, 3, 3, 2, 3), \'same\', \'channels_last\'),\n    ])\n    def test_conv(self, op, input_shape, kernel_shape, padding, data_format):\n        check_two_tensor_operation(\n            op, input_shape, kernel_shape, WITH_NP,\n            padding=padding, data_format=data_format,\n            cntk_dynamicity=True)\n\n    @pytest.mark.parametrize(\n        \'op,input_shape,kernel_shape,output_shape,padding,data_format\', [\n            (\'conv2d_transpose\', (2, 5, 6, 3), (3, 3, 2, 3), (2, 5, 6, 2),\n             \'same\', \'channels_last\'),\n            (\'conv2d_transpose\', (2, 3, 8, 9), (3, 3, 2, 3), (2, 2, 8, 9),\n             \'same\', \'channels_first\'),\n        ])\n    def test_conv_transpose(self,\n                            op,\n                            input_shape,\n                            kernel_shape,\n                            output_shape,\n                            padding,\n                            data_format):\n        check_two_tensor_operation(\n            op, input_shape, kernel_shape, WITH_NP,\n            output_shape=output_shape, padding=padding, data_format=data_format,\n            cntk_dynamicity=True)\n\n    @pytest.mark.skipif((K.backend() == \'cntk\' and KC.dev.type() == 0),\n                        reason=\'cntk only supports dilated conv on GPU\')\n    @pytest.mark.parametrize(\n        \'op,input_shape,kernel_shape,padding,data_format,dilation_rate\', [\n            (\'conv1d\', (2, 8, 3), (4, 3, 2), \'valid\', \'channels_last\', 2),\n            (\'conv1d\', (2, 3, 8), (4, 3, 2), \'valid\', \'channels_first\', 2),\n            (\'conv2d\', (2, 8, 9, 3), (3, 3, 3, 2),\n             \'same\', \'channels_last\', (2, 2)),\n            (\'conv2d\', (2, 3, 9, 8), (4, 3, 3, 4),\n             \'valid\', \'channels_first\', (2, 2)),\n            (\'conv3d\', (2, 5, 4, 6, 3), (2, 2, 3, 3, 4),\n             \'valid\', \'channels_last\', (2, 2, 2)),\n            (\'conv3d\', (2, 3, 5, 4, 6), (2, 2, 3, 3, 4),\n             \'same\', \'channels_first\', (2, 2, 2)),\n        ])\n    def test_dilated_conv(self,\n                          op,\n                          input_shape,\n                          kernel_shape,\n                          padding,\n                          data_format,\n                          dilation_rate):\n        check_two_tensor_operation(\n            op, input_shape, kernel_shape, WITH_NP,\n            padding=padding, data_format=data_format,\n            dilation_rate=dilation_rate, cntk_dynamicity=True)\n\n    @pytest.mark.skipif((K.backend() == \'cntk\' and KC.dev.type() == 0),\n                        reason=\'cntk only supports dilated conv transpose on GPU\')\n    @pytest.mark.parametrize(\n        \'op,input_shape,kernel_shape,output_shape,padding,data_format,dilation_rate\',\n        [\n            (\'conv2d_transpose\', (2, 5, 6, 3), (3, 3, 2, 3), (2, 5, 6, 2),\n             \'same\', \'channels_last\', (2, 2)),\n            (\'conv2d_transpose\', (2, 3, 8, 9), (3, 3, 2, 3), (2, 2, 8, 9),\n             \'same\', \'channels_first\', (2, 2)),\n        ])\n    def test_dilated_conv_transpose(self,\n                                    op,\n                                    input_shape,\n                                    kernel_shape,\n                                    output_shape,\n                                    padding,\n                                    data_format,\n                                    dilation_rate):\n        check_two_tensor_operation(\n            op, input_shape, kernel_shape, WITH_NP, output_shape=output_shape,\n            padding=padding, data_format=data_format, dilation_rate=dilation_rate,\n            cntk_dynamicity=True)\n\n    @pytest.mark.parametrize(\'op,input_shape,kernel_shape,padding,data_format\', [\n        (\'depthwise_conv2d\', (2, 3, 4, 5), (3, 3, 3, 2), \'same\', \'channels_first\'),\n        (\'depthwise_conv2d\', (2, 3, 5, 6), (4, 3, 3, 4), \'valid\', \'channels_first\'),\n        (\'depthwise_conv2d\', (1, 6, 5, 3), (3, 4, 3, 2), \'valid\', \'channels_last\'),\n        (\'depthwise_conv2d\', (1, 7, 6, 3), (3, 3, 3, 4), \'same\', \'channels_last\'),\n    ])\n    def test_depthwise_conv(self,\n                            op,\n                            input_shape,\n                            kernel_shape,\n                            padding,\n                            data_format):\n        check_two_tensor_operation(\n            op, input_shape, kernel_shape, WITH_NP,\n            padding=padding, data_format=data_format,\n            cntk_dynamicity=True)\n\n    @pytest.mark.parametrize(\n        \'op,input_shape,pool_size,strides,padding,data_format,pool_mode\', [\n            (\'pool2d\', (2, 3, 7, 7), (3, 3), (1, 1),\n             \'same\', \'channels_first\', \'avg\'),\n            (\'pool2d\', (3, 3, 8, 5), (2, 3), (1, 1),\n             \'valid\', \'channels_first\', \'max\'),\n            (\'pool2d\', (2, 9, 5, 3), (3, 2), (1, 1),\n             \'valid\', \'channels_last\', \'avg\'),\n            (\'pool2d\', (3, 6, 7, 3), (3, 3), (1, 1),\n             \'same\', \'channels_last\', \'max\'),\n            (\'pool3d\', (2, 3, 7, 7, 7), (3, 3, 3), (1, 1, 1),\n             \'same\', \'channels_first\', \'avg\'),\n            (\'pool3d\', (3, 3, 8, 5, 9), (2, 3, 2), (1, 1, 1),\n             \'valid\', \'channels_first\', \'max\'),\n            (\'pool3d\', (2, 8, 9, 5, 3), (3, 2, 3), (1, 1, 1),\n             \'valid\', \'channels_last\', \'avg\'),\n            (\'pool3d\', (3, 5, 6, 7, 3), (3, 3, 3), (1, 1, 1),\n             \'same\', \'channels_last\', \'max\'),\n        ])\n    def test_pool(self,\n                  op,\n                  input_shape,\n                  pool_size,\n                  strides,\n                  padding,\n                  data_format,\n                  pool_mode):\n        check_single_tensor_operation(\n            op, input_shape, WITH_NP,\n            pool_size=pool_size, strides=strides,\n            padding=padding, data_format=data_format, pool_mode=pool_mode,\n            cntk_dynamicity=True)\n\n    @pytest.mark.parametrize(\n        \'op,input_shape,kernel_shape,depth_multiplier,padding,data_format\', [\n            (\'separable_conv1d\', (2, 8, 2), (3,), 1, \'same\', \'channels_last\'),\n            (\'separable_conv1d\', (1, 8, 2), (3,), 2, \'valid\', \'channels_last\'),\n            (\'separable_conv2d\', (2, 3, 4, 5), (3, 3), 1, \'same\', \'channels_first\'),\n            (\'separable_conv2d\', (2, 3, 5, 6), (4, 3), 2, \'valid\', \'channels_first\'),\n            (\'separable_conv2d\', (1, 6, 5, 3), (3, 4), 1, \'valid\', \'channels_last\'),\n            (\'separable_conv2d\', (1, 7, 6, 3), (3, 3), 2, \'same\', \'channels_last\'),\n        ])\n    def test_separable_conv(self,\n                            op,\n                            input_shape,\n                            kernel_shape,\n                            depth_multiplier,\n                            padding,\n                            data_format):\n        if data_format == \'channels_first\':\n            input_depth = input_shape[1]\n        else:\n            input_depth = input_shape[-1]\n        _, x = parse_shape_or_val(input_shape)\n        _, depthwise = parse_shape_or_val(kernel_shape +\n                                          (input_depth, depth_multiplier))\n        _, pointwise = parse_shape_or_val((1,) * len(kernel_shape) +\n                                          (input_depth * depth_multiplier, 7))\n        y1 = KNP.separable_conv(x, depthwise, pointwise,\n                                padding=padding, data_format=data_format)\n        if K.backend() == \'cntk\':\n            _, cntk_func = cntk_func_tensors(\n                op, [input_shape, depthwise, pointwise],\n                padding=padding, data_format=data_format)\n            y2 = cntk_func([x])[0]\n        else:\n            y2 = K.eval(getattr(K, op)(\n                K.variable(x),\n                K.variable(depthwise), K.variable(pointwise),\n                padding=padding, data_format=data_format))\n        assert_allclose(y1, y2, atol=1e-05)\n\n    def test_random_normal(self):\n        # TODO: make this a parameterized test\n        for mean, std in [(0., 1.), (-10., 5.)]:\n            rand = K.eval(K.random_normal((200, 200),\n                                          mean=mean,\n                                          stddev=std))\n            assert rand.shape == (200, 200)\n            assert np.abs(np.mean(rand) - mean) < std * 0.015\n            assert np.abs(np.std(rand) - std) < std * 0.015\n\n    def test_random_uniform(self):\n        min_val = -1.\n        max_val = 1.\n        rand = K.eval(K.random_uniform((200, 200), min_val, max_val))\n        assert rand.shape == (200, 200)\n        assert np.abs(np.mean(rand)) < 0.015\n        assert max_val - 0.015 < np.max(rand) <= max_val\n        assert min_val + 0.015 > np.min(rand) >= min_val\n\n    def test_random_binomial(self):\n        p = 0.5\n        rand = K.eval(K.random_binomial((200, 200), p))\n        assert rand.shape == (200, 200)\n        assert np.abs(np.mean(rand) - p) < 0.015\n        assert np.max(rand) == 1\n        assert np.min(rand) == 0\n\n    def test_truncated_normal(self):\n        mean = 0.\n        std = 1.\n        min_val = -2.\n        max_val = 2.\n        rand = K.eval(K.truncated_normal((200, 200),\n                                         mean=mean,\n                                         stddev=std))\n        assert rand.shape == (200, 200)\n        assert np.abs(np.mean(rand) - mean) < 0.016\n        assert np.max(rand) <= max_val\n        assert np.min(rand) >= min_val\n\n        # assumption in initializers.VarianceScaling\n        assert np.abs(np.std(rand) - std * 0.87962) < 0.015\n\n    def test_conv_invalid_use(self):\n        dummy_x_1d = K.variable(np.ones((4, 8, 2)))\n        dummy_w_1d = K.variable(np.ones((3, 2, 3)))\n        dummy_x_2d = K.variable(np.ones((2, 3, 4, 5)))\n        dummy_w_2d = K.variable(np.ones((2, 2, 3, 4)))\n        dummy_x_3d = K.variable(np.ones((2, 3, 4, 5, 4)))\n        dummy_w_3d = K.variable(np.ones((2, 2, 2, 3, 4)))\n        dummy_w1x1_2d = K.variable(np.ones((1, 1, 12, 7)))\n\n        with pytest.raises(ValueError):\n            K.conv1d(dummy_x_1d, dummy_w_1d, data_format=\'channels_middle\')\n\n        with pytest.raises(ValueError):\n            K.conv2d(dummy_x_2d, dummy_w_2d, data_format=\'channels_middle\')\n\n        with pytest.raises(ValueError):\n            K.conv3d(dummy_x_3d, dummy_w_3d, data_format=\'channels_middle\')\n\n        with pytest.raises(ValueError):\n            K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n                               data_format=\'channels_middle\')\n\n        with pytest.raises(ValueError):\n            K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n                               data_format=\'channels_middle\')\n\n        if K.backend() == \'cntk\':\n            with pytest.raises(ValueError):\n                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n                                   dilation_rate=(1, 2))\n            with pytest.raises(ValueError):\n                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n                                   strides=(2, 2), dilation_rate=(1, 2))\n            with pytest.raises(ValueError):\n                K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n                                   dilation_rate=(1, 2))\n            with pytest.raises(ValueError):\n                K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n                                   strides=(2, 2), dilation_rate=(1, 2))\n\n    def test_pooling_invalid_use(self):\n        for (input_shape, pool_size) in zip([(5, 10, 12, 3), (5, 10, 12, 6, 3)],\n                                            [(2, 2), (2, 2, 2)]):\n            x = K.variable(np.random.random(input_shape))\n            if len(pool_size) == 2:\n                with pytest.raises(ValueError):\n                    K.pool2d(x, pool_size=pool_size, data_format=\'channels_middle\')\n                with pytest.raises(ValueError):\n                    K.pool2d(x, pool_size=pool_size, padding=\'twice\')\n                with pytest.raises(ValueError):\n                    K.pool2d(x, pool_size=pool_size, pool_mode=\'median\')\n            else:\n                with pytest.raises(ValueError):\n                    K.pool3d(x, pool_size=pool_size, data_format=\'channels_middle\')\n                with pytest.raises(ValueError):\n                    K.pool3d(x, pool_size=pool_size, padding=\'twice\')\n                with pytest.raises(ValueError):\n                    K.pool3d(x, pool_size=pool_size, pool_mode=\'median\')\n\n    def test_resize_images(self):\n        for data_format in [\'channels_first\', \'channels_last\']:\n            shape = (5, 5)\n            if data_format == \'channels_first\':\n                x_shape = (2, 3) + shape\n            elif data_format == \'channels_last\':\n                x_shape = (2,) + shape + (3,)\n            check_single_tensor_operation(\'resize_images\', x_shape,\n                                          WITH_NP, cntk_dynamicity=True,\n                                          height_factor=2,\n                                          width_factor=2,\n                                          data_format=data_format)\n\n        # Test invalid use cases\n        xval = np.random.random(x_shape)\n        with pytest.raises(ValueError):\n            K.resize_images(K.variable(xval), 2, 2,\n                            data_format=\'channels_middle\')\n\n    @staticmethod\n    def _helper_bilinear(data_format, height_factor, width_factor):\n        x_shape = (2, 3, 4, 5)\n        check_single_tensor_operation(\'resize_images\', x_shape,\n                                      [KTF, KTH],\n                                      height_factor=height_factor,\n                                      width_factor=width_factor,\n                                      data_format=data_format,\n                                      interpolation=\'bilinear\')\n\n    @pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported.\')\n    @pytest.mark.parametrize(\'data_format\', [\'channels_first\', \'channels_last\'])\n    def test_resize_images_bilinear(self, data_format):\n        self._helper_bilinear(data_format, 2, 2)\n        with pytest.raises(NotImplementedError):\n            self._helper_bilinear(data_format, 4, 4)\n\n    def test_resize_volumes(self):\n        for data_format in [\'channels_first\', \'channels_last\']:\n            shape = (5, 5, 5)\n            if data_format == \'channels_first\':\n                x_shape = (2, 3) + shape\n            elif data_format == \'channels_last\':\n                x_shape = (2,) + shape + (3,)\n            check_single_tensor_operation(\'resize_volumes\', x_shape,\n                                          WITH_NP, cntk_dynamicity=True,\n                                          depth_factor=2,\n                                          height_factor=2,\n                                          width_factor=2,\n                                          data_format=data_format)\n\n        # Test invalid use cases\n        xval = np.random.random(x_shape)\n        with pytest.raises(ValueError):\n            K.resize_volumes(K.variable(xval), 2, 2, 2,\n                             data_format=\'channels_middle\')\n\n    def test_temporal_padding(self):\n        check_single_tensor_operation(\'temporal_padding\', (4, 3, 3),\n                                      WITH_NP)\n        check_single_tensor_operation(\'temporal_padding\', (2, 3, 4),\n                                      WITH_NP, padding=(1, 2))\n\n    def test_spatial_2d_padding(self):\n        padding = ((1, 2), (2, 1))\n        for data_format in [\'channels_first\', \'channels_last\']:\n            shape = (5, 5)\n            if data_format == \'channels_first\':\n                x_shape = (1, 3) + shape\n            else:\n                x_shape = (1,) + shape + (3,)\n            check_single_tensor_operation(\'spatial_2d_padding\', x_shape, WITH_NP,\n                                          padding=padding, data_format=data_format)\n        # Check handling of dynamic shapes.\n        if K in [KTF, KTH]:\n            x = K.placeholder(shape=(1, None, None, 1))\n            y = K.spatial_2d_padding(x, padding=padding, data_format=\'channels_last\')\n            assert K.int_shape(y) == (1, None, None, 1)\n\n        # Test invalid use cases\n        xval = np.random.random(x_shape)\n        with pytest.raises(ValueError):\n            K.spatial_2d_padding(K.variable(xval), padding=padding,\n                                 data_format=\'channels_middle\')\n\n    def test_spatial_3d_padding(self):\n        padding = ((1, 2), (2, 1), (1, 2))\n        for data_format in [\'channels_first\', \'channels_last\']:\n            shape = (5, 5, 5)\n            if data_format == \'channels_first\':\n                x_shape = (1, 3) + shape\n            else:\n                x_shape = (1,) + shape + (3,)\n            check_single_tensor_operation(\'spatial_3d_padding\', x_shape, WITH_NP,\n                                          padding=padding, data_format=data_format)\n        # Check handling of dynamic shapes.\n        if K in [KTF, KTH]:\n            x = K.placeholder(shape=(1, None, None, None, 1))\n            y = K.spatial_3d_padding(x, padding=padding, data_format=\'channels_last\')\n            assert K.int_shape(y) == (1, None, None, None, 1)\n\n        # Test invalid use cases\n        xval = np.random.random(x_shape)\n        with pytest.raises(ValueError):\n            K.spatial_3d_padding(K.variable(xval), padding=padding,\n                                 data_format=\'channels_middle\')\n\n    def test_bias_add(self):\n        for data_format in [\'channels_first\', \'channels_last\']:\n            for shape in [(), (3,), (2, 3), (5, 3, 2)]:\n                if data_format == \'channels_first\':\n                    x_shape = (1, 4) + shape\n                else:\n                    x_shape = (1,) + shape + (4,)\n                bias_shape = (4,)\n                check_two_tensor_operation(\'bias_add\', x_shape, bias_shape,\n                                           WITH_NP, cntk_dynamicity=True,\n                                           data_format=data_format)\n\n            if data_format == \'channels_first\':\n                x_shape = (20, 6, 10)\n            else:\n                x_shape = (20, 10, 6)\n            check_two_tensor_operation(\'bias_add\', x_shape, (10, 6),\n                                       WITH_NP, cntk_dynamicity=True,\n                                       data_format=data_format)\n\n        # Test invalid use cases\n        x = K.variable(np.random.random(x_shape))\n        b = K.variable(np.random.random(bias_shape))\n        with pytest.raises(ValueError):\n            K.bias_add(x, b, data_format=\'channels_middle\')\n\n    @pytest.mark.skipif(K.backend() == \'theano\',\n                        reason=\'Theano behaves differently \'\n                               \'because of the broadcast.\')\n    @pytest.mark.parametrize(\'axis\', [1, -1])\n    @pytest.mark.parametrize(\'x_shape\', [(3, 2, 4, 5), (3, 2, 4)])\n    def test_batch_normalization(self, axis, x_shape):\n        other_shape = [1] * len(x_shape)\n        other_shape[axis] = x_shape[axis]\n        other_shape = tuple(other_shape)\n        x_np = np.random.random(x_shape)\n        mean_np = np.random.random(other_shape)\n        var_np = np.random.random(other_shape)\n        beta_np = np.random.random(other_shape)\n        gamma_np = np.random.random(other_shape)\n        output_tensors = []\n        output_arrays = []\n        for k in WITH_NP:\n            x = k.variable(x_np)\n            mean = k.variable(mean_np)\n            var = k.variable(var_np)\n            beta = k.variable(beta_np)\n            gamma = k.variable(gamma_np)\n            output = k.batch_normalization(x, mean, var, beta, gamma, axis=axis)\n            output_tensors.append(output)\n            output_arrays.append(k.eval(output))\n        assert_list_pairwise(output_arrays)\n        assert_list_keras_shape(output_tensors, output_arrays)\n\n    @pytest.mark.skipif(K.backend() != \'theano\',\n                        reason=\'Specific to Theano.\')\n    @pytest.mark.parametrize(\'x_shape\', [(1, 4, 2, 3), (1, 2, 3, 4)])\n    def test_batchnorm_th(self, x_shape):\n        x_val = np.random.random(x_shape).astype(np.float32)\n        x = K.variable(x_val)\n        z, _, _ = K.normalize_batch_in_training(\n            x, None, None, reduction_axes=\'per-activation\')\n        z = K.eval(z)\n        assert z.shape == x_shape\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'Specific to Tensorflow.\')\n    @pytest.mark.parametrize(\'x_shape\', [(1, 4, 2, 3), (1, 2, 3, 4)])\n    def test_batchnorm_tf(self, x_shape):\n        x_val = np.random.random(x_shape).astype(np.float32)\n        x = K.variable(x_val)\n        z, _, _ = K.normalize_batch_in_training(\n            x, None, None, reduction_axes=[0, 1, 2, 3])\n        z = K.eval(z)\n        assert z.shape == x_shape\n\n    @pytest.mark.skipif(K.backend() != \'cntk\', reason=\'Specific to CNTK.\')\n    @pytest.mark.parametrize(\'x_shape\', [(1, 4, 2, 3), (1, 2, 3, 4)])\n    def test_batchnorm_cntk(self, x_shape):\n        x_val = np.random.random(x_shape).astype(np.float32)\n        x = K.placeholder(x_shape)\n        z, _, _ = K.normalize_batch_in_training(\n            x, None, None, reduction_axes=[0, 1, 2, 3])\n        z = K.function([x], [z])([x_val])[0]\n        assert z.shape == x_shape\n\n    # the Theano and TensorFlow CTC code use different methods to ensure\n    # numerical stability.  The Theano code subtracts out the max\n    # before the final log, so the results are different but scale\n    # identically and still train properly\n    @pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported.\')\n    def test_ctc(self):\n        if K.backend() == \'theano\':\n            ref = [1.73308, 3.81351]\n        else:\n            ref = [3.34211, 5.42262]\n        # simplified version of TensorFlow\'s test\n\n        label_lens = np.expand_dims(np.asarray([5, 4]), 1)\n        input_lens = np.expand_dims(np.asarray([5, 5]), 1)  # number of timesteps\n\n        # dimensions are batch x time x categories\n        labels = np.asarray([[0, 1, 2, 1, 0], [0, 1, 1, 0, -1]])\n        inputs = np.asarray(\n            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]],\n             [[0.30176, 0.28562, 0.0831517, 0.0862751, 0.0816851, 0.161508],\n              [0.24082, 0.397533, 0.0557226, 0.0546814, 0.0557528, 0.19549],\n              [0.230246, 0.450868, 0.0389607, 0.038309, 0.0391602, 0.202456],\n              [0.280884, 0.429522, 0.0326593, 0.0339046, 0.0326856, 0.190345],\n              [0.423286, 0.315517, 0.0338439, 0.0393744, 0.0339315, 0.154046]]],\n            dtype=np.float32)\n\n        k_labels = K.variable(labels, dtype=""int32"")\n        k_inputs = K.variable(inputs, dtype=""float32"")\n        k_input_lens = K.variable(input_lens, dtype=""int32"")\n        k_label_lens = K.variable(label_lens, dtype=""int32"")\n        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens,\n                                      k_label_lens))\n        if K.backend() == \'theano\':\n            assert_allclose(res[0, :], ref, atol=1e-05)\n        else:\n            assert_allclose(res[:, 0], ref, atol=1e-05)\n\n        # test when batch_size = 1, that is, one sample only\n        # get only first sample from above test case\n        if K.backend() == \'theano\':\n            ref = [1.73308]\n        else:\n            ref = [3.34211]\n\n        input_lens = np.expand_dims(np.asarray([5]), 1)\n        label_lens = np.expand_dims(np.asarray([5]), 1)\n\n        labels = np.asarray([[0, 1, 2, 1, 0]])\n        inputs = np.asarray(\n            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]]],\n            dtype=np.float32)\n\n        k_labels = K.variable(labels, dtype=""int32"")\n        k_inputs = K.variable(inputs, dtype=""float32"")\n        k_input_lens = K.variable(input_lens, dtype=""int32"")\n        k_label_lens = K.variable(label_lens, dtype=""int32"")\n        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens,\n                                      k_label_lens))\n        if K.backend() == \'theano\':\n            assert_allclose(res[0, :], ref, atol=1e-05)\n        else:\n            assert_allclose(res[:, 0], ref, atol=1e-05)\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'Test adapted from tensorflow.\')\n    def test_ctc_decode_greedy(self):\n        """"""Test two batch entries - best path decoder.""""""\n        max_time_steps = 6\n\n        seq_len_0 = 4\n        input_prob_matrix_0 = np.asarray(\n            [[1.0, 0.0, 0.0, 0.0],  # t=0\n             [0.0, 0.0, 0.4, 0.6],  # t=1\n             [0.0, 0.0, 0.4, 0.6],  # t=2\n             [0.0, 0.9, 0.1, 0.0],  # t=3\n             [0.0, 0.0, 0.0, 0.0],  # t=4 (ignored)\n             [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n            dtype=np.float32)\n\n        seq_len_1 = 5\n        # dimensions are time x depth\n\n        input_prob_matrix_1 = np.asarray(\n            [[0.1, 0.9, 0.0, 0.0],  # t=0\n             [0.0, 0.9, 0.1, 0.0],  # t=1\n             [0.0, 0.0, 0.1, 0.9],  # t=2\n             [0.0, 0.9, 0.1, 0.1],  # t=3\n             [0.9, 0.1, 0.0, 0.0],  # t=4\n             [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n            dtype=np.float32)\n\n        # len max_time_steps array of batch_size x depth matrices\n        inputs = [np.vstack([input_prob_matrix_0[t, :],\n                             input_prob_matrix_1[t, :]])\n                  for t in range(max_time_steps)]\n\n        # change tensorflow order to keras backend order\n        inputs = np.asarray(inputs).transpose((1, 0, 2))\n\n        # batch_size length vector of sequence_lengths\n        input_length = np.array([seq_len_0, seq_len_1], dtype=np.int32)\n\n        decode_pred_np, log_prob_pred_np = KNP.ctc_decode(inputs,\n                                                          input_length, greedy=True)\n        inputs = K.variable(inputs)\n        input_length = K.variable(input_length)\n        decode_pred_tf, log_prob_pred_tf = K.ctc_decode(inputs,\n                                                        input_length, greedy=True)\n\n        assert len(decode_pred_tf) == 1\n\n        decode_pred = K.eval(decode_pred_tf[0])\n        log_prob_pred = K.eval(log_prob_pred_tf)\n\n        assert np.alltrue(decode_pred_np == decode_pred)\n        assert np.allclose(log_prob_pred_np, log_prob_pred)\n\n    @pytest.mark.parametrize(\'shape,start,size\', [\n        ((2, 5), (0, 1), (2, 3)),\n        ((2, 5), (1, 0), (1, 4)),\n        ((3, 2, 3), (1, 1, 0), (1, 1, 3)),\n        ((3, 2, 3), (1, 0, 0), (1, 2, 3)),\n        ((3, 2, 3), (1, 0, 0), (2, 1, 3)),\n    ])\n    def test_slice(self, shape, start, size):\n        check_single_tensor_operation(\'slice\', shape, WITH_NP,\n                                      start=start, size=size)\n        with pytest.raises(ValueError):\n            K.slice(K.variable(np.random.random(shape)),\n                    start=[1, 0, 0, 0], size=size)\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'Beam search is only implemented with \'\n                               \'the TensorFlow backend.\')\n    def test_ctc_decode_beam_search(self):\n        """"""Test one batch, two beams - hibernating beam search.""""""\n\n        depth = 6\n\n        seq_len_0 = 5\n        input_prob_matrix_0 = np.asarray(\n            [[0.30999, 0.309938, 0.0679938, 0.0673362, 0.0708352, 0.173908],\n             [0.215136, 0.439699, 0.0370931, 0.0393967, 0.0381581, 0.230517],\n             [0.199959, 0.489485, 0.0233221, 0.0251417, 0.0233289, 0.238763],\n             [0.279611, 0.452966, 0.0204795, 0.0209126, 0.0194803, 0.20655],\n             [0.51286, 0.288951, 0.0243026, 0.0220788, 0.0219297, 0.129878],\n             # Random entry added in at time=5\n             [0.155251, 0.164444, 0.173517, 0.176138, 0.169979, 0.160671]],\n            dtype=np.float32)\n\n        # Add arbitrary offset - this is fine\n        input_prob_matrix_0 = input_prob_matrix_0 + 2.0\n\n        # len max_time_steps array of batch_size x depth matrices\n        inputs = ([input_prob_matrix_0[t, :][np.newaxis, :]\n                   for t in range(seq_len_0)] +  # Pad to max_time_steps = 8\n                  2 * [np.zeros((1, depth), dtype=np.float32)])\n\n        # Take exponential as we directly apply ctc_decode_beam_search\n        inputs = np.exp(inputs)\n\n        # change tensorflow order to keras backend order\n        inputs = K.variable(inputs.transpose((1, 0, 2)))\n\n        # batch_size length vector of sequence_lengths\n        input_length = K.variable(np.array([seq_len_0], dtype=np.int32))\n        # batch_size length vector of log probabilities\n        log_prob_truth = np.array(\n            [\n                -5.811451,  # output beam 0\n                -6.63339  # output beam 1\n            ],\n            np.float32)[np.newaxis, :]\n\n        decode_truth = [np.array([1, 0]), np.array([[1]])]\n\n        beam_width = 2\n        top_paths = 2\n\n        decode_pred_tf, log_prob_pred_tf = K.ctc_decode(inputs,\n                                                        input_length,\n                                                        greedy=False,\n                                                        beam_width=beam_width,\n                                                        top_paths=top_paths)\n\n        assert len(decode_pred_tf) == top_paths\n\n        log_prob_pred = K.eval(log_prob_pred_tf)\n\n        for i in range(top_paths):\n            assert np.alltrue(decode_truth[i] == K.eval(decode_pred_tf[i]))\n\n        assert np.allclose(log_prob_truth, log_prob_pred)\n\n    @pytest.mark.skipif(K.backend() != \'tensorflow\',\n                        reason=\'Beam search is only implemented with \'\n                               \'the TensorFlow backend.\')\n    def test_ctc_decode_beam_search_no_merge(self):\n        # A simple CTC probability map with some repeating characters,\n        # shape(batch, input_width, char_count)\n        # Without merging should be decoded as: ""AABB"", with merging as: ""AB"".\n        input_prob = np.array([\n            [  # blank, A ,B\n                [0, 0, 1],  # blank\n                [1, 0, 0],  # A\n                [0, 0, 1],  # blank\n                [1, 0, 0],  # A\n                [0, 1, 0],  # B\n                [0, 0, 1],  # blank\n                [0, 1, 0]  # B\n            ]\n        ])\n        input_len = np.array(input_prob.shape[0] * [input_prob.shape[1]])\n\n        def decode(merge_repeated):\n            input_prob_tensor = K.placeholder(shape=(None, None, None),\n                                              dtype=\'float32\')\n            input_len_tensor = K.placeholder(shape=(None), dtype=\'int64\')\n            paths_tensors, _ = K.ctc_decode(input_prob_tensor, input_len_tensor,\n                                            greedy=False, beam_width=1, top_paths=1,\n                                            merge_repeated=merge_repeated)\n            decode_func = K.function([input_prob_tensor, input_len_tensor],\n                                     paths_tensors)\n            paths = decode_func([input_prob, input_len])\n            return paths\n\n        # merged: A B\n        assert np.allclose(decode(merge_repeated=True), [np.array([[0, 1]])])\n        # not merged: A A B B\n        assert np.allclose(decode(merge_repeated=False), [np.array([[0, 0, 1, 1]])])\n\n    def test_one_hot(self):\n        input_length = 10\n        num_classes = 20\n        batch_size = 30\n        indices = np.random.randint(0, num_classes, size=(batch_size, input_length))\n        oh = KNP.one_hot(np.int32(indices), num_classes)\n        koh = K.eval(K.one_hot(K.variable(indices, dtype=\'int32\'), num_classes))\n        assert np.all(koh == oh)\n\n    @pytest.mark.skipif(not supports_sparse,\n                        reason=\'Sparse tensors are not supported in cntk \'\n                               \'and Theano has some dependency issues for sparse.\')\n    def test_sparse_dot(self):\n        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n\n        x_sparse = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n        x_dense = x_sparse.toarray()\n\n        W = np.random.random((5, 4))\n        t_W = K.variable(W)\n        k_s = K.eval(K.dot(K.variable(x_sparse), t_W))\n        k_d = K.eval(K.dot(K.variable(x_dense), t_W))\n\n        assert k_s.shape == k_d.shape\n        assert_allclose(k_s, k_d, atol=1e-05)\n\n    @pytest.mark.skipif(not supports_sparse,\n                        reason=\'Sparse tensors are not supported in cntk \'\n                               \'and Theano has some dependency issues for sparse.\')\n    def test_sparse_concat(self):\n        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n\n        x_sparse_1 = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n\n        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n\n        x_sparse_2 = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n\n        x_dense_1 = x_sparse_1.toarray()\n        x_dense_2 = x_sparse_2.toarray()\n\n        k_s = K.concatenate([K.variable(x_sparse_1), K.variable(x_sparse_2)])\n        assert K.is_sparse(k_s)\n\n        k_s_d = K.eval(k_s)\n\n        k_d = K.eval(K.concatenate([K.variable(x_dense_1), K.variable(x_dense_2)]))\n\n        assert k_s_d.shape == k_d.shape\n        assert_allclose(k_s_d, k_d, atol=1e-05)\n\n    @pytest.mark.parametrize(\'shape,shape2,axis\', [\n        ((5, 2), (7, 2), 0),\n        ((5, 4, 6), (5, 3, 6), 1),\n        ((5, 4, 6, 10), (5, 4, 6, 2), 3),\n        ((5, 4, 6, 3), (5, 4, 6, 2), -1),\n    ])\n    def test_concat_operations(self, shape, shape2, axis):\n        # In stack, each array must have the same shape.\n        check_two_tensor_operation(\'stack\', shape, shape, WITH_NP,\n                                   axis=axis, concat_args=True)\n        check_two_tensor_operation(\'concatenate\', shape, shape2, WITH_NP,\n                                   axis=axis, concat_args=True)\n        check_two_tensor_operation(\'concatenate\', shape, shape2, WITH_NP,\n                                   axis=axis, concat_args=True)\n\n    @pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported.\')\n    def test_map(self):\n        x = np.random.rand(10, 3).astype(np.float32)\n        vx = K.variable(x)\n        kx = K.eval(K.map_fn(K.sum, vx))\n        # make sure we can also walk the indexes in tensorflow which we\n        # can\'t without specifying dtype\n        kx2 = K.eval(K.map_fn(\n            lambda i: K.sum(vx[i]),\n            K.arange(10),\n            dtype=K.floatx()\n        ))\n\n        assert (10,) == kx.shape\n        assert (10,) == kx2.shape\n        assert_allclose(x.sum(axis=1), kx, atol=1e-05)\n        assert_allclose(kx, kx2, atol=1e-05)\n\n    def test_foldl(self):\n        x = np.random.rand(10, 3).astype(np.float32)\n        kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))\n\n        assert (3,) == kx.shape\n        assert_allclose(x.sum(axis=0), kx, atol=1e-05)\n\n    def test_foldr(self):\n        # This test aims to make sure that we walk the array from right to left\n        # and checks it in the following way: multiplying left to right 1e-40\n        # cannot be held into a float32 so it causes an underflow while from\n        # right to left we have no such problem and the result is larger\n        x = np.array([1e-20, 1e-20, 10, 10, 10], dtype=np.float32)\n        vx = K.variable(x)\n        p1 = K.eval(K.foldl(lambda a, b: a * b, vx))\n        p2 = K.eval(K.foldr(lambda a, b: a * b, vx))\n\n        assert p1 < p2\n        assert 9e-38 < p2 <= 1e-37\n\n    @pytest.mark.skipif(K.backend() == \'cntk\',\n                        reason=\'cntk has issues with negative number.\')\n    def test_arange(self):\n        for test_value in (-20, 0, 1, 10):\n            a_list = []\n            dtype_list = []\n            for k in WITH_NP:\n                t = k.arange(test_value)\n                a = k.eval(t)\n                assert np.array_equal(a, np.arange(test_value))\n                dtype_list.append(k.dtype(t))\n                a_list.append(a)\n\n            for i in range(len(a_list) - 1):\n                assert np.array_equal(a_list[i], a_list[i + 1])\n\n        for start, stop, step in ((0, 5, 1), (-5, 5, 2), (0, 1, 2)):\n            a_list = []\n            for k in WITH_NP:\n                a = k.eval(k.arange(start, stop, step))\n                assert np.array_equal(a, np.arange(start, stop, step))\n                a_list.append(a)\n            for i in range(len(a_list) - 1):\n                assert np.array_equal(a_list[i], a_list[i + 1])\n\n        for dtype in (\'int32\', \'int64\', \'float32\', \'float64\'):\n            for k in WITH_NP:\n                t = k.arange(10, dtype=dtype)\n                assert k.dtype(t) == dtype\n\n        start = K.constant(1, dtype=\'int32\')\n        t = K.arange(start)\n        assert len(K.eval(t)) == 1\n\n        start = K.constant(-1, dtype=\'int32\')\n        t = K.arange(start)\n        assert len(K.eval(t)) == 0\n\n    @pytest.mark.parametrize(\'training\', [True, False])\n    def test_in_train_phase(self, training):\n        check_two_tensor_operation(\'in_train_phase\', (3, 3), (2, 2), WITH_NP,\n                                   training=training)\n        check_two_tensor_operation(\'in_train_phase\', (2, 3), (2, 3), WITH_NP,\n                                   training=training)\n\n    @pytest.mark.parametrize(\'training\', [True, False])\n    def test_in_test_phase(self, training):\n        check_two_tensor_operation(\'in_test_phase\', (3, 3), (2, 2), WITH_NP,\n                                   training=training)\n        check_two_tensor_operation(\'in_test_phase\', (2, 3), (2, 3), WITH_NP,\n                                   training=training)\n\n    @pytest.mark.parametrize(\'dtype\', [\'\', \'beerfloat\', 123])\n    def test_setfloatx_incorrect_values(self, dtype):\n        # Keep track of the old value\n        old_floatx = K.floatx()\n        with pytest.raises(ValueError):\n            K.set_floatx(dtype)\n        assert K.floatx() == old_floatx\n\n    @pytest.mark.parametrize(\'dtype\', [\'float16\', \'float32\', \'float64\'])\n    def test_setfloatx_correct_values(self, dtype):\n        # Keep track of the old value\n        old_floatx = K.floatx()\n        # Check correct values\n        K.set_floatx(dtype)\n        assert K.floatx() == dtype\n        # Make sure that changes to the global floatx are effectively\n        # taken into account by the backend.\n        check_dtype(K.variable([10]), dtype)\n        # Restore old value\n        K.set_floatx(old_floatx)\n\n    @pytest.mark.parametrize(\'dtype\', [\'float16\', \'float32\', \'float64\'])\n    def test_dtype(self, dtype):\n        assert K.dtype(K.variable(1, dtype=dtype)) == dtype\n\n    @pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported\')\n    def test_variable_support_bool_dtype(self):\n        assert K.dtype(K.variable(1, dtype=\'int16\')) == \'int16\'\n        assert K.dtype(K.variable(False, dtype=\'bool\')) == \'bool\'\n        with pytest.raises(TypeError):\n            K.variable(\'\', dtype=\'unsupported\')\n\n    @pytest.mark.parametrize(\'shape\', [(4, 2), (2, 3)])\n    def test_clip_supports_tensor_arguments(self, shape):\n        # GitHub issue: 11435\n        _, x = parse_shape_or_val(shape)\n        _, min_val = parse_shape_or_val(shape)\n        max_val = min_val + 1.\n        x_k = K.variable(x)\n        min_val_k = K.variable(min_val)\n        max_val_k = K.variable(max_val)\n        assert np.allclose(K.eval(K.clip(x_k, min_val_k, max_val_k)),\n                           KNP.eval(KNP.clip(x, min_val, max_val)))\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/callbacks/callbacks_test.py,0,"b'import os\nimport multiprocessing\n\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom csv import reader\nfrom csv import Sniffer\nimport shutil\nfrom collections import defaultdict\nfrom keras import optimizers\nfrom keras import initializers\nfrom keras import callbacks\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, add, dot, Lambda, Layer\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalAveragePooling1D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.utils.test_utils import get_test_data\nfrom keras.utils.generic_utils import to_list\nfrom keras.utils.generic_utils import unpack_singleton\nfrom keras import backend as K\nfrom keras.utils import np_utils\n\ntry:\n    from unittest.mock import patch\nexcept ImportError:\n    from mock import patch\n\n\ninput_dim = 2\nnum_hidden = 4\nnum_classes = 2\nbatch_size = 5\ntrain_samples = 20\ntest_samples = 20\n\n\ndef data_generator(x, y, batch_size):\n    x = to_list(x)\n    y = to_list(y)\n    max_batch_index = len(x[0]) // batch_size\n    i = 0\n    while 1:\n        x_batch = [array[i * batch_size: (i + 1) * batch_size] for array in x]\n        x_batch = unpack_singleton(x_batch)\n\n        y_batch = [array[i * batch_size: (i + 1) * batch_size] for array in y]\n        y_batch = unpack_singleton(y_batch)\n        yield x_batch, y_batch\n        i += 1\n        i = i % max_batch_index\n\n\n# Changing the default arguments of get_test_data.\ndef get_data_callbacks(num_train=train_samples,\n                       num_test=test_samples,\n                       input_shape=(input_dim,),\n                       classification=True,\n                       num_classes=num_classes):\n    return get_test_data(num_train=num_train,\n                         num_test=num_test,\n                         input_shape=input_shape,\n                         classification=classification,\n                         num_classes=num_classes)\n\n\nclass Counter(callbacks.Callback):\n    """"""Counts the number of times each callback method was run.\n\n    # Arguments\n        method_counts: dict, contains the counts of time\n            each callback method was run.\n    """"""\n\n    def __init__(self):\n        self.method_counts = defaultdict(int)\n        methods_to_count = [\n            \'on_batch_begin\', \'on_batch_end\', \'on_epoch_begin\', \'on_epoch_end\',\n            \'on_train_batch_begin\', \'on_train_batch_end\',\n            \'on_test_batch_begin\', \'on_test_batch_end\',\n            \'on_predict_batch_begin\', \'on_predict_batch_end\',\n            \'on_train_begin\', \'on_train_end\',\n            \'on_predict_begin\', \'on_predict_end\',\n            \'on_test_begin\', \'on_test_end\',\n        ]\n        for method_name in methods_to_count:\n            setattr(self, method_name,\n                    self.wrap_with_counts(\n                        method_name, getattr(self, method_name)))\n\n    def wrap_with_counts(self, method_name, method):\n\n        def _call_and_count(*args, **kwargs):\n            self.method_counts[method_name] += 1\n            return method(*args, **kwargs)\n\n        return _call_and_count\n\n\nclass TestCallbackCounts(object):\n\n    def _check_counts(self, counter, expected_counts):\n        """"""Checks that counts registered by `counter` are those expected.""""""\n        for method_name, expected_count in expected_counts.items():\n            count = counter.method_counts[method_name]\n            assert count == expected_count, \\\n                \'For method {}: expected {}, got: {}\'.format(\n                    method_name, expected_count, count)\n\n    def _get_model(self):\n        layers = [\n            Dense(10, activation=\'relu\', input_dim=input_dim),\n            Dense(num_classes, activation=\'softmax\')\n        ]\n        model = Sequential(layers=layers)\n        model.compile(optimizer=\'adam\', loss=\'binary_crossentropy\')\n        return model\n\n    def test_callback_hooks_are_called_in_fit(self):\n        np.random.seed(1337)\n        (X_train, y_train), (X_test, y_test) = get_data_callbacks(num_train=10,\n                                                                  num_test=4)\n        y_train = np_utils.to_categorical(y_train)\n        y_test = np_utils.to_categorical(y_test)\n\n        model = self._get_model()\n        counter = Counter()\n        model.fit(X_train, y_train, validation_data=(X_test, y_test),\n                  batch_size=2, epochs=5, callbacks=[counter])\n\n        self._check_counts(\n            counter, {\n                \'on_batch_begin\': 25,\n                \'on_batch_end\': 25,\n                \'on_epoch_begin\': 5,\n                \'on_epoch_end\': 5,\n                \'on_predict_batch_begin\': 0,\n                \'on_predict_batch_end\': 0,\n                \'on_predict_begin\': 0,\n                \'on_predict_end\': 0,\n                \'on_test_batch_begin\': 10,\n                \'on_test_batch_end\': 10,\n                \'on_test_begin\': 5,\n                \'on_test_end\': 5,\n                \'on_train_batch_begin\': 25,\n                \'on_train_batch_end\': 25,\n                \'on_train_begin\': 1,\n                \'on_train_end\': 1,\n            })\n\n    def test_callback_hooks_are_called_in_evaluate(self):\n        np.random.seed(1337)\n        (_, _), (X_test, y_test) = get_data_callbacks(num_test=10)\n\n        y_test = np_utils.to_categorical(y_test)\n\n        model = self._get_model()\n        counter = Counter()\n        model.evaluate(X_test, y_test, batch_size=2, callbacks=[counter])\n        self._check_counts(\n            counter, {\n                \'on_test_batch_begin\': 5,\n                \'on_test_batch_end\': 5,\n                \'on_test_begin\': 1,\n                \'on_test_end\': 1,\n                \'on_batch_begin\': 0,\n                \'on_batch_end\': 0,\n                \'on_epoch_begin\': 0,\n                \'on_epoch_end\': 0,\n                \'on_predict_batch_begin\': 0,\n                \'on_predict_batch_end\': 0,\n                \'on_predict_begin\': 0,\n                \'on_predict_end\': 0,\n                \'on_train_batch_begin\': 0,\n                \'on_train_batch_end\': 0,\n                \'on_train_begin\': 0,\n                \'on_train_end\': 0,\n            })\n\n    def test_callback_hooks_are_called_in_predict(self):\n        np.random.seed(1337)\n        (_, _), (X_test, _) = get_data_callbacks(num_test=10)\n\n        model = self._get_model()\n        counter = Counter()\n        model.predict(X_test, batch_size=2, callbacks=[counter])\n        self._check_counts(\n            counter, {\n                \'on_predict_batch_begin\': 5,\n                \'on_predict_batch_end\': 5,\n                \'on_predict_begin\': 1,\n                \'on_predict_end\': 1,\n                \'on_batch_begin\': 0,\n                \'on_batch_end\': 0,\n                \'on_epoch_begin\': 0,\n                \'on_epoch_end\': 0,\n                \'on_test_batch_begin\': 0,\n                \'on_test_batch_end\': 0,\n                \'on_test_begin\': 0,\n                \'on_test_end\': 0,\n                \'on_train_batch_begin\': 0,\n                \'on_train_batch_end\': 0,\n                \'on_train_begin\': 0,\n                \'on_train_end\': 0,\n            })\n\n    def test_callback_hooks_are_called_in_fit_generator(self):\n        np.random.seed(1337)\n        (X_train, y_train), (X_test, y_test) = get_data_callbacks(num_train=10,\n                                                                  num_test=4)\n        y_train = np_utils.to_categorical(y_train)\n        y_test = np_utils.to_categorical(y_test)\n        train_generator = data_generator(X_train, y_train, batch_size=2)\n        validation_generator = data_generator(X_test, y_test, batch_size=2)\n\n        model = self._get_model()\n        counter = Counter()\n        model.fit_generator(train_generator,\n                            steps_per_epoch=len(X_train) // 2,\n                            epochs=5,\n                            validation_data=validation_generator,\n                            validation_steps=len(X_test) // 2,\n                            callbacks=[counter])\n\n        self._check_counts(\n            counter, {\n                \'on_batch_begin\': 25,\n                \'on_batch_end\': 25,\n                \'on_epoch_begin\': 5,\n                \'on_epoch_end\': 5,\n                \'on_predict_batch_begin\': 0,\n                \'on_predict_batch_end\': 0,\n                \'on_predict_begin\': 0,\n                \'on_predict_end\': 0,\n                \'on_test_batch_begin\': 10,\n                \'on_test_batch_end\': 10,\n                \'on_test_begin\': 5,\n                \'on_test_end\': 5,\n                \'on_train_batch_begin\': 25,\n                \'on_train_batch_end\': 25,\n                \'on_train_begin\': 1,\n                \'on_train_end\': 1,\n            })\n\n    def test_callback_hooks_are_called_in_evaluate_generator(self):\n        np.random.seed(1337)\n        (_, _), (X_test, y_test) = get_data_callbacks(num_test=10)\n        y_test = np_utils.to_categorical(y_test)\n\n        model = self._get_model()\n        counter = Counter()\n        model.evaluate_generator(data_generator(X_test, y_test, batch_size=2),\n                                 steps=len(X_test) // 2, callbacks=[counter])\n        self._check_counts(\n            counter, {\n                \'on_test_batch_begin\': 5,\n                \'on_test_batch_end\': 5,\n                \'on_test_begin\': 1,\n                \'on_test_end\': 1,\n                \'on_batch_begin\': 0,\n                \'on_batch_end\': 0,\n                \'on_epoch_begin\': 0,\n                \'on_epoch_end\': 0,\n                \'on_predict_batch_begin\': 0,\n                \'on_predict_batch_end\': 0,\n                \'on_predict_begin\': 0,\n                \'on_predict_end\': 0,\n                \'on_train_batch_begin\': 0,\n                \'on_train_batch_end\': 0,\n                \'on_train_begin\': 0,\n                \'on_train_end\': 0,\n            })\n\n    def test_callback_hooks_are_called_in_predict_generator(self):\n        np.random.seed(1337)\n        (_, _), (X_test, _) = get_data_callbacks(num_test=10)\n\n        def data_generator(x, batch_size):\n            x = to_list(x)\n            max_batch_index = len(x[0]) // batch_size\n            i = 0\n            while 1:\n                x_batch = [\n                    array[i * batch_size: (i + 1) * batch_size] for array in x]\n                x_batch = unpack_singleton(x_batch)\n\n                yield x_batch\n                i += 1\n                i = i % max_batch_index\n\n        model = self._get_model()\n        counter = Counter()\n        model.predict_generator(data_generator(X_test, batch_size=2),\n                                steps=len(X_test) // 2, callbacks=[counter])\n        self._check_counts(\n            counter, {\n                \'on_predict_batch_begin\': 5,\n                \'on_predict_batch_end\': 5,\n                \'on_predict_begin\': 1,\n                \'on_predict_end\': 1,\n                \'on_batch_begin\': 0,\n                \'on_batch_end\': 0,\n                \'on_epoch_begin\': 0,\n                \'on_epoch_end\': 0,\n                \'on_test_batch_begin\': 0,\n                \'on_test_batch_end\': 0,\n                \'on_test_begin\': 0,\n                \'on_test_end\': 0,\n                \'on_train_batch_begin\': 0,\n                \'on_train_batch_end\': 0,\n                \'on_train_begin\': 0,\n                \'on_train_end\': 0,\n            })\n\n    def test_callback_list_methods(self):\n        counter = Counter()\n        callback_list = callbacks.CallbackList([counter])\n\n        batch = 0\n        callback_list.on_test_batch_begin(batch)\n        callback_list.on_test_batch_end(batch)\n        callback_list.on_predict_batch_begin(batch)\n        callback_list.on_predict_batch_end(batch)\n\n        self._check_counts(\n            counter, {\n                \'on_test_batch_begin\': 1,\n                \'on_test_batch_end\': 1,\n                \'on_predict_batch_begin\': 1,\n                \'on_predict_batch_end\': 1,\n                \'on_predict_begin\': 0,\n                \'on_predict_end\': 0,\n                \'on_batch_begin\': 0,\n                \'on_batch_end\': 0,\n                \'on_epoch_begin\': 0,\n                \'on_epoch_end\': 0,\n                \'on_test_begin\': 0,\n                \'on_test_end\': 0,\n                \'on_train_batch_begin\': 0,\n                \'on_train_batch_end\': 0,\n                \'on_train_begin\': 0,\n                \'on_train_end\': 0,\n            })\n\n\ndef test_TerminateOnNaN():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    cbks = [callbacks.TerminateOnNaN()]\n    model = Sequential()\n    initializer = initializers.Constant(value=1e5)\n    for _ in range(5):\n        model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\',\n                        kernel_initializer=initializer))\n    model.add(Dense(num_classes, activation=\'linear\'))\n    model.compile(loss=\'mean_squared_error\',\n                  optimizer=\'rmsprop\')\n\n    # case 1 fit\n    history = model.fit(X_train, y_train,\n                        batch_size=batch_size,\n                        validation_data=(X_test, y_test),\n                        callbacks=cbks,\n                        epochs=20)\n    loss = history.history[\'loss\']\n    assert len(loss) == 1\n    assert loss[0] == np.inf\n\n    history = model.fit_generator(data_generator(X_train, y_train, batch_size),\n                                  len(X_train),\n                                  validation_data=(X_test, y_test),\n                                  callbacks=cbks,\n                                  epochs=20)\n    loss = history.history[\'loss\']\n    assert len(loss) == 1\n    assert loss[0] == np.inf or np.isnan(loss[0])\n\n\ndef test_stop_training_csv(tmpdir):\n    np.random.seed(1337)\n    fp = str(tmpdir / \'test.csv\')\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    cbks = [callbacks.TerminateOnNaN(), callbacks.CSVLogger(fp)]\n    model = Sequential()\n    for _ in range(5):\n        model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'linear\'))\n    model.compile(loss=\'mean_squared_error\',\n                  optimizer=\'rmsprop\')\n\n    def data_generator():\n        i = 0\n        max_batch_index = len(X_train) // batch_size\n        tot = 0\n        while 1:\n            if tot > 3 * len(X_train):\n                yield (np.ones([batch_size, input_dim]) * np.nan,\n                       np.ones([batch_size, num_classes]) * np.nan)\n            else:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            tot += 1\n            i = i % max_batch_index\n\n    history = model.fit_generator(data_generator(),\n                                  len(X_train) // batch_size,\n                                  validation_data=(X_test, y_test),\n                                  callbacks=cbks,\n                                  epochs=20)\n    loss = history.history[\'loss\']\n    assert len(loss) > 1\n    assert loss[-1] == np.inf or np.isnan(loss[-1])\n\n    values = []\n    with open(fp) as f:\n        for x in reader(f):\n            values.append(x)\n\n    assert \'nan\' in values[-1], \'The last epoch was not logged.\'\n    os.remove(fp)\n\n\ndef test_ModelCheckpoint(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / \'checkpoint.h5\')\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    # case 1\n    monitor = \'val_loss\'\n    save_best_only = False\n    mode = \'auto\'\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'rmsprop\',\n                  metrics=[\'accuracy\'])\n\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 2\n    mode = \'min\'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 3\n    mode = \'max\'\n    monitor = \'val_accuracy\'\n    cbks = [callbacks.ModelCheckpoint(filepath,\n                                      monitor=monitor,\n                                      save_best_only=save_best_only,\n                                      mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 4\n    save_best_only = True\n    cbks = [callbacks.ModelCheckpoint(filepath,\n                                      monitor=monitor,\n                                      save_best_only=save_best_only,\n                                      mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 5\n    save_best_only = False\n    period = 2\n    mode = \'auto\'\n    filepath = \'checkpoint.{epoch:02d}.h5\'\n    cbks = [callbacks.ModelCheckpoint(filepath,\n                                      monitor=monitor,\n                                      save_best_only=save_best_only,\n                                      mode=mode,\n                                      period=period)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=4)\n    assert os.path.isfile(filepath.format(epoch=2))\n    assert os.path.isfile(filepath.format(epoch=4))\n    assert not os.path.exists(filepath.format(epoch=1))\n    assert not os.path.exists(filepath.format(epoch=3))\n    os.remove(filepath.format(epoch=2))\n    os.remove(filepath.format(epoch=4))\n    assert not tmpdir.listdir()\n\n\ndef test_EarlyStopping():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'rmsprop\',\n                  metrics=[\'accuracy\'])\n    mode = \'max\'\n    monitor = \'val_acc\'\n    patience = 0\n    cbks = [callbacks.EarlyStopping(patience=patience,\n                                    monitor=monitor,\n                                    mode=mode)]\n    history = model.fit(X_train, y_train,\n                        batch_size=batch_size,\n                        validation_data=(X_test, y_test),\n                        callbacks=cbks,\n                        epochs=20)\n    mode = \'auto\'\n    monitor = \'val_acc\'\n    patience = 2\n    cbks = [callbacks.EarlyStopping(patience=patience,\n                                    monitor=monitor,\n                                    mode=mode)]\n    history = model.fit(X_train, y_train,\n                        batch_size=batch_size,\n                        validation_data=(X_test, y_test),\n                        callbacks=cbks,\n                        epochs=20)\n\n\ndef test_EarlyStopping_reuse():\n    np.random.seed(1337)\n    patience = 3\n    data = np.random.random((100, 1))\n    labels = np.where(data > 0.5, 1, 0)\n    model = Sequential((\n        Dense(1, input_dim=1, activation=\'relu\'),\n        Dense(1, activation=\'sigmoid\'),\n    ))\n    model.compile(optimizer=\'sgd\',\n                  loss=\'binary_crossentropy\',\n                  metrics=[\'accuracy\'])\n    stopper = callbacks.EarlyStopping(monitor=\'acc\', patience=patience)\n    weights = model.get_weights()\n\n    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)\n    assert len(hist.epoch) >= patience\n\n    # This should allow training to go for at least `patience` epochs\n    model.set_weights(weights)\n    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)\n    assert len(hist.epoch) >= patience\n\n\ndef test_EarlyStopping_patience():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n        def get_weights(self):\n            return []\n\n        def set_weights(self, weights):\n            pass\n\n    early_stop = callbacks.EarlyStopping(monitor=\'val_loss\', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040, 0.1019]\n\n    # Should stop after epoch 3,\n    # as the loss has not improved after patience=2 epochs.\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.on_epoch_end(epoch, logs={\'val_loss\': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    assert epochs_trained == 3\n\n\ndef test_EarlyStopping_baseline():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n        def get_weights(self):\n            return []\n\n        def set_weights(self, weights):\n            pass\n\n    def baseline_tester(acc_levels):\n        early_stop = callbacks.EarlyStopping(monitor=\'val_acc\', baseline=0.75,\n                                             patience=2)\n        early_stop.model = DummyModel()\n        epochs_trained = 0\n        early_stop.on_train_begin()\n        for epoch in range(len(acc_levels)):\n            epochs_trained += 1\n            early_stop.on_epoch_end(epoch, logs={\'val_acc\': acc_levels[epoch]})\n            if early_stop.model.stop_training:\n                break\n        return epochs_trained\n\n    acc_levels = [0.55, 0.76, 0.81, 0.81]\n    baseline_met = baseline_tester(acc_levels)\n    acc_levels = [0.55, 0.74, 0.81, 0.81]\n    baseline_not_met = baseline_tester(acc_levels)\n\n    # All epochs should run because baseline was met in second epoch\n    assert baseline_met == 4\n    # Baseline was not met by second epoch and should stop\n    assert baseline_not_met == 2\n\n\ndef test_EarlyStopping_final_weights():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n            self.weights = -1\n\n        def get_weights(self):\n            return self.weights\n\n        def set_weights(self, weights):\n            self.weights = weights\n\n        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch\n\n    early_stop = callbacks.EarlyStopping(monitor=\'val_loss\', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.model.set_weight_to_epoch(epoch=epoch)\n        early_stop.on_epoch_end(epoch, logs={\'val_loss\': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    # The best configuration is in the epoch 2 (loss = 0.1000),\n    # so with patience=2 we need to end up at epoch 4\n    assert early_stop.model.get_weights() == 4\n\n\ndef test_EarlyStopping_final_weights_when_restoring_model_weights():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n            self.weights = -1\n\n        def get_weights(self):\n            return self.weights\n\n        def set_weights(self, weights):\n            self.weights = weights\n\n        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch\n\n    early_stop = callbacks.EarlyStopping(monitor=\'val_loss\', patience=2,\n                                         restore_best_weights=True)\n    early_stop.model = DummyModel()\n\n    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n\n    # The best configuration is in the epoch 2 (loss = 0.1000).\n\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.model.set_weight_to_epoch(epoch=epoch)\n        early_stop.on_epoch_end(epoch, logs={\'val_loss\': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    # The best configuration is in epoch 2 (loss = 0.1000),\n    # and while patience = 2, we\'re restoring the best weights,\n    # so we end up at the epoch with the best weights, i.e. epoch 2\n    assert early_stop.model.get_weights() == 2\n\n\ndef test_LearningRateScheduler():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'sgd\',\n                  metrics=[\'accuracy\'])\n\n    cbks = [callbacks.LearningRateScheduler(lambda x: 1. / (1. + x))]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)\n    assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()\n\n\ndef test_ReduceLROnPlateau():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n        model.add(Dense(num_classes, activation=\'softmax\'))\n\n        model.compile(loss=\'categorical_crossentropy\',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=[\'accuracy\'])\n        return model\n\n    model = make_model()\n\n    # This should reduce the LR after the first epoch (due to high epsilon).\n    cbks = [callbacks.ReduceLROnPlateau(monitor=\'val_loss\',\n                                        factor=0.1,\n                                        min_delta=10,\n                                        patience=1,\n                                        cooldown=5)]\n    model.fit(X_train, y_train,\n              batch_size=batch_size,\n              validation_data=(X_test, y_test),\n              callbacks=cbks,\n              epochs=5,\n              verbose=2)\n    assert_allclose(\n        float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n\n    model = make_model()\n    cbks = [callbacks.ReduceLROnPlateau(monitor=\'val_loss\', factor=0.1,\n                                        min_delta=0, patience=1, cooldown=5)]\n    model.fit(X_train, y_train,\n              batch_size=batch_size,\n              validation_data=(X_test, y_test),\n              callbacks=cbks,\n              epochs=5,\n              verbose=2)\n    assert_allclose(\n        float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())\n\n\ndef test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor=\'val_loss\',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={\'val_loss\': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0\n\n\ndef test_ReduceLROnPlateau_backwards_compatibility():\n    import warnings\n    with warnings.catch_warnings(record=True) as ws:\n        reduce_on_plateau = callbacks.ReduceLROnPlateau(epsilon=1e-13)\n        # Check if warnings are disabled\n        if os.environ.get(""PYTHONWARNINGS"") != ""ignore"":\n            assert ""`epsilon` argument is deprecated"" in str(ws[0].message)\n    assert not hasattr(reduce_on_plateau, \'epsilon\')\n    assert hasattr(reduce_on_plateau, \'min_delta\')\n    assert reduce_on_plateau.min_delta == 1e-13\n\n\ndef test_CSVLogger(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / \'log.tsv\')\n    sep = \'\\t\'\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n        model.add(Dense(num_classes, activation=\'softmax\'))\n\n        model.compile(loss=\'categorical_crossentropy\',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=[\'accuracy\'])\n        return model\n\n    # case 1, create new file with defined separator\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    assert os.path.isfile(filepath)\n    with open(filepath) as csvfile:\n        dialect = Sniffer().sniff(csvfile.read())\n    assert dialect.delimiter == sep\n    del model\n    del cbks\n\n    # case 2, append data to existing file, skip header\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep, append=True)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    # case 3, reuse of CSVLogger object\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)\n\n    import re\n    with open(filepath) as csvfile:\n        list_lines = csvfile.readlines()\n        for line in list_lines:\n            assert line.count(sep) == 4\n        assert len(list_lines) == 5\n        output = "" "".join(list_lines)\n        assert len(re.findall(\'epoch\', output)) == 1\n\n    os.remove(filepath)\n    assert not tmpdir.listdir()\n\n\ndef test_CallbackValData():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'sgd\',\n                  metrics=[\'accuracy\'])\n\n    cbk = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=[cbk], epochs=1)\n\n    cbk2 = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n    train_generator = data_generator(X_train, y_train, batch_size)\n    model.fit_generator(train_generator, len(X_train), epochs=1,\n                        validation_data=(X_test, y_test),\n                        callbacks=[cbk2])\n\n    # callback validation data should always have x, y, and sample weights\n    assert len(cbk.validation_data) == len(cbk2.validation_data) == 3\n    assert cbk.validation_data[0] is cbk2.validation_data[0]\n    assert cbk.validation_data[1] is cbk2.validation_data[1]\n    assert cbk.validation_data[2].shape == cbk2.validation_data[2].shape\n\n\ndef test_LambdaCallback():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'sgd\',\n                  metrics=[\'accuracy\'])\n\n    # Start an arbitrary process that should run during model training and\n    # be terminated after training has completed.\n    def f():\n        while True:\n            pass\n\n    p = multiprocessing.Process(target=f)\n    p.start()\n    cleanup_callback = callbacks.LambdaCallback(\n        on_train_end=lambda logs: p.terminate())\n\n    cbks = [cleanup_callback]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)\n    p.join()\n    assert not p.is_alive()\n\n\n@pytest.mark.skipif(K.backend() != \'tensorflow\', reason=\'Uses TensorBoard\')\ndef test_TensorBoard_with_ReduceLROnPlateau(tmpdir):\n    import shutil\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / \'logs\')\n\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'binary_crossentropy\',\n                  optimizer=\'sgd\',\n                  metrics=[\'accuracy\'])\n\n    cbks = [\n        callbacks.ReduceLROnPlateau(\n            monitor=\'val_loss\',\n            factor=0.5,\n            patience=4,\n            verbose=1),\n        callbacks.TensorBoard(\n            log_dir=filepath)]\n\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()\n\n\ndef tests_RemoteMonitor():\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'rmsprop\',\n                  metrics=[\'accuracy\'])\n    cbks = [callbacks.RemoteMonitor()]\n\n    with patch(\'requests.post\'):\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n\ndef tests_RemoteMonitorWithJsonPayload():\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation=\'relu\'))\n    model.add(Dense(num_classes, activation=\'softmax\'))\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'rmsprop\',\n                  metrics=[\'accuracy\'])\n    cbks = [callbacks.RemoteMonitor(send_as_json=True)]\n\n    with patch(\'requests.post\'):\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/callbacks/tensorboard_test.py,0,"b""import os\nimport numpy as np\nimport pytest\nimport shutil\n\nfrom keras import callbacks\nfrom keras.models import Sequential, Model\nfrom keras import layers\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom keras.utils.test_utils import get_test_data\nfrom keras.utils.generic_utils import to_list\nfrom keras.utils.generic_utils import unpack_singleton\n\n\ninput_dim = 2\nnum_hidden = 4\nnum_classes = 2\nbatch_size = 5\ntrain_samples = 20\ntest_samples = 20\n\n\nif K.backend() != 'tensorflow':\n    pytestmark = pytest.mark.skip\n\n\ndef data_generator(x, y, batch_size):\n    x = to_list(x)\n    y = to_list(y)\n    max_batch_index = len(x[0]) // batch_size\n    i = 0\n    while 1:\n        x_batch = [array[i * batch_size: (i + 1) * batch_size] for array in x]\n        x_batch = unpack_singleton(x_batch)\n\n        y_batch = [array[i * batch_size: (i + 1) * batch_size] for array in y]\n        y_batch = unpack_singleton(y_batch)\n        yield x_batch, y_batch\n        i += 1\n        i = i % max_batch_index\n\n\n# Changing the default arguments of get_test_data.\ndef get_data_callbacks(num_train=train_samples,\n                       num_test=test_samples,\n                       input_shape=(input_dim,),\n                       classification=True,\n                       num_classes=num_classes):\n    return get_test_data(num_train=num_train,\n                         num_test=num_test,\n                         input_shape=input_shape,\n                         classification=classification,\n                         num_classes=num_classes)\n\n\n@pytest.mark.parametrize('update_freq', ['batch', 'epoch', 9])\ndef test_TensorBoard(tmpdir, update_freq):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    class DummyStatefulMetric(layers.Layer):\n\n        def __init__(self, name='dummy_stateful_metric', **kwargs):\n            super(DummyStatefulMetric, self).__init__(name=name, **kwargs)\n            self.stateful = True\n            self.state = K.variable(value=0, dtype='int32')\n\n        def reset_states(self):\n            pass\n\n        def __call__(self, y_true, y_pred):\n            return self.state\n\n    inp = layers.Input((input_dim,))\n    hidden = layers.Dense(num_hidden, activation='relu')(inp)\n    hidden = layers.Dropout(0.1)(hidden)\n    hidden = layers.BatchNormalization()(hidden)\n    output = layers.Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy', DummyStatefulMetric()])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq=0,\n                          embeddings_freq=0,\n                          write_images=False,\n                          write_grads=False):\n        if embeddings_freq:\n            embeddings_layer_names = ['dense_1']\n            embeddings_data = X_test\n        else:\n            embeddings_layer_names = None\n            embeddings_data = None\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=write_images,\n                                      write_grads=write_grads,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=embeddings_layer_names,\n                                      embeddings_data=embeddings_data,\n                                      update_freq=update_freq)]\n\n    # fit without validation data\n    model.fit(X_train, y_train, batch_size=batch_size,\n              callbacks=callbacks_factory(),\n              epochs=2)\n\n    # fit with validation data and accuracy\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test),\n              callbacks=callbacks_factory(),\n              epochs=2)\n\n    # fit generator without validation data\n    train_generator = data_generator(X_train, y_train, batch_size)\n    model.fit_generator(train_generator, len(X_train), epochs=2,\n                        callbacks=callbacks_factory())\n\n    # fit generator with validation data and accuracy\n    train_generator = data_generator(X_train, y_train, batch_size)\n    model.fit_generator(train_generator, len(X_train), epochs=2,\n                        validation_data=(X_test, y_test),\n                        callbacks=callbacks_factory(histogram_freq=1))\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()\n\n\ndef test_TensorBoard_multi_input_output(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_data_callbacks(\n        input_shape=(input_dim, input_dim))\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    inp1 = layers.Input((input_dim, input_dim))\n    inp2 = layers.Input((input_dim, input_dim))\n    inp_3d = layers.add([inp1, inp2])\n    inp_2d = layers.GlobalAveragePooling1D()(inp_3d)\n    # test a layer with a list of output tensors\n    inp_pair = layers.Lambda(lambda x: x)([inp_3d, inp_2d])\n    hidden = layers.dot(inp_pair, axes=-1)\n    hidden = layers.Dense(num_hidden, activation='relu')(hidden)\n    hidden = layers.Dropout(0.1)(hidden)\n    output1 = layers.Dense(num_classes, activation='softmax')(hidden)\n    output2 = layers.Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=[inp1, inp2], outputs=[output1, output2])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq=0,\n                          embeddings_freq=0,\n                          write_images=False,\n                          write_grads=False):\n        if embeddings_freq:\n            embeddings_layer_names = ['dense_1']\n            embeddings_data = [X_test] * 2\n        else:\n            embeddings_layer_names = None\n            embeddings_data = None\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=write_images,\n                                      write_grads=write_grads,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=embeddings_layer_names,\n                                      embeddings_data=embeddings_data)]\n\n    # fit without validation data\n    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n              callbacks=callbacks_factory(),\n              epochs=3)\n\n    # fit with validation data and accuracy\n    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n              validation_data=([X_test] * 2, [y_test] * 2),\n              callbacks=callbacks_factory(histogram_freq=1),\n              epochs=2)\n\n    train_generator = data_generator([X_train] * 2, [y_train] * 2, batch_size)\n\n    # fit generator without validation data\n    model.fit_generator(train_generator, len(X_train), epochs=2,\n                        callbacks=callbacks_factory())\n\n    # fit generator with validation data and accuracy\n    model.fit_generator(train_generator, len(X_train), epochs=2,\n                        validation_data=([X_test] * 2, [y_test] * 2),\n                        callbacks=callbacks_factory())\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()\n\n\ndef test_TensorBoard_convnet(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    input_shape = (16, 16, 3)\n    (x_train, y_train), (x_test, y_test) = get_data_callbacks(\n        num_train=500,\n        num_test=200,\n        input_shape=input_shape)\n    y_train = np_utils.to_categorical(y_train)\n    y_test = np_utils.to_categorical(y_test)\n\n    model = Sequential([\n        layers.Conv2D(filters=8, kernel_size=3,\n                      activation='relu',\n                      input_shape=input_shape),\n        layers.MaxPooling2D(pool_size=2),\n        layers.Conv2D(filters=4, kernel_size=(3, 3),\n                      activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    tsb = callbacks.TensorBoard(filepath, histogram_freq=1)\n    cbks = [tsb]\n    model.summary()\n    history = model.fit(x_train, y_train, epochs=2, batch_size=16,\n                        validation_data=(x_test, y_test),\n                        callbacks=cbks,\n                        verbose=0)\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()\n\n\ndef test_TensorBoard_display_float_from_logs(tmpdir):\n    filepath = str(tmpdir / 'logs')\n\n    input_shape = (3,)\n    (x_train, y_train), _ = get_data_callbacks(num_train=10,\n                                               num_test=0,\n                                               input_shape=input_shape)\n    y_train = np_utils.to_categorical(y_train)\n\n    model = Sequential([\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop')\n\n    class CustomCallback(callbacks.Callback):\n\n        def on_epoch_end(self, epoch, logs=None):\n            logs['test'] = 0.\n\n    tsb = callbacks.TensorBoard(log_dir=filepath)\n    cbks = [CustomCallback(), tsb]\n    model.fit(x_train, y_train, epochs=2, batch_size=16,\n              callbacks=cbks,\n              verbose=0)\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()\n"""
tests/keras/datasets/datasets_test.py,0,"b""import tempfile\n\nimport numpy as np\nimport pytest\n\nfrom keras.datasets import boston_housing\nfrom keras.datasets import imdb\nfrom keras.datasets import reuters\n\n\n@pytest.fixture\ndef fake_downloaded_boston_path(monkeypatch):\n    num_rows = 100\n    num_cols = 10\n    rng = np.random.RandomState(123)\n\n    x = rng.randint(1, 100, size=(num_rows, num_cols))\n    y = rng.normal(loc=100, scale=15, size=num_rows)\n\n    with tempfile.NamedTemporaryFile('wb', delete=True) as f:\n        np.savez(f, x=x, y=y)\n        monkeypatch.setattr(boston_housing, 'get_file',\n                            lambda *args, **kwargs: f.name)\n        yield f.name\n\n\n@pytest.fixture\ndef fake_downloaded_imdb_path(monkeypatch):\n    train_rows = 100\n    test_rows = 20\n    seq_length = 10\n    rng = np.random.RandomState(123)\n\n    x_train = rng.randint(1, 100, size=(train_rows, seq_length))\n    y_train = rng.binomial(n=1, p=0.5, size=train_rows)\n    x_test = rng.randint(1, 100, size=(test_rows, seq_length))\n    y_test = rng.binomial(n=1, p=0.5, size=test_rows)\n\n    with tempfile.NamedTemporaryFile('wb', delete=True) as f:\n        np.savez(f, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n        monkeypatch.setattr(imdb, 'get_file', lambda *args, **kwargs: f.name)\n        yield f.name\n\n\n@pytest.fixture\ndef fake_downloaded_reuters_path(monkeypatch):\n    num_rows = 100\n    seq_length = 10\n    rng = np.random.RandomState(123)\n\n    x = rng.randint(1, 100, size=(num_rows, seq_length))\n    y = rng.binomial(n=1, p=0.5, size=num_rows)\n\n    with tempfile.NamedTemporaryFile('wb', delete=True) as f:\n        np.savez(f, x=x, y=y)\n        monkeypatch.setattr(reuters, 'get_file', lambda *args, **kwargs: f.name)\n        yield f.name\n\n\ndef test_boston_load_does_not_affect_global_rng(fake_downloaded_boston_path):\n    np.random.seed(1337)\n    before = np.random.randint(0, 100, size=10)\n\n    np.random.seed(1337)\n    boston_housing.load_data(path=fake_downloaded_boston_path, seed=9876)\n    after = np.random.randint(0, 100, size=10)\n\n    assert np.array_equal(before, after)\n\n\ndef test_imdb_load_does_not_affect_global_rng(fake_downloaded_imdb_path):\n    np.random.seed(1337)\n    before = np.random.randint(0, 100, size=10)\n\n    np.random.seed(1337)\n    imdb.load_data(path=fake_downloaded_imdb_path, seed=9876)\n    after = np.random.randint(0, 100, size=10)\n\n    assert np.array_equal(before, after)\n\n\ndef test_reuters_load_does_not_affect_global_rng(fake_downloaded_reuters_path):\n    np.random.seed(1337)\n    before = np.random.randint(0, 100, size=10)\n\n    np.random.seed(1337)\n    reuters.load_data(path=fake_downloaded_reuters_path, seed=9876)\n    after = np.random.randint(0, 100, size=10)\n\n    assert np.array_equal(before, after)\n"""
tests/keras/engine/layer_subclassing_tests.py,12,"b""import pytest\nimport keras\nimport numpy as np\nfrom keras import layers\nfrom keras import backend as K\n\n\ndef test_sublayer_tracking():\n    # basic case\n    class MyLayer(layers.Layer):\n\n        def __init__(self):\n            super(MyLayer, self).__init__()\n            self._input_shape = (2, 4)\n            self.dense = layers.Dense(3)\n            self.bidir = layers.Bidirectional(keras.layers.LSTM(2))\n\n        def call(self, inputs):\n            return self.dense(self.bidir(inputs))\n\n    layer = MyLayer()\n    assert len(layer._layers) == 2\n    layer(K.constant(np.random.random((2,) + layer._input_shape)))\n    assert len(layer.weights) == 2 + 3 + 3\n    assert len(layer._layers[0].weights) == 2\n    assert len(layer._layers[1].weights) == 6\n\n    # recursive case\n    class MyRecursiveLayer(layers.Layer):\n\n        def __init__(self):\n            super(MyRecursiveLayer, self).__init__()\n            self._input_shape = (2, 4)\n            self.my_layer = MyLayer()\n            self.dense = layers.Dense(3)\n            self.bidir = layers.Bidirectional(\n                keras.layers.LSTM(2, return_sequences=True))\n\n        def call(self, inputs):\n            return self.my_layer(self.dense(self.bidir(inputs)))\n\n    layer = MyRecursiveLayer()\n    assert len(layer._layers) == 3\n    layer(K.constant(np.random.random((2,) + layer._input_shape)))\n    assert len(layer.weights) == 16\n\n    # subnetwork case\n    class MyLayerWithSubnetwork(keras.layers.Layer):\n\n        def __init__(self):\n            super(MyLayerWithSubnetwork, self).__init__()\n            self._input_shape = (2,)\n            self.dense = layers.Dense(3)\n            self.sequential = keras.Sequential(\n                [layers.Dense(5), layers.Dense(1)], name='seq')\n            inputs = keras.Input((1,))\n            outputs = layers.Dense(1)(inputs)\n            self.functional = keras.Model(inputs, outputs, name='func')\n\n        def call(self, inputs):\n            x = self.dense(inputs)\n            x = self.sequential(x)\n            return self.functional(x)\n\n    layer = MyLayerWithSubnetwork()\n    assert len(layer._layers) == 3\n    layer(K.constant(np.random.random((2,) + layer._input_shape)))\n    assert len(layer.weights) == 2 + (2 + 2) + 2\n    assert len(layer._layers[0].weights) == 2\n    assert len(layer._layers[1].weights) == 4\n    assert len(layer._layers[2].weights) == 2\n\n\ndef test_weight_tracking():\n\n    class MyLayer(layers.Layer):\n\n        def __init__(self):\n            super(MyLayer, self).__init__()\n            self._input_shape = (2,)\n            self.dense = layers.Dense(3)\n            self.w1 = K.variable(0, name='w1')\n\n        def build(self, input_shape):\n            self.w2 = K.variable(1, name='w2')\n            self.w3 = self.add_weight(\n                'w3', shape=(), trainable=False, initializer='zeros')\n\n        def call(self, inputs):\n            return self.dense(inputs) + self.w1 + self.w2\n\n    layer = MyLayer()\n    layer(K.constant(np.random.random((2,) + layer._input_shape)))\n    assert len(layer.weights) == 5\n    assert len(layer.trainable_weights) == 4\n    assert len(layer.non_trainable_weights) == 1\n    assert len(layer._trainable_weights) == 2\n    assert layer._trainable_weights[0] is layer.w1\n    assert layer._trainable_weights[1] is layer.w2\n    assert len(layer._non_trainable_weights) == 1\n    assert layer._non_trainable_weights[0] is layer.w3\n\n\ndef test_loss_tracking():\n    # basic case\n    class MyLayer(layers.Layer):\n\n        def __init__(self):\n            super(MyLayer, self).__init__()\n            self.dense = layers.Dense(\n                3, kernel_regularizer='l2', activity_regularizer='l2')\n\n        def call(self, inputs):\n            return self.dense(inputs)\n\n    inputs = keras.Input((2,))\n    outputs = MyLayer()(inputs)\n    model = keras.Model(inputs, outputs)\n\n    assert len(model.layers) == 2  # includes input layer\n    assert len(model.weights) == 2\n    assert len(model.losses) == 2\n    assert len(model.get_losses_for(None)) == 1\n    assert len(model.get_losses_for(inputs)) == 1\n\n\n@pytest.mark.skipif(K.backend() != 'tensorflow',\n                    reason='Requires TF symbols')\ndef test_tf_keras_guide():\n    import tensorflow as tf\n\n    class Linear(layers.Layer):\n\n        def __init__(self, units=32, input_dim=32):\n            super(Linear, self).__init__()\n            w_init = tf.random_normal_initializer()\n            self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),\n                                                      dtype='float32'),\n                                 trainable=True)\n            b_init = tf.zeros_initializer()\n            self.b = tf.Variable(initial_value=b_init(shape=(units,),\n                                                      dtype='float32'),\n                                 trainable=True)\n\n        def call(self, inputs):\n            return tf.matmul(inputs, self.w) + self.b\n\n    x = tf.ones((2, 2))\n    linear_layer = Linear(4, 2)\n    y = linear_layer(x)\n\n    assert len(linear_layer.trainable_weights) == 2\n\n    class Linear(layers.Layer):\n\n        def __init__(self, units=32):\n            super(Linear, self).__init__()\n            self.units = units\n\n        def build(self, input_shape):\n            self.w = self.add_weight(shape=(input_shape[-1], self.units),\n                                     initializer='random_normal',\n                                     trainable=True)\n            self.b = self.add_weight(shape=(self.units,),\n                                     initializer='random_normal',\n                                     trainable=True)\n\n        def call(self, inputs):\n            return tf.matmul(inputs, self.w) + self.b\n\n    class MLPBlock(layers.Layer):\n\n        def __init__(self):\n            super(MLPBlock, self).__init__()\n            self.linear_1 = Linear(32)\n            self.linear_2 = Linear(32)\n            self.linear_3 = Linear(1)\n\n        def call(self, inputs):\n            x = self.linear_1(inputs)\n            x = tf.nn.relu(x)\n            x = self.linear_2(x)\n            x = tf.nn.relu(x)\n            return self.linear_3(x)\n\n    mlp = MLPBlock()\n    y = mlp(tf.ones(shape=(3, 64)))\n    assert len(mlp.weights) == 6\n    assert len(mlp.trainable_weights) == 6\n\n    class OuterLayer(layers.Layer):\n\n        def __init__(self):\n            super(OuterLayer, self).__init__()\n            self.dense = layers.Dense(\n                32, kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n\n        def call(self, inputs):\n            return self.dense(inputs)\n\n    layer = OuterLayer()\n    _ = layer(tf.zeros((1, 1)))\n    assert len(layer.losses) == 1\n"""
tests/keras/engine/test_topology.py,0,"b'import pytest\nimport json\nimport numpy as np\n\nfrom keras.layers import Dense, Dropout, Conv2D, InputLayer\nfrom keras import layers\nfrom keras.engine import Input, Layer, saving, get_source_inputs\nfrom keras.models import Model, Sequential\nfrom keras import backend as K\nfrom keras.models import model_from_json, model_from_yaml\nfrom keras.initializers import Constant\n\n\nskipif_no_tf_gpu = pytest.mark.skipif(\n    (K.backend() != \'tensorflow\' or\n     not K.tensorflow_backend._get_available_gpus()),\n    reason=\'Requires TensorFlow backend and a GPU\')\n\n\ndef test_get_updates_for():\n    a = Input(shape=(2,))\n    dense_layer = Dense(1)\n    dense_layer.add_update(0, inputs=a)\n    dense_layer.add_update(1, inputs=None)\n\n    assert dense_layer.get_updates_for(a) == [0]\n    assert dense_layer.get_updates_for(None) == [1]\n\n\ndef test_get_losses_for():\n    a = Input(shape=(2,))\n    dense_layer = Dense(1)\n    dense_layer.add_loss(0, inputs=a)\n    dense_layer.add_loss(1, inputs=None)\n\n    assert dense_layer.get_losses_for(a) == [0]\n    assert dense_layer.get_losses_for(None) == [1]\n\n\ndef test_trainable_weights():\n    a = Input(shape=(2,))\n    b = Dense(1)(a)\n    model = Model(a, b)\n\n    weights = model.weights\n    assert model.trainable_weights == weights\n    assert model.non_trainable_weights == []\n\n    model.trainable = False\n    assert model.trainable_weights == []\n    assert model.non_trainable_weights == weights\n\n    model.trainable = True\n    assert model.trainable_weights == weights\n    assert model.non_trainable_weights == []\n\n    model.layers[1].trainable = False\n    assert model.trainable_weights == []\n    assert model.non_trainable_weights == weights\n\n    # sequential model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2))\n    weights = model.weights\n\n    assert model.trainable_weights == weights\n    assert model.non_trainable_weights == []\n\n    model.trainable = False\n    assert model.trainable_weights == []\n    assert model.non_trainable_weights == weights\n\n    model.trainable = True\n    assert model.trainable_weights == weights\n    assert model.non_trainable_weights == []\n\n    model.layers[0].trainable = False\n    assert model.trainable_weights == []\n    assert model.non_trainable_weights == weights\n\n\ndef test_valid_compute_mask():\n    model = Sequential()\n    model.add(Dense(1, input_dim=2))\n    assert model.layers[0].supports_masking is True\n    assert model.layers[0].compute_mask([model.input], [0., 1.]) == [0., 1.]\n\n\ndef test_invalid_compute_mask():\n    model = Sequential()\n    model.add(Conv2D(1, [2, 2], input_shape=[3, 3, 1]))\n    assert model.layers[0].supports_masking is False\n    assert model.layers[0].compute_mask([model.input], [None]) is None\n\n    mask = np.array([[0., 1.], [1., 0.]])\n    with pytest.raises(TypeError):\n        model.layers[0].compute_mask([model.input], [mask])\n    with pytest.raises(TypeError):\n        model.layers[0].compute_mask([model.input], mask)\n\n\ndef test_get_layer():\n    model = Sequential()\n    model.add(Dense(1, input_dim=2))\n    with pytest.raises(ValueError):\n        model.get_layer(index=5)\n    with pytest.raises(ValueError):\n        model.get_layer(index=None)\n    with pytest.raises(ValueError):\n        model.get_layer(name=\'conv\')\n\n\ndef test_learning_phase():\n    a = Input(shape=(32,), name=\'input_a\')\n    b = Input(shape=(32,), name=\'input_b\')\n\n    a_2 = Dense(16, name=\'dense_1\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    b_2 = dp(b)\n\n    assert not a_2._uses_learning_phase\n    assert b_2._uses_learning_phase\n\n    # test merge\n    m = layers.concatenate([a_2, b_2])\n    assert m._uses_learning_phase\n\n    # Test recursion\n    model = Model([a, b], [a_2, b_2])\n    print(model.input_spec)\n    assert model.uses_learning_phase\n\n    c = Input(shape=(32,), name=\'input_c\')\n    d = Input(shape=(32,), name=\'input_d\')\n\n    c_2, b_2 = model([c, d])\n    assert c_2._uses_learning_phase\n    assert b_2._uses_learning_phase\n\n    # try actually running graph\n    fn = K.function(model.inputs + [K.learning_phase()], model.outputs)\n    input_a_np = np.random.random((10, 32))\n    input_b_np = np.random.random((10, 32))\n    fn_outputs_no_dp = fn([input_a_np, input_b_np, 0])\n    fn_outputs_dp = fn([input_a_np, input_b_np, 1])\n    # output a: nothing changes\n    assert fn_outputs_no_dp[0].sum() == fn_outputs_dp[0].sum()\n    # output b: dropout applied\n    assert fn_outputs_no_dp[1].sum() != fn_outputs_dp[1].sum()\n\n\ndef test_layer_call_arguments():\n    # Test the ability to pass and serialize arguments to `call`.\n    inp = layers.Input(shape=(2,))\n    x = layers.Dense(3)(inp)\n    x = layers.Dropout(0.5)(x, training=True)\n    model = Model(inp, x)\n    assert not model.uses_learning_phase\n\n    # Test that argument is kept when applying the model\n    inp2 = layers.Input(shape=(2,))\n    out2 = model(inp2)\n    assert not out2._uses_learning_phase\n\n    # Test that argument is kept after loading a model\n    config = model.get_config()\n    model = Model.from_config(config)\n    assert not model.uses_learning_phase\n\n\ndef test_node_construction():\n    ####################################################\n    # test basics\n\n    a = Input(shape=(32,), name=\'input_a\')\n    b = Input(shape=(32,), name=\'input_b\')\n\n    assert a._keras_shape == (None, 32)\n    a_layer, a_node_index, a_tensor_index = a._keras_history\n    b_layer, b_node_index, b_tensor_index = b._keras_history\n    assert len(a_layer._inbound_nodes) == 1\n    assert a_tensor_index is 0\n    node = a_layer._inbound_nodes[a_node_index]\n    assert node.outbound_layer == a_layer\n\n    assert isinstance(node.inbound_layers, list)\n    assert node.inbound_layers == []\n    assert isinstance(node.input_tensors, list)\n    assert node.input_tensors == [a]\n    assert isinstance(node.input_masks, list)\n    assert node.input_masks == [None]\n    assert isinstance(node.input_shapes, list)\n    assert node.input_shapes == [(None, 32)]\n\n    assert isinstance(node.output_tensors, list)\n    assert node.output_tensors == [a]\n    assert isinstance(node.output_shapes, list)\n    assert node.output_shapes == [(None, 32)]\n    assert isinstance(node.output_masks, list)\n    assert node.output_masks == [None]\n\n    dense = Dense(16, name=\'dense_1\')\n    a_2 = dense(a)\n    b_2 = dense(b)\n\n    assert len(dense._inbound_nodes) == 2\n    assert len(dense._outbound_nodes) == 0\n    assert dense._inbound_nodes[0].inbound_layers == [a_layer]\n    assert dense._inbound_nodes[0].outbound_layer == dense\n    assert dense._inbound_nodes[1].inbound_layers == [b_layer]\n    assert dense._inbound_nodes[1].outbound_layer == dense\n\n    assert dense._inbound_nodes[0].input_tensors == [a]\n    assert dense._inbound_nodes[1].input_tensors == [b]\n\n    assert dense._inbound_nodes[0].get_config()[\'inbound_layers\'] == [\'input_a\']\n    assert dense._inbound_nodes[1].get_config()[\'inbound_layers\'] == [\'input_b\']\n\n    # test layer properties\n    test_layer = Dense(16, name=\'test_layer\')\n    a_test = test_layer(a)\n    assert K.int_shape(test_layer.kernel) == (32, 16)\n    assert test_layer.input is a\n    assert test_layer.output is a_test\n    assert test_layer.input_mask is None\n    assert test_layer.output_mask is None\n    assert test_layer.input_shape == (None, 32)\n    assert test_layer.output_shape == (None, 16)\n\n    with pytest.raises(AttributeError):\n        dense.input\n    with pytest.raises(AttributeError):\n        dense.output\n    with pytest.raises(AttributeError):\n        dense.input_mask\n    with pytest.raises(AttributeError):\n        dense.output_mask\n\n    assert dense.get_input_at(0) is a\n    assert dense.get_input_at(1)is b\n    assert dense.get_output_at(0) is a_2\n    assert dense.get_output_at(1) is b_2\n    assert dense.get_input_shape_at(0) == (None, 32)\n    assert dense.get_input_shape_at(1) == (None, 32)\n    assert dense.get_output_shape_at(0) == (None, 16)\n    assert dense.get_output_shape_at(1) == (None, 16)\n    assert dense.get_input_mask_at(0) is None\n    assert dense.get_input_mask_at(1) is None\n    assert dense.get_output_mask_at(0) is None\n    assert dense.get_output_mask_at(1) is None\n\n\ndef test_multi_input_layer():\n    ####################################################\n    # test multi-input layer\n    a = Input(shape=(32,), name=\'input_a\')\n    b = Input(shape=(32,), name=\'input_b\')\n\n    dense = Dense(16, name=\'dense_1\')\n    a_2 = dense(a)\n    b_2 = dense(b)\n\n    merged = layers.concatenate([a_2, b_2], name=\'merge\')\n    assert merged._keras_shape == (None, 16 * 2)\n    merge_layer, merge_node_index, merge_tensor_index = merged._keras_history\n\n    assert merge_node_index == 0\n    assert merge_tensor_index == 0\n\n    assert len(merge_layer._inbound_nodes) == 1\n    assert len(merge_layer._outbound_nodes) == 0\n\n    assert len(merge_layer._inbound_nodes[0].input_tensors) == 2\n    assert len(merge_layer._inbound_nodes[0].inbound_layers) == 2\n\n    c = Dense(64, name=\'dense_2\')(merged)\n    d = Dense(5, name=\'dense_3\')(c)\n\n    model = Model(inputs=[a, b], outputs=[c, d], name=\'model\')\n    assert len(model.layers) == 6\n    expected_shapes = [(None, 64), (None, 5)]\n    assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes\n    assert model.compute_mask([a, b], [None, None]) == [None, None]\n    assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes\n\n    # we don\'t check names of first 2 layers (inputs) because\n    # ordering of same-level layers is not fixed\n    expected_names = [\'dense_1\', \'merge\', \'dense_2\', \'dense_3\']\n    assert [l.name for l in model.layers][2:] == expected_names\n    assert [l.name for l in model._input_layers] == [\'input_a\', \'input_b\']\n    assert [l.name for l in model._output_layers] == [\'dense_2\', \'dense_3\']\n\n    # actually run model\n    fn = K.function(model.inputs, model.outputs)\n    input_a_np = np.random.random((10, 32))\n    input_b_np = np.random.random((10, 32))\n    fn_outputs = fn([input_a_np, input_b_np])\n    assert [x.shape for x in fn_outputs] == [(10, 64), (10, 5)]\n\n    # test get_source_inputs\n    source_inputs = get_source_inputs(c)\n    assert source_inputs[0] is a\n    assert source_inputs[1] is b\n\n    # serialization / deserialization\n    json_config = model.to_json()\n    recreated_model = model_from_json(json_config)\n    recreated_model.compile(\'rmsprop\', \'mse\')\n\n    assert [l.name for l in recreated_model.layers][2:] == expected_names\n    assert [l.name for l in recreated_model._input_layers] == [\'input_a\', \'input_b\']\n    assert [l.name for l in recreated_model._output_layers] == [\'dense_2\', \'dense_3\']\n\n    fn = K.function(recreated_model.inputs, recreated_model.outputs)\n    input_a_np = np.random.random((10, 32))\n    input_b_np = np.random.random((10, 32))\n    fn_outputs = fn([input_a_np, input_b_np])\n    assert [x.shape for x in fn_outputs] == [(10, 64), (10, 5)]\n\n\ndef test_recursion():\n    ####################################################\n    # test recursion\n\n    a = Input(shape=(32,), name=\'input_a\')\n    b = Input(shape=(32,), name=\'input_b\')\n\n    dense = Dense(16, name=\'dense_1\')\n    a_2 = dense(a)\n    b_2 = dense(b)\n    merged = layers.concatenate([a_2, b_2], name=\'merge\')\n    c = Dense(64, name=\'dense_2\')(merged)\n    d = Dense(5, name=\'dense_3\')(c)\n\n    model = Model(inputs=[a, b], outputs=[c, d], name=\'model\')\n\n    e = Input(shape=(32,), name=\'input_e\')\n    f = Input(shape=(32,), name=\'input_f\')\n    g, h = model([e, f])\n\n    # g2, h2 = model([e, f])\n\n    assert g._keras_shape == c._keras_shape\n    assert h._keras_shape == d._keras_shape\n\n    # test separate manipulation of different layer outputs\n    i = Dense(7, name=\'dense_4\')(h)\n\n    final_model = Model(inputs=[e, f], outputs=[i, g], name=\'final\')\n    assert len(final_model.inputs) == 2\n    assert len(final_model.outputs) == 2\n    assert len(final_model.layers) == 4\n\n    # we don\'t check names of first 2 layers (inputs) because\n    # ordering of same-level layers is not fixed\n    expected_shapes = [(10, 7), (10, 64)]\n    assert [layer.name for layer in final_model.layers][2:] == [\'model\', \'dense_4\']\n    assert model.compute_mask([e, f], [None, None]) == [None, None]\n    assert final_model.compute_output_shape([(10, 32), (10, 32)]) == expected_shapes\n\n    # run recursive model\n    fn = K.function(final_model.inputs, final_model.outputs)\n    input_a_np = np.random.random((10, 32))\n    input_b_np = np.random.random((10, 32))\n    fn_outputs = fn([input_a_np, input_b_np])\n    assert [x.shape for x in fn_outputs] == [(10, 7), (10, 64)]\n\n    # test serialization\n    model_config = final_model.get_config()\n    print(json.dumps(model_config, indent=4))\n    recreated_model = Model.from_config(model_config)\n\n    fn = K.function(recreated_model.inputs, recreated_model.outputs)\n    input_a_np = np.random.random((10, 32))\n    input_b_np = np.random.random((10, 32))\n    fn_outputs = fn([input_a_np, input_b_np])\n    assert [x.shape for x in fn_outputs] == [(10, 7), (10, 64)]\n\n    ####################################################\n    # test multi-input multi-output\n\n    j = Input(shape=(32,), name=\'input_j\')\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n\n    o = Input(shape=(32,), name=\'input_o\')\n    p = Input(shape=(32,), name=\'input_p\')\n    q, r = model([o, p])\n\n    assert n._keras_shape == (None, 5)\n    assert q._keras_shape == (None, 64)\n    s = layers.concatenate([n, q], name=\'merge_nq\')\n    assert s._keras_shape == (None, 64 + 5)\n\n    # test with single output as 1-elem list\n    multi_io_model = Model([j, k, o, p], [s])\n\n    fn = K.function(multi_io_model.inputs, multi_io_model.outputs)\n    fn_outputs = fn([np.random.random((10, 32)), np.random.random((10, 32)),\n                     np.random.random((10, 32)), np.random.random((10, 32))])\n    assert [x.shape for x in fn_outputs] == [(10, 69)]\n\n    # test with single output as tensor\n    multi_io_model = Model([j, k, o, p], s)\n\n    fn = K.function(multi_io_model.inputs, multi_io_model.outputs)\n    fn_outputs = fn([np.random.random((10, 32)), np.random.random((10, 32)),\n                     np.random.random((10, 32)), np.random.random((10, 32))])\n    # note that the output of the K.function will still be a 1-elem list\n    assert [x.shape for x in fn_outputs] == [(10, 69)]\n\n    # test serialization\n    model_config = multi_io_model.get_config()\n    recreated_model = Model.from_config(model_config)\n\n    fn = K.function(recreated_model.inputs, recreated_model.outputs)\n    fn_outputs = fn([np.random.random((10, 32)), np.random.random((10, 32)),\n                     np.random.random((10, 32)), np.random.random((10, 32))])\n    # note that the output of the K.function will still be a 1-elem list\n    assert [x.shape for x in fn_outputs] == [(10, 69)]\n\n    config = model.get_config()\n    Model.from_config(config)\n\n    model.summary()\n    json_str = model.to_json()\n    model_from_json(json_str)\n\n    yaml_str = model.to_yaml()\n    model_from_yaml(yaml_str)\n\n    ####################################################\n    # test invalid graphs\n\n    # input is not an Input tensor\n    j = Input(shape=(32,), name=\'input_j\')\n    j = Dense(32)(j)\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n\n    with pytest.raises(ValueError):\n        Model([j, k], [m, n])\n\n    # disconnected graph\n    j = Input(shape=(32,), name=\'input_j\')\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n    with pytest.raises(ValueError):\n        Model([j], [m, n])\n\n    # redundant outputs\n    j = Input(shape=(32,), name=\'input_j\')\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n    # this should work with a warning\n    Model([j, k], [m, n, n])\n\n    # redundant inputs\n    j = Input(shape=(32,), name=\'input_j\')\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n    with pytest.raises(ValueError):\n        Model([j, k, j], [m, n])\n\n    # i have not idea what I\'m doing: garbage as inputs/outputs\n    j = Input(shape=(32,), name=\'input_j\')\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n    with pytest.raises(ValueError):\n        Model([j, k], [m, n, 0])\n\n    ####################################################\n    # test calling layers/models on placeholders\n    j = Input(shape=(32,), name=\'input_j\')\n    k = Input(shape=(32,), name=\'input_k\')\n    m, n = model([j, k])\n    outer_model = Model([j, k], [m, n])\n\n    j_tf = K.placeholder(shape=(None, 32), dtype=K.floatx())\n    k_tf = K.placeholder(shape=(None, 32), dtype=K.floatx())\n    m_tf, n_tf = outer_model([j_tf, k_tf])\n    assert K.int_shape(m_tf) == (None, 64)\n    assert K.int_shape(n_tf) == (None, 5)\n\n    # test merge\n    layers.concatenate([j_tf, k_tf], axis=1)\n    layers.add([j_tf, k_tf])\n\n    # test tensor input\n    x = K.placeholder(shape=(None, 2), dtype=K.floatx())\n    InputLayer(input_tensor=x)\n\n    x = Input(tensor=x)\n    Dense(2)(x)\n\n\ndef test_load_layers():\n    from keras.layers import ConvLSTM2D, TimeDistributed\n    from keras.layers import Bidirectional, Conv2D, Input\n    from keras.models import Model\n\n    if K.backend() == \'tensorflow\' or K.backend() == \'cntk\':\n        inputs = Input(shape=(10, 20, 20, 1))\n    else:\n        inputs = Input(shape=(10, 1, 20, 20))\n    td_conv = TimeDistributed(Conv2D(15, (5, 5)))(inputs)\n    bi_conv = Bidirectional(ConvLSTM2D(10, (3, 3)), merge_mode=\'concat\')(td_conv)\n    model = Model(inputs=inputs, outputs=bi_conv)\n\n    weight_value_tuples = []\n\n    # TimeDistributed Conv2D layer\n    # use \'channels_first\' data format to check that\n    # the function is being called correctly for Conv2D\n    # old: (filters, stack_size, kernel_rows, kernel_cols)\n    # new: (kernel_rows, kernel_cols, stack_size, filters)\n    weight_tensor_td_conv_old = list()\n    weight_tensor_td_conv_old.append(np.zeros((15, 1, 5, 5)))\n    weight_tensor_td_conv_old.append(np.zeros((15,)))\n    td_conv_layer = model.layers[1]\n    td_conv_layer.layer.data_format = \'channels_first\'\n    weight_tensor_td_conv_new = saving.preprocess_weights_for_loading(\n        td_conv_layer,\n        weight_tensor_td_conv_old,\n        original_keras_version=\'1\')\n    symbolic_weights = td_conv_layer.weights\n    assert (len(symbolic_weights) == len(weight_tensor_td_conv_new))\n    weight_value_tuples += zip(symbolic_weights, weight_tensor_td_conv_new)\n\n    # Bidirectional ConvLSTM2D layer\n    # old ConvLSTM2D took a list of 12 weight tensors,\n    # returns a list of 3 concatenated larger tensors.\n    weights_bi_conv_old = []\n    for j in range(2):  # bidirectional\n        for i in range(4):\n            weights_bi_conv_old.append(np.zeros((3, 3, 15, 10)))  # kernel\n            weights_bi_conv_old.append(np.zeros((3, 3, 10, 10)))  # recurrent kernel\n            weights_bi_conv_old.append(np.zeros((10,)))  # bias\n\n    bi_convlstm_layer = model.layers[2]\n    weights_bi_conv_new = saving.preprocess_weights_for_loading(\n        bi_convlstm_layer,\n        weights_bi_conv_old,\n        original_keras_version=\'1\')\n\n    symbolic_weights = bi_convlstm_layer.weights\n    assert (len(symbolic_weights) == len(weights_bi_conv_new))\n    weight_value_tuples += zip(symbolic_weights, weights_bi_conv_new)\n\n    K.batch_set_value(weight_value_tuples)\n\n    assert np.all(K.eval(model.layers[1].weights[0]) == weight_tensor_td_conv_new[0])\n    assert np.all(K.eval(model.layers[1].weights[1]) == weight_tensor_td_conv_new[1])\n    assert np.all(K.eval(model.layers[2].weights[0]) == weights_bi_conv_new[0])\n    assert np.all(K.eval(model.layers[2].weights[1]) == weights_bi_conv_new[1])\n    assert np.all(K.eval(model.layers[2].weights[2]) == weights_bi_conv_new[2])\n    assert np.all(K.eval(model.layers[2].weights[3]) == weights_bi_conv_new[3])\n    assert np.all(K.eval(model.layers[2].weights[4]) == weights_bi_conv_new[4])\n    assert np.all(K.eval(model.layers[2].weights[5]) == weights_bi_conv_new[5])\n\n\ndef convert_weights(layer, weights):\n    if layer.__class__.__name__ == \'GRU\':\n        W = [np.split(w, 3, axis=-1) for w in weights]\n        return sum(map(list, zip(*W)), [])\n    elif layer.__class__.__name__ in (\'LSTM\', \'ConvLSTM2D\'):\n        W = [np.split(w, 4, axis=-1) for w in weights]\n        for w in W:\n            w[2], w[1] = w[1], w[2]\n        return sum(map(list, zip(*W)), [])\n    elif layer.__class__.__name__ == \'Conv2DTranspose\':\n        return [np.transpose(weights[0], (2, 3, 0, 1)), weights[1]]\n    return weights\n\n\n@pytest.mark.parametrize(""layer"", [\n    layers.GRU(2, input_shape=[3, 5]),\n    layers.LSTM(2, input_shape=[3, 5]),\n    layers.ConvLSTM2D(5, (3, 3),\n                      input_shape=[6, 6, 6, 6],\n                      data_format=\'channels_first\'),\n], ids=[\'GRU\', \'LSTM\', \'ConvLSTM2D\'])\ndef test_preprocess_weights_for_loading(layer):\n    # A model is needed to initialize weights.\n    _ = Sequential([layer])\n    weights1 = layer.get_weights()\n    weights2 = saving.preprocess_weights_for_loading(\n        layer, convert_weights(layer, weights1),\n        original_keras_version=\'1\')\n    assert all([np.allclose(x, y, 1e-5)\n                for (x, y) in zip(weights1, weights2)])\n\n\n@pytest.mark.parametrize(""layer"", [\n    layers.Conv2D(2, (3, 3), input_shape=[5, 5, 3]),\n    layers.Conv2DTranspose(2, (5, 5),\n                           input_shape=[7, 7, 3],\n                           data_format=\'channels_first\'),\n], ids=[\'Conv2D\', \'Conv2DTranspose\'])\ndef test_preprocess_weights_for_loading_for_model(layer):\n    model = Sequential([layer])\n    weights1 = model.get_weights()\n    weights2 = saving.preprocess_weights_for_loading(\n        model, convert_weights(layer, weights1),\n        original_keras_version=\'1\')\n    assert all([np.allclose(x, y, 1e-5)\n                for (x, y) in zip(weights1, weights2)])\n\n\n@pytest.mark.parametrize(\'layer_class,args\', [\n    (layers.GRU, {\'units\': 2, \'input_shape\': [3, 5]}),\n    (layers.GRU, {\'units\': 2, \'input_shape\': [3, 5], \'reset_after\': True}),\n    (layers.LSTM, {\'units\': 2, \'input_shape\': [3, 5]}),\n])\ndef test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, args):\n    """"""\n    Loading weights from a RNN class to itself should not convert the weights.\n    """"""\n    # layer can be instantiated only for supported backends\n    layer = layer_class(**args)\n    # A model is needed to initialize weights.\n    _ = Sequential([layer])\n    weights1 = layer.get_weights()\n    weights2 = saving.preprocess_weights_for_loading(layer, weights1)\n    assert all([np.allclose(x, y, 1e-5) for (x, y) in zip(weights1, weights2)])\n\n\n@pytest.mark.parametrize(\'layer_class,args\', [\n    (layers.CuDNNGRU, {\'units\': 2, \'input_shape\': [3, 5]}),\n    (layers.CuDNNLSTM, {\'units\': 2, \'input_shape\': [3, 5]}),\n])\n@skipif_no_tf_gpu\ndef test_preprocess_weights_for_loading_cudnn_rnn_should_be_idempotent(layer_class,\n                                                                       args):\n    test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, args)\n\n\ndef test_recursion_with_bn_and_loss():\n    model1 = Sequential([\n        layers.Dense(5, input_dim=5, activity_regularizer=\'l1\'),\n        layers.BatchNormalization(),\n        layers.Dense(5),\n    ])\n\n    print(\'NEW MODEL\')\n    inputs = layers.Input(shape=(5,))\n    outputs = model1(inputs)\n    model2 = Model(inputs=inputs, outputs=outputs)\n\n    assert len(model1.updates) == 2\n    assert len(model2.updates) == 2\n    assert len(model1.losses) == 1\n    assert len(model2.losses) == 1, model2.layers[1]._per_input_losses\n\n    model1.compile(optimizer=\'sgd\', loss=\'categorical_crossentropy\')\n    model2.compile(optimizer=\'sgd\', loss=\'categorical_crossentropy\')\n\n    x = np.ones((3, 5))\n    y = np.ones((3, 5))\n    model1.fit(x, y, verbose=0, epochs=1)\n    model2.fit(x, y, verbose=0, epochs=1)\n\n\ndef test_activity_regularization_with_model_composition():\n\n    def reg(x):\n        return K.sum(x)\n\n    net_a_input = Input((2,))\n    net_a = net_a_input\n    net_a = Dense(2, kernel_initializer=\'ones\',\n                  use_bias=False,\n                  activity_regularizer=reg)(net_a)\n    model_a = Model([net_a_input], [net_a])\n\n    net_b_input = Input((2,))\n    net_b = model_a(net_b_input)\n    model_b = Model([net_b_input], [net_b])\n\n    model_b.compile(optimizer=\'sgd\', loss=None)\n    x = np.ones((1, 2))\n    loss = model_b.evaluate(x)\n    assert loss == 4\n\n\ndef test_shared_layer_depth_is_correct():\n    # Basic outline here: we have a shared embedding layer, and two inputs that\n    # go through different depths of computation in the graph before\n    # the final output.  We need the computed depth of the input layers to be\n    # the same, because they both pass through the embedding layer before anything\n    # else happens.  That\'s what we\'re testing.\n    from keras.layers import Embedding, Input, Dense, Concatenate\n    from keras.models import Model\n    input1 = Input(shape=(10,), name=\'input1\')\n    input2 = Input(shape=(10,), name=\'input2\')\n    embedding_layer = Embedding(name=\'embedding\', input_dim=5, output_dim=10)\n    embedded_input1 = embedding_layer(input1)\n    embedded_input2 = embedding_layer(input2)\n    transformed_input2 = Dense(6)(Dense(5)(Dense(3)(embedded_input2)))\n    final_output = Dense(2)(Concatenate()([embedded_input1, transformed_input2]))\n    model = Model(inputs=[input1, input2], outputs=final_output)\n    input1_depth = -1\n    input2_depth = -1\n    for depth, layers in model._layers_by_depth.items():\n        for layer in layers:\n            if layer.name == \'input1\':\n                input1_depth = depth\n            if layer.name == \'input2\':\n                input2_depth = depth\n    assert input1_depth != -1\n    assert input1_depth == input2_depth\n\n\ndef test_layer_sharing_at_heterogeneous_depth():\n    x_val = np.random.random((10, 5))\n\n    x = Input(shape=(5,))\n    A = Dense(5, name=\'A\')\n    B = Dense(5, name=\'B\')\n    output = A(B(A(B(x))))\n    M = Model(x, output)\n\n    output_val = M.predict(x_val)\n\n    config = M.get_config()\n    weights = M.get_weights()\n\n    M2 = Model.from_config(config)\n    M2.set_weights(weights)\n\n    output_val_2 = M2.predict(x_val)\n    np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)\n\n\ndef test_layer_sharing_at_heterogeneous_depth_with_concat():\n    input_shape = (16, 9, 3)\n    input_layer = Input(shape=input_shape)\n\n    A = Dense(3, name=\'dense_A\')\n    B = Dense(3, name=\'dense_B\')\n    C = Dense(3, name=\'dense_C\')\n\n    x1 = B(A(input_layer))\n    x2 = A(C(input_layer))\n    output = layers.concatenate([x1, x2])\n\n    M = Model(inputs=input_layer, outputs=output)\n\n    x_val = np.random.random((10, 16, 9, 3))\n    output_val = M.predict(x_val)\n\n    config = M.get_config()\n    weights = M.get_weights()\n\n    M2 = Model.from_config(config)\n    M2.set_weights(weights)\n\n    output_val_2 = M2.predict(x_val)\n    np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)\n\n\ndef test_layer_sharing_at_heterogeneous_depth_order():\n    # This tests for the bug in this issue\n    # https://github.com/keras-team/keras/issues/11159\n    # It occurs with layer sharing at heterogeneous depth when\n    # the layers need to be applied in an order that differs from\n    # the order that occurs in the config.\n\n    input_shape = (1, 12)\n    input_layer = Input(shape=input_shape)\n\n    A = Dense(12, name=\'layer_a\')\n    r1 = layers.Reshape((12,))(input_layer)\n    Aout1 = A(r1)\n\n    r2 = layers.Reshape((12,))(A(input_layer))\n    Aout2 = A(r2)\n\n    # Note: if the order of the layers in the concat is\n    # changed to ([Aout1, Aout2]) the bug doesn\'t trigger\n    c1 = layers.concatenate([Aout2, Aout1])\n    output = Dense(2, name=\'layer_b\')(c1)\n\n    M = Model(inputs=input_layer, outputs=output)\n\n    x_val = np.random.random((10,) + input_shape)\n    output_val = M.predict(x_val)\n\n    config = M.get_config()\n    weights = M.get_weights()\n\n    M2 = Model.from_config(config)\n    M2.set_weights(weights)\n\n    output_val_2 = M2.predict(x_val)\n    np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)\n\n\ndef test_multi_output_mask():\n    """"""Fixes #7589""""""\n    class TestMultiOutputLayer(Layer):\n        def __init__(self, **kwargs):\n            super(TestMultiOutputLayer, self).__init__(**kwargs)\n\n        def call(self, inputs, **kwargs):\n            return [K.abs(inputs), K.abs(inputs)]\n\n        def compute_output_shape(self, input_shape):\n            out_shape = super(TestMultiOutputLayer, self).compute_output_shape(\n                input_shape)\n            return [out_shape, out_shape]\n\n    class TestMultiInputLayer(Layer):\n        def __init__(self, **kwargs):\n            super(TestMultiInputLayer, self).__init__(**kwargs)\n\n        def call(self, inputs, **kwargs):\n            negative, positive = inputs\n            return negative + positive\n\n    input_layer = Input(shape=(16, 16, 3))\n    x, y = TestMultiOutputLayer()(input_layer)\n    z = TestMultiInputLayer()([x, y])\n    _ = Model(inputs=input_layer, outputs=z)\n    assert K.int_shape(z)[1:] == (16, 16, 3)\n\n\ndef test_constant_initializer_with_numpy():\n    model = Sequential()\n    model.add(Dense(2, input_shape=(3,),\n                    kernel_initializer=Constant(1.)))\n    model.add(Dense(3))\n    model.compile(loss=\'mse\', optimizer=\'sgd\', metrics=[\'acc\'])\n\n    json_str = model.to_json()\n    model_from_json(json_str).summary()\n\n    yaml_str = model.to_yaml()\n    model_from_yaml(yaml_str).summary()\n\n\n@pytest.mark.skipif(K.backend() == \'cntk\',\n                    reason=\'Float64 not supported with CNTK.\')\ndef test_initialization_dtype():\n    class TestLayer(Layer):\n        def __init__(self):\n            super(TestLayer, self).__init__(dtype=\'int64\')\n            self.w = self.add_weight(\'w\', [], initializer=Constant(1))\n\n    layer = TestLayer()\n    assert K.dtype(layer.w) == \'int64\'\n\n    class TestModel(Model):\n        def __init__(self):\n            super(TestModel, self).__init__(dtype=\'int64\')\n            self.w = self.add_weight(\'w\', [], initializer=Constant(1))\n\n    model = TestModel()\n    assert K.dtype(model.w) == \'int64\'\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/engine/test_training.py,8,"b'import threading\n\nimport pytest\nimport numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_allclose\nimport sys\nimport scipy.sparse as sparse\nfrom flaky import flaky\n\nimport keras\nfrom keras import losses\nfrom keras import metrics\nfrom keras.layers import Layer, Activation, Dense, Dropout, Conv2D, Concatenate\nfrom keras.engine import Input\nfrom keras.engine.training import Model\nfrom keras.engine import training_utils\nfrom keras.utils.generic_utils import slice_arrays\nfrom keras.models import Sequential\nfrom keras import backend as K\nfrom keras.utils import Sequence\nfrom keras.callbacks import Callback\n\nif K.backend() == \'tensorflow\':\n    import tensorflow as tf\n\n\nclass RandomSequence(Sequence):\n    def __init__(self, batch_size, sequence_length=12):\n        self.batch_size = batch_size\n        self.sequence_length = sequence_length\n        self.logs = []  # It will work for use_multiprocessing=False\n\n    def __len__(self):\n        return self.sequence_length\n\n    def __getitem__(self, idx):\n        self.logs.append(idx)\n        return ([np.random.random((self.batch_size, 3)),\n                 np.random.random((self.batch_size, 3))],\n                [np.random.random((self.batch_size, 4)),\n                 np.random.random((self.batch_size, 3))])\n\n    def on_epoch_end(self):\n        pass\n\n\nclass IncreaseBatchSizeRandomSequence(Sequence):\n    def __init__(self, initial_batch_size, initial_sequence_length=12,\n                 batch_size_func=lambda x: x + 2):\n        self.batch_size = initial_batch_size\n        self.initial_sequence_length = initial_sequence_length\n        self.batch_size_func = batch_size_func\n        self.logs = []\n\n    def __len__(self):\n        return int(np.ceil(self.initial_sequence_length / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        self.logs.append(idx)\n        return ([np.random.random((self.batch_size, 3)),\n                 np.random.random((self.batch_size, 3))],\n                [np.random.random((self.batch_size, 4)),\n                 np.random.random((self.batch_size, 3))])\n\n    def on_epoch_end(self):\n        self.batch_size = self.batch_size_func(self.batch_size)\n\n\nclass threadsafe_iter:\n    """"""Takes an iterator/generator and makes it thread-safe by\n    serializing call to the `next` method of given iterator/generator.\n    """"""\n\n    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        return self.next()\n\n    def next(self):\n        with self.lock:\n            return next(self.it)\n\n\ndef threadsafe_generator(f):\n    """"""A decorator that takes a generator function and makes it thread-safe.\n    """"""\n\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n\n    return g\n\n\ndef test_check_array_length_consistency():\n    training_utils.check_array_length_consistency(None, None, None)\n    a_np = np.random.random((4, 3, 3))\n    training_utils.check_array_length_consistency(a_np, a_np, a_np)\n    training_utils.check_array_length_consistency(\n        [a_np, a_np], [a_np, a_np], [a_np, a_np])\n    training_utils.check_array_length_consistency([None], [None], [None])\n\n    b_np = np.random.random((3, 4))\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency(a_np, None, None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency(a_np, a_np, None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], [None], None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], [b_np], None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], None, [b_np])\n\n\ndef testslice_arrays():\n    input_a = np.random.random((10, 3))\n    slice_arrays(None)\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = [None, [1, 1], None, [1, 1]]\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = [None]\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = None\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n\n\ndef test_weighted_masked_objective():\n    a = Input(shape=(3,), name=\'input_a\')\n\n    # weighted_masked_objective\n    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)\n\n    weighted_function = training_utils.weighted_masked_objective(\n        losses.categorical_crossentropy)\n    weighted_function(a, a, None)\n\n\ndef get_model(num_outputs=1):\n    a = Input(shape=(3,), name=\'input_a\')\n    b = Input(shape=(3,), name=\'input_b\')\n\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    b_2 = dp(b)\n\n    if num_outputs == 1:\n        model = Model([a, b], a_2)\n    else:\n        model = Model([a, b], [a_2, b_2])\n    return model\n\n\nclass TrackerCallback(Callback):\n\n    def __init__(self):\n        # test starting from non-zero initial epoch\n        self.trained_epochs = []\n        self.trained_batches = []\n        self.steps_per_epoch_log = []\n        super(TrackerCallback, self).__init__()\n\n    def set_params(self, params):\n        super(TrackerCallback, self).set_params(params)\n        self.steps_per_epoch_log.append(params[\'steps\'])\n\n    # define tracer callback\n    def on_epoch_begin(self, epoch, logs):\n        self.trained_epochs.append(epoch)\n\n    def on_batch_begin(self, batch, logs):\n        self.trained_batches.append(batch)\n\n\n# TODO: resolve flakyness issue. Tracked with #11560\n@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\ndef test_model_methods():\n    model = get_model(num_outputs=2)\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    # training/testing doesn\'t work before compiling.\n    with pytest.raises(RuntimeError):\n        model.train_on_batch([input_a_np, input_b_np],\n                             [output_a_np, output_b_np])\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                               {\'dense_1\': output_a_np, \'dropout\': output_b_np})\n\n    # test fit\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                    {\'dense_1\': output_a_np, \'dropout\': output_b_np},\n                    epochs=1, batch_size=4)\n\n    # test validation_split\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n    out = model.fit({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n\n    # test validation data\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4,\n                    validation_data=([input_a_np, input_b_np],\n                                     [output_a_np, output_b_np]))\n    out = model.fit({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=({\'input_a\': input_a_np,\n                                      \'input_b\': input_b_np},\n                                     [output_a_np, output_b_np]))\n    out = model.fit({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                    {\'dense_1\': output_a_np, \'dropout\': output_b_np},\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=(\n                        {\'input_a\': input_a_np, \'input_b\': input_b_np},\n                        {\'dense_1\': output_a_np, \'dropout\': output_b_np}))\n\n    # test_on_batch\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({\'input_a\': input_a_np, \'input_b\': input_b_np},\n                              {\'dense_1\': output_a_np, \'dropout\': output_b_np})\n\n    # predict_on_batch\n    out = model.predict_on_batch([input_a_np, input_b_np])\n    out = model.predict_on_batch({\'input_a\': input_a_np,\n                                  \'input_b\': input_b_np})\n\n    # predict, evaluate\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.evaluate([input_a_np, input_b_np],\n                         [output_a_np, output_b_np],\n                         batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # with sample_weight\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    sample_weight = [None, np.random.random((10,))]\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               sample_weight=sample_weight)\n\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np],\n                              sample_weight=sample_weight)\n\n    # test accuracy metric\n    model.compile(optimizer, loss, metrics=[\'acc\'],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 5\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 5\n\n    # this should also work\n    model.compile(optimizer, loss, metrics={\'dense_1\': \'acc\'},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    # and this as well\n    model.compile(optimizer, loss, metrics={\'dense_1\': [\'acc\']},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    tracker_cb = TrackerCallback()\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=5, batch_size=4,\n                    initial_epoch=2, callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [2, 3, 4]\n\n    # test starting from non-zero initial epoch for generator too\n    tracker_cb = TrackerCallback()\n\n    @threadsafe_generator\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])\n\n    out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,\n                              initial_epoch=2, callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [2, 3, 4]\n\n    # test with a custom metric function\n    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))\n\n    model.compile(optimizer, loss, metrics=[mse],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)\n    assert len(out) == out_len\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == out_len\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    batch_size=4, epochs=1)\n    out = model.evaluate([input_a_np, input_b_np],\n                         [output_a_np, output_b_np],\n                         batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # enable verbose for evaluate_generator\n    out = model.evaluate_generator(gen_data(4), steps=3, verbose=1)\n    # pass generator directly so `is_generator_or_sequence`\n    # doesn\'t get confused.\n    out = model.evaluate(gen_data(4).it, steps=3, verbose=1)\n\n    # empty batch\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.evaluate_generator(gen_data(), steps=1)\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.evaluate(gen_data().it, steps=1)\n\n    # x is not a list of numpy arrays.\n    with pytest.raises(ValueError):\n        out = model.predict([None])\n\n    # x does not match _feed_input_names.\n    with pytest.raises(ValueError):\n        out = model.predict([input_a_np, None, input_b_np])\n    with pytest.raises(ValueError):\n        out = model.predict([None, input_a_np, input_b_np])\n\n    # all input/output/weight arrays should have the same number of samples.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np[:2]],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np[:2]],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=[sample_weight[1],\n                                                  sample_weight[1][:2]])\n\n    # `sample_weight` is neither a dict nor a list.\n    with pytest.raises(TypeError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=tuple(sample_weight))\n\n    # `validation_data` is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4,\n                        validation_data=([input_a_np, input_b_np],))\n\n    # `loss` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=[\'mse\', \'mae\', \'mape\'])\n\n    # `loss_weights` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=\'mse\', loss_weights={\'lstm\': 0.5})\n\n    # `loss_weights` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=\'mse\', loss_weights=[0.5])\n\n    # `loss_weights` is invalid type.\n    with pytest.raises(TypeError):\n        model.compile(optimizer, loss=\'mse\', loss_weights=(0.5, 0.5))\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=\'mse\',\n                      sample_weight_mode={\'lstm\': \'temporal\'})\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=\'mse\', sample_weight_mode=[\'temporal\'])\n\n    # `sample_weight_mode` matches output_names partially.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=\'mse\',\n                      sample_weight_mode={\'dense_1\': \'temporal\'})\n\n    # `loss` does not exist.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=[])\n\n    model.compile(optimizer, loss=[\'mse\', \'mae\'])\n    model.compile(optimizer, loss=\'mse\', loss_weights={\'dense_1\': 0.2,\n                                                       \'dropout\': 0.8})\n    model.compile(optimizer, loss=\'mse\', loss_weights=[0.2, 0.8])\n\n    # the rank of weight arrays should be 1.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch(\n            [input_a_np, input_b_np],\n            [output_a_np, output_b_np],\n            sample_weight=[None, np.random.random((10, 20, 30))])\n\n    model.compile(optimizer, loss=\'mse\',\n                  sample_weight_mode={\'dense_1\': None, \'dropout\': \'temporal\'})\n    model.compile(optimizer, loss=\'mse\', sample_weight_mode=[None, \'temporal\'])\n\n    # the rank of output arrays should be at least 3D.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n\n\n# TODO: resolve flakyness issue. Tracked with #11560\n@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\ndef test_fit_generator():\n    model = get_model(num_outputs=2)\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              steps_per_epoch=3,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              max_queue_size=1,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(3)) * 5\n    assert len(val_seq.logs) <= 4 * 5\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit(RandomSequence(3),\n                    steps_per_epoch=3,\n                    epochs=5,\n                    initial_epoch=0,\n                    validation_data=val_seq,\n                    validation_steps=3,\n                    max_queue_size=1,\n                    callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(3)) * 5\n    assert len(val_seq.logs) <= 4 * 5\n\n    # steps_per_epoch will be equal to len of sequence if it\'s unspecified\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              callbacks=[tracker_cb],\n                              max_queue_size=1)\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(12)) * 5\n    assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit(RandomSequence(3),\n                    epochs=5,\n                    initial_epoch=0,\n                    validation_data=val_seq,\n                    callbacks=[tracker_cb],\n                    max_queue_size=1)\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(12)) * 5\n    assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n\n    # test for workers = 0\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              epochs=5,\n                              validation_data=val_seq,\n                              callbacks=[tracker_cb],\n                              workers=0)\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(12)) * 5\n    assert len(val_seq.logs) == 12 * 5\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit(RandomSequence(3),\n                    steps_per_epoch=3,\n                    epochs=5,\n                    initial_epoch=0,\n                    validation_data=val_seq,\n                    validation_steps=3,\n                    max_queue_size=1,\n                    callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(3)) * 5\n    assert len(val_seq.logs) <= 4 * 5\n\n    # fit_generator will throw an exception\n    # if steps is unspecified for regular generator\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.fit_generator(generator=gen_data(), epochs=5,\n                                  initial_epoch=0, validation_data=gen_data(),\n                                  callbacks=[tracker_cb])\n\n    # Check if generator is only accessed an expected number of times\n    gen_counters = [0, 0]\n\n    @threadsafe_generator\n    def gen_data(i):\n        while True:\n            gen_counters[i] += 1\n            yield ([np.random.random((1, 3)), np.random.random((1, 3))],\n                   [np.random.random((1, 4)), np.random.random((1, 3))])\n    out = model.fit_generator(generator=gen_data(0), epochs=3,\n                              steps_per_epoch=2,\n                              validation_data=gen_data(1),\n                              validation_steps=1,\n                              max_queue_size=2,\n                              workers=2)\n\n    # Need range check here as filling\n    # of the queue depends on sleep in the enqueuers\n    max_train = 3 * 2 + 2 * 2\n    min_train = 2 * 3\n    assert min_train <= gen_counters[0] <= max_train\n    # 12 = (epoch * workers * validation steps * max_queue_size)\n    assert 3 <= gen_counters[1] <= 12\n\n    gen_counters = [0]\n    out = model.fit_generator(generator=RandomSequence(3), epochs=3,\n                              validation_data=gen_data(0),\n                              validation_steps=1,\n                              max_queue_size=2,\n                              workers=2)\n\n    # 12 = (epoch * workers * validation steps * max_queue_size)\n    # Need range check here as filling\n    # of the queue depends on sleep in the enqueuers\n    assert 3 <= gen_counters[0] <= 12\n\n\ndef test_fit_generator_dynamic_size_sequence_with_workers():\n    model = get_model(num_outputs=2)\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    train_seq = IncreaseBatchSizeRandomSequence(3, 20)\n    out = model.fit_generator(generator=train_seq,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              max_queue_size=1,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == [\n        0, 1, 2, 3, 4, 5, 6,  # 1st epoch -> ceil(20 / 3) = 7 batches\n        0, 1, 2, 3,           # 2nd epoch -> ceil(20 / 5) = 4 batches\n        0, 1, 2,              # 3d  epoch -> ceil(20 / 7) = 3 batches\n        0, 1, 2,              # 4th epoch -> ceil(20 / 9) = 3 batches\n        0, 1,                 # 5th epoch -> ceil(20 /11) = 2 batches\n    ]\n    assert tracker_cb.steps_per_epoch_log[0:5] == [7, 4, 3, 3, 2]\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    train_seq = IncreaseBatchSizeRandomSequence(3, 30)\n    out = model.fit_generator(generator=train_seq,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              max_queue_size=1,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9,  # 1st epoch -> ceil(30 / 3) = 10 batches\n        0, 1, 2, 3, 4, 5,              # 2nd epoch -> ceil(30 / 5) =  6 batches\n        0, 1, 2, 3, 4,                 # 3d  epoch -> ceil(30 / 7) =  5 batches\n        0, 1, 2, 3,                    # 4th epoch -> ceil(30 / 9) =  4 batches\n        0, 1, 2,                       # 5th epoch -> ceil(30 /11) =  3 batches\n    ]\n    assert tracker_cb.steps_per_epoch_log[0:5] == [10, 6, 5, 4, 3]\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    train_seq = IncreaseBatchSizeRandomSequence(2, 404, lambda x: x * 2)\n    out = model.fit_generator(generator=train_seq,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              max_queue_size=1,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    # number of trained batches should match sum of steps per each epoch\n    assert len(tracker_cb.trained_batches) == 202 + 101 + 51 + 26 + 13\n    assert tracker_cb.steps_per_epoch_log[0:5] == [202, 101, 51, 26, 13]\n\n\ndef test_fit_generator_dynamic_size_sequence_main_thread():\n    model = get_model(num_outputs=2)\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    train_seq = IncreaseBatchSizeRandomSequence(3, 20)\n    out = model.fit_generator(generator=train_seq,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              workers=0,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == [\n        0, 1, 2, 3, 4, 5, 6,  # 1st epoch -> ceil(20 / 3) = 7 batches\n        0, 1, 2, 3,           # 2nd epoch -> ceil(20 / 5) = 4 batches\n        0, 1, 2,              # 3d  epoch -> ceil(20 / 7) = 3 batches\n        0, 1, 2,              # 4th epoch -> ceil(20 / 9) = 3 batches\n        0, 1,                 # 5th epoch -> ceil(20 /11) = 2 batches\n    ]\n    assert tracker_cb.steps_per_epoch_log[0:5] == [7, 4, 3, 3, 2]\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    train_seq = IncreaseBatchSizeRandomSequence(3, 30)\n    out = model.fit_generator(generator=train_seq,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              workers=0,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9,  # 1st epoch -> ceil(30 / 3) = 10 batches\n        0, 1, 2, 3, 4, 5,              # 2nd epoch -> ceil(30 / 5) =  6 batches\n        0, 1, 2, 3, 4,                 # 3d  epoch -> ceil(30 / 7) =  5 batches\n        0, 1, 2, 3,                    # 4th epoch -> ceil(30 / 9) =  4 batches\n        0, 1, 2,                       # 5th epoch -> ceil(30 /11) =  3 batches\n    ]\n    assert tracker_cb.steps_per_epoch_log[0:5] == [10, 6, 5, 4, 3]\n\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    train_seq = IncreaseBatchSizeRandomSequence(2, 404, lambda x: x * 2)\n    out = model.fit_generator(generator=train_seq,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              workers=0,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    # number of trained batches should match sum of steps per each epoch\n    assert len(tracker_cb.trained_batches) == 202 + 101 + 51 + 26 + 13\n    assert tracker_cb.steps_per_epoch_log[0:5] == [202, 101, 51, 26, 13]\n\n\ndef test_fit_generator_shape():\n    # predict_generator output shape behavior should be consistent\n    def expected_shape(batch_size, n_batches):\n        return (batch_size * n_batches, 4), (batch_size * n_batches, 3)\n\n    model = get_model(num_outputs=2)\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n\n    # Multiple outputs and one step.\n    batch_size = 5\n    sequence_length = 1\n    shape_0, shape_1 = expected_shape(batch_size, sequence_length)\n    out = model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    out = model.predict(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    # Multiple outputs and multiple steps.\n    batch_size = 5\n    sequence_length = 2\n    shape_0, shape_1 = expected_shape(batch_size, sequence_length)\n    out = model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    out = model.predict(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    # Create a model with a single output.\n    single_output_model = get_model(num_outputs=1)\n    single_output_model.compile(optimizer, loss,\n                                metrics=[], sample_weight_mode=None)\n\n    # Single output and one step.\n    batch_size = 5\n    sequence_length = 1\n    shape_0, _ = expected_shape(batch_size, sequence_length)\n    out = single_output_model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0\n\n    out = single_output_model.predict(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0\n\n    # Single output and multiple steps.\n    batch_size = 5\n    sequence_length = 2\n    shape_0, _ = expected_shape(batch_size, sequence_length)\n    out = single_output_model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0\n\n    out = single_output_model.predict(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0\n\n\ndef test_training_with_loss_instance():\n    a = Input(shape=(3,), name=\'input_a\')\n    b = Input(shape=(3,), name=\'input_b\')\n\n    dense = Dense(4, name=\'dense\')\n    c = dense(a)\n    d = dense(b)\n    e = Dropout(0.5, name=\'dropout\')(c)\n\n    model = Model([a, b], [d, e])\n    loss_weights = [1., 0.5]\n    model.compile(\n        \'sgd\',\n        loss=losses.MeanSquaredError(),\n        metrics=[\'mae\'],\n        loss_weights=loss_weights)\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_d_np = np.random.random((10, 4))\n    output_e_np = np.random.random((10, 4))\n\n    model.fit([input_a_np, input_b_np], [output_d_np, output_e_np],\n              epochs=1,\n              batch_size=5)\n\n\n@pytest.mark.skipif(sys.version_info < (3,),\n                    reason=\'Cannot catch warnings in python 2\')\ndef DISABLED_test_warnings():\n    """"""This test hangs Travis.""""""\n    a = Input(shape=(3,), name=\'input_a\')\n    b = Input(shape=(3,), name=\'input_b\')\n\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    @threadsafe_generator\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])\n\n    with pytest.warns(Warning) as w:\n        out = model.fit_generator(gen_data(4),\n                                  steps_per_epoch=10,\n                                  use_multiprocessing=True,\n                                  workers=2)\n    warning_raised = any([\'Sequence\' in str(w_.message) for w_ in w])\n    assert warning_raised, \'No warning raised when using generator with processes.\'\n\n    with pytest.warns(None) as w:\n        out = model.fit_generator(RandomSequence(3),\n                                  steps_per_epoch=4,\n                                  use_multiprocessing=True,\n                                  workers=2)\n    assert all([\'Sequence\' not in str(w_.message) for w_ in w]), (\n        \'A warning was raised for Sequence.\')\n\n\n@pytest.mark.skipif(K.backend() == \'tensorflow\',\n                    reason=\'Must for for tf.keras to support sparse ops.\')\ndef test_sparse_inputs_targets():\n    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n    in1 = Input(shape=(3,))\n    in2 = Input(shape=(3,))\n    out1 = Dropout(0.5, name=\'dropout\')(in1)\n    out2 = Dense(4, name=\'dense_1\')(in2)\n    model = Model([in1, in2], [out1, out2])\n    model.predict(test_inputs, batch_size=2)\n    model.compile(\'rmsprop\', \'mse\')\n    model.fit(test_inputs, test_outputs,\n              epochs=1, batch_size=2, validation_split=0.5)\n    model.evaluate(test_inputs, test_outputs, batch_size=2)\n\n\n@pytest.mark.skipif(K.backend() != \'tensorflow\',\n                    reason=\'sparse operations supported only by TensorFlow\')\ndef DISABLED_test_sparse_placeholder_fit():\n    """"""Must wait for tf.keras to support sparse operations.""""""\n    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n    in1 = Input(shape=(3,))\n    in2 = Input(shape=(3,), sparse=True)\n    out1 = Dropout(0.5, name=\'dropout\')(in1)\n    out2 = Dense(4, name=\'dense_1\')(in2)\n    model = Model([in1, in2], [out1, out2])\n    model.predict(test_inputs, batch_size=2)\n    model.compile(\'rmsprop\', \'mse\')\n    model.fit(test_inputs, test_outputs,\n              epochs=1, batch_size=2, validation_split=0.5)\n    model.evaluate(test_inputs, test_outputs, batch_size=2)\n\n\ndef test_trainable_argument():\n    x = np.random.random((5, 3))\n    y = np.random.random((5, 2))\n\n    model = Sequential()\n    model.add(Dense(2, input_dim=3, trainable=False))\n    model.compile(\'rmsprop\', \'mse\')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)\n\n    # test with nesting\n    inputs = Input(shape=(3,))\n    outputs = model(inputs)\n    model = Model(inputs, outputs)\n    model.compile(\'rmsprop\', \'mse\')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)\n\n\ndef test_with_list_as_targets():\n    model = Sequential()\n    model.add(Dense(1, input_dim=3, trainable=False))\n    model.compile(\'rmsprop\', \'mse\')\n\n    x = np.random.random((2, 3))\n    y = [0, 1]\n    model.train_on_batch(x, y)\n\n\ndef test_check_not_failing():\n    a = np.random.random((2, 1, 3))\n    training_utils.check_loss_and_target_compatibility(\n        [a], [losses.categorical_crossentropy], [a.shape])\n    training_utils.check_loss_and_target_compatibility(\n        [a], [losses.categorical_crossentropy], [(2, None, 3)])\n\n\ndef test_check_last_is_one():\n    a = np.random.random((2, 3, 1))\n    with pytest.raises(ValueError,\n                       match=\'You are passing a target array\'):\n        training_utils.check_loss_and_target_compatibility(\n            [a], [losses.CategoricalCrossentropy()], [a.shape])\n\n\ndef test_check_bad_shape():\n    a = np.random.random((2, 3, 5))\n    with pytest.raises(ValueError,\n                       match=\'targets to have the same shape\'):\n        training_utils.check_loss_and_target_compatibility(\n            [a], [losses.CategoricalCrossentropy()], [(2, 3, 6)])\n\n\n@pytest.mark.skipif(K.backend() != \'tensorflow\',\n                    reason=\'Requires TensorFlow backend\')\ndef test_model_with_input_feed_tensor():\n    """"""We test building a model with a TF variable as input.\n    We should be able to call fit, evaluate, predict,\n    by only passing them data for the placeholder inputs\n    in the model.\n    """"""\n    import tensorflow as tf\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    b = Input(shape=(3,), name=\'input_b\')\n\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n    model.summary()\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=[\'mean_squared_error\'],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch(input_b_np,\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({\'input_b\': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.test_on_batch({\'input_b\': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.predict_on_batch({\'input_b\': input_b_np})\n\n    # test fit\n    out = model.fit({\'input_b\': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n    out = model.fit(input_b_np,\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate({\'input_b\': input_b_np},\n                         [output_a_np, output_b_np], batch_size=10)\n    out = model.evaluate(input_b_np,\n                         [output_a_np, output_b_np], batch_size=10)\n\n    # test predict\n    out = model.predict({\'input_b\': input_b_np}, batch_size=10)\n    out = model.predict(input_b_np, batch_size=10)\n    assert len(out) == 2\n\n    # Now test a model with a single input\n    # i.e. we don\'t pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    a_2 = Dropout(0.5, name=\'dropout\')(a_2)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    model.compile(optimizer, loss, metrics=[\'mean_squared_error\'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)\n\n    # Same, without learning phase\n    # i.e. we don\'t pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    model.compile(optimizer, loss, metrics=[\'mean_squared_error\'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)\n\n\ndef test_model_with_partial_loss():\n    a = Input(shape=(3,), name=\'input_a\')\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    a_3 = dp(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = \'rmsprop\'\n    loss = {\'dropout\': \'mse\'}\n    model.compile(optimizer, loss, metrics=[\'mae\'])\n\n    input_a_np = np.random.random((10, 3))\n    output_a_np = np.random.random((10, 4))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])\n\n    # Same without dropout.\n    a = Input(shape=(3,), name=\'input_a\')\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    a_3 = Dense(4, name=\'dense_2\')(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = \'rmsprop\'\n    loss = {\'dense_2\': \'mse\'}\n    model.compile(optimizer, loss, metrics={\'dense_1\': \'mae\'})\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=\'cntk does not support external loss yet\')\ndef test_model_with_external_loss():\n    # None loss, only regularization loss.\n    a = Input(shape=(3,), name=\'input_a\')\n    a_2 = Dense(4, name=\'dense_1\',\n                kernel_regularizer=\'l1\',\n                bias_regularizer=\'l2\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    a_3 = dp(a_2)\n\n    model = Model(a, [a_2, a_3])\n\n    optimizer = \'rmsprop\'\n    loss = None\n    model.compile(optimizer, loss, metrics=[\'mae\'])\n\n    input_a_np = np.random.random((10, 3))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # No dropout, external loss.\n    a = Input(shape=(3,), name=\'input_a\')\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    a_3 = Dense(4, name=\'dense_2\')(a)\n\n    model = Model(a, [a_2, a_3])\n    model.add_loss(K.mean(a_3 + a_2))\n\n    optimizer = \'rmsprop\'\n    loss = None\n    model.compile(optimizer, loss, metrics=[\'mae\'])\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # Test fit with no external data at all.\n    if K.backend() == \'tensorflow\':\n        import tensorflow as tf\n\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_2 = Dense(4, name=\'dense_1\')(a)\n        a_2 = Dropout(0.5, name=\'dropout\')(a_2)\n        model = Model(a, a_2)\n        model.add_loss(K.mean(a_2))\n\n        model.compile(optimizer=\'rmsprop\',\n                      loss=None,\n                      metrics=[\'mean_squared_error\'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # define a generator to produce x=None and y=None\n        @threadsafe_generator\n        def data_tensors_generator():\n            while True:\n                yield (None, None)\n\n        generator = data_tensors_generator()\n\n        # test fit_generator for framework-native data tensors\n        out = model.fit_generator(generator, epochs=1,\n                                  steps_per_epoch=3)\n\n        # test evaluate_generator for framework-native data tensors\n        out = model.evaluate_generator(generator, steps=3)\n        out = model.evaluate(generator, steps=3)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert out.shape == (10 * 3, 4)\n\n        # Test multi-output model without external data.\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_1 = Dense(4, name=\'dense_1\')(a)\n        a_2 = Dropout(0.5, name=\'dropout\')(a_1)\n        model = Model(a, [a_1, a_2])\n        model.add_loss(K.mean(a_2))\n        model.compile(optimizer=\'rmsprop\',\n                      loss=None,\n                      metrics=[\'mean_squared_error\'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert len(out) == 2\n        assert out[0].shape == (10 * 3, 4)\n        assert out[1].shape == (10 * 3, 4)\n\n\ndef test_target_tensors():\n    # single-output, as list\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(4, input_shape=(4,), name=\'dense\'))\n    input_val = np.random.random((10, 4))\n    target_val = np.random.random((10, 4))\n    target = keras.backend.variable(target_val)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\', target_tensors=[target])\n    model.train_on_batch(input_val, None)\n\n    # single-output, as dict\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                  target_tensors={\'dense\': target})\n    model.train_on_batch(input_val, None)\n\n    # single-output, as tensor\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                  target_tensors=target)\n    model.train_on_batch(input_val, None)\n\n    # test invalid arguments\n    with pytest.raises(TypeError):\n        model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                      target_tensors=set())\n    with pytest.raises(ValueError):\n        model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                      target_tensors=[target, target])\n    with pytest.raises(ValueError):\n        model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                      target_tensors={\'dense2\': None})\n    with pytest.raises(ValueError):\n        model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                      target_tensors=[target])\n        model.train_on_batch(input_val, target_val)\n\n    # multi-output, as list\n    input_val = np.random.random((10, 4))\n    target_val_a = np.random.random((10, 4))\n    target_val_b = np.random.random((10, 4))\n    target_a = keras.backend.variable(target_val_a)\n    target_b = keras.backend.variable(target_val_b)\n\n    inputs = keras.layers.Input(shape=(4,))\n    output_a = keras.layers.Dense(4, name=\'dense_a\')(inputs)\n    output_b = keras.layers.Dense(4, name=\'dense_b\')(inputs)\n    model = keras.models.Model(inputs, [output_a, output_b])\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None)\n\n    # multi-output, as dict\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                  target_tensors={\'dense_a\': target_a,\n                                  \'dense_b\': target_b})\n    model.train_on_batch(input_val, None)\n\n    # multi-output, not enough target tensors when `target_tensors` is not a dict\n    with pytest.raises(ValueError,\n                       match=\'When passing a list as `target_tensors`, it should \'\n                             \'have one entry per model output. The model has \\\\d \'\n                             \'outputs, but you passed target_tensors=\'):\n        model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                      target_tensors=[target_a])\n    with pytest.raises(ValueError,\n                       match=\'The model has \\\\d outputs, but you passed a single \'\n                             \'tensor as `target_tensors`. Expected a list or \'\n                             \'a dict of tensors.\'):\n        model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                      target_tensors=target_a)\n\n    # test with sample weights\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None,\n                         sample_weight={\'dense_a\': np.random.random((10,))})\n\n\n@pytest.mark.skipif(K.backend() == \'tensorflow\' and\n                    tf.__version__.startswith(\'2\'),\n                    reason=\'Cannot have tensors as dict keys in TF2\')\ndef test_model_custom_target_tensors():\n    a = Input(shape=(3,), name=\'input_a\')\n    b = Input(shape=(3,), name=\'input_b\')\n\n    a_2 = Dense(4, name=\'dense_1\')(a)\n    dp = Dropout(0.5, name=\'dropout\')\n    b_2 = dp(b)\n\n    y = K.placeholder([10, 4], name=\'y\')\n    y1 = K.placeholder([10, 3], name=\'y1\')\n    y2 = K.placeholder([7, 5], name=\'y2\')\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n\n    # test list of target tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                      sample_weight_mode=None, target_tensors=[y, y1, y2])\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None, target_tensors=[y, y1])\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n    # test dictionary of target_tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss,\n                      metrics=[],\n                      loss_weights=loss_weights,\n                      sample_weight_mode=None,\n                      target_tensors={\'does_not_exist\': y2})\n    # test dictionary of target_tensors\n    model.compile(optimizer, loss,\n                  metrics=[],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None,\n                  target_tensors={\'dense_1\': y, \'dropout\': y1})\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n\n    # test with custom placeholder as target\n    pl_target_a = K.placeholder(shape=(None, 4))\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\',\n                  target_tensors={\'dense_1\': pl_target_a})\n    model.train_on_batch([input_a_np, input_b_np],\n                         [output_a_np, output_b_np])\n\n\n@pytest.mark.skipif(sys.version_info < (3,),\n                    reason=\'Cannot catch warnings in python 2\')\ndef test_trainable_weights_count_consistency():\n    """"""Tests the trainable weights consistency check of Model.\n\n    This verifies that a warning is shown if model.trainable is modified\n    and the model is summarized/run without a new call to .compile()\n\n    Reproduce issue #8121\n    """"""\n    a = Input(shape=(3,), name=\'input_a\')\n    model1 = Model(inputs=a, outputs=Dense(1)(a))\n\n    model1.trainable = False\n    b = Input(shape=(3,), name=\'input_b\')\n    y = model1(b)\n    model2 = Model(inputs=b, outputs=Dense(1)(y))\n\n    model2.compile(optimizer=\'adam\', loss=\'mse\')\n\n    model1.trainable = True\n\n    # Should warn on .summary()\n    with pytest.warns(UserWarning) as w:\n        model2.summary()\n    warning_raised = any([\'Discrepancy\' in str(w_.message) for w_ in w])\n    assert warning_raised, (\n        \'No warning raised when trainable is modified without .compile.\')\n\n    # And on .fit()\n    with pytest.warns(UserWarning) as w:\n        model2.fit(x=np.zeros((5, 3)), y=np.zeros((5, 1)))\n    warning_raised = any([\'Discrepancy\' in str(w_.message) for w_ in w])\n    assert warning_raised, (\n        \'No warning raised when trainable is modified without .compile.\')\n\n    # And shouldn\'t warn if we recompile\n    model2.compile(optimizer=\'adam\', loss=\'mse\')\n    with pytest.warns(None) as w:\n        model2.summary()\n    assert len(w) == 0, (\n        \'Warning raised even when .compile() is called after modifying .trainable\')\n\n\ndef test_pandas_dataframe():\n    input_a = Input(shape=(3,), name=\'input_a\')\n    input_b = Input(shape=(3,), name=\'input_b\')\n\n    x = Dense(4, name=\'dense_1\')(input_a)\n    y = Dense(3, name=\'desne_2\')(input_b)\n\n    model_1 = Model(inputs=input_a, outputs=x)\n    model_2 = Model(inputs=[input_a, input_b], outputs=[x, y])\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n\n    model_1.compile(optimizer=optimizer, loss=loss)\n    model_2.compile(optimizer=optimizer, loss=loss)\n\n    input_a_df = pd.DataFrame(np.random.random((10, 3)))\n    input_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    output_a_df = pd.DataFrame(np.random.random((10, 4)))\n    output_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    model_1.fit(input_a_df,\n                output_a_df)\n    model_2.fit([input_a_df, input_b_df],\n                [output_a_df, output_b_df])\n    model_1.fit([input_a_df],\n                [output_a_df])\n    model_1.fit({\'input_a\': input_a_df},\n                output_a_df)\n    model_2.fit({\'input_a\': input_a_df, \'input_b\': input_b_df},\n                [output_a_df, output_b_df])\n\n    model_1.predict(input_a_df)\n    model_2.predict([input_a_df, input_b_df])\n    model_1.predict([input_a_df])\n    model_1.predict({\'input_a\': input_a_df})\n    model_2.predict({\'input_a\': input_a_df, \'input_b\': input_b_df})\n\n    model_1.predict_on_batch(input_a_df)\n    model_2.predict_on_batch([input_a_df, input_b_df])\n    model_1.predict_on_batch([input_a_df])\n    model_1.predict_on_batch({\'input_a\': input_a_df})\n    model_2.predict_on_batch({\'input_a\': input_a_df, \'input_b\': input_b_df})\n\n    model_1.evaluate(input_a_df,\n                     output_a_df)\n    model_2.evaluate([input_a_df, input_b_df],\n                     [output_a_df, output_b_df])\n    model_1.evaluate([input_a_df],\n                     [output_a_df])\n    model_1.evaluate({\'input_a\': input_a_df},\n                     output_a_df)\n    model_2.evaluate({\'input_a\': input_a_df, \'input_b\': input_b_df},\n                     [output_a_df, output_b_df])\n\n    model_1.train_on_batch(input_a_df,\n                           output_a_df)\n    model_2.train_on_batch([input_a_df, input_b_df],\n                           [output_a_df, output_b_df])\n    model_1.train_on_batch([input_a_df],\n                           [output_a_df])\n    model_1.train_on_batch({\'input_a\': input_a_df},\n                           output_a_df)\n    model_2.train_on_batch({\'input_a\': input_a_df, \'input_b\': input_b_df},\n                           [output_a_df, output_b_df])\n\n    model_1.test_on_batch(input_a_df,\n                          output_a_df)\n    model_2.test_on_batch([input_a_df, input_b_df],\n                          [output_a_df, output_b_df])\n    model_1.test_on_batch([input_a_df],\n                          [output_a_df])\n    model_1.test_on_batch({\'input_a\': input_a_df},\n                          output_a_df)\n    model_2.test_on_batch({\'input_a\': input_a_df, \'input_b\': input_b_df},\n                          [output_a_df, output_b_df])\n\n\n@pytest.mark.skipif(K.backend() != \'tensorflow\', reason=\'Requires TensorFlow\')\ndef test_training_and_eval_methods_on_symbolic_tensors_single_io():\n    x = keras.layers.Input(shape=(3,), name=\'input\')\n    y = keras.layers.Dense(4, name=\'dense\')(x)\n    model = keras.Model(x, y)\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    metrics = [\'mae\']\n    model.compile(optimizer, loss, metrics=metrics)\n\n    inputs = keras.backend.zeros(shape=(10, 3))\n    targets = keras.backend.zeros(shape=(10, 4))\n\n    model.fit(inputs, targets, epochs=1, steps_per_epoch=2, verbose=0)\n    model.evaluate(inputs, targets, steps=2, verbose=0)\n    model.predict(inputs, steps=2)\n    model.train_on_batch(inputs, targets)\n    model.test_on_batch(inputs, targets)\n    model.fit(inputs, targets,\n              epochs=1, steps_per_epoch=2, verbose=1,\n              validation_data=(inputs, targets), validation_steps=2)\n\n\n@pytest.mark.skipif(K.backend() != \'tensorflow\', reason=\'Requires TensorFlow\')\ndef test_training_and_eval_methods_on_symbolic_tensors_multi_io():\n    a = keras.layers.Input(shape=(3,), name=\'input_a\')\n    b = keras.layers.Input(shape=(3,), name=\'input_b\')\n\n    dense = keras.layers.Dense(4, name=\'dense\')\n    c = dense(a)\n    d = dense(b)\n    e = keras.layers.Dropout(0.5, name=\'dropout\')(c)\n\n    model = keras.models.Model([a, b], [d, e])\n\n    optimizer = \'rmsprop\'\n    loss = \'mse\'\n    loss_weights = [1., 0.5]\n    metrics = [\'mae\']\n    model.compile(optimizer, loss, metrics=metrics, loss_weights=loss_weights)\n\n    input_a_tf = keras.backend.zeros(shape=(10, 3))\n    input_b_tf = keras.backend.zeros(shape=(10, 3))\n\n    output_d_tf = keras.backend.zeros(shape=(10, 4))\n    output_e_tf = keras.backend.zeros(shape=(10, 4))\n\n    model.fit(\n        [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n        epochs=1,\n        steps_per_epoch=2,\n        verbose=0)\n    with pytest.raises(ValueError,\n                       match=\'should specify the `steps_per_epoch`\'):\n        model.fit(\n            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n            epochs=1,\n            batch_size=5,\n            verbose=0)\n\n    model.train_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])\n\n    # Test with dictionary inputs\n    model.fit(\n        {\'input_a\': input_a_tf,\n         \'input_b\': input_b_tf},\n        {\'dense\': output_d_tf,\n         \'dropout\': output_e_tf},\n        epochs=1,\n        steps_per_epoch=2,\n        verbose=0)\n    model.fit(\n        {\'input_a\': input_a_tf,\n         \'input_b\': input_b_tf},\n        {\'dense\': output_d_tf,\n         \'dropout\': output_e_tf},\n        validation_data=({\'input_a\': input_a_tf,\n                          \'input_b\': input_b_tf},\n                         {\'dense\': output_d_tf,\n                          \'dropout\': output_e_tf}),\n        epochs=1,\n        steps_per_epoch=2,\n        validation_steps=2,\n        verbose=0)\n    model.train_on_batch(\n        {\'input_a\': input_a_tf,\n         \'input_b\': input_b_tf},\n        {\'dense\': output_d_tf,\n         \'dropout\': output_e_tf})\n\n    # Test with validation data\n    model.fit(\n        [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n        validation_data=([input_a_tf, input_b_tf],\n                         [output_d_tf, output_e_tf]),\n        epochs=1,\n        steps_per_epoch=2,\n        validation_steps=2,\n        verbose=0)\n    # Test with validation split\n    with pytest.raises(ValueError,\n                       match=\'you cannot use `validation_split`\'):\n        model.fit(\n            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n            epochs=2,\n            steps_per_epoch=2,\n            verbose=0,\n            validation_split=0.2,\n            validation_steps=2)\n\n    # Test evaluation / prediction methods\n    model.evaluate([input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n                   steps=2, verbose=0)\n    model.predict([input_a_tf, input_b_tf], steps=2)\n    model.test_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])\n\n\ndef test_model_with_crossentropy_losses_channels_first():\n    """"""Tests use of all crossentropy losses with `channels_first`.\n\n    Tests `sparse_categorical_crossentropy`, `categorical_crossentropy`,\n    and `binary_crossentropy`.\n    Verifies that evaluate gives the same result with either\n    `channels_first` or `channels_last` image_data_format.\n    Tests PR #9715.\n    """"""\n\n    def prepare_simple_model(input_tensor, loss_name, target):\n        axis = 1 if K.image_data_format() == \'channels_first\' else -1\n        if loss_name == \'sparse_categorical_crossentropy\':\n            loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = np.amax(target) + 1\n            activation = \'softmax\'\n        elif loss_name == \'categorical_crossentropy\':\n            loss = lambda y_true, y_pred: K.categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = target.shape[axis]\n            activation = \'softmax\'\n        elif loss_name == \'binary_crossentropy\':\n            loss = lambda y_true, y_pred: K.binary_crossentropy(y_true, y_pred)\n            num_channels = target.shape[axis]\n            activation = \'sigmoid\'\n        predictions = Conv2D(num_channels, 1, activation=activation,\n                             kernel_initializer=\'ones\',\n                             bias_initializer=\'ones\')(input_tensor)\n        simple_model = Model(inputs=input_tensor, outputs=predictions)\n        simple_model.compile(optimizer=\'rmsprop\', loss=loss)\n        return simple_model\n\n    losses_to_test = [\'sparse_categorical_crossentropy\',\n                      \'categorical_crossentropy\', \'binary_crossentropy\']\n\n    data_channels_first = np.array([[[[8., 7.1, 0.], [4.5, 2.6, 0.55],\n                                      [0.9, 4.2, 11.2]]]], dtype=np.float32)\n    # Labels for testing 4-class sparse_categorical_crossentropy, 4-class\n    # categorical_crossentropy, and 2-class binary_crossentropy:\n    labels_channels_first = [np.array([[[[0, 1, 3], [2, 1, 0], [2, 2, 1]]]]),\n                             np.array([[[[0, 1, 0], [0, 1, 0], [0, 0, 0]],\n                                        [[1, 0, 0], [0, 0, 1], [0, 1, 0]],\n                                        [[0, 0, 0], [1, 0, 0], [0, 0, 1]],\n                                        [[0, 0, 1], [0, 0, 0], [1, 0, 0]]]]),\n                             np.array([[[[0, 1, 0], [0, 1, 0], [0, 0, 1]],\n                                        [[1, 0, 1], [1, 0, 1], [1, 1, 0]]]])]\n    # Compute one loss for each loss function in the list `losses_to_test`:\n    loss_channels_last = [0., 0., 0.]\n    loss_channels_first = [0., 0., 0.]\n\n    old_data_format = K.image_data_format()\n\n    # Evaluate a simple network with channels last, with all three loss\n    # functions:\n    K.set_image_data_format(\'channels_last\')\n    data = np.moveaxis(data_channels_first, 1, -1)\n    for index, loss_function in enumerate(losses_to_test):\n        labels = np.moveaxis(labels_channels_first[index], 1, -1)\n        inputs = Input(shape=(3, 3, 1))\n        model = prepare_simple_model(inputs, loss_function, labels)\n        loss_channels_last[index] = model.evaluate(x=data, y=labels,\n                                                   batch_size=1, verbose=0)\n\n    # Evaluate the same network with channels first, with all three loss\n    # functions:\n    K.set_image_data_format(\'channels_first\')\n    assert K.image_data_format() == \'channels_first\'\n    data = data_channels_first\n    for index, loss_function in enumerate(losses_to_test):\n        labels = labels_channels_first[index]\n        inputs = Input(shape=(1, 3, 3))\n        model = prepare_simple_model(inputs, loss_function, labels)\n        loss_channels_first[index] = model.evaluate(x=data, y=labels,\n                                                    batch_size=1, verbose=0)\n\n    K.set_image_data_format(old_data_format)\n\n    assert_allclose(loss_channels_first, loss_channels_last,\n                    err_msg=\'{}{}\'.format(\'Computed different losses for \',\n                                          \'channels_first and channels_last.\'))\n\n\ndef test_dynamic_set_inputs():\n    model = Sequential()\n    model.add(Dense(16, input_dim=32))\n    model.add(Activation(\'relu\'))\n\n    model2 = Sequential()\n    model2.add(model.layers[-1])\n    model2.add(Dense(8))\n    preds2 = model2.predict([np.random.random((1, 32))])\n    assert preds2.shape == (1, 8)\n\n    model3 = Model(inputs=model.inputs, outputs=model.outputs)\n    with pytest.raises(ValueError):\n        model3._set_inputs(model.inputs)\n\n    model3.inputs = None\n    model3._set_inputs(model.inputs)\n    preds3 = model3.predict([np.random.random((1, 32))])\n    assert preds3.shape == (1, 16)\n\n    model3.inputs = None\n    model3._set_inputs(model.input)\n    preds3 = model3.predict(np.random.random((1, 32)))\n    assert preds3.shape == (1, 16)\n\n    aux_input = Input(shape=(5,), name=\'aux_input\')\n    aux_model = Dense(3)(aux_input)\n    model4 = Model(inputs=model.inputs + [aux_input],\n                   outputs=Concatenate()(model.outputs + [aux_model]))\n    model4.inputs = None\n    model4._set_inputs(model.inputs + [aux_input])\n    preds4 = model4.predict([np.random.random((1, 32)),\n                             np.random.random((1, 5))])\n    assert preds4.shape == (1, 19)\n\n\ndef test_sample_weights():\n    y = np.array([0, 1, 0, 0, 2])\n    sample_weights = np.array([0.5, 1., 1., 0., 2.])\n    class_weights = {0: 0.5, 1: 1., 2: 1.5}\n\n    # Only `sample_weights`.\n    weights = training_utils.standardize_weights(y, sample_weights)\n    assert np.allclose(weights, sample_weights)\n\n    # Only `class_weights`.\n    weights = training_utils.standardize_weights(y, class_weight=class_weights)\n    assert np.allclose(weights, np.array([0.5, 1., 0.5, 0.5, 1.5]))\n\n    # Both \'sample_weights` and \'class_weights`.\n    weights = training_utils.standardize_weights(y, sample_weights,\n                                                 class_weights)\n    expected = sample_weights * np.array([0.5, 1., 0.5, 0.5, 1.5])\n    assert np.allclose(weights, expected)\n\n\ndef test_validation_freq():\n    model = Sequential([Dense(1)])\n    model.compile(\'sgd\', \'mse\')\n\n    def _gen():\n        while True:\n            yield np.ones((2, 10)), np.ones((2, 1))\n\n    x, y = np.ones((10, 10)), np.ones((10, 1))\n\n    class ValCounter(Callback):\n\n        def __init__(self):\n            self.val_runs = 0\n\n        def on_test_begin(self, logs=None):\n            self.val_runs += 1\n\n    # Test in training_arrays.py\n    val_counter = ValCounter()\n    model.fit(\n        x,\n        y,\n        batch_size=2,\n        epochs=4,\n        validation_data=(x, y),\n        validation_freq=2,\n        callbacks=[val_counter])\n    assert val_counter.val_runs == 2\n\n    # Test in training_generator.py\n    val_counter = ValCounter()\n    model.fit_generator(\n        _gen(),\n        epochs=4,\n        steps_per_epoch=5,\n        validation_data=(x, y),\n        validation_freq=[4, 2, 2, 1],\n        callbacks=[val_counter])\n    assert val_counter.val_runs == 3\n\n\ndef test_loss_correctness():\n    class Bias(Layer):\n\n        def build(self, input_shape):\n            self.bias = self.add_weight(\'bias\', (1,), initializer=\'zeros\')\n\n        def call(self, inputs):\n            return inputs + self.bias\n\n    inp = Input(shape=(1,))\n    out = Bias()(inp)\n    model = Model(inp, out)\n    model.compile(\n        keras.optimizers.SGD(lr=0.1),\n        loss=keras.losses.MeanAbsoluteError())\n\n    x = np.array([[0.], [1.], [2.]])\n    y = np.array([[0.5], [2.], [3.5]])\n    history = model.fit(x, y, batch_size=3, epochs=5)\n    np.allclose(history.history[\'loss\'], [1., 0.9, 0.8, 0.7, 0.6])\n\n\ndef test_model_metrics_list():\n\n    class LayerWithAddMetric(Layer):\n\n        def __init__(self):\n            super(LayerWithAddMetric, self).__init__()\n            self.dense = keras.layers.Dense(1, kernel_initializer=\'ones\')\n\n        def __call__(self, inputs):\n            outputs = self.dense(inputs)\n            return outputs\n\n    class LayerWithNestedAddMetricLayer(Layer):\n\n        def __init__(self):\n            super(LayerWithNestedAddMetricLayer, self).__init__()\n            self.layer = LayerWithAddMetric()\n\n        def call(self, inputs):\n            outputs = self.layer(inputs)\n            self.add_metric(K.sum(outputs), name=\'metric_4\')\n            return outputs\n\n    x = Input(shape=(1,))\n    y = LayerWithNestedAddMetricLayer()(x)\n\n    model = keras.models.Model(x, y)\n    model.add_metric(K.sum(y), name=\'metric_2\')\n    model.add_metric(metrics.Mean(name=\'metric_3\')(y))\n\n    model.compile(\n        \'sgd\',\n        loss=\'mse\',\n        metrics=[metrics.MeanSquaredError(\'metric_1\')])\n\n    # Verify that the metrics added using `compile` and `add_metric` API are\n    # included\n    for m1, m2 in zip([m.name for m in model._compile_metrics], [\'metric_1\']):\n        assert m1 == m2\n\n    for m1, m2 in zip(\n            [m.name for m in model.metrics],\n            [\'metric_1\', \'metric_2\', \'metric_3\', \'metric_4\']):\n        assert m1 == m2\n\n\ndef test_model_metrics_list_in_call():\n\n    class TestModel(Model):\n\n        def __init__(self):\n            super(TestModel, self).__init__(name=\'test_model\')\n            self.dense1 = keras.layers.Dense(2)\n\n        def call(self, x):\n            self.add_metric(K.sum(x), name=\'metric_2\')\n            return self.dense1(x)\n\n    model = TestModel()\n    model.compile(\n        loss=\'mse\',\n        optimizer=\'adam\',\n        metrics=[metrics.MeanSquaredError(\'metric_1\')])\n    x = np.ones(shape=(10, 1))\n    y = np.ones(shape=(10, 2))\n    model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))\n\n    # Verify that the metrics added using `compile` and `add_metric` API are\n    # included\n    for m1, m2 in zip([m.name for m in model._compile_metrics], [\'metric_1\']):\n        assert m1 == m2\n\n    for m1, m2 in zip(\n            [m.name for m in model.metrics],\n            [\'metric_1\', \'metric_2\']):\n        assert m1 == m2\n\n\ndef test_duplicate_metric_name_in_add_metric():\n\n    class TestModel(Model):\n\n        def __init__(self):\n            super(TestModel, self).__init__(name=\'test_model\')\n            self.dense1 = keras.layers.Dense(2, kernel_initializer=\'ones\')\n            self.mean = metrics.Mean(name=\'metric_1\')\n            self.mean2 = metrics.Mean(name=\'metric_1\')\n\n        def call(self, x):\n            self.add_metric(self.mean(x), name=\'metric_1\')\n            return self.dense1(x)\n\n    model = TestModel()\n    model.compile(loss=\'mse\', optimizer=\'adam\')\n\n    x = np.ones(shape=(10, 1))\n    y = np.ones(shape=(10, 2))\n    with pytest.raises(ValueError):\n        model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))\n\n\ndef test_add_metric_on_model():\n    x = Input(shape=(1,))\n    y = Dense(1, kernel_initializer=\'ones\', trainable=False)(x)\n    model = Model(x, y)\n    model.add_metric(K.sum(y), name=\'metric_1\')\n    model.add_metric(metrics.Mean(name=\'metric_2\')(y))\n    model.compile(\'sgd\', loss=\'mse\', metrics=[\'mse\'])\n\n    inputs = np.ones(shape=(10, 1))\n    targets = np.zeros(shape=(10, 1))\n    history = model.fit(\n        inputs,\n        targets,\n        epochs=2,\n        batch_size=5,\n        validation_data=(inputs, targets))\n    assert history.history[\'metric_1\'][-1] == 5\n    assert history.history[\'val_metric_1\'][-1] == 5\n\n    assert history.history[\'metric_2\'][-1] == 1\n    assert history.history[\'val_metric_2\'][-1] == 1\n\n    eval_results = model.evaluate(inputs, targets, batch_size=5)\n    assert eval_results[-2] == 5\n    assert eval_results[-1] == 1\n\n    model.predict(inputs, batch_size=5)\n    model.train_on_batch(inputs, targets)\n    model.test_on_batch(inputs, targets)\n\n\ndef test_add_metric_in_model_call():\n\n    class TestModel(Model):\n\n        def __init__(self):\n            super(TestModel, self).__init__(name=\'test_model\')\n            self.dense1 = keras.layers.Dense(2, kernel_initializer=\'ones\')\n            self.mean = metrics.Mean(name=\'metric_1\')\n\n        def call(self, x):\n            self.add_metric(K.sum(x), name=\'metric_2\')\n            # Provide same name as in the instance created in __init__\n            # for eager mode\n            self.add_metric(self.mean(x), name=\'metric_1\')\n            return self.dense1(x)\n\n    model = TestModel()\n    model.compile(loss=\'mse\', optimizer=\'sgd\')\n\n    x = np.ones(shape=(10, 1))\n    y = np.ones(shape=(10, 2))\n    history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))\n    assert np.isclose(history.history[\'metric_1\'][-1], 1, 0)\n    assert np.isclose(history.history[\'val_metric_1\'][-1], 1, 0)\n    assert np.isclose(history.history[\'metric_2\'][-1], 5, 0)\n    assert np.isclose(history.history[\'val_metric_2\'][-1], 5, 0)\n\n    eval_results = model.evaluate(x, y, batch_size=5)\n    assert np.isclose(eval_results[1], 1, 0)\n    assert np.isclose(eval_results[2], 5, 0)\n\n    model.predict(x, batch_size=5)\n    model.train_on_batch(x, y)\n    model.test_on_batch(x, y)\n\n\ndef test_multiple_add_metric_calls():\n\n    class TestModel(Model):\n\n        def __init__(self):\n            super(TestModel, self).__init__(name=\'test_model\')\n            self.dense1 = keras.layers.Dense(2, kernel_initializer=\'ones\')\n            self.mean1 = metrics.Mean(name=\'metric_1\')\n            self.mean2 = metrics.Mean(name=\'metric_2\')\n\n        def call(self, x):\n            self.add_metric(self.mean2(x), name=\'metric_2\')\n            self.add_metric(self.mean1(x), name=\'metric_1\')\n            self.add_metric(K.sum(x), name=\'metric_3\')\n            return self.dense1(x)\n\n    model = TestModel()\n    model.compile(loss=\'mse\', optimizer=\'sgd\')\n\n    x = np.ones(shape=(10, 1))\n    y = np.ones(shape=(10, 2))\n    history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))\n    assert np.isclose(history.history[\'metric_1\'][-1], 1, 0)\n    assert np.isclose(history.history[\'metric_2\'][-1], 1, 0)\n    assert np.isclose(history.history[\'metric_3\'][-1], 5, 0)\n\n    eval_results = model.evaluate(x, y, batch_size=5)\n    assert np.allclose(eval_results[1:4], [1, 1, 5], 0.1)\n\n    model.predict(x, batch_size=5)\n    model.train_on_batch(x, y)\n    model.test_on_batch(x, y)\n\n\ndef test_add_metric_in_layer_call():\n\n    class TestLayer(Layer):\n\n        def build(self, input_shape):\n            self.a = self.add_weight(\n                \'a\', (1, 1), initializer=\'ones\', trainable=False)\n            self.built = True\n\n        def call(self, inputs):\n            self.add_metric(K.sum(inputs), name=\'metric_1\')\n            return inputs + 1\n\n    inp = Input(shape=(1,))\n    x = TestLayer(input_shape=(1,))(inp)\n    x = keras.layers.Dense(2, kernel_initializer=\'ones\')(x)\n\n    model = Model(inp, x)\n    model.compile(\'adam\', loss=\'mse\')\n\n    x = np.ones(shape=(10, 1))\n    y = np.ones(shape=(10, 2))\n    history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))\n    assert np.isclose(history.history[\'metric_1\'][-1], 5, 0)\n    assert np.isclose(history.history[\'val_metric_1\'][-1], 5, 0)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/layers/advanced_activations_test.py,0,"b""import pytest\nfrom keras.utils.test_utils import layer_test\nfrom keras import layers\nfrom keras import backend as K\n\n\n@pytest.mark.parametrize('activation_layer',\n                         [layers.LeakyReLU,\n                          layers.ELU])\n@pytest.mark.parametrize('alpha', [0., .5, -1.])\ndef test_linear_unit_activations(activation_layer,\n                                 alpha):\n    layer_test(activation_layer, kwargs={'alpha': alpha},\n               input_shape=(2, 3, 4))\n\n\ndef test_prelu():\n    layer_test(layers.PReLU, kwargs={},\n               input_shape=(2, 3, 4))\n\n\ndef test_prelu_share():\n    layer_test(layers.PReLU, kwargs={'shared_axes': 1},\n               input_shape=(2, 3, 4))\n\n\ndef test_thresholded_relu():\n    layer_test(layers.ThresholdedReLU, kwargs={'theta': 0.5},\n               input_shape=(2, 3, 4))\n\n\n@pytest.mark.parametrize('axis', [1, -1])\ndef test_softmax(axis):\n    layer_test(layers.Softmax, kwargs={'axis': axis},\n               input_shape=(2, 3, 4))\n\n\ndef test_relu():\n    layer_test(layers.ReLU,\n               kwargs={'max_value': 10,\n                       'negative_slope': 0.2,\n                       'threshold': 3.0},\n               input_shape=(2, 3, 4))\n    layer_test(layers.ReLU,\n               kwargs={'max_value': 6},\n               input_shape=(2, 3, 4))\n    layer_test(layers.ReLU,\n               kwargs={'negative_slope': 0.2},\n               input_shape=(2, 3, 4))\n\n    # max_value of ReLU layer cannot be negative value\n    with pytest.raises(ValueError):\n        layer_test(layers.ReLU, kwargs={'max_value': -2.0},\n                   input_shape=(2, 3, 4))\n\n    # negative_slope of ReLU layer cannot be negative value\n    with pytest.raises(ValueError):\n        layer_test(layers.ReLU, kwargs={'negative_slope': -2.0},\n                   input_shape=(2, 3, 4))\n\n\n@pytest.mark.skipif((K.backend() != 'tensorflow'),\n                    reason='TF-specific implementation.')\ndef test_relu_tf_ops():\n    inputs = layers.Input((3,))\n    # Test that `relu` op gets used.\n    outputs = layers.ReLU()(inputs)\n    assert outputs.op.name.lower().endswith('/relu')\n    # Test that `leakyrelu` op gets used.\n    outputs = layers.ReLU(negative_slope=0.2)(inputs)\n    assert outputs.op.name.lower().endswith('/leakyrelu')\n    # Test that `relu6` op gets used.\n    outputs = layers.ReLU(max_value=6)(inputs)\n    assert outputs.op.name.lower().endswith('/relu6')\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/convolutional_recurrent_test.py,0,"b'import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras import backend as K\nfrom keras.models import Sequential, Model\nfrom keras.layers import convolutional_recurrent, Input, Masking, Lambda\nfrom keras.utils.test_utils import layer_test\nfrom keras import regularizers\n\nnum_row = 3\nnum_col = 3\nfilters = 2\nnum_samples = 1\ninput_channel = 2\ninput_num_row = 5\ninput_num_col = 5\nsequence_len = 2\n\n\n@pytest.mark.parametrize(\'data_format\', [\'channels_first\', \'channels_last\'])\n@pytest.mark.parametrize(\'return_sequences\', [True, False])\n@pytest.mark.parametrize(\'use_mask\', [True, False])\ndef test_convolutional_recurrent(data_format, return_sequences, use_mask):\n\n    class Masking5D(Masking):\n        """"""Regular masking layer returns wrong shape of mask for RNN""""""\n        def compute_mask(self, inputs, mask=None):\n            return K.any(K.not_equal(inputs, 0.), axis=[2, 3, 4])\n\n    if data_format == \'channels_first\':\n        inputs = np.random.rand(num_samples, sequence_len,\n                                input_channel,\n                                input_num_row, input_num_col)\n    else:\n        inputs = np.random.rand(num_samples, sequence_len,\n                                input_num_row, input_num_col,\n                                input_channel)\n\n    # test for return state:\n    x = Input(batch_shape=inputs.shape)\n    kwargs = {\'data_format\': data_format,\n              \'return_sequences\': return_sequences,\n              \'return_state\': True,\n              \'stateful\': True,\n              \'filters\': filters,\n              \'kernel_size\': (num_row, num_col),\n              \'padding\': \'valid\'}\n    layer = convolutional_recurrent.ConvLSTM2D(**kwargs)\n    layer.build(inputs.shape)\n    if use_mask:\n        outputs = layer(Masking5D()(x))\n    else:\n        outputs = layer(x)\n    output, states = outputs[0], outputs[1:]\n    assert len(states) == 2\n    model = Model(x, states[0])\n    state = model.predict(inputs)\n    np.testing.assert_allclose(K.eval(layer.states[0]), state, atol=1e-4)\n\n    # test for output shape:\n    output = layer_test(convolutional_recurrent.ConvLSTM2D,\n                        kwargs={\'data_format\': data_format,\n                                \'return_sequences\': return_sequences,\n                                \'filters\': filters,\n                                \'kernel_size\': (num_row, num_col),\n                                \'padding\': \'valid\'},\n                        input_shape=inputs.shape)\n\n\ndef test_convolutional_recurrent_statefulness():\n\n    data_format = \'channels_last\'\n    return_sequences = False\n    inputs = np.random.rand(num_samples, sequence_len,\n                            input_num_row, input_num_col,\n                            input_channel)\n    # Tests for statefulness\n    model = Sequential()\n    kwargs = {\'data_format\': data_format,\n              \'return_sequences\': return_sequences,\n              \'filters\': filters,\n              \'kernel_size\': (num_row, num_col),\n              \'stateful\': True,\n              \'batch_input_shape\': inputs.shape,\n              \'padding\': \'same\'}\n    layer = convolutional_recurrent.ConvLSTM2D(**kwargs)\n\n    model.add(layer)\n    model.compile(optimizer=\'sgd\', loss=\'mse\')\n    out1 = model.predict(np.ones_like(inputs))\n\n    # train once so that the states change\n    model.train_on_batch(np.ones_like(inputs),\n                         np.random.random(out1.shape))\n    out2 = model.predict(np.ones_like(inputs))\n\n    # if the state is not reset, output should be different\n    assert(out1.max() != out2.max())\n\n    # check that output changes after states are reset\n    # (even though the model itself didn\'t change)\n    layer.reset_states()\n    out3 = model.predict(np.ones_like(inputs))\n    assert(out2.max() != out3.max())\n\n    # check that container-level reset_states() works\n    model.reset_states()\n    out4 = model.predict(np.ones_like(inputs))\n    assert_allclose(out3, out4, atol=1e-5)\n\n    # check that the call to `predict` updated the states\n    out5 = model.predict(np.ones_like(inputs))\n    assert(out4.max() != out5.max())\n\n    # cntk doesn\'t support eval convolution with static\n    # variable, will enable it later\n    if K.backend() != \'cntk\':\n        # check regularizers\n        kwargs = {\'data_format\': data_format,\n                  \'return_sequences\': return_sequences,\n                  \'kernel_size\': (num_row, num_col),\n                  \'stateful\': True,\n                  \'filters\': filters,\n                  \'batch_input_shape\': inputs.shape,\n                  \'kernel_regularizer\': regularizers.L1L2(l1=0.01),\n                  \'recurrent_regularizer\': regularizers.L1L2(l1=0.01),\n                  \'bias_regularizer\': \'l2\',\n                  \'activity_regularizer\': \'l2\',\n                  \'kernel_constraint\': \'max_norm\',\n                  \'recurrent_constraint\': \'max_norm\',\n                  \'bias_constraint\': \'max_norm\',\n                  \'padding\': \'same\'}\n\n        layer = convolutional_recurrent.ConvLSTM2D(**kwargs)\n        layer.build(inputs.shape)\n        assert len(layer.losses) == 3\n        assert layer.activity_regularizer\n        output = layer(K.variable(np.ones(inputs.shape)))\n        assert len(layer.losses) == 4\n        K.eval(output)\n\n    # check dropout\n    layer_test(convolutional_recurrent.ConvLSTM2D,\n               kwargs={\'data_format\': data_format,\n                       \'return_sequences\': return_sequences,\n                       \'filters\': filters,\n                       \'kernel_size\': (num_row, num_col),\n                       \'padding\': \'same\',\n                       \'dropout\': 0.1,\n                       \'recurrent_dropout\': 0.1},\n               input_shape=inputs.shape)\n\n    # check state initialization\n    layer = convolutional_recurrent.ConvLSTM2D(\n        filters=filters, kernel_size=(num_row, num_col),\n        data_format=data_format, return_sequences=return_sequences)\n    layer.build(inputs.shape)\n    x = Input(batch_shape=inputs.shape)\n    initial_state = layer.get_initial_state(x)\n    y = layer(x, initial_state=initial_state)\n    model = Model(x, y)\n    assert (model.predict(inputs).shape ==\n            layer.compute_output_shape(inputs.shape))\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/layers/convolutional_test.py,0,"b'import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras.utils.test_utils import layer_test\nfrom keras import backend as K\nfrom keras.layers import convolutional\nfrom keras.models import Sequential\nfrom keras.backend import load_backend\n\n\n# TensorFlow does not support full convolution.\nif K.backend() == \'theano\':\n    _convolution_paddings = [\'valid\', \'same\', \'full\']\nelse:\n    _convolution_paddings = [\'valid\', \'same\']\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\' and load_backend.dev.type() == 0),\n                    reason=\'cntk only support dilated conv on GPU\')\n@pytest.mark.parametrize(\n    \'layer_kwargs,input_length,expected_output\',\n    [\n        # Causal\n        ({\'filters\': 1, \'kernel_size\': 2, \'dilation_rate\': 1, \'padding\': \'causal\',\n          \'kernel_initializer\': \'ones\', \'use_bias\': False},\n         4, [[[0], [1], [3], [5]]]),\n        # Non-causal\n        ({\'filters\': 1, \'kernel_size\': 2, \'dilation_rate\': 1, \'padding\': \'valid\',\n          \'kernel_initializer\': \'ones\', \'use_bias\': False},\n         4, [[[1], [3], [5]]]),\n        # Causal dilated with larger kernel size\n        ({\'filters\': 1, \'kernel_size\': 3, \'dilation_rate\': 2, \'padding\': \'causal\',\n          \'kernel_initializer\': \'ones\', \'use_bias\': False},\n         10, np.float32([[[0], [1], [2], [4], [6], [9], [12], [15], [18], [21]]])),\n    ]\n)\ndef test_causal_dilated_conv(layer_kwargs, input_length, expected_output):\n    input_data = np.reshape(np.arange(input_length, dtype=\'float32\'),\n                            (1, input_length, 1))\n    layer_test(convolutional.Conv1D, input_data=input_data,\n               kwargs=layer_kwargs, expected_output=expected_output)\n\n\n@pytest.mark.parametrize(\n    \'padding,strides\',\n    [(padding, strides)\n     for padding in _convolution_paddings\n     for strides in [1, 2]\n     if not (padding == \'same\' and strides != 1)]\n)\ndef test_conv_1d(padding, strides):\n    batch_size = 2\n    steps = 8\n    input_dim = 2\n    kernel_size = 3\n    filters = 3\n\n    layer_test(convolutional.Conv1D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'padding\': padding,\n                       \'strides\': strides},\n               input_shape=(batch_size, steps, input_dim))\n\n    layer_test(convolutional.Conv1D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'padding\': padding,\n                       \'kernel_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'kernel_constraint\': \'max_norm\',\n                       \'bias_constraint\': \'max_norm\',\n                       \'strides\': strides},\n               input_shape=(batch_size, steps, input_dim))\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\' and load_backend.dev.type() == 0),\n                    reason=\'cntk only support dilated conv on GPU\')\ndef test_conv_1d_dilation():\n    batch_size = 2\n    steps = 8\n    input_dim = 2\n    kernel_size = 3\n    filters = 3\n    padding = _convolution_paddings[-1]\n\n    layer_test(convolutional.Conv1D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'padding\': padding,\n                       \'dilation_rate\': 2},\n               input_shape=(batch_size, steps, input_dim))\n\n\ndef test_conv_1d_channels_first():\n    batch_size = 2\n    steps = 8\n    input_dim = 2\n    kernel_size = 3\n    filters = 3\n\n    layer_test(convolutional.Conv1D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'data_format\': \'channels_first\'},\n               input_shape=(batch_size, input_dim, steps))\n\n\n@pytest.mark.parametrize(\n    \'strides,padding\',\n    [(strides, padding)\n     for padding in _convolution_paddings\n     for strides in [(1, 1), (2, 2)]\n     if not (padding == \'same\' and strides != (1, 1))]\n)\ndef test_convolution_2d(strides, padding):\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n    kernel_size = (3, 2)\n    num_row = 7\n    num_col = 6\n\n    layer_test(convolutional.Conv2D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'padding\': padding,\n                       \'strides\': strides,\n                       \'data_format\': \'channels_first\'},\n               input_shape=(num_samples, stack_size, num_row, num_col))\n\n\ndef test_convolution_2d_channels_last():\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n    num_row = 7\n    num_col = 6\n    padding = \'valid\'\n    strides = (2, 2)\n\n    layer_test(convolutional.Conv2D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'data_format\': \'channels_last\',\n                       \'activation\': None,\n                       \'kernel_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'kernel_constraint\': \'max_norm\',\n                       \'bias_constraint\': \'max_norm\',\n                       \'strides\': strides},\n               input_shape=(num_samples, num_row, num_col, stack_size))\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\' and load_backend.dev.type() == 0),\n                    reason=\'cntk only supports dilated conv on GPU\')\ndef test_convolution_2d_dilation():\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n    kernel_size = (3, 2)\n    num_row = 7\n    num_col = 6\n    padding = \'valid\'\n\n    layer_test(convolutional.Conv2D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'padding\': padding,\n                       \'dilation_rate\': (2, 2)},\n               input_shape=(num_samples, num_row, num_col, stack_size))\n\n\ndef test_convolution_2d_invalid():\n    filters = 2\n    padding = _convolution_paddings[-1]\n    kernel_size = (3, 2)\n\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv2D(\n            filters=filters, kernel_size=kernel_size, padding=padding,\n            batch_input_shape=(None, None, 5, None))])\n\n\n@pytest.mark.parametrize(\n    \'padding,out_padding,strides\',\n    [(padding, out_padding, strides)\n     for padding in _convolution_paddings\n     for out_padding in [None, (0, 0), (1, 1)]\n     for strides in [(1, 1), (2, 2)]\n     if (not (padding == \'same\' and strides != (1, 1))\n         and not(strides == (1, 1) and out_padding == (1, 1)))]\n)\ndef test_conv2d_transpose(padding, out_padding, strides):\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n    num_row = 5\n    num_col = 6\n\n    layer_test(convolutional.Conv2DTranspose,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'output_padding\': out_padding,\n                       \'strides\': strides,\n                       \'data_format\': \'channels_last\'},\n               input_shape=(num_samples, num_row, num_col, stack_size),\n               fixed_batch_size=True)\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\' and load_backend.dev.type() == 0),\n                    reason=\'cntk only supports dilated conv transpose on GPU\')\ndef test_conv2d_transpose_dilation():\n\n    layer_test(convolutional.Conv2DTranspose,\n               kwargs={\'filters\': 2,\n                       \'kernel_size\': 3,\n                       \'padding\': \'same\',\n                       \'data_format\': \'channels_last\',\n                       \'dilation_rate\': (2, 2)},\n               input_shape=(2, 5, 6, 3))\n\n    # Check dilated conv transpose returns expected output\n    input_data = np.arange(48).reshape((1, 4, 4, 3)).astype(np.float32)\n    expected_output = np.float32([[192, 228, 192, 228],\n                                  [336, 372, 336, 372],\n                                  [192, 228, 192, 228],\n                                  [336, 372, 336, 372]]).reshape((1, 4, 4, 1))\n\n    layer_test(convolutional.Conv2DTranspose,\n               input_data=input_data,\n               kwargs={\'filters\': 1,\n                       \'kernel_size\': 3,\n                       \'padding\': \'same\',\n                       \'data_format\': \'channels_last\',\n                       \'dilation_rate\': (2, 2),\n                       \'kernel_initializer\': \'ones\'},\n               expected_output=expected_output)\n\n\ndef test_conv2d_transpose_channels_first():\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n    num_row = 5\n    num_col = 6\n    padding = \'valid\'\n    strides = (2, 2)\n\n    layer_test(convolutional.Conv2DTranspose,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'data_format\': \'channels_first\',\n                       \'activation\': None,\n                       \'kernel_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'kernel_constraint\': \'max_norm\',\n                       \'bias_constraint\': \'max_norm\',\n                       \'strides\': strides},\n               input_shape=(num_samples, stack_size, num_row, num_col),\n               fixed_batch_size=True)\n\n\ndef test_conv2d_transpose_invalid():\n    filters = 2\n    stack_size = 3\n    num_row = 5\n    num_col = 6\n    padding = \'valid\'\n\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv2DTranspose(\n            filters=filters,\n            kernel_size=3,\n            padding=padding,\n            use_bias=True,\n            batch_input_shape=(None, None, 5, None))])\n\n    # Test invalid output padding for given stride. Output padding equal to stride\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv2DTranspose(\n            filters=filters,\n            kernel_size=3,\n            padding=padding,\n            output_padding=(0, 3),\n            strides=(1, 3),\n            batch_input_shape=(None, num_row, num_col, stack_size))])\n\n    # Output padding greater than stride\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv2DTranspose(\n            filters=filters,\n            kernel_size=3,\n            padding=padding,\n            output_padding=(2, 2),\n            strides=(1, 3),\n            batch_input_shape=(None, num_row, num_col, stack_size))])\n\n\n@pytest.mark.parametrize(\n    \'padding,strides,multiplier,dilation_rate\',\n    [(padding, strides, multiplier, dilation_rate)\n     for padding in _convolution_paddings\n     for strides in [1, 2]\n     for multiplier in [1, 2]\n     for dilation_rate in [1, 2]\n     if (not (padding == \'same\' and strides != 1)\n         and not (dilation_rate != 1 and strides != 1)\n         and not (dilation_rate != 1 and K.backend() == \'cntk\'))]\n)\ndef test_separable_conv_1d(padding, strides, multiplier, dilation_rate):\n    num_samples = 2\n    filters = 6\n    stack_size = 3\n    num_step = 9\n\n    layer_test(convolutional.SeparableConv1D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'strides\': strides,\n                       \'depth_multiplier\': multiplier,\n                       \'dilation_rate\': dilation_rate},\n               input_shape=(num_samples, num_step, stack_size))\n\n\ndef test_separable_conv_1d_additional_args():\n    num_samples = 2\n    filters = 6\n    stack_size = 3\n    num_step = 9\n    padding = \'valid\'\n    multiplier = 2\n\n    layer_test(convolutional.SeparableConv1D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'data_format\': \'channels_first\',\n                       \'activation\': None,\n                       \'depthwise_regularizer\': \'l2\',\n                       \'pointwise_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'pointwise_constraint\': \'unit_norm\',\n                       \'depthwise_constraint\': \'unit_norm\',\n                       \'strides\': 1,\n                       \'use_bias\': True,\n                       \'depth_multiplier\': multiplier},\n               input_shape=(num_samples, stack_size, num_step))\n\n\ndef test_separable_conv_1d_invalid():\n    filters = 6\n    padding = \'valid\'\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.SeparableConv1D(\n            filters=filters, kernel_size=3, padding=padding,\n            batch_input_shape=(None, 5, None))])\n\n\n@pytest.mark.parametrize(\n    \'padding,strides,multiplier,dilation_rate\',\n    [(padding, strides, multiplier, dilation_rate)\n     for padding in _convolution_paddings\n     for strides in [(1, 1), (2, 2)]\n     for multiplier in [1, 2]\n     for dilation_rate in [(1, 1), (2, 2), (2, 1), (1, 2)]\n     if (not (padding == \'same\' and strides != (1, 1))\n         and not (dilation_rate != (1, 1) and strides != (1, 1))\n         and not (dilation_rate != (1, 1) and multiplier == dilation_rate[0])\n         and not (dilation_rate != (1, 1) and K.backend() == \'cntk\'))]\n)\ndef test_separable_conv_2d(padding, strides, multiplier, dilation_rate):\n    num_samples = 2\n    filters = 6\n    stack_size = 3\n    num_row = 7\n    num_col = 6\n\n    layer_test(\n        convolutional.SeparableConv2D,\n        kwargs={\'filters\': filters,\n                \'kernel_size\': (3, 3),\n                \'padding\': padding,\n                \'strides\': strides,\n                \'depth_multiplier\': multiplier,\n                \'dilation_rate\': dilation_rate},\n        input_shape=(num_samples, num_row, num_col, stack_size))\n\n\ndef test_separable_conv_2d_additional_args():\n    num_samples = 2\n    filters = 6\n    stack_size = 3\n    num_row = 7\n    num_col = 6\n    padding = \'valid\'\n    strides = (2, 2)\n    multiplier = 2\n\n    layer_test(convolutional.SeparableConv2D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'data_format\': \'channels_first\',\n                       \'activation\': None,\n                       \'depthwise_regularizer\': \'l2\',\n                       \'pointwise_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'pointwise_constraint\': \'unit_norm\',\n                       \'depthwise_constraint\': \'unit_norm\',\n                       \'strides\': strides,\n                       \'depth_multiplier\': multiplier},\n               input_shape=(num_samples, stack_size, num_row, num_col))\n\n\ndef test_separable_conv_2d_invalid():\n    filters = 6\n    padding = \'valid\'\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.SeparableConv2D(\n            filters=filters, kernel_size=3, padding=padding,\n            batch_input_shape=(None, None, 5, None))])\n\n\n@pytest.mark.parametrize(\n    \'padding,strides,multiplier,dilation_rate\',\n    [(padding, strides, multiplier, dilation_rate)\n     for padding in _convolution_paddings\n     for strides in [(1, 1), (2, 2)]\n     for multiplier in [1, 2]\n     for dilation_rate in [(1, 1), (2, 2), (2, 1), (1, 2)]\n     if (not (padding == \'same\' and strides != (1, 1))\n         and not (dilation_rate != (1, 1) and strides != (1, 1))\n         and not (dilation_rate != (1, 1) and multiplier == dilation_rate[0])\n         and not (dilation_rate != (1, 1) and K.backend() == \'cntk\'))]\n)\ndef test_depthwise_conv_2d(padding, strides, multiplier, dilation_rate):\n    num_samples = 2\n    stack_size = 3\n    num_row = 7\n    num_col = 6\n\n    layer_test(convolutional.DepthwiseConv2D,\n               kwargs={\'kernel_size\': (3, 3),\n                       \'padding\': padding,\n                       \'strides\': strides,\n                       \'depth_multiplier\': multiplier,\n                       \'dilation_rate\': dilation_rate},\n               input_shape=(num_samples,\n                            num_row,\n                            num_col,\n                            stack_size))\n\n\ndef test_depthwise_conv_2d_additional_args():\n    num_samples = 2\n    stack_size = 3\n    num_row = 7\n    num_col = 6\n    padding = \'valid\'\n    strides = (2, 2)\n    multiplier = 2\n\n    layer_test(convolutional.DepthwiseConv2D,\n               kwargs={\'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'data_format\': \'channels_first\',\n                       \'activation\': None,\n                       \'depthwise_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'depthwise_constraint\': \'unit_norm\',\n                       \'use_bias\': True,\n                       \'strides\': strides,\n                       \'depth_multiplier\': multiplier},\n               input_shape=(num_samples, stack_size, num_row, num_col))\n\n\ndef test_depthwise_conv_2d_invalid():\n    padding = \'valid\'\n    with pytest.raises(ValueError):\n        Sequential([convolutional.DepthwiseConv2D(\n            kernel_size=3,\n            padding=padding,\n            batch_input_shape=(None, None, 5, None))])\n\n\n@pytest.mark.parametrize(\n    \'padding,strides\',\n    [(padding, strides)\n     for padding in _convolution_paddings\n     for strides in [(1, 1, 1), (2, 2, 2)]\n     if not (padding == \'same\' and strides != (1, 1, 1))]\n)\ndef test_convolution_3d(padding, strides):\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n\n    input_len_dim1 = 9\n    input_len_dim2 = 8\n    input_len_dim3 = 8\n\n    layer_test(convolutional.Convolution3D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'strides\': strides},\n               input_shape=(num_samples,\n                            input_len_dim1, input_len_dim2, input_len_dim3,\n                            stack_size))\n\n\ndef test_convolution_3d_additional_args():\n    num_samples = 2\n    filters = 2\n    stack_size = 3\n    padding = \'valid\'\n    strides = (2, 2, 2)\n\n    input_len_dim1 = 9\n    input_len_dim2 = 8\n    input_len_dim3 = 8\n\n    layer_test(convolutional.Convolution3D,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': (1, 2, 3),\n                       \'padding\': padding,\n                       \'activation\': None,\n                       \'kernel_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'kernel_constraint\': \'max_norm\',\n                       \'bias_constraint\': \'max_norm\',\n                       \'strides\': strides},\n               input_shape=(num_samples,\n                            input_len_dim1, input_len_dim2, input_len_dim3,\n                            stack_size))\n\n\n@pytest.mark.parametrize(\n    \'padding,out_padding,strides,data_format\',\n    [(padding, out_padding, strides, data_format)\n     for padding in _convolution_paddings\n     for out_padding in [None, (0, 0, 0), (1, 1, 1)]\n     for strides in [(1, 1, 1), (2, 2, 2)]\n     for data_format in [\'channels_first\', \'channels_last\']\n     if (not (padding == \'same\' and strides != (1, 1, 1))\n         and not (strides == (1, 1, 1) and out_padding == (1, 1, 1)))]\n)\ndef test_conv3d_transpose(padding, out_padding, strides, data_format):\n    filters = 2\n    stack_size = 3\n    num_depth = 7\n    num_row = 5\n    num_col = 6\n\n    layer_test(\n        convolutional.Conv3DTranspose,\n        kwargs={\'filters\': filters,\n                \'kernel_size\': 3,\n                \'padding\': padding,\n                \'output_padding\': out_padding,\n                \'strides\': strides,\n                \'data_format\': data_format},\n        input_shape=(None, num_depth, num_row, num_col, stack_size),\n        fixed_batch_size=True)\n\n\ndef test_conv3d_transpose_additional_args():\n    filters = 2\n    stack_size = 3\n    num_depth = 7\n    num_row = 5\n    num_col = 6\n    padding = \'valid\'\n    strides = (2, 2, 2)\n\n    layer_test(convolutional.Conv3DTranspose,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': 3,\n                       \'padding\': padding,\n                       \'data_format\': \'channels_first\',\n                       \'activation\': None,\n                       \'kernel_regularizer\': \'l2\',\n                       \'bias_regularizer\': \'l2\',\n                       \'activity_regularizer\': \'l2\',\n                       \'kernel_constraint\': \'max_norm\',\n                       \'bias_constraint\': \'max_norm\',\n                       \'use_bias\': True,\n                       \'strides\': strides},\n               input_shape=(None, stack_size, num_depth, num_row, num_col),\n               fixed_batch_size=True)\n\n\ndef test_conv3d_transpose_invalid():\n    filters = 2\n    stack_size = 3\n    num_depth = 7\n    num_row = 5\n    num_col = 6\n    padding = \'valid\'\n\n    # Test invalid use case\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv3DTranspose(\n            filters=filters,\n            kernel_size=3,\n            padding=padding,\n            batch_input_shape=(None, None, 5, None, None))])\n\n    # Test invalid output padding for given stride. Output padding equal\n    # to stride\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv3DTranspose(\n            filters=filters,\n            kernel_size=3,\n            padding=padding,\n            output_padding=(0, 3, 3),\n            strides=(1, 3, 4),\n            batch_input_shape=(None, num_depth, num_row, num_col, stack_size))])\n\n    # Output padding greater than stride\n    with pytest.raises(ValueError):\n        model = Sequential([convolutional.Conv3DTranspose(\n            filters=filters,\n            kernel_size=3,\n            padding=padding,\n            output_padding=(2, 2, 3),\n            strides=(1, 3, 4),\n            batch_input_shape=(None, num_depth, num_row, num_col, stack_size))])\n\n\ndef test_zero_padding_1d():\n    num_samples = 2\n    input_dim = 2\n    num_steps = 5\n    shape = (num_samples, num_steps, input_dim)\n    inputs = np.ones(shape)\n\n    # basic test\n    layer_test(convolutional.ZeroPadding1D,\n               kwargs={\'padding\': 2},\n               input_shape=inputs.shape)\n    layer_test(convolutional.ZeroPadding1D,\n               kwargs={\'padding\': (1, 2)},\n               input_shape=inputs.shape)\n\n    # correctness test\n    layer = convolutional.ZeroPadding1D(padding=2)\n    layer.build(shape)\n    outputs = layer(K.variable(inputs))\n    np_output = K.eval(outputs)\n    for offset in [0, 1, -1, -2]:\n        assert_allclose(np_output[:, offset, :], 0.)\n    assert_allclose(np_output[:, 2:-2, :], 1.)\n\n    layer = convolutional.ZeroPadding1D(padding=(1, 2))\n    layer.build(shape)\n    outputs = layer(K.variable(inputs))\n    np_output = K.eval(outputs)\n    for left_offset in [0]:\n        assert_allclose(np_output[:, left_offset, :], 0.)\n    for right_offset in [-1, -2]:\n        assert_allclose(np_output[:, right_offset, :], 0.)\n    assert_allclose(np_output[:, 1:-2, :], 1.)\n    layer.get_config()\n\n\n@pytest.mark.parametrize(\n    \'data_format,padding\',\n    [(data_format, padding)\n     for data_format in [\'channels_first\', \'channels_last\']\n     for padding in [(2, 2), ((1, 2), (3, 4))]]\n)\ndef test_zero_padding_2d(data_format, padding):\n    num_samples = 2\n    stack_size = 2\n    input_num_row = 4\n    input_num_col = 5\n\n    if data_format == \'channels_last\':\n        inputs = np.ones((num_samples, input_num_row, input_num_col, stack_size))\n    else:\n        inputs = np.ones((num_samples, stack_size, input_num_row, input_num_col))\n\n    layer_test(convolutional.ZeroPadding2D,\n               kwargs={\'padding\': padding, \'data_format\': data_format},\n               input_shape=inputs.shape)\n\n\n@pytest.mark.parametrize(\'data_format\',\n                         [\'channels_first\', \'channels_last\'])\ndef test_zero_padding_2d_correctness(data_format):\n    num_samples = 2\n    stack_size = 2\n    input_num_row = 4\n    input_num_col = 5\n    inputs = np.ones((num_samples, stack_size, input_num_row, input_num_col))\n\n    layer = convolutional.ZeroPadding2D(padding=(2, 2),\n                                        data_format=data_format)\n    layer.build(inputs.shape)\n    outputs = layer(K.variable(inputs))\n    np_output = K.eval(outputs)\n    if data_format == \'channels_last\':\n        for offset in [0, 1, -1, -2]:\n            assert_allclose(np_output[:, offset, :, :], 0.)\n            assert_allclose(np_output[:, :, offset, :], 0.)\n        assert_allclose(np_output[:, 2:-2, 2:-2, :], 1.)\n    elif data_format == \'channels_first\':\n        for offset in [0, 1, -1, -2]:\n            assert_allclose(np_output[:, :, offset, :], 0.)\n            assert_allclose(np_output[:, :, :, offset], 0.)\n        assert_allclose(np_output[:, 2:-2, 2:-2, :], 1.)\n\n    layer = convolutional.ZeroPadding2D(padding=((1, 2), (3, 4)),\n                                        data_format=data_format)\n    layer.build(inputs.shape)\n    outputs = layer(K.variable(inputs))\n    np_output = K.eval(outputs)\n    if data_format == \'channels_last\':\n        for top_offset in [0]:\n            assert_allclose(np_output[:, top_offset, :, :], 0.)\n        for bottom_offset in [-1, -2]:\n            assert_allclose(np_output[:, bottom_offset, :, :], 0.)\n        for left_offset in [0, 1, 2]:\n            assert_allclose(np_output[:, :, left_offset, :], 0.)\n        for right_offset in [-1, -2, -3, -4]:\n            assert_allclose(np_output[:, :, right_offset, :], 0.)\n        assert_allclose(np_output[:, 1:-2, 3:-4, :], 1.)\n    elif data_format == \'channels_first\':\n        for top_offset in [0]:\n            assert_allclose(np_output[:, :, top_offset, :], 0.)\n        for bottom_offset in [-1, -2]:\n            assert_allclose(np_output[:, :, bottom_offset, :], 0.)\n        for left_offset in [0, 1, 2]:\n            assert_allclose(np_output[:, :, :, left_offset], 0.)\n        for right_offset in [-1, -2, -3, -4]:\n            assert_allclose(np_output[:, :, :, right_offset], 0.)\n        assert_allclose(np_output[:, :, 1:-2, 3:-4], 1.)\n\n\n@pytest.mark.parametrize(\n    \'data_format,padding\',\n    [(data_format, padding)\n     for data_format in [\'channels_first\', \'channels_last\']\n     for padding in [(2, 2, 2), ((1, 2), (3, 4), (0, 2))]]\n)\ndef test_zero_padding_3d(data_format, padding):\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 4\n    input_len_dim2 = 5\n    input_len_dim3 = 3\n    inputs = np.ones((num_samples,\n                     input_len_dim1, input_len_dim2, input_len_dim3,\n                     stack_size))\n\n    layer_test(convolutional.ZeroPadding3D,\n               kwargs={\'padding\': padding, \'data_format\': data_format},\n               input_shape=inputs.shape)\n\n\n@pytest.mark.parametrize(\'data_format\',\n                         [\'channels_first\', \'channels_last\'])\ndef test_zero_padding_3d_correctness(data_format):\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 4\n    input_len_dim2 = 5\n    input_len_dim3 = 3\n    inputs = np.ones((num_samples,\n                      input_len_dim1, input_len_dim2, input_len_dim3,\n                      stack_size))\n\n    layer = convolutional.ZeroPadding3D(padding=(2, 2, 2),\n                                        data_format=data_format)\n    layer.build(inputs.shape)\n    outputs = layer(K.variable(inputs))\n    np_output = K.eval(outputs)\n    if data_format == \'channels_last\':\n        for offset in [0, 1, -1, -2]:\n            assert_allclose(np_output[:, offset, :, :, :], 0.)\n            assert_allclose(np_output[:, :, offset, :, :], 0.)\n            assert_allclose(np_output[:, :, :, offset, :], 0.)\n        assert_allclose(np_output[:, 2:-2, 2:-2, 2:-2, :], 1.)\n    elif data_format == \'channels_first\':\n        for offset in [0, 1, -1, -2]:\n            assert_allclose(np_output[:, :, offset, :, :], 0.)\n            assert_allclose(np_output[:, :, :, offset, :], 0.)\n            assert_allclose(np_output[:, :, :, :, offset], 0.)\n        assert_allclose(np_output[:, :, 2:-2, 2:-2, 2:-2], 1.)\n\n    layer = convolutional.ZeroPadding3D(padding=((1, 2), (3, 4), (0, 2)),\n                                        data_format=data_format)\n    layer.build(inputs.shape)\n    outputs = layer(K.variable(inputs))\n    np_output = K.eval(outputs)\n    if data_format == \'channels_last\':\n        for dim1_offset in [0, -1, -2]:\n            assert_allclose(np_output[:, dim1_offset, :, :, :], 0.)\n        for dim2_offset in [0, 1, 2, -1, -2, -3, -4]:\n            assert_allclose(np_output[:, :, dim2_offset, :, :], 0.)\n        for dim3_offset in [-1, -2]:\n            assert_allclose(np_output[:, :, :, dim3_offset, :], 0.)\n        assert_allclose(np_output[:, 1:-2, 3:-4, 0:-2, :], 1.)\n    elif data_format == \'channels_first\':\n        for dim1_offset in [0, -1, -2]:\n            assert_allclose(np_output[:, :, dim1_offset, :, :], 0.)\n        for dim2_offset in [0, 1, 2, -1, -2, -3, -4]:\n            assert_allclose(np_output[:, :, :, dim2_offset, :], 0.)\n        for dim3_offset in [-1, -2]:\n            assert_allclose(np_output[:, :, :, :, dim3_offset], 0.)\n        assert_allclose(np_output[:, :, 1:-2, 3:-4, 0:-2], 1.)\n\n\ndef test_upsampling_1d():\n    layer_test(convolutional.UpSampling1D,\n               kwargs={\'size\': 2},\n               input_shape=(3, 5, 4))\n\n\n@pytest.mark.parametrize(\'data_format\',\n                         [\'channels_first\', \'channels_last\'])\ndef test_upsampling_2d(data_format):\n    num_samples = 2\n    stack_size = 2\n    input_num_row = 11\n    input_num_col = 12\n\n    if data_format == \'channels_first\':\n        inputs = np.random.rand(num_samples, stack_size, input_num_row,\n                                input_num_col)\n    else:  # tf\n        inputs = np.random.rand(num_samples, input_num_row, input_num_col,\n                                stack_size)\n\n    # basic test\n    layer_test(convolutional.UpSampling2D,\n               kwargs={\'size\': (2, 2), \'data_format\': data_format},\n               input_shape=inputs.shape)\n\n    for length_row in [2]:\n        for length_col in [2, 3]:\n            layer = convolutional.UpSampling2D(\n                size=(length_row, length_col),\n                data_format=data_format)\n            layer.build(inputs.shape)\n            outputs = layer(K.variable(inputs))\n            np_output = K.eval(outputs)\n            if data_format == \'channels_first\':\n                assert np_output.shape[2] == length_row * input_num_row\n                assert np_output.shape[3] == length_col * input_num_col\n            else:  # tf\n                assert np_output.shape[1] == length_row * input_num_row\n                assert np_output.shape[2] == length_col * input_num_col\n\n            # compare with numpy\n            if data_format == \'channels_first\':\n                expected_out = np.repeat(inputs, length_row, axis=2)\n                expected_out = np.repeat(expected_out, length_col, axis=3)\n            else:  # tf\n                expected_out = np.repeat(inputs, length_row, axis=1)\n                expected_out = np.repeat(expected_out, length_col, axis=2)\n\n            assert_allclose(np_output, expected_out)\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=\'cntk does not support it yet\')\n@pytest.mark.parametrize(\'data_format\',\n                         [\'channels_first\', \'channels_last\'])\ndef test_upsampling_2d_bilinear(data_format):\n    num_samples = 2\n    stack_size = 2\n    input_num_row = 11\n    input_num_col = 12\n\n    if data_format == \'channels_first\':\n        inputs = np.random.rand(num_samples, stack_size, input_num_row,\n                                input_num_col)\n    else:  # tf\n        inputs = np.random.rand(num_samples, input_num_row, input_num_col,\n                                stack_size)\n\n    # basic test\n    layer_test(convolutional.UpSampling2D,\n               kwargs={\'size\': (2, 2),\n                       \'data_format\': data_format,\n                       \'interpolation\': \'bilinear\'},\n               input_shape=inputs.shape)\n\n    for length_row in [2]:\n        for length_col in [2, 3]:\n            layer = convolutional.UpSampling2D(\n                size=(length_row, length_col),\n                data_format=data_format)\n            layer.build(inputs.shape)\n            outputs = layer(K.variable(inputs))\n            np_output = K.eval(outputs)\n            if data_format == \'channels_first\':\n                assert np_output.shape[2] == length_row * input_num_row\n                assert np_output.shape[3] == length_col * input_num_col\n            else:  # tf\n                assert np_output.shape[1] == length_row * input_num_row\n                assert np_output.shape[2] == length_col * input_num_col\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=""cntk does not support it yet"")\n@pytest.mark.parametrize(\'data_format\',\n                         [\'channels_first\', \'channels_last\'])\ndef test_upsampling_3d(data_format):\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 10\n    input_len_dim2 = 11\n    input_len_dim3 = 12\n\n    if data_format == \'channels_first\':\n        inputs = np.random.rand(num_samples,\n                                stack_size,\n                                input_len_dim1, input_len_dim2, input_len_dim3)\n    else:  # tf\n        inputs = np.random.rand(num_samples,\n                                input_len_dim1, input_len_dim2, input_len_dim3,\n                                stack_size)\n\n    # basic test\n    layer_test(convolutional.UpSampling3D,\n               kwargs={\'size\': (2, 2, 2), \'data_format\': data_format},\n               input_shape=inputs.shape)\n\n    for length_dim1 in [2, 3]:\n        for length_dim2 in [2]:\n            for length_dim3 in [3]:\n                layer = convolutional.UpSampling3D(\n                    size=(length_dim1, length_dim2, length_dim3),\n                    data_format=data_format)\n                layer.build(inputs.shape)\n                outputs = layer(K.variable(inputs))\n                np_output = K.eval(outputs)\n                if data_format == \'channels_first\':\n                    assert np_output.shape[2] == length_dim1 * input_len_dim1\n                    assert np_output.shape[3] == length_dim2 * input_len_dim2\n                    assert np_output.shape[4] == length_dim3 * input_len_dim3\n                else:  # tf\n                    assert np_output.shape[1] == length_dim1 * input_len_dim1\n                    assert np_output.shape[2] == length_dim2 * input_len_dim2\n                    assert np_output.shape[3] == length_dim3 * input_len_dim3\n\n                # compare with numpy\n                if data_format == \'channels_first\':\n                    expected_out = np.repeat(inputs, length_dim1, axis=2)\n                    expected_out = np.repeat(expected_out, length_dim2, axis=3)\n                    expected_out = np.repeat(expected_out, length_dim3, axis=4)\n                else:  # tf\n                    expected_out = np.repeat(inputs, length_dim1, axis=1)\n                    expected_out = np.repeat(expected_out, length_dim2, axis=2)\n                    expected_out = np.repeat(expected_out, length_dim3, axis=3)\n\n                assert_allclose(np_output, expected_out)\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=""cntk does not support slice to 0 dimension"")\ndef test_cropping_1d():\n    num_samples = 2\n    time_length = 4\n    input_len_dim1 = 2\n    inputs = np.random.rand(num_samples, time_length, input_len_dim1)\n\n    layer_test(convolutional.Cropping1D,\n               kwargs={\'cropping\': (2, 2)},\n               input_shape=inputs.shape)\n\n\ndef test_cropping_2d():\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 9\n    input_len_dim2 = 9\n    cropping = ((2, 2), (3, 3))\n\n    for data_format in [\'channels_first\', \'channels_last\']:\n        if data_format == \'channels_first\':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    stack_size)\n        # basic test\n        layer_test(convolutional.Cropping2D,\n                   kwargs={\'cropping\': cropping,\n                           \'data_format\': data_format},\n                   input_shape=inputs.shape)\n        # correctness test\n        layer = convolutional.Cropping2D(cropping=cropping,\n                                         data_format=data_format)\n        layer.build(inputs.shape)\n        outputs = layer(K.variable(inputs))\n        np_output = K.eval(outputs)\n        # compare with numpy\n        if data_format == \'channels_first\':\n            expected_out = inputs[:,\n                                  :,\n                                  cropping[0][0]: -cropping[0][1],\n                                  cropping[1][0]: -cropping[1][1]]\n        else:\n            expected_out = inputs[:,\n                                  cropping[0][0]: -cropping[0][1],\n                                  cropping[1][0]: -cropping[1][1],\n                                  :]\n        assert_allclose(np_output, expected_out)\n\n    for data_format in [\'channels_first\', \'channels_last\']:\n        if data_format == \'channels_first\':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    stack_size)\n        # another correctness test (no cropping)\n        cropping = ((0, 0), (0, 0))\n        layer = convolutional.Cropping2D(cropping=cropping,\n                                         data_format=data_format)\n        layer.build(inputs.shape)\n        outputs = layer(K.variable(inputs))\n        np_output = K.eval(outputs)\n        # compare with input\n        assert_allclose(np_output, inputs)\n\n    # Test invalid use cases\n    with pytest.raises(ValueError):\n        layer = convolutional.Cropping2D(cropping=((1, 1),))\n    with pytest.raises(ValueError):\n        layer = convolutional.Cropping2D(cropping=lambda x: x)\n\n\ndef test_cropping_3d():\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 8\n    input_len_dim2 = 8\n    input_len_dim3 = 8\n    cropping = ((2, 2), (3, 3), (2, 3))\n\n    for data_format in [\'channels_last\', \'channels_first\']:\n        if data_format == \'channels_first\':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2, input_len_dim3)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    input_len_dim3, stack_size)\n        # basic test\n        layer_test(convolutional.Cropping3D,\n                   kwargs={\'cropping\': cropping,\n                           \'data_format\': data_format},\n                   input_shape=inputs.shape)\n        # correctness test\n        layer = convolutional.Cropping3D(cropping=cropping,\n                                         data_format=data_format)\n        layer.build(inputs.shape)\n        outputs = layer(K.variable(inputs))\n        np_output = K.eval(outputs)\n        # compare with numpy\n        if data_format == \'channels_first\':\n            expected_out = inputs[:,\n                                  :,\n                                  cropping[0][0]: -cropping[0][1],\n                                  cropping[1][0]: -cropping[1][1],\n                                  cropping[2][0]: -cropping[2][1]]\n        else:\n            expected_out = inputs[:,\n                                  cropping[0][0]: -cropping[0][1],\n                                  cropping[1][0]: -cropping[1][1],\n                                  cropping[2][0]: -cropping[2][1],\n                                  :]\n        assert_allclose(np_output, expected_out)\n\n    for data_format in [\'channels_last\', \'channels_first\']:\n        if data_format == \'channels_first\':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2, input_len_dim3)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    input_len_dim3, stack_size)\n        # another correctness test (no cropping)\n        cropping = ((0, 0), (0, 0), (0, 0))\n        layer = convolutional.Cropping3D(cropping=cropping,\n                                         data_format=data_format)\n        layer.build(inputs.shape)\n        outputs = layer(K.variable(inputs))\n        np_output = K.eval(outputs)\n        # compare with input\n        assert_allclose(np_output, inputs)\n\n    # Test invalid use cases\n    with pytest.raises(ValueError):\n        layer = convolutional.Cropping3D(cropping=((1, 1),))\n    with pytest.raises(ValueError):\n        layer = convolutional.Cropping3D(cropping=lambda x: x)\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=\'CNTK does not support float64\')\n@pytest.mark.parametrize(\n    \'input_shape,conv_class\',\n    [((2, 4, 2), convolutional.Conv1D),\n     ((2, 4, 4, 2), convolutional.Conv2D),\n     ((2, 4, 4, 4, 2), convolutional.Conv3D)]\n)\ndef test_conv_float64(input_shape, conv_class):\n    kernel_size = 3\n    strides = 1\n    filters = 3\n    K.set_floatx(\'float64\')\n    layer_test(conv_class,\n               kwargs={\'filters\': filters,\n                       \'kernel_size\': kernel_size,\n                       \'padding\': \'valid\',\n                       \'strides\': strides},\n               input_shape=input_shape)\n    K.set_floatx(\'float32\')\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/layers/core_test.py,0,"b'import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.utils.test_utils import layer_test\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.layers import deserialize as deserialize_layer\n\n\ndef test_masking():\n    layer_test(layers.Masking,\n               kwargs={},\n               input_shape=(3, 2, 3))\n\n\ndef test_dropout():\n    layer_test(layers.Dropout,\n               kwargs={\'rate\': 0.5},\n               input_shape=(3, 2))\n\n    layer_test(layers.Dropout,\n               kwargs={\'rate\': 0.5, \'noise_shape\': [3, 1]},\n               input_shape=(3, 2))\n\n    layer_test(layers.Dropout,\n               kwargs={\'rate\': 0.5, \'noise_shape\': [None, 1]},\n               input_shape=(3, 2))\n\n    layer_test(layers.SpatialDropout1D,\n               kwargs={\'rate\': 0.5},\n               input_shape=(2, 3, 4))\n\n    for data_format in [\'channels_last\', \'channels_first\']:\n        for shape in [(4, 5), (4, 5, 6)]:\n            if data_format == \'channels_last\':\n                input_shape = (2,) + shape + (3,)\n            else:\n                input_shape = (2, 3) + shape\n            if len(shape) == 2:\n                layer = layers.SpatialDropout2D\n            else:\n                layer = layers.SpatialDropout3D\n            layer_test(layer,\n                       kwargs={\'rate\': 0.5,\n                               \'data_format\': data_format},\n                       input_shape=input_shape)\n\n            # Test invalid use cases\n            with pytest.raises(ValueError):\n                layer_test(layer,\n                           kwargs={\'rate\': 0.5,\n                                   \'data_format\': \'channels_middle\'},\n                           input_shape=input_shape)\n\n\ndef test_activation():\n    # with string argument\n    layer_test(layers.Activation,\n               kwargs={\'activation\': \'relu\'},\n               input_shape=(3, 2))\n\n    # with function argument\n    layer_test(layers.Activation,\n               kwargs={\'activation\': K.relu},\n               input_shape=(3, 2))\n\n\n@pytest.mark.parametrize(\'target_shape,input_shape\',\n                         [((8, 1), (3, 2, 4)),\n                          ((-1, 1), (3, 2, 4)),\n                          ((1, -1), (3, 2, 4)),\n                          ((-1, 1), (None, None, 4))])\ndef test_reshape(target_shape, input_shape):\n    layer_test(layers.Reshape,\n               kwargs={\'target_shape\': target_shape},\n               input_shape=input_shape)\n\n\ndef test_permute():\n    layer_test(layers.Permute,\n               kwargs={\'dims\': (2, 1)},\n               input_shape=(3, 2, 4))\n\n\ndef test_flatten():\n\n    def test_4d():\n        np_inp_channels_last = np.arange(24, dtype=\'float32\').reshape(\n                                        (1, 4, 3, 2))\n\n        np_output_cl = layer_test(layers.Flatten,\n                                  kwargs={\'data_format\':\n                                          \'channels_last\'},\n                                  input_data=np_inp_channels_last)\n\n        np_inp_channels_first = np.transpose(np_inp_channels_last,\n                                             [0, 3, 1, 2])\n\n        np_output_cf = layer_test(layers.Flatten,\n                                  kwargs={\'data_format\':\n                                          \'channels_first\'},\n                                  input_data=np_inp_channels_first,\n                                  expected_output=np_output_cl)\n\n    def test_3d():\n        np_inp_channels_last = np.arange(12, dtype=\'float32\').reshape(\n            (1, 4, 3))\n\n        np_output_cl = layer_test(layers.Flatten,\n                                  kwargs={\'data_format\':\n                                          \'channels_last\'},\n                                  input_data=np_inp_channels_last)\n\n        np_inp_channels_first = np.transpose(np_inp_channels_last,\n                                             [0, 2, 1])\n\n        np_output_cf = layer_test(layers.Flatten,\n                                  kwargs={\'data_format\':\n                                          \'channels_first\'},\n                                  input_data=np_inp_channels_first,\n                                  expected_output=np_output_cl)\n\n    def test_5d():\n        np_inp_channels_last = np.arange(120, dtype=\'float32\').reshape(\n            (1, 5, 4, 3, 2))\n\n        np_output_cl = layer_test(layers.Flatten,\n                                  kwargs={\'data_format\':\n                                          \'channels_last\'},\n                                  input_data=np_inp_channels_last)\n\n        np_inp_channels_first = np.transpose(np_inp_channels_last,\n                                             [0, 4, 1, 2, 3])\n\n        np_output_cf = layer_test(layers.Flatten,\n                                  kwargs={\'data_format\':\n                                          \'channels_first\'},\n                                  input_data=np_inp_channels_first,\n                                  expected_output=np_output_cl)\n    test_3d()\n    test_4d()\n    test_5d()\n\n\ndef test_repeat_vector():\n    layer_test(layers.RepeatVector,\n               kwargs={\'n\': 3},\n               input_shape=(3, 2))\n\n\ndef test_lambda():\n    layer_test(layers.Lambda,\n               kwargs={\'function\': lambda x: x + 1},\n               input_shape=(3, 2))\n\n    layer_test(layers.Lambda,\n               kwargs={\'function\': lambda x, a, b: x * a + b,\n                       \'arguments\': {\'a\': 0.6, \'b\': 0.4}},\n               input_shape=(3, 2))\n\n    def antirectifier(x):\n        x -= K.mean(x, axis=1, keepdims=True)\n        x = K.l2_normalize(x, axis=1)\n        pos = K.relu(x)\n        neg = K.relu(-x)\n        return K.concatenate([pos, neg], axis=1)\n\n    def antirectifier_output_shape(input_shape):\n        shape = list(input_shape)\n        assert len(shape) == 2  # only valid for 2D tensors\n        shape[-1] *= 2\n        return tuple(shape)\n\n    layer_test(layers.Lambda,\n               kwargs={\'function\': antirectifier,\n                       \'output_shape\': antirectifier_output_shape},\n               input_shape=(3, 2))\n\n    # test layer with multiple outputs\n    def test_multiple_outputs():\n        def func(x):\n            return [x * 0.2, x * 0.3]\n\n        def output_shape(input_shape):\n            return [input_shape, input_shape]\n\n        def mask(inputs, mask=None):\n            return [None, None]\n\n        i = layers.Input(shape=(3, 2, 1))\n        o = layers.Lambda(function=func,\n                          output_shape=output_shape,\n                          mask=mask)(i)\n\n        o1, o2 = o\n        assert o1._keras_shape == (None, 3, 2, 1)\n        assert o2._keras_shape == (None, 3, 2, 1)\n\n        model = Model(i, o)\n\n        x = np.random.random((4, 3, 2, 1))\n        out1, out2 = model.predict(x)\n        assert out1.shape == (4, 3, 2, 1)\n        assert out2.shape == (4, 3, 2, 1)\n        assert_allclose(out1, x * 0.2, atol=1e-4)\n        assert_allclose(out2, x * 0.3, atol=1e-4)\n\n    test_multiple_outputs()\n\n    # test layer with multiple outputs and no\n    # explicit mask\n    def test_multiple_outputs_no_mask():\n        def func(x):\n            return [x * 0.2, x * 0.3]\n\n        def output_shape(input_shape):\n            return [input_shape, input_shape]\n\n        i = layers.Input(shape=(3, 2, 1))\n        o = layers.Lambda(function=func,\n                          output_shape=output_shape)(i)\n\n        assert o[0]._keras_shape == (None, 3, 2, 1)\n        assert o[1]._keras_shape == (None, 3, 2, 1)\n\n        o = layers.add(o)\n        model = Model(i, o)\n\n        i2 = layers.Input(shape=(3, 2, 1))\n        o2 = model(i2)\n        model2 = Model(i2, o2)\n\n        x = np.random.random((4, 3, 2, 1))\n        out = model2.predict(x)\n        assert out.shape == (4, 3, 2, 1)\n        assert_allclose(out, x * 0.2 + x * 0.3, atol=1e-4)\n\n    test_multiple_outputs_no_mask()\n\n    def test_dtypes():\n        def func(x):\n            if K.dtype(x) != \'float16\':\n                raise TypeError(\'x dtype is not float16, it is\', K.dtype(x))\n            return x\n\n        i = layers.Input(shape=(3, 2, 1), dtype=\'float16\')\n        o = layers.Lambda(func)\n        _ = o(i)\n        assert o._input_dtypes == \'float16\'\n    test_dtypes()\n\n    # test serialization with function\n    def f(x):\n        return x + 1\n\n    ld = layers.Lambda(f)\n    config = ld.get_config()\n    ld = deserialize_layer({\'class_name\': \'Lambda\', \'config\': config})\n\n    # test with lambda\n    ld = layers.Lambda(\n        lambda x: K.concatenate([K.square(x), x]),\n        output_shape=lambda s: tuple(list(s)[:-1] + [2 * s[-1]]))\n    config = ld.get_config()\n    ld = layers.Lambda.from_config(config)\n\n    # test serialization with output_shape function\n    def f(x):\n        return K.concatenate([K.square(x), x])\n\n    def f_shape(s):\n        return tuple(list(s)[:-1] + [2 * s[-1]])\n\n    ld = layers.Lambda(f, output_shape=f_shape)\n    config = ld.get_config()\n    ld = deserialize_layer({\'class_name\': \'Lambda\', \'config\': config})\n\n\n@pytest.mark.skipif((K.backend() == \'theano\'),\n                    reason=""theano cannot compute ""\n                           ""the output shape automatically."")\ndef test_lambda_output_shape():\n    layer_test(layers.Lambda,\n               kwargs={\'function\': lambda x: K.mean(x, axis=-1)},\n               input_shape=(3, 2, 4))\n\n\ndef test_dense():\n    layer_test(layers.Dense,\n               kwargs={\'units\': 3},\n               input_shape=(3, 2))\n\n    layer_test(layers.Dense,\n               kwargs={\'units\': 3},\n               input_shape=(3, 4, 2))\n\n    layer_test(layers.Dense,\n               kwargs={\'units\': 3},\n               input_shape=(None, None, 2))\n\n    layer_test(layers.Dense,\n               kwargs={\'units\': 3},\n               input_shape=(3, 4, 5, 2))\n\n    layer_test(layers.Dense,\n               kwargs={\'units\': 3,\n                       \'kernel_regularizer\': regularizers.l2(0.01),\n                       \'bias_regularizer\': regularizers.l1(0.01),\n                       \'activity_regularizer\': regularizers.L1L2(l1=0.01, l2=0.01),\n                       \'kernel_constraint\': constraints.MaxNorm(1),\n                       \'bias_constraint\': constraints.max_norm(1)},\n               input_shape=(3, 2))\n\n    layer = layers.Dense(3,\n                         kernel_regularizer=regularizers.l1(0.01),\n                         bias_regularizer=\'l1\')\n    layer.build((None, 4))\n    assert len(layer.losses) == 2\n\n\ndef test_activity_regularization():\n    layer = layers.ActivityRegularization(l1=0.01, l2=0.01)\n\n    # test in functional API\n    x = layers.Input(shape=(3,))\n    z = layers.Dense(2)(x)\n    y = layer(z)\n    model = Model(x, y)\n    model.compile(\'rmsprop\', \'mse\')\n\n    model.predict(np.random.random((2, 3)))\n\n    # test serialization\n    model_config = model.get_config()\n    model = Model.from_config(model_config)\n    model.compile(\'rmsprop\', \'mse\')\n\n\ndef test_sequential_as_downstream_of_masking_layer():\n\n    inputs = layers.Input(shape=(3, 4))\n    x = layers.Masking(mask_value=0., input_shape=(3, 4))(inputs)\n    s = Sequential()\n    s.add(layers.Dense(5, input_shape=(4,)))\n    s.add(layers.Activation(\'relu\'))\n    x = layers.wrappers.TimeDistributed(s)(x)\n    model = Model(inputs=inputs, outputs=x)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model_input = np.random.randint(low=1, high=5, size=(10, 3, 4))\n    for i in range(4):\n        model_input[i, i:, :] = 0.\n    model.fit(model_input,\n              np.random.random((10, 3, 5)), epochs=1, batch_size=6)\n\n    mask_outputs = [model.layers[1].compute_mask(model.layers[1].input)]\n    mask_outputs += [model.layers[2].compute_mask(model.layers[2].input,\n                                                  mask_outputs[-1])]\n    func = K.function([model.input], mask_outputs)\n    mask_outputs_val = func([model_input])\n    assert np.array_equal(mask_outputs_val[0], np.any(model_input, axis=-1))\n    assert np.array_equal(mask_outputs_val[1], np.any(model_input, axis=-1))\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/layers/cudnn_recurrent_test.py,0,"b""import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport keras\nimport keras.backend as K\nfrom keras.utils.test_utils import layer_test\nimport time\n\n\nskipif_no_tf_gpu = pytest.mark.skipif(\n    (K.backend() != 'tensorflow' or\n     not K.tensorflow_backend._get_available_gpus()),\n    reason='Requires TensorFlow backend and a GPU')\n\n\n@skipif_no_tf_gpu\ndef test_cudnn_rnn_canonical_to_params_lstm():\n    units = 1\n    input_size = 1\n    layer = keras.layers.CuDNNLSTM(units)\n    layer.build((None, None, input_size))\n\n    params = layer._canonical_to_params(\n        weights=[\n            layer.kernel_i,\n            layer.kernel_f,\n            layer.kernel_c,\n            layer.kernel_o,\n            layer.recurrent_kernel_i,\n            layer.recurrent_kernel_f,\n            layer.recurrent_kernel_c,\n            layer.recurrent_kernel_o,\n        ],\n        biases=[\n            layer.bias_i_i,\n            layer.bias_f_i,\n            layer.bias_c_i,\n            layer.bias_o_i,\n            layer.bias_i,\n            layer.bias_f,\n            layer.bias_c,\n            layer.bias_o,\n        ],\n    )\n    ref_params = layer._cudnn_lstm.canonical_to_params(\n        weights=[\n            layer.kernel_i,\n            layer.kernel_f,\n            layer.kernel_c,\n            layer.kernel_o,\n            layer.recurrent_kernel_i,\n            layer.recurrent_kernel_f,\n            layer.recurrent_kernel_c,\n            layer.recurrent_kernel_o,\n        ],\n        biases=[\n            layer.bias_i_i,\n            layer.bias_f_i,\n            layer.bias_c_i,\n            layer.bias_o_i,\n            layer.bias_i,\n            layer.bias_f,\n            layer.bias_c,\n            layer.bias_o,\n        ],\n    )\n    ref_params_value = keras.backend.get_value(ref_params)\n    params_value = keras.backend.get_value(params)\n    diff = np.mean(ref_params_value - params_value)\n    assert diff < 1e-8\n\n\n@skipif_no_tf_gpu\ndef test_cudnn_rnn_canonical_to_params_gru():\n    units = 7\n    input_size = 9\n    layer = keras.layers.CuDNNGRU(units)\n    layer.build((None, None, input_size))\n\n    ref_params = layer._cudnn_gru.canonical_to_params(\n        weights=[\n            layer.kernel_r,\n            layer.kernel_z,\n            layer.kernel_h,\n            layer.recurrent_kernel_r,\n            layer.recurrent_kernel_z,\n            layer.recurrent_kernel_h,\n        ],\n        biases=[\n            layer.bias_r_i,\n            layer.bias_z_i,\n            layer.bias_h_i,\n            layer.bias_r,\n            layer.bias_z,\n            layer.bias_h,\n        ],\n    )\n    params = layer._canonical_to_params(\n        weights=[\n            layer.kernel_r,\n            layer.kernel_z,\n            layer.kernel_h,\n            layer.recurrent_kernel_r,\n            layer.recurrent_kernel_z,\n            layer.recurrent_kernel_h,\n        ],\n        biases=[\n            layer.bias_r_i,\n            layer.bias_z_i,\n            layer.bias_h_i,\n            layer.bias_r,\n            layer.bias_z,\n            layer.bias_h,\n        ],\n    )\n    ref_params_value = keras.backend.get_value(ref_params)\n    params_value = keras.backend.get_value(params)\n    diff = np.mean(ref_params_value - params_value)\n    assert diff < 1e-8\n\n\n@pytest.mark.parametrize('rnn_type', ['lstm', 'gru'], ids=['LSTM', 'GRU'])\n@skipif_no_tf_gpu\ndef test_cudnn_rnn_timing(rnn_type):\n    input_size = 1000\n    timesteps = 60\n    units = 256\n    num_samples = 10000\n\n    times = []\n    for use_cudnn in [True, False]:\n        start_time = time.time()\n        inputs = keras.layers.Input(shape=(None, input_size))\n        if use_cudnn:\n            if rnn_type == 'lstm':\n                layer = keras.layers.CuDNNLSTM(units)\n            else:\n                layer = keras.layers.CuDNNGRU(units)\n        else:\n            if rnn_type == 'lstm':\n                layer = keras.layers.LSTM(units)\n            else:\n                layer = keras.layers.GRU(units)\n        outputs = layer(inputs)\n\n        model = keras.models.Model(inputs, outputs)\n        model.compile('sgd', 'mse')\n\n        x = np.random.random((num_samples, timesteps, input_size))\n        y = np.random.random((num_samples, units))\n        model.fit(x, y, epochs=4, batch_size=32)\n\n        times.append(time.time() - start_time)\n\n    speedup = times[1] / times[0]\n    print(rnn_type, 'speedup', speedup)\n    assert speedup > 3\n\n\n@skipif_no_tf_gpu\ndef test_cudnn_rnn_basics():\n    input_size = 10\n    timesteps = 6\n    units = 2\n    num_samples = 32\n    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n        for return_sequences in [True, False]:\n            with keras.utils.CustomObjectScope(\n                    {'keras.layers.CuDNNGRU': keras.layers.CuDNNGRU,\n                     'keras.layers.CuDNNLSTM': keras.layers.CuDNNLSTM}):\n                layer_test(\n                    layer_class,\n                    kwargs={'units': units,\n                            'return_sequences': return_sequences},\n                    input_shape=(num_samples, timesteps, input_size))\n        for go_backwards in [True, False]:\n            with keras.utils.CustomObjectScope(\n                    {'keras.layers.CuDNNGRU': keras.layers.CuDNNGRU,\n                     'keras.layers.CuDNNLSTM': keras.layers.CuDNNLSTM}):\n                layer_test(\n                    layer_class,\n                    kwargs={'units': units,\n                            'go_backwards': go_backwards},\n                    input_shape=(num_samples, timesteps, input_size))\n\n\n@skipif_no_tf_gpu\ndef test_trainability():\n    input_size = 10\n    units = 2\n    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n        layer = layer_class(units)\n        layer.build((None, None, input_size))\n        assert len(layer.weights) == 3\n        assert len(layer.trainable_weights) == 3\n        assert len(layer.non_trainable_weights) == 0\n        layer.trainable = False\n        assert len(layer.weights) == 3\n        assert len(layer.non_trainable_weights) == 3\n        assert len(layer.trainable_weights) == 0\n        layer.trainable = True\n        assert len(layer.weights) == 3\n        assert len(layer.trainable_weights) == 3\n        assert len(layer.non_trainable_weights) == 0\n\n\n@skipif_no_tf_gpu\ndef test_regularizer():\n    input_size = 10\n    timesteps = 6\n    units = 2\n    num_samples = 32\n    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n        layer = layer_class(units, return_sequences=False,\n                            input_shape=(timesteps, input_size),\n                            kernel_regularizer=keras.regularizers.l1(0.01),\n                            recurrent_regularizer=keras.regularizers.l1(0.01),\n                            bias_regularizer='l2')\n        layer.build((None, None, input_size))\n        assert len(layer.losses) == 3\n\n        layer = layer_class(units, return_sequences=False,\n                            input_shape=(timesteps, input_size),\n                            activity_regularizer='l2')\n        assert layer.activity_regularizer\n        x = keras.backend.variable(np.ones((num_samples,\n                                            timesteps,\n                                            input_size)))\n        layer(x)\n        assert len(layer.get_losses_for(x)) == 1\n\n\n@skipif_no_tf_gpu\ndef test_return_state():\n    input_size = 10\n    timesteps = 6\n    units = 2\n    num_samples = 32\n\n    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n        num_states = 2 if layer_class is keras.layers.CuDNNLSTM else 1\n\n        inputs = keras.Input(batch_shape=(num_samples, timesteps, input_size))\n        layer = layer_class(units, return_state=True, stateful=True)\n        outputs = layer(inputs)\n        output, state = outputs[0], outputs[1:]\n        assert len(state) == num_states\n        model = keras.models.Model(inputs, state[0])\n\n        inputs = np.random.random((num_samples, timesteps, input_size))\n        state = model.predict(inputs)\n        np.testing.assert_allclose(\n            keras.backend.eval(layer.states[0]), state, atol=1e-4)\n\n\n@skipif_no_tf_gpu\ndef test_specify_initial_state_keras_tensor():\n    input_size = 10\n    timesteps = 6\n    units = 2\n    num_samples = 32\n    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n        num_states = 2 if layer_class is keras.layers.CuDNNLSTM else 1\n\n        inputs = keras.Input((timesteps, input_size))\n        initial_state = [keras.Input((units,)) for _ in range(num_states)]\n        layer = layer_class(units)\n        if len(initial_state) == 1:\n            output = layer(inputs, initial_state=initial_state[0])\n        else:\n            output = layer(inputs, initial_state=initial_state)\n        assert initial_state[0] in layer._inbound_nodes[0].input_tensors\n\n        model = keras.models.Model([inputs] + initial_state, output)\n        model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n        inputs = np.random.random((num_samples, timesteps, input_size))\n        initial_state = [np.random.random((num_samples, units))\n                         for _ in range(num_states)]\n        targets = np.random.random((num_samples, units))\n        model.fit([inputs] + initial_state, targets)\n\n\n@skipif_no_tf_gpu\ndef test_statefulness():\n    input_size = 10\n    timesteps = 6\n    units = 2\n    num_samples = 32\n\n    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n        model = keras.models.Sequential()\n        model.add(keras.layers.Embedding(10, input_size,\n                                         input_length=timesteps,\n                                         batch_input_shape=(num_samples,\n                                                            timesteps)))\n        layer = layer_class(units,\n                            return_sequences=False,\n                            stateful=True,\n                            weights=None)\n        model.add(layer)\n        model.compile(optimizer='sgd', loss='mse')\n        out1 = model.predict(np.ones((num_samples, timesteps)))\n        assert(out1.shape == (num_samples, units))\n\n        # train once so that the states change\n        model.train_on_batch(np.ones((num_samples, timesteps)),\n                             np.ones((num_samples, units)))\n        out2 = model.predict(np.ones((num_samples, timesteps)))\n\n        # if the state is not reset, output should be different\n        assert(out1.max() != out2.max())\n\n        # check that output changes after states are reset\n        # (even though the model itself didn't change)\n        layer.reset_states()\n        out3 = model.predict(np.ones((num_samples, timesteps)))\n        assert(out2.max() != out3.max())\n\n        # check that container-level reset_states() works\n        model.reset_states()\n        out4 = model.predict(np.ones((num_samples, timesteps)))\n        assert_allclose(out3, out4, atol=1e-5)\n\n        # check that the call to `predict` updated the states\n        out5 = model.predict(np.ones((num_samples, timesteps)))\n        assert(out4.max() != out5.max())\n\n\n@skipif_no_tf_gpu\ndef test_cudnnrnn_bidirectional():\n    rnn = keras.layers.CuDNNGRU\n    samples = 2\n    dim = 2\n    timesteps = 2\n    output_dim = 2\n    mode = 'concat'\n\n    x = np.random.random((samples, timesteps, dim))\n    target_dim = 2 * output_dim if mode == 'concat' else output_dim\n    y = np.random.random((samples, target_dim))\n\n    # test with Sequential model\n    model = keras.Sequential()\n    model.add(keras.layers.Bidirectional(rnn(output_dim),\n                                         merge_mode=mode,\n                                         input_shape=(None, dim)))\n    model.compile(loss='mse', optimizer='sgd')\n    model.fit(x, y, epochs=1, batch_size=1)\n\n    # test config\n    model.get_config()\n    model = keras.models.model_from_json(model.to_json())\n    model.summary()\n\n    # test stacked bidirectional layers\n    model = keras.Sequential()\n    model.add(keras.layers.Bidirectional(rnn(output_dim,\n                                             return_sequences=True),\n                                         merge_mode=mode,\n                                         input_shape=(None, dim)))\n    model.add(keras.layers.Bidirectional(rnn(output_dim), merge_mode=mode))\n    model.compile(loss='mse', optimizer='sgd')\n    model.fit(x, y, epochs=1, batch_size=1)\n\n    # test with functional API\n    inputs = keras.Input((timesteps, dim))\n    outputs = keras.layers.Bidirectional(rnn(output_dim),\n                                         merge_mode=mode)(inputs)\n    model = keras.Model(inputs, outputs)\n    model.compile(loss='mse', optimizer='sgd')\n    model.fit(x, y, epochs=1, batch_size=1)\n\n    # Bidirectional and stateful\n    inputs = keras.Input(batch_shape=(1, timesteps, dim))\n    outputs = keras.layers.Bidirectional(rnn(output_dim, stateful=True),\n                                         merge_mode=mode)(inputs)\n    model = keras.Model(inputs, outputs)\n    model.compile(loss='mse', optimizer='sgd')\n    model.fit(x, y, epochs=1, batch_size=1)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/embeddings_test.py,0,"b""import pytest\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers.embeddings import Embedding\nfrom keras.models import Sequential\nimport keras.backend as K\n\n\ndef test_embedding():\n    layer_test(Embedding,\n               kwargs={'output_dim': 4, 'input_dim': 10, 'input_length': 2},\n               input_shape=(3, 2),\n               input_dtype='int32',\n               expected_output_dtype=K.floatx())\n    layer_test(Embedding,\n               kwargs={'output_dim': 4, 'input_dim': 10, 'mask_zero': True},\n               input_shape=(3, 2),\n               input_dtype='int32',\n               expected_output_dtype=K.floatx())\n    layer_test(Embedding,\n               kwargs={'output_dim': 4, 'input_dim': 10, 'mask_zero': True},\n               input_shape=(3, 2, 5),\n               input_dtype='int32',\n               expected_output_dtype=K.floatx())\n    layer_test(Embedding,\n               kwargs={'output_dim': 4, 'input_dim': 10, 'mask_zero': True,\n                       'input_length': (None, 5)},\n               input_shape=(3, 2, 5),\n               input_dtype='int32',\n               expected_output_dtype=K.floatx())\n\n\n@pytest.mark.parametrize('input_shape',\n                         [(3, 4, 5),\n                          (3, 5)])\ndef test_embedding_invalid(input_shape):\n\n    # len(input_length) should be equal to len(input_shape) - 1\n    with pytest.raises(ValueError):\n        model = Sequential([Embedding(\n            input_dim=10,\n            output_dim=4,\n            input_length=2,\n            input_shape=input_shape)])\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/local_test.py,0,"b""import pytest\n\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers import local\n\n\ndef test_locallyconnected_1d():\n    num_samples = 2\n    num_steps = 8\n    input_dim = 5\n    filter_length = 3\n    filters = 4\n    padding = 'valid'\n    strides = 1\n\n    layer_test(local.LocallyConnected1D,\n               kwargs={'filters': filters,\n                       'kernel_size': filter_length,\n                       'padding': padding,\n                       'kernel_regularizer': 'l2',\n                       'bias_regularizer': 'l2',\n                       'activity_regularizer': 'l2',\n                       'strides': strides},\n               input_shape=(num_samples, num_steps, input_dim))\n\n\ndef test_locallyconnected_2d():\n    num_samples = 5\n    filters = 3\n    stack_size = 4\n    num_row = 6\n    num_col = 8\n    padding = 'valid'\n\n    for strides in [(1, 1), (2, 2)]:\n        layer_test(local.LocallyConnected2D,\n                   kwargs={'filters': filters,\n                           'kernel_size': 3,\n                           'padding': padding,\n                           'kernel_regularizer': 'l2',\n                           'bias_regularizer': 'l2',\n                           'activity_regularizer': 'l2',\n                           'strides': strides,\n                           'data_format': 'channels_last'},\n                   input_shape=(num_samples, num_row, num_col, stack_size))\n\n        layer_test(local.LocallyConnected2D,\n                   kwargs={'filters': filters,\n                           'kernel_size': (3, 3),\n                           'padding': padding,\n                           'kernel_regularizer': 'l2',\n                           'bias_regularizer': 'l2',\n                           'activity_regularizer': 'l2',\n                           'strides': strides,\n                           'data_format': 'channels_first'},\n                   input_shape=(num_samples, stack_size, num_row, num_col))\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/merge_test.py,0,"b""import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom keras import layers\nfrom keras import models\nfrom keras import backend as K\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers import merge\n\n\ndef test_merge_add():\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    i3 = layers.Input(shape=(4, 5))\n    o = layers.add([i1, i2, i3])\n    assert o._keras_shape == (None, 4, 5)\n    model = models.Model([i1, i2, i3], o)\n\n    add_layer = layers.Add()\n    o2 = add_layer([i1, i2, i3])\n    assert add_layer.output_shape == (None, 4, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    x3 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2, x3])\n    assert out.shape == (2, 4, 5)\n    assert_allclose(out, x1 + x2 + x3, atol=1e-4)\n\n    assert add_layer.compute_mask([i1, i2, i3], [None, None, None]) is None\n    assert np.all(K.eval(add_layer.compute_mask(\n        [i1, i2, i3], [K.variable(x1), K.variable(x2), K.variable(x3)])))\n\n    # Test invalid use case\n    with pytest.raises(ValueError):\n        add_layer.compute_mask([i1, i2, i3], x1)\n    with pytest.raises(ValueError):\n        add_layer.compute_mask(i1, [None, None, None])\n    with pytest.raises(ValueError):\n        add_layer.compute_mask([i1, i2, i3], [None, None])\n\n\ndef test_merge_subtract():\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    i3 = layers.Input(shape=(4, 5))\n    i4 = layers.Input(shape=(3, 5))\n    o = layers.subtract([i1, i2])\n    assert o._keras_shape == (None, 4, 5)\n    model = models.Model([i1, i2], o)\n\n    subtract_layer = layers.Subtract()\n    o2 = subtract_layer([i1, i2])\n    assert subtract_layer.output_shape == (None, 4, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 4, 5)\n    assert_allclose(out, x1 - x2, atol=1e-4)\n\n    assert subtract_layer.compute_mask([i1, i2], [None, None]) is None\n    assert np.all(K.eval(subtract_layer.compute_mask(\n        [i1, i2], [K.variable(x1), K.variable(x2)])))\n\n    # Test invalid use case\n    with pytest.raises(ValueError):\n        subtract_layer.compute_mask([i1, i2], x1)\n    with pytest.raises(ValueError):\n        subtract_layer.compute_mask(i1, [None, None])\n    with pytest.raises(ValueError):\n        subtract_layer([i1, i2, i3])\n    with pytest.raises(ValueError):\n        subtract_layer([i1])\n\n\ndef test_merge_multiply():\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    i3 = layers.Input(shape=(4, 5))\n    o = layers.multiply([i1, i2, i3])\n    assert o._keras_shape == (None, 4, 5)\n    model = models.Model([i1, i2, i3], o)\n\n    mul_layer = layers.Multiply()\n    o2 = mul_layer([i1, i2, i3])\n    assert mul_layer.output_shape == (None, 4, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    x3 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2, x3])\n    assert out.shape == (2, 4, 5)\n    assert_allclose(out, x1 * x2 * x3, atol=1e-4)\n\n\ndef test_merge_average():\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    o = layers.average([i1, i2])\n    assert o._keras_shape == (None, 4, 5)\n    model = models.Model([i1, i2], o)\n\n    avg_layer = layers.Average()\n    o2 = avg_layer([i1, i2])\n    assert avg_layer.output_shape == (None, 4, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 4, 5)\n    assert_allclose(out, 0.5 * (x1 + x2), atol=1e-4)\n\n\ndef test_merge_maximum():\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    o = layers.maximum([i1, i2])\n    assert o._keras_shape == (None, 4, 5)\n    model = models.Model([i1, i2], o)\n\n    max_layer = layers.Maximum()\n    o2 = max_layer([i1, i2])\n    assert max_layer.output_shape == (None, 4, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 4, 5)\n    assert_allclose(out, np.maximum(x1, x2), atol=1e-4)\n\n\ndef test_merge_minimum():\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    o = layers.minimum([i1, i2])\n    assert o._keras_shape == (None, 4, 5)\n    model = models.Model([i1, i2], o)\n\n    max_layer = layers.Minimum()\n    o2 = max_layer([i1, i2])\n    assert max_layer.output_shape == (None, 4, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 4, 5)\n    assert_allclose(out, np.minimum(x1, x2), atol=1e-4)\n\n\ndef test_merge_concatenate():\n    i1 = layers.Input(shape=(None, 5))\n    i2 = layers.Input(shape=(None, 5))\n    o = layers.concatenate([i1, i2], axis=1)\n    assert o._keras_shape == (None, None, 5)\n    model = models.Model([i1, i2], o)\n\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(4, 5))\n    o = layers.concatenate([i1, i2], axis=1)\n    assert o._keras_shape == (None, 8, 5)\n    model = models.Model([i1, i2], o)\n\n    concat_layer = layers.Concatenate(axis=1)\n    o2 = concat_layer([i1, i2])\n    assert concat_layer.output_shape == (None, 8, 5)\n\n    x1 = np.random.random((2, 4, 5))\n    x2 = np.random.random((2, 4, 5))\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 8, 5)\n    assert_allclose(out, np.concatenate([x1, x2], axis=1), atol=1e-4)\n\n    x3 = np.random.random((1, 1, 1))\n    nb_layers = 4\n    x_i = layers.Input(shape=(None, None))\n    x_list = [x_i]\n    x = x_i\n    for i in range(nb_layers):\n        x_list.append(x)\n        x = layers.concatenate(x_list, axis=1)\n    concat_model = models.Model(x_i, x)\n    concat_out = concat_model.predict([x3])\n    x3 = np.repeat(x3, 16, axis=1)\n    assert concat_out.shape == (1, 16, 1)\n    assert_allclose(concat_out, x3)\n\n    assert concat_layer.compute_mask([i1, i2], [None, None]) is None\n    assert np.all(K.eval(concat_layer.compute_mask(\n        [i1, i2], [K.variable(x1), K.variable(x2)])).reshape(-1))\n\n    # Test invalid use case\n    with pytest.raises(ValueError):\n        concat_layer.compute_mask([i1, i2], x1)\n    with pytest.raises(ValueError):\n        concat_layer.compute_mask(i1, [None, None])\n    with pytest.raises(ValueError):\n        concat_layer.compute_mask([i1, i2], [None])\n    with pytest.raises(ValueError):\n        concat_layer([i1])\n\n\ndef test_merge_dot():\n    i1 = layers.Input(shape=(4,))\n    i2 = layers.Input(shape=(4,))\n    o = layers.dot([i1, i2], axes=1)\n    assert o._keras_shape == (None, 1)\n    model = models.Model([i1, i2], o)\n\n    dot_layer = layers.Dot(axes=1)\n    o2 = dot_layer([i1, i2])\n    assert dot_layer.output_shape == (None, 1)\n\n    x1 = np.random.random((2, 4))\n    x2 = np.random.random((2, 4))\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 1)\n    expected = np.zeros((2, 1))\n    expected[0, 0] = np.dot(x1[0], x2[0])\n    expected[1, 0] = np.dot(x1[1], x2[1])\n    assert_allclose(out, expected, atol=1e-4)\n\n    # Test with negative tuple of axes.\n    o = layers.dot([i1, i2], axes=(-1, -1))\n    assert o._keras_shape == (None, 1)\n    model = models.Model([i1, i2], o)\n    out = model.predict([x1, x2])\n    assert out.shape == (2, 1)\n    assert_allclose(out, expected, atol=1e-4)\n\n\ndef test_merge_broadcast():\n    # shapes provided\n    i1 = layers.Input(shape=(4, 5))\n    i2 = layers.Input(shape=(5,))\n    ops = [layers.add, layers.maximum]\n    for op in ops:\n        o = op([i1, i2])\n        assert o._keras_shape == (None, 4, 5)\n        model = models.Model([i1, i2], o)\n\n        x1 = np.random.random((2, 4, 5))\n        x2 = np.random.random((2, 5))\n        out = model.predict([x1, x2])\n        assert out.shape == (2, 4, 5)\n\n    # shapes not provided\n    i1 = layers.Input(shape=(None, None))\n    i2 = layers.Input(shape=(None,))\n    ops = [layers.add, layers.maximum]\n    for op in ops:\n        o = op([i1, i2])\n        assert o._keras_shape == (None, None, None)\n        model = models.Model([i1, i2], o)\n\n        x1 = np.random.random((2, 4, 5))\n        x2 = np.random.random((2, 5))\n        out = model.predict([x1, x2])\n        assert out.shape == (2, 4, 5)\n\n    # ndim not provided\n    if K.backend() == 'tensorflow':\n        k_ndim = K.ndim\n        K.ndim = lambda _: None\n\n        i1 = layers.Input(shape=(None, None))\n        i2 = layers.Input(shape=(None,))\n        ops = [layers.add, layers.maximum]\n        for op in ops:\n            o = op([i1, i2])\n            assert o._keras_shape == (None, None, None)\n            model = models.Model([i1, i2], o)\n\n            x1 = np.random.random((2, 4, 5))\n            x2 = np.random.random((2, 5))\n            out = model.predict([x1, x2])\n            assert out.shape == (2, 4, 5)\n        K.ndim = k_ndim\n\n\ndef test_masking_concatenate():\n    input1 = layers.Input(shape=(6,))\n    input2 = layers.Input(shape=(6,))\n    x1 = layers.Embedding(10, 5, input_length=6, mask_zero=True)(input1)\n    x2 = layers.Embedding(10, 5, input_length=6, mask_zero=True)(input2)\n    x = layers.concatenate([x1, x2])\n    x = layers.wrappers.TimeDistributed(layers.Dense(3, activation='softmax'))(x)\n    models.Model(inputs=[input1, input2], outputs=[x])\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/noise_test.py,0,"b'import pytest\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers import noise\nfrom keras import backend as K\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=""cntk does not support it yet"")\ndef test_GaussianNoise():\n    layer_test(noise.GaussianNoise,\n               kwargs={\'stddev\': 1.},\n               input_shape=(3, 2, 3))\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=""cntk does not support it yet"")\ndef test_GaussianDropout():\n    layer_test(noise.GaussianDropout,\n               kwargs={\'rate\': 0.5},\n               input_shape=(3, 2, 3))\n\n\n@pytest.mark.skipif((K.backend() == \'cntk\'),\n                    reason=""cntk does not support it yet"")\ndef test_AlphaDropout():\n    layer_test(noise.AlphaDropout,\n               kwargs={\'rate\': 0.1},\n               input_shape=(3, 2, 3))\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/layers/normalization_test.py,0,"b""import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom keras.layers import Input\nfrom keras import regularizers\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers import normalization\nfrom keras.models import Sequential, Model\nfrom keras import backend as K\n\ninput_1 = np.arange(10)\ninput_2 = np.zeros(10)\ninput_3 = np.ones((10))\ninput_4 = np.expand_dims(np.arange(10.), axis=1)\ninput_shapes = [np.ones((10, 10)), np.ones((10, 10, 10))]\n\n\ndef test_basic_batchnorm():\n    layer_test(normalization.BatchNormalization,\n               kwargs={'momentum': 0.9,\n                       'epsilon': 0.1,\n                       'gamma_regularizer': regularizers.l2(0.01),\n                       'beta_regularizer': regularizers.l2(0.01)},\n               input_shape=(3, 4, 2))\n    layer_test(normalization.BatchNormalization,\n               kwargs={'momentum': 0.9,\n                       'epsilon': 0.1,\n                       'axis': 1},\n               input_shape=(1, 4, 1))\n    layer_test(normalization.BatchNormalization,\n               kwargs={'gamma_initializer': 'ones',\n                       'beta_initializer': 'ones',\n                       'moving_mean_initializer': 'zeros',\n                       'moving_variance_initializer': 'ones'},\n               input_shape=(3, 4, 2, 4))\n    if K.backend() != 'theano':\n        layer_test(normalization.BatchNormalization,\n                   kwargs={'momentum': 0.9,\n                           'epsilon': 0.1,\n                           'axis': 1,\n                           'scale': False,\n                           'center': False},\n                   input_shape=(3, 4, 2, 4))\n\n\ndef test_batchnorm_correctness_1d():\n    np.random.seed(1337)\n    model = Sequential()\n    norm = normalization.BatchNormalization(input_shape=(10,), momentum=0.8)\n    model.add(norm)\n    model.compile(loss='mse', optimizer='rmsprop')\n\n    # centered on 5.0, variance 10.0\n    x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 10))\n    model.fit(x, x, epochs=5, verbose=0)\n    out = model.predict(x)\n    out -= K.eval(norm.beta)\n    out /= K.eval(norm.gamma)\n\n    assert_allclose(out.mean(), 0.0, atol=1e-1)\n    assert_allclose(out.std(), 1.0, atol=1e-1)\n\n\ndef test_batchnorm_correctness_2d():\n    np.random.seed(1337)\n    model = Sequential()\n    norm = normalization.BatchNormalization(axis=1, input_shape=(10, 6),\n                                            momentum=0.8)\n    model.add(norm)\n    model.compile(loss='mse', optimizer='rmsprop')\n\n    # centered on 5.0, variance 10.0\n    x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 10, 6))\n    model.fit(x, x, epochs=5, verbose=0)\n    out = model.predict(x)\n    out -= np.reshape(K.eval(norm.beta), (1, 10, 1))\n    out /= np.reshape(K.eval(norm.gamma), (1, 10, 1))\n\n    assert_allclose(out.mean(axis=(0, 2)), 0.0, atol=1.1e-1)\n    assert_allclose(out.std(axis=(0, 2)), 1.0, atol=1.1e-1)\n\n\ndef test_batchnorm_training_argument():\n    np.random.seed(1337)\n    bn1 = normalization.BatchNormalization(input_shape=(10,))\n    x1 = Input(shape=(10,))\n    y1 = bn1(x1, training=True)\n    assert bn1.updates\n\n    model1 = Model(x1, y1)\n    x = np.random.normal(loc=5.0, scale=10.0, size=(20, 10))\n    output_a = model1.predict(x)\n\n    model1.compile(loss='mse', optimizer='rmsprop')\n    model1.fit(x, x, epochs=1, verbose=0)\n    output_b = model1.predict(x)\n    assert np.abs(np.sum(output_a - output_b)) > 0.1\n    assert_allclose(output_b.mean(), 0.0, atol=1e-1)\n    assert_allclose(output_b.std(), 1.0, atol=1e-1)\n\n    bn2 = normalization.BatchNormalization(input_shape=(10,))\n    x2 = Input(shape=(10,))\n    bn2(x2, training=False)\n    assert not bn2.updates\n\n\ndef test_batchnorm_mode_twice():\n    # This is a regression test for issue #4881 with the old\n    # batch normalization functions in the Theano backend.\n    model = Sequential()\n    model.add(normalization.BatchNormalization(input_shape=(10, 5, 5), axis=1))\n    model.add(normalization.BatchNormalization(input_shape=(10, 5, 5), axis=1))\n    model.compile(loss='mse', optimizer='sgd')\n\n    x = np.random.normal(loc=5.0, scale=10.0, size=(20, 10, 5, 5))\n    model.fit(x, x, epochs=1, verbose=0)\n    model.predict(x)\n\n\ndef test_batchnorm_convnet():\n    np.random.seed(1337)\n    model = Sequential()\n    norm = normalization.BatchNormalization(axis=1, input_shape=(3, 4, 4),\n                                            momentum=0.8)\n    model.add(norm)\n    model.compile(loss='mse', optimizer='sgd')\n\n    # centered on 5.0, variance 10.0\n    x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 3, 4, 4))\n    model.fit(x, x, epochs=4, verbose=0)\n    out = model.predict(x)\n    out -= np.reshape(K.eval(norm.beta), (1, 3, 1, 1))\n    out /= np.reshape(K.eval(norm.gamma), (1, 3, 1, 1))\n\n    assert_allclose(np.mean(out, axis=(0, 2, 3)), 0.0, atol=1e-1)\n    assert_allclose(np.std(out, axis=(0, 2, 3)), 1.0, atol=1e-1)\n\n\n@pytest.mark.skipif((K.backend() == 'theano'),\n                    reason='Bug with theano backend')\ndef test_batchnorm_convnet_no_center_no_scale():\n    np.random.seed(1337)\n    model = Sequential()\n    norm = normalization.BatchNormalization(axis=-1, center=False, scale=False,\n                                            input_shape=(3, 4, 4), momentum=0.8)\n    model.add(norm)\n    model.compile(loss='mse', optimizer='sgd')\n\n    # centered on 5.0, variance 10.0\n    x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 3, 4, 4))\n    model.fit(x, x, epochs=4, verbose=0)\n    out = model.predict(x)\n\n    assert_allclose(np.mean(out, axis=(0, 2, 3)), 0.0, atol=1e-1)\n    assert_allclose(np.std(out, axis=(0, 2, 3)), 1.0, atol=1e-1)\n\n\ndef test_shared_batchnorm():\n    '''Test that a BN layer can be shared\n    across different data streams.\n    '''\n    # Test single layer reuse\n    bn = normalization.BatchNormalization(input_shape=(10,))\n    x1 = Input(shape=(10,))\n    bn(x1)\n\n    x2 = Input(shape=(10,))\n    y2 = bn(x2)\n\n    x = np.random.normal(loc=5.0, scale=10.0, size=(2, 10))\n    model = Model(x2, y2)\n    assert len(model.updates) == 2\n    model.compile('sgd', 'mse')\n    model.train_on_batch(x, x)\n\n    # Test model-level reuse\n    x3 = Input(shape=(10,))\n    y3 = model(x3)\n    new_model = Model(x3, y3)\n    assert len(model.updates) == 2\n    new_model.compile('sgd', 'mse')\n    new_model.train_on_batch(x, x)\n\n\ndef test_that_trainable_disables_updates():\n    val_a = np.random.random((10, 4))\n    val_out = np.random.random((10, 4))\n\n    a = Input(shape=(4,))\n    layer = normalization.BatchNormalization(input_shape=(4,))\n    b = layer(a)\n    model = Model(a, b)\n\n    model.trainable = False\n    assert not model.updates\n\n    model.compile('sgd', 'mse')\n    assert not model.updates\n\n    x1 = model.predict(val_a)\n    model.train_on_batch(val_a, val_out)\n    x2 = model.predict(val_a)\n    assert_allclose(x1, x2, atol=1e-7)\n\n    model.trainable = True\n    model.compile('sgd', 'mse')\n    assert model.updates\n\n    model.train_on_batch(val_a, val_out)\n    x2 = model.predict(val_a)\n    assert np.abs(np.sum(x1 - x2)) > 1e-5\n\n    layer.trainable = False\n    model.compile('sgd', 'mse')\n    assert not model.updates\n\n    x1 = model.predict(val_a)\n    model.train_on_batch(val_a, val_out)\n    x2 = model.predict(val_a)\n    assert_allclose(x1, x2, atol=1e-7)\n\n\ndef test_batchnorm_trainable():\n    bn_mean = 0.5\n    bn_std = 10.\n\n    def get_model(bn_mean, bn_std):\n        input = Input(shape=(1,))\n        x = normalization.BatchNormalization()(input)\n        model = Model(input, x)\n        model.set_weights([np.array([1.]), np.array([0.]),\n                           np.array([bn_mean]), np.array([bn_std ** 2])])\n        return model\n    # Simulates training-mode with trainable layer. Should use mini-batch statistics.\n    K.set_learning_phase(1)\n    model = get_model(bn_mean, bn_std)\n    model.compile(loss='mse', optimizer='rmsprop')\n    out = model.predict(input_4)\n    assert_allclose((input_4 - np.mean(input_4)) / np.std(input_4), out, atol=1e-3)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/pooling_test.py,0,"b""import numpy as np\nimport pytest\n\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers import pooling\nfrom keras.layers import Masking\nfrom keras.layers import convolutional\nfrom keras.models import Sequential\n\n\n@pytest.mark.parametrize(\n    'padding,stride,data_format',\n    [(padding, stride, data_format)\n     for padding in ['valid', 'same']\n     for stride in [1, 2]\n     for data_format in ['channels_first', 'channels_last']]\n)\ndef test_maxpooling_1d(padding, stride, data_format):\n    layer_test(convolutional.MaxPooling1D,\n               kwargs={'strides': stride,\n                       'padding': padding,\n                       'data_format': data_format},\n               input_shape=(3, 5, 4))\n\n\n@pytest.mark.parametrize(\n    'strides',\n    [(1, 1), (2, 3)]\n)\ndef test_maxpooling_2d(strides):\n    pool_size = (3, 3)\n    layer_test(convolutional.MaxPooling2D,\n               kwargs={'strides': strides,\n                       'padding': 'valid',\n                       'pool_size': pool_size},\n               input_shape=(3, 5, 6, 4))\n\n\n@pytest.mark.parametrize(\n    'strides,data_format,input_shape',\n    [(2, None, (3, 11, 12, 10, 4)),\n     (3, 'channels_first', (3, 4, 11, 12, 10))]\n)\ndef test_maxpooling_3d(strides, data_format, input_shape):\n    pool_size = (3, 3, 3)\n    layer_test(convolutional.MaxPooling3D,\n               kwargs={'strides': strides,\n                       'padding': 'valid',\n                       'data_format': data_format,\n                       'pool_size': pool_size},\n               input_shape=input_shape)\n\n\n@pytest.mark.parametrize(\n    'padding,stride,data_format',\n    [(padding, stride, data_format)\n     for padding in ['valid', 'same']\n     for stride in [1, 2]\n     for data_format in ['channels_first', 'channels_last']]\n)\ndef test_averagepooling_1d(padding, stride, data_format):\n    layer_test(convolutional.AveragePooling1D,\n               kwargs={'strides': stride,\n                       'padding': padding,\n                       'data_format': data_format},\n               input_shape=(3, 5, 4))\n\n\n@pytest.mark.parametrize(\n    'strides,padding,data_format,input_shape',\n    [((2, 2), 'same', None, (3, 5, 6, 4)),\n     ((2, 2), 'valid', None, (3, 5, 6, 4)),\n     ((1, 1), 'valid', 'channels_first', (3, 4, 5, 6))]\n)\ndef test_averagepooling_2d(strides, padding, data_format, input_shape):\n    layer_test(convolutional.AveragePooling2D,\n               kwargs={'strides': strides,\n                       'padding': padding,\n                       'pool_size': (2, 2),\n                       'data_format': data_format},\n               input_shape=input_shape)\n\n\n@pytest.mark.parametrize(\n    'strides,data_format,input_shape',\n    [(2, None, (3, 11, 12, 10, 4)),\n     (3, 'channels_first', (3, 4, 11, 12, 10))]\n)\ndef test_averagepooling_3d(strides, data_format, input_shape):\n    pool_size = (3, 3, 3)\n\n    layer_test(convolutional.AveragePooling3D,\n               kwargs={'strides': strides,\n                       'padding': 'valid',\n                       'data_format': data_format,\n                       'pool_size': pool_size},\n               input_shape=input_shape)\n\n\n@pytest.mark.parametrize(\n    'data_format,pooling_class',\n    [(data_format, pooling_class)\n     for data_format in ['channels_first', 'channels_last']\n     for pooling_class in [pooling.GlobalMaxPooling1D,\n                           pooling.GlobalAveragePooling1D]]\n)\ndef test_globalpooling_1d(data_format, pooling_class):\n    layer_test(pooling_class,\n               kwargs={'data_format': data_format},\n               input_shape=(3, 4, 5))\n\n\ndef test_globalpooling_1d_supports_masking():\n    # Test GlobalAveragePooling1D supports masking\n    model = Sequential()\n    model.add(Masking(mask_value=0., input_shape=(3, 4)))\n    model.add(pooling.GlobalAveragePooling1D())\n    model.compile(loss='mae', optimizer='adam')\n\n    model_input = np.random.randint(low=1, high=5, size=(2, 3, 4))\n    model_input[0, 1:, :] = 0\n    output = model.predict(model_input)\n    assert np.array_equal(output[0], model_input[0, 0, :])\n\n\n@pytest.mark.parametrize(\n    'data_format,pooling_class',\n    [(data_format, pooling_class)\n     for data_format in ['channels_first', 'channels_last']\n     for pooling_class in [pooling.GlobalMaxPooling2D,\n                           pooling.GlobalAveragePooling2D]]\n)\ndef test_globalpooling_2d(data_format, pooling_class):\n    layer_test(pooling_class,\n               kwargs={'data_format': data_format},\n               input_shape=(3, 4, 5, 6))\n\n\n@pytest.mark.parametrize(\n    'data_format,pooling_class',\n    [(data_format, pooling_class)\n     for data_format in ['channels_first', 'channels_last']\n     for pooling_class in [pooling.GlobalMaxPooling3D,\n                           pooling.GlobalAveragePooling3D]]\n)\ndef test_globalpooling_3d(data_format, pooling_class):\n    layer_test(pooling_class,\n               kwargs={'data_format': data_format},\n               input_shape=(3, 4, 3, 4, 3))\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/layers/recurrent_test.py,0,"b'import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nimport keras\nfrom keras.utils.test_utils import layer_test\nfrom keras.layers import recurrent\nfrom keras.layers import embeddings\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.engine import Input\nfrom keras.layers import Masking\nfrom keras import regularizers\nfrom keras import backend as K\n\nnum_samples, timesteps, embedding_dim, units = 2, 5, 4, 3\nembedding_num = 12\n\n\nrnn_test = pytest.mark.parametrize(\'layer_class\',\n                                   [recurrent.SimpleRNN,\n                                    recurrent.GRU,\n                                    recurrent.LSTM])\n\n\nrnn_cell_test = pytest.mark.parametrize(\'cell_class\',\n                                        [recurrent.SimpleRNNCell,\n                                         recurrent.GRUCell,\n                                         recurrent.LSTMCell])\n\n\n@rnn_test\ndef test_return_sequences(layer_class):\n    layer_test(layer_class,\n               kwargs={\'units\': units,\n                       \'return_sequences\': True},\n               input_shape=(num_samples, timesteps, embedding_dim))\n\n\n@rnn_test\ndef test_dynamic_behavior(layer_class):\n    layer = layer_class(units, input_shape=(None, embedding_dim))\n    model = Sequential()\n    model.add(layer)\n    model.compile(\'sgd\', \'mse\')\n    x = np.random.random((num_samples, timesteps, embedding_dim))\n    y = np.random.random((num_samples, units))\n    model.train_on_batch(x, y)\n\n\n@rnn_test\ndef test_stateful_invalid_use(layer_class):\n    layer = layer_class(units,\n                        stateful=True,\n                        batch_input_shape=(num_samples,\n                                           timesteps,\n                                           embedding_dim))\n    model = Sequential()\n    model.add(layer)\n    model.compile(\'sgd\', \'mse\')\n    x = np.random.random((num_samples * 2, timesteps, embedding_dim))\n    y = np.random.random((num_samples * 2, units))\n    with pytest.raises(ValueError):\n        model.fit(x, y)\n    with pytest.raises(ValueError):\n        model.predict(x, batch_size=num_samples + 1)\n\n\n@rnn_test\n@pytest.mark.skipif((K.backend() in [\'theano\']),\n                    reason=\'Not supported.\')\ndef test_dropout(layer_class):\n    for unroll in [True, False]:\n        layer_test(layer_class,\n                   kwargs={\'units\': units,\n                           \'dropout\': 0.1,\n                           \'recurrent_dropout\': 0.1,\n                           \'unroll\': unroll},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n\n        # Test that dropout is applied during training\n        x = K.ones((num_samples, timesteps, embedding_dim))\n        layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                            input_shape=(timesteps, embedding_dim))\n        y = layer(x)\n        assert y._uses_learning_phase\n\n        y = layer(x, training=True)\n        assert not getattr(y, \'_uses_learning_phase\')\n\n        # Test that dropout is not applied during testing\n        x = np.random.random((num_samples, timesteps, embedding_dim))\n        layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                            unroll=unroll,\n                            input_shape=(timesteps, embedding_dim))\n        model = Sequential([layer])\n        assert model.uses_learning_phase\n        y1 = model.predict(x)\n        y2 = model.predict(x)\n        assert_allclose(y1, y2)\n\n\n@rnn_test\ndef test_statefulness(layer_class):\n    model = Sequential()\n    model.add(embeddings.Embedding(embedding_num, embedding_dim,\n                                   mask_zero=True,\n                                   input_length=timesteps,\n                                   batch_input_shape=(num_samples, timesteps)))\n    layer = layer_class(units, return_sequences=False,\n                        stateful=True,\n                        weights=None)\n    model.add(layer)\n    model.compile(optimizer=\'sgd\', loss=\'mse\')\n    out1 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out1.shape == (num_samples, units))\n\n    # train once so that the states change\n    model.train_on_batch(np.ones((num_samples, timesteps)),\n                         np.ones((num_samples, units)))\n    out2 = model.predict(np.ones((num_samples, timesteps)))\n\n    # if the state is not reset, output should be different\n    assert(out1.max() != out2.max())\n\n    # check that output changes after states are reset\n    # (even though the model itself didn\'t change)\n    layer.reset_states()\n    out3 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out2.max() != out3.max())\n\n    # check that container-level reset_states() works\n    model.reset_states()\n    out4 = model.predict(np.ones((num_samples, timesteps)))\n    assert_allclose(out3, out4, atol=1e-5)\n\n    # check that the call to `predict` updated the states\n    out5 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out4.max() != out5.max())\n\n\n@rnn_test\ndef test_masking_correctness(layer_class):\n    # Check masking: output with left padding and right padding\n    # should be the same.\n    model = Sequential()\n    model.add(embeddings.Embedding(embedding_num, embedding_dim,\n                                   mask_zero=True,\n                                   input_length=timesteps,\n                                   batch_input_shape=(num_samples, timesteps)))\n    layer = layer_class(units, return_sequences=False)\n    model.add(layer)\n    model.compile(optimizer=\'sgd\', loss=\'mse\')\n\n    left_padded_input = np.ones((num_samples, timesteps))\n    left_padded_input[0, :1] = 0\n    left_padded_input[1, :2] = 0\n    out6 = model.predict(left_padded_input)\n\n    right_padded_input = np.ones((num_samples, timesteps))\n    right_padded_input[0, -1:] = 0\n    right_padded_input[1, -2:] = 0\n    out7 = model.predict(right_padded_input)\n\n    assert_allclose(out7, out6, atol=1e-5)\n\n\n@pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported.\')\ndef test_masking_correctness_output_not_equal_to_first_state():\n\n    class Cell(keras.layers.Layer):\n\n        def __init__(self):\n            self.state_size = None\n            self.output_size = None\n            super(Cell, self).__init__()\n\n        def build(self, input_shape):\n            self.state_size = input_shape[-1]\n            self.output_size = input_shape[-1]\n\n        def call(self, inputs, states):\n            return inputs, [s + 1 for s in states]\n\n    num_samples = 5\n    num_timesteps = 4\n    state_size = input_size = 3  # also equal to `output_size`\n\n    # random inputs and state values\n    x_vals = np.random.random((num_samples, num_timesteps, input_size))\n    # last timestep masked for first sample (all zero inputs masked by Masking layer)\n    x_vals[0, -1, :] = 0\n    s_initial_vals = np.random.random((num_samples, state_size))\n\n    # final outputs equal to last inputs\n    y_vals_expected = x_vals[:, -1].copy()\n    # except for first sample, where it is equal to second to last value due to mask\n    y_vals_expected[0] = x_vals[0, -2]\n\n    s_final_vals_expected = s_initial_vals.copy()\n    # states are incremented `num_timesteps - 1` times for first sample\n    s_final_vals_expected[0] += (num_timesteps - 1)\n    # and `num_timesteps - 1` times for remaining samples\n    s_final_vals_expected[1:] += num_timesteps\n\n    for unroll in [True, False]:\n        x = Input((num_timesteps, input_size), name=""x"")\n        x_masked = Masking()(x)\n        s_initial = Input((state_size,), name=""s_initial"")\n        y, s_final = recurrent.RNN(Cell(),\n                                   return_state=True,\n                                   unroll=unroll)(x_masked, initial_state=s_initial)\n        model = Model([x, s_initial], [y, s_final])\n        model.compile(optimizer=\'sgd\', loss=\'mse\')\n\n        y_vals, s_final_vals = model.predict([x_vals, s_initial_vals])\n        assert_allclose(y_vals,\n                        y_vals_expected,\n                        err_msg=""Unexpected output for unroll={}"".format(unroll))\n        assert_allclose(s_final_vals,\n                        s_final_vals_expected,\n                        err_msg=""Unexpected state for unroll={}"".format(unroll))\n\n\n@pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported.\')\ndef test_masking_correctness_output_size_not_equal_to_first_state_size():\n\n    class Cell(keras.layers.Layer):\n\n        def __init__(self):\n            self.state_size = None\n            self.output_size = None\n            super(Cell, self).__init__()\n\n        def build(self, input_shape):\n            self.state_size = input_shape[-1]\n            self.output_size = input_shape[-1] * 2\n\n        def call(self, inputs, states):\n            return keras.layers.concatenate([inputs] * 2), [s + 1 for s in states]\n\n    num_samples = 5\n    num_timesteps = 6\n    input_size = state_size = 7\n\n    # random inputs and state values\n    x_vals = np.random.random((num_samples, num_timesteps, input_size))\n    # last timestep masked for first sample (all zero inputs masked by Masking layer)\n    x_vals[0, -1, :] = 0\n    s_initial_vals = np.random.random((num_samples, state_size))\n\n    # final outputs equal to last inputs concatenated\n    y_vals_expected = np.concatenate([x_vals[:, -1]] * 2, axis=-1)\n    # except for first sample, where it is equal to second to last value due to mask\n    y_vals_expected[0] = np.concatenate([x_vals[0, -2]] * 2, axis=-1)\n\n    s_final_vals_expected = s_initial_vals.copy()\n    # states are incremented `num_timesteps - 1` times for first sample\n    s_final_vals_expected[0] += (num_timesteps - 1)\n    # and `num_timesteps - 1` times for remaining samples\n    s_final_vals_expected[1:] += num_timesteps\n\n    for unroll in [True, False]:\n        x = Input((num_timesteps, input_size), name=""x"")\n        x_masked = Masking()(x)\n        s_initial = Input((state_size,), name=""s_initial"")\n        y, s_final = recurrent.RNN(Cell(),\n                                   return_state=True,\n                                   unroll=unroll)(x_masked, initial_state=s_initial)\n        model = Model([x, s_initial], [y, s_final])\n        model.compile(optimizer=\'sgd\', loss=\'mse\')\n\n        y_vals, s_final_vals = model.predict([x_vals, s_initial_vals])\n        assert_allclose(y_vals,\n                        y_vals_expected,\n                        err_msg=""Unexpected output for unroll={}"".format(unroll))\n        assert_allclose(s_final_vals,\n                        s_final_vals_expected,\n                        err_msg=""Unexpected state for unroll={}"".format(unroll))\n\n\n@rnn_test\ndef test_implementation_mode(layer_class):\n    for mode in [1, 2]:\n        # Without dropout\n        layer_test(layer_class,\n                   kwargs={\'units\': units,\n                           \'implementation\': mode},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n        # With dropout\n        layer_test(layer_class,\n                   kwargs={\'units\': units,\n                           \'implementation\': mode,\n                           \'dropout\': 0.1,\n                           \'recurrent_dropout\': 0.1},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n        # Without bias\n        layer_test(layer_class,\n                   kwargs={\'units\': units,\n                           \'implementation\': mode,\n                           \'use_bias\': False},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n\n\n@rnn_test\ndef test_regularizer(layer_class):\n    layer = layer_class(units, return_sequences=False, weights=None,\n                        input_shape=(timesteps, embedding_dim),\n                        kernel_regularizer=regularizers.l1(0.01),\n                        recurrent_regularizer=regularizers.l1(0.01),\n                        bias_regularizer=\'l2\')\n    layer.build((None, None, embedding_dim))\n    assert len(layer.losses) == 3\n    assert len(layer.cell.losses) == 3\n\n    layer = layer_class(units, return_sequences=False, weights=None,\n                        input_shape=(timesteps, embedding_dim),\n                        activity_regularizer=\'l2\')\n    assert layer.activity_regularizer\n    x = K.variable(np.ones((num_samples, timesteps, embedding_dim)))\n    layer(x)\n    assert len(layer.cell.get_losses_for(x)) == 0\n    assert len(layer.get_losses_for(x)) == 1\n\n\n@rnn_test\ndef test_trainability(layer_class):\n    layer = layer_class(units)\n    layer.build((None, None, embedding_dim))\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 0\n    layer.trainable = False\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 0\n    assert len(layer.non_trainable_weights) == 3\n    layer.trainable = True\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 0\n\n\ndef test_masking_layer():\n    \'\'\' This test based on a previously failing issue here:\n    https://github.com/keras-team/keras/issues/1567\n    \'\'\'\n    inputs = np.random.random((6, 3, 4))\n    targets = np.abs(np.random.random((6, 3, 5)))\n    targets /= targets.sum(axis=-1, keepdims=True)\n\n    model = Sequential()\n    model.add(Masking(input_shape=(3, 4)))\n    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=False))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\')\n    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)\n\n    model = Sequential()\n    model.add(Masking(input_shape=(3, 4)))\n    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=True))\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\')\n    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)\n\n\n@rnn_test\ndef test_from_config(layer_class):\n    stateful_flags = (False, True)\n    for stateful in stateful_flags:\n        l1 = layer_class(units=1, stateful=stateful)\n        l2 = layer_class.from_config(l1.get_config())\n        assert l1.get_config() == l2.get_config()\n\n\n@rnn_test\ndef test_specify_initial_state_keras_tensor(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with Keras tensor\n    inputs = Input((timesteps, embedding_dim))\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    layer = layer_class(units)\n    if len(initial_state) == 1:\n        output = layer(inputs, initial_state=initial_state[0])\n    else:\n        output = layer(inputs, initial_state=initial_state)\n    assert id(initial_state[0]) in [\n        id(x) for x in layer._inbound_nodes[0].input_tensors]\n\n    model = Model([inputs] + initial_state, output)\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.fit([inputs] + initial_state, targets)\n\n\n@rnn_test\ndef test_specify_initial_state_non_keras_tensor(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with non-Keras tensor\n    inputs = Input((timesteps, embedding_dim))\n    initial_state = [K.random_normal_variable((num_samples, units), 0, 1)\n                     for _ in range(num_states)]\n    layer = layer_class(units)\n    output = layer(inputs, initial_state=initial_state)\n\n    model = Model(inputs, output)\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    targets = np.random.random((num_samples, units))\n    model.fit(inputs, targets)\n\n\n@rnn_test\ndef test_reset_states_with_values(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    layer = layer_class(units, stateful=True)\n    layer.build((num_samples, timesteps, embedding_dim))\n    layer.reset_states()\n    assert len(layer.states) == num_states\n    assert layer.states[0] is not None\n    np.testing.assert_allclose(K.eval(layer.states[0]),\n                               np.zeros(K.int_shape(layer.states[0])),\n                               atol=1e-4)\n    state_shapes = [K.int_shape(state) for state in layer.states]\n    values = [np.ones(shape) for shape in state_shapes]\n    if len(values) == 1:\n        values = values[0]\n    layer.reset_states(values)\n    np.testing.assert_allclose(K.eval(layer.states[0]),\n                               np.ones(K.int_shape(layer.states[0])),\n                               atol=1e-4)\n\n    # Test fit with invalid data\n    with pytest.raises(ValueError):\n        layer.reset_states([1] * (len(layer.states) + 1))\n\n\n@rnn_test\ndef test_initial_states_as_other_inputs(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with Keras tensor\n    main_inputs = Input((timesteps, embedding_dim))\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    inputs = [main_inputs] + initial_state\n\n    layer = layer_class(units)\n    output = layer(inputs)\n    assert id(initial_state[0]) in [\n        id(x) for x in layer._inbound_nodes[0].input_tensors]\n\n    model = Model(inputs, output)\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\')\n\n    main_inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.train_on_batch([main_inputs] + initial_state, targets)\n\n\n@rnn_test\ndef test_specify_state_with_masking(layer_class):\n    \'\'\' This test based on a previously failing issue here:\n    https://github.com/keras-team/keras/issues/1567\n    \'\'\'\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    inputs = Input((timesteps, embedding_dim))\n    _ = Masking()(inputs)\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    output = layer_class(units)(inputs, initial_state=initial_state)\n\n    model = Model([inputs] + initial_state, output)\n    model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.fit([inputs] + initial_state, targets)\n\n\n@rnn_test\ndef test_return_state(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    inputs = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, stateful=True)\n    outputs = layer(inputs)\n    output, state = outputs[0], outputs[1:]\n    assert len(state) == num_states\n    model = Model(inputs, state[0])\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    state = model.predict(inputs)\n    np.testing.assert_allclose(K.eval(layer.states[0]), state, atol=1e-4)\n\n\n@rnn_test\ndef test_state_reuse(layer_class):\n    inputs = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, return_sequences=True)\n    outputs = layer(inputs)\n    output, state = outputs[0], outputs[1:]\n    output = layer_class(units)(output, initial_state=state)\n    model = Model(inputs, output)\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    outputs = model.predict(inputs)\n\n\n@rnn_test\n@pytest.mark.skipif((K.backend() in [\'theano\']),\n                    reason=\'Not supported.\')\ndef test_state_reuse_with_dropout(layer_class):\n    input1 = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, return_sequences=True, dropout=0.2)\n    state = layer(input1)[1:]\n\n    input2 = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    output = layer_class(units)(input2, initial_state=state)\n    model = Model([input1, input2], output)\n\n    inputs = [np.random.random((num_samples, timesteps, embedding_dim)),\n              np.random.random((num_samples, timesteps, embedding_dim))]\n    outputs = model.predict(inputs)\n\n\ndef test_minimal_rnn_cell_non_layer():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(32, 8),\n             MinimalRNNCell(32, 32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n\ndef test_minimal_rnn_cell_non_layer_multiple_states():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(16, 8),\n             MinimalRNNCell(32, 16)]\n    layer = recurrent.RNN(cells)\n    assert layer.cell.state_size == (8, 8, 16, 16, 32, 32)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n\ndef test_minimal_rnn_cell_layer():\n\n    class MinimalRNNCell(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            # no time axis in the input shape passed to RNN cells\n            assert len(input_shape) == 2\n\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer=\'uniform\',\n                                          name=\'kernel\')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer=\'uniform\',\n                name=\'recurrent_kernel\')\n            self.built = True\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]\n\n        def get_config(self):\n            config = {\'units\': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = MinimalRNNCell(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({\'MinimalRNNCell\': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8),\n             MinimalRNNCell(12),\n             MinimalRNNCell(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({\'MinimalRNNCell\': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n\n@rnn_cell_test\ndef test_builtin_rnn_cell_layer(cell_class):\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = cell_class(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [cell_class(8),\n             cell_class(12),\n             cell_class(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n\n@pytest.mark.skipif((K.backend() in [\'cntk\', \'theano\']),\n                    reason=\'Not supported.\')\ndef test_stacked_rnn_dropout():\n    cells = [recurrent.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1),\n             recurrent.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1)]\n    layer = recurrent.RNN(cells)\n\n    x = keras.Input((None, 5))\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(\'sgd\', \'mse\')\n    x_np = np.random.random((6, 5, 5))\n    y_np = np.random.random((6, 3))\n    model.train_on_batch(x_np, y_np)\n\n\ndef test_stacked_rnn_attributes():\n    cells = [recurrent.LSTMCell(3),\n             recurrent.LSTMCell(3, kernel_regularizer=\'l2\')]\n    layer = recurrent.RNN(cells)\n    layer.build((None, None, 5))\n\n    # Test regularization losses\n    assert len(layer.losses) == 1\n\n    # Test weights\n    assert len(layer.trainable_weights) == 6\n    cells[0].trainable = False\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 3\n\n    # Test `get_losses_for`\n    x = keras.Input((None, 5))\n    y = K.sum(x)\n    cells[0].add_loss(y, inputs=x)\n    assert layer.get_losses_for(x) == [y]\n\n\ndef test_stacked_rnn_compute_output_shape():\n    cells = [recurrent.LSTMCell(3),\n             recurrent.LSTMCell(6)]\n    layer = recurrent.RNN(cells, return_state=True, return_sequences=True)\n    output_shape = layer.compute_output_shape((None, timesteps, embedding_dim))\n    expected_output_shape = [(None, timesteps, 6),\n                             (None, 3),\n                             (None, 3),\n                             (None, 6),\n                             (None, 6)]\n    assert output_shape == expected_output_shape\n\n    # Test reverse_state_order = True for stacked cell.\n    stacked_cell = recurrent.StackedRNNCells(\n        cells, reverse_state_order=True)\n    layer = recurrent.RNN(\n        stacked_cell, return_state=True, return_sequences=True)\n    output_shape = layer.compute_output_shape((None, timesteps, embedding_dim))\n    expected_output_shape = [(None, timesteps, 6),\n                             (None, 6),\n                             (None, 6),\n                             (None, 3),\n                             (None, 3)]\n    assert output_shape == expected_output_shape\n\n\n@rnn_test\ndef test_batch_size_equal_one(layer_class):\n    inputs = Input(batch_shape=(1, timesteps, embedding_dim))\n    layer = layer_class(units)\n    outputs = layer(inputs)\n    model = Model(inputs, outputs)\n    model.compile(\'sgd\', \'mse\')\n    x = np.random.random((1, timesteps, embedding_dim))\n    y = np.random.random((1, units))\n    model.train_on_batch(x, y)\n\n\ndef test_rnn_cell_with_constants_layer():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError(\'expects constants shape\')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer=\'uniform\',\n                name=\'kernel\')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer=\'uniform\',\n                name=\'recurrent_kernel\')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer=\'uniform\',\n                name=\'constant_kernel\')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {\'units\': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {\'RNNCellWithConstants\': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, c])\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)\n\n    # Test stacking.\n    cells = [recurrent.GRUCell(8),\n             RNNCellWithConstants(12),\n             RNNCellWithConstants(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n\ndef test_rnn_cell_with_constants_layer_passing_initial_state():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError(\'expects constants shape\')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer=\'uniform\',\n                name=\'kernel\')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer=\'uniform\',\n                name=\'recurrent_kernel\')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer=\'uniform\',\n                name=\'constant_kernel\')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {\'units\': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    s = keras.Input((32,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 32)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    s_np = np.random.random((6, 32))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, s_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {\'RNNCellWithConstants\': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # verify that state is used\n    y_np_2_different_s = model.predict([x_np, s_np + 10., c_np])\n    with pytest.raises(AssertionError):\n        assert_allclose(y_np, y_np_2_different_s, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, s, c])\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)\n\n\n@rnn_test\ndef test_rnn_cell_identity_initializer(layer_class):\n    inputs = Input(shape=(timesteps, embedding_dim))\n    layer = layer_class(units, recurrent_initializer=\'identity\')\n    layer(inputs)\n    recurrent_kernel = layer.get_weights()[1]\n    num_kernels = recurrent_kernel.shape[1] // recurrent_kernel.shape[0]\n    assert np.array_equal(recurrent_kernel,\n                          np.concatenate([np.identity(units)] * num_kernels, axis=1))\n\n\n@pytest.mark.skipif(K.backend() == \'cntk\', reason=\'Not supported.\')\ndef test_inconsistent_output_state_size():\n\n    class PlusOneRNNCell(keras.layers.Layer):\n        """"""Add one to the input and state.\n\n        This cell is used for testing state_size and output_size.""""""\n\n        def __init__(self, num_unit, **kwargs):\n            self.state_size = num_unit\n            super(PlusOneRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            self.output_size = input_shape[-1]\n\n        def call(self, inputs, states):\n            return inputs + 1, [states[0] + 1]\n\n    batch = 32\n    time_step = 4\n    state_size = 5\n    input_size = 6\n    cell = PlusOneRNNCell(state_size)\n    x = keras.Input((None, input_size))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n\n    assert cell.state_size == state_size\n    init_state = layer.get_initial_state(x)\n    assert len(init_state) == 1\n    if K.backend() != \'theano\':\n        # theano does not support static shape inference.\n        assert K.int_shape(init_state[0]) == (None, state_size)\n\n    model = keras.models.Model(x, y)\n    model.compile(optimizer=\'rmsprop\', loss=\'mse\')\n    model.train_on_batch(\n        np.zeros((batch, time_step, input_size)),\n        np.zeros((batch, input_size)))\n    assert model.output_shape == (None, input_size)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/layers/wrappers_test.py,0,"b""import pytest\nimport numpy as np\nimport copy\nfrom numpy.testing import assert_allclose\nfrom keras.utils import CustomObjectScope\nfrom keras.layers import wrappers, Input, Layer\nfrom keras.layers import RNN\nfrom keras import layers\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras import backend as K\nfrom keras.utils.generic_utils import object_list_uid, to_list\n\n\ndef test_TimeDistributed():\n    # first, test with Dense layer\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(layers.Dense(2), input_shape=(3, 4)))\n    model.add(layers.Activation('relu'))\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 2)),\n              epochs=1,\n              batch_size=10)\n\n    # test config\n    model.get_config()\n\n    # test when specifying a batch_input_shape\n    test_input = np.random.random((1, 3, 4))\n    test_output = model.predict(test_input)\n    weights = model.layers[0].get_weights()\n\n    reference = Sequential()\n    reference.add(wrappers.TimeDistributed(layers.Dense(2),\n                                           batch_input_shape=(1, 3, 4)))\n    reference.add(layers.Activation('relu'))\n    reference.compile(optimizer='rmsprop', loss='mse')\n    reference.layers[0].set_weights(weights)\n\n    reference_output = reference.predict(test_input)\n    assert_allclose(test_output, reference_output, atol=1e-05)\n\n    # test with Embedding\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(layers.Embedding(5, 6),\n                                       batch_input_shape=(10, 3, 4),\n                                       dtype='int32'))\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.fit(np.random.randint(5, size=(10, 3, 4), dtype='int32'),\n              np.random.random((10, 3, 4, 6)), epochs=1, batch_size=10)\n\n    # compare to not using batch_input_shape\n    test_input = np.random.randint(5, size=(10, 3, 4), dtype='int32')\n    test_output = model.predict(test_input)\n    weights = model.layers[0].get_weights()\n\n    reference = Sequential()\n    reference.add(wrappers.TimeDistributed(layers.Embedding(5, 6),\n                                           input_shape=(3, 4), dtype='int32'))\n    reference.compile(optimizer='rmsprop', loss='mse')\n    reference.layers[0].set_weights(weights)\n\n    reference_output = reference.predict(test_input)\n    assert_allclose(test_output, reference_output, atol=1e-05)\n\n    # test with Conv2D\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(layers.Conv2D(5, (2, 2),\n                                                     padding='same'),\n                                       input_shape=(2, 4, 4, 3)))\n    model.add(layers.Activation('relu'))\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.random.random((1, 2, 4, 4, 3)),\n                         np.random.random((1, 2, 4, 4, 5)))\n\n    model = model_from_json(model.to_json())\n    model.summary()\n\n    # test stacked layers\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(layers.Dense(2), input_shape=(3, 4)))\n    model.add(wrappers.TimeDistributed(layers.Dense(3)))\n    model.add(layers.Activation('relu'))\n    model.compile(optimizer='rmsprop', loss='mse')\n\n    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 3)),\n              epochs=1, batch_size=10)\n\n    # test wrapping Sequential model\n    model = Sequential()\n    model.add(layers.Dense(3, input_dim=2))\n    outer_model = Sequential()\n    outer_model.add(wrappers.TimeDistributed(model, input_shape=(3, 2)))\n    outer_model.compile(optimizer='rmsprop', loss='mse')\n    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)),\n                    epochs=1, batch_size=10)\n\n    # test with functional API\n    x = Input(shape=(3, 2))\n    y = wrappers.TimeDistributed(model)(x)\n    outer_model = Model(x, y)\n    outer_model.compile(optimizer='rmsprop', loss='mse')\n    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)),\n                    epochs=1, batch_size=10)\n\n    # test with BatchNormalization\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(\n        layers.BatchNormalization(center=True, scale=True),\n        name='bn', input_shape=(10, 2)))\n    model.compile(optimizer='rmsprop', loss='mse')\n    # Assert that mean and variance are 0 and 1.\n    td = model.layers[0]\n    assert np.array_equal(td.get_weights()[2], np.array([0, 0]))\n    assert np.array_equal(td.get_weights()[3], np.array([1, 1]))\n    # Train\n    model.train_on_batch(np.random.normal(loc=2, scale=2, size=(1, 10, 2)),\n                         np.broadcast_to(np.array([0, 1]), (1, 10, 2)))\n    # Assert that mean and variance changed.\n    assert not np.array_equal(td.get_weights()[2], np.array([0, 0]))\n    assert not np.array_equal(td.get_weights()[3], np.array([1, 1]))\n    # Verify input_map has one mapping from inputs to reshaped inputs.\n    uid = object_list_uid(model.inputs)\n    assert len(td._input_map.keys()) == 1\n    assert uid in td._input_map\n    assert K.int_shape(td._input_map[uid]) == (None, 2)\n\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='Flaky with CNTK backend')\ndef test_TimeDistributed_learning_phase():\n    # test layers that need learning_phase to be set\n    np.random.seed(1234)\n    x = Input(shape=(3, 2))\n    y = wrappers.TimeDistributed(layers.Dropout(.999))(x, training=True)\n    model = Model(x, y)\n    y = model.predict(np.random.random((10, 3, 2)))\n    assert_allclose(np.mean(y), 0., atol=1e-1, rtol=1e-1)\n\n\ndef test_TimeDistributed_trainable():\n    # test layers that need learning_phase to be set\n    x = Input(shape=(3, 2))\n    layer = wrappers.TimeDistributed(layers.BatchNormalization())\n    _ = layer(x)\n    assert len(layer.updates) == 2\n    assert len(layer.trainable_weights) == 2\n    layer.trainable = False\n    assert len(layer.updates) == 0\n    assert len(layer.trainable_weights) == 0\n    layer.trainable = True\n    assert len(layer.updates) == 2\n    assert len(layer.trainable_weights) == 2\n\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='Unknown timestamps for RNN not supported in CNTK.')\ndef test_TimeDistributed_with_masked_embedding_and_unspecified_shape():\n    # test with unspecified shape and Embeddings with mask_zero\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(layers.Embedding(5, 6, mask_zero=True),\n                                       input_shape=(None, None)))\n    # the shape so far: (N, t_1, t_2, 6)\n    model.add(wrappers.TimeDistributed(layers.SimpleRNN(7, return_sequences=True)))\n    model.add(wrappers.TimeDistributed(layers.SimpleRNN(8, return_sequences=False)))\n    model.add(layers.SimpleRNN(1, return_sequences=False))\n    model.compile(optimizer='rmsprop', loss='mse')\n    model_input = np.random.randint(low=1, high=5, size=(10, 3, 4), dtype='int32')\n    for i in range(4):\n        model_input[i, i:, i:] = 0\n    model.fit(model_input,\n              np.random.random((10, 1)), epochs=1, batch_size=10)\n    mask_outputs = [model.layers[0].compute_mask(model.input)]\n    for layer in model.layers[1:]:\n        mask_outputs.append(layer.compute_mask(layer.input, mask_outputs[-1]))\n    func = K.function([model.input], mask_outputs[:-1])\n    mask_outputs_val = func([model_input])\n    ref_mask_val_0 = model_input > 0         # embedding layer\n    ref_mask_val_1 = ref_mask_val_0          # first RNN layer\n    ref_mask_val_2 = np.any(ref_mask_val_1, axis=-1)     # second RNN layer\n    ref_mask_val = [ref_mask_val_0, ref_mask_val_1, ref_mask_val_2]\n    for i in range(3):\n        assert np.array_equal(mask_outputs_val[i], ref_mask_val[i])\n    assert mask_outputs[-1] is None  # final layer\n\n\ndef test_TimeDistributed_with_masking_layer():\n    # test with Masking layer\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(layers.Masking(mask_value=0.,),\n                                       input_shape=(None, 4)))\n    model.add(wrappers.TimeDistributed(layers.Dense(5)))\n    model.compile(optimizer='rmsprop', loss='mse')\n    model_input = np.random.randint(low=1, high=5, size=(10, 3, 4))\n    for i in range(4):\n        model_input[i, i:, :] = 0.\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.fit(model_input,\n              np.random.random((10, 3, 5)), epochs=1, batch_size=6)\n    mask_outputs = [model.layers[0].compute_mask(model.input)]\n    mask_outputs += [model.layers[1].compute_mask(model.layers[1].input,\n                                                  mask_outputs[-1])]\n    func = K.function([model.input], mask_outputs)\n    mask_outputs_val = func([model_input])\n    assert np.array_equal(mask_outputs_val[0], np.any(model_input, axis=-1))\n    assert np.array_equal(mask_outputs_val[1], np.any(model_input, axis=-1))\n\n\ndef test_regularizers():\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(\n        layers.Dense(2, kernel_regularizer='l1'), input_shape=(3, 4)))\n    model.add(layers.Activation('relu'))\n    model.compile(optimizer='rmsprop', loss='mse')\n    assert len(model.layers[0].layer.losses) == 1\n    assert len(model.layers[0].losses) == 1\n    assert len(model.layers[0].get_losses_for(None)) == 1\n    assert len(model.losses) == 1\n\n    model = Sequential()\n    model.add(wrappers.TimeDistributed(\n        layers.Dense(2, activity_regularizer='l1'), input_shape=(3, 4)))\n    model.add(layers.Activation('relu'))\n    model.compile(optimizer='rmsprop', loss='mse')\n    assert len(model.losses) == 1\n\n\ndef test_Bidirectional():\n    rnn = layers.SimpleRNN\n    samples = 2\n    dim = 2\n    timesteps = 2\n    output_dim = 2\n    dropout_rate = 0.2\n    for mode in ['sum', 'concat']:\n        x = np.random.random((samples, timesteps, dim))\n        target_dim = 2 * output_dim if mode == 'concat' else output_dim\n        y = np.random.random((samples, target_dim))\n\n        # test with Sequential model\n        model = Sequential()\n        model.add(wrappers.Bidirectional(rnn(output_dim, dropout=dropout_rate,\n                                             recurrent_dropout=dropout_rate),\n                                         merge_mode=mode,\n                                         input_shape=(timesteps, dim)))\n        model.compile(loss='mse', optimizer='sgd')\n        model.fit(x, y, epochs=1, batch_size=1)\n\n        # test config\n        model.get_config()\n        model = model_from_json(model.to_json())\n        model.summary()\n\n        # test stacked bidirectional layers\n        model = Sequential()\n        model.add(wrappers.Bidirectional(rnn(output_dim,\n                                             return_sequences=True),\n                                         merge_mode=mode,\n                                         input_shape=(timesteps, dim)))\n        model.add(wrappers.Bidirectional(rnn(output_dim), merge_mode=mode))\n        model.compile(loss='mse', optimizer='sgd')\n        model.fit(x, y, epochs=1, batch_size=1)\n\n        # Bidirectional and stateful\n        inputs = Input(batch_shape=(1, timesteps, dim))\n        outputs = wrappers.Bidirectional(rnn(output_dim, stateful=True),\n                                         merge_mode=mode)(inputs)\n        model = Model(inputs, outputs)\n        model.compile(loss='mse', optimizer='sgd')\n        model.fit(x, y, epochs=1, batch_size=1)\n\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='Unknown timestamps not supported in CNTK.')\ndef test_Bidirectional_dynamic_timesteps():\n    # test with functional API with dynamic length\n    rnn = layers.SimpleRNN\n    samples = 2\n    dim = 2\n    timesteps = 2\n    output_dim = 2\n    dropout_rate = 0.2\n    for mode in ['sum', 'concat']:\n        x = np.random.random((samples, timesteps, dim))\n        target_dim = 2 * output_dim if mode == 'concat' else output_dim\n        y = np.random.random((samples, target_dim))\n\n        inputs = Input((None, dim))\n        outputs = wrappers.Bidirectional(rnn(output_dim, dropout=dropout_rate,\n                                             recurrent_dropout=dropout_rate),\n                                         merge_mode=mode)(inputs)\n        model = Model(inputs, outputs)\n        model.compile(loss='mse', optimizer='sgd')\n        model.fit(x, y, epochs=1, batch_size=1)\n\n\n@pytest.mark.parametrize('merge_mode', ['sum', 'mul', 'ave', 'concat', None])\ndef test_Bidirectional_merged_value(merge_mode):\n    rnn = layers.LSTM\n    samples = 2\n    dim = 5\n    timesteps = 3\n    units = 3\n    X = [np.random.rand(samples, timesteps, dim)]\n\n    if merge_mode == 'sum':\n        merge_func = lambda y, y_rev: y + y_rev\n    elif merge_mode == 'mul':\n        merge_func = lambda y, y_rev: y * y_rev\n    elif merge_mode == 'ave':\n        merge_func = lambda y, y_rev: (y + y_rev) / 2\n    elif merge_mode == 'concat':\n        merge_func = lambda y, y_rev: np.concatenate((y, y_rev), axis=-1)\n    else:\n        merge_func = lambda y, y_rev: [y, y_rev]\n\n    # basic case\n    inputs = Input((timesteps, dim))\n    layer = wrappers.Bidirectional(rnn(units, return_sequences=True),\n                                   merge_mode=merge_mode)\n    f_merged = K.function([inputs], to_list(layer(inputs)))\n    f_forward = K.function([inputs], [layer.forward_layer(inputs)])\n    f_backward = K.function([inputs],\n                            [K.reverse(layer.backward_layer(inputs), 1)])\n\n    y_merged = f_merged(X)\n    y_expected = to_list(merge_func(f_forward(X)[0], f_backward(X)[0]))\n    assert len(y_merged) == len(y_expected)\n    for x1, x2 in zip(y_merged, y_expected):\n        assert_allclose(x1, x2, atol=1e-5)\n\n    # test return_state\n    inputs = Input((timesteps, dim))\n    layer = wrappers.Bidirectional(rnn(units, return_state=True),\n                                   merge_mode=merge_mode)\n    f_merged = K.function([inputs], layer(inputs))\n    f_forward = K.function([inputs], layer.forward_layer(inputs))\n    f_backward = K.function([inputs], layer.backward_layer(inputs))\n    n_states = len(layer.layer.states)\n\n    y_merged = f_merged(X)\n    y_forward = f_forward(X)\n    y_backward = f_backward(X)\n    y_expected = to_list(merge_func(y_forward[0], y_backward[0]))\n    assert len(y_merged) == len(y_expected) + n_states * 2\n    for x1, x2 in zip(y_merged, y_expected):\n        assert_allclose(x1, x2, atol=1e-5)\n\n    # test if the state of a BiRNN is the concatenation of the underlying RNNs\n    y_merged = y_merged[-n_states * 2:]\n    y_forward = y_forward[-n_states:]\n    y_backward = y_backward[-n_states:]\n    for state_birnn, state_inner in zip(y_merged, y_forward + y_backward):\n        assert_allclose(state_birnn, state_inner, atol=1e-5)\n\n\n@pytest.mark.skipif(K.backend() == 'theano', reason='Not supported.')\n@pytest.mark.parametrize('merge_mode', ['sum', 'concat', None])\ndef test_Bidirectional_dropout(merge_mode):\n    rnn = layers.LSTM\n    samples = 2\n    dim = 5\n    timesteps = 3\n    units = 3\n    X = [np.random.rand(samples, timesteps, dim)]\n\n    inputs = Input((timesteps, dim))\n    wrapped = wrappers.Bidirectional(rnn(units, dropout=0.2, recurrent_dropout=0.2),\n                                     merge_mode=merge_mode)\n    outputs = to_list(wrapped(inputs, training=True))\n    assert all(not getattr(x, '_uses_learning_phase') for x in outputs)\n\n    inputs = Input((timesteps, dim))\n    wrapped = wrappers.Bidirectional(rnn(units, dropout=0.2, return_state=True),\n                                     merge_mode=merge_mode)\n    outputs = to_list(wrapped(inputs))\n    assert all(x._uses_learning_phase for x in outputs)\n\n    model = Model(inputs, outputs)\n    assert model.uses_learning_phase\n    y1 = to_list(model.predict(X))\n    y2 = to_list(model.predict(X))\n    for x1, x2 in zip(y1, y2):\n        assert_allclose(x1, x2, atol=1e-5)\n\n\ndef test_Bidirectional_state_reuse():\n    rnn = layers.LSTM\n    samples = 2\n    dim = 5\n    timesteps = 3\n    units = 3\n\n    input1 = Input((timesteps, dim))\n    layer = wrappers.Bidirectional(rnn(units, return_state=True,\n                                       return_sequences=True))\n    state = layer(input1)[1:]\n\n    # test passing invalid initial_state: passing a tensor\n    input2 = Input((timesteps, dim))\n    with pytest.raises(ValueError):\n        output = wrappers.Bidirectional(rnn(units))(input2, initial_state=state[0])\n\n    # test valid usage: passing a list\n    output = wrappers.Bidirectional(rnn(units))(input2, initial_state=state)\n    model = Model([input1, input2], output)\n    assert len(model.layers) == 4\n    assert isinstance(model.layers[-1].input, list)\n    inputs = [np.random.rand(samples, timesteps, dim),\n              np.random.rand(samples, timesteps, dim)]\n    outputs = model.predict(inputs)\n\n\ndef test_Bidirectional_with_constants():\n    class RNNCellWithConstants(Layer):\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = K.dot(inputs, self.input_kernel)\n            h_state = K.dot(prev_output, self.recurrent_kernel)\n            h_const = K.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = Input((5, 5))\n    c = Input((3,))\n    cell = RNNCellWithConstants(32)\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with CustomObjectScope(custom_objects):\n        layer = wrappers.Bidirectional(RNN(cell))\n    y = layer(x, constants=c)\n    model = Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 64))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    with CustomObjectScope(custom_objects):\n        layer = wrappers.Bidirectional.from_config(copy.deepcopy(config))\n    y = layer(x, constants=c)\n    model = Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # test flat list inputs\n    with CustomObjectScope(custom_objects):\n        layer = wrappers.Bidirectional.from_config(copy.deepcopy(config))\n    y = layer([x, c])\n    model = Model([x, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)\n\n\ndef test_Bidirectional_with_constants_layer_passing_initial_state():\n    class RNNCellWithConstants(Layer):\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = K.dot(inputs, self.input_kernel)\n            h_state = K.dot(prev_output, self.recurrent_kernel)\n            h_const = K.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = Input((5, 5))\n    c = Input((3,))\n    s_for = Input((32,))\n    s_bac = Input((32,))\n    cell = RNNCellWithConstants(32)\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with CustomObjectScope(custom_objects):\n        layer = wrappers.Bidirectional(RNN(cell))\n    y = layer(x, initial_state=[s_for, s_bac], constants=c)\n    model = Model([x, s_for, s_bac, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 32)),\n         np.zeros((6, 32)), np.zeros((6, 3))],\n        np.zeros((6, 64))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    s_fw_np = np.random.random((6, 32))\n    s_bk_np = np.random.random((6, 32))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, s_fw_np, s_bk_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    with CustomObjectScope(custom_objects):\n        layer = wrappers.Bidirectional.from_config(copy.deepcopy(config))\n    y = layer(x, initial_state=[s_for, s_bac], constants=c)\n    model = Model([x, s_for, s_bac, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, s_fw_np, s_bk_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # verify that state is used\n    y_np_2_different_s = model.predict([x_np, s_fw_np + 10., s_bk_np + 10., c_np])\n    with pytest.raises(AssertionError):\n        assert_allclose(y_np, y_np_2_different_s, atol=1e-4)\n\n    # test flat list inputs\n    with CustomObjectScope(custom_objects):\n        layer = wrappers.Bidirectional.from_config(copy.deepcopy(config))\n    y = layer([x, s_for, s_bac, c])\n    model = Model([x, s_for, s_bac, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, s_fw_np, s_bk_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)\n\n\ndef test_Bidirectional_trainable():\n    # test layers that need learning_phase to be set\n    x = Input(shape=(3, 2))\n    layer = wrappers.Bidirectional(layers.SimpleRNN(3))\n    _ = layer(x)\n    assert len(layer.trainable_weights) == 6\n    layer.trainable = False\n    assert len(layer.trainable_weights) == 0\n    layer.trainable = True\n    assert len(layer.trainable_weights) == 6\n\n\ndef test_Bidirectional_updates():\n    x = Input(shape=(3, 2))\n    layer = wrappers.Bidirectional(layers.SimpleRNN(3))\n    assert len(layer.updates) == 0\n    assert len(layer.get_updates_for(None)) == 0\n    assert len(layer.get_updates_for(x)) == 0\n    layer.forward_layer.add_update(0, inputs=x)\n    layer.forward_layer.add_update(1, inputs=None)\n    layer.backward_layer.add_update(0, inputs=x)\n    layer.backward_layer.add_update(1, inputs=None)\n    assert len(layer.updates) == 4\n    assert len(layer.get_updates_for(None)) == 2\n    assert len(layer.get_updates_for(x)) == 2\n\n\ndef test_Bidirectional_losses():\n    x = Input(shape=(3, 2))\n    layer = wrappers.Bidirectional(\n        layers.SimpleRNN(3, kernel_regularizer='l1', bias_regularizer='l1'))\n    _ = layer(x)\n    assert len(layer.losses) == 4\n    assert len(layer.get_losses_for(None)) == 4\n    assert len(layer.get_losses_for(x)) == 0\n    layer.forward_layer.add_loss(0, inputs=x)\n    layer.forward_layer.add_loss(1, inputs=None)\n    layer.backward_layer.add_loss(0, inputs=x)\n    layer.backward_layer.add_loss(1, inputs=None)\n    assert len(layer.losses) == 8\n    assert len(layer.get_losses_for(None)) == 6\n    assert len(layer.get_losses_for(x)) == 2\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/legacy/conftest.py,0,"b'import warnings\r\nimport pytest\r\n\r\n\r\n@pytest.fixture(autouse=True)\r\ndef clear_session_after_test():\r\n    """"""This wrapper runs for all the tests in the legacy directory (recursively).\r\n    """"""\r\n    with warnings.catch_warnings():\r\n        warnings.filterwarnings(\'ignore\', message=r\'(.+) Keras 2 \',\r\n                                category=UserWarning)\r\n        yield\r\n'"
tests/keras/legacy/interface_test.py,0,"b'import pytest\nimport json\nimport keras\nimport keras.backend as K\nimport numpy as np\nimport os\n\n\ndef test_dense_legacy_interface():\n    old_layer = keras.layers.Dense(input_dim=3, output_dim=2, name=\'d\')\n    new_layer = keras.layers.Dense(2, input_shape=(3,), name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Dense(2, bias=False, init=\'normal\',\n                                   W_regularizer=\'l1\',\n                                   W_constraint=\'maxnorm\', name=\'d\')\n    new_layer = keras.layers.Dense(2, use_bias=False,\n                                   kernel_initializer=\'normal\',\n                                   kernel_regularizer=\'l1\',\n                                   kernel_constraint=\'max_norm\', name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Dense(2, bias=True,\n                                   b_regularizer=\'l1\',\n                                   b_constraint=\'maxnorm\', name=\'d\')\n    new_layer = keras.layers.Dense(2, use_bias=True,\n                                   bias_regularizer=\'l1\',\n                                   bias_constraint=\'max_norm\', name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_dropout_legacy_interface():\n    old_layer = keras.layers.Dropout(p=3, name=\'drop\')\n    new_layer1 = keras.layers.Dropout(rate=3, name=\'drop\')\n    new_layer2 = keras.layers.Dropout(3, name=\'drop\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer1.get_config())\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer2.get_config())\n\n\ndef test_embedding_legacy_interface():\n    old_layer = keras.layers.Embedding(4, 2, name=\'d\')\n    new_layer = keras.layers.Embedding(output_dim=2, input_dim=4, name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name=\'d\',\n                                       init=\'normal\',\n                                       W_regularizer=\'l1\',\n                                       W_constraint=\'maxnorm\')\n    new_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name=\'d\',\n                                       embeddings_initializer=\'normal\',\n                                       embeddings_regularizer=\'l1\',\n                                       embeddings_constraint=\'max_norm\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Embedding(1, 1, dropout=0.0, name=\'d\')\n    new_layer = keras.layers.Embedding(1, 1, name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_maxpooling1d_legacy_interface():\n    old_layer = keras.layers.MaxPool1D(pool_length=2,\n                                       border_mode=\'valid\',\n                                       name=\'maxpool1d\')\n    new_layer = keras.layers.MaxPool1D(pool_size=2,\n                                       padding=\'valid\',\n                                       name=\'maxpool1d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPool1D(2, padding=\'valid\', name=\'maxpool1d\')\n    new_layer = keras.layers.MaxPool1D(pool_size=2,\n                                       padding=\'valid\',\n                                       name=\'maxpool1d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_avgpooling1d_legacy_interface():\n    old_layer = keras.layers.AvgPool1D(pool_length=2,\n                                       border_mode=\'valid\',\n                                       name=\'d\')\n    new_layer = keras.layers.AvgPool1D(pool_size=2, padding=\'valid\', name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AvgPool1D(2, padding=\'valid\', name=\'d\')\n    new_layer = keras.layers.AvgPool1D(pool_size=2, padding=\'valid\', name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_prelu_legacy_interface():\n    old_layer = keras.layers.PReLU(init=\'zero\', name=\'p\')\n    new_layer = keras.layers.PReLU(\'zero\', name=\'p\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_gaussiannoise_legacy_interface():\n    old_layer = keras.layers.GaussianNoise(sigma=0.5, name=\'gn\')\n    new_layer = keras.layers.GaussianNoise(stddev=0.5, name=\'gn\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_lstm_legacy_interface():\n    old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name=\'d\')\n    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name=\'d\',\n                                  consume_less=\'mem\')\n    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name=\'d\', implementation=1)\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.LSTM(input_dim=5, input_length=3,\n                                  output_dim=2, name=\'d\', consume_less=\'mem\')\n    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name=\'d\', implementation=1)\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.LSTM(input_dim=5,\n                                  output_dim=2, name=\'d\', consume_less=\'mem\')\n    new_layer = keras.layers.LSTM(2, input_shape=[None, 5], name=\'d\',\n                                  implementation=1)\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name=\'d\',\n                                  consume_less=\'gpu\')\n    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name=\'d\', implementation=2)\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.LSTM(2, init=\'normal\',\n                                  inner_init=\'glorot_uniform\',\n                                  forget_bias_init=\'one\',\n                                  inner_activation=\'hard_sigmoid\',\n                                  W_regularizer=\'l1\',\n                                  U_regularizer=\'l1\',\n                                  b_regularizer=\'l1\',\n                                  dropout_W=0.1,\n                                  dropout_U=0.1,\n                                  name=\'LSTM\')\n\n    new_layer = keras.layers.LSTM(2, kernel_initializer=\'normal\',\n                                  recurrent_initializer=\'glorot_uniform\',\n                                  unit_forget_bias=True,\n                                  recurrent_activation=\'hard_sigmoid\',\n                                  kernel_regularizer=\'l1\',\n                                  recurrent_regularizer=\'l1\',\n                                  bias_regularizer=\'l1\',\n                                  dropout=0.1,\n                                  recurrent_dropout=0.1,\n                                  name=\'LSTM\')\n\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.LSTM(2, init=\'normal\',\n                                  inner_init=\'glorot_uniform\',\n                                  forget_bias_init=\'zero\',\n                                  inner_activation=\'hard_sigmoid\',\n                                  W_regularizer=\'l1\',\n                                  U_regularizer=\'l1\',\n                                  b_regularizer=\'l1\',\n                                  dropout_W=0.1,\n                                  dropout_U=0.1,\n                                  name=\'LSTM\')\n\n    new_layer = keras.layers.LSTM(2, kernel_initializer=\'normal\',\n                                  recurrent_initializer=\'glorot_uniform\',\n                                  unit_forget_bias=True,\n                                  recurrent_activation=\'hard_sigmoid\',\n                                  kernel_regularizer=\'l1\',\n                                  recurrent_regularizer=\'l1\',\n                                  bias_regularizer=\'l1\',\n                                  dropout=0.1,\n                                  recurrent_dropout=0.1,\n                                  name=\'LSTM\')\n\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_simplernn_legacy_interface():\n    old_layer = keras.layers.SimpleRNN(input_shape=[3, 5], output_dim=2, name=\'d\')\n    new_layer = keras.layers.SimpleRNN(2, input_shape=[3, 5], name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.SimpleRNN(2, init=\'normal\',\n                                       inner_init=\'glorot_uniform\',\n                                       W_regularizer=\'l1\',\n                                       U_regularizer=\'l1\',\n                                       b_regularizer=\'l1\',\n                                       dropout_W=0.1,\n                                       dropout_U=0.1,\n                                       name=\'SimpleRNN\')\n    new_layer = keras.layers.SimpleRNN(2, kernel_initializer=\'normal\',\n                                       recurrent_initializer=\'glorot_uniform\',\n                                       kernel_regularizer=\'l1\',\n                                       recurrent_regularizer=\'l1\',\n                                       bias_regularizer=\'l1\',\n                                       dropout=0.1,\n                                       recurrent_dropout=0.1,\n                                       name=\'SimpleRNN\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_gru_legacy_interface():\n    old_layer = keras.layers.GRU(input_shape=[3, 5], output_dim=2, name=\'d\')\n    new_layer = keras.layers.GRU(2, input_shape=[3, 5], name=\'d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GRU(2, init=\'normal\',\n                                 inner_init=\'glorot_uniform\',\n                                 inner_activation=\'hard_sigmoid\',\n                                 W_regularizer=\'l1\',\n                                 U_regularizer=\'l1\',\n                                 b_regularizer=\'l1\',\n                                 dropout_W=0.1,\n                                 dropout_U=0.1,\n                                 name=\'GRU\')\n    new_layer = keras.layers.GRU(2, kernel_initializer=\'normal\',\n                                 recurrent_initializer=\'glorot_uniform\',\n                                 recurrent_activation=\'hard_sigmoid\',\n                                 kernel_regularizer=\'l1\',\n                                 recurrent_regularizer=\'l1\',\n                                 bias_regularizer=\'l1\',\n                                 dropout=0.1,\n                                 recurrent_dropout=0.1,\n                                 name=\'GRU\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_gaussiandropout_legacy_interface():\n    old_layer = keras.layers.GaussianDropout(p=0.6, name=\'drop\')\n    new_layer1 = keras.layers.GaussianDropout(rate=0.6, name=\'drop\')\n    new_layer2 = keras.layers.GaussianDropout(0.6, name=\'drop\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer1.get_config())\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer2.get_config())\n\n\ndef test_maxpooling2d_legacy_interface():\n    old_layer = keras.layers.MaxPooling2D(\n        pool_size=(2, 2), border_mode=\'valid\', name=\'maxpool2d\')\n    new_layer = keras.layers.MaxPool2D(\n        pool_size=2, padding=\'valid\', name=\'maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling2D((2, 2), 2, \'valid\', name=\'maxpool2d\')\n    new_layer = keras.layers.MaxPool2D(\n        pool_size=2, strides=2, padding=\'valid\', name=\'maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling2D(\n        (2, 2), padding=\'valid\', dim_ordering=\'tf\', name=\'maxpool2d\')\n    new_layer = keras.layers.MaxPool2D(\n        pool_size=2, padding=\'valid\', data_format=\'channels_last\', name=\'maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling2D(\n        (2, 2), padding=\'valid\', dim_ordering=\'th\', name=\'maxpool2d\')\n    new_layer = keras.layers.MaxPool2D(\n        pool_size=2, padding=\'valid\', data_format=\'channels_first\',\n        name=\'maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling2D(\n        (2, 2), padding=\'valid\', dim_ordering=\'default\', name=\'maxpool2d\')\n    new_layer = keras.layers.MaxPool2D(\n        pool_size=2, padding=\'valid\', name=\'maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_avgpooling2d_legacy_interface():\n    old_layer = keras.layers.AveragePooling2D(\n        pool_size=(2, 2), border_mode=\'valid\', name=\'avgpooling2d\')\n    new_layer = keras.layers.AvgPool2D(\n        pool_size=(2, 2), padding=\'valid\', name=\'avgpooling2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling2D(\n        (2, 2), (2, 2), \'valid\', name=\'avgpooling2d\')\n    new_layer = keras.layers.AvgPool2D(\n        pool_size=(2, 2), strides=(2, 2), padding=\'valid\', name=\'avgpooling2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling2D(\n        (2, 2), padding=\'valid\', dim_ordering=\'tf\', name=\'avgpooling2d\')\n    new_layer = keras.layers.AvgPool2D(\n        pool_size=2, padding=\'valid\', data_format=\'channels_last\',\n        name=\'avgpooling2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling2D(\n        (2, 2), padding=\'valid\', dim_ordering=\'th\', name=\'avgpooling2d\')\n    new_layer = keras.layers.AvgPool2D(\n        pool_size=2, padding=\'valid\', data_format=\'channels_first\',\n        name=\'avgpooling2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling2D(\n        (2, 2), padding=\'valid\', dim_ordering=\'default\', name=\'avgpooling2d\')\n    new_layer = keras.layers.AvgPool2D(\n        pool_size=2, padding=\'valid\', name=\'avgpooling2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_maxpooling3d_legacy_interface():\n    old_layer = keras.layers.MaxPooling3D(\n        pool_size=(2, 2, 2), border_mode=\'valid\', name=\'maxpool3d\')\n    new_layer = keras.layers.MaxPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', name=\'maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling3D(\n        (2, 2, 2), (2, 2, 2), \'valid\', name=\'maxpool3d\')\n    new_layer = keras.layers.MaxPool3D(\n        pool_size=(2, 2, 2), strides=(2, 2, 2), padding=\'valid\', name=\'maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling3D(\n        (2, 2, 2), padding=\'valid\', dim_ordering=\'tf\', name=\'maxpool3d\')\n    new_layer = keras.layers.MaxPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', data_format=\'channels_last\',\n        name=\'maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling3D(\n        (2, 2, 2), padding=\'valid\', dim_ordering=\'th\', name=\'maxpool3d\')\n    new_layer = keras.layers.MaxPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', data_format=\'channels_first\',\n        name=\'maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.MaxPooling3D(\n        (2, 2, 2), padding=\'valid\', dim_ordering=\'default\', name=\'maxpool3d\')\n    new_layer = keras.layers.MaxPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', name=\'maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_avgpooling3d_legacy_interface():\n    old_layer = keras.layers.AveragePooling3D(\n        pool_size=(2, 2, 2), border_mode=\'valid\', name=\'avgpooling3d\')\n    new_layer = keras.layers.AvgPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', name=\'avgpooling3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling3D(\n        (2, 2, 2), (2, 2, 2), \'valid\', name=\'avgpooling3d\')\n    new_layer = keras.layers.AvgPool3D(\n        pool_size=(2, 2, 2), strides=(2, 2, 2), padding=\'valid\',\n        name=\'avgpooling3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling3D(\n        (2, 2, 2), padding=\'valid\', dim_ordering=\'tf\', name=\'avgpooling3d\')\n    new_layer = keras.layers.AvgPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', data_format=\'channels_last\',\n        name=\'avgpooling3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling3D(\n        (2, 2, 2), padding=\'valid\', dim_ordering=\'th\', name=\'avgpooling3d\')\n    new_layer = keras.layers.AvgPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', data_format=\'channels_first\',\n        name=\'avgpooling3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.AveragePooling3D(\n        (2, 2, 2), padding=\'valid\', dim_ordering=\'default\', name=\'avgpooling3d\')\n    new_layer = keras.layers.AvgPool3D(\n        pool_size=(2, 2, 2), padding=\'valid\', name=\'avgpooling3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_global_maxpooling2d_legacy_interface():\n    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering=\'tf\',\n                                                name=\'global_maxpool2d\')\n    new_layer = keras.layers.GlobalMaxPool2D(data_format=\'channels_last\',\n                                             name=\'global_maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering=\'th\',\n                                                name=\'global_maxpool2d\')\n    new_layer = keras.layers.GlobalMaxPool2D(data_format=\'channels_first\',\n                                             name=\'global_maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering=\'default\',\n                                                name=\'global_maxpool2d\')\n    new_layer = keras.layers.GlobalMaxPool2D(name=\'global_maxpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_global_avgpooling2d_legacy_interface():\n    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering=\'tf\',\n                                                    name=\'global_avgpool2d\')\n    new_layer = keras.layers.GlobalAvgPool2D(data_format=\'channels_last\',\n                                             name=\'global_avgpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering=\'th\',\n                                                    name=\'global_avgpool2d\')\n    new_layer = keras.layers.GlobalAvgPool2D(data_format=\'channels_first\',\n                                             name=\'global_avgpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering=\'default\',\n                                                    name=\'global_avgpool2d\')\n    new_layer = keras.layers.GlobalAvgPool2D(name=\'global_avgpool2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_global_maxpooling3d_legacy_interface():\n    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering=\'tf\',\n                                                name=\'global_maxpool3d\')\n    new_layer = keras.layers.GlobalMaxPool3D(data_format=\'channels_last\',\n                                             name=\'global_maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering=\'th\',\n                                                name=\'global_maxpool3d\')\n    new_layer = keras.layers.GlobalMaxPool3D(data_format=\'channels_first\',\n                                             name=\'global_maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering=\'default\',\n                                                name=\'global_maxpool3d\')\n    new_layer = keras.layers.GlobalMaxPool3D(name=\'global_maxpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_global_avgpooling3d_legacy_interface():\n    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering=\'tf\',\n                                                    name=\'global_avgpool3d\')\n    new_layer = keras.layers.GlobalAvgPool3D(data_format=\'channels_last\',\n                                             name=\'global_avgpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering=\'th\',\n                                                    name=\'global_avgpool3d\')\n    new_layer = keras.layers.GlobalAvgPool3D(data_format=\'channels_first\',\n                                             name=\'global_avgpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering=\'default\',\n                                                    name=\'global_avgpool3d\')\n    new_layer = keras.layers.GlobalAvgPool3D(name=\'global_avgpool3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_upsampling1d_legacy_interface():\n    old_layer = keras.layers.UpSampling1D(length=3, name=\'us1d\')\n    new_layer_1 = keras.layers.UpSampling1D(size=3, name=\'us1d\')\n    new_layer_2 = keras.layers.UpSampling1D(3, name=\'us1d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n\n\ndef test_upsampling2d_legacy_interface():\n    old_layer = keras.layers.UpSampling2D((2, 2), dim_ordering=\'tf\', name=\'us2d\')\n    new_layer = keras.layers.UpSampling2D((2, 2), data_format=\'channels_last\',\n                                          name=\'us2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_upsampling3d_legacy_interface():\n    old_layer = keras.layers.UpSampling3D((2, 2, 2),\n                                          dim_ordering=\'tf\',\n                                          name=\'us3d\')\n    new_layer = keras.layers.UpSampling3D((2, 2, 2),\n                                          data_format=\'channels_last\',\n                                          name=\'us3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_conv2d_legacy_interface():\n    old_layer = keras.layers.Convolution2D(5, 3, 3, name=\'conv\')\n    new_layer = keras.layers.Conv2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution2D(5, 3, nb_col=3, name=\'conv\')\n    new_layer = keras.layers.Conv2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution2D(5, nb_row=3, nb_col=3, name=\'conv\')\n    new_layer = keras.layers.Conv2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution2D(5, 3, 3,\n                                           init=\'normal\',\n                                           subsample=(2, 2),\n                                           border_mode=\'valid\',\n                                           dim_ordering=\'th\',\n                                           W_regularizer=\'l1\',\n                                           b_regularizer=\'l2\',\n                                           W_constraint=\'maxnorm\',\n                                           b_constraint=\'unitnorm\',\n                                           name=\'conv\')\n    new_layer = keras.layers.Conv2D(5, (3, 3),\n                                    kernel_initializer=\'normal\',\n                                    strides=(2, 2),\n                                    padding=\'valid\',\n                                    kernel_regularizer=\'l1\',\n                                    bias_regularizer=\'l2\',\n                                    kernel_constraint=\'max_norm\',\n                                    bias_constraint=\'unit_norm\',\n                                    data_format=\'channels_first\',\n                                    name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_deconv2d_legacy_interface():\n    old_layer = keras.layers.Deconvolution2D(5, 3, 3, (6, 7, 5), name=\'deconv\')\n    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name=\'deconv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Deconvolution2D(5, 3, 3, output_shape=(6, 7, 5),\n                                             name=\'deconv\')\n    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name=\'deconv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Deconvolution2D(5, 3, nb_col=3, output_shape=(6, 7, 5),\n                                             name=\'deconv\')\n    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name=\'deconv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Deconvolution2D(5, nb_row=3, nb_col=3,\n                                             output_shape=(6, 7, 5), name=\'deconv\')\n    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name=\'deconv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Deconvolution2D(5, 3, 3,\n                                             output_shape=(6, 7, 5),\n                                             init=\'normal\',\n                                             subsample=(2, 2),\n                                             border_mode=\'valid\',\n                                             dim_ordering=\'th\',\n                                             W_regularizer=\'l1\',\n                                             b_regularizer=\'l2\',\n                                             W_constraint=\'maxnorm\',\n                                             b_constraint=\'unitnorm\',\n                                             name=\'conv\')\n    new_layer = keras.layers.Conv2DTranspose(\n        5, (3, 3),\n        kernel_initializer=\'normal\',\n        strides=(2, 2),\n        padding=\'valid\',\n        kernel_regularizer=\'l1\',\n        bias_regularizer=\'l2\',\n        kernel_constraint=\'max_norm\',\n        bias_constraint=\'unit_norm\',\n        data_format=\'channels_first\',\n        name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_conv1d_legacy_interface():\n    old_layer = keras.layers.Convolution1D(5,\n                                           filter_length=3,\n                                           input_dim=3,\n                                           input_length=4,\n                                           name=\'conv\')\n    new_layer = keras.layers.Conv1D(5, 3, name=\'conv\', input_shape=(4, 3))\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution1D(5, 3,\n                                           init=\'normal\',\n                                           subsample_length=2,\n                                           border_mode=\'valid\',\n                                           W_regularizer=\'l1\',\n                                           b_regularizer=\'l2\',\n                                           W_constraint=\'maxnorm\',\n                                           b_constraint=\'unitnorm\',\n                                           name=\'conv\')\n    new_layer = keras.layers.Conv1D(5, 3,\n                                    kernel_initializer=\'normal\',\n                                    strides=2,\n                                    padding=\'valid\',\n                                    kernel_regularizer=\'l1\',\n                                    bias_regularizer=\'l2\',\n                                    kernel_constraint=\'max_norm\',\n                                    bias_constraint=\'unit_norm\',\n                                    name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_separable_conv2d_legacy_interface():\n    old_layer = keras.layers.SeparableConv2D(5, 3, 3, name=\'conv\')\n    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.SeparableConv2D(5, 3, nb_col=3, name=\'conv\')\n    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.SeparableConv2D(5, nb_row=3, nb_col=3, name=\'conv\')\n    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.SeparableConv2D(5, 3, 3,\n                                             init=\'normal\',\n                                             subsample=(2, 2),\n                                             border_mode=\'valid\',\n                                             dim_ordering=\'th\',\n                                             depthwise_regularizer=\'l1\',\n                                             b_regularizer=\'l2\',\n                                             depthwise_constraint=\'maxnorm\',\n                                             b_constraint=\'unitnorm\',\n                                             name=\'conv\')\n    new_layer = keras.layers.SeparableConv2D(5, (3, 3),\n                                             depthwise_initializer=\'normal\',\n                                             pointwise_initializer=\'normal\',\n                                             strides=(2, 2),\n                                             padding=\'valid\',\n                                             depthwise_regularizer=\'l1\',\n                                             bias_regularizer=\'l2\',\n                                             depthwise_constraint=\'max_norm\',\n                                             bias_constraint=\'unit_norm\',\n                                             data_format=\'channels_first\',\n                                             name=\'conv\')\n    old_config = json.dumps(old_layer.get_config())\n    new_config = json.dumps(new_layer.get_config())\n    assert old_config == new_config\n\n\ndef test_conv3d_legacy_interface():\n    old_layer = keras.layers.Convolution3D(5, 3, 3, 4, name=\'conv\')\n    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution3D(5, 3, 3, kernel_dim3=4, name=\'conv\')\n    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution3D(5, 3,\n                                           kernel_dim2=3,\n                                           kernel_dim3=4,\n                                           name=\'conv\')\n    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution3D(5,\n                                           kernel_dim1=3,\n                                           kernel_dim2=3,\n                                           kernel_dim3=4,\n                                           name=\'conv\')\n    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.Convolution3D(5, 3, 3, 4,\n                                           init=\'normal\',\n                                           subsample=(2, 2, 2),\n                                           border_mode=\'valid\',\n                                           dim_ordering=\'th\',\n                                           W_regularizer=\'l1\',\n                                           b_regularizer=\'l2\',\n                                           W_constraint=\'maxnorm\',\n                                           b_constraint=\'unitnorm\',\n                                           name=\'conv\')\n    new_layer = keras.layers.Conv3D(5, (3, 3, 4),\n                                    kernel_initializer=\'normal\',\n                                    strides=(2, 2, 2),\n                                    padding=\'valid\',\n                                    kernel_regularizer=\'l1\',\n                                    bias_regularizer=\'l2\',\n                                    kernel_constraint=\'max_norm\',\n                                    bias_constraint=\'unit_norm\',\n                                    data_format=\'channels_first\',\n                                    name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_convlstm2d_legacy_interface():\n    old_layer = keras.layers.ConvLSTM2D(5, 3, 3, name=\'conv\')\n    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.ConvLSTM2D(5, 3, nb_col=3, name=\'conv\')\n    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.ConvLSTM2D(5, nb_row=3, nb_col=3, name=\'conv\')\n    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.ConvLSTM2D(5, 3, 3,\n                                        init=\'normal\',\n                                        inner_init=\'uniform\',\n                                        forget_bias_init=\'one\',\n                                        inner_activation=\'relu\',\n                                        subsample=(2, 2),\n                                        border_mode=\'valid\',\n                                        dim_ordering=\'th\',\n                                        W_regularizer=\'l1\',\n                                        U_regularizer=\'l2\',\n                                        b_regularizer=\'l2\',\n                                        dropout_W=0.2,\n                                        dropout_U=0.1,\n                                        name=\'conv\')\n    new_layer = keras.layers.ConvLSTM2D(5, (3, 3),\n                                        kernel_initializer=\'normal\',\n                                        recurrent_initializer=\'uniform\',\n                                        unit_forget_bias=True,\n                                        recurrent_activation=\'relu\',\n                                        strides=(2, 2),\n                                        padding=\'valid\',\n                                        kernel_regularizer=\'l1\',\n                                        recurrent_regularizer=\'l2\',\n                                        bias_regularizer=\'l2\',\n                                        data_format=\'channels_first\',\n                                        dropout=0.2,\n                                        recurrent_dropout=0.1,\n                                        name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_batchnorm_legacy_interface():\n    old_layer = keras.layers.BatchNormalization(mode=0, name=\'bn\')\n    new_layer = keras.layers.BatchNormalization(name=\'bn\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n    old_layer = keras.layers.BatchNormalization(mode=0,\n                                                beta_init=\'one\',\n                                                gamma_init=\'uniform\',\n                                                name=\'bn\')\n    new_layer = keras.layers.BatchNormalization(beta_initializer=\'ones\',\n                                                gamma_initializer=\'uniform\',\n                                                name=\'bn\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_atrousconv1d_legacy_interface():\n    old_layer = keras.layers.AtrousConvolution1D(5, 3,\n                                                 init=\'normal\',\n                                                 subsample_length=2,\n                                                 border_mode=\'valid\',\n                                                 W_regularizer=\'l1\',\n                                                 b_regularizer=\'l2\',\n                                                 W_constraint=\'maxnorm\',\n                                                 b_constraint=\'unitnorm\',\n                                                 atrous_rate=2,\n                                                 name=\'conv\')\n    new_layer = keras.layers.Conv1D(5, 3,\n                                    kernel_initializer=\'normal\',\n                                    strides=2,\n                                    padding=\'valid\',\n                                    kernel_regularizer=\'l1\',\n                                    bias_regularizer=\'l2\',\n                                    kernel_constraint=\'max_norm\',\n                                    bias_constraint=\'unit_norm\',\n                                    dilation_rate=2,\n                                    name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_atrousconv2d_legacy_interface():\n    old_layer = keras.layers.AtrousConvolution2D(\n        5, 3, 3,\n        atrous_rate=(2, 2),\n        init=\'normal\',\n        subsample=(2, 2),\n        border_mode=\'valid\',\n        dim_ordering=\'th\',\n        W_regularizer=\'l1\',\n        b_regularizer=\'l2\',\n        W_constraint=\'maxnorm\',\n        b_constraint=\'unitnorm\',\n        name=\'conv\')\n    new_layer = keras.layers.Conv2D(5, (3, 3),\n                                    kernel_initializer=\'normal\',\n                                    strides=(2, 2),\n                                    padding=\'valid\',\n                                    kernel_regularizer=\'l1\',\n                                    bias_regularizer=\'l2\',\n                                    kernel_constraint=\'max_norm\',\n                                    bias_constraint=\'unit_norm\',\n                                    data_format=\'channels_first\',\n                                    dilation_rate=(2, 2),\n                                    name=\'conv\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_zeropadding2d_legacy_interface():\n    old_layer = keras.layers.ZeroPadding2D(padding={\'right_pad\': 4,\n                                                    \'bottom_pad\': 2,\n                                                    \'top_pad\': 1,\n                                                    \'left_pad\': 3},\n                                           dim_ordering=\'tf\',\n                                           name=\'zp2d\')\n    new_layer = keras.layers.ZeroPadding2D(((1, 2), (3, 4)),\n                                           data_format=\'channels_last\',\n                                           name=\'zp2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_zeropadding3d_legacy_interface():\n    old_layer = keras.layers.ZeroPadding3D((2, 2, 2),\n                                           dim_ordering=\'tf\',\n                                           name=\'zp3d\')\n    new_layer = keras.layers.ZeroPadding3D((2, 2, 2),\n                                           data_format=\'channels_last\',\n                                           name=\'zp3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_cropping2d_legacy_interface():\n    old_layer = keras.layers.Cropping2D(dim_ordering=\'tf\', name=\'c2d\')\n    new_layer = keras.layers.Cropping2D(data_format=\'channels_last\', name=\'c2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef test_cropping3d_legacy_interface():\n    old_layer = keras.layers.Cropping3D(dim_ordering=\'tf\', name=\'c3d\')\n    new_layer = keras.layers.Cropping3D(data_format=\'channels_last\', name=\'c3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n\n\ndef DISABLED_test_generator_methods_interface():\n    """"""This test may cause Travis to hang.""""""\n\n    def train_generator():\n        x = np.random.randn(2, 2)\n        y = np.random.randint(0, 2, size=[2, 1])\n        while True:\n            yield (x, y)\n\n    def val_generator():\n        x = np.random.randn(2, 2)\n        y = np.random.randint(0, 2, size=[2, 1])\n        while True:\n            yield (x, y)\n\n    def pred_generator():\n        x = np.random.randn(1, 2)\n        while True:\n            yield x\n\n    x = keras.layers.Input(shape=(2, ))\n    y = keras.layers.Dense(2)(x)\n\n    model = keras.models.Model(inputs=x, outputs=y)\n    model.compile(optimizer=\'rmsprop\',\n                  loss=\'sparse_categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n    model.fit_generator(generator=train_generator(),\n                        samples_per_epoch=1,\n                        validation_data=val_generator(),\n                        nb_val_samples=1,\n                        nb_worker=1, pickle_safe=True, max_q_size=3)\n\n    model.evaluate_generator(generator=train_generator(),\n                             val_samples=2,\n                             nb_worker=1, pickle_safe=False, max_q_size=3)\n    model.predict_generator(generator=pred_generator(),\n                            val_samples=2,\n                            nb_worker=1, pickle_safe=False, max_q_size=3)\n\n\ndef test_spatialdropout1d_legacy_interface():\n    old_layer = keras.layers.SpatialDropout1D(p=0.6, name=\'sd1d\')\n    new_layer_1 = keras.layers.SpatialDropout1D(rate=0.6, name=\'sd1d\')\n    new_layer_2 = keras.layers.SpatialDropout1D(0.6, name=\'sd1d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n\n\ndef test_spatialdropout2d_legacy_interface():\n    old_layer = keras.layers.SpatialDropout2D(p=0.5,\n                                              dim_ordering=\'tf\',\n                                              name=\'sd2d\')\n    new_layer_1 = keras.layers.SpatialDropout2D(rate=0.5,\n                                                data_format=\'channels_last\',\n                                                name=\'sd2d\')\n    new_layer_2 = keras.layers.SpatialDropout2D(0.5,\n                                                data_format=\'channels_last\',\n                                                name=\'sd2d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n\n\ndef test_spatialdropout3d_legacy_interface():\n    old_layer = keras.layers.SpatialDropout3D(p=0.5,\n                                              dim_ordering=\'tf\',\n                                              name=\'sd3d\')\n    new_layer_1 = keras.layers.SpatialDropout3D(rate=0.5,\n                                                data_format=\'channels_last\',\n                                                name=\'sd3d\')\n    new_layer_2 = keras.layers.SpatialDropout3D(0.5,\n                                                data_format=\'channels_last\',\n                                                name=\'sd3d\')\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/legacy/layers_test.py,0,"b""import pytest\n\nfrom keras.utils.test_utils import layer_test\nfrom keras.legacy import layers as legacy_layers\nfrom keras import regularizers\nfrom keras import constraints\n\n\ndef test_highway():\n    layer_test(legacy_layers.Highway,\n               kwargs={},\n               input_shape=(3, 2))\n\n    layer_test(legacy_layers.Highway,\n               kwargs={'W_regularizer': regularizers.l2(0.01),\n                       'b_regularizer': regularizers.l1(0.01),\n                       'activity_regularizer': regularizers.l2(0.01),\n                       'W_constraint': constraints.MaxNorm(1),\n                       'b_constraint': constraints.MaxNorm(1)},\n               input_shape=(3, 2))\n\n\ndef test_maxout_dense():\n    layer_test(legacy_layers.MaxoutDense,\n               kwargs={'output_dim': 3},\n               input_shape=(3, 2))\n\n    layer_test(legacy_layers.MaxoutDense,\n               kwargs={'output_dim': 3,\n                       'W_regularizer': regularizers.l2(0.01),\n                       'b_regularizer': regularizers.l1(0.01),\n                       'activity_regularizer': regularizers.l2(0.01),\n                       'W_constraint': constraints.MaxNorm(1),\n                       'b_constraint': constraints.MaxNorm(1)},\n               input_shape=(3, 2))\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/utils/conv_utils_test.py,0,"b""import pytest\nimport numpy as np\nfrom keras.utils import conv_utils\nfrom keras import backend as K\n\n\ndef test_normalize_tuple():\n    assert conv_utils.normalize_tuple(5, 2, 'kernel_size') == (5, 5)\n    assert conv_utils.normalize_tuple([7, 9], 2, 'kernel_size') == (7, 9)\n\n    with pytest.raises(ValueError):\n        conv_utils.normalize_tuple(None, 2, 'kernel_size')\n    with pytest.raises(ValueError):\n        conv_utils.normalize_tuple([2, 3, 4], 2, 'kernel_size')\n    with pytest.raises(ValueError):\n        conv_utils.normalize_tuple(['str', 'impossible'], 2, 'kernel_size')\n\n\ndef test_invalid_data_format():\n    with pytest.raises(ValueError):\n        K.normalize_data_format('channels_middle')\n\n\ndef test_invalid_padding():\n    with pytest.raises(ValueError):\n        conv_utils.normalize_padding('diagonal')\n\n\ndef test_invalid_convert_kernel():\n    with pytest.raises(ValueError):\n        conv_utils.convert_kernel(np.zeros((10, 20)))\n\n\ndef test_conv_output_length():\n    assert conv_utils.conv_output_length(None, 7, 'same', 1) is None\n    assert conv_utils.conv_output_length(224, 7, 'same', 1) == 224\n    assert conv_utils.conv_output_length(224, 7, 'same', 2) == 112\n    assert conv_utils.conv_output_length(32, 5, 'valid', 1) == 28\n    assert conv_utils.conv_output_length(32, 5, 'valid', 2) == 14\n    assert conv_utils.conv_output_length(32, 5, 'causal', 1) == 32\n    assert conv_utils.conv_output_length(32, 5, 'causal', 2) == 16\n    assert conv_utils.conv_output_length(32, 5, 'full', 1) == 36\n    assert conv_utils.conv_output_length(32, 5, 'full', 2) == 18\n\n    with pytest.raises(AssertionError):\n        conv_utils.conv_output_length(32, 5, 'diagonal', 2)\n\n\ndef test_conv_input_length():\n    assert conv_utils.conv_input_length(None, 7, 'same', 1) is None\n    assert conv_utils.conv_input_length(112, 7, 'same', 1) == 112\n    assert conv_utils.conv_input_length(112, 7, 'same', 2) == 223\n    assert conv_utils.conv_input_length(28, 5, 'valid', 1) == 32\n    assert conv_utils.conv_input_length(14, 5, 'valid', 2) == 31\n    assert conv_utils.conv_input_length(36, 5, 'full', 1) == 32\n    assert conv_utils.conv_input_length(18, 5, 'full', 2) == 31\n\n    with pytest.raises(AssertionError):\n        conv_utils.conv_output_length(18, 5, 'diagonal', 2)\n\n\ndef test_deconv_length():\n    assert conv_utils.deconv_length(None, 1, 7, 'same', None) is None\n    assert conv_utils.deconv_length(224, 1, 7, 'same', None) == 224\n    assert conv_utils.deconv_length(224, 2, 7, 'same', None) == 448\n    assert conv_utils.deconv_length(32, 1, 5, 'valid', None) == 36\n    assert conv_utils.deconv_length(32, 2, 5, 'valid', None) == 67\n    assert conv_utils.deconv_length(32, 1, 5, 'full', None) == 28\n    assert conv_utils.deconv_length(32, 2, 5, 'full', None) == 59\n    assert conv_utils.deconv_length(224, 1, 7, 'same', 0) == 224\n    assert conv_utils.deconv_length(224, 2, 7, 'same', 0) == 447\n    assert conv_utils.deconv_length(224, 2, 7, 'same', 1) == 448\n    assert conv_utils.deconv_length(32, 1, 5, 'valid', 0) == 36\n    assert conv_utils.deconv_length(32, 2, 5, 'valid', 0) == 67\n    assert conv_utils.deconv_length(32, 2, 5, 'valid', 1) == 68\n    assert conv_utils.deconv_length(6, 1, 3, 'full', 0) == 4\n    assert conv_utils.deconv_length(6, 2, 3, 'full', 1) == 10\n    assert conv_utils.deconv_length(6, 2, 3, 'full', 2) == 11\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/utils/data_utils_test.py,0,"b'""""""Tests for functions in data_utils.py.\n""""""\nimport os\nimport time\nimport sys\nimport tarfile\nimport threading\nimport signal\nimport shutil\nimport zipfile\nfrom itertools import cycle\nimport multiprocessing as mp\nimport numpy as np\nimport pytest\nimport six\nfrom six.moves.urllib.parse import urljoin\nfrom six.moves.urllib.request import pathname2url\nfrom six.moves import reload_module\n\nfrom flaky import flaky\n\nfrom keras.utils import GeneratorEnqueuer\nfrom keras.utils import OrderedEnqueuer\nfrom keras.utils import Sequence\nfrom keras.utils.data_utils import _hash_file\nfrom keras.utils.data_utils import get_file\nfrom keras.utils.data_utils import validate_file\nfrom keras import backend as K\nfrom keras.backend import load_backend\n\npytestmark = pytest.mark.skipif(\n    six.PY2 and \'TRAVIS_PYTHON_VERSION\' in os.environ,\n    reason=\'Temporarily disabled until the use_multiprocessing problem is solved\')\n\nskip_generators = pytest.mark.skipif(K.backend() in {\'tensorflow\', \'cntk\'} and\n                                     \'TRAVIS_PYTHON_VERSION\' in os.environ,\n                                     reason=\'Generators do not work with `spawn`.\')\n\n\ndef use_spawn(func):\n    """"""Decorator which uses `spawn` when possible.\n    This is useful on Travis to avoid memory issues.\n    """"""\n\n    @six.wraps(func)\n    def wrapper(*args, **kwargs):\n        if sys.version_info > (3, 4) and os.name != \'nt\':\n            mp.set_start_method(\'spawn\', force=True)\n            out = func(*args, **kwargs)\n            mp.set_start_method(\'fork\', force=True)\n        else:\n            out = func(*args, **kwargs)\n        return out\n\n    return wrapper\n\n\nif sys.version_info < (3,):\n    def next(x):\n        return x.next()\n\n\n@pytest.fixture\ndef in_tmpdir(tmpdir):\n    """"""Runs a function in a temporary directory.\n\n    Checks that the directory is empty afterwards.\n    """"""\n    with tmpdir.as_cwd():\n        yield None\n    assert not tmpdir.listdir()\n\n\ndef test_data_utils(in_tmpdir):\n    """"""Tests get_file from a url, plus extraction and validation.\n    """"""\n    dirname = \'data_utils\'\n\n    with open(\'test.txt\', \'w\') as text_file:\n        text_file.write(\'Float like a butterfly, sting like a bee.\')\n\n    with tarfile.open(\'test.tar.gz\', \'w:gz\') as tar_file:\n        tar_file.add(\'test.txt\')\n\n    with zipfile.ZipFile(\'test.zip\', \'w\') as zip_file:\n        zip_file.write(\'test.txt\')\n\n    origin = urljoin(\'file://\', pathname2url(os.path.abspath(\'test.tar.gz\')))\n\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + \'.tar.gz\'\n    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n    assert data_keras_home == os.path.dirname(load_backend._config_path)\n    os.remove(filepath)\n\n    _keras_home = os.path.join(os.path.abspath(\'.\'), \'.keras\')\n    if not os.path.exists(_keras_home):\n        os.makedirs(_keras_home)\n    os.environ[\'KERAS_HOME\'] = _keras_home\n    reload_module(load_backend)\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + \'.tar.gz\'\n    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n    assert data_keras_home == os.path.dirname(load_backend._config_path)\n    os.environ.pop(\'KERAS_HOME\')\n    shutil.rmtree(_keras_home)\n    reload_module(load_backend)\n\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + \'.tar.gz\'\n    hashval_sha256 = _hash_file(filepath)\n    hashval_md5 = _hash_file(filepath, algorithm=\'md5\')\n    path = get_file(dirname, origin, md5_hash=hashval_md5, untar=True)\n    path = get_file(filepath, origin, file_hash=hashval_sha256, extract=True)\n    assert os.path.exists(filepath)\n    assert validate_file(filepath, hashval_sha256)\n    assert validate_file(filepath, hashval_md5)\n    os.remove(filepath)\n    os.remove(\'test.tar.gz\')\n\n    origin = urljoin(\'file://\', pathname2url(os.path.abspath(\'test.zip\')))\n\n    hashval_sha256 = _hash_file(\'test.zip\')\n    hashval_md5 = _hash_file(\'test.zip\', algorithm=\'md5\')\n    path = get_file(dirname, origin, md5_hash=hashval_md5, extract=True)\n    path = get_file(dirname, origin, file_hash=hashval_sha256, extract=True)\n    assert os.path.exists(path)\n    assert validate_file(path, hashval_sha256)\n    assert validate_file(path, hashval_md5)\n\n    os.remove(path)\n    os.remove(os.path.join(os.path.dirname(path), \'test.txt\'))\n    os.remove(\'test.txt\')\n    os.remove(\'test.zip\')\n\n\n""""""Enqueuers Tests""""""\n\n\nclass threadsafe_iter:\n    """"""Takes an iterator/generator and makes it thread-safe by\n    serializing call to the `next` method of given iterator/generator.\n    """"""\n\n    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        return self.next()\n\n    def next(self):\n        with self.lock:\n            return next(self.it)\n\n\ndef threadsafe_generator(f):\n    """"""A decorator that takes a generator function and makes it thread-safe.\n    """"""\n\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n\n    return g\n\n\nclass DummySequence(Sequence):\n    def __init__(self, shape, value=1.0):\n        self.shape = shape\n        self.inner = value\n\n    def __getitem__(self, item):\n        time.sleep(0.05)\n        return np.ones(self.shape, dtype=np.uint32) * item * self.inner\n\n    def __len__(self):\n        return 100\n\n    def on_epoch_end(self):\n        self.inner *= 5.0\n\n\nclass LengthChangingSequence(Sequence):\n    def __init__(self, shape, size=100, value=1.0):\n        self.shape = shape\n        self.inner = value\n        self.size = size\n\n    def __getitem__(self, item):\n        time.sleep(0.05)\n        return np.ones(self.shape, dtype=np.uint32) * item * self.inner\n\n    def __len__(self):\n        return self.size\n\n    def on_epoch_end(self):\n        self.size = int(np.ceil(self.size / 2))\n        self.inner *= 5.0\n\n\nclass FaultSequence(Sequence):\n    def __getitem__(self, item):\n        raise IndexError(item, \'is not present\')\n\n    def __len__(self):\n        return 100\n\n    def on_epoch_end(self):\n        pass\n\n\nclass SlowSequence(Sequence):\n    def __init__(self, shape, value=1.0):\n        self.shape = shape\n        self.inner = value\n        self.wait = True\n\n    def __getitem__(self, item):\n        if self.wait:\n            self.wait = False\n            time.sleep(40)\n        return np.ones(self.shape, dtype=np.uint32) * item * self.inner\n\n    def __len__(self):\n        return 10\n\n    def on_epoch_end(self):\n        pass\n\n\n@threadsafe_generator\ndef create_generator_from_sequence_threads(ds):\n    for i in cycle(range(len(ds))):\n        yield ds[i]\n\n\ndef create_generator_from_sequence_pcs(ds):\n    for i in cycle(range(len(ds))):\n        yield ds[i]\n\n\ndef test_generator_enqueuer_threads():\n    enqueuer = GeneratorEnqueuer(create_generator_from_sequence_threads(\n        DummySequence([3, 10, 10, 3])), use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(int(next(gen_output)[0, 0, 0, 0]))\n\n    """"""\n     Not comparing the order since it is not guaranteed.\n     It may get ordered, but not a lot, one thread can take\n     the GIL before he was supposed to.\n    """"""\n    assert len(set(acc) - set(range(100))) == 0, ""Output is not the same""\n    enqueuer.stop()\n\n\n@skip_generators\ndef DISABLED_test_generator_enqueuer_processes():\n    enqueuer = GeneratorEnqueuer(create_generator_from_sequence_pcs(\n        DummySequence([3, 10, 10, 3])), use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(int(next(gen_output)[0, 0, 0, 0]))\n    assert acc != list(range(100)), (\'Order was keep in GeneratorEnqueuer \'\n                                     \'with processes\')\n    enqueuer.stop()\n\n\ndef test_generator_enqueuer_threadsafe():\n    enqueuer = GeneratorEnqueuer(create_generator_from_sequence_pcs(\n        DummySequence([3, 10, 10, 3])), use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    with pytest.raises(RuntimeError) as e:\n        [next(gen_output) for _ in range(10)]\n    assert \'thread-safe\' in str(e.value)\n    enqueuer.stop()\n\n\n# TODO: resolve flakyness issue. Tracked with #11587\n@flaky(rerun_filter=lambda err, *args: issubclass(err[0], StopIteration))\ndef test_generator_enqueuer_fail_threads():\n    enqueuer = GeneratorEnqueuer(create_generator_from_sequence_threads(\n        FaultSequence()), use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    with pytest.raises(IndexError):\n        next(gen_output)\n\n\n@skip_generators\ndef DISABLED_test_generator_enqueuer_fail_processes():\n    enqueuer = GeneratorEnqueuer(create_generator_from_sequence_pcs(\n        FaultSequence()), use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    with pytest.raises(IndexError):\n        next(gen_output)\n\n\ndef test_ordered_enqueuer_threads():\n    enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                               use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc == list(range(100)), (\'Order was not keep in GeneratorEnqueuer \'\n                                     \'with threads\')\n    enqueuer.stop()\n\n\ndef test_ordered_enqueuer_threads_not_ordered():\n    enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                               use_multiprocessing=False,\n                               shuffle=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc != list(range(100)), (\'Order was not keep in GeneratorEnqueuer \'\n                                     \'with threads\')\n    enqueuer.stop()\n\n\n@use_spawn\ndef test_ordered_enqueuer_processes():\n    enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                               use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc == list(range(100)), (\'Order was not keep in GeneratorEnqueuer \'\n                                     \'with processes\')\n    enqueuer.stop()\n\n\ndef test_ordered_enqueuer_fail_threads():\n    enqueuer = OrderedEnqueuer(FaultSequence(), use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    with pytest.raises(IndexError):\n        next(gen_output)\n\n\ndef test_ordered_enqueuer_timeout_threads():\n    enqueuer = OrderedEnqueuer(SlowSequence([3, 10, 10, 3]),\n                               use_multiprocessing=False)\n\n    def handler(signum, frame):\n        raise TimeoutError(\'Sequence deadlocked\')\n\n    old = signal.signal(signal.SIGALRM, handler)\n    signal.setitimer(signal.ITIMER_REAL, 60)\n    with pytest.warns(UserWarning) as record:\n        enqueuer.start(5, 10)\n        gen_output = enqueuer.get()\n        for epoch_num in range(2):\n            acc = []\n            for i in range(10):\n                acc.append(next(gen_output)[0, 0, 0, 0])\n            assert acc == list(range(10)), \'Order was not keep in \' \\\n                                           \'OrderedEnqueuer with threads\'\n        enqueuer.stop()\n    assert len(record) == 1\n    assert str(record[0].message) == \'The input 0 could not be retrieved. \' \\\n                                     \'It could be because a worker has died.\'\n    signal.setitimer(signal.ITIMER_REAL, 0)\n    signal.signal(signal.SIGALRM, old)\n\n\n@use_spawn\ndef test_on_epoch_end_processes():\n    enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                               use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(200):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc[100:] == list([k * 5 for k in range(100)]), (\n        \'Order was not keep in GeneratorEnqueuer with processes\')\n    enqueuer.stop()\n\n\n@use_spawn\ndef test_context_switch():\n    enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                               use_multiprocessing=True)\n    enqueuer2 = OrderedEnqueuer(DummySequence([3, 10, 10, 3], value=15),\n                                use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    enqueuer2.start(3, 10)\n    gen_output = enqueuer.get()\n    gen_output2 = enqueuer2.get()\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc[-1] == 99\n    # One epoch is completed so enqueuer will switch the Sequence\n\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output2)[0, 0, 0, 0])\n    assert acc[-1] == 99 * 15\n    # One epoch has been completed so enqueuer2 will switch\n\n    # Be sure that both Sequence were updated\n    assert next(gen_output)[0, 0, 0, 0] == 0\n    assert next(gen_output)[0, 0, 0, 0] == 5\n    assert next(gen_output2)[0, 0, 0, 0] == 0\n    assert next(gen_output2)[0, 0, 0, 0] == 15 * 5\n\n    # Tear down everything\n    enqueuer.stop()\n    enqueuer2.stop()\n\n\ndef test_on_epoch_end_threads():\n    enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                               use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc == list([k * 5 for k in range(100)]), (\n        \'Order was not keep in GeneratorEnqueuer with processes\')\n    enqueuer.stop()\n\n\ndef test_on_epoch_end_threads_sequence_change_length():\n    seq = LengthChangingSequence([3, 10, 10, 3])\n    enqueuer = OrderedEnqueuer(seq,\n                               use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for i in range(100):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc == list(range(100)), (\'Order was not keep in GeneratorEnqueuer \'\n                                     \'with threads\')\n\n    enqueuer.join_end_of_epoch()\n    assert len(seq) == 50\n    acc = []\n    for i in range(50):\n        acc.append(next(gen_output)[0, 0, 0, 0])\n    assert acc == list([k * 5 for k in range(50)]), (\n        \'Order was not keep in GeneratorEnqueuer with processes\')\n    enqueuer.stop()\n\n\n@use_spawn\ndef test_ordered_enqueuer_fail_processes():\n    enqueuer = OrderedEnqueuer(FaultSequence(), use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    with pytest.raises(IndexError):\n        next(gen_output)\n\n\n@threadsafe_generator\ndef create_finite_generator_from_sequence_threads(ds):\n    for i in range(len(ds)):\n        yield ds[i]\n\n\ndef create_finite_generator_from_sequence_pcs(ds):\n    for i in range(len(ds)):\n        yield ds[i]\n\n\n# TODO: resolve flakyness issue. Tracked with #11586\n@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\ndef test_finite_generator_enqueuer_threads():\n    enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_threads(\n        DummySequence([3, 10, 10, 3])), use_multiprocessing=False)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for output in gen_output:\n        acc.append(int(output[0, 0, 0, 0]))\n    assert set(acc) == set(range(100)), ""Output is not the same""\n    enqueuer.stop()\n\n\n@skip_generators\ndef DISABLED_test_finite_generator_enqueuer_processes():\n    enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_pcs(\n        DummySequence([3, 10, 10, 3])), use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    acc = []\n    for output in gen_output:\n        acc.append(int(output[0, 0, 0, 0]))\n    assert acc != list(range(100)), (\'Order was keep in GeneratorEnqueuer \'\n                                     \'with processes\')\n    enqueuer.stop()\n\n\n@pytest.mark.skipif(\'TRAVIS_PYTHON_VERSION\' in os.environ,\n                    reason=\'Takes 150s to run\')\ndef DISABLED_test_missing_inputs():\n    missing_idx = 10\n\n    class TimeOutSequence(DummySequence):\n        def __getitem__(self, item):\n            if item == missing_idx:\n                time.sleep(120)\n            return super(TimeOutSequence, self).__getitem__(item)\n\n    enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_pcs(\n        TimeOutSequence([3, 2, 2, 3])), use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    with pytest.warns(UserWarning, match=\'An input could not be retrieved.\'):\n        for _ in range(4 * missing_idx):\n            next(gen_output)\n\n    enqueuer = OrderedEnqueuer(TimeOutSequence([3, 2, 2, 3]),\n                               use_multiprocessing=True)\n    enqueuer.start(3, 10)\n    gen_output = enqueuer.get()\n    warning_msg = ""The input {} could not be retrieved."".format(missing_idx)\n    with pytest.warns(UserWarning, match=warning_msg):\n        for _ in range(11):\n            next(gen_output)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/utils/generic_utils_test.py,0,"b""import sys\nimport pytest\nimport numpy as np\nimport marshal\nfrom keras.utils.generic_utils import custom_object_scope\nfrom keras.utils.generic_utils import has_arg\nfrom keras.utils.generic_utils import Progbar\nfrom keras.utils.generic_utils import func_dump\nfrom keras.utils.generic_utils import func_load\nfrom keras import activations\nfrom keras import regularizers\n\n\ndef test_progbar():\n    values_s = [None,\n                [['key1', 1], ['key2', 1e-4]],\n                [['key3', 1], ['key2', 1e-4]]]\n\n    for target in (len(values_s) - 1, None):\n        for verbose in (0, 1, 2):\n            bar = Progbar(target, width=30, verbose=verbose, interval=0.05)\n            for current, values in enumerate(values_s):\n                bar.update(current, values=values)\n\n\ndef test_custom_objects_scope():\n\n    def custom_fn():\n        pass\n\n    class CustomClass(object):\n        pass\n\n    with custom_object_scope({'CustomClass': CustomClass,\n                              'custom_fn': custom_fn}):\n        act = activations.get('custom_fn')\n        assert act == custom_fn\n        cl = regularizers.get('CustomClass')\n        assert cl.__class__ == CustomClass\n\n\n@pytest.mark.parametrize('fn, name, accept_all, expected', [\n    ('f(x)', 'x', False, True),\n    ('f(x)', 'y', False, False),\n    ('f(x)', 'y', True, False),\n    ('f(x, y)', 'y', False, True),\n    ('f(x, y=1)', 'y', False, True),\n    ('f(x, **kwargs)', 'x', False, True),\n    ('f(x, **kwargs)', 'y', False, False),\n    ('f(x, **kwargs)', 'y', True, True),\n    ('f(x, y=1, **kwargs)', 'y', False, True),\n    # Keyword-only arguments (Python 3 only)\n    ('f(x, *args, y=1)', 'y', False, True),\n    ('f(x, *args, y=1)', 'z', True, False),\n    ('f(x, *, y=1)', 'x', False, True),\n    ('f(x, *, y=1)', 'y', False, True),\n    # lambda\n    (lambda x: x, 'x', False, True),\n    (lambda x: x, 'y', False, False),\n    (lambda x: x, 'y', True, False),\n])\ndef test_has_arg(fn, name, accept_all, expected):\n    if isinstance(fn, str):\n        context = dict()\n        try:\n            exec('def {}: pass'.format(fn), context)\n        except SyntaxError:\n            if sys.version_info >= (3,):\n                raise\n            pytest.skip('Function is not compatible with Python 2')\n        # Sometimes exec adds builtins to the context\n        context.pop('__builtins__', None)\n        fn, = context.values()\n\n    assert has_arg(fn, name, accept_all) is expected\n\n\n@pytest.mark.xfail(sys.version_info < (3, 3),\n                   reason='inspect API does not reveal positional-only arguments')\ndef test_has_arg_positional_only():\n    assert has_arg(pow, 'x') is False\n\n\n@pytest.mark.parametrize(\n    'test_function_type',\n    ('simple function', 'closured function'))\ndef test_func_dump_and_load(test_function_type):\n\n    if test_function_type == 'simple function':\n        def test_func():\n            return r'\\u'\n\n    elif test_function_type == 'closured function':\n        def get_test_func():\n            x = r'\\u'\n\n            def test_func():\n                return x\n            return test_func\n        test_func = get_test_func()\n    else:\n        raise Exception('Unknown test case for test_func_dump_and_load')\n\n    serialized = func_dump(test_func)\n    deserialized = func_load(serialized)\n    assert deserialized.__code__ == test_func.__code__\n    assert deserialized.__defaults__ == test_func.__defaults__\n    assert deserialized.__closure__ == test_func.__closure__\n\n\ndef test_func_dump_and_load_closure():\n    y = 0\n    test_func = lambda x: x + y\n    serialized, _, closure = func_dump(test_func)\n    deserialized = func_load(serialized, closure=closure)\n    assert deserialized.__code__ == test_func.__code__\n    assert deserialized.__defaults__ == test_func.__defaults__\n    assert deserialized.__closure__ == test_func.__closure__\n\n\n@pytest.mark.parametrize(\n    'test_func', [activations.softmax, np.argmax, lambda x: x**2, lambda x: x])\ndef test_func_dump_and_load_backwards_compat(test_func):\n    # this test ensures that models serialized prior to version 2.1.2 can still be\n    # deserialized\n\n    # see:\n    # https://github.com/evhub/keras/blob/2.1.1/keras/utils/generic_utils.py#L166\n    serialized = marshal.dumps(test_func.__code__).decode('raw_unicode_escape')\n\n    deserialized = func_load(serialized, defaults=test_func.__defaults__)\n    assert deserialized.__code__ == test_func.__code__\n    assert deserialized.__defaults__ == test_func.__defaults__\n    assert deserialized.__closure__ == test_func.__closure__\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/utils/io_utils_test.py,0,"b'\'\'\'Tests for functions in io_utils.py.\n\'\'\'\nimport os\nimport io\nimport pytest\n\nfrom contextlib import contextmanager\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils.io_utils import HDF5Matrix\nfrom keras.utils.io_utils import H5Dict\nfrom keras.utils.io_utils import ask_to_proceed_with_overwrite\nfrom keras.utils.io_utils import save_to_binary_h5py\nfrom keras.utils.io_utils import load_from_binary_h5py\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nimport numpy as np\nimport six\nimport h5py\nimport tempfile\ntry:\n    from pathlib import Path\n    from unittest.mock import patch\nexcept:\n    from pathlib2 import Path\n    from mock import patch\n\n\n@pytest.fixture\ndef in_tmpdir(tmpdir):\n    """"""Runs a function in a temporary directory.\n\n    Checks that the directory is empty afterwards.\n    """"""\n    with tmpdir.as_cwd():\n        yield None\n    assert not tmpdir.listdir()\n\n\ndef create_dataset(h5_path=\'test.h5\'):\n    X = np.random.randn(200, 10).astype(\'float32\')\n    y = np.random.randint(0, 2, size=(200, 1))\n    with h5py.File(h5_path, \'w\') as f:\n        # Creating dataset to store features\n        X_dset = f.create_dataset(\'my_data\', (200, 10), dtype=\'f\')\n        X_dset[:] = X\n        # Creating dataset to store labels\n        y_dset = f.create_dataset(\'my_labels\', (200, 1), dtype=\'i\')\n        y_dset[:] = y\n\n\ndef test_io_utils(in_tmpdir):\n    \'\'\'Tests the HDF5Matrix code using the sample from @jfsantos at\n    https://gist.github.com/jfsantos/e2ef822c744357a4ed16ec0c885100a3\n    \'\'\'\n    _, h5_path = tempfile.mkstemp(\'.h5\')\n    create_dataset(h5_path)\n\n    # Instantiating HDF5Matrix for the training set,\n    # which is a slice of the first 150 elements\n    X_train = HDF5Matrix(h5_path, \'my_data\', start=0, end=150)\n    y_train = HDF5Matrix(h5_path, \'my_labels\', start=0, end=150)\n\n    # Likewise for the test set\n    X_test = HDF5Matrix(h5_path, \'my_data\', start=150, end=200)\n    y_test = HDF5Matrix(h5_path, \'my_labels\', start=150, end=200)\n\n    # HDF5Matrix behave more or less like Numpy matrices with regards to indexing\n    assert y_train.shape == (150, 1), \'HDF5Matrix shape should match input array\'\n    # But they do not support negative indices, so don\'t try print(X_train[-1])\n\n    assert y_train.dtype == np.dtype(\'i\'), (\n        \'HDF5Matrix dtype should match input array\')\n    assert y_train.ndim == 2, \'HDF5Matrix ndim should match input array\'\n    assert y_train.size == 150, \'HDF5Matrix ndim should match input array\'\n\n    model = Sequential()\n    model.add(Dense(64, input_shape=(10,), activation=\'relu\'))\n    model.add(Dense(1, activation=\'sigmoid\'))\n\n    model.compile(loss=\'binary_crossentropy\', optimizer=\'sgd\')\n\n    # Note: you have to use shuffle=\'batch\' or False with HDF5Matrix\n    model.fit(X_train, y_train, batch_size=32, shuffle=\'batch\', verbose=False)\n    # test that evalutation and prediction don\'t crash and\n    # return reasonable results\n    out_pred = model.predict(X_test, batch_size=32, verbose=False)\n    out_eval = model.evaluate(X_test, y_test, batch_size=32, verbose=False)\n\n    assert out_pred.shape == (50, 1), \'Prediction shape does not match\'\n    assert out_eval > 0, (\n        \'Evaluation value does not meet criteria: {}\'.format(out_eval))\n\n    # test slicing for shortened array\n    assert len(X_train[0:]) == len(X_train), \'Incorrect shape for sliced data\'\n\n    # test __getitem__\n    with pytest.raises(IndexError):\n        X_train[1000]\n    with pytest.raises(IndexError):\n        X_train[1000:1001]\n    with pytest.raises(IndexError):\n        X_train[[1000, 1001]]\n    with pytest.raises(IndexError):\n        X_train[six.moves.range(1000, 1001)]\n    with pytest.raises(IndexError):\n        X_train[np.array([1000])]\n    with pytest.raises(TypeError):\n        X_train[None]\n    assert (X_train[0] == X_train[:1][0]).all()\n    assert (X_train[[0, 1]] == X_train[:2]).all()\n    assert (X_train[np.array([0, 1])] == X_train[:2]).all()\n\n    # test normalizer\n    normalizer = lambda x: x + 1\n    normalized_X_train = HDF5Matrix(h5_path, \'my_data\', start=0, end=150,\n                                    normalizer=normalizer)\n    assert np.isclose(normalized_X_train[0][0], X_train[0][0] + 1)\n\n    # test resizing normalizer\n    normalizer_rs = lambda x: x[:, ::2]\n    normalized_rs_X_train = HDF5Matrix(h5_path, \'my_data\', start=0, end=150,\n                                       normalizer=normalizer_rs)\n    assert (normalized_rs_X_train.shape[1] == 5)\n\n    # test dtype changing normalizer\n    normalizer_dtype = lambda x: x.astype(np.uint8)\n    normalized_dtype_X_train = HDF5Matrix(h5_path, \'my_data\', start=0, end=150,\n                                          normalizer=normalizer_dtype)\n    assert (normalized_dtype_X_train.dtype == np.uint8)\n\n    os.remove(h5_path)\n\n\ndef test_ask_to_proceed_with_overwrite():\n    with patch(\'six.moves.input\') as mock:\n        mock.return_value = \'y\'\n        assert ask_to_proceed_with_overwrite(\'/tmp/not_exists\')\n\n        mock.return_value = \'n\'\n        assert not ask_to_proceed_with_overwrite(\'/tmp/not_exists\')\n\n\ndef test_H5Dict_attrs():\n    _, h5_path = tempfile.mkstemp(\'.h5\')\n\n    # test both HDF5 and dict implementations\n    paths = [h5_path, dict()]\n\n    for path in paths:\n        f = H5Dict(path, mode=\'w\')\n\n        # str\n        f[\'x\'] = \'abcd\'\n        f[\'x2\'] = u\'abcd\'\n\n        # list<bytes>\n        f[\'y\'] = [b\'efg\', b\'hij\', b\'klmn\']\n        f[\'y2\'] = (b\'asd\', b\'sdf\', b\'dfg\')\n\n        # ndarray\n        array = np.random.random((4, 5, 512))\n        f[\'z\'] = array\n\n        f.close()\n        del f\n\n        f = H5Dict(path, mode=\'r\')\n\n        assert f[\'x\'] == \'abcd\'\n        assert f[\'x2\'] == u\'abcd\'\n        assert f[\'y\'] == [b\'efg\', b\'hij\', b\'klmn\']\n        assert list(f[\'y2\']) == [b\'asd\', b\'sdf\', b\'dfg\']\n        assert_allclose(f[\'z\'], array)\n\n        f.close()\n    os.remove(h5_path)\n\n\ndef test_H5Dict_groups():\n    _, h5_path = tempfile.mkstemp(\'.h5\')\n\n    # test both HDF5 and dict implementations\n    paths = [h5_path, dict()]\n\n    for path in paths:\n        f = H5Dict(path, mode=\'w\')\n\n        group1 = f[\'group1\']\n        group2 = group1[\'group2\']\n\n        group2[\'x\'] = \'abcd\'\n\n        group3 = group2[\'group3\']\n        group3[\'y\'] = [b\'efg\', b\'hij\', b\'klmn\']\n\n        group4 = group3[\'group4\']\n        array = np.random.random((4, 5, 512))\n        group4[\'z\'] = array\n\n        f.close()\n\n        f = H5Dict(path, mode=\'r\')\n\n        assert \'group1\' in f\n        group1 = f[\'group1\']\n\n        assert \'group2\' in group1\n        group2 = group1[\'group2\']\n        assert group2[\'x\'] == \'abcd\'\n\n        assert \'group3\' in group2\n        group3 = group2[\'group3\']\n        assert group3[\'y\'] == [b\'efg\', b\'hij\', b\'klmn\']\n\n        assert \'group4\' in group3\n        group4 = group3[\'group4\']\n        assert_allclose(group4[\'z\'], array)\n\n        f.close()\n    os.remove(h5_path)\n\n\ndef test_H5Dict_accepts_pathlib_Path():\n    """"""GitHub issue: 11459""""""\n    _, h5_path = tempfile.mkstemp(\'.h5\')\n\n    f = H5Dict(Path(h5_path), mode=\'w\')\n    f[\'x\'] = \'abcd\'\n    f.close()\n    del f\n\n    f = H5Dict(Path(h5_path), mode=\'r\')\n    assert f[\'x\'] == \'abcd\'\n    f.close()\n\n    os.remove(h5_path)\n\n\n@contextmanager\ndef temp_filename(suffix):\n    """"""Context that returns a temporary filename and deletes the file on exit if\n    it still exists (so that this is not forgotten).\n    """"""\n    _, temp_fname = tempfile.mkstemp(suffix=suffix)\n    yield temp_fname\n    if os.path.exists(temp_fname):\n        os.remove(temp_fname)\n\n\ndef test_save_to_binary_h5py_direct_to_file():\n    data = np.random.random((3, 5))\n\n    def save_function(h5file_):\n        h5file_[\'data\'] = data\n\n    with temp_filename(\'.h5\') as fname:\n        with open(fname, \'wb\') as f:\n            save_to_binary_h5py(save_function, f)\n\n        with h5py.File(fname) as h5file:\n            data_rec = h5file[\'data\'][:]\n\n    assert_array_equal(data_rec, data)\n\n\ndef test_save_to_binary_h5py_to_bytes_io():\n    data = np.random.random((3, 5))\n\n    def save_function(h5file_):\n        h5file_[\'data\'] = data\n\n    file_like = io.BytesIO()\n    save_to_binary_h5py(save_function, file_like)\n\n    file_like.seek(0)\n\n    with temp_filename(\'.h5\') as fname:\n        with open(fname, \'wb\') as f:\n            f.write(file_like.read())\n\n        with h5py.File(fname) as h5file:\n            data_rec = h5file[\'data\'][:]\n\n    assert_array_equal(data_rec, data)\n\n\ndef test_load_from_binary_h5py_direct_from_file():\n    data = np.random.random((3, 5))\n\n    def load_function(h5file_):\n        return h5file_[\'data\'][:]\n\n    with temp_filename(\'.h5\') as fname:\n        with h5py.File(fname, \'w\') as h5file:\n            h5file[\'data\'] = data\n\n        with open(fname, \'rb\') as f:\n            data_rec = load_from_binary_h5py(load_function, f)\n\n    assert_array_equal(data_rec, data)\n\n\ndef test_load_from_binary_h5py_from_bytes_io():\n    data = np.random.random((3, 5))\n\n    def load_function(h5file_):\n        return h5file_[\'data\'][:]\n\n    with temp_filename(\'.h5\') as fname:\n        with h5py.File(fname, \'w\') as h5file:\n            h5file[\'data\'] = data\n\n        file_like = io.BytesIO()\n        with open(fname, \'rb\') as f:\n            file_like.write(f.read())\n\n    file_like.seek(0)\n    data_rec = load_from_binary_h5py(load_function, file_like)\n\n    assert_array_equal(data_rec, data)\n\n\ndef test_save_load_binary_h5py():\n\n    data1 = np.random.random((3, 5))\n    data2 = np.random.random((2, 3, 5))\n    attr = 1\n    datas = [data1, data2, attr]\n\n    def save_function(h5file_):\n        h5file_[\'data1\'] = data1\n        h5file_[\'subgroup/data2\'] = data2\n        h5file_[\'data1\'].attrs[\'attr\'] = attr\n\n    def load_function(h5file_):\n        d1 = h5file_[\'data1\'][:]\n        d2 = h5file_[\'subgroup/data2\'][:]\n        a = h5file_[\'data1\'].attrs[\'attr\']\n        return d1, d2, a\n\n    file_like = io.BytesIO()\n    save_to_binary_h5py(save_function, file_like)\n    file_like.seek(0)\n    datas_rec = load_from_binary_h5py(load_function, file_like)\n    for d_rec, d in zip(datas_rec, datas):\n        assert_array_equal(d_rec, d)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/utils/layer_utils_test.py,0,"b""import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom keras import backend as K\nfrom keras.layers import Conv2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.models import Sequential\nfrom keras.utils import layer_utils\n\n\ndef test_convert_weights():\n    def get_model(shape, data_format):\n        model = Sequential()\n        model.add(Conv2D(filters=2,\n                         kernel_size=(4, 3),\n                         input_shape=shape,\n                         data_format=data_format))\n        model.add(Flatten())\n        model.add(Dense(5))\n        return model\n\n    for data_format in ['channels_first', 'channels_last']:\n        if data_format == 'channels_first':\n            shape = (3, 5, 5)\n            target_shape = (5, 5, 3)\n            prev_shape = (2, 3, 2)\n            flip = lambda x: np.flip(np.flip(x, axis=2), axis=3)\n            transpose = lambda x: np.transpose(x, (0, 2, 3, 1))\n            target_data_format = 'channels_last'\n        elif data_format == 'channels_last':\n            shape = (5, 5, 3)\n            target_shape = (3, 5, 5)\n            prev_shape = (2, 2, 3)\n            flip = lambda x: np.flip(np.flip(x, axis=1), axis=2)\n            transpose = lambda x: np.transpose(x, (0, 3, 1, 2))\n            target_data_format = 'channels_first'\n\n        model1 = get_model(shape, data_format)\n        model2 = get_model(target_shape, target_data_format)\n        conv = K.function([model1.input], [model1.layers[0].output])\n\n        x = np.random.random((1,) + shape)\n\n        # Test equivalence of convert_all_kernels_in_model\n        convout1 = conv([x])[0]\n        layer_utils.convert_all_kernels_in_model(model1)\n        convout2 = flip(conv([flip(x)])[0])\n\n        assert_allclose(convout1, convout2, atol=1e-5)\n\n        # Test equivalence of convert_dense_weights_data_format\n        out1 = model1.predict(x)\n        layer_utils.convert_dense_weights_data_format(\n            model1.layers[2], prev_shape, target_data_format)\n        for (src, dst) in zip(model1.layers, model2.layers):\n            dst.set_weights(src.get_weights())\n        out2 = model2.predict(transpose(x))\n\n        assert_allclose(out1, out2, atol=1e-5)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n"""
tests/keras/utils/multi_gpu_test.py,2,"b'""""""These tests are not meant to be run on CI.\n""""""\nfrom __future__ import print_function\n\nimport keras\nfrom keras import backend as K\nfrom keras.utils import multi_gpu_model\n\nimport numpy as np\nimport pytest\nimport time\nimport tempfile\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\npytestmark = pytest.mark.skipif(K.backend() != \'tensorflow\',\n                                reason=\'Requires TF.\')\nif K.backend() == \'tensorflow\':\n    available_devices = keras.utils.multi_gpu_utils._get_available_devices()\n    available_devices = [keras.utils.multi_gpu_utils._normalize_device_name(name)\n                         for name in available_devices]\n    pytestmark = pytest.mark.skipif(\'/gpu:7\' not in available_devices,\n                                    reason=\'Requires 8 GPUs.\')\n\n\ndef test_multi_gpu_simple_model():\n    print(\'####### test simple model\')\n    num_samples = 1000\n    input_dim = 10\n    output_dim = 1\n    hidden_dim = 10\n    gpus = 8\n    target_gpu_id = [0, 2, 4]\n    epochs = 2\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(hidden_dim,\n                                 input_shape=(input_dim,)))\n    model.add(keras.layers.Dense(output_dim))\n\n    x = np.random.random((num_samples, input_dim))\n    y = np.random.random((num_samples, output_dim))\n\n    parallel_model = multi_gpu_model(model, gpus=gpus)\n    parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n    parallel_model.fit(x, y, epochs=epochs)\n\n    parallel_model = multi_gpu_model(model, gpus=target_gpu_id)\n    parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n    parallel_model.fit(x, y, epochs=epochs)\n\n\ndef test_multi_gpu_multi_io_model():\n    print(\'####### test multi-io model\')\n    num_samples = 1000\n    input_dim_a = 10\n    input_dim_b = 5\n    output_dim_a = 1\n    output_dim_b = 2\n    hidden_dim = 10\n    gpus = 8\n    target_gpu_id = [0, 2, 4]\n    epochs = 2\n\n    input_a = keras.Input((input_dim_a,))\n    input_b = keras.Input((input_dim_b,))\n    a = keras.layers.Dense(hidden_dim)(input_a)\n    b = keras.layers.Dense(hidden_dim)(input_b)\n    c = keras.layers.concatenate([a, b])\n    output_a = keras.layers.Dense(output_dim_a)(c)\n    output_b = keras.layers.Dense(output_dim_b)(c)\n    model = keras.models.Model([input_a, input_b], [output_a, output_b])\n\n    a_x = np.random.random((num_samples, input_dim_a))\n    b_x = np.random.random((num_samples, input_dim_b))\n    a_y = np.random.random((num_samples, output_dim_a))\n    b_y = np.random.random((num_samples, output_dim_b))\n\n    parallel_model = multi_gpu_model(model, gpus=gpus)\n    parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n    parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n\n    parallel_model = multi_gpu_model(model, gpus=target_gpu_id)\n    parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n    parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n\n\ndef test_multi_gpu_invalid_devices():\n    input_shape = (1000, 10)\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(10,\n                                 activation=\'relu\',\n                                 input_shape=input_shape[1:]))\n    model.add(keras.layers.Dense(1, activation=\'sigmoid\'))\n\n    x = np.random.random(input_shape)\n    y = np.random.random((input_shape[0], 1))\n    with pytest.raises(ValueError):\n        parallel_model = multi_gpu_model(model, gpus=10)\n        parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n        parallel_model.fit(x, y, epochs=2)\n\n    with pytest.raises(ValueError):\n        parallel_model = multi_gpu_model(model, gpus=[0, 2, 4, 6, 8])\n        parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n        parallel_model.fit(x, y, epochs=2)\n\n    with pytest.raises(ValueError):\n        parallel_model = multi_gpu_model(model, gpus=1)\n        parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n        parallel_model.fit(x, y, epochs=2)\n\n    with pytest.raises(ValueError):\n        parallel_model = multi_gpu_model(model, gpus=[0])\n        parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n        parallel_model.fit(x, y, epochs=2)\n\n\ndef test_serialization():\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(3,\n                                 input_shape=(4,)))\n    model.add(keras.layers.Dense(4))\n\n    x = np.random.random((100, 4))\n    y = np.random.random((100, 4))\n\n    parallel_model = multi_gpu_model(model, gpus=2)\n    parallel_model.compile(loss=\'mse\', optimizer=\'rmsprop\')\n    parallel_model.fit(x, y, epochs=1)\n\n    ref_output = parallel_model.predict(x)\n\n    _, fname = tempfile.mkstemp(\'.h5\')\n    parallel_model.save(fname)\n\n    K.clear_session()\n    parallel_model = keras.models.load_model(fname)\n    output = parallel_model.predict(x)\n    np.testing.assert_allclose(ref_output, output, atol=1e-5)\n\n\ndef multi_gpu_application_np_array_benchmark():\n    print(\'####### Xception benchmark - np i/o\')\n    model_cls = keras.applications.Xception\n\n    num_samples = 1000\n    height = 224\n    width = 224\n    num_classes = 1000\n    epochs = 4\n    batch_size = 40\n    x = np.random.random((num_samples, height, width, 3))\n    y = np.random.random((num_samples, num_classes))\n\n    # Baseline\n    model = model_cls(weights=None,\n                      input_shape=(height, width, 3),\n                      classes=num_classes)\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'rmsprop\')\n\n    # Training\n    start_time = time.time()\n    model.fit(x, y, epochs=epochs)\n    total_time = time.time() - start_time\n    print(\'baseline training:\', total_time)\n\n    # Inference\n    start_time = time.time()\n    model.predict(x)\n    total_time = time.time() - start_time\n    print(\'baseline inference:\', total_time)\n\n    for i in range(2, 9, 2):\n        K.clear_session()\n        with tf.device(\'/cpu:0\'):\n            model = model_cls(weights=None,\n                              input_shape=(height, width, 3),\n                              classes=num_classes)\n        parallel_model = multi_gpu_model(model, gpus=i)\n        parallel_model.compile(loss=\'categorical_crossentropy\',\n                               optimizer=\'rmsprop\')\n\n        start_time = time.time()\n        parallel_model.fit(x, y, epochs=epochs, batch_size=batch_size)\n        total_time = time.time() - start_time\n        print(\'%d gpus training:\' % i, total_time)\n\n        # Inference\n        start_time = time.time()\n        parallel_model.predict(x, batch_size=batch_size)\n        total_time = time.time() - start_time\n        print(\'%d gpus inference:\' % i, total_time)\n\n\ndef multi_gpu_application_folder_generator_benchmark():\n    """"""Before running this test:\n\n    wget https://s3.amazonaws.com/img-datasets/cats_and_dogs_small.zip\n    unzip cats_and_dogs_small.zip\n    """"""\n    print(\'####### Xception benchmark - folder generator i/o\')\n    model_cls = keras.applications.Xception\n\n    height = 150\n    width = 150\n    num_classes = 2\n    epochs = 3\n    steps_per_epoch = 100\n    batch_size = 64\n\n    # Baseline\n    model = model_cls(weights=None,\n                      input_shape=(height, width, 3),\n                      classes=num_classes)\n    model.compile(loss=\'categorical_crossentropy\',\n                  optimizer=\'rmsprop\')\n\n    datagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode=\'nearest\')\n    train_dir = \'/home/ubuntu/cats_and_dogs_small/train\'  # Change this\n    train_gen = datagen.flow_from_directory(\n        train_dir,\n        target_size=(height, width),\n        batch_size=batch_size,\n        class_mode=\'categorical\')\n\n    # Training\n    start_time = time.time()\n    model.fit_generator(train_gen,\n                        steps_per_epoch=steps_per_epoch,\n                        epochs=epochs,\n                        workers=4)\n    total_time = time.time() - start_time\n    print(\'baseline training:\', total_time)\n\n    for i in range(2, 9):\n        K.clear_session()\n        with tf.device(\'/cpu:0\'):\n            model = model_cls(weights=None,\n                              input_shape=(height, width, 3),\n                              classes=num_classes)\n        parallel_model = multi_gpu_model(model, gpus=i)\n        parallel_model.compile(loss=\'categorical_crossentropy\',\n                               optimizer=\'rmsprop\')\n\n        train_gen = datagen.flow_from_directory(\n            train_dir,\n            target_size=(height, width),\n            batch_size=batch_size,\n            class_mode=\'categorical\')\n\n        start_time = time.time()\n        parallel_model.fit_generator(\n            train_gen,\n            steps_per_epoch=steps_per_epoch,\n            epochs=epochs,\n            workers=4 * i)\n        total_time = time.time() - start_time\n        print(\'%d gpus training:\' % i, total_time)\n\n\ndef test_multi_gpu_with_multi_input_layers():\n    inputs = keras.Input((4, 3))\n    init_state = keras.Input((3,))\n    outputs = keras.layers.SimpleRNN(\n        3, return_sequences=True)(inputs, initial_state=init_state)\n    x = [np.random.randn(2, 4, 3), np.random.randn(2, 3)]\n    y = np.random.randn(2, 4, 3)\n    model = keras.models.Model([inputs, init_state], outputs)\n    parallel_model = multi_gpu_model(model, 2)\n    parallel_model.compile(loss=\'mean_squared_error\', optimizer=\'adam\')\n    parallel_model.train_on_batch(x, y)\n\n\ndef test_multi_gpu_with_siamese():\n    input_shape = (3,)\n    nested_model = keras.models.Sequential([\n        keras.layers.Dense(32, input_shape=input_shape),\n        keras.layers.Dense(1)\n    ], name=\'nested\')\n\n    input1 = keras.Input(input_shape)\n    input2 = keras.Input(input_shape)\n    score1 = nested_model(input1)\n    score2 = nested_model(input2)\n    score_sum = keras.layers.Add(name=\'add\')([score1, score2])\n\n    siamese = keras.models.Model(inputs=[input1, input2],\n                                 outputs=[score_sum, score1, score2],\n                                 name=\'siamese\')\n    parallel_siamese = multi_gpu_model(siamese, 2)\n    assert parallel_siamese.output_names == [\'add\', \'nested_1\', \'nested_2\']\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/utils/np_utils_test.py,0,"b'""""""Tests for functions in np_utils.py.\n""""""\nimport numpy as np\nimport pytest\nfrom keras.utils import to_categorical\n\n\ndef test_to_categorical():\n    num_classes = 5\n    shapes = [(1,), (3,), (4, 3), (5, 4, 3), (3, 1), (3, 2, 1)]\n    expected_shapes = [(1, num_classes),\n                       (3, num_classes),\n                       (4, 3, num_classes),\n                       (5, 4, 3, num_classes),\n                       (3, num_classes),\n                       (3, 2, num_classes)]\n    labels = [np.random.randint(0, num_classes, shape) for shape in shapes]\n    one_hots = [to_categorical(label, num_classes) for label in labels]\n    for label, one_hot, expected_shape in zip(labels,\n                                              one_hots,\n                                              expected_shapes):\n        # Check shape\n        assert one_hot.shape == expected_shape\n        # Make sure there are only 0s and 1s\n        assert np.array_equal(one_hot, one_hot.astype(bool))\n        # Make sure there is exactly one 1 in a row\n        assert np.all(one_hot.sum(axis=-1) == 1)\n        # Get original labels back from one hots\n        assert np.all(np.argmax(one_hot, -1).reshape(label.shape) == label)\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/utils/vis_utils_test.py,0,"b'import pytest\nimport os\nimport sys\nimport numpy as np\nfrom keras import Input, Model\n\nfrom keras.layers import Conv2D, Bidirectional\nfrom keras.layers import Dense\nfrom keras.layers import Embedding\nfrom keras.layers import Flatten\nfrom keras.layers import LSTM\nfrom keras.layers import TimeDistributed\nfrom keras.models import Sequential\nfrom keras.utils import vis_utils\n\n\ndef test_plot_model():\n    model = Sequential()\n    model.add(Conv2D(2, kernel_size=(2, 3), input_shape=(3, 5, 5), name=\'conv\'))\n    model.add(Flatten(name=\'flat\'))\n    model.add(Dense(5, name=\'dense1\'))\n    vis_utils.plot_model(model, to_file=\'model1.png\', show_layer_names=False)\n    os.remove(\'model1.png\')\n\n    model = Sequential()\n    model.add(LSTM(16, return_sequences=True, input_shape=(2, 3), name=\'lstm\'))\n    model.add(TimeDistributed(Dense(5, name=\'dense2\')))\n    vis_utils.plot_model(model, to_file=\'model2.png\', show_shapes=True)\n    os.remove(\'model2.png\')\n\n    inner_input = Input(shape=(2, 3), dtype=\'float32\', name=\'inner_input\')\n    inner_lstm = Bidirectional(LSTM(16, name=\'inner_lstm\'), name=\'bd\')(inner_input)\n    encoder = Model(inner_input, inner_lstm, name=\'Encoder_Model\')\n    outer_input = Input(shape=(5, 2, 3), dtype=\'float32\', name=\'input\')\n    inner_encoder = TimeDistributed(encoder, name=\'td_encoder\')(outer_input)\n    lstm = LSTM(16, name=\'outer_lstm\')(inner_encoder)\n    preds = Dense(5, activation=\'softmax\', name=\'predictions\')(lstm)\n    model = Model(outer_input, preds)\n    vis_utils.plot_model(model, to_file=\'model3.png\', show_shapes=True,\n                         expand_nested=True, dpi=300)\n    os.remove(\'model3.png\')\n\n\ndef test_plot_sequential_embedding():\n    """"""Fixes #11376""""""\n    model = Sequential()\n    model.add(Embedding(10000, 256, input_length=400, name=\'embed\'))\n    vis_utils.plot_model(model,\n                         to_file=\'model1.png\',\n                         show_shapes=True,\n                         show_layer_names=True)\n    os.remove(\'model1.png\')\n\n\nif __name__ == \'__main__\':\n    pytest.main([__file__])\n'"
tests/keras/wrappers/scikit_learn_test.py,0,"b""import pytest\nimport numpy as np\n\nfrom keras.utils.test_utils import get_test_data\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n\ninput_dim = 5\nhidden_dims = 5\nnum_train = 100\nnum_test = 50\nnum_classes = 3\nbatch_size = 32\nepochs = 1\nverbosity = 0\noptim = 'adam'\nloss = 'categorical_crossentropy'\n\nnp.random.seed(42)\n(X_train, y_train), (X_test, y_test) = get_test_data(\n    num_train=num_train, num_test=num_test, input_shape=(input_dim,),\n    classification=True, num_classes=num_classes)\n\n\ndef build_fn_clf(hidden_dims):\n    model = Sequential()\n    model.add(Dense(input_dim, input_shape=(input_dim,)))\n    model.add(Activation('relu'))\n    model.add(Dense(hidden_dims))\n    model.add(Activation('relu'))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    model.compile(optimizer='sgd', loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n\ndef test_classify_build_fn():\n    clf = KerasClassifier(\n        build_fn=build_fn_clf, hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n\n    assert_classification_works(clf)\n    assert_string_classification_works(clf)\n\n\ndef test_classify_class_build_fn():\n    class ClassBuildFnClf(object):\n\n        def __call__(self, hidden_dims):\n            return build_fn_clf(hidden_dims)\n\n    clf = KerasClassifier(\n        build_fn=ClassBuildFnClf(), hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n\n    assert_classification_works(clf)\n    assert_string_classification_works(clf)\n\n\ndef test_classify_inherit_class_build_fn():\n    class InheritClassBuildFnClf(KerasClassifier):\n\n        def __call__(self, hidden_dims):\n            return build_fn_clf(hidden_dims)\n\n    clf = InheritClassBuildFnClf(\n        build_fn=None, hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n\n    assert_classification_works(clf)\n    assert_string_classification_works(clf)\n\n\ndef assert_classification_works(clf):\n    clf.fit(X_train, y_train, sample_weight=np.ones(X_train.shape[0]),\n            batch_size=batch_size, epochs=epochs)\n\n    score = clf.score(X_train, y_train, batch_size=batch_size)\n    assert np.isscalar(score) and np.isfinite(score)\n\n    preds = clf.predict(X_test, batch_size=batch_size)\n    assert preds.shape == (num_test, )\n    for prediction in np.unique(preds):\n        assert prediction in range(num_classes)\n\n    proba = clf.predict_proba(X_test, batch_size=batch_size)\n    assert proba.shape == (num_test, num_classes)\n    assert np.allclose(np.sum(proba, axis=1), np.ones(num_test))\n\n\ndef assert_string_classification_works(clf):\n    string_classes = ['cls{}'.format(x) for x in range(num_classes)]\n    str_y_train = np.array(string_classes)[y_train]\n\n    clf.fit(X_train, str_y_train, batch_size=batch_size, epochs=epochs)\n\n    score = clf.score(X_train, str_y_train, batch_size=batch_size)\n    assert np.isscalar(score) and np.isfinite(score)\n\n    preds = clf.predict(X_test, batch_size=batch_size)\n    assert preds.shape == (num_test, )\n    for prediction in np.unique(preds):\n        assert prediction in string_classes\n\n    proba = clf.predict_proba(X_test, batch_size=batch_size)\n    assert proba.shape == (num_test, num_classes)\n    assert np.allclose(np.sum(proba, axis=1), np.ones(num_test))\n\n\ndef build_fn_reg(hidden_dims=50):\n    model = Sequential()\n    model.add(Dense(input_dim, input_shape=(input_dim,)))\n    model.add(Activation('relu'))\n    model.add(Dense(hidden_dims))\n    model.add(Activation('relu'))\n    model.add(Dense(1))\n    model.add(Activation('linear'))\n    model.compile(optimizer='sgd', loss='mean_absolute_error',\n                  metrics=['accuracy'])\n    return model\n\n\ndef test_regression_build_fn():\n    reg = KerasRegressor(\n        build_fn=build_fn_reg, hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n\n    assert_regression_works(reg)\n\n\ndef test_regression_class_build_fn():\n    class ClassBuildFnReg(object):\n\n        def __call__(self, hidden_dims):\n            return build_fn_reg(hidden_dims)\n\n    reg = KerasRegressor(\n        build_fn=ClassBuildFnReg(), hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n\n    assert_regression_works(reg)\n\n\ndef test_regression_inherit_class_build_fn():\n    class InheritClassBuildFnReg(KerasRegressor):\n\n        def __call__(self, hidden_dims):\n            return build_fn_reg(hidden_dims)\n\n    reg = InheritClassBuildFnReg(\n        build_fn=None, hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n\n    assert_regression_works(reg)\n\n\ndef assert_regression_works(reg):\n    reg.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n\n    score = reg.score(X_train, y_train, batch_size=batch_size)\n    assert np.isscalar(score) and np.isfinite(score)\n\n    preds = reg.predict(X_test, batch_size=batch_size)\n    assert preds.shape == (num_test, )\n\n\ndef test_regression_predict_shape_correct_num_test_0():\n    assert_regression_predict_shape_correct(num_test=0)\n\n\ndef test_regression_predict_shape_correct_num_test_1():\n    assert_regression_predict_shape_correct(num_test=1)\n\n\ndef assert_regression_predict_shape_correct(num_test):\n    reg = KerasRegressor(\n        build_fn=build_fn_reg, hidden_dims=hidden_dims,\n        batch_size=batch_size, epochs=epochs)\n    reg.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n\n    preds = reg.predict(X_test[:num_test], batch_size=batch_size)\n    assert preds.shape == (num_test, )\n\n\nif __name__ == '__main__':\n    pytest.main([__file__])\n\n# Usage of sklearn's grid_search\n# from sklearn import grid_search\n# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128],\n#                   epochs=[2], verbose=[0])\n# classifier = Inherit_class_build_fn_clf()\n# clf = grid_search.GridSearchCV(classifier, parameters)\n# clf.fit(X_train, y_train)\n# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128],\n#                   epochs=[2], verbose=[0])\n# regressor = Inherit_class_build_fn_reg()\n# reg = grid_search.GridSearchCV(regressor, parameters,\n#                                scoring='mean_squared_error',\n#                                n_jobs=1, cv=2, verbose=2)\n# reg.fit(X_train_reg, y_train_reg)\n"""
