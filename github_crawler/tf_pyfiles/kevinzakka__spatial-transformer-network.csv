file_path,api_count,code
setup.py,0,"b'from setuptools import setup\n\n\nsetup(\n    name=\'stn\',\n    version=\'1.0.1\',\n    description=\'Spatial Transformer Networks.\',\n    long_description=\'Implementation of https://arxiv.org/abs/1506.02025\',\n    url=\'https://github.com/kevinzakka/spatial-transformer-network\',\n    author=\'Kevin Zakka\',\n    author_email=\'kevinarmandzakka@gmail.com\',\n    license=\'MIT\',\n    keywords=\'ai neural networks machine learning ml deep learning dl spatial transformer networks\',\n    packages=[\'stn\'],\n    install_requires=[\'numpy\'],\n    extras_require={\n        ""tf"": [""tensorflow>=1.0.0""],\n        ""tf_gpu"": [""tensorflow-gpu>=1.0.0""]\n    }\n)\n'"
utils.py,0,"b'import numpy as np\n\nfrom PIL import Image\n\n\ndef img2array(data_path, desired_size=None, expand=False, view=False):\n    """"""Loads an RGB image as a 3D or 4D numpy array.""""""\n    img = Image.open(data_path)\n    img = img.convert(\'RGB\')\n    if desired_size:\n        img = img.resize((desired_size[1], desired_size[0]))\n    if view:\n        img.show()\n    x = np.asarray(img, dtype=\'float32\')\n    if expand:\n        x = np.expand_dims(x, axis=0)\n    x /= 255.0\n    return x\n\n\ndef array2img(x):\n    """"""Converts a numpy array to a PIL img.""""""\n    x = np.asarray(x)\n    x = x + max(-np.min(x), 0)\n    x_max = np.max(x)\n    if x_max != 0:\n        x /= x_max\n    x *= 255\n    return Image.fromarray(x.astype(\'uint8\'), \'RGB\')\n\n\ndef deg2rad(x):\n    """"""Converts an angle in degrees to radians.""""""\n    return (x * np.pi) / 180\n'"
stn/__init__.py,0,b'from .transformer import spatial_transformer_network\n'
stn/transformer.py,48,"b'import tensorflow as tf\n\n\ndef spatial_transformer_network(input_fmap, theta, out_dims=None, **kwargs):\n    """"""\n    Spatial Transformer Network layer implementation as described in [1].\n\n    The layer is composed of 3 elements:\n\n    - localization_net: takes the original image as input and outputs\n      the parameters of the affine transformation that should be applied\n      to the input image.\n\n    - affine_grid_generator: generates a grid of (x,y) coordinates that\n      correspond to a set of points where the input should be sampled\n      to produce the transformed output.\n\n    - bilinear_sampler: takes as input the original image and the grid\n      and produces the output image using bilinear interpolation.\n\n    Input\n    -----\n    - input_fmap: output of the previous layer. Can be input if spatial\n      transformer layer is at the beginning of architecture. Should be\n      a tensor of shape (B, H, W, C).\n\n    - theta: affine transform tensor of shape (B, 6). Permits cropping,\n      translation and isotropic scaling. Initialize to identity matrix.\n      It is the output of the localization network.\n\n    Returns\n    -------\n    - out_fmap: transformed input feature map. Tensor of size (B, H, W, C).\n\n    Notes\n    -----\n    [1]: \'Spatial Transformer Networks\', Jaderberg et. al,\n         (https://arxiv.org/abs/1506.02025)\n\n    """"""\n    # grab input dimensions\n    B = tf.shape(input_fmap)[0]\n    H = tf.shape(input_fmap)[1]\n    W = tf.shape(input_fmap)[2]\n\n    # reshape theta to (B, 2, 3)\n    theta = tf.reshape(theta, [B, 2, 3])\n\n    # generate grids of same size or upsample/downsample if specified\n    if out_dims:\n        out_H = out_dims[0]\n        out_W = out_dims[1]\n        batch_grids = affine_grid_generator(out_H, out_W, theta)\n    else:\n        batch_grids = affine_grid_generator(H, W, theta)\n\n    x_s = batch_grids[:, 0, :, :]\n    y_s = batch_grids[:, 1, :, :]\n\n    # sample input with grid to get output\n    out_fmap = bilinear_sampler(input_fmap, x_s, y_s)\n\n    return out_fmap\n\n\ndef get_pixel_value(img, x, y):\n    """"""\n    Utility function to get pixel value for coordinate\n    vectors x and y from a  4D tensor image.\n\n    Input\n    -----\n    - img: tensor of shape (B, H, W, C)\n    - x: flattened tensor of shape (B*H*W,)\n    - y: flattened tensor of shape (B*H*W,)\n\n    Returns\n    -------\n    - output: tensor of shape (B, H, W, C)\n    """"""\n    shape = tf.shape(x)\n    batch_size = shape[0]\n    height = shape[1]\n    width = shape[2]\n\n    batch_idx = tf.range(0, batch_size)\n    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n    b = tf.tile(batch_idx, (1, height, width))\n\n    indices = tf.stack([b, y, x], 3)\n\n    return tf.gather_nd(img, indices)\n\n\ndef affine_grid_generator(height, width, theta):\n    """"""\n    This function returns a sampling grid, which when\n    used with the bilinear sampler on the input feature\n    map, will create an output feature map that is an\n    affine transformation [1] of the input feature map.\n\n    Input\n    -----\n    - height: desired height of grid/output. Used\n      to downsample or upsample.\n\n    - width: desired width of grid/output. Used\n      to downsample or upsample.\n\n    - theta: affine transform matrices of shape (num_batch, 2, 3).\n      For each image in the batch, we have 6 theta parameters of\n      the form (2x3) that define the affine transformation T.\n\n    Returns\n    -------\n    - normalized grid (-1, 1) of shape (num_batch, 2, H, W).\n      The 2nd dimension has 2 components: (x, y) which are the\n      sampling points of the original image for each point in the\n      target image.\n\n    Note\n    ----\n    [1]: the affine transformation allows cropping, translation,\n         and isotropic scaling.\n    """"""\n    num_batch = tf.shape(theta)[0]\n\n    # create normalized 2D grid\n    x = tf.linspace(-1.0, 1.0, width)\n    y = tf.linspace(-1.0, 1.0, height)\n    x_t, y_t = tf.meshgrid(x, y)\n\n    # flatten\n    x_t_flat = tf.reshape(x_t, [-1])\n    y_t_flat = tf.reshape(y_t, [-1])\n\n    # reshape to [x_t, y_t , 1] - (homogeneous form)\n    ones = tf.ones_like(x_t_flat)\n    sampling_grid = tf.stack([x_t_flat, y_t_flat, ones])\n\n    # repeat grid num_batch times\n    sampling_grid = tf.expand_dims(sampling_grid, axis=0)\n    sampling_grid = tf.tile(sampling_grid, tf.stack([num_batch, 1, 1]))\n\n    # cast to float32 (required for matmul)\n    theta = tf.cast(theta, \'float32\')\n    sampling_grid = tf.cast(sampling_grid, \'float32\')\n\n    # transform the sampling grid - batch multiply\n    batch_grids = tf.matmul(theta, sampling_grid)\n    # batch grid has shape (num_batch, 2, H*W)\n\n    # reshape to (num_batch, H, W, 2)\n    batch_grids = tf.reshape(batch_grids, [num_batch, 2, height, width])\n\n    return batch_grids\n\n\ndef bilinear_sampler(img, x, y):\n    """"""\n    Performs bilinear sampling of the input images according to the\n    normalized coordinates provided by the sampling grid. Note that\n    the sampling is done identically for each channel of the input.\n\n    To test if the function works properly, output image should be\n    identical to input image when theta is initialized to identity\n    transform.\n\n    Input\n    -----\n    - img: batch of images in (B, H, W, C) layout.\n    - grid: x, y which is the output of affine_grid_generator.\n\n    Returns\n    -------\n    - out: interpolated images according to grids. Same size as grid.\n    """"""\n    H = tf.shape(img)[1]\n    W = tf.shape(img)[2]\n    max_y = tf.cast(H - 1, \'int32\')\n    max_x = tf.cast(W - 1, \'int32\')\n    zero = tf.zeros([], dtype=\'int32\')\n\n    # rescale x and y to [0, W-1/H-1]\n    x = tf.cast(x, \'float32\')\n    y = tf.cast(y, \'float32\')\n    x = 0.5 * ((x + 1.0) * tf.cast(max_x-1, \'float32\'))\n    y = 0.5 * ((y + 1.0) * tf.cast(max_y-1, \'float32\'))\n\n    # grab 4 nearest corner points for each (x_i, y_i)\n    x0 = tf.cast(tf.floor(x), \'int32\')\n    x1 = x0 + 1\n    y0 = tf.cast(tf.floor(y), \'int32\')\n    y1 = y0 + 1\n\n    # clip to range [0, H-1/W-1] to not violate img boundaries\n    x0 = tf.clip_by_value(x0, zero, max_x)\n    x1 = tf.clip_by_value(x1, zero, max_x)\n    y0 = tf.clip_by_value(y0, zero, max_y)\n    y1 = tf.clip_by_value(y1, zero, max_y)\n\n    # get pixel value at corner coords\n    Ia = get_pixel_value(img, x0, y0)\n    Ib = get_pixel_value(img, x0, y1)\n    Ic = get_pixel_value(img, x1, y0)\n    Id = get_pixel_value(img, x1, y1)\n\n    # recast as float for delta calculation\n    x0 = tf.cast(x0, \'float32\')\n    x1 = tf.cast(x1, \'float32\')\n    y0 = tf.cast(y0, \'float32\')\n    y1 = tf.cast(y1, \'float32\')\n\n    # calculate deltas\n    wa = (x1-x) * (y1-y)\n    wb = (x1-x) * (y-y0)\n    wc = (x-x0) * (y1-y)\n    wd = (x-x0) * (y-y0)\n\n    # add dimension for addition\n    wa = tf.expand_dims(wa, axis=3)\n    wb = tf.expand_dims(wb, axis=3)\n    wc = tf.expand_dims(wc, axis=3)\n    wd = tf.expand_dims(wd, axis=3)\n\n    # compute output\n    out = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n\n    return out\n'"
