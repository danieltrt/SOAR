file_path,api_count,code
changelog.py,0,"b'""""""Module for generating the CHANGELOG.md""""""\n\nfrom collections import defaultdict\nfrom nboost import __version__\nfrom datetime import datetime\nfrom pathlib import Path\nimport git\n\nREPO = git.Repo()\nCOMMIT_URL = \'https://github.com/koursaros-ai/nboost/commit/%s\'\n\nFMT = (\n    \' - [[```{sha}```]({url})] {msg} (*{name}*) \'\n    \'<span style=""color:blue"">\xe2\x96\xb3{changes}</span>\'\n)\n\nEMOJIS = {\n    \'proxy\': \'\xf0\x9f\x93\xa1\',\n    \'maps\': \'\xf0\x9f\x93\x96\',\n    \'helpers\': \'\xf0\x9f\xa7\xb0\',\n    \'translators\': \'\xf0\x9f\x92\xac\',\n    \'delegates\': \'\xf0\x9f\x93\x9e\xef\xb8\x8f\',\n    \'plugins\': \'\xf0\x9f\x94\x8c\',\n    \'cli\': \'\xe2\x8c\xa8\xef\xb8\x8f\',\n    \'models\': \'\xf0\x9f\xa7\xa0\',\n    \'defaults\': \'\xf0\x9f\x8f\xa0\',\n}\n\n\ndef get_last_release() -> datetime:\n    """"""get the last commit date of __version__""""""\n    for commit in REPO.iter_commits(paths=__version__.__file__):\n        return commit.committed_date\n\n\nLAST_RELEASE = get_last_release()\n\n\ndef get_changelog() -> dict:\n    """"""construct changelog dict""""""\n    changelog = defaultdict(list)\n    for commit in REPO.iter_commits():\n        for file in commit.stats.files:\n            if file.startswith(\'nboost\') and not commit.summary.startswith(\'Merge\'):\n                line = FMT.format(\n                    sha=commit.hexsha[:7],\n                    url=COMMIT_URL % commit.hexsha,\n                    msg=commit.summary.split(\': \')[-1],\n                    name=commit.committer.name,\n                    changes=commit.stats.total[\'lines\']\n                )\n                module = file.split(\'/\')[1].split(\'.\')[0] if \'/\' in file else file\n                changelog[module].append(line)\n        if commit.committed_date < LAST_RELEASE:\n            break\n    return changelog\n\n\ndef format_changelog(changelog: dict) -> str:\n    """"""create .md from changelog dict""""""\n    release = \'# Release `%s`\' % __version__.__doc__\n\n    for module, lines in changelog.items():\n        release += \'\\n\\n### %s %s\\n\' % (EMOJIS.get(module, \'\'), module.title())\n        for line in lines:\n            release += \'\\n\' + line\n    return release\n\n\nif __name__ == ""__main__"":\n    with Path(__file__).parent.joinpath(\'CHANGELOG-NEW.md\').open(\'w\') as file:\n        file.write(format_changelog(get_changelog()))\n'"
docker.py,0,"b'""""""Build and push images""""""\n\nfrom nboost import __version__, PKG_PATH\nfrom nboost.logger import set_logger\nfrom nboost.maps import IMAGE_MAP\nimport subprocess\n\nREGISTRY = \'koursaros/nboost\'\nVERSION_TAG = \'%s:%s-{image}\' % (REGISTRY, __version__.__doc__)\nLATEST_TAG = \'%s:latest-{image}\' % REGISTRY\nBUILD = \'docker build -t %s -t %s {path}\' % (VERSION_TAG, LATEST_TAG)\nPUSH = \'docker push %s\' % REGISTRY\n\n\ndef execute(command: str):\n    """"""Execute command in subprocess""""""\n    logger = set_logger(\'RELEASE\')\n    logger.info(command)\n    subprocess.call(command, shell=True)\n\n\ndef build():\n    """"""Build dockerfiles""""""\n    for image, path in IMAGE_MAP.items():\n        path = PKG_PATH.joinpath(path).absolute()\n        execute(BUILD.format(image=image, path=path))\n\n\ndef push():\n    """"""Push images""""""\n    execute(PUSH)\n\n\nif __name__ == ""__main__"":\n    build()\n    push()\n'"
setup.py,0,"b""from setuptools import setup, find_packages\nfrom pathlib import Path\nfrom nboost import __version__\n\nsetup(\n    name='nboost',\n    packages=find_packages(),\n    include_package_data=True,\n    version=__version__.__doc__,\n    license='Apache 2.0',\n    description='Nboost is a scalable, search-'\n                'api-boosting platform for developing and deploying '\n                'automated SOTA models more relevant search results.',\n    long_description=Path('README.md').read_text('utf8'),\n    long_description_content_type='text/markdown',\n    author='Koursaros',\n    author_email='cole.thienes@gmail.com',\n    url='https://github.com/koursaros-ai/nboost',\n    # download_url='https://github.com/koursaros-ai/nboost/archive/0.0.1.tar.gz',\n    keywords=[\n        'elasticsearch',\n        'distributed',\n        'cloud-native',\n        'neural',\n        'inference',\n    ],\n    install_requires=[\n        'termcolor',\n        'requests',\n        'elasticsearch',\n        'tqdm',\n        'jsonpath-ng',\n        'flask',\n        'nltk'\n    ],\n    extras_require={\n        'pt': ['torch', 'transformers==2.7.0'],\n        'tf': ['tensorflow>=2.1.0', 'sentencepiece'],\n        'all': ['torch', 'tensorflow>=2.1.0', 'transformers==2.7.0'],\n    },\n    entry_points={'console_scripts': [\n        'nboost=nboost.__main__:main',\n        'nboost-index=nboost.indexers.__main__:main'\n    ]},\n    classifiers=[\n        'Intended Audience :: Education',\n        'Intended Audience :: Science/Research',\n        'Intended Audience :: Developers',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Topic :: Internet :: WWW/HTTP :: Indexing/Search',\n        'Topic :: Scientific/Engineering',\n        'Topic :: Scientific/Engineering :: Mathematics',\n        'Topic :: Software Development',\n        'Topic :: Software Development :: Libraries',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n    ],\n)"""
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nfrom pathlib import Path\nimport importlib.util\nimport sys\n\nfile = Path(__file__)\nsys.path.insert(0, str(file.parent.parent))\n\n# -- Project information -----------------------------------------------------\n\nproject = \'NBoost Documentation\'\ncopyright = \'2019. Cole Thienes, Jack Pertschuk\'\nauthor = \'Cole Thienes (https://colethienes.github.io)\'\n\n\ninit = file.parent.parent.joinpath(\'nboost/__version__.py\')\nspec = importlib.util.spec_from_file_location(\'version\', init)\nmodule = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(module)\n\n# The short X.Y version\nversion = module.__doc__\n# The full version, including alpha/beta/rc tags\nrelease = module.__doc__\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx_autodoc_typehints\',\n    \'sphinx_markdown_tables\',\n    \'sphinx.ext.viewcode\',\n    \'sphinxcontrib.apidoc\',\n    \'sphinxarg.ext\',\n    \'recommonmark\',\n]\n\n\napidoc_module_dir = \'../nboost\'\napidoc_output_dir = \'api\'\napidoc_excluded_paths = [\'tests\']\napidoc_separate_modules = True\n\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = [\'.rst\', \'.md\']\n# source_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\nhtml_logo = \'../.github/banner-white.svg\'\nhtml_favicon = \'../.github/favicon.ico\'\n\nhtml_css_files = [\'main.css\']\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'NBoostdoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'NBoost.tex\', \'Noost Documentation\',\n     \'Cole Thienes, Jack Pertschuk\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'nboost\', \'NBoost Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'NBOOST\', \'NBoost Documentation\',\n     author, \'NBoost\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n\n\n# -- Extension configuration -------------------------------------------------\n\nautoclass_content = \'both\''"
nboost/__init__.py,0,"b'""""""General nboost package parameters""""""\nfrom pathlib import Path\n\nPKG_PATH = Path(__file__).parent\n\n'"
nboost/__main__.py,0,"b'""""""__main__ cli entrypoint""""""\nfrom nboost.proxy import Proxy\nfrom nboost.cli import set_parser\n\n\ndef main():\n    """"""Entrypoint for nboost""""""\n    parser = set_parser()\n    args = parser.parse_args()\n    proxy = Proxy(**vars(args))\n    proxy.run()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
nboost/__version__.py,0,"b'""""""0.3.8""""""\n'"
nboost/cli.py,0,"b'""""""NBoost command line interface""""""\nfrom argparse import ArgumentParser, ArgumentDefaultsHelpFormatter as AdHf\nimport termcolor\nfrom nboost.__version__ import __doc__\nfrom nboost import defaults\n\n\nTAG = termcolor.colored(\'NBoost (v%s)\' % __doc__, \'cyan\', attrs=[\'underline\'])\nDESCRIPTION = (\'%s: is a scalable, search-api-boosting platform for \'\n               \'developing and deploying SOTA models to improve the \'\n               \'relevance of search results..\' % TAG)\nQA_MODEL = \'adds the qa plugin which treats the query as a question and marks the answer offset\'\nFILTER_RESULTS = \'whether to filter out results based on classification model\'\nDELIM = \'the deliminator to concatenate multiple queries into a single query\'\nCIDS_PATH = \'the jsonpath to find the ids of the choices (for benchmarking)\'\nQUERY_PREP = \'preprocessing filter applied to the query string after request and before reranking\'\nCVALUES_PATH = \'the jsonpath to find the string values of the choices\'\nCHOICES_PATH = \'the jsonpath to find the array of choices to reorder\'\nTOPK_PATH = \'the jsonpath to find the number of requested results\'\nDEFAULT_TOPK = \'the default number of results that the api returns\'\nTRUE_CIDS_PATH = \'the path of the true choice ids in the request\'\nSEARCH_ROUTE = \'the url path to tag for reranking via nboost\'\nQUERY_PATH = \'the jsonpath in the request to find the query\'\nQA_MODEL_DIR = \'name or directory of the finetuned qa model\'\nCONFIG = \'which search api nboost should be configured for\'\nBATCH_SIZE = \'batch size for running through rerank model\'\nMODEL_DIR = \'name or directory of the finetuned model\'\nWORKERS = \'number of threads serving the proxy\'\nTOPN = \'the number of results to rerank (filtered down to topk)\'\nQA = \'whether or not to output qa responses\'\nMAX_SEQ_LEN = \'max combined token length\'\nVERBOSE = \'turn on detailed logging\'\nBUFSIZE = \'size of the http buffer\'\nDATA_DIR = \'dir for model binary\'\nUHOST = \'host of the server\'\nUPORT = \'port of the server\'\nPROTOCOL = \'protocol class\'\nHOST = \'host of the proxy\'\nPORT = \'port of the proxy\'\nMODEL = \'model class\'\nNO_RERANK = \'do not rerank the query results using the model\'\nUSSL = \'use ssl for the upstream connection\'\nDEBUG = \'return the session parameters and parsed objects for that session\'\n\n\ndef set_parser() -> ArgumentParser:\n    """"""Add default nboost cli arguments to a given parser""""""\n    parser = ArgumentParser(prog=\'nboost\', description=DESCRIPTION,\n                            formatter_class=lambda prog: AdHf(prog, max_help_position=100, width=100))\n    parser.add_argument(\'--debug\', type=type(defaults.debug), default=defaults.debug, help=DEBUG)\n    parser.add_argument(\'--no_rerank\', type=type(defaults.no_rerank), default=defaults.no_rerank, help=NO_RERANK)\n    parser.add_argument(\'--search_route\', type=type(defaults.search_route), default=defaults.search_route, help=SEARCH_ROUTE)\n    parser.add_argument(\'--query_path\', type=type(defaults.query_path), default=defaults.query_path, help=QUERY_PATH)\n    parser.add_argument(\'--topk_path\', type=type(defaults.topk_path), default=defaults.topk_path, help=TOPK_PATH)\n    parser.add_argument(\'--default_topk\', type=type(defaults.default_topk), default=defaults.default_topk, help=DEFAULT_TOPK)\n    parser.add_argument(\'--cvalues_path\', type=type(defaults.cvalues_path), default=defaults.cvalues_path, help=CVALUES_PATH)\n    parser.add_argument(\'--cids_path\', type=type(defaults.cids_path), default=defaults.cids_path, help=CIDS_PATH)\n    parser.add_argument(\'--choices_path\', type=type(defaults.choices_path), default=defaults.choices_path, help=CHOICES_PATH)\n    parser.add_argument(\'--query_prep\', type=type(defaults.query_prep), default=defaults.query_prep, help=QUERY_PREP)\n    parser.add_argument(\'--verbose\', type=type(defaults.verbose), default=defaults.verbose, help=VERBOSE)\n    parser.add_argument(\'--host\', type=type(defaults.host), default=defaults.host, help=HOST)\n    parser.add_argument(\'--port\', type=type(defaults.port), default=defaults.port, help=PORT)\n    parser.add_argument(\'--uhost\', type=type(defaults.uhost), default=defaults.uhost, help=UHOST)\n    parser.add_argument(\'--uport\', type=type(defaults.uport), default=defaults.uport, help=UPORT)\n    parser.add_argument(\'--ussl\', type=type(defaults.ussl), default=defaults.ussl, help=USSL)\n    parser.add_argument(\'--delim\', type=type(defaults.query_delim), default=defaults.query_delim, help=DELIM)\n    parser.add_argument(\'--max_seq_len\', type=type(defaults.max_seq_len), default=defaults.max_seq_len, help=MAX_SEQ_LEN)\n    parser.add_argument(\'--bufsize\', type=type(defaults.bufsize), default=defaults.bufsize, help=BUFSIZE)\n    parser.add_argument(\'--batch_size\', type=type(defaults.batch_size), default=defaults.batch_size, help=BATCH_SIZE)\n    parser.add_argument(\'--topn\', type=type(defaults.topn), default=defaults.topn, help=TOPN)\n    parser.add_argument(\'--workers\', type=type(defaults.workers), default=defaults.workers, help=WORKERS)\n    parser.add_argument(\'--data_dir\', type=type(defaults.data_dir), default=defaults.data_dir, help=DATA_DIR)\n    parser.add_argument(\'--model\', type=type(defaults.model), default=defaults.model, help=MODEL)\n    parser.add_argument(\'--model_dir\', type=type(defaults.model_dir), default=defaults.model_dir, help=MODEL_DIR)\n    parser.add_argument(\'--qa\', type=type(defaults.qa), default=defaults.qa, help=QA)\n    parser.add_argument(\'--qa_model\', type=type(defaults.qa_model), default=defaults.qa_model, help=QA_MODEL)\n    parser.add_argument(\'--qa_model_dir\', type=type(defaults.qa_model_dir), default=defaults.qa_model_dir, help=QA_MODEL_DIR)\n    parser.add_argument(\'--filter_results\', type=type(defaults.filter_results), default=defaults.filter_results, help=FILTER_RESULTS)\n    return parser\n'"
nboost/compat.py,0,"b'from nboost.maps import CLASS_MAP, URL_MAP, MODULE_MAP\n\n\nclass BackwardsCompatibility:\n    """"""Augment global modules to be backwards compatible""""""\n    def set(self):\n        MODULE_MAP[\'QAModel\'] = MODULE_MAP[\'QAModelPlugin\']\n        MODULE_MAP[\'RerankModel\'] = MODULE_MAP[\'RerankModelPlugin\']\n        MODULE_MAP[\'ShuffleModel\'] = MODULE_MAP[\'ShuffleRerankModelPlugin\']\n        MODULE_MAP[\'PtBertModel\'] = MODULE_MAP[\'PtBertRerankModelPlugin\']\n        MODULE_MAP[\'TfBertModel\'] = MODULE_MAP[\'TfBertRerankModelPlugin\']\n        MODULE_MAP[\'TfAlbertModel\'] = MODULE_MAP[\'TfAlbertRerankModelPlugin\']\n        MODULE_MAP[\'PtDistilBertQAModel\'] = MODULE_MAP[\'PtDistilBertQAModelPlugin\']\n        URL_MAP[""bert-base-uncased-msmarco""] = URL_MAP[""tf-bert-base-uncased-msmarco""]\n        URL_MAP[""albert-tiny-uncased-msmarco""] = URL_MAP[""tf-albert-tiny-uncased-msmarco""]\n        URL_MAP[""biobert-base-uncased-msmarco""] = URL_MAP[""tf-biobert-base-uncased-msmarco""]\n        CLASS_MAP[""bert-base-uncased-msmarco""] = CLASS_MAP[""tf-bert-base-uncased-msmarco""]\n        CLASS_MAP[""albert-tiny-uncased-msmarco""] = CLASS_MAP[""tf-albert-tiny-uncased-msmarco""]\n        CLASS_MAP[""biobert-base-uncased-msmarco""] = CLASS_MAP[""tf-biobert-base-uncased-msmarco""]\n'"
nboost/database.py,0,"b""import os\nimport time\nfrom typing import Optional\nfrom sqlite3 import Cursor\nimport sqlite3\nfrom nboost import defaults\n\n\nclass Database:\n    def __init__(self, db_file: type(defaults.db_file) = defaults.db_file, **_):\n        os.makedirs(db_file.parent, exist_ok=True)\n        self.db_file = db_file\n\n    def new_row(self):\n        return DatabaseRow()\n\n    def get_cursor(self) -> Cursor:\n        conn = sqlite3.connect(str(self.db_file), isolation_level=None)\n        return conn.cursor()\n\n    def insert(self, db_row: 'DatabaseRow'):\n        cursor = self.get_cursor()\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS searches (\n                time REAL,\n                topk INTEGER,\n                choices INTEGER,\n                qa_time REAL,\n                model_mrr REAL,\n                server_mrr REAL,\n                rerank_time REAL,\n                response_time REAL\n            );\n        ''')\n\n        cursor.execute('''            \n            INSERT INTO searches (\n                time,\n                topk,\n                choices,\n                qa_time,\n                model_mrr,\n                server_mrr,\n                rerank_time,\n                response_time\n            )\n            VALUES(?,?,?,?,?,?,?,?);\n        ''', (\n            time.time(),\n            db_row.topk,\n            db_row.choices,\n            db_row.qa_time,\n            db_row.model_mrr,\n            db_row.server_mrr,\n            db_row.rerank_time,\n            db_row.response_time\n        ))\n\n    def get_stats(self) -> dict:\n        cursor = self.get_cursor()\n        stats = cursor.execute('''\n            SELECT\n                AVG(topk) AS avg_topk,\n                AVG(choices) AS avg_num_choices,\n                AVG(rerank_time) AS avg_rerank_time,\n                AVG(response_time) AS avg_response_time,\n                AVG(model_mrr) AS avg_model_mrr,\n                AVG(server_mrr) AS avg_server_mrr\n            FROM searches\n        ''').fetchone()\n        columns = [column[0] for column in cursor.description]\n        return dict(zip(columns, stats))\n\n\nclass DatabaseRow:\n    def __init__(self):\n        self.topk = None  # type: Optional[int]\n        self.choices = None  # type: Optional[int]\n        self.qa_time = None  # type: Optional[float]\n        self.model_mrr = None  # type: Optional[float]\n        self.server_mrr = None  # type: Optional[float]\n        self.rerank_time = None  # type: Optional[float]\n        self.response_time = None  # type: Optional[float]\n\n"""
nboost/defaults.py,0,"b'\n""""""Default command line arguments.""""""\n\nfrom nboost.helpers import ListOrCommaDelimitedString\nfrom nboost import PKG_PATH\n\nhost = \'0.0.0.0\'\nport = 8000\nuhost = \'0.0.0.0\'\nuport = 9200\nussl = False\nbacklog = 100\nverbose = False\nquery_delim = \'. \'\nlr = 10e-3\nmax_seq_len = 64\nbufsize = 2048\nbatch_size = 4\ntopn = 50\nworkers = 10\ndata_dir = PKG_PATH.joinpath(\'.cache\')\nno_rerank = False\nmodel = \'PtTransformersRerankPlugin\'\nmodel_dir = \'nboost/pt-tinybert-msmarco\'\nqa = False\nqa_model = \'PtDistilBertQAModelPlugin\'\nqa_model_dir = \'distilbert-base-uncased-distilled-squad\'\nqa_threshold = 0\nmax_query_length = 64\nfilter_results = False\nquery_prep = \'lambda query: query\'\ndebug = False\ndb_file = data_dir.joinpath(\'nboost.db\')\nrerank_cids = ListOrCommaDelimitedString()\nprerank = False\n\n# by default, nboost is configured for elasticsearch\nsearch_route = \'/<index>/_search\'\nfrontend_route = \'/nboost\'\nstatus_route = \'/status\'\nquery_path = \'(body.query.match) | (body.query.term.*) | (url.query.q)\'\ntopk_path = \'(body.size) | (url.query.size)\'\ndefault_topk = 10\nchoices_path = \'body.hits.hits\'\ncvalues_path = \'_source.*\'\ncids_path = \'_id\'\n\n'"
nboost/delegates.py,0,"b'import re\nimport collections.abc\nfrom typing import Optional\nfrom nboost.helpers import get_jsonpath, set_jsonpath, JSONTYPES, flatten\nfrom nboost.exceptions import *\nfrom nboost import defaults\n\n\nclass Delegate:\n    """"""A Class that parses the attributes of a request or response. It is\n     configured by command line and runtime arguments. Also used for setting\n     the request/response prior to preparation.""""""\n    def __init__(self):\n        self.dict = None  # type: Optional[dict]\n\n    def get_path(self, path: str) -> JSONTYPES:\n        # To improve performance, don\'t use get_jsonpath if the key is easily accessible using dotted path syntax (e.g. ""path.to.my.key"")\n        is_dotted_path = True if re.match(""^([\\w]+[.]?)+$"", path) else False\n        if is_dotted_path:\n            return [self._get_dict_by_path(self.dict, path)]\n        else:\n            return get_jsonpath(self.dict, path)\n\n    def set_path(self, path: str, value: JSONTYPES):\n        # To improve performance, don\'t use set_jsonpath if the key is easily accessible using dotted path syntax (e.g. ""path.to.my.key"")\n        is_dotted_path = True if re.match(""^([\\w]+[.]?)+$"", path) else False\n        if is_dotted_path:\n            self._update_dict_by_path(self.dict, path, value)\n        else:\n            set_jsonpath(self.dict, path, value)\n\n    def _update_dict_by_path(self, obj, path, value):\n        """""" \n        Update a nested dictionary using dotted path of a key and its value\n        Example: _update_dict_by_path(my_dict, ""path.to.my.key"", 7)\n        """"""\n        split_path = path.split(\'.\', maxsplit=1)\n\n        if len(split_path) == 1:\n            obj[split_path[0]] = value\n        else:\n            if split_path[0] not in obj.keys():\n                obj[split_path[0]] = {}\n            self._update_dict_by_path(obj[split_path[0]], split_path[1], value)\n\n    def _get_dict_by_path(self, obj, path):\n        """""" \n        Retrieve a value in a nested dictionary using dotted path of its key\n        Example: _get_dict_by_path(my_dict, ""path.to.my.key"")\n        """"""\n        split_path = path.split(\'.\', maxsplit=1)\n\n        if len(split_path) == 1:\n            return obj[split_path[0]]\n        else:\n            return self._get_dict_by_path(obj[split_path[0]], split_path[1])\n\n\nclass RequestDelegate(Delegate):\n    def __init__(self, dict_request: dict,\n                 uhost: type(defaults.uhost) = defaults.uhost,\n                 uport: type(defaults.uport) = defaults.uport,\n                 ussl: type(defaults.ussl) = defaults.ussl,\n                 query_delim: type(defaults.query_delim) = defaults.query_delim,\n                 topn: type(defaults.topn) = defaults.topn,\n                 query_prep: type(defaults.query_prep) = defaults.query_prep,\n                 topk_path: type(defaults.topk_path) = defaults.topk_path,\n                 default_topk: type(defaults.default_topk) = defaults.default_topk,\n                 query_path: type(defaults.query_path) = defaults.query_path,\n                 rerank_cids: type(defaults.rerank_cids) = defaults.rerank_cids,\n                 choices_path: type(defaults.choices_path) = defaults.choices_path,\n                 cvalues_path: type(defaults.cvalues_path) = defaults.cvalues_path,\n                 cids_path: type(defaults.cids_path) = defaults.cids_path,\n                 filter_results: type(defaults.filter_results) = defaults.filter_results,\n                 qa_threshold: type(defaults.qa_threshold) = defaults.qa_threshold,\n                 **_):\n        super().__init__()\n        self.dict = dict_request\n        self.uhost = type(defaults.uhost)(uhost)\n        self.uport = type(defaults.uport)(uport)\n        self.ussl = type(defaults.ussl)(ussl)\n        self.query_path = type(defaults.query_path)(query_path)\n        self.query_delim = type(defaults.query_delim)(query_delim)\n        self.query_prep = type(defaults.query_prep)(query_prep)\n        self.topn = type(defaults.topn)(topn)\n        self.topk_path = type(defaults.topk_path)(topk_path)\n        self.default_topk = type(defaults.default_topk)(default_topk)\n        self.rerank_cids = type(defaults.rerank_cids)(rerank_cids)\n        self.choices_path = type(defaults.choices_path)(choices_path)\n        self.cvalues_path = type(defaults.cvalues_path)(cvalues_path)\n        self.cids_path = type(defaults.cids_path)(cids_path)\n        self.filter_results = type(defaults.filter_results)(filter_results)\n        self.qa_threshold = type(defaults.qa_threshold)(qa_threshold)\n\n    @property\n    def topk(self) -> int:\n        topks = self.get_path(self.topk_path)\n        return int(topks[0]) if topks else self.default_topk\n\n    @topk.setter\n    def topk(self, value: int):\n        self.set_path(self.topk_path, value)\n\n    @property\n    def query(self) -> str:\n        queries = self.get_path(self.query_path)\n        query = self.query_delim.join(queries)\n\n        # check for errors\n        if not query:\n            raise MissingQuery\n\n        return eval(self.query_prep)(query)\n\n\nclass ResponseDelegate(Delegate):\n    def __init__(self, dict_response: dict, request: RequestDelegate, **_):\n        super().__init__()\n        self.dict = dict_response\n        self.request = request\n\n    @property\n    def choices(self) -> list:\n        choices = self.get_path(self.request.choices_path)\n\n        if not isinstance(choices, list):\n            raise InvalidChoices(\'choices were not a list\')\n\n        return flatten(choices)\n\n    @choices.setter\n    def choices(self, value: list):\n        self.set_path(self.request.choices_path, value)\n\n    @property\n    def cids(self) -> list:\n        return self.get_path(\n            self.request.choices_path + \'.[*].\' + self.request.cids_path\n        )\n\n    @property\n    def cvalues(self) -> list:\n        return self.get_path(\n            self.request.choices_path + \'.[*].\' + self.request.cvalues_path\n        )\n'"
nboost/exceptions.py,0,"b'""""""NBoost base exceptions""""""\n\n\nclass RequestException(Exception):\n    """"""Exception when receiving client request""""""\n\n\nclass ResponseException(Exception):\n    """"""Upstream response contains error message""""""\n\n\nclass UpstreamConnectionError(Exception):\n    """"""Raised when the upstream host refuses connection""""""\n\n\nclass StatusRequest(RequestException):\n    """"""Client sent status request""""""\n\n\nclass FrontendRequest(RequestException):\n    """"""Client sent frontend request""""""\n\n\nclass UnknownRequest(RequestException):\n    """"""Unrecognized url path in request""""""\n\n\nclass MissingQuery(RequestException):\n    """"""Could not parse query in request""""""\n\n\nclass UpstreamServerError(ResponseException):\n    """"""Raised when the upstream server sends an error status code.""""""\n\n\nclass InvalidChoices(ResponseException):\n    """"""The length of choices, choice ids, and choice values must be the same""""""\n'"
nboost/helpers.py,0,"b'""""""Utility functions for NBoost classes""""""\nfrom urllib.parse import urlparse, parse_qsl, urlunparse, urlencode\nfrom json.decoder import JSONDecodeError\nfrom typing import Any, Union, List, Optional\nfrom http.client import responses\nfrom contextlib import suppress\nfrom functools import reduce\nfrom pathlib import Path\nimport importlib\nimport operator\nimport tarfile\nimport json\nfrom jsonpath_ng.ext import parse\nfrom jsonpath_ng import jsonpath, DatumInContext\nfrom tqdm import tqdm\nimport requests\n\nJSONTYPES = Union[dict, list, str, int, float]\n\n\nclass ListOrCommaDelimitedString:\n\n    def __init__(self, value: Optional[Union[str, list]] = None):\n\n        if isinstance(value, list):\n            self.string = \',\'.join(value)\n            self.list = value\n        elif isinstance(value, str):\n            self.string = value\n            self.list = value.split(\',\')\n        else:\n            self.string = None\n            self.list = []\n\n\ndef update_union(self, data, val):\n    """"""JsonPath Union class patch to support updating.""""""\n    with suppress(TypeError):\n        self.left.update(data, val)\n\n    with suppress(TypeError):\n        self.right.update(data, val)\n\n\ndef update_field(self, data, val):\n    """"""JsonPath Fields class patch to support adding new keys.""""""\n    for field in self.reified_fields(DatumInContext.wrap(data)):\n        if hasattr(val, \'__call__\'):\n            val(data[field], data, field)\n        else:\n            data[field] = val\n    return data\n\n\njsonpath.Union.update = update_union\njsonpath.Fields.update = update_field\n\n\n\n\n\n\ndef get_jsonpath(obj: JSONTYPES, path: str) -> List[JSONTYPES]:\n    """"""Return json values matching jsonpaths.""""""\n    return [match.value for match in parse(path).find(obj)]\n\n\ndef set_jsonpath(obj: JSONTYPES, path: str, value: Any) -> None:\n    """"""Sets the value in each matching jsonpath key.""""""\n    expression = parse(path)\n    expression.update(obj, value)\n\n\ndef download_file(url: str, path: Path):\n    """"""Download file from a specified url to a given path""""""\n    fileobj = path.open(\'wb+\')\n    response = requests.get(url=url, stream=True)\n    content_length = response.headers.get(\'content-length\')\n\n    if content_length is None:  # no content length header\n        raise ConnectionAbortedError(\'No content-length header on request.\')\n    pbar = tqdm(total=int(content_length), unit=\'B\', desc=url)\n    for data in response.iter_content(chunk_size=4096):\n        fileobj.write(data)\n        pbar.update(4096)\n    pbar.close()\n    fileobj.close()\n\n\ndef extract_tar_gz(path: Path, to_dir: Path = None):\n    """"""Extract tar file from path to specified directory""""""\n    if to_dir is None:\n        to_dir = path.parent\n\n    fileobj = path.open(\'rb\')\n    tar = tarfile.open(fileobj=fileobj)\n    tar.extractall(path=str(to_dir))\n    tar.close()\n    fileobj.close()\n\n\ndef load_json(json_string: bytes) -> dict:\n    """"""try to load json and return empty dict if decode error""""""\n    with suppress(JSONDecodeError):\n        return json.loads(json_string.decode())\n    return {}\n\n\ndef dump_json(obj: JSONTYPES, **kwargs) -> bytes:\n    """"""Dump dict to json encoded bytes string""""""\n    return json.dumps(obj, **kwargs).encode()\n\n\ndef count_lines(path: Path):\n    """"""Count the number of lines in a file""""""\n    fileobj = path.open()\n    count = sum(1 for _ in fileobj)\n    fileobj.close()\n    return count\n\n\ndef calculate_mrr(correct: list, guesses: list):\n    """"""Calculate mean reciprocal rank as the first correct result index""""""\n    for i, guess in enumerate(guesses, 1):\n        if guess in correct:\n            return 1 / i\n    return 0\n\n\ndef calculate_overlap(min1, max1, min2, max2):\n    """"""Calculate the overlap of two lines in average percent overlap.""""""\n    dist = max(0, min(max1, max2) - max(min1, min2))\n    len1 = max1 - min1\n    len2 = max2 - min2\n    return (dist / len1 if len1 else 0 + dist / len2 if len2 else 0) / 2\n\n\ndef flatten(array: list):\n    """"""Flatten nested list to a single list""""""\n    return [item for sublist in array for item in sublist]\n\n\ndef import_class(module: str, cls: str):\n    """"""import an nboost class from a module.""""""\n    file = \'nboost.%s\' % module\n    return getattr(importlib.import_module(file), cls)\n\n\n'"
nboost/logger.py,0,"b'""""""Logger for NBoost classes""""""\n\nimport termcolor\nimport logging\nimport copy\nimport os\n\n\ndef set_logger(context, verbose=False):\n    """"""Return colored logger with specified context name and debug=verbose""""""\n    if os.name == \'nt\':  # for Windows\n        return NTLogger(context, verbose)\n\n    # Remove all handlers associated with the root logger object.\n    for handler in logging.root.handlers[:]:\n        logging.root.removeHandler(handler)\n\n    logger = logging.getLogger(context)\n    logger.propagate = False\n    if not logger.handlers:\n        logger.setLevel(logging.DEBUG if verbose else logging.INFO)\n        formatter = ColoredFormatter(\n            \'%(levelname)-.1s:\' + context +\n            \':[%(filename).3s:%(funcName).3s:%(lineno)3d]:%(message)s\',\n            datefmt=\'%m-%d %H:%M:%S\')\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(logging.DEBUG if verbose else logging.INFO)\n        console_handler.setFormatter(formatter)\n        logger.handlers = []\n        logger.addHandler(console_handler)\n\n    return logger\n\n\nclass NTLogger:\n    """"""Windows support for logger""""""\n    def __init__(self, context, verbose):\n        self.context = context\n        self.verbose = verbose\n        self.info = self.format_msg(\'I:%s:%s\')\n        self.debug = self.format_msg(\'D:%s:%s\')\n        self.error = self.format_msg(\'E:%s:%s\')\n        self.warning = self.format_msg(\'W:%s:%s\')\n\n    def format_msg(self, string_format: str):\n        """"""Format incoming logging messages with a given format""""""\n        def func(msg: str, **_):\n            """"""Function to replace incoming stream""""""\n            print(string_format % (self.context, msg), flush=True)\n        return func\n\n\nclass ColoredFormatter(logging.Formatter):\n    """"""Format log levels with color""""""\n    MAPPING = {\n        \'DEBUG\': dict(color=\'green\', on_color=None),\n        \'INFO\': dict(color=\'cyan\', on_color=None),\n        \'WARNING\': dict(color=\'yellow\', on_color=None),\n        \'ERROR\': dict(color=\'grey\', on_color=\'on_red\'),\n        \'CRITICAL\': dict(color=\'grey\', on_color=\'on_blue\'),\n    }\n\n    PREFIX = \'\\033[\'\n    SUFFIX = \'\\033[0m\'\n\n    def format(self, record):\n        """"""Add log ansi colors""""""\n        crecord = copy.copy(record)\n        seq = self.MAPPING.get(crecord.levelname, self.MAPPING[\'INFO\'])\n        crecord.msg = termcolor.colored(crecord.msg, **seq)\n        return super().format(crecord)\n'"
nboost/maps.py,0,"b""\n# class => module\nMODULE_MAP = {\n    'ShuffleRerankPlugin': 'plugins.rerank.shuffle',\n    'PtTransformersRerankPlugin': 'plugins.rerank.transformers',\n    'PtDistilBertQAModelPlugin': 'plugins.qa.distilbert'\n}\n\n# image => directory\nIMAGE_MAP = {\n    'alpine': '../Dockerfiles/alpine',\n    'pt': '../Dockerfiles/pt'\n}\n\nINDEXER_MAP = {\n    'SolrIndexer': 'indexers.solr',\n    'ESIndexer': 'indexers.es'\n}\n"""
nboost/proxy.py,0,"b'from time import perf_counter\nfrom typing import List\nfrom flask import (\n    request as flask_request,\n    Response as FlaskResponse,\n    send_from_directory,\n    jsonify,\n    Flask)\nfrom nboost.plugins.rerank.base import RerankModelPlugin\nfrom nboost.delegates import RequestDelegate, ResponseDelegate\nfrom nboost.plugins.qa.base import QAModelPlugin\nfrom nboost.plugins import resolve_plugin\nfrom nboost.plugins.debug import DebugPlugin\nfrom nboost import defaults, PKG_PATH\nfrom nboost.database import Database\nfrom nboost.logger import set_logger\nfrom nboost.plugins import Plugin\nfrom nboost.translators import *\nfrom json.decoder import JSONDecodeError\nfrom werkzeug.routing import Rule\n\nclass Proxy:\n    def __init__(self, host: type(defaults.host) = defaults.host,\n                 port: type(defaults.port) = defaults.port,\n                 verbose: type(defaults.verbose) = defaults.verbose,\n                 no_rerank: type(defaults.no_rerank) = defaults.no_rerank,\n                 model: type(defaults.model) = defaults.model,\n                 model_dir: type(defaults.model_dir) = defaults.model_dir,\n                 qa: type(defaults.qa) = defaults.qa,\n                 qa_model: type(defaults.qa_model) = defaults.qa_model,\n                 qa_model_dir: type(defaults.qa_model_dir) = defaults.qa_model_dir,\n                 frontend_route: type(defaults.frontend_route) = defaults.frontend_route,\n                 status_route: type(defaults.status_route) = defaults.status_route,\n                 debug: type(defaults.debug) = defaults.debug,\n                 **cli_args):\n        self.logger = set_logger(self.__class__.__name__, verbose=verbose)\n        db = Database()\n        plugins = []  # type: List[Plugin]\n\n        if not no_rerank:  # TODO: FIX SO WORKS WITH DYNAMIC SETTING\n            rerank_model_plugin = resolve_plugin(\n                model,\n                model_dir=model_dir,\n                **cli_args)  # type: RerankModelPlugin\n\n            plugins.append(rerank_model_plugin)\n\n        if qa:\n            qa_model_plugin = resolve_plugin(\n                qa_model,\n                model_dir=qa_model_dir,\n                **cli_args)  # type: QAModelPlugin\n\n            plugins.append(qa_model_plugin)\n\n        if debug:\n            debug_plugin = DebugPlugin(**cli_args)\n            plugins.append(debug_plugin)\n\n        static_dir = str(PKG_PATH.joinpath(\'resources/frontend\'))\n        flask_app = Flask(__name__)\n\n        @flask_app.route(frontend_route, methods=[\'GET\'])\n        def frontend_root():\n            return send_from_directory(static_dir, \'index.html\')\n\n        @flask_app.route(frontend_route + \'/<path:path>\', methods=[\'GET\'])\n        def frontend_path(path):\n            return send_from_directory(static_dir, path)\n\n        @flask_app.route(frontend_route + status_route)\n        def status_path():\n            configs = {}\n\n            for plugin in plugins:\n                configs.update(plugin.configs)\n\n            stats = db.get_stats()\n            return jsonify({**configs, **stats})\n\n        flask_app.url_map.add(Rule(\'/<path:path>\', endpoint=\'proxy\'))\n\n        @flask_app.route(\'/\', defaults={\'path\': \'\'})\n        @flask_app.endpoint(\'proxy\')\n        def proxy_through(path):\n            # parse the client request\n            dict_request = flask_request_to_dict_request(flask_request)  # takes the json\n\n            """"""Search request.""""""\n            db_row = db.new_row()\n\n            # combine command line args and runtime args sent by request\n            query_args = {}\n            for key in list(dict_request[\'url\'][\'query\']):\n                if key in defaults.__dict__:\n                    query_args[key] = dict_request[\'url\'][\'query\'].pop(key)\n            json_args = dict_request[\'body\'].pop(\'nboost\', {})\n            args = {**cli_args, **json_args, **query_args}\n\n            request = RequestDelegate(dict_request, **args)\n            request.dict[\'headers\'].pop(\'Host\', \'\')\n            request.set_path(\'url.headers.host\', \'%s:%s\' % (request.uhost, request.uport))\n            request.set_path(\'url.netloc\', \'%s:%s\' % (request.uhost, request.uport))\n            request.set_path(\'url.scheme\', \'https\' if request.ussl else \'http\')\n\n            for plugin in plugins:  # type: Plugin\n                plugin.on_request(request, db_row)\n\n            # get response from upstream server\n            start_time = perf_counter()\n            requests_response = dict_request_to_requests_response(dict_request)\n            db_row.response_time = perf_counter() - start_time\n            try:\n                dict_response = requests_response_to_dict_response(requests_response)\n            except JSONDecodeError:\n                print(requests_response.content)\n                return requests_response.content\n            response = ResponseDelegate(dict_response, request)\n            response.set_path(\'body.nboost\', {})\n            db_row.choices = len(response.choices)\n\n            for plugin in plugins:  # type: Plugin\n                plugin.on_response(response, db_row)\n\n            # save stats to sql lite\n            db.insert(db_row)\n\n            return dict_response_to_flask_response(dict_response)\n\n        @flask_app.errorhandler(Exception)\n        def handle_json_response(error):\n            self.logger.error(\'\', exc_info=True)\n            return jsonify({\n                \'type\': error.__class__.__name__,\n                \'doc\': error.__class__.__doc__,\n                \'msg\': str(error.args)\n            }), 500\n\n        self.run = lambda: (\n            self.logger.critical(\'LISTENING %s:%s\' % (host, port)) or\n            flask_app.run(host=host, port=port)\n        )\n'"
nboost/translators.py,0,"b'from urllib.parse import ParseResult, urlparse, parse_qsl, urlencode\nimport json\nfrom requests import Response as RequestsResponse, request as requests_request\nfrom flask import Response as FlaskResponse\nfrom werkzeug.local import LocalProxy\n\n__all__ = [\n    \'flask_request_to_dict_request\',\n    \'dict_request_to_requests_response\',\n    \'requests_response_to_dict_response\',\n    \'dict_response_to_flask_response\',\n    \'requests_response_to_flask_response\'\n]\n\n\ndef flask_request_to_dict_request(flask_request: LocalProxy) -> dict:\n    """"""Convert flask request to dict request.""""""\n    urllib_url = urlparse(flask_request.url)\n\n    return {\n        \'headers\': dict(flask_request.headers),\n        \'method\': flask_request.method,\n        \'url\': {\n            \'scheme\': urllib_url.scheme,\n            \'netloc\': urllib_url.netloc,\n            \'path\': urllib_url.path,\n            \'params\': urllib_url.params,\n            \'query\': dict(parse_qsl(urllib_url.query)),\n            \'fragment\': urllib_url.fragment\n        },\n        \'body\': dict(flask_request.json) if flask_request.json else {}\n    }\n\n\ndef flask_request_to_requests_response(flask_request: LocalProxy) -> RequestsResponse:\n    urllib_url = urlparse(flask_request.url)\n\n    return requests_request(\n        headers=flask_request.headers,\n        method=flask_request.method,\n        url=ParseResult(\n            scheme=urllib_url.scheme\n        )\n    )\n\n\ndef dict_request_to_requests_response(dict_request: dict) -> RequestsResponse:\n    return requests_request(\n        headers=dict_request[\'headers\'],\n        method=dict_request[\'method\'],\n        url=ParseResult(\n            scheme=dict_request[\'url\'][\'scheme\'],\n            netloc=dict_request[\'url\'][\'netloc\'],\n            path=dict_request[\'url\'][\'path\'],\n            params=dict_request[\'url\'][\'params\'],\n            query=urlencode(dict_request[\'url\'][\'query\'], quote_via=lambda x, *a: x),\n            fragment=dict_request[\'url\'][\'fragment\']\n        ).geturl(),\n        json=dict_request[\'body\']\n    )\n\n\ndef requests_response_to_dict_response(requests_response: RequestsResponse) -> dict:\n    requests_response.headers.pop(\'content-encoding\', \'\')\n    requests_response.headers.pop(\'content-length\', \'\')\n    requests_response.headers.pop(\'transfer-encoding\', \'\')\n    return {\n        \'status\': requests_response.status_code,\n        \'headers\': dict(requests_response.headers),\n        \'body\': requests_response.json()\n    }\n\n\ndef requests_response_to_flask_response(requests_response: RequestsResponse) -> FlaskResponse:\n    requests_response.headers.pop(\'content-encoding\', \'\')\n    requests_response.headers.pop(\'transfer-encoding\', \'\')\n    requests_response.headers.pop(\'content-length\', \'\')\n    return FlaskResponse(\n        response=requests_response.content,\n        status=requests_response.status_code,\n        headers=dict(requests_response.headers)\n    )\n\n\ndef dict_response_to_flask_response(dict_response: dict) -> FlaskResponse:\n    return FlaskResponse(\n        response=json.dumps(dict_response[\'body\']),\n        status=dict_response[\'status\'],\n        headers=dict_response[\'headers\'],\n    )'"
nboost/indexers/__init__.py,0,b''
nboost/indexers/__main__.py,0,"b'""""""nboost-indexer cli entrypoint""""""\nfrom nboost.indexers.cli import main\n\nif __name__ == \'__main__\':\n    main()\n'"
nboost/indexers/base.py,0,"b'from abc import abstractmethod\nfrom typing import Generator\nfrom nboost.helpers import count_lines\nfrom nboost.logger import set_logger\nfrom nboost.indexers import defaults\nfrom nboost import PKG_PATH\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport csv\n\n\nclass BaseIndexer:\n    """"""An object that sends a csv to a given search api.""""""\n\n    def __init__(self, file: type(defaults.file) = defaults.file,\n                 index_name: type(defaults.index_name) = defaults.index_name,\n                 id_col: type(defaults.id_col) = defaults.id_col,\n                 host: type(defaults.host) = defaults.host,\n                 port: type(defaults.port) = defaults.port,\n                 delim: type(defaults.delim) = defaults.delim,\n                 shards: type(defaults.shards) = defaults.shards,\n                 verbose: type(defaults.verbose) = defaults.verbose, **_):\n        """"""\n        :param name: name of the index\n        :param id_col: column number of the id\n        :param field_col: column number of the field data\n        :param field_name: name of the field\n        :param host: host of the search api server\n        :param port: port the the server\n        :param shards: number of shards for the index\n        """"""\n        self.file = file\n        self.index_name = index_name\n        self.id_col = id_col\n        self.host = host\n        self.port = port\n        self.delim = delim\n        self.shards = shards\n        self.logger = set_logger(self.__class__.__name__, verbose=verbose)\n\n    def csv_generator(self) -> Generator:\n        """"""Check for the csv in the current working directory first, then\n        search for it in the package.\n\n        Generates id_col, passage\n        """"""\n\n        cwd_path = Path().joinpath(self.file).absolute()\n        pkg_path = PKG_PATH.joinpath(\'resources\').joinpath(self.file)\n\n        if cwd_path.exists():\n            path = cwd_path\n        elif pkg_path.exists():\n            path = pkg_path\n        else:\n            self.logger.error(\'Could not find %s or %s\', pkg_path, cwd_path)\n            raise SystemExit\n\n        self.logger.info(\'Estimating completion size...\')\n        num_lines = count_lines(path)\n        with path.open() as file:\n            with tqdm(total=num_lines, desc=path.name) as pbar:\n                for cid, passage in csv.reader(file, delimiter=self.delim):\n                    yield cid, passage\n                    pbar.update()\n\n    @abstractmethod\n    def index(self):\n        """"""uses the csv_generator() to send the csv to the index""""""\n'"
nboost/indexers/cli.py,0,"b'""""""NBoost command line interface""""""\nfrom argparse import ArgumentParser\nfrom typing import List, Type\nimport termcolor\nfrom nboost.indexers.base import BaseIndexer\nfrom nboost.helpers import import_class\nfrom nboost.indexers import defaults\nfrom nboost.maps import INDEXER_MAP\n\n\nTAG = termcolor.colored(\'NBoost Indexer\', \'cyan\', attrs=[\'underline\'])\nDESCRIPTION = (\'This is the %s. This command line utility can be used to send \'\n               \'a csv to a search api for indexing.\' % TAG)\n\nFILE = \'path of the csv to send to the index\'\nINDEX_NAME = \'name of the index send to\'\nID_COL = \'whether to index each doc with an id (should be first col in csv)\'\nHOST = \'host of the search api server\'\nPORT = \'port of the server\'\nDELIM = \'csv delimiter\'\nSHARDS = \'number of index shards to create\'\nINDEXER = \'the indexer class\'\nVERBOSE = \'turn on detailed logging\'\n\n\ndef set_parser() -> ArgumentParser:\n    """"""Add default nboost-index cli arguments to a given parser""""""\n    parser = ArgumentParser(description=DESCRIPTION)\n    parser.add_argument(\'--verbose\', type=type(defaults.verbose), default=defaults.verbose, help=VERBOSE)\n    parser.add_argument(\'--file\', type=type(defaults.file), default=defaults.file, help=FILE)\n    parser.add_argument(\'--index_name\', type=type(defaults.index_name), default=defaults.index_name, help=INDEX_NAME)\n    parser.add_argument(\'--host\', type=type(defaults.host), default=defaults.host, help=HOST)\n    parser.add_argument(\'--port\', type=type(defaults.port), default=defaults.port, help=PORT)\n    parser.add_argument(\'--delim\', type=type(defaults.delim), default=defaults.delim, help=DELIM)\n    parser.add_argument(\'--shards\', type=type(defaults.shards), default=defaults.shards)\n    parser.add_argument(\'--id_col\', action=\'store_true\', help=ID_COL)\n    parser.add_argument(\'--indexer\', type=type(defaults.indexer), default=defaults.indexer, help=INDEXER)\n    return parser\n\n\ndef main(argv: List[str] = None):\n    parser = set_parser()\n    args = vars(parser.parse_args(argv))\n    indexer_class = args.pop(\'indexer\')\n    indexer_module = INDEXER_MAP[indexer_class]\n    indexer = import_class(indexer_module, indexer_class)  # type: Type[BaseIndexer]\n    indexer(**args).index()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
nboost/indexers/defaults.py,0,"b'""""""Default nboost-indexer command line arguments""""""\n\nfrom pathlib import Path\n\nverbose = False\nfile = Path(\'.\')\nindex_name = \'nboost\'\nhost = \'0.0.0.0\'\nport = 9200\ndelim = \'\\t\'\nshards = 5\nindexer = \'ESIndexer\'\nid_col = False\n'"
nboost/indexers/es.py,0,"b'from typing import Dict\nfrom elasticsearch.exceptions import RequestError\nfrom elasticsearch.helpers import bulk\nfrom elasticsearch import Elasticsearch\nfrom nboost.indexers.base import BaseIndexer\n\n\nclass ESIndexer(BaseIndexer):\n    """"""Index csvs in Elasticsearch""""""\n    def __init__(self, shards: int = 1, **kwargs):\n        super().__init__(**kwargs)\n        self.mapping = {\'settings\': {\'index\': {\'number_of_shards\': shards}}}\n\n    def format(self, passage: str, cid: str):\n        """"""Format a passage for indexing""""""\n        body = {\n            \'_index\': self.index_name,\n            \'_type\': \'_doc\',\n            \'_source\': {""passage"": passage}\n        }\n\n        if cid is not None:\n            body[\'_id\'] = cid\n\n        return body\n\n    def index(self):\n        """"""send csv to ES index""""""\n        self.logger.info(\'Setting up Elasticsearch index...\')\n        elastic = Elasticsearch(host=self.host, port=self.port, timeout=10000)\n        try:\n            self.logger.info(\'Creating index %s...\' % self.index_name)\n            elastic.indices.create(self.index_name, self.mapping)\n        except RequestError:\n            self.logger.info(\'Index already exists, skipping...\')\n\n        self.logger.info(\'Indexing %s...\' % self.file)\n        act = (self.format(passage, cid=cid) for cid, passage in self.csv_generator())\n        bulk(elastic, actions=act)\n'"
nboost/indexers/solr.py,0,"b'from typing import Dict\nfrom nboost.indexers.base import BaseIndexer\nfrom pysolr import Solr, SolrCoreAdmin\n\nclass SolrIndexer(BaseIndexer):\n    """"""Index csvs in Solr""""""\n    def __init__(self, shards: int = 1, **kwargs):\n        super().__init__(**kwargs)\n\n    def format(self, passage: str, cid: str):\n        """"""Format a passage for indexing""""""\n        body = {\n            \'passage_t\': passage\n        }\n\n        if cid is not None:\n            body[\'id\'] = cid\n\n        return body\n\n    def index(self):\n        """"""send csv to Solr index""""""\n        self.logger.info(\'Setting up Solr index...\')\n        solr = Solr(""http://{0}:{1}/solr/travel/"".format(self.host, self.port), timeout=10000)\n        \n        self.logger.info(\'Indexing %s...\' % self.file)\n        act = [self.format(passage, cid=cid) for cid, passage in self.csv_generator()]\n        solr.add(act)\n\n        solr.optimize()\n'"
nboost/plugins/__init__.py,0,"b'""""""Base Plugin module""""""\nfrom nboost.delegates import RequestDelegate, ResponseDelegate\nfrom nboost.database import DatabaseRow\nfrom nboost.helpers import import_class\nfrom nboost.maps import MODULE_MAP\n\n\ndef resolve_plugin(plugin, **cli_args):\n    model = import_class(MODULE_MAP[plugin], plugin)\n    return model(**cli_args)\n\n\nclass Plugin:\n    """"""A plugin has two callbacks, one on request and one on response. Each\n    callback, the plugin can get and set the respective messages. The plugin\n    can also add a value to the database row which show up in queries\n    to the /nboost/status path""""""\n    def __init__(self, **cli_args):\n        """"""Configure using command line args""""""\n\n    @property\n    def configs(self):\n        """"""Returns configs to be displayed on /nboost/status""""""\n        return {}\n\n    def on_request(self, request: RequestDelegate, db_row: DatabaseRow):\n        """"""Access request.""""""\n\n    def on_response(self, response: ResponseDelegate, db_row: DatabaseRow):\n        """"""Access response.""""""\n'"
nboost/plugins/debug.py,0,"b'from nboost.plugins import Plugin\nfrom nboost.delegates import ResponseDelegate\nfrom nboost.database import DatabaseRow\n\n\nclass DebugPlugin(Plugin):\n    """"""Adds the request and parsed server response values to the response.""""""\n    def on_response(self, response: ResponseDelegate, db_row: DatabaseRow):\n        response.set_path(\'body.nboost.topk\', db_row.topk)\n        response.set_path(\'body.nboost.topn\', response.request.topn)\n        response.set_path(\'body.nboost.query\', response.request.query)\n        response.set_path(\'body.nboost.choices\', response.choices)\n        response.set_path(\'body.nboost.cids\', response.cids)\n        response.set_path(\'body.nboost.cvalues\', response.cvalues)\n\n'"
nboost/plugins/prerank.py,0,"b'from nboost.plugins import Plugin\nfrom nboost.delegates import ResponseDelegate\nfrom nboost.database import DatabaseRow\nimport numpy as np\nfrom multiprocessing import Pool, cpu_count\nimport math\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport nltk\n\nnltk.download(\'stopwords\')\nnltk.download(\'punkt\')\n\n\nclass BM25:\n    def __init__(self, corpus, tokenizer=None):\n        self.corpus_size = len(corpus)\n        self.avgdl = 0\n        self.doc_freqs = []\n        self.idf = {}\n        self.doc_len = []\n        self.tokenizer = tokenizer\n\n        if tokenizer:\n            corpus = self._tokenize_corpus(corpus)\n\n        nd = self._initialize(corpus)\n        self._calc_idf(nd)\n\n    def _initialize(self, corpus):\n        nd = {}  # word -> number of documents with word\n        num_doc = 0\n        for document in corpus:\n            self.doc_len.append(len(document))\n            num_doc += len(document)\n\n            frequencies = {}\n            for word in document:\n                if word not in frequencies:\n                    frequencies[word] = 0\n                frequencies[word] += 1\n            self.doc_freqs.append(frequencies)\n\n            for word, freq in frequencies.items():\n                if word not in nd:\n                    nd[word] = 0\n                nd[word] += 1\n\n        self.avgdl = num_doc / self.corpus_size\n        return nd\n\n    def _tokenize_corpus(self, corpus):\n        pool = Pool(cpu_count())\n        tokenized_corpus = pool.map(self.tokenizer, corpus)\n        return tokenized_corpus\n\n    def _calc_idf(self, nd):\n        raise NotImplementedError()\n\n    def get_scores(self, query):\n        raise NotImplementedError()\n\n    def get_top_n(self, query, documents, n=5):\n\n        assert self.corpus_size == len(documents), ""The documents given don\'t match the index corpus!""\n\n        scores = self.get_scores(query)\n        top_n = np.argsort(scores)[::-1][:n]\n        return [documents[i] for i in top_n]\n\n\nclass BM25Okapi(BM25):\n    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n        self.k1 = k1\n        self.b = b\n        self.epsilon = epsilon\n        super().__init__(corpus, tokenizer)\n\n    def _calc_idf(self, nd):\n        """"""\n        Calculates frequencies of terms in documents and in corpus.\n        This algorithm sets a floor on the idf values to eps * average_idf\n        """"""\n        # collect idf sum to calculate an average idf for epsilon value\n        idf_sum = 0\n        # collect words with negative idf to set them a special epsilon value.\n        # idf can be negative if word is contained in more than half of documents\n        negative_idfs = []\n        for word, freq in nd.items():\n            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n            self.idf[word] = idf\n            idf_sum += idf\n            if idf < 0:\n                negative_idfs.append(word)\n        self.average_idf = idf_sum / len(self.idf)\n\n        eps = self.epsilon * self.average_idf\n        for word in negative_idfs:\n            self.idf[word] = eps\n\n    def get_scores(self, query):\n        """"""\n        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n        this algorithm also adds a floor to the idf value of epsilon.\n        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n        :param query:\n        :return:\n        """"""\n        score = np.zeros(self.corpus_size)\n        doc_len = np.array(self.doc_len)\n        for q in query:\n            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n        return score\n\n\nclass PrerankPlugin(Plugin):\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.ps = PorterStemmer()\n\n    def on_response(self, response: ResponseDelegate, db_row: DatabaseRow):\n        query = response.request.query\n        choices = response.cvalues\n\n        corpus = [self.tokenize(choice) for choice in choices]\n        bm25 = BM25Okapi(corpus)\n        ranks = np.argsort(bm25.get_scores(self.tokenize(query)))[::-1]\n\n        reranked_choices = [response.choices[rank] for rank in ranks]\n        response.choices = reranked_choices\n\n        response.choices = response.choices[:50]\n\n    def tokenize(self, paragraph):\n        words = [self.ps.stem(word) for word in word_tokenize(paragraph)]\n        filtered_words = [word for word in words if word not in stopwords.words(\'english\')]\n        return filtered_words\n\n    def rank(self, query, choices):\n        pass\n'"
tests/integration/test_benchmark.py,0,"b""import requests, csv\nfrom collections import defaultdict\n\n\nwith open('qrels.dev.small.tsv') as file:\n    qid_map = defaultdict(list)\n    for qid, _, cid, _ in csv.reader(file, delimiter='\\t'):\n        qid_map[qid].append(cid)\n\nwith open('queries.dev.small.tsv') as file:\n    for qid, query in csv.reader(file, delimiter='\\t'):\n        cids = qid_map[qid]\n        print(requests.post(\n            url='http://localhost:8000/ms_marco/_search',\n            json={\n                'nboost': {\n                    'rerank_cids': cids,\n                }\n            },\n            params={\n              'q': query,\n            }\n        ).json())"""
tests/integration/test_es_indexer.py,0,"b'from nboost.indexers.cli import main\nimport subprocess\nimport unittest\nimport requests\nimport time\n\nclass TestESIndexer(unittest.TestCase):\n    def test_travel_tutorial(self):\n        subprocess.call(\'docker pull elasticsearch:7.4.2\', shell=True)\n        subprocess.call(""docker rm -f es_integration"", shell=True)\n\n        subprocess.call(\'docker run -d -p 9200:9200 -p 9300:9300 --name es_integration \'\n                        \'-e ""discovery.type=single-node"" elasticsearch:7.4.2\',\n                        shell=True)\n\n        #TODO: check if the core is ready by the api\n        time.sleep(20.0)\n\n        # dump es index\n        main([\n            \'--verbose\', \'True\',\n            \'--port\', \'9200\',\n            \'--file\', \'travel.csv\',\n            \'--index_name\', \'travel\',\n            \'--id_col\',\n            \'--delim\', \',\'\n        ])\n\n        # search\n        params = dict(size=2, q=\'passage:hotels in vegas, baby\')\n\n        proxy_res = requests.get(\'http://localhost:9200/travel/_search\', params=params)\n        self.assertTrue(proxy_res.ok)\n        \n        subprocess.call(""docker rm -f es_integration"", shell=True)\n'"
tests/integration/test_proxy.py,0,"b'from nboost.proxy import Proxy\nimport subprocess\nimport unittest\nimport requests\nfrom threading import Thread\nfrom elasticsearch import Elasticsearch\nimport time\nfrom pprint import pprint\n\n\nclass TestProxy(unittest.TestCase):\n    def test_travel_tutorial(self):\n        subprocess.call(\'docker pull elasticsearch:7.4.2\', shell=True)\n        subprocess.call(\'docker run -d -p 9200:9200 -p 9300:9300 \'\n                        \'-e ""discovery.type=single-node"" elasticsearch:7.4.2\',\n                        shell=True)\n\n        for _ in range(5):\n            Elasticsearch().index(index=\'example\', body={\'field\': \'value\'})\n\n        proxy = Proxy(\n            model_dir=\'shuffle-model\',\n            model=\'ShuffleRerankPlugin\',\n            uport=9200,\n            debug=True,\n            verbose=True, query_prep=\'lambda query: query.split("":"")[-1]\'\n        )\n\n        t = Thread(target=proxy.run)\n        t.start()\n        time.sleep(2)\n\n        # search\n        proxy_res = requests.get(\n            \'http://localhost:8000/example/_search\',\n            params={\n                \'q\': \'field:value\',\n                \'size\': 3,\n                \'topn\': 20\n            }\n        )\n\n        self.assertTrue(proxy_res.ok)\n        pprint(proxy_res.json())\n        response = proxy_res.json()[\'nboost\']\n        self.assertEqual(\'value\', response[\'query\'])\n        self.assertEqual(3, response[\'topk\'])\n        self.assertEqual(20, response[\'topn\'])\n        self.assertEqual(3, len(response[\'cvalues\']))\n\n        # fallback\n        # fallback_res = requests.get(\'http://localhost:8000/\')\n        # self.assertTrue(fallback_res.ok)\n        # print(fallback_res.content.decode())\n\n        # status\n        status_res = requests.get(\'http://localhost:8000/nboost/status\')\n        self.assertTrue(status_res.ok)\n        print(status_res.content.decode())\n\n        # invalid host\n        invalid_res = requests.get(\'http://localhost:8000/example/_search\', params={\'uport\': 2000})\n        print(invalid_res.content)\n        self.assertFalse(invalid_res.ok)\n\n        t.join()\n'"
tests/integration/test_solr_indexer.py,0,"b'from nboost.indexers.cli import main\nimport subprocess\nimport unittest\nimport requests\nimport time\nimport sys\n\nclass TestSolrIndexer(unittest.TestCase):\n    def test_travel_tutorial(self):\n        subprocess.call(\'docker pull solr:8.5.1\', shell=True)\n        subprocess.call(""docker rm -f solr_integration"", shell=True)\n        subprocess.call(\'docker run -d -p 8983:8983 --name solr_integration -t solr solr-precreate travel\', shell=True)\n\n        #TODO: check if the core is ready by the api\n        time.sleep(20.0)\n\n        # dump es index\n        main([\n            \'--verbose\', \'True\',\n            \'--port\', \'8983\',\n            \'--file\', \'travel.csv\',\n            \'--index_name\', \'travel\',\n            \'--id_col\',\n            \'--delim\', \',\',\n            \'--indexer\', \'SolrIndexer\'\n        ])\n\n        # search\n        params = dict(size=2, q=\'passage_t:hotels in vegas, baby\')\n\n        proxy_res = requests.get(\'http://localhost:8983/solr/travel/select\', params=params)\n        self.assertTrue(proxy_res.ok)\n        \n        subprocess.call(""docker rm -f solr_integration"", shell=True)\n\n'"
tests/unit/test_delegates.py,0,"b'import unittest\nfrom nboost.delegates import RequestDelegate, ResponseDelegate\n\n\nclass TestDelegates(unittest.TestCase):\n    def test_request_1(self):\n        request = RequestDelegate({\n            \'body\': {\n                ""from"": 0,\n                ""size"": 20,\n                ""query"": {\n                    ""term"": {""user"": ""kimchy""}\n                },\n                ""nboost"": {\n                    ""cids"": [\'0\', \'2\']\n                }\n            }\n        })\n\n        self.assertEqual(""kimchy"", request.query)\n        self.assertEqual(20, request.topk)\n\n    def test_request_2(self):\n        request = RequestDelegate({\n            \'url\': {\n                ""query"": {""q"": ""message:test query"", ""size"": 20}\n            }\n        })\n        self.assertEqual(""message:test query"", request.query)\n\n    def test_request_3(self):\n        request = RequestDelegate({\n            \'body\': {\n                ""query"": {\n                    ""match"": ""hello there""\n                },\n            }\n        })\n\n        self.assertEqual(""hello there"", request.query)\n\n    def test_request_4(self):\n        request = RequestDelegate({\n            \'body\': {\n                ""size"": 11,\n                ""query"": {\n                    ""function_score"": {\n                        ""query"": {\n                            ""bool"": {\n                                ""should"": [\n                                    {\n                                        ""match"": {\n                                            ""text"": {\n                                                ""query"": ""query one"",\n                                                ""operator"": ""and""\n                                            }\n                                        }\n                                    },\n                                    {\n                                        ""match"": {\n                                            ""text"": {\n                                                ""query"": ""query two"",\n                                                ""operator"": ""or""\n                                            }\n                                        }\n                                    }\n                                ]\n                            }\n                        },\n                        ""script_score"": {\n                            ""script"": {\n                                ""source"": ""1 + ((5 - doc[\\""priority\\""].value) / 10.0) + ((doc[\\""branch\\""].value == \\""All\\"") ? 0.5 : 0)""\n                            }\n                        }\n                    }\n                }\n            }\n        },\n        query_path=\'body.query.function_score.query.bool.should.[*].match.text.query\'\n        )\n\n        self.assertEqual(\'query one. query two\', request.query)\n\n    def test_request_5(self):\n        request = RequestDelegate({\n            \'body\': {\n                ""id"": ""searchTemplate"",\n                ""params"": {\n                    ""query"": ""my query"",\n                    ""from"": 0,\n                    ""size"": 9\n                }\n            }\n        },\n        query_path=\'body.params.query\'\n        )\n        self.assertEqual(\'my query\', request.query)\n\n    def test_response_1(self):\n        response = ResponseDelegate({\n            \'body\': {\n                ""nboost"": {\'cvalues_path\': \'_source.message\'},\n                ""took"": 5,\n                ""timed_out"": False,\n                ""_shards"": {\n                    ""total"": 1,\n                    ""successful"": 1,\n                    ""skipped"": 0,\n                    ""failed"": 0\n                },\n                ""hits"": {\n                    ""total"": {\n                        ""value"": 1,\n                        ""relation"": ""eq""\n                    },\n                    ""max_score"": 1.3862944,\n                    ""hits"": [\n                        {\n                            ""_index"": ""twitter"",\n                            ""_type"": ""_doc"",\n                            ""_id"": ""0"",\n                            ""_score"": 1.4,\n                            ""_source"": {\n                                ""message"": ""trying out Elasticsearch"",\n                            }\n                        }, {\n                            ""_index"": ""twitter"",\n                            ""_type"": ""_doc"",\n                            ""_id"": ""1"",\n                            ""_score"": 1.34245,\n                            ""_source"": {\n                                ""message"": ""second result"",\n                            }\n                        },\n                        {\n                            ""_index"": ""twitter"",\n                            ""_type"": ""_doc"",\n                            ""_id"": ""2"",\n                            ""_score"": 1.121234,\n                            ""_source"": {\n                                ""message"": ""third result"",\n                            }\n                        }\n                    ]\n                }\n            }\n        }, RequestDelegate({}))\n\n        self.assertEqual(1.4, response.choices[0][\'_score\'])\n\n        self.assertEqual([""trying out Elasticsearch"", ""second result"", ""third result""], response.cvalues)\n        self.assertEqual([\'0\', \'1\', \'2\'], response.cids)\n\n\n\n\n\n\n\n\n\n\n'"
tests/unit/test_onnx_bert_rerank.py,0,"b""# from nboost.plugins.models import resolve_model\n# from nboost import defaults\n# import unittest\n# import numpy as np\n#\n#\n# class TestPtBertRerankModelPlugin(unittest.TestCase):\n#     def setUp(self):\n#         self.model = resolve_model(\n#             model_dir='onnx-bert-base-msmarco',\n#             data_dir=defaults.data_dir,\n#             model_cls=''\n#         )\n#         self.pt_model = resolve_model(\n#             model_dir='pt-bert-base-uncased-msmarco',\n#             data_dir=defaults.data_dir,\n#             model_cls=''\n#         )\n#\n#     def test_rank(self):\n#         QUERY = 'O wherefore art thou'\n#         ranks, scores = self.model.rank(QUERY, CHOICES)\n#         self.assertEqual(self.model.__class__.__name__, 'ONNXBertRerankModelPlugin')\n#         self.assertIsInstance(ranks, list)\n#         self.assertEqual(6, len(ranks))\n#         pt_ranks, pt_scores = self.pt_model.rank(QUERY, CHOICES)\n#         assert np.allclose(pt_scores, scores, rtol=1e-04, atol=1e-05)\n#\n#     def tearDown(self) -> None:\n#         self.model.close()\n\n\nCHOICES = [\n    'From fairest creatures we desire increase' * 4,\n    'That thereby beautys rose might never die' * 4,\n    'But as the riper should by time decease' * 4,\n    'His tender heir might bear his memory:' * 4,\n    'But thou contracted to thine own bright eyes' * 4,\n    'Feedst thy lights flame with self-substantial fuel' * 4,\n]"""
tests/unit/test_pt_bert_model.py,0,"b'from nboost.plugins import resolve_plugin\nfrom nboost import defaults\nimport unittest\nfrom random import shuffle\n\n\nclass TestPtTransformersRerankPlugin(unittest.TestCase):\n    def setUp(self):\n        self.model = resolve_plugin(\n            \'PtTransformersRerankPlugin\',\n            model_dir=\'nboost/pt-bert-base-uncased-msmarco\',\n        )\n        shuffle(CHOICES)\n\n    def test_rank(self):\n        ranks, scores = self.model.rank(\'O wherefore art thou\', CHOICES)\n        self.assertEqual(self.model.__class__.__name__, \'PtTransformersRerankPlugin\')\n        self.assertIsInstance(ranks, list)\n        self.assertEqual(len(CHOICES), len(ranks))\n\n    def test_filter(self):\n        ranks, scores = self.model.rank(\'What is fish oil?\', CHOICES, filter_results=True)\n        self.assertEqual(""EPA Fish Oil can be defined as fish oil that contains a high concentration   of EPA. EPA (Eicosapentaenoic Acid) and DHA (Docosahexaenoic Acid) are both   Omega 3 essential Fatty Acids, both of which are beneficial in their own right.   However, research has shown that EPA can be more effective, over time, when   there is less DHA to compete with it. Therefore, to be considered a high EPA   fish oil, we would want to see a much higher concentration of EPA than DHA.   There are some fish oils claiming EPA/DHA ratios in the region of 8 to 1, but   not many. Pure EPA fish oil, on the other hand, contains no DHA at all, and   as such, has an EPA concentration of 93%, arguably one of the strongest and most concentrated, high-grade EPA fish oils on the market today."",\n                         CHOICES[ranks[0]])\n        self.assertIsInstance(ranks, list)\n        self.assertEqual(2, len(ranks))\n\n        # ranks, scores = self.model.rank(\'His tender heir\', CHOICES[:1], filter_results=True)\n        # self.assertIsInstance(ranks, list)\n        # self.assertEqual(0, len(ranks))\n\n    def tearDown(self) -> None:\n        self.model.close()\n\n\nCHOICES = [\'EPA Fish Oil can be defined as fish oil that contains a high concentration   of EPA. EPA (Eicosapentaenoic Acid) and DHA (Docosahexaenoic Acid) are both   Omega 3 essential Fatty Acids, both of which are beneficial in their own right.   However, research has shown that EPA can be more effective, over time, when   there is less DHA to compete with it. Therefore, to be considered a high EPA   fish oil, we would want to see a much higher concentration of EPA than DHA.   There are some fish oils claiming EPA/DHA ratios in the region of 8 to 1, but   not many. Pure EPA fish oil, on the other hand, contains no DHA at all, and   as such, has an EPA concentration of 93%, arguably one of the strongest and most concentrated, high-grade EPA fish oils on the market today.\', \'Sustainable , Strong  Wild Fish Oil.\', \'What Is Epa Fish Oil?\', \'Pure EPA Fish Oil, Benefiting People All Over The World Since 2005.\', \'*Pure EPA is a powerful pharmaceutical grade omega 3 fish oil\', \'*A unique product containing the purest form of ethyl EPA fish oil in the UK\', \'Surpasses International fish  oil standards\', \'Doctor\xe2\x80\x99s advice\', \'Due to the overwhelming success of this special offer it will be extend until futher notice.\', \'Testimonial\', \'Strong , Clean, Premium  Effective\', \'Results may vary, this is an individual testimonial.\', \'(Box of 60 capsules)\', \'FREE newsletter, all the latest knowledge in health and lifestyle \xe2\x86\x92\', \'Pure EPA Essential Oil Blend\', \'Postage & Packing\\n\\t\\t\\t\\t\\t\\tMainland UK: \\t\xc2\xa32.50 | Rest of EU: \\t\xc2\xa33.00 | Rest of World: \xc2\xa33.50\\n\\t\\t\\t\\t\\t\\tOrder 6 items or more: FREE delivery.\', \'Essential oil Pure EPA is available exclusively from mind 1st.\\n\\t\\t\\t\\t\\t\\t\\tMind1st Information Line: 01772 877925\', \'I think diet is the foundation for health. If somebody isn\xe2\x80\x99t physically healthy ,then you can\xe2\x80\x99t expect to be healthy. You actually need to have EPA molecules in order to get good membranes for your cells so they function properly. Read more about Dr Myers\', \'I started taking pure EPA three months ago for my general health. I am pleased to report an interesting side effect following taking the EPA. Two months after starting to take it, I no longer have any period pain or PMS. I have suffered badly for 30 years and up until last month had always spent a few days in bed. Last month \xe2\x80\x93 nothing! Not a twinge, not an ache, not tired. That is the first time in my whole life I have had a problem free period.\']'"
tests/unit/test_pt_distilbert_qa_model.py,0,"b""from nboost.plugins import resolve_plugin\nimport unittest\n\n\nclass TestPtDistilBertQAModel(unittest.TestCase):\n\n    def setUp(self):\n        self.qa_model = resolve_plugin(\n            'PtDistilBertQAModelPlugin',\n            model_dir='distilbert-base-uncased-distilled-squad',\n            max_seq_length=32\n        )\n\n    def test_rank(self):\n        QUESTION = 'Who bears his memory?'\n        answer, start_pos, end_pos, score = self.qa_model.get_answer(QUESTION, CONTEXT)\n        self.assertEqual(answer, 'His tender heir')\n        self.assertEqual(answer, CONTEXT[start_pos:end_pos])\n\n    def test_long_rank(self):\n        QUESTION = 'Who contracted to thine own bright eyes?'\n        answer, start_pos, end_pos, score = self.qa_model.get_answer(QUESTION*10, CONTEXT)\n        self.assertEqual(answer, '')\n        answer, start_pos, end_pos, score = self.qa_model.get_answer(QUESTION, CONTEXT)\n        self.assertEqual(answer, 'His tender heir might bear his memory, but thou')\n\n    def test(self):\n        QUESTION = 'maps site:smallwebsite.us'\n        CONTEXT = '''High School ReUnion Small Website \xe2\x80\x93 including a custom memorable High School ReUnion domain name. Bring old classmates together with an awesome class reunion website. For $500 you get a custom School ReUnion domain name, a 5 Page secure (httpS) website with maps, and a TEXT widget to capture re-union staff \xe2\x80\x93 TEXT Messages \xe2\x80\x93 [\xe2\x80\xa6]'''\n        answer, start_pos, end_pos, score = self.qa_model.get_answer(QUESTION, CONTEXT)\n        QUESTION = 'relax'\n        CONTEXT = '''High School ReUnion Small Website \xe2\x80\x93 including a custom memorable High School ReUnion domain name. Bring old classmates together with an awesome class reunion website. For $500 you get a custom School ReUnion domain name, a 5 Page secure (httpS) website with maps, and a TEXT widget to capture re-union staff \xe2\x80\x93 TEXT Messages \xe2\x80\x93 [\xe2\x80\xa6]'''\n        answer, start_pos, end_pos, score = self.qa_model.get_answer(QUESTION, CONTEXT)\n\n\n\nCONTEXT = 'His tender heir might bear his memory, but thou contracted to thine own bright eyes'\n"""
nboost/plugins/qa/__init__.py,0,b''
nboost/plugins/qa/base.py,0,"b'from typing import Tuple\nimport time\nfrom nboost.plugins import Plugin\nfrom nboost.delegates import ResponseDelegate\nfrom nboost.database import DatabaseRow\nfrom nboost import defaults\n\n\nclass QAModelPlugin(Plugin):\n    def __init__(self,\n                 max_query_length: type(defaults.max_query_length) = defaults.max_query_length,\n                 model_dir: str = defaults.qa_model_dir,\n                 max_seq_len: int = defaults.max_seq_len,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self.model_dir = model_dir\n        self.max_query_length = max_query_length\n        self.max_seq_len = max_seq_len\n\n    def on_response(self, response: ResponseDelegate, db_row: DatabaseRow):\n        if response.cvalues:\n            start_time = time.perf_counter()\n\n            answer, start_pos, stop_pos, score = self.get_answer(response.request.query, response.cvalues[0])\n\n            db_row.qa_time = time.perf_counter() - start_time\n\n            print(answer, start_pos, stop_pos, score)\n            if score > response.request.qa_threshold:\n                response.set_path(\'body.nboost.answer_text\', answer)\n                response.set_path(\'body.nboost.answer_start_pos\', start_pos)\n                response.set_path(\'body.nboost.answer_stop_pos\', stop_pos)\n\n    def get_answer(self, query: str, cvalue: str) -> Tuple[str, int, int, float]:\n        """"""Return answer, start_pos, end_pos, score""""""\n        raise NotImplementedError()\n'"
nboost/plugins/qa/distilbert.py,0,"b'from typing import Tuple\nfrom transformers import DistilBertForQuestionAnswering, DistilBertTokenizer\nimport numpy as np\nimport torch\nfrom nboost.plugins.qa.base import QAModelPlugin\n\n\ndef _is_whitespace(c):\n    if c in "" \\t\\r\\n"" or ord(c) == 0x202F:\n        return True\n    return False\n\n\nclass PtDistilBertQAModelPlugin(QAModelPlugin):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.model = DistilBertForQuestionAnswering.from_pretrained(self.model_dir)\n        self.tokenizer = DistilBertTokenizer.from_pretrained(self.model_dir)\n        self.device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n        self.model.to(self.device)\n\n    def get_answer(self, query: str, choice: str) -> Tuple[str, int, int, float]:\n        """"""Return (answer, (start_pos, end_pos), score)""""""\n        doc_tokens = []\n        char_to_word_offset = []\n        prev_is_whitespace = True\n\n        # Split on whitespace so that different tokens may be attributed to\n        # their original position.\n        for c in choice:\n            if _is_whitespace(c):\n                prev_is_whitespace = True\n            else:\n                if prev_is_whitespace:\n                    doc_tokens.append(c)\n                else:\n                    doc_tokens[-1] += c\n                prev_is_whitespace = False\n            char_to_word_offset.append(len(doc_tokens) - 1)\n\n        tok_to_orig_index = []\n        all_doc_tokens = []\n        for (i, token) in enumerate(doc_tokens):\n            sub_tokens = self.tokenizer.tokenize(token)\n            for sub_token in sub_tokens:\n                tok_to_orig_index.append(i)\n                all_doc_tokens.append(sub_token)\n\n        truncated_query = self.tokenizer.encode(query,\n                                                add_special_tokens=False,\n                                                max_length=self.max_query_length)\n\n        encoded_dict = self.tokenizer.encode_plus(\n            truncated_query,\n            all_doc_tokens,\n            max_length=self.max_seq_len,\n            return_tensors=\'pt\'\n        )\n\n        self.model.eval()\n        with torch.no_grad():\n            start_logits, end_logits = self.model(\n                input_ids=encoded_dict[\'input_ids\'].to(self.device))\n            start_logits, end_logits = start_logits.cpu(), end_logits.cpu()\n            # add +2 for [CLS] and [SEP], and cut out last [SEP]\n            start_logits = start_logits[0][len(truncated_query) + 2:-1]\n            end_logits = end_logits[0][len(truncated_query) + 2:-1]\n\n        assert len(end_logits) == len(tok_to_orig_index) or len(end_logits) - \\\n               self.max_seq_len - len(truncated_query) <= 3\n\n        if len(start_logits) == 0:\n            return \'\', 0, 0, 0\n\n        max_score = start_logits[0] + end_logits[-1]\n        start_tok = 0\n        end_tok = len(end_logits) - 1\n        for i, start_logit in enumerate(start_logits[:-1]):\n            end_logit_pos = np.argmax(end_logits[i+1:]) + i + 1\n            score = start_logit + end_logits[end_logit_pos]\n            if score > max_score:\n                max_score = score\n                start_tok = i\n                end_tok = end_logit_pos\n\n        answer = \' \'.join(doc_tokens[\n                          tok_to_orig_index[start_tok]\n                          :tok_to_orig_index[end_tok] + 1])\n        start_char_offset = char_to_word_offset.index(\n            tok_to_orig_index[start_tok])\n        end_tok_offset = tok_to_orig_index[end_tok] + 1\n        if end_tok_offset in char_to_word_offset:\n            end_char_offset = char_to_word_offset.index(end_tok_offset) - 1\n        else:\n            end_char_offset = len(char_to_word_offset) - 1\n        return answer, start_char_offset, end_char_offset, float(max_score)\n'"
nboost/plugins/rerank/__init__.py,0,b''
nboost/plugins/rerank/base.py,0,"b'""""""Base Class for ranking models""""""\n\nfrom typing import List, Tuple\nimport time\nfrom nboost.plugins import Plugin\nfrom nboost.delegates import RequestDelegate, ResponseDelegate\nfrom nboost.helpers import calculate_mrr\nfrom nboost.database import DatabaseRow\nfrom nboost import defaults\n\nimport numpy as np\n\n\nclass RerankModelPlugin(Plugin):\n    """"""Base class for reranker models""""""\n\n    def on_request(self, request: RequestDelegate, db_row: DatabaseRow):\n        db_row.topk = request.topk if request.topk else request.default_topk\n        request.topk = request.topn\n\n    def on_response(self, response: ResponseDelegate, db_row: DatabaseRow):\n\n        if response.request.rerank_cids:\n            db_row.server_mrr = calculate_mrr(\n                correct=response.request.rerank_cids.list,\n                guesses=response.cids\n            )\n\n        start_time = time.perf_counter()\n\n        ranks, scores = self.rank(\n            query=response.request.query,\n            choices=response.cvalues,\n            filter_results=response.request.filter_results\n        )\n        db_row.rerank_time = time.perf_counter() - start_time\n\n        # raise helpful error if choices is shorter than ranks\n        reranked_choices = [response.choices[rank] for rank in ranks]\n\n        response.choices = reranked_choices\n        response.set_path(\'body.nboost.scores\', list([float(score) for score in scores]))\n\n        if response.request.rerank_cids:\n            db_row.model_mrr = calculate_mrr(\n                correct=response.request.rerank_cids.list,\n                guesses=response.cids\n            )\n\n        response.choices = response.choices[:db_row.topk]\n\n    def rank(self, query: str, choices: List[str],\n             filter_results=defaults.filter_results\n             ) -> Tuple[List[int], List[float]]:\n        """"""assign relative ranks to each choice""""""\n        if len(choices) == 0:\n            return [], []\n\n        logits = self.get_logits(query, choices)\n        scores = []\n        all_scores = []\n        index_map = []\n        for i, logit in enumerate(logits):\n            neg_logit = logit[0]\n            score = logit[1]\n            all_scores.append(score)\n            if score > neg_logit or not filter_results:\n                scores.append(score)\n                index_map.append(i)\n        sorted_indices = [index_map[i] for i in np.argsort(scores)[::-1]]\n        return sorted_indices, [all_scores[i] for i in sorted_indices]\n\n    def get_logits(self, query: str, choices: List[str]):\n        """"""get search ranking logits for query, choices""""""\n        raise NotImplementedError()\n\n    def close(self):\n        """"""Close the model""""""\n'"
nboost/plugins/rerank/onnxbert.py,0,"b'from transformers import AutoTokenizer\nfrom typing import List\nimport numpy as np\nfrom nboost.plugins.models.rerank.base import RerankModelPlugin\nfrom nboost import defaults\nimport onnxruntime as rt\nimport glob\nimport os\n\n\nclass ONNXBertRerankModelPlugin(RerankModelPlugin):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        sess_options = rt.SessionOptions()\n\n        self.model_dir = glob.glob(os.path.join(self.model_dir, \'*.onnx\'))[0]\n\n        # Set graph optimization level to ORT_ENABLE_EXTENDED to enable bert optimization.\n        sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n\n        # To enable model serialization and store the optimized graph to desired location.\n        sess_options.optimized_model_filepath = self.model_dir\n        self.session = rt.InferenceSession(self.model_dir, sess_options)\n        if \'albert\' in self.model_dir:\n            self.tokenizer = AutoTokenizer.from_pretrained(\'albert-base-uncased\')\n        else:\n            self.tokenizer = AutoTokenizer.from_pretrained(\'bert-base-uncased\')\n\n    def rank(self, query: str, choices: List[str],\n             filter_results=defaults.filter_results):\n        """"""\n        :param query:\n        :param choices:\n        :param filter_results:\n        :return:\n        """"""\n        if len(choices) == 0:\n            return [], []\n        input_ids, attention_mask, token_type_ids = self.encode(query, choices)\n\n        logits = np.array(self.session.run(None, {\n            \'input_ids\': np.array(input_ids), #.reshape(-1, self.max_seq_len),\n            \'input_mask\': np.array(attention_mask), #.reshape(-1, self.max_seq_len),\n            \'segment_ids\': np.array(token_type_ids) #.reshape(-1, self.max_seq_len)\n        }))[0]\n\n        scores = []\n        all_scores = []\n        index_map = []\n        for i, logit in enumerate(logits):\n            neg_logit = logit[0]\n            score = logit[1]\n            all_scores.append(score)\n            if score > neg_logit or not filter_results:\n                scores.append(score)\n                index_map.append(i)\n        sorted_indices = [index_map[i] for i in np.argsort(scores)[::-1]]\n        return sorted_indices, [all_scores[i] for i in sorted_indices]\n\n    def encode(self, query: str, choices: List[str]):\n        """"""\n        :param query:\n        :param choices:\n        :return:\n        """"""\n        inputs = [self.tokenizer.encode_plus(query, choice, add_special_tokens=True)\n                  for choice in choices]\n\n        max_len = min(max(len(t[\'input_ids\']) for t in inputs), self.max_seq_len)\n        input_ids = [t[\'input_ids\'][:max_len] +\n                     [0] * (max_len - len(t[\'input_ids\'][:max_len])) for t in inputs]\n        attention_mask = [[1] * len(t[\'input_ids\'][:max_len]) +\n                          [0] * (max_len - len(t[\'input_ids\'][:max_len])) for t in inputs]\n        token_type_ids = [t[\'token_type_ids\'][:max_len] +\n                          [0] * (max_len - len(t[\'token_type_ids\'][:max_len])) for t in inputs]\n\n        # input_ids = torch.tensor(input_ids).to(self.device, non_blocking=True)\n        # attention_mask = torch.tensor(attention_mask).to(self.device, non_blocking=True)\n        # token_type_ids = torch.tensor(token_type_ids).to(self.device, non_blocking=True)\n\n        return input_ids, attention_mask, token_type_ids'"
nboost/plugins/rerank/shuffle.py,0,"b'""""""Shuffle model""""""\n\nfrom nboost.plugins.rerank.base import RerankModelPlugin\nimport numpy as np\n\n\nclass ShuffleRerankPlugin(RerankModelPlugin):\n    """"""Model that randomly shuffles choices. Useful for benchmarking/testing""""""\n    def get_logits(self, query, choices, **kwargs):\n        """"""random shuffle with no regard for query""""""\n        return np.random.uniform(0, 1, (len(choices), 2))\n'"
nboost/plugins/rerank/transformers.py,0,"b'\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom typing import List\nimport torch.nn\nimport torch\nfrom nboost.plugins.rerank.base import RerankModelPlugin\nfrom nboost import defaults\nfrom nboost.logger import set_logger\n\n\nclass PtTransformersRerankPlugin(RerankModelPlugin):\n    """"""Reranker models based on huggingface/transformers library""""""\n\n    def __init__(self,\n                 model_dir: str = \'nboost/pt-tinybert-msmarco\',\n                 verbose: bool = defaults.verbose,\n                 max_seq_len: int = defaults.max_seq_len,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self.logger = set_logger(model_dir, verbose=verbose)\n        self.max_seq_len = max_seq_len\n\n        self.logger.info(\'Loading from checkpoint %s\' % model_dir)\n        self.device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\n        if self.device == torch.device(""cpu""):\n            self.logger.info(""RUNNING ON CPU"")\n        else:\n            self.logger.info(""RUNNING ON CUDA"")\n            torch.cuda.synchronize(self.device)\n\n        self.rerank_model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n\n        self.rerank_model.to(self.device, non_blocking=True)\n\n    def get_logits(self, query: str, choices: List[str]):\n        """"""\n        :param query:\n        :param choices:\n        :return: logits\n        """"""\n        input_ids, attention_mask, token_type_ids = self.encode(query, choices)\n\n        with torch.no_grad():\n            logits = self.rerank_model(input_ids,\n                                       attention_mask=attention_mask,\n                                       token_type_ids=token_type_ids)[0]\n            logits = logits.detach().cpu().numpy()\n\n            return logits\n\n    def encode(self, query: str, choices: List[str]):\n        """"""\n        :param query:\n        :param choices:\n        :return: Encoded tokens\n        """"""\n        inputs = [self.tokenizer.encode_plus(query, choice, add_special_tokens=True)\n                  for choice in choices]\n\n        max_len = min(max(len(t[\'input_ids\']) for t in inputs), self.max_seq_len)\n        input_ids = [t[\'input_ids\'][:max_len] +\n                     [0] * (max_len - len(t[\'input_ids\'][:max_len])) for t in inputs]\n        attention_mask = [[1] * len(t[\'input_ids\'][:max_len]) +\n                          [0] * (max_len - len(t[\'input_ids\'][:max_len])) for t in inputs]\n        token_type_ids = [t[\'token_type_ids\'][:max_len] +\n                     [0] * (max_len - len(t[\'token_type_ids\'][:max_len])) for t in inputs]\n\n        input_ids = torch.tensor(input_ids).to(self.device, non_blocking=True)\n        attention_mask = torch.tensor(attention_mask).to(self.device, non_blocking=True)\n        token_type_ids = torch.tensor(token_type_ids).to(self.device, non_blocking=True)\n\n        return input_ids, attention_mask, token_type_ids\n'"
nboost/plugins/rerank/use.py,3,"b""import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nfrom nboost.plugins.models.rerank.base import RerankModelPlugin\nfrom nboost import defaults\n\nfrom typing import List, Tuple\n\nclass USERerankModelPlugin(RerankModelPlugin):\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.module = hub.load(self.model_dir)\n\n\n    def rank(self, query: str, choices: List[str],\n             filter_results: type(defaults.filter_results) = defaults.filter_results\n             ) -> Tuple[List[int], List[float]]:\n        # questions = [query]\n\n        # question_embeddings = self.module.signatures['question_encoder'](\n        #     tf.constant(questions))\n        # response_embeddings = self.module.signatures['response_encoder'](\n        #     input=tf.constant(choices),\n        #     context=tf.constant(choices))\n\n        question_embedding = self.module([query])\n\n        candidate_embeddings = self.module(choices)\n\n        scores = np.inner(question_embedding, candidate_embeddings)\n        scores = np.reshape(scores, (-1,))\n        sorted_indices = list(np.argsort(scores)[::-1])\n        return sorted_indices, scores[sorted_indices]\n\n\n\n\n"""
