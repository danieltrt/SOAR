file_path,api_count,code
data.py,14,"b'import os\nimport tensorflow as tf\n\nfrom tensorflow.python.data.experimental import AUTOTUNE\n\n\nclass DIV2K:\n    def __init__(self,\n                 scale=2,\n                 subset=\'train\',\n                 downgrade=\'bicubic\',\n                 images_dir=\'.div2k/images\',\n                 caches_dir=\'.div2k/caches\'):\n\n        self._ntire_2018 = True\n\n        _scales = [2, 3, 4, 8]\n\n        if scale in _scales:\n            self.scale = scale\n        else:\n            raise ValueError(f\'scale must be in ${_scales}\')\n\n        if subset == \'train\':\n            self.image_ids = range(1, 801)\n        elif subset == \'valid\':\n            self.image_ids = range(801, 901)\n        else:\n            raise ValueError(""subset must be \'train\' or \'valid\'"")\n\n        _downgrades_a = [\'bicubic\', \'unknown\']\n        _downgrades_b = [\'mild\', \'difficult\']\n\n        if scale == 8 and downgrade != \'bicubic\':\n            raise ValueError(f\'scale 8 only allowed for bicubic downgrade\')\n\n        if downgrade in _downgrades_b and scale != 4:\n            raise ValueError(f\'{downgrade} downgrade requires scale 4\')\n\n        if downgrade == \'bicubic\' and scale == 8:\n            self.downgrade = \'x8\'\n        elif downgrade in _downgrades_b:\n            self.downgrade = downgrade\n        else:\n            self.downgrade = downgrade\n            self._ntire_2018 = False\n\n        self.subset = subset\n        self.images_dir = images_dir\n        self.caches_dir = caches_dir\n\n        os.makedirs(images_dir, exist_ok=True)\n        os.makedirs(caches_dir, exist_ok=True)\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def dataset(self, batch_size=16, repeat_count=None, random_transform=True):\n        ds = tf.data.Dataset.zip((self.lr_dataset(), self.hr_dataset()))\n        if random_transform:\n            ds = ds.map(lambda lr, hr: random_crop(lr, hr, scale=self.scale), num_parallel_calls=AUTOTUNE)\n            ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n            ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n        ds = ds.batch(batch_size)\n        ds = ds.repeat(repeat_count)\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n        return ds\n\n    def hr_dataset(self):\n        if not os.path.exists(self._hr_images_dir()):\n            download_archive(self._hr_images_archive(), self.images_dir, extract=True)\n\n        ds = self._images_dataset(self._hr_image_files()).cache(self._hr_cache_file())\n\n        if not os.path.exists(self._hr_cache_index()):\n            self._populate_cache(ds, self._hr_cache_file())\n\n        return ds\n\n    def lr_dataset(self):\n        if not os.path.exists(self._lr_images_dir()):\n            download_archive(self._lr_images_archive(), self.images_dir, extract=True)\n\n        ds = self._images_dataset(self._lr_image_files()).cache(self._lr_cache_file())\n\n        if not os.path.exists(self._lr_cache_index()):\n            self._populate_cache(ds, self._lr_cache_file())\n\n        return ds\n\n    def _hr_cache_file(self):\n        return os.path.join(self.caches_dir, f\'DIV2K_{self.subset}_HR.cache\')\n\n    def _lr_cache_file(self):\n        return os.path.join(self.caches_dir, f\'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.cache\')\n\n    def _hr_cache_index(self):\n        return f\'{self._hr_cache_file()}.index\'\n\n    def _lr_cache_index(self):\n        return f\'{self._lr_cache_file()}.index\'\n\n    def _hr_image_files(self):\n        images_dir = self._hr_images_dir()\n        return [os.path.join(images_dir, f\'{image_id:04}.png\') for image_id in self.image_ids]\n\n    def _lr_image_files(self):\n        images_dir = self._lr_images_dir()\n        return [os.path.join(images_dir, self._lr_image_file(image_id)) for image_id in self.image_ids]\n\n    def _lr_image_file(self, image_id):\n        if not self._ntire_2018 or self.scale == 8:\n            return f\'{image_id:04}x{self.scale}.png\'\n        else:\n            return f\'{image_id:04}x{self.scale}{self.downgrade[0]}.png\'\n\n    def _hr_images_dir(self):\n        return os.path.join(self.images_dir, f\'DIV2K_{self.subset}_HR\')\n\n    def _lr_images_dir(self):\n        if self._ntire_2018:\n            return os.path.join(self.images_dir, f\'DIV2K_{self.subset}_LR_{self.downgrade}\')\n        else:\n            return os.path.join(self.images_dir, f\'DIV2K_{self.subset}_LR_{self.downgrade}\', f\'X{self.scale}\')\n\n    def _hr_images_archive(self):\n        return f\'DIV2K_{self.subset}_HR.zip\'\n\n    def _lr_images_archive(self):\n        if self._ntire_2018:\n            return f\'DIV2K_{self.subset}_LR_{self.downgrade}.zip\'\n        else:\n            return f\'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.zip\'\n\n    @staticmethod\n    def _images_dataset(image_files):\n        ds = tf.data.Dataset.from_tensor_slices(image_files)\n        ds = ds.map(tf.io.read_file)\n        ds = ds.map(lambda x: tf.image.decode_png(x, channels=3), num_parallel_calls=AUTOTUNE)\n        return ds\n\n    @staticmethod\n    def _populate_cache(ds, cache_file):\n        print(f\'Caching decoded images in {cache_file} ...\')\n        for _ in ds: pass\n        print(f\'Cached decoded images in {cache_file}.\')\n\n\n# -----------------------------------------------------------\n#  Transformations\n# -----------------------------------------------------------\n\n\ndef random_crop(lr_img, hr_img, hr_crop_size=96, scale=2):\n    lr_crop_size = hr_crop_size // scale\n    lr_img_shape = tf.shape(lr_img)[:2]\n\n    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n\n    hr_w = lr_w * scale\n    hr_h = lr_h * scale\n\n    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n\n    return lr_img_cropped, hr_img_cropped\n\n\ndef random_flip(lr_img, hr_img):\n    rn = tf.random.uniform(shape=(), maxval=1)\n    return tf.cond(rn < 0.5,\n                   lambda: (lr_img, hr_img),\n                   lambda: (tf.image.flip_left_right(lr_img),\n                            tf.image.flip_left_right(hr_img)))\n\n\ndef random_rotate(lr_img, hr_img):\n    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n\n\n# -----------------------------------------------------------\n#  IO\n# -----------------------------------------------------------\n\n\ndef download_archive(file, target_dir, extract=True):\n    source_url = f\'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}\'\n    target_dir = os.path.abspath(target_dir)\n    tf.keras.utils.get_file(file, source_url, cache_subdir=target_dir, extract=extract)\n    os.remove(os.path.join(target_dir, file))\n'"
train.py,15,"b'import time\nimport tensorflow as tf\n\nfrom model import evaluate\nfrom model import srgan\n\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.losses import MeanAbsoluteError\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.metrics import Mean\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n\n\nclass Trainer:\n    def __init__(self,\n                 model,\n                 loss,\n                 learning_rate,\n                 checkpoint_dir=\'./ckpt/edsr\'):\n\n        self.now = None\n        self.loss = loss\n        self.checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n                                              psnr=tf.Variable(-1.0),\n                                              optimizer=Adam(learning_rate),\n                                              model=model)\n        self.checkpoint_manager = tf.train.CheckpointManager(checkpoint=self.checkpoint,\n                                                             directory=checkpoint_dir,\n                                                             max_to_keep=3)\n\n        self.restore()\n\n    @property\n    def model(self):\n        return self.checkpoint.model\n\n    def train(self, train_dataset, valid_dataset, steps, evaluate_every=1000, save_best_only=False):\n        loss_mean = Mean()\n\n        ckpt_mgr = self.checkpoint_manager\n        ckpt = self.checkpoint\n\n        self.now = time.perf_counter()\n\n        for lr, hr in train_dataset.take(steps - ckpt.step.numpy()):\n            ckpt.step.assign_add(1)\n            step = ckpt.step.numpy()\n\n            loss = self.train_step(lr, hr)\n            loss_mean(loss)\n\n            if step % evaluate_every == 0:\n                loss_value = loss_mean.result()\n                loss_mean.reset_states()\n\n                # Compute PSNR on validation dataset\n                psnr_value = self.evaluate(valid_dataset)\n\n                duration = time.perf_counter() - self.now\n                print(f\'{step}/{steps}: loss = {loss_value.numpy():.3f}, PSNR = {psnr_value.numpy():3f} ({duration:.2f}s)\')\n\n                if save_best_only and psnr_value <= ckpt.psnr:\n                    self.now = time.perf_counter()\n                    # skip saving checkpoint, no PSNR improvement\n                    continue\n\n                ckpt.psnr = psnr_value\n                ckpt_mgr.save()\n\n                self.now = time.perf_counter()\n\n    @tf.function\n    def train_step(self, lr, hr):\n        with tf.GradientTape() as tape:\n            lr = tf.cast(lr, tf.float32)\n            hr = tf.cast(hr, tf.float32)\n\n            sr = self.checkpoint.model(lr, training=True)\n            loss_value = self.loss(hr, sr)\n\n        gradients = tape.gradient(loss_value, self.checkpoint.model.trainable_variables)\n        self.checkpoint.optimizer.apply_gradients(zip(gradients, self.checkpoint.model.trainable_variables))\n\n        return loss_value\n\n    def evaluate(self, dataset):\n        return evaluate(self.checkpoint.model, dataset)\n\n    def restore(self):\n        if self.checkpoint_manager.latest_checkpoint:\n            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n            print(f\'Model restored from checkpoint at step {self.checkpoint.step.numpy()}.\')\n\n\nclass EdsrTrainer(Trainer):\n    def __init__(self,\n                 model,\n                 checkpoint_dir,\n                 learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-4, 5e-5])):\n        super().__init__(model, loss=MeanAbsoluteError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n\n    def train(self, train_dataset, valid_dataset, steps=300000, evaluate_every=1000, save_best_only=True):\n        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n\n\nclass WdsrTrainer(Trainer):\n    def __init__(self,\n                 model,\n                 checkpoint_dir,\n                 learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-3, 5e-4])):\n        super().__init__(model, loss=MeanAbsoluteError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n\n    def train(self, train_dataset, valid_dataset, steps=300000, evaluate_every=1000, save_best_only=True):\n        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n\n\nclass SrganGeneratorTrainer(Trainer):\n    def __init__(self,\n                 model,\n                 checkpoint_dir,\n                 learning_rate=1e-4):\n        super().__init__(model, loss=MeanSquaredError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n\n    def train(self, train_dataset, valid_dataset, steps=1000000, evaluate_every=1000, save_best_only=True):\n        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n\n\nclass SrganTrainer:\n    #\n    # TODO: model and optimizer checkpoints\n    #\n    def __init__(self,\n                 generator,\n                 discriminator,\n                 content_loss=\'VGG54\',\n                 learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])):\n\n        if content_loss == \'VGG22\':\n            self.vgg = srgan.vgg_22()\n        elif content_loss == \'VGG54\':\n            self.vgg = srgan.vgg_54()\n        else:\n            raise ValueError(""content_loss must be either \'VGG22\' or \'VGG54\'"")\n\n        self.content_loss = content_loss\n        self.generator = generator\n        self.discriminator = discriminator\n        self.generator_optimizer = Adam(learning_rate=learning_rate)\n        self.discriminator_optimizer = Adam(learning_rate=learning_rate)\n\n        self.binary_cross_entropy = BinaryCrossentropy(from_logits=False)\n        self.mean_squared_error = MeanSquaredError()\n\n    def train(self, train_dataset, steps=200000):\n        pls_metric = Mean()\n        dls_metric = Mean()\n        step = 0\n\n        for lr, hr in train_dataset.take(steps):\n            step += 1\n\n            pl, dl = self.train_step(lr, hr)\n            pls_metric(pl)\n            dls_metric(dl)\n\n            if step % 50 == 0:\n                print(f\'{step}/{steps}, perceptual loss = {pls_metric.result():.4f}, discriminator loss = {dls_metric.result():.4f}\')\n                pls_metric.reset_states()\n                dls_metric.reset_states()\n\n    @tf.function\n    def train_step(self, lr, hr):\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            lr = tf.cast(lr, tf.float32)\n            hr = tf.cast(hr, tf.float32)\n\n            sr = self.generator(lr, training=True)\n\n            hr_output = self.discriminator(hr, training=True)\n            sr_output = self.discriminator(sr, training=True)\n\n            con_loss = self._content_loss(hr, sr)\n            gen_loss = self._generator_loss(sr_output)\n            perc_loss = con_loss + 0.001 * gen_loss\n            disc_loss = self._discriminator_loss(hr_output, sr_output)\n\n        gradients_of_generator = gen_tape.gradient(perc_loss, self.generator.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n\n        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n\n        return perc_loss, disc_loss\n\n    @tf.function\n    def _content_loss(self, hr, sr):\n        sr = preprocess_input(sr)\n        hr = preprocess_input(hr)\n        sr_features = self.vgg(sr) / 12.75\n        hr_features = self.vgg(hr) / 12.75\n        return self.mean_squared_error(hr_features, sr_features)\n\n    def _generator_loss(self, sr_out):\n        return self.binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n\n    def _discriminator_loss(self, hr_out, sr_out):\n        hr_loss = self.binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n        sr_loss = self.binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n        return hr_loss + sr_loss\n'"
utils.py,0,"b""import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\ndef load_image(path):\n    return np.array(Image.open(path))\n\n\ndef plot_sample(lr, sr):\n    plt.figure(figsize=(20, 10))\n\n    images = [lr, sr]\n    titles = ['LR', f'SR (x{sr.shape[0] // lr.shape[0]})']\n\n    for i, (img, title) in enumerate(zip(images, titles)):\n        plt.subplot(1, 2, i+1)\n        plt.imshow(img)\n        plt.title(title)\n        plt.xticks([])\n        plt.yticks([])\n"""
model/__init__.py,0,b'from model.common import resolve\nfrom model.common import resolve_single\nfrom model.common import evaluate\n'
model/common.py,8,"b'import numpy as np\nimport tensorflow as tf\n\n\nDIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n\n\ndef resolve_single(model, lr):\n    return resolve(model, tf.expand_dims(lr, axis=0))[0]\n\n\ndef resolve(model, lr_batch):\n    lr_batch = tf.cast(lr_batch, tf.float32)\n    sr_batch = model(lr_batch)\n    sr_batch = tf.clip_by_value(sr_batch, 0, 255)\n    sr_batch = tf.round(sr_batch)\n    sr_batch = tf.cast(sr_batch, tf.uint8)\n    return sr_batch\n\n\ndef evaluate(model, dataset):\n    psnr_values = []\n    for lr, hr in dataset:\n        sr = resolve(model, lr)\n        psnr_value = psnr(hr, sr)[0]\n        psnr_values.append(psnr_value)\n    return tf.reduce_mean(psnr_values)\n\n\n# ---------------------------------------\n#  Normalization\n# ---------------------------------------\n\n\ndef normalize(x, rgb_mean=DIV2K_RGB_MEAN):\n    return (x - rgb_mean) / 127.5\n\n\ndef denormalize(x, rgb_mean=DIV2K_RGB_MEAN):\n    return x * 127.5 + rgb_mean\n\n\ndef normalize_01(x):\n    """"""Normalizes RGB images to [0, 1].""""""\n    return x / 255.0\n\n\ndef normalize_m11(x):\n    """"""Normalizes RGB images to [-1, 1].""""""\n    return x / 127.5 - 1\n\n\ndef denormalize_m11(x):\n    """"""Inverse of normalize_m11.""""""\n    return (x + 1) * 127.5\n\n\n# ---------------------------------------\n#  Metrics\n# ---------------------------------------\n\n\ndef psnr(x1, x2):\n    return tf.image.psnr(x1, x2, max_val=255)\n\n\n# ---------------------------------------\n#  See https://arxiv.org/abs/1609.05158\n# ---------------------------------------\n\n\ndef pixel_shuffle(scale):\n    return lambda x: tf.nn.depth_to_space(x, scale)\n\n\n'"
model/edsr.py,0,"b'from tensorflow.python.keras.layers import Add, Conv2D, Input, Lambda\nfrom tensorflow.python.keras.models import Model\n\nfrom model.common import normalize, denormalize, pixel_shuffle\n\n\ndef edsr(scale, num_filters=64, num_res_blocks=8, res_block_scaling=None):\n    x_in = Input(shape=(None, None, 3))\n    x = Lambda(normalize)(x_in)\n\n    x = b = Conv2D(num_filters, 3, padding=\'same\')(x)\n    for i in range(num_res_blocks):\n        b = res_block(b, num_filters, res_block_scaling)\n    b = Conv2D(num_filters, 3, padding=\'same\')(b)\n    x = Add()([x, b])\n\n    x = upsample(x, scale, num_filters)\n    x = Conv2D(3, 3, padding=\'same\')(x)\n\n    x = Lambda(denormalize)(x)\n    return Model(x_in, x, name=""edsr"")\n\n\ndef res_block(x_in, filters, scaling):\n    x = Conv2D(filters, 3, padding=\'same\', activation=\'relu\')(x_in)\n    x = Conv2D(filters, 3, padding=\'same\')(x)\n    if scaling:\n        x = Lambda(lambda t: t * scaling)(x)\n    x = Add()([x_in, x])\n    return x\n\n\ndef upsample(x, scale, num_filters):\n    def upsample_1(x, factor, **kwargs):\n        x = Conv2D(num_filters * (factor ** 2), 3, padding=\'same\', **kwargs)(x)\n        return Lambda(pixel_shuffle(scale=factor))(x)\n\n    if scale == 2:\n        x = upsample_1(x, 2, name=\'conv2d_1_scale_2\')\n    elif scale == 3:\n        x = upsample_1(x, 3, name=\'conv2d_1_scale_3\')\n    elif scale == 4:\n        x = upsample_1(x, 2, name=\'conv2d_1_scale_2\')\n        x = upsample_1(x, 2, name=\'conv2d_2_scale_2\')\n\n    return x\n'"
model/srgan.py,0,"b""from tensorflow.python.keras.layers import Add, BatchNormalization, Conv2D, Dense, Flatten, Input, LeakyReLU, PReLU, Lambda\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.applications.vgg19 import VGG19\n\nfrom model.common import pixel_shuffle, normalize_01, normalize_m11, denormalize_m11\n\nLR_SIZE = 24\nHR_SIZE = 96\n\n\ndef upsample(x_in, num_filters):\n    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n    x = Lambda(pixel_shuffle(scale=2))(x)\n    return PReLU(shared_axes=[1, 2])(x)\n\n\ndef res_block(x_in, num_filters, momentum=0.8):\n    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n    x = BatchNormalization(momentum=momentum)(x)\n    x = PReLU(shared_axes=[1, 2])(x)\n    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n    x = BatchNormalization(momentum=momentum)(x)\n    x = Add()([x_in, x])\n    return x\n\n\ndef sr_resnet(num_filters=64, num_res_blocks=16):\n    x_in = Input(shape=(None, None, 3))\n    x = Lambda(normalize_01)(x_in)\n\n    x = Conv2D(num_filters, kernel_size=9, padding='same')(x)\n    x = x_1 = PReLU(shared_axes=[1, 2])(x)\n\n    for _ in range(num_res_blocks):\n        x = res_block(x, num_filters)\n\n    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Add()([x_1, x])\n\n    x = upsample(x, num_filters * 4)\n    x = upsample(x, num_filters * 4)\n\n    x = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n    x = Lambda(denormalize_m11)(x)\n\n    return Model(x_in, x)\n\n\ngenerator = sr_resnet\n\n\ndef discriminator_block(x_in, num_filters, strides=1, batchnorm=True, momentum=0.8):\n    x = Conv2D(num_filters, kernel_size=3, strides=strides, padding='same')(x_in)\n    if batchnorm:\n        x = BatchNormalization(momentum=momentum)(x)\n    return LeakyReLU(alpha=0.2)(x)\n\n\ndef discriminator(num_filters=64):\n    x_in = Input(shape=(HR_SIZE, HR_SIZE, 3))\n    x = Lambda(normalize_m11)(x_in)\n\n    x = discriminator_block(x, num_filters, batchnorm=False)\n    x = discriminator_block(x, num_filters, strides=2)\n\n    x = discriminator_block(x, num_filters * 2)\n    x = discriminator_block(x, num_filters * 2, strides=2)\n\n    x = discriminator_block(x, num_filters * 4)\n    x = discriminator_block(x, num_filters * 4, strides=2)\n\n    x = discriminator_block(x, num_filters * 8)\n    x = discriminator_block(x, num_filters * 8, strides=2)\n\n    x = Flatten()(x)\n\n    x = Dense(1024)(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dense(1, activation='sigmoid')(x)\n\n    return Model(x_in, x)\n\n\ndef vgg_22():\n    return _vgg(5)\n\n\ndef vgg_54():\n    return _vgg(20)\n\n\ndef _vgg(output_layer):\n    vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n    return Model(vgg.input, vgg.layers[output_layer].output)\n"""
model/wdsr.py,0,"b'import tensorflow_addons as tfa\n\nfrom tensorflow.python.keras.layers import Add, Conv2D, Input, Lambda\nfrom tensorflow.python.keras.models import Model\n\nfrom model.common import normalize, denormalize, pixel_shuffle\n\n\ndef wdsr_a(scale, num_filters=32, num_res_blocks=8, res_block_expansion=4, res_block_scaling=None):\n    return wdsr(scale, num_filters, num_res_blocks, res_block_expansion, res_block_scaling, res_block_a)\n\n\ndef wdsr_b(scale, num_filters=32, num_res_blocks=8, res_block_expansion=6, res_block_scaling=None):\n    return wdsr(scale, num_filters, num_res_blocks, res_block_expansion, res_block_scaling, res_block_b)\n\n\ndef wdsr(scale, num_filters, num_res_blocks, res_block_expansion, res_block_scaling, res_block):\n    x_in = Input(shape=(None, None, 3))\n    x = Lambda(normalize)(x_in)\n\n    # main branch\n    m = conv2d_weightnorm(num_filters, 3, padding=\'same\')(x)\n    for i in range(num_res_blocks):\n        m = res_block(m, num_filters, res_block_expansion, kernel_size=3, scaling=res_block_scaling)\n    m = conv2d_weightnorm(3 * scale ** 2, 3, padding=\'same\', name=f\'conv2d_main_scale_{scale}\')(m)\n    m = Lambda(pixel_shuffle(scale))(m)\n\n    # skip branch\n    s = conv2d_weightnorm(3 * scale ** 2, 5, padding=\'same\', name=f\'conv2d_skip_scale_{scale}\')(x)\n    s = Lambda(pixel_shuffle(scale))(s)\n\n    x = Add()([m, s])\n    x = Lambda(denormalize)(x)\n\n    return Model(x_in, x, name=""wdsr"")\n\n\ndef res_block_a(x_in, num_filters, expansion, kernel_size, scaling):\n    x = conv2d_weightnorm(num_filters * expansion, kernel_size, padding=\'same\', activation=\'relu\')(x_in)\n    x = conv2d_weightnorm(num_filters, kernel_size, padding=\'same\')(x)\n    if scaling:\n        x = Lambda(lambda t: t * scaling)(x)\n    x = Add()([x_in, x])\n    return x\n\n\ndef res_block_b(x_in, num_filters, expansion, kernel_size, scaling):\n    linear = 0.8\n    x = conv2d_weightnorm(num_filters * expansion, 1, padding=\'same\', activation=\'relu\')(x_in)\n    x = conv2d_weightnorm(int(num_filters * linear), 1, padding=\'same\')(x)\n    x = conv2d_weightnorm(num_filters, kernel_size, padding=\'same\')(x)\n    if scaling:\n        x = Lambda(lambda t: t * scaling)(x)\n    x = Add()([x_in, x])\n    return x\n\n\ndef conv2d_weightnorm(filters, kernel_size, padding=\'same\', activation=None, **kwargs):\n    return tfa.layers.WeightNormalization(Conv2D(filters, kernel_size, padding=padding, activation=activation, **kwargs), data_init=False)\n'"
