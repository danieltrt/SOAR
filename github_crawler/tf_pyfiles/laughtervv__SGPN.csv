file_path,api_count,code
generate_results.py,8,"b'import argparse\nimport tensorflow as tf\nimport json\nimport numpy as np\nimport os\nos.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""   # see issue #152\nimport sys\nfrom scipy import stats\nimport time\nimport h5py\n\nimport matplotlib.pyplot as plt\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.dirname(BASE_DIR))\nsys.path.append(os.path.join(BASE_DIR, \'../../\'))\nsys.path.append(os.path.join(BASE_DIR, \'../../utils\'))\nsys.path.append(os.path.join(BASE_DIR, \'../../models\'))\nimport provider\nfrom utils.test_utils import *\nfrom models import model\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\'--gpu\', type=str, default=""3"", help=\'GPU to use [default: GPU 1]\')\nparser.add_argument(\'--verbose\', action=\'store_true\', help=\'if specified, use depthconv\')\nparser.add_argument(\'--input_list\', type=str, default=\'/media/hdd2/data/pointnet/stanfordindoor/test_hdf5_file_list5.txt\', help=\'Validation data list\')\nparser.add_argument(\'--restore_dir\', type=str, default=\'checkpoint/stanford_ins_seg51\', help=\'Directory that stores all training logs and trained models\')\n\nFLAGS = parser.parse_args()\n\n# DEFAULT SETTINGS\nos.environ[""CUDA_VISIBLE_DEVICES""] = FLAGS.gpu\nPRETRAINED_MODEL_PATH = os.path.join(FLAGS.restore_dir,\'trained_models/\')\n\nRESTORE_DIR = FLAGS.restore_dir\ngpu_to_use = 0\nOUTPUT_DIR = os.path.join(FLAGS.restore_dir, \'test_results\')\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    os.makedirs(os.path.join(OUTPUT_DIR, \'predicted_masks\'))\n\nGT_DIR = os.path.join(FLAGS.restore_dir, \'test_gt\')\nif not os.path.exists(GT_DIR):\n    os.makedirs(GT_DIR)\n    os.makedirs(os.path.join(GT_DIR, \'predicted_masks\'))\n\noutput_verbose = FLAGS.verbose  # If true, output all color-coded segmentation obj files\n\nlabel_bin = np.loadtxt(os.path.join(RESTORE_DIR, \'pergroup_thres.txt\'))\nmin_num_pts_in_group = np.loadtxt(os.path.join(RESTORE_DIR, \'mingroupsize.txt\'))\n\n# MAIN SCRIPT\nPOINT_NUM = 4096  # the max number of points in the all testing data shapes\nBATCH_SIZE  = 1\nNUM_GROUPS = 50\nNUM_CATEGORY = 13\n\nTESTING_FILE_LISTFILE = FLAGS.input_list\ntest_file_list = provider.getDataFiles(TESTING_FILE_LISTFILE)\nlen_pts_files = len(test_file_list)\n\ndef predict():\n    is_training = False\n\n    with tf.device(\'/gpu:\' + str(gpu_to_use)):\n        is_training_ph = tf.placeholder(tf.bool, shape=())\n\n        pointclouds_ph, ptsseglabel_ph, ptsgroup_label_ph, _, _, _ = \\\n            model.placeholder_inputs(BATCH_SIZE, POINT_NUM, NUM_GROUPS, NUM_CATEGORY)\n\n        net_output = model.get_model(pointclouds_ph, is_training_ph, group_cate_num=NUM_CATEGORY)\n        group_mat_label = tf.matmul(ptsgroup_label_ph, tf.transpose(ptsgroup_label_ph, perm=[0, 2, 1])) #BxNxN: (i,j) if i and j in the same group\n\n    # Add ops to save and restore all the variables.\n\n    saver = tf.train.Saver()\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n\n    with tf.Session(config=config) as sess:\n\n        ckptstate = tf.train.get_checkpoint_state(PRETRAINED_MODEL_PATH)\n        if ckptstate is not None:\n            LOAD_MODEL_FILE = os.path.join(PRETRAINED_MODEL_PATH,os.path.basename(ckptstate.model_checkpoint_path))\n            saver.restore(sess, LOAD_MODEL_FILE)\n            print(""Model loaded in file: %s"" % LOAD_MODEL_FILE)\n        else:\n            print(""Fail to load modelfile: %s"" % PRETRAINED_MODEL_PATH)\n\n\n        for shape_idx in range(len_pts_files):\n\n            cur_train_filename = test_file_list[shape_idx]\n\n            if not os.path.exists(cur_train_filename):\n                continue\n            cur_data, cur_group, _, cur_seg = provider.loadDataFile_with_groupseglabel_stanfordindoor(cur_train_filename)\n\n            seg_output = np.zeros_like(cur_seg)\n            segrefine_output = np.zeros_like(cur_seg)\n            group_output = np.zeros_like(cur_group)\n            conf_output = np.zeros_like(cur_group).astype(np.float)\n\n            pts_label_one_hot, pts_label_mask = model.convert_seg_to_one_hot(cur_seg)\n            pts_group_label, _ = model.convert_groupandcate_to_one_hot(cur_group)\n            num_data = cur_data.shape[0]\n\n            gap = 5e-3\n            volume_num = int(1. / gap)+1\n            volume = -1* np.ones([volume_num,volume_num,volume_num]).astype(np.int32)\n            volume_seg = -1* np.ones([volume_num,volume_num,volume_num, NUM_CATEGORY]).astype(np.int32)\n\n            intersections = np.zeros(NUM_CATEGORY)\n            unions = np.zeros(NUM_CATEGORY)\n            print(\'[%d / %d] Block Number: %d\' % (shape_idx, len_pts_files, num_data))\n            print(\'Loading train file %s\' % (cur_train_filename))\n\n            flag = True\n            for j in range(num_data):\n\n                pts = cur_data[j,...]\n\n                feed_dict = {\n                    pointclouds_ph: np.expand_dims(pts,0),\n                    ptsseglabel_ph: np.expand_dims(pts_label_one_hot[j,...],0),\n                    ptsgroup_label_ph: np.expand_dims(pts_group_label[j,...],0),\n                    is_training_ph: is_training,\n                }\n\n                pts_corr_val0, pred_confidence_val0, ptsclassification_val0, pts_corr_label_val0 = \\\n                    sess.run([net_output[\'simmat\'],\n                              net_output[\'conf\'],\n                              net_output[\'semseg\'],\n                              group_mat_label],\n                              feed_dict=feed_dict)\n\n                seg = cur_seg[j,...]\n                ins = cur_group[j,...]\n\n                pts_corr_val = np.squeeze(pts_corr_val0[0]) #NxG\n                pred_confidence_val = np.squeeze(pred_confidence_val0[0])\n                ptsclassification_val = np.argmax(np.squeeze(ptsclassification_val0[0]),axis=1)\n\n                seg = np.squeeze(seg)\n                # print label_bin\n\n                try:\n                    groupids_block, refineseg, group_seg = GroupMerging_old(pts_corr_val, pred_confidence_val, ptsclassification_val, label_bin)  # yolo_to_groupt(pts_corr_val, pts_corr_label_val0[0], seg,t=5)\n                    groupids = BlockMerging(volume, volume_seg, pts[:,6:], groupids_block.astype(np.int32), group_seg, gap)\n\n\n                seg_output[j,:] = ptsclassification_val\n                segrefine_output[j,:] = refineseg\n                group_output[j,:] = groupids\n                conf_output[j,:] = pred_confidence_val\n\n            ###### Generate Results for Evaluation\n\n            basefilename = os.path.basename(cur_train_filename).split(\'.\')[-2]\n            scene_fn = os.path.join(OUTPUT_DIR, \'%s.txt\' % basefilename)\n            f_scene = open(scene_fn, \'w\')\n            scene_gt_fn = os.path.join(GT_DIR, \'%s.txt\' % basefilename)\n            group_pred = group_output.reshape(-1)\n            seg_pred = seg_output.reshape(-1)\n            conf = conf_output.reshape(-1)\n            pts = cur_data.reshape([-1, 9])\n\n            # filtering\n            x = (pts[:, 6] / gap).astype(np.int32)\n            y = (pts[:, 7] / gap).astype(np.int32)\n            z = (pts[:, 8] / gap).astype(np.int32)\n            for i in range(group_pred.shape[0]):\n                if volume[x[i], y[i], z[i]] != -1:\n                    group_pred[i] = volume[x[i], y[i], z[i]]\n\n            un = np.unique(group_pred)\n            pts_in_pred = [[] for itmp in range(NUM_CATEGORY)]\n            group_pred_final = -1 * np.ones_like(group_pred)\n            grouppred_cnt = 0\n\n            for ig, g in enumerate(un): #each object in prediction\n                if g == -1:\n                    continue\n                obj_fn = ""predicted_masks/%s_%d.txt"" % (basefilename, ig)\n                tmp = (group_pred == g)\n                sem_seg_g = int(stats.mode(seg_pred[tmp])[0])\n                if np.sum(tmp) > 0.25 * min_num_pts_in_group[sem_seg_g]:\n                    pts_in_pred[sem_seg_g] += [tmp]\n                    group_pred_final[tmp] = grouppred_cnt\n                    conf_obj = np.mean(conf[tmp])\n                    grouppred_cnt += 1\n                    f_scene.write(""%s %d %f\\n"" % (obj_fn, sem_seg_g, conf_obj))\n                    np.savetxt(os.path.join(OUTPUT_DIR, obj_fn), tmp.astype(np.int), fmt=\'%d\')\n\n            seg_gt = cur_seg.reshape(-1)\n            group_gt = cur_group.reshape(-1)\n            groupid_gt = seg_gt * 1000 + group_gt\n            np.savetxt(scene_gt_fn, groupid_gt.astype(np.int64), fmt=\'%d\')\n\n            f_scene.close()\n\n            if output_verbose:\n                output_color_point_cloud(pts[:, 6:], seg_pred.astype(np.int32),\n                                         os.path.join(OUTPUT_DIR, \'%s_segpred.obj\' % (obj_fn)))\n                output_color_point_cloud(pts[:, 6:], group_pred_final.astype(np.int32),\n                                         os.path.join(OUTPUT_DIR, \'%s_grouppred.obj\' % (obj_fn)))\n\n\nwith tf.Graph().as_default():\n    predict()'"
provider.py,0,"b'import os\nimport sys\nimport numpy as np\nimport h5py\n# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n# sys.path.append(BASE_DIR)\n#\n# # Download dataset for point cloud classification\n# DATA_DIR = os.path.join(BASE_DIR, \'data\')\n# if not os.path.exists(DATA_DIR):\n#     os.mkdir(DATA_DIR)\n# if not os.path.exists(os.path.join(DATA_DIR, \'modelnet40_ply_hdf5_2048\')):\n#     www = \'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\'\n#     zipfile = os.path.basename(www)\n#     os.system(\'wget %s; unzip %s\' % (www, zipfile))\n#     os.system(\'mv %s %s\' % (zipfile[:-4], DATA_DIR))\n#     os.system(\'rm %s\' % (zipfile))\n\n\ndef shuffle_data(data, labels):\n    """""" Shuffle data and labels.\n        Input:\n          data: B,N,... numpy array\n          label: B,... numpy array\n        Return:\n          shuffled data, label and shuffle indices\n    """"""\n    idx = np.arange(len(labels))\n    np.random.shuffle(idx)\n    return data[idx, ...], labels[idx], idx\n\n\ndef rotate_point_cloud(batch_data):\n    """""" Randomly rotate the point clouds to augument the dataset\n        rotation is per shape based along up direction\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array([[cosval, 0, sinval],\n                                    [0, 1, 0],\n                                    [-sinval, 0, cosval]])\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_point_cloud_by_angle(batch_data, rotation_angle):\n    """""" Rotate the point cloud along up direction with certain angle.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        #rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array([[cosval, 0, sinval],\n                                    [0, 1, 0],\n                                    [-sinval, 0, cosval]])\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n    """""" Randomly jitter points. jittering is per point.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, jittered batch of point clouds\n    """"""\n    B, N, C = batch_data.shape\n    assert(clip > 0)\n    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1*clip, clip)\n    jittered_data += batch_data\n    return jittered_data\n\n\ndef save_h5_output(h5_filename, seg, segrefine, group, grouppred, label_dtype=\'uint8\'):\n    print h5_filename\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n            \'seglabel\', data=seg,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.create_dataset(\n            \'segrefine\', data=segrefine,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.create_dataset(\n            \'pid\', data=group,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.create_dataset(\n            \'predpid\', data=grouppred,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.close()\n\ndef getDataFiles(list_filename):\n    return [line.rstrip() for line in open(list_filename)]\n\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    return (data, label)\n\ndef loadDataFile(filename):\n    return load_h5(filename)\n\ndef load_h5_data_label_seg(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    seg = f[\'pid\'][:]\n    return (data, label, seg)\n\n\ndef loadDataFile_with_seg(filename):\n    return load_h5_data_label_seg(filename)\n\ndef loadDataFile_with_grouplabel(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    # label = f[\'label\'][:]\n    group = f[\'pid\'][:]#Nx1\n    if \'groupcategory\' in f:\n        cate = f[\'groupcategory\'][:]#Gx1\n    else:\n        cate = 0\n    return (data, group, cate)\n\ndef loadDataFile_with_groupseglabel(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    # label = f[\'label\'][:]\n    group = f[\'pid\'][:]#Nx1\n    if \'groupcategory\' in f:\n        cate = f[\'groupcategory\'][:]#Gx1\n    else:\n        cate = 0\n    seg = -1 * np.ones_like(group)\n    for i in range(group.shape[0]):\n        for j in range(group.shape[1]):\n            if group[i,j,0]!=-1 and cate[i,group[i,j,0],0]!=-1:\n                    seg[i,j,0] = cate[i,group[i,j,0],0]\n    return (data, group, cate, seg)\n\ndef loadDataFile_with_groupseglabel_sunrgbd(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    group = f[\'pid\'][:]#NxG\n    if \'groupcategory\' in f:\n        cate = f[\'groupcategory\'][:]#Gx1\n    else:\n        cate = 0\n    if \'seglabel\' in f:\n        seg = f[\'seglabel\'][:]\n    else:\n        seg = f[\'seglabels\'][:]\n    return (data, group, cate, seg)\n\ndef loadDataFile_with_groupseglabel_scannet(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    # label = f[\'label\'][:]\n    group = f[\'pid\'][:]#NxG\n    if \'groupcategory\' in f:\n        cate = f[\'groupcategory\'][:]#Gx1\n    else:\n        cate = 0\n    if \'seglabel\' in f:\n        seg = f[\'seglabel\'][:]\n    else:\n        seg = f[\'seglabels\'][:]\n    return (data, group, cate, seg)\n\n\ndef loadDataFile_with_groupseglabel_nuyv2(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    group = f[\'pid\'][:]#NxG\n    if \'groupcategory\' in f:\n        cate = f[\'groupcategory\'][:]#Gx1\n    else:\n        cate = 0\n    if \'seglabel\' in f:\n        seg = f[\'seglabel\'][:]\n    else:\n        seg = f[\'seglabels\'][:]\n    boxes = f[\'bbox\'][:]\n    return (data, group, cate, seg, boxes)\n\ndef loadDataFile_with_groupseglabel_stanfordindoor(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    group = f[\'pid\'][:].astype(np.int32)#NxG\n    if \'label\' in f:\n        label = f[\'label\'][:].astype(np.int32)\n    else :\n        label = []\n    if \'seglabel\' in f:\n        seg = f[\'seglabel\'][:].astype(np.int32)\n    else:\n        seg = f[\'seglabels\'][:].astype(np.int32)\n    return (data, group, label, seg)\n\ndef loadDataFile_with_img(filename):\n    f = h5py.File(filename)\n    data = f[\'data\'][:]\n    group = f[\'pid\'][:]#NxG\n    seg = f[\'seglabel\'][:]\n    img = f[\'img\'][:].transpose([2,1,0])\n    return (data, group, seg, img)\n'"
train.py,20,"b'import argparse\nimport tensorflow as tf\nimport numpy as np\nimport os\nos.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""  # see issue #152\nimport sys\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nprint BASE_DIR\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.dirname(BASE_DIR))\nsys.path.append(os.path.join(BASE_DIR, \'../../\'))\nsys.path.append(os.path.join(BASE_DIR, \'../../utils\'))\nsys.path.append(os.path.join(BASE_DIR, \'../../models\'))\nimport provider\nfrom models import model\n\n# Parsing Arguments\nparser = argparse.ArgumentParser()\n# Experiment Settings\nparser.add_argument(\'--gpu\', type=str, default=""1"", help=\'GPU to use [default: GPU 1]\')\nparser.add_argument(\'--wd\', type=float, default=0.9, help=\'Weight Decay [Default: 0.0]\')\nparser.add_argument(\'--epoch\', type=int, default=200, help=\'Number of epochs [default: 50]\')\nparser.add_argument(\'--batch\', type=int, default=4, help=\'Batch Size during training [default: 4]\')\nparser.add_argument(\'--point_num\', type=int, default=4096, help=\'Point Number\')\nparser.add_argument(\'--group_num\', type=int, default=50, help=\'Maximum Group Number in one pc\')\nparser.add_argument(\'--cate_num\', type=int, default=13, help=\'Number of categories\')\nparser.add_argument(\'--margin_same\', type=float, default=10., help=\'Double hinge loss margin: same semantic\')\nparser.add_argument(\'--margin_diff\', type=float, default=80., help=\'Double hinge loss margin: different semantic\')\n\n# Input&Output Settings\nparser.add_argument(\'--output_dir\', type=str, default=\'checkpoint/stanford_sem_seg\', help=\'Directory that stores all training logs and trained models\')\nparser.add_argument(\'--input_list\', type=str, default=\'data/train_hdf5_file_list.txt\', help=\'Input data list file\')\nparser.add_argument(\'--restore_model\', type=str, default=\'checkpoint/stanford_ins_seg\', help=\'Pretrained model\')\n\nFLAGS = parser.parse_args()\n\nos.environ[""CUDA_VISIBLE_DEVICES""] = FLAGS.gpu\n\nTRAINING_FILE_LIST = FLAGS.input_list\nPRETRAINED_MODEL_PATH = os.path.join(FLAGS.restore_model, \'trained_models/\')\n\nPOINT_NUM = FLAGS.point_num\nBATCH_SIZE = FLAGS.batch\nOUTPUT_DIR = FLAGS.output_dir\n\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nNUM_GROUPS = FLAGS.group_num\nNUM_CATEGORY = FLAGS.cate_num\n\nprint(\'#### Batch Size: {0}\'.format(BATCH_SIZE))\nprint(\'#### Point Number: {0}\'.format(POINT_NUM))\nprint(\'#### Training using GPU: {0}\'.format(FLAGS.gpu))\n\nDECAY_STEP = 800000.\nDECAY_RATE = 0.5\n\nLEARNING_RATE_CLIP = 1e-6\nBASE_LEARNING_RATE = 1e-4\nMOMENTUM = 0.9\n\nTRAINING_EPOCHES = FLAGS.epoch\nMARGINS = [FLAGS.margin_same, FLAGS.margin_diff]\n\nprint(\'### Training epoch: {0}\'.format(TRAINING_EPOCHES))\n\nMODEL_STORAGE_PATH = os.path.join(OUTPUT_DIR, \'trained_models\')\nif not os.path.exists(MODEL_STORAGE_PATH):\n    os.mkdir(MODEL_STORAGE_PATH)\n\nLOG_STORAGE_PATH = os.path.join(OUTPUT_DIR, \'logs\')\nif not os.path.exists(LOG_STORAGE_PATH):\n    os.mkdir(LOG_STORAGE_PATH)\n\nSUMMARIES_FOLDER = os.path.join(OUTPUT_DIR, \'summaries\')\nif not os.path.exists(SUMMARIES_FOLDER):\n    os.mkdir(SUMMARIES_FOLDER)\n\nLOG_DIR = FLAGS.output_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\n\nos.system(\'cp %s %s\' % (os.path.join(BASE_DIR, \'models/model.py\'), LOG_DIR))  # bkp of model def\nos.system(\'cp %s %s\' % (os.path.join(BASE_DIR, \'train.py\'), LOG_DIR))  # bkp of train procedure\n\ndef printout(flog, data):\n    print(data)\n    flog.write(data + \'\\n\')\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device(\'/gpu:\' + str(FLAGS.gpu)):\n            batch = tf.Variable(0, trainable=False, name=\'batch\')\n            learning_rate = tf.train.exponential_decay(\n                BASE_LEARNING_RATE,  # base learning rate\n                batch * BATCH_SIZE,  # global_var indicating the number of steps\n                DECAY_STEP,  # step size\n                DECAY_RATE,  # decay rate\n                staircase=True  # Stair-case or continuous decreasing\n            )\n            learning_rate = tf.maximum(learning_rate, LEARNING_RATE_CLIP)\n\n            lr_op = tf.summary.scalar(\'learning_rate\', learning_rate)\n\n            pointclouds_ph, ptsseglabel_ph, ptsgroup_label_ph, pts_seglabel_mask_ph, pts_group_mask_ph, alpha_ph = \\\n                model.placeholder_inputs(BATCH_SIZE, POINT_NUM, NUM_GROUPS, NUM_CATEGORY)\n            is_training_ph = tf.placeholder(tf.bool, shape=())\n\n            labels = {\'ptsgroup\': ptsgroup_label_ph,\n                      \'semseg\': ptsseglabel_ph,\n                      \'semseg_mask\': pts_seglabel_mask_ph,\n                      \'group_mask\': pts_group_mask_ph}\n\n            net_output = model.get_model(pointclouds_ph, is_training_ph, group_cate_num=NUM_CATEGORY, m=MARGINS[0])\n            loss, grouperr, same, same_cnt, diff, diff_cnt, pos, pos_cnt = model.get_loss(net_output, labels, alpha_ph, MARGINS)\n\n            total_training_loss_ph = tf.placeholder(tf.float32, shape=())\n            group_err_loss_ph = tf.placeholder(tf.float32, shape=())\n            total_train_loss_sum_op = tf.summary.scalar(\'total_training_loss\', total_training_loss_ph)\n            group_err_op = tf.summary.scalar(\'group_err_loss\', group_err_loss_ph)\n\n        train_variables = tf.trainable_variables()\n\n        trainer = tf.train.AdamOptimizer(learning_rate)\n        train_op = trainer.minimize(loss, var_list=train_variables, global_step=batch)\n\n        loader = tf.train.Saver([v for v in tf.all_variables()#])\n                                 if\n                                   (\'conf_logits\' not in v.name) and\n                                    (\'Fsim\' not in v.name) and\n                                    (\'Fsconf\' not in v.name) and\n                                    (\'batch\' not in v.name)\n                                ])\n\n        saver = tf.train.Saver([v for v in tf.all_variables()])\n\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        sess = tf.Session(config=config)\n\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        train_writer = tf.summary.FileWriter(SUMMARIES_FOLDER + \'/train\', sess.graph)\n\n        train_file_list = provider.getDataFiles(TRAINING_FILE_LIST)\n        num_train_file = len(train_file_list)\n\n        fcmd = open(os.path.join(LOG_STORAGE_PATH, \'cmd.txt\'), \'w\')\n        fcmd.write(str(FLAGS))\n        fcmd.close()\n\n        flog = open(os.path.join(LOG_STORAGE_PATH, \'log.txt\'), \'w\')\n\n        ckptstate = tf.train.get_checkpoint_state(PRETRAINED_MODEL_PATH)\n        if ckptstate is not None:\n            LOAD_MODEL_FILE = os.path.join(PRETRAINED_MODEL_PATH, os.path.basename(ckptstate.model_checkpoint_path))\n            loader.restore(sess, LOAD_MODEL_FILE)\n            printout(flog, ""Model loaded in file: %s"" % LOAD_MODEL_FILE)\n        else:\n            printout(flog, ""Fail to load modelfile: %s"" % PRETRAINED_MODEL_PATH)\n\n\n        train_file_idx = np.arange(0, len(train_file_list))\n        np.random.shuffle(train_file_idx)\n\n        ## load all data into memory\n        all_data = []\n        all_group = []\n        all_seg = []\n        for i in range(num_train_file):\n            cur_train_filename = train_file_list[train_file_idx[i]]\n            # printout(flog, \'Loading train file \' + cur_train_filename)\n            cur_data, cur_group, _, cur_seg = provider.loadDataFile_with_groupseglabel_stanfordindoor(cur_train_filename)\n            all_data += [cur_data]\n            all_group += [cur_group]\n            all_seg += [cur_seg]\n\n        all_data = np.concatenate(all_data,axis=0)\n        all_group = np.concatenate(all_group,axis=0)\n        all_seg = np.concatenate(all_seg,axis=0)\n\n        num_data = all_data.shape[0]\n        num_batch = num_data // BATCH_SIZE\n\n        def train_one_epoch(epoch_num):\n\n            ### NOTE: is_training = False: We do not update bn parameters during training due to the small batch size. This requires pre-training PointNet with large batchsize (say 32).\n            is_training = False\n\n            order = np.arange(num_data)\n            np.random.shuffle(order)\n\n            total_loss = 0.0\n            total_grouperr = 0.0\n            total_same = 0.0\n            total_diff = 0.0\n            total_pos = 0.0\n            same_cnt0 = 0\n\n            for j in range(num_batch):\n                begidx = j * BATCH_SIZE\n                endidx = (j + 1) * BATCH_SIZE\n\n                pts_label_one_hot, pts_label_mask = model.convert_seg_to_one_hot(all_seg[order[begidx: endidx]])\n                pts_group_label, pts_group_mask = model.convert_groupandcate_to_one_hot(all_group[order[begidx: endidx]])\n\n                feed_dict = {\n                    pointclouds_ph: all_data[order[begidx: endidx], ...],\n                    ptsseglabel_ph: pts_label_one_hot,\n                    ptsgroup_label_ph: pts_group_label,\n                    pts_seglabel_mask_ph: pts_label_mask,\n                    pts_group_mask_ph: pts_group_mask,\n                    is_training_ph: is_training,\n                    alpha_ph: min(10., (float(epoch_num) / 5.) * 2. + 2.),\n                }\n\n                _, loss_val, simmat_val, grouperr_val, same_val, same_cnt_val, diff_val, diff_cnt_val, pos_val, pos_cnt_val = sess.run([train_op, loss, net_output[\'simmat\'], grouperr, same, same_cnt, diff, diff_cnt, pos, pos_cnt], feed_dict=feed_dict)\n                total_loss += loss_val\n                total_grouperr += grouperr_val\n                total_diff += (diff_val / diff_cnt_val)\n                if same_cnt_val > 0:\n                    total_same += same_val / same_cnt_val\n                    same_cnt0 += 1\n                total_pos += pos_val / pos_cnt_val\n\n\n                if j % 10 == 9:\n                    printout(flog, \'Batch: %d, loss: %f, grouperr: %f, same: %f, diff: %f, pos: %f\' % (j, total_loss/10, total_grouperr/10, total_same/same_cnt0, total_diff/10, total_pos/10))\n\n                    lr_sum, batch_sum, train_loss_sum, group_err_sum = sess.run( \\\n                        [lr_op, batch, total_train_loss_sum_op, group_err_op], \\\n                        feed_dict={total_training_loss_ph: total_loss / 10.,\n                                   group_err_loss_ph: total_grouperr / 10., })\n\n                    train_writer.add_summary(train_loss_sum, batch_sum)\n                    train_writer.add_summary(lr_sum, batch_sum)\n                    train_writer.add_summary(group_err_sum, batch_sum)\n\n                    total_grouperr = 0.0\n                    total_loss = 0.0\n                    total_diff = 0.0\n                    total_same = 0.0\n                    total_pos = 0.0\n                    same_cnt0 = 0\n\n\n\n            cp_filename = saver.save(sess,\n                                     os.path.join(MODEL_STORAGE_PATH, \'epoch_\' + str(epoch_num + 1) + \'.ckpt\'))\n            printout(flog, \'Successfully store the checkpoint model into \' + cp_filename)\n\n        if not os.path.exists(MODEL_STORAGE_PATH):\n            os.mkdir(MODEL_STORAGE_PATH)\n\n        for epoch in range(TRAINING_EPOCHES):\n            printout(flog, \'\\n>>> Training for the epoch %d/%d ...\' % (epoch, TRAINING_EPOCHES))\n\n            train_file_idx = np.arange(0, len(train_file_list))\n            np.random.shuffle(train_file_idx)\n\n            train_one_epoch(epoch)\n            flog.flush()\n\n            cp_filename = saver.save(sess,\n                                     os.path.join(MODEL_STORAGE_PATH, \'epoch_\' + str(epoch + 1) + \'.ckpt\'))\n            printout(flog, \'Successfully store the checkpoint model into \' + cp_filename)\n\n\n        flog.close()\n\n\nif __name__ == \'__main__\':\n    train()\n'"
valid.py,8,"b'import argparse\nimport tensorflow as tf\nimport os\nos.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""   # see issue #152\nimport provider\nfrom utils.test_utils import *\nfrom models import model\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=str, default=""1"", help=\'GPU to use [default: GPU 1]\')\nparser.add_argument(\'--verbose\', action=\'store_true\', help=\'if specified, use depthconv\')\nparser.add_argument(\'--input_list\', type=str, default=\'/media/hdd2/data/pointnet/stanfordindoor/valid_hdf5_file_list.txt\', help=\'Validation data list\')\nparser.add_argument(\'--restore_dir\', type=str, default=\'checkpoint/stanford_ins_seg_groupmask11_fromgroup_recipweight_nopow2_lr4\', help=\'Directory that stores all training logs and trained models\')\nFLAGS = parser.parse_args()\n\nPRETRAINED_MODEL_PATH = os.path.join(FLAGS.restore_dir,\'trained_models/\')\n\ngpu_to_use = 0\nos.environ[""CUDA_VISIBLE_DEVICES""] = FLAGS.gpu\n\nRESTORE_DIR = FLAGS.restore_dir\nOUTPUT_DIR = os.path.join(FLAGS.restore_dir, \'valid_results\')\nif not os.path.exists(OUTPUT_DIR):\n    os.mkdir(OUTPUT_DIR)\n\nOUTPUT_VERBOSE = FLAGS.verbose  # If true, output similarity\n\n# MAIN SCRIPT\nPOINT_NUM = 4096  # the max number of points in the all testing data shapes\nBATCH_SIZE = 1\nNUM_GROUPS = 50\nNUM_CATEGORY = 13\n\nTESTING_FILE_LISTFILE = FLAGS.input_list\ntest_file_list = provider.getDataFiles(TESTING_FILE_LISTFILE)\nlen_pts_files = len(test_file_list)\n\ndef printout(flog, data):\n    print(data)\n    flog.write(data + \'\\n\')\n\ndef predict():\n    is_training = False\n\n    with tf.device(\'/gpu:\' + str(gpu_to_use)):\n        is_training_ph = tf.placeholder(tf.bool, shape=())\n\n        pointclouds_ph, ptsseglabel_ph, ptsgroup_label_ph, _, _, _ = \\\n            model.placeholder_inputs(BATCH_SIZE, POINT_NUM, NUM_GROUPS, NUM_CATEGORY)\n\n        group_mat_label = tf.matmul(ptsgroup_label_ph, tf.transpose(ptsgroup_label_ph, perm=[0, 2, 1]))\n        net_output = model.get_model(pointclouds_ph, is_training_ph, group_cate_num=NUM_CATEGORY)\n\n    # Add ops to save and restore all the variables.\n    saver = tf.train.Saver()\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n\n    with tf.Session(config=config) as sess:\n\n        # Restore variables from disk.\n\n        ckptstate = tf.train.get_checkpoint_state(PRETRAINED_MODEL_PATH)\n        if ckptstate is not None:\n            LOAD_MODEL_FILE = os.path.join(PRETRAINED_MODEL_PATH,os.path.basename(ckptstate.model_checkpoint_path))\n            saver.restore(sess, LOAD_MODEL_FILE)\n            print (""Model loaded in file: %s"" % LOAD_MODEL_FILE)\n        else:\n            print (""Fail to load modelfile: %s"" % PRETRAINED_MODEL_PATH)\n\n        ths = np.zeros(NUM_CATEGORY)\n        ths_ = np.zeros(NUM_CATEGORY)\n        cnt = np.zeros(NUM_CATEGORY)\n        min_groupsize = np.zeros(NUM_CATEGORY)\n        min_groupsize_cnt = np.zeros(NUM_CATEGORY)\n\n\n        for shape_idx in range(len_pts_files):\n\n            cur_train_filename = test_file_list[shape_idx]\n\n            if not os.path.exists(cur_train_filename):\n                continue\n            cur_data, cur_group, _, cur_seg = provider.loadDataFile_with_groupseglabel_stanfordindoor(cur_train_filename)\n\n            if OUTPUT_VERBOSE:\n                pts = np.reshape(cur_data, [-1,9])\n                output_point_cloud_rgb(pts[:, 6:], pts[:, 3:6], os.path.join(OUTPUT_DIR, \'%d_pts.obj\' % (shape_idx)))\n\n            pts_label_one_hot, pts_label_mask = model.convert_seg_to_one_hot(cur_seg)\n            pts_group_label, _ = model.convert_groupandcate_to_one_hot(cur_group)\n            num_data = cur_data.shape[0]\n\n            cur_seg_flatten = np.reshape(cur_seg, [-1])\n            un, indices = np.unique(cur_group, return_index=True)\n            for iu, u in enumerate(un):\n                groupsize = np.sum(cur_group == u)\n                groupcate = cur_seg_flatten[indices[iu]]\n                min_groupsize[groupcate] += groupsize\n                # print groupsize, min_groupsize[groupcate]/min_groupsize_cnt[groupcate]\n                min_groupsize_cnt[groupcate] += 1\n\n            for j in range(num_data):\n\n                print (""Processsing: Shape [%d] Block[%d]""%(shape_idx, j))\n\n                pts = cur_data[j,...]\n\n                feed_dict = {\n                    pointclouds_ph: np.expand_dims(pts,0),\n                    ptsseglabel_ph: np.expand_dims(pts_label_one_hot[j,...],0),\n                    ptsgroup_label_ph: np.expand_dims(pts_group_label[j,...],0),\n                    is_training_ph: is_training,\n                }\n\n                pts_corr_val0, pred_confidence_val0, ptsclassification_val0, pts_corr_label_val0 = \\\n                                        sess.run([net_output[\'simmat\'],\n                                                  net_output[\'conf\'],\n                                                  net_output[\'semseg\'],\n                                                  group_mat_label],\n                                                  feed_dict=feed_dict)\n                seg = cur_seg[j,...]\n                ins = cur_group[j,...]\n\n                pts_corr_val = np.squeeze(pts_corr_val0[0])\n                pred_confidence_val = np.squeeze(pred_confidence_val0[0])\n                ptsclassification_val = np.argmax(np.squeeze(ptsclassification_val0[0]),axis=1)\n\n                pts_corr_label_val = np.squeeze(1 - pts_corr_label_val0)\n                seg = np.squeeze(seg)\n                ins = np.squeeze(ins)\n\n                ind = (seg == 8)\n                pts_corr_val0 = (pts_corr_val > 1.).astype(np.float)\n                print np.mean(np.transpose(np.abs(pts_corr_label_val[ind] - pts_corr_val0[ind]),axes=[1,0])[ind])\n\n                ths, ths_, cnt = Get_Ths(pts_corr_val, seg, ins, ths, ths_, cnt)\n                print ths/cnt\n\n\n                if OUTPUT_VERBOSE:\n                    un,indices = np.unique(ins,return_index=True)\n                    for ii,id in enumerate(indices):\n                        corr = pts_corr_val[id].copy()\n                        output_scale_point_cloud(pts[:,6:], np.float32(corr), os.path.join(OUTPUT_DIR, \'%d_%d_%d_%d_scale.obj\'%(shape_idx,j,un[ii],seg[id])))\n                        corr = pts_corr_label_val[id]\n                        output_scale_point_cloud(pts[:, 6:], np.float32(corr), os.path.join(OUTPUT_DIR, \'%d_%d_%d_%d_scalegt.obj\' % (shape_idx, j, un[ii],seg[id])))\n                    output_scale_point_cloud(pts[:, 6:], np.float32(pred_confidence_val), os.path.join(OUTPUT_DIR, \'%d_%d_conf.obj\' % (shape_idx, j)))\n                    output_color_point_cloud(pts[:,6:], ptsclassification_val.astype(np.int32), os.path.join(OUTPUT_DIR, \'%d_seg.obj\'%(shape_idx)))\n\n        ths = [ths[i]/cnt[i] if cnt[i] != 0 else 0.2 for i in range(len(cnt))]\n        np.savetxt(os.path.join(RESTORE_DIR, \'pergroup_thres.txt\'), ths)\n\n        min_groupsize = [int(float(min_groupsize[i]) / min_groupsize_cnt[i]) if min_groupsize_cnt[i] != 0 else 0 for i in range(len(min_groupsize))]\n        np.savetxt(os.path.join(RESTORE_DIR, \'mingroupsize.txt\'), min_groupsize)\n\nwith tf.Graph().as_default():\n    predict()\n'"
data/data_prep_util.py,0,"b'""""""\n    Modified from: https://github.com/charlesq34/pointnet/blob/master/utils/data_prep_util.py\n""""""\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nfrom plyfile import (PlyData, PlyElement, make2d, PlyParseError, PlyProperty)\nimport numpy as np\nimport h5py\n\nSAMPLING_BIN = os.path.join(BASE_DIR, \'third_party/mesh_sampling/build/pcsample\')\n\nSAMPLING_POINT_NUM = 2048\nSAMPLING_LEAF_SIZE = 0.005\n\nMODELNET40_PATH = \'../datasets/modelnet40\'\ndef export_ply(pc, filename):\n\tvertex = np.zeros(pc.shape[0], dtype=[(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\')])\n\tfor i in range(pc.shape[0]):\n\t\tvertex[i] = (pc[i][0], pc[i][1], pc[i][2])\n\tply_out = PlyData([PlyElement.describe(vertex, \'vertex\', comments=[\'vertices\'])])\n\tply_out.write(filename)\n\n# Sample points on the obj shape\ndef get_sampling_command(obj_filename, ply_filename):\n    cmd = SAMPLING_BIN + \' \' + obj_filename\n    cmd += \' \' + ply_filename\n    cmd += \' -n_samples %d \' % SAMPLING_POINT_NUM\n    cmd += \' -leaf_size %f \' % SAMPLING_LEAF_SIZE\n    return cmd\n\n# --------------------------------------------------------------\n# Following are the helper functions to load MODELNET40 shapes\n# --------------------------------------------------------------\n\n# Read in the list of categories in MODELNET40\ndef get_category_names():\n    shape_names_file = os.path.join(MODELNET40_PATH, \'shape_names.txt\')\n    shape_names = [line.rstrip() for line in open(shape_names_file)]\n    return shape_names\n\n# Return all the filepaths for the shapes in MODELNET40 \ndef get_obj_filenames():\n    obj_filelist_file = os.path.join(MODELNET40_PATH, \'filelist.txt\')\n    obj_filenames = [os.path.join(MODELNET40_PATH, line.rstrip()) for line in open(obj_filelist_file)]\n    print(\'Got %d obj files in modelnet40.\' % len(obj_filenames))\n    return obj_filenames\n\n# Helper function to create the father folder and all subdir folders if not exist\ndef batch_mkdir(output_folder, subdir_list):\n    if not os.path.exists(output_folder):\n        os.mkdir(output_folder)\n    for subdir in subdir_list:\n        if not os.path.exists(os.path.join(output_folder, subdir)):\n            os.mkdir(os.path.join(output_folder, subdir))\n\n# ----------------------------------------------------------------\n# Following are the helper functions to load save/load HDF5 files\n# ----------------------------------------------------------------\n\n# Write numpy array data and label to h5_filename\ndef save_h5_data_label_normal(h5_filename, data, label, normal, \n\t\tdata_dtype=\'float32\', label_dtype=\'uint8\', normal_dtype=\'float32\'):\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n            \'data\', data=data,\n            compression=\'gzip\', compression_opts=4,\n            dtype=data_dtype)\n    h5_fout.create_dataset(\n            \'normal\', data=normal,\n            compression=\'gzip\', compression_opts=4,\n            dtype=normal_dtype)\n    h5_fout.create_dataset(\n            \'label\', data=label,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.close()\n\n\n# Write numpy array data and label to h5_filename\ndef save_h5(h5_filename, data, label, data_dtype=\'uint8\', label_dtype=\'uint8\'):\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n            \'data\', data=data,\n            compression=\'gzip\', compression_opts=4,\n            dtype=data_dtype)\n    h5_fout.create_dataset(\n            \'label\', data=label,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.close()\n\ndef save_h5ins(h5_filename, data, label, gid,  data_dtype=\'uint8\', label_dtype=\'uint8\'):\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n            \'data\', data=data,\n            compression=\'gzip\', compression_opts=4,\n            dtype=data_dtype)\n    h5_fout.create_dataset(\n            \'seglabel\', data=label,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.create_dataset(\n            \'pid\', data=gid,\n            compression=\'gzip\', compression_opts=1,\n            dtype=label_dtype)\n    # h5_fout.create_dataset(\n    #     \'groupcategory\', data=groupcategory,\n    #     compression=\'gzip\', compression_opts=4,\n    #     dtype=label_dtype)\n    h5_fout.close()\n\n# Read numpy array data and label from h5_filename\ndef load_h5_data_label_normal(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    normal = f[\'normal\'][:]\n    return (data, label, normal)\n\n# Read numpy array data and label from h5_filename\ndef load_h5_data_label_seg(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    seg = f[\'pid\'][:]\n    return (data, label, seg)\n\n# Read numpy array data and label from h5_filename\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    return (data, label)\n\n# ----------------------------------------------------------------\n# Following are the helper functions to load save/load PLY files\n# ----------------------------------------------------------------\n\n# Load PLY file\ndef load_ply_data(filename, point_num):\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data[:point_num]\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n# Load PLY file\ndef load_ply_normal(filename, point_num):\n    plydata = PlyData.read(filename)\n    pc = plydata[\'normal\'].data[:point_num]\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n# Make up rows for Nxk array\n# Input Pad is \'edge\' or \'constant\'\ndef pad_arr_rows(arr, row, pad=\'edge\'):\n    assert(len(arr.shape) == 2)\n    assert(arr.shape[0] <= row)\n    assert(pad == \'edge\' or pad == \'constant\')\n    if arr.shape[0] == row:\n        return arr\n    if pad == \'edge\':\n        return np.lib.pad(arr, ((0, row-arr.shape[0]), (0, 0)), \'edge\')\n    if pad == \'constant\':\n        return np.lib.pad(arr, ((0, row-arr.shape[0]), (0, 0)), \'constant\', (0, 0))\n\n\n'"
data/gen_h5.py,0,"b'import os\nimport numpy as np\nimport data_prep_util\nimport indoor3d_util\n\n# Constants\nStanfordIndoorDataPath = \'StanfordIndoorDataPath\'\nNUM_POINT = 4096\ndata_dtype = \'float32\'\nlabel_dtype = \'int32\'\n\n# Set paths\nfilelist = os.path.join(StanfordIndoorDataPath, \'meta/areaexcept5_data_label.txt\')\ndata_label_files = [os.path.join(StanfordIndoorDataPath, \'annotation/\', line.rstrip()) for line in open(filelist)]\noutput_dir = os.path.join(StanfordIndoorDataPath, \'indoor3d_ins_seg_hdf5\')\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\noutput_room_filelist = os.path.join(output_dir, \'room_filelist.txt\')\nfout_room = open(output_room_filelist, \'w\')\n\nsample_cnt = 0\nfor i in range(0, len(data_label_files)):\n    data_label_filename = data_label_files[i]\n    fname = os.path.basename(data_label_filename).strip(\'.npy\')\n    if not os.path.exists(data_label_filename):\n        continue\n    data, label, inslabel = indoor3d_util.room2blocks_wrapper_normalized(data_label_filename, NUM_POINT, block_size=1.0, stride=0.5,\n                                                 random_sample=False, sample_num=None)\n    for _ in range(data.shape[0]):\n        fout_room.write(os.path.basename(data_label_filename)[0:-4]+\'\\n\')\n\n    sample_cnt += data.shape[0]\n    h5_filename = os.path.join(output_dir, \'%s.h5\' % fname)\n    print(\'{0}: {1}, {2}, {3}\'.format(h5_filename, data.shape, label.shape, inslabel.shape))\n    data_prep_util.save_h5ins(h5_filename,\n                              data,\n                              label,\n                              inslabel,\n                              data_dtype, label_dtype)\n\nfout_room.close()\nprint(""Total samples: {0}"".format(sample_cnt))\n'"
data/indoor3d_util.py,0,"b'""""""\n    Modified from: https://github.com/charlesq34/pointnet/blob/master/sem_seg/indoor3d_util.py\n""""""\nimport numpy as np\nimport glob\nimport os\nimport sys\n\n# -----------------------------------------------------------------------------\n# CONSTANTS\n# -----------------------------------------------------------------------------\nStanfordIndoorDataPath = \'StanfordIndoorDataPath\'\ng_classes = [x.rstrip() for x in open(os.path.join(StanfordIndoorDataPath, \'meta/class_names.txt\'))]\ng_class2label = {cls: i for i,cls in enumerate(g_classes)}\ng_class2color = {\'ceiling\': [0,255,0],\n                 \'floor\':   [0,0,255],\n                 \'wall\':    [0,255,255],\n                 \'beam\':        [255,255,0],\n                 \'column\':      [255,0,255],\n                 \'window\':      [100,100,255],\n                 \'door\':        [200,200,100],\n                 \'table\':       [170,120,200],\n                 \'chair\':       [255,0,0],\n                 \'sofa\':        [200,100,100],\n                 \'bookcase\':    [10,200,100],\n                 \'board\':       [200,200,200],\n                 \'clutter\':     [50,50,50]} \ng_easy_view_labels = [7,8,9,10,11,1]\ng_label2color = {g_classes.index(cls): g_class2color[cls] for cls in g_classes}\n\n\n# -----------------------------------------------------------------------------\n# CONVERT ORIGINAL DATA TO OUR DATA_LABEL FILES\n# -----------------------------------------------------------------------------\n\ndef collect_point_label(anno_path, out_filename, file_format=\'txt\'):\n    """""" Convert original dataset files to data_label file (each line is XYZRGBLG).\n        We aggregated all the points from each instance in the room.\n\n    Args:\n        anno_path: path to annotations. e.g. Area_1/office_2/Annotations/\n        out_filename: path to save collected points and labels (each line is XYZRGBLG)\n        file_format: txt or numpy, determines what file format to save.\n    Returns:\n        None\n    Note:\n        the points are shifted before save, the most negative point is now at origin.\n    """"""\n    points_list = []\n\n    instanceid = 0\n    for f in glob.glob(os.path.join(anno_path, \'*.txt\')):\n        cls = os.path.basename(f).split(\'_\')[0]\n        if cls not in g_classes: # note: in some room there is \'staris\' class..\n            cls = \'clutter\'\n        points = np.loadtxt(f)\n        labels = np.ones((points.shape[0],1)) * g_class2label[cls]\n        instancelabels = np.ones((points.shape[0],1)) * instanceid\n        instanceid += 1\n        points_list.append(np.concatenate([points, labels, instancelabels], 1)) # Nx7\n    \n    data_label = np.concatenate(points_list, 0)\n    xyz_min = np.amin(data_label, axis=0)[0:3]\n    data_label[:, 0:3] -= xyz_min\n    \n    if file_format==\'txt\':\n        fout = open(out_filename, \'w\')\n        for i in range(data_label.shape[0]):\n            fout.write(\'%f %f %f %d %d %d %d\\n\' % \\\n                          (data_label[i,0], data_label[i,1], data_label[i,2],\n                           data_label[i,3], data_label[i,4], data_label[i,5],\n                           data_label[i,6]))\n        fout.close()\n    elif file_format==\'numpy\':\n        np.save(out_filename, data_label)\n    else:\n        print(\'ERROR!! Unknown file format: %s, please use txt or numpy.\' % \\\n            (file_format))\n        exit()\n\ndef point_label_to_obj(input_filename, out_filename, label_color=True, easy_view=False, no_wall=False):\n    """""" For visualization of a room from data_label file,\n    input_filename: each line is X Y Z R G B L\n    out_filename: OBJ filename,\n            visualize input file by coloring point with label color\n        easy_view: only visualize furnitures and floor\n    """"""\n    data_label = np.loadtxt(input_filename)\n    data = data_label[:, 0:6]\n    label = data_label[:, -1].astype(int)\n    fout = open(out_filename, \'w\')\n    for i in range(data.shape[0]):\n        color = g_label2color[label[i]]\n        if easy_view and (label[i] not in g_easy_view_labels):\n            continue\n        if no_wall and ((label[i] == 2) or (label[i]==0)):\n            continue\n        if label_color:\n            fout.write(\'v %f %f %f %d %d %d\\n\' % \\\n                (data[i,0], data[i,1], data[i,2], color[0], color[1], color[2]))\n        else:\n            fout.write(\'v %f %f %f %d %d %d\\n\' % \\\n                (data[i,0], data[i,1], data[i,2], data[i,3], data[i,4], data[i,5]))\n    fout.close()\n \n\n\n# -----------------------------------------------------------------------------\n# PREPARE BLOCK DATA FOR DEEPNETS TRAINING/TESTING\n# -----------------------------------------------------------------------------\n\ndef sample_data(data, num_sample):\n    """""" data is in N x ...\n        we want to keep num_samplexC of them.\n        if N > num_sample, we will randomly keep num_sample of them.\n        if N < num_sample, we will randomly duplicate samples.\n    """"""\n    N = data.shape[0]\n    if (N == num_sample):\n        return data, range(N)\n    elif (N > num_sample):\n        sample = np.random.choice(N, num_sample)\n        return data[sample, ...], sample\n    else:\n        sample = np.random.choice(N, num_sample-N)\n        dup_data = data[sample, ...]\n        return np.concatenate([data, dup_data], 0), range(N)+list(sample)\n\ndef sample_data_label(data, label, inslabel, num_sample):\n    new_data, sample_indices = sample_data(data, num_sample)\n    new_label = label[sample_indices]\n    new_inslabel = inslabel[sample_indices]\n    return new_data, new_label, new_inslabel\n    \ndef room2blocks(data, label, inslabel, num_point, block_size=1.0, stride=1.0,\n                random_sample=False, sample_num=None, sample_aug=1):\n    """""" Prepare block training data.\n    Args:\n        data: N x 6 numpy array, 012 are XYZ in meters, 345 are RGB in [0,1]\n            assumes the data is shifted (min point is origin) and aligned\n            (aligned with XYZ axis)\n        label: N size uint8 numpy array from 0-12\n        num_point: int, how many points to sample in each block\n        block_size: float, physical size of the block in meters\n        stride: float, stride for block sweeping\n        random_sample: bool, if True, we will randomly sample blocks in the room\n        sample_num: int, if random sample, how many blocks to sample\n            [default: room area]\n        sample_aug: if random sample, how much aug\n    Returns:\n        block_datas: K x num_point x 6 np array of XYZRGB, RGB is in [0,1]\n        block_labels: K x num_point x 1 np array of uint8 labels\n        \n    TODO: for this version, blocking is in fixed, non-overlapping pattern.\n    """"""\n    assert(stride<=block_size)\n\n    limit = np.amax(data, 0)[0:3]\n     \n    # Get the corner location for our sampling blocks    \n    xbeg_list = []\n    ybeg_list = []\n    if not random_sample:\n        num_block_x = int(np.ceil((limit[0] - block_size) / stride)) + 1\n        num_block_y = int(np.ceil((limit[1] - block_size) / stride)) + 1\n        for i in range(num_block_x):\n            if i % 2 == 0:\n                for j in range(num_block_y):\n                    xbeg_list.append(i*stride)\n                    ybeg_list.append(j*stride)\n            else:\n                for j in range(num_block_y)[::-1]:\n                    xbeg_list.append(i*stride)\n                    ybeg_list.append(j*stride)\n\n    else:\n        num_block_x = int(np.ceil(limit[0] / block_size))\n        num_block_y = int(np.ceil(limit[1] / block_size))\n        if sample_num is None:\n            sample_num = num_block_x * num_block_y * sample_aug\n        for _ in range(sample_num):\n            xbeg = np.random.uniform(-block_size, limit[0]) \n            ybeg = np.random.uniform(-block_size, limit[1]) \n            xbeg_list.append(xbeg)\n            ybeg_list.append(ybeg)\n\n    # Collect blocks\n    block_data_list = []\n    block_label_list = []\n    block_inslabel_list = []\n    idx = 0\n    for idx in range(len(xbeg_list)): \n       xbeg = xbeg_list[idx]\n       ybeg = ybeg_list[idx]\n       xcond = (data[:,0]<=xbeg+block_size) & (data[:,0]>=xbeg)\n       ycond = (data[:,1]<=ybeg+block_size) & (data[:,1]>=ybeg)\n       cond = xcond & ycond\n       if np.sum(cond) < 100: # discard block if there are less than 100 pts.\n           continue\n       \n       block_data = data[cond, :]\n       block_label = label[cond]\n       block_inslabel = inslabel[cond]\n       \n       # randomly subsample data\n       block_data_sampled, block_label_sampled, block_inslabel_sampled = \\\n           sample_data_label(block_data, block_label, block_inslabel, num_point)\n       block_data_list.append(np.expand_dims(block_data_sampled, 0))\n       block_label_list.append(np.expand_dims(block_label_sampled, 0))\n       block_inslabel_list.append(np.expand_dims(block_inslabel_sampled, 0))\n            \n    return np.concatenate(block_data_list, 0), \\\n           np.concatenate(block_label_list, 0),\\\n           np.concatenate(block_inslabel_list, 0)\n\n\ndef room2blocks_plus(data_label, num_point, block_size, stride,\n                     random_sample, sample_num, sample_aug):\n    """""" room2block with input filename and RGB preprocessing.\n    """"""\n    data = data_label[:,0:6]\n    data[:,3:6] /= 255.0\n    label = data_label[:,-1].astype(np.uint8)\n    \n    return room2blocks(data, label, num_point, block_size, stride,\n                       random_sample, sample_num, sample_aug)\n   \ndef room2blocks_wrapper(data_label_filename, num_point, block_size=1.0, stride=1.0,\n                        random_sample=False, sample_num=None, sample_aug=1):\n    if data_label_filename[-3:] == \'txt\':\n        data_label = np.loadtxt(data_label_filename)\n    elif data_label_filename[-3:] == \'npy\':\n        data_label = np.load(data_label_filename)\n    else:\n        print(\'Unknown file type! exiting.\')\n        exit()\n    return room2blocks_plus(data_label, num_point, block_size, stride,\n                            random_sample, sample_num, sample_aug)\n\ndef room2blocks_plus_normalized(data_label, num_point, block_size, stride,\n                                random_sample, sample_num, sample_aug):\n    """""" room2block, with input filename and RGB preprocessing.\n        for each block centralize XYZ, add normalized XYZ as 678 channels\n    """"""\n    data = data_label[:,0:6]\n    data[:,3:6] /= 255.0\n    label = data_label[:,-2].astype(np.uint8)\n    inslabel = data_label[:,-1].astype(np.uint8)\n    max_room_x = max(data[:,0])\n    max_room_y = max(data[:,1])\n    max_room_z = max(data[:,2])\n    \n    data_batch, label_batch, inslabel_batch = room2blocks(data, label, inslabel, num_point, block_size, stride,\n                                          random_sample, sample_num, sample_aug)\n    new_data_batch = np.zeros((data_batch.shape[0], num_point, 9))\n    for b in range(data_batch.shape[0]):\n        new_data_batch[b, :, 6] = data_batch[b, :, 0]/max_room_x\n        new_data_batch[b, :, 7] = data_batch[b, :, 1]/max_room_y\n        new_data_batch[b, :, 8] = data_batch[b, :, 2]/max_room_z\n        minx = min(data_batch[b, :, 0])\n        miny = min(data_batch[b, :, 1])\n        data_batch[b, :, 0] -= (minx+block_size/2)\n        data_batch[b, :, 1] -= (miny+block_size/2)\n    new_data_batch[:, :, 0:6] = data_batch\n    return new_data_batch, label_batch, inslabel_batch\n\n\ndef room2blocks_wrapper_normalized(data_label_filename, num_point, block_size=1.0, stride=1.0,\n                                   random_sample=False, sample_num=None, sample_aug=1):\n    if data_label_filename[-3:] == \'txt\':\n        data_label = np.loadtxt(data_label_filename)\n    elif data_label_filename[-3:] == \'npy\':\n        data_label = np.load(data_label_filename)\n    else:\n        print(\'Unknown file type! exiting.\')\n        exit()\n    return room2blocks_plus_normalized(data_label, num_point, block_size, stride,\n                                       random_sample, sample_num, sample_aug)\n\n\ndef room2samples(data, label, inslabel, sample_num_point):\n    """""" Prepare whole room samples.\n\n    Args:\n        data: N x 6 numpy array, 012 are XYZ in meters, 345 are RGB in [0,1]\n            assumes the data is shifted (min point is origin) and\n            aligned (aligned with XYZ axis)\n        label: N size uint8 numpy array from 0-12\n        sample_num_point: int, how many points to sample in each sample\n    Returns:\n        sample_datas: K x sample_num_point x 9\n                     numpy array of XYZRGBX\'Y\'Z\', RGB is in [0,1]\n        sample_labels: K x sample_num_point x 1 np array of uint8 labels\n    """"""\n    N = data.shape[0]\n    order = np.arange(N)\n    np.random.shuffle(order) \n    data = data[order, :]\n    label = label[order]\n\n    batch_num = int(np.ceil(N / float(sample_num_point)))\n    sample_datas = np.zeros((batch_num, sample_num_point, 6))\n    sample_labels = np.zeros((batch_num, sample_num_point))\n    sample_inslabels = np.zeros((batch_num, sample_num_point))\n\n    for i in range(batch_num):\n        beg_idx = i*sample_num_point\n        end_idx = min((i+1)*sample_num_point, N)\n        num = end_idx - beg_idx\n        sample_datas[i,0:num,:] = data[beg_idx:end_idx, :]\n        sample_labels[i,0:num] = label[beg_idx:end_idx]\n        sample_inslabels[i,0:num] = inslabel[beg_idx:end_idx]\n        if num < sample_num_point:\n            makeup_indices = np.random.choice(N, sample_num_point - num)\n            sample_datas[i,num:,:] = data[makeup_indices, :]\n            sample_labels[i,num:] = label[makeup_indices]\n            sample_inslabels[i,num:] = inslabel[makeup_indices]\n\n    return sample_datas, sample_labels, sample_inslabels\n\ndef room2samples_plus_normalized(data_label, num_point):\n    """""" room2sample, with input filename and RGB preprocessing.\n        for each block centralize XYZ, add normalized XYZ as 678 channels\n    """"""\n    data = data_label[:,0:6]\n    data[:,3:6] /= 255.0\n    label = data_label[:,-2].astype(np.uint8)\n    inslabel = data_label[:,-1].astype(np.uint8)\n    max_room_x = max(data[:,0])\n    max_room_y = max(data[:,1])\n    max_room_z = max(data[:,2])\n    #print(max_room_x, max_room_y, max_room_z)\n    \n    data_batch, label_batch, inslabel_batch = room2samples(data, label, inslabel, num_point)\n    new_data_batch = np.zeros((data_batch.shape[0], num_point, 9))\n    for b in range(data_batch.shape[0]):\n        new_data_batch[b, :, 6] = data_batch[b, :, 0]/max_room_x\n        new_data_batch[b, :, 7] = data_batch[b, :, 1]/max_room_y\n        new_data_batch[b, :, 8] = data_batch[b, :, 2]/max_room_z\n        #minx = min(data_batch[b, :, 0])\n        #miny = min(data_batch[b, :, 1])\n        #data_batch[b, :, 0] -= (minx+block_size/2)\n        #data_batch[b, :, 1] -= (miny+block_size/2)\n    new_data_batch[:, :, 0:6] = data_batch\n    return new_data_batch, label_batch, inslabel_batch\n\n\ndef room2samples_wrapper_normalized(data_label_filename, num_point):\n    if data_label_filename[-3:] == \'txt\':\n        data_label = np.loadtxt(data_label_filename)\n    elif data_label_filename[-3:] == \'npy\':\n        data_label = np.load(data_label_filename)\n    else:\n        print(\'Unknown file type! exiting.\')\n        exit()\n    return room2samples_plus_normalized(data_label, num_point)\n\n\n# -----------------------------------------------------------------------------\n# EXTRACT INSTANCE BBOX FROM ORIGINAL DATA (for detection evaluation)\n# -----------------------------------------------------------------------------\n\ndef collect_bounding_box(anno_path, out_filename):\n    """""" Compute bounding boxes from each instance in original dataset files on\n        one room. **We assume the bbox is aligned with XYZ coordinate.**\n    \n    Args:\n        anno_path: path to annotations. e.g. Area_1/office_2/Annotations/\n        out_filename: path to save instance bounding boxes for that room.\n            each line is x1 y1 z1 x2 y2 z2 label,\n            where (x1,y1,z1) is the point on the diagonal closer to origin\n    Returns:\n        None\n    Note:\n        room points are shifted, the most negative point is now at origin.\n    """"""\n    bbox_label_list = []\n\n    for f in glob.glob(os.path.join(anno_path, \'*.txt\')):\n        cls = os.path.basename(f).split(\'_\')[0]\n        if cls not in g_classes: # note: in some room there is \'staris\' class..\n            cls = \'clutter\'\n        points = np.loadtxt(f)\n        label = g_class2label[cls]\n        # Compute tightest axis aligned bounding box\n        xyz_min = np.amin(points[:, 0:3], axis=0)\n        xyz_max = np.amax(points[:, 0:3], axis=0)\n        ins_bbox_label = np.expand_dims(\n            np.concatenate([xyz_min, xyz_max, np.array([label])], 0), 0)\n        bbox_label_list.append(ins_bbox_label)\n\n    bbox_label = np.concatenate(bbox_label_list, 0)\n    room_xyz_min = np.amin(bbox_label[:, 0:3], axis=0)\n    bbox_label[:, 0:3] -= room_xyz_min \n    bbox_label[:, 3:6] -= room_xyz_min \n\n    fout = open(out_filename, \'w\')\n    for i in range(bbox_label.shape[0]):\n        fout.write(\'%f %f %f %f %f %f %d\\n\' % \\\n                      (bbox_label[i,0], bbox_label[i,1], bbox_label[i,2],\n                       bbox_label[i,3], bbox_label[i,4], bbox_label[i,5],\n                       bbox_label[i,6]))\n    fout.close()\n\ndef bbox_label_to_obj(input_filename, out_filename_prefix, easy_view=False):\n    """""" Visualization of bounding boxes.\n    \n    Args:\n        input_filename: each line is x1 y1 z1 x2 y2 z2 label\n        out_filename_prefix: OBJ filename prefix,\n            visualize object by g_label2color\n        easy_view: if True, only visualize furniture and floor\n    Returns:\n        output a list of OBJ file and MTL files with the same prefix\n    """"""\n    bbox_label = np.loadtxt(input_filename)\n    bbox = bbox_label[:, 0:6]\n    label = bbox_label[:, -1].astype(int)\n    v_cnt = 0 # count vertex\n    ins_cnt = 0 # count instance\n    for i in range(bbox.shape[0]):\n        if easy_view and (label[i] not in g_easy_view_labels):\n            continue\n        obj_filename = out_filename_prefix+\'_\'+g_classes[label[i]]+\'_\'+str(ins_cnt)+\'.obj\'\n        mtl_filename = out_filename_prefix+\'_\'+g_classes[label[i]]+\'_\'+str(ins_cnt)+\'.mtl\'\n        fout_obj = open(obj_filename, \'w\')\n        fout_mtl = open(mtl_filename, \'w\')\n        fout_obj.write(\'mtllib %s\\n\' % (os.path.basename(mtl_filename)))\n\n        length = bbox[i, 3:6] - bbox[i, 0:3]\n        a = length[0]\n        b = length[1]\n        c = length[2]\n        x = bbox[i, 0]\n        y = bbox[i, 1]\n        z = bbox[i, 2]\n        color = np.array(g_label2color[label[i]], dtype=float) / 255.0\n\n        material = \'material%d\' % (ins_cnt)\n        fout_obj.write(\'usemtl %s\\n\' % (material))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z))\n        fout_obj.write(\'g default\\n\')\n        v_cnt = 0 # for individual box\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 3+v_cnt, 2+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (1+v_cnt, 2+v_cnt, 6+v_cnt, 5+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (7+v_cnt, 6+v_cnt, 2+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 8+v_cnt, 7+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 8+v_cnt, 4+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 6+v_cnt, 7+v_cnt, 8+v_cnt))\n        fout_obj.write(\'\\n\')\n\n        fout_mtl.write(\'newmtl %s\\n\' % (material))\n        fout_mtl.write(\'Kd %f %f %f\\n\' % (color[0], color[1], color[2]))\n        fout_mtl.write(\'\\n\')\n        fout_obj.close()\n        fout_mtl.close() \n\n        v_cnt += 8\n        ins_cnt += 1\n\ndef bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):\n    """""" Visualization of bounding boxes.\n    \n    Args:\n        input_filename: each line is x1 y1 z1 x2 y2 z2 label\n        out_filename_prefix: OBJ filename prefix,\n            visualize object by g_label2color\n        easy_view: if True, only visualize furniture and floor\n        permute: if not None, permute XYZ for rendering, e.g. [0 2 1]\n        center: if True, move obj to have zero origin\n    Returns:\n        output a list of OBJ file and MTL files with the same prefix\n    """"""\n    bbox_label = np.loadtxt(input_filename)\n    bbox = bbox_label[:, 0:6]\n    if permute is not None:\n        assert(len(permute)==3)\n        permute = np.array(permute)\n        bbox[:,0:3] = bbox[:,permute]\n        bbox[:,3:6] = bbox[:,permute+3]\n    if center:\n        xyz_max = np.amax(bbox[:,3:6], 0)\n        bbox[:,0:3] -= (xyz_max/2.0)\n        bbox[:,3:6] -= (xyz_max/2.0)\n        bbox /= np.max(xyz_max/2.0)\n    label = bbox_label[:, -1].astype(int)\n    obj_filename = out_filename_prefix+\'.obj\' \n    mtl_filename = out_filename_prefix+\'.mtl\'\n\n    fout_obj = open(obj_filename, \'w\')\n    fout_mtl = open(mtl_filename, \'w\')\n    fout_obj.write(\'mtllib %s\\n\' % (os.path.basename(mtl_filename)))\n    v_cnt = 0 # count vertex\n    ins_cnt = 0 # count instance\n    for i in range(bbox.shape[0]):\n        if easy_view and (label[i] not in g_easy_view_labels):\n            continue\n        if exclude_table and label[i] == g_classes.index(\'table\'):\n            continue\n\n        length = bbox[i, 3:6] - bbox[i, 0:3]\n        a = length[0]\n        b = length[1]\n        c = length[2]\n        x = bbox[i, 0]\n        y = bbox[i, 1]\n        z = bbox[i, 2]\n        color = np.array(g_label2color[label[i]], dtype=float) / 255.0\n\n        material = \'material%d\' % (ins_cnt)\n        fout_obj.write(\'usemtl %s\\n\' % (material))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z))\n        fout_obj.write(\'g default\\n\')\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 3+v_cnt, 2+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (1+v_cnt, 2+v_cnt, 6+v_cnt, 5+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (7+v_cnt, 6+v_cnt, 2+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 8+v_cnt, 7+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 8+v_cnt, 4+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 6+v_cnt, 7+v_cnt, 8+v_cnt))\n        fout_obj.write(\'\\n\')\n\n        fout_mtl.write(\'newmtl %s\\n\' % (material))\n        fout_mtl.write(\'Kd %f %f %f\\n\' % (color[0], color[1], color[2]))\n        fout_mtl.write(\'\\n\')\n\n        v_cnt += 8\n        ins_cnt += 1\n\n    fout_obj.close()\n    fout_mtl.close() \n\n\ndef collect_point_bounding_box(anno_path, out_filename, file_format):\n    """""" Compute bounding boxes from each instance in original dataset files on\n        one room. **We assume the bbox is aligned with XYZ coordinate.**\n        Save both the point XYZRGB and the bounding box for the point\'s\n        parent element.\n \n    Args:\n        anno_path: path to annotations. e.g. Area_1/office_2/Annotations/\n        out_filename: path to save instance bounding boxes for each point,\n            plus the point\'s XYZRGBL\n            each line is XYZRGBL offsetX offsetY offsetZ a b c,\n            where cx = X+offsetX, cy=X+offsetY, cz=Z+offsetZ\n            where (cx,cy,cz) is center of the box, a,b,c are distances from center\n            to the surfaces of the box, i.e. x1 = cx-a, x2 = cx+a, y1=cy-b etc.\n        file_format: output file format, txt or numpy\n    Returns:\n        None\n\n    Note:\n        room points are shifted, the most negative point is now at origin.\n    """"""\n    point_bbox_list = []\n\n    for f in glob.glob(os.path.join(anno_path, \'*.txt\')):\n        cls = os.path.basename(f).split(\'_\')[0]\n        if cls not in g_classes: # note: in some room there is \'staris\' class..\n            cls = \'clutter\'\n        points = np.loadtxt(f) # Nx6\n        label = g_class2label[cls] # N,\n        # Compute tightest axis aligned bounding box\n        xyz_min = np.amin(points[:, 0:3], axis=0) # 3,\n        xyz_max = np.amax(points[:, 0:3], axis=0) # 3,\n        xyz_center = (xyz_min + xyz_max) / 2\n        dimension = (xyz_max - xyz_min) / 2\n\n        xyz_offsets = xyz_center - points[:,0:3] # Nx3\n        dimensions = np.ones((points.shape[0],3)) * dimension # Nx3\n        labels = np.ones((points.shape[0],1)) * label # N\n        point_bbox_list.append(np.concatenate([points, labels,\n                                           xyz_offsets, dimensions], 1)) # Nx13\n\n    point_bbox = np.concatenate(point_bbox_list, 0) # KxNx13\n    room_xyz_min = np.amin(point_bbox[:, 0:3], axis=0)\n    point_bbox[:, 0:3] -= room_xyz_min \n\n    if file_format == \'txt\':\n        fout = open(out_filename, \'w\')\n        for i in range(point_bbox.shape[0]):\n            fout.write(\'%f %f %f %d %d %d %d %f %f %f %f %f %f\\n\' % \\\n                          (point_bbox[i,0], point_bbox[i,1], point_bbox[i,2],\n                           point_bbox[i,3], point_bbox[i,4], point_bbox[i,5],\n                           point_bbox[i,6],\n                           point_bbox[i,7], point_bbox[i,8], point_bbox[i,9],\n                           point_bbox[i,10], point_bbox[i,11], point_bbox[i,12]))\n        \n        fout.close()\n    elif file_format == \'numpy\':\n        np.save(out_filename, point_bbox)\n    else:\n        print(\'ERROR!! Unknown file format: %s, please use txt or numpy.\' % \\\n            (file_format))\n        exit()\n\n\n'"
models/__init__.py,0,b''
models/alexnet.py,21,"b'""""""This is an TensorFLow implementation of AlexNet by Alex Krizhevsky at all.\nPaper:\n(http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\nExplanation can be found in my blog post:\nhttps://kratzert.github.io/2017/02/24/finetuning-alexnet-with-tensorflow.html\nThis script enables finetuning AlexNet on any given Dataset with any number of\nclasses. The structure of this script is strongly inspired by the fast.ai\nDeep Learning class by Jeremy Howard and Rachel Thomas, especially their vgg16\nfinetuning script:\nLink:\n- https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py\nThe pretrained weights can be downloaded here and should be placed in the same\nfolder as this file:\n- http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\n@author: Frederik Kratzert (contact: f.kratzert(at)gmail.com)\n""""""\n\nimport tensorflow as tf\nimport numpy as np\n\n\nclass AlexNet(object):\n    """"""Implementation of the AlexNet.""""""\n\n    def __init__(self, x,  skip_layer,\n                 weights_path=\'DEFAULT\'):\n        """"""Create the graph of the AlexNet model.\n        Args:\n            x: Placeholder for the input tensor.\n            keep_prob: Dropout probability.\n            num_classes: Number of classes in the dataset.\n            skip_layer: List of names of the layer, that get trained from\n                scratch\n            weights_path: Complete path to the pretrained weight file, if it\n                isn\'t in the same folder as this code\n        """"""\n        # Parse input arguments into class variables\n        self.X = x\n        # self.NUM_CLASSES = num_classes\n        # self.KEEP_PROB = keep_prob\n        self.SKIP_LAYER = skip_layer\n\n        if weights_path == \'DEFAULT\':\n            self.WEIGHTS_PATH = \'bvlc_alexnet.npy\'\n        else:\n            self.WEIGHTS_PATH = weights_path\n\n        # Call the create function to build the computational graph of AlexNet\n        self.create()\n\n    def create(self):\n        """"""Create the network graph.""""""\n        # 1st Layer: Conv (w ReLu) -> Lrn -> Pool\n        conv1 = conv(self.X, 11, 11, 96, 1, 1, padding=\'SAME\', name=\'conv1\')\n        norm1 = lrn(conv1, 2, 2e-05, 0.75, name=\'norm1\')\n        pool1 = max_pool(norm1, 3, 3, 2, 2, padding=\'SAME\', name=\'pool1\')\n        \n        # 2nd Layer: Conv (w ReLu)  -> Lrn -> Pool with 2 groups\n        conv2 = conv(pool1, 5, 5, 256, 1, 1, groups=2, name=\'conv2\')\n        norm2 = lrn(conv2, 2, 2e-05, 0.75, name=\'norm2\')\n        pool2 = max_pool(norm2, 3, 3, 2, 2, padding=\'SAME\', name=\'pool2\')\n        \n        # 3rd Layer: Conv (w ReLu)\n        conv3 = conv(pool2, 3, 3, 384, 1, 1, name=\'conv3\')\n\n        # 4th Layer: Conv (w ReLu) splitted into two groups\n        conv4 = conv(conv3, 3, 3, 384, 1, 1, groups=2, name=\'conv4\')\n\n        # 5th Layer: Conv (w ReLu) -> Pool splitted into two groups\n        conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name=\'conv5\')\n\n        # pool5 = max_pool(conv5, 3, 3, 2, 2, padding=\'VALID\', name=\'pool5\')\n\n        # 6th Layer: Flatten -> FC (w ReLu) -> Dropout\n        # flattened = tf.reshape(pool5, [-1, 6*6*256])\n        # fc6 = fc(flattened, 6*6*256, 4096, name=\'fc6\')\n        # dropout6 = dropout(fc6, self.KEEP_PROB)\n\n        # # 7th Layer: FC (w ReLu) -> Dropout\n        # fc7 = fc(dropout6, 4096, 4096, name=\'fc7\')\n        # dropout7 = dropout(fc7, self.KEEP_PROB)\n\n        # 8th Layer: FC and return unscaled activations\n        self.out = conv5#fc(dropout7, 4096, self.NUM_CLASSES, relu=False, name=\'fc8\')\n\n    def load_initial_weights(self, session):\n        """"""Load weights from file into network.\n        As the weights from http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\n        come as a dict of lists (e.g. weights[\'conv1\'] is a list) and not as\n        dict of dicts (e.g. weights[\'conv1\'] is a dict with keys \'weights\' &\n        \'biases\') we need a special load function\n        """"""\n        # Load the weights into memory\n        weights_dict = np.load(self.WEIGHTS_PATH, encoding=\'bytes\').item()\n\n        # Loop over all layer names stored in the weights dict\n        for op_name in weights_dict:\n\n            # Check if layer should be trained from scratch\n            if op_name not in self.SKIP_LAYER:\n\n                with tf.variable_scope(op_name, reuse=True):\n\n                    # Assign weights/biases to their corresponding tf variable\n                    for data in weights_dict[op_name]:\n\n                        # Biases\n                        if len(data.shape) == 1:\n                            var = tf.get_variable(\'biases\', trainable=False)\n                            session.run(var.assign(data))\n\n                        # Weights\n                        else:\n                            var = tf.get_variable(\'weights\', trainable=False)\n                            session.run(var.assign(data))\n\n\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,\n         padding=\'SAME\', groups=1):\n    """"""Create a convolution layer.\n    Adapted from: https://github.com/ethereon/caffe-tensorflow\n    """"""\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n\n    # Create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k,\n                                         strides=[1, stride_y, stride_x, 1],\n                                         padding=padding)\n\n    with tf.variable_scope(name) as scope:\n        # Create tf variables for the weights and biases of the conv layer\n        weights = tf.get_variable(\'weights\', shape=[filter_height,\n                                                    filter_width,\n                                                    input_channels/groups,\n                                                    num_filters])\n        biases = tf.get_variable(\'biases\', shape=[num_filters])\n\n    if groups == 1:\n        conv = convolve(x, weights)\n\n    # In the cases of multiple groups, split inputs & weights and\n    else:\n        # Split input and weights and convolve them separately\n        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n        weight_groups = tf.split(axis=3, num_or_size_splits=groups,\n                                 value=weights)\n        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n\n        # Concat the convolved output together again\n        conv = tf.concat(axis=3, values=output_groups)\n\n    # Add biases\n    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n\n    # Apply relu function\n    relu = tf.nn.relu(bias, name=scope.name)\n\n    return relu\n\n\ndef fc(x, num_in, num_out, name, relu=True):\n    """"""Create a fully connected layer.""""""\n    with tf.variable_scope(name) as scope:\n\n        # Create tf variables for the weights and biases\n        weights = tf.get_variable(\'weights\', shape=[num_in, num_out],\n                                  trainable=True)\n        biases = tf.get_variable(\'biases\', [num_out], trainable=True)\n\n        # Matrix multiply weights and inputs and add bias\n        act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)\n\n    if relu:\n        # Apply ReLu non linearity\n        relu = tf.nn.relu(act)\n        return relu\n    else:\n        return act\n\n\ndef max_pool(x, filter_height, filter_width, stride_y, stride_x, name,\n             padding=\'SAME\'):\n    """"""Create a max pooling layer.""""""\n    return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],\n                          strides=[1, stride_y, stride_x, 1],\n                          padding=padding, name=name)\n\n\ndef lrn(x, radius, alpha, beta, name, bias=1.0):\n    """"""Create a local response normalization layer.""""""\n    return tf.nn.local_response_normalization(x, depth_radius=radius,\n                                              alpha=alpha, beta=beta,\n                                              bias=bias, name=name)\n\n\ndef dropout(x, keep_prob):\n    """"""Create a dropout layer.""""""\n    return tf.nn.dropout(x, keep_prob)\n\n'"
models/model.py,56,"b'import os\n# os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""  # see issue #152\n# os.environ[""CUDA_VISIBLE_DEVICES""] = ""2""\nimport sys\nBASE_DIR = os.path.dirname(__file__)\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nsys.path.append(os.path.join(BASE_DIR, \'../models\'))\nimport tensorflow as tf\nimport numpy as np\nimport tf_util\nimport pointnet\n\n\nNUM_CATEGORY = 13\nNUM_GROUPS = 50\n\ndef placeholder_inputs(batch_size, num_point, num_group, num_cate):\n\n    if num_point == 0:\n        pointclouds_ph = tf.placeholder(tf.float32, shape=(batch_size, None, 9))\n    else:\n        pointclouds_ph = tf.placeholder(tf.float32, shape=(batch_size, num_point, 9))\n\n    pts_seglabels_ph = tf.placeholder(tf.int32, shape=(batch_size, num_point, num_cate))\n    pts_grouplabels_ph = tf.placeholder(tf.float32, shape=(batch_size, num_point, num_group))\n    pts_seglabel_mask_ph = tf.placeholder(tf.float32, shape=(batch_size, num_point))\n    pts_group_mask_ph = tf.placeholder(tf.float32, shape=(batch_size, num_point))\n\n    alpha_ph = tf.placeholder(tf.float32, shape=())\n\n    return pointclouds_ph, pts_seglabels_ph, pts_grouplabels_ph, pts_seglabel_mask_ph, pts_group_mask_ph, alpha_ph\n\ndef convert_seg_to_one_hot(labels):\n    # labels:BxN\n\n    label_one_hot = np.zeros((labels.shape[0], labels.shape[1], NUM_CATEGORY))\n    pts_label_mask = np.zeros((labels.shape[0], labels.shape[1]))\n\n    un, cnt = np.unique(labels, return_counts=True)\n    label_count_dictionary = dict(zip(un, cnt))\n    totalnum = 0\n    for k_un, v_cnt in label_count_dictionary.iteritems():\n        if k_un != -1:\n            totalnum += v_cnt\n\n    for idx in range(labels.shape[0]):\n        for jdx in range(labels.shape[1]):\n            if labels[idx, jdx] != -1:\n                label_one_hot[idx, jdx, labels[idx, jdx]] = 1\n                pts_label_mask[idx, jdx] = float(totalnum) / float(label_count_dictionary[labels[idx, jdx]]) # 1. - float(label_count_dictionary[labels[idx, jdx]]) / totalnum\n\n    return label_one_hot, pts_label_mask\n\n\ndef convert_groupandcate_to_one_hot(grouplabels):\n    # grouplabels: BxN\n\n    group_one_hot = np.zeros((grouplabels.shape[0], grouplabels.shape[1], NUM_GROUPS))\n    pts_group_mask = np.zeros((grouplabels.shape[0], grouplabels.shape[1]))\n\n    un, cnt = np.unique(grouplabels, return_counts=True)\n    group_count_dictionary = dict(zip(un, cnt))\n    totalnum = 0\n    for k_un, v_cnt in group_count_dictionary.iteritems():\n        if k_un != -1:\n            totalnum += v_cnt\n\n    for idx in range(grouplabels.shape[0]):\n        un = np.unique(grouplabels[idx])\n        grouplabel_dictionary = dict(zip(un, range(len(un))))\n        for jdx in range(grouplabels.shape[1]):\n            if grouplabels[idx, jdx] != -1:\n                group_one_hot[idx, jdx, grouplabel_dictionary[grouplabels[idx, jdx]]] = 1\n                pts_group_mask[idx, jdx] = float(totalnum) / float(group_count_dictionary[grouplabels[idx, jdx]]) # 1. - float(group_count_dictionary[grouplabels[idx, jdx]]) / totalnum\n\n    return group_one_hot.astype(np.float32), pts_group_mask\n\n\n\ndef generate_group_mask(pts, grouplabels, labels):\n    # grouplabels: BxN\n    # pts: BxNx6\n    # labels: BxN\n\n    group_mask = np.zeros((grouplabels.shape[0], grouplabels.shape[1], grouplabels.shape[1]))\n\n    for idx in range(grouplabels.shape[0]):\n        for jdx in range(grouplabels.shape[1]):\n            for kdx in range(grouplabels.shape[1]):\n                if (labels[idx, jdx] == labels[idx, kdx]):\n                    group_mask[idx, jdx, kdx] = 2.\n\n                if np.linalg.norm((pts[idx, jdx, :3] - pts[idx, kdx, :3]) * (\n                    pts[idx, jdx, :3] - pts[idx, kdx, :3])) < 0.04:\n                    if (labels[idx, jdx] == labels[idx, kdx]):\n                        group_mask[idx, jdx, kdx] = 5.\n                    else:\n                        group_mask[idx, jdx, kdx] = 2.\n\n    return group_mask\n\n\n\ndef get_model(point_cloud, is_training, group_cate_num=50, m=10., bn_decay=None):\n    #input: point_cloud: BxNx9 (XYZ, RGB, NormalizedXYZ)\n\n    batch_size = point_cloud.get_shape()[0].value\n    print(point_cloud.get_shape())\n\n    F = pointnet.get_model(point_cloud, is_training, bn=True, bn_decay=bn_decay)\n\n    # Semantic prediction\n    Fsem = tf_util.conv2d(F, 128, [1, 1], padding=\'VALID\', stride=[1, 1], bn=False, is_training=is_training, scope=\'Fsem\')\n\n    ptssemseg_logits = tf_util.conv2d(Fsem, group_cate_num, [1, 1], padding=\'VALID\', stride=[1, 1], activation_fn=None, scope=\'ptssemseg_logits\')\n    ptssemseg_logits = tf.squeeze(ptssemseg_logits, [2])\n\n    ptssemseg = tf.nn.softmax(ptssemseg_logits, name=""ptssemseg"")\n\n    # Similarity matrix\n    Fsim = tf_util.conv2d(F, 128, [1, 1], padding=\'VALID\', stride=[1, 1], bn=False, is_training=is_training, scope=\'Fsim\')\n\n    Fsim = tf.squeeze(Fsim, [2])\n\n    r = tf.reduce_sum(Fsim * Fsim, 2)\n    r = tf.reshape(r, [batch_size, -1, 1])\n    print(r.get_shape(),Fsim.get_shape())\n    D = r - 2 * tf.matmul(Fsim, tf.transpose(Fsim, perm=[0, 2, 1])) + tf.transpose(r, perm=[0, 2, 1])\n\n    # simmat_logits = tf.maximum(D, 0.)\n    simmat_logits = tf.maximum(m * D, 0.)\n\n    # Confidence Map\n    Fconf = tf_util.conv2d(F, 128, [1, 1], padding=\'VALID\', stride=[1, 1], bn=False, is_training=is_training, scope=\'Fsconf\')\n    conf_logits = tf_util.conv2d(Fconf, 1, [1, 1], padding=\'VALID\', stride=[1, 1], activation_fn=None, scope=\'conf_logits\')\n    conf_logits = tf.squeeze(conf_logits, [2])\n\n    conf = tf.nn.sigmoid(conf_logits, name=""confidence"")\n\n    return {\'semseg\': ptssemseg,\n            \'semseg_logits\': ptssemseg_logits,\n            \'simmat\': simmat_logits,\n            \'conf\': conf,\n            \'conf_logits\': conf_logits}\n\ndef get_loss(net_output, labels, alpha=10., margin=[1.,2.]):\n    """"""\n    input:\n        net_output:{\'semseg\', \'semseg_logits\',\'simmat\',\'conf\',\'conf_logits\'}\n        labels:{\'ptsgroup\', \'semseg\',\'semseg_mask\',\'group_mask\'}\n    """"""\n\n    pts_group_label = labels[\'ptsgroup\']\n    pts_semseg_label = labels[\'semseg\']\n    group_mask = tf.expand_dims(labels[\'group_mask\'], dim=2)\n\n    pred_confidence_logits = net_output[\'conf\']\n    pred_simmat = net_output[\'simmat\']\n\n    # Similarity Matrix loss\n    B = pts_group_label.get_shape()[0]\n    N = pts_group_label.get_shape()[1]\n\n    onediag = tf.ones([B,N], tf.float32)\n\n    group_mat_label = tf.matmul(pts_group_label,tf.transpose(pts_group_label, perm=[0, 2, 1])) #BxNxN: (i,j) if i and j in the same group\n    group_mat_label = tf.matrix_set_diag(group_mat_label,onediag)\n\n    sem_mat_label = tf.cast(tf.matmul(pts_semseg_label,tf.transpose(pts_semseg_label, perm=[0, 2, 1])), tf.float32) #BxNxN: (i,j) if i and j are the same semantic category\n    sem_mat_label = tf.matrix_set_diag(sem_mat_label,onediag)\n\n    samesem_mat_label = sem_mat_label\n    diffsem_mat_label = tf.subtract(1.0, sem_mat_label)\n\n    samegroup_mat_label = group_mat_label\n    diffgroup_mat_label = tf.subtract(1.0, group_mat_label)\n    diffgroup_samesem_mat_label = tf.multiply(diffgroup_mat_label, samesem_mat_label)\n    diffgroup_diffsem_mat_label = tf.multiply(diffgroup_mat_label, diffsem_mat_label)\n\n    num_samegroup = tf.reduce_sum(samegroup_mat_label)\n    num_diffgroup_samesem = tf.reduce_sum(diffgroup_samesem_mat_label)\n    num_diffgroup_diffsem = tf.reduce_sum(diffgroup_diffsem_mat_label)\n\n    # Double hinge loss\n\n    C_same = tf.constant(margin[0], name=""C_same"") # same semantic category\n    C_diff = tf.constant(margin[1], name=""C_diff"") # different semantic category\n\n    pos =  tf.multiply(samegroup_mat_label, pred_simmat) # minimize distances if in the same group\n    neg_samesem = alpha * tf.multiply(diffgroup_samesem_mat_label, tf.maximum(tf.subtract(C_same, pred_simmat), 0))\n    neg_diffsem = tf.multiply(diffgroup_diffsem_mat_label, tf.maximum(tf.subtract(C_diff, pred_simmat), 0))\n\n\n    simmat_loss = neg_samesem + neg_diffsem + pos\n    group_mask_weight = tf.matmul(group_mask, tf.transpose(group_mask, perm=[0, 2, 1]))\n    # simmat_loss = tf.add(simmat_loss, pos)\n    simmat_loss = tf.multiply(simmat_loss, group_mask_weight)\n\n    simmat_loss = tf.reduce_mean(simmat_loss)\n\n    # Semantic Segmentation loss\n    ptsseg_loss = tf.nn.softmax_cross_entropy_with_logits(logits=net_output[\'semseg_logits\'], labels=pts_semseg_label)\n    ptsseg_loss = tf.multiply(ptsseg_loss, labels[\'semseg_mask\'])\n    ptsseg_loss = tf.reduce_mean(ptsseg_loss)\n\n    # Confidence Map loss\n    Pr_obj = tf.reduce_sum(pts_semseg_label,axis=2)\n    Pr_obj = tf.cast(Pr_obj, tf.float32)\n    ng_label = group_mat_label\n    ng_label = tf.greater(ng_label, tf.constant(0.5))\n    ng = tf.less(pred_simmat, tf.constant(margin[0]))\n\n    epsilon = tf.constant(np.ones(ng_label.get_shape()[:2]).astype(np.float32) * 1e-6)\n    pts_iou = tf.div(tf.reduce_sum(tf.cast(tf.logical_and(ng,ng_label), tf.float32), axis=2),\n                     (tf.reduce_sum(tf.cast(tf.logical_or(ng,ng_label), tf.float32), axis=2)+epsilon))\n    confidence_label = tf.multiply(pts_iou, Pr_obj) # BxN\n\n    confidence_loss = tf.reduce_mean(tf.squared_difference(confidence_label, tf.squeeze(pred_confidence_logits,[2])))\n\n    loss = simmat_loss + ptsseg_loss + confidence_loss\n\n    grouperr = tf.abs(tf.cast(ng, tf.float32) - tf.cast(ng_label, tf.float32))\n\n    return loss, tf.reduce_mean(grouperr), \\\n           tf.reduce_sum(grouperr * diffgroup_samesem_mat_label), num_diffgroup_samesem, \\\n           tf.reduce_sum(grouperr * diffgroup_diffsem_mat_label), num_diffgroup_diffsem, \\\n           tf.reduce_sum(grouperr * samegroup_mat_label), num_samegroup'"
models/pointnet.py,14,"b'import tensorflow as tf\nimport math\nimport time\nimport numpy as np\nimport os\nimport sys\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, \'utils\'))\nimport tf_util\n\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32,\n                                    shape=(batch_size, num_point, 9))\n    labels_pl = tf.placeholder(tf.int32,\n                               shape=(batch_size, num_point))\n    return pointclouds_pl, labels_pl\n\n\ndef get_model(point_cloud, is_training, bn=True, bn_decay=None):\n    """""" ConvNet baseline, input is BxNx9 gray image """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n\n    input_image = tf.expand_dims(point_cloud, -1)\n    # CONV\n    net = tf_util.conv2d(input_image, 64, [1, 9], padding=\'VALID\', stride=[1, 1],\n                         bn=bn, is_training=is_training, scope=\'conv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1, 1], padding=\'VALID\', stride=[1, 1],\n                         bn=bn, is_training=is_training, scope=\'conv2\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1, 1], padding=\'VALID\', stride=[1, 1],\n                         bn=bn, is_training=is_training, scope=\'conv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1, 1], padding=\'VALID\', stride=[1, 1],\n                         bn=bn, is_training=is_training, scope=\'conv4\', bn_decay=bn_decay)\n    points_feat1 = tf_util.conv2d(net, 1024, [1, 1], padding=\'VALID\', stride=[1, 1],\n                                  bn=bn, is_training=is_training, scope=\'conv5\', bn_decay=bn_decay)\n    # MAX\n    pc_feat1 = tf_util.max_pool2d(points_feat1, [num_point, 1], padding=\'VALID\', scope=\'maxpool1\')\n    # FC\n    pc_feat1 = tf.reshape(pc_feat1, [batch_size, -1])\n    pc_feat1 = tf_util.fully_connected(pc_feat1, 256, bn=bn, is_training=is_training, scope=\'fc1\', bn_decay=bn_decay)\n    pc_feat1 = tf_util.fully_connected(pc_feat1, 128, bn=bn, is_training=is_training, scope=\'fc2\', bn_decay=bn_decay)\n    # print(pc_feat1)\n\n    # CONCAT\n    pc_feat1_expand = tf.tile(tf.reshape(pc_feat1, [batch_size, 1, 1, -1]), [1, num_point, 1, 1])\n    points_feat1_concat = tf.concat(axis=3, values=[points_feat1, pc_feat1_expand])\n\n    # CONV\n    net = tf_util.conv2d(points_feat1_concat, 512, [1, 1], padding=\'VALID\', stride=[1, 1], bn=bn, is_training=is_training, scope=\'conv6\')\n    net = tf_util.conv2d(net, 256, [1, 1], padding=\'VALID\', stride=[1, 1], bn=bn, is_training=is_training, scope=\'conv7\')\n    # net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training, scope=\'dp1\')\n    # net = tf_util.conv2d(net, 13, [1, 1], padding=\'VALID\', stride=[1, 1],\n    #                      activation_fn=None, scope=\'conv8\')\n    # net = tf.squeeze(net, [2])\n\n    return net\n\n\ndef get_loss(pred, label):\n    """""" pred: B,N,13\n        label: B,N """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    return tf.reduce_mean(loss)\n\n\nif __name__ == ""__main__"":\n    with tf.Graph().as_default():\n        a = tf.placeholder(tf.float32, shape=(32, 4096, 9))\n        net = get_model(a, tf.constant(True))\n        with tf.Session() as sess:\n            init = tf.global_variables_initializer()\n            sess.run(init)\n            start = time.time()\n            for i in range(100):\n                print(i)\n                sess.run(net, feed_dict={a: np.random.rand(32, 4096, 9)})\n            print(time.time() - start)\n'"
models/tf_util.py,63,"b'"""""" Wrapper functions for TensorFlow layers.\n\nAuthor: Charles R. Qi\nDate: November 2017\n""""""\n\nimport numpy as np\nimport tensorflow as tf\n\ndef _variable_on_cpu(name, shape, initializer, use_fp16=False):\n  """"""Helper to create a Variable stored on CPU memory.\n  Args:\n    name: name of the variable\n    shape: list of ints\n    initializer: initializer for Variable\n  Returns:\n    Variable Tensor\n  """"""\n  dtype = tf.float16 if use_fp16 else tf.float32\n  var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n  return var\n\ndef _variable_with_weight_decay(name, shape, stddev, wd, use_xavier=True):\n  """"""Helper to create an initialized Variable with weight decay.\n\n  Note that the Variable is initialized with a truncated normal distribution.\n  A weight decay is added only if one is specified.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    stddev: standard deviation of a truncated Gaussian\n    wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n    use_xavier: bool, whether to use xavier initializer\n\n  Returns:\n    Variable Tensor\n  """"""\n  if use_xavier:\n    initializer = tf.contrib.layers.xavier_initializer()\n  else:\n    initializer = tf.truncated_normal_initializer(stddev=stddev)\n  var = _variable_on_cpu(name, shape, initializer)\n  if wd is not None:\n    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=\'weight_loss\')\n    tf.add_to_collection(\'losses\', weight_decay)\n  return var\n\n\ndef conv1d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=1,\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 1D convolution with non-linear operation.\n\n  Args:\n    inputs: 3-D tensor variable BxLxC\n    num_output_channels: int\n    kernel_size: int\n    scope: string\n    stride: int\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_in_channels = inputs.get_shape()[-1].value\n    kernel_shape = [kernel_size,\n                    num_in_channels, num_output_channels]\n    kernel = _variable_with_weight_decay(\'weights\',\n                                         shape=kernel_shape,\n                                         use_xavier=use_xavier,\n                                         stddev=stddev,\n                                         wd=weight_decay)\n    outputs = tf.nn.conv1d(inputs, kernel,\n                           stride=stride,\n                           padding=padding)\n    biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                              tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n\n    if bn:\n      outputs = batch_norm_for_conv1d(outputs, is_training,\n                                      bn_decay=bn_decay, scope=\'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\n\n\n\ndef conv2d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=[1, 1],\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 2D convolution with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n      kernel_h, kernel_w = kernel_size\n      num_in_channels = inputs.get_shape()[-1].value\n      kernel_shape = [kernel_h, kernel_w,\n                      num_in_channels, num_output_channels]\n      kernel = _variable_with_weight_decay(\'weights\',\n                                           shape=kernel_shape,\n                                           use_xavier=use_xavier,\n                                           stddev=stddev,\n                                           wd=weight_decay)\n      stride_h, stride_w = stride\n      outputs = tf.nn.conv2d(inputs, kernel,\n                             [1, stride_h, stride_w, 1],\n                             padding=padding)\n      biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                                tf.constant_initializer(0.0))\n      outputs = tf.nn.bias_add(outputs, biases)\n\n      if bn:\n        outputs = batch_norm_for_conv2d(outputs, is_training,\n                                        bn_decay=bn_decay, scope=\'bn\')\n\n      if activation_fn is not None:\n        outputs = activation_fn(outputs)\n      return outputs\n\n\ndef conv2d_transpose(inputs,\n                     num_output_channels,\n                     kernel_size,\n                     scope,\n                     stride=[1, 1],\n                     padding=\'SAME\',\n                     use_xavier=True,\n                     stddev=1e-3,\n                     weight_decay=0.0,\n                     activation_fn=tf.nn.relu,\n                     bn=False,\n                     bn_decay=None,\n                     is_training=None):\n  """""" 2D convolution transpose with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n\n  Note: conv2d(conv2d_transpose(a, num_out, ksize, stride), a.shape[-1], ksize, stride) == a\n  """"""\n  with tf.variable_scope(scope) as sc:\n      kernel_h, kernel_w = kernel_size\n      num_in_channels = inputs.get_shape()[-1].value\n      kernel_shape = [kernel_h, kernel_w,\n                      num_output_channels, num_in_channels] # reversed to conv2d\n      kernel = _variable_with_weight_decay(\'weights\',\n                                           shape=kernel_shape,\n                                           use_xavier=use_xavier,\n                                           stddev=stddev,\n                                           wd=weight_decay)\n      stride_h, stride_w = stride\n      \n      # from slim.convolution2d_transpose\n      def get_deconv_dim(dim_size, stride_size, kernel_size, padding):\n          dim_size *= stride_size\n\n          if padding == \'VALID\' and dim_size is not None:\n            dim_size += max(kernel_size - stride_size, 0)\n          return dim_size\n\n      # caculate output shape\n      batch_size = inputs.get_shape()[0].value\n      height = inputs.get_shape()[1].value\n      width = inputs.get_shape()[2].value\n      out_height = get_deconv_dim(height, stride_h, kernel_h, padding)\n      out_width = get_deconv_dim(width, stride_w, kernel_w, padding)\n      output_shape = [batch_size, out_height, out_width, num_output_channels]\n\n      outputs = tf.nn.conv2d_transpose(inputs, kernel, output_shape,\n                             [1, stride_h, stride_w, 1],\n                             padding=padding)\n      biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                                tf.constant_initializer(0.0))\n      outputs = tf.nn.bias_add(outputs, biases)\n\n      if bn:\n        outputs = batch_norm_for_conv2d(outputs, is_training,\n                                        bn_decay=bn_decay, scope=\'bn\')\n\n      if activation_fn is not None:\n        outputs = activation_fn(outputs)\n      return outputs\n\n   \n\ndef conv3d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=[1, 1, 1],\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 3D convolution with non-linear operation.\n\n  Args:\n    inputs: 5-D tensor variable BxDxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 3 ints\n    scope: string\n    stride: a list of 3 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    num_in_channels = inputs.get_shape()[-1].value\n    kernel_shape = [kernel_d, kernel_h, kernel_w,\n                    num_in_channels, num_output_channels]\n    kernel = _variable_with_weight_decay(\'weights\',\n                                         shape=kernel_shape,\n                                         use_xavier=use_xavier,\n                                         stddev=stddev,\n                                         wd=weight_decay)\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.conv3d(inputs, kernel,\n                           [1, stride_d, stride_h, stride_w, 1],\n                           padding=padding)\n    biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                              tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n    \n    if bn:\n      outputs = batch_norm_for_conv3d(outputs, is_training,\n                                      bn_decay=bn_decay, scope=\'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\ndef fully_connected(inputs,\n                    num_outputs,\n                    scope,\n                    use_xavier=True,\n                    stddev=1e-3,\n                    weight_decay=0.0,\n                    activation_fn=tf.nn.relu,\n                    bn=False,\n                    bn_decay=None,\n                    is_training=None):\n  """""" Fully connected layer with non-linear operation.\n  \n  Args:\n    inputs: 2-D tensor BxN\n    num_outputs: int\n  \n  Returns:\n    Variable tensor of size B x num_outputs.\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_input_units = inputs.get_shape()[-1].value\n    weights = _variable_with_weight_decay(\'weights\',\n                                          shape=[num_input_units, num_outputs],\n                                          use_xavier=use_xavier,\n                                          stddev=stddev,\n                                          wd=weight_decay)\n    outputs = tf.matmul(inputs, weights)\n    biases = _variable_on_cpu(\'biases\', [num_outputs],\n                             tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n     \n    if bn:\n      outputs = batch_norm_for_fc(outputs, is_training, bn_decay, \'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\n\ndef max_pool2d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2],\n               padding=\'VALID\'):\n  """""" 2D max pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_h, kernel_w = kernel_size\n    stride_h, stride_w = stride\n    outputs = tf.nn.max_pool(inputs,\n                             ksize=[1, kernel_h, kernel_w, 1],\n                             strides=[1, stride_h, stride_w, 1],\n                             padding=padding,\n                             name=sc.name)\n    return outputs\n\ndef avg_pool2d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2],\n               padding=\'VALID\'):\n  """""" 2D avg pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_h, kernel_w = kernel_size\n    stride_h, stride_w = stride\n    outputs = tf.nn.avg_pool(inputs,\n                             ksize=[1, kernel_h, kernel_w, 1],\n                             strides=[1, stride_h, stride_w, 1],\n                             padding=padding,\n                             name=sc.name)\n    return outputs\n\n\ndef max_pool3d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2, 2],\n               padding=\'VALID\'):\n  """""" 3D max pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.max_pool3d(inputs,\n                               ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n                               strides=[1, stride_d, stride_h, stride_w, 1],\n                               padding=padding,\n                               name=sc.name)\n    return outputs\n\ndef avg_pool3d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2, 2],\n               padding=\'VALID\'):\n  """""" 3D avg pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.avg_pool3d(inputs,\n                               ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n                               strides=[1, stride_d, stride_h, stride_w, 1],\n                               padding=padding,\n                               name=sc.name)\n    return outputs\n\n\n\n\n\ndef batch_norm_template(inputs, is_training, scope, moments_dims, bn_decay):\n  """""" Batch normalization on convolutional maps and beyond...\n  Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n  \n  Args:\n      inputs:        Tensor, k-D input ... x C could be BC or BHWC or BDHWC\n      is_training:   boolean tf.Varialbe, true indicates training phase\n      scope:         string, variable scope\n      moments_dims:  a list of ints, indicating dimensions for moments calculation\n      bn_decay:      float or float tensor variable, controling moving average weight\n  Return:\n      normed:        batch-normalized maps\n  """"""\n  # For support of GAN\n  #bn_decay = bn_decay if bn_decay is not None else 0.9\n  #return tf.contrib.layers.batch_norm(inputs, \n  #                                    center=True, scale=True, \n  #                                    is_training=is_training, decay=bn_decay,updates_collections=None,\n  #                                    scope=scope)\n  with tf.variable_scope(scope) as sc:\n    num_channels = inputs.get_shape()[-1].value\n    beta = tf.Variable(tf.constant(0.0, shape=[num_channels]),\n                       name=\'beta\', trainable=True)\n    gamma = tf.Variable(tf.constant(1.0, shape=[num_channels]),\n                        name=\'gamma\', trainable=True)\n    batch_mean, batch_var = tf.nn.moments(inputs, moments_dims, name=\'moments\')\n    decay = bn_decay if bn_decay is not None else 0.9\n    ema = tf.train.ExponentialMovingAverage(decay=decay)\n    # Operator that maintains moving averages of variables.\n    # Need to set reuse=False, otherwise if reuse, will see moments_1/mean/ExponentialMovingAverage/ does not exist\n    # https://github.com/shekkizh/WassersteinGAN.tensorflow/issues/3\n    with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n        ema_apply_op = tf.cond(is_training,\n                               lambda: ema.apply([batch_mean, batch_var]),\n                               lambda: tf.no_op())\n    \n    # Update moving average and return current batch\'s avg and var.\n    def mean_var_with_update():\n      with tf.control_dependencies([ema_apply_op]):\n        return tf.identity(batch_mean), tf.identity(batch_var)\n    \n    # ema.average returns the Variable holding the average of var.\n    mean, var = tf.cond(is_training,\n                        mean_var_with_update,\n                        lambda: (ema.average(batch_mean), ema.average(batch_var)))\n    normed = tf.nn.batch_normalization(inputs, mean, var, beta, gamma, 1e-3)\n  return normed\n\ndef batch_norm_template_old(inputs, is_training, scope, moments_dims, bn_decay):\n  print inputs.get_shape()\n  with tf.variable_scope(scope):\n      normed = tf.contrib.layers.batch_norm(inputs,\n                                            center=True,\n                                            scale=True,\n                                            is_training = is_training,\n                                            decay = bn_decay,\n                                            trainable = True\n                                           )\n\n  return normed\n\ndef batch_norm_for_fc(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on FC data.\n  \n  Args:\n      inputs:      Tensor, 2D BxC input\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,], bn_decay)\n\n\ndef batch_norm_for_conv1d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 1D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 3D BLC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1], bn_decay)\n\n\n\n  \ndef batch_norm_for_conv2d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 2D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 4D BHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1,2], bn_decay)\n\n\n\ndef batch_norm_for_conv3d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 3D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 5D BDHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1,2,3], bn_decay)\n\n\ndef dropout(inputs,\n            is_training,\n            scope,\n            keep_prob=0.5,\n            noise_shape=None):\n  """""" Dropout layer.\n\n  Args:\n    inputs: tensor\n    is_training: boolean tf.Variable\n    scope: string\n    keep_prob: float in [0,1]\n    noise_shape: list of ints\n\n  Returns:\n    tensor variable\n  """"""\n  with tf.variable_scope(scope) as sc:\n    outputs = tf.cond(is_training,\n                      lambda: tf.nn.dropout(inputs, keep_prob, noise_shape),\n                      lambda: inputs)\n    return outputs\n'"
utils/__init__.py,0,b''
utils/eulerangles.py,0,"b'# emacs: -*- mode: python-mode; py-indent-offset: 4; indent-tabs-mode: nil -*-\n# vi: set ft=python sts=4 ts=4 sw=4 et:\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##\n#\n#   See COPYING file distributed along with the NiBabel package for the\n#   copyright and license terms.\n#\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##\n\'\'\' Module implementing Euler angle rotations and their conversions\n\nSee:\n\n* http://en.wikipedia.org/wiki/Rotation_matrix\n* http://en.wikipedia.org/wiki/Euler_angles\n* http://mathworld.wolfram.com/EulerAngles.html\n\nSee also: *Representing Attitude with Euler Angles and Quaternions: A\nReference* (2006) by James Diebel. A cached PDF link last found here:\n\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.5134\n\nEuler\'s rotation theorem tells us that any rotation in 3D can be\ndescribed by 3 angles.  Let\'s call the 3 angles the *Euler angle vector*\nand call the angles in the vector :math:`alpha`, :math:`beta` and\n:math:`gamma`.  The vector is [ :math:`alpha`,\n:math:`beta`. :math:`gamma` ] and, in this description, the order of the\nparameters specifies the order in which the rotations occur (so the\nrotation corresponding to :math:`alpha` is applied first).\n\nIn order to specify the meaning of an *Euler angle vector* we need to\nspecify the axes around which each of the rotations corresponding to\n:math:`alpha`, :math:`beta` and :math:`gamma` will occur.\n\nThere are therefore three axes for the rotations :math:`alpha`,\n:math:`beta` and :math:`gamma`; let\'s call them :math:`i` :math:`j`,\n:math:`k`.\n\nLet us express the rotation :math:`alpha` around axis `i` as a 3 by 3\nrotation matrix `A`.  Similarly :math:`beta` around `j` becomes 3 x 3\nmatrix `B` and :math:`gamma` around `k` becomes matrix `G`.  Then the\nwhole rotation expressed by the Euler angle vector [ :math:`alpha`,\n:math:`beta`. :math:`gamma` ], `R` is given by::\n\n   R = np.dot(G, np.dot(B, A))\n\nSee http://mathworld.wolfram.com/EulerAngles.html\n\nThe order :math:`G B A` expresses the fact that the rotations are\nperformed in the order of the vector (:math:`alpha` around axis `i` =\n`A` first).\n\nTo convert a given Euler angle vector to a meaningful rotation, and a\nrotation matrix, we need to define:\n\n* the axes `i`, `j`, `k`\n* whether a rotation matrix should be applied on the left of a vector to\n  be transformed (vectors are column vectors) or on the right (vectors\n  are row vectors).\n* whether the rotations move the axes as they are applied (intrinsic\n  rotations) - compared the situation where the axes stay fixed and the\n  vectors move within the axis frame (extrinsic)\n* the handedness of the coordinate system\n\nSee: http://en.wikipedia.org/wiki/Rotation_matrix#Ambiguities\n\nWe are using the following conventions:\n\n* axes `i`, `j`, `k` are the `z`, `y`, and `x` axes respectively.  Thus\n  an Euler angle vector [ :math:`alpha`, :math:`beta`. :math:`gamma` ]\n  in our convention implies a :math:`alpha` radian rotation around the\n  `z` axis, followed by a :math:`beta` rotation around the `y` axis,\n  followed by a :math:`gamma` rotation around the `x` axis.\n* the rotation matrix applies on the left, to column vectors on the\n  right, so if `R` is the rotation matrix, and `v` is a 3 x N matrix\n  with N column vectors, the transformed vector set `vdash` is given by\n  ``vdash = np.dot(R, v)``.\n* extrinsic rotations - the axes are fixed, and do not move with the\n  rotations.\n* a right-handed coordinate system\n\nThe convention of rotation around ``z``, followed by rotation around\n``y``, followed by rotation around ``x``, is known (confusingly) as\n""xyz"", pitch-roll-yaw, Cardan angles, or Tait-Bryan angles.\n\'\'\'\n\nimport math\n\nimport sys\nif sys.version_info >= (3,0):\n    from functools import reduce\n\nimport numpy as np\n\n\n_FLOAT_EPS_4 = np.finfo(float).eps * 4.0\n\n\ndef euler2mat(z=0, y=0, x=0):\n    \'\'\' Return matrix for rotations around z, y and x axes\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    M : array shape (3,3)\n       Rotation matrix giving same rotation as for given angles\n\n    Examples\n    --------\n    >>> zrot = 1.3 # radians\n    >>> yrot = -0.1\n    >>> xrot = 0.2\n    >>> M = euler2mat(zrot, yrot, xrot)\n    >>> M.shape == (3, 3)\n    True\n\n    The output rotation matrix is equal to the composition of the\n    individual rotations\n\n    >>> M1 = euler2mat(zrot)\n    >>> M2 = euler2mat(0, yrot)\n    >>> M3 = euler2mat(0, 0, xrot)\n    >>> composed_M = np.dot(M3, np.dot(M2, M1))\n    >>> np.allclose(M, composed_M)\n    True\n\n    You can specify rotations by named arguments\n\n    >>> np.all(M3 == euler2mat(x=xrot))\n    True\n\n    When applying M to a vector, the vector should column vector to the\n    right of M.  If the right hand side is a 2D array rather than a\n    vector, then each column of the 2D array represents a vector.\n\n    >>> vec = np.array([1, 0, 0]).reshape((3,1))\n    >>> v2 = np.dot(M, vec)\n    >>> vecs = np.array([[1, 0, 0],[0, 1, 0]]).T # giving 3x2 array\n    >>> vecs2 = np.dot(M, vecs)\n\n    Rotations are counter-clockwise.\n\n    >>> zred = np.dot(euler2mat(z=np.pi/2), np.eye(3))\n    >>> np.allclose(zred, [[0, -1, 0],[1, 0, 0], [0, 0, 1]])\n    True\n    >>> yred = np.dot(euler2mat(y=np.pi/2), np.eye(3))\n    >>> np.allclose(yred, [[0, 0, 1],[0, 1, 0], [-1, 0, 0]])\n    True\n    >>> xred = np.dot(euler2mat(x=np.pi/2), np.eye(3))\n    >>> np.allclose(xred, [[1, 0, 0],[0, 0, -1], [0, 1, 0]])\n    True\n\n    Notes\n    -----\n    The direction of rotation is given by the right-hand rule (orient\n    the thumb of the right hand along the axis around which the rotation\n    occurs, with the end of the thumb at the positive end of the axis;\n    curl your fingers; the direction your fingers curl is the direction\n    of rotation).  Therefore, the rotations are counterclockwise if\n    looking along the axis of rotation from positive to negative.\n    \'\'\'\n    Ms = []\n    if z:\n        cosz = math.cos(z)\n        sinz = math.sin(z)\n        Ms.append(np.array(\n                [[cosz, -sinz, 0],\n                 [sinz, cosz, 0],\n                 [0, 0, 1]]))\n    if y:\n        cosy = math.cos(y)\n        siny = math.sin(y)\n        Ms.append(np.array(\n                [[cosy, 0, siny],\n                 [0, 1, 0],\n                 [-siny, 0, cosy]]))\n    if x:\n        cosx = math.cos(x)\n        sinx = math.sin(x)\n        Ms.append(np.array(\n                [[1, 0, 0],\n                 [0, cosx, -sinx],\n                 [0, sinx, cosx]]))\n    if Ms:\n        return reduce(np.dot, Ms[::-1])\n    return np.eye(3)\n\n\ndef mat2euler(M, cy_thresh=None):\n    \'\'\' Discover Euler angle vector from 3x3 matrix\n\n    Uses the conventions above.\n\n    Parameters\n    ----------\n    M : array-like, shape (3,3)\n    cy_thresh : None or scalar, optional\n       threshold below which to give up on straightforward arctan for\n       estimating x rotation.  If None (default), estimate from\n       precision of input.\n\n    Returns\n    -------\n    z : scalar\n    y : scalar\n    x : scalar\n       Rotations in radians around z, y, x axes, respectively\n\n    Notes\n    -----\n    If there was no numerical error, the routine could be derived using\n    Sympy expression for z then y then x rotation matrix, which is::\n\n      [                       cos(y)*cos(z),                       -cos(y)*sin(z),         sin(y)],\n      [cos(x)*sin(z) + cos(z)*sin(x)*sin(y), cos(x)*cos(z) - sin(x)*sin(y)*sin(z), -cos(y)*sin(x)],\n      [sin(x)*sin(z) - cos(x)*cos(z)*sin(y), cos(z)*sin(x) + cos(x)*sin(y)*sin(z),  cos(x)*cos(y)]\n\n    with the obvious derivations for z, y, and x\n\n       z = atan2(-r12, r11)\n       y = asin(r13)\n       x = atan2(-r23, r33)\n\n    Problems arise when cos(y) is close to zero, because both of::\n\n       z = atan2(cos(y)*sin(z), cos(y)*cos(z))\n       x = atan2(cos(y)*sin(x), cos(x)*cos(y))\n\n    will be close to atan2(0, 0), and highly unstable.\n\n    The ``cy`` fix for numerical instability below is from: *Graphics\n    Gems IV*, Paul Heckbert (editor), Academic Press, 1994, ISBN:\n    0123361559.  Specifically it comes from EulerAngles.c by Ken\n    Shoemake, and deals with the case where cos(y) is close to zero:\n\n    See: http://www.graphicsgems.org/\n\n    The code appears to be licensed (from the website) as ""can be used\n    without restrictions"".\n    \'\'\'\n    M = np.asarray(M)\n    if cy_thresh is None:\n        try:\n            cy_thresh = np.finfo(M.dtype).eps * 4\n        except ValueError:\n            cy_thresh = _FLOAT_EPS_4\n    r11, r12, r13, r21, r22, r23, r31, r32, r33 = M.flat\n    # cy: sqrt((cos(y)*cos(z))**2 + (cos(x)*cos(y))**2)\n    cy = math.sqrt(r33*r33 + r23*r23)\n    if cy > cy_thresh: # cos(y) not close to zero, standard form\n        z = math.atan2(-r12,  r11) # atan2(cos(y)*sin(z), cos(y)*cos(z))\n        y = math.atan2(r13,  cy) # atan2(sin(y), cy)\n        x = math.atan2(-r23, r33) # atan2(cos(y)*sin(x), cos(x)*cos(y))\n    else: # cos(y) (close to) zero, so x -> 0.0 (see above)\n        # so r21 -> sin(z), r22 -> cos(z) and\n        z = math.atan2(r21,  r22)\n        y = math.atan2(r13,  cy) # atan2(sin(y), cy)\n        x = 0.0\n    return z, y, x\n\n\ndef euler2quat(z=0, y=0, x=0):\n    \'\'\' Return quaternion corresponding to these Euler angles\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    quat : array shape (4,)\n       Quaternion in w, x, y z (real, then vector) format\n\n    Notes\n    -----\n    We can derive this formula in Sympy using:\n\n    1. Formula giving quaternion corresponding to rotation of theta radians\n       about arbitrary axis:\n       http://mathworld.wolfram.com/EulerParameters.html\n    2. Generated formulae from 1.) for quaternions corresponding to\n       theta radians rotations about ``x, y, z`` axes\n    3. Apply quaternion multiplication formula -\n       http://en.wikipedia.org/wiki/Quaternions#Hamilton_product - to\n       formulae from 2.) to give formula for combined rotations.\n    \'\'\'\n    z = z/2.0\n    y = y/2.0\n    x = x/2.0\n    cz = math.cos(z)\n    sz = math.sin(z)\n    cy = math.cos(y)\n    sy = math.sin(y)\n    cx = math.cos(x)\n    sx = math.sin(x)\n    return np.array([\n             cx*cy*cz - sx*sy*sz,\n             cx*sy*sz + cy*cz*sx,\n             cx*cz*sy - sx*cy*sz,\n             cx*cy*sz + sx*cz*sy])\n\n\ndef quat2euler(q):\n    \'\'\' Return Euler angles corresponding to quaternion `q`\n\n    Parameters\n    ----------\n    q : 4 element sequence\n       w, x, y, z of quaternion\n\n    Returns\n    -------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Notes\n    -----\n    It\'s possible to reduce the amount of calculation a little, by\n    combining parts of the ``quat2mat`` and ``mat2euler`` functions, but\n    the reduction in computation is small, and the code repetition is\n    large.\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    return mat2euler(nq.quat2mat(q))\n\n\ndef euler2angle_axis(z=0, y=0, x=0):\n    \'\'\' Return angle, axis corresponding to these Euler angles\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    theta : scalar\n       angle of rotation\n    vector : array shape (3,)\n       axis around which rotation occurs\n\n    Examples\n    --------\n    >>> theta, vec = euler2angle_axis(0, 1.5, 0)\n    >>> print(theta)\n    1.5\n    >>> np.allclose(vec, [0, 1, 0])\n    True\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    return nq.quat2angle_axis(euler2quat(z, y, x))\n\n\ndef angle_axis2euler(theta, vector, is_normalized=False):\n    \'\'\' Convert angle, axis pair to Euler angles\n\n    Parameters\n    ----------\n    theta : scalar\n       angle of rotation\n    vector : 3 element sequence\n       vector specifying axis for rotation.\n    is_normalized : bool, optional\n       True if vector is already normalized (has norm of 1).  Default\n       False\n\n    Returns\n    -------\n    z : scalar\n    y : scalar\n    x : scalar\n       Rotations in radians around z, y, x axes, respectively\n\n    Examples\n    --------\n    >>> z, y, x = angle_axis2euler(0, [1, 0, 0])\n    >>> np.allclose((z, y, x), 0)\n    True\n\n    Notes\n    -----\n    It\'s possible to reduce the amount of calculation a little, by\n    combining parts of the ``angle_axis2mat`` and ``mat2euler``\n    functions, but the reduction in computation is small, and the code\n    repetition is large.\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    M = nq.angle_axis2mat(theta, vector, is_normalized)\n    return mat2euler(M)\n'"
utils/pc_util.py,0,"b'"""""" Utility functions for processing point clouds.\n\nAuthor: Charles R. Qi, Hao Su\nDate: November 2016\n""""""\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.dirname(BASE_DIR))\nsys.path.append(os.path.join(BASE_DIR, \'models\'))\nsys.path.append(os.path.join(BASE_DIR, \'utils\'))\nsys.path.append(os.path.join(BASE_DIR, \'../models\'))\nimport provider\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\n# Draw point cloud\nfrom eulerangles import euler2mat\n\n# Point cloud IO\nimport numpy as np\nfrom plyfile import PlyData, PlyElement\n\n \n# ----------------------------------------\n# Point Cloud/Volume Conversions\n# ----------------------------------------\n\ndef point_cloud_to_volume_batch(point_clouds, vsize=12, radius=1.0, flatten=True):\n    """""" Input is BxNx3 batch of point cloud\n        Output is Bx(vsize^3)\n    """"""\n    vol_list = []\n    for b in range(point_clouds.shape[0]):\n        vol = point_cloud_to_volume(np.squeeze(point_clouds[b,:,:]), vsize, radius)\n        if flatten:\n            vol_list.append(vol.flatten())\n        else:\n            vol_list.append(np.expand_dims(np.expand_dims(vol, -1), 0))\n    if flatten:\n        return np.vstack(vol_list)\n    else:\n        return np.concatenate(vol_list, 0)\n\n\ndef point_cloud_to_volume(points, vsize, radius=1.0):\n    """""" input is Nx3 points.\n        output is vsize*vsize*vsize\n        assumes points are in range [-radius, radius]\n    """"""\n    vol = np.zeros((vsize,vsize,vsize))\n    voxel = 2*radius/float(vsize)\n    locations = (points + radius)/voxel\n    locations = locations.astype(int)\n    vol[locations[:,0],locations[:,1],locations[:,2]] = 1.0\n    return vol\n\n#a = np.zeros((16,1024,3))\n#print point_cloud_to_volume_batch(a, 12, 1.0, False).shape\n\ndef volume_to_point_cloud(vol):\n    """""" vol is occupancy grid (value = 0 or 1) of size vsize*vsize*vsize\n        return Nx3 numpy array.\n    """"""\n    vsize = vol.shape[0]\n    assert(vol.shape[1] == vsize and vol.shape[1] == vsize)\n    points = []\n    for a in range(vsize):\n        for b in range(vsize):\n            for c in range(vsize):\n                if vol[a,b,c] == 1:\n                    points.append(np.array([a,b,c]))\n    if len(points) == 0:\n        return np.zeros((0,3))\n    points = np.vstack(points)\n    return points\n\n# ----------------------------------------\n# Point cloud IO\n# ----------------------------------------\n\ndef read_ply(filename):\n    """""" read XYZ point cloud from filename PLY file """"""\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\ndef read_ply_coloralpha(filename):\n    """""" read XYZRGB point cloud from filename PLY file """"""\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data\n    pc_array = np.array([[x, y, z, r, g, b, a] for x, y, z, r, g, b, a in pc])\n    return pc_array\n\ndef read_ply_all(filename):\n    """""" read XYZRGB point cloud from filename PLY file """"""\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data\n    pc_array = np.array([[x, y, z, r, g, b, a, l] for x, y, z, r, g, b, a, l in pc])\n    return pc_array\n\n\ndef write_ply(points, filename, text=True):\n    """""" input: Nx3, write points to filename as PLY format. """"""\n    points = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n    vertex = np.array(points, dtype=[(\'x\', \'f4\'), (\'y\', \'f4\'),(\'z\', \'f4\')])\n    el = PlyElement.describe(vertex, \'vertex\', comments=[\'vertices\'])\n    PlyData([el], text=text).write(filename)\n\ndef write_ply_color(points, filename, text=True):\n    """""" input: Nx6, write points to filename as PLY format. """"""\n    points_ = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n    points_color_ = [(255*points[i,3], 255*points[i,4], 255*points[i,5]) for i in range(points.shape[0])]\n\n    n = points.shape[0]\n    vertex = np.array(points_, dtype=[(\'x\', \'f4\'), (\'y\', \'f4\'),(\'z\', \'f4\')])\n    vertex_color = np.array(points_color_, dtype=[(\'red\', \'u1\'), (\'green\', \'u1\'),(\'blue\', \'u1\')])\n    vertex_all = np.empty(n, vertex.dtype.descr + vertex_color.dtype.descr)\n\n    for prop in vertex.dtype.names:\n        vertex_all[prop] = vertex[prop]\n\n    for prop in vertex_color.dtype.names:\n        vertex_all[prop] = vertex_color[prop]\n\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n\n\n# ----------------------------------------\n# Simple Point cloud and Volume Renderers\n# ----------------------------------------\n\ndef draw_point_cloud(input_points, canvasSize=500, space=200, diameter=25,\n                     xrot=0, yrot=0, zrot=0, switch_xyz=[0,1,2], normalize=True):\n    """""" Render point cloud to image with alpha channel.\n        Input:\n            points: Nx3 numpy array (+y is up direction)\n        Output:\n            gray image as numpy array of size canvasSizexcanvasSize\n    """"""\n    image = np.zeros((canvasSize, canvasSize))\n    if input_points is None or input_points.shape[0] == 0:\n        return image\n\n    points = input_points[:, switch_xyz]\n    M = euler2mat(zrot, yrot, xrot)\n    points = (np.dot(M, points.transpose())).transpose()\n\n    # Normalize the point cloud\n    # We normalize scale to fit points in a unit sphere\n    if normalize:\n        centroid = np.mean(points, axis=0)\n        points -= centroid\n        furthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n        points /= furthest_distance\n\n    # Pre-compute the Gaussian disk\n    radius = (diameter-1)/2.0\n    disk = np.zeros((diameter, diameter))\n    for i in range(diameter):\n        for j in range(diameter):\n            if (i - radius) * (i-radius) + (j-radius) * (j-radius) <= radius * radius:\n                disk[i, j] = np.exp((-(i-radius)**2 - (j-radius)**2)/(radius**2))\n    mask = np.argwhere(disk > 0)\n    dx = mask[:, 0]\n    dy = mask[:, 1]\n    dv = disk[disk > 0]\n    \n    # Order points by z-buffer\n    zorder = np.argsort(points[:, 2])\n    points = points[zorder, :]\n    points[:, 2] = (points[:, 2] - np.min(points[:, 2])) / (np.max(points[:, 2] - np.min(points[:, 2])))\n    max_depth = np.max(points[:, 2])\n       \n    for i in range(points.shape[0]):\n        j = points.shape[0] - i - 1\n        x = points[j, 0]\n        y = points[j, 1]\n        xc = canvasSize/2 + (x*space)\n        yc = canvasSize/2 + (y*space)\n        xc = int(np.round(xc))\n        yc = int(np.round(yc))\n        \n        px = dx + xc\n        py = dy + yc\n        \n        image[px, py] = image[px, py] * 0.7 + dv * (max_depth - points[j, 2]) * 0.3\n    \n    image = image / np.max(image)\n    return image\n\ndef point_cloud_three_views(points):\n    """""" input points Nx3 numpy array (+y is up direction).\n        return an numpy array gray image of size 500x1500. """""" \n    # +y is up direction\n    # xrot is azimuth\n    # yrot is in-plane\n    # zrot is elevation\n    img1 = draw_point_cloud(points, zrot=110/180.0*np.pi, xrot=45/180.0*np.pi, yrot=0/180.0*np.pi)\n    img2 = draw_point_cloud(points, zrot=70/180.0*np.pi, xrot=135/180.0*np.pi, yrot=0/180.0*np.pi)\n    img3 = draw_point_cloud(points, zrot=180.0/180.0*np.pi, xrot=90/180.0*np.pi, yrot=0/180.0*np.pi)\n    image_large = np.concatenate([img1, img2, img3], 1)\n    return image_large\n\n\nfrom PIL import Image\ndef point_cloud_three_views_demo():\n    """""" Demo for draw_point_cloud function """"""\n    points = read_ply(\'../third_party/mesh_sampling/piano.ply\')\n    im_array = point_cloud_three_views(points)\n    img = Image.fromarray(np.uint8(im_array*255.0))\n    img.save(\'piano.jpg\')\n\nif __name__==""__main__"":\n    # point_cloud_three_views_demo()\n\n    current_data, current_label = provider.loadDataFile(\'/staging/ww/weiyuewa/pointnet/modelnet40_ply_hdf5_2048/ply_data_test1.h5\')#\'/staging/ww/weiyuewa/pointnet/PartClassification/ 9142.h5\')\n    for i in range(2048):\n        points = np.squeeze(current_data[i,:,:])\n        label = np.squeeze(current_label[i,])\n        im_array = point_cloud_three_views(points)\n        img = Image.fromarray(np.uint8(im_array*255.0))\n        img.save(\'tmp/modelnet%d_%d.jpg\'%(label,i))\n\nimport matplotlib.pyplot as plt\ndef pyplot_draw_point_cloud(points, output_filename):\n    """""" points is a Nx3 numpy array """"""\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\'3d\')\n    ax.scatter(points[:,0], points[:,1], points[:,2])\n    ax.set_xlabel(\'x\')\n    ax.set_ylabel(\'y\')\n    ax.set_zlabel(\'z\')\n    #savefig(output_filename)\n\ndef pyplot_draw_volume(vol, output_filename):\n    """""" vol is of size vsize*vsize*vsize\n        output an image to output_filename\n    """"""\n    points = volume_to_point_cloud(vol)\n    pyplot_draw_point_cloud(points, output_filename)\n'"
utils/plyfile.py,0,"b'#   Copyright 2014 Darsh Ranjan\n#\n#   This file is part of python-plyfile.\n#\n#   python-plyfile is free software: you can redistribute it and/or\n#   modify it under the terms of the GNU General Public License as\n#   published by the Free Software Foundation, either version 3 of the\n#   License, or (at your option) any later version.\n#\n#   python-plyfile is distributed in the hope that it will be useful,\n#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n#   General Public License for more details.\n#\n#   You should have received a copy of the GNU General Public License\n#   along with python-plyfile.  If not, see\n#       <http://www.gnu.org/licenses/>.\n\nfrom itertools import islice as _islice\n\nimport numpy as _np\nfrom sys import byteorder as _byteorder\n\n\ntry:\n    _range = xrange\nexcept NameError:\n    _range = range\n\n\n# Many-many relation\n_data_type_relation = [\n    (\'int8\', \'i1\'),\n    (\'char\', \'i1\'),\n    (\'uint8\', \'u1\'),\n    (\'uchar\', \'b1\'),\n    (\'uchar\', \'u1\'),\n    (\'int16\', \'i2\'),\n    (\'short\', \'i2\'),\n    (\'uint16\', \'u2\'),\n    (\'ushort\', \'u2\'),\n    (\'int32\', \'i4\'),\n    (\'int\', \'i4\'),\n    (\'uint32\', \'u4\'),\n    (\'uint\', \'u4\'),\n    (\'float32\', \'f4\'),\n    (\'float\', \'f4\'),\n    (\'float64\', \'f8\'),\n    (\'double\', \'f8\')\n]\n\n_data_types = dict(_data_type_relation)\n_data_type_reverse = dict((b, a) for (a, b) in _data_type_relation)\n\n_types_list = []\n_types_set = set()\nfor (_a, _b) in _data_type_relation:\n    if _a not in _types_set:\n        _types_list.append(_a)\n        _types_set.add(_a)\n    if _b not in _types_set:\n        _types_list.append(_b)\n        _types_set.add(_b)\n\n\n_byte_order_map = {\n    \'ascii\': \'=\',\n    \'binary_little_endian\': \'<\',\n    \'binary_big_endian\': \'>\'\n}\n\n_byte_order_reverse = {\n    \'<\': \'binary_little_endian\',\n    \'>\': \'binary_big_endian\'\n}\n\n_native_byte_order = {\'little\': \'<\', \'big\': \'>\'}[_byteorder]\n\n\ndef _lookup_type(type_str):\n    if type_str not in _data_type_reverse:\n        try:\n            type_str = _data_types[type_str]\n        except KeyError:\n            raise ValueError(""field type %r not in %r"" %\n                             (type_str, _types_list))\n\n    return _data_type_reverse[type_str]\n\n\ndef _split_line(line, n):\n    fields = line.split(None, n)\n    if len(fields) == n:\n        fields.append(\'\')\n\n    assert len(fields) == n + 1\n\n    return fields\n\n\ndef make2d(array, cols=None, dtype=None):\n    \'\'\'\n    Make a 2D array from an array of arrays.  The `cols\' and `dtype\'\n    arguments can be omitted if the array is not empty.\n\n    \'\'\'\n    if (cols is None or dtype is None) and not len(array):\n        raise RuntimeError(""cols and dtype must be specified for empty ""\n                           ""array"")\n\n    if cols is None:\n        cols = len(array[0])\n\n    if dtype is None:\n        dtype = array[0].dtype\n\n    return _np.fromiter(array, [(\'_\', dtype, (cols,))],\n                        count=len(array))[\'_\']\n\n\nclass PlyParseError(Exception):\n\n    \'\'\'\n    Raised when a PLY file cannot be parsed.\n\n    The attributes `element\', `row\', `property\', and `message\' give\n    additional information.training\n\n    \'\'\'\n\n    def __init__(self, message, element=None, row=None, prop=None):\n        self.message = message\n        self.element = element\n        self.row = row\n        self.prop = prop\n\n        s = \'\'\n        if self.element:\n            s += \'element %r: \' % self.element.name\n        if self.row is not None:\n            s += \'row %d: \' % self.row\n        if self.prop:\n            s += \'property %r: \' % self.prop.name\n        s += self.message\n\n        Exception.__init__(self, s)\n\n    def __repr__(self):\n        return (\'PlyParseError(%r, element=%r, row=%r, prop=%r)\' %\n                self.message, self.element, self.row, self.prop)\n\n\nclass PlyData(object):\n\n    \'\'\'\n    PLY file header and data.\n\n    A PlyData instance is created in one of two ways: by the static\n    method PlyData.read (to read a PLY file), or directly from __init__\n    given a sequence of elements (which can then be written to a PLY\n    file).\n\n    \'\'\'\n\n    def __init__(self, elements=[], text=False, byte_order=\'=\',\n                 comments=[], obj_info=[]):\n        \'\'\'\n        elements: sequence of PlyElement instances.\n\n        text: whether the resulting PLY file will be text (True) or\n            binary (False).\n\n        byte_order: \'<\' for little-endian, \'>\' for big-endian, or \'=\'\n            for native.  This is only relevant if `text\' is False.\n\n        comments: sequence of strings that will be placed in the header\n            between the \'ply\' and \'format ...\' lines.\n\n        obj_info: like comments, but will be placed in the header with\n            ""obj_info ..."" instead of ""comment ..."".\n\n        \'\'\'\n        if byte_order == \'=\' and not text:\n            byte_order = _native_byte_order\n\n        self.byte_order = byte_order\n        self.text = text\n\n        self.comments = list(comments)\n        self.obj_info = list(obj_info)\n        self.elements = elements\n\n    def _get_elements(self):\n        return self._elements\n\n    def _set_elements(self, elements):\n        self._elements = tuple(elements)\n        self._index()\n\n    elements = property(_get_elements, _set_elements)\n\n    def _get_byte_order(self):\n        return self._byte_order\n\n    def _set_byte_order(self, byte_order):\n        if byte_order not in [\'<\', \'>\', \'=\']:\n            raise ValueError(""byte order must be \'<\', \'>\', or \'=\'"")\n\n        self._byte_order = byte_order\n\n    byte_order = property(_get_byte_order, _set_byte_order)\n\n    def _index(self):\n        self._element_lookup = dict((elt.name, elt) for elt in\n                                    self._elements)\n        if len(self._element_lookup) != len(self._elements):\n            raise ValueError(""two elements with same name"")\n\n    @staticmethod\n    def _parse_header(stream):\n        \'\'\'\n        Parse a PLY header from a readable file-like stream.\n\n        \'\'\'\n        lines = []\n        comments = {\'comment\': [], \'obj_info\': []}\n        while True:\n            line = stream.readline().decode(\'ascii\').strip()\n            fields = _split_line(line, 1)\n\n            if fields[0] == \'end_header\':\n                break\n\n            elif fields[0] in comments.keys():\n                lines.append(fields)\n            else:\n                lines.append(line.split())\n\n        a = 0\n        if lines[a] != [\'ply\']:\n            raise PlyParseError(""expected \'ply\'"")\n\n        a += 1\n        while lines[a][0] in comments.keys():\n            comments[lines[a][0]].append(lines[a][1])\n            a += 1\n\n        if lines[a][0] != \'format\':\n            raise PlyParseError(""expected \'format\'"")\n\n        if lines[a][2] != \'1.0\':\n            raise PlyParseError(""expected version \'1.0\'"")\n\n        if len(lines[a]) != 3:\n            raise PlyParseError(""too many fields after \'format\'"")\n\n        fmt = lines[a][1]\n\n        if fmt not in _byte_order_map:\n            raise PlyParseError(""don\'t understand format %r"" % fmt)\n\n        byte_order = _byte_order_map[fmt]\n        text = fmt == \'ascii\'\n\n        a += 1\n        while a < len(lines) and lines[a][0] in comments.keys():\n            comments[lines[a][0]].append(lines[a][1])\n            a += 1\n\n        return PlyData(PlyElement._parse_multi(lines[a:]),\n                       text, byte_order,\n                       comments[\'comment\'], comments[\'obj_info\'])\n\n    @staticmethod\n    def read(stream):\n        \'\'\'\n        Read PLY data from a readable file-like object or filename.\n\n        \'\'\'\n        (must_close, stream) = _open_stream(stream, \'read\')\n        try:\n            data = PlyData._parse_header(stream)\n            for elt in data:\n                elt._read(stream, data.text, data.byte_order)\n        finally:\n            if must_close:\n                stream.close()\n\n        return data\n\n    def write(self, stream):\n        \'\'\'\n        Write PLY data to a writeable file-like object or filename.\n\n        \'\'\'\n        (must_close, stream) = _open_stream(stream, \'write\')\n        try:\n            stream.write(self.header.encode(\'ascii\'))\n            stream.write(b\'\\r\\n\')\n            for elt in self:\n                elt._write(stream, self.text, self.byte_order)\n        finally:\n            if must_close:\n                stream.close()\n\n    @property\n    def header(self):\n        \'\'\'\n        Provide PLY-formatted metadata for the instance.\n\n        \'\'\'\n        lines = [\'ply\']\n\n        if self.text:\n            lines.append(\'format ascii 1.0\')\n        else:\n            lines.append(\'format \' +\n                         _byte_order_reverse[self.byte_order] +\n                         \' 1.0\')\n\n        # Some information is lost here, since all comments are placed\n        # between the \'format\' line and the first element.\n        for c in self.comments:\n            lines.append(\'comment \' + c)\n\n        for c in self.obj_info:\n            lines.append(\'obj_info \' + c)\n\n        lines.extend(elt.header for elt in self.elements)\n        lines.append(\'end_header\')\n        return \'\\r\\n\'.join(lines)\n\n    def __iter__(self):\n        return iter(self.elements)\n\n    def __len__(self):\n        return len(self.elements)\n\n    def __contains__(self, name):\n        return name in self._element_lookup\n\n    def __getitem__(self, name):\n        return self._element_lookup[name]\n\n    def __str__(self):\n        return self.header\n\n    def __repr__(self):\n        return (\'PlyData(%r, text=%r, byte_order=%r, \'\n                \'comments=%r, obj_info=%r)\' %\n                (self.elements, self.text, self.byte_order,\n                 self.comments, self.obj_info))\n\n\ndef _open_stream(stream, read_or_write):\n    if hasattr(stream, read_or_write):\n        return (False, stream)\n    try:\n        return (True, open(stream, read_or_write[0] + \'b\'))\n    except TypeError:\n        raise RuntimeError(""expected open file or filename"")\n\n\nclass PlyElement(object):\n\n    \'\'\'\n    PLY file element.\n\n    A client of this library doesn\'t normally need to instantiate this\n    directly, so the following is only for the sake of documenting the\n    internals.\n\n    Creating a PlyElement instance is generally done in one of two ways:\n    as a byproduct of PlyData.read (when reading a PLY file) and by\n    PlyElement.describe (before writing a PLY file).\n\n    \'\'\'\n\n    def __init__(self, name, properties, count, comments=[]):\n        \'\'\'\n        This is not part of the public interface.  The preferred methods\n        of obtaining PlyElement instances are PlyData.read (to read from\n        a file) and PlyElement.describe (to construct from a numpy\n        array).\n\n        \'\'\'\n        self._name = str(name)\n        self._check_name()\n        self._count = count\n\n        self._properties = tuple(properties)\n        self._index()\n\n        self.comments = list(comments)\n\n        self._have_list = any(isinstance(p, PlyListProperty)\n                              for p in self.properties)\n\n    @property\n    def count(self):\n        return self._count\n\n    def _get_data(self):\n        return self._data\n\n    def _set_data(self, data):\n        self._data = data\n        self._count = len(data)\n        self._check_sanity()\n\n    data = property(_get_data, _set_data)\n\n    def _check_sanity(self):\n        for prop in self.properties:\n            if prop.name not in self._data.dtype.fields:\n                raise ValueError(""dangling property %r"" % prop.name)\n\n    def _get_properties(self):\n        return self._properties\n\n    def _set_properties(self, properties):\n        self._properties = tuple(properties)\n        self._check_sanity()\n        self._index()\n\n    properties = property(_get_properties, _set_properties)\n\n    def _index(self):\n        self._property_lookup = dict((prop.name, prop)\n                                     for prop in self._properties)\n        if len(self._property_lookup) != len(self._properties):\n            raise ValueError(""two properties with same name"")\n\n    def ply_property(self, name):\n        return self._property_lookup[name]\n\n    @property\n    def name(self):\n        return self._name\n\n    def _check_name(self):\n        if any(c.isspace() for c in self._name):\n            msg = ""element name %r contains spaces"" % self._name\n            raise ValueError(msg)\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the numpy dtype of the in-memory representation of the\n        data.  (If there are no list properties, and the PLY format is\n        binary, then this also accurately describes the on-disk\n        representation of the element.)\n\n        \'\'\'\n        return [(prop.name, prop.dtype(byte_order))\n                for prop in self.properties]\n\n    @staticmethod\n    def _parse_multi(header_lines):\n        \'\'\'\n        Parse a list of PLY element definitions.\n\n        \'\'\'\n        elements = []\n        while header_lines:\n            (elt, header_lines) = PlyElement._parse_one(header_lines)\n            elements.append(elt)\n\n        return elements\n\n    @staticmethod\n    def _parse_one(lines):\n        \'\'\'\n        Consume one element definition.  The unconsumed input is\n        returned along with a PlyElement instance.\n\n        \'\'\'\n        a = 0\n        line = lines[a]\n\n        if line[0] != \'element\':\n            raise PlyParseError(""expected \'element\'"")\n        if len(line) > 3:\n            raise PlyParseError(""too many fields after \'element\'"")\n        if len(line) < 3:\n            raise PlyParseError(""too few fields after \'element\'"")\n\n        (name, count) = (line[1], int(line[2]))\n\n        comments = []\n        properties = []\n        while True:\n            a += 1\n            if a >= len(lines):\n                break\n\n            if lines[a][0] == \'comment\':\n                comments.append(lines[a][1])\n            elif lines[a][0] == \'property\':\n                properties.append(PlyProperty._parse_one(lines[a]))\n            else:\n                break\n\n        return (PlyElement(name, properties, count, comments),\n                lines[a:])\n\n    @staticmethod\n    def describe(data, name, len_types={}, val_types={},\n                 comments=[]):\n        \'\'\'\n        Construct a PlyElement from an array\'s metadata.\n\n        len_types and val_types can be given as mappings from list\n        property names to type strings (like \'u1\', \'f4\', etc., or\n        \'int8\', \'float32\', etc.). These can be used to define the length\n        and value types of list properties.  List property lengths\n        always default to type \'u1\' (8-bit unsigned integer), and value\n        types default to \'i4\' (32-bit integer).\n\n        \'\'\'\n        if not isinstance(data, _np.ndarray):\n            raise TypeError(""only numpy arrays are supported"")\n\n        if len(data.shape) != 1:\n            raise ValueError(""only one-dimensional arrays are ""\n                             ""supported"")\n\n        count = len(data)\n\n        properties = []\n        descr = data.dtype.descr\n\n        for t in descr:\n            if not isinstance(t[1], str):\n                raise ValueError(""nested records not supported"")\n\n            if not t[0]:\n                raise ValueError(""field with empty name"")\n\n            if len(t) != 2 or t[1][1] == \'O\':\n                # non-scalar field, which corresponds to a list\n                # property in PLY.\n\n                if t[1][1] == \'O\':\n                    if len(t) != 2:\n                        raise ValueError(""non-scalar object fields not ""\n                                         ""supported"")\n\n                len_str = _data_type_reverse[len_types.get(t[0], \'u1\')]\n                if t[1][1] == \'O\':\n                    val_type = val_types.get(t[0], \'i4\')\n                    val_str = _lookup_type(val_type)\n                else:\n                    val_str = _lookup_type(t[1][1:])\n\n                prop = PlyListProperty(t[0], len_str, val_str)\n            else:\n                val_str = _lookup_type(t[1][1:])\n                prop = PlyProperty(t[0], val_str)\n\n            properties.append(prop)\n\n        elt = PlyElement(name, properties, count, comments)\n        elt.data = data\n\n        return elt\n\n    def _read(self, stream, text, byte_order):\n        \'\'\'\n        Read the actual data from a PLY file.\n\n        \'\'\'\n        if text:\n            self._read_txt(stream)\n        else:\n            if self._have_list:\n                # There are list properties, so a simple load is\n                # impossible.\n                self._read_bin(stream, byte_order)\n            else:\n                # There are no list properties, so loading the data is\n                # much more straightforward.\n                self._data = _np.fromfile(stream,\n                                          self.dtype(byte_order),\n                                          self.count)\n\n        if len(self._data) < self.count:\n            k = len(self._data)\n            del self._data\n            raise PlyParseError(""early end-of-file"", self, k)\n\n        self._check_sanity()\n\n    def _write(self, stream, text, byte_order):\n        \'\'\'\n        Write the data to a PLY file.\n\n        \'\'\'\n        if text:\n            self._write_txt(stream)\n        else:\n            if self._have_list:\n                # There are list properties, so serialization is\n                # slightly complicated.\n                self._write_bin(stream, byte_order)\n            else:\n                # no list properties, so serialization is\n                # straightforward.\n                self.data.astype(self.dtype(byte_order),\n                                 copy=False).tofile(stream)\n\n    def _read_txt(self, stream):\n        \'\'\'\n        Load a PLY element from an ASCII-format PLY file.  The element\n        may contain list properties.\n\n        \'\'\'\n        self._data = _np.empty(self.count, dtype=self.dtype())\n\n        k = 0\n        for line in _islice(iter(stream.readline, b\'\'), self.count):\n            fields = iter(line.strip().split())\n            for prop in self.properties:\n                try:\n                    self._data[prop.name][k] = prop._from_fields(fields)\n                except StopIteration:\n                    raise PlyParseError(""early end-of-line"",\n                                        self, k, prop)\n                except ValueError:\n                    raise PlyParseError(""malformed input"",\n                                        self, k, prop)\n            try:\n                next(fields)\n            except StopIteration:\n                pass\n            else:\n                raise PlyParseError(""expected end-of-line"", self, k)\n            k += 1\n\n        if k < self.count:\n            del self._data\n            raise PlyParseError(""early end-of-file"", self, k)\n\n    def _write_txt(self, stream):\n        \'\'\'\n        Save a PLY element to an ASCII-format PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        for rec in self.data:\n            fields = []\n            for prop in self.properties:\n                fields.extend(prop._to_fields(rec[prop.name]))\n\n            _np.savetxt(stream, [fields], \'%.18g\', newline=\'\\r\\n\')\n\n    def _read_bin(self, stream, byte_order):\n        \'\'\'\n        Load a PLY element from a binary PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        self._data = _np.empty(self.count, dtype=self.dtype(byte_order))\n\n        for k in _range(self.count):\n            for prop in self.properties:\n                try:\n                    self._data[prop.name][k] = \\\n                        prop._read_bin(stream, byte_order)\n                except StopIteration:\n                    raise PlyParseError(""early end-of-file"",\n                                        self, k, prop)\n\n    def _write_bin(self, stream, byte_order):\n        \'\'\'\n        Save a PLY element to a binary PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        for rec in self.data:\n            for prop in self.properties:\n                prop._write_bin(rec[prop.name], stream, byte_order)\n\n    @property\n    def header(self):\n        \'\'\'\n        Format this element\'s metadata as it would appear in a PLY\n        header.\n\n        \'\'\'\n        lines = [\'element %s %d\' % (self.name, self.count)]\n\n        # Some information is lost here, since all comments are placed\n        # between the \'element\' line and the first property definition.\n        for c in self.comments:\n            lines.append(\'comment \' + c)\n\n        lines.extend(list(map(str, self.properties)))\n\n        return \'\\r\\n\'.join(lines)\n\n    def __getitem__(self, key):\n        return self.data[key]\n\n    def __setitem__(self, key, value):\n        self.data[key] = value\n\n    def __str__(self):\n        return self.header\n\n    def __repr__(self):\n        return (\'PlyElement(%r, %r, count=%d, comments=%r)\' %\n                (self.name, self.properties, self.count,\n                 self.comments))\n\n\nclass PlyProperty(object):\n\n    \'\'\'\n    PLY property description.  This class is pure metadata; the data\n    itself is contained in PlyElement instances.\n\n    \'\'\'\n\n    def __init__(self, name, val_dtype):\n        self._name = str(name)\n        self._check_name()\n        self.val_dtype = val_dtype\n\n    def _get_val_dtype(self):\n        return self._val_dtype\n\n    def _set_val_dtype(self, val_dtype):\n        self._val_dtype = _data_types[_lookup_type(val_dtype)]\n\n    val_dtype = property(_get_val_dtype, _set_val_dtype)\n\n    @property\n    def name(self):\n        return self._name\n\n    def _check_name(self):\n        if any(c.isspace() for c in self._name):\n            msg = ""Error: property name %r contains spaces"" % self._name\n            raise RuntimeError(msg)\n\n    @staticmethod\n    def _parse_one(line):\n        assert line[0] == \'property\'\n\n        if line[1] == \'list\':\n            if len(line) > 5:\n                raise PlyParseError(""too many fields after ""\n                                    ""\'property list\'"")\n            if len(line) < 5:\n                raise PlyParseError(""too few fields after ""\n                                    ""\'property list\'"")\n\n            return PlyListProperty(line[4], line[2], line[3])\n\n        else:\n            if len(line) > 3:\n                raise PlyParseError(""too many fields after ""\n                                    ""\'property\'"")\n            if len(line) < 3:\n                raise PlyParseError(""too few fields after ""\n                                    ""\'property\'"")\n\n            return PlyProperty(line[2], line[1])\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the numpy dtype description for this property (as a tuple\n        of strings).\n\n        \'\'\'\n        return byte_order + self.val_dtype\n\n    def _from_fields(self, fields):\n        \'\'\'\n        Parse from generator.  Raise StopIteration if the property could\n        not be read.\n\n        \'\'\'\n        return _np.dtype(self.dtype()).type(next(fields))\n\n    def _to_fields(self, data):\n        \'\'\'\n        Return generator over one item.\n\n        \'\'\'\n        yield _np.dtype(self.dtype()).type(data)\n\n    def _read_bin(self, stream, byte_order):\n        \'\'\'\n        Read data from a binary stream.  Raise StopIteration if the\n        property could not be read.\n\n        \'\'\'\n        try:\n            return _np.fromfile(stream, self.dtype(byte_order), 1)[0]\n        except IndexError:\n            raise StopIteration\n\n    def _write_bin(self, data, stream, byte_order):\n        \'\'\'\n        Write data to a binary stream.\n\n        \'\'\'\n        _np.dtype(self.dtype(byte_order)).type(data).tofile(stream)\n\n    def __str__(self):\n        val_str = _data_type_reverse[self.val_dtype]\n        return \'property %s %s\' % (val_str, self.name)\n\n    def __repr__(self):\n        return \'PlyProperty(%r, %r)\' % (self.name,\n                                        _lookup_type(self.val_dtype))\n\n\nclass PlyListProperty(PlyProperty):\n\n    \'\'\'\n    PLY list property description.\n\n    \'\'\'\n\n    def __init__(self, name, len_dtype, val_dtype):\n        PlyProperty.__init__(self, name, val_dtype)\n\n        self.len_dtype = len_dtype\n\n    def _get_len_dtype(self):\n        return self._len_dtype\n\n    def _set_len_dtype(self, len_dtype):\n        self._len_dtype = _data_types[_lookup_type(len_dtype)]\n\n    len_dtype = property(_get_len_dtype, _set_len_dtype)\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        List properties always have a numpy dtype of ""object"".\n\n        \'\'\'\n        return \'|O\'\n\n    def list_dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the pair (len_dtype, val_dtype) (both numpy-friendly\n        strings).\n\n        \'\'\'\n        return (byte_order + self.len_dtype,\n                byte_order + self.val_dtype)\n\n    def _from_fields(self, fields):\n        (len_t, val_t) = self.list_dtype()\n\n        n = int(_np.dtype(len_t).type(next(fields)))\n\n        data = _np.loadtxt(list(_islice(fields, n)), val_t, ndmin=1)\n        if len(data) < n:\n            raise StopIteration\n\n        return data\n\n    def _to_fields(self, data):\n        \'\'\'\n        Return generator over the (numerical) PLY representation of the\n        list data (length followed by actual data).\n\n        \'\'\'\n        (len_t, val_t) = self.list_dtype()\n\n        data = _np.asarray(data, dtype=val_t).ravel()\n\n        yield _np.dtype(len_t).type(data.size)\n        for x in data:\n            yield x\n\n    def _read_bin(self, stream, byte_order):\n        (len_t, val_t) = self.list_dtype(byte_order)\n\n        try:\n            n = _np.fromfile(stream, len_t, 1)[0]\n        except IndexError:\n            raise StopIteration\n\n        data = _np.fromfile(stream, val_t, n)\n        if len(data) < n:\n            raise StopIteration\n\n        return data\n\n    def _write_bin(self, data, stream, byte_order):\n        \'\'\'\n        Write data to a binary stream.\n\n        \'\'\'\n        (len_t, val_t) = self.list_dtype(byte_order)\n\n        data = _np.asarray(data, dtype=val_t).ravel()\n\n        _np.array(data.size, dtype=len_t).tofile(stream)\n        data.tofile(stream)\n\n    def __str__(self):\n        len_str = _data_type_reverse[self.len_dtype]\n        val_str = _data_type_reverse[self.val_dtype]\n        return \'property list %s %s %s\' % (len_str, val_str, self.name)\n\n    def __repr__(self):\n        return (\'PlyListProperty(%r, %r, %r)\' %\n                (self.name,\n                 _lookup_type(self.len_dtype),\n                 _lookup_type(self.val_dtype)))\n'"
utils/pointnet_util.py,28,"b'"""""" PointNet++ Layers\n\nAuthor: Charles R. Qi\nDate: November 2017\n""""""\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(__file__)\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, \'utils\'))\nsys.path.append(os.path.join(ROOT_DIR, \'tf_ops/sampling\'))\nsys.path.append(os.path.join(ROOT_DIR, \'tf_ops/grouping\'))\nsys.path.append(os.path.join(ROOT_DIR, \'tf_ops/3d_interpolation\'))\nfrom tf_sampling import farthest_point_sample, gather_point\nfrom tf_grouping import query_ball_point, group_point, knn_point\nfrom tf_interpolate import three_nn, three_interpolate\nimport tensorflow as tf\nimport numpy as np\nfrom models import tf_util\n\n\ndef sample_and_group(npoint, radius, nsample, xyz, points, tnet_spec=None, knn=False, use_xyz=True):\n    \'\'\'\n    Input:\n        npoint: int32\n        radius: float32\n        nsample: int32\n        xyz: (batch_size, ndataset, 3) TF tensor\n        points: (batch_size, ndataset, channel) TF tensor, if None will just use xyz as points\n        tnet_spec: dict (keys: mlp, mlp2, is_training, bn_decay), if None do not apply tnet\n        knn: bool, if True use kNN instead of radius search\n        use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n    Output:\n        new_xyz: (batch_size, npoint, 3) TF tensor\n        new_points: (batch_size, npoint, nsample, 3+channel) TF tensor\n        idx: (batch_size, npoint, nsample) TF tensor, indices of local points as in ndataset points\n        grouped_xyz: (batch_size, npoint, nsample, 3) TF tensor, normalized point XYZs\n            (subtracted by seed point XYZ) in local regions\n    \'\'\'\n\n    new_xyz = gather_point(xyz, farthest_point_sample(npoint, xyz)) # (batch_size, npoint, 3)\n    if knn:\n        _,idx = knn_point(nsample, xyz, new_xyz)\n    else:\n        idx, pts_cnt = query_ball_point(radius, nsample, xyz, new_xyz)\n    grouped_xyz = group_point(xyz, idx) # (batch_size, npoint, nsample, 3)\n    grouped_xyz -= tf.tile(tf.expand_dims(new_xyz, 2), [1,1,nsample,1]) # translation normalization\n    if tnet_spec is not None:\n        grouped_xyz = tnet(grouped_xyz, tnet_spec)\n    if points is not None:\n        grouped_points = group_point(points, idx) # (batch_size, npoint, nsample, channel)\n        if use_xyz:\n            new_points = tf.concat([grouped_xyz, grouped_points], axis=-1) # (batch_size, npoint, nample, 3+channel)\n        else:\n            new_points = grouped_points\n    else:\n        new_points = grouped_xyz\n\n    return new_xyz, new_points, idx, grouped_xyz\n\n\ndef sample_and_group_all(xyz, points, use_xyz=True):\n    \'\'\'\n    Inputs:\n        xyz: (batch_size, ndataset, 3) TF tensor\n        points: (batch_size, ndataset, channel) TF tensor, if None will just use xyz as points\n        use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n    Outputs:\n        new_xyz: (batch_size, 1, 3) as (0,0,0)\n        new_points: (batch_size, 1, ndataset, 3+channel) TF tensor\n    Note:\n        Equivalent to sample_and_group with npoint=1, radius=inf, use (0,0,0) as the centroid\n    \'\'\'\n    batch_size = xyz.get_shape()[0].value\n    nsample = xyz.get_shape()[1].value\n    new_xyz = tf.constant(np.tile(np.array([0,0,0]).reshape((1,1,3)), (batch_size,1,1)),dtype=tf.float32) # (batch_size, 1, 3)\n    idx = tf.constant(np.tile(np.array(range(nsample)).reshape((1,1,nsample)), (batch_size,1,1)))\n    grouped_xyz = tf.reshape(xyz, (batch_size, 1, nsample, 3)) # (batch_size, npoint=1, nsample, 3)\n    if points is not None:\n        if use_xyz:\n            new_points = tf.concat([xyz, points], axis=2) # (batch_size, 16, 259)\n        else:\n            new_points = points\n        new_points = tf.expand_dims(new_points, 1) # (batch_size, 1, 16, 259)\n    else:\n        new_points = grouped_xyz\n    return new_xyz, new_points, idx, grouped_xyz\n\n\ndef pointnet_sa_module(xyz, points, npoint, radius, nsample, mlp, mlp2, group_all, is_training, bn_decay, scope, bn=True, pooling=\'max\', tnet_spec=None, knn=False, use_xyz=True):\n    \'\'\' PointNet Set Abstraction (SA) Module\n        Input:\n            xyz: (batch_size, ndataset, 3) TF tensor\n            points: (batch_size, ndataset, channel) TF tensor\n            npoint: int32 -- #points sampled in farthest point sampling\n            radius: float32 -- search radius in local region\n            nsample: int32 -- how many points in each local region\n            mlp: list of int32 -- output size for MLP on each point\n            mlp2: list of int32 -- output size for MLP on each region\n            group_all: bool -- group all points into one PC if set true, OVERRIDE\n                npoint, radius and nsample settings\n            use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n        Return:\n            new_xyz: (batch_size, npoint, 3) TF tensor\n            new_points: (batch_size, npoint, mlp[-1] or mlp2[-1]) TF tensor\n            idx: (batch_size, npoint, nsample) int32 -- indices for local regions\n    \'\'\'\n    with tf.variable_scope(scope) as sc:\n        if group_all:\n            nsample = xyz.get_shape()[1].value\n            new_xyz, new_points, idx, grouped_xyz = sample_and_group_all(xyz, points, use_xyz)\n        else:\n            new_xyz, new_points, idx, grouped_xyz = sample_and_group(npoint, radius, nsample, xyz, points, tnet_spec, knn, use_xyz)\n        for i, num_out_channel in enumerate(mlp):\n            new_points = tf_util.conv2d(new_points, num_out_channel, [1, 1],\n                                        padding=\'VALID\', stride=[1,1],\n                                        bn=bn, is_training=is_training,\n                                        scope=\'conv%d\'%(i), bn_decay=bn_decay) \n        if pooling==\'avg\':\n            new_points = tf_util.avg_pool2d(new_points, [1, nsample], stride=[1, 1], padding=\'VALID\', scope=\'avgpool1\')\n        elif pooling==\'weighted_avg\':\n            with tf.variable_scope(\'weighted_avg1\'):\n                dists = tf.norm(grouped_xyz,axis=-1,ord=2,keep_dims=True)\n                exp_dists = tf.exp(-dists * 5)\n                weights = exp_dists/tf.reduce_sum(exp_dists,axis=2,keep_dims=True) # (batch_size, npoint, nsample, 1)\n                new_points *= weights # (batch_size, npoint, nsample, mlp[-1])\n                new_points = tf.reduce_sum(new_points, axis=2, keep_dims=True)\n        elif pooling==\'max\':\n            new_points = tf.reduce_max(new_points, axis=[2], keep_dims=True)\n        elif pooling==\'min\':\n            new_points = tf_util.max_pool2d(-1 * new_points, [1, nsample], stride=[1, 1], padding=\'VALID\', scope=\'minpool1\')\n        elif pooling==\'max_and_avg\':\n            avg_points = tf_util.max_pool2d(new_points, [1, nsample], stride=[1, 1], padding=\'VALID\', scope=\'maxpool1\')\n            max_points = tf_util.avg_pool2d(new_points, [1, nsample], stride=[1, 1], padding=\'VALID\', scope=\'avgpool1\')\n            new_points = tf.concat([avg_points, max_points], axis=-1)\n            \n        if mlp2 is None: mlp2 = []\n        for i, num_out_channel in enumerate(mlp2):\n            new_points = tf_util.conv2d(new_points, num_out_channel, [1, 1],\n                                        padding=\'VALID\', stride=[1,1],\n                                        bn=bn, is_training=is_training,\n                                        scope=\'conv_post_%d\'%(i), bn_decay=bn_decay) \n        new_points = tf.squeeze(new_points, [2]) # (batch_size, npoints, mlp2[-1])\n        return new_xyz, new_points, idx\n\ndef pointnet_sa_module_msg(xyz, points, npoint, radius_list, nsample_list, mlp_list, is_training, bn_decay, scope, bn=True, use_xyz=True):\n    \'\'\' PointNet Set Abstraction (SA) module with Multi-Scale Grouping (MSG)\n        Input:\n            xyz: (batch_size, ndataset, 3) TF tensor\n            points: (batch_size, ndataset, channel) TF tensor\n            npoint: int32 -- #points sampled in farthest point sampling\n            radius: list of float32 -- search radius in local region\n            nsample: list of int32 -- how many points in each local region\n            mlp: list of list of int32 -- output size for MLP on each point\n            use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n        Return:\n            new_xyz: (batch_size, npoint, 3) TF tensor\n            new_points: (batch_size, npoint, \\sum_k{mlp[k][-1]}) TF tensor\n    \'\'\'\n    with tf.variable_scope(scope) as sc:\n        new_xyz = gather_point(xyz, farthest_point_sample(npoint, xyz))\n        new_points_list = []\n        for i in range(len(radius_list)):\n            radius = radius_list[i]\n            nsample = nsample_list[i]\n            idx, pts_cnt = query_ball_point(radius, nsample, xyz, new_xyz)\n            grouped_xyz = group_point(xyz, idx)\n            grouped_xyz -= tf.tile(tf.expand_dims(new_xyz, 2), [1,1,nsample,1])\n            if points is not None:\n                grouped_points = group_point(points, idx)\n                if use_xyz:\n                    grouped_points = tf.concat([grouped_points, grouped_xyz], axis=-1)\n            else:\n                grouped_points = grouped_xyz\n            for j,num_out_channel in enumerate(mlp_list[i]):\n                grouped_points = tf_util.conv2d(grouped_points, num_out_channel, [1, 1],\n                                                padding=\'VALID\', stride=[1,1], bn=bn, is_training=is_training,\n                                                scope=\'conv%d_%d\'%(i,j), bn_decay=bn_decay)\n            new_points = tf.reduce_max(grouped_points, axis=[2])\n            new_points_list.append(new_points)\n        new_points_concat = tf.concat(new_points_list, axis=-1)\n        return new_xyz, new_points_concat\n\n \ndef pointnet_fp_module(xyz1, xyz2, points1, points2, mlp, is_training, bn_decay, scope, bn=True):\n    \'\'\' PointNet Feature Propogation (FP) Module\n        Input:                                                                                                      \n            xyz1: (batch_size, ndataset1, 3) TF tensor                                                              \n            xyz2: (batch_size, ndataset2, 3) TF tensor, sparser than xyz1                                           \n            points1: (batch_size, ndataset1, nchannel1) TF tensor                                                   \n            points2: (batch_size, ndataset2, nchannel2) TF tensor\n            mlp: list of int32 -- output size for MLP on each point                                                 \n        Return:\n            new_points: (batch_size, ndataset1, mlp[-1]) TF tensor\n    \'\'\'\n    with tf.variable_scope(scope) as sc:\n        dist, idx = three_nn(xyz1, xyz2)\n        dist = tf.maximum(dist, 1e-10)\n        norm = tf.reduce_sum((1.0/dist),axis=2,keep_dims=True)\n        norm = tf.tile(norm,[1,1,3])\n        weight = (1.0/dist) / norm\n        interpolated_points = three_interpolate(points2, idx, weight)\n\n        if points1 is not None:\n            new_points1 = tf.concat(axis=2, values=[interpolated_points, points1]) # B,ndataset1,nchannel1+nchannel2\n        else:\n            new_points1 = interpolated_points\n        new_points1 = tf.expand_dims(new_points1, 2)\n        for i, num_out_channel in enumerate(mlp):\n            new_points1 = tf_util.conv2d(new_points1, num_out_channel, [1, 1],\n                                         padding=\'VALID\', stride=[1,1],\n                                         bn=bn, is_training=is_training,\n                                         scope=\'conv_%d\'%(i), bn_decay=bn_decay)\n        new_points1 = tf.squeeze(new_points1, [2]) # B,ndataset1,mlp[-1]\n        return new_points1\n'"
utils/test_utils.py,0,"b""import numpy as np\nfrom scipy import stats\nimport matplotlib as mpl\nimport json\nmpl.use('Agg')\n\n############################\n##    Ths Statistics      ##\n############################\n\ndef Get_Ths(pts_corr, seg, ins, ths, ths_, cnt):\n\n    pts_in_ins = {}\n    for ip, pt in enumerate(pts_corr):\n        if ins[ip] in pts_in_ins.keys():\n            pts_in_curins_ind = pts_in_ins[ins[ip]]\n            pts_notin_curins_ind = (~(pts_in_ins[ins[ip]])) & (seg==seg[ip])\n            hist, bin = np.histogram(pt[pts_in_curins_ind], bins=20)\n\n            if seg[ip]==8:\n                print bin\n\n            numpt_in_curins = np.sum(pts_in_curins_ind)\n            numpt_notin_curins = np.sum(pts_notin_curins_ind)\n\n            if numpt_notin_curins > 0:\n\n                tp_over_fp = 0\n                ib_opt = -2\n                for ib, b in enumerate(bin):\n                    if b == 0:\n                        break\n                    tp = float(np.sum(pt[pts_in_curins_ind] < bin[ib])) / float(numpt_in_curins)\n                    fp = float(np.sum(pt[pts_notin_curins_ind] < bin[ib])) / float(numpt_notin_curins)\n\n                    if tp <= 0.5:\n                        continue\n\n                    if fp == 0. and tp > 0.5:\n                        ib_opt = ib\n                        break\n\n                    if tp/fp > tp_over_fp:\n                        tp_over_fp = tp / fp\n                        ib_opt = ib\n\n                if tp_over_fp >  4.:\n                    ths[seg[ip]] += bin[ib_opt]\n                    ths_[seg[ip]] += bin[ib_opt]\n                    cnt[seg[ip]] += 1\n\n        else:\n            pts_in_curins_ind = (ins == ins[ip])\n            pts_in_ins[ins[ip]] = pts_in_curins_ind\n            pts_notin_curins_ind = (~(pts_in_ins[ins[ip]])) & (seg==seg[ip])\n            hist, bin = np.histogram(pt[pts_in_curins_ind], bins=20)\n\n            if seg[ip]==8:\n                print bin\n\n            numpt_in_curins = np.sum(pts_in_curins_ind)\n            numpt_notin_curins = np.sum(pts_notin_curins_ind)\n\n            if numpt_notin_curins > 0:\n\n                tp_over_fp = 0\n                ib_opt = -2\n                for ib, b in enumerate(bin):\n\n                    if b == 0:\n                        break\n\n                    tp = float(np.sum(pt[pts_in_curins_ind]<bin[ib])) / float(numpt_in_curins)\n                    fp = float(np.sum(pt[pts_notin_curins_ind]<bin[ib])) / float(numpt_notin_curins)\n\n                    if tp <= 0.5:\n                        continue\n\n                    if fp == 0. and tp > 0.5:\n                        ib_opt = ib\n                        break\n\n                    if tp / fp > tp_over_fp:\n                        tp_over_fp = tp / fp\n                        ib_opt = ib\n\n                if tp_over_fp >  4.:\n                    ths[seg[ip]] += bin[ib_opt]\n                    ths_[seg[ip]] += bin[ib_opt]\n                    cnt[seg[ip]] += 1\n\n    return ths, ths_, cnt\n\n\n##############################\n##    Merging Algorithms    ##\n##############################\n\ndef GroupMerging(pts_corr, confidence, seg, label_bin):\n\n    confvalidpts = (confidence>0.4)\n    un_seg = np.unique(seg)\n    refineseg = -1* np.ones(pts_corr.shape[0])\n    groupid = -1* np.ones(pts_corr.shape[0])\n    numgroups = 0\n    groupseg = {}\n    for i_seg in un_seg:\n        if i_seg==-1:\n            continue\n        pts_in_seg = (seg==i_seg)\n        valid_seg_group = np.where(pts_in_seg & confvalidpts)\n        proposals = []\n        if valid_seg_group[0].shape[0]==0:\n            proposals += [pts_in_seg]\n        else:\n            for ip in valid_seg_group[0]:\n                validpt = (pts_corr[ip] < label_bin[i_seg]) & pts_in_seg\n                if np.sum(validpt)>5:\n                    flag = False\n                    for gp in range(len(proposals)):\n                        iou = float(np.sum(validpt & proposals[gp])) / np.sum(validpt|proposals[gp])#uniou\n                        validpt_in_gp = float(np.sum(validpt & proposals[gp])) / np.sum(validpt)#uniou\n                        if iou > 0.6 or validpt_in_gp > 0.8:\n                            flag = True\n                            if np.sum(validpt)>np.sum(proposals[gp]):\n                                proposals[gp] = validpt\n                            continue\n\n                    if not flag:\n                        proposals += [validpt]\n\n            if len(proposals) == 0:\n                proposals += [pts_in_seg]\n        for gp in range(len(proposals)):\n            if np.sum(proposals[gp])>50:\n                groupid[proposals[gp]] = numgroups\n                groupseg[numgroups] = i_seg\n                numgroups += 1\n                refineseg[proposals[gp]] = stats.mode(seg[proposals[gp]])[0]\n\n    un, cnt = np.unique(groupid, return_counts=True)\n    for ig, g in enumerate(un):\n        if cnt[ig] < 50:\n            groupid[groupid==g] = -1\n\n    un, cnt = np.unique(groupid, return_counts=True)\n    groupidnew = groupid.copy()\n    for ig, g in enumerate(un):\n        if g == -1:\n            continue\n        groupidnew[groupid==g] = (ig-1)\n        groupseg[(ig-1)] = groupseg.pop(g)\n    groupid = groupidnew\n\n    for ip, gid in enumerate(groupid):\n        if gid == -1:\n            pts_in_gp_ind = (pts_corr[ip] < label_bin[seg[ip]])\n            pts_in_gp = groupid[pts_in_gp_ind]\n            pts_in_gp_valid = pts_in_gp[pts_in_gp!=-1]\n            if len(pts_in_gp_valid) != 0:\n                groupid[ip] = stats.mode(pts_in_gp_valid)[0][0]\n\n    return groupid, refineseg, groupseg\n\ndef BlockMerging(volume, volume_seg, pts, grouplabel, groupseg, gap=1e-3):\n\n    overlapgroupcounts = np.zeros([100,300])\n    groupcounts = np.ones(100)\n    x=(pts[:,0]/gap).astype(np.int32)\n    y=(pts[:,1]/gap).astype(np.int32)\n    z=(pts[:,2]/gap).astype(np.int32)\n    for i in range(pts.shape[0]):\n        xx=x[i]\n        yy=y[i]\n        zz=z[i]\n        if grouplabel[i] != -1:\n            if volume[xx,yy,zz]!=-1 and volume_seg[xx,yy,zz]==groupseg[grouplabel[i]]:\n                overlapgroupcounts[grouplabel[i],volume[xx,yy,zz]] += 1\n        groupcounts[grouplabel[i]] += 1\n\n    groupcate = np.argmax(overlapgroupcounts,axis=1)\n    maxoverlapgroupcounts = np.max(overlapgroupcounts,axis=1)\n\n    curr_max = np.max(volume)\n    for i in range(groupcate.shape[0]):\n        if maxoverlapgroupcounts[i]<7 and groupcounts[i]>30:\n            curr_max += 1\n            groupcate[i] = curr_max\n\n\n    finalgrouplabel = -1 * np.ones(pts.shape[0])\n\n    for i in range(pts.shape[0]):\n        if grouplabel[i] != -1 and volume[x[i],y[i],z[i]]==-1:\n            volume[x[i],y[i],z[i]] = groupcate[grouplabel[i]]\n            volume_seg[x[i],y[i],z[i]] = groupseg[grouplabel[i]]\n            finalgrouplabel[i] = groupcate[grouplabel[i]]\n    return finalgrouplabel\n\n\n############################\n##    Evaluation Metrics  ##\n############################\n\ndef eval_3d_perclass(tp, fp, npos):\n\n    tp = np.asarray(tp).astype(np.float)\n    fp = np.asarray(fp).astype(np.float)\n    tp = np.cumsum(tp)\n    fp = np.cumsum(fp)\n    rec = tp / npos\n    prec = tp / (fp+tp)\n\n    ap = 0.\n    for t in np.arange(0, 1, 0.1):\n        prec1 = prec[rec>=t]\n        prec1 = prec1[~np.isnan(prec1)]\n        if len(prec1) == 0:\n            p = 0.\n        else:\n            p = max(prec1)\n            if not p:\n                p = 0.\n\n        ap = ap + p / 10\n\n\n    return ap, rec, prec\n\n############################\n##    Visualize Results   ##\n############################\n\ncolor_map = json.load(open('part_color_mapping.json', 'r'))\n\ndef output_bounding_box_withcorners(box_corners, seg, out_file):\n    # ##############   0       1       2       3       4       5       6       7\n    corner_indexes = [[0, 1, 2], [0, 1, 5], [0, 4, 2], [0, 4, 5], [3, 1, 2], [3, 1, 5], [3, 4, 2], [3, 4, 5]]\n    line_indexes = [[0, 1], [0, 2], [0, 4], [1, 3], [1, 5], [2, 3], [2, 6], [3, 7], [4, 5], [4, 6], [5, 7], [6, 7]]\n    with open(out_file, 'w') as f:\n        l = box_corners.shape[0]\n        for i in range(l):\n            box = box_corners[i]\n            color = color_map[seg[i]]\n            for line_index in line_indexes:\n                corner0 = box[line_index[0]]\n                corner1 = box[line_index[1]]\n                print corner0.shape\n                dist = np.linalg.norm(corner0 - corner1)\n                dot_num = int(dist / 0.005)\n                delta = (corner1 - corner0) / dot_num\n                for idot in range(dot_num):\n                    plotdot = corner0 + idot * delta\n                    f.write(\n                        'v %f %f %f %f %f %f\\n' % (plotdot[0], plotdot[1], plotdot[2], color[0], color[1], color[2]))\n\n\ndef output_bounding_box(boxes, seg, out_file):\n    # ##############   0       1       2       3       4       5       6       7\n    #box:nx8x3\n    corner_indexes = [[0, 1, 2], [0, 1, 5], [0, 4, 2], [0, 4, 5], [3, 1, 2], [3, 1, 5], [3, 4, 2], [3, 4, 5]]\n    line_indexes = [[0, 1], [0, 2], [0, 4], [1, 3], [1, 5], [2, 3], [2, 6], [3, 7], [4, 5], [4, 6], [5, 7], [6, 7]]\n    with open(out_file, 'w') as f:\n        l = boxes.shape[0]\n        for i in range(l):\n            box = boxes[i]\n            color = color_map[seg[i]]\n            for line_index in line_indexes:\n                corner0 = box[corner_indexes[line_index[0]]]\n                corner1 = box[corner_indexes[line_index[1]]]\n                dist = np.linalg.norm(corner0 - corner1)\n                dot_num = int(dist / 0.005)\n                delta = (corner1 - corner0) / dot_num\n                for idot in range(dot_num):\n                    plotdot = corner0 + idot * delta\n                    f.write(\n                        'v %f %f %f %f %f %f\\n' % (plotdot[0], plotdot[1], plotdot[2], color[0], color[1], color[2]))\n\n\ndef output_color_point_cloud(data, seg, out_file):\n    with open(out_file, 'w') as f:\n        l = len(seg)\n        for i in range(l):\n            color = color_map[seg[i]]\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], color[0], color[1], color[2]))\n\n\ndef output_point_cloud_rgb(data, rgb, out_file):\n    with open(out_file, 'w') as f:\n        l = len(data)\n        for i in range(l):\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], rgb[i][0],  rgb[i][1],  rgb[i][2]))\n\n\ndef output_color_point_cloud_red_blue(data, seg, out_file):\n    with open(out_file, 'w') as f:\n        l = len(seg)\n        for i in range(l):\n            if seg[i] == 1:\n                color = [0, 0, 1]\n            elif seg[i] == 0:\n                color = [1, 0, 0]\n            else:\n                color = [0, 0, 0]\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], color[0], color[1], color[2]))\n\n\n##define color heat map\nnorm = mpl.colors.Normalize(vmin=0, vmax=255)\nmagma_cmap = mpl.cm.get_cmap('magma')\nmagma_rgb = []\nfor i in range(0, 255):\n       k = mpl.colors.colorConverter.to_rgb(magma_cmap(norm(i)))\n       magma_rgb.append(k)\n\n\ndef output_scale_point_cloud(data, scales, out_file):\n    with open(out_file, 'w') as f:\n        l = len(scales)\n        for i in range(l):\n            scale = int(scales[i]*254)\n            if scale > 254:\n                scale = 254\n            color = magma_rgb[scale]\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], color[0], color[1], color[2]))\n\n"""
