file_path,api_count,code
mnist_acgan.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n""""""\nfile: mnist_acgan.py\nauthor: Luke de Oliveira (lukedeo@vaitech.io)\n\nTrain an Auxiliary Classifier Generative Adversarial Network (ACGAN) on the\nMNIST dataset. See https://arxiv.org/abs/1610.09585 for more details.\n\nYou should start to see reasonable images after ~5 epochs, and good images\nby ~15 epochs. You should use a GPU, as the convolution-heavy operations are\nvery slow on the CPU. Prefer the TensorFlow backend if you plan on iterating, as\nthe compilation time can be a blocker using Theano.\n\nTimings:\n\nHardware           | Backend | Time / Epoch\n-------------------------------------------\n CPU               | TF      | 3 hrs\n Titan X (maxwell) | TF      | 4 min\n Titan X (maxwell) | TH      | 7 min\n\nConsult https://github.com/lukedeo/keras-acgan for more information and\nexample output\n""""""\nfrom __future__ import print_function\n\nfrom collections import defaultdict\nimport cPickle as pickle\nfrom PIL import Image\n\nfrom six.moves import range\n\nimport keras.backend as K\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Embedding, merge, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Convolution2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom keras.utils.generic_utils import Progbar\nimport numpy as np\n\nnp.random.seed(1337)\n\nK.set_image_dim_ordering(\'th\')\n\n\ndef build_generator(latent_size):\n    # we will map a pair of (z, L), where z is a latent vector and L is a\n    # label drawn from P_c, to image space (..., 1, 28, 28)\n    cnn = Sequential()\n\n    cnn.add(Dense(1024, input_dim=latent_size, activation=\'relu\'))\n    cnn.add(Dense(128 * 7 * 7, activation=\'relu\'))\n    cnn.add(Reshape((128, 7, 7)))\n\n    # upsample to (..., 14, 14)\n    cnn.add(UpSampling2D(size=(2, 2)))\n    cnn.add(Convolution2D(256, 5, 5, border_mode=\'same\',\n                          activation=\'relu\', init=\'glorot_normal\'))\n\n    # upsample to (..., 28, 28)\n    cnn.add(UpSampling2D(size=(2, 2)))\n    cnn.add(Convolution2D(128, 5, 5, border_mode=\'same\',\n                          activation=\'relu\', init=\'glorot_normal\'))\n\n    # take a channel axis reduction\n    cnn.add(Convolution2D(1, 2, 2, border_mode=\'same\',\n                          activation=\'tanh\', init=\'glorot_normal\'))\n\n    # this is the z space commonly refered to in GAN papers\n    latent = Input(shape=(latent_size, ))\n\n    # this will be our label\n    image_class = Input(shape=(1,), dtype=\'int32\')\n\n    # 10 classes in MNIST\n    cls = Flatten()(Embedding(10, latent_size,\n                              init=\'glorot_normal\')(image_class))\n\n    # hadamard product between z-space and a class conditional embedding\n    h = merge([latent, cls], mode=\'mul\')\n\n    fake_image = cnn(h)\n\n    return Model(input=[latent, image_class], output=fake_image)\n\n\ndef build_discriminator():\n    # build a relatively standard conv net, with LeakyReLUs as suggested in\n    # the reference paper\n    cnn = Sequential()\n\n    cnn.add(Convolution2D(32, 3, 3, border_mode=\'same\', subsample=(2, 2),\n                          input_shape=(1, 28, 28)))\n    cnn.add(LeakyReLU())\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Convolution2D(64, 3, 3, border_mode=\'same\', subsample=(1, 1)))\n    cnn.add(LeakyReLU())\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Convolution2D(128, 3, 3, border_mode=\'same\', subsample=(2, 2)))\n    cnn.add(LeakyReLU())\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Convolution2D(256, 3, 3, border_mode=\'same\', subsample=(1, 1)))\n    cnn.add(LeakyReLU())\n    cnn.add(Dropout(0.3))\n\n    cnn.add(Flatten())\n\n    image = Input(shape=(1, 28, 28))\n\n    features = cnn(image)\n\n    # first output (name=generation) is whether or not the discriminator\n    # thinks the image that is being shown is fake, and the second output\n    # (name=auxiliary) is the class that the discriminator thinks the image\n    # belongs to.\n    fake = Dense(1, activation=\'sigmoid\', name=\'generation\')(features)\n    aux = Dense(10, activation=\'softmax\', name=\'auxiliary\')(features)\n\n    return Model(input=image, output=[fake, aux])\n\nif __name__ == \'__main__\':\n\n    # batch and latent size taken from the paper\n    nb_epochs = 50\n    batch_size = 100\n    latent_size = 100\n\n    # Adam parameters suggested in https://arxiv.org/abs/1511.06434\n    adam_lr = 0.0002\n    adam_beta_1 = 0.5\n\n    # build the discriminator\n    discriminator = build_discriminator()\n    discriminator.compile(\n        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n        loss=[\'binary_crossentropy\', \'sparse_categorical_crossentropy\']\n    )\n\n    # build the generator\n    generator = build_generator(latent_size)\n    generator.compile(optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n                      loss=\'binary_crossentropy\')\n\n    latent = Input(shape=(latent_size, ))\n    image_class = Input(shape=(1,), dtype=\'int32\')\n\n    # get a fake image\n    fake = generator([latent, image_class])\n\n    # we only want to be able to train generation for the combined model\n    discriminator.trainable = False\n    fake, aux = discriminator(fake)\n    combined = Model(input=[latent, image_class], output=[fake, aux])\n\n    combined.compile(\n        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n        loss=[\'binary_crossentropy\', \'sparse_categorical_crossentropy\']\n    )\n\n    # get our mnist data, and force it to be of shape (..., 1, 28, 28) with\n    # range [-1, 1]\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n    X_train = np.expand_dims(X_train, axis=1)\n\n    X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n    X_test = np.expand_dims(X_test, axis=1)\n\n    nb_train, nb_test = X_train.shape[0], X_test.shape[0]\n\n    train_history = defaultdict(list)\n    test_history = defaultdict(list)\n\n    for epoch in range(nb_epochs):\n        print(\'Epoch {} of {}\'.format(epoch + 1, nb_epochs))\n\n        nb_batches = int(X_train.shape[0] / batch_size)\n        progress_bar = Progbar(target=nb_batches)\n\n        epoch_gen_loss = []\n        epoch_disc_loss = []\n\n        for index in range(nb_batches):\n            progress_bar.update(index)\n            # generate a new batch of noise\n            noise = np.random.uniform(-1, 1, (batch_size, latent_size))\n\n            # get a batch of real images\n            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n            label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n\n            # sample some labels from p_c\n            sampled_labels = np.random.randint(0, 10, batch_size)\n\n            # generate a batch of fake images, using the generated labels as a\n            # conditioner. We reshape the sampled labels to be\n            # (batch_size, 1) so that we can feed them into the embedding\n            # layer as a length one sequence\n            generated_images = generator.predict(\n                [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n\n            X = np.concatenate((image_batch, generated_images))\n            y = np.array([1] * batch_size + [0] * batch_size)\n            aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n\n            # see if the discriminator can figure itself out...\n            epoch_disc_loss.append(discriminator.train_on_batch(X, [y, aux_y]))\n\n            # make new noise. we generate 2 * batch size here such that we have\n            # the generator optimize over an identical number of images as the\n            # discriminator\n            noise = np.random.uniform(-1, 1, (2 * batch_size, latent_size))\n            sampled_labels = np.random.randint(0, 10, 2 * batch_size)\n\n            # we want to train the genrator to trick the discriminator\n            # For the generator, we want all the {fake, not-fake} labels to say\n            # not-fake\n            trick = np.ones(2 * batch_size)\n\n            epoch_gen_loss.append(combined.train_on_batch(\n                [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n\n        print(\'\\nTesting for epoch {}:\'.format(epoch + 1))\n\n        # evaluate the testing loss here\n\n        # generate a new batch of noise\n        noise = np.random.uniform(-1, 1, (nb_test, latent_size))\n\n        # sample some labels from p_c and generate images from them\n        sampled_labels = np.random.randint(0, 10, nb_test)\n        generated_images = generator.predict(\n            [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n\n        X = np.concatenate((X_test, generated_images))\n        y = np.array([1] * nb_test + [0] * nb_test)\n        aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n\n        # see if the discriminator can figure itself out...\n        discriminator_test_loss = discriminator.evaluate(\n            X, [y, aux_y], verbose=False)\n\n        discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n\n        # make new noise\n        noise = np.random.uniform(-1, 1, (2 * nb_test, latent_size))\n        sampled_labels = np.random.randint(0, 10, 2 * nb_test)\n\n        trick = np.ones(2 * nb_test)\n\n        generator_test_loss = combined.evaluate(\n            [noise, sampled_labels.reshape((-1, 1))],\n            [trick, sampled_labels], verbose=False)\n\n        generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n\n        # generate an epoch report on performance\n        train_history[\'generator\'].append(generator_train_loss)\n        train_history[\'discriminator\'].append(discriminator_train_loss)\n\n        test_history[\'generator\'].append(generator_test_loss)\n        test_history[\'discriminator\'].append(discriminator_test_loss)\n\n        print(\'{0:<22s} | {1:4s} | {2:15s} | {3:5s}\'.format(\n            \'component\', *discriminator.metrics_names))\n        print(\'-\' * 65)\n\n        ROW_FMT = \'{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}\'\n        print(ROW_FMT.format(\'generator (train)\',\n                             *train_history[\'generator\'][-1]))\n        print(ROW_FMT.format(\'generator (test)\',\n                             *test_history[\'generator\'][-1]))\n        print(ROW_FMT.format(\'discriminator (train)\',\n                             *train_history[\'discriminator\'][-1]))\n        print(ROW_FMT.format(\'discriminator (test)\',\n                             *test_history[\'discriminator\'][-1]))\n\n        # save weights every epoch\n        generator.save_weights(\n            \'params_generator_epoch_{0:03d}.hdf5\'.format(epoch), True)\n        discriminator.save_weights(\n            \'params_discriminator_epoch_{0:03d}.hdf5\'.format(epoch), True)\n\n        # generate some digits to display\n        noise = np.random.uniform(-1, 1, (100, latent_size))\n\n        sampled_labels = np.array([\n            [i] * 10 for i in range(10)\n        ]).reshape(-1, 1)\n\n        # get a batch to display\n        generated_images = generator.predict(\n            [noise, sampled_labels], verbose=0)\n\n        # arrange them into a grid\n        img = (np.concatenate([r.reshape(-1, 28)\n                               for r in np.split(generated_images, 10)\n                               ], axis=-1) * 127.5 + 127.5).astype(np.uint8)\n\n        Image.fromarray(img).save(\n            \'plot_epoch_{0:03d}_generated.png\'.format(epoch))\n\n    pickle.dump({\'train\': train_history, \'test\': test_history},\n                open(\'acgan-history.pkl\', \'wb\'))\n'"
