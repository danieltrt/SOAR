file_path,api_count,code
src/charger_poids.py,12,"b'from config import path\nimport tensorflow as tf\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\ndef W(number_conv):\n    # Charger weights from the pre-trained in COCO\n    import h5py\n    with h5py.File(path + \'/yolo3/model/yolov3.h5\', \'r\') as f:\n        name = \'conv2d_\' + str(number_conv)\n        w = f[\'model_weights\'][name][name][\'kernel:0\']\n        weights = tf.cast(w, tf.float32)\n    return weights\n\n\ndef B(number_conv):\n    # Charger biases, bat_norm from the pre-trained in COCO\n    import h5py\n    with h5py.File(path + \'/yolo3/model/yolov3.h5\', \'r\') as f:\n        if (number_conv == 59) or (number_conv == 67) or (number_conv == 75):\n            name = \'conv2d_\' + str(number_conv)\n            b = f[\'model_weights\'][name][name][\'bias:0\']\n            biases = tf.cast(b, tf.float32)\n            return biases\n        else:\n            if 68 <= number_conv <= 74:\n                name = \'batch_normalization_\' + str(number_conv-2)\n                if number_conv==74:\n                    print(""Finir de charger les poids!"")\n            elif 66 >= number_conv >= 60:\n                name = \'batch_normalization_\' + str(number_conv - 1)\n            elif 0 < number_conv <= 58:\n                name = \'batch_normalization_\' + str(number_conv)\n            beta = f[\'model_weights\'][name][name][\'beta:0\']\n            beta = tf.cast(beta, tf.float32)\n\n            gamma = f[\'model_weights\'][name][name][\'gamma:0\']\n            gamma = tf.cast(gamma, tf.float32)\n\n            moving_mean = f[\'model_weights\'][name][name][\'moving_mean:0\']\n            moving_mean = tf.cast(moving_mean, tf.float32)\n\n            moving_variance = f[\'model_weights\'][name][name][\'moving_variance:0\']\n            moving_variance = tf.cast(moving_variance, tf.float32)\n\n            return moving_mean, moving_variance, beta, gamma\n""""""\nwith tf.Session() as sess:\n\n    a,b,c,d = B(74)\n    print(sess.run((a)))\n    print(sess.run(tf.shape(a)))\n    print(sess.run((b)))\n    print(sess.run(tf.shape(b)))\n    print(sess.run(c))\n    print(sess.run(tf.shape(c)))\n    # w = W(75)\n    # print(sess.run(w))\n    # print(sess.run(tf.shape(w)))\n    # d = B(75)\n    # print(sess.run(d))\n    # print(sess.run(tf.shape(d)))\n    sess.close()\n""""""'"
src/config.py,0,"b""# CONFIGURE\n# change the path to your project\npath = '/home/minh/PycharmProjects'\n# image pr\xc3\xa9-processing\nInput_shape = 416  # width=height # 608 or 416 or 320\nchannels = 3  # RBG\nangle = 0\nsaturation = 1.5\nexposure = 1.5\nhue = 0.1\njitter = 0.3\nrandom = 1\n\n# training\n# score = 0.3\n# iou = 0.7\n\n# batch_size = 32\nthreshold = 0.3\nignore_thresh = 0.5\ntruth_thresh = 1\nmomentum = 0.9\ndecay = 0.0005\nlearning_rate = 0.001\nburn_in = 1000\nmax_batches = 500200\n\n# policy=steps\nlearning_rate_steps = [40000, 45000]  # steps=400000,450000\nlearning_rate_scales = [0.1, 0.1]  # scales=.1,.1\nanchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n# num = 9 #9 anchors per grille celle\nNumClasses = 80\n\n\n"""
src/detect_function.py,64,"b'# Inf\xc3\xa9rence\nimport tensorflow as tf\n\nfrom config import Input_shape, threshold, ignore_thresh\n\n\ndef yolo_head(feature_maps, anchors, num_classes, input_shape, calc_loss=False):\n    """"""\n    Convert final layer features to bounding box parameters.\n    (Features learned by the convolutional layers ---> a classifier/regressor which makes the detection prediction)\n    :param feature_maps: the feature maps learned by the convolutional layers\n                         3 scale [None, 13, 13, 255] from yolov3 structure anchors:[116, 90], [156, 198], [373, 326]\n                                 [None, 26, 26, 255]                               [30, 61], [62, 45], [59, 119]\n                                 [None, 52, 52, 255]                               [10, 13], [16, 30], [33, 23]\n    :param anchors: 3 anchors for each scale shape=(3,2)\n    :param num_classes: 80 for COCO\n    :param input_shape: 416,416\n    :return: box_xy  [None, 13, 13, 3, 2], 2: x,y center point of BB\n             box_wh  [None, 13, 13, 3, 2], 2: w,h\n             box_conf  [None, 13, 13, 3, 1], 1: conf\n             box_class_pred  [None, 13, 13, 3, 80], 80: prob of each class\n    """"""\n    num_anchors = len(anchors)  # 3\n    # Reshape to batch, height, width, num_anchors, box_params\n    anchors_tensor = tf.cast(anchors, dtype=feature_maps.dtype)\n    anchors_tensor = tf.reshape(anchors_tensor, [1, 1, 1, num_anchors, 2])  # shape=[1,1,1,3,2]\n\n    # CREATE A GRID FOR EACH SCALE\n    with tf.name_scope(\'Create_GRID\'):\n        grid_shape = tf.shape(feature_maps)[1:3]  # height, width ---> grid 13x13 for scale1\n        #         (0,0) (1,0) ...                                      grid 26x26 for scale2\n        #         (0,1) (1,1) ...                                      grid 52x52 for scale3\n        #          ...\n        # In YOLO the height index is the inner most iteration.\n        grid_y = tf.range(0, grid_shape[0])  # array([0,1,...,11,12])\n        grid_x = tf.range(0, grid_shape[1])\n        grid_y = tf.reshape(grid_y, [-1, 1, 1, 1])  # shape=([13,  1,  1,  1])\n        grid_x = tf.reshape(grid_x, [1, -1, 1, 1])  # [1, 13, 1, 1]\n        grid_y = tf.tile(grid_y, [1, grid_shape[1], 1, 1])  # [13, 1, 1, 1] ---> [13, 13, 1, 1]\n        grid_x = tf.tile(grid_x, [grid_shape[0], 1, 1, 1])  # [1, 13, 1, 1] ---> [13, 13, 1, 1]\n        grid = tf.concat([grid_x, grid_y], axis=-1)  # shape=[13, 13,  1,  2]\n        grid = tf.cast(grid, dtype=feature_maps.dtype)  # change type\n\n    # Reshape [None, 13, 13, 255] =>[None, 13, 13, 3, 85]\n    feature_maps_reshape = tf.reshape(feature_maps, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n\n    with tf.name_scope(\'top_feature_maps\'):\n        # top of feature maps is a activation function\n        """"""softmax is used for the multi-class logistic regression: ouput fall into [-1,1] ---> sum(all classes) = 1\n        # sigmoid for the the 2-class logistic regression: output fall into [0,1] ---> sum(all classes) >1\n        # for the relative width and weight, use the exponential function""""""\n        box_xy = tf.sigmoid(feature_maps_reshape[..., :2], name=\'x_y\')  # [None, 13, 13, 3, 2]\n        tf.summary.histogram(box_xy.op.name + \'/activations\', box_xy)\n        box_wh = tf.exp(feature_maps_reshape[..., 2:4], name=\'w_h\')  # [None, 13, 13, 3, 2]\n        tf.summary.histogram(box_wh.op.name + \'/activations\', box_wh)\n        box_confidence = tf.sigmoid(feature_maps_reshape[..., 4:5], name=\'confidence\')  # [None, 13, 13, 3, 1]\n        tf.summary.histogram(box_confidence.op.name + \'/activations\', box_confidence)\n        box_class_probs = tf.sigmoid(feature_maps_reshape[..., 5:], name=\'class_probs\')  # [None, 13, 13, 3, 80]\n        tf.summary.histogram(box_class_probs.op.name + \'/activations\', box_class_probs)\n        # Adjust predictions to each spatial grid point and anchor size.\n        # Note: YOLO iterates over height index before width index.\n        box_xy = (box_xy + grid) / tf.cast(grid_shape[::-1],  # (x,y + grid)/13. ---> in between (0., 1.)\n                                           dtype=feature_maps_reshape.dtype)  # [None, 13, 13, 3, 2]\n        box_wh = box_wh * anchors_tensor / tf.cast(input_shape[::-1],  # following to the scale\n                                                   dtype=feature_maps_reshape.dtype)  # [None, 13, 13, 3, 2]\n\n    if calc_loss == True:\n        return grid, feature_maps_reshape, box_xy, box_wh\n    return box_xy, box_wh, box_confidence, box_class_probs\n\ndef yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n    """"""\n    Convert YOLO box predictions to bounding box corners.(get corrected boxes)\n    :param box_xy: (None, 13, 13, 3, 2) is box_x,y output of yolo_head()\n    :param box_wh: (None, 13, 13, 3, 2) is box_w,h output of yolo_head()\n    :param input_shape: 416,416\n    :param image_shape: shape of input image (normal: height, width) . tf.placeholder(shape=(2, ))\n    :return: box(2 corners) in original image shape (BB corresponding to h and w of image)\n                        : 1 (y_min,x_min) left bottom corner\n                          1 (y_max,x_max) right top corner\n                    ---> (..., (y_min,x_min,y_max,x_max)) (None, 13, 13, 3, 4)\n    """"""\n    # Note: YOLO iterates over height index before width index.\n    # batch_size = 3 #tf.shape(image_shape)[0]\n    box_yx = box_xy[..., ::-1]  # (None, 13, 13, 3, 2) => ex: , x,y --> y,x\n    box_hw = box_wh[..., ::-1]  # (None, 13, 13, 3, 2) w,h--->h,w\n    input_shape = tf.cast(input_shape, dtype=box_yx.dtype)  # ex: (416,416)\n    # input_shape = tf.constant(Input_shape, shape=[batch_size, 2], dtype=box_yx.dtype)\n    image_shape = tf.cast(image_shape, dtype=box_yx.dtype)  # ex: (720, 1028)\n\n    with tf.name_scope(\'resize_to_scale_correspond\'):\n        """"""un image (640, 480) to scale1 (stride 32)(13x13)\n        ---> new shape = (13, 10)""""""\n        constant = (input_shape / image_shape)\n        # constant = tf.reshape((input_shape / image_shape), shape=[batch_size, 2])  # 416/640, 416/480\n        # min=[]\n        min = tf.minimum(constant[0], constant[1])\n        # for i in range(batch_size):\n        #     #i+=1\n        #     x = tf.minimum(constant[i][0], constant[i][1])\n        #     min.append(x)\n            #min = tf.concat([min, x], axis=0 )\n        # min = tf.stack(min)\n        # min = tf.reshape(min, shape=[batch_size, 1])\n        # min = (min.append(tf.minimum(constant[i][0], constant[i][1])) for i in range(batch_size))\n        # min = tf.cast([min[0], min[1], min[2]], dtype=constant.dtype)\n        # min = tf.reshape(min, shape=[batch_size, 2])\n\n        new_shape = image_shape * min  # 640*(416/640), 480*(416/640)\n        new_shape = tf.round(new_shape)  # lam tron ---> (416, 312)\n\n    offset = (input_shape - new_shape) / (input_shape*2.)  # 0,  (416-312)/2/416=0.125\n    scale = input_shape / new_shape  # (1, 416/312)\n\n    with tf.name_scope(\'return_corners_box\'):\n        # box in scale\n        box_yx = (box_yx - offset) * scale  # (x-0)*1, (y-0.125)*416/312\n        box_hw *= scale  # h*1, w*1.333\n        box_mins = box_yx - (box_hw / 2.)  # (x-0)*1-h*1/2 = y_min, (y-0.125)*(416/312)-w*(416/312)/2 = x_min\n        box_maxes = box_yx + (box_hw / 2.)  # (x-0)*1+h*1/2 = y_max, (y-0.125)*(416/312)+w*(416/312)/2 = x_max\n        boxes = tf.concat([box_mins[..., 0:1],  # y_min\n                           box_mins[..., 1:2],  # x_min\n                           box_maxes[..., 0:1],  # y_max\n                           box_maxes[..., 1:2]],  # x_max\n                          axis=-1, name=\'box_in_scale\')\n        # Scale boxes back to original image shape,\n        # y_min*height = 720*(x-0)*1-720*h*1/2\n        # x_min*width,\n        # y_max*height,\n        # x_max*width\n        boxes = tf.multiply(boxes,\n                            tf.concat([image_shape, image_shape], axis=-1), name=\'box_in_original_image_shape\')\n    return boxes\n\n\ndef yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n    """"""\n    Process Conv layer output\n    :param feats: [None, 13, 13, 255] is output of build_networks() (from network_function scripts)\n    :param anchors: for yolo_head()\n    :param num_classes: for yolo_head(), 80 for COCO\n    :param input_shape: see yolo_head(), yolo_correct_boxes()\n    :param image_shape: tensor targets for filtered bounding boxes. tf.placeholder(shape=(2, ))\n    :return: boxes: [None*13*13*3, 4], predicted BBs with 4: cordoning of one BB (y_min,x_min, y_max,x_max)\n             box_scores: [None*13*13*3, 80], 80: score= confidence * class_probability\n    """"""\n    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats, anchors, num_classes, input_shape)\n    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape,\n                               image_shape)  # shape = (None, 13, 13, 3, 4), 4:(y_min,x_min,y_max,x_max)\n    boxes = tf.reshape(boxes, [-1, 4], name=\'boxes\')  # shape = (None*13*13*3, 4)\n\n    with tf.name_scope(\'box_scores\'):\n        box_scores = box_confidence * box_class_probs  # (..., 1) * (..., 80) ---> (None, 13, 13, 3, 80)\n        box_scores = tf.reshape(box_scores, [-1, num_classes])  # (None*13*13*3, 80)\n\n    return boxes, box_scores\n\n\ndef predict(yolo_outputs, anchors, num_classes, image_shape, max_boxes=20, score_threshold=threshold, iou_threshold=ignore_thresh):\n    """"""\n    Evaluate YOLO model on given input and return filtered boxes\n    :param yolo_outputs:\n    :param anchors: [9,2]\n    :param num_classes:\n    :param image_shape: see yolo_boxes_and_scores()\n    :param max_boxes: a scalar integer who present the maximum number of boxes to be selected by non max suppression\n    :param score_threshold: score_threshold=.6\n    :param iou_threshold: iou_threshold=.5\n    :return:\n    """"""\n    # input_shape = tf.shape(yolo_outputs[0])[1:3] * 32  # scale1 13*32=416 [416,416]\n    boxes = []\n    box_scores = []\n    input_shape = (Input_shape, Input_shape)\n    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n\n    for mask in range(3):  # 3 scale\n        name = \'predict\' + str(mask+1)\n        with tf.name_scope(name):\n            _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[mask],\n                                                        anchors[anchor_mask[mask]],\n                                                        num_classes,\n                                                        input_shape,\n                                                        image_shape)\n\n            boxes.append(_boxes)  # list(3 array): [3, None*13*13*3, 4]\n            box_scores.append(_box_scores)  # list(3 array): [3, None*13*13*3, 80]\n\n    boxes = tf.concat(boxes, axis=0)  # [3 *None*13*13*3, 4]\n    box_scores = tf.concat(box_scores, axis=0)  # [3 *None*13*13*3, 80]\n\n    mask = box_scores >= score_threshold  # False & True in [3*None*13*13*3, 80] based on box_scores\n    # maximum number of boxes to be selected by non max suppression\n    max_boxes_tensor = tf.constant(max_boxes, dtype=\'int32\', name=\'max_boxes\')\n\n    boxes_ = []\n    scores_ = []\n    classes_ = []\n\n    for Class in range(num_classes):\n        # name = \'Class\'+str(Class)\n        # with tf.name_scope(name):\n        class_boxes = tf.boolean_mask(boxes, mask[:, Class])  # obj:[3 *None*13*13*3, 4], mask:[3 *None*13*13*3, 1] ---> [..., 4], each class: keep boxes who have (box_scores >= score_threshold)\n        class_box_scores = tf.boolean_mask(box_scores[:, Class], mask[:, Class])  # [..., 1]\n\n        nms_index = tf.image.non_max_suppression(class_boxes,  # [num_box(True), 4]\n                                                 class_box_scores,  # [num_box(True), 1]\n                                                 max_boxes_tensor,  # 20\n                                                 iou_threshold=iou_threshold,\n                                                 name=\'non_max_suppression\')  # return an integer tensor of indices has the shape [M], M <= 20\n        class_boxes = tf.gather(class_boxes,\n                                nms_index, name=\'TopLeft_BottomRight\')  # Take the elements of indices (nms_index) in the class_boxes. [M, 4]\n        class_box_scores = tf.gather(class_box_scores, nms_index, name=\'Box_score\')  # [M, 1]\n        with tf.name_scope(\'Class_prob\'):\n            classes = tf.ones_like(class_box_scores, \'int32\') * Class  # [M, 1]\n        boxes_.append(class_boxes)\n        scores_.append(class_box_scores)\n        classes_.append(classes)\n\n    boxes_ = tf.concat(boxes_, axis=0, name=\'TopLeft_BottomRight\')  # [N, 4] with N: number of objects\n    scores_ = tf.concat(scores_, axis=0)  # [N,]\n    classes_ = tf.concat(classes_, axis=0)  # [N,]\n\n    return boxes_, scores_, classes_\n\n\n'"
src/loss_function.py,14,"b'# Fonction de co\xc3\xbbt\nimport keras.backend as K\nimport tensorflow as tf\nfrom config import ignore_thresh\n\nfrom detect_function import yolo_head\n\n\ndef compute_loss(yolo_outputs, y_true, anchors, num_classes, ignore_thresh=ignore_thresh, print_loss=False):\n    """"""\n        Return yolo_loss tensor\n    :param YOLO_outputs: list of 3 sortie of yolo_neural_network, ko phai cua predict (N, 13, 13, 3*14)\n    :param Y_true: list(3 array) [(N,13,13,3,85), (N,26,26,3,85), (N,52,52,3,14)]\n    :param anchors: array, shape=(T, 2), wh\n    :param num_classes: 80\n    :param ignore_thresh:float, the iou threshold whether to ignore object confidence loss\n    :return: loss\n    """"""\n    # yolo_outputs = YOLO_outputs\n    # y_true = Y_true  # output of preprocess_true_boxes [3, None, 13, 13, 3, 2]\n    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n\n\n    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(3)]\n    loss = 0\n    m = K.shape(yolo_outputs[0])[0]  # batch size, tensor\n    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n\n    for l in range(3):\n        object_mask = y_true[l][..., 4:5]\n        true_class_probs = y_true[l][..., 5:]\n\n        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n                                                     anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n        pred_box = K.concatenate([pred_xy, pred_wh])\n\n        # Darknet raw box to calculate loss.\n        raw_true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid\n        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh))  # avoid log(0)=-inf\n        box_loss_scale = 2 - y_true[l][..., 2:3] * y_true[l][..., 3:4]\n\n        # Find ignore mask, iterate over each of batch.\n        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n        object_mask_bool = K.cast(object_mask, \'bool\')\n\n        def loop_body(b, ignore_mask):\n            true_box = tf.boolean_mask(y_true[l][b, ..., 0:4], object_mask_bool[b, ..., 0])\n            iou = box_IoU(pred_box[b], true_box)\n            best_iou = K.max(iou, axis=-1)\n            ignore_mask = ignore_mask.write(b, K.cast(best_iou < ignore_thresh, K.dtype(true_box)))\n            return b + 1, ignore_mask\n\n        _, ignore_mask = K.control_flow_ops.while_loop(lambda b, *args: b < m, loop_body, [0, ignore_mask])\n        ignore_mask = ignore_mask.stack()\n        ignore_mask = K.expand_dims(ignore_mask, -1)\n\n        # K.binary_crossentropy is helpful to avoid exp overflow.\n        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[..., 0:2],\n                                                                       from_logits=True)\n        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh - raw_pred[..., 2:4])\n        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True) + \\\n                          (1 - object_mask) * K.binary_crossentropy(object_mask, raw_pred[..., 4:5],\n                                                                    from_logits=True) * ignore_mask\n        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[..., 5:], from_logits=True)\n\n        xy_loss = K.sum(xy_loss) / mf\n        wh_loss = K.sum(wh_loss) / mf\n        confidence_loss = K.sum(confidence_loss) / mf\n        class_loss = K.sum(class_loss) / mf\n        loss += xy_loss + wh_loss + confidence_loss + class_loss\n        if print_loss:\n            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)],\n                            message=\'loss: \')\n    return loss\n\ndef box_IoU(b1, b2):\n    """"""\n    Calculer IoU between 2 BBs\n    # hoi bi nguoc han tinh left bottom, right top TODO\n    :param b1: predicted box, shape=[None, 13, 13, 3, 4], 4: xywh\n    :param b2: true box, shape=[None, 13, 13, 3, 4], 4: xywh\n    :return: iou: intersection of 2 BBs, tensor, shape=[None, 13, 13, 3, 1] ,1: IoU\n    b = tf.cast(b, dtype=tf.float32)\n    """"""\n    with tf.name_scope(\'BB1\'):\n        """"""Calculate 2 corners: {left bottom, right top} and area of this box""""""\n        b1 = tf.expand_dims(b1, -2)  # shape= (None, 13, 13, 3, 1, 4)\n        b1_xy = b1[..., :2]  # x,y shape=(None, 13, 13, 3, 1, 2)\n        b1_wh = b1[..., 2:4]  # w,h shape=(None, 13, 13, 3, 1, 2)\n        b1_wh_half = b1_wh / 2.  # w/2, h/2 shape= (None, 13, 13, 3, 1, 2)\n        b1_mins = b1_xy - b1_wh_half  # x,y: left bottom corner of BB\n        b1_maxes = b1_xy + b1_wh_half  # x,y: right top corner of BB\n        b1_area = b1_wh[..., 0] * b1_wh[..., 1]  # w1 * h1 (None, 13, 13, 3, 1)\n\n    with tf.name_scope(\'BB2\'):\n        """"""Calculate 2 corners: {left bottom, right top} and area of this box""""""\n        # b2 = tf.expand_dims(b2, -2)  # shape= (None, 13, 13, 3, 1, 4)\n        b2 = tf.expand_dims(b2, 0)  # shape= (1, None, 13, 13, 3, 4)  # TODO 0?\n        b2_xy = b2[..., :2]  # x,y shape=(None, 13, 13, 3, 1, 2)\n        b2_wh = b2[..., 2:4]  # w,h shape=(None, 13, 13, 3, 1, 2)\n        b2_wh_half = b2_wh / 2.  # w/2, h/2 shape=(None, 13, 13, 3, 1, 2)\n        b2_mins = b2_xy - b2_wh_half  # x,y: left bottom corner of BB\n        b2_maxes = b2_xy + b2_wh_half  # x,y: right top corner of BB\n        b2_area = b2_wh[..., 0] * b2_wh[..., 1]  # w2 * h2\n\n    with tf.name_scope(\'Intersection\'):\n        """"""Calculate 2 corners: {left bottom, right top} based on BB1, BB2 and area of this box""""""\n        # intersect_mins = tf.maximum(b1_mins, b2_mins, name=\'left_bottom\')  # (None, 13, 13, 3, 1, 2)\n        intersect_mins = K.maximum(b1_mins, b2_mins)  # (None, 13, 13, 3, 1, 2)\n        # intersect_maxes = tf.minimum(b1_maxes, b2_maxes, name=\'right_top\')  #\n        intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n        # intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)  # (None, 13, 13, 3, 1, 2), 2: w,h\n        intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]  # intersection: wi * hi (None, 13, 13, 3, 1)\n\n    IoU = tf.divide(intersect_area, (b1_area + b2_area - intersect_area), name=\'divise-IoU\')  # (None, 13, 13, 3, 1)\n\n    return IoU\n\n\n\n'"
src/network_function.py,51,"b'# MODEL_NETWORK\nfrom charger_poids import W, B\nimport tensorflow as tf\nimport numpy as np\nnp.random.seed(101)\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0,1""\n\n\nclass YOLOv3(object):\n    """"""Structure of reseau neural YOLO3""""""\n\n    # def __init__(self, x, num_classes, trainable=True, strategie_training=False, is_training=False):\n    def __init__(self, x, num_classes, trainable=True):\n        """"""\n        Create the graph ofthe YOLOv3 model\n        :param x: Placeholder for the input tensor: (normalised image (416, 416, 3)/255.)\n        :param num_classes: Number of classes in the dataset\n               if it isn\'t in the same folder as this code\n        """"""\n        self.X = x\n        self.NUM_CLASSES = num_classes\n        self.is_training=trainable\n        # self.is_training=is_training\n        # self.ST = False\n        # if strategie_training==1:\n        #     self.ST = True\n\n    def feature_extractor(self):\n        """"""\n        Create the network graph\n        :return: feature maps 5+80 in 3 grid (13,13), (26,26), (52, 52)\n        """"""\n        print(""YOLOv3, let\'s go!!!!!!!"")\n        with tf.name_scope(""Features""):\n            conv_1 = self.conv2d(self.X, 1)\n            # Downsample#############################################\n            conv_2 = self.conv2d(conv_1, 2, stride=2)\n\n            conv_3 = self.conv2d(conv_2, 3)\n            conv_4 = self.conv2d(conv_3, 4)\n            resn_1 = self.resnet(conv_2, conv_4, 1)\n            # Downsample#############################################\n            conv_5 = self.conv2d(resn_1, 5, stride=2)\n\n            conv_6 = self.conv2d(conv_5, 6)\n            conv_7 = self.conv2d(conv_6, 7)\n            resn_2 = self.resnet(conv_5, conv_7, 2)\n\n            conv_8 = self.conv2d(resn_2, 8)\n            conv_9 = self.conv2d(conv_8, 9)\n            resn_3 = self.resnet(resn_2, conv_9, 3)\n            # Downsample#############################################\n            conv_10 = self.conv2d(resn_3, 10, stride=2)\n\n            conv_11 = self.conv2d(conv_10, 11)\n            conv_12 = self.conv2d(conv_11, 12)\n            resn_4 = self.resnet(conv_10, conv_12, 4)\n\n            conv_13 = self.conv2d(resn_4, 13)\n            conv_14 = self.conv2d(conv_13, 14)\n            resn_5 = self.resnet(resn_4, conv_14, 5)\n\n            conv_15 = self.conv2d(resn_5, 15)\n            conv_16 = self.conv2d(conv_15, 16)\n            resn_6 = self.resnet(resn_5, conv_16, 6)\n\n            conv_17 = self.conv2d(resn_6, 17)\n            conv_18 = self.conv2d(conv_17, 18)\n            resn_7 = self.resnet(resn_6, conv_18, 7)\n\n            conv_19 = self.conv2d(resn_7, 19)\n            conv_20 = self.conv2d(conv_19, 20)\n            resn_8 = self.resnet(resn_7, conv_20, 8)\n\n            conv_21 = self.conv2d(resn_8, 21)\n            conv_22 = self.conv2d(conv_21, 22)\n            resn_9 = self.resnet(resn_8, conv_22, 9)\n\n            conv_23 = self.conv2d(resn_9, 23)\n            conv_24 = self.conv2d(conv_23, 24)\n            resn_10 = self.resnet(resn_9, conv_24, 10)\n\n            conv_25 = self.conv2d(resn_10, 25)\n            conv_26 = self.conv2d(conv_25, 26)\n            resn_11 = self.resnet(resn_10, conv_26, 11)\n            # Downsample#############################################\n            conv_27 = self.conv2d(resn_11, 27, stride=2)\n\n            conv_28 = self.conv2d(conv_27, 28)\n            conv_29 = self.conv2d(conv_28, 29)\n            resn_12 = self.resnet(conv_27, conv_29, 12)\n\n            conv_30 = self.conv2d(resn_12, 30)\n            conv_31 = self.conv2d(conv_30, 31)\n            resn_13 = self.resnet(resn_12, conv_31, 13)\n\n            conv_32 = self.conv2d(resn_13, 32)\n            conv_33 = self.conv2d(conv_32, 33)\n            resn_14 = self.resnet(resn_13, conv_33, 14)\n\n            conv_34 = self.conv2d(resn_14, 34)\n            conv_35 = self.conv2d(conv_34, 35)\n            resn_15 = self.resnet(resn_14, conv_35, 15)\n\n            conv_36 = self.conv2d(resn_15, 36)\n            conv_37 = self.conv2d(conv_36, 37)\n            resn_16 = self.resnet(resn_15, conv_37, 16)\n\n            conv_38 = self.conv2d(resn_16, 38)\n            conv_39 = self.conv2d(conv_38, 39)\n            resn_17 = self.resnet(resn_16, conv_39, 17)\n\n            conv_40 = self.conv2d(resn_17, 40)\n            conv_41 = self.conv2d(conv_40, 41)\n            resn_18 = self.resnet(resn_17, conv_41, 18)\n\n            conv_42 = self.conv2d(resn_18, 42)\n            conv_43 = self.conv2d(conv_42, 43)\n            resn_19 = self.resnet(resn_18, conv_43, 19)\n            # Downsample##############################################\n            conv_44 = self.conv2d(resn_19, 44, stride=2)\n\n            conv_45 = self.conv2d(conv_44, 45)\n            conv_46 = self.conv2d(conv_45, 46)\n            resn_20 = self.resnet(conv_44, conv_46, 20)\n\n            conv_47 = self.conv2d(resn_20, 47)\n            conv_48 = self.conv2d(conv_47, 48)\n            resn_21 = self.resnet(resn_20, conv_48, 21)\n\n            conv_49 = self.conv2d(resn_21, 49)\n            conv_50 = self.conv2d(conv_49, 50)\n            resn_22 = self.resnet(resn_21, conv_50, 22)\n\n            conv_51 = self.conv2d(resn_22, 51)\n            conv_52 = self.conv2d(conv_51, 52)\n            resn_23 = self.resnet(resn_22, conv_52, 23)  # [None, 13,13,1024]\n            ##########################################################\n        with tf.name_scope(\'SCALE\'):\n            with tf.name_scope(\'scale_1\'):\n                conv_53 = self.conv2d(resn_23, 53)\n                conv_54 = self.conv2d(conv_53, 54)\n                conv_55 = self.conv2d(conv_54, 55)  # [None,14,14,512]\n                conv_56 = self.conv2d(conv_55, 56)\n                conv_57 = self.conv2d(conv_56, 57)\n                conv_58 = self.conv2d(conv_57, 58)  # [None,13 ,13,1024]\n                conv_59 = self.conv2d(conv_58, 59, batch_norm_and_activation=False, trainable=self.is_training)\n                # [yolo layer] 6,7,8 # 82  --->predict    scale:1, stride:32, detecting large objects => mask: 6,7,8\n                # 13x13x255, 255=3*(80+1+4)\n            with tf.name_scope(\'scale_2\'):\n                route_1 = self.route1(conv_57, name=""route_1"")\n                conv_60 = self.conv2d(route_1, 60)\n                upsam_1 = self.upsample(conv_60, 2, name=""upsample_1"")\n                route_2 = self.route2(upsam_1, resn_19, name=""route_2"")\n                conv_61 = self.conv2d(route_2, 61)\n                conv_62 = self.conv2d(conv_61, 62)\n                conv_63 = self.conv2d(conv_62, 63)\n                conv_64 = self.conv2d(conv_63, 64)\n                conv_65 = self.conv2d(conv_64, 65)\n                conv_66 = self.conv2d(conv_65, 66)\n                conv_67 = self.conv2d(conv_66, 67, batch_norm_and_activation=False, trainable=self.is_training)\n                # [yolo layer] 3,4,5 # 94  --->predict   scale:2, stride:16, detecting medium objects => mask: 3,4,5\n                # 26x26x255, 255=3*(80+1+4)\n            with tf.name_scope(\'scale_3\'):\n                route_3 = self.route1(conv_65, name=""route_3"")\n                conv_68 = self.conv2d(route_3, 68)\n                upsam_2 = self.upsample(conv_68, 2, name=""upsample_2"")\n                route_4 = self.route2(upsam_2, resn_11, name=""route_4"")\n                conv_69 = self.conv2d(route_4, 69)\n                conv_70 = self.conv2d(conv_69, 70)\n                conv_71 = self.conv2d(conv_70, 71)\n                conv_72 = self.conv2d(conv_71, 72)\n                conv_73 = self.conv2d(conv_72, 73)\n                conv_74 = self.conv2d(conv_73, 74)\n                conv_75 = self.conv2d(conv_74, 75, batch_norm_and_activation=False, trainable=self.is_training)\n                # [yolo layer] 0,1,2 # 106 --predict scale:3, stride:8, detecting the smaller objects => mask: 0,1,2\n                # 52x52x255, 255=3*(80+1+4)\n                # Bounding Box:  YOLOv2: 13x13x5\n                #                YOLOv3: 13x13x3x3, 3 for each scale\n\n        return conv_59, conv_67, conv_75\n\n    def conv2d(self, inputs, idx, stride=1, batch_norm_and_activation=True, trainable=False, phase_train=False):\n        """"""\n        Convolutional layer\n        :param inputs:\n        :param idx: conv number\n        :param stride:\n        :param name:\n        :param batch_norm_and_activation:\n        :return:\n        """"""\n        name_conv = \'conv_\' + str(idx)\n        name_w = \'weights\' + str(idx)\n        name_b = \'biases\' + str(idx)\n        name_mean = \'moving_mean\' + str(idx)\n        name_vari = \'moving_variance\' + str(idx)\n        name_beta = \'beta\' + str(idx)\n        name_gam = \'gamma\' + str(idx)\n        # tous = True\n        tous = False\n        # tous = self.ST\n        with tf.variable_scope(name_conv):\n            if trainable == True:\n                # we will initialize weights by a Gaussian distribution with mean 0 and variance 1/sqrt(n)\n                # don\'t set all = 0 or =\n                if idx == 59:\n                    # weights = tf.Variable(\n                    #     tf.random_normal(shape=[1, 1, 1024, 3 * (self.NUM_CLASSES + 1 + 4)], mean=0.0, stddev=0.01), trainable=True,\n                    #     dtype=tf.float32, name=""weights"")\n                    weights = tf.Variable(\n                        np.random.normal(size=[1, 1, 1024, 3 * (self.NUM_CLASSES + 1 + 4)], loc=0.0, scale=0.01), trainable=True,\n                        dtype=np.float32, name=""weights"")\n                elif idx == 67:\n                    weights = tf.Variable(\n                        np.random.normal(size=[1, 1, 512, 3 * (self.NUM_CLASSES + 1 + 4)], loc=0.0, scale=0.01),\n                        trainable=True,\n                        dtype=np.float32, name=""weights"")\n                else:\n                    weights = tf.Variable(\n                        np.random.normal(size=[1, 1, 256, 3 * (self.NUM_CLASSES + 1 + 4)], loc=0.0, scale=0.01),\n                        trainable=True,\n                        dtype=np.float32, name=""weights"")\n            else:\n                weights = tf.Variable(W(idx), trainable=tous, dtype=tf.float32, name=""weights"")\n            tf.summary.histogram(name_w, weights)  # add summary\n\n            if stride == 2:\n                paddings = tf.constant([[0, 0], [1, 0], [1, 0], [0, 0]])\n                inputs_pad = tf.pad(inputs, paddings, ""CONSTANT"")\n                conv = tf.nn.conv2d(inputs_pad, weights, strides=[1, stride, stride, 1], padding=\'VALID\', name=""nn_conv"")\n            else:\n                conv = tf.nn.conv2d(inputs, weights, strides=[1, stride, stride, 1], padding=\'SAME\', name=""conv"")\n\n            if batch_norm_and_activation:  # TODO\n                # conv_1 ---> conv_75 EXCEPT conv_59, conv_67, conv_75\n                with tf.variable_scope(\'BatchNorm\'):\n                    variance_epsilon = tf.constant(0.0001, name=""epsilon"")  # small float number to avoid dividing by 0\n\n                    # batch_mean, batch_var = tf.nn.moments(inputs, [0, 1, 2], name=\'moments\')\n                    # ema = tf.train.ExponentialMovingAverage(decay=0.5)\n                    #\n                    # def mean_var_with_update():\n                    #     ema_apply_op = ema.apply([batch_mean, batch_var])\n                    #     with tf.control_dependencies([ema_apply_op]):\n                    #         return tf.identity(batch_mean), tf.identity(batch_var)\n                    #\n                    # mean, var = tf.cond(self.is_training,\n                    #                     mean_var_with_update,\n                    #                     lambda: (ema.average(batch_mean), ema.average(batch_var)))\n\n                    moving_mean, moving_variance, beta, gamma = B(idx)\n                    moving_mean = tf.Variable(moving_mean, trainable=tous, dtype=tf.float32, name=""moving_mean"")\n                    tf.summary.histogram(name_mean, moving_mean)  # add summary\n                    moving_variance = tf.Variable(moving_variance, trainable=tous, dtype=tf.float32, name=""moving_variance"")\n                    tf.summary.histogram(name_vari, moving_variance)  # add summary\n                    beta = tf.Variable(beta, trainable=tous, dtype=tf.float32, name=""beta"")\n                    tf.summary.histogram(name_beta, beta)  # add summary\n                    gamma = tf.Variable(gamma, trainable=tous, dtype=tf.float32, name=""gamma"")\n                    tf.summary.histogram(name_gam, gamma)  # add summary\n                    # conv = tf.nn.batch_normalization(conv, moving_mean, moving_variance, beta, gamma,\n                    #                                 variance_epsilon, name=\'BatchNorm\')\n                    # conv = tf.nn.batch_normalization(conv, mean, var, beta, gamma,\n                    #                                  variance_epsilon, name=\'BatchNorm\')\n                    conv = tf.layers.batch_normalization(moving_mean_initializer=moving_mean, moving_variance_initializer=moving_variance,\n                                                         beta_initializer=beta, gamma_initializer=gamma, training=self.is_training)\n                with tf.name_scope(\'Activation\'):\n                    alpha = tf.constant(0.1, name=""alpha"")  # Slope of the activation function at x < 0\n                    acti = tf.maximum(alpha * conv, conv)\n                return acti\n\n            else:\n                # for conv_59, conv67, conv_75\n                if trainable == True:\n                    # biases may be  init =0\n                    biases = tf.Variable(\n                        np.random.normal(size=[3 * (self.NUM_CLASSES + 1 + 4), ], loc=0.0, scale=0.01),\n                        trainable=True,\n                        dtype=np.float32, name=""biases"")\n                else:\n                    biases = tf.Variable(B(idx), trainable=False, dtype=tf.float32, name=""biases"")\n                tf.summary.histogram(name_b, biases)  # add summary\n                conv = tf.add(conv, biases)\n                return conv\n\n    @staticmethod\n    def route1(inputs, name):\n        """"""\n        :param inputs: [5, 500, 416, 3]\n        :param name: name in graph\n        :return: output = input [5, 500, 416, 3]\n        """"""\n        # [route]-4\n        with tf.name_scope(name):\n            output = inputs\n            return output\n\n    @staticmethod\n    def route2(input1, input2, name):\n        """"""\n        :param input1: [5, 500, 416, 3]\n        :param input2: [5, 500, 416, 32]\n        :param name: name in graph\n        :return: concatenate{input1, input2} [5, 500, 416, 3+32]\n                 (n\xe1\xbb\x91i l\xe1\xba\xa1i)\n        """"""\n        # [route]-1, 36\n        # [route]-1, 61\n        with tf.name_scope(name):\n            output = tf.concat([input1, input2], -1, name=\'concatenate\')  # input1:-1, input2: 61\n            return output\n\n    @staticmethod\n    def upsample(inputs, size, name):\n        """"""\n        :param inputs: (5, 416, 416, 3) par ex\n        :param size: 2 par ex\n        :param name: name in graph\n        :return: Resize images to size using nearest neighbor interpolation. (5, 832, 832, 3) par ex\n        """"""\n        with tf.name_scope(name):\n            w = tf.shape(inputs)[1]  # 416\n            h = tf.shape(inputs)[2]  # 416\n            output = tf.image.resize_nearest_neighbor(inputs, [size * w, size * h])\n            return output\n\n    @staticmethod\n    def resnet(a, b, idx):\n        """"""\n        :param a: [5, 500, 416, 32]\n        :param b: [5, 500, 416, 32]\n        :param name: name in graph\n        :return: a+b [5, 500, 416, 32]\n        """"""\n        name_res = \'resn\' + str(idx)\n        with tf.name_scope(name_res):\n            resn = a + b\n            return resn\n\n\n'"
src/propagation.py,9,"b'# from argparse import ArgumentParser\nfrom PIL import Image, ImageFont, ImageDraw\nfrom config import Input_shape, channels, threshold, ignore_thresh, path\nfrom network_function import YOLOv3\nfrom detect_function import predict\nfrom utils.yolo_utils import read_anchors, read_classes, letterbox_image  # , resize_image\nfrom timeit import default_timer as timer  # to calculate FPS\nfrom pathlib import Path\nimport numpy as np\nimport tensorflow as tf\nimport argparse\nimport colorsys\nimport random\nimport sys\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n# from tensorflow.python.client import device_lib\n# print(device_lib.list_local_devices())\n\nclass YOLO(object):\n    def __init__(self):\n\n        self.anchors_path = path + \'/yolo3/model/yolo_anchors.txt\'\n        self.COCO = False\n        self.trainable = False\n\n        args1 = sys.argv[2]\n        if args1==\'COCO\':\n            print(""-----------COCO-----------"")\n            self.COCO = True\n            self.classes_path = path + \'/yolo3/model/coco_classes.txt\'\n            self.trainable = False\n        elif args1==\'VOC\':\n            print(""-----------VOC------------"")\n            self.classes_path = path + \'/yolo3/model/voc_classes.txt\'\n        elif args1==\'boat\':\n            print(""-----------boat-----------"")\n            self.classes_path = path + \'/yolo3/model/boat_classes.txt\'\n\n        # args = self.argument()\n        # if args.COCO:\n        #     print(""-----------COCO-----------"")\n        #     self.COCO = True\n        #     self.classes_path = self.PATH + \'/model/coco_classes.txt\'\n        #     self.trainable = False\n        # elif args.VOC:\n        #     print(""-----------VOC------------"")\n        #     self.classes_path = self.PATH + \'/model/voc_classes.txt\'\n        # elif args.boat:\n        #     print(""-----------boat-----------"")\n        #     self.classes_path = self.PATH + \'/model/boat_classes.txt\'\n\n        self.class_names = read_classes(self.classes_path)\n        self.anchors = read_anchors(self.anchors_path)\n        self.threshold = 0.5# threshold\n        self.ignore_thresh = ignore_thresh\n        self.INPUT_SIZE = (Input_shape, Input_shape)  # fixed size or (None, None)\n        self.is_fixed_size = self.INPUT_SIZE != (None, None)\n        # LOADING SESSION...\n        self.boxes, self.scores, self.classes, self.sess = self.load()\n\n    @staticmethod\n    def argument():\n        parser = argparse.ArgumentParser(description=\'COCO or VOC or boat\')\n        parser.add_argument(\'--COCO\', action=\'store_true\', help=\'COCO flag\')\n        parser.add_argument(\'--VOC\', action=\'store_true\', help=\'VOC flag\')\n        parser.add_argument(\'--boat\', action=\'store_true\', help=\'boat flag\')\n        args = parser.parse_args()\n        return args\n    def load(self):\n        # Remove nodes from graph or reset entire default graph\n        tf.reset_default_graph()\n\n        # Generate colors for drawing bounding boxes.\n        hsv_tuples = [(x / len(self.class_names), 1., 1.) for x in range(len(self.class_names))]\n        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n        self.colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), self.colors))\n        random.seed(10101)  # Fixed seed for consistent colors across runs.\n        random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n        random.seed(None)  # Reset seed to default.\n\n        # Generate output tensor targets for filtered bounding boxes.\n        self.x = tf.placeholder(tf.float32, shape=[None, Input_shape, Input_shape, channels])\n        self.image_shape = tf.placeholder(tf.float32, shape=[2, ])\n        # self.is_training = tf.placeholder(tf.bool)\n        # image_shape = np.array([image.size[0], image.size[1]])  # tf.placeholder(tf.float32, shape=[2,])\n\n        # Generate output tensor targets for filtered bounding boxes.\n        # scale1, scale2, scale3 = YOLOv3(self.x, len(self.class_names), trainable=self.trainable, is_training=self.is_training).feature_extractor()\n        scale1, scale2, scale3 = YOLOv3(self.x, len(self.class_names), trainable=self.trainable).feature_extractor()\n        scale_total = [scale1, scale2, scale3]\n\n        # detect\n        boxes, scores, classes = predict(scale_total, self.anchors, len(self.class_names), self.image_shape,\n                                         score_threshold=self.threshold, iou_threshold=self.ignore_thresh)\n\n        # Add ops to save and restore all the variables\n        saver = tf.train.Saver(var_list=None if self.COCO==True else tf.trainable_variables())\n\n        # Allowing GPU memory growth\n\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        sess = tf.Session(config = config)\n        sess.run(tf.global_variables_initializer())\n        epoch = input(\'Entrer a check point at epoch:\')\n        # For the case of COCO\n        epoch = epoch if self.COCO == False else 2000\n        checkpoint = path + ""/yolo3/save_model/SAVER_MODEL_boat10/model.ckpt-"" + str(epoch)\n        try:\n            aaa = checkpoint + \'.meta\'\n            my_abs_path = Path(aaa).resolve()\n        except FileNotFoundError:\n            print(""Not yet training!"")\n        else:\n            saver.restore(sess, checkpoint)\n            print(""checkpoint: "", checkpoint)\n            print(""already training!"")\n\n        return boxes, scores, classes, sess\n\n    def detect_image(self, image):\n        # Generate colors for drawing bounding boxes.\n        hsv_tuples = [(x / len(self.class_names), 1., 1.) for x in range(len(self.class_names))]\n        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n        self.colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), self.colors))\n        random.seed(10101)  # Fixed seed for consistent colors across runs.\n        random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n        random.seed(None)  # Reset seed to default.\n\n        if self.is_fixed_size:\n            assert self.INPUT_SIZE[0] % 32 == 0, \'Multiples of 32 required\'\n            assert self.INPUT_SIZE[1] % 32 == 0, \'Multiples of 32 required\'\n            boxed_image, image_shape = letterbox_image(image, tuple(reversed(self.INPUT_SIZE)))\n            # boxed_image, image_shape = resize_image(image, tuple(reversed(self.INPUT_SIZE)))\n        else:\n            new_image_size = (image.width - (image.width % 32), image.height - (image.height % 32))\n            boxed_image, image_shape = letterbox_image(image, new_image_size)\n            # boxed_image, image_shape = resize_image(image, new_image_size)\n        image_data = np.array(boxed_image, dtype=\'float32\')\n\n        print(""heights, widths:"", image_shape)\n        image_data /= 255.\n        inputs = np.expand_dims(image_data, 0)  # Add batch dimension. #\n\n        out_boxes, out_scores, out_classes = self.sess.run([self.boxes, self.scores, self.classes],\n                                                           feed_dict={self.x: inputs,\n                                                                      self.image_shape: image_shape,\n                                                                      # self.is_training: False\n                                                                      })\n\n        print(\'Found {} boxes for {}\'.format(len(out_boxes), \'img\'))\n\n        # Visualisation#################################################################################################\n        font = ImageFont.truetype(font=path + \'/yolo3/model/font/FiraMono-Medium.otf\', size=np.floor(3e-2 * image.size[1] + 0.5).astype(np.int32))\n        thickness = (image.size[0] + image.size[1]) // 500  # do day cua BB\n\n        for i, c in reversed(list(enumerate(out_classes))):\n            predicted_class = self.class_names[c]\n            box = out_boxes[i]\n            score = out_scores[i]\n\n            label = \'{} {:.2f}\'.format(predicted_class, score)\n            draw = ImageDraw.Draw(image)\n            label_size = draw.textsize(label, font)\n\n            top, left, bottom, right = box  # y_min, x_min, y_max, x_max\n            top = max(0, np.floor(top + 0.5).astype(np.int32))\n            left = max(0, np.floor(left + 0.5).astype(np.int32))\n            bottom = min(image.size[1], np.floor(bottom + 0.5).astype(np.int32))\n            right = min(image.size[0], np.floor(right + 0.5).astype(np.int32))\n            print(label, (left, top), (right, bottom))  # (x_min, y_min), (x_max, y_max)\n\n            if top - label_size[1] >= 0:\n                text_origin = np.array([left, top - label_size[1]])\n            else:\n                text_origin = np.array([left, top + 1])\n\n            # My kingdom for a good redistributable image drawing library.\n            for j in range(thickness):\n                draw.rectangle([left + j, top + j, right - j, bottom - j], outline=self.colors[c])\n            draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=self.colors[c])\n            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n            del draw\n        return image\n\ndef detect_video(yolo, video_path=None, output_video=None):\n    import urllib.request as urllib\n    import cv2\n\n    fourcc = cv2.VideoWriter_fourcc(*\'XVID\')\n    fps = 20.0  # display fps frame per second\n    accum_time = 0\n    curr_fps = 0\n    prev_time = timer()\n    if video_path==\'stream\':\n        url = \'http://10.18.97.1:8080/shot.jpg\'\n        out = cv2.VideoWriter(output_video, fourcc, fps, (1280, 720))\n        while True:\n\n            # Use urllib to get the image and convert into a cv2 usable format\n            imgResp = urllib.urlopen(url)\n            imgNp = np.array(bytearray(imgResp.read()), dtype=np.uint8)\n            img = cv2.imdecode(imgNp, -1)\n            # print(np.shape(img))  # get w, h from here\n\n            image = Image.fromarray(img)\n            image = yolo.detect_image(image)\n            result = np.asarray(image)\n\n            curr_time = timer()\n            exec_time = curr_time - prev_time\n            prev_time = curr_time\n            accum_time = accum_time + exec_time\n            curr_fps = curr_fps + 1\n            if accum_time > 1:\n                accum_time = accum_time - 1\n                fps = ""FPS: "" + str(curr_fps)\n                curr_fps = 0\n            cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                        fontScale=0.50, color=(255, 0, 0), thickness=2)\n            # cv2.namedWindow(""result"", cv2.WINDOW_NORMAL)\n            cv2.imshow(""Result"", result)\n            out.write(result)\n\n            # To give the processor some less stress\n            # time.sleep(0.1)\n\n            if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n                break\n        out.release()\n        # Closes all the frames\n        cv2.destroyAllWindows()\n\n        yolo.sess.close()\n    else:\n        cap = cv2.VideoCapture(video_path)\n        if not cap.isOpened():\n            raise IOError(""Couldn\'t open webcam or video"")\n        # The size of the frames to write\n        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        out = cv2.VideoWriter(output_video, fourcc, fps, (w, h))\n        while True:\n            ret, frame = cap.read()\n            if ret==True:\n                image = Image.fromarray(frame)\n\n                image = yolo.detect_image(image)\n                result = np.asarray(image)\n\n                curr_time = timer()\n                exec_time = curr_time - prev_time\n                prev_time = curr_time\n                accum_time = accum_time + exec_time\n                curr_fps = curr_fps + 1\n                if accum_time > 1:\n                    accum_time = accum_time - 1\n                    fps = ""FPS: "" + str(curr_fps)\n                    curr_fps = 0\n                cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                            fontScale=0.50, color=(255, 0, 0), thickness=2)\n                cv2.namedWindow(""Result"", cv2.WINDOW_NORMAL)\n                cv2.imshow(""Result"", result)\n\n                out.write(result)\n\n                if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n                    break\n            else:\n                break\n        cap.release()\n        out.release()\n        # Closes all the frames\n        cv2.destroyAllWindows()\n\n        yolo.sess.close()\n\ndef detect_img(yolo, output=\'\'):\n    while True:\n        img = input(\'Input image filename:\')\n        try:\n            img = path + \'/yolo3\' + str(img)\n            image = Image.open(img)\n        except:\n            print(\'Open Error! Try again!\')\n            continue\n        else:\n            r_image = yolo.detect_image(image)\n            r_image.save(output)\n            r_image.show()\n\n    yolo.sess.close()\n\n\nif __name__ == \'__main__\':\n    choose = sys.argv[1]\n    if choose==\'image\':\n        output = sys.argv[3]\n        detect_img(YOLO(), output)\n    elif choose==\'video\':\n        video_path = sys.argv[3]\n        output = sys.argv[4]\n        detect_video(YOLO(), video_path, output)'"
src/train.py,35,"b'from config import Input_shape, channels, path\nfrom network_function import YOLOv3\n\nfrom loss_function import compute_loss\nfrom utils.yolo_utils import get_training_data, read_anchors, read_classes\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport argparse\nimport numpy as np\nimport tensorflow as tf\nimport time\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0,1""\n\nnp.random.seed(101)\n\n# Add argument\ndef argument():\n    parser = argparse.ArgumentParser(description=\'COCO or VOC or boat\')\n    parser.add_argument(\'--COCO\', action=\'store_true\', help=\'COCO flag\')\n    parser.add_argument(\'--VOC\', action=\'store_true\', help=\'VOC flag\')\n    parser.add_argument(\'--boat\', action=\'store_true\', help=\'boat flag\')\n    args = parser.parse_args()\n    return args\n# Get Data #############################################################################################################\nPATH = path + \'/yolo3\'\nclasses_paths = PATH + \'/model/boat_classes.txt\'\nclasses_data = read_classes(classes_paths)\nanchors_paths = PATH + \'/model/yolo_anchors.txt\'\nanchors = read_anchors(anchors_paths)\n\nannotation_path_train = PATH + \'/model/boat_train.txt\'\nannotation_path_valid = PATH + \'/model/boat_valid.txt\'\nannotation_path_test = PATH + \'/model/boat_test.txt\'\n\ndata_path_train = PATH + \'/model/boat_train.npz\'\ndata_path_valid = PATH + \'/model/boat_valid.npz\'\ndata_path_test = PATH + \'/model/boat_test.npz\'\nVOC = False\nargs = argument()\nif args.VOC == True:\n    VOC = True\n    classes_paths = PATH + \'/model/voc_classes.txt\'\n    classes_data = read_classes(classes_paths)\n    annotation_path_train = PATH + \'/model/voc_train.txt\'\n    annotation_path_valid = PATH + \'/model/voc_val.txt\'\n    # annotation_path_test = PATH + \'/model/voc_test.txt\'\n\n    data_path_train = PATH + \'/model/voc_train.npz\'\n    data_path_valid = PATH + \'/model/voc_valid.npz\'\n    # data_path_test = PATH + \'/model/voc_test.npz\'\n\n\n\ninput_shape = (Input_shape, Input_shape)  # multiple of 32\nx_train, box_data_train, image_shape_train, y_train = get_training_data(annotation_path_train, data_path_train,\n                                                                        input_shape, anchors, num_classes=len(classes_data), max_boxes=20, load_previous=True)\nx_valid, box_data_valid, image_shape_valid, y_valid = get_training_data(annotation_path_valid, data_path_valid,\n                                                                        input_shape, anchors, num_classes=len(classes_data), max_boxes=20, load_previous=True)\nx_test, box_data_test, image_shape_test, y_test = get_training_data(annotation_path_test, data_path_test,\n                                                                    input_shape, anchors, num_classes=len(classes_data), max_boxes=20, load_previous=True)\nnumber_image_train = np.shape(x_train)[0]\nprint(""number_image_train"", number_image_train)\nnumber_image_valid = np.shape(x_valid)[0]\nprint(""number_image_valid"", number_image_valid)\nnumber_image_test = np.shape(x_test)[0]\nprint(""number_image_test"", number_image_test)\n\n# import matplotlib.pyplot as plt\n#\n# plt.imshow(np.array(x_train[0]))\n# plt.show()\n# print(np.shape(y_train[0]))\n# print(np.shape(y_train[1]))\n# print(np.shape(y_train[2]))\n########################################################################################################################\n""""""\n# Clear the current graph in each run, to avoid variable duplication\n# tf.reset_default_graph()\n""""""\nprint(""Starting 1st session..."")\n# Explicitly create a Graph object\ngraph = tf.Graph()\nwith graph.as_default():\n    global_step = tf.Variable(0, name=\'global_step\', trainable=False)\n    # Start running operations on the Graph.\n    # STEP 1: Input data ###############################################################################################\n\n    X = tf.placeholder(tf.float32, shape=[None, Input_shape, Input_shape, channels], name=\'Input\')  # for image_data\n    with tf.name_scope(""Target""):\n        Y1 = tf.placeholder(tf.float32, shape=[None, Input_shape/32, Input_shape/32, 3, (5+len(classes_data))], name=\'target_S1\')\n        Y2 = tf.placeholder(tf.float32, shape=[None, Input_shape/16, Input_shape/16, 3, (5+len(classes_data))], name=\'target_S2\')\n        Y3 = tf.placeholder(tf.float32, shape=[None, Input_shape/8, Input_shape/8, 3, (5+len(classes_data))], name=\'target_S3\')\n        # Y = tf.placeholder(tf.float32, shape=[None, 100, 5])  # for box_data\n    # Reshape images for visualization\n    x_reshape = tf.reshape(X, [-1, Input_shape, Input_shape, 1])\n    tf.summary.image(""input"", x_reshape)\n    # STEP 2: Building the graph #######################################################################################\n    # Building the graph\n    # Generate output tensor targets for filtered bounding boxes.\n    scale1, scale2, scale3 = YOLOv3(X, len(classes_data)).feature_extractor()\n    scale_total = [scale1, scale2, scale3]\n\n    with tf.name_scope(""Loss_and_Detect""):\n        # Label\n        y_predict = [Y1, Y2, Y3]\n        # Calculate loss\n        loss = compute_loss(scale_total, y_predict, anchors, len(classes_data), print_loss=False)\n        # loss_print = compute_loss(scale_total, y_predict, anchors, len(classes_data), print_loss=False)\n        tf.summary.scalar(""Loss"", loss)\n    with tf.name_scope(""Optimizer""):\n        # optimizer\n        # for VOC: lr:0.0001, decay:0.0003 with RMSProOp after 60 epochs\n        # learning_rate = tf.placeholder(tf.float32, shape=[1], name=\'lr\')\n        decay = 0.0003\n        # optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n        optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss, global_step=global_step)\n        # optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, decay=decay).minimize(loss)\n        # optimizer = tf.train.MomentumOptimizer(learning_rate, 0.01).minimize(loss)\n    # STEP 3: Build the evaluation step ################################################################################\n    # with tf.name_scope(""Accuracy""):\n    #     # Model evaluation\n    #     accuracy = 1  #\n    # STEP 4: Merge all summaries for Tensorboard generation ###########################################################\n    # create a saver\n    # saver = tf.train.Saver(tf.global_variables())\n    # Returns all variables created with trainable=True\n    # saver = tf.train.Saver(var_list=tf.trainable_variables())\n    saver = tf.train.Saver()\n    # Build the summary operation based on the TF collection of Summaries\n    # summary_op = tf.summary.merge_all()\n\n    # STEP 5: Train the model, and write summaries #####################################################################\n    # The Graph to be launched (described above)\n    # config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True) #, gpu_options.allow_growth = False)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    # run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n    with tf.Session(config=config, graph=graph) as sess:\n        # Merges all summaries collected in the default graph\n        summary_op = tf.summary.merge_all()\n        # Summary Writers\n        # tensorboard --logdir=\'./graphs/\' --port 6005\n        if VOC==True:\n            train_summary_writer = tf.summary.FileWriter(PATH + \'/graphs_VOC1/train\', sess.graph)\n            validation_summary_writer = tf.summary.FileWriter(PATH + \'/graphs_VOC1/validation\', sess.graph)\n        else:\n            train_summary_writer = tf.summary.FileWriter(PATH + \'/graphs_boat10/train\', sess.graph)\n            validation_summary_writer = tf.summary.FileWriter(PATH + \'/graphs_boat10/validation\', sess.graph)\n        # summary_writer = tf.summary.FileWriter(\'./graphs\', sess.graph)\n        sess.run(tf.global_variables_initializer())\n        # If you want to continue training from check point\n        # checkpoint = ""/home/minh/PycharmProjects/yolo3/save_model/SAVER_MODEL_boatM/model.ckpt-"" + ""1""\n        # saver.restore(sess, checkpoint)\n        epochs = 50  #\n        batch_size = 32  # consider\n        best_loss_valid = 10e6\n        for epoch in range(epochs):\n            start_time = time.time()\n            # nbr_iteration = epochs * round((12-0)/batch_size)\n\n            ## Training#################################################################################################\n            mean_loss_train = []\n            #for (start, end) in (zip((range(0, number_image_train, (batch_size))), (range(batch_size, number_image_train+1, batch_size)))):\n            for start in (range(0, number_image_train, batch_size)):\n                end = start + batch_size\n                summary_train, loss_train, _ = sess.run([summary_op, loss, optimizer],\n                                                        feed_dict={X: (x_train[start:end]/255.),\n                                                                   Y1: y_train[0][start:end],\n                                                                   Y2: y_train[1][start:end],\n                                                                   Y3: y_train[2][start:end]})  # , options=run_options)\n                train_summary_writer.add_summary(summary_train, epoch)\n                # Flushes the event file to disk\n                train_summary_writer.flush()\n                # summary_writer.add_summary(summary_train, counter)\n                mean_loss_train.append(loss_train)\n                print(""(start: %s end: %s, \\tepoch: %s)\\tloss: %s "" %(start, end, epoch + 1, loss_train))\n\n            # summary_writer.add_summary(summary_train, global_step=epoch)\n            mean_loss_train = np.mean(mean_loss_train)\n            duration = time.time() - start_time\n            examples_per_sec = number_image_train / duration\n            sec_per_batch = float(duration)\n            # Validation ###############################################################################################\n            mean_loss_valid = []\n            for start in (range(0, number_image_valid, batch_size)):\n                end = start + batch_size\n                # Run summaries and measure accuracy on validation set\n                summary_valid, loss_valid = sess.run([summary_op, loss],\n                                                    feed_dict={X: (x_valid[start:end]/255.),\n                                                               Y1: y_valid[0][start:end],\n                                                               Y2: y_valid[1][start:end],\n                                                               Y3: y_valid[2][start:end]})  # ,options=run_options)\n                validation_summary_writer.add_summary(summary_valid, epoch)\n                # Flushes the event file to disk\n                validation_summary_writer.flush()\n                mean_loss_valid.append(loss_valid)\n            mean_loss_valid = np.mean(mean_loss_valid)\n            print(""epoch %s / %s \\ttrain_loss: %s,\\tvalid_loss: %s"" %(epoch+1, epochs, mean_loss_train, mean_loss_valid))\n\n            if best_loss_valid > mean_loss_valid:\n                best_loss_valid = mean_loss_valid\n                if VOC ==True:\n                    create_new_folder = PATH + ""/save_model/SAVER_MODEL_VOC1""\n                else:\n                    create_new_folder = PATH + ""/save_model/SAVER_MODEL_boat10""\n                try:\n                    os.mkdir(create_new_folder)\n                except OSError:\n                    pass\n                checkpoint_path = create_new_folder + ""/model.ckpt""\n                saver.save(sess, checkpoint_path, global_step=epoch)\n                print(""Model saved in file: %s"" % checkpoint_path)\n\n        print(""Tuning completed!"")\n\n        # Testing ######################################################################################################\n        # mean_loss_test = []\n        # for start in (range(0, 128, batch_size)):\n        #     end = start + batch_size\n        #     if end > number_image_train:\n        #         end = number_image_train\n        #     # Loss in test data set\n        #     summary_test, loss_test = sess.run([summary_op, loss],\n        #                                        feed_dict={X: (x_test[start:end]/255.),\n        #                                                   Y1: y_test[0][start:end],\n        #                                                   Y2: y_test[1][start:end],\n        #                                                   Y3: y_test[2][start:end]})\n        #     mean_loss_test.append(mean_loss_test)\n        #     # print(""Loss on test set: "", (loss_test))\n        # mean_loss_test = np.mean(mean_loss_test)\n        # print(""Mean loss in all of test set: "", mean_loss_test)\n        # summary_writer.flush()\n        train_summary_writer.close()\n        validation_summary_writer.close()\n        # summary_writer.close()\n\n\n\n'"
src/model/boat_annotation.py,0,"b'import json\nimport random\nimport time\nimport os\n\nstart = time.time()\nwd = os.getcwd()\n\ndef read_xywhi():\n    with open(\'vt_fullInterpolated.json\') as json_data:\n        d = json.load(json_data)\n        json_data.close()\n        bateau_class = read_classes(""boat_classes.txt"")\n        ################################################################################################################\n        with open(\'vt_fullInterpolated.json\') as json_data:\n            d = json.load(json_data)\n            json_data.close()\n            num = []\n            for i in range(len(d[\'frames\'])):\n                # print(type(d[\'frames\'][i][\'num\']))\n                num.append(d[\'frames\'][i][\'num\'])\n        number_image = len(d[\'frames\'])\n        number_of_trainset = round(number_image*0.7)\n        print(number_of_trainset)\n        number_of_valiset = round((number_image-number_of_trainset)*0.6)\n        print(number_of_valiset)\n        number_of_testset = number_image - number_of_trainset - number_of_valiset\n        print(number_of_testset)\n        train_num = random.sample(population=num, k=number_of_trainset)\n        num1 = list(set(num) - set(train_num))\n        valid_num = random.sample(population=num1, k=number_of_valiset)\n        num2 = list(set(num1) - set(valid_num))\n        test_num = random.sample(population=num2, k=number_of_testset)\n        ################################################################################################################\n        file_train = open(\'boat_train.txt\', \'w\')\n        file_valid = open(\'boat_valid.txt\', \'w\')\n        file_test = open(\'boat_test.txt\', \'w\')\n        for img in range(number_image):\n            image_name = \'0000000.ppm\'\n            c = list(image_name)\n            c[7 - len(str(img+1)):7] = str(img+1)\n            image_name = \'\'.join(c)\n            if len((d[\'frames\'])[img][\'annotations\']) == 0:\n                hihihi=1\n                #if d[\'frames\'][img][\'num\'] in train_num:\n                #    file_train.write(\'%s/dataset/%s\' %(wd, image_name))  # TODO save dataset in folder dataset\n                #    file_train.write(\'\\n\')\n                #elif d[\'frames\'][img][\'num\'] in valid_num:\n                #    file_valid.write(\'%s/dataset/%s\' % (wd, image_name))\n                #    file_valid.write(\'\\n\')\n                #elif d[\'frames\'][img][\'num\'] in test_num:\n                #    file_test.write(\'%s/dataset/%s\' % (wd, image_name))\n                #    file_test.write(\'\\n\')\n            else:\n                for obj in range(len((d[\'frames\'])[img][\'annotations\'])):\n                    id = d[\'frames\'][img][\'annotations\'][obj][\'id\']  # string\n                    type = read_idx(id)\n                    index = bateau_class.index(type)\n                    xmin = d[\'frames\'][img][\'annotations\'][obj][\'x\']  # int\n                    ymin = d[\'frames\'][img][\'annotations\'][obj][\'y\']\n                    w = d[\'frames\'][img][\'annotations\'][obj][\'width\']\n                    h = d[\'frames\'][img][\'annotations\'][obj][\'height\']\n                    xmax = xmin + w\n                    ymax = ymin + h\n                    if obj == 0:\n                        if d[\'frames\'][img][\'num\'] in train_num:\n                            file_train.write(\'%s/dataset/%s \' % (wd, image_name))\n                            file_train.write(str(xmin) + \',\' + str(ymin) + \',\' + str(xmax) + \',\' + str(ymax) + \',\' + str(index))\n                        elif d[\'frames\'][img][\'num\'] in valid_num:\n                            file_valid.write(\'%s/dataset/%s \' % (wd, image_name))\n                            file_valid.write(str(xmin) + \',\' + str(ymin) + \',\' + str(xmax) + \',\' + str(ymax) + \',\' + str(index))\n                        elif d[\'frames\'][img][\'num\'] in test_num:\n                            file_test.write(\'%s/dataset/%s \' % (wd, image_name))\n                            file_test.write(str(xmin) + \',\' + str(ymin) + \',\' + str(xmax) + \',\' + str(ymax) + \',\' + str(index))\n                    else:\n                        if d[\'frames\'][img][\'num\'] in train_num:\n                            file_train.write(\' \' + str(xmin) + \',\' + str(ymin) + \',\' + str(xmax) + \',\' + str(ymax) + \',\' + str(index))\n                        elif d[\'frames\'][img][\'num\'] in valid_num:\n                            file_valid.write(\' \' + str(xmin) + \',\' + str(ymin) + \',\' + str(xmax) + \',\' + str(ymax) + \',\' + str(index))\n                        elif d[\'frames\'][img][\'num\'] in test_num:\n                            file_test.write(\' \' + str(xmin) + \',\' + str(ymin) + \',\' + str(xmax) + \',\' + str(ymax) + \',\' + str(index))\n                if d[\'frames\'][img][\'num\'] in train_num:\n                    file_train.write(\'\\n\')\n                elif d[\'frames\'][img][\'num\'] in valid_num:\n                    file_valid.write(\'\\n\')\n                elif d[\'frames\'][img][\'num\'] in test_num:\n                    file_test.write(\'\\n\')\n        file_train.close()\n        file_valid.close()\n        file_test.close()\n\n\ndef read_idx(id):\n    with open(\'vt_boatstype.json\') as json_data:\n        d = json.load(json_data)\n        json_data.close()\n        id = str(id)\n        type = d[id][\'type\']\n    return type\n\n\ndef read_classes(classes_path):\n    with open(classes_path) as f:\n        class_names = f.readlines()\n    class_names = [c.strip() for c in class_names]\n    return class_names\n\nread_xywhi()\n\nprint(time.time()-start)\n\n\n'"
src/model/voc_annotation.py,0,"b'import xml.etree.ElementTree as ET\nfrom os import getcwd\n\nsets=[(\'2012\', \'train\'), (\'2012\', \'val\')]\n\nclasses = [""aeroplane"", ""bicycle"", ""bird"", ""boat"", ""bottle"", ""bus"", ""car"", ""cat"", ""chair"", ""cow"", ""diningtable"", ""dog"", ""horse"", ""motorbike"", ""person"", ""pottedplant"", ""sheep"", ""sofa"", ""train"", ""tvmonitor""]\n\n\ndef convert_annotation(year, image_id, list_file):\n    in_file = open(\'/home/minh/VT_MarinaCam/VOCdevkit/VOC%s/Annotations/%s.xml\'%(year, image_id))\n    tree=ET.parse(in_file)\n    root = tree.getroot()\n\n    for obj in root.iter(\'object\'):\n        difficult = obj.find(\'difficult\').text\n        cls = obj.find(\'name\').text\n        if cls not in classes or int(difficult)==1:\n            continue\n        cls_id = classes.index(cls)\n        xmlbox = obj.find(\'bndbox\')\n        b = (int(xmlbox.find(\'xmin\').text), int(xmlbox.find(\'ymin\').text), int(xmlbox.find(\'xmax\').text), int(xmlbox.find(\'ymax\').text))\n        list_file.write("" "" + "","".join([str(a) for a in b]) + \',\' + str(cls_id))\n\nwd = getcwd()\n\nfor year, image_set in sets:\n    image_ids = open(\'/home/minh/VT_MarinaCam/VOCdevkit/VOC%s/ImageSets/Main/%s.txt\'%(year, image_set)).read().strip().split()\n    list_file = open(\'./result/%s_%s.txt\'%(year, image_set), \'w\')\n    for image_id in image_ids:\n        list_file.write(\'/home/minh/VT_MarinaCam/VOCdevkit/VOC2012/JPEGImages/%s.jpg\' %(image_id))\n        convert_annotation(year, image_id, list_file)\n        list_file.write(\'\\n\')\n    list_file.close()\n\n'"
src/test_function/test_box_IoU.py,16,"b'import tensorflow as tf\nfrom detect_function import *\nfrom config import *\n# tf.enable_eager_execution()\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\nB1 = tf.constant([[[[3, 5, 3, 6]]]], dtype=tf.float32, name=\'box1\')\nB2 = tf.constant([[[[5, 6, 3, 6]]]], dtype=tf.float32, name=\'box2\')\nIoU = YOLOv3_detection(anchors[0:3], NumClasses).box_IoU(B1, B2)\nwriter = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    print(sess.run(IoU))\nwriter.close()\n""""""\ndef box_IoU(b1, b2):\n    with tf.name_scope(\'BB1\'):\n        b1 = tf.expand_dims(b1, -2)  # shape= (None, 13, 13, 3, 1, 4)\n        b1_xy = b1[..., :2]  # x,y shape=(None, 13, 13, 3, 1, 2)\n        b1_wh = b1[..., 2:4]  # w,h shape=(None, 13, 13, 3, 1, 2)\n        b1_wh_half = b1_wh / 2.  # w/2, h/2 shape= (None, 13, 13, 3, 1, 2)\n        b1_mins = b1_xy - b1_wh_half  # x,y: left bottom corner of BB\n        b1_maxes = b1_xy + b1_wh_half  # x,y: right top corner of BB\n        b1_area = b1_wh[..., 0] * b1_wh[..., 1]  # w1 * h1 (None, 13, 13, 3, 1)\n\n    with tf.name_scope(\'BB2\'):\n        # b2 = tf.expand_dims(b2, -2)  # shape= (None, 13, 13, 3, 1, 4)\n        b2 = tf.expand_dims(b2, 0)  # shape= (None, 13, 13, 3, 1, 4)\n        b2_xy = b2[..., :2]  # x,y shape=(None, 13, 13, 3, 1, 2)\n        b2_wh = b2[..., 2:4]  # w,h shape=(None, 13, 13, 3, 1, 2)\n        b2_wh_half = b2_wh / 2.  # w/2, h/2 shape=(None, 13, 13, 3, 1, 2)\n        b2_mins = b2_xy - b2_wh_half  # x,y: left bottom corner of BB\n        b2_maxes = b2_xy + b2_wh_half  # x,y: right top corner of BB\n        b2_area = b2_wh[..., 0] * b2_wh[..., 1]  # w2 * h2\n\n    with tf.name_scope(\'xy_2_corners_intersection\'):\n        intersect_mins = tf.maximum(b1_mins, b2_mins, name=\'left_bottom\')  # (None, 13, 13, 3, 1, 2)\n        intersect_maxes = tf.minimum(b1_maxes, b2_maxes, name=\'right_top\')  #\n        intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)  # (None, 13, 13, 3, 1, 2), 2: w,h\n        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]  # intersection: wi * hi (None, 13, 13, 3, 1)\n\n\n    IoU = tf.divide(intersect_area, (b1_area + b2_area - intersect_area), name=\'IoU\')  # (None, 13, 13, 3, 1)\n\n    return IoU\n""""""'"
src/test_function/test_grid.py,13,"b'import tensorflow as tf\nimport numpy as np\n#tf.enable_eager_execution()\n\n# CREATE A GRID FOR EACH SCALE\nname = \'Create_GRID\'\nwith tf.name_scope(name) as scope:\n\n    grid_shape = tf.constant([13, 13])  # height, width ---> grid 13x13 for scale1\n    #         (0,0) (1,0) ...   (12,0)                       grid 26x26 for scale2\n    #         (0,1) (1,1) ...   (12,1)                       grid 52x52 for scale3\n    #          ...              (12,12)\n    # In YOLO the height index is the inner most iteration.\n    grid_y = tf.range(0, grid_shape[0])  # array([0,1,...,11,12])\n    grid_x = tf.range(0, grid_shape[1])\n    grid_y = tf.reshape(grid_y, [-1, 1, 1, 1])  # shape=([13,  1,  1,  1])\n    grid_x = tf.reshape(grid_x, [1, -1, 1, 1])  # [1, 13, 1, 1]\n    grid_y = tf.tile(grid_y, [1, grid_shape[1], 1, 1])  # [13, 1, 1, 1] ---> [13, 13, 1, 1]\n    grid_x = tf.tile(grid_x, [grid_shape[0], 1, 1, 1])  # [1, 13, 1, 1] ---> [13, 13, 1, 1]\n    grid = tf.concat([grid_x, grid_y], axis=-1)  # shape=[13, 13,  1,  2]\n    grid = tf.cast(grid, dtype=tf.float32)  # change type\nwriter = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\nwith tf.Session() as sess:\n    print(sess.run(grid))\n    print(""hihihihihi"")\n    print(sess.run((grid[::-1])))\n\nwriter.close()\n'"
src/test_function/test_loss.py,31,"b'from utils.yolo_utils import get_training_data, read_anchors, read_classes\nfrom network_function import YOLOv3\nfrom loss_function import compute_loss\nfrom config import Input_shape, channels\nfrom datetime import datetime\n\nfrom pathlib import Path\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport argparse\nimport numpy as np\nimport tensorflow as tf\nimport time\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""1,0""\n\n# Add argument\ndef argument():\n    parser = argparse.ArgumentParser(description=\'COCO or VOC or boat\')\n    parser.add_argument(\'--COCO\', action=\'store_true\', help=\'COCO flag\')\n    parser.add_argument(\'--VOC\', action=\'store_true\', help=\'VOC flag\')\n    parser.add_argument(\'--boat\', action=\'store_true\', help=\'boat flag\')\n    args = parser.parse_args()\n    return args\n# Get Data #############################################################################################################\nclasses_paths = \'./model_data/boat_classes.txt\'\nclasses_data = read_classes(classes_paths)\nanchors_paths = \'./model_data/yolo_anchors.txt\'\nanchors = read_anchors(anchors_paths)\n\nannotation_path_train = \'./model_data/boat_train.txt\'\nannotation_path_valid = \'./model_data/boat_valid.txt\'\nannotation_path_test = \'./model_data/boat_test.txt\'\n\ndata_path_train = \'./model_data/boat_train.npz\'\ndata_path_valid = \'./model_data/boat_valid.npz\'\ndata_path_test = \'./model_data/boat_test.npz\'\nVOC = False\nargs = argument()\nif args.VOC == True:\n    VOC = True\n    classes_paths = \'./model_data/voc_classes.txt\'\n    classes_data = read_classes(classes_paths)\n    annotation_path_train = \'./model_data/voc_train.txt\'\n    annotation_path_valid = \'./model_data/voc_val.txt\'\n    # annotation_path_test = \'./model_data/voc_test.txt\'\n\n    data_path_train = \'./model_data/voc_train.npz\'\n    data_path_valid = \'./model_data/voc_valid.npz\'\n    # data_path_test = \'./model_data/voc_test.npz\'\n\n\n\ninput_shape = (Input_shape, Input_shape)  # multiple of 32\nx_train, box_data_train, image_shape_train, y_train = get_training_data(annotation_path_train, data_path_train,\n                                                                        input_shape, anchors, num_classes=len(classes_data), max_boxes=100, load_previous=True)\n\nnumber_image_train = np.shape(x_train)[0]\nprint(""number_image_train"", number_image_train)\nX_train = x_train[5:6]\nY_train = [y_train[0][5:6], y_train[1][5:6], y_train[2][5:6]]\n\n# print(np.shape(y_train[0]))\n# print(np.shape(y_train[1]))\n# print(np.shape(y_train[2]))\n########################################################################################################################\n""""""\n# Clear the current graph in each run, to avoid variable duplication\n# tf.reset_default_graph()\n""""""\nprint(""Starting 1st session..."")\n# Explicitly create a Graph object\ngraph = tf.Graph()\nwith graph.as_default():\n    global_step = tf.Variable(0, name=\'global_step\', trainable=False)\n    # Start running operations on the Graph.\n    # STEP 1: Input data ###############################################################################################\n    with tf.name_scope(""Input""):\n        X = tf.placeholder(tf.float32, shape=[None, Input_shape, Input_shape, channels], name=\'Input\')  # for image_data\n    with tf.name_scope(""Target""):\n        Y1 = tf.placeholder(tf.float32, shape=[None, Input_shape/32, Input_shape/32, 3, (5+len(classes_data))], name=\'target_S1\')\n        Y2 = tf.placeholder(tf.float32, shape=[None, Input_shape/16, Input_shape/16, 3, (5+len(classes_data))], name=\'target_S2\')\n        Y3 = tf.placeholder(tf.float32, shape=[None, Input_shape/8, Input_shape/8, 3, (5+len(classes_data))], name=\'target_S3\')\n        # Y = tf.placeholder(tf.float32, shape=[None, 100, 5])  # for box_data\n    # Reshape images for visualization\n    x_reshape = tf.reshape(X, [-1, Input_shape, Input_shape, 1])\n    tf.summary.image(""input"", x_reshape)\n    # STEP 2: Building the graph #######################################################################################\n    # Building the graph\n    # Generate output tensor targets for filtered bounding boxes.\n    scale1, scale2, scale3 = YOLOv3(X, len(classes_data), trainable=False).feature_extractor()\n    scale_total = [scale1, scale2, scale3]\n\n    with tf.name_scope(""Loss""):\n        # Label\n        y_predict = [Y1, Y2, Y3]\n        # Calculate loss\n        loss = compute_loss(scale_total, y_predict, anchors, len(classes_data), print_loss=True)\n        # loss_print = compute_loss(scale_total, y_predict, anchors, len(classes_data), print_loss=False)\n        tf.summary.scalar(""Loss"", loss)\n    with tf.name_scope(""Optimizer""):\n        # optimizer\n        # for VOC: lr:0.0001, decay:0.0003 with RMSProOp after 60 epochs\n        learning_rate = 0.0001\n        decay = 0.0003\n        # learning_rate = 0.0002\n        # decay = 0.0005\n        # optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n        # optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n        # optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, decay=decay).minimize(loss)\n        # optimizer = tf.train.MomentumOptimizer(learning_rate, 0.01).minimize(loss)\n    # STEP 3: Build the evaluation step ################################################################################\n    # with tf.name_scope(""Accuracy""):\n    #     # Model evaluation\n    #     accuracy = 1  #\n    # STEP 4: Merge all summaries for Tensorboard generation ###########################################################\n    # create a saver\n    # saver = tf.train.Saver(tf.global_variables())\n    # Returns all variables created with trainable=True\n    # saver = tf.train.Saver(var_list=tf.trainable_variables())\n    # saver = tf.train.Saver()\n    # Build the summary operation based on the TF collection of Summaries\n    # summary_op = tf.summary.merge_all()\n\n    # STEP 5: Train the model, and write summaries #####################################################################\n    # The Graph to be launched (described above)\n    # config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True) #, gpu_options.allow_growth = False)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = False\n    # run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n    with tf.Session(config=config, graph=graph) as sess:\n        # Merges all summaries collected in the default graph\n        summary_op = tf.summary.merge_all()\n        # Summary Writers\n        # tensorboard --logdir=\'./graphs/\' --port 6005\n        # summary_writer = tf.summary.FileWriter(\'./graphs\', sess.graph)\n        sess.run(tf.global_variables_initializer())\n        # If you want to continue training from check point\n        # checkpoint = ""/home/minh/PycharmProjects/yolo3/SAVER_MODEL_VOCK/model.ckpt-"" + ""3""\n        # saver.restore(sess, checkpoint)\n        epochs = 1#\n        batch_size = 1  # consider\n        best_loss_valid = 10e6\n        for epoch in range(epochs):\n            start_time = time.time()\n            # nbr_iteration = epochs * round((12-0)/batch_size)\n\n            ## Training#################################################################################################\n            mean_loss_train = []\n            #for (start, end) in (zip((range(0, number_image_train, (batch_size))), (range(batch_size, number_image_train+1, batch_size)))):\n            for start in (range(0, np.shape(X_train)[0], batch_size)):\n                end = start + batch_size\n                loss_train = sess.run([loss],\n                                      feed_dict={X: (X_train[start:end] / 255.),\n                                                 Y1: Y_train[0][start:end],\n                                                 Y2: Y_train[1][start:end],\n                                                 Y3: Y_train[2][start:end]})  # , options=run_options)\n                # train_summary_writer.add_summary(summary_train, epoch)\n                # Flushes the event file to disk\n                # train_summary_writer.flush()\n                # summary_writer.add_summary(summary_train, counter)\n                mean_loss_train.append(loss_train)\n                print(""(start: %s end: %s, \\tepoch: %s)\\tloss: %s "" %(start, end, epoch + 1, loss_train))\n\n            # summary_writer.add_summary(summary_train, global_step=epoch)\n            mean_loss_train = np.mean(mean_loss_train)\n            duration = time.time() - start_time\n            examples_per_sec = number_image_train / duration\n            sec_per_batch = float(duration)\n\n        print(""Tuning completed!"")\n\n        # Testing ######################################################################################################\n        # mean_loss_test = []\n        # for start in (range(0, 128, batch_size)):\n        #     end = start + batch_size\n        #     if end > number_image_train:\n        #         end = number_image_train\n        #     # Loss in test data set\n        #     summary_test, loss_test = sess.run([summary_op, loss],\n        #                                        feed_dict={X: (x_test[start:end]/255.),\n        #                                                   Y1: y_test[0][start:end],\n        #                                                   Y2: y_test[1][start:end],\n        #                                                   Y3: y_test[2][start:end]})\n        #     mean_loss_test.append(mean_loss_test)\n        #     # print(""Loss on test set: "", (loss_test))\n        # mean_loss_test = np.mean(mean_loss_test)\n        # print(""Mean loss in all of test set: "", mean_loss_test)\n        # summary_writer.flush()\n        # train_summary_writer.close()\n        # validation_summary_writer.close()\n        # summary_writer.close()\n'"
src/test_function/test_loss_keras.py,0,b''
src/test_function/test_network_function.py,43,"b'from network_function import *\nfrom detect_function import *\nfrom config import anchors\n# TEST BUILD NETWORK\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n\ndef test():\n    path = \'/home/minh/stage/model_data/car.jpg\'\n    width = 416\n    height = 416\n    image = (Image.open(path))\n    M = image\n    M = np.asarray(M)\n    print(""y: "", np.shape(M)[0])\n    print(""x: "", np.shape(M)[1])\n    inputs = image.resize((width, height), Image.NEAREST)\n    with tf.name_scope(\'image\'):\n        inputs = tf.expand_dims(inputs, axis=0)\n        inputs = tf.cast(inputs, dtype=tf.float32)\n\n    a, b, c = YOLOv3(inputs, 80).create()  # build_networks(inputs)\n    # a = YOLOv3(inputs, 80).create()\n    mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n    input_shape = (416, 416)\n    # x, y, z, d = yolo_head(a, anchors[mask[0]], 80, input_shape)\n\n    # x = tf.shape(a)\n    writer = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\n    # python network_function.py\n    # tensorboard --logdir=""./graphs"" --port 6006\n    # these log file is saved in graphs folder, can delete these older log file\n    # porte 6006 may be change\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        print(inputs)\n        a = sess.run(a)\n        # print(sess.run(tf.shape(a)))\n        # print(sess.run(a[0][6][6][:5]))\n        a = np.squeeze(a, axis=0)\n        print(sess.run(tf.shape(a)))\n        print(a)\n        # print(sess.run(tf.shape(x)))\n        fig = plt.figure()\n        for i in range(6):\n            x = a[..., i]\n            plt.subplot(2, 3, i + 1)\n\n            plt.imshow(x)\n        fig.suptitle(\'con_58\')\n        # fig.savefig(\'/home/minh/stage/image_graph/hihi/conv_58\')\n        plt.show()\n    writer.close()\n    sess.close()\n    return 0\n\n\ntest()\n\n\n""""""\n#TEST FUNCTION upsample()\ndef test_upsample():\n    inputs=tf.random_normal([5, 416, 488, 3], mean=1, stddev=4, seed = 1)\n    a=upsample(inputs,stride=2,name=""hihi"")\n    sess=tf.Session()\n    sess.run(tf.global_variables_initializer())\n    b=tf.shape(a)\n    x=sess.run(b)\n    c=tf.shape(inputs)\n    y=sess.run(c)\n    print(""input"", y) #input [  5 416 416   3]\n    print(""output"", x) #output [  5 832 832   3]\n    return 0\ntest_upsample()\n""""""\n\n""""""\n#TEST FUNCTION resnet()\ndef test_resn():\n    input1=tf.random_normal([5, 416, 416, 32], mean=1, stddev=4, seed = 1) #axis=-1 nen 5,500,416 phai giong nhau\n    input2=tf.random_normal([5, 416, 416, 32], mean=1, stddev=4, seed = 1)\n    a=resnet(input1,input2,name=""hihi"")\n    sess=tf.Session()\n    sess.run(tf.global_variables_initializer())\n    b=tf.shape(a)\n    x=sess.run(b)\n    c=tf.shape(input1)\n    y=sess.run(c)\n    d=tf.shape(input2)\n    z=sess.run(d)\n    print(""input1"", y) #input1 [  5 416 416  32]\n    print(""input2"", z) #input2 [  5 416 416  32]\n    print(""output"", x) #output [  5 416 416  32]\n    return 0\ntest_resn()\n""""""\n\n""""""\n#TEST FUNCTION route2\ndef test_route2():\n    input1=tf.random_normal([5, 500, 416, 3], mean=1, stddev=4, seed = 1) #axis=-1 nen 5,500,416 phai giong nhau\n    input2=tf.random_normal([5, 500, 416, 32], mean=1, stddev=4, seed = 1)\n    a=route2(input1,input2,name=""hihi"")\n    sess=tf.Session()\n    sess.run(tf.global_variables_initializer())\n    b=tf.shape(a)\n    x=sess.run(b)\n    c=tf.shape(input1)\n    y=sess.run(c)\n    d=tf.shape(input2)\n    z=sess.run(d)\n    print(""input1"", y) #input1 [  5 500 416   3]\n    print(""input2"", z) #input2 [  5 500 416  32]\n    print(""output"", x) #output [  5 500 416  35]\n    return 0\ntest_route2()\n""""""\n\n""""""\n#TEST FUNCTION conv2dlinear()\nimport matplotlib.pyplot as plt\nfrom PIL import Image\ndef test_conv2dlinear():\n    path = \'model_data/girl.png\'\n    witth = 416\n    height = 416\n    image = (Image.open(path))\n    inputs = image.resize((witth, height), Image.NEAREST)\n    inputs = tf.expand_dims(inputs, axis=0)\n    inputs = tf.cast(inputs, dtype=tf.float32)\n    #inputs=tf.random_normal([5, 13, 13, 1024], mean=1, stddev=4, seed = 1)\n    a=conv2dlinear(inputs, 3, 255, 1, 1, name=""hihi"")\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        a = sess.run(a)\n        print(sess.run(tf.shape(a)))\n        a = np.squeeze(a, axis=0)\n        a = a[..., 100]\n        plt.imshow(a)\n        plt.show()\n    return 0\ntest_conv2dlinear()\n""""""\n\n""""""\n#TEST FUNCTION conv2d()\ndef test_conv2d():\n    inputs=tf.random_normal([5, 416, 416, 3], mean=1, stddev=4, seed = 1)\n    a=conv2d(inputs,3,32,3,1,name=""hihi"")\n    sess=tf.Session()\n    sess.run(tf.global_variables_initializer())\n    b=tf.shape(a)\n    x=sess.run(b)\n    c=tf.shape(inputs)\n    y=sess.run(c)\n    print(""input"", y) #input [  5 416 416   3]\n    print(""output"", x) #output [  5 415 415  32]\n    return 0\ntest_conv2d()\n""""""\n\n""""""\ndef get_classes_names():\n    names = []\n    with open(\'coco_classes.txt\') as f:\n        for name in f.readlines():\n            name = name[:-1]\n            names.append(name)\n    return names\n    """"""\n\n""""""\ndef maxpool2d(self,input,size,stride,name):\n    with tf.name_scope(name):\n        output = tf.nn.max_pool(input, ksize=[1, size, size, 1], \\\n                strides=[1, stride, stride, 1], padding=\'SAME\',name=""pool"")\n\n        return output\n        """"""\n\n\n\n'"
src/test_function/test_predict.py,12,"b'from network_function import *\nfrom detect_function import *\nfrom config import anchors\n# TEST BUILD NETWORK\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n\ndef test():\n    input1 = tf.random_normal([1, 13, 13, 255], mean=1, stddev=4, seed=1)\n    input2 = tf.random_normal([1, 26, 26, 255], mean=1, stddev=4, seed=1)\n    input3 = tf.random_normal([1, 52, 52, 255], mean=1, stddev=4, seed=1)\n    input = [input1, input2, input3]\n    mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n    input_shape = np.array([416, 416])\n    image_shape = np.array([1028, 516])\n    a, b, c = predict(input, anchors, 80, image_shape)\n\n    # x = tf.shape(a)\n    writer = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\n    # python network_function.py\n    # tensorboard --logdir=""./graphs"" --port 6006\n    # these log file is saved in graphs folder, can delete these older log file\n    # porte 6006 may be change\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        print(sess.run(tf.shape(input1)))\n        print(sess.run(tf.shape(a)))\n        print(sess.run(tf.shape(b)))\n        print(sess.run(tf.shape(c)))\n        # print(sess.run(a[0][0][0][0][:]))\n    writer.close()\n    sess.close()\n    return 0\n\n\ntest()'"
src/test_function/test_total_to_predict.py,12,"b'from network_function import *\nfrom detect_function import *\nfrom config import anchors\n# TEST BUILD NETWORK\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\nfrom PIL import Image\n\n\ndef test():\n    path = \'/home/minh/stage/model_data/car.jpg\'\n    width = 416\n    height = 416\n    image = (Image.open(path))\n    M = image\n    M = np.asarray(M)\n    print(""y: "", np.shape(M)[0])\n    print(""x: "", np.shape(M)[1])\n    inputs = image.resize((width, height), Image.NEAREST)\n    with tf.name_scope(\'image\'):\n        inputs = tf.expand_dims(inputs, axis=0)\n        inputs = tf.cast(inputs, dtype=tf.float32)\n\n    a, b, c = YOLOv3(inputs, 80).create()\n\n    K = []\n    K.append(a)\n    K.append(b)\n    K.append(c)\n    anchors = np.array([[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]])\n    image_shape = tf.shape(M[..., 0])\n    x, y, z = predict(K, anchors, 80, image_shape)\n\n    writer = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\n    # python network_function.py\n    # tensorboard --logdir=""./graphs"" --port 6006\n    # these log file is saved in graphs folder, can delete these older log file\n    # porte 6006 may be change\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        print(inputs)\n        print((sess.run(tf.shape(x))))\n        a = sess.run(a)\n        # print(sess.run(tf.shape(a)))\n        # print(sess.run(a[0][6][6][:5]))\n        a = np.squeeze(a, axis=0)\n        print(sess.run(tf.shape(a)))\n        print(sess.run(x))\n        # print(sess.run(tf.shape(x)))\n        fig = plt.figure()\n        for i in range(6):\n            x = a[..., i]\n            plt.subplot(2, 3, i + 1)\n\n            plt.imshow(x)\n        fig.suptitle(\'con_58\')\n        # fig.savefig(\'/home/minh/stage/image_graph/hihi/conv_58\')\n        plt.show()\n    writer.close()\n\ntest()'"
src/test_function/test_yolo_boxes_and_scores.py,9,"b'from network_function import *\nfrom detect_function import *\nfrom config import anchors\n# TEST BUILD NETWORK\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n\ndef test():\n    input1 = tf.random_normal([1, 13, 13, 255], mean=1, stddev=4, seed=1)\n\n    mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n    input_shape = np.array([416, 416])\n    image_shape = np.array([1028, 516])\n    a, b = yolo_boxes_and_scores(input1, anchors[mask[0]], 80, input_shape, image_shape)\n\n    # x = tf.shape(a)\n    writer = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\n    # python network_function.py\n    # tensorboard --logdir=""./graphs"" --port 6006\n    # these log file is saved in graphs folder, can delete these older log file\n    # porte 6006 may be change\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        print(sess.run(tf.shape(input1)))\n        print(sess.run(tf.shape(a)))\n        print(sess.run(tf.shape(b)))\n        # print(sess.run(a[0][0][0][0][:]))\n    writer.close()\n    sess.close()\n    return 0\n\n\ntest()'"
src/test_function/test_yolo_correct_boxes.py,10,"b'from network_function import *\nfrom detect_function import *\nfrom config import anchors\n# TEST BUILD NETWORK\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n\ndef test():\n    box1 = tf.random_normal([1, 13, 13, 3, 2], mean=1, stddev=4, seed=1)\n    box2 = tf.random_normal([1, 13, 13, 3, 2], mean=1, stddev=4, seed=1)\n\n    mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n    input_shape = np.array([416, 416])\n    image_shape = np.array([1028, 516])\n    a = yolo_correct_boxes(box1, box2, input_shape, image_shape)\n\n    # x = tf.shape(a)\n    writer = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\n    # python network_function.py\n    # tensorboard --logdir=""./graphs"" --port 6006\n    # these log file is saved in graphs folder, can delete these older log file\n    # porte 6006 may be change\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        print(sess.run(tf.shape(box1)))\n        print(sess.run(tf.shape(box2)))\n        print(sess.run(tf.shape(a)))\n        # print(sess.run(a[0][0][0][0][:]))\n    writer.close()\n    sess.close()\n    return 0\n\n\ntest()'"
src/test_function/test_yolo_head.py,11,"b'from network_function import *\nfrom detect_function import *\nfrom config import anchors\n# TEST BUILD NETWORK\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n\ndef test():\n    input1 = tf.random_normal([1, 13, 13, 255], mean=1, stddev=4, seed=1)\n\n    mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n    input_shape = np.array([416, 416])\n    a, b, c, d = yolo_head(input1, anchors[mask[0]], 80, input_shape)\n\n    # x = tf.shape(a)\n    writer = tf.summary.FileWriter(\'./graphs\', tf.get_default_graph())\n    # python network_function.py\n    # tensorboard --logdir=""./graphs"" --port 6006\n    # these log file is saved in graphs folder, can delete these older log file\n    # porte 6006 may be change\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        print(sess.run(tf.shape(input1)))\n        print(sess.run(tf.shape(a)))\n        print(sess.run(a[0][0][0][0][:]))\n        print(sess.run(tf.shape(b)))\n        print(sess.run(b[0][0][0][0][:]))\n        print(sess.run(tf.shape(c)))\n        print(sess.run(c[0][0][0][0][:]))\n        print(sess.run(tf.shape(d)))\n        print(sess.run((d[0][0][0][0][:])))\n    writer.close()\n    sess.close()\n    return 0\n\n\ntest()'"
src/test_function/yolo.h5.pb_tensorboard.py,4,"b""import tensorflow as tf\nfrom tensorflow.python.platform import gfile\nwith tf.Session() as sess:\n    model_filename ='/home/minh/stage/yolo.h5.pb'\n    with gfile.FastGFile(model_filename, 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        g_in = tf.import_graph_def(graph_def)\nLOGDIR='/home/minh/stage/graphs'\ntrain_writer = tf.summary.FileWriter(LOGDIR)\ntrain_writer.add_graph(sess.graph)"""
src/utils/yolo_utils.py,2,"b'import random\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport os\n\n\ndef read_classes(classes_path):\n    with open(classes_path) as f:\n        class_names = f.readlines()\n    class_names = [c.strip() for c in class_names]\n    return class_names\n\ndef read_anchors(anchors_path):\n    with open(anchors_path) as f:\n        anchors = f.readline()\n        anchors = [float(x) for x in anchors.split(\',\')]\n        anchors = np.array(anchors).reshape(-1, 2)\n    return anchors\n\ndef get_training_data(annotation_path, data_path, input_shape, anchors, num_classes, max_boxes=100, load_previous=True):\n    """"""\n    processes the data into standard shape\n    :param annotation_path: path_to_image box1,box2,...,boxN with boxX: x_min,y_min,x_max,y_max,class_index\n    :param data_path: saver at ""/home/minh/stage/train.npz""\n    :param input_shape: (416, 416)\n    :param max_boxes: 100: maximum number objects of an image\n    :param load_previous: for 2nd, 3th, .. using\n    :return: image_data [N, 416, 416, 3] not yet normalized, N: number of image\n             box_data: box format: [N, 100, 6], 100: maximum number of an image\n                                                6: top_left{x_min,y_min},bottom_right{x_max,y_max},class_index (no space)\n                                                /home/minh/keras-yolo3/VOCdevkit/VOC2007/JPEGImages/000012.jpg 156,97,351,270,6\n    """"""\n    if load_previous == True and os.path.isfile(data_path):\n        data = np.load(data_path)\n        print(\'Loading training data from \' + data_path)\n        # return data[\'image_data\'], data[\'box_data\'], data[\'image_shape\']\n        return data[\'image_data\'], data[\'box_data\'], data[\'image_shape\'], [data[\'y_true0\'], data[\'y_true1\'], data[\'y_true2\']]\n        # return data[\'image_data\'], data[\'box_data\'], data[\'image_shape\'], [data[\'y_true\']]\n    image_data = []\n    box_data = []\n    image_shape = []\n    with open(annotation_path) as f:\n        GG = f.readlines()\n        np.random.shuffle(GG)\n        for line in (GG):\n            line = line.split(\' \')\n            filename = line[0]\n            if filename[-1] == \'\\n\':\n                filename = filename[:-1]\n            image = Image.open(filename)\n            # For the case 2\n            boxed_image, shape_image = letterbox_image(image, tuple(reversed(input_shape)))\n            # for the case 1\n            # boxed_image, shape_image = resize_image(image, tuple(reversed(input_shape)))\n            image_data.append(np.array(boxed_image, dtype=np.uint8))  # pixel: [0:255] uint8:[-128, 127]\n            image_shape.append(np.array(shape_image))\n\n            boxes = np.zeros((max_boxes, 5), dtype=np.int32)\n            # correct the BBs to the image resize\n            if len(line)==1:  # if there is no object in this image\n                box_data.append(boxes)\n            for i, box in enumerate(line[1:]):\n                if i < max_boxes:\n                    boxes[i] = np.array(list(map(int, box.split(\',\'))))\n                else:\n                    break\n                image_size = np.array(image.size)\n                input_size = np.array(input_shape[::-1])\n                # for case 2\n                new_size = (image_size * np.min(input_size/image_size)).astype(np.int32)\n                # Correct BB to new image\n                boxes[i:i+1, 0:2] = (boxes[i:i+1, 0:2]*new_size/image_size + (input_size-new_size)/2).astype(np.int32)\n                boxes[i:i+1, 2:4] = (boxes[i:i+1, 2:4]*new_size/image_size + (input_size-new_size)/2).astype(np.int32)\n                # for case 1\n                # boxes[i:i + 1, 0] = (boxes[i:i + 1, 0] * input_size[0] / image_size[0]).astype(\'int32\')\n                # boxes[i:i + 1, 1] = (boxes[i:i + 1, 1] * input_size[1] / image_size[1]).astype(\'int32\')\n                # boxes[i:i + 1, 2] = (boxes[i:i + 1, 2] * input_size[0] / image_size[0]).astype(\'int32\')\n                # boxes[i:i + 1, 3] = (boxes[i:i + 1, 3] * input_size[1] / image_size[1]).astype(\'int32\')\n            box_data.append(boxes)\n    image_shape = np.array(image_shape)\n    image_data = np.array(image_data)\n    box_data = (np.array(box_data))\n    y_true = preprocess_true_boxes(box_data, input_shape[0], anchors, num_classes)\n    # np.savez(data_path, image_data=image_data, box_data=box_data, image_shape=image_shape)\n    np.savez(data_path, image_data=image_data, box_data=box_data, image_shape=image_shape, y_true0=y_true[0], y_true1=y_true[1], y_true2=y_true[2])\n    # np.savez(data_path, image_data=image_data, box_data=box_data, image_shape=image_shape, y_true=y_true)\n    print(\'Saving training data into \' + data_path)\n    # return image_data, box_data, image_shape\n    return image_data, box_data, image_shape, y_true\n\ndef letterbox_image(image, size):\n    """"""resize image with unchanged aspect ratio using padding\n    :param: size: input_shape\n    :return:boxed_image:\n            image_shape: original shape (h, w)\n    """"""\n    image_w, image_h = image.size\n    image_shape = np.array([image_h, image_w])\n    w, h = size\n    new_w = int(image_w * min(w/image_w, h/image_h))\n    new_h = int(image_h * min(w/image_w, h/image_h))\n    resized_image = image.resize((new_w, new_h), Image.BICUBIC)\n\n    boxed_image = Image.new(\'RGB\', size, (128, 128, 128))\n    boxed_image.paste(resized_image, ((w-new_w)//2, (h-new_h)//2))\n    return boxed_image, image_shape\n\n# Partie l\'entrainement\ndef preprocess_true_boxes(true_boxes, Input_shape, anchors, num_classes):\n    """"""\n    Preprocess true boxes to training input format\n    :param true_boxes: array, shape=(N, 100, 5)N:so luong anh,100:so object max trong 1 anh, 5:x_min,y_min,x_max,y_max,class_id\n                    Absolute x_min, y_min, x_max, y_max, class_code reletive to input_shape.\n    :param input_shape: array-like, hw, multiples of 32, shape = (2,)\n    :param anchors: array, shape=(9, 2), wh\n    :param num_classes: integer\n    :return: y_true: list(3 array), shape like yolo_outputs, xywh are reletive value 3 array [N,, 13, 13, 3, 85]\n    """"""\n    assert (true_boxes[..., 4] < num_classes).all(), \'class id must be less than num_classes\'\n    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n    true_boxes = np.array(true_boxes, dtype=np.float32)\n    input_shape = np.array([Input_shape, Input_shape], dtype=np.int32)\n    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2  # [m, T, 2]  (x, y)center point of BB\n    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]  # w = x_max - x_min  [m, T, 2]\n                                                            # h = y_max - y_min\n    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1]  # hw -> wh\n    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1]  # hw -> wh\n\n    N = true_boxes.shape[0]\n    grid_shapes = [input_shape // {0: 32, 1: 16, 2: 8}[l] for l in range(3)]\n    # grid_shapes = [np.array(input_shape // scale, dtype=np.int) for scale in [32, 16, 8]]  # [2,] ---> [3, 2]\n    y_true = [np.zeros((N, grid_shapes[l][0], grid_shapes[l][1], len(anchor_mask[l]), 5 + int(num_classes)),\n                       dtype=np.float32) for l in range(3)]  # (m, 13, 13, 3, 85)\n\n    # Expand dim to apply broadcasting.\n    anchors = np.expand_dims(anchors, 0)  # [1, 3, 2]\n    anchor_maxes = anchors / 2.  # w/2, h/2  [1, 3, 2]\n    anchor_mins = -anchor_maxes   # -w/2, -h/2  [1, 3, 2]\n    valid_mask = boxes_wh[..., 0] > 0  # w>0 True, w=0 False\n\n    for b in (range(N)):  # for all of N image\n        # Discard zero rows.\n        wh = boxes_wh[b, valid_mask[b]]  # image 0: wh [[[163., 144.]]]\n        # Expand dim to apply broadcasting.\n        if len(wh)==0:\n            continue\n        wh = np.expand_dims(wh, -2)\n        box_maxes = wh / 2.\n        box_mins = -box_maxes\n\n        intersect_mins = np.maximum(box_mins, anchor_mins)\n        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n        box_area = wh[..., 0] * wh[..., 1]\n        anchor_area = anchors[..., 0] * anchors[..., 1]\n        iou = intersect_area / (box_area + anchor_area - intersect_area)\n\n        # Find best anchor for each true box\n        best_anchor = np.argmax(iou, axis=-1)\n        # print(""Imageeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee numero:"")\n        # print(""True_boxes num\xc3\xa9ro %s"" %b)\n        # print(true_boxes[b][:10])\n        for t, n in enumerate(best_anchor):\n            for l in range(3):  # 1 in 3 scale\n                if n in anchor_mask[l]:  # choose the corresponding mask: best_anchor in [6, 7, 8]or[3, 4, 5]or[0, 1, 2]\n\n                    i = np.floor(true_boxes[b, t, 0] * grid_shapes[l][1]).astype(np.int32)  #ex: 3+1.2=4.2--> vao \xc3\xb4 co y=4\n                    j = np.floor(true_boxes[b, t, 1] * grid_shapes[l][0]).astype(np.int32)  # ex: 3+0.5=3.5--> vao o co x=3 --> o (x,y)=(3,4)  # TODO\n                    if grid_shapes[l][1]==13 and (i>=13 or j>=13):\n                        print(i)\n                    # print(""object %s------------------------------""%t)\n                    # print(grid_shapes[l])\n                    # print(""  j=%s, i=%s"" %(j, i))\n                    k = anchor_mask[l].index(n)\n                    # print(""  scale l:"", l, ""best anchor k:"", k, anchors[:, l + n])\n\n                    c = true_boxes[b, t, 4].astype(np.int32)  # idx classes in voc classes\n                    # print(b, c)\n                    # print(""  idx classes c in voc:"", c)\n                    y_true[l][b, j, i, k, 0:4] = true_boxes[b, t, 0:4]  # l: scale; b; idx image; grid(i:y , j:x); k: best anchor; 0:4: (x,y,w,h)/input_shape\n                    # print(""  x,y,w,h/416:"", y_true[l][b, j, i, k, 0:4])\n                    y_true[l][b, j, i, k, 4] = 1  # score = 1\n                    y_true[l][b, j, i, k, 5 + c] = 1  # classes = 1, the others =0\n                    # print(""  y_true[l][b, j, i, k, :] with l:%s, b:%s, j:%s, i:%s, k:%s, c:%s"" %(l,b,j,i,k,c))\n                    # print(""  with l:"", l, ""b:"", b, ""j:"", j, ""i:"", i, ""k:"", k, ""c:"", c)\n                    # print(y_true[l][b, j, i, k, :])\n                    break  # if chon dung mask (scale) ---> exit (for l in range(3))\n\n    return y_true\n\n# def resize_image(image, size):\n#     """"""\n#     resize image with changed aspect ratio\n#     :param image: origin image\n#     :param size: input_shape\n#     :return: origin_image_shape + image resize\n#     """"""\n#     image_w, image_h = image.size\n#     image_shape = np.array([image_h, image_w])\n#     image_resize = image.resize(size, Image.NEAREST)\n#     return image_resize, image_shape\n\n\n# def generate_colors(class_names):\n#     import colorsys\n#     hsv_tuples = [(x / len(class_names), 1., 1.) for x in range(len(class_names))]\n#     colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n#     colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n#     random.seed(10101)  # Fixed seed for consistent colors across runs.\n#     random.shuffle(colors)  # Shuffle colors to decorate adjacent classes.\n#     random.seed(None)  # Reset seed to default.\n#     return colors\n#\n#\n# def scale_boxes(boxes, image_shape):\n#     """""" Scales the predicted boxes in order to be drawable on the image""""""\n#     import tensorflow as tf\n#     height = image_shape[0]\n#     width = image_shape[1]\n#     image_dims = tf.constant([height, width, height, width])\n#     image_dims = tf.reshape(image_dims, [1, 4])\n#     boxes = boxes * image_dims\n#     return boxes\n#\n#\n# def preprocess_image(img_path, model_image_size):\n#     image = cv2.imread(img_path)\n#     print(image.shape)\n#     resized_image = cv2.resize(image, tuple(reversed(model_image_size)), interpolation=cv2.INTER_AREA)\n#     # images/dog.jpg use this is good\n#     #resized_image = cv2.resize(image, tuple(reversed(model_image_size)), interpolation=cv2.INTER_CUBIC)\n#     resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n#     image_data = np.array(resized_image, dtype=\'float32\')\n#     image_data /= 255.\n#     image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n#\n#     return image, image_data\n#\n#\n# def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n#     h, w, _ = image.shape\n#\n#     for i, c in reversed(list(enumerate(out_classes))):\n#         predicted_class = class_names[c]\n#         box = out_boxes[i]\n#         score = out_scores[i]\n#\n#         label = \'{} {:.2f}\'.format(predicted_class, score)\n#\n#         top, left, bottom, right = box\n#         top = max(0, np.floor(top + 0.5).astype(\'int32\'))\n#         left = max(0, np.floor(left + 0.5).astype(\'int32\'))\n#         bottom = min(h, np.floor(bottom + 0.5).astype(\'int32\'))\n#         right = min(w, np.floor(right + 0.5).astype(\'int32\'))\n#         print(label, (left, top), (right, bottom))\n#\n#         # colors: RGB, opencv: BGR\n#         cv2.rectangle(image, (left, top), (right, bottom), tuple(reversed(colors[c])), 6)\n#\n#         font_face = cv2.FONT_HERSHEY_SIMPLEX\n#         font_scale = 1\n#         font_thickness = 2\n#\n#         label_size = cv2.getTextSize(label, font_face, font_scale, font_thickness)[0]\n#         label_rect_left, label_rect_top = int(left - 3), int(top - 3)\n#         label_rect_right, label_rect_bottom = int(left + 3 + label_size[0]), int(top - 5 - label_size[1])\n#         cv2.rectangle(image, (label_rect_left, label_rect_top), (label_rect_right, label_rect_bottom), tuple(reversed(colors[c])), -1)\n#\n#         cv2.putText(image, label, (left, int(top - 4)), font_face, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA)\n#\n#     return image'"
