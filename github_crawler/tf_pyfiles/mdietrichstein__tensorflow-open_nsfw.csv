file_path,api_count,code
classify_nsfw.py,3,"b'#!/usr/bin/env python\nimport sys\nimport argparse\nimport tensorflow as tf\n\nfrom model import OpenNsfwModel, InputType\nfrom image_utils import create_tensorflow_image_loader\nfrom image_utils import create_yahoo_image_loader\n\nimport numpy as np\n\n\nIMAGE_LOADER_TENSORFLOW = ""tensorflow""\nIMAGE_LOADER_YAHOO = ""yahoo""\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""input_file"", help=""Path to the input image.\\\n                        Only jpeg images are supported."")\n\n    parser.add_argument(""-m"", ""--model_weights"", required=True,\n                        help=""Path to trained model weights file"")\n\n    parser.add_argument(""-l"", ""--image_loader"",\n                        default=IMAGE_LOADER_YAHOO,\n                        help=""image loading mechanism"",\n                        choices=[IMAGE_LOADER_YAHOO, IMAGE_LOADER_TENSORFLOW])\n\n    parser.add_argument(""-i"", ""--input_type"",\n                        default=InputType.TENSOR.name.lower(),\n                        help=""input type"",\n                        choices=[InputType.TENSOR.name.lower(),\n                                 InputType.BASE64_JPEG.name.lower()])\n\n    args = parser.parse_args()\n\n    model = OpenNsfwModel()\n\n    with tf.Session() as sess:\n\n        input_type = InputType[args.input_type.upper()]\n        model.build(weights_path=args.model_weights, input_type=input_type)\n\n        fn_load_image = None\n\n        if input_type == InputType.TENSOR:\n            if args.image_loader == IMAGE_LOADER_TENSORFLOW:\n                fn_load_image = create_tensorflow_image_loader(tf.Session(graph=tf.Graph()))\n            else:\n                fn_load_image = create_yahoo_image_loader()\n        elif input_type == InputType.BASE64_JPEG:\n            import base64\n            fn_load_image = lambda filename: np.array([base64.urlsafe_b64encode(open(filename, ""rb"").read())])\n\n        sess.run(tf.global_variables_initializer())\n\n        image = fn_load_image(args.input_file)\n\n        predictions = \\\n            sess.run(model.predictions,\n                     feed_dict={model.input: image})\n\n        print(""Results for \'{}\'"".format(args.input_file))\n        print(""\\tSFW score:\\t{}\\n\\tNSFW score:\\t{}"".format(*predictions[0]))\n\nif __name__ == ""__main__"":\n    main(sys.argv)\n'"
image_utils.py,15,"b'VGG_MEAN = [104, 117, 123]\n\n\ndef create_yahoo_image_loader(expand_dims=True):\n    """"""Yahoo open_nsfw image loading mechanism\n\n    Approximation of the image loading mechanism defined in\n    https://github.com/yahoo/open_nsfw/blob/79f77bcd45076b000df71742a59d726aa4a36ad1/classify_nsfw.py#L40\n    """"""\n    import numpy as np\n    import skimage\n    import skimage.io\n    from PIL import Image\n    from io import BytesIO\n\n    def load_image(image_path):\n        pimg = open(image_path, \'rb\').read()\n\n        img_data = pimg\n        im = Image.open(BytesIO(img_data))\n\n        if im.mode != ""RGB"":\n            im = im.convert(\'RGB\')\n\n        imr = im.resize((256, 256), resample=Image.BILINEAR)\n\n        fh_im = BytesIO()\n        imr.save(fh_im, format=\'JPEG\')\n        fh_im.seek(0)\n\n        image = (skimage.img_as_float(skimage.io.imread(fh_im, as_grey=False))\n                        .astype(np.float32))\n\n        H, W, _ = image.shape\n        h, w = (224, 224)\n\n        h_off = max((H - h) // 2, 0)\n        w_off = max((W - w) // 2, 0)\n        image = image[h_off:h_off + h, w_off:w_off + w, :]\n\n        # RGB to BGR\n        image = image[:, :, :: -1]\n\n        image = image.astype(np.float32, copy=False)\n        image = image * 255.0\n        image -= np.array(VGG_MEAN, dtype=np.float32)\n\n        if expand_dims:\n            image = np.expand_dims(image, axis=0)\n\n        return image\n\n    return load_image\n\n\ndef create_tensorflow_image_loader(session, expand_dims=True,\n                                   options=None,\n                                   run_metadata=None):\n    """"""Tensorflow image loader\n\n    Results seem to deviate quite a bit from yahoo image loader due to\n    different jpeg encoders/decoders and different image resize\n    implementations between PIL, skimage and tensorflow\n\n    Only supports jpeg images.\n\n    Relevant tensorflow issues:\n        * https://github.com/tensorflow/tensorflow/issues/6720\n        * https://github.com/tensorflow/tensorflow/issues/12753\n    """"""\n    import tensorflow as tf\n\n    def load_image(image_path):\n        image = tf.read_file(image_path)\n        image = __tf_jpeg_process(image)\n\n        if expand_dims:\n            image_batch = tf.expand_dims(image, axis=0)\n            return session.run(image_batch,\n                               options=options,\n                               run_metadata=run_metadata)\n\n        return session.run(image,\n                           options=options,\n                           run_metadata=run_metadata)\n\n    return load_image\n\n\ndef load_base64_tensor(_input):\n    import tensorflow as tf\n\n    def decode_and_process(base64):\n        _bytes = tf.decode_base64(base64)\n        _image = __tf_jpeg_process(_bytes)\n\n        return _image\n\n    # we have to do some preprocessing with map_fn, since functions like\n    # decode_*, resize_images and crop_to_bounding_box do not support\n    # processing of batches\n    image = tf.map_fn(decode_and_process, _input,\n                      back_prop=False, dtype=tf.float32)\n\n    return image\n\n\ndef __tf_jpeg_process(data):\n    import tensorflow as tf\n\n    # The whole jpeg encode/decode dance is neccessary to generate a result\n    # that matches the original model\'s (caffe) preprocessing\n    # (as good as possible)\n    image = tf.image.decode_jpeg(data, channels=3,\n                                 fancy_upscaling=True,\n                                 dct_method=""INTEGER_FAST"")\n\n    image = tf.image.convert_image_dtype(image, tf.float32, saturate=True)\n    image = tf.image.resize_images(image, (256, 256),\n                                   method=tf.image.ResizeMethod.BILINEAR,\n                                   align_corners=True)\n\n    image = tf.image.convert_image_dtype(image, tf.uint8, saturate=True)\n\n    image = tf.image.encode_jpeg(image, format=\'\', quality=75,\n                                 progressive=False, optimize_size=False,\n                                 chroma_downsampling=True,\n                                 density_unit=None,\n                                 x_density=None, y_density=None,\n                                 xmp_metadata=None)\n\n    image = tf.image.decode_jpeg(image, channels=3,\n                                 fancy_upscaling=False,\n                                 dct_method=""INTEGER_ACCURATE"")\n\n    image = tf.cast(image, dtype=tf.float32)\n\n    image = tf.image.crop_to_bounding_box(image, 16, 16, 224, 224)\n\n    image = tf.reverse(image, axis=[2])\n    image -= VGG_MEAN\n\n    return image\n'"
model.py,36,"b'import math\nimport numpy as np\nimport tensorflow as tf\nfrom enum import Enum, unique\n\n\n@unique\nclass InputType(Enum):\n    TENSOR = 1\n    BASE64_JPEG = 2\n\n\nclass OpenNsfwModel:\n    """"""Tensorflow implementation of Yahoo\'s Open NSFW Model\n\n    Original implementation:\n    https://github.com/yahoo/open_nsfw\n\n    Weights have been converted using caffe-tensorflow:\n    https://github.com/ethereon/caffe-tensorflow\n    """"""\n\n    def __init__(self):\n        self.weights = {}\n        self.bn_epsilon = 1e-5  # Default used by Caffe\n\n    def build(self, weights_path=""open_nsfw-weights.npy"",\n              input_type=InputType.TENSOR):\n\n        self.weights = np.load(weights_path, encoding=""latin1"").item()\n        self.input_tensor = None\n\n        if input_type == InputType.TENSOR:\n            self.input = tf.placeholder(tf.float32,\n                                        shape=[None, 224, 224, 3],\n                                        name=""input"")\n            self.input_tensor = self.input\n        elif input_type == InputType.BASE64_JPEG:\n            from image_utils import load_base64_tensor\n\n            self.input = tf.placeholder(tf.string, shape=(None,), name=""input"")\n            self.input_tensor = load_base64_tensor(self.input)\n        else:\n            raise ValueError(""invalid input type \'{}\'"".format(input_type))\n\n        x = self.input_tensor\n\n        x = tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \'CONSTANT\')\n        x = self.__conv2d(""conv_1"", x, filter_depth=64,\n                          kernel_size=7, stride=2, padding=\'valid\')\n\n        x = self.__batch_norm(""bn_1"", x)\n        x = tf.nn.relu(x)\n\n        x = tf.layers.max_pooling2d(x, pool_size=3, strides=2, padding=\'same\')\n\n        x = self.__conv_block(stage=0, block=0, inputs=x,\n                              filter_depths=[32, 32, 128],\n                              kernel_size=3, stride=1)\n\n        x = self.__identity_block(stage=0, block=1, inputs=x,\n                                  filter_depths=[32, 32, 128], kernel_size=3)\n        x = self.__identity_block(stage=0, block=2, inputs=x,\n                                  filter_depths=[32, 32, 128], kernel_size=3)\n\n        x = self.__conv_block(stage=1, block=0, inputs=x,\n                              filter_depths=[64, 64, 256],\n                              kernel_size=3, stride=2)\n        x = self.__identity_block(stage=1, block=1, inputs=x,\n                                  filter_depths=[64, 64, 256], kernel_size=3)\n        x = self.__identity_block(stage=1, block=2, inputs=x,\n                                  filter_depths=[64, 64, 256], kernel_size=3)\n        x = self.__identity_block(stage=1, block=3, inputs=x,\n                                  filter_depths=[64, 64, 256], kernel_size=3)\n\n        x = self.__conv_block(stage=2, block=0, inputs=x,\n                              filter_depths=[128, 128, 512],\n                              kernel_size=3, stride=2)\n        x = self.__identity_block(stage=2, block=1, inputs=x,\n                                  filter_depths=[128, 128, 512], kernel_size=3)\n        x = self.__identity_block(stage=2, block=2, inputs=x,\n                                  filter_depths=[128, 128, 512], kernel_size=3)\n        x = self.__identity_block(stage=2, block=3, inputs=x,\n                                  filter_depths=[128, 128, 512], kernel_size=3)\n        x = self.__identity_block(stage=2, block=4, inputs=x,\n                                  filter_depths=[128, 128, 512], kernel_size=3)\n        x = self.__identity_block(stage=2, block=5, inputs=x,\n                                  filter_depths=[128, 128, 512], kernel_size=3)\n\n        x = self.__conv_block(stage=3, block=0, inputs=x,\n                              filter_depths=[256, 256, 1024], kernel_size=3,\n                              stride=2)\n        x = self.__identity_block(stage=3, block=1, inputs=x,\n                                  filter_depths=[256, 256, 1024],\n                                  kernel_size=3)\n        x = self.__identity_block(stage=3, block=2, inputs=x,\n                                  filter_depths=[256, 256, 1024],\n                                  kernel_size=3)\n\n        x = tf.layers.average_pooling2d(x, pool_size=7, strides=1,\n                                        padding=""valid"", name=""pool"")\n\n        x = tf.reshape(x, shape=(-1, 1024))\n\n        self.logits = self.__fully_connected(name=""fc_nsfw"",\n                                             inputs=x, num_outputs=2)\n        self.predictions = tf.nn.softmax(self.logits, name=""predictions"")\n\n    """"""Get weights for layer with given name\n    """"""\n    def __get_weights(self, layer_name, field_name):\n        if not layer_name in self.weights:\n            raise ValueError(""No weights for layer named \'{}\' found""\n                             .format(layer_name))\n\n        w = self.weights[layer_name]\n        if not field_name in w:\n            raise (ValueError(""No entry for field \'{}\' in layer named \'{}\'""\n                              .format(field_name, layer_name)))\n\n        return w[field_name]\n\n    """"""Layer creation and weight initialization\n    """"""\n    def __fully_connected(self, name, inputs, num_outputs):\n        return tf.layers.dense(\n            inputs=inputs, units=num_outputs, name=name,\n            kernel_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""weights""), dtype=tf.float32),\n            bias_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""biases""), dtype=tf.float32))\n\n    def __conv2d(self, name, inputs, filter_depth, kernel_size, stride=1,\n                 padding=""same"", trainable=False):\n\n        if padding.lower() == \'same\' and kernel_size > 1:\n            if kernel_size > 1:\n                oh = inputs.get_shape().as_list()[1]\n                h = inputs.get_shape().as_list()[1]\n\n                p = int(math.floor(((oh - 1) * stride + kernel_size - h)//2))\n\n                inputs = tf.pad(inputs,\n                                [[0, 0], [p, p], [p, p], [0, 0]],\n                                \'CONSTANT\')\n            else:\n                raise Exception(\'unsupported kernel size for padding: ""{}""\'\n                                .format(kernel_size))\n\n        return tf.layers.conv2d(\n            inputs, filter_depth,\n            kernel_size=(kernel_size, kernel_size),\n            strides=(stride, stride), padding=\'valid\',\n            activation=None, trainable=trainable, name=name,\n            kernel_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""weights""), dtype=tf.float32),\n            bias_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""biases""), dtype=tf.float32))\n\n    def __batch_norm(self, name, inputs, training=False):\n        return tf.layers.batch_normalization(\n            inputs, training=training, epsilon=self.bn_epsilon,\n            gamma_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""scale""), dtype=tf.float32),\n            beta_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""offset""), dtype=tf.float32),\n            moving_mean_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""mean""), dtype=tf.float32),\n            moving_variance_initializer=tf.constant_initializer(\n                self.__get_weights(name, ""variance""), dtype=tf.float32),\n            name=name)\n\n    """"""ResNet blocks\n    """"""\n    def __conv_block(self, stage, block, inputs, filter_depths,\n                     kernel_size=3, stride=2):\n        filter_depth1, filter_depth2, filter_depth3 = filter_depths\n\n        conv_name_base = ""conv_stage{}_block{}_branch"".format(stage, block)\n        bn_name_base = ""bn_stage{}_block{}_branch"".format(stage, block)\n        shortcut_name_post = ""_stage{}_block{}_proj_shortcut"" \\\n                             .format(stage, block)\n\n        shortcut = self.__conv2d(\n            name=""conv{}"".format(shortcut_name_post), stride=stride,\n            inputs=inputs, filter_depth=filter_depth3, kernel_size=1,\n            padding=""same""\n        )\n\n        shortcut = self.__batch_norm(""bn{}"".format(shortcut_name_post),\n                                     shortcut)\n\n        x = self.__conv2d(\n            name=""{}2a"".format(conv_name_base),\n            inputs=inputs, filter_depth=filter_depth1, kernel_size=1,\n            stride=stride, padding=""same"",\n        )\n        x = self.__batch_norm(""{}2a"".format(bn_name_base), x)\n        x = tf.nn.relu(x)\n\n        x = self.__conv2d(\n            name=""{}2b"".format(conv_name_base),\n            inputs=x, filter_depth=filter_depth2, kernel_size=kernel_size,\n            padding=""same"", stride=1\n        )\n        x = self.__batch_norm(""{}2b"".format(bn_name_base), x)\n        x = tf.nn.relu(x)\n\n        x = self.__conv2d(\n            name=""{}2c"".format(conv_name_base),\n            inputs=x, filter_depth=filter_depth3, kernel_size=1,\n            padding=""same"", stride=1\n        )\n        x = self.__batch_norm(""{}2c"".format(bn_name_base), x)\n\n        x = tf.add(x, shortcut)\n\n        return tf.nn.relu(x)\n\n    def __identity_block(self, stage, block, inputs,\n                         filter_depths, kernel_size):\n        filter_depth1, filter_depth2, filter_depth3 = filter_depths\n        conv_name_base = ""conv_stage{}_block{}_branch"".format(stage, block)\n        bn_name_base = ""bn_stage{}_block{}_branch"".format(stage, block)\n\n        x = self.__conv2d(\n            name=""{}2a"".format(conv_name_base),\n            inputs=inputs, filter_depth=filter_depth1, kernel_size=1,\n            stride=1, padding=""same"",\n        )\n\n        x = self.__batch_norm(""{}2a"".format(bn_name_base), x)\n        x = tf.nn.relu(x)\n\n        x = self.__conv2d(\n            name=""{}2b"".format(conv_name_base),\n            inputs=x, filter_depth=filter_depth2, kernel_size=kernel_size,\n            padding=""same"", stride=1\n        )\n        x = self.__batch_norm(""{}2b"".format(bn_name_base), x)\n        x = tf.nn.relu(x)\n\n        x = self.__conv2d(\n            name=""{}2c"".format(conv_name_base),\n            inputs=x, filter_depth=filter_depth3, kernel_size=1,\n            padding=""same"", stride=1\n        )\n        x = self.__batch_norm(""{}2c"".format(bn_name_base), x)\n\n        x = tf.add(x, inputs)\n\n        return tf.nn.relu(x)\n'"
eval/batch_classify.py,5,"b'\nimport os\nimport sys\n\nsys.path.append((os.path.normpath(\n                 os.path.join(os.path.dirname(os.path.realpath(__file__)),\n                              \'..\'))))\n\nimport argparse\nimport glob\nimport tensorflow as tf\nfrom tqdm import tqdm\n\nfrom model import OpenNsfwModel, InputType\nfrom image_utils import create_tensorflow_image_loader\nfrom image_utils import create_yahoo_image_loader\n\n\nIMAGE_LOADER_TENSORFLOW = ""tensorflow""\nIMAGE_LOADER_YAHOO = ""yahoo""\n\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'\ntf.logging.set_verbosity(tf.logging.ERROR)\n\n\ndef create_batch_iterator(filenames, batch_size, fn_load_image):\n    for i in range(0, len(filenames), batch_size):\n        yield list(map(fn_load_image, filenames[i:i+batch_size]))\n\n\ndef create_tf_batch_iterator(filenames, batch_size):\n    for i in range(0, len(filenames), batch_size):\n        with tf.Session(graph=tf.Graph()) as session:\n            fn_load_image = create_tensorflow_image_loader(session,\n                                                           expand_dims=False)\n\n            yield list(map(fn_load_image, filenames[i:i+batch_size]))\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""-s"", ""--source"", required=True,\n                        help=""Folder containing the images to classify"")\n\n    parser.add_argument(""-o"", ""--output_file"", required=True,\n                        help=""Output file path"")\n\n    parser.add_argument(""-m"", ""--model_weights"", required=True,\n                        help=""Path to trained model weights file"")\n\n    parser.add_argument(""-b"", ""--batch_size"", help=""Number of images to \\\n                        classify simultaneously."", type=int, default=64)\n\n    parser.add_argument(""-l"", ""--image_loader"",\n                        default=IMAGE_LOADER_YAHOO,\n                        help=""image loading mechanism"",\n                        choices=[IMAGE_LOADER_YAHOO, IMAGE_LOADER_TENSORFLOW])\n\n    args = parser.parse_args()\n    batch_size = args.batch_size\n    output_file = args.output_file\n\n    input_type = InputType.TENSOR\n    model = OpenNsfwModel()\n\n    filenames = glob.glob(args.source + ""/*.jpg"")\n    num_files = len(filenames)\n\n    num_batches = int(num_files / batch_size)\n\n    print(""Found"", num_files, "" files"")\n    print(""Split into"", num_batches, "" batches"")\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n\n    batch_iterator = None\n\n    if args.image_loader == IMAGE_LOADER_TENSORFLOW:\n        batch_iterator = create_tf_batch_iterator(filenames, batch_size)\n    else:\n        fn_load_image = create_yahoo_image_loader(expand_dims=False)\n        batch_iterator = create_batch_iterator(filenames, batch_size,\n                                               fn_load_image)\n\n    with tf.Session(graph=tf.Graph(), config=config) as session:\n        model.build(weights_path=args.model_weights,\n                    input_type=input_type)\n\n        session.run(tf.global_variables_initializer())\n\n        with tqdm(total=num_files) as progress_bar:\n            with open(output_file, \'w\') as o:\n                o.write(\'File\\tSFW Score\\tNSFW Score\\n\')\n\n                for batch_num, images in enumerate(batch_iterator):\n                    predictions = \\\n                        session.run(model.predictions,\n                                    feed_dict={model.input: images})\n\n                    fi = (batch_num * batch_size)\n                    for i, prediction in enumerate(predictions):\n                        filename = os.path.basename(filenames[fi + i])\n                        o.write(\'{}\\t{}\\t{}\\n\'.format(filename,\n                                                      prediction[0],\n                                                      prediction[1]))\n\n                    progress_bar.update(len(images))\n\nif __name__ == ""__main__"":\n    main(sys.argv)\n'"
eval/eval.py,0,"b'import sys\nimport operator\nimport argparse\nimport numpy as np\nfrom scipy import stats\n\n\ndef load_classifications(filename):\n    is_first = True\n\n    results = {}\n\n    with open(filename, \'r\') as f:\n        for line in f:\n            if is_first:\n                is_first = False\n                continue\n\n            parts = line.split(\'\\t\')\n\n            filename = parts[0]\n            sfw_score = float(parts[1])\n            nsfw_score = float(parts[2])\n\n            results[filename] = (sfw_score, nsfw_score)\n\n    return results\n\n\ndef classification_matrix(classifications):\n    results = np.zeros(shape=(len(classifications), 2))\n\n    for i, classification in enumerate(classifications):\n        results[i] = np.array(classification[1])\n\n    return results\n\n\ndef test(first, second):\n    delta = np.abs(first - second)\n\n    result = {\n        \'min\': np.amin(delta),\n        \'max\': np.amax(delta),\n        \'median\': np.median(delta),\n        \'mean\': np.mean(delta),\n        \'std\': np.std(delta),\n        \'var\': np.var(delta),\n        \'t-prob\': stats.ttest_ind(first, second, equal_var=True)[1]\n    }\n\n    return result\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""original"",\n                        help=""File containing base classifications"")\n\n    parser.add_argument(""other"",\n                        help=""File containing classifications to compare to\\\n                        base results"")\n\n    args = parser.parse_args()\n    filename_original = args.original\n    filename_other = args.other\n\n    original = load_classifications(filename_original)\n    other = load_classifications(filename_other)\n\n    len(original) == len(other)\n\n    original = sorted(original.items(), key=operator.itemgetter(0))\n    other = sorted(other.items(), key=operator.itemgetter(0))\n\n    print(""Found"", len(original), ""entries"")\n\n    original_classifications = classification_matrix(original)\n    other_classifications = classification_matrix(other)\n\n    print(\'SFW:\')\n    print(test(original_classifications[:, 0], other_classifications[:, 0]))\n\n    print()\n    print(\'NSFW:\')\n    print(test(original_classifications[:, 1], other_classifications[:, 1]))\n\nif __name__ == ""__main__"":\n    main(sys.argv)\n'"
tools/create_predict_request.py,3,"b'import base64\nimport json\nimport argparse\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.saved_model.signature_constants import PREDICT_INPUTS\n\nimport os\nimport sys\n\nsys.path.append((os.path.normpath(\n                 os.path.join(os.path.dirname(os.path.realpath(__file__)),\n                              \'..\'))))\n\nfrom image_utils import create_tensorflow_image_loader\nfrom image_utils import create_yahoo_image_loader\nfrom model import InputType\n\nIMAGE_LOADER_TENSORFLOW = ""tensorflow""\nIMAGE_LOADER_YAHOO = ""yahoo""\n\n# Thanks to https://stackoverflow.com/a/47626762\nclass NumpyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return json.JSONEncoder.default(self, obj)\n\n""""""Generates a json prediction request suitable for consumption by a model \ngenerated with \'export-model.py\' and deployed on either ml-engine or tensorflow-serving\n""""""\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""input_file"", help=""Path to the input image file"")\n\n    parser.add_argument(""-i"", ""--input_type"", required=True,\n                        default=InputType.TENSOR.name.lower(),\n                        help=""Input type"",\n                        choices=[InputType.TENSOR.name.lower(),\n                                 InputType.BASE64_JPEG.name.lower()])\n\n    parser.add_argument(""-l"", ""--image_loader"", required=False,\n                        default=IMAGE_LOADER_YAHOO,\n                        help=""Image loading mechanism. Only relevant when using input_type \'tensor\'"",\n                        choices=[IMAGE_LOADER_YAHOO, IMAGE_LOADER_TENSORFLOW])\n\n    parser.add_argument(""-t"", ""--target"", required=True,\n                        choices=[\'ml-engine\', \'tf-serving\'],\n                        help=""Create json request for ml-engine or tensorflow-serving"")\n\n    args = parser.parse_args()\n    target = args.target\n\n    input_type = InputType[args.input_type.upper()]\n\n    image_data = None\n\n    if input_type == InputType.TENSOR:\n        fn_load_image = None\n\n        if args.image_loader == IMAGE_LOADER_TENSORFLOW:\n            with tf.Session() as sess:\n                fn_load_image = create_tensorflow_image_loader(sess)\n                sess.run(tf.global_variables_initializer())\n                image_data = fn_load_image(args.input_file)[0]\n        else:\n            image_data = create_yahoo_image_loader(tf.Session(graph=tf.Graph()))(args.input_file)[0]\n    elif input_type == InputType.BASE64_JPEG:\n        import base64\n        image_data = base64.urlsafe_b64encode(open(args.input_file, ""rb"").read()).decode(""ascii"")\n\n    if target == ""ml-engine"":\n        print(json.dumps({PREDICT_INPUTS: image_data}, cls=NumpyEncoder))\n    elif target == ""tf-serving"":\n        print(json.dumps({""instances"": [image_data]}, cls=NumpyEncoder))\n'"
tools/export_graph.py,8,"b'import os\nimport sys\nimport argparse\n\nimport tensorflow as tf\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\n\nsys.path.append((os.path.normpath(\n                 os.path.join(os.path.dirname(os.path.realpath(__file__)),\n                              \'..\'))))\n\nfrom model import OpenNsfwModel, InputType\n\n""""""Exports the graph so it can be imported via import_graph_def\n\nThe exported model takes an base64 encoded string tensor as input\n""""""\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""target"", help=""output directory"")\n\n    parser.add_argument(""-m"", ""--model_weights"", required=True,\n                        help=""Path to trained model weights file"")\n\n    parser.add_argument(""-i"", ""--input_type"", required=True,\n                        default=InputType.TENSOR.name.lower(),\n                        help=""Input type"",\n                        choices=[InputType.TENSOR.name.lower(),\n                                 InputType.BASE64_JPEG.name.lower()])\n\n    parser.add_argument(""-o"", ""--optimize"", action=\'store_true\',\n                        default=False,\n                        help=""Optimize graph for inference"")\n\n    parser.add_argument(""-f"", ""--freeze"", action=\'store_true\',\n                        required=False, default=False,\n                        help=""Freeze graph: convert variables to ops"")\n\n    parser.add_argument(""-t"", ""--text"", action=\'store_true\',\n                        required=False, default=False,\n                        help=""Write graph as binary (.pb) or text (pbtext)"")\n\n    args = parser.parse_args()\n\n    model = OpenNsfwModel()\n\n    export_base_path = args.target\n    do_freeze = args.freeze\n    do_optimize = args.optimize\n    as_binary =  not args.text\n    input_type = InputType[args.input_type.upper()]\n\n    input_node_name = \'input\'\n    output_node_name = \'predictions\'\n\n    base_name = \'open_nsfw\'\n\n    checkpoint_path = os.path.join(export_base_path, base_name + \'.ckpt\')\n\n    if as_binary:\n        graph_name = base_name + \'.pb\'\n    else:\n        graph_name = base_name + \'.pbtxt\'\n\n    graph_path = os.path.join(export_base_path, graph_name)\n    frozen_graph_path = os.path.join(export_base_path,\n                                     \'frozen_\' + graph_name)\n    optimized_graph_path = os.path.join(export_base_path,\n                                        \'optimized_\' + graph_name)\n\n    with tf.Session() as sess:\n        model.build(weights_path=args.model_weights,\n                    input_type=input_type)\n\n        sess.run(tf.global_variables_initializer())\n\n        saver = tf.train.Saver()\n        saver.save(sess, save_path=checkpoint_path)\n\n        print(\'Checkpoint exported to {}\'.format(checkpoint_path))\n\n        tf.train.write_graph(sess.graph_def, export_base_path, graph_name,\n                             as_text=not as_binary)\n\n        print(\'Graph exported to {}\'.format(graph_path))\n\n        if do_freeze:\n            print(\'Freezing graph...\')\n            freeze_graph.freeze_graph(\n                input_graph=graph_path, input_saver=\'\',\n                input_binary=as_binary, input_checkpoint=checkpoint_path,\n                output_node_names=output_node_name,\n                restore_op_name=\'save/restore_all\',\n                filename_tensor_name=\'save/Const:0\',\n                output_graph=frozen_graph_path, clear_devices=True,\n                initializer_nodes=\'\')\n\n            print(\'Frozen graph exported to {}\'.format(frozen_graph_path))\n\n            graph_path = frozen_graph_path\n\n        if do_optimize:\n            print(\'Optimizing graph...\')\n            input_graph_def = tf.GraphDef()\n\n            with tf.gfile.Open(graph_path, \'rb\') as f:\n                data = f.read()\n                input_graph_def.ParseFromString(data)\n\n                output_graph_def =\\\n                    optimize_for_inference_lib.optimize_for_inference(\n                        input_graph_def,\n                        [input_node_name],\n                        [output_node_name],\n                        tf.float32.as_datatype_enum)\n\n                f = tf.gfile.FastGFile(optimized_graph_path, \'wb\')\n                f.write(output_graph_def.SerializeToString())\n\n                print(\'Optimized graph exported to {}\'\n                      .format(optimized_graph_path))\n'"
tools/export_savedmodel.py,2,"b'import os\nimport sys\nimport argparse\n\nimport tensorflow as tf\nfrom tensorflow.python.saved_model import builder as saved_model_builder\nfrom tensorflow.python.saved_model.signature_def_utils\\\n    import predict_signature_def\n\nfrom tensorflow.python.saved_model.tag_constants import SERVING\nfrom tensorflow.python.saved_model.signature_constants\\\n    import DEFAULT_SERVING_SIGNATURE_DEF_KEY\n\nfrom tensorflow.python.saved_model.signature_constants import PREDICT_INPUTS\nfrom tensorflow.python.saved_model.signature_constants import PREDICT_OUTPUTS\n\nsys.path.append((os.path.normpath(\n                 os.path.join(os.path.dirname(os.path.realpath(__file__)),\n                              \'..\'))))\n\nfrom model import OpenNsfwModel, InputType\n\n""""""Builds a SavedModel which can be used for deployment with\ngcloud ml-engine, tensorflow-serving, ...\n""""""\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""target"", help=""output directory"")\n\n    parser.add_argument(""-i"", ""--input_type"", required=True,\n                        default=InputType.TENSOR.name.lower(),\n                        help=""Input type"",\n                        choices=[InputType.TENSOR.name.lower(),\n                                 InputType.BASE64_JPEG.name.lower()])\n\n    parser.add_argument(""-v"", ""--export_version"",\n                        help=""export model version"",\n                        default=""1"")\n\n    parser.add_argument(""-m"", ""--model_weights"", required=True,\n                        help=""Path to trained model weights file"")\n\n    args = parser.parse_args()\n\n    model = OpenNsfwModel()\n\n    export_base_path = args.target\n    export_version = args.export_version\n    input_type = InputType[args.input_type.upper()]\n\n    export_path = os.path.join(export_base_path, export_version)\n\n    with tf.Session() as sess:\n        model.build(weights_path=args.model_weights,\n                    input_type=input_type)\n\n        sess.run(tf.global_variables_initializer())\n\n        builder = saved_model_builder.SavedModelBuilder(export_path)\n\n        builder.add_meta_graph_and_variables(\n            sess, [SERVING],\n            signature_def_map={\n                DEFAULT_SERVING_SIGNATURE_DEF_KEY: predict_signature_def(\n                    inputs={PREDICT_INPUTS: model.input},\n                    outputs={PREDICT_OUTPUTS: model.predictions}\n                )\n            }\n        )\n\n        builder.save()\n'"
tools/export_tflite.py,3,"b'import os\nimport sys\nimport argparse\n\nimport tensorflow as tf\n\nsys.path.append((os.path.normpath(\n                 os.path.join(os.path.dirname(os.path.realpath(__file__)),\n                              \'..\'))))\n\nfrom model import OpenNsfwModel, InputType\n\n""""""Exports a tflite version of tensorflow-open_nsfw\n\nNote: The standard TFLite runtime does not support all required ops when using the base64_jpeg input type.\nYou will have to implement the missing ones by yourself.\n""""""\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""target"", help=""output filename, e.g. \'open_nsfw.tflite\'"")\n\n    parser.add_argument(""-i"", ""--input_type"", required=True,\n                        default=InputType.TENSOR.name.lower(),\n                        help=""Input type. Warning: base64_jpeg does not work with the standard TFLite runtime since a lot of operations are not supported"",\n                        choices=[InputType.TENSOR.name.lower(),\n                                 InputType.BASE64_JPEG.name.lower()])\n\n    parser.add_argument(""-m"", ""--model_weights"", required=True,\n                        help=""Path to trained model weights file"")\n\n    args = parser.parse_args()\n\n    model = OpenNsfwModel()\n\n    export_path = args.target\n    input_type = InputType[args.input_type.upper()]\n\n    with tf.Session() as sess:\n        model.build(weights_path=args.model_weights,\n                    input_type=input_type)\n\n        sess.run(tf.global_variables_initializer())\n\n        converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [model.input], [model.predictions])\n        tflite_model = converter.convert()\n\n        with open(export_path, ""wb"") as f:\n            f.write(tflite_model)\n'"
