file_path,api_count,code
bottleneck.py,0,"b'import keras.backend as K\nimport numpy as np\n\n\nclass Bottleneck:\n    def __init__(self, model, layer):\n        self.fn = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output])\n\n    def predict(self, data_x, batch_size=32, learning_phase=False):\n        n_data = len(data_x)\n        n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n\n        result = None\n\n        learning_phase = 1 if learning_phase else 0\n\n        for i in range(n_batches):\n            batch_x = data_x[i * batch_size:(i + 1) * batch_size]\n            batch_y = self.fn([batch_x, 0])[0]\n\n            if result is None:\n                result = batch_y\n            else:\n                result = np.vstack([result, batch_y])\n\n        return result\n'"
cnn.py,0,"b""from keras.layers import Flatten, Dense, Dropout\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.layers.advanced_activations import PReLU\n\nfrom keras.models import Sequential\n\n\ndef build_cnn(dim, n_classes):\n    model = Sequential()\n\n    model.add(Convolution2D(96, 11, 11,\n                            subsample=(4, 4),\n                            input_shape=(dim, dim, 3),\n                            init='glorot_uniform',\n                            border_mode='same'))\n    model.add(PReLU())\n    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n\n    model.add(Convolution2D(256, 5, 5,\n                            subsample=(1, 1),\n                            init='glorot_uniform',\n                            border_mode='same'))\n    model.add(PReLU())\n    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n\n    model.add(Convolution2D(384, 3, 3,\n                            subsample=(1, 1),\n                            init='glorot_uniform',\n                            border_mode='same'))\n    model.add(PReLU())\n\n    model.add(Convolution2D(384, 3, 3,\n                            subsample=(1, 1),\n                            init='glorot_uniform',\n                            border_mode='same'))\n    model.add(PReLU())\n\n    model.add(Convolution2D(256, 3, 3,\n                            subsample=(1, 1),\n                            init='glorot_uniform',\n                            border_mode='same'))\n    model.add(PReLU())\n    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(2048, init='glorot_uniform'))\n    model.add(PReLU())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(256, init='glorot_uniform'))\n    model.add(PReLU())\n\n    model.add(Dense(n_classes, init='glorot_uniform', activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return model\n"""
demo_app0.py,0,"b""from model import FaceVerificator\nfrom skimage import io\n\n###\nimg_path_0 = '/home/egor/1.jpg'\nimg_path_1 = '/home/egor/2.jpg'\ndist = 0.85\n###\n\nfv = FaceVerificator('./model')\nfv.initialize_model()\n\nimg_0 = io.imread(img_path_0)\nimg_1 = io.imread(img_path_1)\n\nfaces_0 = fv.process_image(img_0)\nfaces_1 = fv.process_image(img_1)\n\nn_faces_0 = len(faces_0)\nn_faces_1 = len(faces_1)\n\nif n_faces_0 == 0 or n_faces_1 == 0:\n    print('Error: No faces found on the {}!'.format(img_path_0 if n_faces_0 == 0 else img_path_1))\n    exit()\n\nrects_0 = list(map(lambda p: p[0], faces_0))\nrects_1 = list(map(lambda p: p[0], faces_1))\n\nembs_0 = list(map(lambda p: p[1], faces_0))\nembs_1 = list(map(lambda p: p[1], faces_1))\n\nscores, comps = fv.compare_many(dist, embs_0, embs_1)\n\nprint('Rects on image 0: {}'.format(rects_0))\nprint('Rects on image 1: {}'.format(rects_1))\n\n# print('Embeddings of faces on image 0:')\n# print(embs_0)\n#\n# print('Embeddings of faces on image 1:')\n# print(embs_1)\n\nprint('Score matrix:')\nprint(scores)\n\nprint('Decision matrix :')\nprint(comps)\n"""
demo_app1.py,0,"b""import sys\nimport os.path\nimport random\n\nimport numpy as np\n\nfrom PyQt5.QtWidgets import (\n    QWidget,\n    QPushButton,\n    QApplication,\n    QHBoxLayout,\n    QVBoxLayout,\n    QFileDialog,\n    QMessageBox,\n    QLabel,\n    QTableWidget,\n    QTableWidgetItem,\n    QDialog)\nfrom PyQt5.QtGui import QPixmap, QPainter, QBrush, QPen, QColor, QFont\nfrom PyQt5.QtCore import QCoreApplication, Qt\n\nfrom skimage import io\n\nfrom model import FaceVerificator\n\n\nIMWIDTH = 600\nIMHEIGHT = 600\nBASECOLOR = QColor('yellow')\nTEXTCOLOR = QColor('yellow')\nBASEWIDTH = 2.0\nBOXSIZE = 227\nTEXTWIDTH = 2.0\nTEXTSIZE = 16\nTEXTFONT = QFont('Sans', TEXTSIZE)\nMATCHBACKCOLOR = QColor('cyan')\n\n\nclass TablePopup(QDialog):\n    def __init__(self, scores, comp):\n        super().__init__()\n        self.initUI(scores, comp)\n        self.setAttribute(Qt.WA_DeleteOnClose)\n\n    def initUI(self, scores, comp):\n        layout = QVBoxLayout(self)\n        rows, cols = scores.shape\n        table = QTableWidget(rows, cols)\n        layout.addWidget(table)\n\n        for i in range(rows):\n            for j in range(cols):\n                item = QTableWidgetItem('{:.3f}'.format(scores[i, j]))\n                if comp[i, j]:\n                    item.setBackground(MATCHBACKCOLOR)\n                table.setItem(i, j, item)\n\n        hh = list(map(lambda s: '2: {}'.format(s), range(cols)))\n        vh = list(map(lambda s: '1: {}'.format(s), range(rows)))\n\n        table.setHorizontalHeaderLabels(hh)\n        table.setVerticalHeaderLabels(vh)\n\n        self.setLayout(layout)\n        self.setWindowTitle('Scores table')\n        self.show()\n\n\nclass Main(QWidget):\n    def __init__(self):\n        super().__init__()\n\n        self.i_loaded = [False, False]\n        self.i_path = [None, None]\n        self.i_np = [None, None]\n        self.i_scale = [1.0, 1.0]\n        self.i_pixmap = [None, None]\n        self.i_lbl = [None, None]\n\n        self.dist = 0.85\n\n        self.matched = False\n\n        self.fv = FaceVerificator('./model')\n        self.fv.initialize_model()\n\n        self.initUI()\n\n    def initUI(self):\n        self.setGeometry(300, 300, 1280, 720)\n        self.setWindowTitle('Face verification demo 1')\n\n        self.l1_btn = QPushButton('Load 1...')\n        self.l2_btn = QPushButton('Load 2...')\n\n        self.match_btn = QPushButton('Match')\n        self.exit_btn = QPushButton('Exit')\n\n        self.i_lbl[0] = QLabel()\n        self.i_lbl[1] = QLabel()\n\n        self.exit_btn.clicked.connect(QCoreApplication.instance().quit)\n        self.l1_btn.clicked.connect(self.l1_clicked)\n        self.l2_btn.clicked.connect(self.l2_clicked)\n        self.match_btn.clicked.connect(self.match_clicked)\n\n        hbox = QHBoxLayout()\n        hbox.addWidget(self.l1_btn)\n        hbox.addWidget(self.l2_btn)\n        hbox.addStretch(1)\n        hbox.addWidget(self.match_btn)\n        hbox.addStretch(1)\n        hbox.addWidget(self.exit_btn)\n\n        hbox2 = QHBoxLayout()\n        hbox2.addWidget(self.i_lbl[0])\n        hbox2.addStretch(1)\n        hbox2.addWidget(self.i_lbl[1])\n\n        vbox = QVBoxLayout()\n        vbox.addStretch(1)\n        vbox.addLayout(hbox2)\n        vbox.addStretch(1)\n        vbox.addLayout(hbox)\n\n        self.setLayout(vbox)\n\n        self.show()\n\n    def image_file_dialog(self):\n        return QFileDialog().getOpenFileName(self,\n                                             'Single File',\n                                             './',\n                                             'Image files (*.jpg *.jpeg *.png)')[0]\n\n    def load_img_to(self, img_path, n):\n        pixmap = QPixmap(img_path)\n\n        scale = 1\n        if pixmap.width() > IMWIDTH:\n            scale = IMWIDTH / pixmap.width()\n        if pixmap.height() > IMHEIGHT:\n            scale = IMHEIGHT / pixmap.height()\n\n        if scale != 1:\n            neww = pixmap.width() * scale\n            newh = pixmap.height() * scale\n            pixmap = pixmap.scaled(neww, newh)\n\n        self.i_scale[n] = scale\n\n        self.i_pixmap[n] = pixmap\n        self.i_lbl[n].setPixmap(pixmap)\n        self.i_lbl[n].show()\n\n    def ln_clicked(self, n):\n        img_path = self.image_file_dialog()\n\n        if (img_path is None) or (not os.path.exists(img_path)):\n            return\n\n        self.i_path[n] = img_path\n        self.i_loaded[n] = True\n        self.i_np[n] = io.imread(img_path)\n        self.load_img_to(img_path, n)\n\n        if n == 0 and self.i_loaded[1]:\n            self.load_img_to(self.i_path[1], 1)\n        elif n == 1 and self.i_loaded[0]:\n            self.load_img_to(self.i_path[0], 0)\n\n        self.matched = False\n\n    def l1_clicked(self):\n        self.ln_clicked(0)\n\n    def l2_clicked(self):\n        self.ln_clicked(1)\n\n    def match_clicked(self):\n        if self.matched:\n            return\n\n        if not (self.i_loaded[0] and self.i_loaded[1]):\n            msg = QMessageBox()\n            msg.setIcon(QMessageBox.Critical)\n            msg.setText('Load both images!')\n            msg.setWindowTitle('Error')\n            msg.exec_()\n            return\n\n        self.do_vodo_magic()\n\n    def no_faces_on_err(self, n):\n        msg = QMessageBox()\n        msg.setIcon(QMessageBox.Critical)\n        msg.setText('No faces found on image {}'.format(n))\n        msg.setWindowTitle('Error')\n        msg.exec_()\n        return\n\n    def generate_color(self):\n        return QColor(random.randint(0, 255),\n                      random.randint(0, 255),\n                      random.randint(0, 255))\n\n    def draw_box(self, n, box, color, style, num):\n        x1, y1, x2, y2 = box.left(), box.top(), box.right(), box.bottom()\n\n        x1 = int(x1 * self.i_scale[n])\n        y1 = int(y1 * self.i_scale[n])\n        x2 = int(x2 * self.i_scale[n])\n        y2 = int(y2 * self.i_scale[n])\n\n        width = BASEWIDTH\n        if style == 'match':\n            width *= 2\n\n        painter = QPainter(self.i_pixmap[n])\n        painter.setPen(QPen(QBrush(color), width))\n        painter.drawRect(x1, y1, x2 - x1, y2 - y1)\n        painter.setPen(QPen(QBrush(TEXTCOLOR), TEXTWIDTH))\n        painter.setFont(TEXTFONT)\n        painter.drawText(x1, y2 + TEXTSIZE + 2 * BASEWIDTH, '{}: {}'.format(n + 1, num))\n        painter.end()\n        self.i_lbl[n].setPixmap(self.i_pixmap[n])\n\n    def do_vodo_magic(self):\n        faces_0 = self.fv.process_image(self.i_np[0])\n        faces_1 = self.fv.process_image(self.i_np[1])\n\n        n_faces_0 = len(faces_0)\n        n_faces_1 = len(faces_1)\n\n        if n_faces_0 == 0:\n            self.no_faces_on_err(1)\n            return\n\n        if n_faces_1 == 0:\n            self.no_faces_on_err(2)\n            return\n\n        rects_0 = list(map(lambda p: p[0], faces_0))\n        rects_1 = list(map(lambda p: p[0], faces_1))\n\n        embs_0 = list(map(lambda p: p[1], faces_0))\n        embs_1 = list(map(lambda p: p[1], faces_1))\n\n        scores, comps = self.fv.compare_many(self.dist, embs_0, embs_1)\n\n        drawn_1 = [False] * n_faces_1\n\n        for i in range(n_faces_0):\n            color = BASECOLOR\n            style = 'base'\n\n            k = np.argmax(scores[i])\n            if comps[i, k]:\n                color = self.generate_color()\n                style = 'match'\n                drawn_1[k] = True\n                self.draw_box(1, rects_1[k], color, style, k)\n\n            self.draw_box(0, rects_0[i], color, style, i)\n\n        color = BASECOLOR\n        for j in range(n_faces_1):\n            if not drawn_1[j]:\n                self.draw_box(1, rects_1[j], color, 'base', j)\n\n        tbl = TablePopup(scores, comps)\n        tbl.exec_()\n\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    ex = Main()\n    sys.exit(app.exec_())\n"""
identification.py,0,"b""import numpy as np\n\n\ndef get_scores(data_y, protocol):\n    data_y = data_y / np.linalg.norm(data_y, axis=1)[:, np.newaxis]\n    scores = data_y @ data_y.T\n\n    return scores[protocol], scores[np.logical_not(protocol)]\n\n\ndef calc_metrics(targets_scores, imposter_scores):\n    min_score = np.minimum(np.min(targets_scores), np.min(imposter_scores))\n    max_score = np.maximum(np.max(targets_scores), np.max(imposter_scores))\n\n    n_tars = len(targets_scores)\n    n_imps = len(imposter_scores)\n\n    N = 100\n\n    fars = np.zeros((N,))\n    frrs = np.zeros((N,))\n    dists = np.zeros((N,))\n\n    min_gap = float('inf')\n    eer = 0\n\n    for i, dist in enumerate(np.linspace(min_score, max_score, N)):\n        far = len(np.where(imposter_scores > dist)[0]) / n_imps\n        frr = len(np.where(targets_scores < dist)[0]) / n_tars\n        fars[i] = far\n        frrs[i] = frr\n        dists[i] = dist\n\n        gap = np.abs(far - frr)\n\n        if gap < min_gap:\n            min_gap = gap\n            eer = (far + frr) / 2\n\n    return eer, fars, frrs, dists\n"""
model.py,0,"b""import os.path\n\nimport numpy as np\n\nfrom preprocessing import FaceDetector, FaceAligner, clip_to_range\nfrom cnn import build_cnn\nfrom tpe import build_tpe\nfrom bottleneck import Bottleneck\n\n\nGREATER_THAN = 32\nBATCH_SIZE = 128\nIMSIZE = 217\nIMBORDER = 5\n\n\nclass FaceVerificatorError (Exception):\n    pass\n\n\nclass FileNotFoundError (FaceVerificatorError):\n    pass\n\n\nclass FaceVerificator:\n    def __init__(self, model_dir):\n        self._model_dir = model_dir\n\n        self._model_files = {\n            'shape_predictor': os.path.join(model_dir, 'shape_predictor_68_face_landmarks.dat'),\n            'face_template': os.path.join(model_dir, 'face_template.npy'),\n            'mean': os.path.join(model_dir, 'mean.npy'),\n            'stddev': os.path.join(model_dir, 'stddev.npy'),\n            'cnn_weights': os.path.join(model_dir, 'weights_cnn.h5'),\n            'tpe_weights': os.path.join(model_dir, 'weights_tpe.h5'),\n        }\n\n        for model_file in self._model_files.values():\n            if not os.path.exists(model_file):\n                raise FileNotFoundError(model_file)\n\n    def initialize_model(self):\n        self._mean = np.load(self._model_files['mean'])\n        self._stddev = np.load(self._model_files['stddev'])\n        self._fd = FaceDetector()\n        self._fa = FaceAligner(self._model_files['shape_predictor'],\n                               self._model_files['face_template'])\n        cnn = build_cnn(227, 266)\n        cnn.load_weights(self._model_files['cnn_weights'])\n        self._cnn = Bottleneck(cnn, ~1)\n        _, tpe = build_tpe(256, 256)\n        tpe.load_weights(self._model_files['tpe_weights'])\n        self._tpe = tpe\n\n    def normalize(self, img):\n        img = clip_to_range(img)\n        return (img - self._mean) / self._stddev\n\n    def process_image(self, img):\n        face_rects = self._fd.detect_faces(img, upscale_factor=2, greater_than=GREATER_THAN)\n\n        if not face_rects:\n            return []\n\n        faces = self._fa.align_faces(img, face_rects, dim=IMSIZE, border=IMBORDER)\n        faces = list(map(self.normalize, faces))\n\n        faces_y = self._cnn.predict(faces, batch_size=BATCH_SIZE)\n        faces_y = self._tpe.predict(faces_y, batch_size=BATCH_SIZE)\n\n        return list(zip(face_rects, faces_y))\n\n    def compare_many(self, dist, xs, ys):\n        xs = np.array(xs)\n        ys = np.array(ys)\n        scores = xs @ ys.T\n        return scores, scores > dist\n"""
preprocessing.py,0,"b""import dlib\n\nimport numpy as np\nimport skimage.transform as tr\n\nfrom enum import Enum\n\n\nclass FaceDetectorException (Exception):\n    pass\n\n\nclass FaceDetector:\n    def __init__(self):\n        self.detector = dlib.get_frontal_face_detector()\n\n    def detect_faces(self,\n                     image, *,\n                     upscale_factor=1,\n                     greater_than=None,\n                     get_top=None):\n        try:\n            face_rects = list(self.detector(image, upscale_factor))\n        except Exception as e:\n            raise FaceDetectorException(e.args)\n\n        if greater_than is not None:\n            face_rects = list(filter(lambda r:\n                              r.height() > greater_than and r.width() > greater_than,\n                              face_rects))\n\n        face_rects.sort(key=lambda r: r.width() * r.height(), reverse=True)\n\n        if get_top is not None:\n            face_rects = face_rects[:get_top]\n\n        return face_rects\n\n\nclass FaceAlignMask(Enum):\n    INNER_EYES_AND_BOTTOM_LIP = [39, 42, 57]\n    OUTER_EYES_AND_NOSE = [36, 45, 33]\n\n\nclass FaceAligner:\n    def __init__(self,\n                 dlib_predictor_path,\n                 face_template_path):\n        self.predictor = dlib.shape_predictor(dlib_predictor_path)\n        self.face_template = np.load(face_template_path)\n\n    def get_landmarks(self,\n                      image,\n                      face_rect):\n        points = self.predictor(image, face_rect)\n        return np.array(list(map(lambda p: [p.x, p.y], points.parts())))\n\n    def align_face(self,\n                   image,\n                   face_rect, *,\n                   dim=96,\n                   border=0,\n                   mask=FaceAlignMask.INNER_EYES_AND_BOTTOM_LIP):\n        mask = np.array(mask.value)\n\n        landmarks = self.get_landmarks(image, face_rect)\n        proper_landmarks = border + dim * self.face_template[mask]\n        A = np.hstack([landmarks[mask], np.ones((3, 1))]).astype(np.float64)\n        B = np.hstack([proper_landmarks, np.ones((3, 1))]).astype(np.float64)\n        T = np.linalg.solve(A, B).T\n\n        wrapped = tr.warp(image,\n                          tr.AffineTransform(T).inverse,\n                          output_shape=(dim + 2 * border, dim + 2 * border),\n                          order=3,\n                          mode='constant',\n                          cval=0,\n                          clip=True,\n                          preserve_range=True)\n\n        return wrapped\n\n    def align_faces(self,\n                    image,\n                    face_rects,\n                    *args,\n                    **kwargs):\n        result = []\n\n        for rect in face_rects:\n            result.append(self.align_face(image, rect, *args, **kwargs))\n\n        return result\n\n\ndef clip_to_range(img):\n    return img / 255.0\n"""
test_cnn.py,0,"b""import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom cnn import build_cnn\nfrom bottleneck import Bottleneck\n\nfrom identification import get_scores, calc_metrics\n\nWEIGHTS_DIR = './data/weights/'\n\nBATCH_SIZE = 32\n\ndev_x = np.load('data/dev_x.npy')\n\nmodel = build_cnn(227, 266)\n\nweights_to_load = WEIGHTS_DIR + 'weights.best.h5'\nmodel.load_weights(weights_to_load)\n\nbottleneck = Bottleneck(model, ~1)\ndev_y = bottleneck.predict(dev_x, batch_size=BATCH_SIZE)\n\nprotocol = np.load('data/dev_protocol.npy')\ntsc, isc = get_scores(dev_y, protocol)\neer, fars, frrs, dists = calc_metrics(tsc, isc)\n\nprint('EER: {}'.format(eer * 100))\n\nplt.figure()\nplt.hist(tsc, 20, color='g', normed=True, alpha=0.3)\nplt.hist(isc, 20, color='r', normed=True, alpha=0.3)\n\nplt.figure()\nplt.loglog(fars, frrs)\nplt.show()\n"""
test_tpe.py,0,"b""import numpy as np\n\nfrom cnn import build_cnn\nfrom tpe import build_tpe\nfrom bottleneck import Bottleneck\nfrom identification import get_scores, calc_metrics\n\nimport matplotlib.pyplot as plt\n\nn_in = 256\nn_out = 256\n\ncnn = build_cnn(227, 266)\ncnn.load_weights('data/weights/weights.best.h5')\nbottleneck = Bottleneck(cnn, ~1)\n\ntrain_x, train_y = np.load('./data/train_x.npy'), np.load('./data/train_y.npy')\ndev_x = np.load('./data/dev_x.npy')\ndev_protocol = np.load('./data/dev_protocol.npy')\n\ntrain_emb = bottleneck.predict(train_x, batch_size=256)\ndev_emb = bottleneck.predict(dev_x, batch_size=256)\n\ndel train_x\n\n# pca = PCA(n_out)\n# pca.fit(train_emb)\n# W_pca = pca.components_\n# print(W_pca.shape)\n# np.save('data/w_pca', W_pca)\n\nW_pca = np.load('data/w_pca.npy')\n\ntpe, tpe_pred = build_tpe(n_in, n_out, W_pca.T)\n\ntrain_y = np.array(train_y)\nsubjects = list(set(train_y))\n\ntpe.load_weights('data/weights/weights.tpe.mineer.h5')\n\ndev_emb2 = tpe_pred.predict(dev_emb)\n\nprotocol = np.load('data/dev_protocol.npy')\ntsc, isc = get_scores(dev_emb2, protocol)\neer, fars, frrs, dists = calc_metrics(tsc, isc)\n\nprint('EER: {}'.format(eer * 100))\n\nplt.figure()\nplt.hist(tsc, 20, color='g', normed=True, alpha=0.3)\nplt.hist(isc, 20, color='r', normed=True, alpha=0.3)\n\nplt.figure()\nplt.loglog(fars, frrs)\nplt.show()\n\nfor a, b, c in zip(fars, frrs, dists):\n    print('a: {:.2f} | r: {:.2f} | d: {:.2f}'.format(a, b, c))\n"""
tpe.py,0,"b""from keras.layers import Dense, Lambda, Input, merge\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import SGD\n\nimport keras.backend as K\n\nimport numpy as np\n\n\ndef triplet_loss(y_true, y_pred):\n    return -K.mean(K.log(K.sigmoid(y_pred)))\n\n\ndef triplet_merge(inputs):\n    a, p, n = inputs\n\n    return K.sum(a * (p - n), axis=1)\n\n\ndef triplet_merge_shape(input_shapes):\n    return (input_shapes[0][0], 1)\n\n\ndef build_tpe(n_in, n_out, W_pca=None):\n    a = Input(shape=(n_in,))\n    p = Input(shape=(n_in,))\n    n = Input(shape=(n_in,))\n\n    if W_pca is None:\n        W_pca = np.zeros((n_in, n_out))\n\n    base_model = Sequential()\n    base_model.add(Dense(n_out, input_dim=n_in, bias=False, weights=[W_pca], activation='linear'))\n    base_model.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n\n    # base_model = Sequential()\n    # base_model.add(Dense(178, input_dim=n_in, bias=True, activation='relu'))\n    # base_model.add(Dense(n_out, bias=True, activation='tanh'))\n    # base_model.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n\n    a_emb = base_model(a)\n    p_emb = base_model(p)\n    n_emb = base_model(n)\n\n    e = merge([a_emb, p_emb, n_emb], mode=triplet_merge, output_shape=triplet_merge_shape)\n\n    model = Model(input=[a, p, n], output=e)\n    predict = Model(input=a, output=a_emb)\n\n    model.compile(loss=triplet_loss, optimizer='rmsprop')\n\n    return model, predict\n"""
train_cnn.py,0,"b""import os.path\n\nimport numpy as np\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import OneHotEncoder\nfrom cnn import build_cnn\n\n\nWEIGHTS_DIR = './data/weights/'\n\nNB_EPOCH = 1024\nBATCH_SIZE = 32\n\nAUGMENTATION = True\n\n\noh = OneHotEncoder()\n\ntrain_x, train_y = np.load('./data/train_x.npy'), np.load('./data/train_y.npy')\ntest_x, test_y = np.load('./data/test_x.npy'), np.load('./data/test_y.npy')\n\nn_subjects = len(set(train_y))\nn_train = train_x.shape[0]\nn_test = test_x.shape[0]\n\noh.fit(train_y.reshape(-1, 1))\n\ntrain_y = oh.transform(train_y.reshape(-1, 1)).todense()\ntest_y = oh.transform(test_y.reshape(-1, 1)).todense()\n\nprint('n_train: {}'.format(n_train))\nprint('n_test: {}'.format(n_test))\nprint('n_subjects: {}'.format(n_subjects))\n\nmc1 = ModelCheckpoint(WEIGHTS_DIR + 'weights.best.h5', monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n\nif AUGMENTATION:\n    datagen = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        zoom_range=0.1,\n        horizontal_flip=True)\n\nmodel = build_cnn(227, n_subjects)\nmodel.summary()\n\nweights_to_load = WEIGHTS_DIR + 'weights.best.h5'\n\nif os.path.exists(weights_to_load):\n    model.load_weights(weights_to_load)\n\ntry:\n    if AUGMENTATION:\n        model.fit_generator(datagen.flow(train_x, train_y, batch_size=BATCH_SIZE),\n                            samples_per_epoch=train_x.shape[0],\n                            nb_epoch=NB_EPOCH,\n                            validation_data=[test_x, test_y],\n                            callbacks=[mc1])\n    else:\n        model.fit(train_x, train_y,\n                  batch_size=BATCH_SIZE,\n                  nb_epoch=NB_EPOCH,\n                  validation_data=[test_x, test_y],\n                  callbacks=[mc1])\nfinally:\n    model.save_weights(WEIGHTS_DIR + 'weights.finally.h5')\n"""
train_tpe.py,0,"b""import itertools\n\nimport numpy as np\n\nfrom cnn import build_cnn\nfrom tpe import build_tpe\nfrom bottleneck import Bottleneck\nfrom identification import get_scores, calc_metrics\n\nfrom sklearn.decomposition import PCA\n\nn_in = 256\nn_out = 256\n\n\ncnn = build_cnn(227, 266)\ncnn.load_weights('data/weights/weights.best.h5')\nbottleneck = Bottleneck(cnn, ~1)\n\ntrain_x, train_y = np.load('./data/train_x.npy'), np.load('./data/train_y.npy')\ntest_x, test_y = np.load('./data/test_x.npy'), np.load('./data/test_y.npy')\n\ntrain_x = np.vstack([train_x, test_x])\ntrain_y = np.hstack([train_y, test_y])\n\ndev_x = np.load('./data/dev_x.npy')\ndev_protocol = np.load('./data/dev_protocol.npy')\n\ntrain_emb = bottleneck.predict(train_x, batch_size=256)\ndev_emb = bottleneck.predict(dev_x, batch_size=256)\n\ndel train_x\n\npca = PCA(n_out)\npca.fit(train_emb)\nW_pca = pca.components_\n\ntpe, tpe_pred = build_tpe(n_in, n_out, W_pca.T)\n# tpe.load_weights('data/weights/weights.tpe.mineer.h5')\n\ntrain_y = np.array(train_y)\nsubjects = list(set(train_y))\n\nanchors_inds = []\npositives_inds = []\nlabels = []\n\nfor subj in subjects:\n    mask = train_y == subj\n    inds = np.where(mask)[0]\n    for a, p in itertools.permutations(inds, 2):\n        anchors_inds.append(a)\n        positives_inds.append(p)\n        labels.append(subj)\n\nanchors = train_emb[anchors_inds]\npositives = train_emb[positives_inds]\nn_anchors = len(anchors_inds)\n\n\nNB_EPOCH = 5000\nCOLD_START = NB_EPOCH\nBATCH_SIZE = 4\nBIG_BATCH_SIZE = 512\n\n\ninds = np.arange(n_anchors)\n\n\ndef get_batch(hard=False):\n    batch_inds = np.random.choice(inds, size=BIG_BATCH_SIZE, replace=False)\n\n    train_emb2 = tpe_pred.predict(train_emb, batch_size=1024)\n    scores = train_emb2 @ train_emb2.T\n    negative_inds = []\n\n    for i in batch_inds:\n        label = labels[i]\n        mask = train_y == label\n        if hard:\n            negative_inds.append(np.ma.array(scores[label], mask=mask).argmax())\n        else:\n            negative_inds.append(np.random.choice(np.where(np.logical_not(mask))[0], size=1)[0])\n\n    return anchors[batch_inds], positives[batch_inds], train_emb[negative_inds]\n\n\ndef test():\n    dev_emb2 = tpe_pred.predict(dev_emb)\n    tsc, isc = get_scores(dev_emb2, dev_protocol)\n    eer, _, _, _ = calc_metrics(tsc, isc)\n    return eer\n\n\nz = np.zeros((BIG_BATCH_SIZE,))\n\nmineer = float('inf')\n\nfor e in range(NB_EPOCH):\n    print('epoch: {}'.format(e))\n    a, p, n = get_batch(e > COLD_START)\n    tpe.fit([a, p, n], z, batch_size=BATCH_SIZE, nb_epoch=1)\n    eer = test()\n    print('EER: {:.2f}'.format(eer * 100))\n    if eer < mineer:\n        mineer = eer\n        tpe.save_weights('data/weights/weights.tpe.mineer.h5')\n"""
utils/load_data.py,0,"b""import os\nimport os.path\n\nimport numpy as np\n\nfrom skimage import io\nfrom preprocessing import FaceDetector, FaceAligner, clip_to_range\nfrom tqdm import tqdm\nfrom itertools import repeat\n\nfd = FaceDetector()\nfa = FaceAligner('../model/shape_predictor_68_face_landmarks.dat', '../model/face_template.npy')\n\nIMAGE_FORMATS = {'.jpg', '.jpeg', '.png'}\n\n\ndef get_images(path):\n    return list(filter(lambda s: os.path.isfile(os.path.join(path, s)) and os.path.splitext(s)[1] in IMAGE_FORMATS, os.listdir(path)))\n\n\ndef get_folders(path):\n    return list(filter(lambda s: os.path.isdir(os.path.join(path, s)), os.listdir(path)))\n\n\ndef list_data(data_path):\n    train_dir = os.path.join(data_path, 'train')\n    test_dir = os.path.join(data_path, 'test')\n    dev_dir = os.path.join(data_path, 'dev')\n\n    train = []\n    test = []\n    subjects = get_folders(train_dir)\n    subjects.sort()\n\n    for subj in subjects:\n        subj_train_dir = os.path.join(train_dir, subj)\n        subj_test_dir = os.path.join(test_dir, subj)\n\n        train_files = get_images(os.path.join(train_dir, subj))\n        test_files = get_images(os.path.join(test_dir, subj))\n\n        train_files.sort()\n        test_files.sort()\n\n        train_files = list(map(lambda s: os.path.join(subj_train_dir, s), train_files))\n        test_files = list(map(lambda s: os.path.join(subj_test_dir, s), test_files))\n\n        subj = int(subj.split('_')[1])\n\n        train.extend(zip(train_files, repeat(subj)))\n        test.extend(zip(test_files, repeat(subj)))\n\n    dev = get_images(dev_dir)\n    dev.sort(key=lambda s: int(os.path.splitext(s)[0]))\n    dev = list(map(lambda s: os.path.join(dev_dir, s), dev))\n    dev = list(zip(dev, repeat(-1)))\n\n    return train, test, dev\n\n\ndef load_file(filename, imsize=96, border=0):\n    total_size = imsize + 2 * border\n\n    img = io.imread(filename)\n    faces = fd.detect_faces(img, get_top=1)\n\n    if len(faces) == 0:\n        return None\n\n    face = fa.align_face(img, faces[0], dim=imsize, border=border).reshape(1, total_size, total_size, 3)\n    face = clip_to_range(face)\n\n    del img\n\n    return face.astype(np.float32)\n\n\ndef load_data(data, not_found_policy='throw_away', available_subjects=None, imsize=96, border=0):\n    n_data = len(data)\n\n    total_size = imsize + 2 * border\n\n    images = np.zeros((n_data, total_size, total_size, 3), dtype=np.float32)\n    labels = np.zeros((n_data,), dtype=np.int)\n\n    if available_subjects is not None:\n        available_subjects = set(available_subjects)\n\n    black = np.zeros((1, total_size, total_size, 3), dtype=np.float32)\n\n    face_not_found_on = []\n\n    img_ptr = 0\n    for filename, subject in tqdm(data):\n        if available_subjects is not None:\n            if subject not in available_subjects:\n                continue\n\n        face_img = load_file(filename, imsize=imsize, border=border)\n\n        if face_img is None:\n            face_not_found_on.append(filename)\n            if not_found_policy == 'throw_away':\n                continue\n            elif not_found_policy == 'replace_black':\n                face_img = black\n            else:\n                raise Exception('Face not found on {}'.format(filename))\n\n        images[img_ptr] = face_img\n        labels[img_ptr] = subject\n        img_ptr += 1\n\n    images = images[:img_ptr]\n    labels = labels[:img_ptr]\n\n    if len(face_not_found_on) > 0:\n        print('[Warning] Faces was not found on:')\n        for f in face_not_found_on:\n            print(' - {}'.format(f))\n\n    return images, labels\n\n\nIMSIZE = 217\nBORDER = 5\n\n\ntrain, test, dev = list_data('../data')\n\n###\nprint('Loading train files...')\ntrain_x, train_y = load_data(train, imsize=IMSIZE, border=BORDER, not_found_policy='throw_away')\n\ndel train\n\nmean = train_x.mean(axis=0)\nstddev = train_x.std(axis=0)\n\nnp.save('../model/mean', mean)\nnp.save('../model/stddev', stddev)\n\ntrain_x -= mean\ntrain_x /= stddev\n\nnp.save('../data/train_x', train_x)\nnp.save('../data/train_y', train_y)\n###\n\ndel train_x\n\n###\nprint('Loading test files...')\ntest_x, test_y = load_data(test, imsize=IMSIZE, border=BORDER, not_found_policy='throw_away', available_subjects=train_y)\n\ndel test, train_y\n\ntest_x -= mean\ntest_x /= stddev\n\nnp.save('../data/test_x', test_x)\nnp.save('../data/test_y', test_y)\n###\n\ndel test_x, test_y\n\n###\nprint('Loading dev files...')\ndev_x, _ = load_data(dev, imsize=IMSIZE, border=BORDER, not_found_policy='replace_black')\n\ndel dev\n\ndev_x -= mean\ndev_x /= stddev\n\nnp.save('../data/dev_x', dev_x)\n###\n"""
utils/organize_data.py,0,"b'import os\nimport os.path\nimport random\nimport math\nimport itertools\nimport shutil\n\nimport numpy as np\n\nfrom collections import namedtuple\n\n\nFORMATS = {\'.jpg\', \'.jpeg\', \'.png\'}\nDATA_DIR = \'./data/\'\nTRAIN_DIR = DATA_DIR + \'train/\'\nTEST_DIR = DATA_DIR + \'test/\'\nDEV_DIR = DATA_DIR + \'dev/\'\nPROTOCOLS_DIR = \'./data/\'\n\nBASE_DIR = \'/home/egor/faces/\'\nFEI_DIR = BASE_DIR + \'fei/\'\nCAL_DIR = BASE_DIR + \'caltech_faces/\'\nGT_DIR = BASE_DIR + \'gt_db/\'\nLFW2_DIR = BASE_DIR + \'lfw2/\'\n\n\nDEV_RATIO = 0.04\nTEST_RATIO = 0.06\n\n\nDO_NOT_COPY = False\n\n\nEntry = namedtuple(\'Entry\', [\'subject\', \'name\', \'path\'])\n\n\ndef grab_db_plain(path, divisor):\n    res = []\n\n    for file in os.listdir(path):\n        file_path = os.path.join(path, file)\n        ext = os.path.splitext(file)[1]\n        if os.path.isfile(file_path) and ext in FORMATS:\n            subject, name = file.split(divisor)\n            res.append(Entry(path + subject, name, file_path))\n\n    return res\n\n\ndef grab_db_folders(path):\n    res = []\n\n    for dir in os.listdir(path):\n        dir_path = os.path.join(path, dir)\n        if os.path.isdir(dir_path):\n            for file in os.listdir(dir_path):\n                file_path = os.path.join(dir_path, file)\n                ext = os.path.splitext(file)[1]\n                if os.path.isfile(file_path) and ext in FORMATS:\n                    res.append(Entry(path + dir, file, file_path))\n\n    return res\n\n\ndef get_entry_subjects(xs):\n    return list(set(map(lambda e: e.subject, xs)))\n\n\ndef get_subjects(entries):\n    subjects = get_entry_subjects(entries)\n    n_subjects = len(subjects)\n    n_dev_subjects = max(1, math.ceil(n_subjects * DEV_RATIO))\n    random.shuffle(subjects)\n\n    return subjects[:n_dev_subjects], subjects[n_dev_subjects:]\n\n\ndef copy_files(files, dest_dir):\n    if DO_NOT_COPY:\n        return\n\n    if not os.path.exists(dest_dir):\n        os.makedirs(dest_dir)\n\n    h = 0\n    for file in files:\n        ext = os.path.splitext(file)[1]\n        shutil.copy(file, os.path.join(dest_dir, str(h) + ext))\n        h += 1\n\n\ndef main():\n    for dir in {DATA_DIR, TRAIN_DIR, TEST_DIR, DEV_DIR, PROTOCOLS_DIR}:\n        if not os.path.exists(dir):\n            print(\'Creating {}\'.format(dir))\n            os.makedirs(dir)\n\n    entries = [\n        (\'fei\', grab_db_plain(FEI_DIR, \'-\')),\n        (\'caltech_faces\', grab_db_folders(CAL_DIR)),\n        (\'gt\', grab_db_folders(GT_DIR))\n        # (\'lfw2\', grab_db_folders(LFW2_DIR))\n    ]\n\n    all_entries = list(itertools.chain.from_iterable((map(lambda p: p[1], entries))))\n    all_subjects = get_entry_subjects(all_entries)\n    n_files_total = len(all_entries)\n    n_subjects_total = len(all_subjects)\n\n    print(\'-\' * 10)\n\n    print(\'Taking for development set {:.2f}% of subjects\'.format(DEV_RATIO * 100))\n\n    subjects_dev = []\n    subjects = []\n\n    print(\'-\' * 10)\n\n    for name, e in entries:\n        n_e_files = len(e)\n        print(\'Total files in ""{}"" set: {}\'.format(name, n_e_files))\n        subjects_dev_e, subjects_e = get_subjects(e)\n        subjects_dev += subjects_dev_e\n        subjects += subjects_e\n\n    print(\'-\' * 10)\n    print(\'Total files: {}\'.format(n_files_total))\n    print(\'Total subjects: {}\'.format(n_subjects_total))\n    print(\'-\' * 10)\n\n    n_subjects_dev = len(subjects_dev)\n    n_subjects = len(subjects)\n\n    print(\'Number of subjects for development set: {}\'.format(n_subjects_dev))\n    print(\'Number of subjects for train/test set: {}\'.format(n_subjects))\n\n    dev_files = []\n    protocol_data = []\n\n    for subj in subjects_dev:\n        subj_entries = list(map(lambda e: e.path, filter(lambda e: e.subject == subj, all_entries)))\n        n_subjects_entries = len(subj_entries)\n        dev_files.extend(subj_entries)\n        protocol_data.append(n_subjects_entries)\n\n    n_dev_files = sum(protocol_data)\n    protocol = np.zeros((n_dev_files, n_dev_files), dtype=np.bool)\n\n    k = 0\n    for i in protocol_data:\n        protocol[k:k + i, k:k + i] = 1\n        k += i\n\n    print(\'-\' * 10)\n    print(\'Total dev files: {}\'.format(n_dev_files))\n\n    # print(dev_files)\n\n    copy_files(dev_files, DEV_DIR)\n\n    np.save(PROTOCOLS_DIR + \'dev_protocol\', protocol)\n\n    n_test_files = 0\n\n    h = 0\n    for subj in subjects:\n        subj_name = \'subject_\' + str(h)\n        h += 1\n\n        subj_entries = list(map(lambda e: e.path, filter(lambda e: e.subject == subj, all_entries)))\n        n_subj_entries = len(subj_entries)\n        random.shuffle(subj_entries)\n\n        for_test = 0\n\n        if n_subj_entries > 1:\n            for_test = max(1, math.ceil(n_subj_entries * TEST_RATIO))\n\n        n_test_files += for_test\n\n        entries_test, entries_train = subj_entries[:for_test], subj_entries[for_test:]\n\n        subj_train_dir = os.path.join(TRAIN_DIR, subj_name)\n        subj_test_dir = os.path.join(TEST_DIR, subj_name)\n\n        copy_files(entries_train, subj_train_dir)\n        copy_files(entries_test, subj_test_dir)\n\n    print(\'Test files: {}\'.format(n_test_files))\n    print(\'Train files: {}\'.format(n_files_total - k - n_test_files))\n\n    print(\'Done!\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
