file_path,api_count,code
setup.py,0,"b'from distutils.core import setup\n\ndesc = """"""\\\ntensorflow-rbm\n==============\nTensorflow implementation of Restricted Boltzman Machine\nfor layerwise pretraining of deep autoencoders\n""""""\n\nsetup(name=\'tfrbm\',\n      version=\'0.0.2\',\n      author=\'Egor Malykh, Michal Lukac\',\n      author_email=\'fnk@fea.st\',\n      long_description=desc,\n      packages=[\'tfrbm\'],\n      url=\'https://github.com/meownoid/tensorflow-rbm\')\n'"
tfrbm/__init__.py,0,"b'from .bbrbm import BBRBM\nfrom .gbrbm import GBRBM\n\n# default RBM\nRBM = BBRBM\n\n__all__ = [RBM, BBRBM, GBRBM]\n'"
tfrbm/bbrbm.py,11,"b'import tensorflow as tf\nfrom .rbm import RBM\nfrom .util import sample_bernoulli\n\n\nclass BBRBM(RBM):\n    def __init__(self, *args, **kwargs):\n        RBM.__init__(self, *args, **kwargs)\n\n    def _initialize_vars(self):\n        hidden_p = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n        visible_recon_p = tf.nn.sigmoid(tf.matmul(sample_bernoulli(hidden_p), tf.transpose(self.w)) + self.visible_bias)\n        hidden_recon_p = tf.nn.sigmoid(tf.matmul(visible_recon_p, self.w) + self.hidden_bias)\n\n        positive_grad = tf.matmul(tf.transpose(self.x), hidden_p)\n        negative_grad = tf.matmul(tf.transpose(visible_recon_p), hidden_recon_p)\n\n        def f(x_old, x_new):\n            return self.momentum * x_old +\\\n                   self.learning_rate * x_new * (1 - self.momentum) / tf.to_float(tf.shape(x_new)[0])\n\n        delta_w_new = f(self.delta_w, positive_grad - negative_grad)\n        delta_visible_bias_new = f(self.delta_visible_bias, tf.reduce_mean(self.x - visible_recon_p, 0))\n        delta_hidden_bias_new = f(self.delta_hidden_bias, tf.reduce_mean(hidden_p - hidden_recon_p, 0))\n\n        update_delta_w = self.delta_w.assign(delta_w_new)\n        update_delta_visible_bias = self.delta_visible_bias.assign(delta_visible_bias_new)\n        update_delta_hidden_bias = self.delta_hidden_bias.assign(delta_hidden_bias_new)\n\n        update_w = self.w.assign(self.w + delta_w_new)\n        update_visible_bias = self.visible_bias.assign(self.visible_bias + delta_visible_bias_new)\n        update_hidden_bias = self.hidden_bias.assign(self.hidden_bias + delta_hidden_bias_new)\n\n        self.update_deltas = [update_delta_w, update_delta_visible_bias, update_delta_hidden_bias]\n        self.update_weights = [update_w, update_visible_bias, update_hidden_bias]\n\n        self.compute_hidden = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n        self.compute_visible = tf.nn.sigmoid(tf.matmul(self.compute_hidden, tf.transpose(self.w)) + self.visible_bias)\n        self.compute_visible_from_hidden = tf.nn.sigmoid(tf.matmul(self.y, tf.transpose(self.w)) + self.visible_bias)\n'"
tfrbm/gbrbm.py,11,"b'import tensorflow as tf\nfrom .rbm import RBM\nfrom .util import sample_bernoulli, sample_gaussian\n\n\nclass GBRBM(RBM):\n    def __init__(self, n_visible, n_hidden, sample_visible=False, sigma=1, **kwargs):\n        self.sample_visible = sample_visible\n        self.sigma = sigma\n\n        RBM.__init__(self, n_visible, n_hidden, **kwargs)\n\n    def _initialize_vars(self):\n        hidden_p = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n        visible_recon_p = tf.matmul(sample_bernoulli(hidden_p), tf.transpose(self.w)) + self.visible_bias\n\n        if self.sample_visible:\n            visible_recon_p = sample_gaussian(visible_recon_p, self.sigma)\n\n        hidden_recon_p = tf.nn.sigmoid(tf.matmul(visible_recon_p, self.w) + self.hidden_bias)\n\n        positive_grad = tf.matmul(tf.transpose(self.x), hidden_p)\n        negative_grad = tf.matmul(tf.transpose(visible_recon_p), hidden_recon_p)\n\n        def f(x_old, x_new):\n            return self.momentum * x_old +\\\n                   self.learning_rate * x_new * (1 - self.momentum) / tf.to_float(tf.shape(x_new)[0])\n\n        delta_w_new = f(self.delta_w, positive_grad - negative_grad)\n        delta_visible_bias_new = f(self.delta_visible_bias, tf.reduce_mean(self.x - visible_recon_p, 0))\n        delta_hidden_bias_new = f(self.delta_hidden_bias, tf.reduce_mean(hidden_p - hidden_recon_p, 0))\n\n        update_delta_w = self.delta_w.assign(delta_w_new)\n        update_delta_visible_bias = self.delta_visible_bias.assign(delta_visible_bias_new)\n        update_delta_hidden_bias = self.delta_hidden_bias.assign(delta_hidden_bias_new)\n\n        update_w = self.w.assign(self.w + delta_w_new)\n        update_visible_bias = self.visible_bias.assign(self.visible_bias + delta_visible_bias_new)\n        update_hidden_bias = self.hidden_bias.assign(self.hidden_bias + delta_hidden_bias_new)\n\n        self.update_deltas = [update_delta_w, update_delta_visible_bias, update_delta_hidden_bias]\n        self.update_weights = [update_w, update_visible_bias, update_hidden_bias]\n\n        self.compute_hidden = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n        self.compute_visible = tf.matmul(self.compute_hidden, tf.transpose(self.w)) + self.visible_bias\n        self.compute_visible_from_hidden = tf.matmul(self.y, tf.transpose(self.w)) + self.visible_bias\n'"
tfrbm/rbm.py,17,"b""from __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport sys\nfrom .util import tf_xavier_init\n\n\nclass RBM:\n    def __init__(self,\n                 n_visible,\n                 n_hidden,\n                 learning_rate=0.01,\n                 momentum=0.95,\n                 xavier_const=1.0,\n                 err_function='mse',\n                 use_tqdm=False,\n                 # DEPRECATED:\n                 tqdm=None):\n        if not 0.0 <= momentum <= 1.0:\n            raise ValueError('momentum should be in range [0, 1]')\n\n        if err_function not in {'mse', 'cosine'}:\n            raise ValueError('err_function should be either \\'mse\\' or \\'cosine\\'')\n\n        self._use_tqdm = use_tqdm\n        self._tqdm = None\n\n        if use_tqdm or tqdm is not None:\n            from tqdm import tqdm\n            self._tqdm = tqdm\n\n        self.n_visible = n_visible\n        self.n_hidden = n_hidden\n        self.learning_rate = learning_rate\n        self.momentum = momentum\n\n        self.x = tf.placeholder(tf.float32, [None, self.n_visible])\n        self.y = tf.placeholder(tf.float32, [None, self.n_hidden])\n\n        self.w = tf.Variable(tf_xavier_init(self.n_visible, self.n_hidden, const=xavier_const), dtype=tf.float32)\n        self.visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n        self.hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n\n        self.delta_w = tf.Variable(tf.zeros([self.n_visible, self.n_hidden]), dtype=tf.float32)\n        self.delta_visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n        self.delta_hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n\n        self.update_weights = None\n        self.update_deltas = None\n        self.compute_hidden = None\n        self.compute_visible = None\n        self.compute_visible_from_hidden = None\n\n        self._initialize_vars()\n\n        assert self.update_weights is not None\n        assert self.update_deltas is not None\n        assert self.compute_hidden is not None\n        assert self.compute_visible is not None\n        assert self.compute_visible_from_hidden is not None\n\n        if err_function == 'cosine':\n            x1_norm = tf.nn.l2_normalize(self.x, 1)\n            x2_norm = tf.nn.l2_normalize(self.compute_visible, 1)\n            cos_val = tf.reduce_mean(tf.reduce_sum(tf.mul(x1_norm, x2_norm), 1))\n            self.compute_err = tf.acos(cos_val) / tf.constant(np.pi)\n        else:\n            self.compute_err = tf.reduce_mean(tf.square(self.x - self.compute_visible))\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_vars(self):\n        pass\n\n    def get_err(self, batch_x):\n        return self.sess.run(self.compute_err, feed_dict={self.x: batch_x})\n\n    def get_free_energy(self):\n        pass\n\n    def transform(self, batch_x):\n        return self.sess.run(self.compute_hidden, feed_dict={self.x: batch_x})\n\n    def transform_inv(self, batch_y):\n        return self.sess.run(self.compute_visible_from_hidden, feed_dict={self.y: batch_y})\n\n    def reconstruct(self, batch_x):\n        return self.sess.run(self.compute_visible, feed_dict={self.x: batch_x})\n\n    def partial_fit(self, batch_x):\n        self.sess.run(self.update_weights + self.update_deltas, feed_dict={self.x: batch_x})\n\n    def fit(self,\n            data_x,\n            n_epoches=10,\n            batch_size=10,\n            shuffle=True,\n            verbose=True):\n        assert n_epoches > 0\n\n        n_data = data_x.shape[0]\n\n        if batch_size > 0:\n            n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n        else:\n            n_batches = 1\n\n        if shuffle:\n            data_x_cpy = data_x.copy()\n            inds = np.arange(n_data)\n        else:\n            data_x_cpy = data_x\n\n        errs = []\n\n        for e in range(n_epoches):\n            if verbose and not self._use_tqdm:\n                print('Epoch: {:d}'.format(e))\n\n            epoch_errs = np.zeros((n_batches,))\n            epoch_errs_ptr = 0\n\n            if shuffle:\n                np.random.shuffle(inds)\n                data_x_cpy = data_x_cpy[inds]\n\n            r_batches = range(n_batches)\n\n            if verbose and self._use_tqdm:\n                r_batches = self._tqdm(r_batches, desc='Epoch: {:d}'.format(e), ascii=True, file=sys.stdout)\n\n            for b in r_batches:\n                batch_x = data_x_cpy[b * batch_size:(b + 1) * batch_size]\n                self.partial_fit(batch_x)\n                batch_err = self.get_err(batch_x)\n                epoch_errs[epoch_errs_ptr] = batch_err\n                epoch_errs_ptr += 1\n\n            if verbose:\n                err_mean = epoch_errs.mean()\n                if self._use_tqdm:\n                    self._tqdm.write('Train error: {:.4f}'.format(err_mean))\n                    self._tqdm.write('')\n                else:\n                    print('Train error: {:.4f}'.format(err_mean))\n                    print('')\n                sys.stdout.flush()\n\n            errs = np.hstack([errs, epoch_errs])\n\n        return errs\n\n    def get_weights(self):\n        return self.sess.run(self.w),\\\n            self.sess.run(self.visible_bias),\\\n            self.sess.run(self.hidden_bias)\n\n    def save_weights(self, filename, name):\n        saver = tf.train.Saver({name + '_w': self.w,\n                                name + '_v': self.visible_bias,\n                                name + '_h': self.hidden_bias})\n        return saver.save(self.sess, filename)\n\n    def set_weights(self, w, visible_bias, hidden_bias):\n        self.sess.run(self.w.assign(w))\n        self.sess.run(self.visible_bias.assign(visible_bias))\n        self.sess.run(self.hidden_bias.assign(hidden_bias))\n\n    def load_weights(self, filename, name):\n        saver = tf.train.Saver({name + '_w': self.w,\n                                name + '_v': self.visible_bias,\n                                name + '_h': self.hidden_bias})\n        saver.restore(self.sess, filename)\n"""
tfrbm/util.py,3,"b'import numpy as np\nimport tensorflow as tf\n\n\ndef tf_xavier_init(fan_in, fan_out, *, const=1.0, dtype=np.float32):\n    k = const * np.sqrt(6.0 / (fan_in + fan_out))\n    return tf.random_uniform((fan_in, fan_out), minval=-k, maxval=k, dtype=dtype)\n\n\ndef sample_bernoulli(probs):\n    return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n\n\ndef sample_gaussian(x, sigma):\n    return x + tf.random_normal(tf.shape(x), mean=0.0, stddev=sigma, dtype=tf.float32)\n'"
