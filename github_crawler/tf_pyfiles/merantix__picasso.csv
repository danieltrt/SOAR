file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n###############################################################################\n\nfrom setuptools import setup, find_packages\n\nwith open(\'README.rst\') as readme_file:\n    readme = readme_file.read()\n\nwith open(\'HISTORY.rst\') as history_file:\n    history = history_file.read()\n\nrequirements = [\n    \'click>=6.7\',\n    \'cycler>=0.10.0\',\n    \'Flask>=0.12\',\n    \'h5py>=2.6.0\',\n    \'itsdangerous>=0.24\',\n    \'Jinja2>=2.9.5\',\n    \'Keras>=1.2.2\',\n    \'MarkupSafe>=0.23\',\n    \'matplotlib>=2.0.0\',\n    \'numpy>=1.12.0\',\n    \'olefile>=0.44\',\n    \'packaging>=16.8\',\n    \'Pillow>=4.0.0\',\n    \'protobuf>=3.2.0\',\n    \'pyparsing>=2.1.10\',\n    \'python-dateutil>=2.6.0\',\n    \'pytz>=2016.10\',\n    \'PyYAML>=3.12\',\n    \'requests>=2.13.0\',\n    \'scipy>=0.18.1\',\n    \'six>=1.10.0\',\n    \'Werkzeug>=0.11.15\',\n]\n\n# only add tensorflow as a requirement if it is not already provided.\n# E.g. tensorflow-gpu\ntry:\n    import tensorflow\nexcept ImportError:\n    requirements.append(\'tensorflow>=1.0.0\')\n\ntest_requirements = [\n    \'pytest\',\n    \'pytest-flask\',\n    \'selenium==3.6.0\',\n]\n\ndocs_require = [\n    \'Sphinx\',\n    \'sphinxcontrib-napoleon\',\n    \'sphinx-rtd-theme\'\n]\n\nsetup(\n    name=\'picasso_viz\',\n    version=\'v0.2.0\',\n    description=""A CNN model visualizer"",\n    long_description=readme + \'\\n\\n\' + history,\n    author=""Ryan Henderson"",\n    author_email=\'ryan@merantix.com\',\n    url=\'https://github.com/merantix/picasso\',\n    packages=find_packages(),\n    entry_points={\n        \'console_scripts\': [\n            \'picasso=picasso.commands:main\'\n        ],\n    },\n    include_package_data=True,\n    package_data={\'picasso\': [\'examples/keras/*\',\n                              \'examples/tensorflow/*\',\n                              \'examples/keras-vgg16/*\',\n                              \'examples/keras/data-volume/*\',\n                              \'examples/tensorflow/data-volume/*\',\n                              \'examples/keras-vgg16/data-volume/*\',\n                              \'templates/*\',\n                              \'static/*\']},\n    install_requires=requirements,\n    license=""Eclipse Public License 1.0 (EPL-1.0)"",\n    zip_safe=False,\n    keywords=\'picasso\',\n    classifiers=[\n        \'Development Status :: 2 - Pre-Alpha\',\n        \'Intended Audience :: Developers\',\n        \'License :: OSI Approved :: Eclipse Public License 1.0 (EPL-1.0)\',\n        \'Natural Language :: English\',\n        \'Programming Language :: Python :: 3.5\',\n    ],\n    test_suite=\'tests\',\n    tests_require=test_requirements,\n    extras_require={\n        \'test\': test_requirements,\n        \'docs\': docs_require\n    },\n    setup_requires=[\'pytest_runner\']\n)\n'"
travis_pypi_setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n###############################################################################\n""""""Update encrypted deploy password in Travis config file\n""""""\n\n\nfrom __future__ import print_function\nimport base64\nimport json\nimport os\nfrom getpass import getpass\nimport yaml\nfrom cryptography.hazmat.primitives.serialization import load_pem_public_key\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.asymmetric.padding import PKCS1v15\n\n\ntry:\n    from urllib import urlopen\nexcept:\n    from urllib.request import urlopen\n\n\nGITHUB_REPO = \'merantix/picasso\'\nTRAVIS_CONFIG_FILE = os.path.join(\n    os.path.dirname(os.path.abspath(__file__)), \'.travis.yml\')\n\n\ndef load_key(pubkey):\n    """"""Load public RSA key, with work-around for keys using\n    incorrect header/footer format.\n\n    Read more about RSA encryption with cryptography:\n    https://cryptography.io/latest/hazmat/primitives/asymmetric/rsa/\n    """"""\n    try:\n        return load_pem_public_key(pubkey.encode(), default_backend())\n    except ValueError:\n        # workaround for https://github.com/travis-ci/travis-api/issues/196\n        pubkey = pubkey.replace(\'BEGIN RSA\', \'BEGIN\').replace(\'END RSA\', \'END\')\n        return load_pem_public_key(pubkey.encode(), default_backend())\n\n\ndef encrypt(pubkey, password):\n    """"""Encrypt password using given RSA public key and encode it with base64.\n\n    The encrypted password can only be decrypted by someone with the\n    private key (in this case, only Travis).\n    """"""\n    key = load_key(pubkey)\n    encrypted_password = key.encrypt(password, PKCS1v15())\n    return base64.b64encode(encrypted_password)\n\n\ndef fetch_public_key(repo):\n    """"""Download RSA public key Travis will use for this repo.\n\n    Travis API docs: http://docs.travis-ci.com/api/#repository-keys\n    """"""\n    keyurl = \'https://api.travis-ci.org/repos/{0}/key\'.format(repo)\n    data = json.loads(urlopen(keyurl).read().decode())\n    if \'key\' not in data:\n        errmsg = ""Could not find public key for repo: {}.\\n"".format(repo)\n        errmsg += ""Have you already added your GitHub repo to Travis?""\n        raise ValueError(errmsg)\n    return data[\'key\']\n\n\ndef prepend_line(filepath, line):\n    """"""Rewrite a file adding a line to its beginning.\n    """"""\n    with open(filepath) as f:\n        lines = f.readlines()\n\n    lines.insert(0, line)\n\n    with open(filepath, \'w\') as f:\n        f.writelines(lines)\n\n\ndef load_yaml_config(filepath):\n    with open(filepath) as f:\n        return yaml.load(f)\n\n\ndef save_yaml_config(filepath, config):\n    with open(filepath, \'w\') as f:\n        yaml.dump(config, f, default_flow_style=False)\n\n\ndef update_travis_deploy_password(encrypted_password):\n    """"""Update the deploy section of the .travis.yml file\n    to use the given encrypted password.\n    """"""\n    config = load_yaml_config(TRAVIS_CONFIG_FILE)\n\n    config[\'deploy\'][\'password\'] = dict(secure=encrypted_password)\n\n    save_yaml_config(TRAVIS_CONFIG_FILE, config)\n\n    line = (\'# This file was autogenerated and will overwrite\'\n            \' each time you run travis_pypi_setup.py\\n\')\n    prepend_line(TRAVIS_CONFIG_FILE, line)\n\n\ndef main(args):\n    public_key = fetch_public_key(args.repo)\n    password = args.password or getpass(\'PyPI password: \')\n    update_travis_deploy_password(encrypt(public_key, password.encode()))\n    print(""Wrote encrypted password to .travis.yml -- you\'re ready to deploy"")\n\n\nif \'__main__\' == __name__:\n    import argparse\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\'--repo\', default=GITHUB_REPO,\n                        help=\'GitHub repo (default: %s)\' % GITHUB_REPO)\n    parser.add_argument(\'--password\',\n                        help=\'PyPI password (will prompt if not provided)\')\n\n    args = parser.parse_args()\n    main(args)\n'"
docs/conf.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# picasso documentation build configuration file, created by\n# sphinx-quickstart on Tue Jul  9 22:26:36 2013.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\nimport sphinx_rtd_theme\n\n# If extensions (or modules to document with autodoc) are in another\n# directory, add these directories to sys.path here. If the directory is\n# relative to the documentation root, use os.path.abspath to make it\n# absolute, like shown here.\n#sys.path.insert(0, os.path.abspath(\'.\'))\n\n# Get the project root dir, which is the parent dir of this\ncwd = os.getcwd()\nproject_root = os.path.dirname(cwd)\n\n# Insert the project root dir as the first element in the PYTHONPATH.\n# This lets us ensure that the source package is imported, and that its\n# version is used.\nsys.path.insert(0, project_root)\n\n# -- General configuration ---------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\'sphinx.ext.autodoc\', \'sphinxcontrib.napoleon\', \'sphinx.ext.todo\']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'picasso\'\ncopyright = u""2017, Ryan Henderson""\n\n# The version info for the project you\'re documenting, acts as replacement\n# for |version| and |release|, also used in various other places throughout\n# the built documents.\n#\n# The short X.Y version.\nversion = \'v0.2.0\'\n# The full version, including alpha/beta/rc tags.\nrelease = \'v0.2.0\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to\n# some non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'_build\']\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built\n# documents.\n#keep_warnings = False\n\n\n# -- Options for HTML output -------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'sphinx_rtd_theme\'\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n# Theme options are theme-specific and customize the look and feel of a\n# theme further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as\n# html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the\n# top of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon\n# of the docs.  This file should be a Windows icon file (.ico) being\n# 16x16 or 32x32 pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets)\n# here, relative to this directory. They are copied after the builtin\n# static files, so a file named ""default.css"" will overwrite the builtin\n# ""default.css"".\nhtml_static_path = [\'_static\']\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page\n# bottom, using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names\n# to template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer.\n# Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer.\n# Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages\n# will contain a <link> tag referring to it.  The value of this option\n# must be the base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'picassodoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\'preamble\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass\n# [howto/manual]).\nlatex_documents = [\n    (\'index\', \'picasso.tex\',\n     u\'picasso Documentation\',\n     u\'Ryan Henderson\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at\n# the top of the title page.\n#latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings\n# are parts, not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output ------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\'index\', \'picasso\',\n     u\'picasso Documentation\',\n     [u\'Ryan Henderson\'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output ----------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\'index\', \'picasso\',\n     u\'picasso Documentation\',\n     u\'Ryan Henderson\',\n     \'picasso\',\n     \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n#texinfo_no_detailmenu = False\n\n\ndef skip(app, what, name, obj, skip, options):\n    if name == ""__init__"":\n        return False\n    return skip\n\n\n# See https://github.com/rtfd/readthedocs.org/issues/1139\ndef run_apidoc(_):\n    import subprocess\n    module = \'../picasso\'\n    cur_dir = os.path.abspath(os.path.dirname(__file__))\n    output_path = os.path.join(cur_dir, \'source\')\n    cmd_path = \'sphinx-apidoc\'\n    if hasattr(sys, \'real_prefix\'):  # Check to see if we are in a virtualenv\n        # If we are, assemble the path manually\n        cmd_path = os.path.abspath(os.path.join(sys.prefix,\n                                                \'bin\', \'sphinx-apidoc\'))\n    subprocess.check_call([cmd_path, \'-f\', \'-o\',\n                           output_path, module, \'--force\'])\n\ndef setup(app):\n    app.connect(\'builder-inited\', run_apidoc)\n    app.connect(""autodoc-skip-member"", skip)\n'"
integration_tests/conftest.py,0,"b""###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n###############################################################################\nfrom PIL import Image\nimport numpy as np\nimport pytest\nfrom selenium.webdriver import Firefox\nfrom selenium.webdriver.firefox.options import Options\n\nfrom picasso import create_app\n\n\n@pytest.fixture\ndef app():\n    _app = create_app()\n    return _app\n\n\n@pytest.fixture(scope='module')\ndef webdriver():\n    options = Options()\n    options.add_argument('-headless')\n    driver = Firefox(firefox_options=options)\n    yield driver\n    driver.quit()\n"""
integration_tests/test_selenium.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Jan Steinke - Selenium integration tests\n###############################################################################\n\n""""""\ntest_selenium\n----------------------------------\n\nIntegration tests for `picasso` module.\n""""""\n\nimport pytest\nfrom flask import url_for\n\n\n@pytest.mark.usefixtures(\'live_server\')\nclass TestIntegration:\n\n    def test_page_load(self, webdriver):\n        url = url_for(\'frontend.index\', _external=True)\n        webdriver.get(url)\n        webdriver.find_element_by_id(\'appstate_checkpoint\')\n\n\n'"
picasso/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\n__author__ = """"""Ryan Henderson""""""\n__email__ = \'ryan@merantix.com\'\n__version__ = \'v0.2.0\'\n\nfrom flask import Flask\nimport os\nimport sys\nfrom picasso.interfaces.rest import API\nfrom picasso.interfaces.web import frontend\n\nif sys.version_info.major < 3 or (sys.version_info.major == 3 and\n                                  sys.version_info.minor < 5):\n    raise SystemError(\'Python 3.5+ required, found {}\'.format(sys.version))\n\n\ndef create_app(debug=False):\n    _app = Flask(__name__)\n    _app.debug = debug\n    _app.config.from_object(\'picasso.config.Default\')\n    _app.register_blueprint(API, url_prefix=\'/api\')\n    _app.register_blueprint(frontend, url_prefix=\'/\')\n\n    # Use a bogus secret key for debugging ease. No client information is stored;\n    # the secret key is only necessary for generating the session cookie.\n    if _app.debug:\n        _app.secret_key = \'...\'\n    else:\n        _app.secret_key = os.urandom(24)\n\n    return _app\n\n\napp = create_app()\n\nif os.getenv(\'PICASSO_SETTINGS\'):\n    app.config.from_envvar(\'PICASSO_SETTINGS\')\n\ndeprecated_settings = [\'BACKEND_PREPROCESSOR_NAME\',\n                       \'BACKEND_PREPROCESSOR_PATH\',\n                       \'BACKEND_POSTPROCESSOR_NAME\',\n                       \'BACKEND_POSTPROCESSOR_PATH\',\n                       \'BACKEND_PROB_DECODER_NAME\',\n                       \'BACKEND_PROB_DECODER_PATH\',\n                       \'DATA_DIR\']\n\nif any([x in app.config.keys() for x in deprecated_settings]):\n    raise ValueError(\'It looks like you\\\'re using a deprecated\'\n                     \' setting.  The settings and utility functions\'\n                     \' have been changed as of version v0.2.0 (and \'\n                     \'you\\\'re using {}). Changing to the updated \'\n                     \' settings is trivial: see \'\n                     \'https://picasso.readthedocs.io/en/latest/models.html\'\n                     \' and \'\n                     \'https://picasso.readthedocs.io/en/latest/settings.html\'\n                     .format(__version__))\n'"
picasso/config.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport os\n\nbase_dir = os.path.dirname(__file__)  # only for default config\n\n\nclass Default:\n    """"""Default settings for the Flask app.\n\n    The Flask app uses these settings if no custom settings are defined.  You\n    can define custom settings by creating a Python module, defining global\n    variables in that module, and setting the environment variable\n    `PICASSO_SETTINGS` to the path to that module.\n\n    If `PICASSO_SETTINGS` is not set, or if any particular setting is not\n    defined in the indicated module, then the Flask app uses these default\n    settings.\n\n    """"""\n    # :obj:`str`: filepath of the module containing the model to run\n    MODEL_CLS_PATH = os.path.join(\n        base_dir, \'examples\', \'keras\', \'model.py\')\n\n    # :obj:`str`: name of model class\n    MODEL_CLS_NAME = \'KerasMNISTModel\'\n\n    # :obj:`dict`: dictionary of args to pass to the `load` method of the\n    # model instance.\n    MODEL_LOAD_ARGS = {\n        \'data_dir\': os.path.join(base_dir, \'examples\', \'keras\', \'data-volume\'),\n    }\n'"
picasso/utils.py,0,"b'# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Jan Steinke - Restful API\n###############################################################################\n""""""utiltiy code to provide the Flask server with information\n\nThis code only provides utility functions to access the backend.\n""""""\nfrom types import ModuleType\nfrom importlib import import_module\nimport inspect\nfrom flask import (\n    g,\n    current_app\n)\nfrom picasso.visualizations import *\nfrom picasso.visualizations.base import BaseVisualization\nfrom picasso.models.base import load_model\n\nAPP_TITLE = \'Picasso Visualizer\'\n\n\ndef _get_visualization_classes():\n    """"""Import visualizations classes dynamically\n    """"""\n    visualization_attr = vars(import_module(\'picasso.visualizations\'))\n    visualization_submodules = [\n        visualization_attr[x]\n        for x in visualization_attr\n        if isinstance(visualization_attr[x], ModuleType)]\n    visualization_classes = []\n    for submodule in visualization_submodules:\n        attrs = vars(submodule)\n        for attr_name in attrs:\n            attr = attrs[attr_name]\n            if (inspect.isclass(attr)\n                and issubclass(attr, BaseVisualization)\n                    and attr is not BaseVisualization):\n                visualization_classes.append(attr)\n    return visualization_classes\n\n\ndef get_model():\n    """"""Get the NN model that\'s being analyzed from the request context.  Put\n    the model in the request context if it is not yet there.\n\n    Returns:\n        instance of :class:`.models.model.Model` or derived\n        class\n    """"""\n    if not hasattr(g, \'model\'):\n        g.model = load_model(current_app.config[\'MODEL_CLS_PATH\'],\n                             current_app.config[\'MODEL_CLS_NAME\'],\n                             current_app.config[\'MODEL_LOAD_ARGS\'])\n    return g.model\n\n\ndef get_visualizations():\n    """"""Get the available visualizations from the request context.  Put the\n    visualizations in the request context if they are not yet there.\n\n    Returns:\n        :obj:`list` of instances of :class:`.BaseVisualization` or\n        derived class\n\n    """"""\n    if not hasattr(g, \'visualizations\'):\n        g.visualizations = {}\n        for VisClass in _get_visualization_classes():\n            vis = VisClass(get_model())\n            g.visualizations[vis.__class__.__name__] = vis\n    return g.visualizations\n\n\ndef get_app_state():\n    """"""Get current status of application in context\n\n    Returns:\n        :obj:`dict` of application status\n\n    """"""\n    if not hasattr(g, \'app_state\'):\n        model = get_model()\n        g.app_state = {\n            \'app_title\': APP_TITLE,\n            \'model_name\': type(model).__name__,\n            \'latest_ckpt_name\': model.latest_ckpt_name,\n            \'latest_ckpt_time\': model.latest_ckpt_time\n        }\n    return g.app_state\n'"
tests/conftest.py,0,"b""###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n###############################################################################\nfrom PIL import Image\nimport numpy as np\nimport pytest\nfrom selenium.webdriver import Firefox\nfrom selenium.webdriver.firefox.options import Options\n\nfrom picasso import create_app\n\n\n@pytest.fixture\ndef app():\n    _app = create_app()\n    return _app\n\n\n@pytest.fixture(scope='session')\ndef random_image_files(tmpdir_factory):\n    fn = tmpdir_factory.mktemp('images')\n    for i in range(4):\n        imarray = np.random.rand(10**i, 10**i, 3) * 255\n        img = Image.fromarray(imarray.astype('uint8')).convert('RGBA')\n        img.save(str(fn.join('{}.png'.format(i))), 'PNG')\n    return fn\n\n\n@pytest.fixture\ndef test_image():\n    return './tests/resources/input/9.png'\n\n\n@pytest.fixture\ndef example_prob_array():\n    return np.random.random((3, 10))\n\n\n@pytest.fixture\ndef base_model():\n    from picasso.models.base import BaseModel\n\n    class BaseModelForTest(BaseModel):\n        def load(self, data_dir):\n            pass\n    return BaseModelForTest()\n\n\n@pytest.fixture\ndef tensorflow_model():\n    from picasso.models.tensorflow import TFModel\n    return TFModel()\n"""
tests/test_picasso.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n#    Jan Steinke - Restful API\n#    XdpAreKid - Support Keras >= 2\n###############################################################################\n\n""""""\ntest_picasso\n----------------------------------\n\nTests for `picasso` module.\n""""""\nimport os\n\n\nclass TestBaseModel:\n\n    def test_decode_prob(self, base_model, example_prob_array):\n        results = base_model.decode_prob(example_prob_array)\n        for i, result in enumerate(results):\n            max_val = max(example_prob_array[i])\n            assert result[0][\'prob\'] == \'{:.3f}\'.format(max_val)\n            assert result[0][\'index\'] == example_prob_array[i].argmax()\n            assert result[0][\'name\'] == str(result[0][\'index\'])\n\n\nclass TestKerasModel:\n\n    def test_saved_model(self):\n        # tests that KerasModel can load from a saved model\n        import tempfile\n        from picasso.models.keras import KerasModel\n\n        data_path = os.path.join(\'picasso\', \'examples\',\n                                 \'keras\', \'data-volume\')\n\n        km = KerasModel()\n        km.load(data_path)\n\n        temp = tempfile.mkdtemp()\n        km._model.save(os.path.join(temp, \'temp.h5\'))\n\n        km = KerasModel()\n        km.load(temp)\n\n        assert km.tf_predict_var is not None\n\n\nclass TestTensorflowBackend:\n\n    def test_tensorflow_backend(self, tensorflow_model):\n        """"""Only tests tensorflow backend loads without error\n\n        """"""\n        tensorflow_model.load(\n            data_dir=os.path.join(\'picasso\', \'examples\', \'tensorflow\',\n                                  \'data-volume\'),\n            tf_predict_var=\'Softmax:0\',\n            tf_input_var=\'convolution2d_input_1:0\')\n        assert tensorflow_model.tf_predict_var is not None\n        assert tensorflow_model.tf_input_var is not None\n'"
tests/test_rest.py,0,"b'import io\nimport json\n\nimport pytest\nfrom flask import url_for\nfrom PIL import Image, ImageChops\n\n\ndef verify_data(client, data, vis, prefix=\'\'):\n    res_path = \'./tests/resources/\'\n    assert data[\'input_file_name\']\n    assert data[\'predict_probs\']\n    if data[\'has_output\']:\n        assert data[\'output_file_names\']\n        i = 1\n        for filename in data[\'output_file_names\']:\n            actual_image = client.get(url_for(\'api.download_outputs\', filename=filename)).data\n            actual_processed_input = Image.open(io.BytesIO(actual_image))\n            expected_processed_input = Image.open(res_path + vis.__name__ + \'/\' + prefix + \'output/\' + str(i) + \'.png\')\n            assert ImageChops.difference(actual_processed_input, expected_processed_input).getbbox() is None\n            i += 1\n    if data[\'has_processed_input\']:\n        assert data[\'processed_input_file_name\']\n        filename = data[\'processed_input_file_name\']\n        actual_image = client.get(url_for(\'api.download_outputs\', filename=filename)).data\n        actual_processed_input = Image.open(io.BytesIO(actual_image))\n        expected_processed_input = Image.open(res_path + vis.__name__ + \'/\' + prefix + \'pre/default.png\')\n        assert ImageChops.difference(actual_processed_input, expected_processed_input).getbbox() is None\n\n\nclass TestRestAPI:\n    from picasso.utils import _get_visualization_classes\n\n    def test_api_root_get(self, client):\n        assert client.get(url_for(\'api.root\')).status_code == 200\n\n    def test_api_get_app_state(self, client):\n        response = client.get(url_for(\'api.app_state\'))\n        data = json.loads(response.get_data(as_text=True))\n        assert data[\'app_title\']\n        assert data[\'latest_ckpt_name\']\n        assert data[\'latest_ckpt_time\']\n        assert data[\'model_name\']\n\n    def test_api_uploading_file(self, client, random_image_files):\n        upload_file = str(random_image_files.listdir()[0])\n        with open(upload_file, ""rb"") as imageFile:\n            f = imageFile.read()\n            b = bytearray(f)\n        data = dict()\n        data[\'file\'] = (io.BytesIO(b), \'test.png\')\n        response = client.post(url_for(\'api.images\'), data=data)\n        data = json.loads(response.get_data(as_text=True))\n        assert data[\'ok\'] == \'true\'\n        assert type(data[\'file\']) is str\n        assert type(data[\'uid\']) is int\n\n    @pytest.mark.parametrize(""vis"", _get_visualization_classes())\n    def test_api_visualizing_input(self, client, test_image, vis):\n        upload_file = test_image\n        with open(upload_file, ""rb"") as imageFile:\n            f = imageFile.read()\n            b = bytearray(f)\n        upload_data = dict()\n        upload_data[\'file\'] = (io.BytesIO(b), \'test.png\')\n        upload_response = client.post(url_for(\'api.images\'), data=upload_data)\n        upload_response_data = json.loads(upload_response.get_data(as_text=True))\n        base_url = \'{base}?visualizer={visualizer}&image={image}\'.format(\n            base=url_for(\'api.visualize\'),\n            visualizer=vis.__name__,\n            image=str(upload_response_data[\'uid\'])\n        )\n        settings_string = \'\'\n        for setting in vis.ALLOWED_SETTINGS:\n            settings_string += ""&{0}={1}"".format(setting, vis.ALLOWED_SETTINGS[setting][-1])\n\n        default_response = client.get(base_url)\n        assert default_response.status_code == 200\n        raw_data_from_default_response = default_response.get_data(as_text=True)\n        default_data = json.loads(raw_data_from_default_response)\n        verify_data(client, default_data, vis)\n\n        settings_response = client.get(base_url + settings_string)\n        assert settings_response.status_code == 200\n        raw_data_from_settings_response = settings_response.get_data(as_text=True)\n        settings_data = json.loads(raw_data_from_settings_response)\n        verify_data(client, settings_data, vis, prefix=\'settings_\')\n\n    def test_listing_images(self, client):\n        response = client.get(url_for(\'api.images\'))\n        assert response.status_code == 200\n\n    def test_end_session(self, client):\n        response = client.get(url_for(\'api.reset\'))\n        assert response.status_code == 200\n\n    def test_visualizers(self, client):\n        response = client.get(url_for(\'api.visualizers\'))\n        assert response.status_code == 200\n\n    @pytest.mark.parametrize(""vis"", _get_visualization_classes())\n    def test_visualizers_information(self, client, vis):\n        response = client.get(url_for(\'api.visualizers_information\', vis_name=vis.__name__))\n        assert response.status_code == 200\n'"
picasso/interfaces/__init__.py,0,b''
picasso/interfaces/rest.py,0,"b'# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Jan Steinke - Restful API\n###############################################################################\n""""""Flask blueprint for accessing and manipulating image ressources\n\nThis is used by the main flask application to provide a REST API.\n""""""\n\nimport os\nimport shutil\nimport logging\nfrom tempfile import mkdtemp\n\nfrom PIL import Image\nfrom werkzeug.utils import secure_filename\nfrom flask import (\n    Blueprint,\n    current_app,\n    jsonify,\n    session,\n    request,\n    send_from_directory)\nfrom picasso import __version__\nfrom picasso.utils import (\n    get_app_state,\n    get_visualizations\n)\n\nAPI = Blueprint(\'api\', __name__)\nlogger = logging.getLogger(__name__)\n\n\n@API.before_request\ndef initialize_new_session():\n    """"""Check session and initialize if necessary\n\n    Before every request, check the user session.  If no session exists, add\n    one and provide temporary locations for images\n\n    """"""\n    if \'image_uid_counter\' in session and \'image_list\' in session:\n        logger.debug(\'images are already being tracked\')\n    else:\n        # reset image list counter for the session\n        session[\'image_uid_counter\'] = 0\n        session[\'image_list\'] = []\n    if \'img_input_dir\' in session and \'img_output_dir\' in session:\n        logger.debug(\'temporary image directories already exist\')\n    else:\n        # make image upload directory\n        session[\'img_input_dir\'] = mkdtemp()\n        session[\'img_output_dir\'] = mkdtemp()\n\n\n@API.route(\'/\', methods=[\'GET\'])\ndef root():\n    """"""The root of the REST API\n\n    displays a hello world message.\n\n    """"""\n    return jsonify(message=\'Picasso {version}. \'\n                   \'See API documentation at: \'\n                   \'https://picasso.readthedocs.io/en/latest/api.html\'\n                   .format(version=__version__),\n                   version=__version__)\n\n\n@API.route(\'/app_state\', methods=[\'GET\'])\ndef app_state():\n    state = get_app_state()\n    return jsonify(state)\n\n\n@API.route(\'/images\', methods=[\'POST\', \'GET\'])\ndef images():\n    """"""Upload images via REST interface\n\n    Check if file upload was successful and sanatize user input.\n\n    TODO: return file URL instead of filename\n\n    """"""\n    if request.method == \'POST\':\n        file_upload = request.files[\'file\']\n        if file_upload:\n            image = dict()\n            image[\'filename\'] = secure_filename(file_upload.filename)\n            full_path = os.path.join(session[\'img_input_dir\'],\n                                     image[\'filename\'])\n            file_upload.save(full_path)\n            image[\'uid\'] = session[\'image_uid_counter\']\n            session[\'image_uid_counter\'] += 1\n            current_app.logger.debug(\'File %d is saved as %s\',\n                                     image[\'uid\'],\n                                     image[\'filename\'])\n            session[\'image_list\'].append(image)\n            return jsonify(ok=""true"", file=image[\'filename\'], uid=image[\'uid\'])\n        return jsonify(ok=""false"")\n    if request.method == \'GET\':\n        return jsonify(images=session[\'image_list\'])\n\n\n@API.route(\'/visualizers\', methods=[\'GET\'])\ndef visualizers():\n    """"""Get a list of available visualizers\n\n    Responses with a JSON list of available visualizers\n\n    """"""\n    list_of_visualizers = []\n    for visualizer in get_visualizations():\n        list_of_visualizers.append({\'name\': visualizer})\n    return jsonify(visualizers=list_of_visualizers)\n\n\n@API.route(\'/visualizers/<vis_name>\', methods=[\'GET\'])\ndef visualizers_information(vis_name):\n    vis = get_visualizations()[vis_name]\n\n    return jsonify(settings=vis.ALLOWED_SETTINGS)\n\n\n@API.route(\'/visualize\', methods=[\'GET\'])\ndef visualize():\n    """"""Trigger a visualization via the REST API\n\n    Takes a single image and generates the visualization data, returning the\n    output exactly as given by the target visualization.\n\n    """"""\n\n    session[\'settings\'] = {}\n    image_uid = request.args.get(\'image\')\n    vis_name = request.args.get(\'visualizer\')\n    vis = get_visualizations()[vis_name]\n    if vis.ALLOWED_SETTINGS:\n        for key in vis.ALLOWED_SETTINGS.keys():\n            if request.args.get(key) is not None:\n                session[\'settings\'][key] = request.args.get(key)\n            else:\n                session[\'settings\'][key] = vis.ALLOWED_SETTINGS[key][0]\n    else:\n        logger.debug(\'Selected Visualizer {0} has no settings.\'.format(vis_name))\n    inputs = []\n    for image in session[\'image_list\']:\n        if image[\'uid\'] == int(image_uid):\n            full_path = os.path.join(session[\'img_input_dir\'],\n                                     image[\'filename\'])\n            entry = dict()\n            entry[\'filename\'] = image[\'filename\']\n            entry[\'data\'] = Image.open(full_path)\n            inputs.append(entry)\n\n    vis.update_settings(session[\'settings\'])\n    output = vis.make_visualization(\n        inputs, output_dir=session[\'img_output_dir\'])\n    return jsonify(output[0])\n\n\n@API.route(\'/reset\', methods=[\'GET\'])\ndef reset():\n    """"""Delete the session and clear temporary directories\n\n    """"""\n    shutil.rmtree(session[\'img_input_dir\'])\n    shutil.rmtree(session[\'img_output_dir\'])\n    session.clear()\n    return jsonify(ok=\'true\')\n\n\n@API.route(\'/inputs/<filename>\')\ndef download_inputs(filename):\n    """"""For serving input images""""""\n    return send_from_directory(session[\'img_input_dir\'],\n                               filename)\n\n\n@API.route(\'/outputs/<filename>\')\ndef download_outputs(filename):\n    """"""For serving output images""""""\n    return send_from_directory(session[\'img_output_dir\'],\n                               filename)\n\n\n@API.errorhandler(500)\ndef internal_server_error(e):\n    return jsonify(ok=False, error=e, code=500), 500\n\n\n@API.errorhandler(404)\ndef not_found_error(e):\n    return jsonify(ok=False, error=e, code=404), 404\n'"
picasso/interfaces/web.py,0,"b'# -*- coding: utf-8 -*-\n###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Jan Steinke - Restful API\n###############################################################################\n""""""Flask blueprint for interfacing with picasso via web.\n\nThis is used by the main flask application to provide a web front-end based on the REST api.\n""""""\n\nfrom flask import (\n    render_template,\n    Blueprint\n    )\n\nfrontend = Blueprint(\'frontend\', __name__)\n\n\n@frontend.route(\'/\')\ndef index():\n    return render_template(\'index.html\')\n\n'"
picasso/models/__init__.py,0,b''
picasso/models/base.py,3,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport importlib\nfrom operator import itemgetter\nimport warnings\n\n\ndef load_model(model_cls_path, model_cls_name, model_load_args):\n    """"""Get an instance of the described model.\n\n    Args:\n        model_cls_path: Path to the module in which the model class\n            is defined.\n        model_cls_name: Name of the model class.\n        model_load_args: Dictionary of args to pass to the `load` method\n            of the model instance.\n\n    Returns:\n        An instance of :class:`.models.model.BaseModel` or subclass\n\n    """"""\n    spec = importlib.util.spec_from_file_location(\'active_model\',\n                                                  model_cls_path)\n    model_module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(model_module)\n    model_cls = getattr(model_module, model_cls_name)\n    model = model_cls()\n    if not isinstance(model, BaseModel):\n        warnings.warn(""Loaded model \'%s\' at \'%s\' is not an instance of %r""\n                      % (model_cls_name, model_cls_path, BaseModel))\n    model.load(**model_load_args)\n    return model\n\n\nclass BaseModel:\n    """"""Interface encapsulating a trained NN model usable for prediction.\n\n    This interface defines:\n\n      - How to load the model\'s topology and parameters from disk\n      - How to preprocess a batch of examples for the model\n      - How to perform prediction using the model\n      - Etc\n\n    """"""\n\n    def __init__(self,\n                 top_probs=5):\n        """"""Create a new instance of this model.\n\n        `BaseModel` is an interface and should only be instantiated via a\n        subclass.\n\n        Args:\n            top_probs (int): Number of classes to display per result. For\n                instance, VGG16 has 1000 classes, we don\'t want to display a\n                visualization for every single possibility.  Defaults to 5.\n\n        """"""\n        self.top_probs = top_probs\n\n        self._sess = None\n        self._tf_input_var = None\n        self._tf_predict_var = None\n        self._model_name = None\n        self._latest_ckpt_name = None\n        self._latest_ckpt_time = None\n\n    def load(self, *args, **kwargs):\n        """"""Load the model\'s graph and parameters from disk, restoring the model\n        into `self._sess` so that it can be run for inference.\n\n        Subclasses should set the instance variables [self._sess,\n        self._tf_input_var, self._tf_predict_var, self._description] in their\n        implementation.\n\n        """"""\n        raise NotImplementedError\n\n    @property\n    def sess(self):\n        """"""Tensorflow session that can be used to evaluate tensors in the\n        model.\n\n        :type: :obj:`tf.Session`\n\n        """"""\n        return self._sess\n\n    @property\n    def tf_input_var(self):\n        """"""Tensorflow tensor that represents the model\'s inputs.\n\n        :type: :obj:`tf.Tensor`\n\n        """"""\n        return self._tf_input_var\n\n    @property\n    def tf_predict_var(self):\n        """"""Tensorflow tensor that represents the model\'s predicted class\n        probabilities.\n\n        :type: :obj:`tf.Tensor`\n\n        """"""\n        return self._tf_predict_var\n\n    @property\n    def latest_ckpt_time(self):\n        """"""Timestamp of the latest checkpoint\n\n        :type: str\n\n        """"""\n        return self._latest_ckpt_time\n\n    @property\n    def latest_ckpt_name(self):\n        """"""Filename of the checkpoint\n\n        :type: str\n\n        """"""\n        return self._latest_ckpt_name\n\n    def preprocess(self, raw_inputs):\n        """"""Preprocess raw inputs into the format required by the model.\n\n        E.g, the raw image may need to converted to a numpy array of the\n        appropriate dimension.\n\n        By default, we perform no preprocessing.\n\n        Args:\n            raw_inputs (:obj:`list` of :obj:`PIL.Image`): List of raw\n                input images of any mode and shape.\n\n        Returns:\n            array (float32): Images ready to be fed into the model.\n\n        """"""\n        return raw_inputs\n\n    def predict(self, inputs):\n        """"""Given preprocessed inputs, generate class probabilities by using the\n        model to perform inference.\n\n        Given an iterable of examples or numpy array where the first\n        dimension is the number of example, return a n_examples x\n        n_classes array of class predictions\n\n        Args:\n            inputs: Iterable of examples (e.g., a numpy array whose first\n                dimension is the batch size).\n\n        Returns:\n            Class probabilities for each input example, as a numpy array of\n            shape (num_examples, num_classes).\n\n        """"""\n        raise NotImplementedError\n\n    def decode_prob(self, class_probabilities):\n        """"""Given predicted class probabilites for a set of examples, annotate\n        each logit with a class name.\n\n        By default, we name each class using its index in the logits array.\n\n        Args:\n            class_probabilities (array): Class probabilities as output by\n                `self.predict`, i.e., a numpy array of shape (num_examples,\n                num_classes).\n\n        Returns:\n            Annotated class probabilities for each input example, as a list of\n            dicts where each dict is formatted as:\n                {\n                    \'index\': class_index,\n                    \'name\': class_name,\n                    \'prob\': class_probability\n                }\n\n        """"""\n        results = []\n        for row in class_probabilities:\n            entries = []\n            for i, prob in enumerate(row):\n                entries.append({\'index\': i,\n                                \'name\': str(i),\n                                \'prob\': prob})\n\n            entries = sorted(entries,\n                             key=itemgetter(\'prob\'),\n                             reverse=True)[:self.top_probs]\n\n            for entry in entries:\n                entry[\'prob\'] = \'{:.3f}\'.format(entry[\'prob\'])\n            results.append(entries)\n        return results\n'"
picasso/models/keras.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nfrom datetime import datetime\nimport glob\nimport json\nimport os\n\nimport keras.backend as K\nfrom keras.models import model_from_json, load_model\n\nfrom picasso.models.base import BaseModel\n\n\nclass KerasModel(BaseModel):\n    """"""Implements model loading functions for Keras.\n\n    Using this Keras module will require the h5py library, which is not\n    included with Keras.\n\n    """"""\n\n    def load(self, data_dir):\n        """"""Load graph and weight data.\n\n        Args:\n            data_dir (:obj:`str`): location of Keras checkpoint (`.hdf5`) files\n                and model (in `.json`) structure.  The default behavior\n                is to take the latest of each, by OS timestamp.\n        """"""\n        # for tensorflow compatibility\n        K.set_learning_phase(0)\n\n        # find newest ckpt and graph files\n        try:\n            latest_ckpt = max(glob.iglob(\n                os.path.join(data_dir, \'*.h*5\')), key=os.path.getctime)\n            latest_ckpt_name = os.path.basename(latest_ckpt)\n            latest_ckpt_time = str(\n                datetime.fromtimestamp(os.path.getmtime(latest_ckpt)))\n        except ValueError:\n            raise FileNotFoundError(\'No checkpoint (.hdf5 or .h5) files \'\n                                    \'available at {}\'.format(data_dir))\n        try:\n            latest_json = max(glob.iglob(os.path.join(data_dir, \'*.json\')),\n                              key=os.path.getctime)\n            with open(latest_json, \'r\') as f:\n                model_json = json.loads(f.read())\n                self._model = model_from_json(model_json)\n\n            self._model.load_weights(latest_ckpt)\n        except ValueError:\n            try:\n                self._model = load_model(latest_ckpt)\n            except ValueError:\n                raise FileNotFoundError(\'The (.hdf5 or .h5) files available at\'\n                                        \'{} don\\\'t have the model\'\n                                        \' architecture.\'\n                                        .format(latest_ckpt))\n\n        self._sess = K.get_session()\n        self._tf_predict_var = self._model.outputs[0]\n        self._tf_input_var = self._model.inputs[0]\n        self._model_name = type(self).__name__\n        self._latest_ckpt_name = latest_ckpt_name\n        self._latest_ckpt_time = latest_ckpt_time\n\n    def predict(self, input_array):\n        return self._model.predict(input_array)\n'"
picasso/models/tensorflow.py,2,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nfrom datetime import datetime\nimport glob\nimport os\n\nimport tensorflow as tf\n\nfrom picasso.models.base import BaseModel\n\n\nclass TFModel(BaseModel):\n    """"""Implements model loading functions for Tensorflow.\n\n    """"""\n\n    def load(self, data_dir, tf_input_var=None, tf_predict_var=None):\n        """"""Load graph and weight data.\n\n        Args:\n            data_dir (:obj:`str`): location of tensorflow checkpoint data.\n                We\'ll need the .meta file to reconstruct the graph and the data\n                (checkpoint) files to fill in the weights of the model.  The\n                default behavior is take the latest files, by OS timestamp.\n            tf_input_var (:obj:`str`): Name of the tensor corresponding to the\n                model\'s inputs.  You must define this if you are loading the\n                model from a checkpoint.\n            tf_predict_var (:obj:`str`): Name of the tensor corresponding to\n                the model\'s predictions.  You must define this if you are\n                loading the model from a checkpoint.\n\n        """"""\n        # find newest ckpt and meta files\n        try:\n            latest_ckpt_fn = max(\n                filter(\n                    # exclude index and meta files which may have earlier\n                    # timestamps\n                    lambda x: os.path.splitext(x)[-1].startswith(\'.meta\') or\n                    os.path.splitext(x)[-1].startswith(\'.index\'),\n                    glob.glob(os.path.join(data_dir, \'*.ckpt*\'))),\n                key=os.path.getctime)\n            latest_ckpt_time = str(\n                datetime.fromtimestamp(os.path.getmtime(latest_ckpt_fn)))\n            # remove any step info that\'s been appended to the extension\n            fileext_div = latest_ckpt_fn.rfind(\'.ckpt\')\n            additional_ext = latest_ckpt_fn.rfind(\'.\', fileext_div + 1)\n            if additional_ext < 0:\n                latest_ckpt = latest_ckpt_fn\n            else:\n                latest_ckpt = latest_ckpt_fn[:additional_ext]\n        except ValueError:\n            raise FileNotFoundError(\'No checkpoint (.ckpt) files \'\n                                    \'available at {}\'.format(data_dir))\n\n        try:\n            latest_meta = max(glob.iglob(os.path.join(data_dir, \'*.meta\')),\n                              key=os.path.getctime)\n        except ValueError:\n            raise FileNotFoundError(\'No graph (.meta) files \'\n                                    \'available at {}\'.format(data_dir))\n\n        self._sess = tf.Session()\n        self._sess.as_default()\n\n        self._saver = tf.train.import_meta_graph(latest_meta)\n        self._saver.restore(self._sess, latest_ckpt)\n\n        self._tf_input_var = self._sess.graph.get_tensor_by_name(tf_input_var)\n        self._tf_predict_var = self._sess.graph.get_tensor_by_name(\n            tf_predict_var)\n        self._model_name = type(self).__name__\n        self._latest_ckpt_name = latest_ckpt_fn\n        self._latest_ckpt_time = latest_ckpt_time\n\n    def predict(self, input_array):\n        return self.sess.run(self.tf_predict_var,\n                             {self.tf_input_var: input_array})\n'"
picasso/visualizations/__init__.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\n""""""Visualizations live here\n\nAll default and user-defined visualizations are submodules of this\nmodule.  All classes defined in this directory (except BaseVisualization)\nwill be imported.\n\n""""""\nimport os\n\n__all__ = [x.rpartition(\'.\')[0] for x in os.listdir(__path__[0])\n           if not x.startswith(\'__\') and x.endswith(\'py\')]\n'"
picasso/visualizations/base.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport re\n\n\nclass BaseVisualization:\n    """"""Interface encapsulating a NN visualization.\n\n    This interface defines how a visualization is computed for a given NN\n    model.\n\n    """"""\n    # (:obj:`str`): Short description of the visualization.\n    DESCRIPTION = None\n\n    # (:obj:`str`): Optional link to the paper specifying the visualization.\n    REFERENCE_LINK = None\n\n    # (:obj:`dict`): Optional visualization settings that the user can select,\n    # as a dict mapping setting names to lists of their allowed values.\n    ALLOWED_SETTINGS = None\n\n    def __init__(self, model):\n        """"""Create a new instance of this visualization.\n\n        `BaseVisualization` is an interface and should only be instantiated via\n        a subclass.\n\n        Args:\n            model (:obj:`.models.model.BaseModel`): NN model to be\n                visualized.\n\n        """"""\n        self._model = model\n\n        # give default settings\n        if self.ALLOWED_SETTINGS:\n            self.update_settings({setting: self.ALLOWED_SETTINGS[setting][0]\n                                  for setting in self.ALLOWED_SETTINGS})\n\n    @property\n    def model(self):\n        """"""NN model to be visualized.\n\n        (:obj:`.models.model.BaseModel`)\n\n        """"""\n        return self._model\n\n    def update_settings(self, settings):\n        """"""Update the settings\n\n        If a derived class has an ALLOWED_SETTINGS dict, we check here that\n        incoming settings from the web app are allowed, and set the child\n        properties as appropriate.\n\n        """"""\n\n        def error_string(setting, setting_val):\n            return (\'{val} is not an acceptable value for \'\n                    \'parameter {param} for visualization\'\n                    \'{vis}.\').format(val=setting_val,\n                                     param=setting,\n                                     vis=self.__class__.__name__)\n\n        for setting in settings:\n            if settings[setting] in self.ALLOWED_SETTINGS[setting]:\n                # if the setting is allowed, set the attribute but remove\n                # invalid variable characters\n                #\n                # see:\n                #\n                # https://stackoverflow.com/questions/3303312/how-do-i-convert-a-string-to-a-valid-variable-name-in-python\n                setattr(self, \'_\' + re.sub(\'\\W|^(?=\\d)\', \'_\', setting).lower(),\n                        settings[setting])\n            else:\n                raise ValueError(error_string(settings[setting], setting))\n\n    def make_visualization(self, inputs, output_dir, settings=None):\n        """"""Generate the visualization.\n\n        All visualizations must implement this method.\n\n        Args:\n            inputs (iterable of :class:`PIL.Image`): Batch of input images to\n                make visualizations for, as PIL :obj:`Image` objects.\n            output_dir (:obj:`str`): A directory to write outputs (e.g.,\n                plots) to.\n            settings (:obj:`str`): Dictionary of settings that the user\n                selected, as a dict mapping setting names to values.  This\n                should only be provided if this class\'s `ALLOWED_SETTINGS`\n                attribute is non-null.\n\n        Returns:\n            Object used to render the visualization, passed directly to the\n            visualization class\'s associated HTML template.  Since this HTML\n            template is custom for each visualization class, the return type\n            is arbitrary.\n\n        """"""\n        raise NotImplementedError\n'"
picasso/visualizations/class_probabilities.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nfrom picasso.visualizations.base import BaseVisualization\n\n\nclass ClassProbabilities(BaseVisualization):\n    """"""Display top class probabilities for a given image\n\n    This is the simplest kind of visualization -- it merely displays the top\n    class probabilities of the input image.\n\n    """"""\n\n    DESCRIPTION = \'Predict class probabilities from new examples\'\n\n    ALLOWED_SETTINGS = dict()\n\n    def make_visualization(self, inputs, output_dir):\n        pre_processed_arrays = self.model.preprocess([example[\'data\']\n                                                      for example in inputs])\n        predictions = self.model.sess.run(self.model.tf_predict_var,\n                                          feed_dict={self.model.tf_input_var:\n                                                     pre_processed_arrays})\n        filtered_predictions = self.model.decode_prob(predictions)\n        results = []\n        for i, inp in enumerate(inputs):\n            results.append({\'input_file_name\': inp[\'filename\'],\n                            \'has_output\': False,\n                            \'has_processed_input\': False,\n                            \'predict_probs\': filtered_predictions[i]})\n        return results\n'"
picasso/visualizations/partial_occlusion.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport os\nimport time\n\nimport numpy as np\nfrom PIL import Image\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nfrom matplotlib import pyplot\n\nfrom picasso.visualizations.base import BaseVisualization\n\n\nclass PartialOcclusion(BaseVisualization):\n    """"""Partial occlusion visualization\n\n    The partial occlusion class blocks out part of the image and checks\n    the classification.  Regions where classification probability drops\n    significantly are likely very important to classification.\n\n    The visualization can therefore be used to check if the model is\n    classifying on the image feature we expect.\n\n    """"""\n    DESCRIPTION = (\'Partially occlude image to determine regions \'\n                   \'important to classification\')\n\n    REFERENCE_LINK = \'https://arxiv.org/abs/1311.2901\'\n\n    ALLOWED_SETTINGS = {\n        \'Window\': [\'0.50\', \'0.40\', \'0.30\', \'0.20\', \'0.10\', \'0.05\'],\n        \'Strides\': [\'2\', \'5\', \'10\', \'20\', \'30\'],\n        \'Occlusion\': [\'grey\', \'black\', \'white\']\n    }\n\n    @property\n    def window(self):\n        return float(self._window)\n\n    @property\n    def num_windows(self):\n        return int(self._strides)\n\n    @property\n    def occlusion_method(self):\n        return self._occlusion\n\n    def __init__(self, model):\n        super().__init__(model)\n        self.predict_tensor = self.get_predict_tensor()\n\n        self.grid_percent = 0.01\n        self.occlusion_value = 255\n        self.initial_resize = (244, 244)\n\n    def make_visualization(self, inputs, output_dir):\n        if self.occlusion_method == \'black\':\n            self.occlusion_value = 0\n        elif self.occlusion_method == \'grey\':\n            self.occlusion_value = 128\n\n        # get class predictions as in ClassProbabilities\n        pre_processed_arrays = self.model.preprocess([example[\'data\']\n                                                      for example in inputs])\n        class_predictions = self.model.sess.run(\n            self.model.tf_predict_var,\n            feed_dict={self.model.tf_input_var: pre_processed_arrays})\n        decoded_predictions = self.model.decode_prob(class_predictions)\n\n        results = []\n        for i, example in enumerate(inputs):\n            im = example[\'data\']\n            im_format = im.format\n            if self.initial_resize:\n                im = im.resize(self.initial_resize, Image.ANTIALIAS)\n\n            occ_im = self.occluded_images(im)\n            predictions = self.model.sess.run(\n                self.predict_tensor,\n                feed_dict={self.model.tf_input_var:\n                           self.model.preprocess(occ_im[\'occluded_images\'])})\n\n            example_im = self.make_example_image(im,\n                                                 occ_im[\'centers_horizontal\'],\n                                                 occ_im[\'centers_vertical\'],\n                                                 occ_im[\'win_width\'],\n                                                 occ_im[\'win_length\'],\n                                                 occ_im[\'pad_vertical\'],\n                                                 occ_im[\'pad_horizontal\'])\n            example_filename = \'{ts}{fn}\'.format(ts=str(time.time()),\n                                                 fn=example[\'filename\'])\n            example_im.save(\n                os.path.join(output_dir, example_filename),\n                format=im_format)\n\n            filenames = self.make_heatmaps(\n                predictions, output_dir, example[\'filename\'],\n                decoded_predictions=decoded_predictions[i])\n            results.append({\'input_file_name\': example[\'filename\'],\n                            \'has_output\': True,\n                            \'output_file_names\': filenames,\n                            \'predict_probs\': decoded_predictions[i],\n                            \'has_processed_input\': True,\n                            \'processed_input_file_name\': example_filename})\n        return results\n\n    def get_predict_tensor(self):\n        # Assume that predict is the softmax\n        # tensor in the computation graph\n        return self.model.sess.graph.get_tensor_by_name(\n            self.model.tf_predict_var.name)\n\n    def make_heatmaps(self, predictions,\n                      output_dir, filename,\n                      decoded_predictions=None):\n        if decoded_predictions:\n            relevant_class_indices = [pred[\'index\']\n                                      for pred in decoded_predictions]\n            predictions = predictions[:, relevant_class_indices]\n        stacked_heatmaps = predictions.reshape(self.num_windows,\n                                               self.num_windows,\n                                               predictions.shape[-1])\n        filenames = []\n        for i in range(predictions.shape[-1]):\n            grid = stacked_heatmaps[:, :, i]\n            pyplot.axis(\'off\')\n            if i == 0:\n                im = pyplot.imshow(grid, vmin=0, vmax=1)\n                pyplot.axis(\'off\')\n                im.axes.get_xaxis().set_visible(False)\n                im.axes.get_yaxis().set_visible(False)\n            else:\n                im.set_data(grid)\n            hm_filename = \'{ts}{label}_{fn}\'.format(ts=str(time.time()),\n                                                    label=str(i),\n                                                    fn=filename)\n            pyplot.savefig(os.path.join(output_dir, hm_filename),\n                           format=\'PNG\', bbox_inches=\'tight\', pad_inches=0)\n            filenames.append(hm_filename)\n        return filenames\n\n    def occluded_images(self, im):\n        width = im.size[0]\n        length = im.size[1]\n        win_width = round(self.window * width)\n        win_length = round(self.window * length)\n        pad_horizontal = win_width // 2\n        pad_vertical = win_length // 2\n        centers_horizontal, centers_vertical = self.get_centers(\n            width, length, win_width, win_length, pad_horizontal, pad_vertical,\n            self.num_windows)\n        upper_left_corners = np.array(\n            [(w - pad_vertical, v - pad_horizontal)\n             for w in centers_vertical\n             for v in centers_horizontal]\n        )\n\n        images = []\n        for corner in upper_left_corners:\n            arr = np.array(im)\n            self.add_occlusion_to_arr(arr, corner,\n                                      win_width, win_length,\n                                      occ_val=self.occlusion_value)\n            images.append(\n                Image.fromarray(arr)\n            )\n\n        return {\'occluded_images\': images,\n                \'centers_horizontal\': centers_horizontal,\n                \'centers_vertical\': centers_vertical,\n                \'win_width\': win_width,\n                \'win_length\': win_length,\n                \'pad_horizontal\': pad_horizontal,\n                \'pad_vertical\': pad_vertical}\n\n    def make_example_image(self, im,\n                           centers_horizontal, centers_vertical,\n                           win_width, win_length, pad_vertical,\n                           pad_horizontal, output_size=(244, 244)):\n        arr = np.array(im)\n        # add an example occlusion\n        self.add_occlusion_to_arr(arr,\n                                  (centers_vertical[1] - pad_vertical,\n                                   centers_horizontal[1] - pad_horizontal),\n                                  win_width, win_length, occ_val=100)\n        # add grid\n        g_pad_vertical = round(self.grid_percent * im.size[1]) or 1\n        g_pad_horizontal = round(self.grid_percent * im.size[0]) or 1\n        w_grid = 2 * g_pad_horizontal\n        l_grid = 2 * g_pad_vertical\n        upper_left_corners = np.array(\n            [(w - g_pad_vertical, v - g_pad_horizontal)\n             for w in centers_vertical\n             for v in centers_horizontal]\n        )\n        for corner in upper_left_corners:\n            self.add_occlusion_to_arr(arr, corner,\n                                      w_grid, l_grid)\n        return Image.fromarray(arr)\n\n    @staticmethod\n    def get_centers(width, length,\n                    win_width, win_length,\n                    pad_horizontal, pad_vertical,\n                    num_windows):\n        centers_horizontal = np.linspace(pad_horizontal,\n                                         width - pad_horizontal,\n                                         num_windows).astype(\'int\')\n        centers_vertical = np.linspace(pad_vertical,\n                                       length - pad_vertical,\n                                       num_windows).astype(\'int\')\n        return centers_horizontal, centers_vertical\n\n    @staticmethod\n    def add_occlusion_to_arr(arr, upper_left_corner,\n                             width_horizontal,\n                             width_vertical,\n                             occ_val=0):\n        arr[upper_left_corner[0]:\n            upper_left_corner[0] + width_vertical,\n            upper_left_corner[1]:\n            upper_left_corner[1] + width_horizontal] = occ_val\n'"
picasso/visualizations/saliency_maps.py,2,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport os\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nfrom matplotlib import pyplot\n\nfrom picasso.visualizations.base import BaseVisualization\n\n\nclass SaliencyMaps(BaseVisualization):\n    """"""Derivative of classification with respect to input pixels\n\n    Saliency maps are a way of showing which inputs matter most to\n    classification.  The derivative of a class probability with\n    respect to each input pixel are found with backpropagation.\n    High values for the derivative indicate pixels important to\n    classification (as changing them would change the classification).\n\n    """"""\n    DESCRIPTION = (\'See maximal derivates against class with respect \'\n                   \'to input\')\n\n    REFERENCE_LINK = \'https://arxiv.org/pdf/1312.6034\'\n\n    ALLOWED_SETTINGS = {\'Transparency\': [\'0.0\', \'0.25\', \'0.5\', \'0.75\']}\n\n    @property\n    def transparency(self):\n        return float(self._transparency)\n\n    def __init__(self, model, logit_tensor_name=None):\n        super().__init__(model)\n        if logit_tensor_name:\n            self.logit_tensor = self.model.sess.graph.get_tensor_by_name(\n                logit_tensor_name)\n        else:\n            self.logit_tensor = self.get_logit_tensor()\n\n        self.input_shape = self.model.tf_input_var.get_shape()[1:].as_list()\n\n    def get_gradient_wrt_class(self, class_index):\n        gradient_name = \'bv_{class_index}_gradient\'.format(\n            class_index=class_index)\n        try:\n            return self.model.sess.graph.get_tensor_by_name(\n                \'{}:0\'.format(gradient_name))\n        except KeyError:\n            class_logit = tf.slice(self.logit_tensor,\n                                   [0, class_index],\n                                   [1, 1])\n            return tf.gradients(class_logit,\n                                self.model.tf_input_var,\n                                name=gradient_name)[0]\n\n    def make_visualization(self, inputs, output_dir):\n\n        pre_processed_arrays = self.model.preprocess([example[\'data\']\n                                                     for example in inputs])\n\n        # get predictions\n        predictions = self.model.sess.run(self.model.tf_predict_var,\n                                          feed_dict={self.model.tf_input_var:\n                                                     pre_processed_arrays})\n        decoded_predictions = self.model.decode_prob(predictions)\n\n        results = []\n        for i, inp in enumerate(inputs):\n            class_gradients = []\n            relevant_class_indices = [pred[\'index\']\n                                      for pred in decoded_predictions[i]]\n            gradients_wrt_class = [self.get_gradient_wrt_class(index)\n                                   for index in relevant_class_indices]\n            for gradient_wrt_class in gradients_wrt_class:\n                class_gradients.append([self.model.sess.run(\n                    gradient_wrt_class,\n                    feed_dict={self.model.tf_input_var: [arr]})\n                    for arr in pre_processed_arrays])\n\n            output_arrays = np.array([gradient[i]\n                                      for gradient in class_gradients])\n            # if images are color, take the maximum channel\n            if output_arrays.shape[-1] == 3:\n                output_arrays = output_arrays.max(-1)\n            # we care about the size of the derivative, not the sign\n            output_arrays = np.abs(output_arrays)\n\n            # We want each array to be represented as a 1-channel image of\n            # the same size as the model\'s input image.\n            output_images = output_arrays.reshape([-1] + self.input_shape[0:2])\n\n            output_fns = []\n            pyplot.clf()\n            for j, output_image in enumerate(output_images):\n                output_fn = \'{fn}-{j}-{ts}.png\'.format(ts=str(time.time()),\n                                                       j=j,\n                                                       fn=inp[\'filename\'])\n\n                if j == 0:\n                    pyplot.imshow(inputs[i][\'data\']\n                                  .resize(output_image.shape)\n                                  .convert(\'RGB\'),\n                                  alpha=self.transparency)\n\n                    im = pyplot.imshow(output_image,\n                                       alpha=1. - self.transparency,\n                                       cmap=\'inferno\')\n                    pyplot.axis(\'off\')\n                    im.axes.get_xaxis().set_visible(False)\n                    im.axes.get_yaxis().set_visible(False)\n                else:\n                    im.set_data(output_image)\n\n                pyplot.savefig(os.path.join(output_dir, output_fn),\n                               bbox_inches=\'tight\', pad_inches=0)\n                output_fns.append(output_fn)\n\n            results.append({\'input_file_name\': inp[\'filename\'],\n                            \'has_output\': True,\n                            \'predict_probs\': decoded_predictions[i],\n                            \'has_processed_input\': False,\n                            \'output_file_names\': output_fns})\n        return results\n\n    def get_logit_tensor(self):\n        # Assume that the logits are the tensor input to the last softmax\n        # operation in the computation graph\n        sm = [node\n              for node in self.model.sess.graph_def.node\n              if node.name == self.model.tf_predict_var.name.split(\':\')[0]][-1]\n        logit_op_name = sm.input[0]\n        return self.model.sess.graph.get_tensor_by_name(\n            \'{}:0\'.format(logit_op_name))\n'"
picasso/examples/keras-vgg16/config.py,0,"b""###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\n\n# Note: By default, Flask doesn't know that this file exists.  If you want\n# Flask to load the settings you specify here, you must set the environment\n# variable `PICASSO_SETTINGS` to point to this file.  E.g.:\n#\n#   export PICASSO_SETTINGS=/path/to/examples/keras-vgg16/config.py\n#\nimport os\n\nbase_dir = os.path.dirname(os.path.abspath(__file__))\n\nMODEL_CLS_PATH = os.path.join(base_dir, 'model.py')\nMODEL_CLS_NAME = 'KerasVGG16Model'\nMODEL_LOAD_ARGS = {\n    'data_dir': os.path.join(base_dir, 'data-volume'),\n}\n"""
picasso/examples/keras-vgg16/model.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nfrom keras.applications import imagenet_utils\nimport numpy as np\nfrom PIL import Image\n\nfrom picasso.models.keras import KerasModel\n\nVGG16_DIM = (224, 224, 3)\n\n\nclass KerasVGG16Model(KerasModel):\n\n    def preprocess(self, raw_inputs):\n        """"""\n        Args:\n            raw_inputs (list of Images): a list of PIL Image objects\n        Returns:\n            array (float32): num images * height * width * num channels\n        """"""\n        image_arrays = []\n        for raw_im in raw_inputs:\n            im = raw_im.resize(VGG16_DIM[:2], Image.ANTIALIAS)\n            im = im.convert(\'RGB\')\n            arr = np.array(im).astype(\'float32\')\n            image_arrays.append(arr)\n\n        all_raw_inputs = np.array(image_arrays)\n        return imagenet_utils.preprocess_input(all_raw_inputs)\n\n    def decode_prob(self, class_probabilities):\n        r = imagenet_utils.decode_predictions(class_probabilities,\n                                              top=self.top_probs)\n        results = [\n            [{\'code\': entry[0],\n              \'name\': entry[1],\n              \'prob\': \'{:.3f}\'.format(entry[2])}\n             for entry in row]\n            for row in r\n        ]\n        classes = imagenet_utils.CLASS_INDEX\n        class_keys = list(classes.keys())\n        class_values = list(classes.values())\n\n        for result in results:\n            for entry in result:\n                entry[\'index\'] = int(\n                    class_keys[class_values.index([entry[\'code\'],\n                                                   entry[\'name\']])])\n        return results\n'"
picasso/examples/keras-vgg16/prepare_model.py,0,"b""###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n###############################################################################\nimport os\nimport json\nfrom keras.applications.vgg16 import VGG16\n\npath = 'data-volume'\ntry:\n    os.mkdir(path)\nexcept FileExistsError:\n    pass\n\nprint('Downloading and setting up VGG16...')\n\nvgg16 = VGG16()\n\nprint('Saving...')\n\nif not os.path.exists(os.path.join(os.path.dirname(__file__), path)):\n    os.makedirs(os.path.join(os.path.dirname(__file__), path))\n\nwith open(os.path.join(os.path.dirname(__file__),\n                       path,\n                       'vgg16.json'), 'w') as json_file:\n    json.dump(vgg16.to_json(), json_file)\n\nvgg16.save_weights(os.path.join(os.path.dirname(__file__),\n                                path,\n                                'vgg16.hdf5'))\n\nprint('Done.')\n"""
picasso/examples/keras/config.py,0,"b""###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\n\n# Note: By default, Flask doesn't know that this file exists.  If you want\n# Flask to load the settings you specify here, you must set the environment\n# variable `PICASSO_SETTINGS` to point to this file.  E.g.:\n#\n#   export PICASSO_SETTINGS=/path/to/examples/keras/config.py\n#\nimport os\n\nbase_dir = os.path.dirname(os.path.abspath(__file__))\n\nMODEL_CLS_PATH = os.path.join(base_dir, 'model.py')\nMODEL_CLS_NAME = 'KerasMNISTModel'\nMODEL_LOAD_ARGS = {\n    'data_dir': os.path.join(base_dir, 'data-volume'),\n}\n"""
picasso/examples/keras/model.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport numpy as np\nfrom PIL import Image\n\nfrom picasso.models.keras import KerasModel\n\nMNIST_DIM = (28, 28)\n\n\nclass KerasMNISTModel(KerasModel):\n\n    def preprocess(self, raw_inputs):\n        """"""Convert images into the format required by our model.\n\n        Our model requires that inputs be grayscale (mode \'L\'), be resized to\n        `MNIST_DIM`, and be represented as float32 numpy arrays in range\n        [0, 1].\n\n        Args:\n            raw_inputs (list of Images): a list of PIL Image objects\n\n        Returns:\n            array (float32): num images * height * width * num channels\n\n        """"""\n        image_arrays = []\n        for raw_im in raw_inputs:\n            im = raw_im.convert(\'L\')\n            im = im.resize(MNIST_DIM, Image.ANTIALIAS)\n            arr = np.array(im)\n            image_arrays.append(arr)\n\n        inputs = np.array(image_arrays)\n        return inputs.reshape(len(inputs),\n                              MNIST_DIM[0],\n                              MNIST_DIM[1], 1).astype(\'float32\') / 255\n'"
picasso/examples/tensorflow/config.py,0,"b""###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\n\n# Note: By default, Flask doesn't know that this file exists.  If you want\n# Flask to load the settings you specify here, you must set the environment\n# variable `PICASSO_SETTINGS` to point to this file.  E.g.:\n#\n#   export PICASSO_SETTINGS=/path/to/examples/tensorflow/config.py\n#\nimport os\n\nbase_dir = os.path.dirname(os.path.abspath(__file__))\n\nMODEL_CLS_PATH = os.path.join(base_dir, 'model.py')\nMODEL_CLS_NAME = 'TensorflowMNISTModel'\nMODEL_LOAD_ARGS = {\n    'data_dir': os.path.join(base_dir, 'data-volume'),\n    'tf_input_var': 'convolution2d_input_1:0',\n    'tf_predict_var': 'Softmax:0',\n}\n"""
picasso/examples/tensorflow/model.py,0,"b'###############################################################################\n# Copyright (c) 2017 Merantix GmbH\n# All rights reserved. This program and the accompanying materials\n# are made available under the terms of the Eclipse Public License v1.0\n# which accompanies this distribution, and is available at\n# http://www.eclipse.org/legal/epl-v10.html\n#\n# Contributors:\n#    Ryan Henderson - initial API and implementation and/or initial\n#    documentation\n#    Josh Chen - refactor and class config\n###############################################################################\nimport numpy as np\nfrom PIL import Image\n\nfrom picasso.models.tensorflow import TFModel\n\nMNIST_DIM = (28, 28)\n\n\nclass TensorflowMNISTModel(TFModel):\n\n    def preprocess(self, raw_inputs):\n        """"""Convert images into the format required by our model.\n\n        Our model requires that inputs be grayscale (mode \'L\'), be resized to\n        `MNIST_DIM`, and be represented as float32 numpy arrays in range\n        [0, 1].\n\n        Args:\n            raw_inputs (list of Images): a list of PIL Image objects\n\n        Returns:\n            array (float32): num images * height * width * num channels\n\n        """"""\n        image_arrays = []\n        for raw_im in raw_inputs:\n            im = raw_im.convert(\'L\')\n            im = im.resize(MNIST_DIM, Image.ANTIALIAS)\n            arr = np.array(im)\n            image_arrays.append(arr)\n\n        inputs = np.array(image_arrays)\n        return inputs.reshape(len(inputs),\n                              MNIST_DIM[0],\n                              MNIST_DIM[1], 1).astype(\'float32\') / 255\n'"
