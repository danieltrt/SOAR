file_path,api_count,code
InstallPackages.py,0,"b""import os\n\n# Run this script from within an anaconda virtual environment to install the required packages\n# Be sure to run this script as root or as administrator.\n\nos.system('python -m pip install --upgrade pip')\n#os.system('conda update -n base conda')\nos.system('conda install jupyter')\nos.system('pip install matplotlib==2.1.2')\nos.system('pip install image')\nos.system('pip install keras_tqdm')\nos.system('conda install -c conda-forge opencv')\nos.system('pip install msgpack-rpc-python')\nos.system('pip install pandas')\nos.system('pip install numpy')\nos.system('conda install scipy')"""
AirSimE2EDeepLearning/AirSimClient.py,0,"b'from __future__ import print_function\nimport msgpackrpc #install as admin: pip install msgpack-rpc-python\nimport numpy as np #pip install numpy\nimport msgpack\nimport math\nimport time\nimport sys\nimport os\nimport inspect\nimport types\nimport re\n\n\nclass MsgpackMixin:\n    def to_msgpack(self, *args, **kwargs):\n        return self.__dict__ #msgpack.dump(self.to_dict(*args, **kwargs))\n\n    @classmethod\n    def from_msgpack(cls, encoded):\n        obj = cls()\n        obj.__dict__ = {k.decode(\'utf-8\'): v for k, v in encoded.items()}\n        return obj\n\n\nclass AirSimImageType:    \n    Scene = 0\n    DepthPlanner = 1\n    DepthPerspective = 2\n    DepthVis = 3\n    DisparityNormalized = 4\n    Segmentation = 5\n    SurfaceNormals = 6\n\nclass DrivetrainType:\n    MaxDegreeOfFreedom = 0\n    ForwardOnly = 1\n    \nclass LandedState:\n    Landed = 0\n    Flying = 1\n\nclass Vector3r(MsgpackMixin):\n    x_val = np.float32(0)\n    y_val = np.float32(0)\n    z_val = np.float32(0)\n\n    def __init__(self, x_val = np.float32(0), y_val = np.float32(0), z_val = np.float32(0)):\n        self.x_val = x_val\n        self.y_val = y_val\n        self.z_val = z_val\n\n\nclass Quaternionr(MsgpackMixin):\n    w_val = np.float32(0)\n    x_val = np.float32(0)\n    y_val = np.float32(0)\n    z_val = np.float32(0)\n\n    def __init__(self, x_val = np.float32(0), y_val = np.float32(0), z_val = np.float32(0), w_val = np.float32(1)):\n        self.x_val = x_val\n        self.y_val = y_val\n        self.z_val = z_val\n        self.w_val = w_val\n\nclass Pose(MsgpackMixin):\n    position = Vector3r()\n    orientation = Quaternionr()\n\n    def __init__(self, position_val, orientation_val):\n        self.position = position_val\n        self.orientation = orientation_val\n\n\nclass CollisionInfo(MsgpackMixin):\n    has_collided = False\n    normal = Vector3r()\n    impact_point = Vector3r()\n    position = Vector3r()\n    penetration_depth = np.float32(0)\n    time_stamp = np.float32(0)\n    object_name = """"\n    object_id = -1\n\nclass GeoPoint(MsgpackMixin):\n    latitude = 0.0\n    longitude = 0.0\n    altitude = 0.0\n\nclass YawMode(MsgpackMixin):\n    is_rate = True\n    yaw_or_rate = 0.0\n    def __init__(self, is_rate = True, yaw_or_rate = 0.0):\n        self.is_rate = is_rate\n        self.yaw_or_rate = yaw_or_rate\n\nclass ImageRequest(MsgpackMixin):\n    camera_id = np.uint8(0)\n    image_type = AirSimImageType.Scene\n    pixels_as_float = False\n    compress = False\n\n    def __init__(self, camera_id, image_type, pixels_as_float = False, compress = True):\n        self.camera_id = camera_id\n        self.image_type = image_type\n        self.pixels_as_float = pixels_as_float\n        self.compress = compress\n\n\nclass ImageResponse(MsgpackMixin):\n    image_data_uint8 = np.uint8(0)\n    image_data_float = np.float32(0)\n    camera_position = Vector3r()\n    camera_orientation = Quaternionr()\n    time_stamp = np.uint64(0)\n    message = \'\'\n    pixels_as_float = np.float32(0)\n    compress = True\n    width = 0\n    height = 0\n    image_type = AirSimImageType.Scene\n\nclass CarControls(MsgpackMixin):\n    throttle = np.float32(0)\n    steering = np.float32(0)\n    brake = np.float32(0)\n    handbrake = False\n    is_manual_gear = False\n    manual_gear = 0\n    gear_immediate = True\n\n    def set_throttle(self, throttle_val, forward):\n        if (forward):\n            is_manual_gear = False\n            manual_gear = 0\n            throttle = abs(throttle_val)\n        else:\n            is_manual_gear = False\n            manual_gear = -1\n            throttle = - abs(throttle_val)\n\nclass CarState(MsgpackMixin):\n    speed = np.float32(0)\n    gear = 0\n    position = Vector3r()\n    velocity = Vector3r()\n    orientation = Quaternionr()\n\nclass AirSimClientBase:\n    def __init__(self, ip, port):\n        self.client = msgpackrpc.Client(msgpackrpc.Address(ip, port), timeout = 3600)\n        \n    def ping(self):\n        return self.client.call(\'ping\')\n    \n    def reset(self):\n        self.client.call(\'reset\')\n\n    def confirmConnection(self):\n        print(\'Waiting for connection: \', end=\'\')\n        home = self.getHomeGeoPoint()\n        while ((home.latitude == 0 and home.longitude == 0 and home.altitude == 0) or\n                math.isnan(home.latitude) or  math.isnan(home.longitude) or  math.isnan(home.altitude)):\n            time.sleep(1)\n            home = self.getHomeGeoPoint()\n            print(\'X\', end=\'\')\n        print(\'\')\n\n    def getHomeGeoPoint(self):\n        return GeoPoint.from_msgpack(self.client.call(\'getHomeGeoPoint\'))\n\n    # basic flight control\n    def enableApiControl(self, is_enabled):\n        return self.client.call(\'enableApiControl\', is_enabled)\n    def isApiControlEnabled(self):\n        return self.client.call(\'isApiControlEnabled\')\n\n    def simSetSegmentationObjectID(self, mesh_name, object_id, is_name_regex = False):\n        return self.client.call(\'simSetSegmentationObjectID\', mesh_name, object_id, is_name_regex)\n    def simGetSegmentationObjectID(self, mesh_name):\n        return self.client.call(\'simGetSegmentationObjectID\', mesh_name)\n            \n    # camera control\n    # simGetImage returns compressed png in array of bytes\n    # image_type uses one of the AirSimImageType members\n    def simGetImage(self, camera_id, image_type):\n        # because this method returns std::vector<uint8>, msgpack decides to encode it as a string unfortunately.\n        result = self.client.call(\'simGetImage\', camera_id, image_type)\n        if (result == """" or result == ""\\0""):\n            return None\n        return result\n\n    # camera control\n    # simGetImage returns compressed png in array of bytes\n    # image_type uses one of the AirSimImageType members\n    def simGetImages(self, requests):\n        responses_raw = self.client.call(\'simGetImages\', requests)\n        return [ImageResponse.from_msgpack(response_raw) for response_raw in responses_raw]\n\n    def getCollisionInfo(self):\n        return CollisionInfo.from_msgpack(self.client.call(\'getCollisionInfo\'))\n\n    @staticmethod\n    def stringToUint8Array(bstr):\n        return np.fromstring(bstr, np.uint8)\n    @staticmethod\n    def stringToFloatArray(bstr):\n        return np.fromstring(bstr, np.float32)\n    @staticmethod\n    def listTo2DFloatArray(flst, width, height):\n        return np.reshape(np.asarray(flst, np.float32), (height, width))\n    @staticmethod\n    def getPfmArray(response):\n        return AirSimClientBase.listTo2DFloatArray(response.image_data_float, response.width, response.height)\n\n    @staticmethod\n    def get_public_fields(obj):\n        return [attr for attr in dir(obj)\n                             if not (attr.startswith(""_"") \n                                or inspect.isbuiltin(attr)\n                                or inspect.isfunction(attr)\n                                or inspect.ismethod(attr))]\n\n\n    @staticmethod\n    def to_dict(obj):\n        return dict([attr, getattr(obj, attr)] for attr in AirSimClientBase.get_public_fields(obj))\n\n    @staticmethod\n    def to_str(obj):\n        return str(AirSimClientBase.to_dict(obj))\n\n    @staticmethod\n    def write_file(filename, bstr):\n        with open(filename, \'wb\') as afile:\n            afile.write(bstr)\n\n    def simSetPose(self, pose, ignore_collison):\n        self.client.call(\'simSetPose\', pose, ignore_collison)\n\n    def simGetPose(self):\n        return self.client.call(\'simGetPose\')\n\n    # helper method for converting getOrientation to roll/pitch/yaw\n    # https:#en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles\n    @staticmethod\n    def toEulerianAngle(q):\n        z = q.z_val\n        y = q.y_val\n        x = q.x_val\n        w = q.w_val\n        ysqr = y * y\n\n        # roll (x-axis rotation)\n        t0 = +2.0 * (w*x + y*z)\n        t1 = +1.0 - 2.0*(x*x + ysqr)\n        roll = math.atan2(t0, t1)\n\n        # pitch (y-axis rotation)\n        t2 = +2.0 * (w*y - z*x)\n        if (t2 > 1.0):\n            t2 = 1\n        if (t2 < -1.0):\n            t2 = -1.0\n        pitch = math.asin(t2)\n\n        # yaw (z-axis rotation)\n        t3 = +2.0 * (w*z + x*y)\n        t4 = +1.0 - 2.0 * (ysqr + z*z)\n        yaw = math.atan2(t3, t4)\n\n        return (pitch, roll, yaw)\n\n    @staticmethod\n    def toQuaternion(pitch, roll, yaw):\n        t0 = math.cos(yaw * 0.5)\n        t1 = math.sin(yaw * 0.5)\n        t2 = math.cos(roll * 0.5)\n        t3 = math.sin(roll * 0.5)\n        t4 = math.cos(pitch * 0.5)\n        t5 = math.sin(pitch * 0.5)\n\n        q = Quaternionr()\n        q.w_val = t0 * t2 * t4 + t1 * t3 * t5 #w\n        q.x_val = t0 * t3 * t4 - t1 * t2 * t5 #x\n        q.y_val = t0 * t2 * t5 + t1 * t3 * t4 #y\n        q.z_val = t1 * t2 * t4 - t0 * t3 * t5 #z\n        return q\n\n    @staticmethod\n    def wait_key(message = \'\'):\n        \'\'\' Wait for a key press on the console and return it. \'\'\'\n        if message != \'\':\n            print (message)\n\n        result = None\n        if os.name == \'nt\':\n            import msvcrt\n            result = msvcrt.getch()\n        else:\n            import termios\n            fd = sys.stdin.fileno()\n\n            oldterm = termios.tcgetattr(fd)\n            newattr = termios.tcgetattr(fd)\n            newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO\n            termios.tcsetattr(fd, termios.TCSANOW, newattr)\n\n            try:\n                result = sys.stdin.read(1)\n            except IOError:\n                pass\n            finally:\n                termios.tcsetattr(fd, termios.TCSAFLUSH, oldterm)\n\n        return result\n\n    @staticmethod\n    def read_pfm(file):\n        """""" Read a pfm file """"""\n        file = open(file, \'rb\')\n\n        color = None\n        width = None\n        height = None\n        scale = None\n        endian = None\n\n        header = file.readline().rstrip()\n        header = str(bytes.decode(header, encoding=\'utf-8\'))\n        if header == \'PF\':\n            color = True\n        elif header == \'Pf\':\n            color = False\n        else:\n            raise Exception(\'Not a PFM file.\')\n\n        temp_str = str(bytes.decode(file.readline(), encoding=\'utf-8\'))\n        dim_match = re.match(r\'^(\\d+)\\s(\\d+)\\s$\', temp_str)\n        if dim_match:\n            width, height = map(int, dim_match.groups())\n        else:\n            raise Exception(\'Malformed PFM header.\')\n\n        scale = float(file.readline().rstrip())\n        if scale < 0: # little-endian\n            endian = \'<\'\n            scale = -scale\n        else:\n            endian = \'>\' # big-endian\n\n        data = np.fromfile(file, endian + \'f\')\n        shape = (height, width, 3) if color else (height, width)\n\n        data = np.reshape(data, shape)\n        # DEY: I don\'t know why this was there.\n        #data = np.flipud(data)\n        file.close()\n    \n        return data, scale\n\n    @staticmethod\n    def write_pfm(file, image, scale=1):\n        """""" Write a pfm file """"""\n        file = open(file, \'wb\')\n\n        color = None\n\n        if image.dtype.name != \'float32\':\n            raise Exception(\'Image dtype must be float32.\')\n\n        image = np.flipud(image)\n\n        if len(image.shape) == 3 and image.shape[2] == 3: # color image\n            color = True\n        elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1: # greyscale\n            color = False\n        else:\n            raise Exception(\'Image must have H x W x 3, H x W x 1 or H x W dimensions.\')\n\n        file.write(\'PF\\n\'.encode(\'utf-8\')  if color else \'Pf\\n\'.encode(\'utf-8\'))\n        temp_str = \'%d %d\\n\' % (image.shape[1], image.shape[0])\n        file.write(temp_str.encode(\'utf-8\'))\n\n        endian = image.dtype.byteorder\n\n        if endian == \'<\' or endian == \'=\' and sys.byteorder == \'little\':\n            scale = -scale\n\n        temp_str = \'%f\\n\' % scale\n        file.write(temp_str.encode(\'utf-8\'))\n\n        image.tofile(file)\n\n    @staticmethod\n    def write_png(filename, image):\n        """""" image must be numpy array H X W X channels\n        """"""\n        import zlib, struct\n\n        buf = image.flatten().tobytes()\n        width = image.shape[1]\n        height = image.shape[0]\n\n        # reverse the vertical line order and add null bytes at the start\n        width_byte_4 = width * 4\n        raw_data = b\'\'.join(b\'\\x00\' + buf[span:span + width_byte_4]\n                            for span in range((height - 1) * width_byte_4, -1, - width_byte_4))\n\n        def png_pack(png_tag, data):\n            chunk_head = png_tag + data\n            return (struct.pack(""!I"", len(data)) +\n                    chunk_head +\n                    struct.pack(""!I"", 0xFFFFFFFF & zlib.crc32(chunk_head)))\n\n        png_bytes = b\'\'.join([\n            b\'\\x89PNG\\r\\n\\x1a\\n\',\n            png_pack(b\'IHDR\', struct.pack(""!2I5B"", width, height, 8, 6, 0, 0, 0)),\n            png_pack(b\'IDAT\', zlib.compress(raw_data, 9)),\n            png_pack(b\'IEND\', b\'\')])\n\n        AirSimClientBase.write_file(filename, png_bytes)\n\n\n# -----------------------------------  Multirotor APIs ---------------------------------------------\nclass MultirotorClient(AirSimClientBase, object):\n    def __init__(self, ip = """"):\n        if (ip == """"):\n            ip = ""127.0.0.1""\n        super(MultirotorClient, self).__init__(ip, 41451)\n\n    def armDisarm(self, arm):\n        return self.client.call(\'armDisarm\', arm)\n\n    def takeoff(self, max_wait_seconds = 15):\n        return self.client.call(\'takeoff\', max_wait_seconds)\n        \n    def land(self, max_wait_seconds = 60):\n        return self.client.call(\'land\', max_wait_seconds)\n        \n    def goHome(self):\n        return self.client.call(\'goHome\')\n\n    def hover(self):\n        return self.client.call(\'hover\')\n\n        \n    # query vehicle state\n    def getPosition(self):\n        return Vector3r.from_msgpack(self.client.call(\'getPosition\'))\n    def getVelocity(self):\n        return Vector3r.from_msgpack(self.client.call(\'getVelocity\'))\n    def getOrientation(self):\n        return Quaternionr.from_msgpack(self.client.call(\'getOrientation\'))\n    def getLandedState(self):\n        return self.client.call(\'getLandedState\')\n    def getGpsLocation(self):\n        return GeoPoint.from_msgpack(self.client.call(\'getGpsLocation\'))\n    def getPitchRollYaw(self):\n        return self.toEulerianAngle(self.getOrientation())\n\n    #def getRCData(self):\n    #    return self.client.call(\'getRCData\')\n    def timestampNow(self):\n        return self.client.call(\'timestampNow\')\n    def isApiControlEnabled(self):\n        return self.client.call(\'isApiControlEnabled\')\n    def isSimulationMode(self):\n        return self.client.call(\'isSimulationMode\')\n    def getServerDebugInfo(self):\n        return self.client.call(\'getServerDebugInfo\')\n\n\n    # APIs for control\n    def moveByAngle(self, pitch, roll, z, yaw, duration):\n        return self.client.call(\'moveByAngle\', pitch, roll, z, yaw, duration)\n\n    def moveByVelocity(self, vx, vy, vz, duration, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode()):\n        return self.client.call(\'moveByVelocity\', vx, vy, vz, duration, drivetrain, yaw_mode)\n\n    def moveByVelocityZ(self, vx, vy, z, duration, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode()):\n        return self.client.call(\'moveByVelocityZ\', vx, vy, z, duration, drivetrain, yaw_mode)\n\n    def moveOnPath(self, path, velocity, max_wait_seconds = 60, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode(), lookahead = -1, adaptive_lookahead = 1):\n        return self.client.call(\'moveOnPath\', path, velocity, max_wait_seconds, drivetrain, yaw_mode, lookahead, adaptive_lookahead)\n\n    def moveToZ(self, z, velocity, max_wait_seconds = 60, yaw_mode = YawMode(), lookahead = -1, adaptive_lookahead = 1):\n        return self.client.call(\'moveToZ\', z, velocity, max_wait_seconds, yaw_mode, lookahead, adaptive_lookahead)\n\n    def moveToPosition(self, x, y, z, velocity, max_wait_seconds = 60, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode(), lookahead = -1, adaptive_lookahead = 1):\n        return self.client.call(\'moveToPosition\', x, y, z, velocity, max_wait_seconds, drivetrain, yaw_mode, lookahead, adaptive_lookahead)\n\n    def moveByManual(self, vx_max, vy_max, z_min, duration, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode()):\n        return self.client.call(\'moveByManual\', vx_max, vy_max, z_min, duration, drivetrain, yaw_mode)\n\n    def rotateToYaw(self, yaw, max_wait_seconds = 60, margin = 5):\n        return self.client.call(\'rotateToYaw\', yaw, max_wait_seconds, margin)\n\n    def rotateByYawRate(self, yaw_rate, duration):\n        return self.client.call(\'rotateByYawRate\', yaw_rate, duration)\n\n# -----------------------------------  Car APIs ---------------------------------------------\nclass CarClient(AirSimClientBase, object):\n    def __init__(self, ip = """"):\n        if (ip == """"):\n            ip = ""127.0.0.1""\n        super(CarClient, self).__init__(ip, 42451)\n\n    def setCarControls(self, controls):\n        self.client.call(\'setCarControls\', controls)\n\n    def getCarState(self):\n        state_raw = self.client.call(\'getCarState\')\n        return CarState.from_msgpack(state_raw)\n'"
AirSimE2EDeepLearning/Cooking.py,0,"b'import random\nimport csv\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport sys\nimport os\nimport errno\nfrom collections import OrderedDict\nimport h5py\nfrom pathlib import Path\nimport copy\nimport re\n\ndef checkAndCreateDir(full_path):\n    """"""Checks if a given path exists and if not, creates the needed directories.\n            Inputs:\n                full_path: path to be checked\n    """"""\n    if not os.path.exists(os.path.dirname(full_path)):\n        try:\n            os.makedirs(os.path.dirname(full_path))\n        except OSError as exc:  # Guard against race condition\n            if exc.errno != errno.EEXIST:\n                raise\n                \ndef readImagesFromPath(image_names):\n    """""" Takes in a path and a list of image file names to be loaded and returns a list of all loaded images after resize.\n           Inputs:\n                image_names: list of image names\n           Returns:\n                List of all loaded and resized images\n    """"""\n    returnValue = []\n    for image_name in image_names:\n        im = Image.open(image_name)\n        imArr = np.asarray(im)\n        \n        #Remove alpha channel if exists\n        if len(imArr.shape) == 3 and imArr.shape[2] == 4:\n            if (np.all(imArr[:, :, 3] == imArr[0, 0, 3])):\n                imArr = imArr[:,:,0:3]\n        if len(imArr.shape) != 3 or imArr.shape[2] != 3:\n            print(\'Error: Image\', image_name, \'is not RGB.\')\n            sys.exit()            \n\n        returnIm = np.asarray(imArr)\n\n        returnValue.append(returnIm)\n    return returnValue\n    \n    \n    \ndef splitTrainValidationAndTestData(all_data_mappings, split_ratio=(0.7, 0.2, 0.1)):\n    """"""Simple function to create train, validation and test splits on the data.\n            Inputs:\n                all_data_mappings: mappings from the entire dataset\n                split_ratio: (train, validation, test) split ratio\n\n            Returns:\n                train_data_mappings: mappings for training data\n                validation_data_mappings: mappings for validation data\n                test_data_mappings: mappings for test data\n\n    """"""\n    if round(sum(split_ratio), 5) != 1.0:\n        print(""Error: Your splitting ratio should add up to 1"")\n        sys.exit()\n\n    train_split = int(len(all_data_mappings) * split_ratio[0])\n    val_split = train_split + int(len(all_data_mappings) * split_ratio[1])\n\n    train_data_mappings = all_data_mappings[0:train_split]\n    validation_data_mappings = all_data_mappings[train_split:val_split]\n    test_data_mappings = all_data_mappings[val_split:]\n\n    return [train_data_mappings, validation_data_mappings, test_data_mappings]\n    \ndef generateDataMapAirSim(folders):\n    """""" Data map generator for simulator(AirSim) data. Reads the driving_log csv file and returns a list of \'center camera image name - label(s)\' tuples\n           Inputs:\n               folders: list of folders to collect data from\n\n           Returns:\n               mappings: All data mappings as a dictionary. Key is the image filepath, the values are a 2-tuple:\n                   0 -> label(s) as a list of double\n                   1 -> previous state as a list of double\n    """"""\n\n    all_mappings = {}\n    for folder in folders:\n        print(\'Reading data from {0}...\'.format(folder))\n        current_df = pd.read_csv(os.path.join(folder, \'airsim_rec.txt\'), sep=\'\\t\')\n        \n        for i in range(1, current_df.shape[0] - 1, 1):\n            previous_state = list(current_df.iloc[i-1][[\'Steering\', \'Throttle\', \'Brake\', \'Speed (kmph)\']])\n            current_label = list((current_df.iloc[i][[\'Steering\']] + current_df.iloc[i-1][[\'Steering\']] + current_df.iloc[i+1][[\'Steering\']]) / 3.0)\n            \n            image_filepath = os.path.join(os.path.join(folder, \'images\'), current_df.iloc[i][\'ImageName\']).replace(\'\\\\\', \'/\')\n            \n            # Sanity check\n            if (image_filepath in all_mappings):\n                print(\'Error: attempting to add image {0} twice.\'.format(image_filepath))\n            \n            all_mappings[image_filepath] = (current_label, previous_state)\n    \n    mappings = [(key, all_mappings[key]) for key in all_mappings]\n    \n    random.shuffle(mappings)\n    \n    return mappings\n\ndef generatorForH5py(data_mappings, chunk_size=32):\n    """"""\n    This function batches the data for saving to the H5 file\n    """"""\n    for chunk_id in range(0, len(data_mappings), chunk_size):\n        # Data is expected to be a dict of <image: (label, previousious_state)>\n        # Extract the parts\n        data_chunk = data_mappings[chunk_id:chunk_id + chunk_size]\n        if (len(data_chunk) == chunk_size):\n            image_names_chunk = [a for (a, b) in data_chunk]\n            labels_chunk = np.asarray([b[0] for (a, b) in data_chunk])\n            previous_state_chunk = np.asarray([b[1] for (a, b) in data_chunk])\n            \n            #Flatten and yield as tuple\n            yield (image_names_chunk, labels_chunk.astype(float), previous_state_chunk.astype(float))\n            if chunk_id + chunk_size > len(data_mappings):\n                raise StopIteration\n    raise StopIteration\n    \ndef saveH5pyData(data_mappings, target_file_path):\n    """"""\n    Saves H5 data to file\n    """"""\n    chunk_size = 32\n    gen = generatorForH5py(data_mappings,chunk_size)\n\n    image_names_chunk, labels_chunk, previous_state_chunk = next(gen)\n    images_chunk = np.asarray(readImagesFromPath(image_names_chunk))\n    row_count = images_chunk.shape[0]\n\n    checkAndCreateDir(target_file_path)\n    with h5py.File(target_file_path, \'w\') as f:\n\n        # Initialize a resizable dataset to hold the output\n        images_chunk_maxshape = (None,) + images_chunk.shape[1:]\n        labels_chunk_maxshape = (None,) + labels_chunk.shape[1:]\n        previous_state_maxshape = (None,) + previous_state_chunk.shape[1:]\n\n        dset_images = f.create_dataset(\'image\', shape=images_chunk.shape, maxshape=images_chunk_maxshape,\n                                chunks=images_chunk.shape, dtype=images_chunk.dtype)\n\n        dset_labels = f.create_dataset(\'label\', shape=labels_chunk.shape, maxshape=labels_chunk_maxshape,\n                                       chunks=labels_chunk.shape, dtype=labels_chunk.dtype)\n        \n        dset_previous_state = f.create_dataset(\'previous_state\', shape=previous_state_chunk.shape, maxshape=previous_state_maxshape,\n                                       chunks=previous_state_chunk.shape, dtype=previous_state_chunk.dtype)\n                                       \n        dset_images[:] = images_chunk\n        dset_labels[:] = labels_chunk\n        dset_previous_state[:] = previous_state_chunk\n\n        for image_names_chunk, label_chunk, previous_state_chunk in gen:\n            image_chunk = np.asarray(readImagesFromPath(image_names_chunk))\n            \n            # Resize the dataset to accommodate the next chunk of rows\n            dset_images.resize(row_count + image_chunk.shape[0], axis=0)\n            dset_labels.resize(row_count + label_chunk.shape[0], axis=0)\n            dset_previous_state.resize(row_count + previous_state_chunk.shape[0], axis=0)\n            # Write the next chunk\n            dset_images[row_count:] = image_chunk\n            dset_labels[row_count:] = label_chunk\n            dset_previous_state[row_count:] = previous_state_chunk\n\n            # Increment the row count\n            row_count += image_chunk.shape[0]\n            \n            \ndef cook(folders, output_directory, train_eval_test_split):\n    """""" Primary function for data pre-processing. Reads and saves all data as h5 files.\n            Inputs:\n                folders: a list of all data folders\n                output_directory: location for saving h5 files\n                train_eval_test_split: dataset split ratio\n    """"""\n    output_files = [os.path.join(output_directory, f) for f in [\'train.h5\', \'eval.h5\', \'test.h5\']]\n    if (any([os.path.isfile(f) for f in output_files])):\n       print(""Preprocessed data already exists at: {0}. Skipping preprocessing."".format(output_directory))\n\n    else:\n        all_data_mappings = generateDataMapAirSim(folders)\n        \n        split_mappings = splitTrainValidationAndTestData(all_data_mappings, split_ratio=train_eval_test_split)\n        \n        for i in range(0, len(split_mappings), 1):\n            print(\'Processing {0}...\'.format(output_files[i]))\n            saveH5pyData(split_mappings[i], output_files[i])\n            print(\'Finished saving {0}.\'.format(output_files[i]))'"
AirSimE2EDeepLearning/Generator.py,0,"b'from keras.preprocessing import image\nimport numpy as np\nimport keras.backend as K\nimport os\nimport cv2\n\nclass DriveDataGenerator(image.ImageDataGenerator):\n    def __init__(self,\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 zca_whitening=False,\n                 zca_epsilon=1e-6,\n                 rotation_range=0.,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode=\'nearest\',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 preprocessing_function=None,\n                 data_format=None,\n                 brighten_range=0):\n        super(DriveDataGenerator, self).__init__(featurewise_center,\n                 samplewise_center,\n                 featurewise_std_normalization,\n                 samplewise_std_normalization,\n                 zca_whitening,\n                 zca_epsilon,\n                 rotation_range,\n                 width_shift_range,\n                 height_shift_range,\n                 shear_range,\n                 zoom_range,\n                 channel_shift_range,\n                 fill_mode,\n                 cval,\n                 horizontal_flip,\n                 vertical_flip,\n                 rescale,\n                 preprocessing_function,\n                 data_format)\n        self.brighten_range = brighten_range\n\n    def flow(self, x_images, x_prev_states = None, y=None, batch_size=32, shuffle=True, seed=None,\n             save_to_dir=None, save_prefix=\'\', save_format=\'png\', zero_drop_percentage=0.5, roi=None):\n        return DriveIterator(\n            x_images, x_prev_states, y, self,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            data_format=self.data_format,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            zero_drop_percentage=zero_drop_percentage,\n            roi=roi)\n    \n    def random_transform_with_states(self, x, seed=None):\n        """"""Randomly augment a single image tensor.\n        # Arguments\n            x: 3D tensor, single image.\n            seed: random seed.\n        # Returns\n            A tuple. 0 -> randomly transformed version of the input (same shape). 1 -> true if image was horizontally flipped, false otherwise\n        """"""\n        # x is a single image, so it doesn\'t have image number at index 0\n        img_row_axis = self.row_axis\n        img_col_axis = self.col_axis\n        img_channel_axis = self.channel_axis\n\n        is_image_horizontally_flipped = False\n\n        # use composition of homographies\n        # to generate final transform that needs to be applied\n        if self.rotation_range:\n            theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)\n        else:\n            theta = 0\n\n        if self.height_shift_range:\n            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_axis]\n        else:\n            tx = 0\n\n        if self.width_shift_range:\n            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_axis]\n        else:\n            ty = 0\n\n        if self.shear_range:\n            shear = np.random.uniform(-self.shear_range, self.shear_range)\n        else:\n            shear = 0\n\n        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n            zx, zy = 1, 1\n        else:\n            zx, zy = np.random.uniform(self.zoom_range[0], self.zoom_range[1], 2)\n\n        transform_matrix = None\n        if theta != 0:\n            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                        [np.sin(theta), np.cos(theta), 0],\n                                        [0, 0, 1]])\n            transform_matrix = rotation_matrix\n\n        if tx != 0 or ty != 0:\n            shift_matrix = np.array([[1, 0, tx],\n                                     [0, 1, ty],\n                                     [0, 0, 1]])\n            transform_matrix = shift_matrix if transform_matrix is None else np.dot(transform_matrix, shift_matrix)\n\n        if shear != 0:\n            shear_matrix = np.array([[1, -np.sin(shear), 0],\n                                    [0, np.cos(shear), 0],\n                                    [0, 0, 1]])\n            transform_matrix = shear_matrix if transform_matrix is None else np.dot(transform_matrix, shear_matrix)\n\n        if zx != 1 or zy != 1:\n            zoom_matrix = np.array([[zx, 0, 0],\n                                    [0, zy, 0],\n                                    [0, 0, 1]])\n            transform_matrix = zoom_matrix if transform_matrix is None else np.dot(transform_matrix, zoom_matrix)\n\n        if transform_matrix is not None:\n            h, w = x.shape[img_row_axis], x.shape[img_col_axis]\n            transform_matrix = image.transform_matrix_offset_center(transform_matrix, h, w)\n            x = image.apply_transform(x, transform_matrix, img_channel_axis,\n                                fill_mode=self.fill_mode, cval=self.cval)\n\n        if self.channel_shift_range != 0:\n            x = image.random_channel_shift(x,\n                                     self.channel_shift_range,\n                                     img_channel_axis)\n        if self.horizontal_flip:\n            if np.random.random() < 0.5:\n                x = image.flip_axis(x, img_col_axis)\n                is_image_horizontally_flipped = True\n\n        if self.vertical_flip:\n            if np.random.random() < 0.5:\n                x = image.flip_axis(x, img_row_axis)\n                \n        if self.brighten_range != 0:\n            random_bright = np.random.uniform(low = 1.0-self.brighten_range, high=1.0+self.brighten_range)\n            \n            #TODO: Write this as an apply to push operations into C for performance\n            img = cv2.cvtColor(x, cv2.COLOR_RGB2HSV)\n            img[:, :, 2] = np.clip(img[:, :, 2] * random_bright, 0, 255)\n            x = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n\n        return (x, is_image_horizontally_flipped)\n\nclass DriveIterator(image.Iterator):\n    """"""Iterator yielding data from a Numpy array.\n\n    # Arguments\n        x: Numpy array of input data.\n        y: Numpy array of targets data.\n        image_data_generator: Instance of `ImageDataGenerator`\n            to use for random transformations and normalization.\n        batch_size: Integer, size of a batch.\n        shuffle: Boolean, whether to shuffle the data between epochs.\n        seed: Random seed for data shuffling.\n        data_format: String, one of `channels_first`, `channels_last`.\n        save_to_dir: Optional directory where to save the pictures\n            being yielded, in a viewable format. This is useful\n            for visualizing the random transformations being\n            applied, for debugging purposes.\n        save_prefix: String prefix to use for saving sample\n            images (if `save_to_dir` is set).\n        save_format: Format to use for saving sample images\n            (if `save_to_dir` is set).\n    """"""\n\n    def __init__(self, x_images, x_prev_states, y, image_data_generator,\n                 batch_size=32, shuffle=False, seed=None,\n                 data_format=None,\n                 save_to_dir=None, save_prefix=\'\', save_format=\'png\', zero_drop_percentage = 0.5, roi = None):\n        if y is not None and len(x_images) != len(y):\n            raise ValueError(\'X (images tensor) and y (labels) \'\n                             \'should have the same length. \'\n                             \'Found: X.shape = %s, y.shape = %s\' %\n                             (np.asarray(x_images).shape, np.asarray(y).shape))\n\n        if data_format is None:\n            data_format = K.image_data_format()\n        \n        self.x_images = x_images\n        \n        self.zero_drop_percentage = zero_drop_percentage\n        self.roi = roi\n        \n        if self.x_images.ndim != 4:\n            raise ValueError(\'Input data in `NumpyArrayIterator` \'\n                             \'should ave rank 4. You passed an array \'\n                             \'with shape\', self.x_images.shape)\n        channels_axis = 3 if data_format == \'channels_last\' else 1\n        if self.x_images.shape[channels_axis] not in {1, 3, 4}:\n            raise ValueError(\'NumpyArrayIterator is set to use the \'\n                             \'data format convention ""\' + data_format + \'"" \'\n                             \'(channels on axis \' + str(channels_axis) + \'), i.e. expected \'\n                             \'either 1, 3 or 4 channels on axis \' + str(channels_axis) + \'. \'\n                             \'However, it was passed an array with shape \' + str(self.x_images.shape) +\n                             \' (\' + str(self.x_images.shape[channels_axis]) + \' channels).\')\n        if x_prev_states is not None:\n            self.x_prev_states = x_prev_states\n        else:\n            self.x_prev_states = None\n\n        if y is not None:\n            self.y = y\n        else:\n            self.y = None\n        self.image_data_generator = image_data_generator\n        self.data_format = data_format\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_format = save_format\n        self.batch_size = batch_size\n        super(DriveIterator, self).__init__(x_images.shape[0], batch_size, shuffle, seed)\n\n    def next(self):\n        """"""For python 2.x.\n\n        # Returns\n            The next batch.\n        """"""\n        # Keeps under lock only the mechanism which advances\n        # the indexing of each batch.\n        with self.lock:\n            index_array = next(self.index_generator)\n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n\n        return self.__get_indexes(index_array)\n\n    def __get_indexes(self, index_array):\n        index_array = sorted(index_array)\n        if self.x_prev_states is not None:\n            batch_x_images = np.zeros(tuple([self.batch_size]+ list(self.x_images.shape)[1:]),\n                                      dtype=K.floatx())\n            batch_x_prev_states = np.zeros(tuple([self.batch_size]+list(self.x_prev_states.shape)[1:]), dtype=K.floatx())\n        else:\n            batch_x_images = np.zeros(tuple([self.batch_size] + list(self.x_images.shape)[1:]), dtype=K.floatx())\n\n        if self.roi is not None:\n            batch_x_images = batch_x_images[:, self.roi[0]:self.roi[1], self.roi[2]:self.roi[3], :]\n            \n        used_indexes = []\n        is_horiz_flipped = []\n        for i, j in enumerate(index_array):\n            x_images = self.x_images[j]\n            \n            if self.roi is not None:\n                x_images = x_images[self.roi[0]:self.roi[1], self.roi[2]:self.roi[3], :]\n            \n            transformed = self.image_data_generator.random_transform_with_states(x_images.astype(K.floatx()))\n            x_images = transformed[0]\n            is_horiz_flipped.append(transformed[1])\n            x_images = self.image_data_generator.standardize(x_images)\n            batch_x_images[i] = x_images\n\n            if self.x_prev_states is not None:\n                x_prev_states = self.x_prev_states[j]\n                \n                if (transformed[1]):\n                    x_prev_states[0] *= -1.0\n                \n                batch_x_prev_states[i] = x_prev_states\n            \n            used_indexes.append(j)\n\n        if self.x_prev_states is not None:\n            batch_x = [np.asarray(batch_x_images), np.asarray(batch_x_prev_states)]\n        else:\n            batch_x = np.asarray(batch_x_images)\n            \n        if self.save_to_dir:\n            for i in range(0, self.batch_size, 1):\n                hash = np.random.randint(1e4)\n               \n                img = image.array_to_img(batch_x_images[i], self.data_format, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                        index=1,\n                                                                        hash=hash,\n                                                                        format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n\n        batch_y = self.y[list(sorted(used_indexes))]\n        idx = []\n        for i in range(0, len(is_horiz_flipped), 1):\n            if batch_y.shape[1] == 1:\n                if (is_horiz_flipped[i]):\n                    batch_y[i] *= -1\n                    \n                if (np.isclose(batch_y[i], 0)):\n                    if (np.random.uniform(low=0, high=1) > self.zero_drop_percentage):\n                        idx.append(True)\n                    else:\n                        idx.append(False)\n                else:\n                    idx.append(True)\n            else:\n                if (batch_y[i][int(len(batch_y[i])/2)] == 1):\n                    if (np.random.uniform(low=0, high=1) > self.zero_drop_percentage):\n                        idx.append(True)\n                    else:\n                        idx.append(False)\n                else:\n                    idx.append(True)\n                \n                if (is_horiz_flipped[i]):\n                    batch_y[i] = batch_y[i][::-1]\n\n        batch_y = batch_y[idx]\n        batch_x[0] = batch_x[0][idx]\n        batch_x[1] = batch_x[1][idx]\n        \n        return batch_x, batch_y\n        \n    def _get_batches_of_transformed_samples(self, index_array):\n        return self.__get_indexes(index_array)\n        '"
AirSimE2EDeepLearning/InstallPackages.py,0,"b""import os\n\n# Run this script from within an anaconda virtual environment to install the required packages\n# Be sure to run this script as root or as administrator.\n\nos.system('python -m pip install --upgrade pip')\n#os.system('conda update -n base conda')\nos.system('conda install jupyter')\nos.system('pip install matplotlib==2.1.2')\nos.system('pip install image')\nos.system('pip install keras_tqdm')\nos.system('conda install -c conda-forge opencv')\nos.system('pip install msgpack-rpc-python')\nos.system('pip install pandas')\nos.system('pip install numpy')\nos.system('conda install scipy')"""
DistributedRL/Share/scripts_downpour/manage.py,0,"b'import os\nimport sys\nimport argparse\n\ndef setup_logs():\n    output_dir = \'Z:\\\\logs\\\\{0}\\\\trainer\'.format(os.environ[\'experiment_name\'])\n    if not os.path.isdir(output_dir):\n        try:\n            os.makedirs(output_dir)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n    sys.stdout = open(os.path.join(output_dir, \'{0}.stdout.txt\'.format(os.environ[\'AZ_BATCH_NODE_ID\'])), \'w\')\n    sys.stderr = open(os.path.join(output_dir, \'{0}.stderr.txt\'.format(os.environ[\'AZ_BATCH_NODE_ID\'])), \'w\')\n\n\n\nif __name__ == ""__main__"":\n    print(\'IN MANAGE.PY\')\n    os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""downpour.settings"")\n    \n    custom_args = sys.argv[3:]\n    original_args = sys.argv[:3]\n    #known_args = [\'data_dir\', \'role\', \'experiment_name\', \'batch_update_frequency\']\n    parser = argparse.ArgumentParser(add_help=False)\n    for arg in custom_args:\n        arg_name = arg.split(\'=\')[0]\n        parser.add_argument(arg_name)\n    args, _ = parser.parse_known_args(custom_args)\n    args = vars(args)\n    for arg in args:\n        os.environ[arg] = args[arg].split(\'=\')[1]\n    \n    print(\'**************\')\n    print(\'OS.ENVIRON\')\n    print(os.environ)\n    print(\'**************\')\n    \n    setup_logs()\n    \n    print(\'MANAGE.PY: name: {0}\'.format(__name__))\n    print(\'TO STDERR: name: {0}\'.format(__name__), file=sys.stderr)\n    sys.stdout.flush()\n    sys.stderr.flush()\n    \n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(\n            ""Couldn\'t import Django. Are you sure it\'s installed and ""\n            ""available on your PYTHONPATH environment variable? Did you ""\n            ""forget to activate a virtual environment?""\n        ) from exc\n    execute_from_command_line(original_args)\n'"
DistributedRL/Share/scripts_downpour/app/airsim_client.py,0,"b'from __future__ import print_function\nimport msgpackrpc #install as admin: pip install msgpack-rpc-python\nimport numpy as np #pip install numpy\nimport msgpack\nimport math\nimport time\nimport sys\nimport os\nimport inspect\nimport types\nimport re\n\n\nclass MsgpackMixin:\n    def to_msgpack(self, *args, **kwargs):\n        return self.__dict__ #msgpack.dump(self.to_dict(*args, **kwargs))\n\n    @classmethod\n    def from_msgpack(cls, encoded):\n        obj = cls()\n        obj.__dict__ = {k.decode(\'utf-8\'): v for k, v in encoded.items()}\n        return obj\n\n\nclass AirSimImageType:    \n    Scene = 0\n    DepthPlanner = 1\n    DepthPerspective = 2\n    DepthVis = 3\n    DisparityNormalized = 4\n    Segmentation = 5\n    SurfaceNormals = 6\n\nclass DrivetrainType:\n    MaxDegreeOfFreedom = 0\n    ForwardOnly = 1\n    \nclass LandedState:\n    Landed = 0\n    Flying = 1\n\nclass Vector3r(MsgpackMixin):\n    x_val = np.float32(0)\n    y_val = np.float32(0)\n    z_val = np.float32(0)\n\n    def __init__(self, x_val = np.float32(0), y_val = np.float32(0), z_val = np.float32(0)):\n        self.x_val = x_val\n        self.y_val = y_val\n        self.z_val = z_val\n\n\nclass Quaternionr(MsgpackMixin):\n    w_val = np.float32(0)\n    x_val = np.float32(0)\n    y_val = np.float32(0)\n    z_val = np.float32(0)\n\n    def __init__(self, x_val = np.float32(0), y_val = np.float32(0), z_val = np.float32(0), w_val = np.float32(1)):\n        self.x_val = x_val\n        self.y_val = y_val\n        self.z_val = z_val\n        self.w_val = w_val\n\nclass Pose(MsgpackMixin):\n    position = Vector3r()\n    orientation = Quaternionr()\n\n    def __init__(self, position_val, orientation_val):\n        self.position = position_val\n        self.orientation = orientation_val\n\n\nclass CollisionInfo(MsgpackMixin):\n    has_collided = False\n    normal = Vector3r()\n    impact_point = Vector3r()\n    position = Vector3r()\n    penetration_depth = np.float32(0)\n    time_stamp = np.float32(0)\n    object_name = """"\n    object_id = -1\n\nclass GeoPoint(MsgpackMixin):\n    latitude = 0.0\n    longitude = 0.0\n    altitude = 0.0\n\nclass YawMode(MsgpackMixin):\n    is_rate = True\n    yaw_or_rate = 0.0\n    def __init__(self, is_rate = True, yaw_or_rate = 0.0):\n        self.is_rate = is_rate\n        self.yaw_or_rate = yaw_or_rate\n\nclass ImageRequest(MsgpackMixin):\n    camera_id = np.uint8(0)\n    image_type = AirSimImageType.Scene\n    pixels_as_float = False\n    compress = False\n\n    def __init__(self, camera_id, image_type, pixels_as_float = False, compress = True):\n        self.camera_id = camera_id\n        self.image_type = image_type\n        self.pixels_as_float = pixels_as_float\n        self.compress = compress\n\n\nclass ImageResponse(MsgpackMixin):\n    image_data_uint8 = np.uint8(0)\n    image_data_float = np.float32(0)\n    camera_position = Vector3r()\n    camera_orientation = Quaternionr()\n    time_stamp = np.uint64(0)\n    message = \'\'\n    pixels_as_float = np.float32(0)\n    compress = True\n    width = 0\n    height = 0\n    image_type = AirSimImageType.Scene\n\nclass CarControls(MsgpackMixin):\n    throttle = np.float32(0)\n    steering = np.float32(0)\n    brake = np.float32(0)\n    handbrake = False\n    is_manual_gear = False\n    manual_gear = 0\n    gear_immediate = True\n\n    def set_throttle(self, throttle_val, forward):\n        if (forward):\n            is_manual_gear = False\n            manual_gear = 0\n            throttle = abs(throttle_val)\n        else:\n            is_manual_gear = False\n            manual_gear = -1\n            throttle = - abs(throttle_val)\n\nclass CarState(MsgpackMixin):\n    speed = np.float32(0)\n    gear = 0\n    position = Vector3r()\n    velocity = Vector3r()\n    orientation = Quaternionr()\n\nclass AirSimClientBase:\n    def __init__(self, ip, port):\n        self.client = msgpackrpc.Client(msgpackrpc.Address(ip, port), timeout = 5)\n        \n    def ping(self):\n        return self.client.call(\'ping\')\n    \n    def reset(self):\n        self.client.call(\'reset\')\n\n    def confirmConnection(self):\n        print(\'Waiting for connection: \', end=\'\')\n        home = self.getHomeGeoPoint()\n        while ((home.latitude == 0 and home.longitude == 0 and home.altitude == 0) or\n                math.isnan(home.latitude) or  math.isnan(home.longitude) or  math.isnan(home.altitude)):\n            time.sleep(1)\n            home = self.getHomeGeoPoint()\n            print(\'X\', end=\'\')\n        print(\'\')\n\n    def getHomeGeoPoint(self):\n        return GeoPoint.from_msgpack(self.client.call(\'getHomeGeoPoint\'))\n\n    # basic flight control\n    def enableApiControl(self, is_enabled):\n        return self.client.call(\'enableApiControl\', is_enabled)\n    def isApiControlEnabled(self):\n        return self.client.call(\'isApiControlEnabled\')\n\n    def simSetSegmentationObjectID(self, mesh_name, object_id, is_name_regex = False):\n        return self.client.call(\'simSetSegmentationObjectID\', mesh_name, object_id, is_name_regex)\n    def simGetSegmentationObjectID(self, mesh_name):\n        return self.client.call(\'simGetSegmentationObjectID\', mesh_name)\n            \n    # camera control\n    # simGetImage returns compressed png in array of bytes\n    # image_type uses one of the AirSimImageType members\n    def simGetImage(self, camera_id, image_type):\n        # because this method returns std::vector<uint8>, msgpack decides to encode it as a string unfortunately.\n        result = self.client.call(\'simGetImage\', camera_id, image_type)\n        if (result == """" or result == ""\\0""):\n            return None\n        return result\n\n    # camera control\n    # simGetImage returns compressed png in array of bytes\n    # image_type uses one of the AirSimImageType members\n    def simGetImages(self, requests):\n        responses_raw = self.client.call(\'simGetImages\', requests)\n        return [ImageResponse.from_msgpack(response_raw) for response_raw in responses_raw]\n\n    def getCollisionInfo(self):\n        return CollisionInfo.from_msgpack(self.client.call(\'getCollisionInfo\'))\n\n    @staticmethod\n    def stringToUint8Array(bstr):\n        return np.fromstring(bstr, np.uint8)\n    @staticmethod\n    def stringToFloatArray(bstr):\n        return np.fromstring(bstr, np.float32)\n    @staticmethod\n    def listTo2DFloatArray(flst, width, height):\n        return np.reshape(np.asarray(flst, np.float32), (height, width))\n    @staticmethod\n    def getPfmArray(response):\n        return AirSimClientBase.listTo2DFloatArray(response.image_data_float, response.width, response.height)\n\n    @staticmethod\n    def get_public_fields(obj):\n        return [attr for attr in dir(obj)\n                             if not (attr.startswith(""_"") \n                                or inspect.isbuiltin(attr)\n                                or inspect.isfunction(attr)\n                                or inspect.ismethod(attr))]\n\n\n    @staticmethod\n    def to_dict(obj):\n        return dict([attr, getattr(obj, attr)] for attr in AirSimClientBase.get_public_fields(obj))\n\n    @staticmethod\n    def to_str(obj):\n        return str(AirSimClientBase.to_dict(obj))\n\n    @staticmethod\n    def write_file(filename, bstr):\n        with open(filename, \'wb\') as afile:\n            afile.write(bstr)\n\n    def simSetPose(self, pose, ignore_collison):\n        self.client.call(\'simSetPose\', pose, ignore_collison)\n\n    def simGetPose(self):\n        return self.client.call(\'simGetPose\')\n\n    # helper method for converting getOrientation to roll/pitch/yaw\n    # https:#en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles\n    @staticmethod\n    def toEulerianAngle(q):\n        z = q.z_val\n        y = q.y_val\n        x = q.x_val\n        w = q.w_val\n        ysqr = y * y\n\n        # roll (x-axis rotation)\n        t0 = +2.0 * (w*x + y*z)\n        t1 = +1.0 - 2.0*(x*x + ysqr)\n        roll = math.atan2(t0, t1)\n\n        # pitch (y-axis rotation)\n        t2 = +2.0 * (w*y - z*x)\n        if (t2 > 1.0):\n            t2 = 1\n        if (t2 < -1.0):\n            t2 = -1.0\n        pitch = math.asin(t2)\n\n        # yaw (z-axis rotation)\n        t3 = +2.0 * (w*z + x*y)\n        t4 = +1.0 - 2.0 * (ysqr + z*z)\n        yaw = math.atan2(t3, t4)\n\n        return (pitch, roll, yaw)\n\n    @staticmethod\n    def toQuaternion(pitch, roll, yaw):\n        t0 = math.cos(yaw * 0.5)\n        t1 = math.sin(yaw * 0.5)\n        t2 = math.cos(roll * 0.5)\n        t3 = math.sin(roll * 0.5)\n        t4 = math.cos(pitch * 0.5)\n        t5 = math.sin(pitch * 0.5)\n\n        q = Quaternionr()\n        q.w_val = t0 * t2 * t4 + t1 * t3 * t5 #w\n        q.x_val = t0 * t3 * t4 - t1 * t2 * t5 #x\n        q.y_val = t0 * t2 * t5 + t1 * t3 * t4 #y\n        q.z_val = t1 * t2 * t4 - t0 * t3 * t5 #z\n        return q\n\n    @staticmethod\n    def wait_key(message = \'\'):\n        \'\'\' Wait for a key press on the console and return it. \'\'\'\n        if message != \'\':\n            print (message)\n\n        result = None\n        if os.name == \'nt\':\n            import msvcrt\n            result = msvcrt.getch()\n        else:\n            import termios\n            fd = sys.stdin.fileno()\n\n            oldterm = termios.tcgetattr(fd)\n            newattr = termios.tcgetattr(fd)\n            newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO\n            termios.tcsetattr(fd, termios.TCSANOW, newattr)\n\n            try:\n                result = sys.stdin.read(1)\n            except IOError:\n                pass\n            finally:\n                termios.tcsetattr(fd, termios.TCSAFLUSH, oldterm)\n\n        return result\n\n    @staticmethod\n    def read_pfm(file):\n        """""" Read a pfm file """"""\n        file = open(file, \'rb\')\n\n        color = None\n        width = None\n        height = None\n        scale = None\n        endian = None\n\n        header = file.readline().rstrip()\n        header = str(bytes.decode(header, encoding=\'utf-8\'))\n        if header == \'PF\':\n            color = True\n        elif header == \'Pf\':\n            color = False\n        else:\n            raise Exception(\'Not a PFM file.\')\n\n        temp_str = str(bytes.decode(file.readline(), encoding=\'utf-8\'))\n        dim_match = re.match(r\'^(\\d+)\\s(\\d+)\\s$\', temp_str)\n        if dim_match:\n            width, height = map(int, dim_match.groups())\n        else:\n            raise Exception(\'Malformed PFM header.\')\n\n        scale = float(file.readline().rstrip())\n        if scale < 0: # little-endian\n            endian = \'<\'\n            scale = -scale\n        else:\n            endian = \'>\' # big-endian\n\n        data = np.fromfile(file, endian + \'f\')\n        shape = (height, width, 3) if color else (height, width)\n\n        data = np.reshape(data, shape)\n        # DEY: I don\'t know why this was there.\n        #data = np.flipud(data)\n        file.close()\n    \n        return data, scale\n\n    @staticmethod\n    def write_pfm(file, image, scale=1):\n        """""" Write a pfm file """"""\n        file = open(file, \'wb\')\n\n        color = None\n\n        if image.dtype.name != \'float32\':\n            raise Exception(\'Image dtype must be float32.\')\n\n        image = np.flipud(image)\n\n        if len(image.shape) == 3 and image.shape[2] == 3: # color image\n            color = True\n        elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1: # greyscale\n            color = False\n        else:\n            raise Exception(\'Image must have H x W x 3, H x W x 1 or H x W dimensions.\')\n\n        file.write(\'PF\\n\'.encode(\'utf-8\')  if color else \'Pf\\n\'.encode(\'utf-8\'))\n        temp_str = \'%d %d\\n\' % (image.shape[1], image.shape[0])\n        file.write(temp_str.encode(\'utf-8\'))\n\n        endian = image.dtype.byteorder\n\n        if endian == \'<\' or endian == \'=\' and sys.byteorder == \'little\':\n            scale = -scale\n\n        temp_str = \'%f\\n\' % scale\n        file.write(temp_str.encode(\'utf-8\'))\n\n        image.tofile(file)\n\n    @staticmethod\n    def write_png(filename, image):\n        """""" image must be numpy array H X W X channels\n        """"""\n        import zlib, struct\n\n        buf = image.flatten().tobytes()\n        width = image.shape[1]\n        height = image.shape[0]\n\n        # reverse the vertical line order and add null bytes at the start\n        width_byte_4 = width * 4\n        raw_data = b\'\'.join(b\'\\x00\' + buf[span:span + width_byte_4]\n                            for span in range((height - 1) * width_byte_4, -1, - width_byte_4))\n\n        def png_pack(png_tag, data):\n            chunk_head = png_tag + data\n            return (struct.pack(""!I"", len(data)) +\n                    chunk_head +\n                    struct.pack(""!I"", 0xFFFFFFFF & zlib.crc32(chunk_head)))\n\n        png_bytes = b\'\'.join([\n            b\'\\x89PNG\\r\\n\\x1a\\n\',\n            png_pack(b\'IHDR\', struct.pack(""!2I5B"", width, height, 8, 6, 0, 0, 0)),\n            png_pack(b\'IDAT\', zlib.compress(raw_data, 9)),\n            png_pack(b\'IEND\', b\'\')])\n\n        AirSimClientBase.write_file(filename, png_bytes)\n\n\n# -----------------------------------  Multirotor APIs ---------------------------------------------\nclass MultirotorClient(AirSimClientBase, object):\n    def __init__(self, ip = """"):\n        if (ip == """"):\n            ip = ""127.0.0.1""\n        super(MultirotorClient, self).__init__(ip, 41451)\n\n    def armDisarm(self, arm):\n        return self.client.call(\'armDisarm\', arm)\n\n    def takeoff(self, max_wait_seconds = 15):\n        return self.client.call(\'takeoff\', max_wait_seconds)\n        \n    def land(self, max_wait_seconds = 60):\n        return self.client.call(\'land\', max_wait_seconds)\n        \n    def goHome(self):\n        return self.client.call(\'goHome\')\n\n    def hover(self):\n        return self.client.call(\'hover\')\n\n        \n    # query vehicle state\n    def getPosition(self):\n        return Vector3r.from_msgpack(self.client.call(\'getPosition\'))\n    def getVelocity(self):\n        return Vector3r.from_msgpack(self.client.call(\'getVelocity\'))\n    def getOrientation(self):\n        return Quaternionr.from_msgpack(self.client.call(\'getOrientation\'))\n    def getLandedState(self):\n        return self.client.call(\'getLandedState\')\n    def getGpsLocation(self):\n        return GeoPoint.from_msgpack(self.client.call(\'getGpsLocation\'))\n    def getPitchRollYaw(self):\n        return self.toEulerianAngle(self.getOrientation())\n\n    #def getRCData(self):\n    #    return self.client.call(\'getRCData\')\n    def timestampNow(self):\n        return self.client.call(\'timestampNow\')\n    def isApiControlEnabled(self):\n        return self.client.call(\'isApiControlEnabled\')\n    def isSimulationMode(self):\n        return self.client.call(\'isSimulationMode\')\n    def getServerDebugInfo(self):\n        return self.client.call(\'getServerDebugInfo\')\n\n\n    # APIs for control\n    def moveByAngle(self, pitch, roll, z, yaw, duration):\n        return self.client.call(\'moveByAngle\', pitch, roll, z, yaw, duration)\n\n    def moveByVelocity(self, vx, vy, vz, duration, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode()):\n        return self.client.call(\'moveByVelocity\', vx, vy, vz, duration, drivetrain, yaw_mode)\n\n    def moveByVelocityZ(self, vx, vy, z, duration, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode()):\n        return self.client.call(\'moveByVelocityZ\', vx, vy, z, duration, drivetrain, yaw_mode)\n\n    def moveOnPath(self, path, velocity, max_wait_seconds = 60, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode(), lookahead = -1, adaptive_lookahead = 1):\n        return self.client.call(\'moveOnPath\', path, velocity, max_wait_seconds, drivetrain, yaw_mode, lookahead, adaptive_lookahead)\n\n    def moveToZ(self, z, velocity, max_wait_seconds = 60, yaw_mode = YawMode(), lookahead = -1, adaptive_lookahead = 1):\n        return self.client.call(\'moveToZ\', z, velocity, max_wait_seconds, yaw_mode, lookahead, adaptive_lookahead)\n\n    def moveToPosition(self, x, y, z, velocity, max_wait_seconds = 60, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode(), lookahead = -1, adaptive_lookahead = 1):\n        return self.client.call(\'moveToPosition\', x, y, z, velocity, max_wait_seconds, drivetrain, yaw_mode, lookahead, adaptive_lookahead)\n\n    def moveByManual(self, vx_max, vy_max, z_min, duration, drivetrain = DrivetrainType.MaxDegreeOfFreedom, yaw_mode = YawMode()):\n        return self.client.call(\'moveByManual\', vx_max, vy_max, z_min, duration, drivetrain, yaw_mode)\n\n    def rotateToYaw(self, yaw, max_wait_seconds = 60, margin = 5):\n        return self.client.call(\'rotateToYaw\', yaw, max_wait_seconds, margin)\n\n    def rotateByYawRate(self, yaw_rate, duration):\n        return self.client.call(\'rotateByYawRate\', yaw_rate, duration)\n\n# -----------------------------------  Car APIs ---------------------------------------------\nclass CarClient(AirSimClientBase, object):\n    def __init__(self, ip = """"):\n        if (ip == """"):\n            ip = ""127.0.0.1""\n        super(CarClient, self).__init__(ip, 42451)\n\n    def setCarControls(self, controls):\n        self.client.call(\'setCarControls\', controls)\n\n    def getCarState(self):\n        state_raw = self.client.call(\'getCarState\')\n        return CarState.from_msgpack(state_raw)\n'"
DistributedRL/Share/scripts_downpour/app/distributed_agent.py,0,"b'from airsim_client import *\nfrom rl_model import RlModel\nimport time\nimport numpy as np\nimport threading\nimport json\nimport os\nimport uuid\nimport glob\nimport datetime\nimport h5py\nimport sys\nimport requests\nimport PIL\nimport copy\nimport datetime\n\n# A class that represents the agent that will drive the vehicle, train the model, and send the gradient updates to the trainer.\nclass DistributedAgent():\n    def __init__(self, parameters):\n        required_parameters = [\'data_dir\', \'max_epoch_runtime_sec\', \'replay_memory_size\', \'batch_size\', \'min_epsilon\', \'per_iter_epsilon_reduction\', \'experiment_name\', \'train_conv_layers\']\n        for required_parameter in required_parameters:\n            if required_parameter not in parameters:\n                raise ValueError(\'Missing required parameter {0}\'.format(required_parameter))\n\n        parameters[\'role_type\'] = \'agent\'\n\n        \n        print(\'Starting time: {0}\'.format(datetime.datetime.utcnow()), file=sys.stderr)\n        self.__model_buffer = None\n        self.__model = None\n        self.__airsim_started = False\n        self.__data_dir = parameters[\'data_dir\']\n        self.__per_iter_epsilon_reduction = float(parameters[\'per_iter_epsilon_reduction\'])\n        self.__min_epsilon = float(parameters[\'min_epsilon\'])\n        self.__max_epoch_runtime_sec = float(parameters[\'max_epoch_runtime_sec\'])\n        self.__replay_memory_size = int(parameters[\'replay_memory_size\'])\n        self.__batch_size = int(parameters[\'batch_size\'])\n        self.__experiment_name = parameters[\'experiment_name\']\n        self.__train_conv_layers = bool((parameters[\'train_conv_layers\'].lower().strip() == \'true\'))\n        self.__epsilon = 1\n        self.__num_batches_run = 0\n        self.__last_checkpoint_batch_count = 0\n        \n        if \'batch_update_frequency\' in parameters:\n            self.__batch_update_frequency = int(parameters[\'batch_update_frequency\'])\n        \n        if \'weights_path\' in parameters:\n            self.__weights_path = parameters[\'weights_path\']\n        else:\n            self.__weights_path = None\n            \n        if \'airsim_path\' in parameters:\n            self.__airsim_path = parameters[\'airsim_path\']\n        else:\n            self.__airsim_path = None\n\n        self.__local_run = \'local_run\' in parameters\n\n        self.__car_client = None\n        self.__car_controls = None\n\n        self.__minibatch_dir = os.path.join(self.__data_dir, \'minibatches\')\n        self.__output_model_dir = os.path.join(self.__data_dir, \'models\')\n\n        self.__make_dir_if_not_exist(self.__minibatch_dir)\n        self.__make_dir_if_not_exist(self.__output_model_dir)\n        self.__last_model_file = \'\'\n\n        self.__possible_ip_addresses = []\n        self.__trainer_ip_address = None\n\n        self.__experiences = {}\n\n        self.__init_road_points()\n        self.__init_reward_points()\n\n    # Starts the agent\n    def start(self):\n        self.__run_function()\n\n    # The function that will be run during training.\n    # It will initialize the connection to the trainer, start AirSim, and continuously run training iterations.\n    def __run_function(self):\n        print(\'Starting run function\')\n        \n        # Once the trainer is online, it will write its IP to a file in (data_dir)\\trainer_ip\\trainer_ip.txt\n        # Wait for that file to exist\n        if not self.__local_run:\n            print(\'Waiting for trainer to come online\')\n            while True:\n                trainer_ip_dir = os.path.join(os.path.join(self.__data_dir, \'trainer_ip\'), self.__experiment_name)\n                print(\'Checking {0}...\'.format(trainer_ip_dir))\n                if os.path.isdir(trainer_ip_dir):\n                    with open(os.path.join(trainer_ip_dir, \'trainer_ip.txt\'), \'r\') as f:\n                        self.__possible_ip_addresses.append(f.read().replace(\'\\n\', \'\'))\n                        break\n                print(\'Not online yet. Sleeping...\')\n                time.sleep(5)\n        \n            # We now have the IP address for the trainer. Attempt to ping the trainer.\n            ping_idx = -1\n            while True:\n                ping_idx += 1\n                print(\'Attempting to ping trainer...\')\n                try:\n                    print(\'\\tPinging {0}...\'.format(self.__possible_ip_addresses[ping_idx % len(self.__possible_ip_addresses)]))\n                    response = requests.get(\'http://{0}:80/ping\'.format(self.__possible_ip_addresses[ping_idx % len(self.__possible_ip_addresses)])).json()\n                    if response[\'message\'] != \'pong\':\n                        raise ValueError(\'Received unexpected message: {0}\'.format(response))\n                    print(\'Success!\')\n                    self.__trainer_ip_address = self.__possible_ip_addresses[ping_idx % len(self.__possible_ip_addresses)]\n                    break\n                except Exception as e:\n                    print(\'Could not get response. Message is {0}\'.format(e))\n                    if (ping_idx % len(self.__possible_ip_addresses) == 0):\n                        print(\'Waiting 5 seconds and trying again...\')\n                        time.sleep(5)\n\n            # Get the latest model from the trainer\n            print(\'Getting model from the trainer\')\n            sys.stdout.flush()\n            self.__model = RlModel(self.__weights_path, self.__train_conv_layers)\n            self.__get_latest_model()\n        \n        else:\n            print(\'Run is local. Skipping connection to trainer.\')\n            self.__model = RlModel(self.__weights_path, self.__train_conv_layers)\n            \n            \n        # Connect to the AirSim exe\n        self.__connect_to_airsim()\n\n        # Fill the replay memory by driving randomly.\n        print(\'Filling replay memory...\')\n        while True:\n            print(\'Running Airsim Epoch.\')\n            try:\n                self.__run_airsim_epoch(True)\n                percent_full = 100.0 * len(self.__experiences[\'actions\'])/self.__replay_memory_size\n                print(\'Replay memory now contains {0} members. ({1}% full)\'.format(len(self.__experiences[\'actions\']), percent_full))\n\n                if (percent_full >= 100.0):\n                    break\n            except msgpackrpc.error.TimeoutError:\n                print(\'Lost connection to AirSim while fillling replay memory. Attempting to reconnect.\')\n                self.__connect_to_airsim()\n            \n        # Get the latest model. Other agents may have finished before us.\n        print(\'Replay memory filled. Starting main loop...\')\n        \n        if not self.__local_run:\n            self.__get_latest_model()\n        while True:\n            try:\n                if (self.__model is not None):\n\n                    #Generate a series of training examples by driving the vehicle in AirSim\n                    print(\'Running Airsim Epoch.\')\n                    experiences, frame_count = self.__run_airsim_epoch(False)\n\n                    # If we didn\'t immediately crash, train on the gathered experiences\n                    if (frame_count > 0):\n                        print(\'Generating {0} minibatches...\'.format(frame_count))\n\n                        print(\'Sampling Experiences.\')\n                        # Sample experiences from the replay memory\n                        sampled_experiences = self.__sample_experiences(experiences, frame_count, True)\n\n                        self.__num_batches_run += frame_count\n                        \n                        # If we successfully sampled, train on the collected minibatches and send the gradients to the trainer node\n                        if (len(sampled_experiences) > 0):\n                            print(\'Publishing AirSim Epoch.\')\n                            self.__publish_batch_and_update_model(sampled_experiences, frame_count)\n            \n            # Occasionally, the AirSim exe will stop working.\n            # For example, if a user connects to the node to visualize progress.\n            # In that case, attempt to reconnect.\n            except msgpackrpc.error.TimeoutError:\n                print(\'Lost connection to AirSim. Attempting to reconnect.\')\n                self.__connect_to_airsim()\n\n    # Connects to the AirSim Exe.\n    # Assume that it is already running. After 10 successive attempts, attempt to restart the executable.\n    def __connect_to_airsim(self):\n        attempt_count = 0\n        while True:\n            try:\n                print(\'Attempting to connect to AirSim (attempt {0})\'.format(attempt_count))\n                self.__car_client = CarClient()\n                self.__car_client.confirmConnection()\n                self.__car_client.enableApiControl(True)\n                self.__car_controls = CarControls()\n                print(\'Connected!\')\n                return\n            except:\n                print(\'Failed to connect.\')\n                attempt_count += 1\n                if (attempt_count % 10 == 0):\n                    print(\'10 consecutive failures to connect. Attempting to start AirSim on my own.\')\n                    \n                    if self.__local_run:\n                        os.system(\'START """" powershell.exe {0}\'.format(os.path.join(self.__airsim_path, \'AD_Cookbook_Start_AirSim.ps1 neighborhood -windowed\')))\n                    else:\n                        os.system(\'START """" powershell.exe D:\\\\AD_Cookbook_AirSim\\\\Scripts\\\\DistributedRL\\\\restart_airsim_if_agent.ps1\')\n                print(\'Waiting a few seconds.\')\n                time.sleep(10)\n\n    # Appends a sample to a ring buffer.\n    # If the appended example takes the size of the buffer over buffer_size, the example at the front will be removed.\n    def __append_to_ring_buffer(self, item, buffer, buffer_size):\n        if (len(buffer) >= buffer_size):\n            buffer = buffer[1:]\n        buffer.append(item)\n        return buffer\n    \n    # Runs an interation of data generation from AirSim.\n    # Data will be saved in the replay memory.\n    def __run_airsim_epoch(self, always_random):\n        print(\'Running AirSim epoch.\')\n        \n        # Pick a random starting point on the roads\n        starting_points, starting_direction = self.__get_next_starting_point()\n        \n        # Initialize the state buffer.\n        # For now, save 4 images at 0.01 second intervals.\n        state_buffer_len = 4\n        state_buffer = []\n        wait_delta_sec = 0.01\n\n        print(\'Getting Pose\')\n        self.__car_client.simSetPose(Pose(Vector3r(starting_points[0], starting_points[1], starting_points[2]), AirSimClientBase.toQuaternion(starting_direction[0], starting_direction[1], starting_direction[2])), True)\n\n        # Currently, simSetPose does not allow us to set the velocity. \n        # So, if we crash and call simSetPose, the car will be still moving at its previous velocity.\n        # We need the car to stop moving, so push the brake and wait for a few seconds.\n        print(\'Waiting for momentum to die\')\n        self.__car_controls.steering = 0\n        self.__car_controls.throttle = 0\n        self.__car_controls.brake = 1\n        self.__car_client.setCarControls(self.__car_controls)\n        time.sleep(4)\n        \n        print(\'Resetting\')\n        self.__car_client.simSetPose(Pose(Vector3r(starting_points[0], starting_points[1], starting_points[2]), AirSimClientBase.toQuaternion(starting_direction[0], starting_direction[1], starting_direction[2])), True)\n\n        #Start the car rolling so it doesn\'t get stuck\n        print(\'Running car for a few seconds...\')\n        self.__car_controls.steering = 0\n        self.__car_controls.throttle = 1\n        self.__car_controls.brake = 0\n        self.__car_client.setCarControls(self.__car_controls)\n        \n        # While the car is rolling, start initializing the state buffer\n        stop_run_time =datetime.datetime.now() + datetime.timedelta(seconds=2)\n        while(datetime.datetime.now() < stop_run_time):\n            time.sleep(wait_delta_sec)\n            state_buffer = self.__append_to_ring_buffer(self.__get_image(), state_buffer, state_buffer_len)\n        done = False\n        actions = [] #records the state we go to\n        pre_states = []\n        post_states = []\n        rewards = []\n        predicted_rewards = []\n        car_state = self.__car_client.getCarState()\n\n        start_time = datetime.datetime.utcnow()\n        end_time = start_time + datetime.timedelta(seconds=self.__max_epoch_runtime_sec)\n        \n        num_random = 0\n        far_off = False\n        \n        # Main data collection loop\n        while not done:\n            collision_info = self.__car_client.getCollisionInfo()\n            utc_now = datetime.datetime.utcnow()\n            \n            # Check for terminal conditions:\n            # 1) Car has collided\n            # 2) Car is stopped\n            # 3) The run has been running for longer than max_epoch_runtime_sec. \n            #       This constraint is so the model doesn\'t end up having to churn through huge chunks of data, slowing down training\n            # 4) The car has run off the road\n            if (collision_info.has_collided or car_state.speed < 2 or utc_now > end_time or far_off):\n                print(\'Start time: {0}, end time: {1}\'.format(start_time, utc_now), file=sys.stderr)\n                if (utc_now > end_time):\n                    print(\'timed out.\')\n                    print(\'Full autonomous run finished at {0}\'.format(utc_now), file=sys.stderr)\n                done = True\n                sys.stderr.flush()\n            else:\n\n                # The Agent should occasionally pick random action instead of best action\n                do_greedy = np.random.random_sample()\n                pre_state = copy.deepcopy(state_buffer)\n                if (do_greedy < self.__epsilon or always_random):\n                    num_random += 1\n                    next_state = self.__model.get_random_state()\n                    predicted_reward = 0\n                    \n                else:\n                    next_state, predicted_reward = self.__model.predict_state(pre_state)\n                    print(\'Model predicts {0}\'.format(next_state))\n\n                # Convert the selected state to a control signal\n                next_control_signals = self.__model.state_to_control_signals(next_state, self.__car_client.getCarState())\n\n                # Take the action\n                self.__car_controls.steering = next_control_signals[0]\n                self.__car_controls.throttle = next_control_signals[1]\n                self.__car_controls.brake = next_control_signals[2]\n                self.__car_client.setCarControls(self.__car_controls)\n                \n                # Wait for a short period of time to see outcome\n                time.sleep(wait_delta_sec)\n\n                # Observe outcome and compute reward from action\n                state_buffer = self.__append_to_ring_buffer(self.__get_image(), state_buffer, state_buffer_len)\n                car_state = self.__car_client.getCarState()\n                collision_info = self.__car_client.getCollisionInfo()\n                reward, far_off = self.__compute_reward(collision_info, car_state)\n                \n                # Add the experience to the set of examples from this iteration\n                pre_states.append(pre_state)\n                post_states.append(state_buffer)\n                rewards.append(reward)\n                predicted_rewards.append(predicted_reward)\n                actions.append(next_state)\n\n        # Only the last state is a terminal state.\n        is_not_terminal = [1 for i in range(0, len(actions)-1, 1)]\n        is_not_terminal.append(0)\n        \n        # Add all of the states from this iteration to the replay memory\n        self.__add_to_replay_memory(\'pre_states\', pre_states)\n        self.__add_to_replay_memory(\'post_states\', post_states)\n        self.__add_to_replay_memory(\'actions\', actions)\n        self.__add_to_replay_memory(\'rewards\', rewards)\n        self.__add_to_replay_memory(\'predicted_rewards\', predicted_rewards)\n        self.__add_to_replay_memory(\'is_not_terminal\', is_not_terminal)\n\n        print(\'Percent random actions: {0}\'.format(num_random / max(1, len(actions))))\n        print(\'Num total actions: {0}\'.format(len(actions)))\n        \n        # If we are in the main loop, reduce the epsilon parameter so that the model will be called more often\n        # Note: this will be overwritten by the trainer\'s epsilon if running in distributed mode\n        if not always_random:\n            self.__epsilon -= self.__per_iter_epsilon_reduction\n            self.__epsilon = max(self.__epsilon, self.__min_epsilon)\n        \n        return self.__experiences, len(actions)\n\n    # Adds a set of examples to the replay memory\n    def __add_to_replay_memory(self, field_name, data):\n        if field_name not in self.__experiences:\n            self.__experiences[field_name] = data\n        else:\n            self.__experiences[field_name] += data\n            start_index = max(0, len(self.__experiences[field_name]) - self.__replay_memory_size)\n            self.__experiences[field_name] = self.__experiences[field_name][start_index:]\n\n    # Sample experiences from the replay memory\n    def __sample_experiences(self, experiences, frame_count, sample_randomly):\n        sampled_experiences = {}\n        sampled_experiences[\'pre_states\'] = []\n        sampled_experiences[\'post_states\'] = []\n        sampled_experiences[\'actions\'] = []\n        sampled_experiences[\'rewards\'] = []\n        sampled_experiences[\'predicted_rewards\'] = []\n        sampled_experiences[\'is_not_terminal\'] = []\n\n        # Compute the surprise factor, which is the difference between the predicted an the actual Q value for each state.\n        # We can use that to weight examples so that we are more likely to train on examples that the model got wrong.\n        suprise_factor = np.abs(np.array(experiences[\'rewards\'], dtype=np.dtype(float)) - np.array(experiences[\'predicted_rewards\'], dtype=np.dtype(float)))\n        suprise_factor_normalizer = np.sum(suprise_factor)\n        suprise_factor /= float(suprise_factor_normalizer)\n\n        # Generate one minibatch for each frame of the run\n        for _ in range(0, frame_count, 1):\n            if sample_randomly:\n                idx_set = set(np.random.choice(list(range(0, suprise_factor.shape[0], 1)), size=(self.__batch_size), replace=False))\n            else:\n                idx_set = set(np.random.choice(list(range(0, suprise_factor.shape[0], 1)), size=(self.__batch_size), replace=False, p=suprise_factor))\n        \n            sampled_experiences[\'pre_states\'] += [experiences[\'pre_states\'][i] for i in idx_set]\n            sampled_experiences[\'post_states\'] += [experiences[\'post_states\'][i] for i in idx_set]\n            sampled_experiences[\'actions\'] += [experiences[\'actions\'][i] for i in idx_set]\n            sampled_experiences[\'rewards\'] += [experiences[\'rewards\'][i] for i in idx_set]\n            sampled_experiences[\'predicted_rewards\'] += [experiences[\'predicted_rewards\'][i] for i in idx_set]\n            sampled_experiences[\'is_not_terminal\'] += [experiences[\'is_not_terminal\'][i] for i in idx_set]\n            \n        return sampled_experiences\n        \n     \n    # Train the model on minibatches and post to the trainer node.\n    # The trainer node will respond with the latest version of the model that will be used in further data generation iterations.\n    def __publish_batch_and_update_model(self, batches, batches_count):\n        # Train and get the gradients\n        print(\'Publishing epoch data and getting latest model from parameter server...\')\n        gradients = self.__model.get_gradient_update_from_batches(batches)\n        \n        # Post the data to the trainer node\n        if not self.__local_run:\n            post_data = {}\n            post_data[\'gradients\'] = gradients\n            post_data[\'batch_count\'] = batches_count\n            \n            response = requests.post(\'http://{0}:80/gradient_update\'.format(self.__trainer_ip_address), json=post_data)\n            print(\'Response:\')\n            print(response)\n\n            new_model_parameters = response.json()\n            \n            # Update the existing model with the new parameters\n            self.__model.from_packet(new_model_parameters)\n            \n            #If the trainer sends us a epsilon, allow it to override our local value\n            if (\'epsilon\' in new_model_parameters):\n                new_epsilon = float(new_model_parameters[\'epsilon\'])\n                print(\'Overriding local epsilon with {0}, which was sent from trainer\'.format(new_epsilon))\n                self.__epsilon = new_epsilon\n                \n        else:\n            if (self.__num_batches_run > self.__batch_update_frequency + self.__last_checkpoint_batch_count):\n                self.__model.update_critic()\n                \n                checkpoint = {}\n                checkpoint[\'model\'] = self.__model.to_packet(get_target=True)\n                checkpoint[\'batch_count\'] = batches_count\n                checkpoint_str = json.dumps(checkpoint)\n\n                checkpoint_dir = os.path.join(os.path.join(self.__data_dir, \'checkpoint\'), self.__experiment_name)\n                \n                if not os.path.isdir(checkpoint_dir):\n                    try:\n                        os.makedirs(checkpoint_dir)\n                    except OSError as e:\n                        if e.errno != errno.EEXIST:\n                            raise\n                            \n                file_name = os.path.join(checkpoint_dir,\'{0}.json\'.format(self.__num_batches_run)) \n                with open(file_name, \'w\') as f:\n                    print(\'Checkpointing to {0}\'.format(file_name))\n                    f.write(checkpoint_str)\n                \n                self.__last_checkpoint_batch_count = self.__num_batches_run\n                \n    # Gets the latest model from the trainer node\n    def __get_latest_model(self):\n        print(\'Getting latest model from parameter server...\')\n        response = requests.get(\'http://{0}:80/latest\'.format(self.__trainer_ip_address)).json()\n        self.__model.from_packet(response)\n\n    # Gets an image from AirSim\n    def __get_image(self):\n        image_response = self.__car_client.simGetImages([ImageRequest(0, AirSimImageType.Scene, False, False)])[0]\n        image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n        image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n\n        return image_rgba[76:135,0:255,0:3].astype(float)\n\n    # Computes the reward functinon based on the car position.\n    def __compute_reward(self, collision_info, car_state):\n        #Define some constant parameters for the reward function\n        THRESH_DIST = 3.5                # The maximum distance from the center of the road to compute the reward function\n        DISTANCE_DECAY_RATE = 1.2        # The rate at which the reward decays for the distance function\n        CENTER_SPEED_MULTIPLIER = 2.0    # The ratio at which we prefer the distance reward to the speed reward\n\n        # If the car has collided, the reward is always zero\n        if (collision_info.has_collided):\n            return 0.0, True\n        \n        # If the car is stopped, the reward is always zero\n        speed = car_state.speed\n        if (speed < 2):\n            return 0.0, True\n        \n        #Get the car position\n        position_key = bytes(\'position\', encoding=\'utf8\')\n        x_val_key = bytes(\'x_val\', encoding=\'utf8\')\n        y_val_key = bytes(\'y_val\', encoding=\'utf8\')\n\n        car_point = np.array([car_state.kinematics_true[position_key][x_val_key], car_state.kinematics_true[position_key][y_val_key], 0])\n        \n        # Distance component is exponential distance to nearest line\n        distance = 999\n        \n        #Compute the distance to the nearest center line\n        for line in self.__reward_points:\n            local_distance = 0\n            length_squared = ((line[0][0]-line[1][0])**2) + ((line[0][1]-line[1][1])**2)\n            if (length_squared != 0):\n                t = max(0, min(1, np.dot(car_point-line[0], line[1]-line[0]) / length_squared))\n                proj = line[0] + (t * (line[1]-line[0]))\n                local_distance = np.linalg.norm(proj - car_point)\n            \n            distance = min(local_distance, distance)\n            \n        distance_reward = math.exp(-(distance * DISTANCE_DECAY_RATE))\n        \n        return distance_reward, distance > THRESH_DIST\n\n    # Initializes the points used for determining the starting point of the vehicle\n    def __init_road_points(self):\n        self.__road_points = []\n        car_start_coords = [12961.722656, 6660.329102, 0]\n        with open(os.path.join(os.path.join(self.__data_dir, \'data\'), \'road_lines.txt\'), \'r\') as f:\n            for line in f:\n                points = line.split(\'\\t\')\n                first_point = np.array([float(p) for p in points[0].split(\',\')] + [0])\n                second_point = np.array([float(p) for p in points[1].split(\',\')] + [0])\n                self.__road_points.append(tuple((first_point, second_point)))\n\n        # Points in road_points.txt are in unreal coordinates\n        # But car start coordinates are not the same as unreal coordinates\n        for point_pair in self.__road_points:\n            for point in point_pair:\n                point[0] -= car_start_coords[0]\n                point[1] -= car_start_coords[1]\n                point[0] /= 100\n                point[1] /= 100\n              \n    # Initializes the points used for determining the optimal position of the vehicle during the reward function\n    def __init_reward_points(self):\n        self.__reward_points = []\n        with open(os.path.join(os.path.join(self.__data_dir, \'data\'), \'reward_points.txt\'), \'r\') as f:\n            for line in f:\n                point_values = line.split(\'\\t\')\n                first_point = np.array([float(point_values[0]), float(point_values[1]), 0])\n                second_point = np.array([float(point_values[2]), float(point_values[3]), 0])\n                self.__reward_points.append(tuple((first_point, second_point)))\n\n    # Randomly selects a starting point on the road\n    # Used for initializing an iteration of data generation from AirSim\n    def __get_next_starting_point(self):\n    \n        # Get the current state of the vehicle\n        car_state = self.__car_client.getCarState()\n\n        # Pick a random road.\n        random_line_index = np.random.randint(0, high=len(self.__road_points))\n        \n        # Pick a random position on the road. \n        # Do not start too close to either end, as the car may crash during the initial run.\n        random_interp = (np.random.random_sample() * 0.4) + 0.3\n        \n        # Pick a random direction to face\n        random_direction_interp = np.random.random_sample()\n\n        # Compute the starting point of the car\n        random_line = self.__road_points[random_line_index]\n        random_start_point = list(random_line[0])\n        random_start_point[0] += (random_line[1][0] - random_line[0][0])*random_interp\n        random_start_point[1] += (random_line[1][1] - random_line[0][1])*random_interp\n\n        # Compute the direction that the vehicle will face\n        # Vertical line\n        if (np.isclose(random_line[0][1], random_line[1][1])):\n            if (random_direction_interp > 0.5):\n                random_direction = (0,0,0)\n            else:\n                random_direction = (0, 0, math.pi)\n        # Horizontal line\n        elif (np.isclose(random_line[0][0], random_line[1][0])):\n            if (random_direction_interp > 0.5):\n                random_direction = (0,0,math.pi/2)\n            else:\n                random_direction = (0,0,-1.0 * math.pi/2)\n\n        # The z coordinate is always zero\n        random_start_point[2] = -0\n        return (random_start_point, random_direction)\n\n    # A helper function to make a directory if it does not exist\n    def __make_dir_if_not_exist(self, directory):\n        if not (os.path.exists(directory)):\n            try:\n                os.makedirs(directory)\n            except OSError as e:\n                if e.errno != errno.EEXIST:\n                    raise\n\n# Sets up the logging framework.\n# This allows us to log using simple print() statements.\n# The output is redirected to a unique file on the file share.\ndef setup_logs(parameters):\n    output_dir = \'Z:\\\\logs\\\\{0}\\\\agent\'.format(parameters[\'experiment_name\'])\n    if not os.path.isdir(output_dir):\n        try:\n            os.makedirs(output_dir)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n    sys.stdout = open(os.path.join(output_dir, \'{0}.stdout.txt\'.format(os.environ[\'AZ_BATCH_NODE_ID\'])), \'w\')\n    sys.stderr = open(os.path.join(output_dir, \'{0}.stderr.txt\'.format(os.environ[\'AZ_BATCH_NODE_ID\'])), \'w\')\n\n# Parse the command line parameters\nparameters = {}\nfor arg in sys.argv:\n    if \'=\' in arg:\n        args = arg.split(\'=\')\n        print(\'0: {0}, 1: {1}\'.format(args[0], args[1]))\n        parameters[args[0].replace(\'--\', \'\')] = args[1]\n    if arg.replace(\'-\', \'\') == \'local_run\':\n        parameters[\'local_run\'] = True\n\n#Make the debug statements easier to read\nnp.set_printoptions(threshold=np.nan, suppress=True)\n\n# Check additional parameters needed for local run\nif \'local_run\' in parameters:\n    if \'airsim_path\' not in parameters:\n        print(\'ERROR: for a local run, airsim_path must be defined.\')\n        print(\'Please provide the path to airsim in a parameter like ""airsim_path=<path_to_airsim>""\')\n        print(\'It should point to the folder containing AD_Cookbook_Start_AirSim.ps1\')\n        sys.exit()\n    if \'batch_update_frequency\' not in parameters:\n        print(\'ERROR: for a local run, batch_update_frequency must be defined.\')\n        print(\'Please provide the path to airsim in a parameter like ""batch_update_frequency=<int>""\')\n        sys.exit()\n\n# Set up the logging to the file share if not running locally.\nif \'local_run\' not in parameters:\n    setup_logs(parameters)\n\nprint(\'------------STARTING AGENT----------------\')\nprint(parameters)\n\nprint(\'***\')\nprint(os.environ)\nprint(\'***\')\n\n# Identify the node as an agent and start AirSim\nif \'local_run\' not in parameters:\n    os.system(\'echo 1 >> D:\\\\agent.agent\')\n    os.system(\'START """" powershell.exe D:\\\\AD_Cookbook_AirSim\\\\Scripts\\\\DistributedRL\\\\restart_airsim_if_agent.ps1\')\nelse:\n    os.system(\'START """" powershell.exe {0}\'.format(os.path.join(parameters[\'airsim_path\'], \'AD_Cookbook_Start_AirSim.ps1 neighborhood -windowed\')))\n    \n# Start the training\nagent = DistributedAgent(parameters)\nagent.start()\n'"
DistributedRL/Share/scripts_downpour/app/rl_model.py,8,"b""import time\nimport numpy as np\nimport json\nimport threading\nimport os\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model, clone_model, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Lambda, Input, concatenate\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import ELU\nfrom keras.optimizers import Adam, SGD, Adamax, Nadam, Adagrad, Adadelta\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\nimport keras.backend as K\nfrom keras.preprocessing import image\nfrom keras.initializers import random_normal\n\n# Prevent TensorFlow from allocating the entire GPU at the start of the program.\n# Otherwise, AirSim will sometimes refuse to launch, as it will be unable to \nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.Session(config=config)\nK.set_session(session)\n\n# A wrapper class for the DQN model\nclass RlModel():\n    def __init__(self, weights_path, train_conv_layers):\n        self.__angle_values = [-1, -0.5, 0, 0.5, 1]\n\n        self.__nb_actions = 5\n        self.__gamma = 0.99\n\n        #Define the model\n        activation = 'relu'\n        pic_input = Input(shape=(59,255,3))\n        \n        img_stack = Conv2D(16, (3, 3), name='convolution0', padding='same', activation=activation, trainable=train_conv_layers)(pic_input)\n        img_stack = MaxPooling2D(pool_size=(2,2))(img_stack)\n        img_stack = Conv2D(32, (3, 3), activation=activation, padding='same', name='convolution1', trainable=train_conv_layers)(img_stack)\n        img_stack = MaxPooling2D(pool_size=(2, 2))(img_stack)\n        img_stack = Conv2D(32, (3, 3), activation=activation, padding='same', name='convolution2', trainable=train_conv_layers)(img_stack)\n        img_stack = MaxPooling2D(pool_size=(2, 2))(img_stack)\n        img_stack = Flatten()(img_stack)\n        img_stack = Dropout(0.2)(img_stack)\n\n        img_stack = Dense(128, name='rl_dense', kernel_initializer=random_normal(stddev=0.01))(img_stack)\n        img_stack=Dropout(0.2)(img_stack)\n        output = Dense(self.__nb_actions, name='rl_output', kernel_initializer=random_normal(stddev=0.01))(img_stack)\n\n        opt = Adam()\n        self.__action_model = Model(inputs=[pic_input], outputs=output)\n\n        self.__action_model.compile(optimizer=opt, loss='mean_squared_error')\n        self.__action_model.summary()\n        \n        # If we are using pretrained weights for the conv layers, load them and verify the first layer.\n        if (weights_path is not None and len(weights_path) > 0):\n            print('Loading weights from my_model_weights.h5...')\n            print('Current working dir is {0}'.format(os.getcwd()))\n            self.__action_model.load_weights(weights_path, by_name=True)\n            \n            print('First layer: ')\n            w = np.array(self.__action_model.get_weights()[0])\n            print(w)\n        else:\n            print('Not loading weights')\n\n        # Set up the target model. \n        # This is a trick that will allow the model to converge more rapidly.\n        self.__action_context = tf.get_default_graph()\n        self.__target_model = clone_model(self.__action_model)\n\n        self.__target_context = tf.get_default_graph()\n        self.__model_lock = threading.Lock()\n\n    # A helper function to read in the model from a JSON packet.\n    # This is used both to read the file from disk and from a network packet\n    def from_packet(self, packet):\n        with self.__action_context.as_default():\n            self.__action_model.set_weights([np.array(w) for w in packet['action_model']])\n            self.__action_context = tf.get_default_graph()\n        if 'target_model' in packet:\n            with self.__target_context.as_default():\n                self.__target_model.set_weights([np.array(w) for w in packet['target_model']])\n                self.__target_context = tf.get_default_graph()\n\n    # A helper function to write the model to a JSON packet.\n    # This is used to send the model across the network from the trainer to the agent\n    def to_packet(self, get_target = True):\n        packet = {}\n        with self.__action_context.as_default():\n            packet['action_model'] = [w.tolist() for w in self.__action_model.get_weights()]\n            self.__action_context = tf.get_default_graph()\n        if get_target:\n            with self.__target_context.as_default():\n                packet['target_model'] = [w.tolist() for w in self.__target_model.get_weights()]\n\n        return packet\n\n    # Updates the model with the supplied gradients\n    # This is used by the trainer to accept a training iteration update from the agent\n    def update_with_gradient(self, gradients, should_update_critic):\n        with self.__action_context.as_default():\n            action_weights = self.__action_model.get_weights()\n            if (len(action_weights) != len(gradients)):\n                raise ValueError('len of action_weights is {0}, but len gradients is {1}'.format(len(action_weights), len(gradients)))\n            \n            print('UDPATE GRADIENT DEBUG START')\n            \n            dx = 0\n            for i in range(0, len(action_weights), 1):\n                action_weights[i] += gradients[i]\n                dx += np.sum(np.sum(np.abs(gradients[i])))\n            print('Moved weights {0}'.format(dx))\n            self.__action_model.set_weights(action_weights)\n            self.__action_context = tf.get_default_graph()\n\n            if (should_update_critic):\n                with self.__target_context.as_default():\n                    print('Updating critic')\n                    self.__target_model.set_weights([np.array(w, copy=True) for w in action_weights])\n            \n            print('UPDATE GRADIENT DEBUG END')\n            \n    def update_critic(self):\n        with self.__target_context.as_default():\n            self.__target_model.set_weights([np.array(w, copy=True) for w in self.__action_model.get_weights()])\n    \n            \n    # Given a set of training data, trains the model and determine the gradients.\n    # The agent will use this to compute the model updates to send to the trainer\n    def get_gradient_update_from_batches(self, batches):\n        pre_states = np.array(batches['pre_states'])\n        post_states = np.array(batches['post_states'])\n        rewards = np.array(batches['rewards'])\n        actions = list(batches['actions'])\n        is_not_terminal = np.array(batches['is_not_terminal'])\n        \n        # For now, our model only takes a single image in as input. \n        # Only read in the last image from each set of examples\n        pre_states = pre_states[:, 3, :, :, :]\n        post_states = post_states[:, 3, :, :, :]\n        \n        print('START GET GRADIENT UPDATE DEBUG')\n        \n        # We only have labels for the action that the agent actually took.\n        # To prevent the model from training the other actions, figure out what the model currently predicts for each input.\n        # Then, the gradients with respect to those outputs will always be zero.\n        with self.__action_context.as_default():\n            labels = self.__action_model.predict([pre_states], batch_size=32)\n        \n        # Find out what the target model will predict for each post-decision state.\n        with self.__target_context.as_default():\n            q_futures = self.__target_model.predict([post_states], batch_size=32)\n\n        # Apply the Bellman equation\n        q_futures_max = np.max(q_futures, axis=1)\n        q_labels = (q_futures_max * is_not_terminal * self.__gamma) + rewards\n        \n        # Update the label only for the actions that were actually taken.\n        for i in range(0, len(actions), 1):\n            labels[i][actions[i]] = q_labels[i]\n\n        # Perform a training iteration.\n        with self.__action_context.as_default():\n            original_weights = [np.array(w, copy=True) for w in self.__action_model.get_weights()]\n            self.__action_model.fit([pre_states], labels, epochs=1, batch_size=32, verbose=1)\n            \n            # Compute the gradients\n            new_weights = self.__action_model.get_weights()\n            gradients = []\n            dx = 0\n            for i in range(0, len(original_weights), 1):\n                gradients.append(new_weights[i] - original_weights[i])\n                dx += np.sum(np.sum(np.abs(new_weights[i]-original_weights[i])))\n            print('change in weights from training iteration: {0}'.format(dx))\n        \n        print('END GET GRADIENT UPDATE DEBUG')\n\n        # Numpy arrays are not JSON serializable by default\n        return [w.tolist() for w in gradients]\n\n    # Performs a state prediction given the model input\n    def predict_state(self, observation):\n        if (type(observation) == type([])):\n            observation = np.array(observation)\n        \n        # Our model only predicts on a single state.\n        # Take the latest image\n        observation = observation[3, :, :, :]\n        observation = observation.reshape(1, 59,255,3)\n        with self.__action_context.as_default():\n            predicted_qs = self.__action_model.predict([observation])\n\n        # Select the action with the highest Q value\n        predicted_state = np.argmax(predicted_qs)\n        return (predicted_state, predicted_qs[0][predicted_state])\n\n    # Convert the current state to control signals to drive the car.\n    # As we are only predicting steering angle, we will use a simple controller to keep the car at a constant speed\n    def state_to_control_signals(self, state, car_state):\n        if car_state.speed > 9:\n            return (self.__angle_values[state], 0, 1)\n        else:\n            return (self.__angle_values[state], 1, 0)\n\n    # Gets a random state\n    # Used during annealing\n    def get_random_state(self):\n        return np.random.randint(low=0, high=(self.__nb_actions) - 1)\n"""
DistributedRL/Share/scripts_downpour/app/views.py,0,"b'from django.shortcuts import render\nfrom django.http import HttpRequest, JsonResponse\nfrom django.template import RequestContext\nfrom django.views.decorators.csrf import csrf_exempt\nfrom datetime import datetime\nfrom ipware.ip import get_ip\nimport json\nimport inspect\nimport threading\nimport glob\nimport os\nimport sys\nfrom app.rl_model import RlModel\n\n# The main code file for the trainer.\n\n# Initialize the RL model\nif (\'weights_path\' in os.environ):\n    rl_model = RlModel(os.environ[\'weights_path\'], os.environ[\'train_conv_layers\'].lower() == \'true\')\nelse:\n    rl_model = RlModel(None, os.environ[\'train_conv_layers\'].lower() == \'true\')\n    \nmodel_lock = threading.Lock()\nbatch_count = 0\nbatch_update_frequency = 0\nnext_batch_update_count = 0\ncheckpoint_dir = \'\'\nagents_having_latest_critic = []\n\nmin_epsilon = float(os.environ[\'min_epsilon\'])\nepsilon_step = float(os.environ[\'per_iter_epsilon_reduction\'])\nepsilon = 1.0\n\n# A simple endpoint that can be used to determine if the trainer is online.\n# All requests will be responded to with a JSON {""message"": ""PONG""}\n# Routed to /ping\n@csrf_exempt\ndef ping(request):\n    try:\n        print(\'PONG\')\n        return JsonResponse({\'message\': \'pong\'})\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n# This endpoint is used to send gradient updates.\n# It expects a POST request with the gradients in the body.\n# It will return the latest model in the body\n# Routed to /gradient_update\n@csrf_exempt\ndef gradient_update(request):\n    global rl_model\n    global batch_count\n    global agents_having_latest_critic\n    global next_batch_update_count\n    global batch_update_frequency\n    global checkpoint_dir\n    global agents_having_latest_critic\n    global epsilon\n    global epsilon_step\n    global min_epsilon\n    try:\n        # Check that the request is a POST\n        if (request.method != \'POST\'):\n            raise ValueError(\'Need post method, got {0}\'.format(request.method))\n\n        # Read in the data and determine which trainer sent the information\n        post_data = json.loads(request.body.decode(\'utf-8\'))\n        request_ip = get_ip(request)\n\n        print(\'request_ip is {0}\'.format(request_ip))\n\n        # Django does not play nicely with TensorFlow in a multi-threaded context.\n        # Ensure that only a single minibatch is being processed at a time.\n        # Other threads will enter a queue and will be processed once the lock is released.\n        with model_lock:\n            \n            # Update the number of batches received\n            batch_count += int(post_data[\'batch_count\'])\n            print(\'Received {0} batches. batch count is now {1}.\'.format(int(post_data[\'batch_count\']), batch_count))\n\n            # We only occasionally update the critic (target) model. Determine if it\'s time to update the critic.\n            should_update_critic = (batch_count >= next_batch_update_count)\n\n            if (should_update_critic):\n                print(\'updating critic this iter.\')\n            else:\n                print(\'not updating critic\')\n\n            # Read in the gradients and update the model\n            model_gradients = post_data[\'gradients\']\n            rl_model.update_with_gradient(model_gradients, should_update_critic)\n            \n            # If we updated the critic, checkpoint the model.\n            if should_update_critic:\n                print(\'checkpointing...\')\n                checkpoint_state()\n                next_batch_update_count += batch_update_frequency\n                agents_having_latest_critic = []\n\n            # To save network bandwidth, we only need to send the critic if it\'s changed.\n            # Create the response to send to the agent\n            if request_ip not in agents_having_latest_critic:\n                print(\'Agent {0} has not received the latest critic model. Sending both.\'.format(request_ip))\n                model_response = rl_model.to_packet(get_target=True)\n                agents_having_latest_critic.append(request_ip)\n            else:\n                print(\'Agent {0} has received the latest critic model. Sending only the actor.\'.format(request_ip))\n                model_response = rl_model.to_packet(get_target=False)\n\n            epsilon -= epsilon_step\n            epsilon = max(epsilon, min_epsilon)\n            \n            print(\'Sending epsilon of {0} to {1}\'.format(epsilon, request_ip))\n            \n            model_response[\'epsilon\'] = epsilon\n                \n            # Send the response to the agent.\n            return JsonResponse(model_response)\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n# An endpoint to get the latest model.\n# It is expected to be called with a GET request.\n# The response will be the model.\n# Routed to /latest\n@csrf_exempt\ndef get_latest_model(request):\n    global rl_model\n    try:\n        if (request.method != \'GET\'):\n            raise ValueError(\'Need get method, got {0}\'.format(request.method))\n\n        with model_lock:\n            model_response = rl_model.to_packet(get_target=True)\n            return JsonResponse(model_response)\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n# A helper function to checkpoint the current state of the model.\n@csrf_exempt\ndef checkpoint_state():\n    global rl_model\n    global batch_count\n    try:\n        checkpoint = {}\n        checkpoint[\'model\'] = rl_model.to_packet(get_target=True)\n        checkpoint[\'batch_count\'] = batch_count\n        checkpoint_str = json.dumps(checkpoint)\n\n        file_name = os.path.join(checkpoint_dir, \'{0}.json\'.format(batch_count)) \n        with open(file_name, \'w\') as f:\n            print(\'Checkpointing to {0}\'.format(file_name))\n            f.write(checkpoint_str)\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n# A helper function to read the latest model from disk.\n@csrf_exempt\ndef read_latest_state():\n    global rl_model\n    global batch_count\n    global next_batch_update_count\n    global batch_update_frequency\n    global checkpoint_dir\n\n    try:\n        search_path = os.path.join(checkpoint_dir, \'*.json\')\n        print(\'searching {0}\'.format(search_path))\n        file_list = glob.glob(search_path)\n\n        print(\'Checkpoint dir: {0}\'.format(checkpoint_dir))\n        print(\'file_list: {0}\'.format(file_list))\n        \n        if (len(file_list) > 0):\n            latest_file = max(file_list, key=os.path.getctime)\n\n            print(\'Attempting to read latest state from {0}\'.format(latest_file))\n            file_text = \'\'\n            with open(latest_file, \'r\') as f:\n                file_text = f.read().replace(\'\\n\', \'\')\n            checkpoint_json = json.loads(file_text)\n            rl_model.from_packet(checkpoint_json[\'model\'])\n            batch_count = int(checkpoint_json[\'batch_count\'])\n            next_batch_update_count = batch_count + batch_update_frequency\n            print(\'Read latest state from {0}\'.format(latest_file))\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n# A helper function to parse environment variables\n@csrf_exempt\ndef parse_parameters():\n    global checkpoint_dir\n    global batch_update_frequency\n\n    try:\n        checkpoint_dir = os.path.join(os.path.join(os.environ[\'data_dir\'], \'checkpoint\'), os.environ[\'experiment_name\'])\n        \n        print(\'Checkpoint dir is {0}\'.format(checkpoint_dir))\n        \n        if not os.path.isdir(checkpoint_dir):\n            try:\n                os.makedirs(checkpoint_dir)\n            except OSError as e:\n                if e.errno != errno.EEXIST:\n                    raise\n        \n        print(\'checkpoint_dir is {0}\'.format(checkpoint_dir))\n        batch_update_frequency = int(os.environ[\'batch_update_frequency\'])\n        print(\'batch_update_frequency is {0}\'.format(batch_update_frequency))\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n        \n# On startup, the trainer node should identify itself to the agents by writing it IP address to (data_dir)\\trainer_ip\\(experiment_name)\\trainer_ip.txt\n@csrf_exempt\ndef write_ip():\n    try:\n        file_dir = os.path.join(os.path.join(os.environ[\'data_dir\'], \'trainer_ip\'), os.environ[\'experiment_name\'])\n        \n        print(\'Writing to {0}...\'.format(file_dir))\n        \n        if not os.path.isdir(file_dir):\n            try:\n                os.makedirs(file_dir)\n            except OSError as e:\n                if e.errno != errno.EEXIST:\n                    raise\n        \n        with open(os.path.join(file_dir, \'trainer_ip.txt\'), \'w\') as f:\n            print(\'writing ip of {0}\'.format(os.environ[\'AZ_BATCH_NODE_LIST\'].split(\';\')[0]))\n            f.write(os.environ[\'AZ_BATCH_NODE_LIST\'].split(\';\')[0])\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()\n    \n# stdout / stderr have already been redirected in manage.py\nprint(\'-----------STARTING TRAINER---------------\')\nprint(\'-----------STARTING TRAINER---------------e\', file=sys.stderr)\n\n# Identify this node as a trainer, and kill all running instances of AirSim\nos.system(\'DEL D:\\\\*.agent\')\nos.system(\'START """" powershell.exe D:\\\\AD_Cookbook_AirSim\\\\Scripts\\\\DistributedRL\\\\restart_airsim_if_agent.ps1\')\nsys.stdout.flush()\nsys.stderr.flush()\n\n# Initialize the node and notify agent nodes.\nparse_parameters()\nread_latest_state()\nwrite_ip()\n'"
DistributedRL/Share/scripts_downpour/downpour/__init__.py,0,b''
DistributedRL/Share/scripts_downpour/downpour/settings.py,0,"b'""""""\nDjango settings for downpour project.\n\nGenerated by \'django-admin startproject\' using Django 2.0.1.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/2.0/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/2.0/ref/settings/\n""""""\n\nimport os\n\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/2.0/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = \'zcuio9+444c@rtg-n-894as79tur-2msjzp201-eewy&#e8_9)\'\n\n# SECURITY WARNING: don\'t run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = [\'*\']\n\nDATA_UPLOAD_MAX_NUMBER_FIELDS = None\nDATA_UPLOAD_MAX_MEMORY_SIZE = None\n\n# Application definition\n\nINSTALLED_APPS = [\n    \'django.contrib.admin\',\n    \'django.contrib.auth\',\n    \'django.contrib.contenttypes\',\n    \'django.contrib.sessions\',\n    \'django.contrib.messages\',\n    \'django.contrib.staticfiles\',\n]\n\nMIDDLEWARE = [\n    \'django.middleware.security.SecurityMiddleware\',\n    \'django.contrib.sessions.middleware.SessionMiddleware\',\n    \'django.middleware.common.CommonMiddleware\',\n    \'django.middleware.csrf.CsrfViewMiddleware\',\n    \'django.contrib.auth.middleware.AuthenticationMiddleware\',\n    \'django.contrib.messages.middleware.MessageMiddleware\',\n    \'django.middleware.clickjacking.XFrameOptionsMiddleware\',\n]\n\nROOT_URLCONF = \'downpour.urls\'\n\nTEMPLATES = [\n    {\n        \'BACKEND\': \'django.template.backends.django.DjangoTemplates\',\n        \'DIRS\': [],\n        \'APP_DIRS\': True,\n        \'OPTIONS\': {\n            \'context_processors\': [\n                \'django.template.context_processors.debug\',\n                \'django.template.context_processors.request\',\n                \'django.contrib.auth.context_processors.auth\',\n                \'django.contrib.messages.context_processors.messages\',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = \'downpour.wsgi.application\'\n\n\n# Database\n# https://docs.djangoproject.com/en/2.0/ref/settings/#databases\n\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django.db.backends.sqlite3\',\n        \'NAME\': os.path.join(BASE_DIR, \'db.sqlite3\'),\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/2.0/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.UserAttributeSimilarityValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.MinimumLengthValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.CommonPasswordValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.NumericPasswordValidator\',\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/2.0/topics/i18n/\n\nLANGUAGE_CODE = \'en-us\'\n\nTIME_ZONE = \'UTC\'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.0/howto/static-files/\n\nSTATIC_URL = \'/static/\'\n'"
DistributedRL/Share/scripts_downpour/downpour/urls.py,0,"b'""""""downpour URL Configuration\n\nThe `urlpatterns` list routes URLs to views. For more information please see:\n    https://docs.djangoproject.com/en/2.0/topics/http/urls/\nExamples:\nFunction views\n    1. Add an import:  from my_app import views\n    2. Add a URL to urlpatterns:  path(\'\', views.home, name=\'home\')\nClass-based views\n    1. Add an import:  from other_app.views import Home\n    2. Add a URL to urlpatterns:  path(\'\', Home.as_view(), name=\'home\')\nIncluding another URLconf\n    1. Import the include() function: from django.urls import include, path\n    2. Add a URL to urlpatterns:  path(\'blog/\', include(\'blog.urls\'))\n""""""\nfrom django.contrib import admin\nfrom django.urls import path\nimport app.views\n\nurlpatterns = [\n    path(\'ping\', app.views.ping, name=\'ping\'),\n    path(\'gradient_update\', app.views.gradient_update, name=\'gradient_update\'),\n    path(\'latest\', app.views.get_latest_model, name=\'latest_state\')\n]\n'"
DistributedRL/Share/scripts_downpour/downpour/wsgi.py,0,"b'""""""\nWSGI config for downpour project.\n\nIt exposes the WSGI callable as a module-level variable named ``application``.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/2.0/howto/deployment/wsgi/\n""""""\n\nimport os\n\nfrom django.core.wsgi import get_wsgi_application\n\nos.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""downpour.settings"")\n\napplication = get_wsgi_application()\n'"
