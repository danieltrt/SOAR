file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\n\nlong_description = '''\nGive an input CSV file and a target field you want to predict to automl-gs, and get a trained high-performing machine learning or deep learning model plus native code pipelines allowing you to integrate that model into any prediction workflow. No black box: you can see *exactly* how the data is processed, how the model is constructed, and you can make tweaks as necessary.\n\nautoml-gs is an AutoML tool which, unlike Microsoft's [NNI](https://github.com/Microsoft/nni), Uber's [Ludwig](https://github.com/uber/ludwig), and [TPOT](https://github.com/EpistasisLab/tpot), offers a *zero code/model definition interface* to getting an optimized model and data transformation pipeline in multiple popular ML/DL frameworks, with minimal Python dependencies (pandas + scikit-learn + your framework of choice). automl-gs is designed for citizen data scientists and engineers without a deep statistical background under the philosophy that you don't need to know any modern data preprocessing and machine learning engineering techniques to create a powerful prediction workflow.\n\nNowadays, the cost of computing many different models and hyperparameters is much lower than the oppertunity cost of an data scientist's time. automl-gs is a Python 3 module designed to abstract away the common approaches to transforming tabular data, architecting machine learning/deep learning models, and performing random hyperparameter searches to identify the best-performing model. This allows data scientists and researchers to better utilize their time on model performance optimization.\n\n* Generates native Python code; no platform lock-in, and no need to use automl-gs after the model script is created.\n* Train model configurations super-fast *for free* using a **TPU** in Google Colaboratory.\n* Handles messy datasets that normally require manual intervention, such as datetime/categorical encoding and spaced/parathesized column names.\n* Each part of the generated model pipeline is its own function w/ docstrings, making it much easier to integrate into production workflows.\n* Extremely detailed metrics reporting for every trial stored in a tidy CSV, allowing you to identify and visualize model strengths and weaknesses.\n* Correct serialization of data pipeline encoders on disk (i.e. no pickled Python objects!)\n* Retrain the generated model on new data without making any code/pipeline changes.\n* Quit the hyperparameter search at any time, as the results are saved after each trial.\n\nThe models generated by automl-gs are intended to give a very strong *baseline* for solving a given problem; they're not the end-all-be-all that often accompanies the AutoML hype, but the resulting code is easily tweakable to improve from the baseline.\n'''\n\n\nsetup(\n    name='automl_gs',\n    packages=['automl_gs'],  # this must be the same as the name above\n    version='0.2.1',\n    description='Provide an input CSV and a target field to predict, ' \\\n    'generate a model + code to run it.',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    author='Max Woolf',\n    author_email='max@minimaxir.com',\n    url='https://github.com/minimaxir/automl-gs',\n    keywords=['deep learning', 'tensorflow', 'keras', 'automl', 'xgboost'],\n    classifiers=[],\n    license='MIT',\n    entry_points = {\n        'console_scripts': ['automl_gs=automl_gs.automl_gs:cmd'],\n    },\n    python_requires='>=3.5',\n    include_package_data=True,\n    install_requires=['pandas', 'scikit-learn', 'autopep8', 'tqdm', 'jinja2>=2.8', 'pyyaml']\n)\n"""
automl_gs/__init__.py,0,b'from .automl_gs import automl_grid_search\nfrom .automl_gs import cmd'
automl_gs/automl_gs.py,0,"b'import os\nimport pandas as pd\nfrom jinja2 import Environment, PackageLoader\nfrom tqdm import tqdm, tqdm_notebook\nfrom datetime import datetime\nimport shutil\nimport uuid\nimport argparse\nfrom .utils_automl import *\n\n\ndef automl_grid_search(csv_path, target_field,\n                       target_metric=None,\n                       framework=\'tensorflow\',\n                       model_name=\'automl\',\n                       context=\'standalone\',\n                       num_trials=100,\n                       split=0.7,\n                       num_epochs=20,\n                       col_types={},\n                       gpu=False,\n                       tpu_address=None):\n    """"""Parent function which performs the hyperparameter search.\n\n    See the package README for parameter descriptions:\n    https://github.com/minimaxir/automl-gs\n    """"""\n\n    # Prepare environment and source data\n    env = Environment(\n        loader=PackageLoader(\'automl_gs\', \'templates\'),\n        trim_blocks=True,\n        lstrip_blocks=True\n    )\n\n    df = pd.read_csv(csv_path, nrows=100)\n    object_cols = [col for col, col_type in df.dtypes.iteritems() if col_type == \'object\']\n    df[object_cols] = df[object_cols].apply(pd.to_datetime, errors=\'ignore\')\n\n    problem_type, target_metric, direction = get_problem_config(\n        df[target_field], framework, target_metric)\n    input_types = get_input_types(df, col_types, target_field)\n    hp_grid = build_hp_grid(framework, set(input_types.values()), num_trials, problem_type)\n    fields = normalize_col_names(input_types)\n\n    metrics_csv = open(""automl_results.csv"", \'w\')\n    best_result = None\n    timeformat_utc = ""{:%Y%m%d_%H%M%S}"".format(datetime.utcnow())\n    best_folder = ""{}_{}_{}"".format(model_name, framework, timeformat_utc)\n    train_folder = ""{}_train"".format(model_name)\n    cmd = build_subprocess_cmd(csv_path, train_folder)\n\n\n    \n    # https://stackoverflow.com/a/39662359\n    try:\n        is_notebook = get_ipython().__class__.__name__ in [\'ZMQInteractiveShell\',\n                                                           \'Shell\']\n    except:\n        is_notebook = False\n\n    pbar_func = tqdm_notebook if is_notebook else tqdm\n    pbar = pbar_func(hp_grid, smoothing=0, unit=\'trial\')\n    pbar_sub = pbar_func(total=num_epochs, leave=False,\n                         smoothing=0, unit=\'epoch\')\n    \n    for params in pbar:\n\n        # Create destination folders for the model scripts + metadata\n        if not os.path.exists(train_folder):\n            os.mkdir(train_folder)\n            os.mkdir(os.path.join(train_folder, \'metadata\'))\n            os.mkdir(os.path.join(train_folder, \'encoders\'))\n\n        # Generate model files according to the given hyperparameters.\n        render_model(params, model_name,\n                    framework, env, problem_type,\n                    target_metric, target_field,\n                    train_folder, fields, split, num_epochs, gpu, tpu_address)\n\n        # Execute model training using the generated files.\n        train_generated_model(cmd, num_epochs, train_folder, pbar_sub)\n\n        # Load the training results from the generated CSV,\n        # and append to the metrics CSV.\n        results = pd.read_csv(os.path.join(train_folder, \n                                        ""metadata"", ""results.csv""))\n        results = results.assign(**params)\n        results.insert(0, \'trial_id\', uuid.uuid4())\n\n        results.to_csv(""automl_results.csv"", mode=""a"", index=False,\n                    header=(best_result is None))\n\n        train_results = results.tail(1).to_dict(\'records\')[0]\n\n        # If the target metric improves, save the new hps/files,\n        # update the hyperparameters in console,\n        # and delete the previous best files.\n\n        top_result = train_results[target_metric]\n\n        if top_result is not None:\n            if best_result is None:   # if first iteration\n                best_result = top_result\n                shutil.copytree(train_folder, best_folder)\n                print_progress_tqdm(params, train_results,\n                                    pbar, is_notebook, False)\n            else:\n                is_imp = top_result > best_result\n                is_imp = not is_imp if direction == \'min\' else is_imp\n                if is_imp:\n                    best_result = top_result\n                    shutil.rmtree(best_folder)\n                    shutil.copytree(train_folder, best_folder)\n                    print_progress_tqdm(params, train_results,\n                                        pbar, is_notebook)\n\n        # Clean up the generated file folder for the next trial.\n        shutil.rmtree(train_folder)\n\n    metrics_csv.close()\n    pbar.close()\n    pbar_sub.close()\n\ndef cmd():\n    """"""Function called when invoking from the terminal.""""""\n\n    parser = argparse.ArgumentParser(\n        description=""Provide an input CSV and a target field to predict, generate a model + code to run it. (https://github.com/minimaxir/automl-gs)""\n    )\n\n\n\n    # Explicit arguments\n    parser.add_argument(\n        \'--csv_path\',  help=\'Path to the CSV file (must be in the current directory) [Required]\', nargs=\'?\')\n    parser.add_argument(\n        \'--target_field\',  help=""Target field to predict [Required]"",\n        nargs=\'?\')\n    parser.add_argument(\n        \'--target_metric\',  help=\'Target metric to optimize [Default: Automatically determined depending on problem type]\', nargs=\'?\', default=None)\n    parser.add_argument(\n        \'--framework\',  help=\'Machine learning framework to use [Default: tensorflow]\', nargs=\'?\', default=\'tensorflow\')\n    parser.add_argument(\n        \'--model_name\',  help="" Name of the model (if you want to train models with different names) [Default: \'automl\']"",\n        nargs=\'?\', default=\'automl\')\n    parser.add_argument(\n        \'--num_trials\',  help=\'Number of trials / different hyperameter combos to test. [Default: 100]\', nargs=\'?\', type=int, default=100)\n    parser.add_argument(\n        \'--split\',  help=""Train-val split when training the models [Default: 0.7]"",\n        nargs=\'?\', type=float, default=0.7)\n    parser.add_argument(\n        \'--num_epochs\',  help=\'Number of epochs / passes through the data when training the models. [Default: 20]\', type=int, default=20)\n    parser.add_argument(\n        \'--gpu\',  help=""For non-Tensorflow frameworks and Pascal-or-later GPUs, boolean to determine whether to use GPU-optimized training methods (TensorFlow can detect it automatically) [Default: False]"",\n        nargs=\'?\', type=bool, default=False)\n    parser.add_argument(\n        \'--tpu_address\',  help=""For TensorFlow, hardware address of the TPU on the system. [Default: None]"",\n        nargs=\'?\', default=None)\n\n    # Positional arguments\n    parser.add_argument(\'csv_path\', nargs=\'?\')\n    parser.add_argument(\'target_field\', nargs=\'?\')\n\n    args = parser.parse_args()\n    automl_grid_search(csv_path=args.csv_path,\n                       target_field=args.target_field,\n                       target_metric=args.target_metric,\n                       framework=args.framework,\n                       model_name=args.model_name,\n                       num_trials=args.num_trials,\n                       split=args.split,\n                       num_epochs=args.num_epochs,\n                       gpu=args.gpu,\n                       tpu_address=args.tpu_address)\n'"
automl_gs/utils_automl.py,0,"b'import re\nimport pandas as pd\nimport random\nimport yaml\nimport os\nimport shutil\nfrom time import time\nfrom pkg_resources import resource_filename\nfrom tqdm import tqdm, tqdm_notebook\nfrom tqdm._utils import _term_move_up\nfrom subprocess import Popen, PIPE, DEVNULL, CalledProcessError\nfrom autopep8 import fix_code\nfrom collections import OrderedDict\n\n\ndef get_input_types(df, col_types, target_field):\n    """"""Get the input types for each field in the DataFrame that corresponds\n    to an input type to be fed into the model.\n\n    Valid values are [\'text\', \'categorical\', \'numeric\', \'datetime\', \'ignore\']\n\n    # Arguments:\n        df: A pandas DataFrame.\n        col_types: A dict of explicitly defined {field_name: type} mappings.\n        target_field: string indicating the target field\n\n    # Returns:\n        A dict of {field_name: type} mappings.\n    """"""\n\n    fields = df.columns\n    nrows = df.shape[0]\n    avg_spaces = -1\n\n    field_types = OrderedDict()\n\n    for field in fields:\n        if field in col_types:\n            field_types[field] = col_types[field]\n            continue\n        field_type = df[field].dtype\n        num_unique_values = df[field].nunique()\n        if field_type == \'object\':\n            avg_spaces = df[field].str.count(\' \').mean()\n\n        # Automatically ignore `id`-related fields\n        if field.lower() in [\'id\', \'uuid\', \'guid\', \'pk\', \'name\']:\n            field_types[field] = \'ignore\'\n\n        # Foreign key fields are always categorical\n        # else if ""_id"" in field or ""_uuid"" in field:\n        #     field_types[field] = \'categorical\'\n\n        # Datetime is a straightforward data type.\n        elif field_type == \'datetime64[ns]\':\n            field_types[field] = \'datetime\'\n\n        # Assume a float is always numeric.\n        elif field_type == \'float64\':\n            field_types[field] = \'numeric\'\n\n        # If it\'s an object where the contents has\n        # many spaces on average, it\'s text\n        elif field_type == \'object\' and avg_spaces >= 2.0:\n            field_types[field] = \'text\'\n\n        # If the field has very few distinct values, it\'s categorical\n        elif num_unique_values <= 10:\n            field_types[field] = \'categorical\'\n\n        # If the field has many distinct integers, assume numeric.\n        elif field_type == \'int64\':\n            field_types[field] = \'numeric\'\n\n        # If the field has many distinct nonintegers, it\'s not helpful.\n        elif num_unique_values > 0.9 * nrows:\n            field_types[field] = \'ignore\'\n\n        # The rest (e.g. bool) is categorical\n        else:\n            field_types[field] = \'categorical\'\n\n    # Print to console for user-level debugging\n    print(""Modeling with field specifications:"")\n    print(""\\n"".join([""{}: {}"".format(k, v) for k, v in field_types.items() if k != target_field]))\n\n    field_types = {k: v for k, v in field_types.items() if v != \'ignore\'}\n\n    return field_types\n\n\ndef normalize_col_names(input_types):\n    """"""Fixes unusual column names (e.g. Caps, Spaces)\n    to make them suitable printing into code templates.\n\n    # Arguments:\n        input_types: dict of col names: input types\n\n    # Returns:\n        A dict of col names: input types with normalized keys\n    """"""\n\n    pattern = re.compile(\'\\W+\')\n    fields = [(re.sub(pattern, \'_\', field.lower()), field, field_type)\n                   for field, field_type in input_types.items()]\n\n    return fields\n\n\ndef build_hp_grid(framework, types, num_trials,\n                  problem_type,\n                  hp_path=resource_filename(__name__, ""hyperparameters.yml"")):\n    """"""Builds the hyperparameter grid for model grid search.\n\n    # Arguments:\n        framework: string indicating the framework (e.g. `tensorflow`)\n        types: list of hyperparameter types to consider; exclude rest\n        num_trials: number of distinct trials to keep\n        problem_type: type of problem to solve\n        hp_path: filepath of hyperparameters\n\n    # Returns\n        A list of dicts of hyperparameter specifications\n    """"""\n\n    with open(hp_path) as f:\n        hps = yaml.safe_load(f)\n\n    # Refine hyperparameters by only using ones relevant to\n    # the data and framework of choice\n    hps = dict(hps[\'base\'], **hps[framework])\n    keys = [key for key in hps.keys() if (hps[key][\'type\'] in types\n                                          or hps[key][\'type\'] == \'base\'\n                                          or hps[key][\'type\'] == problem_type)]\n    values = [hps[key][\'hyperparams\'] for key in keys]\n\n    grid = set()\n    while len(grid) < num_trials:\n        grid.add(tuple([random.choice(x) for x in values]))\n\n    grid_params = [dict(zip(keys, grid_hps)) for grid_hps in grid]\n    return grid_params\n\n\ndef print_progress_tqdm(hps, metrics, pbar, is_notebook, clear=True):\n    """"""Custom writer for tqdm which prints winning metrics\n    to console after each iteration.\n\n    Uses a hack for tqdm.write(): https://github.com/tqdm/tqdm/issues/520\n\n    # Arguments:\n        hps: dict of hyperparameters\n        metrics: dict of hyperparameters+metrics\n        pbar: a tqdm progressbar\n        is_notebook: boolean if automl-gs is running in a Notebook.\n        clear: if writing should clear existing output\n    """"""\n\n    # hp_str = \'\\n\'.join([\'{}: {}\'.format(k, v) for k, v in hps.items()])\n    metrics_str = \'\\n\'.join([\'{}: {}\'.format(k, v) for k, v in metrics.items()\n                             if k not in hps.keys()])\n\n    # console_str = (""\\nHyperparameters:\\n"" + hp_str + ""\\n"" +\n    #              ""\\nMetrics:\\n"" + metrics_str)\n\n    console_str = ""\\nMetrics:\\n"" + metrics_str\n\n    # Print to console, removing appropriate number of lines\n    move_up_char = \'\' if is_notebook else _term_move_up()\n    if clear:\n        pbar.write("""".join([move_up_char] * (console_str.count(\'\\n\') + 2)))\n\n    pbar.write(console_str)\n\n\ndef render_model(params, model_name, framework, env, problem_type, \n                 target_metric, target_field, train_folder, fields,\n                 split, num_epochs, gpu, tpu_address,\n                 metrics_path=resource_filename(__name__, ""metrics.yml"")):\n    """"""Renders and saves the files (model.py, pipeline.py, requirements.txt) for the given hyperparameters.\n    """"""\n\n    files = [\'model.py\', \'pipeline.py\', \'requirements.txt\']\n\n    type_map = {\n    \'numeric\': \'float64\',\n    \'categorical\': \'str\',\n    \'datetime\': \'str\',\n    \'text\': \'str\'\n    }\n\n    load_fields = {field[1]: type_map[field[2]] for field in fields}\n    text_fields = [field for field in fields if field[2] == \'text\']\n    nontarget_fields = [field for field in fields if field[1] != target_field]\n    target_field, target_field_raw = [(field[0], field[1]) for field in fields if field[1] == target_field][0]\n    has_text_input = \'text\' in [field[2] for field in fields]\n    text_framework = \'tensorflow\' if framework == \'tensorflow\' else \'sklearn\'\n\n    with open(metrics_path) as f:\n        metrics = yaml.safe_load(f)[problem_type]\n\n    for file in files:\n        script = env.get_template(\'scripts/\' + file.replace(\'.py\', \'\')).render(\n            params=params,\n            model_name=model_name,\n            framework=framework,\n            problem_type=problem_type,\n            target_metric=target_metric,\n            target_field=target_field,\n            fields=fields,\n            split=split,\n            num_epochs=num_epochs,\n            load_fields=load_fields,\n            text_fields=text_fields,\n            nontarget_fields=nontarget_fields,\n            target_field_raw=target_field_raw,\n            has_text_input=has_text_input,\n            metrics=metrics,\n            text_framework=text_framework,\n            gpu=gpu,\n            tpu_address=tpu_address)\n\n        script = fix_code(script)\n\n        with open(train_folder + ""/"" + file, \'w\', encoding=\'utf8\') as outfile:\n            outfile.write(script)\n\n\ndef get_problem_config(target_data,\n                       framework,\n                       target_metric,\n                       metrics_path=resource_filename(__name__, ""metrics.yml"")):\n    """"""Gets the problem type, target metric, and metric direction, or infers\n    them from the data if not expicitly specified.\n\n    # Arguments:\n        target_data: Data column to infer problem spec on.\n        framework: problem framework\n        target_metric: Target metric to optimize (overrides automatic selection)\n        metrics_path: location of the metrics file\n\n    # Returns:\n        problem_type: One of \'regression\', \'binary_classification\' or\n                      \'classification\'.\n        target_metric: Target metric to optimize.\n        direction: Direction of the metric to optimize (either \'max\' or \'min\')\n    """"""\n\n    nrows = target_data.size\n    num_unique_values = target_data.nunique()\n    field_type = target_data.dtype\n\n    # Problem Type\n    if num_unique_values == 2:\n        problem_type = \'binary_classification\'\n    elif field_type == \'float64\':\n        problem_type = \'regression\'\n    else:\n        problem_type = \'classification\'\n\n    # Target Metric\n    if target_metric is not None:\n        pass\n    elif problem_type == \'regression\':\n        target_metric = \'mse\'\n    else:\n        target_metric = \'accuracy\'\n\n    # Direction\n    with open(metrics_path) as f:\n        metrics = yaml.safe_load(f)\n\n    direction = metrics[target_metric][\'objective\']\n    direction_text = \'minimizing\' if direction == \'min\' else \'maximizing\'\n\n    # Print config to console for user-level debugging.\n    print(""Solving a {} problem, {} {} using {}.\\n"".format(\n        problem_type, direction_text, target_metric, framework))\n\n    return problem_type, target_metric, direction\n\n\ndef build_subprocess_cmd(csv_path, train_folder):\n    """"""Builds the command used to call a subprocess for model training.\n\n    Other parameters like split and num_epochs are not passed\n    since they are the default in the generated code.\n    """"""\n\n    csv_path_join = os.path.join(\'..\', csv_path)\n\n    # Find the python executable\n    if shutil.which(\'python3\') is not None:\n        pycmd = shutil.which(\'python3\')\n    elif shutil.which(\'python\'):\n        # fall back to regular python, which may be py3\n        pycmd = shutil.which(\'python\')\n    else:\n        # might be a better exception for this\n        raise Exception(""error: unable to locate the python binary for the subprocess call"")\n\n    return [pycmd, ""model.py"",\n            ""-d"", csv_path_join,\n            ""-m"", ""train"",\n            ""-c"", ""automl-gs""]\n\n\ndef train_generated_model(cmd, num_epochs, train_folder, pbar_sub):\n    """"""Trains a generated model script in a Python subprocess,\n       and maintains a progress bar of the subprocess training.\n\n       Each subprocess must output a stdout flush + an\n       ""EPOCH_END"" string accordingly\n\n    # Arguments:\n        cmd: A generate command\n        num_epochs: number of epochs\n        train_folder: subfolder where the training occurs.\n        pbar_sub: tqdm progress bar for the subprocess\n    """"""\n\n    p = Popen(cmd, cwd=train_folder, stdout=PIPE, bufsize=1,\n              universal_newlines=True) \n        \n    for line in iter(p.stdout.readline, """"):\n        if line == ""EPOCH_END\\n"":\n            pbar_sub.update(1)\n\n    if p.returncode is not None:\n        raise CalledProcessError(p.returncode, p.args)\n\n    p.stdout.close()\n\n    # Reset the subprogress bar without destroying it\n    # https://github.com/tqdm/tqdm/issues/545#issuecomment-471090550\n    pbar_sub.n = 0\n    pbar_sub.last_print_n = 0\n    pbar_sub.start_t = time()\n    pbar_sub.last_print_t = time()\n    pbar_sub.refresh()\n'"
