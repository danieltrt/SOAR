file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\n\nsetup(\n    name='reactionrnn',\n    packages=['reactionrnn'],  # this must be the same as the name above\n    version='0.1',\n    description='Pretrained character-based neural network for ' \\\n    'predicting the reaction to given text(s).',\n    author='Max Woolf',\n    author_email='max@minimaxir.com',\n    url='https://github.com/minimaxir/reactionrnn',\n    keywords=['deep learning', 'tensorflow', 'keras', 'sentiment analysis'],\n    classifiers=[],\n    license='MIT',\n    include_package_data=True,\n    install_requires=['tensorflow', 'keras', 'h5py']\n)\n"""
reactionrnn/__init__.py,0,b'from .reactionrnn import reactionrnn\n'
reactionrnn/reactionrnn.py,0,"b""from keras.layers import Input, Embedding, Dense, GRU\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nimport numpy as np\nimport json\nimport h5py\nfrom pkg_resources import resource_filename\nfrom collections import OrderedDict\nfrom keras import backend as K\n\n\nclass reactionrnn:\n    MAXLEN = 140\n    REACTIONS = ['love', 'wow', 'haha', 'sad', 'angry']\n\n    def __init__(self, weights_path=None,\n                 vocab_path=None):\n\n        if weights_path is None:\n            weights_path = resource_filename(__name__,\n                                             'reactionrnn_weights.hdf5')\n\n        if vocab_path is None:\n            vocab_path = resource_filename(__name__,\n                                           'reactionrnn_vocab.json')\n\n        with open(vocab_path, 'r') as json_file:\n            self.vocab = json.load(json_file)\n\n        self.tokenizer = Tokenizer(filters='', char_level=True)\n        self.tokenizer.word_index = self.vocab\n        self.num_classes = len(self.vocab) + 1\n        self.model = reactionrnn_model(weights_path, self.num_classes)\n        self.model_enc = Model(inputs=self.model.input,\n                               outputs=self.model.get_layer('rnn').output)\n\n    def predict(self, texts, **kwargs):\n        texts_enc = reactionrnn_encode_sequences(texts, self.tokenizer)\n        predicts = self.model.predict(texts_enc, batch_size=1)\n        if len(texts_enc) == 1:\n            predicts_dict = {react: round(float(predicts[0][i]), 4)\n                             for i, react in enumerate(self.REACTIONS)}\n            predicts_dict = OrderedDict(sorted(predicts_dict.items(),\n                                               key=lambda t: -t[1]))\n            return predicts_dict\n        return predicts\n\n    def predict_label(self, texts, **kwargs):\n        texts_enc = reactionrnn_encode_sequences(texts, self.tokenizer)\n        predicts = self.model.predict(texts_enc, batch_size=1)\n        return list(np.array(self.REACTIONS)[np.argmax(predicts, axis=1)])\n\n    def encode(self, texts, **kwargs):\n        text_enc = reactionrnn_encode_sequences(texts, self.tokenizer)\n        predicts = self.model_enc.predict(text_enc)\n        return predicts\n\n\ndef reactionrnn_model(weights_path, num_classes, maxlen=140):\n    '''\n    Builds the model architecture for textgenrnn and\n    loads the pretrained weights for the model.\n    '''\n\n    input = Input(shape=(maxlen,), name='input')\n    embedded = Embedding(num_classes, 100, input_length=maxlen,\n                         name='embedding')(input)\n    rnn = GRU(256, return_sequences=False, name='rnn')(embedded)\n    output = Dense(5, name='output',\n                   activation=lambda x: K.relu(x) / K.sum(K.relu(x),\n                                                          axis=-1))(rnn)\n\n    model = Model(inputs=[input], outputs=[output])\n    model.load_weights(weights_path, by_name=True)\n    model.compile(loss='mse', optimizer='nadam')\n    return model\n\n\ndef reactionrnn_encode_sequences(texts, tokenizer, maxlen=140):\n    '''\n    Encodes text(s) into the corresponding encoding(s) for prediction(s) with\n    the model.\n    '''\n\n    texts = texts if isinstance(texts, list) else [texts]\n    texts_enc = tokenizer.texts_to_sequences(texts)\n    texts_enc = sequence.pad_sequences(texts_enc, maxlen=maxlen)\n    return texts_enc\n"""
