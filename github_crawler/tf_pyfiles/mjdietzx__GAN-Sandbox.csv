file_path,api_count,code
gan.py,0,"b'""""""\nStandard GAN implemented on top of keras/tensorflow.\n\n""""""\n\nimport os\nimport pickle\nimport sys\n\nfrom keras import applications\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.preprocessing import image\nimport numpy as np\nfrom PIL import Image\n\nfrom dlutils import plot_image_batch_w_labels\n\n\n#\n# directory paths\n#\n\npath = os.path.dirname(os.path.abspath(__file__))\ncache_dir = os.path.join(path, \'cache\')\n\n#\n# generator input params\n#\n\nrand_dim = 64  # dimension of generator\'s input tensor (gaussian noise)\n\n#\n# image dimensions\n#\n\nimg_height = 28\nimg_width = 28\nimg_channels = 3\n\n#\n# training params\n#\n\nnb_steps = 10000\nbatch_size = 64\nk_d = 1  # number of discriminator network updates per adversarial training step\nk_g = 1  # number of generative network updates per adversarial training step\n\n#\n# logging params\n#\n\nlog_interval = 100  # interval (in steps) at which to log loss summaries and save plots of image samples to disc\nfixed_noise = np.random.normal(size=(batch_size, rand_dim))  # fixed noise to generate batches of generated images\n\n#\n# shared network params\n#\n\nkernel_size = 4\nconv_layer_keyword_args = {\'strides\': 2, \'padding\': \'same\'}\n\n\n#\n# generator and discriminator architecture from: https://github.com/buriburisuri/ac-gan\n#\n\ndef generator_network(x):\n    def add_common_layers(y):\n        y = layers.advanced_activations.LeakyReLU()(y)\n        y = layers.Dropout(0.25)(y)\n        return y\n\n    x = layers.Dense(1024)(x)\n    x = add_common_layers(x)\n\n    #\n    # input dimensions to the first de-conv layer in the generator\n    #\n\n    height_dim = 7\n    width_dim = 7\n    assert img_height % height_dim == 0 and img_width % width_dim == 0, \\\n        \'Generator network must be able to transform `x` into a tensor of shape (img_height, img_width, img_channels).\'\n\n    x = layers.Dense(height_dim * width_dim * 128)(x)\n    x = add_common_layers(x)\n\n    x = layers.Reshape((height_dim, width_dim, -1))(x)\n\n    x = layers.Conv2DTranspose(64, kernel_size, **conv_layer_keyword_args)(x)\n    x = add_common_layers(x)\n\n    # number of feature maps => number of image channels\n    return layers.Conv2DTranspose(img_channels, 1, strides=2, padding=\'same\', activation=\'tanh\')(x)\n\n\ndef discriminator_network(x):\n    def add_common_layers(y):\n        y = layers.advanced_activations.LeakyReLU()(y)\n        y = layers.Dropout(0.25)(y)\n        return y\n\n    x = layers.GaussianNoise(stddev=0.2)(x)\n\n    x = layers.Conv2D(64, kernel_size, **conv_layer_keyword_args)(x)\n    x = add_common_layers(x)\n\n    x = layers.Conv2D(128, kernel_size, **conv_layer_keyword_args)(x)\n    x = add_common_layers(x)\n\n    x = layers.Flatten()(x)\n\n    x = layers.Dense(1024)(x)\n    x = add_common_layers(x)\n\n    return layers.Dense(1, activation=\'sigmoid\')(x)\n\n\ndef adversarial_training(data_dir, generator_model_path, discriminator_model_path):\n    """"""\n    Adversarial training of the generator network G\xce\xb8 and discriminator network D\xcf\x86.\n\n    """"""\n    #\n    # define model input and output tensors\n    #\n\n    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n    generated_image_tensor = generator_network(generator_input_tensor)\n\n    generated_or_real_image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n    discriminator_output = discriminator_network(generated_or_real_image_tensor)\n\n    #\n    # define models\n    #\n\n    generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor],\n                                   name=\'generator\')\n    discriminator_model = models.Model(inputs=[generated_or_real_image_tensor], outputs=[discriminator_output],\n                                       name=\'discriminator\')\n\n    combined_output = discriminator_model(generator_model(generator_input_tensor))\n    combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name=\'combined\')\n\n    #\n    # compile models\n    #\n\n    adam = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)  # as described in appendix A of DeepMind\'s AC-GAN paper\n\n    generator_model.compile(optimizer=adam, loss=\'binary_crossentropy\')\n    discriminator_model.compile(optimizer=adam, loss=\'binary_crossentropy\')\n    discriminator_model.trainable = False\n    combined_model.compile(optimizer=adam, loss=\'binary_crossentropy\')\n\n    print(generator_model.summary())\n    print(discriminator_model.summary())\n    print(combined_model.summary())\n\n    #\n    # data generators\n    #\n\n    data_generator = image.ImageDataGenerator(\n        preprocessing_function=applications.xception.preprocess_input,\n        data_format=\'channels_last\',\n        rotation_range=180.0,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        zoom_range=0.1,\n        channel_shift_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True)\n\n    flow_from_directory_params = {\'target_size\': (img_height, img_width),\n                                  \'color_mode\': \'grayscale\' if img_channels == 1 else \'rgb\',\n                                  \'class_mode\': None,\n                                  \'batch_size\': batch_size}\n\n    real_image_generator = data_generator.flow_from_directory(\n        directory=data_dir,\n        **flow_from_directory_params\n    )\n\n    def get_image_batch():\n        img_batch = real_image_generator.next()\n\n        # keras generators may generate an incomplete batch for the last batch in an epoch of data\n        if len(img_batch) != batch_size:\n            img_batch = real_image_generator.next()\n\n        assert img_batch.shape == (batch_size, img_height, img_width, img_channels), img_batch.shape\n        return img_batch\n\n    combined_loss = np.empty(shape=1)\n    disc_loss_real = np.empty(shape=1)\n    disc_loss_generated = np.empty(shape=1)\n\n    if generator_model_path:\n        generator_model.load_weights(generator_model_path, by_name=True)\n    if discriminator_model_path:\n        discriminator_model.load_weights(discriminator_model_path, by_name=True)\n\n    for i in range(nb_steps):\n        print(\'Step: {} of {}.\'.format(i, nb_steps))\n\n        # train the discriminator\n        for _ in range(k_d):\n            # sample a mini-batch of noise (generator input)\n            z = np.random.normal(size=(batch_size, rand_dim))\n\n            # sample a mini-batch of real images\n            x = get_image_batch()\n\n            # generate a batch of images with the current generator\n            g_z = generator_model.predict(z)\n\n            # update \xcf\x86 by taking an SGD step on mini-batch loss LD(\xcf\x86)\n            disc_loss_real = np.append(disc_loss_real, discriminator_model.train_on_batch(x, np.random.uniform(\n                low=0.7, high=1.2, size=batch_size)))\n            disc_loss_generated = np.append(disc_loss_generated, discriminator_model.train_on_batch(g_z,\n                np.random.uniform(low=0.0, high=0.3, size=batch_size)))\n\n        # train the generator\n        for _ in range(k_g * 2):\n            z = np.random.normal(size=(batch_size, rand_dim))\n\n            # update \xce\xb8 by taking an SGD step on mini-batch loss LR(\xce\xb8)\n            combined_loss = np.append(combined_loss, combined_model.train_on_batch(z, np.random.uniform(\n                low=0.7, high=1.2, size=batch_size)))\n\n        if not i % log_interval and i != 0:\n            # plot batch of generated images w/ current generator\n            figure_name = \'generated_image_batch_step_{}.png\'.format(i)\n            print(\'Saving batch of generated images at adversarial step: {}.\'.format(i))\n\n            g_z = generator_model.predict(fixed_noise)\n            x = get_image_batch()\n\n            # save one generated image to disc\n            Image.fromarray(g_z[0], mode=\'RGB\').save(os.path.join(cache_dir, \'generated_image_step_{}.png\').format(i))\n            # save a batch of generated and real images to disc\n            plot_image_batch_w_labels.plot_batch(np.concatenate((g_z, x)), os.path.join(cache_dir, figure_name),\n                                                 label_batch=[\'generated\'] * batch_size + [\'real\'] * batch_size)\n\n            # log loss summary\n            print(\'Generator model loss: {}.\'.format(np.mean(combined_loss[-log_interval:], axis=0)))\n            print(\'Discriminator model loss real: {}.\'.format(np.mean(disc_loss_real[-log_interval:], axis=0)))\n            print(\'Discriminator model loss generated: {}.\'.format(np.mean(disc_loss_generated[-log_interval:], axis=0)))\n\n            # save model checkpoints\n            model_checkpoint_base_name = os.path.join(cache_dir, \'{}_model_weights_step_{}.h5\')\n            generator_model.save_weights(model_checkpoint_base_name.format(\'generator\', i))\n            discriminator_model.save_weights(model_checkpoint_base_name.format(\'discriminator\', i))\n\n            # write the losses to disc as a serialized dict\n            with open(os.path.join(cache_dir, \'losses.pickle\'), \'wb\') as handle:\n                pickle.dump({\'combined_loss\': combined_loss,\n                             \'disc_loss_real\': disc_loss_real,\n                             \'disc_loss_generated\': disc_loss_generated},\n                            handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n\ndef main(data_dir, generator_model_path, discriminator_model_path):\n    adversarial_training(data_dir, generator_model_path, discriminator_model_path)\n\n\nif __name__ == \'__main__\':\n    # Note: if pre-trained models are passed in we don\'t take the steps they\'ve been trained for into account\n    gen_model_path = sys.argv[2] if len(sys.argv) >= 3 else None\n    disc_model_path = sys.argv[3] if len(sys.argv) >= 4 else None\n\n    main(sys.argv[1], gen_model_path, disc_model_path)\n'"
setup.py,0,"b'import os\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n\ndef read(file_name):\n    with open(os.path.join(os.path.dirname(__file__), file_name), \'r\') as f:\n        return f.readlines()\n\nsetup(\n    name=\'GAN-Sandbox\',\n    version=\'0.0.0\',\n    description=\'Enabling rapid experimentation & research for generative adversarial networks (GANs).\',\n    # long_description=read(\'README.md\'),\n    url=\'https://github.com/wayaai/GAN-Sandbox.git\',\n    author=\'Michael Dietz\',\n    keywords=\'\',\n    packages=find_packages(exclude=[""tests.*"", ""tests""]))\n'"
