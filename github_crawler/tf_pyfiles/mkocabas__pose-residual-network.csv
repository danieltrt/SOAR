file_path,api_count,code
main.py,0,"b'import os\nimport keras\nfrom pycocotools.coco import  COCO\nfrom opt import Options\nfrom src.model import PRN, PRN_Seperate\nfrom src.utils import train_bbox_generator, val_bbox_generator\nfrom src.utils import get_anns\nfrom src.evaluate import Evaluation\n\n\nclass My_Callback(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        self.model.save(\'checkpoint/\'+option.exp + \'epoch_{}.h5\'.format(epoch))\n        print \'Epoch\', epoch+1, \'has been saved\'\n        Evaluation(self.model, option, coco_val)\n        print \'Epoch\', epoch+1, \'has been tested\'\n        return\n\n\ndef main(option):\n    if not os.path.exists(\'checkpoint/\'+option.exp):\n        os.makedirs(\'checkpoint/\'+option.exp)\n\n    model = PRN_Seperate(option.coeff*28,option.coeff*18, option.node_count)\n\n    adam_optimizer = keras.optimizers.Adam(lr=option.lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    model.compile(loss=\'binary_crossentropy\', optimizer=adam_optimizer)\n    Own_callback = My_Callback()\n\n\n    model.fit_generator(generator=train_bbox_generator(coco_train, option.batch_size, option.coeff*28,option.coeff*18,option.threshold),\n                        steps_per_epoch=len(get_anns(coco_train)) // option.batch_size,\n                        validation_data=val_bbox_generator(coco_val, option.batch_size,option.coeff*28,option.coeff*18, option.threshold),\n                        validation_steps=len(coco_val.getAnnIds()) // option.batch_size,\n                        epochs=option.number_of_epoch,\n                        callbacks=[Own_callback],\n                        verbose=1,\n                        initial_epoch=0)\n\n\nif __name__ == ""__main__"":\n    option = Options().parse()\n    coco_train = COCO(os.path.join(\'data/annotations/person_keypoints_train2017.json\'))\n    coco_val = COCO(os.path.join(\'data/annotations/person_keypoints_val2017.json\'))\n    main(option)\n'"
opt.py,0,"b'import argparse\nfrom pprint import pprint\n\n\nclass Options:\n    def __init__(self):\n        self.parser = argparse.ArgumentParser()\n        self.opt = None\n\n    def _initial(self):\n\n        # --------------------------  General Training Options\n        self.parser.add_argument(\'--lr\', type=float, default=0.0001, help=\'Learning Rate\')\n        self.parser.add_argument(\'--number_of_epoch\', type=int, default=16, help=\'Epoch\')\n        self.parser.add_argument(\'--batch_size\', type=int, default=8, help=\'Batch Size\')\n        self.parser.add_argument(\'--node_count\', type=int, default=1024, help=\'Hidden Layer Node Count\')\n        # --------------------------  General Training Options\n\n        self.parser.add_argument(\'--exp\', type=str, default=\'test/\', help=\'Experiment name\')\n\n        # --------------------------\n        self.parser.add_argument(\'--coeff\', type=int, default=2, help=\'Coefficient of bbox size\')\n        self.parser.add_argument(\'--threshold\', type=int, default=0.21, help=\'BBOX threshold\')\n        self.parser.add_argument(\'--window_size\', type=int, default=15, help=\'Windows size for cropping\')\n        # --------------------------\n\n    def _print(self):\n        print(""\\n==================Options================="")\n        pprint(vars(self.opt), indent=4)\n        print(""==========================================\\n"")\n\n    def parse(self):\n        self._initial()\n        self.opt = self.parser.parse_args()\n        self._print()\n        return self.opt\n'"
src/__init__.py,0,"b'import os\nimport sys\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""progress""))'"
src/evaluate.py,0,"b""import os\nimport math\nimport json\nimport numpy as np\nfrom tqdm import tqdm\nfrom random import shuffle\n\nfrom pycocotools.cocoeval import COCOeval\nfrom gaussian import gaussian, crop, gaussian_multi_input_mp\n\ndef Evaluation(model,optin,coco):\n    print ('------------Evaulation Started------------')\n    coeff = optin.coeff\n    in_thres = optin.threshold\n    n_kernel = optin.window_size\n    modelname = 'temporary'\n\n    cocodir = 'data/annotations/person_keypoints_val2017.json'\n    ann = json.load(open(cocodir))\n    bbox_results = ann['annotations']\n\n    img_ids = coco.getImgIds(catIds=[1])\n\n    peak_results = []\n\n    for i in img_ids:\n        anns = coco.loadAnns(coco.getAnnIds(imgIds=i))\n        kps = [a['keypoints'] for a in anns]\n\n        idx = 0\n\n        ks = []\n        for i in range(17):\n            t = []\n            for k in kps:\n                x = k[0::3][i]\n                y = k[1::3][i]\n                v = k[2::3][i]\n\n                if v > 0:\n                    t.append([x, y, 1, idx])\n                    idx += 1\n            ks.append(t)\n        image_id = anns[0]['image_id']\n        peaks = ks\n\n        element = {\n            'image_id': image_id,\n            'peaks': peaks,\n            'file_name': coco.loadImgs(image_id)[0]['file_name']\n        }\n\n        peak_results.append(element)\n\n    shuffle(peak_results)\n\n    my_results = []\n    image_ids = []\n\n    w = int(18 * coeff)\n    h = int(28 * coeff)\n\n    temporary_peak_res = []\n    for p in peak_results:\n        if (sum(1 for i in p['peaks'] if i != []) >= 0):\n            temporary_peak_res.append(p)\n    peak_results = temporary_peak_res\n\n    for p in tqdm(peak_results):\n        idx = p['image_id']\n        image_ids.append(idx)\n\n        peaks = p['peaks']\n        bboxes = [k['bbox'] for k in bbox_results if k['image_id'] == idx]\n\n\n        if len(bboxes) == 0 or len(peaks) == 0:\n            continue\n\n        weights_bbox = np.zeros((len(bboxes), h, w, 4, 17))\n\n        for joint_id, peak in enumerate(peaks):\n\n\n            for instance_id, instance in enumerate(peak):\n\n                p_x = instance[0]\n                p_y = instance[1]\n\n                for bbox_id, b in enumerate(bboxes):\n\n                    is_inside = p_x > b[0] - b[2] * in_thres and \\\n                                p_y > b[1] - b[3] * in_thres and \\\n                                p_x < b[0] + b[2] * (1.0 + in_thres) and \\\n                                p_y < b[1] + b[3] * (1.0 + in_thres)\n\n                    if is_inside:\n                        x_scale = float(w) / math.ceil(b[2])\n                        y_scale = float(h) / math.ceil(b[3])\n\n                        x0 = int((p_x - b[0]) * x_scale)\n                        y0 = int((p_y - b[1]) * y_scale)\n\n                        if x0 >= w and y0 >= h:\n                            x0 = w - 1\n                            y0 = h - 1\n                        elif x0 >= w:\n                            x0 = w - 1\n                        elif y0 >= h:\n                            y0 = h - 1\n                        elif x0 < 0 and y0 < 0:\n                            x0 = 0\n                            y0 = 0\n                        elif x0 < 0:\n                            x0 = 0\n                        elif y0 < 0:\n                            y0 = 0\n\n                        p = 1e-9\n\n                        weights_bbox[bbox_id, y0, x0, :, joint_id] = [1, instance[2], instance[3], p]\n\n        old_weights_bbox = np.copy(weights_bbox)\n\n        for j in range(weights_bbox.shape[0]):\n            for t in range(17):\n                weights_bbox[j, :, :, 0, t] = gaussian(weights_bbox[j, :, :, 0, t])\n            # weights_bbox[j, :, :, 0, :]      = gaussian_multi_input_mp(weights_bbox[j, :, :, 0, :])\n\n        output_bbox = []\n        for j in range(weights_bbox.shape[0]):\n            inp = weights_bbox[j, :, :, 0, :]\n            output = model.predict(np.expand_dims(inp, axis=0))\n            output_bbox.append(output[0])\n\n        output_bbox = np.array(output_bbox)\n\n        keypoints_score = []\n\n        for t in range(17):\n            indexes = np.argwhere(old_weights_bbox[:, :, :, 0, t] == 1)\n            keypoint = []\n            for i in indexes:\n                cr = crop(output_bbox[i[0], :, :, t], (i[1], i[2]), N=n_kernel)\n                score = np.sum(cr)\n\n                kp_id = old_weights_bbox[i[0], i[1], i[2], 2, t]\n                kp_score = old_weights_bbox[i[0], i[1], i[2], 1, t]\n                p_score = old_weights_bbox[i[0], i[1], i[2], 3, t]  ## ??\n                bbox_id = i[0]\n\n                score = kp_score * score\n\n                s = [kp_id, bbox_id, kp_score, score]\n\n                keypoint.append(s)\n            keypoints_score.append(keypoint)\n\n        bbox_keypoints = np.zeros((weights_bbox.shape[0], 17, 3))\n        bbox_ids = np.arange(len(bboxes)).tolist()\n\n        # kp_id, bbox_id, kp_score, my_score\n        for i in range(17):\n            joint_keypoints = keypoints_score[i]\n            if len(joint_keypoints) > 0:\n\n                kp_ids = list(set([x[0] for x in joint_keypoints]))\n\n                table = np.zeros((len(bbox_ids), len(kp_ids), 4))\n\n                for b_id, bbox in enumerate(bbox_ids):\n                    for k_id, kp in enumerate(kp_ids):\n                        own = [x for x in joint_keypoints if x[0] == kp and x[1] == bbox]\n\n                        if len(own) > 0:\n                            table[bbox, k_id] = own[0]\n                        else:\n                            table[bbox, k_id] = [0] * 4\n\n                for b_id, bbox in enumerate(bbox_ids):\n\n                    row = np.argsort(-table[bbox, :, 3])\n\n                    if table[bbox, row[0], 3] > 0:\n                        for r in row:\n                            if table[bbox, r, 3] > 0:\n                                column = np.argsort(-table[:, r, 3])\n\n                                if bbox == column[0]:\n                                    bbox_keypoints[bbox, i, :] = [x[:3] for x in peaks[i] if x[3] == table[bbox, r, 0]][0]\n                                    break\n                                else:\n                                    row2 = np.argsort(table[column[0], :, 3])\n                                    if row2[0] == r:\n                                        bbox_keypoints[bbox, i, :] = \\\n                                        [x[:3] for x in peaks[i] if x[3] == table[bbox, r, 0]][0]\n                                        break\n            else:\n                for j in range(weights_bbox.shape[0]):\n                    b = bboxes[j]\n                    x_scale = float(w) / math.ceil(b[2])\n                    y_scale = float(h) / math.ceil(b[3])\n\n                    for t in range(17):\n                        indexes = np.argwhere(old_weights_bbox[j, :, :, 0, t] == 1)\n                        if len(indexes) == 0:\n                            max_index = np.argwhere(output_bbox[j, :, :, t] == np.max(output_bbox[j, :, :, t]))\n                            bbox_keypoints[j, t, :] = [max_index[0][1] / x_scale + b[0],\n                                                       max_index[0][0] / y_scale + b[1], 0]\n\n        my_keypoints = []\n\n        for i in range(bbox_keypoints.shape[0]):\n            k = np.zeros(51)\n            k[0::3] = bbox_keypoints[i, :, 0]\n            k[1::3] = bbox_keypoints[i, :, 1]\n            k[2::3] = [2] * 17\n\n            pose_score = 0\n            count = 0\n            for f in range(17):\n                if bbox_keypoints[i, f, 0] != 0 and bbox_keypoints[i, f, 1] != 0:\n                    count += 1\n                pose_score += bbox_keypoints[i, f, 2]\n            pose_score /= 17.0\n\n            my_keypoints.append(k)\n\n            image_data = {\n                'image_id': idx,\n                'bbox': bboxes[i],\n                'score': pose_score,\n                'category_id': 1,\n                'keypoints': k.tolist()\n            }\n            my_results.append(image_data)\n\n\n    ann_filename = 'data/val2017_PRN_keypoint_results_{}.json'.format(modelname)\n    # write output\n    json.dump(my_results, open(ann_filename, 'w'), indent=4)\n\n    # load results in COCO evaluation tool\n    coco_pred = coco.loadRes(ann_filename)\n\n    # run COCO evaluation\n    coco_eval = COCOeval(coco, coco_pred, 'keypoints')\n    coco_eval.params.imgIds = image_ids\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n    os.remove(ann_filename)\n"""
src/gaussian.py,0,"b""import numpy as np\nfrom skimage.filters import gaussian\n\nsigmas = np.array([.26, .25, .25, .35, .35, .79, .79, .72, .72, .62, .62, 1.07, 1.07, .87, .87, .89, .89])\n\n\ndef multivariate_gaussian(N, sigma=2):\n    t = 4\n    X = np.linspace(-t, t, N)\n    Y = np.linspace(-t, t, N)\n    X, Y = np.meshgrid(X, Y)\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n    mu = np.array([0., 0.])\n    sigma = np.array([[sigma, 0], [0, sigma]])\n    n = mu.shape[0]\n    Sigma_det = np.linalg.det(sigma)\n    Sigma_inv = np.linalg.inv(sigma)\n    N = np.sqrt((2 * np.pi) ** n * Sigma_det)\n    fac = np.einsum('...k,kl,...l->...', pos - mu, Sigma_inv, pos - mu)\n    return np.exp(-fac / 2) / N\n\n\ndef crop_paste(img, c, N=13, sigma=2):\n    Z = multivariate_gaussian(N, sigma)\n\n    H = img.shape[1]\n    W = img.shape[0]\n\n    h = (Z.shape[0] - 1) / 2\n\n    N = Z.shape[0]\n    x1 = (c[0] - h)\n    y1 = (c[1] - h)\n\n    x2 = (c[0] + h) + 1\n    y2 = (c[1] + h) + 1\n\n    zx1 = 0\n    zy1 = 0\n    zx2 = N + 1\n    zy2 = N + 1\n\n    if x1 < 0:\n        x1 = 0\n        zx1 = 0 - (c[0] - h)\n\n    if y1 < 0:\n        y1 = 0\n        zy1 = 0 - (c[1] - h)\n\n    if x2 > W - 1:\n        x2 = W - 1\n        zx2 = x2 - x1 + 1\n        x2 = W\n\n    if y2 > H - 1:\n        y2 = H - 1\n        zy2 = y2 - y1 + 1\n        y2 = H\n\n    img[x1:x2, y1:y2] = np.maximum(Z[zx1:zx2, zy1:zy2], img[x1:x2, y1:y2])\n\n\n'''\ndef gaussian(img, N = 13, sigma=2):\n    cs = np.where(img==1)\n    img = np.zeros_like(img)\n    for c in zip(cs[0], cs[1]):\n        crop_paste(img, c, N, sigma)\n    return img\n'''\n\n\ndef gaussian_multi_input_mp(inp):\n    '''\n    :param inp: Multi person ground truth heatmap input (17 ch) Each channel contains multiple joints.\n    :return: out: Gaussian augmented output. Values are between 0. and 1.\n    '''\n\n    h, w, ch = inp.shape\n    out = np.zeros_like(inp)\n    for i in range(ch):\n        layer = inp[:, :, i]\n        ind = np.argwhere(layer == 1)\n        b = []\n        if len(ind) > 0:\n            for j in ind:\n                t = np.zeros((h, w))\n                t[j[0], j[1]] = 1\n                t = gaussian(t, sigma=sigmas[i], mode='constant')\n                t = t * (1 / t.max())\n                b.append(t)\n\n            out[:, :, i] = np.maximum.reduce(b)\n        else:\n            out[:, :, i] = np.zeros((h, w))\n    return out\n\n\ndef gaussian_multi_output(inp):\n    '''\n    :param inp: Single person ground truth heatmap input (17 ch) Each channel contains one joint.\n    :return: out: Gaussian augmented output. Values are between 0. and 1.\n    '''\n    h, w, ch = inp.shape\n    out = np.zeros_like(inp)\n    for i in range(ch):\n        j = np.argwhere(inp[:, :, i] == 1)\n        if len(j) == 0:\n            out[:, :, i] = np.zeros((h, w))\n            continue\n        j = j[0]\n        t = np.zeros((h, w))\n        t[j[0], j[1]] = 1\n        t = gaussian(t, sigma=sigmas[i], mode='constant')\n        out[:, :, i] = t * (1 / t.max())\n    return out\n\n\ndef crop(img, c, N=13):\n    H = img.shape[1]\n    W = img.shape[0]\n\n    h = (N - 1) / 2\n\n    x1 = (c[0] - h)\n    y1 = (c[1] - h)\n\n    x2 = (c[0] + h) + 1\n    y2 = (c[1] + h) + 1\n\n    if x1 < 0:\n        x1 = 0\n\n    if y1 < 0:\n        y1 = 0\n\n    if x2 > W - 1:\n        x2 = W\n\n    if y2 > H - 1:\n        y2 = H\n\n    return img[x1:x2, y1:y2]"""
src/model.py,0,"b""import keras\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Flatten, Reshape, Dropout, Activation\n\ndef PRN(height, width, node_count):\n    input = Input(shape=(height, width, 17))\n    y = Flatten()(input)\n    x = Dense(node_count, activation='relu')(y)\n    x = Dropout(0.5)(x)\n    x = Dense(width * height * 17, activation='relu')(x)\n    x = keras.layers.Add()([x, y])\n    x = keras.layers.Activation('softmax')(x)\n    x = Reshape((height, width, 17))(x)\n    model = Model(inputs=input, outputs=x)\n    print model.summary()\n    return model\n\n\ndef PRN_Seperate(height, width, node_count):\n    input = Input(shape=(height, width, 17))\n    y = Flatten()(input)\n    x = Dense(node_count, activation='relu')(y)\n    x = Dropout(0.5)(x)\n    x = Dense(width * height * 17, activation='relu')(x)\n    x = keras.layers.Add()([x, y])\n    out = []\n    start = 0\n    end = width * height\n\n    for i in range(17):\n        o = keras.layers.Lambda(lambda x: x[:, start:end])(x)\n        o = Activation('softmax')(o)\n        out.append(o)\n        start = end\n        end = start + width * height\n\n    x = keras.layers.Concatenate()(out)\n    x = Reshape((height, width, 17))(x)\n    model = Model(inputs=input, outputs=x)\n    print model.summary()\n    return model"""
src/utils.py,0,"b""import math\nimport numpy as np\nfrom gaussian import gaussian, gaussian_multi_input_mp, gaussian_multi_output\nfrom random import shuffle\n\n\ndef get_data(ann_data, coco, height, width,thres):\n    weights = np.zeros((height, width, 17))\n    output = np.zeros((height, width, 17))\n\n\n    bbox = ann_data['bbox']\n    x = int(bbox[0])\n    y = int(bbox[1])\n    w = float(bbox[2])\n    h = float(bbox[3])\n\n    x_scale = float(width) / math.ceil(w)\n    y_scale = float(height) / math.ceil(h)\n\n    kpx = ann_data['keypoints'][0::3]\n    kpy = ann_data['keypoints'][1::3]\n    kpv = ann_data['keypoints'][2::3]\n\n    for j in range(17):\n        if kpv[j] > 0:\n            x0 = int((kpx[j] - x) * x_scale)\n            y0 = int((kpy[j] - y) * y_scale)\n\n            if x0 >= width and y0 >= height:\n                output[height - 1, width - 1, j] = 1\n            elif x0 >= width:\n                output[y0, width - 1, j] = 1\n            elif y0 >= height:\n                output[height - 1, x0, j] = 1\n            elif x0 < 0 and y0 < 0:\n                output[0, 0, j] = 1\n            elif x0 < 0:\n                output[y0, 0, j] = 1\n            elif y0 < 0:\n                output[0, x0, j] = 1\n            else:\n                output[y0, x0, j] = 1\n\n    img_id = ann_data['image_id']\n    img_data = coco.loadImgs(img_id)[0]\n    ann_data = coco.loadAnns(coco.getAnnIds(img_data['id']))\n\n    for ann in ann_data:\n        kpx = ann['keypoints'][0::3]\n        kpy = ann['keypoints'][1::3]\n        kpv = ann['keypoints'][2::3]\n\n        for j in range(17):\n            if kpv[j] > 0:\n                if (kpx[j] > bbox[0] - bbox[2] * thres and kpx[j] < bbox[0] + bbox[2] * (1 + thres)):\n                    if (kpy[j] > bbox[1] - bbox[3] * thres and kpy[j] < bbox[1] + bbox[3] * (1 + thres)):\n                        x0 = int((kpx[j] - x) * x_scale)\n                        y0 = int((kpy[j] - y) * y_scale)\n\n                        if x0 >= width and y0 >= height:\n                            weights[height - 1, width - 1, j] = 1\n                        elif x0 >= width:\n                            weights[y0, width - 1, j] = 1\n                        elif y0 >= height:\n                            weights[height - 1, x0, j] = 1\n                        elif x0 < 0 and y0 < 0:\n                            weights[0, 0, j] = 1\n                        elif x0 < 0:\n                            weights[y0, 0, j] = 1\n                        elif y0 < 0:\n                            weights[0, x0, j] = 1\n                        else:\n                            weights[y0, x0, j] = 1\n\n    for t in range(17):\n        weights[:, :, t] = gaussian(weights[:, :, t])\n    output  =  gaussian(output, sigma=2, mode='constant', multichannel=True)\n    #weights = gaussian_multi_input_mp(weights)\n    return weights, output\n\n\ndef get_anns(coco):\n    '''\n    :param coco: COCO instance\n    :return: anns: List of annotations that contain person with at least 6 keypoints\n    '''\n    ann_ids = coco.getAnnIds()\n    anns = []\n    for i in ann_ids:\n        ann = coco.loadAnns(i)[0]\n        if ann['iscrowd'] == 0 and ann['num_keypoints'] > 4:\n            anns.append(ann) # ann\n    sorted_list = sorted(anns, key=lambda k: k['num_keypoints'], reverse=True)\n    return sorted_list\n\n\ndef train_bbox_generator(coco_train,batch_size,height,width,thres):\n    anns = get_anns(coco_train)\n    while 1:\n        shuffle(anns)\n        for i in range(0, len(anns) // batch_size, batch_size):\n            X = np.zeros((batch_size, height, width, 17))\n            Y = np.zeros((batch_size, height, width, 17))\n            for j in range(batch_size):\n                ann_data = anns[i+j]\n                try:\n                    x, y = get_data(ann_data, coco_train, height, width, thres)\n                except:\n                    continue\n                X[j, :, :, :] = x\n                Y[j, :, :, :] = y\n            yield X, Y\n\n\n\n\ndef val_bbox_generator(coco_val, batch_size,height,width,thres):\n    ann_ids = coco_val.getAnnIds()\n    while 1:\n        shuffle(ann_ids)\n        for i in range(len(ann_ids) // batch_size):\n            X = np.zeros((batch_size, height, width, 17))\n            Y = np.zeros((batch_size, height, width, 17))\n            for j in range(batch_size):\n                ann_data = coco_val.loadAnns(ann_ids[i + j])[0]\n                try:\n                    x, y = get_data(ann_data, coco_val,height,width,thres)\n                except:\n                    continue\n                X[j, :, :, :] = x\n                Y[j, :, :, :] = y\n            yield X, Y\n"""
