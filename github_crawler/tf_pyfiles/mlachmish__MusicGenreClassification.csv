file_path,api_count,code
mel-spec/code/formatInput.py,0,"b'#!/usr/bin/python\n\nfrom __future__ import print_function\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tsne import bh_sne\nimport pickle\nimport sys\nimport os\nfrom numpy import array\n\ndef die_with_usage():\n    """""" HELP MENU """"""\n    print (\'USAGE: python visuallizePreproccess.py [path to MSD pp data]\')\n    sys.exit(0)\n\ndef update_progress(progress):\n    print (\'\\r[{0}] {1}%\'.format(\'#\' * (progress / 10), progress))\n\nlabelsDict = {\n    \'blues\'     :   0,\n    \'classical\' :   1,\n    \'country\'   :   2,\n    \'disco\'     :   3,\n    \'hiphop\'    :   4,\n    \'jazz\'      :   5,\n    \'metal\'     :   6,\n    \'pop\'       :   7,\n    \'reggae\'    :   8,\n    \'rock\'      :   9,\n}\n\nif __name__ == ""__main__"":\n\n    # help menu\n    if len(sys.argv) < 2:\n        die_with_usage()\n\n    #Load Data\n    data = {}\n    labels = []\n\n    i = 0.0\n    walk_dir = sys.argv[1]\n    print(\'walk_dir = \' + walk_dir)\n\n    for root, subdirs, files in os.walk(walk_dir):\n        for filename in files:\n            if filename.endswith(\'pp\'):\n                file_path = os.path.join(root, filename)\n                # print(\'\\t- file %s (full path: %s)\' % (filename, file_path))\n\n                with open(file_path, \'r\') as f:\n                    try:\n                        soundId = os.path.splitext(filename)[0]\n                        content = f.read()\n                        pp = pickle.loads(content)\n                        pp = np.asarray(pp)\n                        # pp = np.delete(pp, 1, axis=2)\n                        data[soundId] = pp\n\n                        labelName = filename.split(\'.\')[0]\n                        labelAsArray = [0] * len(labelsDict)\n                        labelAsArray[labelsDict[labelName]] = 1\n                        labels.append(labelAsArray)\n                    except Exception as e:\n                        print (""Error occurred"" + str(e))\n\n            if filename.endswith(\'pp\'):\n                sys.stdout.write(""\\r%d%%"" % int(i / 1000 * 100))\n                sys.stdout.flush()\n                i += 1\n\n    #save data and lables\n    with open(""data"", \'w\') as f:\n        f.write(pickle.dumps(data.values()))\n\n    with open(""labels"", \'w\') as f:\n        f.write(pickle.dumps(array(labels)))\n\n    # print sizes\n    print(""Data set size: "" + str(len(data.keys())))\n    print(""Number of genres: "" + str(len(labelsDict.keys())))\n\n    # convert image data to float64 matrix. float64 is need for bh_sne\n    reshapedList = array(data.values())\n    x_data = np.asarray(reshapedList).astype(\'float64\')\n    x_data = x_data.reshape((x_data.shape[0], -1))\n\n    # perform t-SNE embedding\n    vis_data = bh_sne(x_data, perplexity=30)\n\n    # plot the result\n    vis_x = vis_data[:, 0]\n    vis_y = vis_data[:, 1]\n\n    colors = []\n    for label in labels:\n        colors.append(label.index(1))\n\n    plt.scatter(vis_x, vis_y, c=colors, cmap=plt.cm.get_cmap(""jet"", 10))\n    plt.colorbar(ticks=range(10), label=\'Genres\')\n    plt.clim(-0.5, 9.5)\n    plt.title(\'t-SNE mel-spectrogram samples as genres\')\n    plt.show()'"
mel-spec/code/preproccess.py,0,"b'#!/usr/bin/python\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport numpy as np\nimport pickle\nimport sys\nimport os\n\nimport librosa\n\nSOUND_SAMPLE_LENGTH = 30000\n\nHAMMING_SIZE = 100\nHAMMING_STRIDE = 40\n\n\ndef die_with_usage():\n    """""" HELP MENU """"""\n    print \'USAGE: python preproccess.py [path to MSD mp3 data]\'\n    sys.exit(0)\n\n\ndef update_progress(progress):\n    print \'\\r[{0}] {1}%\'.format(\'#\' * (progress / 10), progress)\n\n\ndef rreplace(s, old, new, occurrence):\n    li = s.rsplit(old, occurrence)\n    return new.join(li)\n\n\ndef prepossessingAudio(audioPath, ppFilePath):\n    print \'Prepossessing \' + audioPath\n\n    featuresArray = []\n    for i in range(0, SOUND_SAMPLE_LENGTH, HAMMING_STRIDE):\n        if i + HAMMING_SIZE <= SOUND_SAMPLE_LENGTH - 1:\n            y, sr = librosa.load(audioPath, offset=i / 1000.0, duration=HAMMING_SIZE / 1000.0)\n\n            # Let\'s make and display a mel-scaled power (energy-squared) spectrogram\n            S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n\n            # Convert to log scale (dB). We\'ll use the peak power as reference.\n            log_S = librosa.logamplitude(S, ref_power=np.max)\n\n            mfcc = librosa.feature.mfcc(S=log_S, sr=sr, n_mfcc=13)\n            # featuresArray.append(mfcc)\n\n            featuresArray.append(S)\n\n            if len(featuresArray) == 599:\n                break\n\n    print \'storing pp file: \' + ppFilePath\n\n    f = open(ppFilePath, \'w\')\n    f.write(pickle.dumps(featuresArray))\n    f.close()\n\n\nif __name__ == ""__main__"":\n\n    # help menu\n    if len(sys.argv) < 2:\n        die_with_usage()\n\n    i = 0.0\n    walk_dir = sys.argv[1]\n\n    print(\'walk_dir = \' + walk_dir)\n\n    for root, subdirs, files in os.walk(walk_dir):\n        for filename in files:\n            if filename.endswith(\'.au\'):\n                file_path = os.path.join(root, filename)\n                # print(\'\\t- file %s (full path: %s)\' % (filename, file_path))\n                ppFileName = rreplace(file_path, "".au"", "".pp"", 1)\n\n                # if os.path.isfile(ppFileName):  # Skip if pp file already exist\n                #     continue\n\n                try:\n                    prepossessingAudio(file_path, ppFileName)\n                except Exception as e:\n                    print ""Error accured"" + str(e)\n\n            if filename.endswith(\'au\'):\n                sys.stdout.write(""\\r%d%%"" % int(i / 7620 * 100))\n                sys.stdout.flush()\n                i += 1\n'"
mel-spec/code/train.py,30,"b'#!/usr/bin/python\n\nfrom __future__ import print_function\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport tensorflow as tf\nimport numpy as np\nimport pickle\n\ndef getBatch(data, labels, batchSize, iteration):\n    startOfBatch = (iteration * batchSize) % len(data)\n    endOfBacth = (iteration * batchSize + batchSize) % len(data)\n\n    if startOfBatch < endOfBacth:\n        return data[startOfBatch:endOfBacth], labels[startOfBatch:endOfBacth]\n    else:\n        dataBatch = np.vstack((data[startOfBatch:],data[:endOfBacth]))\n        labelsBatch = np.vstack((labels[startOfBatch:],labels[:endOfBacth]))\n\n        return dataBatch, labelsBatch\n\n\nif __name__ == ""__main__"":\n\n    # Parameters\n    learning_rate = 0.001\n    training_iters = 100000\n    batch_size = 64\n    display_step = 1\n    train_size = 800\n\n    # Network Parameters\n    # n_input = 599 * 128\n    n_input = 599 * 128*2\n    n_classes = 10\n    dropout = 0.75  # Dropout, probability to keep units\n\n    # Load data\n    data = []\n    with open(""data"", \'r\') as f:\n        content = f.read()\n        data = pickle.loads(content)\n    data = np.asarray(data)\n    data = data\n    data = data.reshape((data.shape[0], n_input))\n\n    labels = []\n    with open(""labels"", \'r\') as f:\n        content = f.read()\n        labels = pickle.loads(content)\n\n    # #Hack\n    # data = np.random.random((1000, n_input))\n    # labels = np.random.random((1000, 10))\n\n    # Shuffle data\n    permutation = np.random.permutation(len(data))\n    data = data[permutation]\n    labels = labels[permutation]\n\n    # Split Train/Test\n    trainData = data[:train_size]\n    trainLabels = labels[:train_size]\n\n    testData = data[train_size:]\n    testLabels = labels[train_size:]\n\n\n    # tf Graph input\n    x = tf.placeholder(tf.float32, [None, n_input])\n    y = tf.placeholder(tf.float32, [None, n_classes])\n    keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n\n\n    # Create model\n    def conv2d(sound, w, b):\n        return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(sound, w, strides=[1, 1, 1, 1],\n                                                      padding=\'SAME\'), b))\n\n\n    def max_pool(sound, k):\n        return tf.nn.max_pool(sound, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=\'SAME\')\n\n\n    def conv_net(_X, _weights, _biases, _dropout):\n        # Reshape input picture\n        _X = tf.reshape(_X, shape=[-1, 599, 128, 2])\n\n        # Convolution Layer\n        conv1 = conv2d(_X, _weights[\'wc1\'], _biases[\'bc1\'])\n        # Max Pooling (down-sampling)\n        conv1 = max_pool(conv1, k=4)\n        # Apply Dropout\n        conv1 = tf.nn.dropout(conv1, _dropout)\n\n        # Convolution Layer\n        conv2 = conv2d(conv1, _weights[\'wc2\'], _biases[\'bc2\'])\n        # Max Pooling (down-sampling)\n        conv2 = max_pool(conv2, k=2)\n        # Apply Dropout\n        conv2 = tf.nn.dropout(conv2, _dropout)\n\n        # Convolution Layer\n        conv3 = conv2d(conv2, _weights[\'wc3\'], _biases[\'bc3\'])\n        # Max Pooling (down-sampling)\n        conv3 = max_pool(conv3, k=2)\n        # Apply Dropout\n        conv3 = tf.nn.dropout(conv3, _dropout)\n\n        # Fully connected layer\n        # Reshape conv3 output to fit dense layer input\n        dense1 = tf.reshape(conv3, [-1, _weights[\'wd1\'].get_shape().as_list()[0]])\n        # Relu activation\n        dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, _weights[\'wd1\']), _biases[\'bd1\']))\n        # Apply Dropout\n        dense1 = tf.nn.dropout(dense1, _dropout)  # Apply Dropout\n\n        # Output, class prediction\n        out = tf.add(tf.matmul(dense1, _weights[\'out\']), _biases[\'out\'])\n        return out\n\n\n    # Store layers weight & bias\n    weights = {\n        # 4x4 conv, 1 input, 149 outputs\n        \'wc1\': tf.Variable(tf.random_normal([4, 4, 2, 149])),\n        # 4x4 conv, 149 inputs, 73 outputs\n        \'wc2\': tf.Variable(tf.random_normal([4, 4, 149, 73])),\n        # 4x4 conv, 73 inputs, 35 outputs\n        \'wc3\': tf.Variable(tf.random_normal([4, 4, 73, 35])),\n        # fully connected, 38*8*35 inputs, 2^13 outputs\n        \'wd1\': tf.Variable(tf.random_normal([38 * 8 * 35, 8192])),\n        # 2^13 inputs, 13 outputs (class prediction)\n        \'out\': tf.Variable(tf.random_normal([8192, n_classes]))\n    }\n\n    biases = {\n        \'bc1\': tf.Variable(tf.random_normal([149])+0.01),\n        \'bc2\': tf.Variable(tf.random_normal([73])+0.01),\n        \'bc3\': tf.Variable(tf.random_normal([35])+0.01),\n        \'bd1\': tf.Variable(tf.random_normal([8192])+0.01),\n        \'out\': tf.Variable(tf.random_normal([n_classes])+0.01)\n    }\n\n    # Construct model\n    pred = conv_net(x, weights, biases, keep_prob)\n\n    # Define loss and optimizer\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n    # Evaluate model\n    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    # Initializing the variables\n    init = tf.initialize_all_variables()\n\n    # Add ops to save and restore all the variables.\n    saver = tf.train.Saver()\n\n    # Launch the graph\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n        sess.run(init)\n        step = 1\n        # Keep training until reach max iterations\n        while step * batch_size < training_iters:\n            batch_xs, batch_ys = getBatch(trainData, trainLabels, batch_size, step)\n            # Fit training using batch data\n            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n\n            if step % display_step == 0:\n                # Calculate batch accuracy\n                acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n                # Calculate batch loss\n                loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n                print(""Iter "" + str(step * batch_size) + "", Minibatch Loss= "" + \\\n                      ""{:.6f}"".format(loss) + "", Training Accuracy= "" + ""{:.5f}"".format(acc))\n\n                save_path = saver.save(sess, ""model.ckpt"")\n                print(""Model saved in file: %s"" % save_path)\n            step += 1\n        print(""Optimization Finished!"")\n\n        save_path = saver.save(sess, ""model.final"")\n        print(""Model saved in file: %s"" % save_path)\n\n        # Calculate accuracy\n        print(""Testing Accuracy:"", sess.run(accuracy, feed_dict={x: testData,\n                                                                 y: testLabels,\n                                                                 keep_prob: 1.}))\n'"
mfcc/code/formatInput.py,0,"b'#!/usr/bin/python\n\nfrom __future__ import print_function\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tsne import bh_sne\nimport pickle\nimport sys\nimport os\nfrom numpy import array\n\ndef die_with_usage():\n    """""" HELP MENU """"""\n    print (\'USAGE: python visuallizePreproccess.py [path to MSD pp data]\')\n    sys.exit(0)\n\ndef update_progress(progress):\n    print (\'\\r[{0}] {1}%\'.format(\'#\' * (progress / 10), progress))\n\nlabelsDict = {\n    \'blues\'     :   0,\n    \'classical\' :   1,\n    \'country\'   :   2,\n    \'disco\'     :   3,\n    \'hiphop\'    :   4,\n    \'jazz\'      :   5,\n    \'metal\'     :   6,\n    \'pop\'       :   7,\n    \'reggae\'    :   8,\n    \'rock\'      :   9,\n}\n\nif __name__ == ""__main__"":\n\n    # help menu\n    if len(sys.argv) < 2:\n        die_with_usage()\n\n    #Load Data\n    data = {}\n    labels = []\n\n    i = 0.0\n    walk_dir = sys.argv[1]\n    print(\'walk_dir = \' + walk_dir)\n\n    for root, subdirs, files in os.walk(walk_dir):\n        for filename in files:\n            if filename.endswith(\'pp\'):\n                file_path = os.path.join(root, filename)\n                # print(\'\\t- file %s (full path: %s)\' % (filename, file_path))\n\n                with open(file_path, \'r\') as f:\n                    try:\n                        soundId = os.path.splitext(filename)[0]\n                        content = f.read()\n                        pp = pickle.loads(content)\n                        pp = np.asarray(pp)\n                        # pp = np.delete(pp, 1, axis=2)\n                        data[soundId] = pp\n\n                        labelName = filename.split(\'.\')[0]\n                        labelAsArray = [0] * len(labelsDict)\n                        labelAsArray[labelsDict[labelName]] = 1\n                        labels.append(labelAsArray)\n                    except Exception as e:\n                        print (""Error occurred"" + str(e))\n\n            if filename.endswith(\'pp\'):\n                sys.stdout.write(""\\r%d%%"" % int(i / 1000 * 100))\n                sys.stdout.flush()\n                i += 1\n\n    #save data and lables\n    with open(""data"", \'w\') as f:\n        f.write(pickle.dumps(data.values()))\n\n    with open(""labels"", \'w\') as f:\n        f.write(pickle.dumps(array(labels)))\n\n    # print sizes\n    print(""Data set size: "" + str(len(data.keys())))\n    print(""Number of genres: "" + str(len(labelsDict.keys())))\n\n    # convert image data to float64 matrix. float64 is need for bh_sne\n    reshapedList = array(data.values())\n    x_data = np.asarray(reshapedList).astype(\'float64\')\n    x_data = x_data.reshape((x_data.shape[0], -1))\n\n    # perform t-SNE embedding\n    vis_data = bh_sne(x_data, perplexity=30)\n\n    # plot the result\n    vis_x = vis_data[:, 0]\n    vis_y = vis_data[:, 1]\n\n    colors = []\n    for label in labels:\n        colors.append(label.index(1))\n\n    plt.scatter(vis_x, vis_y, c=colors, cmap=plt.cm.get_cmap(""jet"", 10))\n    plt.colorbar(ticks=range(10), label=\'Genres\')\n    plt.clim(-0.5, 9.5)\n    plt.title(\'t-SNE MFCC samples as genres\')\n    plt.show()'"
mfcc/code/preproccess.py,0,"b'#!/usr/bin/python\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport numpy as np\nimport pickle\nimport sys\nimport os\n\nimport librosa\n\nSOUND_SAMPLE_LENGTH = 30000\n\nHAMMING_SIZE = 100\nHAMMING_STRIDE = 40\n\n\ndef die_with_usage():\n    """""" HELP MENU """"""\n    print \'USAGE: python preproccess.py [path to MSD mp3 data]\'\n    sys.exit(0)\n\n\ndef update_progress(progress):\n    print \'\\r[{0}] {1}%\'.format(\'#\' * (progress / 10), progress)\n\n\ndef rreplace(s, old, new, occurrence):\n    li = s.rsplit(old, occurrence)\n    return new.join(li)\n\n\ndef prepossessingAudio(audioPath, ppFilePath):\n    print \'Prepossessing \' + audioPath\n\n    featuresArray = []\n    for i in range(0, SOUND_SAMPLE_LENGTH, HAMMING_STRIDE):\n        if i + HAMMING_SIZE <= SOUND_SAMPLE_LENGTH - 1:\n            y, sr = librosa.load(audioPath, offset=i / 1000.0, duration=HAMMING_SIZE / 1000.0)\n\n            # Let\'s make and display a mel-scaled power (energy-squared) spectrogram\n            S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n\n            # Convert to log scale (dB). We\'ll use the peak power as reference.\n            log_S = librosa.logamplitude(S, ref_power=np.max)\n\n            mfcc = librosa.feature.mfcc(S=log_S, sr=sr, n_mfcc=13)\n            featuresArray.append(mfcc)\n\n            # featuresArray.append(S)\n\n            if len(featuresArray) == 599:\n                break\n\n    print \'storing pp file: \' + ppFilePath\n\n    f = open(ppFilePath, \'w\')\n    f.write(pickle.dumps(featuresArray))\n    f.close()\n\n\nif __name__ == ""__main__"":\n\n    # help menu\n    if len(sys.argv) < 2:\n        die_with_usage()\n\n    i = 0.0\n    walk_dir = sys.argv[1]\n\n    print(\'walk_dir = \' + walk_dir)\n\n    for root, subdirs, files in os.walk(walk_dir):\n        for filename in files:\n            if filename.endswith(\'.au\'):\n                file_path = os.path.join(root, filename)\n                # print(\'\\t- file %s (full path: %s)\' % (filename, file_path))\n                ppFileName = rreplace(file_path, "".au"", "".pp"", 1)\n\n                # if os.path.isfile(ppFileName):  # Skip if pp file already exist\n                #     continue\n\n                try:\n                    prepossessingAudio(file_path, ppFileName)\n                except Exception as e:\n                    print ""Error accured"" + str(e)\n\n            if filename.endswith(\'au\'):\n                sys.stdout.write(""\\r%d%%"" % int(i / 7620 * 100))\n                sys.stdout.flush()\n                i += 1\n'"
mfcc/code/train.py,30,"b'#!/usr/bin/python\n\nfrom __future__ import print_function\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport tensorflow as tf\nimport numpy as np\nimport pickle\n\ndef getBatch(data, labels, batchSize, iteration):\n    startOfBatch = (iteration * batchSize) % len(data)\n    endOfBacth = (iteration * batchSize + batchSize) % len(data)\n\n    if startOfBatch < endOfBacth:\n        return data[startOfBatch:endOfBacth], labels[startOfBatch:endOfBacth]\n    else:\n        dataBatch = np.vstack((data[startOfBatch:],data[:endOfBacth]))\n        labelsBatch = np.vstack((labels[startOfBatch:],labels[:endOfBacth]))\n\n        return dataBatch, labelsBatch\n\n\nif __name__ == ""__main__"":\n\n    # Parameters\n    learning_rate = 0.001\n    training_iters = 100000\n    batch_size = 64\n    display_step = 1\n    train_size = 800\n\n    # Network Parameters\n    # n_input = 599 * 128*2\n    n_input = 599 * 13 * 5\n    n_classes = 10\n    dropout = 0.75  # Dropout, probability to keep units\n\n    # Load data\n    data = []\n    with open(""data"", \'r\') as f:\n        content = f.read()\n        data = pickle.loads(content)\n    data = np.asarray(data)\n    data = data\n    data = data.reshape((data.shape[0], n_input))\n\n    labels = []\n    with open(""labels"", \'r\') as f:\n        content = f.read()\n        labels = pickle.loads(content)\n\n    # #Hack\n    # data = np.random.random((1000, n_input))\n    # labels = np.random.random((1000, 10))\n\n    # Shuffle data\n    permutation = np.random.permutation(len(data))\n    data = data[permutation]\n    labels = labels[permutation]\n\n    # Split Train/Test\n    trainData = data[:train_size]\n    trainLabels = labels[:train_size]\n\n    testData = data[train_size:]\n    testLabels = labels[train_size:]\n\n\n    # tf Graph input\n    x = tf.placeholder(tf.float32, [None, n_input])\n    y = tf.placeholder(tf.float32, [None, n_classes])\n    keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n\n\n    # Create model\n    def conv2d(sound, w, b):\n        return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(sound, w, strides=[1, 1, 1, 1],\n                                                      padding=\'SAME\'), b))\n\n\n    def max_pool(sound, k):\n        return tf.nn.max_pool(sound, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=\'SAME\')\n\n\n    def conv_net(_X, _weights, _biases, _dropout):\n        # Reshape input picture\n        _X = tf.reshape(_X, shape=[-1, 599, 13, 5])\n\n        # Convolution Layer\n        conv1 = conv2d(_X, _weights[\'wc1\'], _biases[\'bc1\'])\n        # Max Pooling (down-sampling)\n        conv1 = max_pool(conv1, k=4)\n        # Apply Dropout\n        conv1 = tf.nn.dropout(conv1, _dropout)\n\n        # Convolution Layer\n        conv2 = conv2d(conv1, _weights[\'wc2\'], _biases[\'bc2\'])\n        # Max Pooling (down-sampling)\n        conv2 = max_pool(conv2, k=2)\n        # Apply Dropout\n        conv2 = tf.nn.dropout(conv2, _dropout)\n        #\n        # # Convolution Layer\n        # conv3 = conv2d(conv2, _weights[\'wc3\'], _biases[\'bc3\'])\n        # # Max Pooling (down-sampling)\n        # conv3 = max_pool(conv3, k=2)\n        # # Apply Dropout\n        # conv3 = tf.nn.dropout(conv3, _dropout)\n\n        # Fully connected layer\n        # Reshape conv3 output to fit dense layer input\n        dense1 = tf.reshape(conv2, [-1, _weights[\'wd1\'].get_shape().as_list()[0]])\n        # Relu activation\n        dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, _weights[\'wd1\']), _biases[\'bd1\']))\n        # Apply Dropout\n        dense1 = tf.nn.dropout(dense1, _dropout)  # Apply Dropout\n\n        # Output, class prediction\n        out = tf.add(tf.matmul(dense1, _weights[\'out\']), _biases[\'out\'])\n        return out\n\n\n    # Store layers weight & bias\n    weights = {\n        # 4x4 conv, 1 input, 149 outputs\n        \'wc1\': tf.Variable(tf.random_normal([4, 4, 5, 149])),\n        # 4x4 conv, 149 inputs, 73 outputs\n        \'wc2\': tf.Variable(tf.random_normal([4, 4, 149, 73])),\n        # 4x4 conv, 73 inputs, 35 outputs\n        \'wc3\': tf.Variable(tf.random_normal([2, 2, 73, 35])),\n        # fully connected, 38*8*35 inputs, 2^13 outputs\n        \'wd1\': tf.Variable(tf.random_normal([75 * 2 * 73, 1024])),\n        # 2^13 inputs, 13 outputs (class prediction)\n        \'out\': tf.Variable(tf.random_normal([1024, n_classes]))\n    }\n\n    biases = {\n        \'bc1\': tf.Variable(tf.random_normal([149])),\n        \'bc2\': tf.Variable(tf.random_normal([73])),\n        \'bc3\': tf.Variable(tf.random_normal([35])),\n        \'bd1\': tf.Variable(tf.random_normal([1024])),\n        \'out\': tf.Variable(tf.random_normal([n_classes]))\n    }\n\n    # Construct model\n    pred = conv_net(x, weights, biases, keep_prob)\n\n    # Define loss and optimizer\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n    # Evaluate model\n    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    # Initializing the variables\n    init = tf.initialize_all_variables()\n\n    # Add ops to save and restore all the variables.\n    saver = tf.train.Saver()\n\n    # Launch the graph\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n        sess.run(init)\n        step = 1\n        # Keep training until reach max iterations\n        while step * batch_size < training_iters:\n            batch_xs, batch_ys = getBatch(trainData, trainLabels, batch_size, step)\n            # Fit training using batch data\n            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n\n            if step % display_step == 0:\n                # Calculate batch accuracy\n                acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n                # Calculate batch loss\n                loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n                print(""Iter "" + str(step * batch_size) + "", Minibatch Loss= "" + \\\n                      ""{:.6f}"".format(loss) + "", Training Accuracy= "" + ""{:.5f}"".format(acc))\n\n                save_path = saver.save(sess, ""model.ckpt"")\n                print(""Model saved in file: %s"" % save_path)\n            step += 1\n        print(""Optimization Finished!"")\n\n        save_path = saver.save(sess, ""model.final"")\n        print(""Model saved in file: %s"" % save_path)\n\n        # Calculate accuracy\n        print(""Testing Accuracy:"", sess.run(accuracy, feed_dict={x: testData,\n                                                                 y: testLabels,\n                                                                 keep_prob: 1.}))\n'"
mel-spec/code/lib/__init__.py,0,b''
mel-spec/code/lib/api_settings.py,0,"b""''' your local settings.\n    Note that if you install using setuptools, change this\n    module first before running setup.py install.\n'''\noauthkey = '7dkss6x9fn5v'\nsecret = 't5f28uhdmct7zhdr'\ncountry = 'US'\n"""
mel-spec/code/lib/hdf5_getters.py,0,"b'""""""\nThierry Bertin-Mahieux (2010) Columbia University\ntb2332@columbia.edu\nThis code contains a set of getters functions to access the fields\nfrom an HDF5 song file (regular file with one song or\naggregate / summary file with many songs)\nThis is part of the Million Song Dataset project from\nLabROSA (Columbia University) and The Echo Nest.\nCopyright 2010, Thierry Bertin-Mahieux\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\n\nimport tables\n\n\ndef open_h5_file_read(h5filename):\n    """"""\n    Open an existing H5 in read mode.\n    Same function as in hdf5_utils, here so we avoid one import\n    """"""\n    return tables.open_file(h5filename, mode=\'r\')\n\n\ndef get_num_songs(h5):\n    """"""\n    Return the number of songs contained in this h5 file, i.e. the number of rows\n    for all basic informations like name, artist, ...\n    """"""\n    return h5.root.metadata.songs.nrows\n\ndef get_artist_familiarity(h5,songidx=0):\n    """"""\n    Get artist familiarity from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_familiarity[songidx]\n\ndef get_artist_hotttnesss(h5,songidx=0):\n    """"""\n    Get artist hotttnesss from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_hotttnesss[songidx]\n\ndef get_artist_id(h5,songidx=0):\n    """"""\n    Get artist id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_id[songidx]\n\ndef get_artist_mbid(h5,songidx=0):\n    """"""\n    Get artist musibrainz id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_mbid[songidx]\n\ndef get_artist_playmeid(h5,songidx=0):\n    """"""\n    Get artist playme id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_playmeid[songidx]\n\ndef get_artist_7digitalid(h5,songidx=0):\n    """"""\n    Get artist 7digital id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_7digitalid[songidx]\n\ndef get_artist_latitude(h5,songidx=0):\n    """"""\n    Get artist latitude from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_latitude[songidx]\n\ndef get_artist_longitude(h5,songidx=0):\n    """"""\n    Get artist longitude from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_longitude[songidx]\n\ndef get_artist_location(h5,songidx=0):\n    """"""\n    Get artist location from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_location[songidx]\n\ndef get_artist_name(h5,songidx=0):\n    """"""\n    Get artist name from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_name[songidx]\n\ndef get_release(h5,songidx=0):\n    """"""\n    Get release from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.release[songidx]\n\ndef get_release_7digitalid(h5,songidx=0):\n    """"""\n    Get release 7digital id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.release_7digitalid[songidx]\n\ndef get_song_id(h5,songidx=0):\n    """"""\n    Get song id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.song_id[songidx]\n\ndef get_song_hotttnesss(h5,songidx=0):\n    """"""\n    Get song hotttnesss from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.song_hotttnesss[songidx]\n\ndef get_title(h5,songidx=0):\n    """"""\n    Get title from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.title[songidx]\n\ndef get_track_7digitalid(h5,songidx=0):\n    """"""\n    Get track 7digital id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.track_7digitalid[songidx]\n\ndef get_similar_artists(h5,songidx=0):\n    """"""\n    Get similar artists array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:]\n    return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:\n                                            h5.root.metadata.songs.cols.idx_similar_artists[songidx+1]]\n\ndef get_artist_terms(h5,songidx=0):\n    """"""\n    Get artist terms array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n    return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n                                            h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n\ndef get_artist_terms_freq(h5,songidx=0):\n    """"""\n    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n    return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n                                              h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n\ndef get_artist_terms_weight(h5,songidx=0):\n    """"""\n    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n    return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n                                                h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n\ndef get_analysis_sample_rate(h5,songidx=0):\n    """"""\n    Get analysis sample rate from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.analysis_sample_rate[songidx]\n\ndef get_audio_md5(h5,songidx=0):\n    """"""\n    Get audio MD5 from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.audio_md5[songidx]\n\ndef get_danceability(h5,songidx=0):\n    """"""\n    Get danceability from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.danceability[songidx]\n\ndef get_duration(h5,songidx=0):\n    """"""\n    Get duration from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.duration[songidx]\n\ndef get_end_of_fade_in(h5,songidx=0):\n    """"""\n    Get end of fade in from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.end_of_fade_in[songidx]\n\ndef get_energy(h5,songidx=0):\n    """"""\n    Get energy from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.energy[songidx]\n\ndef get_key(h5,songidx=0):\n    """"""\n    Get key from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.key[songidx]\n\ndef get_key_confidence(h5,songidx=0):\n    """"""\n    Get key confidence from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.key_confidence[songidx]\n\ndef get_loudness(h5,songidx=0):\n    """"""\n    Get loudness from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.loudness[songidx]\n\ndef get_mode(h5,songidx=0):\n    """"""\n    Get mode from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.mode[songidx]\n\ndef get_mode_confidence(h5,songidx=0):\n    """"""\n    Get mode confidence from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.mode_confidence[songidx]\n\ndef get_start_of_fade_out(h5,songidx=0):\n    """"""\n    Get start of fade out from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.start_of_fade_out[songidx]\n\ndef get_tempo(h5,songidx=0):\n    """"""\n    Get tempo from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.tempo[songidx]\n\ndef get_time_signature(h5,songidx=0):\n    """"""\n    Get signature from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.time_signature[songidx]\n\ndef get_time_signature_confidence(h5,songidx=0):\n    """"""\n    Get signature confidence from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.time_signature_confidence[songidx]\n\ndef get_track_id(h5,songidx=0):\n    """"""\n    Get track id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.track_id[songidx]\n\ndef get_segments_start(h5,songidx=0):\n    """"""\n    Get segments start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:]\n    return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:\n                                           h5.root.analysis.songs.cols.idx_segments_start[songidx+1]]\n\ndef get_segments_confidence(h5,songidx=0):\n    """"""\n    Get segments confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:]\n    return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:\n                                                h5.root.analysis.songs.cols.idx_segments_confidence[songidx+1]]\n\ndef get_segments_pitches(h5,songidx=0):\n    """"""\n    Get segments pitches array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:,:]\n    return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:\n                                             h5.root.analysis.songs.cols.idx_segments_pitches[songidx+1],:]\n\ndef get_segments_timbre(h5,songidx=0):\n    """"""\n    Get segments timbre array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:,:]\n    return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:\n                                            h5.root.analysis.songs.cols.idx_segments_timbre[songidx+1],:]\n\ndef get_segments_loudness_max(h5,songidx=0):\n    """"""\n    Get segments loudness max array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:]\n    return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:\n                                                  h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx+1]]\n\ndef get_segments_loudness_max_time(h5,songidx=0):\n    """"""\n    Get segments loudness max time array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:]\n    return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:\n                                                       h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx+1]]\n\ndef get_segments_loudness_start(h5,songidx=0):\n    """"""\n    Get segments loudness start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:]\n    return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:\n                                                    h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx+1]]\n\ndef get_sections_start(h5,songidx=0):\n    """"""\n    Get sections start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:]\n    return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:\n                                           h5.root.analysis.songs.cols.idx_sections_start[songidx+1]]\n\ndef get_sections_confidence(h5,songidx=0):\n    """"""\n    Get sections confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:]\n    return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:\n                                                h5.root.analysis.songs.cols.idx_sections_confidence[songidx+1]]\n\ndef get_beats_start(h5,songidx=0):\n    """"""\n    Get beats start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:]\n    return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:\n                                        h5.root.analysis.songs.cols.idx_beats_start[songidx+1]]\n\ndef get_beats_confidence(h5,songidx=0):\n    """"""\n    Get beats confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:]\n    return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:\n                                             h5.root.analysis.songs.cols.idx_beats_confidence[songidx+1]]\n\ndef get_bars_start(h5,songidx=0):\n    """"""\n    Get bars start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:]\n    return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:\n                                       h5.root.analysis.songs.cols.idx_bars_start[songidx+1]]\n\ndef get_bars_confidence(h5,songidx=0):\n    """"""\n    Get bars start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:]\n    return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:\n                                            h5.root.analysis.songs.cols.idx_bars_confidence[songidx+1]]\n\ndef get_tatums_start(h5,songidx=0):\n    """"""\n    Get tatums start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:]\n    return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:\n                                         h5.root.analysis.songs.cols.idx_tatums_start[songidx+1]]\n\ndef get_tatums_confidence(h5,songidx=0):\n    """"""\n    Get tatums confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:]\n    return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:\n                                              h5.root.analysis.songs.cols.idx_tatums_confidence[songidx+1]]\n\ndef get_artist_mbtags(h5,songidx=0):\n    """"""\n    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n\ndef get_artist_mbtags_count(h5,songidx=0):\n    """"""\n    Get artist musicbrainz tag count array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n        return h5.root.musicbrainz.artist_mbtags_count[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n    return h5.root.musicbrainz.artist_mbtags_count[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n                                                   h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n\ndef get_year(h5,songidx=0):\n    """"""\n    Get release year from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.musicbrainz.songs.cols.year[songidx]'"
mel-spec/code/lib/oauth7digital.py,0,"b'import httplib\nimport re\nimport sys\n\nimport api_settings\nimport oauth2 as oauth\n\nSERVER = \'api.7digital.com\'\nAPI_VERSION = \'1.2\'\nREQUEST_TOKEN_URL = \'https://%s/%s/oauth/requesttoken\' % (SERVER, API_VERSION)\nACCESS_TOKEN_URL = \'https://%s/%s/oauth/accesstoken\' % (SERVER, API_VERSION)\nAUTHORIZATION_URL = \'https://account.7digital.com/%s/oauth/authorise\'\n\n\ndef _consumer():\n    return oauth.Consumer(api_settings.oauthkey, api_settings.secret)\n\n\ndef _token_from_response_content(content):\n\n    try:\n        key = re.search(\n            ""<oauth_token>(\\w.+)</oauth_token>"",\n            content).groups()[0]\n        secret = re.search(\n            ""<oauth_token_secret>(\\w.+)</oauth_token_secret>"",\n            content).groups()[0]\n    except AttributeError, e:\n        return ""Error processing response from 7digital: (%s) [AttributeError: %s]"" % (content, e)\n\n    return oauth.Token(key, secret)\n\n\ndef request_2legged(url, http_method=""GET""):\n    client = oauth.Client(_consumer())\n    response, content = client.request(\n        url,\n        headers = {""Content-Type"":""application/x-www-form-urlencoded""},\n        body=""country=%s"" % api_settings.country,\n        method = http_method\n    )\n    return response, content\n\n\ndef request_token():\n    response, content = request_2legged(REQUEST_TOKEN_URL)\n\n    if response[\'status\'] == \'200\':\n        return _token_from_response_content(content)\n\n    return response, content\n\n\ndef authorize_request_token(token, debug=False):\n    keyed_auth_url = AUTHORIZATION_URL % api_settings.oauthkey\n    auth_url=""%s?oauth_token=%s"" % (keyed_auth_url, token.key)\n\n    if debug:\n        print \'Authorization URL: %s\' % auth_url\n        oauth_verifier = raw_input(\n            \'Please go to the above URL and authorize the app. \\\n            Hit return when you have been authorized: \'\n        )\n\n    return auth_url\n\n\ndef request_access_token(token):\n    client = oauth.Client(_consumer(), token=token)\n    response, content = client.request(\n            ACCESS_TOKEN_URL,\n            headers={""Content-Type"":""application/x-www-form-urlencoded""}\n    )\n\n    return _token_from_response_content(content)\n\n\ndef request_3legged(url, access_token, http_method=""GET"", body=\'\'):\n    \'\'\' Once you have an access_token authorized by a customer,\n        execute a request on their behalf\n    \'\'\'\n    client = oauth.Client(_consumer(), token=access_token)\n    response = client.request(\n            url,\n            headers={""Content-Type"":""application/x-www-form-urlencoded""},\n            method=http_method,\n            body=body\n    )\n\n    return response\n\ndef signed_request(url, access_token=None):\n    \'\'\' return a signed request. Usually not used, save for specific\n        functions like deriving a preview-clip URL.\n    \'\'\'\n    consumer = _consumer()\n\n    req = oauth.Request.from_consumer_and_token(\n                consumer,\n                http_url=url,\n                is_form_encoded=True,\n                parameters={\'country\':api_settings.country})\n\n    signing_method = oauth.SignatureMethod_HMAC_SHA1()\n    req.sign_request(signing_method, consumer, access_token)\n\n    return req\n'"
mel-spec/code/lib/previewDownloader.py,0,"b'#!/usr/bin/python\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport sys\nimport os\nimport urllib\nimport py7D\nimport hdf5_getters\n\ndef die_with_usage():\n    """""" HELP MENU """"""\n    print \'USAGE: python previewDownloader.py [path to MSD data]\'\n    sys.exit(0)\n\ndef update_progress(progress):\n    print \'\\r[{0}] {1}%\'.format(\'#\' * (progress / 10), progress)\n\n# def download\n\nif __name__ == ""__main__"":\n    # help menu\n    if len(sys.argv) < 2:\n        die_with_usage()\n\n    msdPath = sys.argv[1]\n    i = 0.0\n    for folder in os.listdir(msdPath):\n        insidePath = msdPath+\'/\'+folder\n        if (os.path.isdir(insidePath)):\n            for folder2 in os.listdir(insidePath):\n                insidePath2 = insidePath + \'/\' + folder2\n                if (os.path.isdir(insidePath2)):\n                    for file in os.listdir(insidePath2):\n                        previewFilePath = insidePath2 + \'/\' + os.path.splitext(file)[0] + \'.mp3\'\n                        print previewFilePath\n                        if file.endswith(\'h5\') and not os.path.isfile(previewFilePath):\n                            h5FilePath = insidePath2+\'/\'+file\n                            # print \'Processing \' + h5FilePath\n\n                            try:\n                                h5 = hdf5_getters.open_h5_file_read(h5FilePath)\n                                id7Digital = hdf5_getters.get_track_7digitalid(h5)\n                                h5.close()\n\n                                url = py7D.preview_url(id7Digital)\n                                urlretrieve = urllib.urlretrieve(url, previewFilePath)\n                            except Exception as e:\n                                print ""Error accured: "" + str(e)\n\n                        if file.endswith(\'h5\'):\n                            # update_progress(int(i/7620 * 100))\n                            sys.stdout.write(""\\r%d%%"" % int(i/7620 * 100))\n                            sys.stdout.flush()\n                            i += 1'"
mel-spec/code/lib/py7D.py,0,"b'import httplib2\nimport os\nimport urllib\nimport re\nimport urlparse\nimport xmltodict\nimport collections\n\nimport oauth7digital as oa7D\nimport api_settings\n\n__name__ = \'py7D\'\n__doc__ = \'A lightweight python interface to 7Digital web service\'\n__author__ = \'Jason Rubenstein\'\n__version__ = \'0.2\'\n__maintainer__ = \'Jason Rubenstein\'\n__email__ = \'jasondrubenstein@gmail.com\'\n__status__ = \'Beta\'\n\nSERVER = \'api.7digital.com\'\nAPI_VERSION = \'1.2\'\nAPI_URL = \'https://%s/%s\' % (SERVER, API_VERSION)\nCLIP_URL = \'http://previews.7digital.com/clip/%s?\' % (\n                                                ""%s"")\n\nclass APIServiceException(Exception):\n    pass\n\n\nclass APIClientException(Exception):\n    pass\n\n\ndef _assemble_url(host, method, function, oauth, **kwargs):\n    data = []\n\n    for k,v in kwargs.iteritems():\n        if isinstance(v, (int, float, long)):\n            kwargs[k] = str(v)\n\n    quote = lambda _param_name: urllib.quote_plus(\n                        _param_name.replace(\'&amp;\', \'&\').encode(\'utf8\')\n    )\n\n    for name in kwargs.keys():\n        data.append(\'=\'.join((name, quote(kwargs[name]))))\n\n    data = \'&\'.join(data)\n\n    url = os.path.join(host, method)\n    if function:\n        url = os.path.join(url, function)\n\n    if not oauth:\n        url = ""%s%s"" % (url, \'?oauth_consumer_key=%s&country=%s\' % (\n                                                        api_settings.oauthkey,\n                                                        api_settings.country)\n                       )\n    if data:\n        url += ""&%s"" % data\n\n    return url\n\n\ndef _execute(method, function, access_token=None, **kwargs):\n\n    \'\'\' This common execution function is overloaded to\n        handle standard requests, 2-legged oauth requests, and\n        3-legged oauth requests.\n    \'\'\'\n    dc = kwargs.pop(\'dict_constructor\', None) or collections.OrderedDict\n    is_2legged = kwargs.pop(\'is_2legged\', False)\n    http_method = kwargs.pop(\'http_method\', ""GET"")\n    body = kwargs.pop(\'body\', \'\')\n\n    oauth = False\n    if access_token or is_2legged:\n        oauth = True\n\n    url = _assemble_url(API_URL, method, function, oauth, **kwargs)\n\n    # a request is one of 3legged oauth, a 2legged oauth, or standard\n    if access_token:\n        http_response, content = oa7D.request_3legged(url,\n                                                      access_token,\n                                                      http_method=http_method,\n                                                      body=body)\n        api_response = xmltodict.parse(\n            content, xml_attribs=True, dict_constructor=dc)\n    else:\n        if is_2legged is True:\n            http_response, content = oa7D.request_2legged(\n                                                    url,\n                                                    http_method=http_method)\n        else:\n            http_response, content = httplib2.Http().request(url)\n\n        api_response = xmltodict.parse(\n            content, xml_attribs=True, dict_constructor=dc)\n\n    if api_response[\'response\'][\'@status\'] == ""error"":\n        raise APIServiceException(\'Error code %s: %s\' % (\n                api_response[\'response\'][\'error\'][\'@code\'],\n                api_response[\'response\'][\'error\'][\'errorMessage\']\n                )\n        )\n\n    api_response[\'http_headers\'] = http_response\n    return api_response\n\n\ndef request(method, function, **kwargs):\n    \'\'\' Input:\n            method      : a valid 7Digital method\n            function    : a valid function for the method\n            Other kwargs specific to the API method/function\n\n        Output:\n            A python Ordered Dictionary of the results of the\n            API, converted from XML.\n    \'\'\'\n    if kwargs.get(\'access_token\'):\n        raise APIClientException(\n            ""Please use oauth_request() for calls containing access_token"")\n\n    return _execute(method, function, **kwargs)\n\n\ndef oauth_3legged_request(method, function, access_token, **kwargs):\n    \'\'\' Input:\n            method      : a valid 7Digital method for 3-legged oauth\n            function    : a valid function for the method\n            access_token: the access_token required for 3-legged oauth\n            Other kwargs specific to the API method/function\n\n        Output:\n            A python Ordered Dictionary of the results of the\n            API, converted from XML.\n    \'\'\'\n    if not access_token:\n        raise APIClientException(""access_token required for oauth request"")\n\n    return _execute(method, function, access_token, **kwargs)\n\n\ndef oauth_2legged_request(method, function, **kwargs):\n    \'\'\' Input:\n            method      : a valid 7Digital method; commonly \'oauth\'\n            function    : a valid function for the method\n            Other kwargs specific to the API method/function\n\n        Output:\n            A python Ordered Dictionary of the results of the\n            API, converted from XML.\n    \'\'\'\n    return _execute(method, function, is_2legged=True, **kwargs)\n\n\n\ndef preview_clip(track_id):\n    \'\'\' return a preview clip in mp3 format,\n        from the 7digital preview servers.\n\n        Input:\n            valid track_id\n\n        Output:\n            An mp3 (attachment) preview-clip for the requested track.\n    \'\'\'\n    response, content = oa7D.request_2legged(\n            CLIP_URL % (track_id)\n    )\n    return response, content\n\n\ndef preview_url(track_id):\n    \'\'\' return the URL for preview clip, from the 7digital preview servers.\n\n        Input:\n            valid track_id\n\n        Output:\n            The OAuth-signed URL for a preview clip. This URL can be used\n            to retrieve the mp3 preview-clip from 7digital.\n    \'\'\'\n    s_req = oa7D.signed_request(CLIP_URL % (track_id))\n    return s_req.to_url()\n'"
mfcc/code/lib/__init__.py,0,b''
mfcc/code/lib/api_settings.py,0,"b""''' your local settings.\n    Note that if you install using setuptools, change this\n    module first before running setup.py install.\n'''\noauthkey = '7dkss6x9fn5v'\nsecret = 't5f28uhdmct7zhdr'\ncountry = 'US'\n"""
mfcc/code/lib/hdf5_getters.py,0,"b'""""""\nThierry Bertin-Mahieux (2010) Columbia University\ntb2332@columbia.edu\n\n\nThis code contains a set of getters functions to access the fields\nfrom an HDF5 song file (regular file with one song or\naggregate / summary file with many songs)\n\nThis is part of the Million Song Dataset project from\nLabROSA (Columbia University) and The Echo Nest.\n\n\nCopyright 2010, Thierry Bertin-Mahieux\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\n\nimport tables\n\n\ndef open_h5_file_read(h5filename):\n    """"""\n    Open an existing H5 in read mode.\n    Same function as in hdf5_utils, here so we avoid one import\n    """"""\n    return tables.openFile(h5filename, mode=\'r\')\n\n\ndef get_num_songs(h5):\n    """"""\n    Return the number of songs contained in this h5 file, i.e. the number of rows\n    for all basic informations like name, artist, ...\n    """"""\n    return h5.root.metadata.songs.nrows\n\ndef get_artist_familiarity(h5,songidx=0):\n    """"""\n    Get artist familiarity from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_familiarity[songidx]\n\ndef get_artist_hotttnesss(h5,songidx=0):\n    """"""\n    Get artist hotttnesss from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_hotttnesss[songidx]\n\ndef get_artist_id(h5,songidx=0):\n    """"""\n    Get artist id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_id[songidx]\n\ndef get_artist_mbid(h5,songidx=0):\n    """"""\n    Get artist musibrainz id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_mbid[songidx]\n\ndef get_artist_playmeid(h5,songidx=0):\n    """"""\n    Get artist playme id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_playmeid[songidx]\n\ndef get_artist_7digitalid(h5,songidx=0):\n    """"""\n    Get artist 7digital id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_7digitalid[songidx]\n\ndef get_artist_latitude(h5,songidx=0):\n    """"""\n    Get artist latitude from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_latitude[songidx]\n\ndef get_artist_longitude(h5,songidx=0):\n    """"""\n    Get artist longitude from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_longitude[songidx]\n\ndef get_artist_location(h5,songidx=0):\n    """"""\n    Get artist location from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_location[songidx]\n\ndef get_artist_name(h5,songidx=0):\n    """"""\n    Get artist name from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.artist_name[songidx]\n\ndef get_release(h5,songidx=0):\n    """"""\n    Get release from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.release[songidx]\n\ndef get_release_7digitalid(h5,songidx=0):\n    """"""\n    Get release 7digital id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.release_7digitalid[songidx]\n\ndef get_song_id(h5,songidx=0):\n    """"""\n    Get song id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.song_id[songidx]\n\ndef get_song_hotttnesss(h5,songidx=0):\n    """"""\n    Get song hotttnesss from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.song_hotttnesss[songidx]\n\ndef get_title(h5,songidx=0):\n    """"""\n    Get title from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.title[songidx]\n\ndef get_track_7digitalid(h5,songidx=0):\n    """"""\n    Get track 7digital id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.metadata.songs.cols.track_7digitalid[songidx]\n\ndef get_similar_artists(h5,songidx=0):\n    """"""\n    Get similar artists array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:]\n    return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:\n                                            h5.root.metadata.songs.cols.idx_similar_artists[songidx+1]]\n\ndef get_artist_terms(h5,songidx=0):\n    """"""\n    Get artist terms array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n    return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n                                            h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n\ndef get_artist_terms_freq(h5,songidx=0):\n    """"""\n    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n    return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n                                              h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n\ndef get_artist_terms_weight(h5,songidx=0):\n    """"""\n    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.metadata.songs.nrows == songidx + 1:\n        return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n    return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n                                                h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n\ndef get_analysis_sample_rate(h5,songidx=0):\n    """"""\n    Get analysis sample rate from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.analysis_sample_rate[songidx]\n\ndef get_audio_md5(h5,songidx=0):\n    """"""\n    Get audio MD5 from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.audio_md5[songidx]\n\ndef get_danceability(h5,songidx=0):\n    """"""\n    Get danceability from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.danceability[songidx]\n\ndef get_duration(h5,songidx=0):\n    """"""\n    Get duration from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.duration[songidx]\n\ndef get_end_of_fade_in(h5,songidx=0):\n    """"""\n    Get end of fade in from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.end_of_fade_in[songidx]\n\ndef get_energy(h5,songidx=0):\n    """"""\n    Get energy from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.energy[songidx]\n\ndef get_key(h5,songidx=0):\n    """"""\n    Get key from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.key[songidx]\n\ndef get_key_confidence(h5,songidx=0):\n    """"""\n    Get key confidence from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.key_confidence[songidx]\n\ndef get_loudness(h5,songidx=0):\n    """"""\n    Get loudness from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.loudness[songidx]\n\ndef get_mode(h5,songidx=0):\n    """"""\n    Get mode from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.mode[songidx]\n\ndef get_mode_confidence(h5,songidx=0):\n    """"""\n    Get mode confidence from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.mode_confidence[songidx]\n\ndef get_start_of_fade_out(h5,songidx=0):\n    """"""\n    Get start of fade out from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.start_of_fade_out[songidx]\n\ndef get_tempo(h5,songidx=0):\n    """"""\n    Get tempo from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.tempo[songidx]\n\ndef get_time_signature(h5,songidx=0):\n    """"""\n    Get signature from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.time_signature[songidx]\n\ndef get_time_signature_confidence(h5,songidx=0):\n    """"""\n    Get signature confidence from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.time_signature_confidence[songidx]\n\ndef get_track_id(h5,songidx=0):\n    """"""\n    Get track id from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.analysis.songs.cols.track_id[songidx]\n\ndef get_segments_start(h5,songidx=0):\n    """"""\n    Get segments start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:]\n    return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:\n                                           h5.root.analysis.songs.cols.idx_segments_start[songidx+1]]\n    \ndef get_segments_confidence(h5,songidx=0):\n    """"""\n    Get segments confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:]\n    return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:\n                                                h5.root.analysis.songs.cols.idx_segments_confidence[songidx+1]]\n\ndef get_segments_pitches(h5,songidx=0):\n    """"""\n    Get segments pitches array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:,:]\n    return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:\n                                             h5.root.analysis.songs.cols.idx_segments_pitches[songidx+1],:]\n\ndef get_segments_timbre(h5,songidx=0):\n    """"""\n    Get segments timbre array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:,:]\n    return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:\n                                            h5.root.analysis.songs.cols.idx_segments_timbre[songidx+1],:]\n\ndef get_segments_loudness_max(h5,songidx=0):\n    """"""\n    Get segments loudness max array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:]\n    return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:\n                                                  h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx+1]]\n\ndef get_segments_loudness_max_time(h5,songidx=0):\n    """"""\n    Get segments loudness max time array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:]\n    return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:\n                                                       h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx+1]]\n\ndef get_segments_loudness_start(h5,songidx=0):\n    """"""\n    Get segments loudness start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:]\n    return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:\n                                                    h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx+1]]\n\ndef get_sections_start(h5,songidx=0):\n    """"""\n    Get sections start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:]\n    return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:\n                                           h5.root.analysis.songs.cols.idx_sections_start[songidx+1]]\n\ndef get_sections_confidence(h5,songidx=0):\n    """"""\n    Get sections confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:]\n    return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:\n                                                h5.root.analysis.songs.cols.idx_sections_confidence[songidx+1]]\n\ndef get_beats_start(h5,songidx=0):\n    """"""\n    Get beats start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:]\n    return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:\n                                        h5.root.analysis.songs.cols.idx_beats_start[songidx+1]]\n\ndef get_beats_confidence(h5,songidx=0):\n    """"""\n    Get beats confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:]\n    return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:\n                                             h5.root.analysis.songs.cols.idx_beats_confidence[songidx+1]]\n\ndef get_bars_start(h5,songidx=0):\n    """"""\n    Get bars start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:]\n    return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:\n                                       h5.root.analysis.songs.cols.idx_bars_start[songidx+1]]\n\ndef get_bars_confidence(h5,songidx=0):\n    """"""\n    Get bars start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:]\n    return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:\n                                            h5.root.analysis.songs.cols.idx_bars_confidence[songidx+1]]\n\ndef get_tatums_start(h5,songidx=0):\n    """"""\n    Get tatums start array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:]\n    return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:\n                                         h5.root.analysis.songs.cols.idx_tatums_start[songidx+1]]\n\ndef get_tatums_confidence(h5,songidx=0):\n    """"""\n    Get tatums confidence array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.analysis.songs.nrows == songidx + 1:\n        return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:]\n    return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:\n                                              h5.root.analysis.songs.cols.idx_tatums_confidence[songidx+1]]\n\ndef get_artist_mbtags(h5,songidx=0):\n    """"""\n    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n\ndef get_artist_mbtags_count(h5,songidx=0):\n    """"""\n    Get artist musicbrainz tag count array. Takes care of the proper indexing if we are in aggregate\n    file. By default, return the array for the first song in the h5 file.\n    To get a regular numpy ndarray, cast the result to: numpy.array( )\n    """"""\n    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n        return h5.root.musicbrainz.artist_mbtags_count[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n    return h5.root.musicbrainz.artist_mbtags_count[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n                                                   h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n\ndef get_year(h5,songidx=0):\n    """"""\n    Get release year from a HDF5 song file, by default the first song in it\n    """"""\n    return h5.root.musicbrainz.songs.cols.year[songidx]\n'"
mfcc/code/lib/oauth7digital.py,0,"b'import httplib\nimport re\nimport sys\n\nimport api_settings\nimport oauth2 as oauth\n\nSERVER = \'api.7digital.com\'\nAPI_VERSION = \'1.2\'\nREQUEST_TOKEN_URL = \'https://%s/%s/oauth/requesttoken\' % (SERVER, API_VERSION)\nACCESS_TOKEN_URL = \'https://%s/%s/oauth/accesstoken\' % (SERVER, API_VERSION)\nAUTHORIZATION_URL = \'https://account.7digital.com/%s/oauth/authorise\'\n\n\ndef _consumer():\n    return oauth.Consumer(api_settings.oauthkey, api_settings.secret)\n\n\ndef _token_from_response_content(content):\n\n    try:\n        key = re.search(\n            ""<oauth_token>(\\w.+)</oauth_token>"",\n            content).groups()[0]\n        secret = re.search(\n            ""<oauth_token_secret>(\\w.+)</oauth_token_secret>"",\n            content).groups()[0]\n    except AttributeError, e:\n        return ""Error processing response from 7digital: (%s) [AttributeError: %s]"" % (content, e)\n\n    return oauth.Token(key, secret)\n\n\ndef request_2legged(url, http_method=""GET""):\n    client = oauth.Client(_consumer())\n    response, content = client.request(\n        url,\n        headers = {""Content-Type"":""application/x-www-form-urlencoded""},\n        body=""country=%s"" % api_settings.country,\n        method = http_method\n    )\n    return response, content\n\n\ndef request_token():\n    response, content = request_2legged(REQUEST_TOKEN_URL)\n\n    if response[\'status\'] == \'200\':\n        return _token_from_response_content(content)\n\n    return response, content\n\n\ndef authorize_request_token(token, debug=False):\n    keyed_auth_url = AUTHORIZATION_URL % api_settings.oauthkey\n    auth_url=""%s?oauth_token=%s"" % (keyed_auth_url, token.key)\n\n    if debug:\n        print \'Authorization URL: %s\' % auth_url\n        oauth_verifier = raw_input(\n            \'Please go to the above URL and authorize the app. \\\n            Hit return when you have been authorized: \'\n        )\n\n    return auth_url\n\n\ndef request_access_token(token):\n    client = oauth.Client(_consumer(), token=token)\n    response, content = client.request(\n            ACCESS_TOKEN_URL,\n            headers={""Content-Type"":""application/x-www-form-urlencoded""}\n    )\n\n    return _token_from_response_content(content)\n\n\ndef request_3legged(url, access_token, http_method=""GET"", body=\'\'):\n    \'\'\' Once you have an access_token authorized by a customer,\n        execute a request on their behalf\n    \'\'\'\n    client = oauth.Client(_consumer(), token=access_token)\n    response = client.request(\n            url,\n            headers={""Content-Type"":""application/x-www-form-urlencoded""},\n            method=http_method,\n            body=body\n    )\n\n    return response\n\ndef signed_request(url, access_token=None):\n    \'\'\' return a signed request. Usually not used, save for specific\n        functions like deriving a preview-clip URL.\n    \'\'\'\n    consumer = _consumer()\n\n    req = oauth.Request.from_consumer_and_token(\n                consumer,\n                http_url=url,\n                is_form_encoded=True,\n                parameters={\'country\':api_settings.country})\n\n    signing_method = oauth.SignatureMethod_HMAC_SHA1()\n    req.sign_request(signing_method, consumer, access_token)\n\n    return req\n'"
mfcc/code/lib/previewDownloader.py,0,"b'#!/usr/bin/python\n\n__author__ = ""Matan Lachmish""\n__copyright__ = ""Copyright 2016, Tel Aviv University""\n__version__ = ""1.0""\n__status__ = ""Development""\n\nimport sys\nimport os\nimport urllib\nimport py7D\nimport hdf5_getters\n\ndef die_with_usage():\n    """""" HELP MENU """"""\n    print \'USAGE: python previewDownloader.py [path to MSD data]\'\n    sys.exit(0)\n\ndef update_progress(progress):\n    print \'\\r[{0}] {1}%\'.format(\'#\' * (progress / 10), progress)\n\n# def download\n\nif __name__ == ""__main__"":\n    # help menu\n    if len(sys.argv) < 2:\n        die_with_usage()\n\n    msdPath = sys.argv[1]\n    i = 0.0\n    for folder in os.listdir(msdPath):\n        insidePath = msdPath+\'/\'+folder\n        if (os.path.isdir(insidePath)):\n            for folder2 in os.listdir(insidePath):\n                insidePath2 = insidePath + \'/\' + folder2\n                if (os.path.isdir(insidePath2)):\n                    for file in os.listdir(insidePath2):\n                        previewFilePath = insidePath2 + \'/\' + os.path.splitext(file)[0] + \'.mp3\'\n                        print previewFilePath\n                        if file.endswith(\'h5\') and not os.path.isfile(previewFilePath):\n                            h5FilePath = insidePath2+\'/\'+file\n                            # print \'Processing \' + h5FilePath\n\n                            try:\n                                h5 = hdf5_getters.open_h5_file_read(h5FilePath)\n                                id7Digital = hdf5_getters.get_track_7digitalid(h5)\n                                h5.close()\n\n                                url = py7D.preview_url(id7Digital)\n                                urlretrieve = urllib.urlretrieve(url, previewFilePath)\n                            except Exception:\n                                print ""Error accured""\n\n                        if file.endswith(\'h5\'):\n                            # update_progress(int(i/7620 * 100))\n                            sys.stdout.write(""\\r%d%%"" % int(i/7620 * 100))\n                            sys.stdout.flush()\n                            i += 1'"
mfcc/code/lib/py7D.py,0,"b'import httplib2\nimport os\nimport urllib\nimport re\nimport urlparse\nimport xmltodict\nimport collections\n\nimport oauth7digital as oa7D\nimport api_settings\n\n__name__ = \'py7D\'\n__doc__ = \'A lightweight python interface to 7Digital web service\'\n__author__ = \'Jason Rubenstein\'\n__version__ = \'0.2\'\n__maintainer__ = \'Jason Rubenstein\'\n__email__ = \'jasondrubenstein@gmail.com\'\n__status__ = \'Beta\'\n\nSERVER = \'api.7digital.com\'\nAPI_VERSION = \'1.2\'\nAPI_URL = \'https://%s/%s\' % (SERVER, API_VERSION)\nCLIP_URL = \'http://previews.7digital.com/clip/%s?\' % (\n                                                ""%s"")\n\nclass APIServiceException(Exception):\n    pass\n\n\nclass APIClientException(Exception):\n    pass\n\n\ndef _assemble_url(host, method, function, oauth, **kwargs):\n    data = []\n\n    for k,v in kwargs.iteritems():\n        if isinstance(v, (int, float, long)):\n            kwargs[k] = str(v)\n\n    quote = lambda _param_name: urllib.quote_plus(\n                        _param_name.replace(\'&amp;\', \'&\').encode(\'utf8\')\n    )\n\n    for name in kwargs.keys():\n        data.append(\'=\'.join((name, quote(kwargs[name]))))\n\n    data = \'&\'.join(data)\n\n    url = os.path.join(host, method)\n    if function:\n        url = os.path.join(url, function)\n\n    if not oauth:\n        url = ""%s%s"" % (url, \'?oauth_consumer_key=%s&country=%s\' % (\n                                                        api_settings.oauthkey,\n                                                        api_settings.country)\n                       )\n    if data:\n        url += ""&%s"" % data\n\n    return url\n\n\ndef _execute(method, function, access_token=None, **kwargs):\n\n    \'\'\' This common execution function is overloaded to\n        handle standard requests, 2-legged oauth requests, and\n        3-legged oauth requests.\n    \'\'\'\n    dc = kwargs.pop(\'dict_constructor\', None) or collections.OrderedDict\n    is_2legged = kwargs.pop(\'is_2legged\', False)\n    http_method = kwargs.pop(\'http_method\', ""GET"")\n    body = kwargs.pop(\'body\', \'\')\n\n    oauth = False\n    if access_token or is_2legged:\n        oauth = True\n\n    url = _assemble_url(API_URL, method, function, oauth, **kwargs)\n\n    # a request is one of 3legged oauth, a 2legged oauth, or standard\n    if access_token:\n        http_response, content = oa7D.request_3legged(url,\n                                                      access_token,\n                                                      http_method=http_method,\n                                                      body=body)\n        api_response = xmltodict.parse(\n            content, xml_attribs=True, dict_constructor=dc)\n    else:\n        if is_2legged is True:\n            http_response, content = oa7D.request_2legged(\n                                                    url,\n                                                    http_method=http_method)\n        else:\n            http_response, content = httplib2.Http().request(url)\n\n        api_response = xmltodict.parse(\n            content, xml_attribs=True, dict_constructor=dc)\n\n    if api_response[\'response\'][\'@status\'] == ""error"":\n        raise APIServiceException(\'Error code %s: %s\' % (\n                api_response[\'response\'][\'error\'][\'@code\'],\n                api_response[\'response\'][\'error\'][\'errorMessage\']\n                )\n        )\n\n    api_response[\'http_headers\'] = http_response\n    return api_response\n\n\ndef request(method, function, **kwargs):\n    \'\'\' Input:\n            method      : a valid 7Digital method\n            function    : a valid function for the method\n            Other kwargs specific to the API method/function\n\n        Output:\n            A python Ordered Dictionary of the results of the\n            API, converted from XML.\n    \'\'\'\n    if kwargs.get(\'access_token\'):\n        raise APIClientException(\n            ""Please use oauth_request() for calls containing access_token"")\n\n    return _execute(method, function, **kwargs)\n\n\ndef oauth_3legged_request(method, function, access_token, **kwargs):\n    \'\'\' Input:\n            method      : a valid 7Digital method for 3-legged oauth\n            function    : a valid function for the method\n            access_token: the access_token required for 3-legged oauth\n            Other kwargs specific to the API method/function\n\n        Output:\n            A python Ordered Dictionary of the results of the\n            API, converted from XML.\n    \'\'\'\n    if not access_token:\n        raise APIClientException(""access_token required for oauth request"")\n\n    return _execute(method, function, access_token, **kwargs)\n\n\ndef oauth_2legged_request(method, function, **kwargs):\n    \'\'\' Input:\n            method      : a valid 7Digital method; commonly \'oauth\'\n            function    : a valid function for the method\n            Other kwargs specific to the API method/function\n\n        Output:\n            A python Ordered Dictionary of the results of the\n            API, converted from XML.\n    \'\'\'\n    return _execute(method, function, is_2legged=True, **kwargs)\n\n\n\ndef preview_clip(track_id):\n    \'\'\' return a preview clip in mp3 format,\n        from the 7digital preview servers.\n\n        Input:\n            valid track_id\n\n        Output:\n            An mp3 (attachment) preview-clip for the requested track.\n    \'\'\'\n    response, content = oa7D.request_2legged(\n            CLIP_URL % (track_id)\n    )\n    return response, content\n\n\ndef preview_url(track_id):\n    \'\'\' return the URL for preview clip, from the 7digital preview servers.\n\n        Input:\n            valid track_id\n\n        Output:\n            The OAuth-signed URL for a preview clip. This URL can be used\n            to retrieve the mp3 preview-clip from 7digital.\n    \'\'\'\n    s_req = oa7D.signed_request(CLIP_URL % (track_id))\n    return s_req.to_url()\n'"
