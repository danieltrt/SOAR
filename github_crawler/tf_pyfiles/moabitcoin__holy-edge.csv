file_path,api_count,code
run-hed.py,3,"b""# LIBRARY_PATH=/usr/local/cuda/lib64\nimport os\nimport sys\nimport argparse\nimport tensorflow as tf\nfrom hed.utils.io import IO\nfrom hed.test import HEDTester\nfrom hed.train import HEDTrainer\n\n\ndef get_session(gpu_fraction):\n\n    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n\n    num_threads = int(os.environ.get('OMP_NUM_THREADS'))\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n\n    if num_threads:\n        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n    else:\n        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n\n\ndef main(args):\n\n    if not (args.run_train or args.run_test or args.download_data):\n        print 'Set atleast one of the options --train | --test | --download-data'\n        parser.print_help()\n        return\n\n    if args.run_test or args.run_train:\n        session = get_session(args.gpu_limit)\n\n    if args.run_train:\n\n        trainer = HEDTrainer(args.config_file)\n        trainer.setup()\n        trainer.run(session)\n\n    if args.run_test:\n\n        tester = HEDTester(args.config_file)\n        tester.setup(session)\n        tester.run(session)\n\n    if args.download_data:\n\n        io = IO()\n        cfgs = io.read_yaml_file(args.config_file)\n        io.download_data(cfgs['rar_file'], cfgs['download_path'])\n\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser(description='Utility for Training/Testing DL models(Concepts/Captions) using theano/keras')\n    parser.add_argument('--config-file', dest='config_file', type=str, help='Experiment configuration file')\n    parser.add_argument('--train', dest='run_train', action='store_true', default=False, help='Launch training')\n    parser.add_argument('--test', dest='run_test', action='store_true', default=False, help='Launch testing on a list of images')\n    parser.add_argument('--download-data', dest='download_data', action='store_true', default=False, help='Download training data')\n    parser.add_argument('--gpu-limit', dest='gpu_limit', type=float, default=1.0, help='Use fraction of GPU memory (Useful with TensorFlow backend)')\n\n    args = parser.parse_args()\n\n    main(args)\n"""
hed/__init__.py,0,b''
hed/losses.py,7,"b'import tensorflow as tf\n\n\ndef sigmoid_cross_entropy_balanced(logits, label, name=\'cross_entropy_loss\'):\n    """"""\n    Implements Equation [2] in https://arxiv.org/pdf/1504.06375.pdf\n    Compute edge pixels for each training sample and set as pos_weights to\n    tf.nn.weighted_cross_entropy_with_logits\n    """"""\n    y = tf.cast(label, tf.float32)\n\n    count_neg = tf.reduce_sum(1. - y)\n    count_pos = tf.reduce_sum(y)\n\n    # Equation [2]\n    beta = count_neg / (count_neg + count_pos)\n\n    # Equation [2] divide by 1 - beta\n    pos_weight = beta / (1 - beta)\n\n    cost = tf.nn.weighted_cross_entropy_with_logits(logits=logits, targets=y, pos_weight=pos_weight)\n\n    # Multiply by 1 - beta\n    cost = tf.reduce_mean(cost * (1 - beta))\n\n    # check if image has no edge pixels return 0 else return complete error function\n    return tf.where(tf.equal(count_pos, 0.0), 0.0, cost, name=name)\n'"
hed/test.py,1,"b'import os\nimport sys\nimport argparse\nimport yaml\nimport urlparse\nimport urllib\nimport StringIO\nimport cStringIO\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\n\nfrom hed.models.vgg16 import Vgg16\nfrom hed.utils.io import IO\n\n\nclass HEDTester():\n\n    def __init__(self, config_file):\n\n        self.io = IO()\n        self.init = True\n\n        try:\n            pfile = open(config_file)\n            self.cfgs = yaml.load(pfile)\n            pfile.close()\n\n        except Exception as err:\n\n            self.io.print_error(\'Error reading config file {}, {}\'.format(config_file), err)\n\n    def setup(self, session):\n\n        try:\n\n            self.model = Vgg16(self.cfgs, run=\'testing\')\n\n            meta_model_file = os.path.join(self.cfgs[\'save_dir\'], \'models/hed-model-{}\'.format(self.cfgs[\'test_snapshot\']))\n\n            saver = tf.train.Saver()\n            saver.restore(session, meta_model_file)\n\n            self.io.print_info(\'Done restoring VGG-16 model from {}\'.format(meta_model_file))\n\n        except Exception as err:\n\n            self.io.print_error(\'Error setting up VGG-16 model, {}\'.format(err))\n            self.init = False\n\n    def run(self, session):\n\n        if not self.init:\n            return\n\n        self.model.setup_testing(session)\n\n        filepath = os.path.join(self.cfgs[\'download_path\'], self.cfgs[\'testing\'][\'list\'])\n        train_list = self.io.read_file_list(filepath)\n\n        self.io.print_info(\'Writing PNGs at {}\'.format(self.cfgs[\'test_output\']))\n\n        for idx, img in enumerate(train_list):\n\n            test_filename = os.path.join(self.cfgs[\'download_path\'], self.cfgs[\'testing\'][\'dir\'], img)\n            im = self.fetch_image(test_filename)\n\n            edgemap = session.run(self.model.predictions, feed_dict={self.model.images: [im]})\n            self.save_egdemaps(edgemap, idx)\n\n            self.io.print_info(\'Done testing {}, {}\'.format(test_filename, im.shape))\n\n    def save_egdemaps(self, em_maps, index):\n\n        # Take the edge map from the network from side layers and fuse layer\n        em_maps = [e[0] for e in em_maps]\n        em_maps = em_maps + [np.mean(np.array(em_maps), axis=0)]\n\n        for idx, em in enumerate(em_maps):\n\n            em[em < self.cfgs[\'testing_threshold\']] = 0.0\n\n            em = 255.0 * (1.0 - em)\n            em = np.tile(em, [1, 1, 3])\n\n            em = Image.fromarray(np.uint8(em))\n            em.save(os.path.join(self.cfgs[\'test_output\'], \'testing-{}-{:03}.png\'.format(index, idx)))\n\n    def fetch_image(self, test_image):\n\n        # is url\n        image = None\n\n        if not urlparse.urlparse(test_image).scheme == """":\n\n            url_response = urllib.urlopen(test_image)\n\n            if url_response.code == 404:\n                print self.io.print_error(\'[Testing] URL error code : {1} for {0}\'.format(test_image, url_response.code))\n                return None\n\n            try:\n\n                image_buffer = cStringIO.StringIO(url_response.read())\n                image = self.capture_pixels(image_buffer)\n\n            except Exception as err:\n\n                print self.io.print_error(\'[Testing] Error with URL {0} {1}\'.format(test_image, err))\n                return None\n\n        # read from disk\n        elif os.path.exists(test_image):\n\n            try:\n\n                fid = open(test_image, \'r\')\n                stream = fid.read()\n                fid.close()\n\n                image_buffer = cStringIO.StringIO(stream)\n                image = self.capture_pixels(image_buffer)\n\n            except Exception as err:\n\n                print self.io.print_error(\'[Testing] Error with image file {0} {1}\'.format(test_image, err))\n                return None\n\n        return image\n\n    def capture_pixels(self, image_buffer):\n\n        image = Image.open(image_buffer)\n        image = image.resize((self.cfgs[\'testing\'][\'image_width\'], self.cfgs[\'testing\'][\'image_height\']))\n        image = np.array(image, np.float32)\n        image = self.colorize(image)\n\n        image = image[:, :, self.cfgs[\'channel_swap\']]\n        image -= self.cfgs[\'mean_pixel_value\']\n\n        return image\n\n    def colorize(self, image):\n\n        # BW to 3 channel RGB image\n        if image.ndim == 2:\n            image = image[:, :, np.newaxis]\n            image = np.tile(image, (1, 1, 3))\n        elif image.shape[2] == 4:\n            image = image[:, :, :3]\n\n        return image\n'"
hed/train.py,5,"b""import os\nimport sys\nimport yaml\nimport argparse\nimport tensorflow as tf\nfrom termcolor import colored\n\nfrom hed.models.vgg16 import Vgg16\nfrom hed.utils.io import IO\nfrom hed.data.data_parser import DataParser\n\n\nclass HEDTrainer():\n\n    def __init__(self, config_file):\n\n        self.io = IO()\n        self.init = True\n\n        try:\n            pfile = open(config_file)\n            self.cfgs = yaml.load(pfile)\n            pfile.close()\n\n        except Exception as err:\n\n            print('Error reading config file {}, {}'.format(config_file, err))\n\n    def setup(self):\n\n        try:\n\n            self.model = Vgg16(self.cfgs)\n            self.io.print_info('Done initializing VGG-16 model')\n\n            dirs = ['train', 'val', 'test', 'models']\n            dirs = [os.path.join(self.cfgs['save_dir'] + '/{}'.format(d)) for d in dirs]\n            _ = [os.makedirs(d) for d in dirs if not os.path.exists(d)]\n\n        except Exception as err:\n\n            self.io.print_error('Error setting up VGG-16 model, {}'.format(err))\n            self.init = False\n\n    def run(self, session):\n\n        if not self.init:\n            return\n\n        train_data = DataParser(self.cfgs)\n\n        self.model.setup_training(session)\n\n        opt = tf.train.AdamOptimizer(self.cfgs['optimizer_params']['learning_rate'])\n        train = opt.minimize(self.model.loss)\n\n        session.run(tf.global_variables_initializer())\n\n        for idx in range(self.cfgs['max_iterations']):\n\n            im, em, _ = train_data.get_training_batch()\n\n            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n\n            _, summary, loss = session.run([train, self.model.merged_summary, self.model.loss],\n                                           feed_dict={self.model.images: im, self.model.edgemaps: em},\n                                           options=run_options,\n                                           run_metadata=run_metadata)\n\n            self.model.train_writer.add_run_metadata(run_metadata, 'step{:06}'.format(idx))\n            self.model.train_writer.add_summary(summary, idx)\n\n            self.io.print_info('[{}/{}] TRAINING loss : {}'.format(idx, self.cfgs['max_iterations'], loss))\n\n            if idx % self.cfgs['save_interval'] == 0:\n\n                saver = tf.train.Saver()\n                saver.save(session, os.path.join(self.cfgs['save_dir'], 'models/hed-model'), global_step=idx)\n\n            if idx % self.cfgs['val_interval'] == 0:\n\n                im, em, _ = train_data.get_validation_batch()\n\n                summary, error = session.run([self.model.merged_summary, self.model.error], feed_dict={self.model.images: im, self.model.edgemaps: em})\n\n                self.model.val_writer.add_summary(summary, idx)\n                self.io.print_info('[{}/{}] VALIDATION error : {}'.format(idx, self.cfgs['max_iterations'], error))\n\n        self.model.train_writer.close()\n"""
hed/data/__init__.py,0,b''
hed/data/data_parser.py,0,"b""import os\nimport sys\nimport time\nimport wget\nimport numpy as np\nfrom PIL import Image\nfrom hed.utils.io import IO\n\n\nclass DataParser():\n\n    def __init__(self, cfgs):\n\n        self.io = IO()\n        self.cfgs = cfgs\n        self.train_file = os.path.join(cfgs['download_path'], cfgs['training']['list'])\n        self.train_data_dir = os.path.join(cfgs['download_path'], cfgs['training']['dir'])\n        self.training_pairs = self.io.read_file_list(self.train_file)\n\n        self.samples = self.io.split_pair_names(self.training_pairs, self.train_data_dir)\n        self.io.print_info('Training data set-up from {}'.format(os.path.join(self.train_file)))\n        self.n_samples = len(self.training_pairs)\n\n        self.all_ids = range(self.n_samples)\n        np.random.shuffle(self.all_ids)\n\n        self.training_ids = self.all_ids[:int(self.cfgs['train_split'] * len(self.training_pairs))]\n        self.validation_ids = self.all_ids[int(self.cfgs['train_split'] * len(self.training_pairs)):]\n\n        self.io.print_info('Training samples {}'.format(len(self.training_ids)))\n        self.io.print_info('Validation samples {}'.format(len(self.validation_ids)))\n\n    def get_training_batch(self):\n\n        batch_ids = np.random.choice(self.training_ids, self.cfgs['batch_size_train'])\n\n        return self.get_batch(batch_ids)\n\n    def get_validation_batch(self):\n\n        batch_ids = np.random.choice(self.validation_ids, self.cfgs['batch_size_val'])\n\n        return self.get_batch(batch_ids)\n\n    def get_batch(self, batch):\n\n        tstart = time.time()\n\n        filenames = []\n        images = []\n        edgemaps = []\n\n        for idx, b in enumerate(batch):\n\n            im = Image.open(self.samples[b][0])\n            em = Image.open(self.samples[b][1])\n\n            im = im.resize((self.cfgs['training']['image_width'], self.cfgs['training']['image_height']))\n            em = em.resize((self.cfgs['training']['image_width'], self.cfgs['training']['image_height']))\n\n            im = np.array(im, dtype=np.float32)\n            im = im[:, :, self.cfgs['channel_swap']]\n            im -= self.cfgs['mean_pixel_value']\n\n            # Labels needs to be 1 or 0 (edge pixel or not)\n            # or can use regression targets as done by the author\n            # https://github.com/s9xie/hed/blob/9e74dd710773d8d8a469ad905c76f4a7fa08f945/src/caffe/layers/image_labelmap_data_layer.cpp#L213\n\n            em = np.array(em.convert('L'), dtype=np.float32)\n\n            if self.cfgs['target_regression']:\n                bin_em = em / 255.0\n            else:\n                bin_em = np.zeros_like(em)\n                bin_em[np.where(em)] = 1\n\n            # Some edge maps have 3 channels some dont\n            bin_em = bin_em if bin_em.ndim == 2 else bin_em[:, :, 0]\n            # To fit [batch_size, H, W, 1] output of the network\n            bin_em = np.expand_dims(bin_em, 2)\n\n            images.append(im)\n            edgemaps.append(bin_em)\n            filenames.append(self.samples[b])\n\n        return images, edgemaps, filenames\n"""
hed/models/__init__.py,0,b''
hed/models/vgg16.py,35,"b'# Adapted from : VGG 16 model : https://github.com/machrisaa/tensorflow-vgg\nimport time\nimport os\nimport inspect\n\nimport numpy as np\nfrom termcolor import colored\nimport tensorflow as tf\n\nfrom hed.losses import sigmoid_cross_entropy_balanced\nfrom hed.utils.io import IO\n\n\nclass Vgg16():\n\n    def __init__(self, cfgs, run=\'training\'):\n\n        self.cfgs = cfgs\n        self.io = IO()\n\n        base_path = os.path.abspath(os.path.dirname(__file__))\n        weights_file = os.path.join(base_path, self.cfgs[\'model_weights_path\'])\n\n        self.data_dict = np.load(weights_file, encoding=\'latin1\').item()\n        self.io.print_info(""Model weights loaded from {}"".format(self.cfgs[\'model_weights_path\']))\n\n        self.images = tf.placeholder(tf.float32, [None, self.cfgs[run][\'image_height\'], self.cfgs[run][\'image_width\'], self.cfgs[run][\'n_channels\']])\n        self.edgemaps = tf.placeholder(tf.float32, [None, self.cfgs[run][\'image_height\'], self.cfgs[run][\'image_width\'], 1])\n\n        self.define_model()\n\n    def define_model(self):\n\n        """"""\n        Load VGG params from disk without FC layers A\n        Add branch layers (with deconv) after each CONV block\n        """"""\n\n        start_time = time.time()\n\n        self.conv1_1 = self.conv_layer_vgg(self.images, ""conv1_1"")\n        self.conv1_2 = self.conv_layer_vgg(self.conv1_1, ""conv1_2"")\n        self.side_1 = self.side_layer(self.conv1_2, ""side_1"", 1)\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n\n        self.io.print_info(\'Added CONV-BLOCK-1+SIDE-1\')\n\n        self.conv2_1 = self.conv_layer_vgg(self.pool1, ""conv2_1"")\n        self.conv2_2 = self.conv_layer_vgg(self.conv2_1, ""conv2_2"")\n        self.side_2 = self.side_layer(self.conv2_2, ""side_2"", 2)\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n\n        self.io.print_info(\'Added CONV-BLOCK-2+SIDE-2\')\n\n        self.conv3_1 = self.conv_layer_vgg(self.pool2, ""conv3_1"")\n        self.conv3_2 = self.conv_layer_vgg(self.conv3_1, ""conv3_2"")\n        self.conv3_3 = self.conv_layer_vgg(self.conv3_2, ""conv3_3"")\n        self.side_3 = self.side_layer(self.conv3_3, ""side_3"", 4)\n        self.pool3 = self.max_pool(self.conv3_3, \'pool3\')\n\n        self.io.print_info(\'Added CONV-BLOCK-3+SIDE-3\')\n\n        self.conv4_1 = self.conv_layer_vgg(self.pool3, ""conv4_1"")\n        self.conv4_2 = self.conv_layer_vgg(self.conv4_1, ""conv4_2"")\n        self.conv4_3 = self.conv_layer_vgg(self.conv4_2, ""conv4_3"")\n        self.side_4 = self.side_layer(self.conv4_3, ""side_4"", 8)\n        self.pool4 = self.max_pool(self.conv4_3, \'pool4\')\n\n        self.io.print_info(\'Added CONV-BLOCK-4+SIDE-4\')\n\n        self.conv5_1 = self.conv_layer_vgg(self.pool4, ""conv5_1"")\n        self.conv5_2 = self.conv_layer_vgg(self.conv5_1, ""conv5_2"")\n        self.conv5_3 = self.conv_layer_vgg(self.conv5_2, ""conv5_3"")\n        self.side_5 = self.side_layer(self.conv5_3, ""side_5"", 16)\n\n        self.io.print_info(\'Added CONV-BLOCK-5+SIDE-5\')\n\n        self.side_outputs = [self.side_1, self.side_2, self.side_3, self.side_4, self.side_5]\n\n        w_shape = [1, 1, len(self.side_outputs), 1]\n        self.fuse = self.conv_layer(tf.concat(self.side_outputs, axis=3),\n                                    w_shape, name=\'fuse_1\', use_bias=False,\n                                    w_init=tf.constant_initializer(0.2))\n\n        self.io.print_info(\'Added FUSE layer\')\n\n        # complete output maps from side layer and fuse layers\n        self.outputs = self.side_outputs + [self.fuse]\n\n        self.data_dict = None\n        self.io.print_info(""Build model finished: {:.4f}s"".format(time.time() - start_time))\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def conv_layer_vgg(self, bottom, name):\n        """"""\n            Adding a conv layer + weight parameters from a dict\n        """"""\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter(name)\n\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def conv_layer(self, x, W_shape, b_shape=None, name=None,\n                   padding=\'SAME\', use_bias=True, w_init=None, b_init=None):\n\n        W = self.weight_variable(W_shape, w_init)\n        tf.summary.histogram(\'weights_{}\'.format(name), W)\n\n        if use_bias:\n            b = self.bias_variable([b_shape], b_init)\n            tf.summary.histogram(\'biases_{}\'.format(name), b)\n\n        conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=padding)\n\n        return conv + b if use_bias else conv\n\n    def deconv_layer(self, x, upscale, name, padding=\'SAME\', w_init=None):\n\n        x_shape = tf.shape(x)\n        in_shape = x.shape.as_list()\n\n        w_shape = [upscale * 2, upscale * 2, in_shape[-1], 1]\n        strides = [1, upscale, upscale, 1]\n\n        W = self.weight_variable(w_shape, w_init)\n        tf.summary.histogram(\'weights_{}\'.format(name), W)\n\n        out_shape = tf.stack([x_shape[0], x_shape[1], x_shape[2], w_shape[2]]) * tf.constant(strides, tf.int32)\n        deconv = tf.nn.conv2d_transpose(x, W, out_shape, strides=strides, padding=padding)\n\n        return deconv\n\n    def side_layer(self, inputs, name, upscale):\n        """"""\n            https://github.com/s9xie/hed/blob/9e74dd710773d8d8a469ad905c76f4a7fa08f945/examples/hed/train_val.prototxt#L122\n            1x1 conv followed with Deconvoltion layer to upscale the size of input image sans color\n        """"""\n        with tf.variable_scope(name):\n\n            in_shape = inputs.shape.as_list()\n            w_shape = [1, 1, in_shape[-1], 1]\n\n            classifier = self.conv_layer(inputs, w_shape, b_shape=1,\n                                         w_init=tf.constant_initializer(),\n                                         b_init=tf.constant_initializer(),\n                                         name=name + \'_reduction\')\n\n            classifier = self.deconv_layer(classifier, upscale=upscale,\n                                           name=\'{}_deconv_{}\'.format(name, upscale),\n                                           w_init=tf.truncated_normal_initializer(stddev=0.1))\n\n            return classifier\n\n    def get_conv_filter(self, name):\n        return tf.constant(self.data_dict[name][0], name=""filter"")\n\n    def get_bias(self, name):\n        return tf.constant(self.data_dict[name][1], name=""biases"")\n\n    def weight_variable(self, shape, initial):\n\n        init = initial(shape)\n        return tf.Variable(init)\n\n    def bias_variable(self, shape, initial):\n\n        init = initial(shape)\n        return tf.Variable(init)\n\n    def setup_testing(self, session):\n\n        """"""\n            Apply sigmoid non-linearity to side layer ouputs + fuse layer outputs for predictions\n        """"""\n\n        self.predictions = []\n\n        for idx, b in enumerate(self.outputs):\n            output = tf.nn.sigmoid(b, name=\'output_{}\'.format(idx))\n            self.predictions.append(output)\n\n    def setup_training(self, session):\n\n        """"""\n            Apply sigmoid non-linearity to side layer ouputs + fuse layer outputs\n            Compute total loss := side_layer_loss + fuse_layer_loss\n            Compute predicted edge maps from fuse layer as pseudo performance metric to track\n        """"""\n\n        self.predictions = []\n        self.loss = 0\n\n        self.io.print_warning(\'Deep supervision application set to {}\'.format(self.cfgs[\'deep_supervision\']))\n\n        for idx, b in enumerate(self.side_outputs):\n            output = tf.nn.sigmoid(b, name=\'output_{}\'.format(idx))\n            cost = sigmoid_cross_entropy_balanced(b, self.edgemaps, name=\'cross_entropy{}\'.format(idx))\n\n            self.predictions.append(output)\n            if self.cfgs[\'deep_supervision\']:\n                self.loss += (self.cfgs[\'loss_weights\'] * cost)\n\n        fuse_output = tf.nn.sigmoid(self.fuse, name=\'fuse\')\n        fuse_cost = sigmoid_cross_entropy_balanced(self.fuse, self.edgemaps, name=\'cross_entropy_fuse\')\n\n        self.predictions.append(fuse_output)\n        self.loss += (self.cfgs[\'loss_weights\'] * fuse_cost)\n\n        pred = tf.cast(tf.greater(fuse_output, 0.5), tf.int32, name=\'predictions\')\n        error = tf.cast(tf.not_equal(pred, tf.cast(self.edgemaps, tf.int32)), tf.float32)\n        self.error = tf.reduce_mean(error, name=\'pixel_error\')\n\n        tf.summary.scalar(\'loss\', self.loss)\n        tf.summary.scalar(\'error\', self.error)\n\n        self.merged_summary = tf.summary.merge_all()\n\n        self.train_writer = tf.summary.FileWriter(self.cfgs[\'save_dir\'] + \'/train\', session.graph)\n        self.val_writer = tf.summary.FileWriter(self.cfgs[\'save_dir\'] + \'/val\')\n'"
hed/utils/__init__.py,0,b''
hed/utils/io.py,0,"b'import os\nimport yaml\nimport wget\nfrom pyunpack import Archive\nfrom time import strftime, localtime\nfrom termcolor import colored\n\n\nclass IO():\n\n    def __init__(self, log_dir=None):\n\n        self.log_dir = log_dir\n\n    def read_yaml_file(self, config_file):\n\n        pfile = open(config_file)\n        d = yaml.load(pfile)\n        pfile.close()\n\n        return d\n\n    def download_data(self, filepath, outputdir):\n\n        _, rar_file = os.path.split(filepath)\n        rar_file = os.path.join(outputdir, rar_file)\n\n        if not os.path.exists(rar_file):\n            self.print_info(\'Downloading {} to {}\'.format(filepath, rar_file))\n            _ = wget.download(filepath, out=outputdir)\n\n        self.print_info(\'Decompressing {} to {}\'.format(rar_file, outputdir))\n        Archive(rar_file).extractall(outputdir)\n\n    def print_info(self, info_string, quite=False):\n\n        info = \'[{0}][INFO] {1}\'.format(self.get_local_time(), info_string)\n        print colored(info, \'green\')\n\n    def print_warning(self, warning_string):\n\n        warning = \'[{0}][WARNING] {1}\'.format(self.get_local_time(), warning_string)\n\n        print colored(warning, \'blue\')\n\n    def print_error(self, error_string):\n\n        error = \'[{0}][ERROR] {1}\'.format(self.get_local_time(), error_string)\n\n        print colored(error, \'red\')\n\n    def get_local_time(self):\n\n        return strftime(""%d %b %Y %Hh%Mm%Ss"", localtime())\n\n    def read_file_list(self, filelist):\n\n        pfile = open(filelist)\n        filenames = pfile.readlines()\n        pfile.close()\n\n        filenames = [f.strip() for f in filenames]\n\n        return filenames\n\n    def split_pair_names(self, filenames, base_dir):\n\n        filenames = [c.split(\' \') for c in filenames]\n        filenames = [(os.path.join(base_dir, c[0]), os.path.join(base_dir, c[1])) for c in filenames]\n\n        return filenames\n'"
