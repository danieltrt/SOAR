file_path,api_count,code
app.py,1,"b'import os\nimport sys\n\n# Flask\nfrom flask import Flask, redirect, url_for, request, render_template, Response, jsonify, redirect\nfrom werkzeug.utils import secure_filename\nfrom gevent.pywsgi import WSGIServer\n\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n\n# Some utilites\nimport numpy as np\nfrom util import base64_to_pil\n\n\n# Declare a flask app\napp = Flask(__name__)\n\n\n# You can use pretrained model from Keras\n# Check https://keras.io/applications/\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nmodel = MobileNetV2(weights=\'imagenet\')\n\nprint(\'Model loaded. Check http://127.0.0.1:5000/\')\n\n\n# Model saved with Keras model.save()\nMODEL_PATH = \'models/your_model.h5\'\n\n# Load your own trained model\n# model = load_model(MODEL_PATH)\n# model._make_predict_function()          # Necessary\n# print(\'Model loaded. Start serving...\')\n\n\ndef model_predict(img, model):\n    img = img.resize((224, 224))\n\n    # Preprocessing the image\n    x = image.img_to_array(img)\n    # x = np.true_divide(x, 255)\n    x = np.expand_dims(x, axis=0)\n\n    # Be careful how your trained model deals with the input\n    # otherwise, it won\'t make correct prediction!\n    x = preprocess_input(x, mode=\'tf\')\n\n    preds = model.predict(x)\n    return preds\n\n\n@app.route(\'/\', methods=[\'GET\'])\ndef index():\n    # Main page\n    return render_template(\'index.html\')\n\n\n@app.route(\'/predict\', methods=[\'GET\', \'POST\'])\ndef predict():\n    if request.method == \'POST\':\n        # Get the image from post request\n        img = base64_to_pil(request.json)\n\n        # Save the image to ./uploads\n        # img.save(""./uploads/image.png"")\n\n        # Make prediction\n        preds = model_predict(img, model)\n\n        # Process your result for human\n        pred_proba = ""{:.3f}"".format(np.amax(preds))    # Max probability\n        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\n\n        result = str(pred_class[0][0][1])               # Convert to string\n        result = result.replace(\'_\', \' \').capitalize()\n        \n        # Serialize the result, you can add additional fields\n        return jsonify(result=result, probability=pred_proba)\n\n    return None\n\n\nif __name__ == \'__main__\':\n    # app.run(port=5002, threaded=False)\n\n    # Serve the app with gevent\n    http_server = WSGIServer((\'0.0.0.0\', 5000), app)\n    http_server.serve_forever()\n'"
util.py,0,"b'""""""Utilities\n""""""\nimport re\nimport base64\n\nimport numpy as np\n\nfrom PIL import Image\nfrom io import BytesIO\n\n\ndef base64_to_pil(img_base64):\n    """"""\n    Convert base64 image data to PIL image\n    """"""\n    image_data = re.sub(\'^data:image/.+;base64,\', \'\', img_base64)\n    pil_image = Image.open(BytesIO(base64.b64decode(image_data)))\n    return pil_image\n\n\ndef np_to_base64(img_np):\n    """"""\n    Convert numpy image (RGB) to base64 string\n    """"""\n    img = Image.fromarray(img_np.astype(\'uint8\'), \'RGB\')\n    buffered = BytesIO()\n    img.save(buffered, format=""PNG"")\n    return u""data:image/png;base64,"" + base64.b64encode(buffered.getvalue()).decode(""ascii"")\n\n'"
