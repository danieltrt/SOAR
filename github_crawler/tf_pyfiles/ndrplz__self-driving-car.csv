file_path,api_count,code
capstone_traffic_light_classifier/test.py,2,"b'import argparse\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom glob import glob\nfrom os.path import join\nfrom traffic_light_dataset import TrafficLightDataset\nfrom traffic_light_classifier import TrafficLightClassifier\n\n\ndef parse_arguments():\n    """"""\n    Parse command line arguments\n    """"""\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\'checkpoint_path\', type=str)\n    parser.add_argument(\'--mode\', type=str, choices=[\'from_npy\', \'from_file\', \'from_dir\'], required=True)\n    parser.add_argument(\'--data_path\', type=str, required=True)\n    parser.add_argument(\'--resize_h\', type=int, default=64, help=\'Height to which input is resized\')\n    parser.add_argument(\'--resize_w\', type=int, default=64, help=\'Width to which input is resized\')\n    return parser.parse_args()\n\n\ndef load_test_data(args):\n    """"""\n    Load a data batch to perform inference, according to selected mode.\n    """"""\n    dataset = TrafficLightDataset()\n\n    def read_and_resize_image(image_path):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        return cv2.resize(image, (args.resize_h, args.resize_w))\n\n    # Load a random batch of data from a `.npy` dataset\n    if args.mode == \'from_npy\':\n        dataset.init_from_npy(args.data_path)                 # Init traffic light dataset\n        x_batch, y_batch = dataset.load_batch(batch_size=16)  # Random batch of examples\n\n    # Load a single image from disk\n    elif args.mode == \'from_file\':\n        image = read_and_resize_image(args.data_path)\n        x_batch = np.expand_dims(dataset.preprocess(image), 0)\n        y_batch = np.ones(shape=(x_batch.shape[0], 1)) * -1   # -1 means label not available\n\n    # Load all images in a certain directory\n    elif args.mode == \'from_dir\':\n        x_batch, y_batch = [], []\n        image_list = glob(join(args.data_path, \'*.jpg\'))\n        for image_path in image_list:\n            image = read_and_resize_image(image_path)\n            x_batch.append(dataset.preprocess(image))\n            y_batch.append([-1])                              # -1 means label not available\n        x_batch = np.array(x_batch)\n        y_batch = np.array(y_batch)\n    else:\n        raise ValueError(\'Mode: ""{}"" not supported.\'.format(args.mode))\n\n    return x_batch, y_batch\n\n\nif __name__ == \'__main__\':\n\n    # Parse command line arguments\n    args = parse_arguments()\n\n    # Load data on which prediction will be performed\n    x_batch, y_batch = load_test_data(args)\n\n    # Define model\n    classifier = TrafficLightClassifier(input_shape=[args.resize_h, args.resize_w], learning_rate=1e-4)\n\n    # Add a saver to save the model after each epoch\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n\n        # Restore pretrained weights\n        saver.restore(sess, args.checkpoint_path)\n\n        # Predict on loaded batch\n        prediction = sess.run(fetches=classifier.inference,\n                              feed_dict={classifier.x: x_batch, classifier.keep_prob: 1.})\n        prediction = np.argmax(prediction, axis=1)  # from onehot vectors to labels\n\n        # Qualitatively show results\n        for b in range(x_batch.shape[0]):\n\n            # Revert data normalization\n            image = x_batch[b]\n            image += np.abs(np.min(image))\n            image *= 255\n            image = np.clip(image, 0, 255).astype(np.uint8)\n\n            # Display result\n            image = cv2.resize(image, (256, 256))\n            cv2.imshow(\'PRED {} GT {}\'.format(prediction[b], y_batch[b]), image)\n            cv2.waitKey()\n'"
capstone_traffic_light_classifier/traffic_light_classifier.py,26,"b""import numpy as np\nimport tensorflow as tf\n\n\nEPS  = np.finfo('float32').eps\n\n\nclass TrafficLightClassifier:\n\n    def __init__(self, input_shape, learning_rate, verbose=True):\n\n        # Placeholders\n        input_h, input_w = input_shape\n        self.x = tf.placeholder(dtype=tf.float32, shape=[None, input_h, input_w, 3])  # input placeholder\n        self.targets = tf.placeholder(dtype=tf.int32, shape=[None])\n        self.keep_prob = tf.placeholder(dtype=tf.float32)  # dropout keep probability\n\n        self.n_classes      = 4              # {void, red, yellow, green}\n        self.learning_rate  = learning_rate  # learning rate used in train step\n\n        self._inference     = None\n        self._loss          = None\n        self._train_step    = None\n        self._accuracy      = None\n        self._summaries     = None\n\n        self.inference\n        self.loss\n        self.train_step\n        self.accuracy\n        # self.summaries # todo add these\n\n        if verbose:\n            self.print_summary()\n\n    @property\n    def inference(self):\n        if self._inference is None:\n            with tf.variable_scope('inference'):\n\n                kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3)\n\n                conv1_filters = 32\n                conv1 = tf.layers.conv2d(self.x, conv1_filters, kernel_size=(3, 3), padding='same',\n                                         activation=tf.nn.relu, kernel_regularizer=kernel_regularizer)\n                pool1 = tf.layers.max_pooling2d(conv1, pool_size=(2, 2), strides=(2, 2), padding='same')\n\n                conv2_filters = 64\n                conv2 = tf.layers.conv2d(pool1, conv2_filters, kernel_size=(3, 3), padding='same',\n                                         activation=tf.nn.relu, kernel_regularizer=kernel_regularizer)\n                pool2 = tf.layers.max_pooling2d(conv2, pool_size=(2, 2), strides=(2, 2), padding='same')\n\n                _, h, w, c = pool2.get_shape().as_list()\n                pool2_flat = tf.reshape(pool2, shape=[-1, h * w * c])\n\n                pool2_drop = tf.nn.dropout(pool2_flat, keep_prob=self.keep_prob)\n\n                hidden_units = self.n_classes\n                hidden = tf.layers.dense(pool2_drop, units=hidden_units, activation=tf.nn.relu)\n\n                logits = tf.layers.dense(hidden, units=self.n_classes, activation=None)\n\n                self._inference = tf.nn.softmax(logits)\n\n        return self._inference\n\n    @property\n    def loss(self):\n        if self._loss is None:\n            with tf.variable_scope('loss'):\n                predictions = self.inference\n                targets_onehot = tf.one_hot(self.targets, depth=self.n_classes)\n                self._loss = tf.reduce_mean(-tf.reduce_sum(targets_onehot * tf.log(predictions + EPS), reduction_indices=1))\n        return self._loss\n\n    @property\n    def train_step(self):\n        if self._train_step is None:\n            with tf.variable_scope('training'):\n                self._train_step = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n        return self._train_step\n\n    @property\n    def accuracy(self):\n        if self._accuracy is None:\n            with tf.variable_scope('accuracy'):\n                correct_predictions = tf.equal(tf.argmax(self.inference, axis=1),\n                                               tf.argmax(tf.one_hot(self.targets, depth=self.n_classes), axis=1))\n                self._accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n        return self._accuracy\n\n    @staticmethod\n    def print_summary():\n        def pretty_border():\n            print('*' * 50)\n\n        pretty_border()\n        print('Classifier initialized.')\n\n        trainable_variables  = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n        num_trainable_params = np.sum([np.prod(v.get_shape()) for v in trainable_variables])\n        print('Number of trainable parameters: {}'.format(num_trainable_params))\n        pretty_border()\n"""
capstone_traffic_light_classifier/train.py,3,"b""import tensorflow as tf\nfrom os import makedirs\nfrom os.path import exists, join\nfrom traffic_light_dataset import TrafficLightDataset\nfrom traffic_light_classifier import TrafficLightClassifier\n\n\nif __name__ == '__main__':\n\n    # Parameters\n    input_h, input_w = 128, 128    # Shape to which input is resized\n\n    # Init traffic light dataset\n    dataset = TrafficLightDataset()\n    dataset_file = 'traffic_light_dataset_npy/traffic_light_dataset_mixed_resize_{}.npy'.format(input_h)\n    dataset.init_from_npy(dataset_file)\n\n    # Define model\n    classifier = TrafficLightClassifier(input_shape=[input_h, input_w], learning_rate=1e-4, verbose=True)\n\n    # Checkpoint stuff\n    saver = tf.train.Saver()  # saver to save the model after each epoch\n    checkpoint_dir = './checkpoint_mixed_{}'.format(input_h)  # checkpoint directory\n    if not exists(checkpoint_dir):\n        makedirs(checkpoint_dir)\n\n    with tf.Session() as sess:\n\n        # Initialize all variables\n        sess.run(tf.global_variables_initializer())\n\n        # Training parameters\n        batch_size         = 32\n        batches_each_epoch = 1000\n\n        epoch = 0\n\n        while True:\n\n            loss_cur_epoch = 0\n\n            for _ in range(batches_each_epoch):\n\n                # Load a batch of training data\n                x_batch, y_batch = dataset.load_batch(batch_size, augmentation=True)\n\n                # Actually run one training step here\n                _, loss_this_batch = sess.run(fetches=[classifier.train_step, classifier.loss],\n                                              feed_dict={classifier.x: x_batch,\n                                                         classifier.targets: y_batch,\n                                                         classifier.keep_prob: 0.5})\n\n                loss_cur_epoch += loss_this_batch\n\n            loss_cur_epoch /= batches_each_epoch\n            print('Loss cur epoch: {:.04f}'.format(loss_cur_epoch))\n\n            # Eventually evaluate on whole test set when training ends\n            average_test_accuracy = 0.0\n            num_test_batches = 500\n            for _ in range(num_test_batches):\n                x_batch, y_batch = dataset.load_batch(batch_size)\n                average_test_accuracy += sess.run(fetches=classifier.accuracy,\n                                                  feed_dict={classifier.x: x_batch,\n                                                             classifier.targets: y_batch,\n                                                             classifier.keep_prob: 1.0})\n            average_test_accuracy /= num_test_batches\n            print('Training accuracy: {:.03f}'.format(average_test_accuracy))\n            print('*' * 50)\n\n            # Save the variables to disk.\n            save_path = saver.save(sess, join(checkpoint_dir, 'TLC_epoch_{}.ckpt'.format(epoch)))\n\n            epoch += 1\n"""
project_12_road_segmentation/helper.py,1,"b'import re\nimport random\nimport numpy as np\nimport os.path\nimport scipy.misc\nimport shutil\nimport zipfile\nimport time\nimport tensorflow as tf\nfrom glob import glob\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\n\nclass DLProgress(tqdm):\n    last_block = 0\n\n    def hook(self, block_num=1, block_size=1, total_size=None):\n        self.total = total_size\n        self.update((block_num - self.last_block) * block_size)\n        self.last_block = block_num\n\n\ndef maybe_download_pretrained_vgg(data_dir):\n    """"""\n    Download and extract pretrained vgg model if it doesn\'t exist\n    :param data_dir: Directory to download the model to\n    """"""\n    vgg_filename = \'vgg.zip\'\n    vgg_path = os.path.join(data_dir, \'vgg\')\n    vgg_files = [\n        os.path.join(vgg_path, \'variables/variables.data-00000-of-00001\'),\n        os.path.join(vgg_path, \'variables/variables.index\'),\n        os.path.join(vgg_path, \'saved_model.pb\')]\n\n    missing_vgg_files = [vgg_file for vgg_file in vgg_files if not os.path.exists(vgg_file)]\n    if missing_vgg_files:\n        # Clean vgg dir\n        if os.path.exists(vgg_path):\n            shutil.rmtree(vgg_path)\n        os.makedirs(vgg_path)\n\n        # Download vgg\n        print(\'Downloading pre-trained vgg model...\')\n        with DLProgress(unit=\'B\', unit_scale=True, miniters=1) as pbar:\n            urlretrieve(\n                \'https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip\',\n                os.path.join(vgg_path, vgg_filename),\n                pbar.hook)\n\n        # Extract vgg\n        print(\'Extracting model...\')\n        zip_ref = zipfile.ZipFile(os.path.join(vgg_path, vgg_filename), \'r\')\n        zip_ref.extractall(data_dir)\n        zip_ref.close()\n\n        # Remove zip file to save space\n        os.remove(os.path.join(vgg_path, vgg_filename))\n\n\ndef gen_batch_function(data_folder, image_shape):\n    """"""\n    Generate function to create batches of training data\n    :param data_folder: Path to folder that contains all the datasets\n    :param image_shape: Tuple - Shape of image\n    :return:\n    """"""\n    def get_batches_fn(batch_size):\n        """"""\n        Create batches of training data\n        :param batch_size: Batch Size\n        :return: Batches of training data\n        """"""\n        image_paths = glob(os.path.join(data_folder, \'image_2\', \'*.png\'))\n        label_paths = {\n            re.sub(r\'_(lane|road)_\', \'_\', os.path.basename(path)): path\n            for path in glob(os.path.join(data_folder, \'gt_image_2\', \'*_road_*.png\'))}\n        background_color = np.array([255, 0, 0])\n\n        random.shuffle(image_paths)\n        for batch_i in range(0, len(image_paths), batch_size):\n            images = []\n            gt_images = []\n            for image_file in image_paths[batch_i:batch_i+batch_size]:\n                gt_image_file = label_paths[os.path.basename(image_file)]\n\n                image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n                gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n\n                gt_bg = np.all(gt_image == background_color, axis=2)\n                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n\n                images.append(image)\n                gt_images.append(gt_image)\n\n            yield np.array(images), np.array(gt_images)\n    return get_batches_fn\n\n\ndef gen_test_output(sess, logits, keep_prob, image_pl, data_folder, image_shape):\n    """"""\n    Generate test output using the test images\n    :param sess: TF session\n    :param logits: TF Tensor for the logits\n    :param keep_prob: TF Placeholder for the dropout keep robability\n    :param image_pl: TF Placeholder for the image placeholder\n    :param data_folder: Path to the folder that contains the datasets\n    :param image_shape: Tuple - Shape of image\n    :return: Output for for each test image\n    """"""\n    for image_file in glob(os.path.join(data_folder, \'image_2\', \'*.png\')):\n        image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n\n        im_softmax = sess.run(\n            [tf.nn.softmax(logits)],\n            {keep_prob: 1.0, image_pl: [image]})\n        im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n        segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n        mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n        mask = scipy.misc.toimage(mask, mode=""RGBA"")\n        street_im = scipy.misc.toimage(image)\n        street_im.paste(mask, box=None, mask=mask)\n\n        yield os.path.basename(image_file), np.array(street_im)\n\n\ndef save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image):\n    # Make folder for current run\n    output_dir = os.path.join(runs_dir, str(time.time()))\n    if os.path.exists(output_dir):\n        shutil.rmtree(output_dir)\n    os.makedirs(output_dir)\n\n    # Run NN on test images and save them to HD\n    print(\'Training Finished. Saving test images to: {}\'.format(output_dir))\n    image_outputs = gen_test_output(\n        sess, logits, keep_prob, input_image, os.path.join(data_dir, \'data_road/testing\'), image_shape)\n    for name, image in image_outputs:\n        scipy.misc.imsave(os.path.join(output_dir, name), image)\n'"
project_12_road_segmentation/main.py,25,"b'import os\r\nimport argparse\r\nimport warnings\r\nimport tensorflow as tf\r\nfrom helper import gen_batch_function, save_inference_samples\r\nfrom distutils.version import LooseVersion\r\nfrom os.path import join, expanduser\r\nimport project_tests as tests\r\nfrom image_augmentation import perform_augmentation\r\n\r\n\r\n# Check TensorFlow Version\r\nassert LooseVersion(tf.__version__) >= LooseVersion(\'1.0\'),\\\r\n    \'Please use TensorFlow version 1.0 or newer.  You are using {}\'.format(tf.__version__)\r\nprint(\'TensorFlow Version: {}\'.format(tf.__version__))\r\n\r\n# Check for a GPU\r\nif not tf.test.gpu_device_name():\r\n    warnings.warn(\'No GPU found. Please use a GPU to train your neural network.\')\r\nelse:\r\n    print(\'Default GPU Device: {}\'.format(tf.test.gpu_device_name()))\r\n\r\n\r\ndef load_vgg(sess, vgg_path):\r\n    """"""\r\n    Load Pretrained VGG Model into TensorFlow.\r\n\r\n    :param sess: TensorFlow Session\r\n    :param vgg_path: Path to vgg folder, containing ""variables/"" and ""saved_model.pb""\r\n    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\r\n    """"""\r\n\r\n    vgg_input_tensor_name = \'image_input:0\'\r\n    vgg_keep_prob_tensor_name = \'keep_prob:0\'\r\n    vgg_layer3_out_tensor_name = \'layer3_out:0\'\r\n    vgg_layer4_out_tensor_name = \'layer4_out:0\'\r\n    vgg_layer7_out_tensor_name = \'layer7_out:0\'\r\n\r\n    tf.saved_model.loader.load(sess, [\'vgg16\'], vgg_path)\r\n    graph = tf.get_default_graph()\r\n\r\n    image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\r\n    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\r\n    layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\r\n    layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\r\n    layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\r\n\r\n    return image_input, keep_prob, layer3_out, layer4_out, layer7_out\r\n\r\n\r\ndef layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\r\n    """"""\r\n    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\r\n    For reference: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\r\n\r\n    :param vgg_layer7_out: TF Tensor for VGG Layer 3 output\r\n    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\r\n    :param vgg_layer3_out: TF Tensor for VGG Layer 7 output\r\n    :param num_classes: Number of classes to classify\r\n    :return: The Tensor for the last layer of output\r\n    """"""\r\n\r\n    kernel_regularizer = tf.contrib.layers.l2_regularizer(0.5)\r\n\r\n    # Compute logits\r\n    layer3_logits = tf.layers.conv2d(vgg_layer3_out, num_classes, kernel_size=[1, 1],\r\n                                     padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n    layer4_logits = tf.layers.conv2d(vgg_layer4_out, num_classes, kernel_size=[1, 1],\r\n                                     padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n    layer7_logits = tf.layers.conv2d(vgg_layer7_out, num_classes, kernel_size=[1, 1],\r\n                                     padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n\r\n    # Add skip connection before 4th and 7th layer\r\n    layer7_logits_up = tf.image.resize_images(layer7_logits, size=[10, 36])\r\n    layer_4_7_fused = tf.add(layer7_logits_up, layer4_logits)\r\n\r\n    # Add skip connection before (4+7)th and 3rd layer\r\n    layer_4_7_fused_up = tf.image.resize_images(layer_4_7_fused, size=[20, 72])\r\n    layer_3_4_7_fused = tf.add(layer3_logits, layer_4_7_fused_up)\r\n\r\n    # resize to original size\r\n    layer_3_4_7_up = tf.image.resize_images(layer_3_4_7_fused, size=[160, 576])\r\n    layer_3_4_7_up = tf.layers.conv2d(layer_3_4_7_up, num_classes, kernel_size=[15, 15],\r\n                                      padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n\r\n    return layer_3_4_7_up\r\n\r\n\r\ndef optimize(net_prediction, labels, learning_rate, num_classes):\r\n    """"""\r\n    Build the TensorFLow loss and optimizer operations.\r\n    :param net_prediction: TF Tensor of the last layer in the neural network\r\n    :param labels: TF Placeholder for the correct label image\r\n    :param learning_rate: TF Placeholder for the learning rate\r\n    :param num_classes: Number of classes to classify\r\n    :return: Tuple of (logits, train_op, cross_entropy_loss)\r\n    """"""\r\n\r\n    # Unroll\r\n    logits_flat = tf.reshape(net_prediction, (-1, num_classes))\r\n    labels_flat = tf.reshape(labels, (-1, num_classes))\r\n\r\n    # Define loss\r\n    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_flat, logits=logits_flat))\r\n\r\n    # Define optimization step\r\n    train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy_loss)\r\n\r\n    return logits_flat, train_step, cross_entropy_loss\r\n\r\n\r\ndef train_nn(sess, training_epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss,\r\n             image_input, labels, keep_prob, learning_rate):\r\n    """"""\r\n    Train neural network and print out the loss during training.\r\n    :param sess: TF Session\r\n    :param training_epochs: Number of epochs\r\n    :param batch_size: Batch size\r\n    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\r\n    :param train_op: TF Operation to train the neural network\r\n    :param cross_entropy_loss: TF Tensor for the amount of loss\r\n    :param image_input: TF Placeholder for input images\r\n    :param labels: TF Placeholder for label images\r\n    :param keep_prob: TF Placeholder for dropout keep probability\r\n    :param learning_rate: TF Placeholder for learning rate\r\n    """"""\r\n\r\n    # Variable initialization\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    lr = args.learning_rate\r\n\r\n    for e in range(0, training_epochs):\r\n\r\n        loss_this_epoch = 0.0\r\n\r\n        for i in range(0, args.batches_per_epoch):\r\n\r\n            # Load a batch of examples\r\n            batch_x, batch_y = next(get_batches_fn(batch_size))\r\n            if should_do_augmentation:\r\n                batch_x, batch_y = perform_augmentation(batch_x, batch_y)\r\n\r\n            _, cur_loss = sess.run(fetches=[train_op, cross_entropy_loss],\r\n                                   feed_dict={image_input: batch_x, labels: batch_y, keep_prob: 0.25,\r\n                                              learning_rate: lr})\r\n\r\n            loss_this_epoch += cur_loss\r\n\r\n        print(\'Epoch: {:02d}  -  Loss: {:.03f}\'.format(e, loss_this_epoch / args.batches_per_epoch))\r\n\r\n\r\ndef perform_tests():\r\n    tests.test_for_kitti_dataset(data_dir)\r\n    tests.test_load_vgg(load_vgg, tf)\r\n    tests.test_layers(layers)\r\n    tests.test_optimize(optimize)\r\n    tests.test_train_nn(train_nn)\r\n\r\n\r\ndef run():\r\n\r\n    num_classes = 2\r\n\r\n    image_h, image_w = (160, 576)\r\n\r\n    with tf.Session() as sess:\r\n\r\n        # Path to vgg model\r\n        vgg_path = join(data_dir, \'vgg\')\r\n\r\n        # Create function to get batches\r\n        batch_generator = gen_batch_function(join(data_dir, \'data_road/training\'), (image_h, image_w))\r\n\r\n        # Load VGG pretrained\r\n        image_input, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\r\n\r\n        # Add skip connections\r\n        output = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\r\n\r\n        # Define placeholders\r\n        labels = tf.placeholder(tf.float32, shape=[None, image_h, image_w, num_classes])\r\n        learning_rate = tf.placeholder(tf.float32, shape=[])\r\n\r\n        logits, train_op, cross_entropy_loss = optimize(output, labels, learning_rate, num_classes)\r\n\r\n        # Training parameters\r\n        train_nn(sess, args.training_epochs, args.batch_size, batch_generator, train_op, cross_entropy_loss,\r\n                 image_input, labels, keep_prob, learning_rate)\r\n\r\n        save_inference_samples(runs_dir, data_dir, sess, (image_h, image_w), logits, keep_prob, image_input)\r\n\r\n\r\ndef parse_arguments():\r\n    """"""\r\n    Parse command line arguments\r\n    """"""\r\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\r\n    parser.add_argument(\'--batch_size\', type=int, default=8, help=\'Batch size used for training\', metavar=\'\')\r\n    parser.add_argument(\'--batches_per_epoch\', type=int, default=100, help=\'Batches each training epoch\', metavar=\'\')\r\n    parser.add_argument(\'--training_epochs\', type=int, default=30, help=\'Number of training epoch\', metavar=\'\')\r\n    parser.add_argument(\'--learning_rate\', type=float, default=1e-4, help=\'Learning rate\', metavar=\'\')\r\n    parser.add_argument(\'--augmentation\', type=bool, default=True, help=\'Perform augmentation in training\', metavar=\'\')\r\n    parser.add_argument(\'--gpu\', type=int, default=0, help=\'Which GPU to use\', metavar=\'\')\r\n    return parser.parse_args()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n\r\n    data_dir = join(expanduser(""~""), \'code\', \'self-driving-car\', \'project_12_road_segmentation\', \'data\')\r\n    runs_dir = join(expanduser(""~""), \'majinbu_home\', \'road_segmentation_prediction\')\r\n\r\n    args = parse_arguments()\r\n\r\n    # Appropriately set GPU device\r\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = str(args.gpu)\r\n    print(\'Using GPU: {:02d}.\'.format(args.gpu))\r\n\r\n    # Turn off augmentation during tests\r\n    should_do_augmentation = False\r\n    perform_tests()\r\n\r\n    # Restore appropriate augmentation value\r\n    should_do_augmentation = args.augmentation\r\n    run()\r\n'"
project_12_road_segmentation/main_27.py,24,"b'""""""\r\nDirty and running file to use Python2.7\r\n\r\nDependency form helper and unittests have been removed due to compatibility issues.\r\n\r\nOnce training is done, code will be moved to `main.py`\r\n""""""\r\nfrom __future__ import division\r\nimport tensorflow as tf\r\nimport warnings\r\nfrom distutils.version import LooseVersion\r\nfrom os.path import join, expanduser\r\nimport re\r\nimport random\r\nimport shutil\r\nimport numpy as np\r\nimport os.path\r\nimport scipy.misc\r\nimport time\r\nfrom glob import glob\r\n\r\n\r\ndef gen_batch_function(data_folder, image_shape):\r\n    """"""\r\n    Generate function to create batches of training data\r\n    :param data_folder: Path to folder that contains all the datasets\r\n    :param image_shape: Tuple - Shape of image\r\n    :return:\r\n    """"""\r\n    def get_batches_fn(batch_size):\r\n        """"""\r\n        Create batches of training data\r\n        :param batch_size: Batch Size\r\n        :return: Batches of training data\r\n        """"""\r\n        image_paths = glob(os.path.join(data_folder, \'image_2\', \'*.png\'))\r\n        label_paths = {\r\n            re.sub(r\'_(lane|road)_\', \'_\', os.path.basename(path)): path\r\n            for path in glob(os.path.join(data_folder, \'gt_image_2\', \'*_road_*.png\'))}\r\n        background_color = np.array([255, 0, 0])\r\n\r\n        random.shuffle(image_paths)\r\n        for batch_i in range(0, len(image_paths), batch_size):\r\n            images = []\r\n            gt_images = []\r\n            for image_file in image_paths[batch_i:batch_i+batch_size]:\r\n                gt_image_file = label_paths[os.path.basename(image_file)]\r\n\r\n                image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\r\n                gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\r\n\r\n                gt_bg = np.all(gt_image == background_color, axis=2)\r\n                h, w = gt_bg.shape\r\n                gt_bg = gt_bg.reshape(h, w, 1)\r\n                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\r\n\r\n                images.append(image)\r\n                gt_images.append(gt_image)\r\n\r\n            yield np.array(images), np.array(gt_images)\r\n    return get_batches_fn\r\n\r\n\r\ndef gen_test_output(sess, logits, keep_prob, image_pl, data_folder, image_shape):\r\n    """"""\r\n    Generate test output using the test images\r\n    :param sess: TF session\r\n    :param logits: TF Tensor for the logits\r\n    :param keep_prob: TF Placeholder for the dropout keep robability\r\n    :param image_pl: TF Placeholder for the image placeholder\r\n    :param data_folder: Path to the folder that contains the datasets\r\n    :param image_shape: Tuple - Shape of image\r\n    :return: Output for for each test image\r\n    """"""\r\n    for image_file in glob(os.path.join(data_folder, \'image_2\', \'*.png\')):\r\n        image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\r\n\r\n        im_softmax = sess.run(\r\n            [tf.nn.softmax(logits)],\r\n            {keep_prob: 1.0, image_pl: [image]})\r\n        im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\r\n        segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\r\n        mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\r\n        mask = scipy.misc.toimage(mask, mode=""RGBA"")\r\n        street_im = scipy.misc.toimage(image)\r\n        street_im.paste(mask, box=None, mask=mask)\r\n\r\n        yield os.path.basename(image_file), np.array(street_im)\r\n\r\n\r\ndef save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image):\r\n    # Make folder for current run\r\n    output_dir = os.path.join(runs_dir, str(time.time()))\r\n    if os.path.exists(output_dir):\r\n        shutil.rmtree(output_dir)\r\n    os.makedirs(output_dir)\r\n\r\n    # Run NN on test images and save them to HD\r\n    print(\'Training Finished. Saving test images to: {}\'.format(output_dir))\r\n    image_outputs = gen_test_output(\r\n        sess, logits, keep_prob, input_image, os.path.join(data_dir, \'data_road/testing\'), image_shape)\r\n    for name, image in image_outputs:\r\n        scipy.misc.imsave(os.path.join(output_dir, name), image)\r\n\r\n\r\n# Check TensorFlow Version\r\nassert LooseVersion(tf.__version__) >= LooseVersion(\'1.0\'), \'Please use TensorFlow version 1.0 or newer.  You are using {}\'.format(tf.__version__)\r\nprint(\'TensorFlow Version: {}\'.format(tf.__version__))\r\n\r\n# Check for a GPU\r\nif not tf.test.gpu_device_name():\r\n    warnings.warn(\'No GPU found. Please use a GPU to train your neural network.\')\r\nelse:\r\n    print(\'Default GPU Device: {}\'.format(tf.test.gpu_device_name()))\r\n\r\n\r\ndef load_vgg(sess, vgg_path):\r\n    """"""\r\n    Load Pretrained VGG Model into TensorFlow.\r\n\r\n    :param sess: TensorFlow Session\r\n    :param vgg_path: Path to vgg folder, containing ""variables/"" and ""saved_model.pb""\r\n    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\r\n    """"""\r\n\r\n    vgg_input_tensor_name = \'image_input:0\'\r\n    vgg_keep_prob_tensor_name = \'keep_prob:0\'\r\n    vgg_layer3_out_tensor_name = \'layer3_out:0\'\r\n    vgg_layer4_out_tensor_name = \'layer4_out:0\'\r\n    vgg_layer7_out_tensor_name = \'layer7_out:0\'\r\n\r\n    tf.saved_model.loader.load(sess, [\'vgg16\'], vgg_path)\r\n    graph = tf.get_default_graph()\r\n\r\n    image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\r\n    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\r\n    layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\r\n    layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\r\n    layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\r\n    \r\n    return image_input, keep_prob, layer3_out, layer4_out, layer7_out\r\n\r\n\r\ndef layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\r\n    """"""\r\n    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\r\n    For reference: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\r\n\r\n    :param vgg_layer7_out: TF Tensor for VGG Layer 3 output\r\n    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\r\n    :param vgg_layer3_out: TF Tensor for VGG Layer 7 output\r\n    :param num_classes: Number of classes to classify\r\n    :return: The Tensor for the last layer of output\r\n    """"""\r\n\r\n    kernel_regularizer = tf.contrib.layers.l2_regularizer(0.5)\r\n\r\n    # Compute logits\r\n    layer3_logits = tf.layers.conv2d(vgg_layer3_out, num_classes, kernel_size=[1, 1],\r\n                                     padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n    layer4_logits = tf.layers.conv2d(vgg_layer4_out, num_classes, kernel_size=[1, 1],\r\n                                     padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n    layer7_logits = tf.layers.conv2d(vgg_layer7_out, num_classes, kernel_size=[1, 1],\r\n                                     padding=\'same\', kernel_regularizer=kernel_regularizer)\r\n\r\n    # Add skip connection before 4th and 7th layer\r\n    layer7_logits_up   = tf.image.resize_images(layer7_logits, size=[10, 36])\r\n    layer_4_7_fused = tf.add(layer7_logits_up, layer4_logits)\r\n\r\n    # Add skip connection before (4+7)th and 3rd layer\r\n    layer_4_7_fused_up = tf.image.resize_images(layer_4_7_fused, size=[20, 72])\r\n    layer_3_4_7_fused = tf.add(layer3_logits, layer_4_7_fused_up)\r\n\r\n    # resize to original size\r\n    layer_3_4_7_up = tf.image.resize_images(layer_3_4_7_fused, size=[160, 576])\r\n\r\n    return layer_3_4_7_up\r\n\r\n\r\ndef optimize(net_prediction, labels, learning_rate, num_classes):\r\n    """"""\r\n    Build the TensorFLow loss and optimizer operations.\r\n    :param net_prediction: TF Tensor of the last layer in the neural network\r\n    :param labels: TF Placeholder for the correct label image\r\n    :param learning_rate: TF Placeholder for the learning rate\r\n    :param num_classes: Number of classes to classify\r\n    :return: Tuple of (logits, train_op, cross_entropy_loss)\r\n    """"""\r\n\r\n    # Unroll\r\n    logits_flat = tf.reshape(net_prediction, (-1, num_classes))\r\n    labels_flat = tf.reshape(labels, (-1, num_classes))\r\n\r\n    # Define loss\r\n    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_flat, logits=logits_flat))\r\n\r\n    # Define optimization step\r\n    train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy_loss)\r\n\r\n    return logits_flat, train_step, cross_entropy_loss\r\n\r\n\r\ndef train_nn(sess, training_epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss,\r\n             image_input, labels, keep_prob, learning_rate):\r\n    """"""\r\n    Train neural network and print out the loss during training.\r\n    :param sess: TF Session\r\n    :param training_epochs: Number of epochs\r\n    :param batch_size: Batch size\r\n    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\r\n    :param train_op: TF Operation to train the neural network\r\n    :param cross_entropy_loss: TF Tensor for the amount of loss\r\n    :param image_input: TF Placeholder for input images\r\n    :param labels: TF Placeholder for label images\r\n    :param keep_prob: TF Placeholder for dropout keep probability\r\n    :param learning_rate: TF Placeholder for learning rate\r\n    """"""\r\n\r\n    # Variable initialization\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    lr = 1e-4\r\n    examples_each_epoch = 100\r\n\r\n    for e in range(0, training_epochs):\r\n\r\n        loss_this_epoch = 0.0\r\n\r\n        for i in range(0, examples_each_epoch):\r\n\r\n            # Load a batch of examples\r\n            batch_x, batch_y = next(get_batches_fn(batch_size))\r\n\r\n            _, cur_loss = sess.run(fetches=[train_op, cross_entropy_loss],\r\n                                   feed_dict={image_input: batch_x, labels: batch_y, keep_prob: 0.25, learning_rate: lr})\r\n\r\n            loss_this_epoch += cur_loss\r\n\r\n        print(\'Epoch: {:02d}  -  Loss: {:.03f}\'.format(e, loss_this_epoch / examples_each_epoch))\r\n\r\n\r\ndef run():\r\n\r\n    num_classes = 2\r\n\r\n    image_h, image_w = (160, 576)\r\n\r\n    with tf.Session() as sess:\r\n\r\n        # Path to vgg model\r\n        vgg_path = join(data_dir, \'vgg\')\r\n\r\n        # Create function to get batches\r\n        batch_generator = gen_batch_function(join(data_dir, \'data_road/training\'), (image_h, image_w))\r\n\r\n        # Load VGG pretrained\r\n        image_input, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\r\n\r\n        # Add skip connections\r\n        output = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\r\n\r\n        # Define placeholders\r\n        labels = tf.placeholder(tf.float32, shape=[None, image_h, image_w, num_classes])\r\n        learning_rate = tf.placeholder(tf.float32, shape=[])\r\n\r\n        logits, train_op, cross_entropy_loss = optimize(output, labels, learning_rate, num_classes)\r\n\r\n        # Training parameters\r\n        training_epochs = 40\r\n        batch_size      = 8\r\n\r\n        train_nn(sess, training_epochs, batch_size, batch_generator, train_op, cross_entropy_loss,\r\n                 image_input, labels, keep_prob, learning_rate)\r\n\r\n        save_inference_samples(runs_dir, data_dir, sess, (image_h, image_w), logits, keep_prob, image_input)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n\r\n    data_dir = join(expanduser(""~""), \'code\', \'self-driving-car\', \'project_12_road_segmentation\', \'data\')\r\n    runs_dir = join(expanduser(""~""), \'majinbu_home\', \'road_segmentation_prediction\')\r\n    # runs_dir = join(expanduser(""~""), \'code\', \'self-driving-car\', \'project_12_road_segmentation\', \'runs\')\r\n\r\n    run()\r\n'"
project_12_road_segmentation/project_tests.py,25,"b'import sys\nimport os\nfrom copy import deepcopy\nfrom glob import glob\nfrom unittest import mock\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef test_safe(func):\n    """"""\n    Isolate tests\n    """"""\n    def func_wrapper(*args):\n        with tf.Graph().as_default():\n            result = func(*args)\n        print(\'Tests Passed\')\n        return result\n\n    return func_wrapper\n\n\ndef _prevent_print(function, params):\n    sys.stdout = open(os.devnull, ""w"")\n    function(**params)\n    sys.stdout = sys.__stdout__\n\n\ndef _assert_tensor_shape(tensor, shape, display_name):\n    assert tf.assert_rank(tensor, len(shape), message=\'{} has wrong rank\'.format(display_name))\n\n    tensor_shape = tensor.get_shape().as_list() if len(shape) else []\n\n    wrong_dimension = [ten_dim for ten_dim, cor_dim in zip(tensor_shape, shape)\n                       if cor_dim is not None and ten_dim != cor_dim]\n    assert not wrong_dimension, \\\n        \'{} has wrong shape.  Found {}\'.format(display_name, tensor_shape)\n\n\nclass TmpMock(object):\n    """"""\n    Mock a attribute.  Restore attribute when exiting scope.\n    """"""\n    def __init__(self, module, attrib_name):\n        self.original_attrib = deepcopy(getattr(module, attrib_name))\n        setattr(module, attrib_name, mock.MagicMock())\n        self.module = module\n        self.attrib_name = attrib_name\n\n    def __enter__(self):\n        return getattr(self.module, self.attrib_name)\n\n    def __exit__(self, type, value, traceback):\n        setattr(self.module, self.attrib_name, self.original_attrib)\n\n\n@test_safe\ndef test_load_vgg(load_vgg, tf_module):\n    with TmpMock(tf_module.saved_model.loader, \'load\') as mock_load_model:\n        vgg_path = \'\'\n        sess = tf.Session()\n        test_input_image = tf.placeholder(tf.float32, name=\'image_input\')\n        test_keep_prob = tf.placeholder(tf.float32, name=\'keep_prob\')\n        test_vgg_layer3_out = tf.placeholder(tf.float32, name=\'layer3_out\')\n        test_vgg_layer4_out = tf.placeholder(tf.float32, name=\'layer4_out\')\n        test_vgg_layer7_out = tf.placeholder(tf.float32, name=\'layer7_out\')\n\n        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n\n        assert mock_load_model.called, \\\n            \'tf.saved_model.loader.load() not called\'\n        assert mock_load_model.call_args == mock.call(sess, [\'vgg16\'], vgg_path), \\\n            \'tf.saved_model.loader.load() called with wrong arguments.\'\n\n        assert input_image == test_input_image, \'input_image is the wrong object\'\n        assert keep_prob == test_keep_prob, \'keep_prob is the wrong object\'\n        assert vgg_layer3_out == test_vgg_layer3_out, \'layer3_out is the wrong object\'\n        assert vgg_layer4_out == test_vgg_layer4_out, \'layer4_out is the wrong object\'\n        assert vgg_layer7_out == test_vgg_layer7_out, \'layer7_out is the wrong object\'\n\n\n@test_safe\ndef test_layers(layers):\n    num_classes = 2\n    vgg_layer3_out = tf.placeholder(tf.float32, [None, None, None, 256])\n    vgg_layer4_out = tf.placeholder(tf.float32, [None, None, None, 512])\n    vgg_layer7_out = tf.placeholder(tf.float32, [None, None, None, 4096])\n    layers_output = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n\n    _assert_tensor_shape(layers_output, [None, None, None, num_classes], \'Layers Output\')\n\n\n@test_safe\ndef test_optimize(optimize):\n    num_classes = 2\n    shape = [2, 3, 4, num_classes]\n    layers_output = tf.Variable(tf.zeros(shape))\n    correct_label = tf.placeholder(tf.float32, [None, None, None, num_classes])\n    learning_rate = tf.placeholder(tf.float32)\n    logits, train_op, cross_entropy_loss = optimize(layers_output, correct_label, learning_rate, num_classes)\n\n    _assert_tensor_shape(logits, [2*3*4, num_classes], \'Logits\')\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run([train_op], {correct_label: np.arange(np.prod(shape)).reshape(shape), learning_rate: 10})\n        test, loss = sess.run([layers_output, cross_entropy_loss], {correct_label: np.arange(np.prod(shape)).reshape(shape)})\n\n    assert test.min() != 0 or test.max() != 0, \'Training operation not changing weights.\'\n\n\n@test_safe\ndef test_train_nn(train_nn):\n    epochs = 1\n    batch_size = 2\n\n    def get_batches_fn(batch_size_parm):\n        shape = [batch_size_parm, 2, 3, 3]\n        yield np.arange(np.prod(shape)).reshape(shape)\n\n    train_op = tf.constant(0)\n    cross_entropy_loss = tf.constant(10.11)\n    input_image = tf.placeholder(tf.float32, name=\'input_image\')\n    correct_label = tf.placeholder(tf.float32, name=\'correct_label\')\n    keep_prob = tf.placeholder(tf.float32, name=\'keep_prob\')\n    learning_rate = tf.placeholder(tf.float32, name=\'learning_rate\')\n    with tf.Session() as sess:\n        parameters = {\n            \'sess\': sess,\n            \'training_epochs\': epochs,\n            \'batch_size\': batch_size,\n            \'get_batches_fn\': get_batches_fn,\n            \'train_op\': train_op,\n            \'cross_entropy_loss\': cross_entropy_loss,\n            \'image_input\': input_image,\n            \'labels\': correct_label,\n            \'keep_prob\': keep_prob,\n            \'learning_rate\': learning_rate}\n        _prevent_print(train_nn, parameters)\n\n\n@test_safe\ndef test_for_kitti_dataset(data_dir):\n    kitti_dataset_path = os.path.join(data_dir, \'data_road\')\n    training_labels_count = len(glob(os.path.join(kitti_dataset_path, \'training/gt_image_2/*_road_*.png\')))\n    training_images_count = len(glob(os.path.join(kitti_dataset_path, \'training/image_2/*.png\')))\n    testing_images_count = len(glob(os.path.join(kitti_dataset_path, \'testing/image_2/*.png\')))\n\n    assert not (training_images_count == training_labels_count == testing_images_count == 0),\\\n        \'Kitti dataset not found. Extract Kitti dataset in {}\'.format(kitti_dataset_path)\n    assert training_images_count == 289, \'Expected 289 training images, found {} images.\'.format(training_images_count)\n    assert training_labels_count == 289, \'Expected 289 training labels, found {} labels.\'.format(training_labels_count)\n    assert testing_images_count == 290, \'Expected 290 testing images, found {} images.\'.format(testing_images_count)\n'"
