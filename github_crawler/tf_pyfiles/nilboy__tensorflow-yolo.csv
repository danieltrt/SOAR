file_path,api_count,code
demo.py,3,"b'import sys\r\n\r\nsys.path.append(\'./\')\r\n\r\nfrom yolo.net.yolo_tiny_net import YoloTinyNet \r\nimport tensorflow as tf \r\nimport cv2\r\nimport numpy as np\r\n\r\nclasses_name =  [""aeroplane"", ""bicycle"", ""bird"", ""boat"", ""bottle"", ""bus"", ""car"", ""cat"", ""chair"", ""cow"", ""diningtable"", ""dog"", ""horse"", ""motorbike"", ""person"", ""pottedplant"", ""sheep"", ""sofa"", ""train"",""tvmonitor""]\r\n\r\n\r\ndef process_predicts(predicts):\r\n  p_classes = predicts[0, :, :, 0:20]\r\n  C = predicts[0, :, :, 20:22]\r\n  coordinate = predicts[0, :, :, 22:]\r\n\r\n  p_classes = np.reshape(p_classes, (7, 7, 1, 20))\r\n  C = np.reshape(C, (7, 7, 2, 1))\r\n\r\n  P = C * p_classes\r\n\r\n  #print P[5,1, 0, :]\r\n\r\n  index = np.argmax(P)\r\n\r\n  index = np.unravel_index(index, P.shape)\r\n\r\n  class_num = index[3]\r\n\r\n  coordinate = np.reshape(coordinate, (7, 7, 2, 4))\r\n\r\n  max_coordinate = coordinate[index[0], index[1], index[2], :]\r\n\r\n  xcenter = max_coordinate[0]\r\n  ycenter = max_coordinate[1]\r\n  w = max_coordinate[2]\r\n  h = max_coordinate[3]\r\n\r\n  xcenter = (index[1] + xcenter) * (448/7.0)\r\n  ycenter = (index[0] + ycenter) * (448/7.0)\r\n\r\n  w = w * 448\r\n  h = h * 448\r\n\r\n  xmin = xcenter - w/2.0\r\n  ymin = ycenter - h/2.0\r\n\r\n  xmax = xmin + w\r\n  ymax = ymin + h\r\n\r\n  return xmin, ymin, xmax, ymax, class_num\r\n\r\ncommon_params = {\'image_size\': 448, \'num_classes\': 20, \r\n                \'batch_size\':1}\r\nnet_params = {\'cell_size\': 7, \'boxes_per_cell\':2, \'weight_decay\': 0.0005}\r\n\r\nnet = YoloTinyNet(common_params, net_params, test=True)\r\n\r\nimage = tf.placeholder(tf.float32, (1, 448, 448, 3))\r\npredicts = net.inference(image)\r\n\r\nsess = tf.Session()\r\n\r\nnp_img = cv2.imread(\'cat.jpg\')\r\nresized_img = cv2.resize(np_img, (448, 448))\r\nnp_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\r\n\r\n\r\nnp_img = np_img.astype(np.float32)\r\n\r\nnp_img = np_img / 255.0 * 2 - 1\r\nnp_img = np.reshape(np_img, (1, 448, 448, 3))\r\n\r\nsaver = tf.train.Saver(net.trainable_collection)\r\n\r\nsaver.restore(sess, \'models/pretrain/yolo_tiny.ckpt\')\r\n\r\nnp_predict = sess.run(predicts, feed_dict={image: np_img})\r\n\r\nxmin, ymin, xmax, ymax, class_num = process_predicts(np_predict)\r\nclass_name = classes_name[class_num]\r\ncv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255))\r\ncv2.putText(resized_img, class_name, (int(xmin), int(ymin)), 2, 1.5, (0, 0, 255))\r\ncv2.imwrite(\'cat_out.jpg\', resized_img)\r\nsess.close()\r\n'"
tools/preprocess_pascal_voc.py,0,"b'""""""preprocess pascal_voc data\r\n""""""\r\nimport os\r\nimport xml.etree.ElementTree as ET \r\nimport struct\r\nimport numpy as np\r\n\r\n\r\nclasses_name =  [""aeroplane"", ""bicycle"", ""bird"", ""boat"", ""bottle"", ""bus"", ""car"", ""cat"", ""chair"", ""cow"", ""diningtable"", ""dog"", ""horse"", ""motorbike"", ""person"", ""pottedplant"", ""sheep"", ""sofa"", ""train"",""tvmonitor""]\r\n\r\n\r\nclasses_num = {\'aeroplane\': 0, \'bicycle\': 1, \'bird\': 2, \'boat\': 3, \'bottle\': 4, \'bus\': 5,\r\n    \'car\': 6, \'cat\': 7, \'chair\': 8, \'cow\': 9, \'diningtable\': 10, \'dog\': 11,\r\n    \'horse\': 12, \'motorbike\': 13, \'person\': 14, \'pottedplant\': 15, \'sheep\': 16,\r\n    \'sofa\': 17, \'train\': 18, \'tvmonitor\': 19}\r\n\r\nYOLO_ROOT = os.path.abspath(\'./\')\r\nDATA_PATH = os.path.join(YOLO_ROOT, \'data/VOCdevkit2007\')\r\nOUTPUT_PATH = os.path.join(YOLO_ROOT, \'data/pascal_voc.txt\')\r\n\r\ndef parse_xml(xml_file):\r\n  """"""parse xml_file\r\n\r\n  Args:\r\n    xml_file: the input xml file path\r\n\r\n  Returns:\r\n    image_path: string\r\n    labels: list of [xmin, ymin, xmax, ymax, class]\r\n  """"""\r\n  tree = ET.parse(xml_file)\r\n  root = tree.getroot()\r\n  image_path = \'\'\r\n  labels = []\r\n\r\n  for item in root:\r\n    if item.tag == \'filename\':\r\n      image_path = os.path.join(DATA_PATH, \'VOC2007/JPEGImages\', item.text)\r\n    elif item.tag == \'object\':\r\n      obj_name = item[0].text\r\n      obj_num = classes_num[obj_name]\r\n      xmin = int(item[4][0].text)\r\n      ymin = int(item[4][1].text)\r\n      xmax = int(item[4][2].text)\r\n      ymax = int(item[4][3].text)\r\n      labels.append([xmin, ymin, xmax, ymax, obj_num])\r\n    \r\n  return image_path, labels\r\n\r\ndef convert_to_string(image_path, labels):\r\n  """"""convert image_path, lables to string \r\n  Returns:\r\n    string \r\n  """"""\r\n  out_string = \'\'\r\n  out_string += image_path\r\n  for label in labels:\r\n    for i in label:\r\n      out_string += \' \' + str(i)\r\n  out_string += \'\\n\'\r\n  return out_string\r\n\r\ndef main():\r\n  out_file = open(OUTPUT_PATH, \'w\')\r\n\r\n  xml_dir = DATA_PATH + \'/VOC2007/Annotations/\'\r\n\r\n  xml_list = os.listdir(xml_dir)\r\n  xml_list = [xml_dir + temp for temp in xml_list]\r\n\r\n  for xml in xml_list:\r\n    try:\r\n      image_path, labels = parse_xml(xml)\r\n      record = convert_to_string(image_path, labels)\r\n      out_file.write(record)\r\n    except Exception:\r\n      pass\r\n\r\n  out_file.close()\r\n\r\nif __name__ == \'__main__\':\r\n  main()'"
tools/train.py,0,"b'import sys\r\nfrom optparse import OptionParser\r\n\r\nsys.path.append(\'./\')\r\n\r\nimport yolo\r\nfrom yolo.utils.process_config import process_config\r\n\r\nparser = OptionParser()\r\nparser.add_option(""-c"", ""--conf"", dest=""configure"",  \r\n                  help=""configure filename"")\r\n(options, args) = parser.parse_args() \r\nif options.configure:\r\n  conf_file = str(options.configure)\r\nelse:\r\n  print(\'please sspecify --conf configure filename\')\r\n  exit(0)\r\n\r\ncommon_params, dataset_params, net_params, solver_params = process_config(conf_file)\r\ndataset = eval(dataset_params[\'name\'])(common_params, dataset_params)\r\nnet = eval(net_params[\'name\'])(common_params, net_params)\r\nsolver = eval(solver_params[\'name\'])(dataset, net, common_params, solver_params)\r\nsolver.solve()'"
yolo/__init__.py,0,b'import dataset\nimport net\nimport solver\n'
yolo/dataset/__init__.py,0,b'import dataset\nimport text_dataset\n'
yolo/dataset/dataset.py,0,"b'""""""DataSet  base class \r\n""""""\r\nclass DataSet(object):\r\n  """"""Base DataSet\r\n  """"""\r\n  def __init__(self, common_params, dataset_params):\r\n    """"""\r\n    common_params: A params dict \r\n    dataset_params: A params dict\r\n    """"""\r\n    raise NotImplementedError\r\n\r\n  def batch(self):\r\n    """"""Get batch\r\n    """"""\r\n    raise NotImplementedError'"
yolo/dataset/text_dataset.py,0,"b'from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport math\r\nimport random\r\nimport cv2\r\nimport numpy as np\r\nfrom Queue import Queue \r\nfrom threading import Thread\r\n\r\nfrom yolo.dataset.dataset import DataSet \r\n\r\nclass TextDataSet(DataSet):\r\n  """"""TextDataSet\r\n  process text input file dataset \r\n  text file format:\r\n    image_path xmin1 ymin1 xmax1 ymax1 class1 xmin2 ymin2 xmax2 ymax2 class2\r\n  """"""\r\n\r\n  def __init__(self, common_params, dataset_params):\r\n    """"""\r\n    Args:\r\n      common_params: A dict\r\n      dataset_params: A dict\r\n    """"""\r\n    #process params\r\n    self.data_path = str(dataset_params[\'path\'])\r\n    self.width = int(common_params[\'image_size\'])\r\n    self.height = int(common_params[\'image_size\'])\r\n    self.batch_size = int(common_params[\'batch_size\'])\r\n    self.thread_num = int(dataset_params[\'thread_num\'])\r\n    self.max_objects = int(common_params[\'max_objects_per_image\'])\r\n\r\n    #record and image_label queue\r\n    self.record_queue = Queue(maxsize=10000)\r\n    self.image_label_queue = Queue(maxsize=512)\r\n\r\n    self.record_list = []  \r\n\r\n    # filling the record_list\r\n    input_file = open(self.data_path, \'r\')\r\n\r\n    for line in input_file:\r\n      line = line.strip()\r\n      ss = line.split(\' \')\r\n      ss[1:] = [float(num) for num in ss[1:]]\r\n      self.record_list.append(ss)\r\n\r\n    self.record_point = 0\r\n    self.record_number = len(self.record_list)\r\n\r\n    self.num_batch_per_epoch = int(self.record_number / self.batch_size)\r\n\r\n    t_record_producer = Thread(target=self.record_producer)\r\n    t_record_producer.daemon = True \r\n    t_record_producer.start()\r\n\r\n    for i in range(self.thread_num):\r\n      t = Thread(target=self.record_customer)\r\n      t.daemon = True\r\n      t.start() \r\n\r\n  def record_producer(self):\r\n    """"""record_queue\'s processor\r\n    """"""\r\n    while True:\r\n      if self.record_point % self.record_number == 0:\r\n        random.shuffle(self.record_list)\r\n        self.record_point = 0\r\n      self.record_queue.put(self.record_list[self.record_point])\r\n      self.record_point += 1\r\n\r\n  def record_process(self, record):\r\n    """"""record process \r\n    Args: record \r\n    Returns:\r\n      image: 3-D ndarray\r\n      labels: 2-D list [self.max_objects, 5] (xcenter, ycenter, w, h, class_num)\r\n      object_num:  total object number  int \r\n    """"""\r\n    image = cv2.imread(record[0])\r\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n    h = image.shape[0]\r\n    w = image.shape[1]\r\n\r\n    width_rate = self.width * 1.0 / w \r\n    height_rate = self.height * 1.0 / h \r\n\r\n    image = cv2.resize(image, (self.height, self.width))\r\n\r\n    labels = [[0, 0, 0, 0, 0]] * self.max_objects\r\n    i = 1\r\n    object_num = 0\r\n    while i < len(record):\r\n      xmin = record[i]\r\n      ymin = record[i + 1]\r\n      xmax = record[i + 2]\r\n      ymax = record[i + 3]\r\n      class_num = record[i + 4]\r\n\r\n      xcenter = (xmin + xmax) * 1.0 / 2 * width_rate\r\n      ycenter = (ymin + ymax) * 1.0 / 2 * height_rate\r\n\r\n      box_w = (xmax - xmin) * width_rate\r\n      box_h = (ymax - ymin) * height_rate\r\n\r\n      labels[object_num] = [xcenter, ycenter, box_w, box_h, class_num]\r\n      object_num += 1\r\n      i += 5\r\n      if object_num >= self.max_objects:\r\n        break\r\n    return [image, labels, object_num]\r\n\r\n  def record_customer(self):\r\n    """"""record queue\'s customer \r\n    """"""\r\n    while True:\r\n      item = self.record_queue.get()\r\n      out = self.record_process(item)\r\n      self.image_label_queue.put(out)\r\n\r\n  def batch(self):\r\n    """"""get batch\r\n    Returns:\r\n      images: 4-D ndarray [batch_size, height, width, 3]\r\n      labels: 3-D ndarray [batch_size, max_objects, 5]\r\n      objects_num: 1-D ndarray [batch_size]\r\n    """"""\r\n    images = []\r\n    labels = []\r\n    objects_num = []\r\n    for i in range(self.batch_size):\r\n      image, label, object_num = self.image_label_queue.get()\r\n      images.append(image)\r\n      labels.append(label)\r\n      objects_num.append(object_num)\r\n    images = np.asarray(images, dtype=np.float32)\r\n    images = images/255 * 2 - 1\r\n    labels = np.asarray(labels, dtype=np.float32)\r\n    objects_num = np.asarray(objects_num, dtype=np.int32)\r\n    return images, labels, objects_num'"
yolo/net/__init__.py,0,b'import net\r\nimport yolo_net\r\nimport yolo_tiny_net'
yolo/net/net.py,18,"b'from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport re\r\n\r\nclass Net(object):\r\n  """"""Base Net class \r\n  """"""\r\n  def __init__(self, common_params, net_params):\r\n    """"""\r\n    common_params: a params dict\r\n    net_params: a params dict\r\n    """"""\r\n    #pretrained variable collection\r\n    self.pretrained_collection = []\r\n    #trainable variable collection\r\n    self.trainable_collection = []\r\n\r\n  def _variable_on_cpu(self, name, shape, initializer, pretrain=True, train=True):\r\n    """"""Helper to create a Variable stored on CPU memory.\r\n\r\n    Args:\r\n      name: name of the Variable\r\n      shape: list of ints\r\n      initializer: initializer of Variable\r\n\r\n    Returns:\r\n      Variable Tensor\r\n    """"""\r\n    with tf.device(\'/cpu:0\'):\r\n      var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\r\n      if pretrain:\r\n        self.pretrained_collection.append(var)\r\n      if train:\r\n        self.trainable_collection.append(var)\r\n    return var \r\n\r\n\r\n  def _variable_with_weight_decay(self, name, shape, stddev, wd, pretrain=True, train=True):\r\n    """"""Helper to create an initialized Variable with weight decay.\r\n\r\n    Note that the Variable is initialized with truncated normal distribution\r\n    A weight decay is added only if one is specified.\r\n\r\n    Args:\r\n      name: name of the variable \r\n      shape: list of ints\r\n      stddev: standard devision of a truncated Gaussian\r\n      wd: add L2Loss weight decay multiplied by this float. If None, weight \r\n      decay is not added for this Variable.\r\n\r\n   Returns:\r\n      Variable Tensor \r\n    """"""\r\n    var = self._variable_on_cpu(name, shape,\r\n      tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32), pretrain, train)\r\n    if wd is not None:\r\n      weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=\'weight_loss\')\r\n      tf.add_to_collection(\'losses\', weight_decay)\r\n    return var \r\n\r\n  def conv2d(self, scope, input, kernel_size, stride=1, pretrain=True, train=True):\r\n    """"""convolutional layer\r\n\r\n    Args:\r\n      input: 4-D tensor [batch_size, height, width, depth]\r\n      scope: variable_scope name \r\n      kernel_size: [k_height, k_width, in_channel, out_channel]\r\n      stride: int32\r\n    Return:\r\n      output: 4-D tensor [batch_size, height/stride, width/stride, out_channels]\r\n    """"""\r\n    with tf.variable_scope(scope) as scope:\r\n      kernel = self._variable_with_weight_decay(\'weights\', \r\n                                      shape=kernel_size,\r\n                                      stddev=5e-2,\r\n                                      wd=self.weight_decay, pretrain=pretrain, train=train)\r\n      conv = tf.nn.conv2d(input, kernel, [1, stride, stride, 1], padding=\'SAME\')\r\n      biases = self._variable_on_cpu(\'biases\', kernel_size[3:], tf.constant_initializer(0.0), pretrain, train)\r\n      bias = tf.nn.bias_add(conv, biases)\r\n      conv1 = self.leaky_relu(bias)\r\n\r\n    return conv1\r\n\r\n\r\n  def max_pool(self, input, kernel_size, stride):\r\n    """"""max_pool layer\r\n\r\n    Args:\r\n      input: 4-D tensor [batch_zie, height, width, depth]\r\n      kernel_size: [k_height, k_width]\r\n      stride: int32\r\n    Return:\r\n      output: 4-D tensor [batch_size, height/stride, width/stride, depth]\r\n    """"""\r\n    return tf.nn.max_pool(input, ksize=[1, kernel_size[0], kernel_size[1], 1], strides=[1, stride, stride, 1],\r\n                  padding=\'SAME\')\r\n\r\n  def local(self, scope, input, in_dimension, out_dimension, leaky=True, pretrain=True, train=True):\r\n    """"""Fully connection layer\r\n\r\n    Args:\r\n      scope: variable_scope name\r\n      input: [batch_size, ???]\r\n      out_dimension: int32\r\n    Return:\r\n      output: 2-D tensor [batch_size, out_dimension]\r\n    """"""\r\n    with tf.variable_scope(scope) as scope:\r\n      reshape = tf.reshape(input, [tf.shape(input)[0], -1])\r\n\r\n      weights = self._variable_with_weight_decay(\'weights\', shape=[in_dimension, out_dimension],\r\n                          stddev=0.04, wd=self.weight_decay, pretrain=pretrain, train=train)\r\n      biases = self._variable_on_cpu(\'biases\', [out_dimension], tf.constant_initializer(0.0), pretrain, train)\r\n      local = tf.matmul(reshape, weights) + biases\r\n\r\n      if leaky:\r\n        local = self.leaky_relu(local)\r\n      else:\r\n        local = tf.identity(local, name=scope.name)\r\n\r\n    return local\r\n\r\n  def leaky_relu(self, x, alpha=0.1, dtype=tf.float32):\r\n    """"""leaky relu \r\n    if x > 0:\r\n      return x\r\n    else:\r\n      return alpha * x\r\n    Args:\r\n      x : Tensor\r\n      alpha: float\r\n    Return:\r\n      y : Tensor\r\n    """"""\r\n    x = tf.cast(x, dtype=dtype)\r\n    bool_mask = (x > 0)\r\n    mask = tf.cast(bool_mask, dtype=dtype)\r\n    return 1.0 * mask * x + alpha * (1 - mask) * x\r\n\r\n  def inference(self, images):\r\n    """"""Build the yolo model\r\n\r\n    Args:\r\n      images:  4-D tensor [batch_size, image_height, image_width, channels]\r\n    Returns:\r\n      predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\r\n    """"""\r\n    raise NotImplementedError\r\n\r\n  def loss(self, predicts, labels, objects_num):\r\n    """"""Add Loss to all the trainable variables\r\n\r\n    Args:\r\n      predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\r\n      ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\r\n      labels  : 3-D tensor of [batch_size, max_objects, 5]\r\n      objects_num: 1-D tensor [batch_size]\r\n    """"""\r\n    raise NotImplementedError'"
yolo/net/yolo_net.py,64,"b'from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport re\r\n\r\nfrom yolo.net.net import Net \r\n\r\nclass YoloNet(Net):\r\n\r\n  def __init__(self, common_params, net_params, test=False):\r\n    """"""\r\n    common params: a params dict\r\n    net_params   : a params dict\r\n    """"""\r\n    super(YoloNet, self).__init__(common_params, net_params)\r\n    #process params\r\n    self.image_size = int(common_params[\'image_size\'])\r\n    self.num_classes = int(common_params[\'num_classes\'])\r\n    self.cell_size = int(net_params[\'cell_size\'])\r\n    self.boxes_per_cell = int(net_params[\'boxes_per_cell\'])\r\n    self.batch_size = int(common_params[\'batch_size\'])\r\n    self.weight_decay = float(net_params[\'weight_decay\'])\r\n\r\n    if not test:\r\n      self.object_scale = float(net_params[\'object_scale\'])\r\n      self.noobject_scale = float(net_params[\'noobject_scale\'])\r\n      self.class_scale = float(net_params[\'class_scale\'])\r\n      self.coord_scale = float(net_params[\'coord_scale\'])\r\n\r\n  def inference(self, images):\r\n    """"""Build the yolo model\r\n\r\n    Args:\r\n      images:  4-D tensor [batch_size, image_height, image_width, channels]\r\n    Returns:\r\n      predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\r\n    """"""\r\n    conv_num = 1\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), images, [7, 7, 3, 64], stride=2)\r\n    conv_num += 1\r\n\r\n\r\n    temp_pool = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_pool, [3, 3, 64, 192], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_pool = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_pool, [1, 1, 192, 128], stride=1)\r\n    conv_num += 1\r\n    \r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 128, 256], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [1, 1, 256, 256], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 256, 512], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    for i in range(4):\r\n      temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [1, 1, 512, 256], stride=1)\r\n      conv_num += 1\r\n\r\n      temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 256, 512], stride=1)\r\n      conv_num += 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [1, 1, 512, 512], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 512, 1024], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    for i in range(2):\r\n      temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [1, 1, 1024, 512], stride=1)\r\n      conv_num += 1\r\n\r\n      temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 512, 1024], stride=1)\r\n      conv_num += 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 1024, 1024], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 1024, 1024], stride=2)\r\n    conv_num += 1\r\n\r\n    #\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 1024, 1024], stride=1)\r\n    conv_num += 1\r\n    \r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 1024, 1024], stride=1)\r\n    conv_num += 1\r\n\r\n\r\n    #Fully connected layer\r\n    local1 = self.local(\'local1\', temp_conv, 49 * 1024, 4096)\r\n\r\n\r\n    local1 = tf.nn.dropout(local1, keep_prob=0.5)\r\n\r\n    local2 = self.local(\'local2\', local1, 4096, self.cell_size * self.cell_size * ( self.num_classes + 5 * self.boxes_per_cell), leaky=False)\r\n\r\n    local2 = tf.reshape(local2, [tf.shape(local2)[0], self.cell_size, self.cell_size, self.num_classes + 5 * self.boxes_per_cell])\r\n\r\n    predicts = local2\r\n\r\n\r\n    return predicts\r\n\r\n  def iou(self, boxes1, boxes2):\r\n    """"""calculate ious\r\n    Args:\r\n      boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\r\n      boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\r\n    Return:\r\n      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    """"""\r\n    boxes1 = tf.pack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\r\n                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\r\n    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\r\n    boxes2 =  tf.pack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\r\n                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\r\n\r\n    #calculate the left up point\r\n    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\r\n    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\r\n\r\n    #intersection\r\n    intersection = rd - lu \r\n\r\n    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\r\n\r\n    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\r\n    \r\n    inter_square = mask * inter_square\r\n    \r\n    #calculate the boxs1 square and boxs2 square\r\n    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\r\n    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\r\n    \r\n    return inter_square/(square1 + square2 - inter_square + 1e-6)\r\n\r\n  def cond1(self, num, object_num, loss, predict, label, nilboy):\r\n    """"""\r\n    if num < object_num\r\n    """"""\r\n    return num < object_num\r\n\r\n\r\n  def body1(self, num, object_num, loss, predict, labels, nilboy):\r\n    """"""\r\n    calculate loss\r\n    Args:\r\n      predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\r\n      labels : [max_objects, 5]  (x_center, y_center, w, h, class)\r\n    """"""\r\n    label = labels[num:num+1, :]\r\n    label = tf.reshape(label, [-1])\r\n\r\n    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\r\n    min_x = (label[0] - label[2] / 2) / (self.image_size / self.cell_size)\r\n    max_x = (label[0] + label[2] / 2) / (self.image_size / self.cell_size)\r\n\r\n    min_y = (label[1] - label[3] / 2) / (self.image_size / self.cell_size)\r\n    max_y = (label[1] + label[3] / 2) / (self.image_size / self.cell_size)\r\n\r\n    min_x = tf.floor(min_x)\r\n    min_y = tf.floor(min_y)\r\n\r\n    max_x = tf.ceil(max_x)\r\n    max_y = tf.ceil(max_y)\r\n\r\n    temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\r\n    objects = tf.ones(temp, tf.float32)\r\n\r\n    temp = tf.cast(tf.stack([min_y, self.cell_size - max_y, min_x, self.cell_size - max_x]), tf.int32)\r\n    temp = tf.reshape(temp, (2, 2))\r\n    objects = tf.pad(objects, temp, ""CONSTANT"")\r\n\r\n    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\r\n    #calculate responsible tensor [CELL_SIZE, CELL_SIZE]\r\n    center_x = label[0] / (self.image_size / self.cell_size)\r\n    center_x = tf.floor(center_x)\r\n\r\n    center_y = label[1] / (self.image_size / self.cell_size)\r\n    center_y = tf.floor(center_y)\r\n\r\n    response = tf.ones([1, 1], tf.float32)\r\n\r\n    temp = tf.cast(tf.stack([center_y, self.cell_size - center_y - 1, center_x, self.cell_size -center_x - 1]), tf.int32)\r\n    temp = tf.reshape(temp, (2, 2))\r\n    response = tf.pad(response, temp, ""CONSTANT"")\r\n    #objects = response\r\n\r\n    #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    predict_boxes = predict[:, :, self.num_classes + self.boxes_per_cell:]\r\n    \r\n\r\n    predict_boxes = tf.reshape(predict_boxes, [self.cell_size, self.cell_size, self.boxes_per_cell, 4])\r\n\r\n    predict_boxes = predict_boxes * [self.image_size / self.cell_size, self.image_size / self.cell_size, self.image_size, self.image_size]\r\n\r\n    base_boxes = np.zeros([self.cell_size, self.cell_size, 4])\r\n\r\n    for y in range(self.cell_size):\r\n      for x in range(self.cell_size):\r\n        #nilboy\r\n        base_boxes[y, x, :] = [self.image_size / self.cell_size * x, self.image_size / self.cell_size * y, 0, 0]\r\n    base_boxes = np.tile(np.resize(base_boxes, [self.cell_size, self.cell_size, 1, 4]), [1, 1, self.boxes_per_cell, 1])\r\n\r\n    predict_boxes = base_boxes + predict_boxes\r\n\r\n    iou_predict_truth = self.iou(predict_boxes, label[0:4])\r\n    #calculate C [cell_size, cell_size, boxes_per_cell]\r\n    C = iou_predict_truth * tf.reshape(response, [self.cell_size, self.cell_size, 1])\r\n\r\n    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    I = iou_predict_truth * tf.reshape(response, (self.cell_size, self.cell_size, 1))\r\n    \r\n    max_I = tf.reduce_max(I, 2, keep_dims=True)\r\n\r\n    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (self.cell_size, self.cell_size, 1))\r\n\r\n    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    no_I = tf.ones_like(I, dtype=tf.float32) - I \r\n\r\n\r\n    p_C = predict[:, :, self.num_classes:self.num_classes + self.boxes_per_cell]\r\n\r\n    #calculate truth x,y,sqrt_w,sqrt_h 0-D\r\n    x = label[0]\r\n    y = label[1]\r\n\r\n    sqrt_w = tf.sqrt(tf.abs(label[2]))\r\n    sqrt_h = tf.sqrt(tf.abs(label[3]))\r\n    #sqrt_w = tf.abs(label[2])\r\n    #sqrt_h = tf.abs(label[3])\r\n\r\n    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    p_x = predict_boxes[:, :, :, 0]\r\n    p_y = predict_boxes[:, :, :, 1]\r\n\r\n    #p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\r\n    #p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\r\n    #p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\r\n    #p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\r\n    #p_sqrt_w = predict_boxes[:, :, :, 2]\r\n    #p_sqrt_h = predict_boxes[:, :, :, 3]\r\n    p_sqrt_w = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\r\n    p_sqrt_h = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\r\n    #calculate truth p 1-D tensor [NUM_CLASSES]\r\n    P = tf.one_hot(tf.cast(label[4], tf.int32), self.num_classes, dtype=tf.float32)\r\n\r\n    #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\r\n    p_P = predict[:, :, 0:self.num_classes]\r\n\r\n    #class_loss\r\n    class_loss = tf.nn.l2_loss(tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\r\n    #class_loss = tf.nn.l2_loss(tf.reshape(response, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\r\n\r\n    #object_loss\r\n    object_loss = tf.nn.l2_loss(I * (p_C - C)) * self.object_scale\r\n    #object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * self.object_scale\r\n\r\n    #noobject_loss\r\n    #noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * self.noobject_scale\r\n    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * self.noobject_scale\r\n\r\n    #coord_loss\r\n    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(self.image_size/self.cell_size)) +\r\n                 tf.nn.l2_loss(I * (p_y - y)/(self.image_size/self.cell_size)) +\r\n                 tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ self.image_size +\r\n                 tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/self.image_size) * self.coord_scale\r\n\r\n    nilboy = I\r\n\r\n    return num + 1, object_num, [loss[0] + class_loss, loss[1] + object_loss, loss[2] + noobject_loss, loss[3] + coord_loss], predict, labels, nilboy\r\n\r\n\r\n  def loss(self, predicts, labels, objects_num):\r\n    """"""Add Loss to all the trainable variables\r\n\r\n    Args:\r\n      predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\r\n      ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\r\n      labels  : 3-D tensor of [batch_size, max_objects, 5]\r\n      objects_num: 1-D tensor [batch_size]\r\n    """"""\r\n    class_loss = tf.constant(0, tf.float32)\r\n    object_loss = tf.constant(0, tf.float32)\r\n    noobject_loss = tf.constant(0, tf.float32)\r\n    coord_loss = tf.constant(0, tf.float32)\r\n    loss = [0, 0, 0, 0]\r\n    for i in range(self.batch_size):\r\n      predict = predicts[i, :, :, :]\r\n      label = labels[i, :, :]\r\n      object_num = objects_num[i]\r\n      nilboy = tf.ones([7,7,2])\r\n      tuple_results = tf.while_loop(self.cond1, self.body1, [tf.constant(0), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy])\r\n      for j in range(4):\r\n        loss[j] = loss[j] + tuple_results[2][j]\r\n      nilboy = tuple_results[5]\r\n\r\n    tf.add_to_collection(\'losses\', (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size)\r\n\r\n    tf.scalar_summary(\'class_loss\', loss[0]/self.batch_size)\r\n    tf.scalar_summary(\'object_loss\', loss[1]/self.batch_size)\r\n    tf.scalar_summary(\'noobject_loss\', loss[2]/self.batch_size)\r\n    tf.scalar_summary(\'coord_loss\', loss[3]/self.batch_size)\r\n    tf.scalar_summary(\'weight_loss\', tf.add_n(tf.get_collection(\'losses\')) - (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size )\r\n\r\n    return tf.add_n(tf.get_collection(\'losses\'), name=\'total_loss\'), nilboy'"
yolo/net/yolo_tiny_net.py,67,"b'from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport re\r\n\r\nfrom yolo.net.net import Net \r\n\r\nclass YoloTinyNet(Net):\r\n\r\n  def __init__(self, common_params, net_params, test=False):\r\n    """"""\r\n    common params: a params dict\r\n    net_params   : a params dict\r\n    """"""\r\n    super(YoloTinyNet, self).__init__(common_params, net_params)\r\n    #process params\r\n    self.image_size = int(common_params[\'image_size\'])\r\n    self.num_classes = int(common_params[\'num_classes\'])\r\n    self.cell_size = int(net_params[\'cell_size\'])\r\n    self.boxes_per_cell = int(net_params[\'boxes_per_cell\'])\r\n    self.batch_size = int(common_params[\'batch_size\'])\r\n    self.weight_decay = float(net_params[\'weight_decay\'])\r\n\r\n    if not test:\r\n      self.object_scale = float(net_params[\'object_scale\'])\r\n      self.noobject_scale = float(net_params[\'noobject_scale\'])\r\n      self.class_scale = float(net_params[\'class_scale\'])\r\n      self.coord_scale = float(net_params[\'coord_scale\'])\r\n\r\n  def inference(self, images):\r\n    """"""Build the yolo model\r\n\r\n    Args:\r\n      images:  4-D tensor [batch_size, image_height, image_width, channels]\r\n    Returns:\r\n      predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\r\n    """"""\r\n    conv_num = 1\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), images, [3, 3, 3, 16], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_pool = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_pool, [3, 3, 16, 32], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_pool = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_pool, [3, 3, 32, 64], stride=1)\r\n    conv_num += 1\r\n    \r\n    temp_conv = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 64, 128], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 128, 256], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 256, 512], stride=1)\r\n    conv_num += 1\r\n\r\n    temp_conv = self.max_pool(temp_conv, [2, 2], 2)\r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 512, 1024], stride=1)\r\n    conv_num += 1     \r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 1024, 1024], stride=1)\r\n    conv_num += 1 \r\n\r\n    temp_conv = self.conv2d(\'conv\' + str(conv_num), temp_conv, [3, 3, 1024, 1024], stride=1)\r\n    conv_num += 1 \r\n\r\n    temp_conv = tf.transpose(temp_conv, (0, 3, 1, 2))\r\n\r\n    #Fully connected layer\r\n    local1 = self.local(\'local1\', temp_conv, self.cell_size * self.cell_size * 1024, 256)\r\n\r\n    local2 = self.local(\'local2\', local1, 256, 4096)\r\n \r\n    local3 = self.local(\'local3\', local2, 4096, self.cell_size * self.cell_size * (self.num_classes + self.boxes_per_cell * 5), leaky=False, pretrain=False, train=True)\r\n\r\n    n1 = self.cell_size * self.cell_size * self.num_classes\r\n\r\n    n2 = n1 + self.cell_size * self.cell_size * self.boxes_per_cell\r\n\r\n    class_probs = tf.reshape(local3[:, 0:n1], (-1, self.cell_size, self.cell_size, self.num_classes))\r\n    scales = tf.reshape(local3[:, n1:n2], (-1, self.cell_size, self.cell_size, self.boxes_per_cell))\r\n    boxes = tf.reshape(local3[:, n2:], (-1, self.cell_size, self.cell_size, self.boxes_per_cell * 4))\r\n\r\n    local3 = tf.concat([class_probs, scales, boxes], 3)\r\n\r\n    predicts = local3\r\n\r\n    return predicts\r\n\r\n  def iou(self, boxes1, boxes2):\r\n    """"""calculate ious\r\n    Args:\r\n      boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\r\n      boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\r\n    Return:\r\n      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    """"""\r\n    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\r\n                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\r\n    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\r\n    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\r\n                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\r\n\r\n    #calculate the left up point\r\n    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\r\n    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\r\n\r\n    #intersection\r\n    intersection = rd - lu \r\n\r\n    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\r\n\r\n    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\r\n    \r\n    inter_square = mask * inter_square\r\n    \r\n    #calculate the boxs1 square and boxs2 square\r\n    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\r\n    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\r\n    \r\n    return inter_square/(square1 + square2 - inter_square + 1e-6)\r\n\r\n  def cond1(self, num, object_num, loss, predict, label, nilboy):\r\n    """"""\r\n    if num < object_num\r\n    """"""\r\n    return num < object_num\r\n\r\n\r\n  def body1(self, num, object_num, loss, predict, labels, nilboy):\r\n    """"""\r\n    calculate loss\r\n    Args:\r\n      predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\r\n      labels : [max_objects, 5]  (x_center, y_center, w, h, class)\r\n    """"""\r\n    label = labels[num:num+1, :]\r\n    label = tf.reshape(label, [-1])\r\n\r\n    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\r\n    min_x = (label[0] - label[2] / 2) / (self.image_size / self.cell_size)\r\n    max_x = (label[0] + label[2] / 2) / (self.image_size / self.cell_size)\r\n\r\n    min_y = (label[1] - label[3] / 2) / (self.image_size / self.cell_size)\r\n    max_y = (label[1] + label[3] / 2) / (self.image_size / self.cell_size)\r\n\r\n    min_x = tf.floor(min_x)\r\n    min_y = tf.floor(min_y)\r\n\r\n    max_x = tf.ceil(max_x)\r\n    max_y = tf.ceil(max_y)\r\n\r\n    temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\r\n    objects = tf.ones(temp, tf.float32)\r\n\r\n    temp = tf.cast(tf.stack([min_y, self.cell_size - max_y, min_x, self.cell_size - max_x]), tf.int32)\r\n    temp = tf.reshape(temp, (2, 2))\r\n    objects = tf.pad(objects, temp, ""CONSTANT"")\r\n\r\n    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\r\n    #calculate responsible tensor [CELL_SIZE, CELL_SIZE]\r\n    center_x = label[0] / (self.image_size / self.cell_size)\r\n    center_x = tf.floor(center_x)\r\n\r\n    center_y = label[1] / (self.image_size / self.cell_size)\r\n    center_y = tf.floor(center_y)\r\n\r\n    response = tf.ones([1, 1], tf.float32)\r\n\r\n    temp = tf.cast(tf.stack([center_y, self.cell_size - center_y - 1, center_x, self.cell_size -center_x - 1]), tf.int32)\r\n    temp = tf.reshape(temp, (2, 2))\r\n    response = tf.pad(response, temp, ""CONSTANT"")\r\n    #objects = response\r\n\r\n    #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    predict_boxes = predict[:, :, self.num_classes + self.boxes_per_cell:]\r\n    \r\n\r\n    predict_boxes = tf.reshape(predict_boxes, [self.cell_size, self.cell_size, self.boxes_per_cell, 4])\r\n\r\n    predict_boxes = predict_boxes * [self.image_size / self.cell_size, self.image_size / self.cell_size, self.image_size, self.image_size]\r\n\r\n    base_boxes = np.zeros([self.cell_size, self.cell_size, 4])\r\n\r\n    for y in range(self.cell_size):\r\n      for x in range(self.cell_size):\r\n        #nilboy\r\n        base_boxes[y, x, :] = [self.image_size / self.cell_size * x, self.image_size / self.cell_size * y, 0, 0]\r\n    base_boxes = np.tile(np.resize(base_boxes, [self.cell_size, self.cell_size, 1, 4]), [1, 1, self.boxes_per_cell, 1])\r\n\r\n    predict_boxes = base_boxes + predict_boxes\r\n\r\n    iou_predict_truth = self.iou(predict_boxes, label[0:4])\r\n    #calculate C [cell_size, cell_size, boxes_per_cell]\r\n    C = iou_predict_truth * tf.reshape(response, [self.cell_size, self.cell_size, 1])\r\n\r\n    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    I = iou_predict_truth * tf.reshape(response, (self.cell_size, self.cell_size, 1))\r\n    \r\n    max_I = tf.reduce_max(I, 2, keep_dims=True)\r\n\r\n    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (self.cell_size, self.cell_size, 1))\r\n\r\n    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    no_I = tf.ones_like(I, dtype=tf.float32) - I \r\n\r\n\r\n    p_C = predict[:, :, self.num_classes:self.num_classes + self.boxes_per_cell]\r\n\r\n    #calculate truth x,y,sqrt_w,sqrt_h 0-D\r\n    x = label[0]\r\n    y = label[1]\r\n\r\n    sqrt_w = tf.sqrt(tf.abs(label[2]))\r\n    sqrt_h = tf.sqrt(tf.abs(label[3]))\r\n    #sqrt_w = tf.abs(label[2])\r\n    #sqrt_h = tf.abs(label[3])\r\n\r\n    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\r\n    p_x = predict_boxes[:, :, :, 0]\r\n    p_y = predict_boxes[:, :, :, 1]\r\n\r\n    #p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\r\n    #p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\r\n    #p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\r\n    #p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\r\n    #p_sqrt_w = predict_boxes[:, :, :, 2]\r\n    #p_sqrt_h = predict_boxes[:, :, :, 3]\r\n    p_sqrt_w = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\r\n    p_sqrt_h = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\r\n    #calculate truth p 1-D tensor [NUM_CLASSES]\r\n    P = tf.one_hot(tf.cast(label[4], tf.int32), self.num_classes, dtype=tf.float32)\r\n\r\n    #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\r\n    p_P = predict[:, :, 0:self.num_classes]\r\n\r\n    #class_loss\r\n    class_loss = tf.nn.l2_loss(tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\r\n    #class_loss = tf.nn.l2_loss(tf.reshape(response, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\r\n\r\n    #object_loss\r\n    object_loss = tf.nn.l2_loss(I * (p_C - C)) * self.object_scale\r\n    #object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * self.object_scale\r\n\r\n    #noobject_loss\r\n    #noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * self.noobject_scale\r\n    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * self.noobject_scale\r\n\r\n    #coord_loss\r\n    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(self.image_size/self.cell_size)) +\r\n                 tf.nn.l2_loss(I * (p_y - y)/(self.image_size/self.cell_size)) +\r\n                 tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ self.image_size +\r\n                 tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/self.image_size) * self.coord_scale\r\n\r\n    nilboy = I\r\n\r\n    return num + 1, object_num, [loss[0] + class_loss, loss[1] + object_loss, loss[2] + noobject_loss, loss[3] + coord_loss], predict, labels, nilboy\r\n\r\n\r\n\r\n  def loss(self, predicts, labels, objects_num):\r\n    """"""Add Loss to all the trainable variables\r\n\r\n    Args:\r\n      predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\r\n      ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\r\n      labels  : 3-D tensor of [batch_size, max_objects, 5]\r\n      objects_num: 1-D tensor [batch_size]\r\n    """"""\r\n    class_loss = tf.constant(0, tf.float32)\r\n    object_loss = tf.constant(0, tf.float32)\r\n    noobject_loss = tf.constant(0, tf.float32)\r\n    coord_loss = tf.constant(0, tf.float32)\r\n    loss = [0, 0, 0, 0]\r\n    for i in range(self.batch_size):\r\n      predict = predicts[i, :, :, :]\r\n      label = labels[i, :, :]\r\n      object_num = objects_num[i]\r\n      nilboy = tf.ones([7,7,2])\r\n      tuple_results = tf.while_loop(self.cond1, self.body1, [tf.constant(0), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy])\r\n      for j in range(4):\r\n        loss[j] = loss[j] + tuple_results[2][j]\r\n      nilboy = tuple_results[5]\r\n\r\n    tf.add_to_collection(\'losses\', (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size)\r\n\r\n    tf.summary.scalar(\'class_loss\', loss[0]/self.batch_size)\r\n    tf.summary.scalar(\'object_loss\', loss[1]/self.batch_size)\r\n    tf.summary.scalar(\'noobject_loss\', loss[2]/self.batch_size)\r\n    tf.summary.scalar(\'coord_loss\', loss[3]/self.batch_size)\r\n    tf.summary.scalar(\'weight_loss\', tf.add_n(tf.get_collection(\'losses\')) - (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size )\r\n\r\n    return tf.add_n(tf.get_collection(\'losses\'), name=\'total_loss\'), nilboy\r\n'"
yolo/solver/__init__.py,0,b'import solver\r\nimport yolo_solver'
yolo/solver/solver.py,0,"b'""""""Solver Abstract class \r\n""""""\r\nclass Solver(object):\r\n\r\n  def __init__(self, dataset, net, common_params, solver_params):\r\n    raise NotImplementedError\r\n\r\n  def solve(self):\r\n    raise NotImplementedError\r\n'"
yolo/solver/yolo_solver.py,13,"b'from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport re\r\nimport sys\r\nimport time\r\nfrom datetime import datetime\r\n\r\nfrom yolo.solver.solver import Solver\r\n\r\nclass YoloSolver(Solver):\r\n  """"""Yolo Solver \r\n  """"""\r\n  def __init__(self, dataset, net, common_params, solver_params):\r\n    #process params\r\n    self.moment = float(solver_params[\'moment\'])\r\n    self.learning_rate = float(solver_params[\'learning_rate\'])\r\n    self.batch_size = int(common_params[\'batch_size\'])\r\n    self.height = int(common_params[\'image_size\'])\r\n    self.width = int(common_params[\'image_size\'])\r\n    self.max_objects = int(common_params[\'max_objects_per_image\'])\r\n    self.pretrain_path = str(solver_params[\'pretrain_model_path\'])\r\n    self.train_dir = str(solver_params[\'train_dir\'])\r\n    self.max_iterators = int(solver_params[\'max_iterators\'])\r\n    #\r\n    self.dataset = dataset\r\n    self.net = net\r\n    #construct graph\r\n    self.construct_graph()\r\n\r\n  def _train(self):\r\n    """"""Train model\r\n\r\n    Create an optimizer and apply to all trainable variables.\r\n\r\n    Args:\r\n      total_loss: Total loss from net.loss()\r\n      global_step: Integer Variable counting the number of training steps\r\n      processed\r\n    Returns:\r\n      train_op: op for training\r\n    """"""\r\n\r\n    opt = tf.train.MomentumOptimizer(self.learning_rate, self.moment)\r\n    grads = opt.compute_gradients(self.total_loss)\r\n\r\n    apply_gradient_op = opt.apply_gradients(grads, global_step=self.global_step)\r\n\r\n    return apply_gradient_op\r\n\r\n  def construct_graph(self):\r\n    # construct graph\r\n    self.global_step = tf.Variable(0, trainable=False)\r\n    self.images = tf.placeholder(tf.float32, (self.batch_size, self.height, self.width, 3))\r\n    self.labels = tf.placeholder(tf.float32, (self.batch_size, self.max_objects, 5))\r\n    self.objects_num = tf.placeholder(tf.int32, (self.batch_size))\r\n\r\n    self.predicts = self.net.inference(self.images)\r\n    self.total_loss, self.nilboy = self.net.loss(self.predicts, self.labels, self.objects_num)\r\n    \r\n    tf.summary.scalar(\'loss\', self.total_loss)\r\n    self.train_op = self._train()\r\n\r\n  def solve(self):\r\n    saver1 = tf.train.Saver(self.net.pretrained_collection, write_version=1)\r\n    #saver1 = tf.train.Saver(self.net.trainable_collection)\r\n    saver2 = tf.train.Saver(self.net.trainable_collection, write_version=1)\r\n\r\n    init =  tf.global_variables_initializer()\r\n\r\n    summary_op = tf.summary.merge_all()\r\n\r\n    sess = tf.Session()\r\n\r\n    sess.run(init)\r\n    saver1.restore(sess, self.pretrain_path)\r\n\r\n\r\n    summary_writer = tf.summary.FileWriter(self.train_dir, sess.graph)\r\n\r\n    for step in xrange(self.max_iterators):\r\n      start_time = time.time()\r\n      np_images, np_labels, np_objects_num = self.dataset.batch()\r\n\r\n      _, loss_value, nilboy = sess.run([self.train_op, self.total_loss, self.nilboy], feed_dict={self.images: np_images, self.labels: np_labels, self.objects_num: np_objects_num})\r\n      #loss_value, nilboy = sess.run([self.total_loss, self.nilboy], feed_dict={self.images: np_images, self.labels: np_labels, self.objects_num: np_objects_num})\r\n\r\n\r\n      duration = time.time() - start_time\r\n\r\n      assert not np.isnan(loss_value), \'Model diverged with loss = NaN\'\r\n\r\n      if step % 10 == 0:\r\n        num_examples_per_step = self.dataset.batch_size\r\n        examples_per_sec = num_examples_per_step / duration\r\n        sec_per_batch = float(duration)\r\n\r\n        format_str = (\'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f \'\r\n                      \'sec/batch)\')\r\n        print (format_str % (datetime.now(), step, loss_value,\r\n                             examples_per_sec, sec_per_batch))\r\n\r\n        sys.stdout.flush()\r\n      if step % 100 == 0:\r\n        summary_str = sess.run(summary_op, feed_dict={self.images: np_images, self.labels: np_labels, self.objects_num: np_objects_num})\r\n        summary_writer.add_summary(summary_str, step)\r\n      if step % 5000 == 0:\r\n        saver2.save(sess, self.train_dir + \'/model.ckpt\', global_step=step)\r\n    sess.close()\r\n'"
yolo/utils/__init__.py,0,b'import process_config'
yolo/utils/process_config.py,0,"b'import ConfigParser\r\n\r\ndef process_config(conf_file):\r\n  """"""process configure file to generate CommonParams, DataSetParams, NetParams \r\n\r\n  Args:\r\n    conf_file: configure file path \r\n  Returns:\r\n    CommonParams, DataSetParams, NetParams, SolverParams\r\n  """"""\r\n  common_params = {}\r\n  dataset_params = {}\r\n  net_params = {}\r\n  solver_params = {}\r\n\r\n  #configure_parser\r\n  config = ConfigParser.ConfigParser()\r\n  config.read(conf_file)\r\n\r\n  #sections and options\r\n  for section in config.sections():\r\n    #construct common_params\r\n    if section == \'Common\':\r\n      for option in config.options(section):\r\n        common_params[option] = config.get(section, option)\r\n    #construct dataset_params\r\n    if section == \'DataSet\':\r\n      for option in config.options(section):\r\n        dataset_params[option] = config.get(section, option)\r\n    #construct net_params\r\n    if section == \'Net\':\r\n      for option in config.options(section):\r\n        net_params[option] = config.get(section, option)\r\n    #construct solver_params\r\n    if section == \'Solver\':\r\n      for option in config.options(section):\r\n        solver_params[option] = config.get(section, option)\r\n\r\n  return common_params, dataset_params, net_params, solver_params'"
