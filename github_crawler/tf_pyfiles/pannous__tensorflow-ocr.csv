file_path,api_count,code
Clockwork_RNN.py,19,"b'import tensorflow as tf\n# import tensorlayer as tl\nclass ClockworkLayer(tl.layers.RNNLayer):\n\t"""""" A clockwork RNN layer.\n\n\tAs done in the original paper, we restrict ourselves to an exponential\n\tseries of periods. As noted in the paper, this lets W_H and W_I be\n\tcontiguous, and the implementation is therefore much simpler.\n\n\tThis is based on Jan Koutnik et al.: A Clockwork RNN.\n\tarXiv preprint arXiv:1402.3511. 2014.\n\n\tSee `RNNLayer`.\n\n\t**kwargs:\n\t\tnum_periods: An integer. The periods will be `2 ** np.arange(num_periods)`.\n\t\t\t8 by default.\n\t""""""\n\n\tdef __init__(self, *args, **kwargs):\n\t\tkwargs.setdefault(\'num_periods\', 8)\n\t\tsuper().__init__(*args, **kwargs)\n\n\tdef _compute_states(self):\n\t\tunits_per_period, remainder = divmod(self.num_hidden_units, self.num_periods)\n\t\tif remainder != 0:\n\t\t\traise ValueError(\'Current implementation requires num_hidden_units to be divisible by num_periods.\')\n\n\t\t_inputs = tf.transpose(self.inputs, [1, 0, 2])\n\t\tx_ta = tf.TensorArray(tf.float32, size=self.length).unstack(_inputs)\n\t\th_ta = tf.TensorArray(tf.float32, size=self.length)\n\n\t\tdef cond(t, h, h_ta):\n\t\t\treturn tf.less(t, self.length)\n\n\t\tdef body(t, h, h_ta):\n\t\t\tx = x_ta.read(t)\n\t\t\tnum_units, input_size = self.num_hidden_units, self.input_size\n\t\t\tperiods = tf.constant(2**np.arange(self.num_periods), dtype=tf.int32)\n\n\t\t\t# We need to transpose everything in Figure 2 of the paper.\n\t\t\tweight_mask = utils.block_triu_mask(units_per_period, self.num_periods).T\n\t\t\tweight_mask = tf.constant(weight_mask, dtype=tf.float32)\n\n\t\t\tactive_period_mask = tf.to_int32(tf.equal(tf.mod(t, periods), 0))\n\t\t\tnum_active_periods = tf.reduce_sum(active_period_mask)\n\t\t\tnum_active_units = num_active_periods * units_per_period\n\n\t\t\tW_h = tf.get_variable(\'W_h\', shape=[num_units, num_units], initializer=self.non_square_initializer)\n\t\t\tW_x = tf.get_variable(\'W_x\', shape=[input_size, num_units], initializer=self.non_square_initializer)\n\t\t\tb = tf.get_variable(\'b\', shape=[num_units], initializer=self.bias_initializer)\n\n\t\t\t# W_h was created fully for simplicity and efficiency, but only its\n\t\t\t# lower-block-triangular version stores clockwork parameters.\n\t\t\tW_h = weight_mask * W_h\n\n\t\t\t# Shutting off parts of h is handled using the W_h mask above. Therefore\n\t\t\t# we will always multiply by all of h (and therefore use the entire first\n\t\t\t# axis of W_h). None of x is ever shut off, so we do the same. Finally,\n\t\t\t# we only want outputs for active states, which correspond to the left\n\t\t\t# sides of W_h, W_x, and b.\n\t\t\tW_h = W_h[:, :num_active_units]\n\t\t\tW_x = W_x[:, :num_active_units]\n\t\t\tb = b[:num_active_units]\n\n\t\t\th_new_active = self.activation(tf.matmul(h, W_h) + tf.matmul(x, W_x) + b)\n\t\t\th_new_inactive = h[:, num_active_units:]\n\t\t\th_new = tf.concat_v2([h_new_active, h_new_inactive], axis=1)\n\t\t\th_new = tf.reshape(h_new, [self.batch_size, self.num_hidden_units])\n\n\t\t\th_ta_new = h_ta.write(t, h_new)\n\t\t\treturn t + 1, h_new, h_ta_new\n\n\t\tt = tf.constant(0)\n\t\th = tf.squeeze(self.initial_states, [1])\n\t\t_, _, h_ta = tf.while_loop(cond, body, [t, h, h_ta])\n\n\t\tstates = tf.transpose(h_ta.stack(), [1, 0, 2], name=\'states\')\n\t\toutputs = tf.identity(states, name=\'outputs\')\n\t\treturn outputs, states\n'"
__init__.py,0,"b'from .net import *  \nfrom .tensorboard_util import *\nfrom .baselines import *\n# PyCharm has bad auto-complete if separated into different modules\n# THEREFORE, the following files are now all merged in net.py !\n# from conv import *\n# from batch_norm import *\n# from dense import *\n# from densenet import *\n\n__all__ = [""net""]\n\nshow_tensorboard()\n'"
baselines.py,6,"b'# import .net as layer.net\n# import net as layer.net\nimport layer\nimport tensorflow as tf\n\n\nclass identity(layer.net):  # baseline 0 ;)\n\tdef __init__(self):\n\t\tpass\n\tdef predict(self, eval_data=None, model=None):\n\t\treturn eval_data\n\ndef baseline(net):\n\t# type: (layer.net) -> None\n\tnet.dense(400, activation=tf.nn.tanh)\n\n\n# over-fitting okay: Step 3000 Loss= 0.301323 Accuracy= 1.000 Time= 20s \t\t\tTest Accuracy:  1.0""""""\ndef baselineDeep3(net):\n\t# type: (layer.net) -> None\n\tnet.dense(400, depth=3, activation=tf.nn.tanh)\n\ndef baselineWide(net):\n\tnet.dense(hidden=20000, depth=2, dropout=True)\n\n\ndef baselineBatchNorm(net):\n\t# type: (layer.net) -> None\n\tnet.batchnorm()\n\tnet.dense(400, activation=tf.nn.tanh, bn=1)\n\tnet.batchnorm()\n\n\ndef baselineBatchNormDeep(net):\n\t# type: (layer.net) -> None\n\tnet.batchnorm()  # start lower, else no effect\n\tnet.dense(400, depth=3, activation=tf.nn.tanh, bn=1)\n\n\n# Interesting: losses dropping, still 0.0 accuracy! => predicting zeros!?!\nsize=10\ndef baselineDenseConv(net):\n\t# type: (layer.net) -> None\n\tprint(""Building dense-net"")\n\tnet.reshape(shape=[-1, size, size, 1])  # Reshape input picture\n\tnet.buildDenseConv(nBlocks=1)\n\tnet.classifier()  # 10 classes auto\n\n\n# Patience! Alex does converge after ~10k steps ... maybe\ndef alex(net):\n\t# type: (layer.net) -> None\n\tprint(""Building Alex-net"")\n\tnet.reshape(shape=[-1, size, size, 1])  # Reshape input picture\n\t# net.batchnorm()\n\tnet.conv([3, 3, 1, 64])\n\tnet.conv([3, 3, 64, 128])\n\tnet.conv([3, 3, 128, 256])\n\tnet.dense(1024, activation=tf.nn.relu)\n\tnet.dense(1024, activation=tf.nn.relu)\n'"
combine.py,0,"b'#!/usr/bin/env python\n\nimport requests\nimport json\nfrom PIL import Image # Image.open(test_image)\n# import cv2 # cv2.imwrite(output_path, img)\n# import skimage #skimage.io.imread\n# server=\'0.0.0.0\'\nserver=\'87.118.88.144\' #dev03\'\n\nclass Box(object):\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\nimage_file=\'test_image.png\'\ntest_file=\'test_out.png\'\nimage = Image.open(image_file)\nwith open(image_file, \'rb\') as f:\n    r = requests.post(\'http://\'+server+\':8769/?json=1\', files={\'image\': f})\n    raw=r.text.replace(""&#34;"",\'""\')\n    print(raw)\n    boxes=json.loads(raw)\n    for line in boxes[\'text_lines\']:\n      print(line)\n      b=Box(**line)\n      print(b.x0)\n      word=image.crop((b.x0-5, b.y0-5, b.x2+15, b.y2+15))\n      word.save(open(test_file, \'wb\'))\n'"
create-ocr-character-images.py,0,"b'#!/usr/local/bin/python\nfrom PIL import Image\nimport ImageDraw, ImageFont\nimport numpy as np\n\ndef demo():\n\ttext=\'A\'\n\tsize=32\n\tcolor=\'white\'\n\tfontPath = \'/data/fonts/DroidSans.ttf\' #/FreeSansBold.ttf\'\n\tfont = ImageFont.truetype(fontPath, size)\n\tsize2 = font.getsize(text)\n\tpadding = 2\n\tpadding_y = 3\n\tsize2 = (size2[0],size2[1]+padding_y) # add margin\n\tsize2 = (size + padding, size + padding) # ignore rendered font size!\n\timg = Image.new(\'L\', size2)# # grey\n\t# img = Image.new(\'RGBA\', size2, (0, 0, 0, 0))\n\tdraw = ImageDraw.Draw(img)\n\tdraw.text((padding, -padding), text, font=font, fill=color)\n\tx=np.array(img)\n\timg.show()\n\ndemo()\nprint(""Just a demo; The ocr data is created on the fly in letter.py when training"")\n'"
deep_prior.py,8,"b'import os\nimport scipy.misc\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import conv2d, conv2d_transpose\n\n\ndef pool(X):\n\treturn tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n\ndef uppool(X):\n\theight, width = X.get_shape().as_list()[1:3]\n\treturn tf.image.resize_images(X, (height * 2, width * 2))\n\n\n# download from https://i.imgur.com/ytjR2QF.png\nimage = scipy.misc.imread(""snail256.png"").astype(np.float32) / 255.0\n\n\ndef make_unet(X):\n\tdepths = [16, 32, 64, 128, 256, 512]\n\t# TODO figure out how to make batchnorm work\n\n\tactivation_fn = tf.nn.tanh\n\t# convolve and half image size a few times\n\tfor depth in depths:\n\t\t# \t\tX = convolution(X, kernel_size=depth, stride=3, activation_fn=activation_fn)\n\t\tX = conv2d(X, depth, 3, activation_fn=activation_fn)\n\t\tX = pool(X)\n\n\tX = conv2d(X, depth, 3, activation_fn=activation_fn)\n\n\t# upconcolve and double image size a few times\n\tfor depth in reversed(depths):\n\t\tX = uppool(X)\n\t\tX = conv2d_transpose(X, depth, 3, activation_fn=activation_fn)\n\n\tX = conv2d(X, 3, 3, activation_fn=None)\n\n\treturn X\n\n\ninput = tf.constant(image.reshape((1, 256, 256, 3)))\n\noutput = make_unet(input)\n\nloss = tf.reduce_mean(tf.square(input - output))\n\n# TODO L-BFGS-B should be faster here, but could not get it to work\noptimizer = tf.train.AdamOptimizer()\ntrain_op = optimizer.minimize(loss)\n\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())\n\nif not os.path.exists(""frames""):\n\tos.mkdir(""frames"")\n\ndef save(frame):\n\t\tscipy.misc.imsave(""frames/%d.png"" % frame, sess.run(output).reshape((256, 256, 3)).clip(0, 1))\n\nfor i in range(10000):\n\tprint(""\\r#"" + str(i), end=\'\', flush=True)\n\tsess.run(train_op)\n\tif not i % 100:\n\t\tsave(i/100)\n'"
extensions.py,0,"b'# encoding: utf-8\n# nocoding: interpy ""string interpolation #{like ruby}""\n# encoding=utf8\nimport io\nimport math\nimport sys\nimport inspect\nimport re  # for \'is_file\'\nimport os\n# import __builtin__\nimport numpy as np\nfrom random import randint\nfrom random import random as _random\nimport shutil\n\n# from extension_functions import * MERGED BACK!\n\npy2 = sys.version < \'3\'\npy3 = sys.version >= \'3\'\n\ntrue = True\nfalse = False\n\npi = math.pi\nE = math.e\n\n\ndef Max(a, b):\n\tif a > b:\n\t\treturn a\n\treturn b\n\n\ndef Min(a, b):\n\tif a > b:\n\t\treturn b\n\treturn a\n\n\ndef rand(n=1): return _random() * n\n\n\ndef random(n=1): return _random() * n\n\n\ndef random_array(l): return np.random.rand(l)  # (0,1) x,y don\'t work ->\n\n\ndef random_matrix(x, y): return np.random.rand(x, y)  # (0,1) !\n\n\ndef pick(xs):\n\treturn xs[randint(len(xs))]\n\n\ndef reverse(x):\n\ty = x.reverse()\n\treturn y or x\n\n\ndef h(x):\n\thelp(x)\n\n\ndef log(msg):\n\tprint(msg)\n\n\ndef fold(self, x, fun):\n\tif not callable(fun):\n\t\tfun, x = x, fun\n\treturn reduce(fun, self, x)\n\n\ndef last(xs):\n\treturn xs[-1]\n\n\ndef Pow(x, y):\n\treturn x**y\n\n\ndef is_string(s):\n\treturn isinstance(s, str) or isinstance(s, xstr) or isinstance(s, unicode)\n\n\n# or issubclass(s,str) or issubclass(s,unicode)\n\n\ndef flatten(l):\n\tif isinstance(l, list) or isinstance(l, tuple):\n\t\tfor k in l:\n\t\t\tif isinstance(k, list):\n\t\t\t\tl.remove(k)\n\t\t\t\tl.append(*k)\n\telse:\n\t\treturn [l]\n\t# verbose(""NOT flattenable: %s""%s)\n\treturn l\n\n\ndef square(x):\n\tif isinstance(x, list): return map(square, x)\n\treturn x * x\n\n\ndef puts(x):\n\tprint(x)\n\treturn x\n\n\ndef increase(x):\n\timport nodes\n\t# if isinstance(x, dict)\n\tif isinstance(x, nodes.Variable):\n\t\tx.value = x.value + 1\n\t\treturn x.value\n\treturn x + 1\n\n\ndef grep(xs, x):\n\t# filter(lambda y: re.match(x,y),xs)\n\t# return filter(pattern, xs)\n\tif isinstance(x, list):\n\t\treturn filter(lambda y: x[0] in str(y), xs)\n\treturn filter(lambda y: x in str(y), xs)\n\n\ndef ls(mypath="".""):\n\tfrom extensions import xlist\n\treturn xlist(os.listdir(mypath))\n\n\ndef length(self):\n\treturn len(self)\n\n\ndef say(x):\n\tprint(x)\n\tos.system(""say \'%s\'"" % x)\n\n\ndef bash(x):\n\tos.system(x)\n\n\ndef beep():\n\tprint(""\\aBEEP "")\n\n\ndef beep(bug=True):\n\tprint(""\\aBEEP "")\n\timport context\n\tif not context.testing:\n\t\timport os\n\t\tos.system(""say \'beep\'"")\n\treturn \'beeped\'\n\n\ndef match_path(p):\n\tif not isinstance(p, str): return False\n\tm = re.search(r\'^(/[\\w\\\'.]+)\', p)\n\tif not m: return []\n\treturn m\n\n\ndef regex_match(a, b):\n\tNONE = ""None""\n\tmatch = regex_matches(a, b)\n\tif match:\n\t\ttry:\n\t\t\treturn a[match.start():match.end()].strip()\n\t\texcept:\n\t\t\treturn b[match.start():match.end()].strip()\n\treturn NONE\n\n\n# RegexType= _sre.SRE_Pattern#type(r\'\')\nMatchObjectType = type(re.search(\'\', \'\'))\ndef typeof(x):\n\tprint(""type(x)"")\n\treturn type(x)\n\ndef regex_matches(a, b):\n\tif isinstance(a, re._pattern_type):\n\t\treturn a.search(b)  #\n\tif isinstance(b, re._pattern_type):\n\t\treturn b.search(a)\n\tif is_string(a) and len(a) > 0:\n\t\tif a[0] == ""/"": return re.compile(a).search(b)\n\tif is_string(b) and len(b) > 0:\n\t\tif b[0] == ""/"": return re.compile(b).search(a)\n\n\ttry:\n\t\tb = re.compile(b)\n\texcept:\n\t\tprint(""FAILED: re.compile(%s)"" % b)\n\t\tb = re.compile(str(b))\n\tprint(a)\n\tprint(b)\n\treturn b.search(str(a))  # vs\n\n\n# return b.match(a) # vs search\n# return a.__matches__(b) # other cases\n# return a.contains(b)\n\n\ndef is_file(p, must_exist=True):\n\tif not isinstance(p, str): return False\n\tif re.search(r\'^\\d*\\.\\d+\', p): return False\n\tif re.match(r\'^\\d*\\.\\d+\', str(p)): return False\n\tm = re.search(r\'^(\\/[\\w\\\'\\.]+)\', p)\n\tm = m or re.search(r\'^([\\w\\/\\.]*\\.\\w+)\', p)\n\tif not m: return False\n\treturn must_exist and m and os.path.isfile(m.string) or m\n\n\ndef is_dir(x, must_exist=True):\n\t# (the.string+"" "").match(r\'^(\\\')?([^\\/\\\\0]+(\\\')?)+ \')\n\tm = match_path(x)\n\treturn must_exist and m and (py3 and os.path.isdir(m[0])) or (py2 and os.path.isdirectory(m[0]))\n\n\n# def print(x # debug!):\n# print x\n#   print ""\\n""\n#   x\n\n\ndef exists(x):\n\treturn os.path.isfile(x)\n\ndef is_dir(x):\n\treturn os.path.isfile(x) and os.path.isdir(x)\n\ndef is_file(x):#Is it a file, or a directory?\n\treturn os.path.isfile(x) and not os.path.isdir(x)\n\ndef is_a(self, clazz):\n\tif self is clazz: return True\n\ttry:\n\t\tok = isinstance(self, clazz)\n\t\tif ok: return True\n\texcept Exception as e:\n\t\tprint(e)\n\n\tclassName = str(clazz).lower()\n\tif className == str(self).lower(): return True  # KINDA\n\n\tif self.is_(clazz): return True\n\treturn False\n\n\n# print(""extension functions loaded"")\n\n\n# from fractions import Fraction\n# x = Fraction(22, 7) \t# Ruby: 22 / 7r 22r / 7\n\nif py3:\n\tclass file(io.IOBase):\n\t\tpass  # WTF python3 !?!?!?!?!??\n\n\n\tclass xrange:  # WTF python3 !?!?!?!?!??\n\t\tpass\n\n\n\tclass xstr(str):\n\t\tpass  # later\n\n\n\tclass unicode(xstr):  # , bytes):  # xchar[] TypeError: multiple bases have instance lay-out conflict\n\t\t# Python 3 renamed the unicode type to str, the old str type has been replaced by bytes.\n\t\tpass\n\n\t# else: https://stackoverflow.com/questions/22098099/reason-why-xrange-is-not-inheritable-in-python\n\t#   class range(xrange):\n\t#     pass\n\nelse:  # Python 2 needs:\n\tclass bytes(str):\n\t\tpass\n\n\n\tclass char(str):\n\t\tpass\n\n\n# char = char\n\nclass byte(str):\n\tpass\n\n\n# byte= byte\nfile = file  # nice trick: native py2 class or local py3 class\nunicode = unicode\nxrange = xrange\n\nif py2:\n\timport cPickle as pickle\nelse:\n\timport dill as pickle\n\n\n# try: # py2\n#   import sys\n#   reload(sys)\n#   sys.setdefaultencoding(\'utf8\')\n# except:\n#   pass\n\n\ndef type_name(x):\n\treturn type(x).__name__\n\n\ndef xx(y):\n\tif type_name(y).startswith(\'x\'):   return y\n\t# if isinstance(y, xstr):   return y\n\t# if isinstance(y, xlist):   return y\n\tif isinstance(y, xrange): return xlist(y)\n\tif isinstance(y, bool):  return y  # xbool(y)\n\tif isinstance(y, list):  return xlist(y)\n\tif isinstance(y, str):   return xstr(y)\n\tif isinstance(y, unicode):   return xstr(y)\n\tif isinstance(y, dict):  return xdict(y)\n\tif isinstance(y, float): return xfloat(y)\n\tif isinstance(y, int):   return xint(y)\n\tif isinstance(y, file):   return xfile(y)\n\tif isinstance(y, char):  return xchar(y)\n\tif isinstance(y, byte):  return xchar(y)\n\tif py3 and isinstance(y, range): return xlist(y)\n\tprint(""No extension for type %s"" % type(y))\n\treturn y\n\n\nextensionMap = {}\n\n\ndef extension(clazz):\n\ttry:\n\t\tfor base in clazz.__bases__:\n\t\t\textensionMap[base] = clazz\n\texcept:\n\t\tpass\n\treturn clazz\n\n\n# class Extension:\n#     def __init__(self, base,b=None,c=None):\n#         self.base=base\n#\n#     def __call__(self,clazz):\n#         self.base()\n#         import angle\n#         angle.extensionMap[self.base]=clazz\n#         print(angle.extensionMap)\n\n\n\nclass Class:\n\tpass\n\n\n# not def(self):\n#   False\n\n\n# class Method(__builtin__.function):\n#     pass\n\n# file() is no supported in python3\n# use open() instead\n\n@extension\nclass xfile(file):\n\t# import fileutils\n\n\t# str(def)(self):\n\t#   path\n\tpath = """"\n\n\tdef name(self):\n\t\treturn self.path\n\n\tdef filename(self):\n\t\treturn self.path\n\n\tdef mv(self, to):\n\t\tos.rename(self.path, to)\n\n\tdef move(self, to):\n\t\tos.rename(self.path, to)\n\n\tdef copy(self, to):\n\t\tshutil.copyfile(self.path, to)\n\n\tdef cp(self, to):\n\t\tshutil.copyfile(self.path, to)\n\n\tdef contain(self, x):\n\t\treturn self.path.index(x)\n\n\tdef contains(self, x):\n\t\treturn self.path.index(x)\n\n\t@staticmethod\n\tdef delete():\n\t\traise Exception(""SecurityError: cannot delete files"")\n\n\t# FileUtils.remove_dir(to_path, True)\n\n\t# @classmethod\n\t# def open(cls):return open(cls)\n\t# @classmethod\n\t# def read(cls):return open(cls)\n\t# @classmethod\n\t# def ls(cls):\n\t#     return os.listdir(cls)\n\n\t@staticmethod\n\tdef open(x): return open(x)\n\n\t@staticmethod\n\tdef read(x): return open(x)\n\n\t@staticmethod\n\tdef ls(mypath="".""):\n\t\treturn xlist(os.listdir(mypath))\n\n\n@extension\nclass File(xfile):\n\tpass\n\n\n@extension\nclass Directory(file):  #\n\t# str(def)(self):\n\t#   path\n\n\t@classmethod\n\tdef cd(path):\n\t\tos.chdir(path)\n\n\tdef files(self):\n\t\tos.listdir(str(self))  # ?\n\n\t@classmethod\n\tdef ls(path="".""):\n\t\tos.listdir(path)\n\n\t@classmethod\n\tdef files(path):\n\t\tos.listdir(path)\n\n\tdef contains(self, x):\n\t\treturn self.files().has(x)\n\n\t# Dir.cd\n\t#  Dir.glob ""*.JPG""\n\t#\n\t# import fileutils\n\t#\n\t# def remove_leaves(dir=""."", matching= "".svn""):\n\t#   Dir.chdir(dir) do\n\t#     entries=Dir.entries(Dir.pwd).reject (lambda e: e==""."" or e=="":"" )\n\t#     if entries.size == 1 and entries.first == matching:\n\t#       print ""Removing #{Dir.pwd}""\n\t#       FileUtils.rm_rf(Dir.pwd)\n\t#     else:\n\t#       entries.each do |e|\n\t#         if File.directory? e:\n\t#           remove_leaves(e)\n\n\n\n\n\t#\n\t# def delete(self):\n\t#   raise SecurityError ""cannot delete directories""\n\t# FileUtils.remove_dir(to_path, True)\n\n\nclass Dir(Directory):\n\tpass\n\n\nclass xdir(Directory):\n\tpass\n\n\n# class Number < Numeric\n#\n# def not None(self):\n#   return True\n#\n# def None.test(self):\n#   ""None.test OK""\n#\n# def None.+ x(self):\n#   x\n\n# def None.to_s:\n#  """"\n#  #""None""\n#\n@extension\nclass xdict(dict):\n\tdef clone(self):\n\t\timport copy\n\t\treturn copy.copy(self)\n\n\t# return copy.deepcopy(self)\n\n\t# filter ==  x.select{|z|z>1}\n\n\t# CAREFUL! MESSES with rails etc!!\n\t# alias_method :orig_index, :[]\n\n\n\t# Careful hash.map returns an Array, not a map as expected\n\t# Therefore we need a new method:\n\t# {a:1,b:2}.map_values{|x|x*3} => {a:3,b:6}\n\n\n\t# if not normed here too!!: DANGER: NOT surjective\n\t# def []= x,y # NORM only through getter:\n\t#   super[x.to_sym]=y\n\t#\n\t# def __index__(self,x):\n\t#   if not x: return\n\t#   if isinstance(x, symtable.Symbol): return orig_index(x)  or  orig_index(str(x))\n\t#   if isinstance(x,str): return orig_index(x)\n\t#   # yay! todo: eqls {a:b}=={:a=>b}=={""a""=>b} !!\n\t#   return orig_index(x)\n\n\tdef contains(self, key):\n\t\treturn self.keys().contains(key)\n\n\nclass Class:\n\tdef wrap(self):\n\t\treturn str(self)  # TODO!?\n\n\n# WOW YAY WORKS!!!\n# ONLY VIA EXPLICIT CONSTRUCTOR!\n# NOOOO!! BAAAD! isinstance(my_xlist,list) FALSE !!\n\nfrom functools import partial  # for method_missing\n\n\n@extension\nclass xlist(list):\n\tdef unique(xs):\n\t\treturn xlist(set(xs))\n\n\t#\n\t# def list(xs):\n\t# \tfor x in xs:\n\t# \t\tprint(x)\n\t# \treturn xs\n\n\tdef uniq(xs):\n\t\treturn xlist(set(xs))\n\n\tdef unique(xs):\n\t\treturn xlist(set(xs))\n\n\tdef add(self, x):\n\t\tself.insert(len(self), x)\n\n\tdef method_missing(xs, name, *args, **kwargs):  # [2.1,4.8].int=[2,5]\n\t\tif len(xs) == 0: return None\n\t\ttry:\n\t\t\tmethod = getattr(xs.first(), name)\n\t\texcept:\n\t\t\t# if str(name) in globals():\n\t\t\tmethod = globals()[str(name)]  # .method(m)\n\t\tif not callable(method):\n\t\t\tproperties = xlist(map(lambda x: getattr(x, name), xs))\n\t\t\treturn xlist(zip(xs, properties))\n\t\t# return properties\n\t\treturn xlist(map(lambda x: method(args, kwargs), xs))  # method bound to x\n\n\tdef pick(xs):\n\t\treturn xs[randint(len(xs))]\n\n\tdef __getattr__(self, name):\n\t\tif str(name) in globals():\n\t\t\tmethod = globals()[str(name)]  # .method(m)\n\t\t\ttry:\n\t\t\t\treturn method(self)\n\t\t\texcept:\n\t\t\t\txlist(map(method, self))\n\t\treturn self.method_missing(name)\n\n\t# return partial(self.method_missing, name)\n\n\tdef select(xs, func):  # VS MAP!!\n\t\t# return [x for x in xs if func(x)]\n\t\treturn filter(func, xs)\n\n\tdef map(xs, func):\n\t\treturn xlist(map(func, xs))\n\n\tdef last(xs):\n\t\treturn xs[-1]\n\n\tdef first(xs):\n\t\treturn xs[0]\n\n\tdef fold(self, x, fun):\n\t\tif not callable(fun):\n\t\t\tfun, x = x, fun\n\t\treturn self.reduce(fun, self, x)\n\n\tdef row(xs, n):\n\t\treturn xs[int(n) - 1]\n\n\tdef column(xs, n):\n\t\tif isinstance(xs[0], str):\n\t\t\treturn xlist(map(lambda row: xstr(row).word(n + 1), xs))\n\t\tif isinstance(xs[0], list):\n\t\t\treturn xlist(map(lambda row: row[n], xs))\n\t\traise Exception(""column of %s undefined"" % type(xs[0]))\n\n\t# c=self[n]\n\n\tdef length(self):\n\t\treturn len(self)\n\n\tdef clone(self):\n\t\timport copy\n\t\treturn copy.copy(self)\n\n\t# return copy.deepcopy(self)\n\n\tdef flatten(self):\n\t\tfrom itertools import chain\n\t\treturn list(chain.from_iterable(self))\n\n\tdef __gt__(self, other):\n\t\tif not isinstance(other, list): other = [other]\n\t\treturn list.__gt__(self, other)\n\n\tdef __lt__(self, other):\n\t\tif not isinstance(other, list): other = [other]\n\t\treturn list.__lt__(self, other)\n\n\t# TypeError: unorderable types: int() < list() fucking python 3\n\t# def __cmp__(self, other):\n\t# \tif not isinstance(other, list): other = [other]\n\t# \treturn list.__cmp__(self, other)\n\n\tdef __sub__(self, other):  # xlist-[1]-[2] minus\n\t\tif not hasattr(other, \'__iter__\'): other = [other]\n\t\treturn xlist(i for i in self if i not in other)\n\n\tdef __rsub__(self, other):  # [1]-xlist-[2] ok!\n\t\treturn xlist(i for i in other if i not in self)\n\n\tdef c(self):\n\t\treturn xlist(map(str.c, self).join("", ""))  # leave [] which is not compatible with C\n\n\tdef wrap(self):\n\t\t# map(wrap).join("", "") # leave [] which is not compatible with C\n\t\treturn ""rb_ary_new3(#{size}/*size*\', #{wraps})""  # values\n\n\tdef wraps(self):\n\t\treturn xlist(map(lambda x: x.wrap, self).join("", ""))  # leave [] which is not compatible with C\n\n\tdef values(self):\n\t\treturn xlist(map(lambda x: x.value, self).join("", ""))  # leave [] which is not compatible with C\n\n\tdef contains_a(self, type):\n\t\tfor a in self:\n\t\t\tif isinstance(a, type): return True\n\t\treturn False\n\n\tdef drop(self, x):\n\t\treturn self.reject(x)\n\n\tdef to_s(self):\n\t\treturn self.join("", "")\n\n\t# ifdef $auto_map:\n\t# def method_missing(method, *args, block):\n\t#   if args.count==0: return self.map (lambda x: x.send(method ))\n\t#   if args.count>0: return self.map (lambda x: x.send(method, args) )\n\t# super method, *args, block\n\n\t# def matches(item):\n\t#   contains item\n\t#\n\t# remove: confusing!!\n\tdef matches(self, regex):\n\t\tfor i in self.flatten():\n\t\t\tm = regex.match(i.gsub(r\'([^\\w])\', ""\\\\\\\\\\\\1""))  # escape_token(i))\n\t\t\tif m:\n\t\t\t\treturn m\n\t\treturn False\n\n\tdef And(self, x):\n\t\tif not isinstance(x, list): self + [x]\n\t\treturn self + x\n\n\tdef plus(self, x):\n\t\tif not isinstance(x, list): self + [x]\n\t\treturn self + x\n\n\t# EVIL!!\n\t# not def(self):\n\t#   None? not or\n\n\t# def = x  unexpected \'=\':\n\t#  is x\n\t#\n\t# def grep(x):\n\t#  select{|y|y.to_s.match(x)}\n\t#\n\tdef names(self):\n\t\treturn xlist(map(str, self))\n\n\tdef rest(self, index=1):\n\t\treturn self[index:]\n\n\tdef fix_int(self, i):\n\t\tif str(i) == ""middle"": i = self.count() / 2\n\t\tif isinstance(i, Numeric): return i - 1\n\t\ti = xstr(i).parse_integer()\n\t\treturn i - 1\n\n\tdef character(self, nr):\n\t\treturn self.item(nr)\n\n\tdef item(self, nr):  # -1 AppleScript style ! BUT list[0] !\n\t\treturn self[xlist(self).fix_int(nr)]\n\n\tdef word(self, nr):  # -1 AppleScript style ! BUT list[0] !):\n\t\treturn self[xlist(self).fix_int(nr)]\n\n\tdef invert(self):  # ! Self modifying !\n\t\tself.reverse()\n\t\treturn self\n\n\tdef get(self, x):\n\t\treturn self[self.index(x)]\n\n\t# def row(self, n):\n\t#     return self.at(n)\n\n\tdef has(self, x):\n\t\treturn self.index(x)\n\n\tdef contains(self, x):\n\t\tok = self.index(x)\n\t\tif ok:\n\t\t\treturn self.at(self.index(x))\n\t\telse:\n\t\t\treturn False\n\n\t\t# def to_s:\n\t\t#  ""[""+join("", "")+""]""\n\t\t#\n\n\n\t\t# class TrueClass:\n\t\t#   not def(self):\n\t\t#     False\n\n\nclass FalseClass:\n\t# not def(self):\n\t#   True\n\n\tdef wrap(self):\n\t\treturn self\n\n\tdef c(self):\n\t\treturn self\n\n\n@extension\nclass xstr(str):\n\t# @staticmethod\n\t# def invert(self):\n\t#     r=reversed(self) #iterator!\n\t#     return """".join(r)\n\n\tdef invert(self):\n\t\tr = reversed(self)  # iterator!\n\t\tself = """".join(r)\n\t\treturn self\n\n\tdef inverse(self):\n\t\tr = reversed(self)  # iterator!\n\t\treturn """".join(r)\n\n\tdef reverse(self):\n\t\tr = reversed(self)  # iterator!\n\t\treturn """".join(r)\n\n\tdef to_i(self):\n\t\treturn int(self)\n\n\t# to_i=property(to_i1,to_i1)\n\n\tdef quoted(self):\n\t\treturn ""%s"" % self\n\n\t# def c(self):\n\t#     return self.quoted()\n\n\t# def id(self):\n\t#     return ""id(%s)"" % self\n\t#\n\t# def wrap(self):\n\t#     return ""s(%s)"" % self\n\n\t# def value(self):\n\t#     return self  # variable\n\t# quoted\n\n\t# def name(self):\n\t#     return self\n\n\tdef number(self):\n\t\treturn int(self)\n\n\tdef is_in(self, ary):\n\t\treturn ary.has(self)\n\n\tdef cut_to(self, pattern):\n\t\treturn self.sub(0, self.indexOf(pattern))\n\n\tdef matches(self, regex):\n\t\tif isinstance(regex, list):\n\t\t\tfor x in regex:\n\t\t\t\tif re.match(x):\n\t\t\t\t\treturn x\n\t\telse:\n\t\t\treturn re.match(regex)\n\t\treturn False\n\n\tdef strip_newline(self):\n\t\treturn self.strip()  # .sub(r\';$\', \'\')\n\n\tdef join(self, x):\n\t\treturn self + x\n\n\t# def < x:\n\t#   i=x.is_a?Numeric\n\t#   if i:\n\t#     return int(self)<x\n\t#\n\t#   super.< x\n\t#\n\tdef starts_with(self, x):\n\t\t# puts ""WARNING: start_with? missspelled as starts_with?""\n\t\tif isinstance(x, list):\n\t\t\tfor y in x:\n\t\t\t\tif self.startswith(y): return y\n\t\treturn self.startswith(x)\n\n\t# def show(self, x=None):\n\t#     print(x or self)\n\t#     return x or self\n\n\tdef contains(self, *things):\n\t\tfor t in flatten(things):\n\t\t\tif self.index(t): return True\n\t\treturn False\n\n\tdef fix_int(self, i):\n\t\tif str(i) == ""middle"": i = self.count / 2\n\t\tif isinstance(i, int): return i - 1\n\t\ti = xstr(i).parse_integer()\n\t\treturn i - 1\n\n\tdef sentence(self, i):\n\t\ti = self.fix_int(i)\n\t\treturn self.split(r\'[\\.\\?\\!\\;]\')[i]\n\n\tdef paragraph(self, i):\n\t\ti = self.fix_int(i)\n\t\treturn self.split(""\\n"")[i]\n\n\tdef word(self, i):\n\t\ti = self.fix_int(i)\n\t\treplaced = self.replace(""\\t"", "" "").replace(""  "", "" "").replace(""\\t"", "" "").replace(""  "", "" "")  # WTF\n\t\twords = replaced.split("" "")\n\t\tif i >= len(words): return self  # be gentle\n\t\treturn words[i]\n\n\tdef item(self, i):\n\t\treturn self.word(i)\n\n\tdef char(self, i):\n\t\treturn self.character(i)\n\n\tdef character(self, i):\n\t\ti = self.fix_int(i)\n\t\treturn self[i - 1:i]\n\n\tdef flip(self):\n\t\treturn self.split("" "").reverse.join("" "")\n\n\tdef plus(self, x):\n\t\treturn self + x\n\n\tdef _and(self, x):\n\t\treturn self + x\n\n\tdef add(self, x):\n\t\treturn self + x\n\n\tdef offset(self, x):\n\t\treturn self.index(x)\n\n\tdef __sub__(self, x):\n\t\treturn self.gsub(x, """")\n\n\t# self[0:self.index(x)-1]+self[self.index(x)+x.length:-1]\n\n\tdef synsets(self, param):\n\t\tpass\n\n\tdef is_noun(self):  # expensive!):\n\t\t# Sequel::InvalidOperation Invalid argument used for IS operator\n\t\treturn self.synsets(\'noun\') or self.gsub(r\'s$\', """").synsets(\'noun\')  # except False\n\n\tdef is_verb(self):\n\t\treturn self.synsets(\'verb\') or self.gsub(r\'s$\', """").synsets(\'verb\')\n\n\tdef is_a(className):\n\t\tclassName = className.lower()\n\t\tif className == ""quote"": return True\n\t\treturn className == ""string""\n\n\tdef is_adverb(self):\n\t\treturn self.synsets(\'adverb\')\n\n\tdef is_adjective(self):\n\t\treturn self.synsets(\'adjective\')\n\n\tdef examples(self):\n\t\treturn xlist(self.synsets.flatten.map(\'hyponyms\').flatten().map(\'words\').flatten.uniq.map(\'to_s\'))\n\n\t# def not_(self):\n\t#   return None or not\n\tdef lowercase(self):\n\t\treturn self.lower()\n\n\t# def replace(self,param, param1):\n\t#   pass\n\n\tdef replaceAll(self, pattern, string):\n\t\treturn re.sub(pattern, string, self)\n\n\tdef shift(self, n=1):\n\t\tn.times(self=self.replaceAll(r\'^.\', """"))\n\n\t# self[n:-1]\n\n\tdef replace_numerals(self):\n\t\tx = self\n\t\tx = x.replace(r\'([a-z])-([a-z])\', ""\\\\1+\\\\2"")  # WHOOOT???\n\t\tx = x.replace(""last"", ""-1"")  # index trick\n\t\t# x = x.replace(""last"", ""0"")  # index trick\n\t\tx = x.replace(""first"", ""1"")  # index trick\n\n\t\tx = x.replace(""tenth"", ""10"")\n\t\tx = x.replace(""ninth"", ""9"")\n\t\tx = x.replace(""eighth"", ""8"")\n\t\tx = x.replace(""seventh"", ""7"")\n\t\tx = x.replace(""sixth"", ""6"")\n\t\tx = x.replace(""fifth"", ""5"")\n\t\tx = x.replace(""fourth"", ""4"")\n\t\tx = x.replace(""third"", ""3"")\n\t\tx = x.replace(""second"", ""2"")\n\t\tx = x.replace(""first"", ""1"")\n\t\tx = x.replace(""zero"", ""0"")\n\n\t\tx = x.replace(""4th"", ""4"")\n\t\tx = x.replace(""3rd"", ""3"")\n\t\tx = x.replace(""2nd"", ""2"")\n\t\tx = x.replace(""1st"", ""1"")\n\t\tx = x.replace(""(\\d+)th"", ""\\\\1"")\n\t\tx = x.replace(""(\\d+)rd"", ""\\\\1"")\n\t\tx = x.replace(""(\\d+)nd"", ""\\\\1"")\n\t\tx = x.replace(""(\\d+)st"", ""\\\\1"")\n\n\t\tx = x.replace(""a couple of"", ""2"")\n\t\tx = x.replace(""a dozen"", ""12"")\n\t\tx = x.replace(""ten"", ""10"")\n\t\tx = x.replace(""twenty"", ""20"")\n\t\tx = x.replace(""thirty"", ""30"")\n\t\tx = x.replace(""forty"", ""40"")\n\t\tx = x.replace(""fifty"", ""50"")\n\t\tx = x.replace(""sixty"", ""60"")\n\t\tx = x.replace(""seventy"", ""70"")\n\t\tx = x.replace(""eighty"", ""80"")\n\t\tx = x.replace(""ninety"", ""90"")\n\n\t\tx = x.replace(""ten"", ""10"")\n\t\tx = x.replace(""eleven"", ""11"")\n\t\tx = x.replace(""twelve"", ""12"")\n\t\tx = x.replace(""thirteen"", ""13"")\n\t\tx = x.replace(""fourteen"", ""14"")\n\t\tx = x.replace(""fifteen"", ""15"")\n\t\tx = x.replace(""sixteen"", ""16"")\n\t\tx = x.replace(""seventeen"", ""17"")\n\t\tx = x.replace(""eighteen"", ""18"")\n\t\tx = x.replace(""nineteen"", ""19"")\n\n\t\tx = x.replace(""ten"", ""10"")\n\t\tx = x.replace(""nine"", ""9"")\n\t\tx = x.replace(""eight"", ""8"")\n\t\tx = x.replace(""seven"", ""7"")\n\t\tx = x.replace(""six"", ""6"")\n\t\tx = x.replace(""five"", ""5"")\n\t\tx = x.replace(""four"", ""4"")\n\t\tx = x.replace(""three"", ""3"")\n\t\tx = x.replace(""two"", ""2"")\n\t\tx = x.replace(""one"", ""1"")\n\t\tx = x.replace(""dozen"", ""12"")\n\t\tx = x.replace(""couple"", ""2"")\n\n\t\t# x = x.replace(""\xc2\xbd"", ""+.5"");\n\t\tx = x.replace(""\xc2\xbd"", ""+1/2.0"");\n\t\tx = x.replace(""\xe2\x85\x93"", ""+1/3.0"");\n\t\tx = x.replace(""\xe2\x85\x94"", ""+2/3.0"");\n\t\tx = x.replace(""\xc2\xbc"", ""+.25"");\n\t\tx = x.replace(""\xc2\xbc"", ""+1/4.0"");\n\t\tx = x.replace(""\xc2\xbe"", ""+3/4.0"");\n\t\tx = x.replace(""\xe2\x85\x95"", ""+1/5.0"");\n\t\tx = x.replace(""\xe2\x85\x96"", ""+2/5.0"");\n\t\tx = x.replace(""\xe2\x85\x97"", ""+3/5.0"");\n\t\tx = x.replace(""\xe2\x85\x98"", ""+4/5.0"");\n\t\tx = x.replace(""\xe2\x85\x99"", ""+1/6.0"");\n\t\tx = x.replace(""\xe2\x85\x9a"", ""+5/6.0"");\n\t\tx = x.replace(""\xe2\x85\x9b"", ""+1/8.0"");\n\t\tx = x.replace(""\xe2\x85\x9c"", ""+3/8.0"");\n\t\tx = x.replace(""\xe2\x85\x9d"", ""+5/8.0"");\n\t\tx = x.replace(""\xe2\x85\x9e"", ""+7/8.0"");\n\n\t\tx = x.replace("" hundred thousand"", "" 100000"")\n\t\tx = x.replace("" hundred"", "" 100"")\n\t\tx = x.replace("" thousand"", "" 1000"")\n\t\tx = x.replace("" million"", "" 1000000"")\n\t\tx = x.replace("" billion"", "" 1000000000"")\n\t\tx = x.replace(""hundred thousand"", ""*100000"")\n\t\tx = x.replace(""hundred "", ""*100"")\n\t\tx = x.replace(""thousand "", ""*1000"")\n\t\tx = x.replace(""million "", ""*1000000"")\n\t\tx = x.replace(""billion "", ""*1000000000"")\n\t\treturn x\n\n\tdef parse_integer(self):\n\t\tn = self.replace_numerals()\n\t\ti = int(n)  # except 666\n\t\t# i = int(eval(str(self)))  # except 666\n\t\treturn i\n\n\tdef parse_number(self):\n\t\tx = self.replace_numerals()\n\t\ttry:\n\t\t\tx = float(x)\n\t\texcept:\n\t\t\tx = eval(x)  # !! danger!\n\t\tif x == 0: return ""0""  # ZERO\n\t\treturn x\n\n\t# def __sub__(self, other): # []= MISSING in python!!\n\t#     x=""abc""\n\t#     >>> x[2]=\'a\'\n\t#     TypeError: \'str\' object does not support item assignment WTF\n\n\tdef reverse(self):\n\t\t# return self[slice(start=None,stop=None,step=-1)]\n\t\treturn self[::-1]  # very pythonic,  It works by doing [begin:end:step]\n\n\t# a slower approach is \'\'.join(reversed(s))\n\n\t@staticmethod\n\tdef reverse_string(str):\n\t\treturn xstr(str).reverse()\n\n\nclass xchar(unicode):  # unicode: multiple bases have instance lay-out conflict\n\tdef __coerce__(self, other):\n\t\tif isinstance(other, int):\n\t\t\tother = chr(other)\n\t\t# if isinstance(other,str):\n\t\t#     other=chr(other)\n\t\treturn type(other)(self), other\n\n\n# class Fixnum Float\n# class Numeric:\n# @Extension(int)\n@extension\nclass xint(int):\n\t# operator.truth(obj)\n\t#     Return True if obj is true, and False otherwise. This is equivalent to using the bool constructor.\n\t# operator.is_(a, b)\n\t#     Return a is b. Tests object identity.\n\t# operator.is_not(a, b)\n\t#     Return a is not b. Tests object identity.\n\n\tdef __coerce__(self, other):\n\t\treturn int(other)\n\n\t# def __cmp__(self, other):\n\t# \tif isinstance(other, list): return list.__cmp__([self], other)\n\n\tdef c(self):  # unwrap, for optimization):\n\t\treturn str(self)  # ""NUM2INT(#{self.to_s})""\n\n\tdef value(self):\n\t\treturn self\n\n\tdef wrap(self):\n\t\treturn ""INT2NUM(#{self.to_s})""\n\n\tdef number(self):\n\t\treturn self\n\n\tdef _and(self, x):\n\t\treturn self + x\n\n\tdef plus(self, x):\n\t\treturn self + x\n\n\tdef minus(self, x):\n\t\treturn self - x\n\n\tdef times(self, x):\n\t\tif callable(x):\n\t\t\treturn [x() for i in xrange(self)]\n\t\telse:\n\t\t\treturn self * x\n\n\tdef times_do(self, fun):\n\t\tx = None\n\t\tfor i in range(0, self):\n\t\t\tx = fun()\n\t\treturn x\n\n\tdef less(self, x):\n\t\tif isinstance(x, str): return self < int(x)\n\t\treturn super.__lt__(x)\n\n\tdef is_blank(self):\n\t\treturn False\n\n\tdef is_a(self, clazz):\n\t\tclassName = str(clazz).lower()\n\t\tif className == ""number"": return True\n\t\tif className == ""real"": return True\n\t\tif className == ""float"": return True\n\t\t# int = ALL : Fixnum = small int  AND :. Bignum = big : 2 ** (1.size * 8 - 2)\n\t\tif isinstance(self, int) and className == ""integer"": return True  # todo move\n\t\tif isinstance(self, int) and className == ""int"": return True\n\t\tif className == str(self).lower(): return True  # KINDA\n\t\tif self.isa(clazz): return True\n\t\treturn False\n\n\tdef add(self, x):\n\t\treturn self + x\n\n\tdef increase(self, by=1):\n\t\treturn self + by  # Can\'t change the value of numeric self!!\n\n\tdef decrease(self, by=1):\n\t\treturn self - by  # Can\'t change the value of numeric self!!\n\n\tdef bigger(self, x):\n\t\treturn self > x\n\n\tdef smaller(self, x):\n\t\treturn self < x\n\n\tdef to_the_power_of(self, x):\n\t\treturn self**x\n\n\tdef to_the(self, x):\n\t\treturn self**x\n\n\tdef logarithm(self):\n\t\treturn math.log(self)\n\n\tdef e(self):\n\t\treturn math.exp(self)\n\n\tdef exponential(self):\n\t\treturn math.exp(self)\n\n\tdef sine(self):\n\t\treturn math.sin(self)\n\n\tdef cosine(self):\n\t\treturn math.cos(self)\n\n\tdef root(self):\n\t\treturn math.sqrt(self)\n\n\tdef power(self, x):\n\t\treturn self**x\n\n\tdef square(self):\n\t\treturn self * self\n\n\t# todo: use ^^\n\tdef squared(self):\n\t\treturn self * self\n\n\nclass Numeric(xint):\n\tpass\n\n\nclass Integer(xint):\n\t@classmethod\n\tdef __eq__(self, other):\n\t\tif other == int: return True\n\t\tif other == xint: return True\n\t\tif other == Integer: return True\n\t\treturn False\n\n\n@extension\nclass xfloat(float):\n\tdef to_i(self):\n\t\treturn int(self)\n\n\tdef c(self):  # unwrap, for optimization):\n\t\treturn str(self)  # ""NUM2INT(#{self.to_s})""\n\n\tdef value(self):\n\t\treturn self\n\n\tdef number(self):\n\t\treturn self\n\n\tdef _and(self, x):\n\t\treturn self + x\n\n\tdef add(self, x):\n\t\treturn self + x\n\n\tdef plus(self, x):\n\t\treturn self + x\n\n\tdef minus(self, x):\n\t\treturn self - x\n\n\tdef times(self, x):\n\t\treturn self * x\n\n\tdef less(self, x):\n\t\tif isinstance(x, str): return self < int(x)\n\t\treturn super.__lt__(x)\n\n\tdef is_blank(self):\n\t\treturn False\n\n\tdef is_a(self, clazz):\n\t\tclassName = str(clazz).lower()\n\t\tif className == ""number"": return True\n\t\tif className == ""real"": return True\n\t\tif className == ""float"": return True\n\t\t# int = ALL : Fixnum = small int  AND :. Bignum = big : 2 ** (1.size * 8 - 2)\n\t\tif isinstance(self, int) and className == ""integer"": return True  # todo move\n\t\tif isinstance(self, int) and className == ""int"": return True\n\t\tif className == str(self).lower(): return True  # KINDA\n\t\tif self.isa(clazz): return True\n\t\treturn False\n\n\tdef increase(self, by=1):\n\t\treturn self + by  # Can\'t change the value of numeric self!!\n\n\tdef decrease(self, by=1):\n\t\treturn self - by  # Can\'t change the value of numeric self!!\n\n\tdef bigger(self, x):\n\t\treturn self > x\n\n\tdef smaller(self, x):\n\t\treturn self < x\n\n\tdef is_bigger(self, x):\n\t\treturn self > x\n\n\tdef is_smaller(self, x):\n\t\treturn self < x\n\n\tdef to_the_power_of(self, x):\n\t\treturn self**x\n\n\tdef to_the(self, x):\n\t\treturn self**x\n\n\tdef logarithm(self):\n\t\treturn math.log(self)\n\n\tdef e(self):\n\t\treturn math.exp(self)\n\n\tdef exponential(self):\n\t\treturn math.exp(self)\n\n\tdef sine(self):\n\t\treturn math.sin(self)\n\n\tdef cosine(self):\n\t\treturn math.cos(self)\n\n\tdef root(self):\n\t\treturn math.sqrt(self)\n\n\tdef power(self, x):\n\t\treturn self**x\n\n\tdef square(self):\n\t\treturn self * self\n\n\t# todo: use ^^\n\tdef squared(self):\n\t\treturn self * self\n\n\n# if self==false: return True\n# if self==True: return false\n# class Enumerator\n\n@extension  # DANGER?\nclass xobject:\n\tdef __init__(selfy):\n\t\tselfy.self = selfy\n\n\tdef value(self):\n\t\treturn self\n\n\tdef number(self):\n\t\treturn False\n\n\t# not def(self):\n\t# return    False\n\n\tdef throw(self, x):\n\t\traise x\n\n\tdef type(self):\n\t\treturn self.__class__\n\n\tdef kind(self):\n\t\treturn self.__class__\n\n\tdef log(*x):\n\t\tprint(x)\n\n\tdef debug(*x):\n\t\tprint(x)\n\n\tdef is_a(self, clazz):\n\t\tif self is clazz: return True\n\t\ttry:\n\t\t\tok = isinstance(self, clazz)\n\t\t\tif ok: return True\n\t\texcept Exception as e:\n\t\t\tprint(e)\n\n\t\tclassName = str(clazz).lower()\n\t\tif className == str(self).lower(): return True  # KINDA\n\n\t\tif self.is_(clazz): return True\n\t\treturn False\n\n\tdef is_(self, x):\n\t\tif not x and not self: return True\n\t\tif x == self: return True\n\t\tif x is self: return True\n\t\tif str(x).lower() == str(self).lower(): return True  # KINDA\n\t\tif isinstance(self, list) and self.length == 1 and x.is_(self[0]): return True\n\t\tif isinstance(x, list) and x.length == 1 and self.is_(x[0]):  return True\n\t\treturn False\n\n\ndef load(file):\n\treturn open(file, \'rt\').read()\n\n\ndef load_binary(file):\n\treturn open(file, \'rb\').read()\n\n\ndef read(file):\n\treturn open(file, \'rt\').read()\n\n\n\ndef readlines(source):\n\t# print(""open(source).readlines()"")\n\treturn list(map(str.strip, open(source).readlines()))\n\n# def readlines(file):\n# \treturn open(file, \'rt\').readlines()\n\n\ndef writelines(file, xs):\n\topen(file, \'wt\').write(""\\n"".join(xs))\n\ndef read_binary(file):\n\treturn open(file, \'rb\').read()\n\n\ndef dump(o, file=""dump.bin""):\n\tpickle.dump(o, open(file, \'wb\'), protocol=pickle.HIGHEST_PROTOCOL)\n\tprint(""saved to \'"" + file + ""\'"")\n\n\nsave = dump\nwrite = dump  # ok for plain bytes too++\n\n\ndef write_direct(data, file):\n\topen(file, \'wb\').write(data)\n\n\ndef load_pickle(file_name=""dump.bin""):\n\treturn pickle.load(open(file_name, \'rb\'))\n\n\ndef unpickle(file_name=""dump.bin""):\n\treturn pickle.load(open(file_name, \'rb\'))\n\n\ndef undump(file_name=""dump.bin""):\n\treturn pickle.load(open(file_name, \'rb\'))\n\n\ndef restore(file_name=""dump.bin""):\n\treturn pickle.load(open(file_name, \'rb\'))\n\n\ndef run(cmd):\n\tos.system(cmd)\n\n\ndef exists(file):\n\tos.path.exists(file)\n\n\n# class Encoding:\n#     pass\n\n\ndef find_in_module(module, match="""", recursive=True):  # all\n\tif isinstance(module, str):\n\t\tmodule = sys.modules[module]\n\tfor name, obj in inspect.getmembers(module):\n\t\t# if inspect.isclass(obj):\n\t\tif match in name:\n\t\t\tprint(obj)\n\t\tif inspect.ismodule(obj) and recursive and obj != module:\n\t\t\tif module.__name__ in obj.__name__:\n\t\t\t\t# print(""SUBMODULE: %s""%obj)\n\t\t\t\tfind_in_module(obj, match)\n\n\ndef find_class(match=""""):  # all\n\timport sys, inspect\n\tfor module in sys.modules.keys():  # sys.modules[module] #by key\n\t\tfor name, obj in inspect.getmembers(sys.modules[module]):\n\t\t\tif inspect.isclass(obj):\n\t\t\t\tif match in str(obj):\n\t\t\t\t\tprint(obj)\n\n\n# @extension\n# class Math:\n# WOOOT? just\n# import math as Math\n# def __getattr__(self, attr):\n#     import sys\n#     import math\n#  # ruby method_missing !\n#     import inspect\n#     for name, obj in inspect.getmembers(sys.modules[\'math\']):\n#         if name==attr: return obj\n#     return False\n\nprint(""extensions loaded"")\n'"
letter.py,0,"b'# coding=utf-8\nfrom random import randint\nfrom PIL import Image, ImageDraw, ImageFont\nimport os\n# import os.path\nimport numpy\nimport numpy as np\nfrom sys import platform\nfrom extensions import *\n\n# overfit = False\noverfit = True\nif overfit:\n\tprint(""using OVERFIT DEBUG DATA!"")\n\tmin_size = 24\n\tmax_size = 24\n\tmax_padding = 8\n\tmax_angle = 0\nelse:\n\tmin_size = 8  # 8#12\n\tmax_size = 32  # street view size, above that: scale image down!\n\tmax_padding=10\n\tmax_angle=45 #! +90deg. with lower probability! see (SVHN) Dataset\n\nshift_up = 9 # pull small letters up\nshift_left = 2 #\nmin_char = 32 # still keep ascii[0-32] for special data: \'white\' \'black\' \'noise\' background line! unicode\noffset = 32 #0  # vs min_char keep ascii[0-32] for special data\nextra_y=0\n\nsizes=range(min_size,max_size)\nif min_size==max_size: sizes=[min_size]\nletterz= list(map(chr, range(min_char, 128)))\nnLetters=len(letterz)\n\n\ndef find_fonts():\n\tif platform == ""darwin"":\n\t\tos.system(""mdfind -name \'.ttf\' | grep \'.ttf$\' | iconv -f utf-8 -t ascii  > fonts.list"")\n\telif ""win"" in platform:\n\t\tprint(""sorry, how do I find fonts on Windows? falling back to Menlo.ttf"")\n\t\treturn [""Menlo.ttf""]\n\telse:\n\t\tos.system(""locate \'.ttf\' | grep \'.ttf$\'  > fonts.list"")\n\treturn readlines(""fonts.list"")\n\n# copy all \'good\' fonts to one directory if you want\n# os.system(""mkdir -p ""+fonts_dir)\n\n# fonts={} # cache all?\ndef check_fonts():\n\tfor font in fontnames:\n\t\tif not exists(font.strip()):\n\t\t\tprint(""old font ""+font)\n\t\t\tfontnames.remove(font)\n\t\t\tcontinue\n\t\ttry:\n\t\t\tif not \'/\' in font :\n\t\t\t\tImageFont.truetype(fonts_dir+font, max_size)\n\t\t\t\tImageFont.truetype(fonts_dir+font, min_size)\n\t\t\telse:\n\t\t\t\tImageFont.truetype(font, max_size)\n\t\t\t\tImageFont.truetype(font, min_size)\n\t\t\tprint(""check_font OK "",font)\n\t\texcept:\n\t\t\tprint(""BAD font ""+font)\n\t\t\tfontnames.remove(font)\n\nif not os.path.exists(""fonts.list""):\n\tprint(""Building fonts.list"")\n\tfind_fonts()\nelse:\n\tprint(""Using cashed fonts.list"")\n\nfonts_dir=""/data/fonts/""\n\ntry:\n\tfontnames=readlines(""fonts.list"")\n\tif len(fontnames)==0:raise\nexcept:\n\tprint(""searching for local fonts"")\n\tfontnames=find_fonts()\n\ncheck_fonts()\nwritelines(""fonts.list"",  fontnames)\nif overfit:\n\tfontnames=fontnames[0:2] # ONLY 2 to overfit\n\nstyles=[\'regular\',\'light\',\'medium\',\'bold\',\'italic\']\n# Regular Medium Heavy Demi \'none\',\'normal\', Subsetted Sans #,\'underline\',\'strikethrough\']\n\nfrom enum import Enum\n\n# color_channels = 4 Useless: just use 6 \'gray\' channels! # RGBA\ncolor_channels = 1  # gray\n\ndef random_color():\n\tif color_channels<=1:\n\t\treturn None #pick(range(-90, 180))\n\t\t# return \'white\'  # None #pick(range(-90, 180))\n\tr = randint(0, 255)\n\tg = randint(0, 255)\n\tb = randint(0, 255)\n\ta = randint(0, 255)\n\treturn (r, g, b, a)\n\nclass Target(Enum):  # labels\n\tletter = 1\n\tsize = 2\n\tcolor = 3\n\tfont = 4\n\tposition = 5\n\tstyle = 6\n\tangle = 7\n\ttext = 8 \n\n\nclass Kind(Enum):\n\tblank = 0\n\tletter = 1\n\tdigit = 2  # special! e.g. House Numbers\n\tbackground = 3\n\tline = 4\n\temoji = 5  # special icons\n\tcolour_image = 6\n\tblack_and_white_image = 7\n\ticon = 8  # \'save\', favicons etc\n\tlatin = 9  # \xc3\xa5\xc2\xb5 ...\n\tmixed = 10 # needs disentangling\n\tarabic = 11\n\tchinese = 12  # also korean, japan ...\n\tcyril = 13\n\tunicode = 14\n\n\nnClasses={ # / dimensions\n\tTarget.letter: nLetters,  # classification\n\tTarget.font: len(fontnames),  # classification\n\tTarget.style: len(styles),  # classification\n\tTarget.size: 1,  # max_size # regression\n\tTarget.angle: 1,  # max_angle # regression\n\tTarget.position: 2,  # x,y # regression\n\tTarget.color: 3,  # RGB # regression\n\t# Target.invert: 1,  # -1 0 1\n\t# Target.mean: 1,  # -1 0 1\n}\n\n\nclass TargetType(Enum):\n\tclassification=1,\n\tregression = 2,  # also multi regression? :\n\tmulti_regression = 3,\n\tvector_generation = 4,  #\n\timage_generation = 5,\n\tstring = 6  # special vector\n\tmap = 7,\n\n\ntargetTypes={\n\tTarget.letter: TargetType.classification,\n\tTarget.font: TargetType.classification, # or string\n\tTarget.style: TargetType.classification,\n\tTarget.size: TargetType.regression,\n\tTarget.angle: TargetType.regression,\n\tTarget.position: TargetType.multi_regression, # x,y or box\n\tTarget.color: TargetType.multi_regression, # multi\n\tTarget.text: TargetType.string,\n\t# Target.word: TargetType.string,\n}\n\n\ndef pos_to_arr(pos):\n\treturn [pos[\'x\'],pos[\'y\']]\n\n\nclass batch():\n\n\tdef __init__(self,target=Target.letter, batch_size=64):\n\t\tself.batch_size=batch_size\n\t\tself.target= target\n\t\tself.shape=[max_size * max_size+extra_y, nClasses[target]]\n\t\t# self.shape=[batch_size,max_size,max_size,len(letters)]\n\t\tself.train= self\n\t\tself.test = self\n\t\tself.test.images,self.test.labels = self.next_batch()\n\n\tdef next_batch(self,batch_size=None):\n\t\tletters=[letter() for i in range(batch_size or self.batch_size)]\n\t\tdef norm(letter):\n\t\t\treturn letter.matrix()\n\t\txs=map(norm, letters) # 1...-1 range\n\t\tif self.target==Target.letter: ys=[one_hot(l.ord,nLetters,offset) for l in letters]\n\t\tif self.target == Target.size: ys = [l.size for l in letters]\n\t\tif self.target == Target.position: ys = [pos_to_arr(l.pos) for l in letters]\n\t\treturn list(xs), list(ys)\n\ndef pick(xs):\n\treturn xs[randint(0,len(xs)-1)]\n\n\ndef one_hot(item, num_classes,offset):\n\tlabels_one_hot = numpy.zeros(num_classes)\n\tlabels_one_hot[item-offset] = 1\n\treturn labels_one_hot\n\nclass letter():\n\t# fonts=\n\t# font=property(get_font,set_font)\n\t# number=property(lambda self:ord(self.char))\n\n\n\tdef __init__(self, *margs, **args): # optional arguments\n\t\tif not args:\n\t\t\tif margs: args=margs[0] # ruby style hash args\n\t\t\telse:args={}\n\t\t# super(Argument, self).__init__(*margs, **args)\n\t\t# self.name = args[\'name\']\t\tif \'name\' in args else None\n\t\t# self.family = args[\'family\'] if \'family\' in args else pick(families)\n\t\tself.font = args[\'font\'] if \'font\' in args else pick(fontnames)\n\t\tself.size = args[\'size\'] if \'size\' in args else pick(sizes)\n\t\tself.char = args[\'char\'] if \'char\' in args else pick(letterz)\n\t\tself.back = args[\'back\'] if \'back\' in args else None #self.random_color() # \'white\' #None #pick(range(-90, 180))\n\t\tself.ord\t= args[\'ord\'] if \'ord\' in args else ord(self.char)\n\t\tself.pos\t= args[\'pos\'] if \'pos\' in args else {\'x\':pick(range(0,max_padding)),\'y\':pick(range(0, max_padding))}\n\t\tself.angle= args[\'angle\'] if \'angle\' in args else 0#pick(range(-max_angle,max_angle))\n\t\tself.color= args[\'color\'] if \'color\' in args else \'black\'#\'white\'#self.random_color() #  #None #pick(range(-90, 180))\n\t\tself.style= args[\'style\'] if \'style\' in args else self.get_style(self.font)# pick(styles)\n\t\tself.invert=args[\'invert\'] if \'invert\' in args else pick([-1,0,1])\n\n\t# self.padding = self.pos\n\n\tdef projection(self):\n\t\treturn self.matrix(),self.ord\n\n\tdef get_style(self,font):\n\t\tif \'BI\' in font: return \'bold&italic\'\n\t\tif \'IB\' in font: return \'bold&italic\'\n\t\tif \'BoldItalic\' in font: return \'bold&italic\'\n\t\tif \'Black\' in font: return \'bold\' #~\n\t\tif \'Bol\' in font: return \'bold\'\n\t\tif \'bold\' in font: return \'bold\'\n\t\tif \'Bd\' in font: return \'bold\'\n\t\tif \'B.\' in font: return \'bold\'\n\t\tif \'B-\' in font: return \'bold\'\n\t\tif \'_RB\' in font: return \'bold\'\n\t\t# if \'-B\' in font: return \'bold\'\n\t\t# if \'_B\' in font: return \'bold\'\n\t\tif \'Ita\' in font: return \'italic\'\n\t\tif \'It.\' in font: return \'italic\'\n\t\tif \'I.\' in font: return \'italic\'\n\t\tif \'I-\' in font: return \'italic\'\n\t\tif \'_RI\' in font: return \'italic\'\n\t\tif \'Demi\' in font: return \'medium\'\n\t\tif \'Medi\' in font: return \'medium\'\n\t\tif \'Light\' in font: return \'light\'\n\t\tif \'Lt.\' in font: return \'light\'\n\t\tif \'Thin\' in font: return \'light\'\n\t# Mono\n\t\treturn \'regular\'\n\n\tdef matrix(self, normed=true):\n\t\tmatrix = np.array(self.image())\n\t\tif normed: matrix=matrix/ 255.\n\t\tif self.invert == -1:\n\t\t\tmatrix = 1 - 2 * matrix # -1..1\n\t\telif self.invert:\n\t\t\tmatrix = 1 - matrix # 0..1\n\t\treturn matrix\n\t\t# except:\n\t\t# \treturn np.array(max_size*(max_size+extra_y))\n\n\tdef load_font(self):\n\t\tfontPath = self.font if \'/\' in self.font else fonts_dir + self.font\n\t\ttry:\n\t\t\tfontPath = fontPath.strip()\n\t\t\tttf_font = ImageFont.truetype(fontPath, self.size)\n\t\texcept:\n\t\t\traise Exception(""BAD FONT: "" + fontPath)\n\t\treturn ttf_font\n\n\tdef image(self):\n\t\tttf_font = self.load_font()\n\t\tpadding = self.pos\n\t\ttext = self.char\n\t\tsize = ttf_font.getsize(text)\n\t\tsize = (size[0], size[1] + extra_y)\t# add margin\n\t\tsize = (self.size, self.size)\t# ignore rendered font size!\n\t\tsize = (max_size, max_size + extra_y)\t# ignore font size!\n\t\tif self.back:\n\t\t\timg = Image.new(\'RGBA\', size, self.back) # background_color\n\t\telse:\n\t\t\timg = Image.new(\'L\', size, \'white\')\t# # grey\n\t\tdraw = ImageDraw.Draw(img)\n\t\t# -\n\t\tdraw.text((padding[\'x\']-shift_left, padding[\'y\']-shift_up), text, font=ttf_font, fill=self.color)\n\t\tif self.angle:\n\t\t\trot = img.rotate(self.angle, expand=1).resize(size)\n\t\t\tif self.back:\n\t\t\t\timg = Image.new(\'RGBA\', size, self.back)  # background_color\n\t\t\telse:\n\t\t\t\timg = Image.new(\'L\', size,\'#FFF\')#FUCK BUG! \'white\')#,\'grey\')  # # grey\n\t\t\timg.paste(rot, (0, 0), rot)\n\t\treturn img\n\n\tdef show(self):\n\t\tself.image().show()\n\n\t@classmethod\n\tdef random(cls):\n\t\tl=letter()\n\t\tl.size=pick(sizes)\n\t\tl.font=pick(fontnames)\n\t\tl.char=pick(letterz)\n\t\tl.ord=ord(l.char)\n\t\tl.position=(pick(range(0,10)),pick(range(0,10)))\n\t\tl.offset=l.position\n\t\tl.style=pick(styles) #None #\n\t\tl.angle=0\n\n\tdef __str__(self):\n\t\tformat=""letter{char=\'%s\',size=%d,font=\'%s\',angle=%d,ord=%d,pos=%s}""\n\t\treturn format % (self.char, self.size, self.font, self.angle, ord(self.char), self.pos)\n\n\tdef __repr__(self):\n\t\treturn self.__str__()\n\t# def print(self):\n\t# \tprint(self.__str__)\n\tdef save(self, path):\n\t\tself.image().save(path)\n\n\n# @classmethod\t# can access class cls\n# def ls(cls, mypath=None):\n\n# @staticmethod\t# CAN\'T access class\n# def ls(mypath):\nimport matplotlib.pyplot as plt\n\ndef show_matrix(mat):\n\tplt.matshow(mat, fignum=1)\n\t# plt.imshow(image)\n\n\t# convolve(mat)\n\t# predict(mat)\n\n\tplt.draw()\n\tplt.waitforbuttonpress()\n\n\nif __name__ == ""__main__"":\n\twhile 1:\n\t\t# l = letter(char=\'x\')\n\t\tl = letter()\n\t\t# l.save(""letters/letter_%s_%d.png""%(l.char,l.size))\n\t\tmat=l.matrix()\n\t\tprint(np.max(mat))\n\t\tprint(np.min(mat))\n\t\tprint(np.average(mat))\n\t\tprint(l)\n\t\tshow_matrix(mat)\n\n\n'"
mouse_prediction.py,0,"b'#!/usr/bin/env python\nimport numpy\n\nimport numpy as np\nimport sys\n\nimport matplotlib.pyplot as plt\nimport pyscreenshot\n\nfrom text_recognizer import predict_tensor\n\ntry:\n  import Tkinter as tkinter\nexcept Exception as ex:\n  import tkinter\n\nif sys.platform == \'Windows\':\n  import win32api # GetCursorPos\n\napp = tkinter.Tk()  # must be declared before Mat\n\nplt.matshow([[1, 0], [0, 1]], fignum=1)\nplt.draw()\n\n# if mac\n# system(\'\'\'/usr/bin/osascript -e \'tell app ""Finder"" to set frontmost of process ""Python"" to true\' \'\'\')\n\ni = 0\n\ndef get_mouse_position():\n  if sys.platform == \'Windows\':\n    x, y = win32api.GetCursorPos()\n  else:\n    x, y = app.winfo_pointerxy()\n  return x, y\n\n\nif __name__ == ""__main__"":\n  while 1:\n    x, y = get_mouse_position()\n    # im = ImageGrab.grab() fullscreen\n    # image = ImageGrab.grab([x - 60, y - 20, x + 40, y + 20])\n    # image = ImageGrab.grab([x - 14, y - 14, x + 14, y + 14])\n    # image = ImageGrab.grab([x - 10, y - 10, x + 10, y + 10])\n    w = 512\n    h = 64\n    # image = pyscreenshot.grab([x - w/2, y - h / 2, x + w / 2, y + h / 2])\n    # image = pyscreenshot.grab([x - 10, y - 10, x + w - 10, y + h - 10]) # pointer\n    image = pyscreenshot.grab([x - 10, y , x + w - 10, y + h] ) # cursor\n    # image = pyscreenshot.grab([x, y, x + w, y + h])\n    mat = np.array(image) / 255.0  # RGBA: h*w*4\n\n    lines=numpy.average(mat, axis=1)\n    # todo make model robust to extra text\n    argmax = numpy.argmax(lines) # most white\n    argmin = numpy.argmin(lines) # most black\n    # if(argmax<argmin):\n    #   mat[:,:argmax,:]=1. # fill white above\n    # if(argmin<argmax):\n    #   mat[:,argmax:,:]=1. # fill white below\n    # todo: what if invert image!?\n\n    tensor = mat\n    print(tensor.shape)\n    # tensor=cv2.resize(tensor,(64,512))\n    if len(tensor.shape) == 2:\n      tensor = tensor.transpose((1, 0))\n      tensor = tensor[np.newaxis, :, :, np.newaxis]\n    elif len(tensor.shape) == 3:\n      mat = numpy.average(tensor, axis=2)  # R+G+B\n      tensor = tensor.transpose((2, 1, 0))  # 4*w*h\n      tensor = tensor[:, :, :, np.newaxis]\n\n    # mat = 1 - 2 * mat / 255.  # norm [-1,1] !\n    # mat = 1 - mat / 255.  # norm [0,1]! black=1\n    # mat = mat / 255.  # norm [0,1]! black=0 (default)\n\n    """"""\n\n TEST Text 01234 Hello     <- point your mouse here\n \n""""""\n\n    plt.matshow(mat, fignum=1)\n    # plt.imshow(image)\n\n    histogram = numpy.histogram(mat, bins=10, range=None, normed=False, weights=None, density=None)\n    print(argmax)\n\n    words = predict_tensor(tensor)\n    if len(words) > 0:\n      best = words[0]\n    else:\n      best = ""???""\n    print(""interpreted as: %s"" % (best))\n    plt.title(""predicted: "" + best)\n\n    plt.draw()\n    plt.pause(0.01)\n    del image\n    del mat\n\n  # k = cv2.waitKey(0) & 0xFF  # 0xFF To get the lowest byte.\n  # if k == 27: exit(0)\n'"
net.py,127,"b'from __future__ import print_function\n\nimport time\nimport numpy as np\nimport tensorflow as tf # needs tf > 1.0\nfrom tensorflow.contrib.tensorboard.plugins import projector  # for 3d PCA/ t-SNE\nfrom .tensorboard_util import *\n\nprint(""tf.__version__:%s"" % tf.__version__)\n\nstart = int(time.time())\n\ngpu = True\n# gpu = False\ndebug = False  # summary.histogram  : \'module\' object has no attribute \'histogram\' WTF\n# debug = True  # histogram_summary ...\n\n# clear_tensorboard()\nif debug:\n\tset_tensorboard_run(auto_increment=True)\n\trun_tensorboard(restart=False)\n\nvisualize_cluster = False  # NOT YET: \'ProjectorConfig\' object has no attribute \'embeddings\'\n\nweight_divider = 10.\ndefault_learning_rate = 0.001  # mostly overwritten, so ignore it\ndecay_steps = 100000\ndecay_size = 0.1\nsave_step = 10000  # if you don\'t want to save snapshots, set to 0\n\ncheckpoint_dir = ""checkpoints""\n_cpu = \'/cpu:0\'\n_gpu = \'/GPU:0\'\n\nif not os.path.exists(checkpoint_dir):\n\tos.makedirs(checkpoint_dir)\n\n\ndef nop(): return 0\n\n\ndef closest_unitary(A):\n\t"""""" Calculate the unitary matrix U that is closest with respect to the operator norm distance to the general matrix A. """"""\n\ttry:\n\t\timport scipy\n\t\tV, __, Wh = scipy.linalg.svd(A)\n\t\treturn np.matrix(V.dot(Wh))\n\texcept:\n\t\treturn A\n\n\nclass net:\n\tdef __init__(self, model, input_width=0, output_width=0, input_shape=[], name=0, learning_rate=default_learning_rate):\n\t\tself.fully_connected = self.dense  # alias\n\t\tdevice = _gpu if gpu else _cpu\n\t\tdevice = None  # auto\n\t\tprint(""Using device "", device)\n\t\twith tf.device(device):\n\t\t\tself.session = tf.Session()\n\t\t\tself.model = model\n\t\t\tself.input_shape = input_shape or [input_width, input_width]\n\t\t\tif not input_width: input_width, _ = self.get_data_shape()\n\t\t\tself.input_width = input_width\n\t\t\tself.last_width = self.input_width\n\t\t\tself.last_shape = self.input_shape\n\t\t\tself.output_width = output_width\n\t\t\tself.num_classes = output_width\n\t\t\t# self.batch_size=batch_size\n\t\t\tself.layers = []\n\t\t\tself.learning_rate = learning_rate\n\t\t\tif isinstance(model, str):\n\t\t\t\tself.name = model\n\t\t\t\tself.restore()\n\t\t\t\treturn\n\t\t\tself.name = model.__name__\n\t\t\tif input_width == 0:\n\t\t\t\traise Exception(""Please set input_width or input_shape"")\n\t\t\tif output_width == 0:\n\t\t\t\traise Exception(""Please set number of classes via output_width"")\n\t\t\tself.generate_model(model)\n\n\tdef get_data_shape(self):\n\t\tif self.input_shape:\n\t\t\tif len(self.input_shape) == 1: return [self.input_shape[0], 0]\n\t\t\treturn self.input_shape[0], self.input_shape[1]\n\t\ttry:\n\t\t\treturn self.data.shape[0], self.data.shape[-1]\n\t\texcept:\n\t\t\traise Exception(""Data does not have shape"")\n\n\tdef generate_model(self, model, name=\'\'):\n\t\tif not model: return self\n\t\twith tf.name_scope(\'state\'):\n\t\t\tself.keep_prob = tf.placeholder(tf.float32, name=""dropout_keep_prob"")  # 1 for testing! else 1 - dropout\n\t\t\tself.train_phase = tf.placeholder(tf.bool, name=\'train_phase\')\n\t\t\twith tf.device(_cpu): self.global_step = tf.Variable(0)\n\t\t\t# dont set, feed or increment global_step, tensorflow will do it automatically\n\t\twith tf.name_scope(\'data\'):\n\t\t\tif self.input_shape and len(self.input_shape) == 2:\n\t\t\t\tshape_ = [None, self.input_shape[0], self.input_shape[1]]  # batch:None\n\t\t\t\t# todo [None, *self.input_shape]\n\t\t\t\tself.x = x = self.input = tf.placeholder(tf.float32, shape_, name=""input_x"")\n\t\t\t\tself.last_shape = x\n\t\t\telif self.input_width:\n\t\t\t\tself.x = x = self.input = tf.placeholder(tf.float32, [None, self.input_width], name=""input_x"")\n\t\t\telse:\n\t\t\t\traise Exception(""need input_shape or input_width by now"")\n\t\t\tself.last_layer = self.x\n\t\t\ttf.add_to_collection(\'inputs\', self.x)\n\t\t\tself.y = y = self.target = tf.placeholder(tf.float32, [None, self.output_width], name=""target_y"")\n\t\t\ttf.add_to_collection(\'targets\', self.target)\n\t\twith tf.name_scope(\'model\'):\n\t\t\tmodel(self)\n\t\tif (self.last_width != self.output_width):\n\t\t\tself.classifier()  # 10 classes auto\n\n\tdef dropout(self, keep_rate=0.6):\n\t\tself.add(tf.nn.dropout(self.last_layer, keep_rate))\n\n\tdef add(self, layer):\n\t\tself.layers.append(layer)\n\t\tself.last_layer = layer\n\t\tself.last_shape = layer.get_shape()\n\n\tdef reshape(self, shape):\n\t\tself.last_layer = tf.reshape(self.last_layer, shape)\n\t\tself.last_shape = shape\n\t\tself.last_width = shape[-1]\n\n\t# BN also serve as a stochastic regularizer and makes dropout regularization redundant! Furthermore dropout never really helped when inserted between convolution layers and was most useful between fully connected layers.\n\t# when applying batchnorm you can drop biases [redundant: BN(x)=ax+b] and must increase learning rate!! ++\n\tdef batchnorm(self, input=None, center=False):  # for conv2d and fully_connected [only!?]\n\t\tif input is None: input = self.last_layer\n\t\tfrom tensorflow.contrib.layers.python.layers import batch_norm as batch_norm\n\t\twith tf.name_scope(\'batchnorm\') as scope:\n\t\t\t# mean, var = tf.nn.moments(input, axes=[0, 1, 2])\n\t\t\t# self.batch_norm = tf.nn.batch_normalization(input, mean, var, offset=1, scale=1, variance_epsilon=1e-6)\n\t\t\t# self.last_layer=self.batch_norm\n\t\t\t# activation_fn all in one go!  sigmoid: center=true! relu:center=False?\n\t\t\t# is_training why not automatic??  bad implementation: placeholder -> needs_moments\n\t\t\t# vs low level nn.batch_normalization(inputs, mean, variance, beta, gamma, epsilon)   # nn.fused_batch_norm\n\t\t\t# data_format: A string. `NHWC` vs NCHW WHY NOT AUTO??\n\t\t\t# activation_fn inline\n\t\t\ttrain_op = batch_norm(input, is_training=True, center=center, updates_collections=None, scope=scope)\n\t\t\ttest_op = batch_norm(input, is_training=False, updates_collections=None, center=False, scope=scope, reuse=True)\n\t\t\toutput = tf.cond(self.train_phase, lambda: train_op, lambda: test_op)\n\t\t\t# output=self.debug_print(output)\n\t\t\tself.add(output)\n\t\t\treturn output\n\n\tdef addLayer(self, nChannels, nOutChannels, do_dropout):\n\t\tident = self.last_layer\n\t\tself.batchnorm()\n\t\t# self.add(tf.nn.relu(ident)) # nChannels ?\n\t\tself.conv([3, 3, nChannels, nOutChannels], pool=False, dropout=do_dropout, norm=tf.nn.relu)  # None\n\t\tconcat = tf.concat(axis=3, values=[ident, self.last_layer])\n\t\tprint(""concat "", concat.get_shape())\n\t\tself.add(concat)\n\n\tdef addTransition(self, nChannels, nOutChannels, do_dropout):\n\t\tself.batchnorm()\n\t\tself.add(tf.nn.relu(self.last_layer))\n\t\tself.conv([1, 1, nChannels, nOutChannels], pool=True, dropout=do_dropout, norm=None)  # pool (2, 2)\n\n\t# self.add(tf.nn.SpatialConvolution(nChannels, nOutChannels, 1, 1, 1, 1, 0, 0))\n\n\n\t# Fully connected \'pyramid\' layer, allows very high learning_rate >0.1 (but don\'t abuse)\n\t# NOT TO BE CONFUSED with buildDenseConv below!\n\tdef fullDenseNet(self, hidden=20, depth=3, act=tf.nn.tanh, dropout=True, norm=None):  #\n\t\tif hidden > 100: print(""WARNING: denseNet uses O(n^2) quadratic memory for "" + str(hidden)) + "" hidden units""\n\t\tif depth < 3: print(\n\t\t\t""WARNING: did you mean to use Fully connected layer \'dense\'? Expecting depth>3 vs "" + str(depth))\n\t\tinputs = self.last_layer\n\t\tinputs_width = self.last_width\n\t\twidth = hidden\n\t\twhile depth > 0:\n\t\t\twith tf.name_scope(\'DenNet_{:d}\'.format(width)) as scope:\n\t\t\t\tprint(""dense width "", inputs_width, ""x"", width)\n\t\t\t\tnr = len(self.layers)\n\t\t\t\tweights = tf.Variable(tf.random_uniform([inputs_width, width], minval=-1. / width, maxval=1. / width),\n\t\t\t\t                      name=""weights"")\n\t\t\t\tbias = tf.Variable(tf.random_uniform([width], minval=-1. / width, maxval=1. / width),\n\t\t\t\t                   name=""bias"")  # auto nr + context\n\t\t\t\tdense1 = tf.matmul(inputs, weights, name=\'dense_\' + str(nr)) + bias\n\t\t\t\ttf.summary.histogram(\'dense_\' + str(nr), dense1)\n\t\t\t\ttf.summary.histogram(\'dense_\' + str(nr) + \'/sparsity\', tf.nn.zero_fraction(dense1))\n\t\t\t\ttf.summary.histogram(\'weights_\' + str(nr), weights)\n\t\t\t\ttf.summary.histogram(\'weights_\' + str(nr) + \'/sparsity\', tf.nn.zero_fraction(weights))\n\t\t\t\ttf.summary.histogram(\'bias_\' + str(nr), bias)\n\n\t\t\t\tif act: dense1 = act(dense1)\n\t\t\t\tif norm: dense1 = self.norm(dense1, lsize=1)  # SHAPE!\n\t\t\t\tif dropout: dense1 = tf.nn.dropout(dense1, self.keep_prob)\n\t\t\t\tself.add(dense1)\n\t\t\t\tself.last_width = width\n\t\t\t\tinputs = tf.concat(axis=1, values=[inputs, dense1])\n\t\t\t\tinputs_width += width\n\t\t\t\tdepth = depth - 1\n\t\tself.last_width = width\n\n\t# Densely Connected Convolutional Networks https://arxiv.org/abs/1608.06993\n\tdef buildDenseConv(self, nBlocks=3, nChannels=64, magic_factor=0):\n\t\tif magic_factor: print(""magic_factor DEPRECATED!"")\n\t\tdepth = 3 * nBlocks + 4\n\t\tif (depth - 4) % 3:  raise Exception(""Depth must be 3N + 4! (4,7,10,...) "")  # # layers in each denseblock\n\t\tN = (depth - 4) // 3\n\t\tprint(""N=%d"" % N)\n\t\tdo_dropout = True  # None  nil to disable dropout, non - zero number to enable dropout and set drop rate\n\t\t# dropRate = self.keep_prob # nil to disable dropout, non - zero number to enable dropout and set drop rate\n\t\t# channels before entering the first denseblock ??\n\t\t# set it to be comparable with growth rate ??\n\n\t\tgrowthRate = 12\n\t\tself.conv([3, 3, 1, nChannels])  # why this\n\t\t# self.conv([1, 3, 3, nChannels]) # and not this?\n\n\t\t# self.add(tf.nn.SpatialConvolution(3, nChannels, 3, 3, 1, 1, 1, 1))\n\n\t\tfor i in range(N):\n\t\t\tself.addLayer(nChannels, growthRate, do_dropout)\n\t\t\tnChannels += growthRate\n\t\tself.addTransition(nChannels, nChannels, do_dropout)\n\n\t\tfor i in range(N):\n\t\t\tself.addLayer(nChannels, growthRate, do_dropout)\n\t\t\tnChannels += growthRate\n\t\tself.addTransition(nChannels, nChannels, do_dropout)\n\n\t\tfor i in range(N):\n\t\t\tself.addLayer(nChannels, growthRate, do_dropout)\n\t\t\tnChannels += growthRate\n\n\t\tself.batchnorm()\n\t\tself.add(tf.nn.relu(self.last_layer))\n\t\t# self.add(tf.nn.max_pool(self.last_layer, ksize=[1, 8, 8, 1], strides=[1, 2, 2, 1], padding=\'SAME\'))\n\t\t# self.add(tf.nn.max_pool(self.last_layer, ksize=[1, 8, 8, 1], strides=[1, 1, 1, 1], padding=\'SAME\'))\n\t\t# self.add(tf.nn.max_pool(self.last_layer, ksize=[1, 4, 4, 1], strides=[1, 1, 1, 1], padding=\'SAME\'))\n\t\tself.add(tf.nn.max_pool(self.last_layer, ksize=[1, 4, 4, 1], strides=[1, 2, 2, 1], padding=\'SAME\'))\n\t\t# self.add(tf.nn.SpatialAveragePooling(8, 8)).add(nn.Reshape(nChannels))\n\n\t\tshape = self.last_layer.get_shape()\n\t\tnBytes = shape[1] * shape[2] * shape[3]\n\t\tself.reshape([-1, int(nBytes)])  # ready for classification\n\n\t# Today\'s most performant vision models don\'t use fully connected layers anymore (they use convolutional blocks till the end and then some parameterless global averaging layer).\n\t# Fully connected layer\n\tdef dense(self, hidden=1024, depth=1, activation=tf.nn.tanh, dropout=False, parent=-1, bn=False):  #\n\t\tif parent == -1: parent = self.last_layer\n\t\tif bn:\n\t\t\tprint(""dropout = False while using batchnorm"")\n\t\t\tdropout = False\n\t\tshape = self.last_layer.get_shape()\n\t\tif shape and len(shape) > 2:\n\t\t\tif len(shape) == 3:\n\t\t\t\tself.last_width = int(shape[1] * shape[2])\n\t\t\telse:\n\t\t\t\tself.last_width = int(shape[1] * shape[2] * shape[3])\n\t\t\tif self.last_width == 0:\n\t\t\t\traise Exception(""self.last_width Must not be zero"")\n\t\t\tprint(""reshaping "", shape, ""to"", self.last_width)\n\t\t\tparent = tf.reshape(parent, [-1, self.last_width])\n\n\t\twidth = hidden\n\t\twhile depth > 0:\n\t\t\twith tf.name_scope(\'Dense_{:d}\'.format(hidden)) as scope:\n\t\t\t\tprint(""Dense "", self.last_width, width)\n\t\t\t\tnr = len(self.layers)\n\t\t\t\tU = tf.random_uniform([self.last_width, width], minval=-1. / width, maxval=1. / width)\n\t\t\t\t# U = np.random.rand(self.last_width, width) / (self.last_width + width)\n\t\t\t\tif self.last_width == width:\n\t\t\t\t\tU = closest_unitary(U / weight_divider)\n\t\t\t\tweights = tf.Variable(U, name=""weights_dense_"" + str(nr), dtype=tf.float32)\n\t\t\t\tbias = tf.Variable(tf.random_uniform([width], minval=-1. / width, maxval=1. / width), name=""bias_dense"")\n\t\t\t\tdense1 = tf.matmul(parent, weights, name=\'dense_\' + str(nr)) + bias\n\t\t\t\ttf.summary.histogram(\'dense_\' + str(nr), dense1)\n\t\t\t\ttf.summary.histogram(\'weights_\' + str(nr), weights)\n\t\t\t\ttf.summary.histogram(\'bias_\' + str(nr), bias)\n\t\t\t\ttf.summary.histogram(\'dense_\' + str(nr) + \'/sparsity\', tf.nn.zero_fraction(dense1))\n\t\t\t\ttf.summary.histogram(\'weights_\' + str(nr) + \'/sparsity\', tf.nn.zero_fraction(weights))\n\t\t\t\tif bn: dense1 = self.batchnorm(dense1, center=True)\n\t\t\t\tif activation: dense1 = activation(dense1)\n\t\t\t\tif dropout: dense1 = tf.nn.dropout(dense1, self.keep_prob)\n\t\t\t\tself.layers.append(dense1)\n\t\t\t\tself.last_layer = parent = dense1\n\t\t\t\tself.last_width = width\n\t\t\t\tdepth = depth - 1\n\t\t\t\tself.last_shape = [-1, width]  # dense\n\n\tdef conv2(self, shape, act=tf.nn.relu, pool=True, dropout=False, norm=True, name=None):\n\t\twith tf.name_scope(\'conv\'):\n\t\t\tprint(""input  shape "", self.last_shape)\n\t\t\tprint(""conv   shape "", shape)\n\t\t\t# padding=\'VALID\'\n\t\t\tconv = slim.conv2d(self.last_layer, shape[-1], [shape[1], shape[2]], 3, padding=\'SAME\', scope=name)\n\t\t\t# if pool: conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\t\t\t# if(pool): conv = slim.max_pool2d(conv, [2, 2], 1, scope=\'pool1\')\n\t\t\t# if(pool): conv = slim.max_pool2d(conv, [3, 3], 2, scope=\'pool1\')\n\t\t\tself.add(conv)\n\n\t# Convolution Layer\n\tdef conv(self, shape, act=tf.nn.relu, pool=True, dropout=False, norm=True,\n\t         name=None):  # True why dropout bad in tensorflow??\n\t\twith tf.name_scope(\'conv\'):\n\t\t\tprint(""input  shape "", self.last_shape)\n\t\t\tprint(""conv   shape "", shape)\n\t\t\twidth = shape[-1]\n\t\t\tfilters = tf.Variable(tf.random_normal(shape), name=""filters"")\n\t\t\t# filters = tf.Variable(tf.random_uniform(shape, minval=-1. / width, maxval=1. / width), name=""filters"")\n\t\t\t_bias = tf.Variable(tf.random_normal([shape[-1]]), name=""bias"")\n\n\t\t\t# # conv1 = conv2d(\'conv\', _X, _weights, _bias)\n\t\t\tconv1 = tf.nn.bias_add(tf.nn.conv2d(self.last_layer, filter=filters, strides=[1, 1, 1, 1], padding=\'SAME\'), _bias)\n\t\t\tif debug: tf.summary.histogram(\'conv_\' + str(len(self.layers)), conv1)\n\t\t\tif act: conv1 = act(conv1)\n\t\t\tif pool: conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\t\t\tif norm: conv1 = tf.nn.lrn(conv1, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n\t\t\tif debug: tf.summary.histogram(\'norm_\' + str(len(self.layers)), conv1)\n\t\t\tif dropout: conv1 = tf.nn.dropout(conv1, self.keep_prob)\n\t\t\tprint(""output shape "", conv1.get_shape())\n\t\t\tself.add(conv1)\n\n\tdef rnn(self, num_hidden=42):\n\t\t# tf.contrib.rnn.BasicLSTMCell() OLD\n\t\t# tensorflow.python.ops.rnn_cell.BasicLSTMCell()\n\t\t# tensorflow.models.rnn.BasicLSTMCell()\n\t\tcell = tf.nn.rnn_cell.LSTMCell(num_hidden)\n\t\tval, _ = tf.nn.dynamic_rnn(cell, self.last_layer, dtype=tf.float32)\n\t\t# Dropout does actually work quite well between recurrent units if you tie the dropout masks across time\n\t\t# val = tf.nn.dropout(val,self.keep_prob) # deprecated by batchnorm\n\t\tval = tf.transpose(val, [1, 0, 2])\n\t\tself.last = tf.gather(val, int(val.get_shape()[0]) - 1)\n\n\tdef classifier(self, classes=0):  # Define loss and optimizer\n\t\tif not classes: classes = self.num_classes\n\t\tif not classes: raise Exception(""Please specify num_classes"")\n\t\twith tf.name_scope(\'prediction\'):  # prediction\n\t\t\tif self.last_width != classes:\n\t\t\t\t# print(""Automatically adding dense prediction"")\n\t\t\t\tself.dense(hidden=classes, activation=None, dropout=False)\n\t\t\t# cross_entropy = -tf.reduce_sum(y_*y)\n\t\twith tf.name_scope(\'classifier\'):\n\t\t\ty_ = self.target\n\t\t\tmanual = False  # True\n\t\t\tif classes > 100:\n\t\t\t\tprint(""using sampled_softmax_loss"")\n\t\t\t\ty = prediction = self.last_layer\n\t\t\t\tself.cost = tf.reduce_mean(tf.nn.sampled_softmax_loss(y, y_))  # for big vocab\n\t\t\telif manual:\n\t\t\t\t# prediction = y =self.last_layer=tf.nn.softmax(self.last_layer)\n\t\t\t\t# self.cost = cross_entropy = -tf.reduce_sum(y_ * tf.log(y+ 1e-10)) # against NaN!\n\t\t\t\tprediction = y = tf.nn.log_softmax(self.last_layer)\n\t\t\t\tself.cost = cross_entropy = -tf.reduce_sum(y_ * y)\n\t\t\telse:\n\t\t\t\tself.output = y = prediction = self.last_layer\n\t\t\t\tself.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))  # prediction, target\n\t\t\ttf.add_to_collection(\'outputs\', self.output)\n\n\t\t\t# if not gpu:\n\t\t\twith tf.device(_cpu):\n\t\t\t\ttf.summary.scalar(\'cost\', self.cost)\n\t\t\t# self.cost = tf.Print(self.cost , [self.cost ], ""debug cost : "")\n\t\t\t# learning_scheme=self.learning_rate\n\t\t\tlearning_scheme = tf.train.exponential_decay(self.learning_rate, self.global_step, decay_steps, decay_size,\n\t\t\t                                             staircase=True)\n\t\t\twith tf.device(_cpu):\n\t\t\t\ttf.summary.scalar(\'learning_rate\', learning_scheme)\n\t\t\tself.optimize = tf.train.AdamOptimizer(learning_scheme).minimize(self.cost)\n\t\t\t# self.optimizer = NeuralOptimizer(data=None, learning_rate=0.01, shared_loss=self.cost).minimize(self.cost) No good\n\n\t\t\t# Evaluate model\n\t\t\tcorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(self.target, 1))\n\t\t\tself.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\t\t\t# if not gpu:\n\t\t\ttf.summary.scalar(\'accuracy\', self.accuracy)\n\t\t# Launch the graph\n\n\t# noinspection PyAttributeOutsideInit\n\tdef regression(self, dimensions, tolerance=3.):\n\t\t# self.dense(100)\n\t\twith tf.name_scope(""regression""):\n\t\t\tself.dense(dimensions)\n\t\t\tself.y = tf.placeholder(tf.float32, [None, dimensions], name=""target_y"")  # self.batch_size\n\t\t\tprint(""REGRESSION \'accuracy\' might not be indicative, watch loss"")\n\t\t\twith tf.name_scope(""train""):\n\t\t\t\t# self.learning_rate = tf.Variable(0.5, trainable=False)\n\t\t\t\tself.cost = tf.reduce_mean(tf.pow(self.y - self.last_layer, 2))\n\t\t\t\tself.optimize = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n\t\t\t\tself.accuracy = tf.maximum(0., 100 - tf.sqrt(self.cost)/tolerance)\n\t\t\t\t# self.accuracy = 1 - abs(self.y - self.last_layer)\n\t\t\t\ttf.add_to_collection(\'train_ops\', [self.learning_rate, self.cost, self.optimize, self.accuracy])\n\n\tdef debug_print(self, throughput, to_print=[]):\n\t\treturn tf.cond(self.train_phase, lambda: throughput, lambda: tf.Print(throughput, to_print + [nop()], ""OK!""))\n\n\tdef next_batch(self, batch_size, session, test=False):\n\t\t# self.data either a generator or a data struct with properties .train/test.images/labels\n\t\ttry:\n\t\t\tif test:\n\t\t\t\ttest_images = self.data.test.images[:batch_size]\n\t\t\t\ttest_labels = self.data.test.labels[:batch_size]\n\t\t\t\treturn test_images, test_labels\n\t\t\treturn self.data.train.next_batch(batch_size)\n\t\texcept:\n\t\t\ttry:\n\t\t\t\treturn next(self.data)\n\t\t\texcept:\n\t\t\t\treturn next(self.data.train)\n\n\tdef train(self, data=0, steps=-1, dropout=None, display_step=10, test_step=100, batch_size=10,\n\t          resume=save_step):  # epochs=-1,\n\t\tprint(""learning_rate: %f"" % self.learning_rate)\n\t\tif data: self.data = data\n\t\tsteps = 9999999 if steps < 0 else steps\n\t\tsession = self.session\n\t\t# with tf.device(_cpu):\n\t\t# t = tf.verify_tensor_all_finite(t, msg)\n\t\ttf.add_check_numerics_ops()\n\t\tself.summaries = tf.summary.merge_all()\n\t\tself.summary_writer = tf.summary.FileWriter(current_logdir(), session.graph)  \n\t\tif not dropout: dropout = 1.  # keep all\n\t\tx = self.x\n\t\ty = self.y\n\t\tkeep_prob = self.keep_prob\n\t\tif not resume or not self.resume(session):\n\t\t\tsession.run([tf.global_variables_initializer()])\n\t\tsaver = tf.train.Saver(tf.global_variables())\n\t\tsnapshot = self.name + str(get_last_tensorboard_run_nr())\n\t\tstep = 0  # show first\n\t\twhile step < steps:\n\t\t\tbatch_xs, batch_ys = self.next_batch(batch_size, session)\n\t\t\t# batch_xs=np.array(batch_xs).reshape([-1]+self.input_shape)\n\t\t\t# print(""step %d \\r"" % step)# end=\' \')\n\t\t\t# tf.train.shuffle_batch_join(example_list, batch_size, capacity=min_queue_size + batch_size * 16, min_queue_size)\n\t\t\t# Fit training using batch data\n\t\t\tfeed_dict = {x: batch_xs, y: batch_ys, keep_prob: dropout, self.train_phase: True}\n\t\t\tloss, _ = session.run([self.cost, self.optimize], feed_dict=feed_dict)\n\t\t\tif step % display_step == 0:\n\t\t\t\tseconds = int(time.time()) - start\n\t\t\t\t# Calculate batch accuracy, loss\n\t\t\t\tfeed = {x: batch_xs, y: batch_ys, keep_prob: 1., self.train_phase: False}\n\t\t\t\tacc, summary = session.run([self.accuracy, self.summaries], feed_dict=feed)\n\t\t\t\t# self.summary_writer.add_summary(summary, step) # only test summaries for smoother curve\n\t\t\t\tprint(""\\rStep {:d} Loss= {:.6f} Accuracy= {:.3f} Time= {:d}s"".format(step, loss, acc, seconds), end=\' \')\n\t\t\t\tif str(loss) == ""nan"": return print(""\\nLoss gradiant explosion, exiting!"")  # restore!\n\t\t\tif step % test_step == 0: self.test(step)\n\t\t\tif step % save_step == 0 and step > 0:\n\t\t\t\tprint(""SAVING snapshot %s"" % snapshot)\n\t\t\t\tsaver.save(session, checkpoint_dir + ""/"" + snapshot + "".ckpt"", self.global_step)\n\n\t\t\tstep += 1\n\t\tprint(""\\nOptimization Finished!"")\n\t\tself.test(step, number=10000)  # final test\n\n\tdef test(self, step, number=400):  # 256 self.batch_size\n\t\tsession = sess = self.session\n\t\tconfig = projector.ProjectorConfig()\n\t\tif visualize_cluster:  # EMBEDDINGs ++ https://github.com/tensorflow/tensorflow/issues/6322\n\t\t\tembedding = config.embeddings.add()  # You can add multiple embeddings. Here just one.\n\n\t\trun_metadata = tf.RunMetadata()\n\t\trun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n\t\t# Calculate accuracy for 256 mnist test images\n\n\t\ttest_images, test_labels = self.next_batch(number, session, test=True)\n\t\t# test_images = np.array(test_images).reshape([-1] + self.input_shape)\n\n\t\tfeed_dict = {self.x: test_images, self.y: test_labels, self.keep_prob: 1., self.train_phase: False}\n\t\t# accuracy,summary= self.session.run([self.accuracy, self.summaries], feed_dict=feed_dict)\n\t\taccuracy, summary = session.run([self.accuracy, self.summaries], feed_dict, run_options, run_metadata)\n\t\tprint(\'\\t\' * 3 + ""Test Accuracy: {:.2f}"".format( accuracy))\n\t\tself.summary_writer.add_run_metadata(run_metadata, \'step #%03d\' % step)\n\t\tself.summary_writer.add_summary(summary, global_step=step)\n\t\tif accuracy == 1.0:\n\t\t\tprint(""OVERFIT OK. Early stopping"")\n\t\t\texit(0)\n\n\tdef resume(self, session):\n\t\tcheckpoint = tf.train.latest_checkpoint(checkpoint_dir)\n\t\tif checkpoint:\n\t\t\tif self.name and not self.name in checkpoint:\n\t\t\t\tprint(""IGNORING checkpoint of other run : "" + checkpoint + "" !"")\n\t\t\t\tcheckpoint = None\n\t\telse:\n\t\t\tprint(""NO checkpoint, nothing to resume"")\n\t\tif checkpoint:\n\t\t\tprint(""LOADING "" + checkpoint + "" !"")\n\t\t\ttry:\n\t\t\t\tpersister = tf.train.Saver(tf.global_variables())\n\t\t\t\tpersister.restore(session, checkpoint)\n\t\t\t\tprint(""resume checkpoint successful!"")\n\t\t\t\treturn True\n\t\t\texcept Exception as ex:\n\t\t\t\tprint(ex)\n\t\t\t\tprint(""CANNOT LOAD checkpoint %s !"" % checkpoint)\n\t\treturn False\n\n\tdef restore(self):  # name\n\t\t# if not session: session= tf.Session()\n\t\tself.session = tf.Session()\n\t\tcheckpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n\t\tif checkpoint and checkpoint.model_checkpoint_path:\n\t\t\tprint(""Restoring old model from meta graph"")\n\t\t\tloader = tf.train.import_meta_graph(checkpoint.model_checkpoint_path + "".meta"")\n\t\telse:\n\t\t\tprint(""No model from meta graph, nothing to restore"")\n\t\t\treturn self\n\t\tself.session.run(tf.global_variables_initializer())\n\t\tprint(""loading checkpoint %s"" % checkpoint.model_checkpoint_path)\n\t\ttry:\n\t\t\tloader.restore(self.session, tf.train.latest_checkpoint(checkpoint_dir))\n\t\texcept:\n\t\t\tpass\n\t\t# loader.restore(self.session , checkpoint) #Unable to get element from the feed as bytes!  HUH??\n\t\tself.input = self.x = tf.get_collection(\'inputs\')[0]\n\t\tself.target = self.y = tf.get_collection(\'targets\')[0]\n\t\tself.output = self.last_layer = tf.get_collection(\'outputs\')[0]\n\t\tself.dropout_keep_prob = self.session.graph.get_tensor_by_name(""state/dropout_keep_prob:0"")  # :0 WTF!?!?!\n\t\tself.train_phase = self.session.graph.get_tensor_by_name(name=\'state/train_phase:0\')\n\t\treturn self\n\n\tdef predict(self, eval_data=None, model=None):\n\t\tif eval_data is None:\n\t\t\teval_data = np.random.random(self.input_shape)\n\t\tfeed_dict = {self.x: [eval_data], self.dropout_keep_prob: 1.0, self.train_phase: False}\n\t\tresult = self.session.run([self.output], feed_dict)\n\t\tbest = np.argmax(result)\n\t\t# print(""prediction: %s"" % result)\n\t\tprint(""predicted: %s"" % best)\n\t\treturn best\n'"
predict_image.py,2,"b'#!/usr/bin/python\nimport layer\nimport letter\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom letter import letter as l\nsize = letter.max_size\n# def denseConv(net):\n# \t# type: (layer.net) -> None\n# \tprint(""Building dense-net"")\n# \tnet.reshape(shape=[-1, size, size, 1])  # Reshape input picture\n# \tnet.buildDenseConv(nBlocks=1)\n# \tnet.classifier()  # 10 classes auto\n# # net=layer.net(alex,input_width=28, output_width=nClasses, learning_rate=learning_rate) # NOPE!?\n# net = layer.net(denseConv, input_width=size, output_width=letter.nClasses)\n\n# # LOAD MODEL!\nnet = layer.net(model=""denseConv"", input_shape=[size, size])\n# net = layer.net(model=""denseConv"", input_shape=[784])\n# net.predict()  # random : debug\n\n# net.generate(3)  # nil=random\ndef norm(mat):\n\tmat = 1 - 2 * mat / 255.  # norm [-1,1] !\n# mat = 1 - mat / 255.  # norm [0,1]!\n# mat = mat / 255.  # norm [0,1]!\n\ndef predict(mat,norm=False):\n\ttry:\n\t\tbest = net.predict(mat)\n\t\tbest = chr(best)\n\t\tprint(best)\n\t\treturn best\n\texcept Exception as ex:\n\t\tprint(""%s"" % ex)\n\t# plt.waitforbuttonpress(0)\n\t# plt.close()\n\n\n# noinspection PyTypeChecker\ndef convolve(mat):\n\tX = 1\n\tsession=tf.Session()\n\tt = letter.letter(font=""Menlo.ttc"", size=size, char=""X"")\n\tmat = t.matrix()\n\t# plt.matshow(filter,fignum=2)\n\t# mat = np.reshape(mat, [1, image.height, image.width, 1]).astype(np.float32)\n\t# f_ = np.reshape([[f]], [3, 3])\n\tfilter = np.reshape(filter, [size, size, 1, 1]).astype(np.float32)\n\tconv = tf.nn.conv2d(mat, filter, strides=[1, 1, 1, 1], padding=\'SAME\')  # VALID\n\tret = session.run(conv)\n\tret = np.reshape(ret, [size, size])\n\tplt.matshow(ret, fignum=2)\n\tscore = np.max(ret)\n\tplt.title(""score: %f"" % score)\n\n\nassert predict(l(char=""a"").matrix())==""A"" # Case insensitive prediction for now\n'"
setup.py,0,"b'from __future__ import print_function\n\nimport warnings\nfrom setuptools import setup, find_packages, Extension\nfrom setuptools.command.install import install\n\nclass layer_install(install):\n    def run(self):\n        print(""please type `install`.\\n"")\n        mode = None\n        return install.run(self)\n\ncmdclass = {}\next_modules = []\ncmdclass.update({\'install\': layer_install})\n\nsetup(\n    cmdclass=cmdclass,\n    ext_modules=ext_modules,\n    name=\'layer\',\n    version=""0.1.11"",\n    author=""Pannous"",\n    author_email=""info@pannous.com"",\n    packages=find_packages(),\n    description=\'tensorflow custom comfort wrapper\',\n    license=\'Apache2 license\',\n    long_description=open(\'README.md\', \'rb\').read().decode(\'utf8\'),\n    dependency_links=[\'git+http://github.com/pannous/context.git#egg=layer\'],\n    install_requires=[\'tensorflow\'],\n    # scripts=[\'bin/angle\'],\n    package_data={\n        # \'\': [\'*.cu\', \'*.cuh\', \'*.h\'],\n    },\n)\n'"
tensorboard_util.py,1,"b'import os\nimport sys\nimport subprocess  # NEW WAY!\n\nif ""win32"" in sys.platform:\n\ttensorboard_logs = \'./logs/\' # windows friendly\nelse:\n\ttensorboard_logs = \'/tmp/tensorboard_logs/\'\n\nglobal logdir\n\ndef get_last_tensorboard_run_nr():\n\ttry:\n\t\tlogs=subprocess.check_output([""ls"", tensorboard_logs]).split(""\\n"")\n\texcept:\n\t\tos.system(""mkdir "" + tensorboard_logs)\n\t\tprint(""first run!"")\n\t\treturn 0\n\t# print(""logs: "",logs)\n\truns=map(lambda x: (not x.startswith(""run"") and -1) or int(x[-1]) ,logs)\n\t# print(""runs "",runs)\n\tif runs==9: runs=0 # restart\n\treturn max(runs)+1\n\n\n\ndef set_tensorboard_run(reset=False,auto_increment=True,run_nr=-1):\n\tif run_nr < 1 or auto_increment:\n\t\trun_nr = get_last_tensorboard_run_nr()\n\tif run_nr == 0 or reset:\n\t\trun_nr=0\n\t\tclear_tensorboard()\n\tprint(""RUN NUMBER "" + str(run_nr))\n\tglobal logdir\n\tlast = tensorboard_logs + \'run\' + str(run_nr - 1)\n\tif run_nr>0 and (not os.path.exists(last) or len(os.listdir(last))==0):\n\t\trun_nr -= 1  #   previous run was not successful\n\n\tlogdir = tensorboard_logs + \'run\' + str(run_nr)\n\tif not os.path.exists(logdir):\n\t\tos.system(""mkdir "" + logdir)\n\n\ndef clear_tensorboard():\n\tos.system(""rm -rf %s/*"" % tensorboard_logs)  # sync\n\ndef nop():\n\treturn tf.constant(""nop"")\n\t# pass\n\ndef show_tensorboard():\n\t\t# add in /usr/local/lib/python2.7/site-packages/tensorflow/tensorboard/dist/index.html :\n\t\t# <link rel=""stylesheet"" type=""text/css"" href=""plottable/plottable.css""> due to BUG in tf 10.0\n\t\tprint(""run: tensorboard --debug --logdir="" + tensorboard_logs+"" and navigate to http://0.0.0.0:6006"")\n\ndef kill_tensorboard():\n\tos.system(""ps -afx | grep tensorboard | grep -v \'grep\' | awk \'{print $2}\'| xargs kill -9"")\n\ndef current_logdir():\n\tprint(""current logdir: ""+logdir)\n\treturn logdir\n\ndef run_tensorboard(restart=False,show_browser=False):\n\tif restart: kill_tensorboard()\n\t\t#  cd /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/ in tf 10.0 due to BUG\n\t\t# ,cwd=""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard""\n\tsubprocess.Popen([""tensorboard"", \'--logdir=\' + tensorboard_logs])  # async\n\t# os.system(""sleep 5; open http://0.0.0.0:6006"")\n\tif show_browser:\n\t\tsubprocess.Popen([""open"", \'http://0.0.0.0:6006\'])  # async\n\n# run_tensorboard()\n'"
text.py,0,"b'# coding=utf-8\nfrom enum import Enum\n\nimport PIL.ImageOps\nimport numpy\nfrom PIL import Image, ImageDraw, ImageFont\n\nimport letter\nfrom extensions import *\n\nnum_characters = letter.nLetters # ascii: 127\nword_file = ""/usr/share/dict/words""\nWORDS = open(word_file).read().splitlines()\n\nclass Target(Enum):  # labels\n\tword = 1\n\ttext = 2\n\tbox = 3 # start,end\n\tposition = 4\n\tposition_hot = 40\n\tposition_x = 44\n\tstart = 4 #position\n\tend = 5 #position\n\tstyle = 6\n\tangle = 7\n\tsize = 8\n\n\n\ndef random_word():\n\treturn pick(WORDS)\n\tpass # Don\'t (just) use dictionary because we really want to ocr passwords too\n\n\n\ndef pos_to_arr(pos):\n\treturn [pos[\'x\'],pos[\'y\']]\n\n\nmax_size = letter.max_size\nmax_word_length= 15\ncanvas_size=300 # Arbitrary,  shouldn\'t need to be specified in advance when doing inference\n\ndef pad(vec, pad_to=max_word_length, one_hot=False, terminal_symbol=0):\n\tfor i in range(0, pad_to - len(vec)):\n\t\tif one_hot:\n\t\t\tvec.append([terminal_symbol] * num_characters)\n\t\telse:\n\t\t\tvec.append(terminal_symbol)\n\treturn vec\n\nclass data():\n\tdef __init__(self):\n\t\tself.input_shape = None\n\t\tself.output_shape = None\n\n\tdef __next__(self):\n\t\treturn self.next_batch()\n\n\tdef __iter__(self):\n\t\t# return next(self.generator)\n\t\treturn self.next_batch()\n\n\tdef next_batch(self):\n\t\traise Exception(""abstract data class must be implemented"")\n\n\nclass batch(data):\n\n\tdef __init__(self, target=Target.word, batch_size=64):\n\t\t#super().__init__()\n\t\tself.batch_size=batch_size\n\t\tself.target= target\n\t\tself.shape=[max_size * max_size, max_word_length * letter.nLetters]\n\t\t# self.shape=[batch_size,max_size,max_size,len(letters)]\n\t\tself.train= self\n\t\tself.test = self\n\t\t# self.test.images,self.test.labels = self.next_batch() # nonesense!\n\n\tdef next_batch(self,batch_size=None):\n\t\t# type: () -> (list,list)\n\t\twords = [word() for i in range(batch_size or self.batch_size)]\n\t\tdef norm(word):\n\t\t\t# type: (word) -> ndarray\n\t\t\treturn word.matrix() # dump  the whole abstract representation as an image\n\t\txs=list(map(norm, words)) # 1...-1 range\n\t\tif self.target == Target.word: ys=  [many_hot(w.text, num_characters) for w in words]\n\t\tif self.target == Target.size: ys = [l.size for l in words]\n\t\tif self.target == Target.position: ys = [pos_to_arr(l.pos) for l in words]\n\t\tif self.target == Target.position_x: ys = [l.pos[\'x\'] for l in words]\n\t\tif self.target == Target.position_hot:\n\t\t\tys = [many_hot(pos_to_arr(l.pos), canvas_size, limit=2,swap=True) for l in words]\n\t\treturn xs, ys\n\n\ndef pick(xs):\n\treturn xs[randint(0,len(xs)-1)]\n\ndef many_hot(word, num_classes, offset=0, limit=max_word_length, swap=False):\n\tlabels_many_hot = []\n\t\t# for item in items:\n\tfor letter in word:\n\t\titem=ord(letter)\n\t\tlabels_one_hot = numpy.zeros(num_classes)\n\t\tif item >= num_classes:\n\t\t\tprint(""item > num_classes  %s > %d  ignoring"" % (item, limit))\n\t\telse:\n\t\t\tlabels_one_hot[item - offset] = 1\n\t\tlabels_many_hot.append(labels_one_hot)\n\t\tif len(labels_many_hot) > limit:\n\t\t\tprint(""#items > limit   %s > %d  ignoring rest""%(len(labels_many_hot),limit))\n\t\t\tbreak\n\tl = len(labels_many_hot)\n\tif l < limit:\n\t\tpad(labels_many_hot,limit,true)\n\tif l > limit:\n\t\traise Exception(""Too many items: %d > %d""%(l,limit))\n\tlabels_many_hot = np.array(labels_many_hot)\n\tif swap:\n\t\tlabels_many_hot = labels_many_hot.swapaxes(0,1)  # .transpose([0,1]) theano.dimshuffle\n\t# print(labels_many_hot.shape)\n\treturn labels_many_hot\n\n\nclass word():\n\n\n\tdef __init__(self, *margs, **args): # optional arguments\n\t\tif not args:\n\t\t\tif margs: args=margs[0] # ruby style hash args\n\t\t\telse:args={}\n\t\t# super(Argument, self).__init__(*margs, **args)\n\t\t# self.name = args[\'name\']\t\tif \'name\' in args else None\n\t\t# self.family = args[\'family\'] if \'family\' in args else pick(families)\n\t\tself.font = args[\'font\'] if \'font\' in args else pick(letter.fontnames)\n\t\tself.size = args[\'size\'] if \'size\' in args else pick(letter.sizes)\n\t\tself.color= args[\'color\'] if \'color\' in args else \'black\'#\'white\'#self.random_color() #  #None #pick(range(-90, 180))\n\t\tself.back = args[\'back\'] if \'back\' in args else letter.random_color()\n\t\tself.angle= args[\'angle\'] if \'angle\' in args else 0 #pick(range(-max_angle,max_angle))\n\t\tself.pos\t= args[\'pos\'] if \'pos\' in args else {\'x\':pick(range(0,canvas_size)),\'y\':pick(range(0, canvas_size))}\n\t\t# self.style= args[\'style\'] if \'style\' in args else self.get_style(self.font)# pick(styles)\n\t\tself.text = args[\'text\'] if \'text\' in args else random_word()\n\t\tself.invert = args[\'invert\'] if \'invert\' in args else pick([-1, 0, 1])\n\t\t# if chaotic: # captcha style (or syntax highlighting?)\n\t\t# self.letters=[letter.letter(args,char=char) for char in self.word] # almost java style ;)\n\t\t# else: one word, one style!\n\n\tdef projection(self):\n\t\treturn self.matrix(),self.ord\n\n\tdef matrix(self, normed=true):\n\t\t# type: (bool) -> ndarray\n\t\tmatrix = np.array(self.image())\n\t\tif normed: matrix = matrix / 255.\n\t\tif self.invert == -1:\n\t\t\tmatrix = 1 - 2 * matrix # -1..1\n\t\telif self.invert:\n\t\t\tmatrix = 1 - matrix # 0..1\n\t\treturn matrix\n\t\t# except:\n\t\t# \treturn np.array(max_size*(max_size+extra_y))\n\n\tdef image(self):\n\t\tttf_font = self.load_font()\n\t\tpadding = self.pos\n\t\tsize = [canvas_size, canvas_size]\n\t\tif self.back:\n\t\t\timg = Image.new(\'RGBA\', size, self.back) # background_color\n\t\telse:\n\t\t\timg = Image.new(\'L\', size, \'white\')\t# grey\n\t\tdraw = ImageDraw.Draw(img)\n\t\tdraw.text((padding[\'x\'], padding[\'y\']), self.text, font=ttf_font, fill=self.color)\n\t\tif self.angle:\n\t\t\trot = img.rotate(self.angle, expand=1).resize(size)\n\t\t\tif self.back:\n\t\t\t\timg = Image.new(\'RGBA\', size, self.back)  # background_color\n\t\t\telse:\n\t\t\t\timg = Image.new(\'L\', size,\'#FFF\')#FUCK BUG! \'white\')#,\'grey\')  # # grey\n\t\t\timg.paste(PIL.ImageOps.colorize(rot, (0, 0, 0),self.back ) (0, 0), rot)\n\t\treturn img\n\n\tdef load_font(self):\n\t\tfontPath = self.font if \'/\' in self.font else letter.fonts_dir + self.font\n\t\ttry:\n\t\t\tfontPath = fontPath.strip()\n\t\t\tttf_font = ImageFont.truetype(fontPath, self.size)\n\t\texcept:\n\t\t\tprint(""BAD FONT: "" + fontPath,self.size)\n\t\t\t# raise\n\t\t\texit()\n\t\t\t# raise Exception(""BAD FONT: "" + fontPath,self.size)\n\t\treturn ttf_font\n\n\tdef show(self):\n\t\tself.image().show()\n\n\tdef __str__(self):\n\t\tformat=""text{\'%s\',size=%d,font=\'%s\',position=%s}"" # angle=%d,\n\t\treturn format % (self.text, self.size, self.font, self.pos)\n\n\tdef __repr__(self):\n\t\treturn self.__str__()\n\n\tdef save(self, path):\n\t\tself.image().save(path)\n\n\n# @classmethod\t# can access class cls\n# def ls(cls, mypath=None):\n\n# @staticmethod\t# CAN\'T access class\n# def ls(mypath):\nimport matplotlib.pyplot as plt\n\n\ndef show_matrix(mat):\n\tplt.matshow(mat, fignum=1)\n\t# plt.imshow(image)\n\tplt.draw()\n\tplt.waitforbuttonpress()\n\n\ndef show_image(image):\n\tplt.imshow(image)\n\tplt.draw()\n\tplt.waitforbuttonpress()\n\n\nif __name__ == ""__main__"":\n\twhile 1:\n\t\t# l = word(text=\'hello\')\n\t\tw = word()\n\t\t# l.save(""letters/letter_%s_%d.png""%(l.char,l.size))\n\t\tprint(w)\n\t\ttry:\n\t\t\t# show_matrix(mat)\n\t\t\timage = w.image()\n\t\t\tshow_image(image)\n\t\t\tdel(image)\n\t\t\t# mat = w.matrix()\n\t\t\t# print(np.average(mat))\n\t\t\t# print(np.max(mat))\n\t\t\t# print(np.min(mat))\n\t\texcept KeyboardInterrupt:\n\t\t\texit()\n\t\t\t# return\n\t\t\tbreak\n\n\n\n'"
text_recognizer.py,0,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\nimport itertools\nimport sys\n\nimport numpy as np\nfrom keras.models import load_model\nfrom PIL import Image # python -m pip install --upgrade Pillow  # WTF\n\nweight_file = None # use model weights\n# weight_file = \'best_weights.h5\'\n# weight_file = \'current_weights.h5\'\n# weight_file = \'weights_ascii.h5\' # learned on noisy data\nweight_file = \'weights_ascii_easy.h5\' # no freckles\n# weight_file = \'weights_ascii_clean.h5\' # pure text, no rotation etc\n\nchars = u\'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\xc3\xa4\xc3\xb6\xc3\xbc\xc3\x84\xc3\x96\xc3\x9c\xc3\x9f0123456789!@#$%^&*()[]{}-_=+\\\\|""\\\'`;:/.,?><~ \'\n\n\nglobal model\nmodel=None\n\ndef init_model(model_file=""current_model.h5""):\n  global model\n  model = load_model(model_file)\n  model.summary()\n  if weight_file:\n    model.load_weights(weight_file, reshape=True, by_name=True)\n\ndef predict_tensor(tensor):\n  if len(tensor.shape) == 2:\n    tensor = tensor.transpose((1, 0))\n    tensor = tensor[np.newaxis, :, :, np.newaxis]\n  elif len(tensor.shape) == 3:\n    tensor = tensor.transpose((2, 1, 0))  # 4*w*h\n    tensor = tensor[:, :, :, np.newaxis]\n\n  print(tensor.shape)\n  if not model: init_model()\n  prediction = model.predict([tensor], batch_size=1, verbose=1)\n  result = decode_results(prediction)\n  return result\n\n\ndef decode_labels(labels):\n  ret = []\n  for c in labels:\n    # ret += chr(c)\n    if c == len(chars):\n      ret.append("""")\n    else:\n      ret.append(chars[c])\n  return """".join(ret)\n\n\n# could be extended to beam search with a dictionary and language model.\ndef decode_results(prediction):\n  ret = []\n  for j in range(prediction.shape[0]):\n    out_best = list(np.argmax(prediction[j, 2:], 1))\n    out_best = [k for k, g in itertools.groupby(out_best)]\n    outstr = decode_labels(out_best)\n    ret.append(outstr)\n  return ret\n\n\nif __name__ == \'__main__\':\n\n  np.random.seed(128)\n  if (len(sys.argv) > 1):\n    test_image = sys.argv[1]\n  else:\n    test_image = ""test_image.png""\n  image = Image.open(test_image)\n  # image = image.transpose(Image.FLIP_TOP_BOTTOM)\n  tensor = np.array(image) / 255.0  # RGBA: h*w*4\n  words = predict_tensor(tensor)\n  print(words)\n'"
train.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\'\'\'\nThis example uses a convolutional stack followed by a recurrent stack\nand a CTC logloss function to perform optical character recognition\nof generated text images. I have no evidence of whether it actually\nlearns general shapes of text, or just is able to recognize all\nthe different fonts thrown at it...the purpose is more to demonstrate CTC\ninside of Keras.  Note that the font list may need to be updated\nfor the particular OS in use.\n\nThis starts off with 4 letter words.  For the first 12 epochs, the\ndifficulty is gradually increased using the TextImageGenerator class\nwhich is both a generator class for test/train data and a Keras\ncallback class. After 20 epochs, longer sequences are thrown at it\nby recompiling the model to handle a wider image and rebuilding\nthe word list to include two words separated by a space.\n\nBased on a script by Mike Henry, with modifications to the model and training procedure\n\'\'\'\nimport os\nimport itertools\nimport codecs\nimport re\nimport datetime\nfrom random import random, randint,uniform\n\nimport cairocffi as cairo\nimport editdistance\nimport numpy as np\nfrom scipy import ndimage\nimport pylab\nfrom keras import backend as K\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Reshape, Lambda\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model\nfrom keras.layers.recurrent import GRU\nfrom keras.optimizers import SGD, Adam\nfrom keras.utils.data_utils import get_file\nfrom keras.preprocessing import image\nimport keras.callbacks\nimport easygui\n\nMODEL_DIR = \'weights\'\n\n# chars  = u\'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \'\nchars = u\'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\xc3\xa4\xc3\xb6\xc3\xbc\xc3\x84\xc3\x96\xc3\x9c\xc3\x9f0123456789!@#$%^&*()[]{}-_=+\\\\|""\\\'`;:/.,?><~ \'\npattern = r\'^[A-Za-z0-9 ]+$\'\n\n\n\nnp.random.seed(55)\n\n# this creates larger ""blotches"" of noise which look\n# more realistic than just adding gaussian noise\n# assumes greyscale with pixels ranging from 0 to 1\ndef speckle(img):\n    # severity = np.random.uniform(-0.2,0.6)\n    severity = np.random.uniform(-0.2,0.4)\n    gray = uniform(-0.5,0.2) # >0 = whiten!\n    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n    img_speck = (img + blur + gray)\n    img_speck[img_speck > 1] = 1\n    img_speck[img_speck <= 0] = 0\n    return img_speck\n\n\n# paints the string in a random location the bounding box\n# also uses a random font, a slight random rotation,\n# and a random amount of speckle noise\n\ndef paint_text(text, w, h, rotate=False, move=False, multi_fonts=False, background=False):\n    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n    with cairo.Context(surface) as context:\n        context.set_source_rgb(1, 1, 1)  # White\n        context.paint()\n        if multi_fonts:\n            # Calibri Century Comic Sans  Courier New Futura Georgia\n            fonts = [\'Century Schoolbook\', \'Courier\', \'Arial\', \'STIX\',\'Tahoma\',\'Times New Roman\',\'Trebuchet MS\',\n                     \'Verdana\',\'Wide Latin\',\'Calibri\',\'Century\',\'Comic Sans\',\'Courier\',\'New Futura\',\'Georgia\',\n                     \'Lucida\',\'Lucida Console\',\'Magneto\',\'Mistral\',\'URW Chancery L\', \'FreeMono\',\'DejaVue Sans Mono\']\n            font_slant = np.random.choice([cairo.FONT_SLANT_NORMAL,cairo.FONT_SLANT_ITALIC,cairo.FONT_SLANT_OBLIQUE])\n            font_weight = np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL, cairo.FONT_WEIGHT_NORMAL])\n            context.select_font_face(np.random.choice(fonts), font_slant, font_weight)\n        else:\n            context.select_font_face(\'Courier\', cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\n        # context.set_font_size(25)\n        font_size = randint(12, 42)\n        context.set_font_size(font_size)\n        box = context.text_extents(text)\n        border_w_h = (font_size/2, font_size/2)\n        # if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n        #     raise IOError(\'Could not fit string into image. Max char count is too large for given image width.\')\n\n        # teach the RNN translational invariance by\n        # fitting text box randomly on canvas, with some room to rotate\n        min_x = 0 #font_size/4\n        min_y = 0# font_size/4\n        max_shift_x = w - box[2] - border_w_h[0]\n        max_shift_y = h - box[3] - border_w_h[1]\n\n        if max_shift_x <= min_x :\n            top_left_x = 10\n        else:\n            top_left_x = np.random.randint(min_x, int(max_shift_x))\n\n        if move and max_shift_y > min_y + 1:\n            top_left_y = np.random.randint(min_y, int(max_shift_y))\n        else:\n            top_left_y = h // 2\n        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n        context.set_source_rgb(0, 0, 0)\n        if text:\n            context.show_text(text)\n\n    buf = surface.get_data()\n    a = np.frombuffer(buf, np.uint8)\n    a.shape = (h, w, 4)\n    a = a[:, :, 0]  # grab single channel\n    a = a.astype(np.float32) / 255\n    a = np.expand_dims(a, 0)\n    if rotate:\n        angle = randint(0, 3)\n        a = image.random_rotation(a, angle * (w - top_left_x) / w + 1)\n        sheer = randint(0, 3)\n        a = image.random_shear(a,sheer)\n    if background:\n        a = speckle(a)\n\n    return a\n\n\ndef shuffle_mats_or_lists(matrix_list, stop_ind=None):\n    ret = []\n    assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n    len_val = len(matrix_list[0])\n    if stop_ind is None:\n        stop_ind = len_val\n    assert stop_ind <= len_val\n\n    a = list(range(stop_ind))\n    np.random.shuffle(a)\n    a += list(range(stop_ind, len_val))\n    for mat in matrix_list:\n        if isinstance(mat, np.ndarray):\n            ret.append(mat[a])\n        elif isinstance(mat, list):\n            ret.append([mat[i] for i in a])\n        else:\n            raise TypeError(\'`shuffle_mats_or_lists` only supports \'\n                            \'numpy.array and list objects.\')\n    return ret\n\n\n# Translation of characters to unique integer values\ndef text_to_labels(text):\n    ret = []\n    for char in text:\n        # ord(char)\n        ret.append(chars.find(char))\n    return ret\n\n\n# Reverse translation of numerical classes back to characters\ndef labels_to_text(labels):\n    ret = []\n    for c in labels:\n        # ret += chr(c)\n        if c == len(chars):  # CTC Blank\n            ret.append("""")\n        else:\n            ret.append(chars[c])\n    return """".join(ret)\n\n\n# only a-z and space..probably not too difficult\n# to expand to uppercase and symbols\n\ndef is_valid_str(in_str):\n    search = re.compile(pattern, re.UNICODE).search\n    return bool(search(in_str))\n\n\n# Uses generator functions to supply train/test with\n# data. Image renderings are text are created on the fly\n# each time with random perturbations\n\ndef random_word(max_string_len):\n    s=""""\n    l = len(chars)\n    for i in range(0,randint(4,max_string_len)):\n        s+=chars[randint(0, l - 1)]\n    return s\n\nclass WtfException(Exception):\n    pass\n\nclass TextImageGenerator(keras.callbacks.Callback):\n\n    def __init__(self, monogram_file, bigram_file, minibatch_size,\n                 img_w, img_h, downsample_factor, val_split,\n                 absolute_max_string_len=16):\n\n        self.minibatch_size = minibatch_size\n        self.img_w = img_w\n        self.img_h = img_h\n        self.monogram_file = monogram_file\n        self.bigram_file = bigram_file\n        self.downsample_factor = downsample_factor\n        self.val_split = val_split\n        self.blank_label = self.get_output_size() - 1\n        self.absolute_max_string_len = absolute_max_string_len\n\n    def get_output_size(self):\n        return len(chars) + 1\n\n    # num_words can be independent of the epoch size due to the use of generators\n    # as max_string_len grows, num_words can grow\n    def build_word_list(self, num_words, max_string_len=None, mono_fraction=0.5):\n        assert max_string_len <= self.absolute_max_string_len\n        assert num_words % self.minibatch_size == 0\n        assert (self.val_split * num_words) % self.minibatch_size == 0\n        self.num_words = num_words\n        self.string_list = [\'\'] * self.num_words\n        tmp_string_list = []\n        self.max_string_len = max_string_len\n        self.Y_data = np.ones([self.num_words, self.absolute_max_string_len]) * -1\n        self.X_text = []\n        self.Y_len = [0] * self.num_words\n\n        if mono_fraction <1 :\n            mono_fraction = 0.2\n            random_fraction = 0.3\n            for i in range(0,int(self.num_words * random_fraction)):\n                word = random_word(max_string_len)\n                tmp_string_list.append(word)\n\n\n\n        # monogram file is sorted by frequency in english speech\n        moo=0\n        with codecs.open(self.monogram_file, mode=\'r\', encoding=\'utf-8\') as f:\n            for line in f:\n                if moo == int(self.num_words * mono_fraction):\n                    break\n                word = line.rstrip()\n                if max_string_len == -1 or max_string_len is None or len(word) <= max_string_len:\n                    tmp_string_list.append(word)\n                    moo += 1\n\n        # bigram file contains common word pairings in english speech\n        with codecs.open(self.bigram_file, mode=\'r\', encoding=\'utf-8\') as f:\n            lines = f.readlines()\n            l = len(lines)\n            for line in lines:\n                if len(tmp_string_list) == self.num_words:\n                    break\n                columns = line.lower().split()\n                word = columns[0] + \' \' + columns[1]\n                if is_valid_str(word) and \\\n                        (max_string_len == -1 or max_string_len is None or len(word) <= max_string_len):\n                    tmp_string_list.append(word)\n        if len(tmp_string_list) != self.num_words:\n            print(len(tmp_string_list) , self.num_words)\n            raise IOError(\'Could not pull enough words from supplied monogram and bigram files. \')\n        # interlace to mix up the easy and hard words\n        self.string_list[::2] = tmp_string_list[:self.num_words // 2]\n        self.string_list[1::2] = tmp_string_list[self.num_words // 2:]\n\n        for i, word in enumerate(self.string_list):\n            self.Y_len[i] = len(word)\n            self.Y_data[i, 0:len(word)] = text_to_labels(word)\n            self.X_text.append(word)\n        self.Y_len = np.expand_dims(np.array(self.Y_len), 1)\n\n        self.cur_val_index = self.val_split\n        self.cur_train_index = 0\n\n    # each time an image is requested from train/val/test, a new random\n    # painting of the text is performed\n    def get_batch(self, index, size, train):\n        # width and height are backwards from typical Keras convention\n        # because width is the time dimension when it gets fed into the RNN\n        if K.image_data_format() == \'channels_first\':\n            X_data = np.ones([size, 1, self.img_w, self.img_h])\n        else:\n            X_data = np.ones([size, self.img_w, self.img_h, 1])\n\n        labels = np.ones([size, self.absolute_max_string_len])\n        input_length = np.zeros([size, 1])\n        label_length = np.zeros([size, 1])\n        source_str = []\n        for i in range(size):\n            # Mix in some blank inputs.  This seems to be important for\n            # achieving translational invariance\n            if train and i > size - 4:\n                if K.image_data_format() == \'channels_first\':\n                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(\'\')[0, :, :].T\n                else:\n                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(\'\',)[0, :, :].T\n                labels[i, 0] = self.blank_label\n                input_length[i] = self.img_w // self.downsample_factor - 2\n                label_length[i] = 1\n                source_str.append(\'\')\n            else:\n                len1 = len(self.X_text)\n                if len1 > (index + i):\n                    a_text = self.X_text[index + i]\n                    lable = self.Y_data[index + i]\n                else:\n                    raise WtfException()\n                    print(""error"")\n                    a_text = ""error"" # how / what now??\n                    lable = np.ones([self.absolute_max_string_len]) * -1\n                    lable[0:len(a_text)]=text_to_labels(a_text)\n                func = self.paint_func(a_text)\n                text = func[0, :, :].T\n                if K.image_data_format() == \'channels_first\':\n                    X_data[i, 0, 0:self.img_w, :] = text\n                else:\n                    X_data[i, 0:self.img_w, :, 0] = text\n                labels[i, :] = lable\n                input_length[i] = self.img_w // self.downsample_factor - 2\n                label_length[i] = self.Y_len[index + i]\n                source_str.append(a_text)\n        inputs = {\'the_input\': X_data,\n                  \'the_labels\': labels,\n                  \'input_length\': input_length,\n                  \'label_length\': label_length,\n                  \'source_str\': source_str  # used for visualization only\n                  }\n        outputs = {\'ctc\': np.zeros([size])}  # dummy data for dummy loss function\n        return (inputs, outputs)\n\n    def next_train(self):\n        while 1:\n            try:\n                ret = self.get_batch(self.cur_train_index, self.minibatch_size, train=True)\n                self.cur_train_index += self.minibatch_size\n                if self.cur_train_index >= self.val_split:\n                    self.cur_train_index = self.cur_train_index % 32\n                    (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists(\n                        [self.X_text, self.Y_data, self.Y_len], self.val_split)\n                yield ret\n            except WtfException:\n                pass # just try new batch\n            except Exception as e:\n                print(e)\n                # raise\n                pass\n\n    def next_val(self):\n        while 1:\n            try:\n                ret = self.get_batch(self.cur_val_index, self.minibatch_size, train=False)\n                self.cur_val_index += self.minibatch_size\n                if self.cur_val_index >= self.num_words:\n                    self.cur_val_index = self.val_split + self.cur_val_index % 32\n                yield ret\n            except Exception as e:\n                print(e)\n                # raise\n                pass # text don\'t fit etc\n\n    def on_train_begin(self, logs={}):\n        self.build_word_list(16000, 4, 1)\n        self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n                                                  rotate=False, move=False, multi_fonts=False)\n\n    def on_epoch_begin(self, epoch, logs={}):\n        # rebind the paint function to implement curriculum learning\n        if 3 <= epoch < 6:\n            self.paint_func = lambda text: \\\n                paint_text(text, self.img_w, self.img_h, rotate=False, move=True, multi_fonts=False)\n        elif 6 <= epoch < 9:\n            self.paint_func = lambda text: \\\n                paint_text(text, self.img_w, self.img_h, rotate=False, move=True, multi_fonts=True)\n        elif epoch >= 9:\n            self.paint_func = lambda text: \\\n            paint_text(text, self.img_w, self.img_h, move=True, multi_fonts=True) # clean\n            # hardest :\n            # paint_text(text, self.img_w, self.img_h, rotate=True, move=True, multi_fonts=True,background=True)\n\n        if epoch >= 21 and self.max_string_len < 12:\n            self.build_word_list(32000, 12, 0.5)\n\n\n# the actual loss calc occurs here despite it not being\n# an internal Keras loss function\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN tend to be garbage:\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n# This could be beam search with a dictionary and language model.\ndef decode_batch(test_func, word_batch):\n    out = test_func([word_batch])[0]\n    ret = []\n    for j in range(out.shape[0]):\n        out_best = list(np.argmax(out[j, 2:], 1))\n        out_best = [k for k, g in itertools.groupby(out_best)]\n        outstr = labels_to_text(out_best)\n        ret.append(outstr)\n    return ret\n\n\nclass VizCallback(keras.callbacks.Callback):\n\n    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n        self.test_func = test_func\n        self.output_dir = os.path.join(MODEL_DIR, run_name)\n        self.text_img_gen = text_img_gen\n        self.num_display_words = num_display_words\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n\n    def show_edit_distance(self, num):\n        num_left = num\n        mean_norm_ed = 0.0\n        mean_ed = 0.0\n        while num_left > 0:\n            word_batch = next(self.text_img_gen)[0]\n            num_proc = min(word_batch[\'the_input\'].shape[0], num_left)\n            decoded_res = decode_batch(self.test_func, word_batch[\'the_input\'][0:num_proc])\n            for j in range(num_proc):\n                edit_dist = editdistance.eval(decoded_res[j], word_batch[\'source_str\'][j])\n                mean_ed += float(edit_dist)\n                mean_norm_ed += float(edit_dist) / len(word_batch[\'source_str\'][j])\n            num_left -= num_proc\n        mean_norm_ed = mean_norm_ed / num\n        mean_ed = mean_ed / num\n        print(\'\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f\'\n              % (num, mean_ed, mean_norm_ed))\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.model.save_weights(os.path.join(self.output_dir, \'weights%03d.h5\' % (epoch+1)))\n        self.show_edit_distance(256)\n        word_batch = next(self.text_img_gen)[0]\n        res = decode_batch(self.test_func, word_batch[\'the_input\'][0:self.num_display_words])\n        if word_batch[\'the_input\'][0].shape[0] < 256:\n            cols = 2\n        else:\n            cols = 1\n        for i in range(self.num_display_words):\n            pylab.subplot(self.num_display_words // cols, cols, i + 1)\n            if K.image_data_format() == \'channels_first\':\n                the_input = word_batch[\'the_input\'][i, 0, :, :]\n            else:\n                the_input = word_batch[\'the_input\'][i, :, :, 0]\n            pylab.imshow(the_input.T, cmap=\'Greys_r\')\n            pylab.xlabel(\'Truth = \\\'%s\\\'\\nDecoded = \\\'%s\\\'\' % (word_batch[\'source_str\'][i], res[i]))\n        fig = pylab.gcf()\n        fig.set_size_inches(10, 13)\n        try:\n            pylab.savefig(os.path.join(self.output_dir, \'e%03d.png\' % (epoch+1)))\n            pylab.close()\n        except:\n            print(""CANT SAVE"")\n            pass\n\nglobal first\nfirst=10 # quick eval in first n epochs\n\n\ndef train(run_name, start_epoch, stop_epoch, img_w):\n    img_h = 64\n    minibatch_size = 16\n    global first\n    # Input Parameters\n    if first>0 and start_epoch<300:\n        first-=1\n        words_per_epoch = 1600 # debug first\n    else:\n        words_per_epoch = int(1000*minibatch_size/2)\n    val_split = 0.2\n    val_words = int(words_per_epoch * (val_split))\n\n    # Network parameters\n    conv_filters = 16 # * 2 can\'t relearn !?\n    kernel_size = (3, 3)\n    pool_size = 2\n    time_dense_size = 32 *2 # 2 makes it WORSE!\n    rnn_size = 512 * 2 # 2 helps a lot\n\n    # minibatch_size = 32\n\n    if K.image_data_format() == \'channels_first\':\n        input_shape = (1, img_w, img_h)\n    else:\n        input_shape = (img_w, img_h, 1)\n\n    fdir = os.path.dirname(get_file(\'wordlists.tgz\',\n                                    origin=\'http://www.mythic-ai.com/datasets/wordlists.tgz\', untar=True))\n\n    img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, \'wordlist_mono_clean.txt\'),\n                                 bigram_file=os.path.join(fdir, \'wordlist_bi_clean.txt\'),\n                                 minibatch_size=minibatch_size,\n                                  img_w=img_w,\n                                 img_h=img_h,\n                                 downsample_factor=(pool_size ** 2),\n                                 val_split=words_per_epoch - val_words\n                                 )\n    act = \'relu\'\n    input_data = Input(name=\'the_input\', shape=input_shape, dtype=\'float32\')\n    inner = Conv2D(conv_filters, kernel_size, padding=\'same\',\n                   activation=act, kernel_initializer=\'he_normal\',\n                   name=\'conv1\')(input_data)\n    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name=\'max1\')(inner)\n    inner = Conv2D(conv_filters, kernel_size, padding=\'same\',\n                   activation=act, kernel_initializer=\'he_normal\',\n                   name=\'conv2\')(inner)\n    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name=\'max2\')(inner)\n\n    # inner = Conv2D(conv_filters, kernel_size, padding=\'same\',\n    #                activation=act, kernel_initializer=\'he_normal\',\n    #                name=\'conv3\')(inner)\n    # inner = MaxPooling2D(pool_size=(pool_size, pool_size), name=\'max3\')(inner)\n\n    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n    inner = Reshape(target_shape=conv_to_rnn_dims, name=\'reshape\')(inner)\n\n    # cuts down input size going into RNN:\n    inner = Dropout(rate=0.2, name=\'dropout_dense1a\')(inner)\n    inner = Dense(time_dense_size, activation=act, name=\'dense1\')(inner)\n    inner = Dropout(rate=0.2, name=\'dropout_dense1b\')(inner)\n\n    # Two layers of bidirectional GRUs\n    # GRU seems to work as well, if not better than LSTM:\n    gru_1 = GRU(rnn_size, return_sequences=True, dropout=0.3, kernel_initializer=\'he_normal\', name=\'gru1\')(inner)\n    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer=\'he_normal\', name=\'gru1_b\')(inner)\n    gru1_merged = add([gru_1, gru_1b])\n    gru_2 = GRU(rnn_size, return_sequences=True, dropout=0.3, kernel_initializer=\'he_normal\', name=\'gru2\')(gru1_merged)\n    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer=\'he_normal\', name=\'gru2_b\')(gru1_merged)\n\n    # transforms RNN output to character activations:\n    dense2 = Dense(img_gen.get_output_size(), kernel_initializer=\'he_normal\', name=\'dense2\')\n    inner = dense2(concatenate([gru_2, gru_2b]))\n    y_pred = Activation(\'softmax\', name=\'softmax\')(inner)\n    model0=Model(inputs=input_data, outputs=y_pred)\n    model0.summary()\n    model0.save(os.path.join(MODEL_DIR, \'model%03d.h5\' % (start_epoch + 1)))\n\n# training extension:\n    labels = Input(name=\'the_labels\', shape=[img_gen.absolute_max_string_len], dtype=\'float32\')\n    input_length = Input(name=\'input_length\', shape=[1], dtype=\'int64\')\n    label_length = Input(name=\'label_length\', shape=[1], dtype=\'int64\')\n    # Keras doesn\'t currently support loss funcs with extra parameters\n    # so CTC loss is implemented in a lambda layer\n    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name=\'ctc\')([y_pred, labels, input_length, label_length])\n\n    # clipnorm seems to speeds up convergence\n    if start_epoch==0:\n        sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5) # quick\n    elif start_epoch<100:\n        sgd = SGD(lr=0.008, decay=1e-5, momentum=0.8, nesterov=True, clipnorm=5) # medium speed\n    elif start_epoch>250 and start_epoch<300:\n        sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5) # quick relearn\n    else:\n        # sgd = SGD(lr=0.00005, decay=1e-4, momentum=0.7, nesterov=True, clipnorm=5) # slow\n        # sgd = SGD(lr=0.001, decay=1e-5 , momentum=0.8, nesterov=True, clipnorm=5)  # medium speed\n        # sgd = SGD(lr=0.03, decay=1e-5, momentum=0.8, nesterov=True, clipnorm=5)  # high speed relearn\n        sgd=Adam(lr=0.00005,decay=1e-5)\n        # sgd=Adam(lr=0.1)# to start\n        # sgd = Adam()\n\n    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n    # for l in model.layers:\n    #     if not ""conv"" in l.name and not ""dense1"" in l.name:\n    #         l.trainable=False\n\n    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n    model.compile(loss={\'ctc\': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n    if start_epoch > 0:\n        weight_file = os.path.join(MODEL_DIR, os.path.join(run_name, \'weights%02d.h5\' % start_epoch ))\n        model.load_weights(weight_file,by_name=True,reshape=True) # reshape=True, => FILL!\n    # captures output of softmax so we can decode the output during visualization\n    test_func = K.function([input_data], [y_pred])\n\n    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n\n    model.fit_generator(generator=img_gen.next_train(),\n                        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,\n                        epochs=stop_epoch,\n                        validation_data=img_gen.next_val(),\n                        validation_steps=val_words // minibatch_size,\n                        callbacks=[viz_cb, img_gen],\n                        initial_epoch=start_epoch)\n\ndef last_epoch():\n    maxi=0\n    for date in os.listdir(MODEL_DIR):\n        if not os.path.isdir(date): continue\n        for f in os.listdir(MODEL_DIR+""/""+date):\n            if not f.startswith(""weights""): continue\n            if len(f)==12:\n                i = int(f[7:9])\n            else:\n                i = int(f[7:10])\n            if i>maxi:\n                maxi=i\n    print(""start from last_epoch:"",maxi)\n    return maxi\n\ndef beep(e):\n    print(\'\\a\')\n    print(e)\n    easygui.msgbox(e, title=""ERROR"")\n\nif __name__ == \'__main__\':\n    try:\n        run_name = \'last\' #datetime.datetime.now().strftime(\'%Y:%m:%d:%H:%M:%S\')\n\n        start_epoch = last_epoch() # 553 good but no sigils / 723 not so good with sigils\n        if start_epoch<20:\n            train(run_name, start_epoch, 20, 128)\n            # increase to wider images and start at epoch 20.\n            # The learned weights are reloaded\n            train(run_name, 20, 125, 512)\n        else:\n            train(run_name, start_epoch,10000, 512) # quick eval\n            # train(run_name, start_epoch, start_epoch+20, 512) # quick eval\n            # train(run_name, start_epoch+20, 10000, 512)\n    except Exception as e:\n        print(e)\n        raise\n\n'"
train_attention.py,1,"b'#!/usr/bin/python\nimport tensorflow as tf\nimport layer\nimport letter\nfrom letter import Target,batch\n\n\n# learning_rate = 0.0003\ntarget=Target.position\nlearning_rate = 0.0001\nnClasses = letter.nClasses[target]\nsize = letter.max_size\ntraining_iters = 500000\nbatch_size = 64\ndata = batch(batch_size,target)\nprint(""data.shape %s""% data.shape)\n\n# best with lr ~0.001\ndef baseline(net):\n\t# type: (layer.net) -> None\n\t# net.batchnorm() # start lower, else no effect\n\tnet.dense(400, activation=tf.nn.tanh)\n\tnet.regression(nClasses)# regression\n\t# net.denseNet(40, depth=4)\n\treturn\n\n\n# net=layer.net(baseline, input_shape=[28,28], output_width=nClasses,learning_rate=0.001)\n# net=layer.net(alex,data, learning_rate=0.001) # NOPE!?\n# net=layer.net(denseConv, input_shape=[size, size], output_width=nClasses,learning_rate=learning_rate)\n\n# net.train(steps=50000,dropout=0.6,display_step=1,test_step=1) # debug\n# net.train(steps=50000,dropout=0.6,display_step=5,test_step=20) # test\nnet.train(data=data, steps=training_iters, dropout=.6, display_step=10, test_step=100) # run\n\n# net.predict() # nil=random\n# net.generate(3)  # nil=random\n'"
train_generator.py,0,"b'#!/usr/bin/env python\n#!/usr/bin/python\nimport layer\nimport letter\n# import tensorflow as tf\n# import layer.baselines\n\n# layer.clear_tensorboard() # Get rid of old runs\n\ndata = letter.batch()\ninput_width, output_width=data.shape[0],data.shape[1]\n\n# learning_rate = 0.03 # divergence even on overfit\n# learning_rate = 0.003 # quicker overfit\nlearning_rate = 0.0003\n\nnClasses =letter.nLetters\ntraining_steps = 500000\nbatch_size = 64\nsize = letter.max_size\n\n\n# OH, it does converge\n# Test Accuracy:  ~0.875 Step 1.000.000 52148s\ndef denseConv(net):\n\t# type: (layer.net) -> None\n\tprint(""Building dense-net"")\n\tnet.reshape(shape=[-1, size, size, 1])  # Reshape input picture\n\tnet.buildDenseConv(nBlocks=1)\n\tnet.classifier() # 10 classes auto\n\n\n"""""" Baseline tests to see that your model doesn\'t have any bugs and can learn small test sites without efforts """"""\n\n# net = layer.net(layer.baseline, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: full overfit at Step 800\n# learning_rate: 0.0003: full overfit at Step 2400\n\n# net = layer.net(layer.baselineDeep3, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: overfit 98% at Step 5000\n# learning_rate: 0.0003: full overfit at Step 24000\n\n# net = layer.net(layer.baselineBatchNormDeep, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: overfit 98% at Step 3000 ++\n\n# net = layer.net(layer.baselineDenseConv, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: overfit 98% at Step 3000 ++\n\n# alex = broken baseline! lol, how?\n# net = layer.net(layer.alex, input_width=size, output_width=nClasses, learning_rate=.001)\n\n# net.train(data=data, test_step=1000)  # run\n\n"""""" here comes the real network """"""\n\n# net=layer.net(alex,input_width=28, output_width=nClasses, learning_rate=learning_rate) # NOPE!?\nnet = layer.net(denseConv, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n\n# net.train(data=data,steps=50000,dropout=0.6,display_step=1,test_step=1) # debug\n# net.train(data=data, steps=training_steps,dropout=0.6,display_step=5,test_step=20) # test\nnet.train(data=data, dropout=.6, display_step=10, test_step=1000) # run resume\n\n# net.predict() # nil=random\n# net.generate(3)  # nil=random\n'"
train_letters.py,0,"b'#!/usr/bin/env python\n#!/usr/bin/python\nimport layer\nimport letter\n# import tensorflow as tf\n# import layer.baselines\n\n# layer.clear_tensorboard() # Get rid of old runs\n\ndata = letter.batch()\ninput_width, output_width=data.shape[0],data.shape[1]\n\n# learning_rate = 0.03 # divergence even on overfit\n# learning_rate = 0.003 # quicker overfit\nlearning_rate = 0.0003\n\nnClasses =letter.nLetters\ntraining_steps = 500000\nbatch_size = 64\nsize = letter.max_size\n\n\n# OH, it does converge\n# Test Accuracy:  ~0.875 Step 1.000.000 52148s\ndef denseConv(net):\n\t# type: (layer.net) -> None\n\tprint(""Building dense-net"")\n\tnet.reshape(shape=[-1, size, size, 1])  # Reshape input picture\n\tnet.buildDenseConv(nBlocks=1)\n\tnet.classifier() # 10 classes auto\n\n\n"""""" Baseline tests to see that your model doesn\'t have any bugs and can learn small test sites without efforts """"""\n\n# net = layer.net(layer.baseline, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: full overfit at Step 800\n# learning_rate: 0.0003: full overfit at Step 2400\n\n# net = layer.net(layer.baselineDeep3, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: overfit 98% at Step 5000\n# learning_rate: 0.0003: full overfit at Step 24000\n\n# net = layer.net(layer.baselineBatchNormDeep, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: overfit 98% at Step 3000 ++\n\n# net = layer.net(layer.baselineDenseConv, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# learning_rate: 0.003: overfit 98% at Step 3000 ++\n\n# alex = broken baseline! lol, how?\n# net = layer.net(layer.alex, input_width=size, output_width=nClasses, learning_rate=.001)\n\n# net.train(data=data, test_step=1000)  # run\n\n"""""" here comes the real network """"""\n\n# net=layer.net(alex,input_width=28, output_width=nClasses, learning_rate=learning_rate) # NOPE!?\nnet = layer.net(denseConv, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n\n# net.train(data=data,steps=50000,dropout=0.6,display_step=1,test_step=1) # debug\n# net.train(data=data, steps=training_steps,dropout=0.6,display_step=5,test_step=20) # test\nnet.train(data=data, dropout=.6, display_step=10, test_step=1000) # run resume\n\n# net.predict() # nil=random\n# net.generate(3)  # nil=random\n'"
train_ocr_layer.py,0,"b'#!/usr/bin/python\nimport text\nimport layer\nimport letter\n\n# layer.clear_tensorboard() # Get rid of old runs\n\ndata = letter.batch(letter.Target.letter, batch_size=10)\n# data = text.batch(text.Target.word, batch_size=10)\ninput_width, output_width=data.shape[0],data.shape[1]\n# x,y = next(data)\n# print(np.array(x).shape)\n# print(np.array(y).shape)\n# # exit(0)\n\n\n# learning_rate = 0.03 # divergence even on overfit\n# learning_rate = 0.003 # quicker overfit\nlearning_rate = 0.0003\ntraining_steps = 500000\nbatch_size = 10\n# size = text.canvas_size\nsize = letter.max_size\n\n\ndef denseConv(net):\n\t# type: (layer.net) -> None\n\tprint(""Building dense-net"")\n\tnet.reshape(shape=[-1, size, size, letter.color_channels])  # Reshape input picture\n\tnet.buildDenseConv(nBlocks=1)\n\n\n"""""" Baseline tests to see that your model doesn\'t have any bugs and can learn small test sites without efforts """"""\n\n# net = layer.net(layer.baseline, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# net.train(data=data, test_step=1000)  # run\n\n"""""" here comes the real network """"""\nnet = layer.net(denseConv, input_width=size, output_width=96, learning_rate=learning_rate)\n\n# net.train(data=data,steps=50000,dropout=0.6,display_step=1,test_step=1) # debug\n# net.train(data=data, steps=training_steps,dropout=0.6,display_step=5,test_step=20) # test\nnet.train(data=data, dropout=.6, display_step=5, test_step=100) # run resume\n\n# net.predict() # nil=random\n# net.generate(3)  # nil=random\n'"
train_text_localizer.py,0,"b'#!/usr/bin/python\nimport letter\nimport text\nimport layer\nimport numpy as np\n\n# layer.clear_tensorboard() # Get rid of old runs\n\n# data = text.batch(text.Target.position, batch_size=10)\ndata = text.batch(text.Target.position_hot, batch_size=10)\n# input_width = 300  #data.shape[0]\ninput_shape=[text.canvas_size, text.canvas_size]\noutput_shape = [text.canvas_size, 2]  # one hot encoding for (x,y) position of text ~ upper right boundary box corner\n# output_shape = 2  # (x,y) todo: one hot encoding INSIDE net!\n\n# print(data.train.images[0].shape)\nx,y = next(data)\nprint(np.array(x).shape)\nprint(np.array(y).shape)\n# exit(0)\n\n\n# learning_rate = 0.03 # divergence even on overfit\n# learning_rate = 0.003 # quicker overfit\nlearning_rate = 0.0003\n\ntraining_steps = 500000\n# batch_size = 64\nbatch_size = 10\nsize = text.canvas_size\n\n\ndata_format={\n\t\'input_width\': size,\n\t\'output_width\': output_shape,  # x,y position\n\t# output_width: 4,  # x,y start+end position (box)\n}\n\n\ndef positionGanglion(net):\n\t# type: (layer.net) -> None\n\tprint(""Building start position detecting ganglion"")\n\tnet.input([300,300])\n\tnet.reshape(shape=[-1, size, size, letter.color_channels])  # Reshape input picture\n\t# net.buildDenseConv(nBlocks=1)\n\tnet.conv2d(20, pool=False)\n\tnet.conv2d(1, pool=False) #  hopefully the heat map activation can learn the start position of our word :\n\tnet.targets([300,2]) # reduce-max per axis\n\tnet.argmax_2D_loss()\n\t# net.classifier(dim=2)\n\ndef positionRegression(net):\n\t# type: (layer.net) -> None\n\tprint(""Building start position detecting ganglion"")\n\tnet.reshape(shape=[-1, size, size, letter.color_channels])  # Reshape input picture\n\t# net.buildDenseConv(nBlocks=1)\n\tnet.conv2d(20)\n\tnet.argmax2d()\n\tnet.regression(dimensions=2) # for\n\n\n\ndef denseConv(net):\n\t# type: (layer.net) -> None\n\tprint(""Building dense-net"")\n\tnet.reshape(shape=[-1, size, size, letter.color_channels])  # Reshape input picture\n\tnet.buildDenseConv(nBlocks=1)\n\n\n"""""" Baseline tests to see that your model doesn\'t have any bugs and can learn small test sites without efforts """"""\n\n# net = layer.net(layer.baseline, input_width=size, output_width=nClasses, learning_rate=learning_rate)\n# net.train(data=data, test_step=1000)  # run\n\n"""""" here comes the real network """"""\n\n# net = layer.net(denseConv, input_width=size, output_width=2, learning_rate=learning_rate)\nnet = layer.net(positionGanglion, input_width=size, output_width=output_shape, learning_rate=learning_rate)\n\n# net.train(data=data,steps=50000,dropout=0.6,display_step=1,test_step=1) # debug\n# net.train(data=data, steps=training_steps,dropout=0.6,display_step=5,test_step=20) # test\nnet.train(data=data, dropout=.6, display_step=5, test_step=100) # run resume\n\n# net.predict() # nil=random\n# net.generate(3)  # nil=random\n'"
word_recognizer.py,3,"b""# tf.train.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None)\n\n#  tensor flow now supports generalized dilated atrous co'lusion !!\n# -    x = tf.nn.conv3d(x, kernel, strides, padding)\n# +    x = tf.nn.convolution(x, kernel, padding,strides=strides, dilation_rate=filter_dilation)\n# https://github.com/fchollet/keras/pull/4115/files\n\n# AtrousConv1D = AtrousConvolution1D\n# YAY!!!!\n\n# https://github.com/nrTQgc/deep-anpr/commit/adfbbe7f3deeaa39bdecc36d8398434b76fdf211\n#  fork confusion : ^^  13 days ago BUUUUT: # https://github.com/nrTQgc/deep-anpr  two months ago!?!?!?!\n"""
old/batch_norm.py,7,"b""import layer\n\nimport tensorflow as tf\nfrom tensorflow.contrib.layers.python.layers import batch_norm as batch_norm\n\nclass net(layer.net):\n\tdef batchnorm(self):\n\t\tisTraining=self.train_phase\n\t\tinputT=self.last_layer\n\t\tscope=None\n\t\twith tf.name_scope('batchnorm') as scope:\n\t\t\treturn tf.cond(isTraining,\n\t\t               lambda: batch_norm(inputT, is_training=True,\n\t\t                                  center=False, updates_collections=None, scope=scope),\n\t\t               lambda: batch_norm(inputT, is_training=False,\n\t\t                                  updates_collections=None, center=False, scope=scope, reuse=True))\n\n# \t\tscope_bn=None\n# \t\twith tf.name_scope('batchnorm') as scope_bn:\n# \t\t\t# beta=tf.Variable(0.5,name='beta')\n# \t\t\tbeta =tf.get_variable('beta',[1],dtype=tf.float32)\n# \t\t\tx=self.last_layer\n# \t\t\t# reuse=None#  ValueError: reuse=True cannot be used without a name_or_scope\n# \t\t\treuse =True\n# \t\t\tbn_train = batch_norm(x, decay=0.999, center=True, scale=True, updates_collections=None, is_training=True, reuse=reuse,  trainable=True, scope=scope_bn)\n# # ValueError: Variable model/conv/batchnorm//beta does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\n# \t\t\tbn_inference = \\\n# \t\t\t\tbatch_norm(x,\n# \t\t\t           decay=0.999,\n# \t\t\t           center=True,\n# \t\t\t           scale=True,\n# \t\t\t           updates_collections=None,\n# \t\t\t           is_training=False,\n# \t\t\t           reuse=reuse,\n# \t\t\t           trainable=True,\n# \t\t\t           scope=scope_bn)\n# \t\t\tz = tf.cond(self.train_phase, lambda: bn_train, lambda: bn_inference)\n# \t\t\treturn z\n\n\n\n"""
old/conv.py,8,"b'import tensorflow as tf\nimport layer\n\nclass net(layer.net):\n\n\tdef conv_slim(w, b,pool=False):\n\t\tnet = slim.conv2d(inputs, 64, [11, 11], 4, padding=\'VALID\',scope=\'conv1\')\n\t\tif(pool): net = slim.max_pool2d(net, [3, 3], 2, scope=\'pool1\')\n\t\tself.last_layer = net\n\n\t# Convolution Layer\n\tdef conv(self, shape, act=tf.nn.relu, pool=True, dropout=True, norm=True, name=None):\n\t\twith tf.name_scope(\'conv\'):\n\t\t\tself.batchnorm()\n\t\t\tprint(""conv "", shape)\n\t\t\tfilter_weights = tf.Variable(tf.random_normal(shape))  # WTF?\n\t\t\t_bias = tf.Variable(tf.random_normal([shape[-1]]))\n\t\t\t# conv1 = conv2d(\'conv\', _X, _weights, _bias)\n\t\t\tconv1 = tf.nn.bias_add(tf.nn.conv2d(self.last_layer, filter=filter_weights, strides=[1, 1, 1, 1], padding=\'SAME\'),\n\t\t\t                       _bias)\n\t\t\tif act: conv1 = act(conv1)\n\t\t\t# Max Pooling (down-sampling)\n\t\t\tif pool: conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\t\t\tif norm: conv1 = tf.nn.lrn(conv1, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n\t\t\tif dropout: conv1 = tf.nn.dropout(conv1, self.dropout_rate)\n\t\t\tself.last_layer = conv1\n\t\t# self.last_shape = conv1.get_shape()\n'"
old/dense.py,0,b''
old/densenet.py,11,"b'import tensorflow as tf\nimport layer\n\nclass net(layer.net):\n\n\tdef addConvLayer(self, nChannels, nOutChannels, dropRate):\n\t\tconcate = nn.Concat(2)\n\t\tconcate.add(nn.Identity())  # ?\n\t\tconvFactory.add(tf.nn.SpatialBatchNormalization(nChannels))\n\t\tconvFactory.add(tf.nn.ReLU(true))\n\t\tconvFactory.add(tf.nn.SpatialConvolution(nChannels, nOutChannels, 3, 3, 1, 1, 1, 1))\n\t\tif dropRate: convFactory.add(nn.Dropout(dropRate))\n\t\tconcate.add(convFactory)\n\t\tself.add(concate)\n\n\tdef addTransition(self, nChannels, nOutChannels, dropRate):\n\t\tself.add(tf.nn.SpatialBatchNormalization(nChannels))\n\t\tself.add(tf.nn.ReLU(true))\n\t\tself.add(tf.nn.SpatialConvolution(nChannels, nOutChannels, 1, 1, 1, 1, 0, 0))\n\t\tif dropRate: self.add(nn.Dropout(dropRate))\n\t\tself.add(tf.nn.SpatialAveragePooling(2, 2))\n\t\tself.conv([1,1,1,1],pool=True,dropout=dropRate) # ja?\n\n\n\tdef buildDenseConv(self):\n\t\tdepth = 3 * 1 + 4\n\t\tif (depth - 4) % 3 == 0:  raise (""Depth must be 3N + 4! (4,7,10,...) "")  # # layers in each denseblock\n\t\tN = (depth - 4) / 3\n\t\tdropRate = nil  # nil to disable dropout, non - zero number to enable dropout and set drop rate\n\t\t# # channels before entering the first denseblock ??\n\t\t# set it to be comparable with growth rate ??\n\t\tnChannels = 16\n\t\tgrowthRate = 12\n\n\t\tself.add(tf.nn.SpatialConvolution(3, nChannels, 3, 3, 1, 1, 1, 1))\n\n\t\tfor i in range(N):\n\t\t\taddConvLayer(self, nChannels, growthRate, dropRate)\n\t\t\tnChannels = nChannels + growthRate\n\t\t\taddTransition(self, nChannels, nChannels, dropRate)\n\n\t\tfor i in range(N):\n\t\t\taddConvLayer(self, nChannels, growthRate, dropRate)\n\t\t\tnChannels = nChannels + growthRate\n\t\t\taddTransition(self, nChannels, nChannels, dropRate)\n\n\t\tfor i in range(N):\n\t\t\taddConvLayer(self, nChannels, growthRate, dropRate)\n\t\t\tnChannels = nChannels + growthRate\n\n\t\tself.add(tf.nn.SpatialBatchNormalization(nChannels))\n\t\tself.add(tf.nn.ReLU(true))\n\t\tself.add(tf.nn.SpatialAveragePooling(8, 8)).add(nn.Reshape(nChannels))\n\t\tif opt.dataset == \'cifar100\':\n\t\t\tself.add(nn.Linear(nChannels, 100))\n\t\telif opt.dataset == \'cifar10\':\n\t\t\tself.add(nn.Linear(nChannels, 10))\n\t\telse:\n\t\t\traise (""Dataset not supported yet!"")\n'"
old/seq2seq2be.py,19,"b'from __future__ import print_function\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops import seq2seq\nfrom tensorflow.python.ops import rnn_cell\n\nnp.random.seed(seed= 7)\nn_iterations = 300\n\n\ndef generate_sequences(sequence_num, sequence_length, batch_size):\n    x_data = np.random.uniform(0, 1, size=(sequence_num / batch_size, sequence_length, batch_size, 1))\n    y_data = []\n    for x in x_data:\n        sequence = [x[0]]\n        for index in xrange(1, len(x)):\n            sequence.append(x[0] * x[index]) # m u l OK\n            # sequence.append(x[0] + x[index]) # sum DOESNT\n            # sequence.append(1-x[index-1])\n            # sequence.append(1.-x[index])\n            # sequence.append(x[index-1] * x[index]) # m u l OK\n            # sequence.append(x[index] *np.average(x[index-1]))\n            # sequence.append(x[0] *np.average(x[index]))\n            # sequence.append(x[0] *np.max(x[index]))\n            # sequence.append([1]*sequence_length *np.max(x[index]))\n            # sequence.append([sequence.max(axis=0)])\n            # max=np.max(sequence,axis=None, out=None, keepdims=True)#/2\n            # sequence.append([np.maximum(sequence, max)])\n            # sequence.append([np.max(sequence, axis=0)])\n            # candidates_for_min = sequence[1:]\n            # sequence.append([np.min(candidates_for_min, axis=0)])\n        y_data.append(sequence)\n    return x_data, y_data\n\n\ndef variable_summaries(var, name):\n    """"""Attach a lot of summaries to a Tensor.""""""\n    with tf.name_scope(\'summaries\'):\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar(\'mean/\' + name, mean)\n        with tf.name_scope(\'stddev\'):\n            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n        tf.summary.scalar(\'sttdev/\' + name, stddev)\n        tf.summary.scalar(\'max/\' + name, tf.reduce_max(var))\n        tf.summary.scalar(\'min/\' + name, tf.reduce_min(var))\n        tf.summary.histogram(name, var)\n\n\ndef main():\n    sequence_num = 100 # datapoints_number\n    sequence_length = 10\n    batch_size = 10\n    data_point_dim = 1\n    if sequence_num % float(batch_size) != 0:\n        raise ValueError(\'Number of samples must be divisible with batch size\')\n    inputs, outputs = generate_sequences(sequence_num, sequence_length, batch_size)\n\n    input_dim = len(inputs[0][0])\n    output_dim = len(outputs[0][0])\n\n    encoder_inputs = [tf.placeholder(tf.float32, shape=[batch_size, data_point_dim]) for _ in xrange(input_dim)]\n    decoder_inputs = [tf.placeholder(tf.float32, shape=[batch_size, data_point_dim]) for _ in xrange(output_dim)]\n    lstm_cell = rnn_cell.BasicLSTMCell(data_point_dim, state_is_tuple=True)\n    model_outputs, states = seq2seq.basic_rnn_seq2seq(encoder_inputs, decoder_inputs, lstm_cell)\n\n    reshaped_outputs = tf.reshape(model_outputs, [-1])\n    reshaped_results = tf.reshape(decoder_inputs, [-1])\n\n    cost = tf.reduce_sum(tf.squared_difference(reshaped_outputs, reshaped_results))\n    variable_summaries(cost, \'cost\')\n    step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n    merged = tf.summary.merge_all()\n\n    with tf.Session() as session:\n        session.run(tf.global_variables_initializer())\n        writer = tf.summary.FileWriter(""/tmp/tensor/train"", session.graph)\n        costs = []\n        for i in xrange(n_iterations):\n            batch_costs = []\n            summary = None\n            for batch_inputs, batch_outputs in zip(inputs, outputs):\n                # x_list = {key: value for (key, value) in zip(encoder_inputs, batch_inputs)}\n                # y_list = {key: value for (key, value) in zip(decoder_inputs, batch_outputs)}\n                # feed_dict = dict(x_list.items() + y_list.items())\n                feed_dict = {encoder_inputs: batch_inputs, decoder_inputs: batch_outputs}\n                # summary, err, _ = session.run([merged, cost, step], )\n                summary, err, _ = session.run([merged, cost, step], feed_dict)\n                batch_costs.append(err)\n                print(""err"",err)\n            if summary is not None:\n                writer.add_summary(summary, i)\n            costs.append(np.average(batch_costs, axis=0))\n\n    # predict = session.run([model_outputs], feed_dict=dict(x_list.items() + y_list.items()))\n    # print(""predict"",predict)\n    plt.plot(costs)\n    plt.show()\n\nif __name__ == \'__main__\':\n\tmain()\n'"
