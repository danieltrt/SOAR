file_path,api_count,code
tf-test/1.0/gpu.py,5,"b""import tensorflow as tf\n#import tensorrt as trt\n\n# Creates a graph.\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nconfig = tf.ConfigProto()\nconfig.log_device_placement=True\nconfig.gpu_options.allow_growth = True\n#config.gpu_options.allow_growth = True\nsess = tf.Session(config=config)\n# Runs the op.\nprint(sess.run(c))\n"""
tf-test/1.0/test_tftrt.py,1,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Script to test TF-TensorRT integration.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n# normally we should do import tensorflow as tf and then\n# tf.placeholder, tf.constant, tf.nn.conv2d etc but\n# it looks like internal builds don\'t like it so\n# importing every module individually\n\nfrom tensorflow.contrib import tensorrt as trt\nfrom tensorflow.core.protobuf import config_pb2 as cpb2\nfrom tensorflow.python.client import session as csess\nfrom tensorflow.python.framework import constant_op as cop\nfrom tensorflow.python.framework import dtypes as dtypes\nfrom tensorflow.python.framework import importer as importer\nfrom tensorflow.python.framework import ops as ops\nfrom tensorflow.python.ops import array_ops as aops\nfrom tensorflow.python.ops import nn as nn\nfrom tensorflow.python.ops import nn_ops as nn_ops\n\n\ndef get_simple_graph_def():\n  """"""Create a simple graph and return its graph_def.""""""\n  g = ops.Graph()\n  with g.as_default():\n    a = aops.placeholder(\n        dtype=dtypes.float32, shape=(None, 24, 24, 2), name=""input"")\n    e = cop.constant(\n        [[[[1., 0.5, 4., 6., 0.5, 1.], [1., 0.5, 1., 1., 0.5, 1.]]]],\n        name=""weights"",\n        dtype=dtypes.float32)\n    conv = nn.conv2d(\n        input=a, filter=e, strides=[1, 2, 2, 1], padding=""SAME"", name=""conv"")\n    b = cop.constant(\n        [4., 1.5, 2., 3., 5., 7.], name=""bias"", dtype=dtypes.float32)\n    t = nn.bias_add(conv, b, name=""biasAdd"")\n    relu = nn.relu(t, ""relu"")\n    idty = aops.identity(relu, ""ID"")\n    v = nn_ops.max_pool(\n        idty, [1, 2, 2, 1], [1, 2, 2, 1], ""VALID"", name=""max_pool"")\n    aops.squeeze(v, name=""output"")\n  return g.as_graph_def()\n\n\ndef run_graph(gdef, dumm_inp):\n  """"""Run given graphdef once.""""""\n  gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\n  ops.reset_default_graph()\n  g = ops.Graph()\n  with g.as_default():\n    inp, out = importer.import_graph_def(\n        graph_def=gdef, return_elements=[""input"", ""output""])\n    inp = inp.outputs[0]\n    out = out.outputs[0]\n  with csess.Session(\n      config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\n    val = sess.run(out, {inp: dumm_inp})\n  return val\n\n\n# Use real data that is representatitive of the inference dataset\n# for calibration. For this test script it is random data.\ndef run_calibration(gdef, dumm_inp):\n  """"""Run given calibration graph multiple times.""""""\n  gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\n  ops.reset_default_graph()\n  g = ops.Graph()\n  with g.as_default():\n    inp, out = importer.import_graph_def(\n        graph_def=gdef, return_elements=[""input"", ""output""])\n    inp = inp.outputs[0]\n    out = out.outputs[0]\n  with csess.Session(\n      config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\n    # run over real calibration data here, we are mimicking a calibration set of\n    # 30 different batches. Use as much calibration data as you want\n    for _ in range(30):\n      val = sess.run(out, {inp: dumm_inp})\n  return val\n\n\nif ""__main__"" in __name__:\n  inp_dims = (100, 24, 24, 2)\n  dummy_input = np.random.random_sample(inp_dims)\n  orig_graph = get_simple_graph_def()  # use a frozen graph for inference\n  # Get optimized graph\n  trt_graph = trt.create_inference_graph(\n      input_graph_def=orig_graph,\n      outputs=[""output""],\n      max_batch_size=inp_dims[0],\n      max_workspace_size_bytes=1 << 25,\n      precision_mode=""FP32"",  # TRT Engine precision ""FP32"",""FP16"" or ""INT8""\n      minimum_segment_size=2  # minimum number of nodes in an engine\n  )\n  o1 = run_graph(orig_graph, dummy_input)\n  o2 = run_graph(trt_graph, dummy_input)\n  o3 = run_graph(trt_graph, dummy_input)\n  assert np.array_equal(o1, o2)\n  assert np.array_equal(o3, o2)  # sanity check\n  fp16_graph = trt.create_inference_graph(\n      input_graph_def=orig_graph,\n      outputs=[""output""],\n      max_batch_size=inp_dims[0],\n      max_workspace_size_bytes=1 << 25,\n      precision_mode=""FP16"",  # TRT Engine precision ""FP32"",""FP16"" or ""INT8""\n      minimum_segment_size=2  # minimum number of nodes in an engine\n  )\n  int8_calib_gdef = trt.create_inference_graph(\n      input_graph_def=orig_graph,\n      outputs=[""output""],\n      max_batch_size=inp_dims[0],\n      max_workspace_size_bytes=1 << 25,\n      precision_mode=""INT8"",  # TRT Engine precision ""FP32"",""FP16"" or ""INT8""\n      minimum_segment_size=2  # minimum number of nodes in an engine\n  )\n  o4 = run_graph(fp16_graph, dummy_input)\n  _ = run_calibration(int8_calib_gdef, dummy_input)\n  int8_graph = trt.calib_graph_to_infer_graph(int8_calib_gdef)\n  o5 = run_graph(int8_graph, dummy_input)\n  assert np.allclose(o1, o4)\n  assert np.allclose(o1, o5)\n  print(""Pass"")\n'"
tf-test/2.0/gpu.py,5,"b'from __future__ import absolute_import, division, print_function, unicode_literals\nimport tensorflow as tf\nprint(""GPU Available: "", tf.test.is_gpu_available())\n\n#import tensorrt as trt\ntf.debugging.set_log_device_placement(True)\n\n# Create some tensors\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\n\nprint(c)\n'"
tf-test/2.0/mnist.py,7,"b""from __future__ import absolute_import, division, print_function, unicode_literals\nimport tensorflow as tf\n\nprint(tf.__version__)\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=20)\n\nmodel.evaluate(x_test, y_test)\n"""
