file_path,api_count,code
check_blas.py,0,"b'#!/usr/bin/env python\n\n# print info to check we link with witch version of blas\n# test the speed of the blas gemm fct:\n# C=a*C+dot(A,B)*b\n# A,B,C matrix\n# a,b scalar\nfrom __future__ import absolute_import, print_function, division\n\nimport os\nimport sys\nimport time\nfrom optparse import OptionParser\n\nimport numpy as np\nimport theano\nimport theano.tensor as T\n\n\ndef execute(execute=True, verbose=True, M=2000, N=2000, K=2000,\n            iters=10, order=\'C\'):\n    """"""\n    :param execute: If True, execute a Theano function that should call gemm.\n    :param verbose: If True, will print some Theano flags and env variables.\n    :param M,N,K: The M,N,K size used by gemm.\n    :param iters: The number of calls to gemm to do.\n\n    :return: a tuple (execution time,\n                      str that represents the implementation used)\n    """"""\n\n    if verbose:\n        print(\'Some Theano flags:\')\n        print(\'    blas.ldflags=\', theano.config.blas.ldflags)\n        print(\'    compiledir=\', theano.config.compiledir)\n        print(\'    floatX=\', theano.config.floatX)\n        print(\'    device=\', theano.config.device)\n        print(\'Some OS information:\')\n        print(\'    sys.platform=\', sys.platform)\n        print(\'    sys.version=\', sys.version)\n        print(\'    sys.prefix=\', sys.prefix)\n        print(\'Some environment variables:\')\n        print(\'    MKL_NUM_THREADS=\', os.getenv(\'MKL_NUM_THREADS\'))\n        print(\'    OMP_NUM_THREADS=\', os.getenv(\'OMP_NUM_THREADS\'))\n        print(\'    GOTO_NUM_THREADS=\', os.getenv(\'GOTO_NUM_THREADS\'))\n        print()\n        print(\'Numpy config: (used when the Theano flag\'\n              \' ""blas.ldflags"" is empty)\')\n        np.show_config()\n        print(\'Numpy dot module:\', np.dot.__module__)\n        print(\'Numpy location:\', np.__file__)\n        print(\'Numpy version:\', np.__version__)\n\n    a = theano.shared(np.ones((M, N), dtype=theano.config.floatX,\n                              order=order))\n    b = theano.shared(np.ones((N, K), dtype=theano.config.floatX,\n                              order=order))\n    c = theano.shared(np.ones((M, K), dtype=theano.config.floatX,\n                              order=order))\n    f = theano.function([], updates=[(c, 0.4 * c + .8 * T.dot(a, b))])\n\n    if any([x.op.__class__.__name__ == \'Gemm\' for x in\n            f.maker.fgraph.toposort()]):\n        c_impl = [hasattr(thunk, \'cthunk\')\n                  for node, thunk in zip(f.fn.nodes, f.fn.thunks)\n                  if node.op.__class__.__name__ == ""Gemm""]\n        assert len(c_impl) == 1\n        if c_impl[0]:\n            impl = \'CPU (with direct Theano binding to blas)\'\n        else:\n            impl = \'CPU (without direct Theano binding to blas but with numpy/scipy binding to blas)\'\n    elif any([x.op.__class__.__name__ == \'GpuGemm\' for x in\n              f.maker.fgraph.toposort()]):\n        impl = \'GPU\'\n    else:\n        impl = \'ERROR, unable to tell if Theano used the cpu or the gpu:\\n\'\n        impl += str(f.maker.fgraph.toposort())\n\n    t0 = 0\n    t1 = -1\n\n    f()  # Ignore first function call to get representative time.\n    if execute:\n        sync = (hasattr(theano, ""gpuarray"") and\n                isinstance(c, theano.gpuarray.GpuArraySharedVariable))\n        if sync:\n            # Make sure we don\'t include the time from the first call\n            c.get_value(borrow=True, return_internal_type=True).sync()\n        t0 = time.time()\n        for i in range(iters):\n            f()\n        if sync:\n            c.get_value(borrow=True, return_internal_type=True).sync()\n        t1 = time.time()\n    return t1 - t0, impl\n\n\ndef jobman_job(state, channel):\n    execute()\n    return channel.COMPLETE\n\n\ndef test():\n    return execute()\n\n\nparser = OptionParser(\n    usage=\'%prog <options>\\nCompute time needed to perform BLAS gemm \'\n    \'computations between matrices of size (M, N) and (N, K).\')\n\nparser.add_option(\'-q\', \'--quiet\', action=\'store_true\', dest=\'quiet\',\n                  default=False,\n                  help=""If true, do not print the comparison table and config ""\n                       ""options"")\nparser.add_option(\'--print_only\', action=\'store_true\', dest=\'print_only\',\n                  default=False,\n                  help=""If true, do not perform gemm computations"")\nparser.add_option(\'-M\', \'--M\', action=\'store\', dest=\'M\',\n                  default=0, type=""int"",\n                  help=""The M size to gemm"")\nparser.add_option(\'-N\', \'--N\', action=\'store\', dest=\'N\',\n                  default=0, type=""int"",\n                  help=""The N size to gemm"")\nparser.add_option(\'-K\', \'--K\', action=\'store\', dest=\'K\',\n                  default=0, type=""int"",\n                  help=""The K size to gemm"")\nparser.add_option(\'--iter\', action=\'store\', dest=\'iter\',\n                  default=10, type=""int"",\n                  help=""The number of calls to gemm"")\nparser.add_option(\'--order\', action=\'store\', dest=\'order\',\n                  default=""C"",\n                  help=""The numpy memory layout parameter used when creating""\n                  "" the numpy.ndarray objects. It accepts \'C\' for C memory""\n                  "" order and \'F\' for Fortran order (for all matrices)."")\nparser.add_option(\'-B\', \'--B\', action=\'store\', dest=\'B\',\n                  default=5000, type=""int"",\n                  help=""The M, N, and K for big gemm"")\n\n\nif __name__ == ""__main__"":\n    options, arguments = parser.parse_args(sys.argv)\n\n    if hasattr(options, ""help""):\n        print(options.help)\n        sys.exit(0)\n\n    if not options.quiet:\n        print(""""""\n        Some results that you can compare against. They were 10 executions\n        of gemm in float64 with matrices of shape 2000x2000 (M=N=K=2000).\n        All memory layout was in C order.\n\n        CPU tested: Xeon E5345(2.33Ghz, 8M L2 cache, 1333Mhz FSB),\n                    Xeon E5430(2.66Ghz, 12M L2 cache, 1333Mhz FSB),\n                    Xeon E5450(3Ghz, 12M L2 cache, 1333Mhz FSB),\n                    Xeon X5560(2.8Ghz, 12M L2 cache, hyper-threads?)\n                    Core 2 E8500, Core i7 930(2.8Ghz, hyper-threads enabled),\n                    Core i7 950(3.07GHz, hyper-threads enabled)\n                    Xeon X5550(2.67GHz, 8M l2 cache?, hyper-threads enabled)\n\n\n        Libraries tested:\n            * numpy with ATLAS from distribution (FC9) package (1 thread)\n            * manually compiled numpy and ATLAS with 2 threads\n            * goto 1.26 with 1, 2, 4 and 8 threads\n            * goto2 1.13 compiled with multiple threads enabled\n\n                          Xeon   Xeon   Xeon  Core2 i7    i7     Xeon   Xeon\n        lib/nb threads    E5345  E5430  E5450 E8500 930   950    X5560  X5550\n\n        numpy 1.3.0 blas                                                775.92s\n        numpy_FC9_atlas/1 39.2s  35.0s  30.7s 29.6s 21.5s 19.60s\n        goto/1            18.7s  16.1s  14.2s 13.7s 16.1s 14.67s\n        numpy_MAN_atlas/2 12.0s  11.6s  10.2s  9.2s  9.0s\n        goto/2             9.5s   8.1s   7.1s  7.3s  8.1s  7.4s\n        goto/4             4.9s   4.4s   3.7s  -     4.1s  3.8s\n        goto/8             2.7s   2.4s   2.0s  -     4.1s  3.8s\n        openblas/1                                        14.04s\n        openblas/2                                         7.16s\n        openblas/4                                         3.71s\n        openblas/8                                         3.70s\n        mkl 11.0.083/1            7.97s\n        mkl 10.2.2.025/1                                         13.7s\n        mkl 10.2.2.025/2                                          7.6s\n        mkl 10.2.2.025/4                                          4.0s\n        mkl 10.2.2.025/8                                          2.0s\n        goto2 1.13/1                                                     14.37s\n        goto2 1.13/2                                                      7.26s\n        goto2 1.13/4                                                      3.70s\n        goto2 1.13/8                                                      1.94s\n        goto2 1.13/16                                                     3.16s\n\n        Test time in float32. There were 10 executions of gemm in\n        float32 with matrices of shape 5000x5000 (M=N=K=5000)\n        All memory layout was in C order.\n\n\n        cuda version      8.0    7.5    7.0\n        gpu\n        M40               0.45s  0.47s\n        k80               0.92s  0.96s\n        K6000/NOECC       0.71s         0.69s\n        P6000/NOECC       0.25s\n\n        Titan X (Pascal)  0.28s\n        GTX Titan X       0.45s  0.45s  0.47s\n        GTX Titan Black   0.66s  0.64s  0.64s\n        GTX 1080          0.35s\n        GTX 980 Ti               0.41s\n        GTX 970                  0.66s\n        GTX 680                         1.57s\n        GTX 750 Ti               2.01s  2.01s\n        GTX 750                  2.46s  2.37s\n        GTX 660                  2.32s  2.32s\n        GTX 580                  2.42s\n        GTX 480                  2.87s\n        TX1                             7.6s (float32 storage and computation)\n        GT 610                          33.5s\n        """""")\n\n    if options.M == 0:\n        M = options.B\n    else:\n        M = options.M\n    if options.N == 0:\n        N = options.B\n    else:\n        N = options.N\n    if options.K == 0:\n        K = options.B\n    else:\n        K = options.K\n\n    t, impl = execute(not options.print_only, not options.quiet,\n                      M=M, N=N, K=K, iters=options.iter,\n                      order=options.order)\n\n    if options.print_only:\n        pass\n    elif options.quiet:\n        print(t)\n    else:\n        print()\n        print(""We executed"", options.iter, end=\' \')\n        print(""calls to gemm with a and b matrices of shapes"", end=\' \')\n        print(""(%d, %d) and (%d, %d)."" % (M, N, N, K))\n\n        print()\n        print(\'Total execution time: %.2fs on %s.\' % (t, impl))\n        print()\n        print(\'Try to run this script a few times. Experience shows that\'\n              \' the first time is not as fast as followings calls. The\'\n              \' difference is not big, but consistent.\')\n'"
cpu_gpu_test.py,0,"b'from theano import function, config, shared, tensor\nimport numpy\nimport time\n\nvlen = 10 * 30 * 768  # 10 x #cores x # threads per core\niters = 1000\n\nrng = numpy.random.RandomState(22)\nx = shared(numpy.asarray(rng.rand(vlen), config.floatX))\nf = function([], tensor.exp(x))\nprint(f.maker.fgraph.toposort())\nt0 = time.time()\nfor i in range(iters):\n    r = f()\nt1 = time.time()\nprint(""Looping %d times took %f seconds"" % (iters, t1 - t0))\nprint(""Result is %s"" % (r,))\nif numpy.any([isinstance(x.op, tensor.Elemwise) and\n              (\'Gpu\' not in type(x.op).__name__)\n              for x in f.maker.fgraph.toposort()]):\n    print(\'Used the cpu\')\nelse:\n    print(\'Used the gpu\')\n'"
mnist_cnn.py,0,"b""'''Trains a simple convnet on the MNIST dataset.\n\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n'''\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
mnist_cnn_mxnet.py,0,"b'\'\'\'Trains a simple convnet on the MNIST dataset.\n\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n\'\'\'\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=\'relu\',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation=\'relu\'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\'relu\'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=\'softmax\'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=[\'accuracy\'],\n              context= [""gpu(0)""])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', score[0])\nprint(\'Test accuracy:\', score[1])\n'"
mnist_cnn_pytorch.py,0,"b'from __future__ import print_function\nimport sys, argparse\nfrom time import time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\ntracker_length = 30\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(12*12*64, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))      # 28x28x32 -> 26x26x32\n        x = F.relu(self.conv2(x))      # 26x26x32 -> 24x24x64\n        x = F.max_pool2d(x, 2) # 24x24x64 -> 12x12x64\n        x = F.dropout(x, p=0.25, training=self.training)\n        x = x.view(-1, 12*12*64)       # flatten 12x12x64 = 9216\n        x = F.relu(self.fc1(x))        # fc 9216 -> 128\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.fc2(x)                # fc 128 -> 10\n        return F.log_softmax(x, dim=1) # to 10 logits\n\ndef train(args, model, device, train_loader, optimizer):\n    model.train()\n    start_time = time()\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            percentage = 100. * batch_idx / len(train_loader)\n            cur_length = int((tracker_length * int(percentage)) / 100)\n            bar = \'=\' * cur_length + \'>\' + \'-\' * (tracker_length - cur_length)\n            sys.stdout.write(\'\\r{}/{} [{}] - loss: {:.4f}\'.format(\n                batch_idx * len(data), len(train_loader.dataset),\n                bar, loss.item()))\n            sys.stdout.flush()\n\n    train_time = time() - start_time\n    sys.stdout.write(\'\\r{}/{} [{}] - {:.1f}s {:.1f}us/step - loss: {:.4f}\'.format(\n        len(train_loader.dataset), len(train_loader.dataset), \'=\' * tracker_length, \n        train_time, (train_time / len(train_loader.dataset)) * 1000000.0, loss.item()))\n    sys.stdout.flush()\n\n    return len(train_loader.dataset), train_time, loss.item()\n\ndef test(args, model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    test_accuracy = correct / len(test_loader.dataset)\n\n    return test_loss, test_accuracy\n\ndef main():\n    # Training settings\n    parser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\n    parser.add_argument(\'--batch-size\', type=int, default=128, metavar=\'N\',\n                        help=\'input batch size for training (default: 128)\')\n    parser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                        help=\'input batch size for testing (default: 1000)\')\n    parser.add_argument(\'--epochs\', type=int, default=12, metavar=\'N\',\n                        help=\'number of epochs to train (default: 12)\')\n    parser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                        help=\'learning rate (default: 0.01)\')\n    parser.add_argument(\'--momentum\', type=float, default=0.5, metavar=\'M\',\n                        help=\'SGD momentum (default: 0.5)\')\n    parser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                        help=\'disables CUDA training\')\n    parser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                        help=\'random seed (default: 1)\')\n    parser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                        help=\'how many batches to wait before logging training status\')\n    args = parser.parse_args()\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n\n    torch.manual_seed(args.seed)\n\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if use_cuda else {}\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\'../data\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\'../data\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\n    model = Net().to(device)\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n    for epoch in range(1, args.epochs + 1):\n        print(""\\nEpoch {}/{}"".format(epoch, args.epochs))\n        train_len, train_time, train_loss = train(args, model, device, train_loader, optimizer)\n        test_loss, test_accuracy = test(args, model, device, test_loader)\n        sys.stdout.write(\'\\r{}/{} [{}] - {:.1f}s {:.1f}us/step - loss: {:.4f} - val_loss: {:.4f} - val_acc: {:.4f}\'.format(\n            train_len, train_len, \'=\' * tracker_length, \n            train_time, (train_time / train_len) * 1000000.0, train_loss,\n            test_loss, test_accuracy))\n        sys.stdout.flush()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
openblas_test.py,0,"b'import numpy as np\nimport time\nimport theano\n\nprint(\'blas.ldflags=\', theano.config.blas.ldflags)\n\nA = np.random.rand(1000, 10000).astype(theano.config.floatX)\nB = np.random.rand(10000, 1000).astype(theano.config.floatX)\nnp_start = time.time()\nAB = A.dot(B)\nnp_end = time.time()\nX, Y = theano.tensor.matrices(\'XY\')\nmf = theano.function([X, Y], X.dot(Y))\nt_start = time.time()\ntAB = mf(A, B)\nt_end = time.time()\nprint(""numpy time: %f[s], theano time: %f[s] (times should be close when run on CPU!)"" % (\nnp_end - np_start, t_end - t_start))\nprint(""Result difference: %f"" % (np.abs(AB - tAB).max(), ))\n'"
