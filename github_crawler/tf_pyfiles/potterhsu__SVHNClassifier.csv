file_path,api_count,code
convert_to_tfrecords.py,10,"b'import os\nimport numpy as np\nimport h5py\nimport random\nfrom PIL import Image\nimport tensorflow as tf\nfrom meta import Meta\n\ntf.app.flags.DEFINE_string(\'data_dir\', \'./data\',\n                           \'Directory to SVHN (format 1) folders and write the converted files\')\nFLAGS = tf.app.flags.FLAGS\n\n\nclass ExampleReader(object):\n    def __init__(self, path_to_image_files):\n        self._path_to_image_files = path_to_image_files\n        self._num_examples = len(self._path_to_image_files)\n        self._example_pointer = 0\n\n    @staticmethod\n    def _get_attrs(digit_struct_mat_file, index):\n        """"""\n        Returns a dictionary which contains keys: label, left, top, width and height, each key has multiple values.\n        """"""\n        attrs = {}\n        f = digit_struct_mat_file\n        item = f[\'digitStruct\'][\'bbox\'][index].item()\n        for key in [\'label\', \'left\', \'top\', \'width\', \'height\']:\n            attr = f[item][key]\n            values = [f[attr.value[i].item()].value[0][0]\n                      for i in range(len(attr))] if len(attr) > 1 else [attr.value[0][0]]\n            attrs[key] = values\n        return attrs\n\n    @staticmethod\n    def _preprocess(image, bbox_left, bbox_top, bbox_width, bbox_height):\n        cropped_left, cropped_top, cropped_width, cropped_height = (int(round(bbox_left - 0.15 * bbox_width)),\n                                                                    int(round(bbox_top - 0.15 * bbox_height)),\n                                                                    int(round(bbox_width * 1.3)),\n                                                                    int(round(bbox_height * 1.3)))\n        image = image.crop([cropped_left, cropped_top, cropped_left + cropped_width, cropped_top + cropped_height])\n        image = image.resize([64, 64])\n        return image\n\n    @staticmethod\n    def _int64_feature(value):\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n    @staticmethod\n    def _float_feature(value):\n        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n    @staticmethod\n    def _bytes_feature(value):\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n    def read_and_convert(self, digit_struct_mat_file):\n        """"""\n        Read and convert to example, returns None if no data is available.\n        """"""\n        if self._example_pointer == self._num_examples:\n            return None\n        path_to_image_file = self._path_to_image_files[self._example_pointer]\n        index = int(path_to_image_file.split(\'/\')[-1].split(\'.\')[0]) - 1\n        self._example_pointer += 1\n\n        attrs = ExampleReader._get_attrs(digit_struct_mat_file, index)\n        label_of_digits = attrs[\'label\']\n        length = len(label_of_digits)\n        if length > 5:\n            # skip this example\n            return self.read_and_convert(digit_struct_mat_file)\n\n        digits = [10, 10, 10, 10, 10]   # digit 10 represents no digit\n        for idx, label_of_digit in enumerate(label_of_digits):\n            digits[idx] = int(label_of_digit if label_of_digit != 10 else 0)    # label 10 is essentially digit zero\n\n        attrs_left, attrs_top, attrs_width, attrs_height = map(lambda x: [int(i) for i in x], [attrs[\'left\'], attrs[\'top\'], attrs[\'width\'], attrs[\'height\']])\n        min_left, min_top, max_right, max_bottom = (min(attrs_left),\n                                                    min(attrs_top),\n                                                    max(map(lambda x, y: x + y, attrs_left, attrs_width)),\n                                                    max(map(lambda x, y: x + y, attrs_top, attrs_height)))\n        center_x, center_y, max_side = ((min_left + max_right) / 2.0,\n                                        (min_top + max_bottom) / 2.0,\n                                        max(max_right - min_left, max_bottom - min_top))\n        bbox_left, bbox_top, bbox_width, bbox_height = (center_x - max_side / 2.0,\n                                                        center_y - max_side / 2.0,\n                                                        max_side,\n                                                        max_side)\n        image = np.array(ExampleReader._preprocess(Image.open(path_to_image_file), bbox_left, bbox_top, bbox_width, bbox_height)).tobytes()\n\n        example = tf.train.Example(features=tf.train.Features(feature={\n            \'image\': ExampleReader._bytes_feature(image),\n            \'length\': ExampleReader._int64_feature(length),\n            \'digits\': tf.train.Feature(int64_list=tf.train.Int64List(value=digits))\n        }))\n        return example\n\n\ndef convert_to_tfrecords(path_to_dataset_dir_and_digit_struct_mat_file_tuples,\n                         path_to_tfrecords_files, choose_writer_callback):\n    num_examples = []\n    writers = []\n\n    for path_to_tfrecords_file in path_to_tfrecords_files:\n        num_examples.append(0)\n        writers.append(tf.python_io.TFRecordWriter(path_to_tfrecords_file))\n\n    for path_to_dataset_dir, path_to_digit_struct_mat_file in path_to_dataset_dir_and_digit_struct_mat_file_tuples:\n        path_to_image_files = tf.gfile.Glob(os.path.join(path_to_dataset_dir, \'*.png\'))\n        total_files = len(path_to_image_files)\n        print \'%d files found in %s\' % (total_files, path_to_dataset_dir)\n\n        with h5py.File(path_to_digit_struct_mat_file, \'r\') as digit_struct_mat_file:\n            example_reader = ExampleReader(path_to_image_files)\n            for index, path_to_image_file in enumerate(path_to_image_files):\n                print \'(%d/%d) processing %s\' % (index + 1, total_files, path_to_image_file)\n\n                example = example_reader.read_and_convert(digit_struct_mat_file)\n                if example is None:\n                    break\n\n                idx = choose_writer_callback(path_to_tfrecords_files)\n                writers[idx].write(example.SerializeToString())\n                num_examples[idx] += 1\n\n    for writer in writers:\n        writer.close()\n\n    return num_examples\n\n\ndef create_tfrecords_meta_file(num_train_examples, num_val_examples, num_test_examples,\n                               path_to_tfrecords_meta_file):\n    print \'Saving meta file to %s...\' % path_to_tfrecords_meta_file\n    meta = Meta()\n    meta.num_train_examples = num_train_examples\n    meta.num_val_examples = num_val_examples\n    meta.num_test_examples = num_test_examples\n    meta.save(path_to_tfrecords_meta_file)\n\n\ndef main(_):\n    path_to_train_dir = os.path.join(FLAGS.data_dir, \'train\')\n    path_to_test_dir = os.path.join(FLAGS.data_dir, \'test\')\n    path_to_extra_dir = os.path.join(FLAGS.data_dir, \'extra\')\n    path_to_train_digit_struct_mat_file = os.path.join(path_to_train_dir, \'digitStruct.mat\')\n    path_to_test_digit_struct_mat_file = os.path.join(path_to_test_dir, \'digitStruct.mat\')\n    path_to_extra_digit_struct_mat_file = os.path.join(path_to_extra_dir, \'digitStruct.mat\')\n\n    path_to_train_tfrecords_file = os.path.join(FLAGS.data_dir, \'train.tfrecords\')\n    path_to_val_tfrecords_file = os.path.join(FLAGS.data_dir, \'val.tfrecords\')\n    path_to_test_tfrecords_file = os.path.join(FLAGS.data_dir, \'test.tfrecords\')\n    path_to_tfrecords_meta_file = os.path.join(FLAGS.data_dir, \'meta.json\')\n\n    for path_to_file in [path_to_train_tfrecords_file, path_to_val_tfrecords_file, path_to_test_tfrecords_file]:\n        assert not os.path.exists(path_to_file), \'The file %s already exists\' % path_to_file\n\n    print \'Processing training and validation data...\'\n    [num_train_examples, num_val_examples] = convert_to_tfrecords([(path_to_train_dir, path_to_train_digit_struct_mat_file),\n                                                                   (path_to_extra_dir, path_to_extra_digit_struct_mat_file)],\n                                                                  [path_to_train_tfrecords_file, path_to_val_tfrecords_file],\n                                                                  lambda paths: 0 if random.random() > 0.1 else 1)\n    print \'Processing test data...\'\n    [num_test_examples] = convert_to_tfrecords([(path_to_test_dir, path_to_test_digit_struct_mat_file)],\n                                               [path_to_test_tfrecords_file],\n                                               lambda paths: 0)\n\n    create_tfrecords_meta_file(num_train_examples, num_val_examples, num_test_examples,\n                               path_to_tfrecords_meta_file)\n\n    print \'Done\'\n\n\nif __name__ == \'__main__\':\n    tf.app.run(main=main)\n'"
donkey.py,16,"b""import tensorflow as tf\n\n\nclass Donkey(object):\n    @staticmethod\n    def _preprocess(image):\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n        image = tf.multiply(tf.subtract(image, 0.5), 2)\n        image = tf.reshape(image, [64, 64, 3])\n        image = tf.random_crop(image, [54, 54, 3])\n        return image\n\n    @staticmethod\n    def _read_and_decode(filename_queue):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n        features = tf.parse_single_example(\n            serialized_example,\n            features={\n                'image': tf.FixedLenFeature([], tf.string),\n                'length': tf.FixedLenFeature([], tf.int64),\n                'digits': tf.FixedLenFeature([5], tf.int64)\n            })\n\n        image = Donkey._preprocess(tf.decode_raw(features['image'], tf.uint8))\n        length = tf.cast(features['length'], tf.int32)\n        digits = tf.cast(features['digits'], tf.int32)\n        return image, length, digits\n\n    @staticmethod\n    def build_batch(path_to_tfrecords_file, num_examples, batch_size, shuffled):\n        assert tf.gfile.Exists(path_to_tfrecords_file), '%s not found' % path_to_tfrecords_file\n\n        filename_queue = tf.train.string_input_producer([path_to_tfrecords_file], num_epochs=None)\n        image, length, digits = Donkey._read_and_decode(filename_queue)\n\n        min_queue_examples = int(0.4 * num_examples)\n        if shuffled:\n            image_batch, length_batch, digits_batch = tf.train.shuffle_batch([image, length, digits],\n                                                                             batch_size=batch_size,\n                                                                             num_threads=2,\n                                                                             capacity=min_queue_examples + 3 * batch_size,\n                                                                             min_after_dequeue=min_queue_examples)\n        else:\n            image_batch, length_batch, digits_batch = tf.train.batch([image, length, digits],\n                                                                     batch_size=batch_size,\n                                                                     num_threads=2,\n                                                                     capacity=min_queue_examples + 3 * batch_size)\n        return image_batch, length_batch, digits_batch\n"""
eval.py,6,"b""import os\nimport tensorflow as tf\nfrom meta import Meta\nfrom evaluator import Evaluator\n\ntf.app.flags.DEFINE_string('data_dir', './data', 'Directory to read TFRecords files')\ntf.app.flags.DEFINE_string('checkpoint_dir', './logs/train', 'Directory to read checkpoint files')\ntf.app.flags.DEFINE_string('eval_logdir', './logs/eval', 'Directory to write evaluation logs')\nFLAGS = tf.app.flags.FLAGS\n\n\ndef _eval(path_to_checkpoint_dir, path_to_eval_tfrecords_file, num_eval_examples, path_to_eval_log_dir):\n    evaluator = Evaluator(path_to_eval_log_dir)\n\n    checkpoint_paths = tf.train.get_checkpoint_state(path_to_checkpoint_dir).all_model_checkpoint_paths\n    for global_step, path_to_checkpoint in [(path.split('-')[-1], path) for path in checkpoint_paths]:\n        try:\n            global_step_val = int(global_step)\n        except ValueError:\n            continue\n\n        accuracy = evaluator.evaluate(path_to_checkpoint, path_to_eval_tfrecords_file, num_eval_examples,\n                                      global_step_val)\n        print 'Evaluate %s on %s, accuracy = %f' % (path_to_checkpoint, path_to_eval_tfrecords_file, accuracy)\n\n\ndef main(_):\n    path_to_train_tfrecords_file = os.path.join(FLAGS.data_dir, 'train.tfrecords')\n    path_to_val_tfrecords_file = os.path.join(FLAGS.data_dir, 'val.tfrecords')\n    path_to_test_tfrecords_file = os.path.join(FLAGS.data_dir, 'test.tfrecords')\n    path_to_tfrecords_meta_file = os.path.join(FLAGS.data_dir, 'meta.json')\n    path_to_checkpoint_dir = FLAGS.checkpoint_dir\n\n    path_to_train_eval_log_dir = os.path.join(FLAGS.eval_logdir, 'train')\n    path_to_val_eval_log_dir = os.path.join(FLAGS.eval_logdir, 'val')\n    path_to_test_eval_log_dir = os.path.join(FLAGS.eval_logdir, 'test')\n\n    meta = Meta()\n    meta.load(path_to_tfrecords_meta_file)\n\n    _eval(path_to_checkpoint_dir, path_to_train_tfrecords_file, meta.num_train_examples, path_to_train_eval_log_dir)\n    _eval(path_to_checkpoint_dir, path_to_val_tfrecords_file, meta.num_val_examples, path_to_val_eval_log_dir)\n    _eval(path_to_checkpoint_dir, path_to_test_tfrecords_file, meta.num_test_examples, path_to_test_eval_log_dir)\n\n\nif __name__ == '__main__':\n    tf.app.run(main=main)\n"""
evaluator.py,19,"b""import tensorflow as tf\nfrom donkey import Donkey\nfrom model import Model\n\n\nclass Evaluator(object):\n    def __init__(self, path_to_eval_log_dir):\n        self.summary_writer = tf.summary.FileWriter(path_to_eval_log_dir)\n\n    def evaluate(self, path_to_checkpoint, path_to_tfrecords_file, num_examples, global_step):\n        batch_size = 128\n        num_batches = num_examples / batch_size\n        needs_include_length = False\n\n        with tf.Graph().as_default():\n            image_batch, length_batch, digits_batch = Donkey.build_batch(path_to_tfrecords_file,\n                                                                         num_examples=num_examples,\n                                                                         batch_size=batch_size,\n                                                                         shuffled=False)\n            length_logits, digits_logits = Model.inference(image_batch, drop_rate=0.0)\n            length_predictions = tf.argmax(length_logits, axis=1)\n            digits_predictions = tf.argmax(digits_logits, axis=2)\n\n            if needs_include_length:\n                labels = tf.concat([tf.reshape(length_batch, [-1, 1]), digits_batch], axis=1)\n                predictions = tf.concat([tf.reshape(length_predictions, [-1, 1]), digits_predictions], axis=1)\n            else:\n                labels = digits_batch\n                predictions = digits_predictions\n\n            labels_string = tf.reduce_join(tf.as_string(labels), axis=1)\n            predictions_string = tf.reduce_join(tf.as_string(predictions), axis=1)\n\n            accuracy, update_accuracy = tf.metrics.accuracy(\n                labels=labels_string,\n                predictions=predictions_string\n            )\n\n            tf.summary.image('image', image_batch)\n            tf.summary.scalar('accuracy', accuracy)\n            tf.summary.histogram('variables',\n                                 tf.concat([tf.reshape(var, [-1]) for var in tf.trainable_variables()], axis=0))\n            summary = tf.summary.merge_all()\n\n            with tf.Session() as sess:\n                sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n                coord = tf.train.Coordinator()\n                threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n                restorer = tf.train.Saver()\n                restorer.restore(sess, path_to_checkpoint)\n\n                for _ in xrange(num_batches):\n                    sess.run(update_accuracy)\n\n                accuracy_val, summary_val = sess.run([accuracy, summary])\n                self.summary_writer.add_summary(summary_val, global_step=global_step)\n\n                coord.request_stop()\n                coord.join(threads)\n\n        return accuracy_val\n"""
inference.py,15,"b""import tensorflow as tf\nfrom model import Model\n\ntf.app.flags.DEFINE_string('image', None, 'Path to image file')\ntf.app.flags.DEFINE_string('restore_checkpoint', None,\n                           'Path to restore checkpoint (without postfix), e.g. ./logs/train/model.ckpt-100')\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n    path_to_image_file = FLAGS.image\n    path_to_restore_checkpoint_file = FLAGS.restore_checkpoint\n\n    image = tf.image.decode_jpeg(tf.read_file(path_to_image_file), channels=3)\n    image = tf.reshape(image, [64, 64, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.multiply(tf.subtract(image, 0.5), 2)\n    image = tf.image.resize_images(image, [54, 54])\n    images = tf.reshape(image, [1, 54, 54, 3])\n\n    length_logits, digits_logits = Model.inference(images, drop_rate=0.0)\n    length_predictions = tf.argmax(length_logits, axis=1)\n    digits_predictions = tf.argmax(digits_logits, axis=2)\n    digits_predictions_string = tf.reduce_join(tf.as_string(digits_predictions), axis=1)\n\n    with tf.Session() as sess:\n        restorer = tf.train.Saver()\n        restorer.restore(sess, path_to_restore_checkpoint_file)\n\n        length_predictions_val, digits_predictions_string_val = sess.run([length_predictions, digits_predictions_string])\n        length_prediction_val = length_predictions_val[0]\n        digits_prediction_string_val = digits_predictions_string_val[0]\n        print 'length: %d' % length_prediction_val\n        print 'digits: %s' % digits_prediction_string_val\n\n\nif __name__ == '__main__':\n    tf.app.run(main=main)"""
meta.py,0,"b""import json\n\n\nclass Meta(object):\n    def __init__(self):\n        self.num_train_examples = None\n        self.num_val_examples = None\n        self.num_test_examples = None\n\n    def save(self, path_to_json_file):\n        with open(path_to_json_file, 'w') as f:\n            content = {\n                'num_examples': {\n                    'train': self.num_train_examples,\n                    'val': self.num_val_examples,\n                    'test': self.num_test_examples\n                }\n            }\n            json.dump(content, f)\n\n    def load(self, path_to_json_file):\n        with open(path_to_json_file, 'r') as f:\n            content = json.load(f)\n            self.num_train_examples = content['num_examples']['train']\n            self.num_val_examples = content['num_examples']['val']\n            self.num_test_examples = content['num_examples']['test']\n"""
model.py,72,"b""import tensorflow as tf\n\n\nclass Model(object):\n\n    @staticmethod\n    def inference(x, drop_rate):\n        with tf.variable_scope('hidden1'):\n            conv = tf.layers.conv2d(x, filters=48, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden1 = dropout\n\n        with tf.variable_scope('hidden2'):\n            conv = tf.layers.conv2d(hidden1, filters=64, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden2 = dropout\n\n        with tf.variable_scope('hidden3'):\n            conv = tf.layers.conv2d(hidden2, filters=128, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden3 = dropout\n\n        with tf.variable_scope('hidden4'):\n            conv = tf.layers.conv2d(hidden3, filters=160, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden4 = dropout\n\n        with tf.variable_scope('hidden5'):\n            conv = tf.layers.conv2d(hidden4, filters=192, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden5 = dropout\n\n        with tf.variable_scope('hidden6'):\n            conv = tf.layers.conv2d(hidden5, filters=192, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden6 = dropout\n\n        with tf.variable_scope('hidden7'):\n            conv = tf.layers.conv2d(hidden6, filters=192, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden7 = dropout\n\n        with tf.variable_scope('hidden8'):\n            conv = tf.layers.conv2d(hidden7, filters=192, kernel_size=[5, 5], padding='same')\n            norm = tf.layers.batch_normalization(conv)\n            activation = tf.nn.relu(norm)\n            pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n            dropout = tf.layers.dropout(pool, rate=drop_rate)\n            hidden8 = dropout\n\n        flatten = tf.reshape(hidden8, [-1, 4 * 4 * 192])\n\n        with tf.variable_scope('hidden9'):\n            dense = tf.layers.dense(flatten, units=3072, activation=tf.nn.relu)\n            hidden9 = dense\n\n        with tf.variable_scope('hidden10'):\n            dense = tf.layers.dense(hidden9, units=3072, activation=tf.nn.relu)\n            hidden10 = dense\n\n        with tf.variable_scope('digit_length'):\n            dense = tf.layers.dense(hidden10, units=7)\n            length = dense\n\n        with tf.variable_scope('digit1'):\n            dense = tf.layers.dense(hidden10, units=11)\n            digit1 = dense\n\n        with tf.variable_scope('digit2'):\n            dense = tf.layers.dense(hidden10, units=11)\n            digit2 = dense\n\n        with tf.variable_scope('digit3'):\n            dense = tf.layers.dense(hidden10, units=11)\n            digit3 = dense\n\n        with tf.variable_scope('digit4'):\n            dense = tf.layers.dense(hidden10, units=11)\n            digit4 = dense\n\n        with tf.variable_scope('digit5'):\n            dense = tf.layers.dense(hidden10, units=11)\n            digit5 = dense\n\n        length_logits, digits_logits = length, tf.stack([digit1, digit2, digit3, digit4, digit5], axis=1)\n        return length_logits, digits_logits\n\n    @staticmethod\n    def loss(length_logits, digits_logits, length_labels, digits_labels):\n        length_cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=length_labels, logits=length_logits))\n        digit1_cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=digits_labels[:, 0], logits=digits_logits[:, 0, :]))\n        digit2_cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=digits_labels[:, 1], logits=digits_logits[:, 1, :]))\n        digit3_cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=digits_labels[:, 2], logits=digits_logits[:, 2, :]))\n        digit4_cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=digits_labels[:, 3], logits=digits_logits[:, 3, :]))\n        digit5_cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=digits_labels[:, 4], logits=digits_logits[:, 4, :]))\n        loss = length_cross_entropy + digit1_cross_entropy + digit2_cross_entropy + digit3_cross_entropy + digit4_cross_entropy + digit5_cross_entropy\n        return loss\n"""
train.py,25,"b""import os\nfrom datetime import datetime\nimport time\nimport tensorflow as tf\nfrom meta import Meta\nfrom donkey import Donkey\nfrom model import Model\nfrom evaluator import Evaluator\n\ntf.app.flags.DEFINE_string('data_dir', './data', 'Directory to read TFRecords files')\ntf.app.flags.DEFINE_string('train_logdir', './logs/train', 'Directory to write training logs')\ntf.app.flags.DEFINE_string('restore_checkpoint', None,\n                           'Path to restore checkpoint (without postfix), e.g. ./logs/train/model.ckpt-100')\ntf.app.flags.DEFINE_integer('batch_size', 32, 'Default 32')\ntf.app.flags.DEFINE_float('learning_rate', 1e-2, 'Default 1e-2')\ntf.app.flags.DEFINE_integer('patience', 100, 'Default 100, set -1 to train infinitely')\ntf.app.flags.DEFINE_integer('decay_steps', 10000, 'Default 10000')\ntf.app.flags.DEFINE_float('decay_rate', 0.9, 'Default 0.9')\nFLAGS = tf.app.flags.FLAGS\n\n\ndef _train(path_to_train_tfrecords_file, num_train_examples, path_to_val_tfrecords_file, num_val_examples,\n           path_to_train_log_dir, path_to_restore_checkpoint_file, training_options):\n    batch_size = training_options['batch_size']\n    initial_patience = training_options['patience']\n    num_steps_to_show_loss = 100\n    num_steps_to_check = 1000\n\n    with tf.Graph().as_default():\n        image_batch, length_batch, digits_batch = Donkey.build_batch(path_to_train_tfrecords_file,\n                                                                     num_examples=num_train_examples,\n                                                                     batch_size=batch_size,\n                                                                     shuffled=True)\n        length_logtis, digits_logits = Model.inference(image_batch, drop_rate=0.2)\n        loss = Model.loss(length_logtis, digits_logits, length_batch, digits_batch)\n\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        learning_rate = tf.train.exponential_decay(training_options['learning_rate'], global_step=global_step,\n                                                   decay_steps=training_options['decay_steps'], decay_rate=training_options['decay_rate'], staircase=True)\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n        train_op = optimizer.minimize(loss, global_step=global_step)\n\n        tf.summary.image('image', image_batch)\n        tf.summary.scalar('loss', loss)\n        tf.summary.scalar('learning_rate', learning_rate)\n        summary = tf.summary.merge_all()\n\n        with tf.Session() as sess:\n            summary_writer = tf.summary.FileWriter(path_to_train_log_dir, sess.graph)\n            evaluator = Evaluator(os.path.join(path_to_train_log_dir, 'eval/val'))\n\n            sess.run(tf.global_variables_initializer())\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n            saver = tf.train.Saver()\n            if path_to_restore_checkpoint_file is not None:\n                assert tf.train.checkpoint_exists(path_to_restore_checkpoint_file), \\\n                    '%s not found' % path_to_restore_checkpoint_file\n                saver.restore(sess, path_to_restore_checkpoint_file)\n                print 'Model restored from file: %s' % path_to_restore_checkpoint_file\n\n            print 'Start training'\n            patience = initial_patience\n            best_accuracy = 0.0\n            duration = 0.0\n\n            while True:\n                start_time = time.time()\n                _, loss_val, summary_val, global_step_val, learning_rate_val = sess.run([train_op, loss, summary, global_step, learning_rate])\n                duration += time.time() - start_time\n\n                if global_step_val % num_steps_to_show_loss == 0:\n                    examples_per_sec = batch_size * num_steps_to_show_loss / duration\n                    duration = 0.0\n                    print '=> %s: step %d, loss = %f (%.1f examples/sec)' % (\n                        datetime.now(), global_step_val, loss_val, examples_per_sec)\n\n                if global_step_val % num_steps_to_check != 0:\n                    continue\n\n                summary_writer.add_summary(summary_val, global_step=global_step_val)\n\n                print '=> Evaluating on validation dataset...'\n                path_to_latest_checkpoint_file = saver.save(sess, os.path.join(path_to_train_log_dir, 'latest.ckpt'))\n                accuracy = evaluator.evaluate(path_to_latest_checkpoint_file, path_to_val_tfrecords_file,\n                                              num_val_examples,\n                                              global_step_val)\n                print '==> accuracy = %f, best accuracy %f' % (accuracy, best_accuracy)\n\n                if accuracy > best_accuracy:\n                    path_to_checkpoint_file = saver.save(sess, os.path.join(path_to_train_log_dir, 'model.ckpt'),\n                                                         global_step=global_step_val)\n                    print '=> Model saved to file: %s' % path_to_checkpoint_file\n                    patience = initial_patience\n                    best_accuracy = accuracy\n                else:\n                    patience -= 1\n\n                print '=> patience = %d' % patience\n                if patience == 0:\n                    break\n\n            coord.request_stop()\n            coord.join(threads)\n            print 'Finished'\n\n\ndef main(_):\n    path_to_train_tfrecords_file = os.path.join(FLAGS.data_dir, 'train.tfrecords')\n    path_to_val_tfrecords_file = os.path.join(FLAGS.data_dir, 'val.tfrecords')\n    path_to_tfrecords_meta_file = os.path.join(FLAGS.data_dir, 'meta.json')\n    path_to_train_log_dir = FLAGS.train_logdir\n    path_to_restore_checkpoint_file = FLAGS.restore_checkpoint\n    training_options = {\n        'batch_size': FLAGS.batch_size,\n        'learning_rate': FLAGS.learning_rate,\n        'patience': FLAGS.patience,\n        'decay_steps': FLAGS.decay_steps,\n        'decay_rate': FLAGS.decay_rate\n    }\n\n    meta = Meta()\n    meta.load(path_to_tfrecords_meta_file)\n\n    _train(path_to_train_tfrecords_file, meta.num_train_examples,\n           path_to_val_tfrecords_file, meta.num_val_examples,\n           path_to_train_log_dir, path_to_restore_checkpoint_file,\n           training_options)\n\n\nif __name__ == '__main__':\n    tf.app.run(main=main)\n"""
