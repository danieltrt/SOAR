file_path,api_count,code
keras_mobilenet/__init__.py,0,b'from keras_mobilenet.mobilenet import MobileNet\n'
keras_mobilenet/depthwise_conv2d.py,1,"b""from keras import backend as K, initializers, regularizers, constraints\nfrom keras.backend import image_data_format\nfrom keras.backend.tensorflow_backend import _preprocess_conv2d_input, _preprocess_padding\nfrom keras.engine.topology import InputSpec\nimport tensorflow as tf\nfrom keras.layers import Conv2D\nfrom keras.legacy.interfaces import conv2d_args_preprocessor, generate_legacy_interface\nfrom keras.utils import conv_utils\n\n# This code mostly is taken form Keras: Separable Convolution Layer source code and changed according to needs.\n\n\ndef depthwise_conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'init' in kwargs:\n        init = kwargs.pop('init')\n        kwargs['depthwise_initializer'] = init\n        converted.append(('init', 'depthwise_initializer'))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted\n\nlegacy_depthwise_conv2d_support = generate_legacy_interface(\n    allowed_positional_args=['filters', 'kernel_size'],\n    conversions=[('nb_filter', 'filters'),\n                 ('subsample', 'strides'),\n                 ('border_mode', 'padding'),\n                 ('dim_ordering', 'data_format'),\n                 ('b_regularizer', 'bias_regularizer'),\n                 ('b_constraint', 'bias_constraint'),\n                 ('bias', 'use_bias')],\n    value_conversions={'dim_ordering': {'tf': 'channels_last',\n                                        'th': 'channels_first',\n                                        'default': None}},\n    preprocessor=depthwise_conv2d_args_preprocessor)\n\n\nclass DepthwiseConv2D(Conv2D):\n\n    @legacy_depthwise_conv2d_support\n    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(DepthwiseConv2D, self).__init__(\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n\n    def build(self, input_shape):\n        if len(input_shape) < 4:\n            raise ValueError('Inputs to `SeparableConv2D` should have rank 4. '\n                             'Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = 3\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs to '\n                             '`SeparableConv2D` '\n                             'should be defined. Found `None`.')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = (self.kernel_size[0],\n                                  self.kernel_size[1],\n                                  input_dim,\n                                  self.depth_multiplier)\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name='depthwise_kernel',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n\n        if self.data_format is None:\n            data_format = image_data_format()\n        if self.data_format not in {'channels_first', 'channels_last'}:\n            raise ValueError('Unknown data_format ' + str(data_format))\n\n        x = _preprocess_conv2d_input(inputs, self.data_format)\n        padding = _preprocess_padding(self.padding)\n        strides = (1,) + self.strides + (1,)\n\n        outputs = tf.nn.depthwise_conv2d(inputs, self.depthwise_kernel,\n                                         strides=strides,\n                                         padding=padding,\n                                         rate=self.dilation_rate)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding,\n                                             self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding,\n                                             self.strides[1])\n        if self.data_format == 'channels_first':\n            return (input_shape[0], self.filters, rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, self.filters)\n\n    def get_config(self):\n        config = super(DepthwiseConv2D, self).get_config()\n        config.pop('kernel_initializer')\n        config.pop('kernel_regularizer')\n        config.pop('kernel_constraint')\n        config['depth_multiplier'] = self.depth_multiplier\n        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n        return config\n\nDepthwiseConvolution2D = DepthwiseConv2D\n"""
keras_mobilenet/mobilenet.py,0,"b'from keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras import backend as K\nfrom keras.layers import Input, Convolution2D, \\\n    GlobalAveragePooling2D, Dense, BatchNormalization, Activation\nfrom keras.models import Model\nfrom keras.engine.topology import get_source_inputs\nfrom depthwise_conv2d import DepthwiseConvolution2D\n\n\'\'\'Google MobileNet model for Keras.\n# Reference:\n- [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf)\n\'\'\'\n\ndef MobileNet(input_tensor=None, input_shape=None, alpha=1, shallow=False, classes=1000):\n    """"""Instantiates the MobileNet.Network has two hyper-parameters\n        which are the width of network (controlled by alpha)\n        and input size.\n        \n        # Arguments\n            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n                to use as image input for the model.\n            input_shape: optional shape tuple, only to be specified\n                if `include_top` is False (otherwise the input shape\n                has to be `(224, 224, 3)` (with `channels_last` data format)\n                or `(3, 224, 244)` (with `channels_first` data format).\n                It should have exactly 3 inputs channels,\n                and width and height should be no smaller than 96.\n                E.g. `(200, 200, 3)` would be one valid value.\n            alpha: optional parameter of the network to change the \n                width of model.\n            shallow: optional parameter for making network smaller.\n            classes: optional number of classes to classify images\n                into.\n        # Returns\n            A Keras model instance.\n\n        """"""\n\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=96,\n                                      data_format=K.image_data_format(),\n                                      include_top=True)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    x = Convolution2D(int(32 * alpha), (3, 3), strides=(2, 2), padding=\'same\', use_bias=False)(img_input)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(32 * alpha), (3, 3), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(64 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(64 * alpha), (3, 3), strides=(2, 2), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(128 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(128 * alpha), (3, 3), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(128 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(128 * alpha), (3, 3), strides=(2, 2), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(256 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(256 * alpha), (3, 3), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(256 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(256 * alpha), (3, 3), strides=(2, 2), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    if not shallow:\n        for _ in range(5):\n            x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n            x = BatchNormalization()(x)\n            x = Activation(\'relu\')(x)\n            x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n            x = BatchNormalization()(x)\n            x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(2, 2), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(1024 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = DepthwiseConvolution2D(int(1024 * alpha), (3, 3), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n    x = Convolution2D(int(1024 * alpha), (1, 1), strides=(1, 1), padding=\'same\', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\'relu\')(x)\n\n    x = GlobalAveragePooling2D()(x)\n    out = Dense(classes, activation=\'softmax\')(x)\n\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    model = Model(inputs, out, name=\'mobilenet\')\n\n    return model\n\n\nif __name__ == \'__main__\':\n    m = MobileNet()\n    print ""model ready""\n'"
tests/model_size.py,0,"b'from keras_mobilenet import MobileNet\n\n\nm = MobileNet()\nm.save_weights(""../temp/model.h5"")\n'"
