file_path,api_count,code
setup.py,0,"b'from setuptools import setup, find_packages\nexec(open(\'keras_vggface/version.py\').read())\nsetup(\n    name=\'keras_vggface\',\n    version=__version__,\n    description=\'VGGFace implementation with Keras framework\',\n    url=\'https://github.com/rcmalli/keras-vggface\',\n    author=\'Refik Can MALLI\',\n    author_email=""mallir@itu.edu.tr"",\n    license=\'MIT\',\n    keywords=[\'keras\', \'vggface\', \'deeplearning\'],\n    packages=find_packages(exclude=[""tools"", ""training"", ""temp"", ""test"", ""data"", ""visualize"",""image"","".venv"","".github""]),\n    zip_safe=False,\n    install_requires=[\n        \'numpy>=1.9.1\', \'scipy>=0.14\', \'h5py\', \'pillow\', \'keras\',\n        \'six>=1.9.0\', \'pyyaml\'\n    ],\n    extras_require={\n        ""tf"": [""tensorflow""],\n        ""tf_gpu"": [""tensorflow-gpu""],\n    })\n'"
test.py,0,"b'import numpy as np\nfrom keras_vggface import VGGFace\nfrom keras.preprocessing import image\nfrom keras_vggface import utils\nimport keras\nimport unittest\n\n\nclass VGGFaceTests(unittest.TestCase):\n\n    def testVGG16(self):\n        keras.backend.image_data_format()\n        model = VGGFace(model=\'vgg16\')\n        img = image.load_img(\'image/ajb.jpg\', target_size=(224, 224))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = utils.preprocess_input(x, version=1)\n        preds = model.predict(x)\n        # print (\'\\n\', ""VGG16"")\n        # print(\'\\n\',preds)\n        # print(\'\\n\',\'Predicted:\', utils.decode_predictions(preds))\n        self.assertIn(\'A.J._Buckley\', utils.decode_predictions(preds)[0][0][0])\n        self.assertAlmostEqual(utils.decode_predictions(preds)[0][0][1], 0.9790116, places=3)\n\n    def testRESNET50(self):\n        keras.backend.image_data_format()\n        model = VGGFace(model=\'resnet50\')\n        img = image.load_img(\'image/ajb.jpg\', target_size=(224, 224))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = utils.preprocess_input(x, version=2)\n        preds = model.predict(x)\n        # print (\'\\n\',""RESNET50"")\n        # print(\'\\n\',preds)\n        # print(\'\\n\',\'Predicted:\', utils.decode_predictions(preds))\n        self.assertIn(\'A._J._Buckley\', utils.decode_predictions(preds)[0][0][0])\n        self.assertAlmostEqual(utils.decode_predictions(preds)[0][0][1], 0.91819614, places=3)\n\n    def testSENET50(self):\n        keras.backend.image_data_format()\n        model = VGGFace(model=\'senet50\')\n        img = image.load_img(\'image/ajb.jpg\', target_size=(224, 224))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = utils.preprocess_input(x, version=2)\n        preds = model.predict(x)\n        # print (\'\\n\', ""SENET50"")\n        # print(\'\\n\',preds)\n        # print(\'\\n\',\'Predicted:\', utils.decode_predictions(preds))\n        self.assertIn(\'A._J._Buckley\', utils.decode_predictions(preds)[0][0][0])\n        self.assertAlmostEqual(utils.decode_predictions(preds)[0][0][1], 0.9993529, places=3)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
keras_vggface/__init__.py,0,b'from keras_vggface.vggface import VGGFace\nfrom keras_vggface.version import __version__'
keras_vggface/models.py,0,"b'\'\'\'VGGFace models for Keras.\n\n# Notes:\n- Resnet50 and VGG16  are modified architectures from Keras Application folder. [Keras](https://keras.io)\n\n- Squeeze and excitation block is taken from  [Squeeze and Excitation Networks in\n Keras](https://github.com/titu1994/keras-squeeze-excite-network) and modified.\n\n\'\'\'\n\n\nfrom keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n    AveragePooling2D, Reshape, Permute, multiply\nfrom keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras import backend as K\nfrom keras_vggface import utils\nfrom keras.engine.topology import get_source_inputs\nimport warnings\nfrom keras.models import Model\nfrom keras import layers\n\n\ndef VGG16(include_top=True, weights=\'vggface\',\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=2622):\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    # Block 1\n    x = Conv2D(64, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv1_1\')(\n        img_input)\n    x = Conv2D(64, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv1_2\')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool1\')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv2_1\')(\n        x)\n    x = Conv2D(128, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv2_2\')(\n        x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool2\')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv3_1\')(\n        x)\n    x = Conv2D(256, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv3_2\')(\n        x)\n    x = Conv2D(256, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv3_3\')(\n        x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool3\')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv4_1\')(\n        x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv4_2\')(\n        x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv4_3\')(\n        x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool4\')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv5_1\')(\n        x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv5_2\')(\n        x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv5_3\')(\n        x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool5\')(x)\n\n    if include_top:\n        # Classification block\n        x = Flatten(name=\'flatten\')(x)\n        x = Dense(4096, name=\'fc6\')(x)\n        x = Activation(\'relu\', name=\'fc6/relu\')(x)\n        x = Dense(4096, name=\'fc7\')(x)\n        x = Activation(\'relu\', name=\'fc7/relu\')(x)\n        x = Dense(classes, name=\'fc8\')(x)\n        x = Activation(\'softmax\', name=\'fc8/softmax\')(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n            # Ensure that the model takes into account\n            # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n        # Create model.\n    model = Model(inputs, x, name=\'vggface_vgg16\')  # load weights\n    if weights == \'vggface\':\n        if include_top:\n            weights_path = get_file(\'rcmalli_vggface_tf_vgg16.h5\',\n                                    utils.\n                                    VGG16_WEIGHTS_PATH,\n                                    cache_subdir=utils.VGGFACE_DIR)\n        else:\n            weights_path = get_file(\'rcmalli_vggface_tf_notop_vgg16.h5\',\n                                    utils.VGG16_WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir=utils.VGGFACE_DIR)\n        model.load_weights(weights_path, by_name=True)\n        if K.backend() == \'theano\':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == \'channels_first\':\n            if include_top:\n                maxpool = model.get_layer(name=\'pool5\')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name=\'fc6\')\n                layer_utils.convert_dense_weights_data_format(dense, shape,\n                                                              \'channels_first\')\n\n            if K.backend() == \'tensorflow\':\n                warnings.warn(\'You are using the TensorFlow backend, yet you \'\n                              \'are using the Theano \'\n                              \'image data format convention \'\n                              \'(`image_data_format=""channels_first""`). \'\n                              \'For best performance, set \'\n                              \'`image_data_format=""channels_last""` in \'\n                              \'your Keras config \'\n                              \'at ~/.keras/keras.json.\')\n    return model\n\n\ndef resnet_identity_block(input_tensor, kernel_size, filters, stage, block,\n                          bias=False):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv1_reduce_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_1x1_reduce""\n    conv1_increase_name = \'conv\' + str(stage) + ""_"" + str(\n        block) + ""_1x1_increase""\n    conv3_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_3x3""\n\n    x = Conv2D(filters1, (1, 1), use_bias=bias, name=conv1_reduce_name)(\n        input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + ""/bn"")(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters2, kernel_size, use_bias=bias,\n               padding=\'same\', name=conv3_name)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + ""/bn"")(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters3, (1, 1), use_bias=bias, name=conv1_increase_name)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + ""/bn"")(x)\n\n    x = layers.add([x, input_tensor])\n    x = Activation(\'relu\')(x)\n    return x\n\n\ndef resnet_conv_block(input_tensor, kernel_size, filters, stage, block,\n                      strides=(2, 2), bias=False):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv1_reduce_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_1x1_reduce""\n    conv1_increase_name = \'conv\' + str(stage) + ""_"" + str(\n        block) + ""_1x1_increase""\n    conv1_proj_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_1x1_proj""\n    conv3_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_3x3""\n\n    x = Conv2D(filters1, (1, 1), strides=strides, use_bias=bias,\n               name=conv1_reduce_name)(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + ""/bn"")(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters2, kernel_size, padding=\'same\', use_bias=bias,\n               name=conv3_name)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + ""/bn"")(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + ""/bn"")(x)\n\n    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=bias,\n                      name=conv1_proj_name)(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, name=conv1_proj_name + ""/bn"")(\n        shortcut)\n\n    x = layers.add([x, shortcut])\n    x = Activation(\'relu\')(x)\n    return x\n\n\ndef RESNET50(include_top=True, weights=\'vggface\',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=8631):\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = Conv2D(\n        64, (7, 7), use_bias=False, strides=(2, 2), padding=\'same\',\n        name=\'conv1/7x7_s2\')(img_input)\n    x = BatchNormalization(axis=bn_axis, name=\'conv1/7x7_s2/bn\')(x)\n    x = Activation(\'relu\')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = resnet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n\n    x = resnet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n\n    x = resnet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n\n    x = resnet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n\n    x = AveragePooling2D((7, 7), name=\'avg_pool\')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation=\'softmax\', name=\'classifier\')(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name=\'vggface_resnet50\')\n\n    # load weights\n    if weights == \'vggface\':\n        if include_top:\n            weights_path = get_file(\'rcmalli_vggface_tf_resnet50.h5\',\n                                    utils.RESNET50_WEIGHTS_PATH,\n                                    cache_subdir=utils.VGGFACE_DIR)\n        else:\n            weights_path = get_file(\'rcmalli_vggface_tf_notop_resnet50.h5\',\n                                    utils.RESNET50_WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir=utils.VGGFACE_DIR)\n        model.load_weights(weights_path)\n        if K.backend() == \'theano\':\n            layer_utils.convert_all_kernels_in_model(model)\n            if include_top:\n                maxpool = model.get_layer(name=\'avg_pool\')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name=\'classifier\')\n                layer_utils.convert_dense_weights_data_format(dense, shape,\n                                                              \'channels_first\')\n\n        if K.image_data_format() == \'channels_first\' and K.backend() == \'tensorflow\':\n            warnings.warn(\'You are using the TensorFlow backend, yet you \'\n                          \'are using the Theano \'\n                          \'image data format convention \'\n                          \'(`image_data_format=""channels_first""`). \'\n                          \'For best performance, set \'\n                          \'`image_data_format=""channels_last""` in \'\n                          \'your Keras config \'\n                          \'at ~/.keras/keras.json.\')\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model\n\n\ndef senet_se_block(input_tensor, stage, block, compress_rate=16, bias=False):\n    conv1_down_name = \'conv\' + str(stage) + ""_"" + str(\n        block) + ""_1x1_down""\n    conv1_up_name = \'conv\' + str(stage) + ""_"" + str(\n        block) + ""_1x1_up""\n\n    num_channels = int(input_tensor.shape[-1])\n    bottle_neck = int(num_channels // compress_rate)\n\n    se = GlobalAveragePooling2D()(input_tensor)\n    se = Reshape((1, 1, num_channels))(se)\n    se = Conv2D(bottle_neck, (1, 1), use_bias=bias,\n                name=conv1_down_name)(se)\n    se = Activation(\'relu\')(se)\n    se = Conv2D(num_channels, (1, 1), use_bias=bias,\n                name=conv1_up_name)(se)\n    se = Activation(\'sigmoid\')(se)\n\n    x = input_tensor\n    x = multiply([x, se])\n    return x\n\n\ndef senet_conv_block(input_tensor, kernel_size, filters,\n                     stage, block, bias=False, strides=(2, 2)):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    bn_eps = 0.0001\n\n    conv1_reduce_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_1x1_reduce""\n    conv1_increase_name = \'conv\' + str(stage) + ""_"" + str(\n        block) + ""_1x1_increase""\n    conv1_proj_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_1x1_proj""\n    conv3_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_3x3""\n\n    x = Conv2D(filters1, (1, 1), use_bias=bias, strides=strides,\n               name=conv1_reduce_name)(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + ""/bn"",epsilon=bn_eps)(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters2, kernel_size, padding=\'same\', use_bias=bias,\n               name=conv3_name)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + ""/bn"",epsilon=bn_eps)(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + ""/bn"" ,epsilon=bn_eps)(x)\n\n    se = senet_se_block(x, stage=stage, block=block, bias=True)\n\n    shortcut = Conv2D(filters3, (1, 1), use_bias=bias, strides=strides,\n                      name=conv1_proj_name)(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis,\n                                  name=conv1_proj_name + ""/bn"",epsilon=bn_eps)(shortcut)\n\n    m = layers.add([se, shortcut])\n    m = Activation(\'relu\')(m)\n    return m\n\n\ndef senet_identity_block(input_tensor, kernel_size,\n                         filters, stage, block, bias=False):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    bn_eps = 0.0001\n\n    conv1_reduce_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_1x1_reduce""\n    conv1_increase_name = \'conv\' + str(stage) + ""_"" + str(\n        block) + ""_1x1_increase""\n    conv3_name = \'conv\' + str(stage) + ""_"" + str(block) + ""_3x3""\n\n    x = Conv2D(filters1, (1, 1), use_bias=bias,\n               name=conv1_reduce_name)(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + ""/bn"",epsilon=bn_eps)(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters2, kernel_size, padding=\'same\', use_bias=bias,\n               name=conv3_name)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + ""/bn"",epsilon=bn_eps)(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + ""/bn"",epsilon=bn_eps)(x)\n\n    se = senet_se_block(x, stage=stage, block=block, bias=True)\n\n    m = layers.add([se, input_tensor])\n    m = Activation(\'relu\')(m)\n\n    return m\n\n\ndef SENET50(include_top=True, weights=\'vggface\',\n            input_tensor=None, input_shape=None,\n            pooling=None,\n            classes=8631):\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=197,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    bn_eps = 0.0001\n\n    x = Conv2D(\n        64, (7, 7), use_bias=False, strides=(2, 2), padding=\'same\',\n        name=\'conv1/7x7_s2\')(img_input)\n    x = BatchNormalization(axis=bn_axis, name=\'conv1/7x7_s2/bn\',epsilon=bn_eps)(x)\n    x = Activation(\'relu\')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = senet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n\n    x = senet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n\n    x = senet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n\n    x = senet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n\n    x = AveragePooling2D((7, 7), name=\'avg_pool\')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation=\'softmax\', name=\'classifier\')(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name=\'vggface_senet50\')\n\n    # load weights\n    if weights == \'vggface\':\n        if include_top:\n            weights_path = get_file(\'rcmalli_vggface_tf_senet50.h5\',\n                                    utils.SENET50_WEIGHTS_PATH,\n                                    cache_subdir=utils.VGGFACE_DIR)\n        else:\n            weights_path = get_file(\'rcmalli_vggface_tf_notop_senet50.h5\',\n                                    utils.SENET50_WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir=utils.VGGFACE_DIR)\n        model.load_weights(weights_path)\n        if K.backend() == \'theano\':\n            layer_utils.convert_all_kernels_in_model(model)\n            if include_top:\n                maxpool = model.get_layer(name=\'avg_pool\')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name=\'classifier\')\n                layer_utils.convert_dense_weights_data_format(dense, shape,\n                                                              \'channels_first\')\n\n        if K.image_data_format() == \'channels_first\' and K.backend() == \'tensorflow\':\n            warnings.warn(\'You are using the TensorFlow backend, yet you \'\n                          \'are using the Theano \'\n                          \'image data format convention \'\n                          \'(`image_data_format=""channels_first""`). \'\n                          \'For best performance, set \'\n                          \'`image_data_format=""channels_last""` in \'\n                          \'your Keras config \'\n                          \'at ~/.keras/keras.json.\')\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model\n'"
keras_vggface/utils.py,0,"b""'''VGGFace models for Keras.\n\n# Notes:\n- Utility functions are modified versions of Keras functions [Keras](https://keras.io)\n\n'''\n\n\n\nimport numpy as np\nfrom keras import backend as K\nfrom keras.utils.data_utils import get_file\n\nV1_LABELS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v1.npy'\nV2_LABELS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy'\n\nVGG16_WEIGHTS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_vgg16.h5'\nVGG16_WEIGHTS_PATH_NO_TOP = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5'\n\n\nRESNET50_WEIGHTS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_resnet50.h5'\nRESNET50_WEIGHTS_PATH_NO_TOP = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5'\n\nSENET50_WEIGHTS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_senet50.h5'\nSENET50_WEIGHTS_PATH_NO_TOP = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_senet50.h5'\n\n\nVGGFACE_DIR = 'models/vggface'\n\n\ndef preprocess_input(x, data_format=None, version=1):\n    x_temp = np.copy(x)\n    if data_format is None:\n        data_format = K.image_data_format()\n    assert data_format in {'channels_last', 'channels_first'}\n\n    if version == 1:\n        if data_format == 'channels_first':\n            x_temp = x_temp[:, ::-1, ...]\n            x_temp[:, 0, :, :] -= 93.5940\n            x_temp[:, 1, :, :] -= 104.7624\n            x_temp[:, 2, :, :] -= 129.1863\n        else:\n            x_temp = x_temp[..., ::-1]\n            x_temp[..., 0] -= 93.5940\n            x_temp[..., 1] -= 104.7624\n            x_temp[..., 2] -= 129.1863\n\n    elif version == 2:\n        if data_format == 'channels_first':\n            x_temp = x_temp[:, ::-1, ...]\n            x_temp[:, 0, :, :] -= 91.4953\n            x_temp[:, 1, :, :] -= 103.8827\n            x_temp[:, 2, :, :] -= 131.0912\n        else:\n            x_temp = x_temp[..., ::-1]\n            x_temp[..., 0] -= 91.4953\n            x_temp[..., 1] -= 103.8827\n            x_temp[..., 2] -= 131.0912\n    else:\n        raise NotImplementedError\n\n    return x_temp\n\n\ndef decode_predictions(preds, top=5):\n    LABELS = None\n    if len(preds.shape) == 2:\n        if preds.shape[1] == 2622:\n            fpath = get_file('rcmalli_vggface_labels_v1.npy',\n                             V1_LABELS_PATH,\n                             cache_subdir=VGGFACE_DIR)\n            LABELS = np.load(fpath)\n        elif preds.shape[1] == 8631:\n            fpath = get_file('rcmalli_vggface_labels_v2.npy',\n                             V2_LABELS_PATH,\n                             cache_subdir=VGGFACE_DIR)\n            LABELS = np.load(fpath)\n        else:\n            raise ValueError('`decode_predictions` expects '\n                             'a batch of predictions '\n                             '(i.e. a 2D array of shape (samples, 2622)) for V1 or '\n                             '(samples, 8631) for V2.'\n                             'Found array with shape: ' + str(preds.shape))\n    else:\n        raise ValueError('`decode_predictions` expects '\n                         'a batch of predictions '\n                         '(i.e. a 2D array of shape (samples, 2622)) for V1 or '\n                         '(samples, 8631) for V2.'\n                         'Found array with shape: ' + str(preds.shape))\n    results = []\n    for pred in preds:\n        top_indices = pred.argsort()[-top:][::-1]\n        result = [[str(LABELS[i].encode('utf8')), pred[i]] for i in top_indices]\n        result.sort(key=lambda x: x[1], reverse=True)\n        results.append(result)\n    return results\n"""
keras_vggface/version.py,1,"b'__version__ = \'0.6\'\n\ndef pretty_versions():\n    import keras\n    import tensorflow as tf\n    k_version = keras.__version__\n    t_version = tf.__version__\n    return ""keras-vggface : {}, keras : {} , tensorflow : {} "".format(__version__,k_version,t_version)'"
keras_vggface/vggface.py,0,"b'\'\'\'VGGFace models for Keras.\n\n# Reference:\n- [Deep Face Recognition](http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf)\n- [VGGFace2: A dataset for recognising faces across pose and age](http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/vggface2.pdf)\n\n\'\'\'\nfrom __future__ import print_function\nfrom keras_vggface.models import RESNET50, VGG16, SENET50\n\n\ndef VGGFace(include_top=True, model=\'vgg16\', weights=\'vggface\',\n            input_tensor=None, input_shape=None,\n            pooling=None,\n            classes=None):\n    """"""Instantiates the VGGFace architectures.\n    Optionally loads weights pre-trained\n    on VGGFace datasets. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=""channels_last""` in your Keras config\n    at ~/.keras/keras.json.\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or ""vggface"" (pre-training on VGGFACE datasets).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        model: selects the one of the available architectures \n            vgg16, resnet50 or senet50 default is vgg16.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    """"""\n\n    if weights not in {\'vggface\', None}:\n        raise ValueError(\'The `weights` argument should be either \'\n                         \'`None` (random initialization) or `vggface`\'\n                         \'(pre-training on VGGFace Datasets).\')\n\n    if model == \'vgg16\':\n\n        if classes is None:\n            classes = 2622\n\n        if weights == \'vggface\' and include_top and classes != 2622:\n            raise ValueError(\n                \'If using `weights` as vggface original with `include_top`\'\n                \' as true, `classes` should be 2622\')\n\n        return VGG16(include_top=include_top, input_tensor=input_tensor,\n                     input_shape=input_shape, pooling=pooling,\n                     weights=weights,\n                     classes=classes)\n\n\n    if model == \'resnet50\':\n\n        if classes is None:\n            classes = 8631\n\n        if weights == \'vggface\' and include_top and classes != 8631:\n            raise ValueError(\n                \'If using `weights` as vggface original with `include_top`\'\n                \' as true, `classes` should be 8631\')\n\n        return RESNET50(include_top=include_top, input_tensor=input_tensor,\n                        input_shape=input_shape, pooling=pooling,\n                        weights=weights,\n                        classes=classes)\n\n    if model == \'senet50\':\n\n        if classes is None:\n            classes = 8631\n\n        if weights == \'vggface\' and include_top and classes != 8631:\n            raise ValueError(\n                \'If using `weights` as vggface original with `include_top`\'\n                \' as true, `classes` should be 8631\')\n\n        return SENET50(include_top=include_top, input_tensor=input_tensor,\n                        input_shape=input_shape, pooling=pooling,\n                        weights=weights,\n                        classes=classes)'"
tools/draw_networks.py,0,"b""from keras.utils import plot_model\nfrom keras_vggface import VGGFace\n\nmodel = VGGFace(model='vgg16')\nplot_model(model, to_file='vgg16.png', show_shapes=True)\n\nmodel = VGGFace(model='resnet50')\nplot_model(model, to_file='resnet50.png', show_shapes=True)\n\nmodel = VGGFace(model='senet50')\nplot_model(model, to_file='senet50.png' ,show_shapes=True)"""
