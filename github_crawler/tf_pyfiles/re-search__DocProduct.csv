file_path,api_count,code
__init__.py,0,b''
setup.py,0,"b'\nimport codecs\nfrom setuptools import setup, find_packages\n\nwith codecs.open(\'README.md\', \'r\', \'utf8\') as reader:\n    long_description = reader.read()\n\n\nwith codecs.open(\'requirements.txt\', \'r\', \'utf8\') as reader:\n    install_requires = list(map(lambda x: x.strip(), reader.readlines()))\n\n\nsetup(\n    name=\'docproduct\',\n    version=\'0.2.0\',\n    packages=find_packages(),\n    url=\'https://github.com/re-search/DocProduct\',\n    license=\'MIT\',\n    author=\'MedicalQATeam\',\n    author_email=\'SanGupta.ML@gmail.com\',\n    description=\'BERT in TF2.0 for Medical QA info retrieval + GPT2 for answer generation\',\n    long_description=\'None so far\',\n    long_description_content_taype=\'text/markdown\',\n    python_requires=\'>=3.5.0\',\n    install_requires=install_requires,\n    classifiers=(\n        ""Programming Language :: Python :: 2.7"",\n        ""Programming Language :: Python :: 3.6"",\n        ""License :: OSI Approved :: MIT License"",\n        ""Operating System :: OS Independent"",\n    ),\n)\n'"
docproduct/__init__.py,0,b'from docproduct.train_data_to_embedding import train_data_to_embedding\nfrom docproduct.train_embedding_to_gpt2_data import train_embedding_to_gpt2_data\nfrom docproduct.train_ffn import train_ffn\nfrom docproduct.train_bertffn import train_bertffn\nfrom docproduct.train_gpt2 import train_gpt2\nfrom docproduct import tokenization\nfrom docproduct import loss\nfrom docproduct import metrics\nfrom docproduct import dataset\nfrom docproduct import models\nfrom docproduct import predictor\nfrom docproduct import mqa_load_dataset\n'
docproduct/bert.py,1,"b'import json\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\n\nfrom keras_bert.keras_pos_embd import PositionEmbedding\nfrom keras_bert.layers import get_inputs, get_embedding, TokenEmbedding, EmbeddingSimilarity, Masked, Extract\nfrom keras_bert.keras_layer_normalization import LayerNormalization\nfrom keras_bert.keras_multi_head import MultiHeadAttention\nfrom keras_bert.keras_position_wise_feed_forward import FeedForward\n\ndef gelu(x):\n    return 0.5 * x * (1.0 + tf.math.erf(x / tf.sqrt(2.0)))\n\nclass Bert(keras.Model):\n    def __init__(\n            self,\n            token_num,\n            pos_num=512,\n            seq_len=512,\n            embed_dim=768,\n            transformer_num=12,\n            head_num=12,\n            feed_forward_dim=3072,\n            dropout_rate=0.1,\n            attention_activation=None,\n            feed_forward_activation=gelu,\n            custom_layers=None,\n            training=True,\n            trainable=None,\n            lr=1e-4,\n            name=\'Bert\'):\n        super().__init__(name=name)\n        self.token_num = token_num\n        self.pos_num = pos_num\n        self.seq_len = seq_len\n        self.embed_dim = embed_dim\n        self.transformer_num = transformer_num\n        self.head_num = head_num\n        self.feed_forward_dim = feed_forward_dim\n        self.dropout_rate = dropout_rate\n        self.attention_activation = attention_activation\n        self.feed_forward_activation = feed_forward_activation\n        self.custom_layers = custom_layers\n        self.training = training\n        self.trainable = trainable\n        self.lr = lr\n\n        # build layers\n        # embedding\n        self.token_embedding_layer = TokenEmbedding(\n            input_dim=token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            trainable=trainable,\n            name=\'Embedding-Token\',\n        )\n        self.segment_embedding_layer = keras.layers.Embedding(\n            input_dim=2,\n            output_dim=embed_dim,\n            trainable=trainable,\n            name=\'Embedding-Segment\',\n        )\n        self.position_embedding_layer = PositionEmbedding(\n            input_dim=pos_num,\n            output_dim=embed_dim,\n            mode=PositionEmbedding.MODE_ADD,\n            trainable=trainable,\n            name=\'Embedding-Position\',\n        )\n        self.embedding_layer_norm = LayerNormalization(\n            trainable=trainable,\n            name=\'Embedding-Norm\',\n        )\n\n        self.encoder_multihead_layers = []\n        self.encoder_ffn_layers = []\n        self.encoder_attention_norm = []\n        self.encoder_ffn_norm = []\n        # attention layers\n        for i in range(transformer_num):\n            base_name = \'Encoder-%d\' % (i + 1)\n            attention_name = \'%s-MultiHeadSelfAttention\' % base_name\n            feed_forward_name = \'%s-FeedForward\' % base_name\n            self.encoder_multihead_layers.append(MultiHeadAttention(\n                head_num=head_num,\n                activation=attention_activation,\n                history_only=False,\n                trainable=trainable,\n                name=attention_name,\n            ))\n            self.encoder_ffn_layers.append(FeedForward(\n                units=feed_forward_dim,\n                activation=feed_forward_activation,\n                trainable=trainable,\n                name=feed_forward_name,\n            ))\n            self.encoder_attention_norm.append(LayerNormalization(\n                trainable=trainable,\n                name=\'%s-Norm\' % attention_name,\n            ))\n            self.encoder_ffn_norm.append(LayerNormalization(\n                trainable=trainable,\n                name=\'%s-Norm\' % feed_forward_name,\n            ))\n\n    def call(self, inputs):\n\n        embeddings = [\n            self.token_embedding_layer(inputs[0]),\n            self.segment_embedding_layer(inputs[1])\n        ]\n        embeddings[0], embed_weights = embeddings[0]\n        embed_layer = keras.layers.Add(\n            name=\'Embedding-Token-Segment\')(embeddings)\n        embed_layer = self.position_embedding_layer(embed_layer)\n\n        if self.dropout_rate > 0.0:\n            dropout_layer = keras.layers.Dropout(\n                rate=self.dropout_rate,\n                name=\'Embedding-Dropout\',\n            )(embed_layer)\n        else:\n            dropout_layer = embed_layer\n\n        embedding_output = self.embedding_layer_norm(dropout_layer)\n\n        def _wrap_layer(name, input_layer, build_func, norm_layer, dropout_rate=0.0, trainable=True):\n            """"""Wrap layers with residual, normalization and dropout.\n\n            :param name: Prefix of names for internal layers.\n            :param input_layer: Input layer.\n            :param build_func: A callable that takes the input tensor and generates the output tensor.\n            :param dropout_rate: Dropout rate.\n            :param trainable: Whether the layers are trainable.\n            :return: Output layer.\n            """"""\n            build_output = build_func(input_layer)\n            if dropout_rate > 0.0:\n                dropout_layer = keras.layers.Dropout(\n                    rate=dropout_rate,\n                    name=\'%s-Dropout\' % name,\n                )(build_output)\n            else:\n                dropout_layer = build_output\n            if isinstance(input_layer, list):\n                input_layer = input_layer[0]\n            add_layer = keras.layers.Add(name=\'%s-Add\' %\n                                         name)([input_layer, dropout_layer])\n            normal_layer = norm_layer(add_layer)\n            return normal_layer\n\n        last_layer = embedding_output\n        output_tensor_list = [last_layer]\n        # self attention\n        for i in range(self.transformer_num):\n            base_name = \'Encoder-%d\' % (i + 1)\n            attention_name = \'%s-MultiHeadSelfAttention\' % base_name\n            feed_forward_name = \'%s-FeedForward\' % base_name\n            self_attention_output = _wrap_layer(\n                name=attention_name,\n                input_layer=last_layer,\n                build_func=self.encoder_multihead_layers[i],\n                norm_layer=self.encoder_attention_norm[i],\n                dropout_rate=self.dropout_rate,\n                trainable=self.trainable)\n            last_layer = _wrap_layer(\n                name=attention_name,\n                input_layer=self_attention_output,\n                build_func=self.encoder_ffn_layers[i],\n                norm_layer=self.encoder_ffn_norm[i],\n                dropout_rate=self.dropout_rate,\n                trainable=self.trainable)\n            output_tensor_list.append(last_layer)\n\n        return output_tensor_list\n\n\ndef build_model_from_config(config_file,\n                            training=False,\n                            trainable=None,\n                            seq_len=None,\n                            build=True):\n    """"""Build the model from config file.\n    :param config_file: The path to the JSON configuration file.\n    :param training: If training, the whole model will be returned.\n    :param trainable: Whether the model is trainable.\n    :param seq_len: If it is not None and it is shorter than the value in the config file, the weights in\n                    position embeddings will be sliced to fit the new length.\n    :return: model and config\n    """"""\n    with open(config_file, \'r\') as reader:\n        config = json.loads(reader.read())\n    if seq_len is not None:\n        config[\'max_position_embeddings\'] = min(\n            seq_len, config[\'max_position_embeddings\'])\n    if trainable is None:\n        trainable = training\n    model = Bert(\n        token_num=config[\'vocab_size\'],\n        pos_num=config[\'max_position_embeddings\'],\n        seq_len=config[\'max_position_embeddings\'],\n        embed_dim=config[\'hidden_size\'],\n        transformer_num=config[\'num_hidden_layers\'],\n        head_num=config[\'num_attention_heads\'],\n        feed_forward_dim=config[\'intermediate_size\'],\n        training=training,\n        trainable=trainable,\n    )\n    if build:\n        model.build(input_shape=[(None, None), (None, None), (None, None)])\n    return model, config\n'"
docproduct/dataset.py,26,"b'\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nSEED = 42\n\n\ndef _float_list_feature(value):\n    """"""Returns a float_list from a float / double.""""""\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef _int64_list_feature(value):\n    """"""Returns an int64_list from a bool / enum / int / uint.""""""\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef _int64_feature(value):\n    """"""Returns an int64_list from a bool / enum / int / uint.""""""\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef create_generator_for_ffn(\n        file_list,\n        mode=\'train\'):\n\n    # file_list = glob(os.path.join(data_dir, \'*.csv\'))\n\n    for full_file_path in file_list:\n        # full_file_path = os.path.join(data_dir, file_name)\n        if not os.path.exists(full_file_path):\n            raise FileNotFoundError(""File %s not found"" % full_file_path)\n        df = pd.read_csv(full_file_path, encoding=\'utf8\')\n\n        # so train test split\n        if mode == \'train\':\n            df, _ = train_test_split(df, test_size=0.2, random_state=SEED)\n        else:\n            _, df = train_test_split(df, test_size=0.2, random_state=SEED)\n\n        for _, row in df.iterrows():\n            q_vectors = np.fromstring(row.question_bert.replace(\n                \'[[\', \'\').replace(\']]\', \'\'), sep=\' \')\n            a_vectors = np.fromstring(row.answer_bert.replace(\n                \'[[\', \'\').replace(\']]\', \'\'), sep=\' \')\n            vectors = np.stack([q_vectors, a_vectors], axis=0)\n            if mode in [\'train\', \'eval\']:\n                yield vectors, 1\n            else:\n                yield vectors\n\n\ndef ffn_serialize_fn(features):\n    features_tuple = {\'features\': _float_list_feature(\n        features[0].flatten()), \'labels\': _int64_feature(features[1])}\n    example_proto = tf.train.Example(\n        features=tf.train.Features(feature=features_tuple))\n    return example_proto.SerializeToString()\n\n\ndef make_tfrecord(data_dir, generator_fn, serialize_fn, suffix=\'\', **kwargs):\n    """"""Function to make TF Records from csv files\n    This function will take all csv files in data_dir, convert them\n    to tf example and write to *_{suffix}_train/eval.tfrecord to data_dir.\n\n    Arguments:\n        data_dir {str} -- dir that has csv files and store tf record\n        generator_fn {fn} -- A function that takes a list of filepath and yield the\n        parsed recored from file.\n        serialize_fn {fn} -- A function that takes output of generator fn and convert to tf example\n\n    Keyword Arguments:\n        suffix {str} -- suffix to add to tf record files (default: {\'\'})\n    """"""\n    file_list = glob(os.path.join(data_dir, \'*.csv\'))\n    train_tf_record_file_list = [\n        f.replace(\'.csv\', \'_{0}_train.tfrecord\'.format(suffix)) for f in file_list]\n    test_tf_record_file_list = [\n        f.replace(\'.csv\', \'_{0}_eval.tfrecord\'.format(suffix)) for f in file_list]\n    for full_file_path, train_tf_record_file_path, test_tf_record_file_path in zip(file_list, train_tf_record_file_list, test_tf_record_file_list):\n        print(\'Converting file {0} to TF Record\'.format(full_file_path))\n        with tf.io.TFRecordWriter(train_tf_record_file_path) as writer:\n            for features in generator_fn([full_file_path], mode=\'train\', **kwargs):\n                example = serialize_fn(features)\n                writer.write(example)\n        with tf.io.TFRecordWriter(test_tf_record_file_path) as writer:\n            for features in generator_fn([full_file_path], mode=\'eval\', **kwargs):\n                example = serialize_fn(features)\n                writer.write(example)\n\n\ndef create_dataset_for_ffn(\n        data_dir,\n        mode=\'train\',\n        hidden_size=768,\n        shuffle_buffer=10000,\n        prefetch=10000,\n        batch_size=32):\n\n    tfrecord_file_list = glob(os.path.join(\n        data_dir, \'*_FFN_{0}.tfrecord\'.format((mode))))\n    if not tfrecord_file_list:\n        print(\'TF Record not found\')\n        make_tfrecord(\n            data_dir, create_generator_for_ffn,\n            ffn_serialize_fn, \'FFN\')\n\n    dataset = tf.data.TFRecordDataset(tfrecord_file_list)\n\n    def _parse_ffn_example(example_proto):\n        feature_description = {\n            \'features\': tf.io.FixedLenFeature([2*768], tf.float32),\n            \'labels\': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n        }\n        feature_dict = tf.io.parse_single_example(\n            example_proto, feature_description)\n        return tf.reshape(feature_dict[\'features\'], (2, 768)), feature_dict[\'labels\']\n    dataset = dataset.map(_parse_ffn_example)\n\n    if mode == \'train\':\n        dataset = dataset.shuffle(shuffle_buffer)\n\n    dataset = dataset.prefetch(prefetch)\n\n    dataset = dataset.batch(batch_size)\n    return dataset\n\n\nclass PaddingInputExample(object):\n    """"""Fake example so the num input examples is a multiple of the batch size.\n    When running eval/predict on the TPU, we need to pad the number of examples\n    to be a multiple of the batch size, because the TPU requires a fixed batch\n    size. The alternative is to drop the last batch, which is bad because it means\n    the entire output data won\'t be generated.\n    We use this class instead of `None` because treating `None` as padding\n    battches could cause silent errors.\n    """"""\n\n\nclass InputExample(object):\n    """"""A single training/test example for simple sequence classification.""""""\n\n    def __init__(self, guid, text_a, text_b=None, label=None):\n        """"""Constructs a InputExample.\n    Args:\n      guid: Unique id for the example.\n      text_a: string. The untokenized text of the first sequence. For single\n        sequence tasks, only this sequence must be specified.\n      text_b: (Optional) string. The untokenized text of the second sequence.\n        Only must be specified for sequence pair tasks.\n      label: (Optional) string. The label of the example. This should be\n        specified for train and dev examples, but not for test examples.\n    """"""\n        self.guid = guid\n        self.text_a = text_a\n        self.text_b = text_b\n        self.label = label\n\n\ndef convert_single_example(tokenizer, example, max_seq_length=256, dynamic_padding=False):\n    """"""Converts a single `InputExample` into a single `InputFeatures`.""""""\n\n    if isinstance(example, PaddingInputExample):\n        input_ids = [0] * max_seq_length\n        input_mask = [0] * max_seq_length\n        segment_ids = [0] * max_seq_length\n        label = 0\n        return input_ids, input_mask, segment_ids, label\n\n    tokens_a = tokenizer.tokenize(example.text_a)\n    if len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[0: (max_seq_length - 2)]\n\n    tokens = []\n    segment_ids = []\n    tokens.append(""[CLS]"")\n    segment_ids.append(0)\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(0)\n    tokens.append(""[SEP]"")\n    segment_ids.append(0)\n\n    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n\n    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n    # tokens are attended to.\n    input_mask = [1] * len(input_ids)\n\n    # Zero-pad up to the sequence length.\n    if not dynamic_padding:\n        while len(input_ids) < max_seq_length:\n            input_ids.append(0)\n            input_mask.append(0)\n            segment_ids.append(0)\n\n        assert len(input_ids) == max_seq_length\n        assert len(input_mask) == max_seq_length\n        assert len(segment_ids) == max_seq_length\n\n    return input_ids, input_mask, segment_ids, example.label\n\n\ndef convert_examples_to_features(tokenizer, examples, max_seq_length=256, dynamic_padding=False):\n    """"""Convert a set of `InputExample`s to a list of `InputFeatures`.""""""\n\n    input_ids, input_masks, segment_ids, labels = [], [], [], []\n    for example in examples:\n        input_id, input_mask, segment_id, label = convert_single_example(\n            tokenizer, example, max_seq_length, dynamic_padding=dynamic_padding\n        )\n        input_ids.append(input_id)\n        input_masks.append(input_mask)\n        segment_ids.append(segment_id)\n        labels.append(label)\n    return (\n        np.squeeze(np.array(input_ids)),\n        np.squeeze(np.array(input_masks)),\n        np.squeeze(np.array(segment_ids)),\n        np.array(labels).reshape(-1, 1),\n    )\n\n\ndef convert_text_to_feature(text, tokenizer, max_seq_length, dynamic_padding=False):\n    example = InputExample(\n        guid=None, text_a=text)\n    features = convert_examples_to_features(\n        tokenizer, [example], max_seq_length, dynamic_padding=dynamic_padding)\n    return features\n\n\ndef create_generator_for_bert(\n        file_list,\n        tokenizer,\n        mode=\'train\',\n        max_seq_length=256,\n        dynamic_padding=False):\n    # file_list = glob(os.path.join(data_dir, \'*.csv\'))\n    for full_file_path in file_list:\n        # full_file_path = os.path.join(data_dir, file_name)\n        if not os.path.exists(full_file_path):\n            raise FileNotFoundError(""File %s not found"" % full_file_path)\n\n        if os.path.basename(full_file_path) == \'healthtap_data_cleaned.csv\':\n            df = pd.read_csv(full_file_path, lineterminator=\'\\n\')\n            df.columns = [\'index\', \'question\', \'answer\']\n            df.drop(columns=[\'index\'], inplace=True)\n        else:\n            df = pd.read_csv(full_file_path, lineterminator=\'\\n\')\n\n        # so train test split\n        if mode == \'train\':\n            df, _ = train_test_split(df, test_size=0.2, random_state=SEED)\n        else:\n            _, df = train_test_split(df, test_size=0.2, random_state=SEED)\n\n        for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\'Writing to TFRecord\'):\n            try:\n                q_features = convert_text_to_feature(\n                    row.question, tokenizer, max_seq_length, dynamic_padding=dynamic_padding)\n            except (ValueError, AttributeError):\n                continue\n            # no labels\n            q_features = q_features[:3]\n            try:\n                a_features = convert_text_to_feature(\n                    row.answer, tokenizer, max_seq_length, dynamic_padding=dynamic_padding)\n            except (ValueError, AttributeError):\n                continue\n            a_features = a_features[:3]\n            yield (q_features+a_features, 1)\n\n\ndef _qa_ele_to_length(features, labels):\n    return tf.shape(features[\'q_input_ids\'])[0] + tf.shape(features[\'a_input_ids\'])[0]\n\n\ndef bert_serialize_fn(features):\n    feature, labels = features\n    # feature = [_int64_feature(f.flatten()) for f in feature]\n    # labels = _int64_feature(labels)\n    # features_tuple = (feature, labels)\n    features_tuple = {\n        \'q_input_ids\': _int64_list_feature(\n            feature[0].flatten()),\n        \'q_input_masks\': _int64_list_feature(\n            feature[1].flatten()),\n        \'q_segment_ids\': _int64_list_feature(\n            feature[2].flatten()),\n        \'q_input_shape\': _int64_list_feature(\n            feature[0].shape),\n        \'a_input_ids\': _int64_list_feature(\n            feature[3].flatten()),\n        \'a_input_masks\': _int64_list_feature(\n            feature[4].flatten()),\n        \'a_segment_ids\': _int64_list_feature(\n            feature[5].flatten()),\n        \'a_input_shape\': _int64_list_feature(\n            feature[3].shape),\n        \'labels\': _int64_feature(labels)}\n    example_proto = tf.train.Example(\n        features=tf.train.Features(feature=features_tuple))\n    return example_proto.SerializeToString()\n\n\ndef create_dataset_for_bert(\n        data_dir,\n        tokenizer=None,\n        mode=\'train\',\n        max_seq_length=256,\n        shuffle_buffer=10000,\n        prefetch=10000,\n        batch_size=32,\n        dynamic_padding=False,\n        bucket_batch_sizes=[32, 16, 8],\n        bucket_boundaries=[64, 128],\n        element_length_func=_qa_ele_to_length):\n\n    tfrecord_file_list = glob(os.path.join(\n        data_dir, \'*_BertFFN_{0}.tfrecord\'.format((mode))))\n    if not tfrecord_file_list:\n        print(\'TF Record not found\')\n        make_tfrecord(\n            data_dir, create_generator_for_bert,\n            bert_serialize_fn, \'BertFFN\', tokenizer=tokenizer, dynamic_padding=True, max_seq_length=max_seq_length)\n        tfrecord_file_list = glob(os.path.join(\n            data_dir, \'*_BertFFN_{0}.tfrecord\'.format((mode))))\n\n    dataset = tf.data.TFRecordDataset(tfrecord_file_list)\n\n    def _parse_bert_example(example_proto):\n        feature_description = {\n            \'q_input_ids\': tf.io.VarLenFeature(tf.int64),\n            \'q_input_masks\': tf.io.VarLenFeature(tf.int64),\n            \'q_segment_ids\': tf.io.VarLenFeature(tf.int64),\n            \'a_input_ids\': tf.io.VarLenFeature(tf.int64),\n            \'a_input_masks\': tf.io.VarLenFeature(tf.int64),\n            \'a_segment_ids\': tf.io.VarLenFeature(tf.int64),\n            \'labels\': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n        }\n        feature_dict = tf.io.parse_single_example(\n            example_proto, feature_description)\n        dense_feature_dict = {k: tf.sparse.to_dense(\n            v) for k, v in feature_dict.items() if k != \'labels\'}\n        dense_feature_dict[\'labels\'] = feature_dict[\'labels\']\n        return dense_feature_dict, feature_dict[\'labels\']\n    dataset = dataset.map(_parse_bert_example)\n\n    if mode == \'train\':\n        dataset = dataset.shuffle(shuffle_buffer)\n    if dynamic_padding:\n        dataset = dataset.apply(\n            tf.data.experimental.bucket_by_sequence_length(\n                element_length_func=element_length_func,\n                bucket_batch_sizes=bucket_batch_sizes,\n                bucket_boundaries=bucket_boundaries\n            ))\n    else:\n        dataset = dataset.batch(batch_size)\n\n    dataset = dataset.prefetch(prefetch)\n\n    return dataset\n'"
docproduct/get_data.py,0,"b'"""""" Download Pushshift Data """"""\n\nimport os\nfrom urllib import request as req\nimport re\nimport pycurl\nimport hashlib\n# Define values\n\nURLS=[""https://files.pushshift.io/reddit/comments/"",""https://files.pushshift.io/reddit/submissions""]\nBZ2_LINK_RE_PATTERN = r""<a\\s.*href=[\\""\'](\\S+)[\\""\'][^>]*>\\S*.bz2<\\/a>""\nSHA256_LINK_RE_PATTERN = r""<a\\s.*href=[\\""\'](\\S+)[\\""\'][^>]*>sha256\\S*<\\/a>""\nOUTPUT_DIR = ""reddit_submissions""\n# Define functions\ndef main():\n    """"""The main entrypoint.""""""\n\n    for BASE_URL in URLS:\n        submissions_page=req.urlopen(BASE_URL).read().decode(""utf-8"")\n\n\n        # Get BZ2 Links\n        raw_links = re.findall(BZ2_LINK_RE_PATTERN,submissions_page)\n        filtered_links = [link[2:] for link in raw_links if link.startswith(""./"")]\n        individual_links = list(set(filtered_links))\n\n        # Download files\n        if not os.path.exists(OUTPUT_DIR):\n            os.makedirs(OUTPUT_DIR)\n        else:\n            # get first match and remove the ./ from the start of the link\n            sha256_link = re.findall(SHA256_LINK_RE_PATTERN,submissions_page)[0][2:]\n            hash_file=(req.urlopen(""%s/%s""%(BASE_URL,sha256_link)).read().decode(""utf-8""))\n\n            hash_file_pairs=({entry.split(""  "")[1]:entry.split(""  "")[0] for entry in hash_file.split(""\\n"") if len(entry.split(""  ""))>1})\n            for file in hash_file_pairs.keys():\n                file_path=os.path.join(OUTPUT_DIR,file)\n                if(os.path.exists(file_path) and hashlib.sha256(open(file_path,\'rb\').read()).hexdigest()!=hash_file_pairs[file.split(""/"")[-1]]):\n                    print(""File is corrput, deleting %s""%file_path)\n                    os.remove(file_path)\n\n\n        curl = pycurl.Curl()\n        for link in sorted(individual_links):\n            url = BASE_URL + ""/"" + link\n            file_path=os.path.join(OUTPUT_DIR, link)\n\n            if not os.path.exists(file_path):\n                with open(file_path, ""wb"") as file:\n                    curl.setopt(curl.URL, url)\n                    curl.setopt(curl.WRITEDATA, file)\n                    curl.perform()\n                print(""Downloaded"", link)\n        curl.close()\n\n# Execute main function\nif __name__ == ""__main__"":\n    main()\n'"
docproduct/inference_GenerateQADoc.py,0,"b""from docproduct.predictor import GenerateQADoc\n\npretrained_path = 'pubmed_pmc_470k/'\nffn_weight_file = None\nbert_ffn_weight_file = 'models/bertffn_crossentropy/bertffn'\nembedding_file = 'qa_embeddings/bertffn_crossentropy.pkl'\n\ndoc = GenerateQADoc(pretrained_path=pretrained_path,\n                    ffn_weight_file=None,\n                    bert_ffn_weight_file=bert_ffn_weight_file,\n                    embedding_file=embedding_file)\nprint(doc.predict('my eyes hurts and i have a headache.',\n                  search_by='answer', topk=5, answer_only=False))\nprint(doc.predict('my eyes hurts and i have a headache.',\n                  search_by='question', topk=5, answer_only=False))\n"""
docproduct/inference_question_to_topk.py,0,"b""from docproduct.predictor import RetreiveQADoc\n\npretrained_path = 'pubmed_pmc_470k/'\nffn_weight_file = None\nbert_ffn_weight_file = 'models/bertffn_crossentropy/bertffn'\nembedding_file = 'qa_embeddings/bertffn_crossentropy.pkl'\n\ndoc = RetreiveQADoc(pretrained_path=pretrained_path,\n                    ffn_weight_file=None,\n                    bert_ffn_weight_file=bert_ffn_weight_file,\n                    embedding_file=embedding_file)\n\nprint(doc.predict('my eyes hurts and i have a headache.',\n                  search_by='answer', topk=5, answer_only=True))\nprint(doc.predict('my eyes hurts and i have a headache.',\n                  search_by='question', topk=5, answer_only=True))\n"""
docproduct/loss.py,11,"b'import tensorflow as tf\n\ndef qa_pair_loss(y_true, y_pred):\n    y_true = tf.eye(tf.shape(y_pred)[0])*2-1\n    q_embedding, a_embedding = tf.unstack(y_pred, axis=1)\n    q_embedding = q_embedding / \\\n        tf.norm(q_embedding, axis=-1, keepdims=True)\n    a_embedding = a_embedding / \\\n        tf.norm(a_embedding, axis=-1, keepdims=True)\n    similarity_matrix = tf.matmul(\n        q_embedding, a_embedding, transpose_b=True)\n    return tf.reduce_mean(tf.norm(y_true - similarity_matrix, axis=-1))\n\n\ndef qa_pair_cross_entropy_loss(y_true, y_pred):\n    y_true = tf.eye(tf.shape(y_pred)[0])\n    q_embedding, a_embedding = tf.unstack(y_pred, axis=1)\n    similarity_matrix = tf.matmul(\n        a=q_embedding, b=a_embedding, transpose_b=True)\n    similarity_matrix_softmaxed = tf.nn.softmax(similarity_matrix)\n    return tf.keras.losses.categorical_crossentropy(y_true, similarity_matrix_softmaxed, from_logits=False)\n'"
docproduct/metrics.py,6,"b'import tensorflow as tf\n\n\ndef qa_pair_batch_accuracy(y_true, y_pred):\n    y_true = tf.eye(tf.shape(y_pred)[0])\n    q_embedding, a_embedding = tf.unstack(y_pred, axis=1)\n    similarity_matrix = tf.matmul(\n        q_embedding, a_embedding, transpose_b=True)\n    y_true = tf.argmax(y_true, axis=1)\n    y_pred = tf.argmax(similarity_matrix, axis=1)\n    acc = tf.reduce_mean(tf.cast(tf.equal(y_pred, y_true), tf.float32))\n    return acc\n'"
docproduct/models.py,11,"b'from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\n\nfrom docproduct.bert import build_model_from_config\n\nfrom keras_bert.loader import load_model_weights_from_checkpoint\n\n\nclass FFN(tf.keras.layers.Layer):\n    def __init__(\n            self,\n            hidden_size=768,\n            dropout=0.2,\n            residual=True,\n            name=\'FFN\',\n            **kwargs):\n        """"""Simple Dense wrapped with various layers\n        """"""\n\n        super(FFN, self).__init__(name=name, **kwargs)\n        self.hidden_size = hidden_size\n        self.dropout = dropout\n        self.residual = residual\n        self.ffn_layer = tf.keras.layers.Dense(\n            units=hidden_size,\n            use_bias=True\n        )\n\n    def call(self, inputs):\n        ffn_embedding = self.ffn_layer(inputs)\n        ffn_embedding = tf.keras.layers.ReLU()(ffn_embedding)\n        if self.dropout > 0:\n            ffn_embedding = tf.keras.layers.Dropout(\n                self.dropout)(ffn_embedding)\n\n        if self.residual:\n            ffn_embedding += inputs\n        return ffn_embedding\n\n\nclass MedicalQAModel(tf.keras.Model):\n    def __init__(self, name=\'\'):\n        super(MedicalQAModel, self).__init__(name=name)\n        self.q_ffn = FFN(name=\'q_ffn\', input_shape=(768,))\n        self.a_ffn = FFN(name=\'a_ffn\', input_shape=(768,))\n\n    def call(self, inputs):\n        q_bert_embedding, a_bert_embedding = tf.unstack(inputs, axis=1)\n        q_embedding, a_embedding = self.q_ffn(\n            q_bert_embedding), self.a_ffn(a_bert_embedding)\n        return tf.stack([q_embedding, a_embedding], axis=1)\n\n\nclass MedicalQAModelwithBert(tf.keras.Model):\n    def __init__(\n            self,\n            hidden_size=768,\n            dropout=0.2,\n            residual=True,\n            config_file=None,\n            checkpoint_file=None,\n            bert_trainable=True,\n            layer_ind=-1,\n            name=\'\'):\n        super(MedicalQAModelwithBert, self).__init__(name=name)\n        build = checkpoint_file != None\n        self.biobert, config = build_model_from_config(\n            config_file=config_file,\n            training=False,\n            trainable=bert_trainable,\n            build=build)\n        if checkpoint_file is not None:\n            load_model_weights_from_checkpoint(\n                model=self.biobert, config=config, checkpoint_file=checkpoint_file, training=False)\n        self.q_ffn_layer = FFN(\n            hidden_size=hidden_size,\n            dropout=dropout,\n            residual=residual,\n            name=\'q_ffn\')\n        self.a_ffn_layer = FFN(\n            hidden_size=hidden_size,\n            dropout=dropout,\n            residual=residual,\n            name=\'a_ffn\')\n        self.layer_ind = layer_ind\n\n    def call(self, inputs):\n\n        if \'q_input_ids\' in inputs:\n            with_question = True\n        else:\n            with_question = False\n\n        if \'a_input_ids\' in inputs:\n            with_answer = True\n        else:\n            with_answer = False\n        # according to USE, the DAN network average embedding across tokens\n        if with_question:\n            q_bert_embedding = self.biobert(\n                (inputs[\'q_input_ids\'], inputs[\'q_segment_ids\'], inputs[\'q_input_masks\']))[self.layer_ind]\n            q_bert_embedding = tf.reduce_mean(q_bert_embedding, axis=1)\n        if with_answer:\n            a_bert_embedding = self.biobert(\n                (inputs[\'a_input_ids\'], inputs[\'a_segment_ids\'], inputs[\'a_input_masks\']))[self.layer_ind]\n            a_bert_embedding = tf.reduce_mean(a_bert_embedding, axis=1)\n\n        if with_question:\n            q_embedding = self.q_ffn_layer(q_bert_embedding)\n            output = q_embedding\n        if with_answer:\n            a_embedding = self.a_ffn_layer(a_bert_embedding)\n            output = a_embedding\n\n        if with_question and with_answer:\n            output = tf.stack([q_embedding, a_embedding], axis=1)\n\n        return output\n'"
docproduct/mqa_load_dataset.py,0,"b'import glob\nimport numpy as np\nimport os\nimport random\nimport tensorflow.compat.v1 as tf\nimport tqdm\nimport csv\nimport pandas as pd\n\n\ndef load_dataset(enc, path, combine, pretokenize=True, topk=10):\n    paths = []\n    if os.path.isfile(path):\n        # Simple file\n        paths.append(path)\n    elif os.path.isdir(path):\n        # Directory\n        for (dirpath, _, fnames) in os.walk(path):\n            for fname in fnames:\n                paths.append(os.path.join(dirpath, fname))\n    else:\n        # Assume glob\n        paths = glob.glob(path)\n    if paths == []:\n        raise Exception(""No data found"")\n\n    token_chunks = []\n\n    if pretokenize:\n\n        pt_path = path.split(\'.\')[0] + \'_pretokenized.\' + \'npy\'\n\n        if not os.path.exists(pt_path):\n\n            print(\'Pretokenizing data..\')\n\n            token_list = []\n\n            for path in paths:\n\n                df = pd.read_parquet(path)\n\n                for sample_ind, sample in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\'Pretokenization\'):\n                    line = \'`QUESTION: %s `ANSWER: %s\' % (\n                        sample[0], sample[1])\n                    for i in range(2, len(sample), 2):\n                        if i <= topk*2:\n                            line = \'`QUESTION: %s `ANSWER: %s \' % (\n                                sample[i], sample[i+1]) + line\n                    line = line.replace(\'\\n\', \'\')\n                    if sample_ind <= 10:\n                        print(line)\n                    token_list.append(np.stack(enc.encode(line)))\n\n                print(\'Pretokenization successful!\')\n            np.save(pt_path, np.array(token_list))\n\n        print(\'Loading pretokenized data..\')\n        token_chunks = np.load(pt_path, allow_pickle=True)\n\n        # with open(pt_path, \'r\', encoding=\'utf8\') as pt:\n        #     pt_reader = csv.reader(pt)\n        #     pt_iter = list(pt_reader)\n\n        #     for j, sample in enumerate(tqdm.tqdm(pt_iter[1:])):\n        #         tokens = np.asarray(\n        #             sample[-1].strip(\'[]\').replace(\',\', \'\').split(), dtype=np.int32)\n        #         token_chunks.append(tokens)\n\n    else:\n        raise NotImplementedError\n\n        for path in paths:\n            \'\'\'\n            if path.endswith(\'.npz\'):\n                # Pre-encoded\n                with np.load(path) as npz:\n                    for item in npz.files:\n                        token_chunks.append(npz[item])\n            else:\n                # Plain text\n                with open(path, \'r\', encoding=\'utf8\', errors=\'ignore\') as fp:\n                    raw_text += fp.read()\n                if len(raw_text) >= combine:\n                    tokens = np.stack(enc.encode(raw_text))\n                    token_chunks.append(tokens)\n                    raw_text = \'\'\n                else:\n                    raw_text += \'<|endoftext|>\'\n            \'\'\'\n            with open(path, \'r\', encoding=\'utf8\', errors=\'ignore\') as fp:\n                csv_reader = csv.reader(fp)\n\n                for j, sample in enumerate(tqdm.tqdm(csv_reader)):\n                    line = \'`QUESTION: %s `ANSWER: %s\' % (\n                        sample[0], sample[1])\n                    for i in range(len(sample), 2, -2):\n                        line = \'`QUESTION: %s `ANSWER: %s \' % (\n                            sample[i-2], sample[i-1]) + line\n                    tokens = np.stack(enc.encode(line))\n                    token_chunks.append(tokens)\n        \'\'\'\n        if raw_text:\n            tokens = np.stack(enc.encode(raw_text))\n            token_chunks.append(tokens)\n        \'\'\'\n\n    return token_chunks\n\n\ndef binary_search(f, lo, hi):\n    if f(lo) or not f(hi):\n        return None\n    while hi > lo + 1:\n        mid = (lo + hi) // 2\n        if f(mid):\n            hi = mid\n        else:\n            lo = mid\n    return hi\n\n\nclass Sampler(object):\n    """"""Fairly samples a slice from a set of variable sized chunks.\n\n    \'Fairly\' means that the distribution is the same as sampling from one concatenated chunk,\n    but without crossing chunk boundaries.""""""\n\n    def __init__(self, chunks):\n        self.chunks = chunks\n        self.total_size = sum(chunk.shape[0] for chunk in chunks)\n        self.boundaries = [0]\n        for i in range(len(chunks)):\n            self.boundaries.append(self.boundaries[-1] + chunks[i].shape[0])\n\n    def sample(self, length):\n        \'\'\'\n        assert length < self.total_size // len(\n            self.chunks\n        ), ""Dataset files are too small to sample {} tokens at a time"".format(\n            length)\n        while True:\n            index = random.randint(0, self.total_size - length - 1)\n            i = binary_search(lambda j: self.boundaries[j] > index, 0,\n                              len(self.boundaries) - 1) - 1\n            if self.boundaries[i + 1] > index + length:\n                within_chunk = index - self.boundaries[i]\n                return self.chunks[i][within_chunk:within_chunk + length]\n        \'\'\'\n        return random.choice(self.chunks)\n'"
docproduct/predictor.py,8,"b'import json\nimport os\nimport re\nfrom collections import defaultdict\nfrom multiprocessing import Pool, cpu_count\nfrom time import time\n\nimport faiss\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm import tqdm\n\nimport gpt2_estimator\nfrom docproduct.dataset import convert_text_to_feature\nfrom docproduct.models import MedicalQAModelwithBert\nfrom docproduct.tokenization import FullTokenizer\nfrom keras_bert.loader import checkpoint_loader\n\n\ndef load_weight(model, bert_ffn_weight_file=None, ffn_weight_file=None):\n    if bert_ffn_weight_file:\n        model.load_weights(bert_ffn_weight_file)\n    elif ffn_weight_file:\n        loader = checkpoint_loader(ffn_weight_file)\n        model.get_layer(\'q_ffn\').set_weights(\n            [loader(\'q_ffn/ffn_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE\'),\n             loader(\'q_ffn/ffn_layer/bias/.ATTRIBUTES/VARIABLE_VALUE\')])\n        model.get_layer(\'a_ffn\').set_weights(\n            [loader(\'a_ffn/ffn_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE\'),\n             loader(\'a_ffn/ffn_layer/bias/.ATTRIBUTES/VARIABLE_VALUE\')]\n        )\n\n\nclass QAEmbed(object):\n    def __init__(\n            self,\n            hidden_size=768,\n            dropout=0.2,\n            residual=True,\n            pretrained_path=None,\n            batch_size=128,\n            max_seq_length=256,\n            ffn_weight_file=None,\n            bert_ffn_weight_file=None,\n            load_pretrain=True,\n            with_question=True,\n            with_answer=True):\n        super(QAEmbed, self).__init__()\n\n        config_file = os.path.join(pretrained_path, \'bert_config.json\')\n        if load_pretrain:\n            checkpoint_file = os.path.join(\n                pretrained_path, \'biobert_model.ckpt\')\n        else:\n            checkpoint_file = None\n\n        # the ffn model takes 2nd to last layer\n        if bert_ffn_weight_file is None:\n            layer_ind = -2\n        else:\n            layer_ind = -1\n\n        self.model = MedicalQAModelwithBert(\n            hidden_size=768,\n            dropout=0.2,\n            residual=True,\n            config_file=config_file,\n            checkpoint_file=checkpoint_file,\n            layer_ind=layer_ind)\n        self.batch_size = batch_size\n        self.tokenizer = FullTokenizer(\n            os.path.join(pretrained_path, \'vocab.txt\'))\n        self.max_seq_length = max_seq_length\n\n        # build mode in order to load\n        question = \'fake\' if with_question else None\n        answer = \'fake\' if with_answer else None\n        self.predict(questions=question, answers=answer, dataset=False)\n        load_weight(self.model, bert_ffn_weight_file, ffn_weight_file)\n\n    def _type_check(self, inputs):\n        if inputs is not None:\n            if isinstance(inputs, str):\n                inputs = [inputs]\n            elif isinstance(inputs, list):\n                pass\n            else:\n                raise TypeError(\n                    \'inputs are supposed to be str of list of str, got {0} instead.\'.format(type(inputs)))\n            return inputs\n\n    def _make_inputs(self, questions=None, answers=None, dataset=True):\n\n        if questions:\n            data_size = len(questions)\n            q_feature_dict = defaultdict(list)\n            for q in questions:\n                q_feature = convert_text_to_feature(\n                    q, tokenizer=self.tokenizer, max_seq_length=self.max_seq_length)\n                q_feature_dict[\'q_input_ids\'].append(q_feature[0])\n                q_feature_dict[\'q_input_masks\'].append(q_feature[1])\n                q_feature_dict[\'q_segment_ids\'].append(q_feature[2])\n\n        if answers:\n            data_size = len(answers)\n            a_feature_dict = defaultdict(list)\n            for a in answers:\n                a_feature = convert_text_to_feature(\n                    a, tokenizer=self.tokenizer, max_seq_length=self.max_seq_length)\n                a_feature_dict[\'a_input_ids\'].append(a_feature[0])\n                a_feature_dict[\'a_input_masks\'].append(a_feature[1])\n                a_feature_dict[\'a_segment_ids\'].append(a_feature[2])\n\n        if questions and answers:\n            q_feature_dict.update(a_feature_dict)\n            model_inputs = q_feature_dict\n        elif questions:\n            model_inputs = q_feature_dict\n        elif answers:\n            model_inputs = a_feature_dict\n\n        model_inputs = {k: tf.convert_to_tensor(\n            np.stack(v, axis=0)) for k, v in model_inputs.items()}\n        if dataset:\n            model_inputs = tf.data.Dataset.from_tensor_slices(model_inputs)\n            model_inputs = model_inputs.batch(self.batch_size)\n\n        return model_inputs\n\n    def predict(self, questions=None, answers=None, dataset=True):\n\n        # type check\n        questions = self._type_check(questions)\n        answers = self._type_check(answers)\n\n        if questions is not None and answers is not None:\n            assert len(questions) == len(answers)\n\n        model_inputs = self._make_inputs(questions, answers, dataset)\n        model_outputs = []\n\n        if dataset:\n            for batch in tqdm(iter(model_inputs), total=int(len(questions) / self.batch_size)):\n                model_outputs.append(self.model(batch))\n            model_outputs = np.concatenate(model_outputs, axis=0)\n        else:\n            model_outputs = self.model(model_inputs)\n        return model_outputs\n\n\nclass FaissTopK(object):\n    def __init__(self, embedding_file):\n        super(FaissTopK, self).__init__()\n        self.embedding_file = embedding_file\n        _, ext = os.path.splitext(self.embedding_file)\n        if ext == \'.pkl\':\n            self.df = pd.read_pickle(self.embedding_file)\n        else:\n            self.df = pd.read_parquet(self.embedding_file)\n        self._get_faiss_index()\n        # self.df.drop(columns=[""Q_FFNN_embeds"", ""A_FFNN_embeds""], inplace=True)\n\n    def _get_faiss_index(self):\n        # with Pool(cpu_count()) as p:\n        #     question_bert = p.map(eval, self.df[""Q_FFNN_embeds""].tolist())\n        #     answer_bert = p.map(eval, self.df[""A_FFNN_embeds""].tolist())\n        question_bert = self.df[""Q_FFNN_embeds""].tolist()\n        self.df.drop(columns=[""Q_FFNN_embeds""], inplace=True)\n        answer_bert = self.df[""A_FFNN_embeds""].tolist()\n        self.df.drop(columns=[""A_FFNN_embeds""], inplace=True)\n        question_bert = np.array(question_bert, dtype=\'float32\')\n        answer_bert = np.array(answer_bert, dtype=\'float32\')\n\n        self.answer_index = faiss.IndexFlatIP(answer_bert.shape[-1])\n\n        self.question_index = faiss.IndexFlatIP(question_bert.shape[-1])\n\n        self.answer_index.add(answer_bert)\n        self.question_index.add(question_bert)\n\n        del answer_bert, question_bert\n\n    def predict(self, q_embedding, search_by=\'answer\', topk=5, answer_only=True):\n        if search_by == \'answer\':\n            _, index = self.answer_index.search(\n                q_embedding.astype(\'float32\'), topk)\n        else:\n            _, index = self.question_index.search(\n                q_embedding.astype(\'float32\'), topk)\n\n        output_df = self.df.iloc[index[0], :]\n        if answer_only:\n            return output_df.answer.tolist()\n        else:\n            return (output_df.question.tolist(), output_df.answer.tolist())\n\n\nclass RetreiveQADoc(object):\n    def __init__(self,\n                 pretrained_path=None,\n                 ffn_weight_file=None,\n                 bert_ffn_weight_file=\'models/bertffn_crossentropy/bertffn\',\n                 embedding_file=\'qa_embeddings/bertffn_crossentropy.zip\'\n                 ):\n        super(RetreiveQADoc, self).__init__()\n        self.qa_embed = QAEmbed(\n            pretrained_path=pretrained_path,\n            ffn_weight_file=ffn_weight_file,\n            bert_ffn_weight_file=bert_ffn_weight_file\n        )\n        self.faiss_topk = FaissTopK(embedding_file)\n\n    def predict(self, questions, search_by=\'answer\', topk=5, answer_only=True):\n        embedding = self.qa_embed.predict(questions=questions)\n        return self.faiss_topk.predict(embedding, search_by, topk, answer_only)\n\n    def getEmbedding(self, questions, search_by=\'answer\', topk=5, answer_only=True):\n        embedding = self.qa_embed.predict(questions=questions)\n        return embedding\n\n\nclass GenerateQADoc(object):\n    def __init__(self,\n                 pretrained_path=\'models/pubmed_pmc_470k/\',\n                 ffn_weight_file=None,\n                 bert_ffn_weight_file=\'models/bertffn_crossentropy/bertffn\',\n                 gpt2_weight_file=\'models/gpt2\',\n                 embedding_file=\'qa_embeddings/bertffn_crossentropy.zip\'\n                 ):\n        super(GenerateQADoc, self).__init__()\n        tf.compat.v1.disable_eager_execution()\n        session_config = tf.compat.v1.ConfigProto(\n            allow_soft_placement=True)\n        session_config.gpu_options.allow_growth = False\n        config = tf.estimator.RunConfig(\n            session_config=session_config)\n        self.batch_size = 1\n        self.gpt2_weight_file = gpt2_weight_file\n        gpt2_model_fn = gpt2_estimator.get_gpt2_model_fn(\n            accumulate_gradients=5,\n            learning_rate=0.1,\n            length=512,\n            batch_size=self.batch_size,\n            temperature=0.7,\n            top_k=0\n        )\n        hparams = gpt2_estimator.default_hparams()\n        with open(os.path.join(gpt2_weight_file, \'hparams.json\')) as f:\n            hparams.override_from_dict(json.load(f))\n        self.estimator = tf.estimator.Estimator(\n            gpt2_model_fn,\n            model_dir=gpt2_weight_file,\n            params=hparams,\n            config=config)\n        self.encoder = gpt2_estimator.encoder.get_encoder(gpt2_weight_file)\n\n        config = tf.compat.v1.ConfigProto()\n        config.gpu_options.allow_growth = True\n        self.embed_sess = tf.compat.v1.Session(config=config)\n        with self.embed_sess.as_default():\n            self.qa_embed = QAEmbed(\n                pretrained_path=pretrained_path,\n                ffn_weight_file=ffn_weight_file,\n                bert_ffn_weight_file=bert_ffn_weight_file,\n                with_answer=False,\n                load_pretrain=False\n            )\n\n        self.faiss_topk = FaissTopK(embedding_file)\n\n    def _get_gpt2_inputs(self, question, questions, answers):\n        assert len(questions) == len(answers)\n        line = \'`QUESTION: %s `ANSWER: \' % question\n        for q, a in zip(questions, answers):\n            line = \'`QUESTION: %s `ANSWER: %s \' % (q, a) + line\n        return line\n\n    def predict(self, questions, search_by=\'answer\', topk=5, answer_only=False):\n        embedding = self.qa_embed.predict(\n            questions=questions, dataset=False).eval(session=self.embed_sess)\n        if answer_only:\n            topk_answer = self.faiss_topk.predict(\n                embedding, search_by, topk, answer_only)\n        else:\n            topk_question, topk_answer = self.faiss_topk.predict(\n                embedding, search_by, topk, answer_only)\n\n        gpt2_input = self._get_gpt2_inputs(\n            questions[0], topk_question, topk_answer)\n        gpt2_pred = self.estimator.predict(\n            lambda: gpt2_estimator.predict_input_fn(inputs=gpt2_input, batch_size=self.batch_size, checkpoint_path=self.gpt2_weight_file))\n        raw_output = gpt2_estimator.predictions_parsing(\n            gpt2_pred, self.encoder)\n        # result_list = [re.search(\'`ANSWER:(.*)`QUESTION:\', s)\n        #                for s in raw_output]\n        # result_list = [s for s in result_list if s]\n        # try:\n        #     r = result_list[0].group(1)\n        # except (AttributeError, IndexError):\n        #     r = topk_answer[0]\n        refine1 = re.sub(\'`QUESTION:.*?`ANSWER:\',\'\' , str(raw_output[0]) , flags=re.DOTALL)\n        refine2 = refine1.split(\'`QUESTION: \')[0]\n        return refine2\n\n\nif __name__ == ""__main__"":\n    gen = GenerateQADoc()\n    print(gen.predict(\'my eyes hurt\'))\n'"
docproduct/tokenization.py,1,"b'# coding=utf-8\n# Copyright 2018 The Google AI Language Team Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tokenization classes.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport re\nimport unicodedata\nimport six\nimport tensorflow as tf\n\n\ndef validate_case_matches_checkpoint(do_lower_case, init_checkpoint):\n    """"""Checks whether the casing config is consistent with the checkpoint name.""""""\n\n    # The casing has to be passed in by the user and there is no explicit check\n    # as to whether it matches the checkpoint. The casing information probably\n    # should have been stored in the bert_config.json file, but it\'s not, so\n    # we have to heuristically detect it to validate.\n\n    if not init_checkpoint:\n        return\n\n    m = re.match(""^.*?([A-Za-z0-9_-]+)/bert_model.ckpt"", init_checkpoint)\n    if m is None:\n        return\n\n    model_name = m.group(1)\n\n    lower_models = [\n        ""uncased_L-24_H-1024_A-16"", ""uncased_L-12_H-768_A-12"",\n        ""multilingual_L-12_H-768_A-12"", ""chinese_L-12_H-768_A-12""\n    ]\n\n    cased_models = [\n        ""cased_L-12_H-768_A-12"", ""cased_L-24_H-1024_A-16"",\n        ""multi_cased_L-12_H-768_A-12""\n    ]\n\n    is_bad_config = False\n    if model_name in lower_models and not do_lower_case:\n        is_bad_config = True\n        actual_flag = ""False""\n        case_name = ""lowercased""\n        opposite_flag = ""True""\n\n    if model_name in cased_models and do_lower_case:\n        is_bad_config = True\n        actual_flag = ""True""\n        case_name = ""cased""\n        opposite_flag = ""False""\n\n    if is_bad_config:\n        raise ValueError(\n            ""You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. ""\n            ""However, `%s` seems to be a %s model, so you ""\n            ""should pass in `--do_lower_case=%s` so that the fine-tuning matches ""\n            ""how the model was pre-training. If this error is wrong, please ""\n            ""just comment out this check."" % (actual_flag, init_checkpoint,\n                                              model_name, case_name, opposite_flag))\n\n\ndef convert_to_unicode(text):\n    """"""Converts `text` to Unicode (if it\'s not already), assuming utf-8 input.""""""\n    if six.PY3:\n        if isinstance(text, str):\n            return text\n        elif isinstance(text, bytes):\n            return text.decode(""utf-8"", ""ignore"")\n        else:\n            raise ValueError(""Unsupported string type: %s"" % (type(text)))\n    elif six.PY2:\n        if isinstance(text, str):\n            return text.decode(""utf-8"", ""ignore"")\n        elif isinstance(text, unicode):\n            return text\n        else:\n            raise ValueError(""Unsupported string type: %s"" % (type(text)))\n    else:\n        raise ValueError(""Not running on Python2 or Python 3?"")\n\n\ndef printable_text(text):\n    """"""Returns text encoded in a way suitable for print or `tf.logging`.""""""\n\n    # These functions want `str` for both Python2 and Python3, but in one case\n    # it\'s a Unicode string and in the other it\'s a byte string.\n    if six.PY3:\n        if isinstance(text, str):\n            return text\n        elif isinstance(text, bytes):\n            return text.decode(""utf-8"", ""ignore"")\n        else:\n            raise ValueError(""Unsupported string type: %s"" % (type(text)))\n    elif six.PY2:\n        if isinstance(text, str):\n            return text\n        elif isinstance(text, unicode):\n            return text.encode(""utf-8"")\n        else:\n            raise ValueError(""Unsupported string type: %s"" % (type(text)))\n    else:\n        raise ValueError(""Not running on Python2 or Python 3?"")\n\n\ndef load_vocab(vocab_file):\n    """"""Loads a vocabulary file into a dictionary.""""""\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, ""r"", encoding=\'utf-8\') as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n\ndef convert_by_vocab(vocab, items):\n    """"""Converts a sequence of [tokens|ids] using the vocab.""""""\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n\ndef convert_tokens_to_ids(vocab, tokens):\n    return convert_by_vocab(vocab, tokens)\n\n\ndef convert_ids_to_tokens(inv_vocab, ids):\n    return convert_by_vocab(inv_vocab, ids)\n\n\ndef whitespace_tokenize(text):\n    """"""Runs basic whitespace cleaning and splitting on a piece of text.""""""\n    text = text.strip()\n    if not text:\n        return []\n    tokens = text.split()\n    return tokens\n\n\nclass FullTokenizer(object):\n    """"""Runs end-to-end tokenziation.""""""\n\n    def __init__(self, vocab_file, do_lower_case=True):\n        self.vocab = load_vocab(vocab_file)\n        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n\n    def tokenize(self, text):\n        split_tokens = []\n        for token in self.basic_tokenizer.tokenize(text):\n            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n                split_tokens.append(sub_token)\n\n        return split_tokens\n\n    def convert_tokens_to_ids(self, tokens):\n        return convert_by_vocab(self.vocab, tokens)\n\n    def convert_ids_to_tokens(self, ids):\n        return convert_by_vocab(self.inv_vocab, ids)\n\n\nclass BasicTokenizer(object):\n    """"""Runs basic tokenization (punctuation splitting, lower casing, etc.).""""""\n\n    def __init__(self, do_lower_case=True):\n        """"""Constructs a BasicTokenizer.\n        Args:\n          do_lower_case: Whether to lower case the input.\n        """"""\n        self.do_lower_case = do_lower_case\n\n    def tokenize(self, text):\n        """"""Tokenizes a piece of text.""""""\n        text = convert_to_unicode(text)\n        text = self._clean_text(text)\n\n        # This was added on November 1st, 2018 for the multilingual and Chinese\n        # models. This is also applied to the English models now, but it doesn\'t\n        # matter since the English models were not trained on any Chinese data\n        # and generally don\'t have any Chinese data in them (there are Chinese\n        # characters in the vocabulary because Wikipedia does have some Chinese\n        # words in the English Wikipedia.).\n        text = self._tokenize_chinese_chars(text)\n\n        orig_tokens = whitespace_tokenize(text)\n        split_tokens = []\n        for token in orig_tokens:\n            if self.do_lower_case:\n                token = token.lower()\n                token = self._run_strip_accents(token)\n            split_tokens.extend(self._run_split_on_punc(token))\n\n        output_tokens = whitespace_tokenize("" "".join(split_tokens))\n        return output_tokens\n\n    def _run_strip_accents(self, text):\n        """"""Strips accents from a piece of text.""""""\n        text = unicodedata.normalize(""NFD"", text)\n        output = []\n        for char in text:\n            cat = unicodedata.category(char)\n            if cat == ""Mn"":\n                continue\n            output.append(char)\n        return """".join(output)\n\n    def _run_split_on_punc(self, text):\n        """"""Splits punctuation on a piece of text.""""""\n        chars = list(text)\n        i = 0\n        start_new_word = True\n        output = []\n        while i < len(chars):\n            char = chars[i]\n            if _is_punctuation(char):\n                output.append([char])\n                start_new_word = True\n            else:\n                if start_new_word:\n                    output.append([])\n                start_new_word = False\n                output[-1].append(char)\n            i += 1\n\n        return ["""".join(x) for x in output]\n\n    def _tokenize_chinese_chars(self, text):\n        """"""Adds whitespace around any CJK character.""""""\n        output = []\n        for char in text:\n            cp = ord(char)\n            if self._is_chinese_char(cp):\n                output.append("" "")\n                output.append(char)\n                output.append("" "")\n            else:\n                output.append(char)\n        return """".join(output)\n\n    def _is_chinese_char(self, cp):\n        """"""Checks whether CP is the codepoint of a CJK character.""""""\n        # This defines a ""chinese character"" as anything in the CJK Unicode block:\n        #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n        #\n        # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n        # despite its name. The modern Korean Hangul alphabet is a different block,\n        # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n        # space-separated words, so they are not treated specially and handled\n        # like the all of the other languages.\n        if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n            (cp >= 0x3400 and cp <= 0x4DBF) or  #\n            (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n            (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n            (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n            (cp >= 0x2B820 and cp <= 0x2CEAF) or\n            (cp >= 0xF900 and cp <= 0xFAFF) or  #\n                (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n            return True\n\n        return False\n\n    def _clean_text(self, text):\n        """"""Performs invalid character removal and whitespace cleanup on text.""""""\n        output = []\n        for char in text:\n            cp = ord(char)\n            if cp == 0 or cp == 0xfffd or _is_control(char):\n                continue\n            if _is_whitespace(char):\n                output.append("" "")\n            else:\n                output.append(char)\n        return """".join(output)\n\n\nclass WordpieceTokenizer(object):\n    """"""Runs WordPiece tokenziation.""""""\n\n    def __init__(self, vocab, unk_token=""[UNK]"", max_input_chars_per_word=200):\n        self.vocab = vocab\n        self.unk_token = unk_token\n        self.max_input_chars_per_word = max_input_chars_per_word\n\n    def tokenize(self, text):\n        """"""Tokenizes a piece of text into its word pieces.\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n        For example:\n          input = ""unaffable""\n          output = [""un"", ""##aff"", ""##able""]\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer.\n        Returns:\n          A list of wordpiece tokens.\n        """"""\n\n        text = convert_to_unicode(text)\n\n        output_tokens = []\n        for token in whitespace_tokenize(text):\n            chars = list(token)\n            if len(chars) > self.max_input_chars_per_word:\n                output_tokens.append(self.unk_token)\n                continue\n\n            is_bad = False\n            start = 0\n            sub_tokens = []\n            while start < len(chars):\n                end = len(chars)\n                cur_substr = None\n                while start < end:\n                    substr = """".join(chars[start:end])\n                    if start > 0:\n                        substr = ""##"" + substr\n                    if substr in self.vocab:\n                        cur_substr = substr\n                        break\n                    end -= 1\n                if cur_substr is None:\n                    is_bad = True\n                    break\n                sub_tokens.append(cur_substr)\n                start = end\n\n            if is_bad:\n                output_tokens.append(self.unk_token)\n            else:\n                output_tokens.extend(sub_tokens)\n        return output_tokens\n\n\ndef _is_whitespace(char):\n    """"""Checks whether `chars` is a whitespace character.""""""\n    # \\t, \\n, and \\r are technically contorl characters but we treat them\n    # as whitespace since they are generally considered as such.\n    if char == "" "" or char == ""\\t"" or char == ""\\n"" or char == ""\\r"":\n        return True\n    cat = unicodedata.category(char)\n    if cat == ""Zs"":\n        return True\n    return False\n\n\ndef _is_control(char):\n    """"""Checks whether `chars` is a control character.""""""\n    # These are technically control characters but we count them as whitespace\n    # characters.\n    if char == ""\\t"" or char == ""\\n"" or char == ""\\r"":\n        return False\n    cat = unicodedata.category(char)\n    if cat in (""Cc"", ""Cf""):\n        return True\n    return False\n\n\ndef _is_punctuation(char):\n    """"""Checks whether `chars` is a punctuation character.""""""\n    cp = ord(char)\n    # We treat all non-letter/number ASCII as punctuation.\n    # Characters such as ""^"", ""$"", and ""`"" are not in the Unicode\n    # Punctuation class but we treat them as punctuation anyways, for\n    # consistency.\n    if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n            (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n        return True\n    cat = unicodedata.category(char)\n    if cat.startswith(""P""):\n        return True\n    return False\n'"
docproduct/train_bertffn.py,3,"b'import argparse\nimport os\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nfrom docproduct.dataset import create_dataset_for_bert\nfrom docproduct.models import MedicalQAModelwithBert\nfrom docproduct.loss import qa_pair_loss, qa_pair_cross_entropy_loss\nfrom docproduct.tokenization import FullTokenizer\nfrom docproduct.metrics import qa_pair_batch_accuracy\n\n\ndef train_bertffn(model_path=\'models/bertffn_crossentropy/bertffn\',\n                  data_path=\'data/mqa_csv\',\n                  num_epochs=20,\n                  num_gpu=1,\n                  batch_size=64,\n                  learning_rate=2e-5,\n                  validation_split=0.2,\n                  loss=\'categorical_crossentropy\',\n                  pretrained_path=\'models/pubmed_pmc_470k/\',\n                  max_seq_len=256):\n    """"""A function to train BertFFNN similarity embedding model.\n\n    Input file format:\n        question,answer\n        my eyes hurts, go see a doctor\n\n    For more information about training details:\n    https://github.com/Santosh-Gupta/DocProduct/blob/master/README.md\n\n    Keyword Arguments:\n        model_path {str} -- Path to save embedding model weights, ends with prefix of model files (default: {\'models/bertffn_crossentropy/bertffn\'})\n        data_path {str} -- CSV data path (default: {\'data/mqa_csv\'})\n        num_epochs {int} -- Number of Epochs to train (default: {20})\n        num_gpu {int} -- Number of GPU to use(Currently only support single GPU) (default: {1})\n        batch_size {int} -- Batch size (default: {64})\n        learning_rate {float} -- learning rate (default: {2e-5})\n        validation_split {float} -- validation split (default: {0.2})\n        loss {str} -- Loss type, either MSE or crossentropy (default: {\'categorical_crossentropy\'})\n        pretrained_path {str} -- Pretrained bioBert model path (default: {\'models/pubmed_pmc_470k/\'})\n        max_seq_len {int} -- Max sequence length of model(No effects if dynamic padding is enabled) (default: {256})\n    """"""\n    tf.compat.v1.disable_eager_execution()\n    if loss == \'categorical_crossentropy\':\n        loss_fn = qa_pair_cross_entropy_loss\n    else:\n        loss_fn = qa_pair_loss\n    K.set_floatx(\'float32\')\n    tokenizer = FullTokenizer(os.path.join(pretrained_path, \'vocab.txt\'))\n    d = create_dataset_for_bert(\n        data_path, tokenizer=tokenizer, batch_size=batch_size,\n        shuffle_buffer=500000, dynamic_padding=True, max_seq_length=max_seq_len)\n    eval_d = create_dataset_for_bert(\n        data_path, tokenizer=tokenizer, batch_size=batch_size,\n        mode=\'eval\', dynamic_padding=True, max_seq_length=max_seq_len,\n        bucket_batch_sizes=[64, 64, 64])\n\n    medical_qa_model = MedicalQAModelwithBert(\n        config_file=os.path.join(\n            pretrained_path, \'bert_config.json\'),\n        checkpoint_file=os.path.join(pretrained_path, \'biobert_model.ckpt\'))\n    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n    medical_qa_model.compile(\n        optimizer=optimizer, loss=loss_fn, metrics=[qa_pair_batch_accuracy])\n\n    epochs = num_epochs\n\n    callback = tf.keras.callbacks.ModelCheckpoint(\n        model_path, verbose=1, save_weights_only=True, save_best_only=False, period=1)\n\n    medical_qa_model.fit(d, epochs=epochs, callbacks=[callback])\n    medical_qa_model.summary()\n    medical_qa_model.save_weights(model_path)\n    medical_qa_model.evaluate(eval_d)\n\n\nif __name__ == ""__main__"":\n\n    train_bertffn()\n'"
docproduct/train_bertffn_estimator.py,7,"b'import argparse\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nfrom docproduct.dataset import create_dataset_for_bert\nfrom docproduct.models import MedicalQAModelwithBert\nfrom docproduct.loss import qa_pair_loss, qa_pair_cross_entropy_loss\nfrom docproduct.tokenization import FullTokenizer\nfrom docproduct.metrics import qa_pair_batch_accuracy\n\nDEVICE = [""/gpu:0"", ""/gpu:1""]\n\n\ndef train_bertffn(model_path=\'models/bertffn_crossentropy/bertffn\',\n                  data_path=\'data/mqa_csv\',\n                  num_epochs=20,\n                  num_gpu=1,\n                  batch_size=64,\n                  learning_rate=2e-5,\n                  validation_split=0.2,\n                  loss=\'categorical_crossentropy\',\n                  pretrained_path=\'pubmed_pmc_470k/\',\n                  max_seq_len=256):\n    tf.compat.v1.disable_eager_execution()\n    if loss == \'categorical_crossentropy\':\n        loss_fn = qa_pair_cross_entropy_loss\n    else:\n        loss_fn = qa_pair_loss\n\n    K.set_floatx(\'float32\')\n    tokenizer = FullTokenizer(os.path.join(pretrained_path, \'vocab.txt\'))\n    d = create_dataset_for_bert(\n        data_path, tokenizer=tokenizer, batch_size=batch_size,\n        shuffle_buffer=500000, dynamic_padding=False, max_seq_length=max_seq_len)\n    eval_d = create_dataset_for_bert(\n        data_path, tokenizer=tokenizer, batch_size=batch_size,\n        mode=\'eval\', dynamic_padding=False, max_seq_length=max_seq_len,\n        bucket_batch_sizes=[64, 64, 64])\n\n    mirrored_strategy = tf.distribute.MirroredStrategy(\n        devices=DEVICE[:num_gpu])\n    global_batch_size = batch_size*num_gpu\n    learning_rate = learning_rate*1.5**num_gpu\n\n    # with mirrored_strategy.scope():\n    # d = create_dataset_for_bert(\n    #     data_path, batch_size=global_batch_size, shuffle_buffer=100000)\n\n    # d_iter = mirrored_strategy.make_dataset_iterator(d)\n    input_layer = {\n        \'q_input_ids\': keras.Input(shape=(None, ), name=\'q_input_ids\'),\n        \'q_input_masks\': keras.Input(shape=(None, ), name=\'q_input_masks\'),\n        \'q_segment_ids\': keras.Input(shape=(None, ), name=\'q_segment_ids\'),\n        \'a_input_ids\': keras.Input(shape=(None, ), name=\'a_input_ids\'),\n        \'a_input_masks\': keras.Input(shape=(None, ), name=\'a_input_masks\'),\n        \'a_segment_ids\': keras.Input(shape=(None, ), name=\'a_segment_ids\'),\n    }\n\n    base_model = MedicalQAModelwithBert(config_file=os.path.join(\n        pretrained_path, \'bert_config.json\'),\n        checkpoint_file=os.path.join(pretrained_path, \'biobert_model.ckpt\'))\n    outputs = base_model(input_layer)\n\n    medical_qa_model = keras.Model(inputs=input_layer, outputs=outputs)\n    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n    # optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n    medical_qa_model.compile(\n        optimizer=optimizer, loss=loss)\n\n    config = tf.estimator.RunConfig(\n        train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)\n\n    estimator = tf.keras.estimator.model_to_estimator(\n        medical_qa_model, model_dir=model_path)\n\n    def train_input_fn():\n        return create_dataset_for_bert(\n            data_path, tokenizer=tokenizer, batch_size=batch_size,\n            shuffle_buffer=500000, dynamic_padding=False, max_seq_length=max_seq_len)\n    estimator.train(train_input_fn, steps=100)\n\n    epochs = num_epochs\n    loss_metric = tf.keras.metrics.Mean()\n\n    medical_qa_model.fit(d, epochs=epochs)\n    medical_qa_model.summary()\n    medical_qa_model.save_weights(model_path)\n    medical_qa_model.evaluate(eval_d)\n\n\nif __name__ == ""__main__"":\n\n    train_bertffn()\n'"
docproduct/train_data_to_embedding.py,0,"b'import argparse\nimport os\nfrom glob import glob\n\nimport pandas as pd\nimport numpy as np\n\nfrom docproduct.predictor import QAEmbed\n\n\ndef read_all(data_path):\n    glob_pattern = os.path.join(data_path, \'*.csv\')\n    df_list = []\n    for f in glob(glob_pattern):\n        print(\'Reading {0}\'.format(f))\n        if os.path.basename(f) == \'healthtap_data_cleaned.csv\':\n            df = pd.read_csv(f, lineterminator=\'\\n\')\n            df.columns = [\'index\', \'question\', \'answer\']\n            df.drop(columns=[\'index\'], inplace=True)\n        else:\n            df = pd.read_csv(f, encoding=\'utf8\', lineterminator=\'\\n\')\n        try:\n            df.drop(columns=[\'question_bert\', \'answer_bert\'], inplace=True)\n        except:\n            pass\n        df_list.append(df)\n    return pd.concat(df_list, axis=0)\n\n\ndef train_data_to_embedding(model_path=\'models/bertffn_crossentropy/bertffn\',\n                            data_path=\'data/mqa_csv\',\n                            output_path=\'qa_embeddings/bertffn_crossentropy.zip\',\n                            pretrained_path=\'models/pubmed_pmc_470k/\'):\n    """"""Function to generate similarity embeddings for QA pairs.\n\n    Input file format:\n        question,answer\n        my eyes hurts, go see a doctor\n\n    Keyword Arguments:\n        model_path {str} -- Similarity embedding model path (default: {\'models/bertffn_crossentropy/bertffn\'})\n        data_path {str} -- CSV data path (default: {\'data/mqa_csv\'})\n        output_path {str} -- Embedding output path (default: {\'qa_embeddings/bertffn_crossentropy.zip\'})\n        pretrained_path {str} -- Pretrained BioBert model path (default: {\'models/pubmed_pmc_470k/\'})\n    """"""\n    if os.path.basename(model_path) == \'ffn\':\n        ffn_weight_file = model_path\n    else:\n        ffn_weight_file = None\n\n    if os.path.basename(model_path) == \'bertffn\':\n        bert_ffn_weight_file = model_path\n    else:\n        bert_ffn_weight_file = None\n    embeder = QAEmbed(\n        pretrained_path=pretrained_path,\n        ffn_weight_file=ffn_weight_file,\n        bert_ffn_weight_file=bert_ffn_weight_file\n    )\n    qa_df = read_all(data_path)\n    qa_df.dropna(inplace=True)\n    qa_vectors = embeder.predict(\n        questions=qa_df.question.tolist(),\n        answers=qa_df.answer.tolist())\n\n    q_embedding, a_embedding = np.split(qa_vectors, 2, axis=1)\n    qa_df[\'Q_FFNN_embeds\'] = np.squeeze(q_embedding).tolist()\n    qa_df[\'A_FFNN_embeds\'] = np.squeeze(a_embedding).tolist()\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    qa_df.to_parquet(output_path, index=False)\n\n\nif __name__ == ""__main__"":\n\n    train_data_to_embedding()\n'"
docproduct/train_embedding_to_gpt2_data.py,0,"b'import pandas as pd\nimport numpy as np\nimport os\nimport csv\nfrom tqdm import tqdm\nimport argparse\nfrom glob import glob\nimport faiss\nfrom multiprocessing import Pool, cpu_count\nfrom math import ceil\nfrom collections import defaultdict\n\n\ndef train_embedding_to_gpt2_data(\n    data_path=\'qa_embeddings/bertffn_crossentropy.zip\',\n    output_path=\'gpt2_train_data/bertffn_crossentropy_gpt2_train_data.zip\',\n    number_samples=10,\n    batch_size=512,\n    search_by=\'answer\'\n):\n    """"""Function to create gpt2 training data\n\n    For each question, we take number_samples similar question/answer pair as prefix of GPT2 model.\n    For more details:\n    https://github.com/Santosh-Gupta/DocProduct/blob/master/README.md\n\n    Keyword Arguments:\n        data_path {str} -- Embedding data path, usually the output file of train_data_to_embedding (default: {\'qa_embeddings/bertffn_crossentropy.zip\'})\n        output_path {str} -- GPT2 training data output path (default: {\'gpt2_train_data/bertffn_crossentropy_gpt2_train_data.zip\'})\n        number_samples {int} -- Number of sample per question (default: {10})\n        batch_size {int} -- Retreive batch size of FAISS (default: {512})\n\n    """"""\n    _, ext = os.path.splitext(data_path)\n    if ext == \'.pkl\':\n        qa = pd.read_pickle(data_path)\n    else:\n        qa = pd.read_parquet(data_path)\n    # qa = pd.read_parquet(data_path)\n    question_bert = qa[""Q_FFNN_embeds""].tolist()\n    answer_bert = qa[""A_FFNN_embeds""].tolist()\n    question_bert = np.array(question_bert)\n    answer_bert = np.array(answer_bert)\n\n    question_bert = question_bert.astype(\'float32\')\n    answer_bert = answer_bert.astype(\'float32\')\n\n    answer_index = faiss.IndexFlatIP(answer_bert.shape[-1])\n\n    question_index = faiss.IndexFlatIP(question_bert.shape[-1])\n\n    faiss.normalize_L2(question_bert)\n    faiss.normalize_L2(answer_bert)\n\n    answer_index.add(answer_bert)\n    question_index.add(question_bert)\n\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n\n    df_dict = defaultdict(list)\n\n    def topKforGPT2(start_ind, end_ind, topk, search_by):\n        if search_by == \'answer\':\n            _, I1 = answer_index.search(\n                question_bert[start_ind:end_ind].astype(\'float32\'), topk)\n            return I1\n        else:\n            _, I2 = question_index.search(\n                question_bert[start_ind:end_ind].astype(\'float32\'), topk)\n            return I2\n\n    steps = ceil(qa.shape[0] / batch_size)\n\n    # for k in tqdm(range(1000), mininterval=30, maxinterval=60):\n    for k in tqdm(range(0, qa.shape[0], batch_size), total=steps):\n        start_ind = k\n        end_ind = k+batch_size\n\n        a_batch_index = topKforGPT2(\n            start_ind, end_ind, int(number_samples), search_by=search_by)\n        for i, a_index in enumerate(a_batch_index):\n\n            df_dict[\'question\'].append(qa[""question""].iloc[k+i])\n            df_dict[\'answer\'].append(qa[""answer""].iloc[k+i])\n\n            for ii in range(number_samples):\n                df_dict[\'question{0}\'.format(ii)].append(\n                    qa.question.iloc[a_index[ii]])\n                df_dict[\'answer{0}\'.format(ii)].append(\n                    qa.answer.iloc[a_index[ii]])\n\n    df = pd.DataFrame(df_dict)\n    df.to_parquet(\n        output_path, index=False)\n\n\nif __name__ == ""__main__"":\n\n    train_embedding_to_gpt2_data()\n'"
docproduct/train_ffn.py,13,"b'import argparse\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nfrom docproduct.dataset import create_dataset_for_ffn\nfrom docproduct.models import MedicalQAModel\nfrom docproduct.loss import qa_pair_loss, qa_pair_cross_entropy_loss\nfrom docproduct.metrics import qa_pair_batch_accuracy\n\nDEVICE = [""/gpu:0"", ""/gpu:1""]\n\n\ndef multi_gpu_train(batch_size, num_gpu, data_path, num_epochs, model_path, loss=qa_pair_loss):\n    mirrored_strategy = tf.distribute.MirroredStrategy(\n        devices=DEVICE[:num_gpu])\n    global_batch_size = batch_size*num_gpu\n    learning_rate = learning_rate*1.5**num_gpu\n    with mirrored_strategy.scope():\n        d = create_dataset_for_ffn(\n            data_path, batch_size=global_batch_size, shuffle_buffer=100000)\n\n        d_iter = mirrored_strategy.make_dataset_iterator(d)\n\n        medical_qa_model = tf.keras.Sequential()\n        medical_qa_model.add(tf.keras.layers.Input((2, 768)))\n        medical_qa_model.add(MedicalQAModel())\n        optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n        medical_qa_model.compile(\n            optimizer=optimizer, loss=loss)\n\n    epochs = num_epochs\n    loss_metric = tf.keras.metrics.Mean()\n\n    medical_qa_model.fit(d_iter, epochs=epochs, metrics=[\n                         qa_pair_batch_accuracy])\n    medical_qa_model.save_weights(model_path)\n    return medical_qa_model\n\n\ndef single_gpu_train(batch_size, num_gpu, data_path, num_epochs, model_path, loss=qa_pair_loss):\n    global_batch_size = batch_size*num_gpu\n    learning_rate = learning_rate\n    d = create_dataset_for_ffn(\n        data_path, batch_size=global_batch_size, shuffle_buffer=500000)\n    eval_d = create_dataset_for_ffn(\n        data_path, batch_size=batch_size, mode=\'eval\')\n\n    medical_qa_model = MedicalQAModel()\n    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n    medical_qa_model.compile(\n        optimizer=optimizer, loss=loss, metrics=[\n            qa_pair_batch_accuracy])\n\n    epochs = num_epochs\n\n    medical_qa_model.fit(d, epochs=epochs, validation_data=eval_d)\n    medical_qa_model.save_weights(model_path)\n    return medical_qa_model\n\n\ndef train_ffn(model_path=\'models/ffn_crossentropy/ffn\',\n              data_path=\'data/mqa_csv\',\n              num_epochs=300,\n              num_gpu=1,\n              batch_size=64,\n              learning_rate=0.0001,\n              validation_split=0.2,\n              loss=\'categorical_crossentropy\'):\n\n    if loss == \'categorical_crossentropy\':\n        loss_fn = qa_pair_cross_entropy_loss\n    else:\n        loss_fn = qa_pair_loss\n    eval_d = create_dataset_for_ffn(\n        data_path, batch_size=batch_size, mode=\'eval\')\n\n    if num_gpu > 1:\n        medical_qa_model = multi_gpu_train(\n            batch_size, num_gpu, data_path, num_epochs, model_path, loss_fn)\n    else:\n        medical_qa_model = single_gpu_train(\n            batch_size, num_gpu, data_path, num_epochs, model_path, loss_fn)\n\n    medical_qa_model.summary()\n    medical_qa_model.save_weights(model_path, overwrite=True)\n    # K.set_learning_phase(0)\n    # q_embedding, a_embedding = tf.unstack(\n    #     medical_qa_model(next(iter(eval_d))[0]), axis=1)\n\n    # q_embedding = q_embedding / tf.norm(q_embedding, axis=-1, keepdims=True)\n    # a_embedding = a_embedding / tf.norm(a_embedding, axis=-1, keepdims=True)\n\n    # batch_score = tf.reduce_sum(q_embedding*a_embedding, axis=-1)\n    # baseline_score = tf.reduce_mean(\n    #     tf.matmul(q_embedding, tf.transpose(a_embedding)))\n\n    # print(\'Eval Batch Cos similarity\')\n    # print(tf.reduce_mean(batch_score))\n    # print(\'Baseline: {0}\'.format(baseline_score))\n\n    # medical_qa_model.save_weights(model_path, overwrite=True)\n\n\nif __name__ == ""__main__"":\n\n    train_ffn()\n'"
docproduct/train_gpt2.py,4,"b'import os\nimport json\nfrom shutil import copyfile\n\nimport tensorflow as tf\n# import tensorflow.compat.v1 as tf\nimport tensorflow_estimator as tf_estimator\n\nimport gpt2_estimator\n\nfrom docproduct.mqa_load_dataset import Sampler, load_dataset\n\nDEVICE = [""/gpu:0"", ""/gpu:1"", ""/gpu:2"", ""/gpu:3""]\n\n\ndef train_gpt2(\n        model_dir=\'models/gpt2\',\n        pretrained_path=\'models/117M\',\n        steps=100000,\n        batch_size=1,\n        max_seq_len=1024,\n        num_gpu=3,\n        learning_rate=0.0001):\n    """"""Function to train the GPT2 model\n\n    For each question, we use topk qa pairs that retreived by FAISS and the question\n    as features, and correct answer as target to train GPT2. \n\n    Data: my eyes hurt, go see a doctor\n    Feature:\n        question: aaa, answer: bbb, question: ccc, answer: ddd, question: my eyes hurt, answer:\n    Target: \n        go see a doctor\n\n\n    Keyword Arguments:\n        model_dir {str} -- Path to save the GPT2 model (default: {\'models/gpt2\'})\n        pretrained_path {str} -- Pretrained GPT2 model path, \n            usually the output file of train_embedding_to_gpt2_data (default: {\'models/117M\'})\n        steps {int} -- Number of steps of training (default: {100000})\n        batch_size {int} -- Batch size per GPU (default: {4})\n        num_gpu {int} -- Number of GPU to use (default: {4})\n        learning_rate {float} -- Learning rate (default: {0.0001})\n    """"""\n    os.makedirs(model_dir, exist_ok=True)\n\n    tf.compat.v1.disable_eager_execution()\n    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.DEBUG)\n    mirrored_strategy = tf.distribute.MirroredStrategy(\n        devices=DEVICE[:num_gpu])\n    learning_rate = learning_rate*num_gpu\n    session_config = tf.compat.v1.ConfigProto(\n        allow_soft_placement=True)\n    session_config.gpu_options.allow_growth = False\n    config = tf_estimator.estimator.RunConfig(\n        session_config=session_config,\n        train_distribute=mirrored_strategy,\n        eval_distribute=mirrored_strategy,\n        log_step_count_steps=50)\n\n    gpt2_model_fn = gpt2_estimator.get_gpt2_model_fn(\n        accumulate_gradients=3,\n        learning_rate=learning_rate,\n        length=max_seq_len,\n        batch_size=batch_size,\n        temperature=0.7,\n        top_k=1\n    )\n    copyfile(os.path.join(pretrained_path, \'hparams.json\'),\n             os.path.join(model_dir, \'hparams.json\'))\n    copyfile(os.path.join(pretrained_path, \'vocab.bpe\'),\n             os.path.join(model_dir, \'vocab.bpe\'))\n    copyfile(os.path.join(pretrained_path, \'encoder.json\'),\n             os.path.join(model_dir, \'encoder.json\'))\n    hparams = gpt2_estimator.default_hparams()\n    with open(os.path.join(pretrained_path, \'hparams.json\')) as f:\n        hparams.override_from_dict(json.load(f))\n    estimator = tf_estimator.estimator.Estimator(\n        gpt2_model_fn,\n        model_dir=model_dir,\n        params=hparams,\n        config=config)\n\n    restore_hook = gpt2_estimator.RestoreCheckpointHook(pretrained_path)\n    estimator.train(\n        lambda: gpt2_estimator.train_input_fn(batch_size=batch_size, dataset_load_fn=load_dataset, sampler=Sampler, max_seq_len=max_seq_len), max_steps=steps, hooks=[restore_hook])\n\n    # keep as an example\n    # pred = estimator.predict(\n    #     lambda: gpt2_estimator.predict_input_fn(\n    #         \'i am sick\', batch_size=batch_size)\n    # )\n\n\nif __name__ == ""__main__"":\n    train_gpt2(steps=5000000)\n'"
keras_bert/__init__.py,0,b'from .bert import *\nfrom .loader import *\nfrom .tokenizer import Tokenizer\n'
keras_bert/bert.py,1,"b'import math\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nimport numpy as np\nfrom .keras_pos_embd import PositionEmbedding\nfrom .keras_layer_normalization import LayerNormalization\nfrom .keras_transformer import get_encoders\nfrom .keras_transformer import get_custom_objects as get_encoder_custom_objects\nfrom .layers import (get_inputs, get_embedding,\n                     TokenEmbedding, EmbeddingSimilarity, Masked, Extract)\nfrom .keras_multi_head import MultiHeadAttention\nfrom .keras_position_wise_feed_forward import FeedForward\n\n\n__all__ = [\n    \'TOKEN_PAD\', \'TOKEN_UNK\', \'TOKEN_CLS\', \'TOKEN_SEP\', \'TOKEN_MASK\',\n    \'gelu\', \'get_model\', \'get_custom_objects\', \'get_base_dict\', \'gen_batch_inputs\',\n]\n\n\nTOKEN_PAD = \'\'  # Token for padding\nTOKEN_UNK = \'[UNK]\'  # Token for unknown words\nTOKEN_CLS = \'[CLS]\'  # Token for classification\nTOKEN_SEP = \'[SEP]\'  # Token for separation\nTOKEN_MASK = \'[MASK]\'  # Token for masking\n\n\ndef gelu(x):\n    if K.backend() == \'tensorflow\':\n        return 0.5 * x * (1.0 + tf.math.erf(x / tf.sqrt(2.0)))\n    return 0.5 * x * (1.0 + K.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * K.pow(x, 3))))\n\n\nclass Bert(keras.Model):\n    def __init__(\n            self,\n            token_num,\n            pos_num=512,\n            seq_len=512,\n            embed_dim=768,\n            transformer_num=12,\n            head_num=12,\n            feed_forward_dim=3072,\n            dropout_rate=0.1,\n            attention_activation=None,\n            feed_forward_activation=gelu,\n            custom_layers=None,\n            training=True,\n            trainable=None,\n            lr=1e-4,\n            name=\'Bert\'):\n        super().__init__(name=name)\n        self.token_num = token_num\n        self.pos_num = pos_num\n        self.seq_len = seq_len\n        self.embed_dim = embed_dim\n        self.transformer_num = transformer_num\n        self.head_num = head_num\n        self.feed_forward_dim = feed_forward_dim\n        self.dropout_rate = dropout_rate\n        self.attention_activation = attention_activation\n        self.feed_forward_activation = feed_forward_activation\n        self.custom_layers = custom_layers\n        self.training = training\n        self.trainable = trainable\n        self.lr = lr\n\n        # build layers\n        # embedding\n        self.token_embedding_layer = TokenEmbedding(\n            input_dim=token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            trainable=trainable,\n            name=\'Embedding-Token\',\n        )\n        self.segment_embedding_layer = keras.layers.Embedding(\n            input_dim=2,\n            output_dim=embed_dim,\n            trainable=trainable,\n            name=\'Embedding-Segment\',\n        )\n        self.position_embedding_layer = PositionEmbedding(\n            input_dim=pos_num,\n            output_dim=embed_dim,\n            mode=PositionEmbedding.MODE_ADD,\n            trainable=trainable,\n            name=\'Embedding-Position\',\n        )\n        self.embedding_layer_norm = LayerNormalization(\n            trainable=trainable,\n            name=\'Embedding-Norm\',\n        )\n\n        self.encoder_multihead_layers = []\n        self.encoder_ffn_layers = []\n        self.encoder_attention_norm = []\n        self.encoder_ffn_norm = []\n        # attention layers\n        for i in range(transformer_num):\n            base_name = \'Encoder-%d\' % (i + 1)\n            attention_name = \'%s-MultiHeadSelfAttention\' % base_name\n            feed_forward_name = \'%s-FeedForward\' % base_name\n            self.encoder_multihead_layers.append(MultiHeadAttention(\n                head_num=head_num,\n                activation=attention_activation,\n                history_only=False,\n                trainable=trainable,\n                name=attention_name,\n            ))\n            self.encoder_ffn_layers.append(FeedForward(\n                units=feed_forward_dim,\n                activation=feed_forward_activation,\n                trainable=trainable,\n                name=feed_forward_name,\n            ))\n            self.encoder_attention_norm.append(LayerNormalization(\n                trainable=trainable,\n                name=\'%s-Norm\' % attention_name,\n            ))\n            self.encoder_ffn_norm.append(LayerNormalization(\n                trainable=trainable,\n                name=\'%s-Norm\' % feed_forward_name,\n            ))\n\n    def call(self, inputs):\n\n        embeddings = [\n            self.token_embedding_layer(inputs[0]),\n            self.segment_embedding_layer(inputs[1])\n        ]\n        embeddings[0], embed_weights = embeddings[0]\n        embed_layer = keras.layers.Add(\n            name=\'Embedding-Token-Segment\')(embeddings)\n        embed_layer = self.position_embedding_layer(embed_layer)\n\n        if self.dropout_rate > 0.0:\n            dropout_layer = keras.layers.Dropout(\n                rate=self.dropout_rate,\n                name=\'Embedding-Dropout\',\n            )(embed_layer)\n        else:\n            dropout_layer = embed_layer\n\n        embedding_output = self.embedding_layer_norm(dropout_layer)\n\n        def _wrap_layer(name, input_layer, build_func, norm_layer, dropout_rate=0.0, trainable=True):\n            """"""Wrap layers with residual, normalization and dropout.\n\n            :param name: Prefix of names for internal layers.\n            :param input_layer: Input layer.\n            :param build_func: A callable that takes the input tensor and generates the output tensor.\n            :param dropout_rate: Dropout rate.\n            :param trainable: Whether the layers are trainable.\n            :return: Output layer.\n            """"""\n            build_output = build_func(input_layer)\n            if dropout_rate > 0.0:\n                dropout_layer = keras.layers.Dropout(\n                    rate=dropout_rate,\n                    name=\'%s-Dropout\' % name,\n                )(build_output)\n            else:\n                dropout_layer = build_output\n            if isinstance(input_layer, list):\n                input_layer = input_layer[0]\n            add_layer = keras.layers.Add(name=\'%s-Add\' %\n                                         name)([input_layer, dropout_layer])\n            normal_layer = norm_layer(add_layer)\n            return normal_layer\n\n        last_layer = embedding_output\n        output_tensor_list = [last_layer]\n        # self attention\n        for i in range(self.transformer_num):\n            base_name = \'Encoder-%d\' % (i + 1)\n            attention_name = \'%s-MultiHeadSelfAttention\' % base_name\n            feed_forward_name = \'%s-FeedForward\' % base_name\n            self_attention_output = _wrap_layer(\n                name=attention_name,\n                input_layer=last_layer,\n                build_func=self.encoder_multihead_layers[i],\n                norm_layer=self.encoder_attention_norm[i],\n                dropout_rate=self.dropout_rate,\n                trainable=self.trainable)\n            last_layer = _wrap_layer(\n                name=attention_name,\n                input_layer=self_attention_output,\n                build_func=self.encoder_ffn_layers[i],\n                norm_layer=self.encoder_ffn_norm[i],\n                dropout_rate=self.dropout_rate,\n                trainable=self.trainable)\n            output_tensor_list.append(last_layer)\n\n        return output_tensor_list\n\n\ndef get_model(token_num,\n              pos_num=512,\n              seq_len=512,\n              embed_dim=768,\n              transformer_num=12,\n              head_num=12,\n              feed_forward_dim=3072,\n              dropout_rate=0.1,\n              attention_activation=None,\n              feed_forward_activation=gelu,\n              custom_layers=None,\n              training=True,\n              trainable=None,\n              lr=1e-4):\n    """"""Get BERT model.\n\n    See: https://arxiv.org/pdf/1810.04805.pdf\n\n    :param token_num: Number of tokens.\n    :param pos_num: Maximum position.\n    :param seq_len: Maximum length of the input sequence or None.\n    :param embed_dim: Dimensions of embeddings.\n    :param transformer_num: Number of transformers.\n    :param head_num: Number of heads in multi-head attention in each transformer.\n    :param feed_forward_dim: Dimension of the feed forward layer in each transformer.\n    :param dropout_rate: Dropout rate.\n    :param attention_activation: Activation for attention layers.\n    :param feed_forward_activation: Activation for feed-forward layers.\n    :param custom_layers: A function that takes the embedding tensor and returns the tensor after feature extraction.\n                          Arguments such as `transformer_num` and `head_num` will be ignored if `custom_layer` is not\n                          `None`.\n    :param training: The built model will be returned if it is `True`, otherwise the input layers and the last feature\n                     extraction layer will be returned.\n    :param trainable: Whether the model is trainable.\n    :param lr: Learning rate.\n    :return: The compiled model.\n    """"""\n    if trainable is None:\n        trainable = training\n    inputs = get_inputs(seq_len=seq_len)\n    embed_layer, embed_weights = get_embedding(\n        inputs,\n        token_num=token_num,\n        embed_dim=embed_dim,\n        pos_num=pos_num,\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    transformed = embed_layer\n    if custom_layers is not None:\n        kwargs = {}\n        if keras.utils.generic_utils.has_arg(custom_layers, \'trainable\'):\n            kwargs[\'trainable\'] = trainable\n        transformed = custom_layers(transformed, **kwargs)\n    else:\n        transformed = get_encoders(\n            encoder_num=transformer_num,\n            input_layer=transformed,\n            head_num=head_num,\n            hidden_dim=feed_forward_dim,\n            attention_activation=attention_activation,\n            feed_forward_activation=feed_forward_activation,\n            dropout_rate=dropout_rate,\n            trainable=trainable,\n        )\n    if not training:\n        return inputs, transformed\n    mlm_dense_layer = keras.layers.Dense(\n        units=embed_dim,\n        activation=feed_forward_activation,\n        trainable=trainable,\n        name=\'MLM-Dense\',\n    )(transformed)\n    mlm_norm_layer = LayerNormalization(name=\'MLM-Norm\')(mlm_dense_layer)\n    mlm_pred_layer = EmbeddingSimilarity(\n        name=\'MLM-Sim\')([mlm_norm_layer, embed_weights])\n    masked_layer = Masked(name=\'MLM\')([mlm_pred_layer, inputs[-1]])\n    extract_layer = Extract(index=0, name=\'Extract\')(transformed)\n    nsp_dense_layer = keras.layers.Dense(\n        units=embed_dim,\n        activation=\'tanh\',\n        trainable=trainable,\n        name=\'NSP-Dense\',\n    )(extract_layer)\n    nsp_pred_layer = keras.layers.Dense(\n        units=2,\n        activation=\'softmax\',\n        trainable=trainable,\n        name=\'NSP\',\n    )(nsp_dense_layer)\n    model = keras.models.Model(inputs=inputs, outputs=[\n                               masked_layer, nsp_pred_layer])\n    model.compile(\n        optimizer=keras.optimizers.Adam(lr=lr),\n        loss=keras.losses.sparse_categorical_crossentropy,\n    )\n    return model\n\n\ndef get_custom_objects():\n    """"""Get all custom objects for loading saved models.""""""\n    custom_objects = get_encoder_custom_objects()\n    custom_objects[\'PositionEmbedding\'] = PositionEmbedding\n    custom_objects[\'TokenEmbedding\'] = TokenEmbedding\n    custom_objects[\'EmbeddingSimilarity\'] = EmbeddingSimilarity\n    custom_objects[\'Masked\'] = Masked\n    custom_objects[\'Extract\'] = Extract\n    custom_objects[\'gelu\'] = gelu\n    return custom_objects\n\n\ndef get_base_dict():\n    """"""Get basic dictionary containing special tokens.""""""\n    return {\n        TOKEN_PAD: 0,\n        TOKEN_UNK: 1,\n        TOKEN_CLS: 2,\n        TOKEN_SEP: 3,\n        TOKEN_MASK: 4,\n    }\n\n\ndef gen_batch_inputs(sentence_pairs,\n                     token_dict,\n                     token_list,\n                     seq_len=512,\n                     mask_rate=0.15,\n                     mask_mask_rate=0.8,\n                     mask_random_rate=0.1,\n                     swap_sentence_rate=0.5,\n                     force_mask=True):\n    """"""Generate a batch of inputs and outputs for training.\n\n    :param sentence_pairs: A list of pairs containing lists of tokens.\n    :param token_dict: The dictionary containing special tokens.\n    :param token_list: A list containing all tokens.\n    :param seq_len: Length of the sequence.\n    :param mask_rate: The rate of choosing a token for prediction.\n    :param mask_mask_rate: The rate of replacing the token to `TOKEN_MASK`.\n    :param mask_random_rate: The rate of replacing the token to a random word.\n    :param swap_sentence_rate: The rate of swapping the second sentences.\n    :param force_mask: At least one position will be masked.\n    :return: All the inputs and outputs.\n    """"""\n    batch_size = len(sentence_pairs)\n    base_dict = get_base_dict()\n    unknown_index = token_dict[TOKEN_UNK]\n    # Generate sentence swapping mapping\n    nsp_outputs = np.zeros((batch_size,))\n    mapping = {}\n    if swap_sentence_rate > 0.0:\n        indices = [index for index in range(\n            batch_size) if np.random.random() < swap_sentence_rate]\n        mapped = indices[:]\n        np.random.shuffle(mapped)\n        for i in range(len(mapped)):\n            if indices[i] != mapped[i]:\n                nsp_outputs[indices[i]] = 1.0\n        mapping = {indices[i]: mapped[i] for i in range(len(indices))}\n    # Generate MLM\n    token_inputs, segment_inputs, masked_inputs = [], [], []\n    mlm_outputs = []\n    for i in range(batch_size):\n        first, second = sentence_pairs[i][0], sentence_pairs[mapping.get(\n            i, i)][1]\n        segment_inputs.append(\n            ([0] * (len(first) + 2) + [1] * (seq_len - (len(first) + 2)))[:seq_len])\n        tokens = [TOKEN_CLS] + first + [TOKEN_SEP] + second + [TOKEN_SEP]\n        tokens = tokens[:seq_len]\n        tokens += [TOKEN_PAD] * (seq_len - len(tokens))\n        token_input, masked_input, mlm_output = [], [], []\n        has_mask = False\n        for token in tokens:\n            mlm_output.append(token_dict.get(token, unknown_index))\n            if token not in base_dict and np.random.random() < mask_rate:\n                has_mask = True\n                masked_input.append(1)\n                r = np.random.random()\n                if r < mask_mask_rate:\n                    token_input.append(token_dict[TOKEN_MASK])\n                elif r < mask_mask_rate + mask_random_rate:\n                    while True:\n                        token = np.random.choice(token_list)\n                        if token not in base_dict:\n                            token_input.append(token_dict[token])\n                            break\n                else:\n                    token_input.append(token_dict.get(token, unknown_index))\n            else:\n                masked_input.append(0)\n                token_input.append(token_dict.get(token, unknown_index))\n        if force_mask and not has_mask:\n            masked_input[1] = 1\n        token_inputs.append(token_input)\n        masked_inputs.append(masked_input)\n        mlm_outputs.append(mlm_output)\n    inputs = [np.asarray(x)\n              for x in [token_inputs, segment_inputs, masked_inputs]]\n    outputs = [np.asarray(np.expand_dims(x, axis=-1))\n               for x in [mlm_outputs, nsp_outputs]]\n    return inputs, outputs\n'"
keras_bert/loader.py,1,"b'import json\nfrom tensorflow import keras\nimport numpy as np\nimport tensorflow as tf\nfrom .bert import get_model\n\n\n__all__ = [\n    \'build_model_from_config\',\n    \'load_model_weights_from_checkpoint\',\n    \'load_trained_model_from_checkpoint\',\n]\n\n\ndef checkpoint_loader(checkpoint_file):\n    def _loader(name):\n        return tf.train.load_variable(checkpoint_file, name)\n    return _loader\n\n\ndef build_model_from_config(config_file,\n                            training=False,\n                            trainable=None,\n                            seq_len=None):\n    """"""Build the model from config file.\n\n    :param config_file: The path to the JSON configuration file.\n    :param training: If training, the whole model will be returned.\n    :param trainable: Whether the model is trainable.\n    :param seq_len: If it is not None and it is shorter than the value in the config file, the weights in\n                    position embeddings will be sliced to fit the new length.\n    :return: model and config\n    """"""\n    with open(config_file, \'r\') as reader:\n        config = json.loads(reader.read())\n    if seq_len is not None:\n        config[\'max_position_embeddings\'] = min(\n            seq_len, config[\'max_position_embeddings\'])\n    if trainable is None:\n        trainable = training\n\n    model = get_model(\n        token_num=config[\'vocab_size\'],\n        pos_num=config[\'max_position_embeddings\'],\n        seq_len=config[\'max_position_embeddings\'],\n        embed_dim=config[\'hidden_size\'],\n        transformer_num=config[\'num_hidden_layers\'],\n        head_num=config[\'num_attention_heads\'],\n        feed_forward_dim=config[\'intermediate_size\'],\n        training=training,\n        trainable=trainable,\n    )\n    model.build(input_shape=[(None, None), (None, None), (None, None)])\n    return model, config\n\n\ndef load_model_weights_from_checkpoint(model,\n                                       config,\n                                       checkpoint_file,\n                                       training=False):\n    """"""Load trained official model from checkpoint.\n\n    :param model: Built keras model.\n    :param config: Loaded configuration file.\n    :param checkpoint_file: The path to the checkpoint files, should end with \'.ckpt\'.\n    :param training: If training, the whole model will be returned.\n                     Otherwise, the MLM and NSP parts will be ignored.\n    """"""\n    loader = checkpoint_loader(checkpoint_file)\n\n    model.get_layer(name=\'Embedding-Token\').set_weights([\n        loader(\'bert/embeddings/word_embeddings\'),\n    ])\n    model.get_layer(name=\'Embedding-Position\').set_weights([\n        loader(\n            \'bert/embeddings/position_embeddings\')[:config[\'max_position_embeddings\'], :],\n    ])\n    model.get_layer(name=\'Embedding-Segment\').set_weights([\n        loader(\'bert/embeddings/token_type_embeddings\'),\n    ])\n    model.get_layer(name=\'Embedding-Norm\').set_weights([\n        loader(\'bert/embeddings/LayerNorm/gamma\'),\n        loader(\'bert/embeddings/LayerNorm/beta\'),\n    ])\n    for i in range(config[\'num_hidden_layers\']):\n        model.get_layer(name=\'Encoder-%d-MultiHeadSelfAttention\' % (i + 1)).set_weights([\n            loader(\'bert/encoder/layer_%d/attention/self/query/kernel\' % i),\n            loader(\'bert/encoder/layer_%d/attention/self/query/bias\' % i),\n            loader(\'bert/encoder/layer_%d/attention/self/key/kernel\' % i),\n            loader(\'bert/encoder/layer_%d/attention/self/key/bias\' % i),\n            loader(\'bert/encoder/layer_%d/attention/self/value/kernel\' % i),\n            loader(\'bert/encoder/layer_%d/attention/self/value/bias\' % i),\n            loader(\'bert/encoder/layer_%d/attention/output/dense/kernel\' % i),\n            loader(\'bert/encoder/layer_%d/attention/output/dense/bias\' % i),\n        ])\n        model.get_layer(name=\'Encoder-%d-MultiHeadSelfAttention-Norm\' % (i + 1)).set_weights([\n            loader(\'bert/encoder/layer_%d/attention/output/LayerNorm/gamma\' % i),\n            loader(\'bert/encoder/layer_%d/attention/output/LayerNorm/beta\' % i),\n        ])\n        model.get_layer(name=\'Encoder-%d-MultiHeadSelfAttention-Norm\' % (i + 1)).set_weights([\n            loader(\'bert/encoder/layer_%d/attention/output/LayerNorm/gamma\' % i),\n            loader(\'bert/encoder/layer_%d/attention/output/LayerNorm/beta\' % i),\n        ])\n        model.get_layer(name=\'Encoder-%d-FeedForward\' % (i + 1)).set_weights([\n            loader(\'bert/encoder/layer_%d/intermediate/dense/kernel\' % i),\n            loader(\'bert/encoder/layer_%d/intermediate/dense/bias\' % i),\n            loader(\'bert/encoder/layer_%d/output/dense/kernel\' % i),\n            loader(\'bert/encoder/layer_%d/output/dense/bias\' % i),\n        ])\n        model.get_layer(name=\'Encoder-%d-FeedForward-Norm\' % (i + 1)).set_weights([\n            loader(\'bert/encoder/layer_%d/output/LayerNorm/gamma\' % i),\n            loader(\'bert/encoder/layer_%d/output/LayerNorm/beta\' % i),\n        ])\n    if training:\n        model.get_layer(name=\'MLM-Dense\').set_weights([\n            loader(\'cls/predictions/transform/dense/kernel\'),\n            loader(\'cls/predictions/transform/dense/bias\'),\n        ])\n        model.get_layer(name=\'MLM-Norm\').set_weights([\n            loader(\'cls/predictions/transform/LayerNorm/gamma\'),\n            loader(\'cls/predictions/transform/LayerNorm/beta\'),\n        ])\n        model.get_layer(name=\'MLM-Sim\').set_weights([\n            loader(\'cls/predictions/output_bias\'),\n        ])\n        model.get_layer(name=\'NSP-Dense\').set_weights([\n            loader(\'bert/pooler/dense/kernel\'),\n            loader(\'bert/pooler/dense/bias\'),\n        ])\n        model.get_layer(name=\'NSP\').set_weights([\n            np.transpose(loader(\'cls/seq_relationship/output_weights\')),\n            loader(\'cls/seq_relationship/output_bias\'),\n        ])\n\n\ndef load_trained_model_from_checkpoint(config_file,\n                                       checkpoint_file,\n                                       training=False,\n                                       trainable=None,\n                                       seq_len=None):\n    """"""Load trained official model from checkpoint.\n\n    :param config_file: The path to the JSON configuration file.\n    :param checkpoint_file: The path to the checkpoint files, should end with \'.ckpt\'.\n    :param training: If training, the whole model will be returned.\n                     Otherwise, the MLM and NSP parts will be ignored.\n    :param trainable: Whether the model is trainable. The default value is the same with `training`.\n    :param seq_len: If it is not None and it is shorter than the value in the config file, the weights in\n                    position embeddings will be sliced to fit the new length.\n    :return: model\n    """"""\n    model, config = build_model_from_config(\n        config_file, training=training, trainable=trainable, seq_len=seq_len)\n    load_model_weights_from_checkpoint(\n        model, config, checkpoint_file, training=training)\n    return model\n'"
keras_bert/tokenizer.py,0,"b'import unicodedata\nfrom .bert import TOKEN_CLS, TOKEN_SEP, TOKEN_UNK\n\n\nclass Tokenizer(object):\n\n    def __init__(self,\n                 token_dict,\n                 token_cls=TOKEN_CLS,\n                 token_sep=TOKEN_SEP,\n                 token_unk=TOKEN_UNK,\n                 pad_index=0,\n                 cased=False):\n        """"""Initialize tokenizer.\n\n        :param token_dict: A dict maps tokens to indices.\n        :param token_cls: The token represents classification.\n        :param token_sep: The token represents separator.\n        :param token_unk: The token represents unknown token.\n        :param pad_index: The index to pad.\n        :param cased: Whether to keep the case.\n        """"""\n        self._token_dict = token_dict\n        self._token_cls = token_cls\n        self._token_sep = token_sep\n        self._token_unk = token_unk\n        self._pad_index = pad_index\n        self._cased = cased\n\n    @staticmethod\n    def _truncate(first_tokens, second_tokens=None, max_len=None):\n        if max_len is None:\n            return\n\n        if second_tokens is not None:\n            while True:\n                total_len = len(first_tokens) + len(second_tokens)\n                if total_len <= max_len - 3:  # 3 for [CLS] .. tokens_a .. [SEP] .. tokens_b [SEP]\n                    break\n                if len(first_tokens) > len(second_tokens):\n                    first_tokens.pop()\n                else:\n                    second_tokens.pop()\n        else:\n            del first_tokens[max_len - 2:]  # 2 for [CLS] .. tokens .. [SEP]\n\n    def _pack(self, first_tokens, second_tokens=None):\n        first_packed_tokens = [self._token_cls] + first_tokens + [self._token_sep]\n        if second_tokens is not None:\n            second_packed_tokens = second_tokens + [self._token_sep]\n            return first_packed_tokens + second_packed_tokens, len(first_packed_tokens), len(second_packed_tokens)\n        else:\n            return first_packed_tokens, len(first_packed_tokens), 0\n\n    def _convert_tokens_to_ids(self, tokens):\n        unk_id = self._token_dict.get(self._token_unk)\n        return [self._token_dict.get(token, unk_id) for token in tokens]\n\n    def tokenize(self, first, second=None):\n        first_tokens = self._tokenize(first)\n        second_tokens = self._tokenize(second) if second is not None else None\n        tokens, _, _ = self._pack(first_tokens, second_tokens)\n        return tokens\n\n    def encode(self, first, second=None, max_len=None):\n        first_tokens = self._tokenize(first)\n        second_tokens = self._tokenize(second) if second is not None else None\n        self._truncate(first_tokens, second_tokens, max_len)\n        tokens, first_len, second_len = self._pack(first_tokens, second_tokens)\n\n        token_ids = self._convert_tokens_to_ids(tokens)\n        segment_ids = [0] * first_len + [1] * second_len\n\n        if max_len is not None:\n            pad_len = max_len - first_len - second_len\n            token_ids += [self._pad_index] * pad_len\n            segment_ids += [0] * pad_len\n\n        return token_ids, segment_ids\n\n    def _tokenize(self, text):\n        if not self._cased:\n            text = unicodedata.normalize(\'NFD\', text)\n            text = \'\'.join([ch for ch in text if unicodedata.category(ch) != \'Mn\'])\n            text = text.lower()\n        spaced = \'\'\n        for ch in text:\n            if self._is_punctuation(ch) or self._is_cjk_character(ch):\n                spaced += \' \' + ch + \' \'\n            elif self._is_space(ch):\n                spaced += \' \'\n            elif ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\n                continue\n            else:\n                spaced += ch\n        tokens = []\n        for word in spaced.strip().split():\n            tokens += self._word_piece_tokenize(word)\n        return tokens\n\n    def _word_piece_tokenize(self, word):\n        if word in self._token_dict:\n            return [word]\n        tokens = []\n        start, stop = 0, 0\n        while start < len(word):\n            stop = len(word)\n            while stop > start:\n                sub = word[start:stop]\n                if start > 0:\n                    sub = \'##\' + sub\n                if sub in self._token_dict:\n                    break\n                stop -= 1\n            if start == stop:\n                stop += 1\n            tokens.append(sub)\n            start = stop\n        return tokens\n\n    @staticmethod\n    def _is_punctuation(ch):\n        code = ord(ch)\n        return 33 <= code <= 47 or \\\n            58 <= code <= 64 or \\\n            91 <= code <= 96 or \\\n            123 <= code <= 126 or \\\n            unicodedata.category(ch).startswith(\'P\')\n\n    @staticmethod\n    def _is_cjk_character(ch):\n        code = ord(ch)\n        return 0x4E00 <= code <= 0x9FFF or \\\n            0x3400 <= code <= 0x4DBF or \\\n            0x20000 <= code <= 0x2A6DF or \\\n            0x2A700 <= code <= 0x2B73F or \\\n            0x2B740 <= code <= 0x2B81F or \\\n            0x2B820 <= code <= 0x2CEAF or \\\n            0xF900 <= code <= 0xFAFF or \\\n            0x2F800 <= code <= 0x2FA1F\n\n    @staticmethod\n    def _is_space(ch):\n        return ch == \' \' or ch == \'\\n\' or ch == \'\\r\' or ch == \'\\t\' or \\\n            unicodedata.category(ch) == \'Zs\'\n\n    @staticmethod\n    def _is_control(ch):\n        return unicodedata.category(ch).startswith(\'C\')\n'"
keras_bert/keras_embed_sim/__init__.py,0,b'from .embeddings import *\n'
keras_bert/keras_embed_sim/embeddings.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n__all__ = [\'EmbeddingRet\', \'EmbeddingSim\', \'get_custom_objects\']\n\n\nclass EmbeddingRet(keras.layers.Embedding):\n    """"""Embedding layer with weights returned.""""""\n\n    def compute_output_shape(self, input_shape):\n        return [\n            super(EmbeddingRet, self).compute_output_shape(input_shape),\n            (self.input_dim, self.output_dim),\n        ]\n\n    def compute_mask(self, inputs, mask=None):\n        return [\n            super(EmbeddingRet, self).compute_mask(inputs, mask),\n            None,\n        ]\n\n    def call(self, inputs):\n        return [\n            super(EmbeddingRet, self).call(inputs),\n            self.embeddings,\n        ]\n\n\nclass EmbeddingSim(keras.layers.Layer):\n    """"""Calculate similarity between features and token embeddings with bias term.""""""\n\n    def __init__(self,\n                 use_bias=True,\n                 initializer=\'zeros\',\n                 regularizer=None,\n                 constraint=None,\n                 **kwargs):\n        """"""Initialize the layer.\n\n        :param output_dim: Same as embedding output dimension.\n        :param use_bias: Whether to use bias term.\n        :param initializer: Initializer for bias.\n        :param regularizer: Regularizer for bias.\n        :param constraint: Constraint for bias.\n        :param kwargs: Arguments for parent class.\n        """"""\n        super(EmbeddingSim, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.use_bias = use_bias\n        self.initializer = keras.initializers.get(initializer)\n        self.regularizer = keras.regularizers.get(regularizer)\n        self.constraint = keras.constraints.get(constraint)\n        self.bias = None\n\n    def get_config(self):\n        config = {\n            \'use_bias\': self.use_bias,\n            \'initializer\': keras.initializers.serialize(self.initializer),\n            \'regularizer\': keras.regularizers.serialize(self.regularizer),\n            \'constraint\': keras.constraints.serialize(self.constraint),\n        }\n        base_config = super(EmbeddingSim, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def build(self, input_shape):\n        if self.use_bias:\n            embed_shape = input_shape[1]\n            token_num = embed_shape[0]\n            self.bias = self.add_weight(\n                shape=(token_num,),\n                initializer=self.initializer,\n                regularizer=self.regularizer,\n                constraint=self.constraint,\n                name=\'bias\',\n            )\n        super(EmbeddingSim, self).build(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        feature_shape, embed_shape = input_shape\n        token_num = embed_shape[0]\n        return feature_shape[:-1] + (token_num,)\n\n    def compute_mask(self, inputs, mask=None):\n        return mask[0]\n\n    def call(self, inputs, mask=None, **kwargs):\n        inputs, embeddings = inputs\n        outputs = K.dot(inputs, K.transpose(embeddings))\n        if self.use_bias:\n            outputs = K.bias_add(outputs, self.bias)\n        return keras.activations.softmax(outputs)\n\n\ndef get_custom_objects():\n    return {\n        \'EmbeddingRet\': EmbeddingRet,\n        \'EmbeddingSim\': EmbeddingSim,\n    }\n'"
keras_bert/keras_layer_normalization/__init__.py,0,b'from .layer_normalization import LayerNormalization\n'
keras_bert/keras_layer_normalization/layer_normalization.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass LayerNormalization(keras.layers.Layer):\n\n    def __init__(self,\n                 center=True,\n                 scale=True,\n                 epsilon=None,\n                 gamma_initializer=\'ones\',\n                 beta_initializer=\'zeros\',\n                 gamma_regularizer=None,\n                 beta_regularizer=None,\n                 gamma_constraint=None,\n                 beta_constraint=None,\n                 **kwargs):\n        """"""Layer normalization layer\n\n        See: [Layer Normalization](https://arxiv.org/pdf/1607.06450.pdf)\n\n        :param center: Add an offset parameter if it is True.\n        :param scale: Add a scale parameter if it is True.\n        :param epsilon: Epsilon for calculating variance.\n        :param gamma_initializer: Initializer for the gamma weight.\n        :param beta_initializer: Initializer for the beta weight.\n        :param gamma_regularizer: Optional regularizer for the gamma weight.\n        :param beta_regularizer: Optional regularizer for the beta weight.\n        :param gamma_constraint: Optional constraint for the gamma weight.\n        :param beta_constraint: Optional constraint for the beta weight.\n        :param kwargs:\n        """"""\n        super(LayerNormalization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.center = center\n        self.scale = scale\n        if epsilon is None:\n            epsilon = K.epsilon() * K.epsilon()\n        self.epsilon = epsilon\n        self.gamma_initializer = keras.initializers.get(gamma_initializer)\n        self.beta_initializer = keras.initializers.get(beta_initializer)\n        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)\n        self.beta_regularizer = keras.regularizers.get(beta_regularizer)\n        self.gamma_constraint = keras.constraints.get(gamma_constraint)\n        self.beta_constraint = keras.constraints.get(beta_constraint)\n        self.gamma, self.beta = None, None\n\n    def get_config(self):\n        config = {\n            \'center\': self.center,\n            \'scale\': self.scale,\n            \'epsilon\': self.epsilon,\n            \'gamma_initializer\': keras.initializers.serialize(self.gamma_initializer),\n            \'beta_initializer\': keras.initializers.serialize(self.beta_initializer),\n            \'gamma_regularizer\': keras.regularizers.serialize(self.gamma_regularizer),\n            \'beta_regularizer\': keras.regularizers.serialize(self.beta_regularizer),\n            \'gamma_constraint\': keras.constraints.serialize(self.gamma_constraint),\n            \'beta_constraint\': keras.constraints.serialize(self.beta_constraint),\n        }\n        base_config = super(LayerNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n    def compute_mask(self, inputs, input_mask=None):\n        return input_mask\n\n    def build(self, input_shape):\n        self.input_spec = keras.layers.InputSpec(shape=input_shape)\n        shape = input_shape[-1:]\n        if self.scale:\n            self.gamma = self.add_weight(\n                shape=shape,\n                initializer=self.gamma_initializer,\n                regularizer=self.gamma_regularizer,\n                constraint=self.gamma_constraint,\n                name=\'gamma\',\n            )\n        if self.center:\n            self.beta = self.add_weight(\n                shape=shape,\n                initializer=self.beta_initializer,\n                regularizer=self.beta_regularizer,\n                constraint=self.beta_constraint,\n                name=\'beta\',\n            )\n        super(LayerNormalization, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        mean = K.mean(inputs, axis=-1, keepdims=True)\n        variance = K.mean(K.square(inputs - mean), axis=-1, keepdims=True)\n        std = K.sqrt(variance + self.epsilon)\n        outputs = (inputs - mean) / std\n        if self.scale:\n            outputs *= self.gamma\n        if self.center:\n            outputs += self.beta\n        return outputs\n'"
keras_bert/keras_multi_head/__init__.py,0,b'from .multi_head import MultiHead\nfrom .multi_head_attention import MultiHeadAttention\n'
keras_bert/keras_multi_head/multi_head.py,0,"b'import copy\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass MultiHead(keras.layers.Wrapper):\n\n    def __init__(self,\n                 layer,\n                 layer_num=1,\n                 hidden_dim=None,\n                 use_bias=True,\n                 reg_index=None,\n                 reg_slice=None,\n                 reg_factor=0.0,\n                 **kwargs):\n        """"""Initialize the wrapper layer.\n\n        :param layer: The layer to be duplicated or a list of layers.\n        :param layer_num: The number of duplicated layers.\n        :param hidden_dim: A linear transformation will be applied to the input data if provided, otherwise the original\n                           data will be feed to the sub-layers.\n        :param use_bias: Whether to use bias in the linear transformation.\n        :param reg_index: The index of weights to be regularized.\n        :param reg_slice: The slice indicates which part of the weight to be regularized.\n        :param reg_factor: The weights of the regularization.\n        :param kwargs: Arguments for parent.\n        """"""\n        if type(layer) is list:\n            self.layer = layer[0]\n            self.layers = layer\n            self.layer_num = len(self.layers)\n            self.rename = False\n        else:\n            self.layer = layer\n            self.layers = []\n            self.layer_num = layer_num\n            self.rename = True\n        self.hidden_dim = hidden_dim\n        self.use_bias = use_bias\n        if reg_index is None or type(reg_index) is list:\n            self.reg_index = reg_index\n        else:\n            self.reg_index = [reg_index]\n        if type(reg_slice) is list or reg_index is None:\n            self.reg_slice = reg_slice\n        else:\n            self.reg_slice = [reg_slice] * len(self.reg_index)\n        if reg_factor is None or type(reg_factor) is list or reg_index is None:\n            self.reg_weight = reg_factor\n        else:\n            self.reg_weight = [reg_factor] * len(self.reg_index)\n\n        self.W, self.b = None, None\n        self.supports_masking = self.layer.supports_masking\n        super(MultiHead, self).__init__(self.layer, **kwargs)\n\n    def get_config(self):\n        slices = None\n        if self.reg_slice:\n            slices = []\n            for interval in self.reg_slice:\n                if interval is None:\n                    slices.append(None)\n                elif type(interval) is slice:\n                    slices.append([interval.start, interval.stop, interval.step])\n                else:\n                    slices.append([])\n                    for sub in interval:\n                        slices[-1].append([sub.start, sub.stop, sub.step])\n        config = {\n            \'layers\': [],\n            \'hidden_dim\': self.hidden_dim,\n            \'use_bias\': self.use_bias,\n            \'reg_index\': self.reg_index,\n            \'reg_slice\': slices,\n            \'reg_factor\': self.reg_weight,\n        }\n        for layer in self.layers:\n            config[\'layers\'].append({\n                \'class_name\': layer.__class__.__name__,\n                \'config\': layer.get_config(),\n            })\n        base_config = super(MultiHead, self).get_config()\n        base_config.pop(\'layer\')\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        reg_slice = config.pop(\'reg_slice\')\n        if reg_slice is not None:\n            slices = []\n            for interval in reg_slice:\n                if interval is None:\n                    slices.append(None)\n                elif type(interval[0]) is list:\n                    slices.append([])\n                    for sub in interval:\n                        slices[-1].append(slice(sub[0], sub[1], sub[2]))\n                    slices[-1] = tuple(slices[-1])\n                else:\n                    slices.append(slice(interval[0], interval[1], interval[2]))\n            reg_slice = slices\n        layers = [keras.layers.deserialize(layer, custom_objects=custom_objects) for layer in config.pop(\'layers\')]\n        return cls(layers, reg_slice=reg_slice, **config)\n\n    def build(self, input_shape):\n        if type(input_shape) == list:\n            self.input_spec = list(map(lambda x: keras.engine.InputSpec(shape=x), input_shape))\n        else:\n            self.input_spec = keras.engine.InputSpec(shape=input_shape)\n        if not self.layers:\n            self.layers = [copy.deepcopy(self.layer) for _ in range(self.layer_num)]\n        if self.hidden_dim is not None:\n            self.W = self.add_weight(\n                shape=(input_shape[-1], self.hidden_dim * self.layer_num),\n                name=\'{}_W\'.format(self.name),\n                initializer=keras.initializers.get(\'uniform\'),\n            )\n            if self.use_bias:\n                self.b = self.add_weight(\n                    shape=(self.hidden_dim * self.layer_num,),\n                    name=\'{}_b\'.format(self.name),\n                    initializer=keras.initializers.get(\'zeros\'),\n                )\n            input_shape = input_shape[:-1] + (self.hidden_dim,)\n        for i, layer in enumerate(self.layers):\n            if not layer.built:\n                if self.rename:\n                    layer.name = layer.name + \'_%d\' % (i + 1)\n                layer.build(input_shape)\n        if self.reg_index:\n            for i, (index, interval, weight) in enumerate(zip(self.reg_index, self.reg_slice, self.reg_weight)):\n                weights = []\n                if type(interval) is slice:\n                    interval = (interval,)\n                for layer in self.layers:\n                    if interval is None:\n                        weights.append(K.flatten(layer.get_weights()[index]))\n                    else:\n                        weights.append(K.flatten(layer.get_weights()[index][interval]))\n                weights = K.stack(weights)\n                self.add_loss(weight * K.sum(K.square(K.dot(weights, K.transpose(weights)) - K.eye(len(self.layers)))))\n        super(MultiHead, self).build(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        if self.hidden_dim is not None:\n            input_shape = input_shape[:-1] + (self.hidden_dim,)\n        child_output_shape = self.layers[0].compute_output_shape(input_shape)\n        return child_output_shape + (self.layer_num,)\n\n    def compute_mask(self, inputs, mask=None):\n        return self.layers[0].compute_mask(inputs, mask)\n\n    def call(self, inputs, training=None, mask=None):\n        kwargs = {}\n        if keras.utils.generic_utils.has_arg(self.layer.call, \'training\'):\n            kwargs[\'training\'] = training\n        if keras.utils.generic_utils.has_arg(self.layer.call, \'mask\') and mask is not None:\n            kwargs[\'mask\'] = mask\n        if self.hidden_dim is None:\n            outputs = [K.expand_dims(layer.call(inputs, **kwargs)) for layer in self.layers]\n        else:\n            outputs = []\n            for i, layer in enumerate(self.layers):\n                begin = i * self.hidden_dim\n                end = begin + self.hidden_dim\n                transformed = K.dot(inputs, self.W[:, begin:end])\n                if self.use_bias:\n                    transformed += self.b[begin:end]\n                outputs.append(K.expand_dims(layer.call(transformed, **kwargs)))\n        return K.concatenate(outputs, axis=-1)\n\n    @property\n    def trainable_weights(self):\n        weights = self._trainable_weights[:]\n        for layer in self.layers:\n            weights += layer.trainable_weights\n        return weights\n\n    @property\n    def non_trainable_weights(self):\n        weights = self._non_trainable_weights[:]\n        for layer in self.layers:\n            weights += layer.non_trainable_weights\n        return weights\n\n    @property\n    def updates(self):\n        updates = self._updates\n        for layer in self.layers:\n            if hasattr(layer, \'updates\'):\n                updates += layer.updates\n        return []\n\n    def get_updates_for(self, inputs=None):\n        inner_inputs = inputs\n        if inputs is not None:\n            uid = keras.utils.generic_utils.object_list_uid(inputs)\n            if uid in self._input_map:\n                inner_inputs = self._input_map[uid]\n\n        updates = self._updates\n        for layer in self.layers:\n            layer_updates = layer.get_updates_for(inner_inputs)\n            layer_updates += super(MultiHead, self).get_updates_for(inputs)\n            updates += layer_updates\n        return updates\n\n    @property\n    def losses(self):\n        losses = self._losses\n        for layer in self.layers:\n            if hasattr(layer, \'losses\'):\n                losses += layer.losses\n        return losses\n\n    def get_losses_for(self, inputs=None):\n        if inputs is None:\n            losses = []\n            for layer in self.layers:\n                losses = layer.get_losses_for(None)\n            return losses + super(MultiHead, self).get_losses_for(None)\n        return super(MultiHead, self).get_losses_for(inputs)\n'"
keras_bert/keras_multi_head/multi_head_attention.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom ..keras_self_attention import ScaledDotProductAttention\n\n\nclass MultiHeadAttention(keras.layers.Layer):\n    """"""Multi-head attention layer.\n\n    See: https://arxiv.org/pdf/1706.03762.pdf\n    """"""\n\n    def __init__(self,\n                 head_num,\n                 activation=\'relu\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_normal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 history_only=False,\n                 **kwargs):\n        """"""Initialize the layer.\n\n        :param head_num: Number of heads.\n        :param activation: Activations for linear mappings.\n        :param use_bias: Whether to use bias term.\n        :param kernel_initializer: Initializer for linear mappings.\n        :param bias_initializer: Initializer for linear mappings.\n        :param kernel_regularizer: Regularizer for linear mappings.\n        :param bias_regularizer: Regularizer for linear mappings.\n        :param kernel_constraint: Constraints for linear mappings.\n        :param bias_constraint: Constraints for linear mappings.\n        :param history_only: Whether to only use history in attention layer.\n        """"""\n        self.supports_masking = True\n        self.head_num = head_num\n        self.activation = keras.activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n        self.bias_initializer = keras.initializers.get(bias_initializer)\n        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n        self.bias_constraint = keras.constraints.get(bias_constraint)\n        self.history_only = history_only\n\n        self.Wq, self.Wk, self.Wv, self.Wo = None, None, None, None\n        self.bq, self.bk, self.bv, self.bo = None, None, None, None\n        super(MultiHeadAttention, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = {\n            \'head_num\': self.head_num,\n            \'activation\': keras.activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': keras.initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': keras.initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': keras.regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': keras.regularizers.serialize(self.bias_regularizer),\n            \'kernel_constraint\': keras.constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': keras.constraints.serialize(self.bias_constraint),\n            \'history_only\': self.history_only,\n        }\n        base_config = super(MultiHeadAttention, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            q, k, v = input_shape\n            return q[:-1] + (v[-1],)\n        return input_shape\n\n    def compute_mask(self, inputs, input_mask=None):\n        if isinstance(input_mask, list):\n            return input_mask[0]\n        return input_mask\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            q, k, v = input_shape\n        else:\n            q = k = v = input_shape\n        feature_dim = v[-1]\n        if feature_dim % self.head_num != 0:\n            raise IndexError(\'Invalid head number %d with the given input dim %d\' % (\n                self.head_num, feature_dim))\n        self.Wq = self.add_weight(\n            shape=(q[-1], feature_dim),\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            name=\'%s_Wq\' % self.name,\n        )\n        if self.use_bias:\n            self.bq = self.add_weight(\n                shape=(feature_dim,),\n                initializer=self.bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                name=\'%s_bq\' % self.name,\n            )\n        self.Wk = self.add_weight(\n            shape=(k[-1], feature_dim),\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            name=\'%s_Wk\' % self.name,\n        )\n        if self.use_bias:\n            self.bk = self.add_weight(\n                shape=(feature_dim,),\n                initializer=self.bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                name=\'%s_bk\' % self.name,\n            )\n        self.Wv = self.add_weight(\n            shape=(v[-1], feature_dim),\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            name=\'%s_Wv\' % self.name,\n        )\n        if self.use_bias:\n            self.bv = self.add_weight(\n                shape=(feature_dim,),\n                initializer=self.bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                name=\'%s_bv\' % self.name,\n            )\n        self.Wo = self.add_weight(\n            shape=(feature_dim, feature_dim),\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            name=\'%s_Wo\' % self.name,\n        )\n        if self.use_bias:\n            self.bo = self.add_weight(\n                shape=(feature_dim,),\n                initializer=self.bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                name=\'%s_bo\' % self.name,\n            )\n        super(MultiHeadAttention, self).build(input_shape)\n\n    @staticmethod\n    def _reshape_to_batches(x, head_num):\n        input_shape = K.shape(x)\n        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n        head_dim = feature_dim // head_num\n        x = K.reshape(x, (batch_size, seq_len, head_num, head_dim))\n        x = K.permute_dimensions(x, [0, 2, 1, 3])\n        return K.reshape(x, (batch_size * head_num, seq_len, head_dim))\n\n    @staticmethod\n    def _reshape_from_batches(x, head_num):\n        input_shape = K.shape(x)\n        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n        x = K.reshape(x, (batch_size // head_num,\n                          head_num, seq_len, feature_dim))\n        x = K.permute_dimensions(x, [0, 2, 1, 3])\n        return K.reshape(x, (batch_size // head_num, seq_len, feature_dim * head_num))\n\n    @staticmethod\n    def _reshape_mask(mask, head_num):\n        if mask is None:\n            return mask\n        seq_len = K.shape(mask)[1]\n        mask = K.expand_dims(mask, axis=1)\n        mask = K.tile(mask, [1, head_num, 1])\n        return K.reshape(mask, (-1, seq_len))\n\n    def call(self, inputs, mask=None):\n        if isinstance(inputs, list):\n            q, k, v = inputs\n        else:\n            q = k = v = inputs\n        if isinstance(mask, list):\n            q_mask, k_mask, v_mask = mask\n        else:\n            q_mask = k_mask = v_mask = mask\n        q = K.dot(q, self.Wq)\n        k = K.dot(k, self.Wk)\n        v = K.dot(v, self.Wv)\n        if self.use_bias:\n            q += self.bq\n            k += self.bk\n            v += self.bv\n        if self.activation is not None:\n            q = self.activation(q)\n            k = self.activation(k)\n            v = self.activation(v)\n        y = ScaledDotProductAttention(\n            history_only=self.history_only,\n            name=\'%s-Attention\' % self.name,\n        )(\n            inputs=[\n                self._reshape_to_batches(q, self.head_num),\n                self._reshape_to_batches(k, self.head_num),\n                self._reshape_to_batches(v, self.head_num),\n            ],\n            mask=[\n                self._reshape_mask(q_mask, self.head_num),\n                self._reshape_mask(k_mask, self.head_num),\n                self._reshape_mask(v_mask, self.head_num),\n            ],\n        )\n        y = self._reshape_from_batches(y, self.head_num)\n        y = K.dot(y, self.Wo)\n        if self.use_bias:\n            y += self.bo\n        if self.activation is not None:\n            y = self.activation(y)\n        return y\n'"
keras_bert/keras_pos_embd/__init__.py,0,b'from .pos_embd import PositionEmbedding\nfrom .trig_pos_embd import TrigPosEmbedding\n'
keras_bert/keras_pos_embd/pos_embd.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass PositionEmbedding(keras.layers.Layer):\n    """"""Turn integers (positions) into dense vectors of fixed size.\n    eg. [[-4], [10]] -> [[0.25, 0.1], [0.6, -0.2]]\n\n    Expand mode: negative integers (relative position) could be used in this mode.\n        # Input shape\n            2D tensor with shape: `(batch_size, sequence_length)`.\n\n        # Output shape\n            3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n\n    Add mode:\n        # Input shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim)`.\n\n        # Output shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim)`.\n\n    Concat mode:\n        # Input shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim)`.\n\n        # Output shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim + output_dim)`.\n    """"""\n    MODE_EXPAND = \'expand\'\n    MODE_ADD = \'add\'\n    MODE_CONCAT = \'concat\'\n\n    def __init__(self,\n                 input_dim,\n                 output_dim,\n                 mode=MODE_EXPAND,\n                 embeddings_initializer=\'uniform\',\n                 embeddings_regularizer=None,\n                 activity_regularizer=None,\n                 embeddings_constraint=None,\n                 mask_zero=False,\n                 **kwargs):\n        """"""\n        :param input_dim: The maximum absolute value of positions.\n        :param output_dim: The embedding dimension.\n        :param embeddings_initializer:\n        :param embeddings_regularizer:\n        :param activity_regularizer:\n        :param embeddings_constraint:\n        :param mask_zero: The index that represents padding. Only works in `append` mode.\n        :param kwargs:\n        """"""\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.mode = mode\n        self.embeddings_initializer = keras.initializers.get(embeddings_initializer)\n        self.embeddings_regularizer = keras.regularizers.get(embeddings_regularizer)\n        self.activity_regularizer = keras.regularizers.get(activity_regularizer)\n        self.embeddings_constraint = keras.constraints.get(embeddings_constraint)\n        self.mask_zero = mask_zero\n        self.supports_masking = mask_zero is not False\n\n        self.embeddings = None\n        super(PositionEmbedding, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = {\'input_dim\': self.input_dim,\n                  \'output_dim\': self.output_dim,\n                  \'mode\': self.mode,\n                  \'embeddings_initializer\': keras.initializers.serialize(self.embeddings_initializer),\n                  \'embeddings_regularizer\': keras.regularizers.serialize(self.embeddings_regularizer),\n                  \'activity_regularizer\': keras.regularizers.serialize(self.activity_regularizer),\n                  \'embeddings_constraint\': keras.constraints.serialize(self.embeddings_constraint),\n                  \'mask_zero\': self.mask_zero}\n        base_config = super(PositionEmbedding, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def build(self, input_shape):\n        if self.mode == self.MODE_EXPAND:\n            self.embeddings = self.add_weight(\n                shape=(self.input_dim * 2 + 1, self.output_dim),\n                initializer=self.embeddings_initializer,\n                name=\'embeddings\',\n                regularizer=self.embeddings_regularizer,\n                constraint=self.embeddings_constraint,\n            )\n        else:\n            self.embeddings = self.add_weight(\n                shape=(self.input_dim, self.output_dim),\n                initializer=self.embeddings_initializer,\n                name=\'embeddings\',\n                regularizer=self.embeddings_regularizer,\n                constraint=self.embeddings_constraint,\n            )\n        super(PositionEmbedding, self).build(input_shape)\n\n    def compute_mask(self, inputs, mask=None):\n        if self.mode == self.MODE_EXPAND:\n            if self.mask_zero:\n                output_mask = K.not_equal(inputs, self.mask_zero)\n            else:\n                output_mask = None\n        else:\n            output_mask = mask\n        return output_mask\n\n    def compute_output_shape(self, input_shape):\n        if self.mode == self.MODE_EXPAND:\n            return input_shape + (self.output_dim,)\n        if self.mode == self.MODE_CONCAT:\n            return input_shape[:-1] + (input_shape[-1] + self.output_dim,)\n        return input_shape\n\n    def call(self, inputs, **kwargs):\n        if self.mode == self.MODE_EXPAND:\n            if K.dtype(inputs) != \'int32\':\n                inputs = K.cast(inputs, \'int32\')\n            return K.gather(\n                self.embeddings,\n                K.minimum(K.maximum(inputs, -self.input_dim), self.input_dim) + self.input_dim,\n            )\n        input_shape = K.shape(inputs)\n        if self.mode == self.MODE_ADD:\n            batch_size, seq_len, output_dim = input_shape[0], input_shape[1], input_shape[2]\n        else:\n            batch_size, seq_len, output_dim = input_shape[0], input_shape[1], self.output_dim\n        pos_embeddings = K.tile(\n            K.expand_dims(self.embeddings[:seq_len, :self.output_dim], axis=0),\n            [batch_size, 1, 1],\n        )\n        if self.mode == self.MODE_ADD:\n            return inputs + pos_embeddings\n        return K.concatenate([inputs, pos_embeddings], axis=-1)\n'"
keras_bert/keras_pos_embd/trig_pos_embd.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass TrigPosEmbedding(keras.layers.Layer):\n    """"""Position embedding use sine and cosine functions.\n\n    See: https://arxiv.org/pdf/1706.03762\n\n    Expand mode:\n        # Input shape\n            2D tensor with shape: `(batch_size, sequence_length)`.\n\n        # Output shape\n            3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n\n    Add mode:\n        # Input shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim)`.\n\n        # Output shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim)`.\n\n    Concat mode:\n        # Input shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim)`.\n\n        # Output shape\n            3D tensor with shape: `(batch_size, sequence_length, feature_dim + output_dim)`.\n    """"""\n    MODE_EXPAND = \'expand\'\n    MODE_ADD = \'add\'\n    MODE_CONCAT = \'concat\'\n\n    def __init__(self,\n                 mode=MODE_ADD,\n                 output_dim=None,\n                 **kwargs):\n        """"""\n        :param output_dim: The embedding dimension.\n        :param kwargs:\n        """"""\n        if mode in [self.MODE_EXPAND, self.MODE_CONCAT]:\n            if output_dim is None:\n                raise NotImplementedError(\'`output_dim` is required in `%s` mode\' % mode)\n            if output_dim % 2 != 0:\n                raise NotImplementedError(\'It does not make sense to use an odd output dimension: %d\' % output_dim)\n        self.mode = mode\n        self.output_dim = output_dim\n        self.supports_masking = True\n        super(TrigPosEmbedding, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = {\n            \'mode\': self.mode,\n            \'output_dim\': self.output_dim,\n        }\n        base_config = super(TrigPosEmbedding, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_mask(self, inputs, mask=None):\n        return mask\n\n    def compute_output_shape(self, input_shape):\n        if self.mode == self.MODE_EXPAND:\n            return input_shape + (self.output_dim,)\n        if self.mode == self.MODE_CONCAT:\n            return input_shape[:-1] + (input_shape[-1] + self.output_dim,)\n        return input_shape\n\n    def call(self, inputs, mask=None):\n        input_shape = K.shape(inputs)\n        if self.mode == self.MODE_ADD:\n            batch_size, seq_len, output_dim = input_shape[0], input_shape[1], input_shape[2]\n            pos_input = K.tile(K.expand_dims(K.arange(seq_len), axis=0), [batch_size, 1])\n        elif self.mode == self.MODE_CONCAT:\n            batch_size, seq_len, output_dim = input_shape[0], input_shape[1], self.output_dim\n            pos_input = K.tile(K.expand_dims(K.arange(seq_len), axis=0), [batch_size, 1])\n        else:\n            output_dim = self.output_dim\n            pos_input = inputs\n        if K.dtype(pos_input) != K.floatx():\n            pos_input = K.cast(pos_input, K.floatx())\n        evens = K.arange(output_dim // 2) * 2\n        odds = K.arange(output_dim // 2) * 2 + 1\n        even_embd = K.sin(\n            K.dot(\n                K.expand_dims(pos_input, -1),\n                K.expand_dims(1.0 / K.pow(\n                    10000.0,\n                    K.cast(evens, K.floatx()) / K.cast(output_dim, K.floatx())\n                ), 0)\n            )\n        )\n        odd_embd = K.cos(\n            K.dot(\n                K.expand_dims(pos_input, -1),\n                K.expand_dims(1.0 / K.pow(\n                    10000.0, K.cast((odds - 1), K.floatx()) / K.cast(output_dim, K.floatx())\n                ), 0)\n            )\n        )\n        embd = K.stack([even_embd, odd_embd], axis=-1)\n        output = K.reshape(embd, [-1, K.shape(inputs)[1], output_dim])\n        if self.mode == self.MODE_CONCAT:\n            output = K.concatenate([inputs, output], axis=-1)\n        if self.mode == self.MODE_ADD:\n            output += inputs\n        return output\n'"
keras_bert/keras_position_wise_feed_forward/__init__.py,0,b'from .feed_forward import FeedForward\n'
keras_bert/keras_position_wise_feed_forward/feed_forward.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass FeedForward(keras.layers.Layer):\n    """"""Position-wise feed-forward layer.\n\n    See: https://arxiv.org/pdf/1706.03762.pdf\n    """"""\n\n    def __init__(self,\n                 units,\n                 activation=\'relu\',\n                 use_bias=True,\n                 kernel_initializer=\'glorot_normal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        """"""Initialize the layer.\n\n        :param units: Dimension of hidden units.\n        :param activation: Activation for the first linear transformation.\n        :param use_bias: Whether to use the bias term.\n        :param kernel_initializer: Initializer for kernels.\n        :param bias_initializer: Initializer for kernels.\n        :param kernel_regularizer: Regularizer for kernels.\n        :param bias_regularizer: Regularizer for kernels.\n        :param kernel_constraint: Constraint for kernels.\n        :param bias_constraint: Constraint for kernels.\n        :param kwargs:\n        """"""\n        self.supports_masking = True\n        self.units = units\n        self.activation = keras.activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n        self.bias_initializer = keras.initializers.get(bias_initializer)\n        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n        self.bias_constraint = keras.constraints.get(bias_constraint)\n        self.W1, self.b1 = None, None\n        self.W2, self.b2 = None, None\n        super(FeedForward, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = {\n            \'units\': self.units,\n            \'activation\': keras.activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': keras.initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': keras.initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': keras.regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': keras.regularizers.serialize(self.bias_regularizer),\n            \'kernel_constraint\': keras.constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': keras.constraints.serialize(self.bias_constraint),\n        }\n        base_config = super(FeedForward, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n    def compute_mask(self, inputs, input_mask=None):\n        return input_mask\n\n    def build(self, input_shape):\n        feature_dim = input_shape[-1]\n        self.W1 = self.add_weight(\n            shape=(feature_dim, self.units),\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            name=\'{}_W1\'.format(self.name),\n        )\n        if self.use_bias:\n            self.b1 = self.add_weight(\n                shape=(self.units,),\n                initializer=self.bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                name=\'{}_b1\'.format(self.name),\n            )\n        self.W2 = self.add_weight(\n            shape=(self.units, feature_dim),\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            name=\'{}_W2\'.format(self.name),\n        )\n        if self.use_bias:\n            self.b2 = self.add_weight(\n                shape=(feature_dim,),\n                initializer=self.bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                name=\'{}_b2\'.format(self.name),\n            )\n        super(FeedForward, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        h = K.dot(x, self.W1)\n        if self.use_bias:\n            h = K.bias_add(h, self.b1)\n        if self.activation is not None:\n            h = self.activation(h)\n        y = K.dot(h, self.W2)\n        if self.use_bias:\n            y = K.bias_add(y, self.b2)\n        return y\n'"
keras_bert/keras_self_attention/__init__.py,0,b'from .seq_self_attention import SeqSelfAttention\nfrom .seq_weighted_attention import SeqWeightedAttention\nfrom .scaled_dot_attention import ScaledDotProductAttention\n'
keras_bert/keras_self_attention/scaled_dot_attention.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass ScaledDotProductAttention(keras.layers.Layer):\n    """"""The attention layer that takes three inputs representing queries, keys and values.\n\n    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n\n    See: https://arxiv.org/pdf/1706.03762.pdf\n    """"""\n\n    def __init__(self,\n                 return_attention=False,\n                 history_only=False,\n                 **kwargs):\n        """"""Initialize the layer.\n\n        :param return_attention: Whether to return attention weights.\n        :param history_only: Whether to only use history data.\n        :param kwargs: Arguments for parent class.\n        """"""\n        self.supports_masking = True\n        self.return_attention = return_attention\n        self.history_only = history_only\n        super(ScaledDotProductAttention, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = {\n            \'return_attention\': self.return_attention,\n            \'history_only\': self.history_only,\n        }\n        base_config = super(ScaledDotProductAttention, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            query_shape, key_shape, value_shape = input_shape\n        else:\n            query_shape = key_shape = value_shape = input_shape\n        output_shape = query_shape[:-1] + value_shape[-1:]\n        if self.return_attention:\n            attention_shape = query_shape[:2] + (key_shape[1],)\n            return [output_shape, attention_shape]\n        return output_shape\n\n    def compute_mask(self, inputs, mask=None):\n        if isinstance(mask, list):\n            mask = mask[0]\n        if self.return_attention:\n            return [mask, None]\n        return mask\n\n    def call(self, inputs, mask=None, **kwargs):\n        if isinstance(inputs, list):\n            query, key, value = inputs\n        else:\n            query = key = value = inputs\n        if isinstance(mask, list):\n            mask = mask[1]\n        feature_dim = K.shape(query)[-1]\n        e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(feature_dim, dtype=K.floatx()))\n        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n        if self.history_only:\n            query_len, key_len = K.shape(query)[1], K.shape(key)[1]\n            indices = K.tile(K.expand_dims(K.arange(key_len), axis=0), [query_len, 1])\n            upper = K.expand_dims(K.arange(key_len), axis=-1)\n            e *= K.expand_dims(K.cast(indices <= upper, K.floatx()), axis=0)\n        if mask is not None:\n            e *= K.cast(K.expand_dims(mask, axis=-2), K.floatx())\n        a = e / (K.sum(e, axis=-1, keepdims=True) + K.epsilon())\n        v = K.batch_dot(a, value)\n        if self.return_attention:\n            return [v, a]\n        return v\n'"
keras_bert/keras_self_attention/seq_self_attention.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\n\n\nclass SeqSelfAttention(keras.layers.Layer):\n\n    ATTENTION_TYPE_ADD = \'additive\'\n    ATTENTION_TYPE_MUL = \'multiplicative\'\n\n    def __init__(self,\n                 units=32,\n                 attention_width=None,\n                 attention_type=ATTENTION_TYPE_ADD,\n                 return_attention=False,\n                 history_only=False,\n                 kernel_initializer=\'glorot_normal\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 use_additive_bias=True,\n                 use_attention_bias=True,\n                 attention_activation=None,\n                 attention_regularizer_weight=0.0,\n                 **kwargs):\n        """"""Layer initialization.\n\n        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n\n        :param units: The dimension of the vectors that used to calculate the attention weights.\n        :param attention_width: The width of local attention.\n        :param attention_type: \'additive\' or \'multiplicative\'.\n        :param return_attention: Whether to return the attention weights for visualization.\n        :param history_only: Only use historical pieces of data.\n        :param kernel_initializer: The initializer for weight matrices.\n        :param bias_initializer: The initializer for biases.\n        :param kernel_regularizer: The regularization for weight matrices.\n        :param bias_regularizer: The regularization for biases.\n        :param kernel_constraint: The constraint for weight matrices.\n        :param bias_constraint: The constraint for biases.\n        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n                                  in additive mode.\n        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n        :param attention_activation: The activation used for calculating the weights of attention.\n        :param attention_regularizer_weight: The weights of attention regularizer.\n        :param kwargs: Parameters for parent class.\n        """"""\n        self.supports_masking = True\n        self.units = units\n        self.attention_width = attention_width\n        self.attention_type = attention_type\n        self.return_attention = return_attention\n        self.history_only = history_only\n        if history_only and attention_width is None:\n            self.attention_width = int(1e9)\n\n        self.use_additive_bias = use_additive_bias\n        self.use_attention_bias = use_attention_bias\n        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n        self.bias_initializer = keras.initializers.get(bias_initializer)\n        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n        self.bias_constraint = keras.constraints.get(bias_constraint)\n        self.attention_activation = keras.activations.get(attention_activation)\n        self.attention_regularizer_weight = attention_regularizer_weight\n        self._backend = keras.backend.backend()\n\n        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n            self.Wx, self.Wt, self.bh = None, None, None\n            self.Wa, self.ba = None, None\n        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n            self.Wa, self.ba = None, None\n        else:\n            raise NotImplementedError(\'No implementation for attention type : \' + attention_type)\n\n        super(SeqSelfAttention, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = {\n            \'units\': self.units,\n            \'attention_width\': self.attention_width,\n            \'attention_type\': self.attention_type,\n            \'return_attention\': self.return_attention,\n            \'history_only\': self.history_only,\n            \'use_additive_bias\': self.use_additive_bias,\n            \'use_attention_bias\': self.use_attention_bias,\n            \'kernel_initializer\': keras.regularizers.serialize(self.kernel_initializer),\n            \'bias_initializer\': keras.regularizers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': keras.regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': keras.regularizers.serialize(self.bias_regularizer),\n            \'kernel_constraint\': keras.constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': keras.constraints.serialize(self.bias_constraint),\n            \'attention_activation\': keras.activations.serialize(self.attention_activation),\n            \'attention_regularizer_weight\': self.attention_regularizer_weight,\n        }\n        base_config = super(SeqSelfAttention, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n            self._build_additive_attention(input_shape)\n        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n            self._build_multiplicative_attention(input_shape)\n        super(SeqSelfAttention, self).build(input_shape)\n\n    def _build_additive_attention(self, input_shape):\n        feature_dim = input_shape[2]\n\n        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n                                  name=\'{}_Add_Wt\'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n                                  name=\'{}_Add_Wx\'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        if self.use_additive_bias:\n            self.bh = self.add_weight(shape=(self.units,),\n                                      name=\'{}_Add_bh\'.format(self.name),\n                                      initializer=self.bias_initializer,\n                                      regularizer=self.bias_regularizer,\n                                      constraint=self.bias_constraint)\n\n        self.Wa = self.add_weight(shape=(self.units, 1),\n                                  name=\'{}_Add_Wa\'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        if self.use_attention_bias:\n            self.ba = self.add_weight(shape=(1,),\n                                      name=\'{}_Add_ba\'.format(self.name),\n                                      initializer=self.bias_initializer,\n                                      regularizer=self.bias_regularizer,\n                                      constraint=self.bias_constraint)\n\n    def _build_multiplicative_attention(self, input_shape):\n        feature_dim = input_shape[2]\n\n        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n                                  name=\'{}_Mul_Wa\'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        if self.use_attention_bias:\n            self.ba = self.add_weight(shape=(1,),\n                                      name=\'{}_Mul_ba\'.format(self.name),\n                                      initializer=self.bias_initializer,\n                                      regularizer=self.bias_regularizer,\n                                      constraint=self.bias_constraint)\n\n    def call(self, inputs, mask=None, **kwargs):\n        input_len = K.shape(inputs)[1]\n\n        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n            e = self._call_additive_emission(inputs)\n        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n            e = self._call_multiplicative_emission(inputs)\n\n        if self.attention_activation is not None:\n            e = self.attention_activation(e)\n        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n        if self.attention_width is not None:\n            if self.history_only:\n                lower = K.arange(input_len) - (self.attention_width - 1)\n            else:\n                lower = K.arange(input_len) - self.attention_width // 2\n            lower = K.expand_dims(lower, axis=-1)\n            upper = lower + self.attention_width\n            indices = K.tile(K.expand_dims(K.arange(input_len), axis=0), [input_len, 1])\n            e = e * K.cast(lower <= indices, K.floatx()) * K.cast(indices < upper, K.floatx())\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            mask = K.expand_dims(mask)\n            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n\n        # a_{t} = \\text{softmax}(e_t)\n        s = K.sum(e, axis=-1, keepdims=True)\n        a = e / (s + K.epsilon())\n\n        # l_t = \\sum_{t\'} a_{t, t\'} x_{t\'}\n        v = K.batch_dot(a, inputs)\n        if self.attention_regularizer_weight > 0.0:\n            self.add_loss(self._attention_regularizer(a))\n\n        if self.return_attention:\n            return [v, a]\n        return v\n\n    def _call_additive_emission(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size, input_len = input_shape[0], input_shape[1]\n\n        # h_{t, t\'} = \\tanh(x_t^T W_t + x_{t\'}^T W_x + b_h)\n        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n        q = K.tile(K.expand_dims(q, 2), [1, 1, input_len, 1])\n        k = K.tile(K.expand_dims(k, 1), [1, input_len, 1, 1])\n        if self.use_additive_bias:\n            h = K.tanh(q + k + self.bh)\n        else:\n            h = K.tanh(q + k)\n\n        # e_{t, t\'} = W_a h_{t, t\'} + b_a\n        if self.use_attention_bias:\n            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n        else:\n            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n        return e\n\n    def _call_multiplicative_emission(self, inputs):\n        # e_{t, t\'} = x_t^T W_a x_{t\'} + b_a\n        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n        if self.use_attention_bias:\n            e = e + self.ba\n        return e\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape, pos_shape = input_shape\n            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n        else:\n            output_shape = input_shape\n        if self.return_attention:\n            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n            return [output_shape, attention_shape]\n        return output_shape\n\n    def compute_mask(self, inputs, mask=None):\n        if isinstance(inputs, list):\n            mask = mask[1]\n        if self.return_attention:\n            return [mask, None]\n        return mask\n\n    def _attention_regularizer(self, attention):\n        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n        input_len = K.shape(attention)[-1]\n        indices = K.tile(K.expand_dims(K.arange(input_len), axis=0), [input_len, 1])\n        diagonal = K.expand_dims(K.arange(input_len), axis=-1)\n        eye = K.cast(K.equal(indices, diagonal), K.floatx())\n        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n            attention,\n            K.permute_dimensions(attention, (0, 2, 1))) - eye)) / batch_size\n\n    @staticmethod\n    def get_custom_objects():\n        return {\'SeqSelfAttention\': SeqSelfAttention}\n'"
keras_bert/keras_self_attention/seq_weighted_attention.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass SeqWeightedAttention(keras.layers.Layer):\n    """"""Y = \\text{softmax}(XW + b) X\n\n    See: https://arxiv.org/pdf/1708.00524.pdf\n    """"""\n\n    def __init__(self, use_bias=True, return_attention=False, **kwargs):\n        self.supports_masking = True\n        self.use_bias = use_bias\n        self.return_attention = return_attention\n        self.W, self.b = None, None\n        super(SeqWeightedAttention, self).__init__(** kwargs)\n\n    def get_config(self):\n        config = {\n            \'use_bias\': self.use_bias,\n            \'return_attention\': self.return_attention,\n        }\n        base_config = super(SeqWeightedAttention, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def build(self, input_shape):\n        self.W = self.add_weight(shape=(input_shape[2], 1),\n                                 name=\'{}_W\'.format(self.name),\n                                 initializer=keras.initializers.get(\'uniform\'))\n        if self.use_bias:\n            self.b = self.add_weight(shape=(1,),\n                                     name=\'{}_b\'.format(self.name),\n                                     initializer=keras.initializers.get(\'zeros\'))\n        super(SeqWeightedAttention, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        logits = K.dot(x, self.W)\n        if self.use_bias:\n            logits += self.b\n        x_shape = K.shape(x)\n        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            ai = ai * mask\n        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n        weighted_input = x * K.expand_dims(att_weights)\n        result = K.sum(weighted_input, axis=1)\n        if self.return_attention:\n            return [result, att_weights]\n        return result\n\n    def compute_output_shape(self, input_shape):\n        output_len = input_shape[2]\n        if self.return_attention:\n            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n        return input_shape[0], output_len\n\n    def compute_mask(self, _, input_mask=None):\n        if self.return_attention:\n            return [None, None]\n        return None\n\n    @staticmethod\n    def get_custom_objects():\n        return {\'SeqWeightedAttention\': SeqWeightedAttention}\n'"
keras_bert/keras_transformer/__init__.py,0,b'from .gelu import gelu\nfrom .transformer import *\n'
keras_bert/keras_transformer/gelu.py,0,"b'import math\nimport tensorflow.keras.backend as K\n\n\ndef gelu(x):\n    """"""An approximation of gelu.\n\n    See: https://arxiv.org/pdf/1606.08415.pdf\n    """"""\n    return 0.5 * x * (1.0 + K.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * K.pow(x, 3))))\n'"
keras_bert/keras_transformer/transformer.py,0,"b'from tensorflow import keras\nimport numpy as np\nfrom ..keras_layer_normalization import LayerNormalization\nfrom ..keras_multi_head import MultiHeadAttention\nfrom ..keras_position_wise_feed_forward import FeedForward\nfrom ..keras_pos_embd import TrigPosEmbedding\nfrom ..keras_embed_sim import EmbeddingRet, EmbeddingSim\n\n\n__all__ = [\n    \'get_custom_objects\', \'get_encoders\', \'get_decoders\', \'get_model\', \'decode\',\n    \'attention_builder\', \'feed_forward_builder\', \'get_encoder_component\', \'get_decoder_component\',\n]\n\n\ndef get_custom_objects():\n    return {\n        \'LayerNormalization\': LayerNormalization,\n        \'MultiHeadAttention\': MultiHeadAttention,\n        \'FeedForward\': FeedForward,\n        \'TrigPosEmbedding\': TrigPosEmbedding,\n        \'EmbeddingRet\': EmbeddingRet,\n        \'EmbeddingSim\': EmbeddingSim,\n    }\n\n\ndef _wrap_layer(name, input_layer, build_func, dropout_rate=0.0, trainable=True):\n    """"""Wrap layers with residual, normalization and dropout.\n\n    :param name: Prefix of names for internal layers.\n    :param input_layer: Input layer.\n    :param build_func: A callable that takes the input tensor and generates the output tensor.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    """"""\n    build_output = build_func(input_layer)\n    if dropout_rate > 0.0:\n        dropout_layer = keras.layers.Dropout(\n            rate=dropout_rate,\n            name=\'%s-Dropout\' % name,\n        )(build_output)\n    else:\n        dropout_layer = build_output\n    if isinstance(input_layer, list):\n        input_layer = input_layer[0]\n    add_layer = keras.layers.Add(name=\'%s-Add\' %\n                                 name)([input_layer, dropout_layer])\n    normal_layer = LayerNormalization(\n        trainable=trainable,\n        name=\'%s-Norm\' % name,\n    )(add_layer)\n    return normal_layer\n\n\ndef attention_builder(name, head_num, activation, history_only, trainable=True):\n    """"""Get multi-head self-attention builder.\n\n    :param name: Prefix of names for internal layers.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param activation: Activation for multi-head self-attention.\n    :param history_only: Only use history data.\n    :param trainable: Whether the layer is trainable.\n    :return:\n    """"""\n    def _attention_builder(x):\n        return MultiHeadAttention(\n            head_num=head_num,\n            activation=activation,\n            history_only=history_only,\n            trainable=trainable,\n            name=name,\n        )(x)\n    return _attention_builder\n\n\ndef feed_forward_builder(name, hidden_dim, activation, trainable=True):\n    """"""Get position-wise feed-forward layer builder.\n\n    :param name: Prefix of names for internal layers.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param activation: Activation for feed-forward layer.\n    :param trainable: Whether the layer is trainable.\n    :return:\n    """"""\n    def _feed_forward_builder(x):\n        return FeedForward(\n            units=hidden_dim,\n            activation=activation,\n            trainable=trainable,\n            name=name,\n        )(x)\n    return _feed_forward_builder\n\n\ndef get_encoder_component(name,\n                          input_layer,\n                          head_num,\n                          hidden_dim,\n                          attention_activation=None,\n                          feed_forward_activation=\'relu\',\n                          dropout_rate=0.0,\n                          trainable=True):\n    """"""Multi-head self-attention and feed-forward layer.\n\n    :param name: Prefix of names for internal layers.\n    :param input_layer: Input layer.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    """"""\n    attention_name = \'%s-MultiHeadSelfAttention\' % name\n    feed_forward_name = \'%s-FeedForward\' % name\n    attention_layer = _wrap_layer(\n        name=attention_name,\n        input_layer=input_layer,\n        build_func=attention_builder(\n            name=attention_name,\n            head_num=head_num,\n            activation=attention_activation,\n            history_only=False,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    feed_forward_layer = _wrap_layer(\n        name=feed_forward_name,\n        input_layer=attention_layer,\n        build_func=feed_forward_builder(\n            name=feed_forward_name,\n            hidden_dim=hidden_dim,\n            activation=feed_forward_activation,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    return feed_forward_layer\n\n\ndef get_decoder_component(name,\n                          input_layer,\n                          encoded_layer,\n                          head_num,\n                          hidden_dim,\n                          attention_activation=None,\n                          feed_forward_activation=\'relu\',\n                          dropout_rate=0.0,\n                          trainable=True):\n    """"""Multi-head self-attention, multi-head query attention and feed-forward layer.\n\n    :param name: Prefix of names for internal layers.\n    :param input_layer: Input layer.\n    :param encoded_layer: Encoded layer from encoder.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    """"""\n    self_attention_name = \'%s-MultiHeadSelfAttention\' % name\n    query_attention_name = \'%s-MultiHeadQueryAttention\' % name\n    feed_forward_name = \'%s-FeedForward\' % name\n    self_attention_layer = _wrap_layer(\n        name=self_attention_name,\n        input_layer=input_layer,\n        build_func=attention_builder(\n            name=self_attention_name,\n            head_num=head_num,\n            activation=attention_activation,\n            history_only=True,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    query_attention_layer = _wrap_layer(\n        name=query_attention_name,\n        input_layer=[self_attention_layer, encoded_layer, encoded_layer],\n        build_func=attention_builder(\n            name=query_attention_name,\n            head_num=head_num,\n            activation=attention_activation,\n            history_only=False,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    feed_forward_layer = _wrap_layer(\n        name=feed_forward_name,\n        input_layer=query_attention_layer,\n        build_func=feed_forward_builder(\n            name=feed_forward_name,\n            hidden_dim=hidden_dim,\n            activation=feed_forward_activation,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    return feed_forward_layer\n\n\ndef get_encoders(encoder_num,\n                 input_layer,\n                 head_num,\n                 hidden_dim,\n                 attention_activation=None,\n                 feed_forward_activation=\'relu\',\n                 dropout_rate=0.0,\n                 trainable=True):\n    """"""Get encoders.\n\n    :param encoder_num: Number of encoder components.\n    :param input_layer: Input layer.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    """"""\n    last_layer = input_layer\n    for i in range(encoder_num):\n        last_layer = get_encoder_component(\n            name=\'Encoder-%d\' % (i + 1),\n            input_layer=last_layer,\n            head_num=head_num,\n            hidden_dim=hidden_dim,\n            attention_activation=attention_activation,\n            feed_forward_activation=feed_forward_activation,\n            dropout_rate=dropout_rate,\n            trainable=trainable,\n        )\n    return last_layer\n\n\ndef get_decoders(decoder_num,\n                 input_layer,\n                 encoded_layer,\n                 head_num,\n                 hidden_dim,\n                 attention_activation=None,\n                 feed_forward_activation=\'relu\',\n                 dropout_rate=0.0,\n                 trainable=True):\n    """"""Get decoders.\n\n    :param decoder_num: Number of decoder components.\n    :param input_layer: Input layer.\n    :param encoded_layer: Encoded layer from encoder.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    """"""\n    last_layer = input_layer\n    for i in range(decoder_num):\n        last_layer = get_decoder_component(\n            name=\'Decoder-%d\' % (i + 1),\n            input_layer=last_layer,\n            encoded_layer=encoded_layer,\n            head_num=head_num,\n            hidden_dim=hidden_dim,\n            attention_activation=attention_activation,\n            feed_forward_activation=feed_forward_activation,\n            dropout_rate=dropout_rate,\n            trainable=trainable,\n        )\n    return last_layer\n\n\ndef get_model(token_num,\n              embed_dim,\n              encoder_num,\n              decoder_num,\n              head_num,\n              hidden_dim,\n              attention_activation=None,\n              feed_forward_activation=\'relu\',\n              dropout_rate=0.0,\n              use_same_embed=True,\n              embed_weights=None,\n              embed_trainable=None,\n              trainable=True):\n    """"""Get full model without compilation.\n\n    :param token_num: Number of distinct tokens.\n    :param embed_dim: Dimension of token embedding.\n    :param encoder_num: Number of encoder components.\n    :param decoder_num: Number of decoder components.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param use_same_embed: Whether to use the same token embedding layer. `token_num`, `embed_weights` and\n                           `embed_trainable` should be lists of two elements if it is False.\n    :param embed_weights: Initial weights of token embedding.\n    :param embed_trainable: Whether the token embedding is trainable. It will automatically set to False if the given\n                            value is None when embedding weights has been provided.\n    :param trainable: Whether the layers are trainable.\n    :return: Keras model.\n    """"""\n    if not isinstance(token_num, list):\n        token_num = [token_num, token_num]\n    encoder_token_num, decoder_token_num = token_num\n\n    if not isinstance(embed_weights, list):\n        embed_weights = [embed_weights, embed_weights]\n    encoder_embed_weights, decoder_embed_weights = embed_weights\n    if encoder_embed_weights is not None:\n        encoder_embed_weights = [encoder_embed_weights]\n    if decoder_embed_weights is not None:\n        decoder_embed_weights = [decoder_embed_weights]\n\n    if not isinstance(embed_trainable, list):\n        embed_trainable = [embed_trainable, embed_trainable]\n    encoder_embed_trainable, decoder_embed_trainable = embed_trainable\n    if encoder_embed_trainable is None:\n        encoder_embed_trainable = encoder_embed_weights is None\n    if decoder_embed_trainable is None:\n        decoder_embed_trainable = decoder_embed_weights is None\n\n    if use_same_embed:\n        encoder_embed_layer = decoder_embed_layer = EmbeddingRet(\n            input_dim=encoder_token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            weights=encoder_embed_weights,\n            trainable=encoder_embed_trainable,\n            name=\'Token-Embedding\',\n        )\n    else:\n        encoder_embed_layer = EmbeddingRet(\n            input_dim=encoder_token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            weights=encoder_embed_weights,\n            trainable=encoder_embed_trainable,\n            name=\'Encoder-Token-Embedding\',\n        )\n        decoder_embed_layer = EmbeddingRet(\n            input_dim=decoder_token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            weights=decoder_embed_weights,\n            trainable=decoder_embed_trainable,\n            name=\'Decoder-Token-Embedding\',\n        )\n    encoder_input = keras.layers.Input(shape=(None,), name=\'Encoder-Input\')\n    encoder_embed = TrigPosEmbedding(\n        mode=TrigPosEmbedding.MODE_ADD,\n        name=\'Encoder-Embedding\',\n    )(encoder_embed_layer(encoder_input)[0])\n    encoded_layer = get_encoders(\n        encoder_num=encoder_num,\n        input_layer=encoder_embed,\n        head_num=head_num,\n        hidden_dim=hidden_dim,\n        attention_activation=attention_activation,\n        feed_forward_activation=feed_forward_activation,\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    decoder_input = keras.layers.Input(shape=(None,), name=\'Decoder-Input\')\n    decoder_embed, decoder_embed_weights = decoder_embed_layer(decoder_input)\n    decoder_embed = TrigPosEmbedding(\n        mode=TrigPosEmbedding.MODE_ADD,\n        name=\'Decoder-Embedding\',\n    )(decoder_embed)\n    decoded_layer = get_decoders(\n        decoder_num=decoder_num,\n        input_layer=decoder_embed,\n        encoded_layer=encoded_layer,\n        head_num=head_num,\n        hidden_dim=hidden_dim,\n        attention_activation=attention_activation,\n        feed_forward_activation=feed_forward_activation,\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    dense_layer = EmbeddingSim(\n        trainable=trainable,\n        name=\'Output\',\n    )([decoded_layer, decoder_embed_weights])\n    return keras.models.Model(inputs=[encoder_input, decoder_input], outputs=dense_layer)\n\n\ndef _get_max_suffix_repeat_times(tokens, max_len):\n    detect_len = min(max_len, len(tokens))\n    next = [-1] * detect_len\n    k = -1\n    for i in range(1, detect_len):\n        while k >= 0 and tokens[len(tokens) - i - 1] != tokens[len(tokens) - k - 2]:\n            k = next[k]\n        if tokens[len(tokens) - i - 1] == tokens[len(tokens) - k - 2]:\n            k += 1\n        next[i] = k\n    max_repeat = 1\n    for i in range(2, detect_len):\n        if next[i] >= 0 and (i + 1) % (i - next[i]) == 0:\n            max_repeat = max(max_repeat, (i + 1) // (i - next[i]))\n    return max_repeat\n\n\ndef decode(model, tokens, start_token, end_token, pad_token, max_len=10000, max_repeat=10, max_repeat_block=10):\n    """"""Decode with the given model and input tokens.\n\n    :param model: The trained model.\n    :param tokens: The input tokens of encoder.\n    :param start_token: The token that represents the start of a sentence.\n    :param end_token: The token that represents the end of a sentence.\n    :param pad_token: The token that represents padding.\n    :param max_len: Maximum length of decoded list.\n    :param max_repeat: Maximum number of repeating blocks.\n    :param max_repeat_block: Maximum length of the repeating block.\n    :return: Decoded tokens.\n    """"""\n    is_single = not isinstance(tokens[0], list)\n    if is_single:\n        tokens = [tokens]\n    batch_size = len(tokens)\n    decoder_inputs = [[start_token] for _ in range(batch_size)]\n    outputs = [None for _ in range(batch_size)]\n    output_len = 1\n    while len(list(filter(lambda x: x is None, outputs))) > 0:\n        output_len += 1\n        batch_inputs, batch_outputs = [], []\n        max_input_len = 0\n        index_map = {}\n        for i in range(batch_size):\n            if outputs[i] is None:\n                index_map[len(batch_inputs)] = i\n                batch_inputs.append(tokens[i][:])\n                batch_outputs.append(decoder_inputs[i])\n                max_input_len = max(max_input_len, len(tokens[i]))\n        for i in range(len(batch_inputs)):\n            batch_inputs[i] += [pad_token] * \\\n                (max_input_len - len(batch_inputs[i]))\n        predicts = model.predict(\n            [np.asarray(batch_inputs), np.asarray(batch_outputs)])\n        for i in range(len(predicts)):\n            last_token = np.argmax(predicts[i][-1])\n            decoder_inputs[index_map[i]].append(last_token)\n            if last_token == end_token or\\\n                    (max_len is not None and output_len >= max_len) or\\\n                    _get_max_suffix_repeat_times(decoder_inputs, max_repeat * max_repeat_block) >= max_repeat:\n                outputs[index_map[i]] = decoder_inputs[index_map[i]]\n    if is_single:\n        outputs = outputs[0]\n    return outputs\n'"
keras_bert/layers/__init__.py,0,"b'from .inputs import get_inputs\nfrom .embedding import get_embedding, TokenEmbedding, EmbeddingSimilarity\nfrom .masked import Masked\nfrom .extract import Extract\nfrom .pooling import MaskedGlobalMaxPool1D\nfrom .conv import MaskedConv1D\n'"
keras_bert/layers/conv.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass MaskedConv1D(keras.layers.Conv1D):\n\n    def __init__(self, **kwargs):\n        super(MaskedConv1D, self).__init__(**kwargs)\n        self.supports_masking = True\n\n    def compute_mask(self, inputs, mask=None):\n        return mask\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            inputs *= K.expand_dims(mask, axis=-1)\n        return super(MaskedConv1D, self).call(inputs)\n'"
keras_bert/layers/embedding.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom ..keras_pos_embd import PositionEmbedding\nfrom ..keras_layer_normalization import LayerNormalization\n\n\nclass TokenEmbedding(keras.layers.Embedding):\n    """"""Embedding layer with weights returned.""""""\n\n    def compute_output_shape(self, input_shape):\n        return [super(TokenEmbedding, self).compute_output_shape(input_shape), (self.input_dim, self.output_dim)]\n\n    def compute_mask(self, inputs, mask=None):\n        return [super(TokenEmbedding, self).compute_mask(inputs, mask), None]\n\n    def call(self, inputs):\n        return [super(TokenEmbedding, self).call(inputs), self.embeddings]\n\n\ndef get_embedding(inputs, token_num, pos_num, embed_dim, dropout_rate=0.1, trainable=True):\n    """"""Get embedding layer.\n\n    See: https://arxiv.org/pdf/1810.04805.pdf\n\n    :param inputs: Input layers.\n    :param token_num: Number of tokens.\n    :param pos_num: Maximum position.\n    :param embed_dim: The dimension of all embedding layers.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: The merged embedding layer and weights of token embedding.\n    """"""\n    embeddings = [\n        TokenEmbedding(\n            input_dim=token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            trainable=trainable,\n            name=\'Embedding-Token\',\n        )(inputs[0]),\n        keras.layers.Embedding(\n            input_dim=2,\n            output_dim=embed_dim,\n            trainable=trainable,\n            name=\'Embedding-Segment\',\n        )(inputs[1]),\n    ]\n    embeddings[0], embed_weights = embeddings[0]\n    embed_layer = keras.layers.Add(name=\'Embedding-Token-Segment\')(embeddings)\n    embed_layer = PositionEmbedding(\n        input_dim=pos_num,\n        output_dim=embed_dim,\n        mode=PositionEmbedding.MODE_ADD,\n        trainable=trainable,\n        name=\'Embedding-Position\',\n    )(embed_layer)\n    if dropout_rate > 0.0:\n        dropout_layer = keras.layers.Dropout(\n            rate=dropout_rate,\n            name=\'Embedding-Dropout\',\n        )(embed_layer)\n    else:\n        dropout_layer = embed_layer\n    norm_layer = LayerNormalization(\n        trainable=trainable,\n        name=\'Embedding-Norm\',\n    )(dropout_layer)\n    return norm_layer, embed_weights\n\n\nclass EmbeddingSimilarity(keras.layers.Layer):\n    """"""Calculate similarity between features and token embeddings with bias term.""""""\n\n    def __init__(self,\n                 initializer=\'zeros\',\n                 regularizer=None,\n                 constraint=None,\n                 **kwargs):\n        """"""Initialize the layer.\n\n        :param output_dim: Same as embedding output dimension.\n        :param initializer: Initializer for bias.\n        :param regularizer: Regularizer for bias.\n        :param constraint: Constraint for bias.\n        :param kwargs: Arguments for parent class.\n        """"""\n        super(EmbeddingSimilarity, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.initializer = keras.initializers.get(initializer)\n        self.regularizer = keras.regularizers.get(regularizer)\n        self.constraint = keras.constraints.get(constraint)\n        self.bias = None\n\n    def get_config(self):\n        config = {\n            \'initializer\': keras.initializers.serialize(self.initializer),\n            \'regularizer\': keras.regularizers.serialize(self.regularizer),\n            \'constraint\': keras.constraints.serialize(self.constraint),\n        }\n        base_config = super(EmbeddingSimilarity, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def build(self, input_shape):\n        self.bias = self.add_weight(\n            shape=(input_shape[1][0],),\n            initializer=self.initializer,\n            regularizer=self.regularizer,\n            constraint=self.constraint,\n            name=\'bias\',\n        )\n        super(EmbeddingSimilarity, self).build(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0][:2] + (input_shape[1][0],)\n\n    def compute_mask(self, inputs, mask=None):\n        return mask[0]\n\n    def call(self, inputs, mask=None, **kwargs):\n        inputs, embeddings = inputs\n        outputs = K.bias_add(\n            K.dot(inputs, K.transpose(embeddings)), self.bias)\n        return keras.activations.softmax(outputs)\n'"
keras_bert/layers/extract.py,0,"b'from tensorflow import keras\n\n\nclass Extract(keras.layers.Layer):\n    """"""Extract from index.\n\n    See: https://arxiv.org/pdf/1810.04805.pdf\n    """"""\n\n    def __init__(self, index, **kwargs):\n        super(Extract, self).__init__(**kwargs)\n        self.index = index\n        self.supports_masking = True\n\n    def get_config(self):\n        config = {\n            \'index\': self.index,\n        }\n        base_config = super(Extract, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[:1] + input_shape[2:]\n\n    def compute_mask(self, inputs, mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        return x[:, self.index]\n'"
keras_bert/layers/inputs.py,0,"b'from tensorflow import keras\n\n\ndef get_inputs(seq_len):\n    """"""Get input layers.\n\n    See: https://arxiv.org/pdf/1810.04805.pdf\n\n    :param seq_len: Length of the sequence or None.\n    """"""\n    names = [\'Token\', \'Segment\', \'Masked\']\n    return [keras.layers.Input(\n        shape=(None,),\n        name=\'Input-%s\' % name,\n    ) for name in names]\n'"
keras_bert/layers/masked.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass Masked(keras.layers.Layer):\n    """"""Generate output mask based on the given mask.\n\n    The inputs for the layer is the original input layer and the masked locations.\n\n    See: https://arxiv.org/pdf/1810.04805.pdf\n    """"""\n\n    def __init__(self,\n                 return_masked=False,\n                 **kwargs):\n        """"""Initialize the layer.\n\n        :param return_masked: Whether to return the merged mask.\n        :param kwargs: Arguments for parent class.\n        """"""\n        super(Masked, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.return_masked = return_masked\n\n    def get_config(self):\n        config = {\n            \'return_masked\': self.return_masked,\n        }\n        base_config = super(Masked, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        if self.return_masked:\n            return [input_shape[0], input_shape[0][:-1]]\n        return input_shape[0]\n\n    def compute_mask(self, inputs, mask=None):\n        token_mask = K.not_equal(inputs[1], 0)\n        return K.all(K.stack([token_mask, mask[0]], axis=0), axis=0)\n\n    def call(self, inputs, mask=None, **kwargs):\n        if self.return_masked:\n            return [inputs[0], K.cast(self.compute_mask(inputs, mask), K.floatx())]\n        return inputs[0]\n'"
keras_bert/layers/pooling.py,0,"b'from tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\nclass MaskedGlobalMaxPool1D(keras.layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(MaskedGlobalMaxPool1D, self).__init__(**kwargs)\n        self.supports_masking = True\n\n    def compute_mask(self, inputs, mask=None):\n        return None\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[:-2] + (input_shape[-1],)\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            inputs -= K.expand_dims((1.0 - mask) * 1e6, axis=-1)\n        return K.max(inputs, axis=-2)\n'"
