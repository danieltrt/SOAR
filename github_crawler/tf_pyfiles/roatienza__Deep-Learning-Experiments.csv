file_path,api_count,code
utils/bleu_similarity.py,0,"b'""""""\nTests the linguistic similarity between two sentences in English\n\nUsage (BLEU-4): \npython3 bleu_similarity.py --reference=""the sun rises in the east"" --hypothesis=""the sun sets in the west""\n\nUsage (BLEU-1): \npython3 bleu_similarity.py --reference=""the sun rises in the east"" --hypothesis=""the sun sets in the west"" --bleuone\n\n\n""""""\n\nimport argparse\nfrom nltk.translate.bleu_score import sentence_bleu\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    help_ = ""Reference sentence (ground truth)""\n    parser.add_argument(""-r"", ""--reference"", help=help_)\n    help_ = ""Hypothesis or test sentence""\n    parser.add_argument(""-t"", ""--hypothesis"", help=help_)\n    help_ = ""Use BLEU-1 instead of default BLEU-4""\n    parser.add_argument(""-o"", ""--bleuone"", help=help_, action=\'store_true\')\n    args = parser.parse_args()\n\n    if args.reference is None:\n        print(""Please provide a reference sentence"")\n        exit(1)\n    else:\n        reference = args.reference\n\n    if args.hypothesis is None:\n        print(""Please provide a hypothesis sentence"")\n        exit(1)\n    else:\n        hypothesis = args.hypothesis\n\n    \n    reference = [reference.split()]\n    hypothesis = hypothesis.split()\n    if args.bleuone:\n        score = sentence_bleu(reference, hypothesis, weights=(1, 0, 0, 0))\n        print(""BLEU-1 Score: "", score)\n    else:\n        score = sentence_bleu(reference, hypothesis)\n        print(""BLEU-4 Score: "", score)\n\n'"
utils/spacy_similarity.py,0,"b'""""""\nTests the linguistic similarity between two sentences in English\n\nUsage:\npython3 spacy_similarity.py --reference=""the sun rises in the east"" --hypothesis=""the sun sets in the west""\n\n""""""\n\nimport spacy\nimport argparse\n\nnlp = spacy.load(\'en\')\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    help_ = ""Reference sentence (ground truth)""\n    parser.add_argument(""-r"", ""--reference"", help=help_)\n    help_ = ""Hypothesis or test sentence""\n    parser.add_argument(""-t"", ""--hypothesis"", help=help_)\n    args = parser.parse_args()\n\n    if args.reference is None:\n        print(""Please provide a reference sentence"")\n        exit(1)\n    else:\n        reference = nlp(args.reference)\n\n    if args.hypothesis is None:\n        print(""Please provide a hypothesis sentence"")\n        exit(1)\n    else:\n        hypothesis = nlp(args.hypothesis)\n\n    score = reference.similarity(hypothesis)\n\n    print(""Score: "", score)\n'"
keras/chapter1/cnn-mnist-1.4.1.py,0,"b'\'\'\' CNN MNIST digits classification\n\n3-layer CNN for MNIST digits classification \nFirst 2 layers - Conv2D-ReLU-MaxPool\n3rd layer - Conv2D-ReLU-Dropout\n4th layer - Dense(10)\nOutput Activation - softmax\nOptimizer - Adam\n\n99.4% test accuracy in 10epochs\n\nhttps://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.utils import to_categorical\n# from tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.datasets import mnist\n\nimport datetime\n\n# load mnist dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# input image dimensions\nimage_size = x_train.shape[1]\n# resize and normalize\nx_train = np.reshape(x_train,[-1, image_size, image_size, 1])\nx_test = np.reshape(x_test,[-1, image_size, image_size, 1])\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\n# image is processed as is (square grayscale)\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\npool_size = 2\nfilters = 64\ndropout = 0.2\n\n# model is a stack of CNN-ReLU-MaxPooling\nmodel = Sequential()\nmodel.add(Conv2D(filters=filters,\n                 kernel_size=kernel_size,\n                 activation=\'relu\',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size))\nmodel.add(Conv2D(filters=filters,\n                 kernel_size=kernel_size,\n                 activation=\'relu\'))\nmodel.add(MaxPooling2D(pool_size))\nmodel.add(Conv2D(filters=filters,\n                 kernel_size=kernel_size,\n                 activation=\'relu\'))\nmodel.add(Flatten())\n# dropout added as regularizer\nmodel.add(Dropout(dropout))\n# output layer is 10-dim one-hot vector\nmodel.add(Dense(num_labels))\nmodel.add(Activation(\'softmax\'))\nmodel.summary()\n# plot_model(model, to_file=\'cnn-mnist.png\', show_shapes=True)\n\n# loss function for one-hot vector\n# use of adam optimizer\n# accuracy is good metric for classification tasks\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n# train the network\nstart_time = datetime.datetime.now()\nmodel.fit(x_train, y_train, epochs=10, batch_size=batch_size)\nelapsed_time = datetime.datetime.now() - start_time\nprint(""Elapsed time (train): %s"" % elapsed_time)\n\nloss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.2f%%"" % (100.0 * acc))\n'"
keras/cnn/cnn-functional-2.1.1.py,0,"b'\'\'\' Using Functional API to build CNN\n\n~99.3% test accuracy\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom keras.layers import Dense, Dropout, Input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\n\n\n# load MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# from sparse label to categorical\nnum_labels = len(np.unique(y_train))\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# reshape and normalize input images\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train,[-1, image_size, image_size, 1])\nx_test = np.reshape(x_test,[-1, image_size, image_size, 1])\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\nfilters = 64\ndropout = 0.3\n\n# use functional API to build cnn layers\ninputs = Input(shape=input_shape)\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation=\'relu\')(inputs)\ny = MaxPooling2D()(y)\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation=\'relu\')(y)\ny = MaxPooling2D()(y)\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation=\'relu\')(y)\n# image to vector before connecting to dense layer\ny = Flatten()(y)\n# dropout regularization\ny = Dropout(dropout)(y)\noutputs = Dense(num_labels, activation=\'softmax\')(y)\n\n# build the model by supplying inputs/outputs\nmodel = Model(inputs=inputs, outputs=outputs)\n# network model in text\nmodel.summary()\n\n# classifier loss, Adam optimizer, classifier accuracy\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n\n# train the model with input images and labels\nmodel.fit(x_train,\n          y_train,\n          validation_data=(x_test, y_test),\n          epochs=20,\n          batch_size=batch_size)\n\n# model accuracy on test dataset\nscore = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.1f%%"" % (100.0 * score[1]))\n'"
keras/cnn/cnn-mnist-1.4.1.py,0,"b'\'\'\' CNN MNIST digits classification\n\n3-layer CNN for MNIST digits classification \nFirst 2 layers - Conv2D-ReLU-MaxPool\n3rd layer - Conv2D-ReLU-Dropout\n4th layer - Dense(10)\nOutput Activation - softmax\nOptimizer - Adam\n\n99.4% test accuracy in 10epochs\n\nhttps://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.utils import to_categorical, plot_model\nfrom keras.datasets import mnist\n\n# load mnist dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# input image dimensions\nimage_size = x_train.shape[1]\n# resize and normalize\nx_train = np.reshape(x_train,[-1, image_size, image_size, 1])\nx_test = np.reshape(x_test,[-1, image_size, image_size, 1])\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\n# image is processed as is (square grayscale)\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\npool_size = 2\nfilters = 64\ndropout = 0.2\n\n# model is a stack of CNN-ReLU-MaxPooling\nmodel = Sequential()\nmodel.add(Conv2D(filters=filters,\n                 kernel_size=kernel_size,\n                 activation=\'relu\',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size))\nmodel.add(Conv2D(filters=filters,\n                 kernel_size=kernel_size,\n                 activation=\'relu\'))\nmodel.add(MaxPooling2D(pool_size))\nmodel.add(Conv2D(filters=filters,\n                 kernel_size=kernel_size,\n                 activation=\'relu\'))\nmodel.add(Flatten())\n# dropout added as regularizer\nmodel.add(Dropout(dropout))\n# output layer is 10-dim one-hot vector\nmodel.add(Dense(num_labels))\nmodel.add(Activation(\'softmax\'))\nmodel.summary()\nplot_model(model, to_file=\'cnn-mnist.png\', show_shapes=True)\n\n# loss function for one-hot vector\n# use of adam optimizer\n# accuracy is good metric for classification tasks\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n# train the network\nmodel.fit(x_train, y_train, epochs=10, batch_size=batch_size)\n\nloss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.1f%%"" % (100.0 * acc))\n'"
keras/cnn/cnn-y-network-2.1.2.py,0,"b'\'\'\'Implements a Y-Network using Functional API\n\n~99.3% test accuracy\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom keras.layers import Dense, Dropout, Input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras.layers.merge import concatenate\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom keras.utils import plot_model\n\n# load MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# from sparse label to categorical\nnum_labels = len(np.unique(y_train))\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# reshape and normalize input images\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train,[-1, image_size, image_size, 1])\nx_test = np.reshape(x_test,[-1, image_size, image_size, 1])\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\ninput_shape = (image_size, image_size, 1)\nbatch_size = 32\nkernel_size = 3\ndropout = 0.4\nn_filters = 32\n\n# left branch of Y network\nleft_inputs = Input(shape=input_shape)\nx = left_inputs\nfilters = n_filters\n# 3 layers of Conv2D-Dropout-MaxPooling2D\n# number of filters doubles after each layer (32-64-128)\nfor i in range(3):\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               padding=\'same\',\n               activation=\'relu\')(x)\n    x = Dropout(dropout)(x)\n    x = MaxPooling2D()(x)\n    filters *= 2\n\n# right branch of Y network\nright_inputs = Input(shape=input_shape)\ny = right_inputs\nfilters = n_filters\n# 3 layers of Conv2D-Dropout-MaxPooling2D\n# number of filters doubles after each layer (32-64-128)\nfor i in range(3):\n    y = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               padding=\'same\',\n               activation=\'relu\',\n               dilation_rate=2)(y)\n    y = Dropout(dropout)(y)\n    y = MaxPooling2D()(y)\n    filters *= 2\n\n# merge left and right branches outputs\ny = concatenate([x, y])\n# feature maps to vector in preparation to connecting to Dense layer\ny = Flatten()(y)\ny = Dropout(dropout)(y)\noutputs = Dense(num_labels, activation=\'softmax\')(y)\n\n# build the model in functional API\nmodel = Model([left_inputs, right_inputs], outputs)\n# verify the model using graph\nplot_model(model, to_file=\'cnn-y-network.png\', show_shapes=True)\n# verify the model using layer text description\nmodel.summary()\n\n# classifier loss, Adam optimizer, classifier accuracy\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n\n# train the model with input images and labels\nmodel.fit([x_train, x_train],\n          y_train, \n          validation_data=([x_test, x_test], y_test),\n          epochs=20,\n          batch_size=batch_size)\n\n# model accuracy on test dataset\nscore = model.evaluate([x_test, x_test], y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.1f%%"" % (100.0 * score[1]))\n'"
keras/embedding/word.py,4,"b'\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nwith tf.Graph().as_default():\n  module_url = ""https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1""\n  embed = hub.Module(module_url)\n  embeddings = embed([""world""])\n\n  with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.tables_initializer())\n\n    print(sess.run(embeddings))\n    print(sess.run(embeddings).shape)\n'"
keras/regularization/mlp-mnist-data_augment.py,1,"b'#!/usr/bin/env python\n# coding: utf-8\n\n# ## MLP MNIST with data augmentation\n\n# In[ ]:\n\n\n\'\'\'\nMLP network for MNIST digits classification w/ data augment\nTest accuracy: 97.7\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# numpy package\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\n\nfrom numpy.random import seed\nseed(12345)\nimport tensorflow as tf\ntf.random.set_seed(12345)\n\n# load mnist dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# compute the number of labels\nnum_labels = np.amax(y_train) + 1\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# image dimensions (assumed square)\nimage_size = x_train.shape[1]\ninput_size = image_size * image_size\n# we train our network using float data\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\nbatch_size = 128\nhidden_units = 256\ndata_augmentation = True\nepochs = 20\nmax_batches = len(x_train) / batch_size\n\n# this is 3-layer MLP with ReLU after each layer\nmodel = Sequential()\nmodel.add(Dense(hidden_units, input_dim=input_size))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dense(hidden_units))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dense(num_labels))\n# this is the output for one-hot vector\nmodel.add(Activation(\'softmax\'))\nmodel.summary()\n\n# loss function for one-hot vector\n# use of sgd optimizer\n# accuracy is good metric for classification tasks\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'sgd\',\n              metrics=[\'accuracy\'])\n\n# validate the model on test dataset to determine generalization\n# score = model.evaluate(x_test, y_test, batch_size=batch_size)\n# print(""\\nTest accuracy: %.1f%%"" % (100.0 * score[1]))\n\n# Run training, with or without data augmentation.\nif not data_augmentation:\n    print(\'Not using data augmentation.\')\n    # train the network no data augmentation\n    x_train = np.reshape(x_train, [-1, input_size])\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\nelse:\n    print(\'Using real-time data augmentation.\')\n    # This will do preprocessing and realtime data augmentation:\n    # we need [width, height, channel] dim for data aug\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    datagen = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=False)\n\n    # Compute quantities required for featurewise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)\n    # fits the model on batches with real-time data augmentation:\n    #model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n    #                    steps_per_epoch=len(x_train) / 32, \n    #                    epochs=epochs)\n    for e in range(epochs):\n        print(\'Epoch\', e)\n        batches = 0\n        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n            x_batch = np.reshape(x_batch, [-1, image_size*image_size])\n            model.fit(x_batch, y_batch)\n            batches += 1\n            if batches >= len(x_train) / 32:\n                # we need to break the loop by hand because\n                # the generator loops indefinitely\n                break\n\n# Score trained model.\nx_test = np.reshape(x_test, [-1, input_size])\nscores = model.evaluate(x_test,\n                        y_test,\n                        batch_size=batch_size,\n                        verbose=False)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy: %0.1f%%\' % (100 * scores[1]) )\n\n\n# In[ ]:\n\n\n\n\n'"
keras/regularization/mlp-mnist-dropout.py,0,"b'\'\'\'\nMLP network for MNIST digits classification with Dropout\nTest accuracy: 95.5%\n\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# numpy package\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\n\n# load mnist dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# image dimensions (assumed square)\nimage_size = x_train.shape[1]\ninput_size = image_size * image_size\n# for mlp, the input dim is a vector, so we reshape\nx_train = np.reshape(x_train, [-1, input_size])\n# we train our network using float data\nx_train = x_train.astype(\'float32\') / 255\nx_test = np.reshape(x_test, [-1, input_size])\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\nbatch_size = 128\nhidden_units = 256\ndropout = 0.2\n\n# this is 3-layer MLP with ReLU. Dropout reg.\nmodel = Sequential()\nmodel.add(Dense(hidden_units,\n                input_dim=input_size))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(hidden_units))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_labels))\n# this is the output for one-hot vector\nmodel.add(Activation(\'softmax\'))\nmodel.summary()\n\n# loss function for one-hot vector\n# use of sgd optimizer\n# accuracy is good metric for classification tasks\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'sgd\',\n              metrics=[\'accuracy\'])\n# train the network\nmodel.fit(x_train, y_train, epochs=20, batch_size=batch_size)\n\n# validate the model on test dataset to determine generalization\nscore = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.1f%%"" % (100.0 * score[1]))\n'"
keras/regularization/mlp-mnist-l2.py,0,"b'\'\'\'\nMLP network for MNIST digits classification with L2 reg\nTest accuracy: 95.2%\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# numpy package\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.datasets import mnist\nfrom keras.regularizers import l2\nfrom keras.utils import to_categorical\n\n# load mnist dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# image dimensions (assumed square)\nimage_size = x_train.shape[1]\ninput_size = image_size * image_size\n# for mlp, the input dim is a vector, so we reshape\nx_train = np.reshape(x_train, [-1, input_size])\n# we train our network using float data\nx_train = x_train.astype(\'float32\') / 255\nx_test = np.reshape(x_test, [-1, input_size])\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\nbatch_size = 128\nhidden_units = 256\n\nkernel_regularizer = l2(0.0001)\n# this is 3-layer MLP with ReLU and l2 kernel regularizer\nmodel = Sequential()\nmodel.add(Dense(hidden_units,\n                kernel_regularizer=kernel_regularizer,\n                input_dim=input_size))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dense(hidden_units,\n                kernel_regularizer=kernel_regularizer))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dense(num_labels))\n# this is the output for one-hot vector\nmodel.add(Activation(\'softmax\'))\nmodel.summary()\n\n# loss function for one-hot vector\n# use of sgd optimizer\n# accuracy is good metric for classification tasks\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'sgd\',\n              metrics=[\'accuracy\'])\n# train the network\nmodel.fit(x_train, y_train, epochs=20, batch_size=batch_size)\n\n# validate the model on test dataset to determine generalization\nscore = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.1f%%"" % (100.0 * score[1]))\n'"
keras/regularization/mlp-mnist-noreg.py,0,"b'\'\'\'\nMLP network for MNIST digits classification\nTest accuracy: 95.2%\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# numpy package\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\n\n# load mnist dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# image dimensions (assumed square)\nimage_size = x_train.shape[1]\ninput_size = image_size * image_size\n# for mlp, the input dim is a vector, so we reshape\nx_train = np.reshape(x_train, [-1, input_size])\n# we train our network using float data\nx_train = x_train.astype(\'float32\') / 255\nx_test = np.reshape(x_test, [-1, input_size])\nx_test = x_test.astype(\'float32\') / 255\n\n# network parameters\nbatch_size = 128\nhidden_units = 256\n\n# this is 3-layer MLP with ReLU. No regularizer\nmodel = Sequential()\nmodel.add(Dense(hidden_units,\n                input_dim=input_size))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dense(hidden_units))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dense(num_labels))\n# this is the output for one-hot vector\nmodel.add(Activation(\'softmax\'))\nmodel.summary()\n\n# loss function for one-hot vector\n# use of sgd optimizer\n# accuracy is good metric for classification tasks\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'sgd\',\n              metrics=[\'accuracy\'])\n# train the network\nmodel.fit(x_train, y_train, epochs=20, batch_size=batch_size)\n\n# validate the model on test dataset to determine generalization\nscore = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(""\\nTest accuracy: %.1f%%"" % (100.0 * score[1]))\n'"
keras/seq2seq/seq2seq_translate.py,0,"b'\'\'\'Sequence to sequence example in Keras \n\nEnglish to Tagalog sentence pairs.\nhttp://www.manythings.org/anki/tgl-eng.zip\n\nLots of neat sentence pairs datasets can be found at:\nhttp://www.manythings.org/anki/\n\n# References\n\n- Sequence to Sequence Learning with Neural Networks\n    https://arxiv.org/abs/1409.3215\n- Learning Phrase Representations using\n    RNN Encoder-Decoder for Statistical Machine Translation\n    https://arxiv.org/abs/1406.1078\n\'\'\'\nfrom __future__ import print_function\n\nfrom keras.models import Model\nfrom keras.layers import Input, LSTM, Dense\nimport numpy as np\n\n\ndef read_data(fname):\n    with open(fname) as f:\n        content = f.readlines()\n    content = [x.strip() for x in content]\n    content = [content[i].split() for i in range(len(content))]\n    content = np.array(content)\n    content = np.reshape(content, [-1, ])\n    return content\n\ndef build_dicts(words):\n    dictionary = dict()\n    for word in words:\n        dictionary[word] = len(dictionary)\n    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, reverse_dictionary\n\ndef build_seq2seq(latent_dim=256):\n    # Define an input sequence and process it.\n    encoder_inputs = Input(shape=(None,))\n    x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n    x, state_h, state_c = LSTM(latent_dim,\n                               return_state=True)(x)\n    encoder_states = [state_h, state_c]\n\n    # Set up the decoder, using `encoder_states` as initial state.\n    decoder_inputs = Input(shape=(None,))\n    x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n    x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n    decoder_outputs = Dense(num_decoder_tokens, activation=\'softmax\')(x)\n\n    # Define the model that will turn\n    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n    return model\n\ndef build_models(latent_dim=256):\n    return \n\ndef train_model():\n    batch_size = 64  # Batch size for training.\n    epochs = 1  # Number of epochs to train for.\n    latent_dim = 256 # Latent dimensionality of the encoding space.\n    # Path to the data txt file on disk.\n\n    model = build_seq2seq()\n\n    # Compile & run training\n    model.compile(optimizer=\'rmsprop\', loss=\'categorical_crossentropy\')\n    # Note that `decoder_target_data` needs to be one-hot encoded,\n    # rather than sequences of integers like `decoder_input_data`!\n    model.fit([encoder_input_data, decoder_input_data],\n              decoder_target_data,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_split=0.2)\n\ndef input2target(data_path, sos, eos):\n    input_texts = []\n    target_texts = []\n\n    with open(data_path, \'r\', encoding=\'utf-8\') as f:\n        lines = f.read().split(\'\\n\')\n    for line in lines:\n        if len(line) <= 0:\n            continue\n        line = line.replace("","", "" ,"")\n        line = line.replace(""."", "" ."")\n        line = line.replace(""!"", "" !"")\n        line = line.replace(""?"", "" ?"")\n        line = line.lower()\n        target_text, input_text = line.split(\'\\t\')\n        # print(input_text , "" : "", target_text)\n        target_text = ""%s %s %s"" % (sos, target_text, eos)\n        input_texts.append(input_text)\n        target_texts.append(target_text)\n\n    return input_texts, target_texts\n\ndef get_words(sentences):\n    words = []\n    for sen in sentences:\n        tokens = sen.split()\n        for token in tokens:\n            if token not in words:\n                words.append(token)\n    print(len(words))\n    return words\n\ndef sentence2tensor(input_texts, input_dict):\n    return\n\ndef max_wordnum(texts):\n    count = 0\n    for text in texts:\n        if len(text.split()) > count:\n            count = len(text.split())\n    return count\n    \n\ndata_path = \'tgl-eng/tgl.txt\'\neos = ""<EOS>""\nsos = ""<SOS>""\n\ninput_texts, target_texts = input2target(data_path, sos, eos)\n\ninput_words = get_words(input_texts)\ninput_dict, input_rev_dict = build_dicts(input_words)\n\ntarget_words = get_words(target_texts)\nif sos in target_words:\n    print(""Present"")\n\ntarget_dict, target_rev_dict = build_dicts(target_words)\n\n\nnum_encoder_tokens = len(input_words)\nnum_decoder_tokens = len(target_words)\nmax_encoder_seq_length = max([len(words.split()) for words in input_texts])\nmax_decoder_seq_length = max([len(words.split()) for words in target_texts])\n\nprint(\'Number of samples:\', len(input_texts))\nprint(\'Number of unique input tokens:\', num_encoder_tokens)\nprint(\'Number of unique output tokens:\', num_decoder_tokens)\nprint(\'Max sequence length for inputs:\', max_encoder_seq_length)\nprint(\'Max sequence length for outputs:\', max_decoder_seq_length)\n\nencoder_input_data = np.zeros(\n            (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n                dtype=\'float32\')\ndecoder_input_data = np.zeros(\n            (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n                dtype=\'float32\')\ndecoder_target_data = np.zeros(\n            (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n                dtype=\'float32\')\n\nfor i, text, in enumerate(input_texts):\n    words = text.split()\n    for t, word in enumerate(words):\n        encoder_input_data[i, t, input_dict[word]] = 1.\n\nfor i, text, in enumerate(target_texts):\n    words = text.split()\n    for t, word in enumerate(words):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_dict[word]] = 1.\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_dict[word]] = 1.\n\n# indexes = np.random.randint(0, len(input_texts), 40)\n# encoder_test_data = encoder_input_data[indexes]\n# encoder_input_data = np.delete(encoder_input_data, indexes, axis=0)\n# decoder_input_data = np.delete(decoder_input_data, indexes, axis=0)\n# decoder_target_data = np.delete(decoder_target_data, indexes, axis=0)\n\nbatch_size = 64  # Batch size for training.\nepochs = 100  # Number of epochs to train for.\nlatent_dim = 512 # Latent dimensionality of the encoding space.\n\n# Path to the data txt file on disk.\n# Define an input sequence and process it.\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nencoder = LSTM(latent_dim, return_sequences=True)(encoder_inputs)\nencoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don\'t use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation=\'softmax\')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.summary()\n\n# Compile & run training\nmodel.compile(optimizer=\'rmsprop\', loss=\'categorical_crossentropy\')\n# Note that `decoder_target_data` needs to be one-hot encoded,\n# rather than sequences of integers like `decoder_input_data`!\nmodel.fit([encoder_input_data, decoder_input_data],\n          decoder_target_data,\n          batch_size=batch_size,\n          epochs=epochs,\n          shuffle=True,\n          validation_split=0.05)\n\n# Save model\nmodel.save(\'s2s.h5\')\n\n# Next: inference mode (sampling).\n# Here\'s the drill:\n# 1) encode input and retrieve initial decoder state\n# 2) run one step of decoder with this initial state\n# and a ""start of sequence"" token as target.\n# Output will be the next target token\n# 3) Repeat with the current target token and current states\n\n# Define sampling models\nencoder_model = Model(encoder_inputs, encoder_states)\nencoder_model.summary()\n\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_outputs, state_h, state_c = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs] + decoder_states)\ndecoder_model.summary()\n\ndef decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0, target_dict[sos]] = 1.\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = \'\'\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict(\n            [target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_word = target_rev_dict[sampled_token_index]\n        decoded_sentence += sampled_word + "" ""\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        # if sampled_word in [""."", ""?"", ""!""] or\n        if (sampled_word == eos or\n           len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence\n\n# print(""-------------------- TEST ---------------------------"")\n# for seq_index in range(40):\n#    # Take one sequence (part of the training set)\n#    # for trying out decoding.\n#    input_seq = encoder_test_data[seq_index: seq_index + 1]\n#    decoded_sentence = decode_sequence(input_seq)\n#    print(\'Input sentence:\', input_texts[seq_index])\n#    print(\'Decoded sentence:\', decoded_sentence)\n\n\n\nprint(""-------------------- TRAIN ---------------------------"")\nindexes = np.random.randint(0, len(input_texts), 40)\nfor seq_index in indexes:\n    # Take one sequence (part of the training set)\n    # for trying out decoding.\n    input_seq = encoder_input_data[seq_index: seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print(\'Input sentence:\', input_texts[seq_index])\n    print(\'Decoded sentence:\', decoded_sentence)\n    print(""----"")\n'"
pytorch/chapter1/cnn-mnist.py,0,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\nimport datetime\nimport argparse\n\nclass Model(nn.Module):\n\n    def __init__(self):\n        super(Model, self).__init__()\n        # (channel, filters, kernel_size)\n        self.classifier = nn.Sequential(\n            nn.Conv2d(1, 64, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 64, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 64, 3),\n            nn.Dropout(0.2),\n            nn.Flatten(),\n            nn.Linear(64 * 3 * 3, 10),\n            nn.LogSoftmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.classifier(x)\n        return x\n\ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    log_interval = len(train_loader) // 10\n    for i, data in enumerate(train_loader):\n        inputs, labels = data[0].to(device), data[1].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = F.nll_loss(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if (i + 1) % log_interval == 0:\n            print(\'Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                  epoch,\n                  i * len(data),\n                  len(train_loader.dataset),\n                  100. * i / len(train_loader),\n                  loss.item()))\n\n\ndef test(args, model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data in test_loader:\n            inputs, labels = data[0].to(device), data[1].to(device)\n            outputs = model(inputs)\n            test_loss += F.nll_loss(outputs, labels, reduction=\'sum\').item()\n            pred = outputs.argmax(dim=1, keepdim=True)\n            correct += pred.eq(labels.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n          test_loss,\n          correct,\n          len(test_loader.dataset),\n          100. * correct / len(test_loader.dataset)))\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\n    parser.add_argument(\'--no-cuda\',\n                        action=\'store_true\',\n                        default=False,\n                        help=\'disables CUDA training\')\n    parser.add_argument(\'--seed\',\n                        type=int,\n                        default=1,\n                        metavar=\'S\',\n                        help=\'random seed (default: 1)\')\n    parser.add_argument(\'--batch-size\',\n                        type=int,\n                        default=128,\n                        metavar=\'N\',\n                        help=\'input batch size for training (default: 128)\')\n    parser.add_argument(\'--epochs\',\n                        type=int,\n                        default=10,\n                        metavar=\'N\',\n                        help=\'number of epochs to train (default: 10)\')\n    parser.add_argument(\'--save-model\',\n                        action=\'store_true\',\n                        default=False,\n                        help=\'For Saving the current Model\')\n    args = parser.parse_args()\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n    torch.manual_seed(args.seed)\n\n    # kwargs = {\'num_workers\': 4, \'pin_memory\': True} if use_cuda else {}\n    kwargs = {\'num_workers\': 4} if use_cuda else {}\n\n    #transform = transforms.Compose([transforms.ToTensor(),\n    #                                transforms.Normalize((0.1307,), (0.3081,))])\n    transform = transforms.Compose([transforms.ToTensor()])\n    x_train = datasets.MNIST(root=\'./data\',\n                             train=True,\n                             download=True,\n                             transform=transform)\n\n    x_test = datasets.MNIST(root=\'./data\',\n                            train=False,\n                            download=True,\n                            transform=transform)\n\n    print(""Train dataset size:"", len(x_train))\n    print(""Test dataset size"", len(x_test))\n\n\n    DataLoader = torch.utils.data.DataLoader\n    train_loader = DataLoader(x_train,\n                              shuffle=True,\n                              batch_size=args.batch_size,\n                              **kwargs)\n\n    test_loader = DataLoader(x_test,\n                             shuffle=True,\n                             batch_size=args.batch_size,\n                             **kwargs)\n\n\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n    model = Model().to(device)\n    if torch.cuda.device_count() > 1:\n        print(""Available GPUs:"", torch.cuda.device_count())\n        # model = nn.DataParallel(model)\n    print(model)\n    print(device)\n    # criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters())\n\n    start_time = datetime.datetime.now()\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch)\n    elapsed_time = datetime.datetime.now() - start_time\n    print(""Elapsed time (train): %s"" % elapsed_time)\n    test(args, model, device, test_loader)\n\n    if (args.save_model):\n        torch.save(model.state_dict(), ""mnist_cnn.pt"")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
Experiments/Tensorflow/Deep_Networks/mnist_a2j_2pickle.py,0,"b'""""""\nDownload notMNIST and generate a pickle file\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n""""""\n# On command line: python3 mnist_a2j_2pickle.py\n# Prerequisite: tensorflow (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport pickle\nimport os\nimport sys\nimport tarfile\nimport random\nimport matplotlib.image as img\n\nfrom os.path import join\nfrom six.moves.urllib.request import urlretrieve\n\nurl = \'http://yaroslavvb.com/upload/notMNIST/\'\n\ndef maybe_download(filename, expected_bytes):\n    """"""Download a file if not present, and make sure it\'s the right size.""""""\n    if not os.path.exists(filename):\n        print(\'Downloading \', filename, "" ..."")\n        filename, _ = urlretrieve(url + filename, filename)\n        statinfo = os.stat(filename)\n        if statinfo.st_size == expected_bytes:\n            print(\'Found and verified\', filename)\n        else:\n            raise Exception(\'Failed to verify\' +\n                            filename + \'. Can you get to it with a browser?\')\n    else:\n        print(\'Found and verified\', filename)\n    return filename\n\ndef extract(filename):\n    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n    data_folders = []\n    if os.path.exists(root):\n        data_folders = [os.path.join(root, d)\n                        for d in sorted(os.listdir(root)) if d != \'.DS_Store\']\n    if len(data_folders) == num_classes:\n        print(""Using previously extracted files..."")\n        print(data_folders)\n        return data_folders\n    tar = tarfile.open(filename)\n    print(\'Extracting data for %s. This may take a while. Please wait.\' % root)\n    sys.stdout.flush()\n    tar.extractall()\n    tar.close()\n    data_folders = [os.path.join(root, d)\n                    for d in sorted(os.listdir(root)) if d != \'.DS_Store\']\n    if len(data_folders) != num_classes:\n        raise Exception(\n            \'Expected %d folders, one per class. Found %d instead.\' % (\n                num_classes, len(data_folders)))\n    print(data_folders)\n    return data_folders\n\ndef getfiles_fromlist(dirs):\n    files = []\n    for dir in dirs:\n        files.extend([os.path.join(dir,f) for f in sorted(os.listdir(dir)) if f != \'.DS_Store\'])\n    return files\n\ndef readfile(path):\n    try:\n        data = img.imread(path)\n        return data\n    except:\n        print(""Error reading: "", path)\n        return np.array([])\n\ndef read_image_files(files):\n    imagelabels = []\n    imagedata = []\n    for file in files:\n        parent_dir = os.path.dirname(file)\n        label =  (np.arange(num_classes) == (ord(parent_dir[-1])-ord(\'A\')) ).astype(np.float32)\n        data = readfile(file)\n        if (data.size > 0):\n            imagelabels.append(label)\n            imagedata.append(data)\n    return np.array(imagedata),np.array(imagelabels)\n\ntrain_filename = maybe_download(\'notMNIST_large.tar.gz\', 247336696)\ntest_filename = maybe_download(\'notMNIST_small.tar.gz\', 8458043)\n\nnum_classes = 10\n\ntrain_folders = extract(train_filename)\ntest_folders = extract(test_filename)\n\ntrain_files = np.array(getfiles_fromlist(train_folders))\ntest_files = np.array(getfiles_fromlist(test_folders))\nrandom.shuffle(train_files)\n\nall_dataset, all_labels = read_image_files(train_files)\ntest_dataset, test_labels = read_image_files(test_files)\nimage_size = all_dataset.shape[2]\n\nall_dataset = all_dataset.reshape((-1,image_size*image_size)).astype(np.float32)\ntest_dataset = test_dataset.reshape((-1,image_size*image_size)).astype(np.float32)\n\ndata = { ""test_labels"" : test_labels, ""all_labels"" : all_labels, ""test_dataset"" : test_dataset,\n         ""all_dataset"" : all_dataset }\n\npickle_file = open( ""mnist_a2j.pickle"", ""wb"" )\npickle.dump( data, pickle_file )\npickle_file.close()'"
Experiments/Tensorflow/Deep_Networks/mnist_a2j_cnn.py,36,"b'""""""\nCNN on Not MNIST\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n""""""\n# On command line: python3 mnist_a2j_cnn.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n# must run mnist_a2j_2pickle.py first (one-time) to generate the data\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nimport pickle\nimport time\n\nstart_time = time.time()\ndef elapsed(sec):\n    if sec<60:\n        return str(sec) + "" sec""\n    elif sec<(60*60):\n        return str(sec/60) + "" min""\n    else:\n        return str(sec/(60*60)) + "" hr""\n\n# use of pickle to speed up loading of data\npickle_file = open( ""mnist_a2j.pickle"", ""rb"" )\ndata = pickle.load(pickle_file)\ntest_labels = data[""test_labels""]\ntrain_labels = data[""all_labels""]\ntest_dataset = data[""test_dataset""]\ntrain_dataset = data[""all_dataset""]\ndel data\npickle_file.close()\n\nnum_labels = train_labels.shape[1]\nnum_data = train_labels.shape[0]\n\nimage_size = 28\nchannel = 1\ntrain_dataset = train_dataset.reshape((-1,image_size, image_size, channel)).astype(np.float32)\ntest_dataset = test_dataset.reshape((-1,image_size, image_size, channel)).astype(np.float32)\n\nprint(train_dataset.shape)\nprint(train_labels.shape)\nprint(test_dataset.shape)\nprint(test_labels.shape)\n\n# small batch size appears to work\nbatch_size = 128\ndepth1 = 32\ndepth2 = 64\n\nhidden_units1 = int((depth2*image_size/4*image_size/4))\nhidden_units2 = 1024\npatch_size = 3\nnum_steps = 50001\ndropout = 0.8\nlearning_rate = 0.001\n\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32,\n                                     shape=(batch_size, image_size , image_size, channel))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n\n    weights0 = tf.Variable(\n        tf.truncated_normal([patch_size, patch_size, channel, depth1], stddev=1.0))\n    biases0 = tf.Variable(tf.zeros([depth1]))\n\n    weights1 = tf.Variable(\n        tf.truncated_normal([patch_size, patch_size, depth1, depth2], stddev=1.0))\n    biases1 = tf.Variable(tf.zeros([depth2]))\n\n    weights2 = tf.Variable(\n        tf.truncated_normal([hidden_units1, hidden_units2], stddev=0.1))\n    biases2 = tf.Variable(tf.constant(1.0, shape=[hidden_units2]))\n\n    weights3 = tf.Variable(\n        tf.truncated_normal([hidden_units2, num_labels], stddev=0.1))\n    biases3 = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n    keep_prob = tf.placeholder(tf.float32)\n\n    def model(data, dropout):\n        conv1 = tf.nn.conv2d(data, weights0, [1, 1, 1, 1], padding=\'SAME\')\n        relu1 = tf.nn.bias_add(conv1, biases0)\n        pool1 = tf.nn.max_pool(tf.nn.relu(relu1), [1, 2, 2, 1], [1, 2, 2, 1], padding=\'SAME\')\n\n        conv2 = tf.nn.conv2d(pool1, weights1, [1, 1, 1, 1], padding=\'SAME\')\n        relu2 = tf.nn.bias_add(conv2, biases1)\n        pool2 = tf.nn.max_pool(tf.nn.relu(relu2), [1, 2, 2, 1], [1, 2, 2, 1], padding=\'SAME\')\n\n        shape = pool2.get_shape().as_list()\n        reshape = tf.reshape(pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n\n        logits1 = tf.nn.relu( tf.add(tf.matmul(reshape, weights2), biases2) )\n        logits1 = tf.nn.dropout(logits1, dropout)\n        logits2 = tf.add( tf.matmul(logits1, weights3), biases3 )\n\n        return logits2, tf.nn.softmax(logits2)\n\n    logits, train_pred = model(tf_train_dataset,dropout=dropout)\n    loss = tf.reduce_mean(\n         tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n\n    test_logits, test_pred = model(test_dataset,1.0)\n\ndef accuracy(predictions, labels):\n    correct_prediction = tf.equal(tf.argmax(labels, 1), tf.argmax(predictions, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    return accuracy.eval()*100.0\n\n# with tf.Session(graph=graph,config=tf.ConfigProto(log_device_placement=True)) as session:\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print(tf.__version__)\n    for step in range(num_steps):\n        offset = (step * batch_size)% (num_data - batch_size)\n        # Generate a minibatch.\n        batch_data = train_dataset[offset:(offset + batch_size), :]\n        batch_labels = train_labels[offset:(offset + batch_size), :]\n        feed_dict = {tf_train_dataset:\n                     batch_data, tf_train_labels: batch_labels}\n        _, l, predictions = session.run(\n            [optimizer, loss, train_pred], feed_dict=feed_dict)\n        if (step % 500 == 0):\n            print(""Minibatch (size=%d) loss at step %d: %f"" % (batch_size, step, l))\n            print(""Minibatch accuracy: %.1f%%"" % accuracy(predictions,\n                                                          batch_labels))\n    # Accuracy: 97.4%\n    print(""Test accuracy: %.1f%%"" % accuracy(test_pred.eval(),\n                                             test_labels))\n    print(""Elapsed: "", elapsed(time.time() - start_time))\n    # print(np.rint(test_pred.eval()))\n\n'"
Experiments/Tensorflow/Deep_Networks/mnist_a2j_cnn_keras.py,0,"b'""""""\nCNN on Not MNIST using Keras\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n""""""\n# On command line: python3 mnist_a2j_cnn_keras.py\n# Prerequisite: tensorflow 1.0 and keras 2.0\n# must run mnist_a2j_2pickle.py first (one-time) to generate the data\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport pickle\nimport time\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Conv2D\nfrom keras.optimizers import Adam\n\nstart_time = time.time()\ndef elapsed(sec):\n    if sec<60:\n        return str(sec) + "" sec""\n    elif sec<(60*60):\n        return str(sec/60) + "" min""\n    else:\n        return str(sec/(60*60)) + "" hr""\n\n# use of pickle to speed up loading of data\npickle_file = open( ""mnist_a2j.pickle"", ""rb"" )\ndata = pickle.load(pickle_file)\ntest_labels = data[""test_labels""]\ntrain_labels = data[""all_labels""]\ntest_dataset = data[""test_dataset""]\ntrain_dataset = data[""all_dataset""]\ndel data\npickle_file.close()\n\nnum_labels = train_labels.shape[1]\nnum_data = train_labels.shape[0]\n\nimage_size = 28\nchannel = 1\ntrain_dataset = train_dataset.reshape((-1,image_size, image_size, channel)).astype(np.float32)\ntest_dataset = test_dataset.reshape((-1,image_size, image_size, channel)).astype(np.float32)\n\nprint(""Training size: "", train_dataset.shape)\nprint(""Training labels: "", train_labels.shape)\nprint(""Test size: "", test_dataset.shape)\nprint(""Test labels: "", test_labels.shape)\n\n# small batch size appears to work\nbatch_size = 128\ndepth1 = 32\ndepth2 = 64\n\n# already figured out by keras\n# hidden_units1 = int((depth2*image_size/4*image_size/4))\nhidden_units2 = 1024\npatch_size = 3\ndropout = 0.8\nlearning_rate = 0.001\n\nmodel = Sequential()\n# input: 28x28 images with 1 channel -> (28, 28, 1) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Conv2D(depth1, patch_size, input_shape=(image_size, image_size, channel), padding=\'same\'))\nmodel.add(Activation(\'relu\'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(depth2, patch_size))\nmodel.add(Activation(\'relu\'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\n# Note: Keras does automatic shape inference.\nmodel.add(Dense(hidden_units2))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_labels))\nmodel.add(Activation(\'softmax\'))\n\nadam = Adam(lr=learning_rate)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=adam,\n              metrics=[\'accuracy\'])\n\nmodel.fit(train_dataset, train_labels,\n          epochs=10,\n          batch_size=batch_size, shuffle=False)\nscore = np.asarray(model.evaluate(test_dataset, test_labels, batch_size=batch_size))*100.0\n# Accuracy: 98.0%\nprint(""\\nTest accuracy: %.1f%%"" % score[1])\n\n'"
Experiments/Tensorflow/Deep_Networks/mnist_a2j_mlp.py,29,"b'""""""\nDeep Neural Networks on Not MNIST\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n""""""\n# On command line: python3 mnist_a2j_mlp.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n# must run mnist_a2j_2pickle.py first (one-time) to generate the data\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nimport pickle\nimport time\n\nstart_time = time.time()\ndef elapsed(sec):\n    if sec<60:\n        return str(sec) + "" sec""\n    elif sec<(60*60):\n        return str(sec/60) + "" min""\n    else:\n        return str(sec/(60*60)) + "" hr""\n\n# use of pickle to speed up loading of data\npickle_file = open( ""mnist_a2j.pickle"", ""rb"" )\ndata = pickle.load(pickle_file)\ntest_labels = data[""test_labels""]\ntrain_labels = data[""all_labels""]\ntest_dataset = data[""test_dataset""]\ntrain_dataset = data[""all_dataset""]\ndel data\npickle_file.close()\n\nprint(""Training size: "", train_dataset.shape)\nprint(""Training labels: "", train_labels.shape)\nprint(""Test size: "", test_dataset.shape)\nprint(""Test labels: "", test_labels.shape)\n\nnum_labels = train_labels.shape[1]\nnum_data = train_labels.shape[0]\n\nimage_size = 28\nbatch_size = 128\nhidden_units = 512*4\nlearning_rate = 0.0002\nnum_steps = 20001\ndropout = 0.8\n\ngraph = tf.Graph()\nwith graph.as_default():\n    # Input data. For the training data, we use a placeholder that will be fed\n    # at run time with a training minibatch.\n    tf_train_dataset = tf.placeholder(tf.float32,\n                                      shape=(None, image_size *\n                                             image_size))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(None, num_labels))\n\n    weights1 = tf.Variable(\n        tf.truncated_normal([image_size * image_size, hidden_units]))\n    biases1 = tf.add(tf.Variable(tf.zeros([hidden_units])),0.1)\n\n    weights2 = tf.Variable(\n        tf.truncated_normal([hidden_units, hidden_units]))\n    biases2 = tf.add(tf.Variable(tf.zeros([hidden_units])),0.1)\n\n    weights3 = tf.Variable(\n        tf.truncated_normal([hidden_units, num_labels]))\n    biases3 = tf.add(tf.Variable(tf.zeros([num_labels])),0.1)\n\n# 3-layer with dropout at hidden layer\n    def model(data,dropout=0.5):\n        logits1 = tf.add(tf.matmul(data, weights1), biases1)\n        relu1 = tf.nn.relu(logits1)\n        dropout1 = tf.nn.dropout(relu1, dropout)\n        logits2 = tf.add(tf.matmul(dropout1, weights2), biases2)\n        relu2 = tf.nn.relu(logits2)\n        dropout2 = tf.nn.dropout(relu2, dropout)\n        logits = tf.add(tf.matmul(dropout2, weights3), biases3)\n        return logits, tf.nn.softmax(logits)\n\n    train_logits, train_pred = model(tf_train_dataset,dropout=dropout)\n    loss = tf.reduce_mean(\n         tf.nn.softmax_cross_entropy_with_logits(logits=train_logits, labels=tf_train_labels))\n\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n    test_logits, test_pred = model(test_dataset,dropout=1.0)\n\ndef accuracy(predictions, labels):\n    correct_prediction = tf.equal(tf.argmax(labels, 1), tf.argmax(predictions, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    return accuracy.eval()*100.0\n\n# with tf.Session(graph=graph,config=tf.ConfigProto(log_device_placement=True)) as session:\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print(tf.__version__)\n    for step in range(num_steps):\n        offset = (step * batch_size)% (num_data - batch_size)\n        # Generate a minibatch.\n        batch_data = train_dataset[offset:(offset + batch_size), :]\n        batch_labels = train_labels[offset:(offset + batch_size), :]\n        feed_dict = {tf_train_dataset:\n                     batch_data, tf_train_labels: batch_labels}\n        _, l, predictions = session.run(\n            [optimizer, loss, train_pred], feed_dict=feed_dict)\n        if (step % 500 == 0):\n            print(""Minibatch (size=%d) loss at step %d: %f"" % (batch_size, step, l))\n            print(""Minibatch accuracy: %.1f%%"" % accuracy(predictions,\n                                                          batch_labels))\n    # Accuracy: 91.6%\n    print(""Test accuracy: %.1f%%"" % accuracy(test_pred.eval(),\n                                             test_labels))\n    print(""Elapsed: "", elapsed(time.time() - start_time))\n    # print(np.rint(test_pred.eval()))\n\n'"
Experiments/Tensorflow/Deep_Networks/mnist_a2j_mlp_keras.py,0,"b'""""""\nDeep Neural Networks on Not MNIST using Keras\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n""""""\n# On command line: python3 mnist_a2j_mlp_keras.py\n# Prerequisite: tensorflow 1.0 and keras 2.0\n# must run mnist_a2j_2pickle.py first (one-time) to generate the data\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport pickle\nimport time\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nstart_time = time.time()\ndef elapsed(sec):\n    if sec<60:\n        return str(sec) + "" sec""\n    elif sec<(60*60):\n        return str(sec/60) + "" min""\n    else:\n        return str(sec/(60*60)) + "" hr""\n\n# use of pickle to speed up loading of data\npickle_file = open( ""mnist_a2j.pickle"", ""rb"" )\ndata = pickle.load(pickle_file)\ntest_labels = data[""test_labels""]\ntrain_labels = data[""all_labels""]\ntest_dataset = data[""test_dataset""]\ntrain_dataset = data[""all_dataset""]\ndel data\npickle_file.close()\n\nprint(""Training size: "", train_dataset.shape)\nprint(""Training labels: "", train_labels.shape)\nprint(""Test size: "", test_dataset.shape)\nprint(""Test labels: "", test_labels.shape)\n\nnum_labels = train_labels.shape[1]\n\nimage_size = 28\ninput_size = image_size*image_size\nbatch_size = 128\nhidden_units = 512*4\nlearning_rate = 0.0002\ndropout = 0.8\n\nmodel = Sequential()\nmodel.add(Dense(hidden_units, input_dim=input_size))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(hidden_units))\nmodel.add(Activation(\'relu\'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_labels))\nmodel.add(Activation(\'softmax\'))\n\nsgd = SGD(lr=learning_rate) # , decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=sgd,\n              metrics=[\'accuracy\'])\n\nmodel.fit(train_dataset, train_labels,\n          epochs=5,\n          batch_size=batch_size, shuffle=False)\nscore = np.asarray(model.evaluate(test_dataset, test_labels, batch_size=batch_size))*100.0\n# Accuracy: 86.0%\nprint(""\\nTest accuracy: %.1f%%"" % score[1])\nprint(""Elapsed: "" , elapsed(time.time() - start_time))\n'"
Experiments/Tensorflow/Deep_Networks/mnist_library.py,0,b'import matplotlib.image as img\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef readfile(path):\n    try:\n        data = img.imread(path)\n        return data\n    except:\n        return np.array([])\n\n\ndef displayimage(path):\n    data = img.imread(path)\n    plt.imshow(data)\n    plt.show()\n    return'
Experiments/Tensorflow/GAN/dcgan_mnist.py,0,"b'\'\'\'\nDCGAN on MNIST using Keras\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\nDependencies: tensorflow 1.0 and keras 2.0\nUsage: python3 dcgan_mnist.py\n\'\'\'\n\nimport numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\n\nimport matplotlib.pyplot as plt\n\nclass ElapsedTimer(object):\n    def __init__(self):\n        self.start_time = time.time()\n    def elapsed(self,sec):\n        if sec < 60:\n            return str(sec) + "" sec""\n        elif sec < (60 * 60):\n            return str(sec / 60) + "" min""\n        else:\n            return str(sec / (60 * 60)) + "" hr""\n    def elapsed_time(self):\n        print(""Elapsed: %s "" % self.elapsed(time.time() - self.start_time) )\n\nclass DCGAN(object):\n    def __init__(self, img_rows=28, img_cols=28, channel=1):\n\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.channel = channel\n        self.D = None   # discriminator\n        self.G = None   # generator\n        self.AM = None  # adversarial model\n        self.DM = None  # discriminator model\n\n    # (W\xe2\x88\x92F+2P)/S+1\n    def discriminator(self):\n        if self.D:\n            return self.D\n        self.D = Sequential()\n        depth = 64\n        dropout = 0.4\n        # In: 28 x 28 x 1, depth = 1\n        # Out: 14 x 14 x 1, depth=64\n        input_shape = (self.img_rows, self.img_cols, self.channel)\n        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n            padding=\'same\'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*2, 5, strides=2, padding=\'same\'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*4, 5, strides=2, padding=\'same\'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*8, 5, strides=1, padding=\'same\'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        # Out: 1-dim probability\n        self.D.add(Flatten())\n        self.D.add(Dense(1))\n        self.D.add(Activation(\'sigmoid\'))\n        self.D.summary()\n        return self.D\n\n    def generator(self):\n        if self.G:\n            return self.G\n        self.G = Sequential()\n        dropout = 0.4\n        depth = 64+64+64+64\n        dim = 7\n        # In: 100\n        # Out: dim x dim x depth\n        self.G.add(Dense(dim*dim*depth, input_dim=100))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation(\'relu\'))\n        self.G.add(Reshape((dim, dim, depth)))\n        self.G.add(Dropout(dropout))\n\n        # In: dim x dim x depth\n        # Out: 2*dim x 2*dim x depth/2\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/2), 5, padding=\'same\'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation(\'relu\'))\n\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/4), 5, padding=\'same\'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation(\'relu\'))\n\n        self.G.add(Conv2DTranspose(int(depth/8), 5, padding=\'same\'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation(\'relu\'))\n\n        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n        self.G.add(Conv2DTranspose(1, 5, padding=\'same\'))\n        self.G.add(Activation(\'sigmoid\'))\n        self.G.summary()\n        return self.G\n\n    def discriminator_model(self):\n        if self.DM:\n            return self.DM\n        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n        self.DM = Sequential()\n        self.DM.add(self.discriminator())\n        self.DM.compile(loss=\'binary_crossentropy\', optimizer=optimizer,\\\n            metrics=[\'accuracy\'])\n        return self.DM\n\n    def adversarial_model(self):\n        if self.AM:\n            return self.AM\n        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n        self.AM = Sequential()\n        self.AM.add(self.generator())\n        self.AM.add(self.discriminator())\n        self.AM.compile(loss=\'binary_crossentropy\', optimizer=optimizer,\\\n            metrics=[\'accuracy\'])\n        return self.AM\n\nclass MNIST_DCGAN(object):\n    def __init__(self):\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channel = 1\n\n        self.x_train = input_data.read_data_sets(""mnist"",\\\n        \tone_hot=True).train.images\n        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n        \tself.img_cols, 1).astype(np.float32)\n\n        self.DCGAN = DCGAN()\n        self.discriminator =  self.DCGAN.discriminator_model()\n        self.adversarial = self.DCGAN.adversarial_model()\n        self.generator = self.DCGAN.generator()\n\n    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n        noise_input = None\n        if save_interval>0:\n            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n        for i in range(train_steps):\n            images_train = self.x_train[np.random.randint(0,\n                self.x_train.shape[0], size=batch_size), :, :, :]\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            images_fake = self.generator.predict(noise)\n            x = np.concatenate((images_train, images_fake))\n            y = np.ones([2*batch_size, 1])\n            y[batch_size:, :] = 0\n            d_loss = self.discriminator.train_on_batch(x, y)\n\n            y = np.ones([batch_size, 1])\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            a_loss = self.adversarial.train_on_batch(noise, y)\n            log_mesg = ""%d: [D loss: %f, acc: %f]"" % (i, d_loss[0], d_loss[1])\n            log_mesg = ""%s  [A loss: %f, acc: %f]"" % (log_mesg, a_loss[0], a_loss[1])\n            print(log_mesg)\n            if save_interval>0:\n                if (i+1)%save_interval==0:\n                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n                        noise=noise_input, step=(i+1))\n\n    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n        filename = \'mnist.png\'\n        if fake:\n            if noise is None:\n                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n            else:\n                filename = ""mnist_%d.png"" % step\n            images = self.generator.predict(noise)\n        else:\n            i = np.random.randint(0, self.x_train.shape[0], samples)\n            images = self.x_train[i, :, :, :]\n\n        plt.figure(figsize=(10,10))\n        for i in range(images.shape[0]):\n            plt.subplot(4, 4, i+1)\n            image = images[i, :, :, :]\n            image = np.reshape(image, [self.img_rows, self.img_cols])\n            plt.imshow(image, cmap=\'gray\')\n            plt.axis(\'off\')\n        plt.tight_layout()\n        if save2file:\n            plt.savefig(filename)\n            plt.close(\'all\')\n        else:\n            plt.show()\n\nif __name__ == \'__main__\':\n    mnist_dcgan = MNIST_DCGAN()\n    timer = ElapsedTimer()\n    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n    timer.elapsed_time()\n    mnist_dcgan.plot_images(fake=True)\n    mnist_dcgan.plot_images(fake=False, save2file=True)\n'"
Experiments/Tensorflow/Intro/hello.py,3,"b'\'\'\'\nHello World on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python hello.py\n# Prerequisite: tensorflow (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# create a tensorflow constant string\nhello = tf.constant(\'Hello World!\')\n\n# run within a session and print\nwith tf.Session() as session:\n    print(""Tensorflow version: "" + tf.__version__)\n    print(hello.eval())\n'"
Experiments/Tensorflow/Machine_Learning/optfit_regression.py,16,"b'\'\'\'\nOptimal Fitting in Linear Regression\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 optfit_regression.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n#             : matplotlib (http://matplotlib.org/)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport math\n\n# Tunable parameters (Try changing the values and see what happens)\nsamples = 100\nlearning_rate = 0.01\n\n# xcoeff should be predicted by the model, yp\nxcoeff = tf.transpose(tf.constant([[1., 1., 1.]]))\n\n# a = tf.random_uniform([1, samples],-2.5,2.5)\na = tf.linspace(-2.5,2.5,samples)\n# Correct the shape\na = tf.reshape(a,[samples,1])\n\n# Inputs to form yp = a*a*xp[0] + a*xp[1] + xp[2], xp[] are the weights\n# Optimal fit since our data generating model is quadratic\nAp = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n\n# Inputs to form y = a*a*xcoeff[0] + a*xcoeff[1] + xcoeff[2]\nA = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n\n# Initial guess on coefficients of predicted linear model\nxp = tf.Variable(tf.random_uniform([3,1], -1.0, 1.0))\n\n# Predicted Model\nyp = tf.matmul(Ap,xp)\n\n# Observed outputs\ny = tf.matmul(A,xcoeff)\n# noise = tf.random_normal(y.get_shape(),stddev=0.8)\nnoise = tf.sin(math.pi*a)\ny = tf.add(y,noise)\n\n# The smaller the loss, the closer our prediction to the observed outputs\n# The loss model used is square of error (yp - y)\n# Miinimization of loss is done by Gradient Descent\nloss = tf.reduce_mean(tf.square(yp - y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    for i in range(1000):\n        session.run(train_step)\n        if ((i+1) % 100) == 0:\n            print(""%d : Loss=%0.1lf,  Predicted Parameters = %s"" % (i+1, loss.eval(), session.run(xp)))\n    # Let\'s plot\n    a = np.array(a.eval())\n    plt.plot(a, y.eval(), \'ro\', a, yp.eval(), \'b\')\n    red = mpatches.Patch(color=\'red\', label=\'Data\')\n    blue = mpatches.Patch(color=\'blue\', label=\'Model\')\n    plt.legend(handles=[red,blue])\n    plt.show()'"
Experiments/Tensorflow/Machine_Learning/overfit_regression.py,18,"b'\'\'\'\nOverfitting in Linear Regression\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 overfit_regression.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n#             : matplotlib (http://matplotlib.org/)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport math\n\n# Tunable parameters (Try changing the values and see what happens)\nsamples = 100\nlearning_rate = 0.0001\n\n# xcoeff should be predicted by the model, yp\nxcoeff = tf.transpose(tf.constant([[1., 1., 1.]]))\n\n# a = tf.random_uniform([1, samples],-2.5,2.5)\na = tf.linspace(-2.5,2.5,samples)\n# Correct the shape\na = tf.reshape(a,[samples,1])\n\n# In theory, polynomial degree greater than 2 will overfit but the training is still able to guess the weights\n# correctly for 3rd and 4th degree polynomials\n# Inputs to form yp = a*a*a*a*xp[0] + a*a*a*xp[1] + a*a*xp[2] + a*xp[3] + xp[4], xp[] are the weights\n# Overfit since our data generating model is quadratic\nAp = tf.concat([tf.concat([tf.concat([tf.concat([a*a*a*a*a*a,a*a*a*a],1),a*a],1),a],1),tf.ones_like(a)],1)\n\n# Inputs to form yp = a*a*a*xp[0] + a*a*xp[1] + a*xp[2] + xp[3], xp[] are the weights\n# Overfit since our data generating model is quadratic\n# Ap = tf.concat(1,[tf.concat(1,[tf.concat(1,[a*a*a,a*a]),a]),tf.ones_like(a)])\n\n# Inputs to form y = a*a*xcoeff[0] + a*xcoeff[1] + xcoeff[2]\nA = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n\n# Initial guess on coefficients of predicted linear model\nxp = tf.Variable(tf.random_uniform([5,1], -1.0, 1.0))\n\n# xp = tf.Variable(tf.random_uniform([4,1], -1.0, 1.0))\n\n# Predicted Model\nyp = tf.matmul(Ap,xp)\n\n# Observed outputs\ny = tf.matmul(A,xcoeff)\n# noise = tf.random_normal(y.get_shape(),stddev=0.8)\nnoise = tf.sin(math.pi*a)\ny = tf.add(y,noise)\n\n# The smaller the loss, the closer our prediction to the observed outputs\n# The loss model used is square of error (yp - y)\n# Miinimization of loss is done by Gradient Descent\nloss = tf.reduce_mean(tf.square(yp - y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    for i in range(10000):\n        session.run(train_step)\n        if ((i+1) % 100) == 0:\n            print(""%d : Loss=%0.1lf,  Predicted Parameters = %s"" % (i+1, loss.eval(), session.run(xp)))\n    # Let\'s plot\n    a = np.array(a.eval())\n    plt.plot(a, y.eval(), \'ro\', a, yp.eval(), \'b\')\n    red = mpatches.Patch(color=\'red\', label=\'Data\')\n    blue = mpatches.Patch(color=\'blue\', label=\'Model\')\n    plt.legend(handles=[red,blue])\n    plt.show()'"
Experiments/Tensorflow/Machine_Learning/pca.py,3,"b'\'\'\'\nPrincipal Component Analysis\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 pca.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport math\n\nprint(""Tensorflow version: "" + tf.__version__)\n\n# let\'s represent digits 1..5 by black(1)/white(0) 5x5pix images\n# Try tweaking the image after the first run of observation\n\none_1 = np.array([  [0., 1., 0., 0., 0.],\n                    [0., 1., 0., 0., 0.],\n                    [0., 1., 0., 0., 0.],\n                    [0., 1., 0., 0., 0.],\n                    [0., 1., 0., 0., 0.]\n                ])\n\none_2 = np.array([  [0., 0., 0., 1., 1.],\n                    [0., 0., 0., 1., 1.],\n                    [0., 0., 0., 1., 1.],\n                    [0., 0., 0., 1., 1.],\n                    [0., 0., 0., 1., 1.]\n                ])\n\ntwo_1 = np.array([  [1., 1., 1., 1., 1.],\n                    [0., 0., 0., 1., 0.],\n                    [0., 0., 1., 0., 0.],\n                    [0., 1., 0., 0., 0.],\n                    [1., 1., 1., 1., 1.]\n                ])\ntwo_2 = np.array([  [0., 1., 1., 1., 0.],\n                    [0., 0., 0., 1., 0.],\n                    [0., 0., 1., 0., 0.],\n                    [0., 1., 0., 0., 0.],\n                    [0., 1., 1., 1., 0.]\n                ])\n\nthree_1 = np.array([[1., 1., 1., 1., 1.],\n                    [0., 0., 1., 1., 1.],\n                    [1., 1., 1., 1., 1.],\n                    [0., 0., 1., 1., 1.],\n                    [1., 1., 1., 1., 1.]\n                ])\nthree_2 = np.array([[1., 1., 1., 1., 0.],\n                    [0., 0., 0., 1., 0.],\n                    [1., 1., 1., 1., 0.],\n                    [0., 0., 0., 1., 0.],\n                    [1., 1., 1., 1., 0.]\n                ])\n\nfour_1 = np.array([ [1., 0., 0., 0., 1.],\n                    [1., 0., 0., 0., 1.],\n                    [1., 1., 1., 1., 1.],\n                    [0., 0., 0., 0., 1.],\n                    [0., 0., 0., 0., 1.]\n                ])\nfour_2 = np.array([ [1., 1., 0., 0., 1.],\n                    [1., 1., 0., 0., 1.],\n                    [1., 1., 1., 1., 1.],\n                    [0., 0., 0., 0., 1.],\n                    [0., 0., 0., 0., 1.]\n                ])\n\nfive_1 = np.array([ [1., 1., 1., 1., 0.],\n                    [1., 0., 0., 0., 0.],\n                    [1., 1., 1., 1., 0.],\n                    [0., 0., 0., 1., 0.],\n                    [1., 1., 1., 1., 0.]\n                ])\nfive_2 = np.array([ [0., 1., 1., 1., 0.],\n                    [0., 1., 0., 0., 0.],\n                    [0., 1., 1., 1., 0.],\n                    [0., 0., 0., 1., 0.],\n                    [0., 1., 1., 1., 0.]\n                ])\n\n\n# Let\'s observe the largest eigenvector of each image\n\nw, v = np.linalg.eig(one_1)\nmax = np.argmax(w)\nprint(""1 eig: "", v[:,max])\nw, v = np.linalg.eig(one_2)\nmax = np.argmax(w)\nprint(""1 eig: "", v[:,max])\nprint("""")\n\nw, v = np.linalg.eig(two_1)\nmax = np.argmax(w)\nprint(""2 eig: "", v[:,max])\nw, v = np.linalg.eig(two_2)\nmax = np.argmax(w)\nprint(""2 eig: "", v[:,max])\nprint("""")\n\nw, v = np.linalg.eig(three_1)\nmax = np.argmax(w)\nprint(""3 eig: "", v[:,max])\nw, v = np.linalg.eig(three_2)\nmax = np.argmax(w)\nprint(""3 eig: "", v[:,max])\nprint("""")\n\nw, v = np.linalg.eig(four_1)\nmax = np.argmax(w)\nprint(""4 eig: "", v[:,max])\nw, v = np.linalg.eig(four_2)\nmax = np.argmax(w)\nprint(""4 eig: "", v[:,max])\nprint("""")\n\nw, v = np.linalg.eig(five_1)\nmax = np.argmax(w)\nprint(""5 eig: "", v[:,max])\nw, v = np.linalg.eig(five_2)\nmax = np.argmax(w)\nprint(""5 eig: "", v[:,max])\nprint("""")\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n'"
Experiments/Tensorflow/Machine_Learning/regression_nn.py,19,"b""'''\nNearest Neighbor\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n'''\n# On command line: python3 regression_nn.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport math\n\n# Tunable parameters (Try changing the values and see what happens)\nsamples = 10\n\n# xcoeff used by the model y\nxcoeff = tf.transpose(tf.constant([[1., 1., 1.]]))\n\n# Sample distribution x\nx = tf.linspace(-2.5,2.5,samples)\n# Correct the shape\na = tf.reshape(x,[samples,1])\n\n# New inputs whose outputs are to be predicted using nearest neighbor\nb = tf.linspace(-4.,4.,samples)\n\n# Correct the shape\nb = tf.reshape(b,[samples,1])\n\n# Inputs to form y = a*a*xcoeff[0] + a*xcoeff[1] + xcoeff[2]\nA = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n\n# Observed outputs\ny = tf.matmul(A,xcoeff)\n# noise = tf.random_normal(y.get_shape(),stddev=0.8)\nnoise = tf.sin(math.pi*a)\ny = tf.add(y,noise)\n\n# L1 distance of each b from sample distribution x\nl1 = tf.abs(tf.subtract(x,b))\n# get the nearest neighbor index\nnn = tf.argmin(l1,1)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    # the nearest neighbor to x based l1 between b and x\n    xnn = x.eval()[nn.eval()]\n    ann = tf.reshape(xnn, [samples, 1])\n    # Use the same model generating inputs y = a*a*xcoeff[0] + a*xcoeff[1] + xcoeff[2]\n    Ann = tf.concat([tf.concat([ann * ann, ann],1), tf.ones_like(ann)],1)\n    # Predicted outputs\n    yp = tf.matmul(Ann, xcoeff)\n    noisenn = tf.sin(math.pi * ann)\n    yp = tf.add(yp, noisenn)\n\n    # Debugging: print model inputs (x), new inputs (b), nearest neighbor inputs (xnn)\n    print(x.eval())\n    print(b.eval().reshape([1,samples]))\n    print(xnn)\n\n    # Let's plot\n    # a = np.array(a.eval())\n    plt.plot(a.eval(), y.eval(), 'ro', b.eval(), yp.eval(), 'b')\n    red = mpatches.Patch(color='red', label='Data')\n    blue = mpatches.Patch(color='blue', label='Model')\n    plt.legend(handles=[red,blue])\n    plt.show()"""
Experiments/Tensorflow/Machine_Learning/underfit_regression.py,16,"b'\'\'\'\nUnderfitting in Linear Regression\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 underfit_regression.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n#             : matplotlib (http://matplotlib.org/)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport math\n\n# Tunable parameters (Try changing the values and see what happens)\nsamples = 100\nlearning_rate = 0.1\n\n# xcoeff should be predicted by the model, yp\nxcoeff = tf.transpose(tf.constant([[1., 1., 1.]]))\n\n# The computation\n# a = tf.random_uniform([1, samples],-2.5,2.5)\na = tf.linspace(-2.5,2.5,samples)\n# Correct the shape\na = tf.reshape(a,[samples,1])\n\n# Inputs to form yp = a*xp[0] + xp[1], xp[] are the weights;\n# Underfit since our data generating model is quadratic\nAp = tf.concat([a,tf.ones_like(a)],1)\n\n# Data generating model y = a*a*xcoeff[0] + a*xcoeff[1] + xcoeff[2]\nA = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n\n# Initial guess on coefficients of predicted linear model\nxp = tf.Variable(tf.random_uniform([2,1], -1.0, 1.0))\n\n# Predicted Model\nyp = tf.matmul(Ap,xp)\n\n# Observed outputs\ny = tf.matmul(A,xcoeff)\n# noise = tf.random_normal(y.get_shape(),stddev=0.8)\nnoise = tf.sin(math.pi*a)\ny = tf.add(y,noise)\n\n# The smaller the loss, the closer our prediction to the observed outputs\n# The loss model used is square of error (yp - y)\n# Miinimization of loss is done by Gradient Descent\nloss = tf.reduce_mean(tf.square(yp - y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    for i in range(1000):\n        session.run(train_step)\n        if ((i+1) % 100) == 0:\n            print(""%d : Loss=%0.1lf,  Predicted Parameters = %s"" % (i+1, loss.eval(), session.run(xp)))\n    # Let\'s plot\n    a = np.array(a.eval())\n    plt.plot(a, y.eval(), \'ro\', a, yp.eval(), \'b\')\n    red = mpatches.Patch(color=\'red\', label=\'Data\')\n    blue = mpatches.Patch(color=\'blue\', label=\'Model\')\n    plt.legend(handles=[red,blue])\n    plt.show()'"
Experiments/Tensorflow/Math/decomposition.py,17,"b'\'\'\'\nMatrix Decomposition on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python decomposition.py\n# Prerequisite: tensorflow (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport numpy.linalg as la\n\nprint(""Tensorflow version: "" + tf.__version__)\n# Real symmetric matrix S of rank 2\nS = tf.constant([ [1.,2.], [2.,1.] ])\nprint(""S = "")\nprint(S.eval(session=tf.Session()))\n\n# Eigen Decomposition - for square symmetric matrices only\n# self_adjoint_eig works only bec symmetric matrix is equal to its self adjoint\n# otherwise, use np.linalg.eig\ne,Q = tf.self_adjoint_eig(S)\n# Diagonal matrix made of eigenvalues of S\nV = tf.diag(e)\n# S_ = S since S = Q*V*tran(Q) for real symmetric matrix\nS_ = tf.matmul(Q,tf.matmul(V,Q))\nprint(""S_ = S = "")\nprint(S_.eval(session=tf.Session()))\n\n# SVD decomposition\nd, U, V1 = tf.svd(S, full_matrices=True, compute_uv=True)\n# U and V1 are orthogonal matrices; I must be therefore an identity matrix\nI = tf.matmul(U,tf.transpose(V1))\nprint(""I = "")\nprint(I.eval(session=tf.Session()))\nD = tf.diag(d)\n# S_ = S since S = U*D*tran(V1)\nprint(""S_ = S = "")\nS_ = tf.matmul(U,tf.matmul(D,tf.transpose(V1)))\nprint(S_.eval(session=tf.Session()))\n\n# Moore-Penrose pseudoinverse\n# For non-square matrices, padding of m-n zero columns needed (see linear_inv.y)\nD = tf.transpose(tf.diag(np.reciprocal(d)))\nprint(""pseudo_inv(S) = "")\nS_ = tf.matmul(V1,tf.matmul(D,tf.transpose(U)))\nprint(S_.eval(session=tf.Session()))\n\n# inverse of S BUT applicable to non-singular square matrices only\nprint(""inv(S) = "")\nprint(tf.matrix_inverse(S).eval(session=tf.Session()))\n'"
Experiments/Tensorflow/Math/linear_algebra.py,35,"b'\'\'\'\nLinear Algebra on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python linear_algebra.py\n# Prerequisite: tensorflow (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\n\n# Square matrix A of rank 2\nA = tf.constant([ [1.,2.], [3.,4.] ])\n\n# 2x2 Square, Diagonal, Symmetric matrix B\nB = tf.diag([5.,6.])\n\n# 2x2 Square matrix\nC = tf.constant([ [1.,2.], [2.,4.] ])\n\n# 2x1 vector will all elements equal to 1\nx = tf.ones([2,1])\n\n# 2x1 vector will all elements equal to 2.0\nb = tf.fill([2,1], 2.)\n\n# 2x1 vector\ny = tf.constant([ [-1.], [1.] ])\n\n# run within a session and print\nwith tf.Session() as session:\n    print(""Tensorflow version: "" + tf.__version__)\n    tf.global_variables_initializer().run()\n\n    print(""A = "")\n    print(A.eval())\n\n    print(""B = "")\n    print(B.eval())\n\n    print(""C = "")\n    print(C.eval())\n\n    print(""x = "")\n    print(x.eval())\n\n    print(""b = "")\n    print(b.eval())\n\n    print(""y = "")\n    print(y.eval())\n\n    # Tensor multiplication\n    print(""Ax = "")\n    print(tf.matmul(A, x).eval())\n\n    # Tensor addition\n    print(""A + B ="")\n    print(tf.add(A, B).eval())\n\n    print(""A + b ="")\n    print(tf.add(A, b).eval())\n\n    # Rank of A and B; Number of indices to identify each element\n    print(""tensorRank(A) = "")\n    print(tf.rank(A).eval())\n    print(""tensorRank(C) = "")\n    print(tf.rank(C).eval())\n\n    # Matrix rank\n    print(""rank(A) = "")\n    print(np.linalg.matrix_rank(A.eval()))\n    print(""rank(C) = "")\n    print(np.linalg.matrix_rank(C.eval()))\n\n    # Transpose\n    print(""tran(A) = "")\n    print(tf.matrix_transpose(A).eval())\n    print(""tran(B) = "")\n    print(tf.matrix_transpose(B).eval())\n\n    # Inverse\n    print(""inv(A) = "")\n    print(tf.matrix_inverse(A).eval())\n    # Inverse of diagonal matrix has diag elements of the reciprocal of diag elements B\n    print(""inv(B) = "")\n    print(tf.matrix_inverse(B).eval())\n    print(""inv(C) = "") # since C has rank 1, this will cause error\n    try:\n        print(tf.matrix_inverse(C).eval())\n    except:\n        print(""C is not invertible"")\n\n    # Product of a matrix and its inverse is an identity (non-singular)\n    print(""A*inv(A) = Eye(2)"")\n    print( tf.matmul(A,tf.matrix_inverse(A)).eval() )\n\n    # Element-wise multiplication\n    print(""elem(A)*elem(B) = "")\n    print(tf.multiply(A,B).eval())\n\n    # Element-wise addition\n    print(""elem(A)+elem(B) = "")\n    print(tf.add(A,B).eval())\n\n    # Dot product\n    print(""x dot b"")\n    print(tf.matmul(x,b,transpose_a=True).eval())\n\n    # Identity matrix of same shape as A\n    print(""eye(A) = "")\n    I = tf.eye(A.get_shape().as_list()[0],A.get_shape().as_list()[1])\n    print(I.eval())\n\n    # Multiply eye(A) and A = A\n    print(""eye(A)*A = A = "")\n    print(tf.matmul(I,A).eval())\n    print(""A * eye(A) = A = "")\n    print(tf.matmul(A, I).eval())\n\n    # l1, l2, Frobenius norm\n    print(""l1(x) = "")\n    print(tf.reduce_sum(tf.abs(x)).eval())\n    print(""l2(x) = "")\n    print(tf.sqrt(tf.reduce_sum(tf.square(x))).eval())\n    print(""Frobenius(A) = "")\n    print(tf.sqrt(tf.reduce_sum(tf.square(A))).eval())\n    print(""Numpy l2(x) ="")\n    print(np.linalg.norm(x.eval(session=tf.Session())))\n    print(""Numpy Forbenius(A) ="")\n    print(np.linalg.norm(A.eval(session=tf.Session())))\n\n    # Can you write the L(inf) ?\n\n    # Orthogonal vectors; How do you make x and y orthonormal?\n    print(""x dot y"")\n    print(tf.matmul(x,y,transpose_a=True).eval())\n\n    # Eigenvalues and eigenvectors\n    print(""Numpy Eigenvalues of (A)="")\n    e, v = np.linalg.eig(A.eval())\n    print(e)\n    print(""Numpy Eigenvectors of (A)="")\n    print(v)\n\n    # Frobenius norm is equal to the trace of A*tran(A)\n    print(""Frobenius(A) = Tr(A*tran(A) = "")\n    print(tf.sqrt(tf.trace(tf.matmul(A,tf.transpose(A)))).eval())\n\n    # Determinant of A is the product of its eigenvalues\n    print(""det(A)="")\n    print(tf.matrix_determinant(A).eval())\n    # Determinant from eigenvalues\n    print(""det(A) as product of eigenvalues"")\n    print(tf.reduce_prod(e).eval())'"
Experiments/Tensorflow/Neural_Networks/logic_gate_linear_regressor.py,15,"b'\'\'\'\nLogical Operation by 2-layer Neural Networks (using TF Layers) on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 logic_gate_linear_regressor.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport tensorflow.contrib.learn as learn\nfrom tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn\ntf.logging.set_verbosity(tf.logging.INFO)\n\nlearning_rate = 0.01\n# try other values for nhidden\nnhidden = 16\n\ndef fnn_model_fn(features,labels,mode):\n    print(features)\n    print(labels)\n    # output_labels = tf.reshape(labels,[-1,1])\n    dense = tf.layers.dense(features,units=nhidden,activation=tf.nn.relu,use_bias=True)\n    print(dense)\n    logits = tf.layers.dense(dense,units=1,use_bias=True)\n    print(logits)\n    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=1)\n    if mode != learn.ModeKeys.EVAL:\n        # loss = tf.losses.sigmoid_cross_entropy(output_labels,logits)\n        # loss = tf.losses.mean_squared_error(labels=output_labels,predictions=logits)\n        loss = tf.losses.softmax_cross_entropy(\n             onehot_labels=onehot_labels, logits=logits)\n    if mode==learn.ModeKeys.TRAIN:\n        train_op = tf.contrib.layers.optimize_loss(\n            loss=loss,\n            global_step=tf.contrib.framework.get_global_step(),\n            learning_rate=learning_rate,\n            optimizer=""SGD"")\n    predictions = {\n        ""classes"": tf.round(logits),\n        ""probabilities"": tf.nn.softmax(\n             logits, name=""softmax_tensor"")\n    }\n    return model_fn.ModelFnOps(\n        mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n\n\ndef main(arg):\n    x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n    # try other logics; xor = [0., 1., 1., 0.], or = [0., 1., 1., 1.], and = [0., 0., 0., 1.], etc\n    y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n    classifier = learn.Estimator(model_fn=fnn_model_fn, model_dir=""/tmp/fnn"")\n    to_log = {""probabilities"": ""softmax_tensor""}\n    log_hook = tf.train.LoggingTensorHook(to_log, every_n_iter=10)\n    classifier.fit(x=x_data, y=y_data, batch_size=1, steps=50, monitors=[log_hook])\n    metrics = {\n        ""accuracy"":\n            learn.MetricSpec(\n                metric_fn=tf.metrics.accuracy, prediction_key=""classes""),\n    }\n\n    eval_results = classifier.evaluate(\n        x=x_data, y=y_data, metrics=metrics)\n    print(eval_results)\n\nif __name__ == ""__main__"":\n  tf.app.run()\n'"
Experiments/Tensorflow/Neural_Networks/logic_gate_logits.py,16,"b'\'\'\'\nLogical Operation by 2-layer Neural Networks (Logistic Regression) on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 logic_gate_logits.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\n\nlearning_rate = 0.3\nx_data = np.reshape(np.array( [[0., 0.], [0., 1.], [1., 0.], [1., 1.]], dtype=np.float32 ),[4,2])\n# try other logics; xor = [0., 1., 1., 0.], or = [0., 1., 1., 1.], and = [0., 0., 0., 1.], etc\nlogic_out = np.array([0., 1., 1., 0.], dtype=np.float32)\ny_data = np.reshape(logic_out,[4,1])\nn = y_data.shape[0]\n\nx = tf.placeholder(tf.float32, shape=(None, 2))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\n# try other values for nhidden\nnhidden = 16\nW0 = tf.Variable(tf.random_normal([2, nhidden],stddev=0.1))\nb0 = tf.Variable(tf.zeros([nhidden]))\n\nW1 = tf.Variable(tf.random_normal([nhidden, 1],stddev=0.1))\nb1 = tf.Variable(tf.zeros([1]))\n\nhidden = tf.matmul(x, W0) + b0\nyp = tf.matmul(tf.nn.relu(hidden), W1) + b1\nlogits = tf.nn.softmax(yp,dim=0)\n\nentropy = -tf.multiply(y,tf.log(logits))\nloss = tf.reduce_mean(entropy)\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    for i in range(1000):\n        # mini-batch can also be used but we have a small set of data only\n        # offset = (i*2)%(n-2)\n        # feed_dict ={x:x_data[offset:(offset+2),:], y:y_data[offset:(offset+2)]}\n        # so we use all data during training\n        feed_dict = {x: x_data[:,:], y: y_data[:]}\n        _, l, y_, yp_ = session.run([train_step, loss, y, logits],feed_dict=feed_dict)\n        if (i+1) % 100 == 0:\n            print(""--- %d: Loss = %lf"" % (i+1, l))\n    # Let\'s validate if we get the correct output given an input\n    print(""In: "")\n    # You can choose all inputs (0:4) or some by modifying the range eg (1:2)\n    input = x_data[0:4,:]\n    print(input)\n    hidden = tf.matmul(input, W0) + b0\n    print(""Predicted output:"")\n    yp = tf.nn.softmax(tf.matmul(tf.nn.relu(hidden), W1) + b1,dim=0)\n    print(print(1*np.greater(yp.eval(),0.25)))\n'"
Experiments/Tensorflow/Neural_Networks/logic_gate_mse.py,18,"b'\'\'\'\nLogical Operation by 2-layer Neural Networks on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python logic_gate_mse.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\n\nlearning_rate = 0.6\nx_data = np.reshape(np.array( [[0., 0.], [0., 1.], [1., 0.], [1., 1.]], dtype=np.float32 ),[4,2])\n# try other logics; xor = [0., 1., 1., 0.], or = [0., 1., 1., 1.], and = [0., 0., 0., 1.], etc\nlogic_out = np.array([0., 1., 1., 0.], dtype=np.float32)\ny_data = np.reshape(logic_out,[4,1])\n# n = y_data.shape[0]\n\nx = tf.placeholder(tf.float32, shape=(None, 2))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\n# try other values for nhidden\nnhidden = 16\nW0 = tf.Variable(tf.random_normal([2, nhidden],stddev=0.1))\nb0 = tf.Variable(tf.zeros([nhidden]))\n# b0 = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[nhidden]))\n\n\nW1 = tf.Variable(tf.random_normal([nhidden, 1],stddev=0.1))\nb1 = tf.Variable(tf.zeros([1]))\n# b1 = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[1]))\n\nhidden = tf.matmul(x, W0) + b0\nyp = tf.matmul(tf.nn.relu(hidden), W1) + b1\n# yp = tf.matmul(hidden, W1) + b1\n\nloss = tf.reduce_mean(tf.square(yp - y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    for i in range(1000):\n        # mini-batch can also be used but we have a small set of data only\n        # offset = (i*2)%(n-2)\n        # feed_dict ={x:x_data[offset:(offset+2),:], y:y_data[offset:(offset+2)]}\n        # so we use all data during training\n        feed_dict = {x: x_data[:,:], y: y_data[:]}\n        _, l = session.run([train_step, loss],feed_dict=feed_dict)\n        if (i+1) % 100 == 0:\n            print(""--- %d: Loss = %lf"" % (i+1, l))\n    # Let\'s validate if we get the correct output given an input\n    print(""In: "")\n    # You can choose all inputs (0:4) or some by modifying the range eg (1:2)\n    input = x_data[0:4,:]\n    print(input)\n    hidden = tf.matmul(input, W0) + b0\n    print(""Predicted output:"")\n    yp = tf.matmul(tf.nn.relu(hidden), W1) + b1\n    # yp = tf.matmul(hidden, W1) + b1\n    print(print(1*np.greater(yp.eval(),0.25)))\n'"
Experiments/Tensorflow/Probability/distributions.py,17,"b'\'\'\'\nCommon Distributions in TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 distributions.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Temporary directory for storing data for plotting using TensorBoard\nlogs_path = \'/tmp/tensorflow_logs/normal\'\n\nprint(""Tensorflow version: "" + tf.__version__)\n\n# Generate N=100k samples from Gaussian or Normal dist; mean=0.0, std=1.0\nwith tf.name_scope(\'normal\'):\n    normal_dist = tf.Variable(tf.random_normal([100000]))\n    # normal_dist = tf.mul(A,[1])\n\n# Generate N=100k samples from Uniform dist; min=0, max=None\nwith tf.name_scope(\'uniform\'):\n    uniform_dist = tf.Variable(tf.random_uniform([100000]))\n    # uniform_dist = tf.mul(B,[1])\n\n# Generate a multinomial with 4 categories (ie 0,1,2,3), 100 samples\nwith tf.name_scope(\'multinomial\'):\n    multi_dist = tf.Variable(tf.multinomial([[1.,1.,1.,1.]],100000))\n    # multi_dist = C # tf.mul(C,[1])\n\n# Create a summary to monitor normal dist\ntf.summary.histogram(""normal"", normal_dist)\n# Create a summary to monitor uniform dist\ntf.summary.histogram(""uniform"", uniform_dist)\n# Create a summary to monitor multinomial dist\ntf.summary.histogram(""multinomial"", multi_dist)\n\n# Merge all summaries into a single op\nmerged = tf.summary.merge_all()\n\n# Summary writer\nwith tf.Session() as session:\n    tf.global_variables_initializer().run()\n    # Logs to Tensorboard\n    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n    for i in range(2):\n        _, _, _, summary = session.run([normal_dist,uniform_dist,multi_dist, merged])\n        writer.add_summary(summary,i)\n    print(""Run on command line."")\n    print(""\\ttensorboard --logdir=/tmp/tensorflow_logs/normal "")\n    print(""Point your web browser to: http://localhost:6006/"")'"
Experiments/Tensorflow/RNN/rnn_words.py,17,"b'\'\'\'\nA Recurrent Neural Network (LSTM) implementation example using TensorFlow..\nNext word prediction after n_input words learned from text file.\nA story is automatically generated if the predicted word is fed back as input.\n\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport random\nimport collections\nimport time\n\nstart_time = time.time()\ndef elapsed(sec):\n    if sec<60:\n        return str(sec) + "" sec""\n    elif sec<(60*60):\n        return str(sec/60) + "" min""\n    else:\n        return str(sec/(60*60)) + "" hr""\n\n\n# Target log path\nlogs_path = \'/tmp/tensorflow/rnn_words\'\nwriter = tf.summary.FileWriter(logs_path)\n\n# Text file containing words for training\ntraining_file = \'belling_the_cat.txt\'\n\ndef read_data(fname):\n    with open(fname) as f:\n        content = f.readlines()\n    content = [x.strip() for x in content]\n    content = [word for i in range(len(content)) for word in content[i].split()]\n    content = np.array(content)\n    return content\n\ntraining_data = read_data(training_file)\nprint(""Loaded training data..."")\n\ndef build_dataset(words):\n    count = collections.Counter(words).most_common()\n    dictionary = dict()\n    for word, _ in count:\n        dictionary[word] = len(dictionary)\n    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, reverse_dictionary\n\ndictionary, reverse_dictionary = build_dataset(training_data)\nvocab_size = len(dictionary)\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 50000\ndisplay_step = 1000\nn_input = 3\n\n# number of units in RNN cell\nn_hidden = 512\n\n# tf Graph input\nx = tf.placeholder(""float"", [None, n_input, 1])\ny = tf.placeholder(""float"", [None, vocab_size])\n\n# RNN output node weights and biases\nweights = {\n    \'out\': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([vocab_size]))\n}\n\ndef RNN(x, weights, biases):\n\n    # reshape to [1, n_input]\n    x = tf.reshape(x, [-1, n_input])\n\n    # Generate a n_input-element sequence of inputs\n    # (eg. [had] [a] [general] -> [20] [6] [33])\n    x = tf.split(x,n_input,1)\n\n    # 2-layer LSTM, each layer has n_hidden units.\n    # Average Accuracy= 95.20% at 50k iter\n    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n\n    # 1-layer LSTM with n_hidden units but with lower accuracy.\n    # Average Accuracy= 90.60% 50k iter\n    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n\n    # generate prediction\n    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n\n    # there are n_input outputs but\n    # we only want the last output\n    return tf.matmul(outputs[-1], weights[\'out\']) + biases[\'out\']\n\npred = RNN(x, weights, biases)\n\n# Loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Model evaluation\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\n# Launch the graph\nwith tf.Session() as session:\n    session.run(init)\n    step = 0\n    offset = random.randint(0,n_input+1)\n    end_offset = n_input + 1\n    acc_total = 0\n    loss_total = 0\n\n    writer.add_graph(session.graph)\n\n    while step < training_iters:\n        # Generate a minibatch. Add some randomness on selection process.\n        if offset > (len(training_data)-end_offset):\n            offset = random.randint(0, n_input+1)\n\n        symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n\n        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n\n        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n        loss_total += loss\n        acc_total += acc\n        if (step+1) % display_step == 0:\n            print(""Iter= "" + str(step+1) + "", Average Loss= "" + \\\n                  ""{:.6f}"".format(loss_total/display_step) + "", Average Accuracy= "" + \\\n                  ""{:.2f}%"".format(100*acc_total/display_step))\n            acc_total = 0\n            loss_total = 0\n            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n            symbols_out = training_data[offset + n_input]\n            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n            print(""%s - [%s] vs [%s]"" % (symbols_in,symbols_out,symbols_out_pred))\n        step += 1\n        offset += (n_input+1)\n    print(""Optimization Finished!"")\n    print(""Elapsed time: "", elapsed(time.time() - start_time))\n    print(""Run on command line."")\n    print(""\\ttensorboard --logdir=%s"" % (logs_path))\n    print(""Point your web browser to: http://localhost:6006/"")\n    while True:\n        prompt = ""%s words: "" % n_input\n        sentence = input(prompt)\n        sentence = sentence.strip()\n        words = sentence.split(\' \')\n        if len(words) != n_input:\n            continue\n        try:\n            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n            for i in range(32):\n                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n                onehot_pred = session.run(pred, feed_dict={x: keys})\n                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n                sentence = ""%s %s"" % (sentence,reverse_dictionary[onehot_pred_index])\n                symbols_in_keys = symbols_in_keys[1:]\n                symbols_in_keys.append(onehot_pred_index)\n            print(sentence)\n        except:\n            print(""Word not in dictionary"")\n\n'"
Experiments/Tensorflow/Regression/linear_inv.py,18,"b'\'\'\'\nLinear Regression by SVD on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 linear_inv.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n#             : matplotlib (http://matplotlib.org/)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\n\n# Tunable parameters (Try changing the values and see what happens)\n# Variable samples >= 3 ; stddev > 0.; xcoeff are real numbers\nsamples = 100\nstddev = 1.0\n# xcoeff should be predicted by solving y = A*x using SVD; try changing the values\nxcoeff = tf.transpose(tf.constant([[2., -3.5, 12.5]]))\n\n# The computation\n# We get elements of A by sampling a normal distribution\na = tf.Variable(tf.random_normal([1, samples],stddev=stddev))\n# Sort to produce a nice plot later\nb, _ = tf.nn.top_k(a,k=samples)\n# Correct the shape\na = tf.reshape(b,[samples,1])\n\n# Inputs to form y = a*a*xcoeff[0] + a*xcoeff[1] + xcoeff[2]\nA = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n# Observable outputs\ny = tf.matmul(A,xcoeff)\n\n# SVD - Singular Value Decomposition\nd, U, V = tf.svd(A, full_matrices=True, compute_uv=True)\n\n# Wondering why tensorflow does not generate the diagonal matrix directly\n# D is the diagonal matrix with the diagonal elements being the reciprocal of d\nD = tf.diag(np.reciprocal(d))\n\n# D is actually nxm so zero padding is needed\nr = D.get_shape().as_list()[0]\nZ = tf.zeros([r,samples-r])\nD = tf.concat([D,Z],1)\n\n# This is linear regression by SVD\n# Ax = y  mxn nx1 = mx3 3x1 = mx1\n# x = Inv(A)y = nxm mx1 = 3xm mx1  ; x is our predicted xcoeff\n# Inv(A) = A_ = VDtran(U) = nxn nxm mxm = nxm = 3x3 3xm 3xm = 3xm\n\n# x (predicted xcoeff) is determined using Moore-Penrose pseudoinverse\nA_ = tf.matmul(V,tf.matmul(D,tf.transpose(U)))\nx = tf.matmul(A_,y)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    # values are the xcoeff\n    print(""Actual x ="")\n    print(xcoeff.eval())\n\n    print(""\\nPredicted x = "")\n    print(x.eval())\n\n    # Let\'s plot; Make all variables 1D by reshaping\n    a = tf.reshape(a,[a.get_shape().as_list()[0]])\n    y = tf.reshape(y,[y.get_shape().as_list()[0]])\n    # Predicted model, yp, based on x\n    yp = tf.matmul(A,x)\n    yp = tf.reshape(yp,[yp.get_shape().as_list()[0]])\n    plt.plot(a.eval(), y.eval(), \'ro\', a.eval(), yp.eval(), \'b\')\n    red = mpatches.Patch(color=\'red\', label=\'Data\')\n    blue = mpatches.Patch(color=\'blue\', label=\'Model\')\n    plt.legend(handles=[red,blue])\n    plt.show()\n'"
Experiments/Tensorflow/Regression/linear_regression.py,17,"b'\'\'\'\nLinear Regression by Machine Learning on TensorFlow\nAuthor: Rowel Atienza\nProject: https://github.com/roatienza/Deep-Learning-Experiments\n\'\'\'\n# On command line: python3 linear_regression.py\n# Prerequisite: tensorflow 1.0 (see tensorflow.org)\n#             : matplotlib (http://matplotlib.org/)\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\n\n# Tunable parameters (Try changing the values and see what happens)\n# Variable samples >= 3 ; stddev > 0.; xcoeff are real numbers\nsamples = 100\nstddev = 1.0\n# xcoeff should be predicted by the model, yp\nxcoeff = tf.transpose(tf.constant([[2., -3.5, 12.5]]))\nlearning_rate = 0.1\n\n# The computation\n# We get elements of A by sampling a normal distribution\n# a = tf.random_normal([samples,1],stddev=stddev)\na = tf.random_normal([1, samples],stddev=stddev)\n# a = tf.Variable(tf.random_normal([1, samples],stddev=stddev))\n# Sort to produce a nice plot later\nb, _ = tf.nn.top_k(a,k=samples)\n# Correct the shape\na = tf.reshape(b,[samples,1])\n\n# Inputs to form y = a*a*xp[0] + a*xp[1] + xp[2], xp[] are the weights\nA = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n\n# Initial guess on coefficients of predicted linear model\nxp = tf.Variable(tf.random_uniform([3,1], -1.0, 1.0))\n\n# Predicted Model\nyp = tf.matmul(A,xp)\n\n# Observed outputs\ny = tf.matmul(A,xcoeff)\n\n# The smaller the loss, the closer our prediction to the observed outputs\n# The loss model used is square of error (yp - y)\n# Miinimization of loss is done by Gradient Descent\nloss = tf.reduce_mean(tf.square(yp - y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    for i in range(100):\n        session.run(train_step)\n        if ((i+1) % 10) == 0:\n            print(""%d : Loss=%0.1lf,  Predicted Parameters = %s"" % (i+1, loss.eval(), session.run(xp)))\n    # Let\'s plot\n    # Note we have to resample a and save in a constant array a\n    # Before this, everytime you call a.eval(), it is resampled\n    a = np.array(a.eval())\n    A = tf.concat([tf.concat([a*a,a],1),tf.ones_like(a)],1)\n    yp = tf.matmul(A,xp)\n    y = tf.matmul(A,xcoeff)\n    plt.plot(a, y.eval(), \'ro\', a, yp.eval(), \'b\')\n    red = mpatches.Patch(color=\'red\', label=\'Data\')\n    blue = mpatches.Patch(color=\'blue\', label=\'Model\')\n    plt.legend(handles=[red,blue])\n    plt.show()'"
Experiments/Tensorflow/Word2Vec/word2vec.py,33,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n# Modified word2vec_basic.py to include Tensorbaord Embedding Viz - Rowel Atienza\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport math\nimport os\nimport random\nimport zipfile\n\nimport numpy as np\nfrom six.moves import urllib\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\nfrom tensorflow.contrib.tensorboard.plugins import projector\n\n# Step 1: Download the data.\nurl = \'http://mattmahoney.net/dc/\'\n\n# Target log path\nlogs_path = \'/tmp/tensorflow/word2vec\'\nwriter = tf.summary.FileWriter(logs_path)\n\ndef maybe_download(filename, expected_bytes):\n  """"""Download a file if not present, and make sure it\'s the right size.""""""\n  if not os.path.exists(filename):\n    filename, _ = urllib.request.urlretrieve(url + filename, filename)\n  statinfo = os.stat(filename)\n  if statinfo.st_size == expected_bytes:\n    print(\'Found and verified\', filename)\n  else:\n    print(statinfo.st_size)\n    raise Exception(\n        \'Failed to verify \' + filename + \'. Can you get to it with a browser?\')\n  return filename\n\nfilename = maybe_download(\'text8.zip\', 31344016)\n\n# Read the data into a list of strings.\ndef read_data(filename):\n  """"""Extract the first file enclosed in a zip file as a list of words""""""\n  with zipfile.ZipFile(filename) as f:\n    data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n  return data\n\nwords = read_data(filename)\nprint(\'Data size\', len(words))\n\n# Step 2: Build the dictionary and replace rare words with UNK token.\nvocabulary_size = 500\n\ndef build_dataset(words):\n  count = [[\'UNK\', -1]]\n  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n  dictionary = dict()\n  for word, _ in count:\n    dictionary[word] = len(dictionary)\n  data = list()\n  unk_count = 0\n  for word in words:\n    if word in dictionary:\n      index = dictionary[word]\n    else:\n      index = 0  # dictionary[\'UNK\']\n      unk_count += 1\n    data.append(index)\n  count[0][1] = unk_count\n  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n  return data, count, dictionary, reverse_dictionary\n\ndata, count, dictionary, reverse_dictionary = build_dataset(words)\ndel words  # Hint to reduce memory.\nprint(\'Most common words (+UNK)\', count[:5])\nprint(\'Sample data\', data[:10], [reverse_dictionary[i] for i in data[:10]])\n\ndata_index = 0\n\n# Step 3: Function to generate a training batch for the skip-gram model.\ndef generate_batch(batch_size, num_skips, skip_window):\n  global data_index\n  assert batch_size % num_skips == 0\n  assert num_skips <= 2 * skip_window\n  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n  span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n  buffer = collections.deque(maxlen=span)\n  for _ in range(span):\n    buffer.append(data[data_index])\n    data_index = (data_index + 1) % len(data)\n  for i in range(batch_size // num_skips):\n    target = skip_window  # target label at the center of the buffer\n    targets_to_avoid = [skip_window]\n    for j in range(num_skips):\n      while target in targets_to_avoid:\n        target = random.randint(0, span - 1)\n      targets_to_avoid.append(target)\n      batch[i * num_skips + j] = buffer[skip_window]\n      labels[i * num_skips + j, 0] = buffer[target]\n    buffer.append(data[data_index])\n    data_index = (data_index + 1) % len(data)\n  # Backtrack a little bit to avoid skipping words in the end of a batch\n  data_index = (data_index + len(data) - span) % len(data)\n  return batch, labels\n\nbatch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\nfor i in range(8):\n  print(batch[i], reverse_dictionary[batch[i]],\n        \'->\', labels[i, 0], reverse_dictionary[labels[i, 0]])\n\n# Step 4: Build and train a skip-gram model.\n\nbatch_size = 128\nembedding_size = 128  # Dimension of the embedding vector.\nskip_window = 1       # How many words to consider left and right.\nnum_skips = 2         # How many times to reuse an input to generate a label.\n\n# We pick a random validation set to sample nearest neighbors. Here we limit the\n# validation samples to the words that have a low numeric ID, which by\n# construction are also the most frequent.\nvalid_size = 16     # Random set of words to evaluate similarity on.\nvalid_window = 100  # Only pick dev samples in the head of the distribution.\nvalid_examples = np.random.choice(valid_window, valid_size, replace=False)\nnum_sampled = 64    # Number of negative examples to sample.\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n\n  # Input data.\n  train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n  train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n\n  # Ops and variables pinned to the CPU because of missing GPU implementation\n  with tf.device(\'/cpu:0\'):\n    # Look up embeddings for inputs.\n    embeddings = tf.Variable(\n        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0), name=""embeddings"")\n    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n\n    # Construct the variables for the NCE loss\n    nce_weights = tf.Variable(\n        tf.truncated_normal([vocabulary_size, embedding_size],\n                            stddev=1.0 / math.sqrt(embedding_size)))\n    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n\n  # Compute the average NCE loss for the batch.\n  # tf.nce_loss automatically draws a new sample of the negative labels each\n  # time we evaluate the loss.\n  loss = tf.reduce_mean(\n      tf.nn.nce_loss(weights=nce_weights,\n                     biases=nce_biases,\n                     labels=train_labels,\n                     inputs=embed,\n                     num_sampled=num_sampled,\n                     num_classes=vocabulary_size))\n\n  # Construct the SGD optimizer using a learning rate of 1.0.\n  optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n\n  # Compute the cosine similarity between minibatch examples and all embeddings.\n  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n  normalized_embeddings = embeddings / norm\n  print(tf.Tensor.get_shape(valid_dataset))\n  valid_embeddings = tf.nn.embedding_lookup(\n      normalized_embeddings, valid_dataset)\n  print(tf.Tensor.get_shape(valid_embeddings))\n  similarity = tf.matmul(\n      valid_embeddings, normalized_embeddings, transpose_b=True)\n\n  # Add variable initializer.\n  init = tf.global_variables_initializer()\n\n\n# Step 5: Begin training.\nnum_steps = 100001\n\nwith tf.Session(graph=graph) as session:\n  # We must initialize all variables before we use them.\n  init.run()\n  print(""Initialized"")\n\n  # Tensorboard Embedding\n  writer.add_graph(session.graph)\n  saver = tf.train.Saver()\n\n  metafilename = os.path.join(logs_path, ""metadata.tsv"")\n  metafile = open(metafilename, ""w"")\n  metafile.write(""label\\tid\\n"")\n  for i in xrange(vocabulary_size):\n    metafile.write(""%s\\t%d\\n"" % (reverse_dictionary[i],i))\n  metafile.close()\n\n  config = projector.ProjectorConfig()\n  embedding = config.embeddings.add()\n  embedding.tensor_name = embeddings.name\n  embedding.metadata_path = metafilename\n  projector.visualize_embeddings(writer, config)\n\n  average_loss = 0\n  for step in xrange(num_steps):\n    batch_inputs, batch_labels = generate_batch(\n        batch_size, num_skips, skip_window)\n    feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n\n    # We perform one update step by evaluating the optimizer op (including it\n    # in the list of returned values for session.run()\n    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n\n    average_loss += loss_val\n\n    if step % 2000 == 0:\n      # Log tensorboard data every 2000\n      saver.save(session, os.path.join(logs_path, ""model.ckpt""), step)\n\n      if step > 0:\n        average_loss /= 2000\n      # The average loss is an estimate of the loss over the last 2000 batches.\n      print(""Average loss at step "", step, "": "", average_loss)\n      average_loss = 0\n\n    # Note that this is expensive (~20% slowdown if computed every 500 steps)\n    if step % 10000 == 0:\n      sim = similarity.eval()\n      for i in xrange(valid_size):\n        valid_word = reverse_dictionary[valid_examples[i]]\n        top_k = 8  # number of nearest neighbors\n        nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n        log_str = ""Nearest to %s:"" % valid_word\n        for k in xrange(top_k):\n          close_word = reverse_dictionary[nearest[k]]\n          log_str = ""%s %s,"" % (log_str, close_word)\n        print(log_str)\n  final_embeddings = normalized_embeddings.eval()\n  print(""Run on command line."")\n  print(""\\ttensorboard --logdir=%s"" % (logs_path))\n  print(""Point your web browser to: http://localhost:6006/"")\n\n  while True:\n    print(""result = (arg1 - arg2) + arg OR result = arg1 + arg2 if arg is blank"")\n    arg1_in = """"\n    arg2_in = """"\n    arg_in = """"\n    while len(arg1_in)==0:\n      arg1_in = input(""arg1: "").strip(\' \').lower()\n    if arg1_in == ""quit"":\n      break\n    while len(arg2_in)==0:\n      arg2_in = input(""arg2: "").strip(\' \').lower()\n\n    arg_in = input(""arg : "").strip(\' \').lower()\n    if len(arg_in)==0:\n      arg1 = tf.nn.embedding_lookup(normalized_embeddings, [dictionary[arg1_in]])\n      arg2 = tf.nn.embedding_lookup(normalized_embeddings, [dictionary[arg2_in]])\n      result = tf.add(arg1,arg2)\n    else:\n      arg = tf.nn.embedding_lookup(normalized_embeddings, [dictionary[arg_in]])\n      arg1 = tf.nn.embedding_lookup(normalized_embeddings, [dictionary[arg1_in]])\n      arg2 = tf.nn.embedding_lookup(normalized_embeddings, [dictionary[arg2_in]])\n      result = tf.add(tf.subtract(arg1,arg2),arg)\n\n    similarity = tf.matmul(result, normalized_embeddings, transpose_b=True)\n    sim = similarity.eval()\n    for i in xrange(1):\n      valid_word = valid_word = ""%s + %s"" % (arg1_in,arg2_in)\n      if len(arg_in)>0:\n        valid_word = ""%s - %s + %s"" % (arg1_in,arg2_in,arg_in)\n      top_k = 8  # number of nearest neighbors\n      nearest = (-sim[i, :]).argsort()[1:top_k+1]\n      log_str = ""Nearest to %s:"" % valid_word\n      for k in xrange(top_k):\n        close_word = reverse_dictionary[nearest[k]]\n        if (close_word==arg_in or close_word==arg2_in or close_word==arg1_in):\n          continue\n        else:\n          log_str = ""%s %s"" % (log_str, close_word)\n          break\n\n      print(log_str)\n\n'"
