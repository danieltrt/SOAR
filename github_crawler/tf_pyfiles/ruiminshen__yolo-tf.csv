file_path,api_count,code
cache.py,7,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport argparse\nimport configparser\nimport shutil\nimport importlib\nimport pandas as pd\nimport tensorflow as tf\nimport utils\n\n\ndef main():\n    cachedir = utils.get_cachedir(config)\n    os.makedirs(cachedir, exist_ok=True)\n    path = os.path.join(cachedir, \'names\')\n    shutil.copyfile(os.path.expanduser(os.path.expandvars(config.get(\'cache\', \'names\'))), path)\n    with open(path, \'r\') as f:\n        names = [line.strip() for line in f]\n    name_index = dict([(name, i) for i, name in enumerate(names)])\n    datasets = [(os.path.basename(os.path.splitext(path)[0]), pd.read_csv(os.path.expanduser(os.path.expandvars(path)), sep=\'\\t\')) for path in config.get(\'cache\', \'datasets\').split(\':\')]\n    module = importlib.import_module(\'utils.data.cache\')\n    for profile in args.profile:\n        path = os.path.join(cachedir, profile + \'.tfrecord\')\n        tf.logging.info(\'write tfrecords file: \' + path)\n        with tf.python_io.TFRecordWriter(path) as writer:\n            for name, dataset in datasets:\n                tf.logging.info(\'loading %s %s dataset\' % (name, profile))\n                func = getattr(module, name)\n                for i, row in dataset.iterrows():\n                    tf.logging.info(\'loading data %d (%s)\' % (i, \', \'.join([k + \'=\' + str(v) for k, v in row.items()])))\n                    func(writer, name_index, profile, row, args.verify)\n    tf.logging.info(\'%s data are saved into %s\' % (str(args.profile), cachedir))\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-p\', \'--profile\', nargs=\'+\', default=[\'train\', \'val\', \'test\'])\n    parser.add_argument(\'-v\', \'--verify\', action=\'store_true\')\n    parser.add_argument(\'--level\', default=\'info\', help=\'logging level\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    with tf.Session() as sess:\n        main()\n'"
demo_data_augmentation.py,10,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport argparse\nimport configparser\nimport multiprocessing\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport utils.data\nimport utils.visualize\n\n\ndef main():\n    model = config.get(\'config\', \'model\')\n    cachedir = utils.get_cachedir(config)\n    with open(os.path.join(cachedir, \'names\'), \'r\') as f:\n        names = [line.strip() for line in f]\n    width = config.getint(model, \'width\')\n    height = config.getint(model, \'height\')\n    cell_width, cell_height = utils.calc_cell_width_height(config, width, height)\n    tf.logging.info(\'(width, height)=(%d, %d), (cell_width, cell_height)=(%d, %d)\' % (width, height, cell_width, cell_height))\n    batch_size = args.rows * args.cols\n    paths = [os.path.join(cachedir, profile + \'.tfrecord\') for profile in args.profile]\n    num_examples = sum(sum(1 for _ in tf.python_io.tf_record_iterator(path)) for path in paths)\n    tf.logging.warn(\'num_examples=%d\' % num_examples)\n    with tf.Session() as sess:\n        with tf.name_scope(\'batch\'):\n            image_rgb, labels = utils.data.load_image_labels(paths, len(names), width, height, cell_width, cell_height, config)\n            batch = tf.train.shuffle_batch((tf.cast(image_rgb, tf.uint8),) + labels, batch_size=batch_size,\n                capacity=config.getint(\'queue\', \'capacity\'), min_after_dequeue=config.getint(\'queue\', \'min_after_dequeue\'), num_threads=multiprocessing.cpu_count()\n            )\n        tf.global_variables_initializer().run()\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess, coord)\n        batch_image, batch_labels = sess.run([batch[0], batch[1:]])\n        coord.request_stop()\n        coord.join(threads)\n    batch_image = batch_image.astype(np.uint8)\n    fig, axes = plt.subplots(args.rows, args.cols)\n    for b, (ax, image) in enumerate(zip(axes.flat, batch_image)):\n        ax.imshow(image)\n        utils.visualize.draw_labels(ax, names, width, height, cell_width, cell_height, *[l[b] for l in batch_labels])\n        if args.grid:\n            ax.set_xticks(np.arange(0, width, width / cell_width))\n            ax.set_yticks(np.arange(0, height, height / cell_height))\n            ax.grid(which=\'both\')\n            ax.tick_params(labelbottom=\'off\', labelleft=\'off\')\n        else:\n            ax.set_xticks([])\n            ax.set_yticks([])\n    fig.tight_layout()\n    plt.show()\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-p\', \'--profile\', nargs=\'+\', default=[\'train\', \'val\'])\n    parser.add_argument(\'-g\', \'--grid\', action=\'store_true\')\n    parser.add_argument(\'--rows\', default=5, type=int)\n    parser.add_argument(\'--cols\', default=5, type=int)\n    parser.add_argument(\'--level\', default=\'info\', help=\'logging level\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    main()\n'"
demo_detect.py,19,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport argparse\nimport configparser\nimport importlib\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport utils.data\nimport utils.visualize\n\n\nclass Drawer(object):\n    def __init__(self, sess, names, cell_width, cell_height, image, labels, model, feed_dict):\n        self.sess = sess\n        self.names = names\n        self.cell_width, self.cell_height = cell_width, cell_height\n        self.image, self.labels = image, labels\n        self.model = model\n        self.feed_dict = feed_dict\n        self.fig = plt.figure()\n        self.ax = self.fig.gca()\n        height, width, _ = image.shape\n        self.scale = [width / self.cell_width, height / self.cell_height]\n        self.ax.imshow(image)\n        self.plots = utils.visualize.draw_labels(self.ax, names, width, height, cell_width, cell_height, *labels)\n        self.ax.set_xticks(np.arange(0, width, width / cell_width))\n        self.ax.set_yticks(np.arange(0, height, height / cell_height))\n        self.ax.grid(which=\'both\')\n        self.ax.tick_params(labelbottom=\'off\', labelleft=\'off\')\n        self.fig.canvas.mpl_connect(\'button_press_event\', self.onclick)\n        self.colors = [prop[\'color\'] for _, prop in zip(names, itertools.cycle(plt.rcParams[\'axes.prop_cycle\']))]\n    \n    def onclick(self, event):\n        for p in self.plots:\n            p.remove()\n        self.plots = []\n        height, width, _ = self.image.shape\n        ix = int(event.xdata * self.cell_width / width)\n        iy = int(event.ydata * self.cell_height / height)\n        self.plots.append(self.ax.add_patch(patches.Rectangle((ix * width / self.cell_width, iy * height / self.cell_height), width / self.cell_width, height / self.cell_height, linewidth=0, facecolor=\'black\', alpha=.2)))\n        index = iy * self.cell_width + ix\n        prob, iou, xy_min, wh = self.sess.run([self.model.prob[0][index], self.model.iou[0][index], self.model.xy_min[0][index], self.model.wh[0][index]], feed_dict=self.feed_dict)\n        xy_min = xy_min * self.scale\n        wh = wh * self.scale\n        for _prob, _iou, (x, y), (w, h), color in zip(prob, iou, xy_min, wh, self.colors):\n            index = np.argmax(_prob)\n            name = self.names[index]\n            _prob = _prob[index]\n            _conf = _prob * _iou\n            linewidth = min(_conf * 10, 3)\n            self.plots.append(self.ax.add_patch(patches.Rectangle((x, y), w, h, linewidth=linewidth, edgecolor=color, facecolor=\'none\')))\n            self.plots.append(self.ax.annotate(name + \' (%.1f%%, %.1f%%)\' % (_iou * 100, _prob * 100), (x, y), color=color))\n        self.fig.canvas.draw()\n\n\ndef main():\n    model = config.get(\'config\', \'model\')\n    cachedir = utils.get_cachedir(config)\n    with open(os.path.join(cachedir, \'names\'), \'r\') as f:\n        names = [line.strip() for line in f]\n    width = config.getint(model, \'width\')\n    height = config.getint(model, \'height\')\n    yolo = importlib.import_module(\'model.\' + model)\n    cell_width, cell_height = utils.calc_cell_width_height(config, width, height)\n    tf.logging.info(\'(width, height)=(%d, %d), (cell_width, cell_height)=(%d, %d)\' % (width, height, cell_width, cell_height))\n    with tf.Session() as sess:\n        paths = [os.path.join(cachedir, profile + \'.tfrecord\') for profile in args.profile]\n        num_examples = sum(sum(1 for _ in tf.python_io.tf_record_iterator(path)) for path in paths)\n        tf.logging.warn(\'num_examples=%d\' % num_examples)\n        image_rgb, labels = utils.data.load_image_labels(paths, len(names), width, height, cell_width, cell_height, config)\n        image_std = tf.image.per_image_standardization(image_rgb)\n        image_rgb = tf.cast(image_rgb, tf.uint8)\n        ph_image = tf.placeholder(image_std.dtype, [1] + image_std.get_shape().as_list(), name=\'ph_image\')\n        global_step = tf.contrib.framework.get_or_create_global_step()\n        builder = yolo.Builder(args, config)\n        builder(ph_image)\n        variables_to_restore = slim.get_variables_to_restore()\n        ph_labels = [tf.placeholder(l.dtype, [1] + l.get_shape().as_list(), name=\'ph_\' + l.op.name) for l in labels]\n        with tf.name_scope(\'total_loss\') as name:\n            builder.create_objectives(ph_labels)\n            total_loss = tf.losses.get_total_loss(name=name)\n        tf.global_variables_initializer().run()\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess, coord)\n        _image_rgb, _image_std, _labels = sess.run([image_rgb, image_std, labels])\n        coord.request_stop()\n        coord.join(threads)\n        feed_dict = dict([(ph, np.expand_dims(d, 0)) for ph, d in zip(ph_labels, _labels)])\n        feed_dict[ph_image] = np.expand_dims(_image_std, 0)\n        logdir = utils.get_logdir(config)\n        assert os.path.exists(logdir)\n        model_path = tf.train.latest_checkpoint(logdir)\n        tf.logging.info(\'load \' + model_path)\n        slim.assign_from_checkpoint_fn(model_path, variables_to_restore)(sess)\n        tf.logging.info(\'global_step=%d\' % sess.run(global_step))\n        tf.logging.info(\'total_loss=%f\' % sess.run(total_loss, feed_dict))\n        _ = Drawer(sess, names, builder.model.cell_width, builder.model.cell_height, _image_rgb, _labels, builder.model, feed_dict)\n        plt.show()\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-p\', \'--profile\', nargs=\'+\', default=[\'train\'])\n    parser.add_argument(\'--level\', default=\'info\', help=\'logging level\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    main()\n'"
detect.py,9,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport argparse\nimport configparser\nimport importlib\nimport itertools\nfrom PIL import Image, ExifTags\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport utils.preprocess\nimport utils.postprocess\n\n\ndef std(image):\n    return utils.preprocess.per_image_standardization(image)\n\n\ndef darknet(image):\n    return image / 255.\n\n\ndef read_image(path):\n    image = Image.open(path)\n    for key in ExifTags.TAGS.keys():\n        if ExifTags.TAGS[key] == \'Orientation\':\n            break\n    try:\n        exif = dict(image._getexif().items())\n    except AttributeError:\n        return image\n    if exif[key] == 3:\n        image = image.rotate(180, expand=True)\n    elif exif[key] == 6:\n        image = image.rotate(270, expand=True)\n    elif exif[key] == 8:\n        image = image.rotate(90, expand=True)\n    return image\n\n\ndef detect(sess, model, names, image, path):\n    preprocess = eval(args.preprocess)\n    _, height, width, _ = image.get_shape().as_list()\n    _image = read_image(path)\n    image_original = np.array(np.uint8(_image))\n    if len(image_original.shape) == 2:\n        image_original = np.repeat(np.expand_dims(image_original, -1), 3, 2)\n    image_height, image_width, _ = image_original.shape\n    image_std = preprocess(np.array(np.uint8(_image.resize((width, height)))).astype(np.float32))\n    feed_dict = {image: np.expand_dims(image_std, 0)}\n    tensors = [model.conf, model.xy_min, model.xy_max]\n    conf, xy_min, xy_max = sess.run([tf.check_numerics(t, t.op.name) for t in tensors], feed_dict=feed_dict)\n    boxes = utils.postprocess.non_max_suppress(conf[0], xy_min[0], xy_max[0], args.threshold, args.threshold_iou)\n    scale = [image_width / model.cell_width, image_height / model.cell_height]\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.imshow(image_original)\n    colors = [prop[\'color\'] for _, prop in zip(names, itertools.cycle(plt.rcParams[\'axes.prop_cycle\']))]\n    cnt = 0\n    for _conf, _xy_min, _xy_max in boxes:\n        index = np.argmax(_conf)\n        if _conf[index] > args.threshold:\n            wh = _xy_max - _xy_min\n            _xy_min = _xy_min * scale\n            _wh = wh * scale\n            linewidth = min(_conf[index] * 10, 3)\n            ax.add_patch(patches.Rectangle(_xy_min, _wh[0], _wh[1], linewidth=linewidth, edgecolor=colors[index], facecolor=\'none\'))\n            ax.annotate(names[index] + \' (%.1f%%)\' % (_conf[index] * 100), _xy_min, color=colors[index])\n            cnt += 1\n    fig.canvas.set_window_title(\'%d objects detected\' % cnt)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    return fig\n\n\ndef main():\n    model = config.get(\'config\', \'model\')\n    yolo = importlib.import_module(\'model.\' + model)\n    width = config.getint(model, \'width\')\n    height = config.getint(model, \'height\')\n    with tf.Session() as sess:\n        image = tf.placeholder(tf.float32, [1, height, width, 3], name=\'image\')\n        builder = yolo.Builder(args, config)\n        builder(image)\n        global_step = tf.contrib.framework.get_or_create_global_step()\n        model_path = tf.train.latest_checkpoint(utils.get_logdir(config))\n        tf.logging.info(\'load \' + model_path)\n        slim.assign_from_checkpoint_fn(model_path, tf.global_variables())(sess)\n        tf.logging.info(\'global_step=%d\' % sess.run(global_step))\n        path = os.path.expanduser(os.path.expandvars(args.path))\n        if os.path.isfile(path):\n            detect(sess, builder.model, builder.names, image, path)\n            plt.show()\n        else:\n            for dirpath, _, filenames in os.walk(path):\n                for filename in filenames:\n                    if os.path.splitext(filename)[-1].lower() in args.exts:\n                        _path = os.path.join(dirpath, filename)\n                        print(_path)\n                        detect(sess, builder.model, builder.names, image, _path)\n                        plt.show()\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'path\', help=\'input image path\')\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-p\', \'--preprocess\', default=\'std\', help=\'the preprocess function\')\n    parser.add_argument(\'-t\', \'--threshold\', type=float, default=0.3)\n    parser.add_argument(\'--threshold_iou\', type=float, default=0.4, help=\'IoU threshold\')\n    parser.add_argument(\'-e\', \'--exts\', nargs=\'+\', default=[\'.jpg\', \'.png\'])\n    parser.add_argument(\'--level\', default=\'info\', help=\'logging level\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    main()\n'"
detect_camera.py,9,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport argparse\nimport configparser\nimport importlib\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport utils.postprocess\n\n\ndef main():\n    model = config.get(\'config\', \'model\')\n    yolo = importlib.import_module(\'model.\' + model)\n    width = config.getint(model, \'width\')\n    height = config.getint(model, \'height\')\n    preprocess = getattr(importlib.import_module(\'detect\'), args.preprocess)\n    with tf.Session() as sess:\n        ph_image = tf.placeholder(tf.float32, [1, height, width, 3], name=\'ph_image\')\n        builder = yolo.Builder(args, config)\n        builder(ph_image)\n        global_step = tf.contrib.framework.get_or_create_global_step()\n        model_path = tf.train.latest_checkpoint(utils.get_logdir(config))\n        tf.logging.info(\'load \' + model_path)\n        slim.assign_from_checkpoint_fn(model_path, tf.global_variables())(sess)\n        tf.logging.info(\'global_step=%d\' % sess.run(global_step))\n        tensors = [builder.model.conf, builder.model.xy_min, builder.model.xy_max]\n        tensors = [tf.check_numerics(t, t.op.name) for t in tensors]\n        cap = cv2.VideoCapture(0)\n        try:\n            while True:\n                ret, image_bgr = cap.read()\n                assert ret\n                image_height, image_width, _ = image_bgr.shape\n                scale = [image_width / builder.model.cell_width, image_height / builder.model.cell_height]\n                image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n                image_std = np.expand_dims(preprocess(cv2.resize(image_rgb, (width, height))).astype(np.float32), 0)\n                feed_dict = {ph_image: image_std}\n                conf, xy_min, xy_max = sess.run(tensors, feed_dict)\n                boxes = utils.postprocess.non_max_suppress(conf[0], xy_min[0], xy_max[0], args.threshold, args.threshold_iou)\n                for _conf, _xy_min, _xy_max in boxes:\n                    index = np.argmax(_conf)\n                    if _conf[index] > args.threshold:\n                        _xy_min = (_xy_min * scale).astype(np.int)\n                        _xy_max = (_xy_max * scale).astype(np.int)\n                        cv2.rectangle(image_bgr, tuple(_xy_min), tuple(_xy_max), (255, 0, 255), 3)\n                        cv2.putText(image_bgr, builder.names[index] + \' (%.1f%%)\' % (_conf[index] * 100), tuple(_xy_min), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n                cv2.imshow(\'detection\', image_bgr)\n                cv2.waitKey(1)\n        finally:\n            cv2.destroyAllWindows()\n            cap.release()\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-p\', \'--preprocess\', default=\'std\', help=\'the preprocess function\')\n    parser.add_argument(\'-t\', \'--threshold\', type=float, default=0.3)\n    parser.add_argument(\'--threshold_iou\', type=float, default=0.4, help=\'IoU threshold\')\n    parser.add_argument(\'--level\', default=\'info\', help=\'logging level\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    main()\n'"
parse_darknet_yolo2.py,17,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport re\nimport time\nimport shutil\nimport argparse\nimport configparser\nimport operator\nimport itertools\nimport struct\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport model.yolo2.inference as inference\nimport utils\n\n\ndef transpose_weights(weights, num_anchors):\n    ksize1, ksize2, channels_in, _ = weights.shape\n    weights = weights.reshape([ksize1, ksize2, channels_in, num_anchors, -1])\n    coords = weights[:, :, :, :, 0:4]\n    iou = np.expand_dims(weights[:, :, :, :, 4], -1)\n    classes = weights[:, :, :, :, 5:]\n    return np.concatenate([iou, coords, classes], -1).reshape([ksize1, ksize2, channels_in, -1])\n\n\ndef transpose_biases(biases, num_anchors):\n    biases = biases.reshape([num_anchors, -1])\n    coords = biases[:, 0:4]\n    iou = np.expand_dims(biases[:, 4], -1)\n    classes = biases[:, 5:]\n    return np.concatenate([iou, coords, classes], -1).reshape([-1])\n\n\ndef transpose(sess, layer, num_anchors):\n    v = next(filter(lambda v: v.op.name.endswith(\'weights\'), layer))\n    sess.run(v.assign(transpose_weights(sess.run(v), num_anchors)))\n    v = next(filter(lambda v: v.op.name.endswith(\'biases\'), layer))\n    sess.run(v.assign(transpose_biases(sess.run(v), num_anchors)))\n\n\ndef main():\n    model = config.get(\'config\', \'model\')\n    cachedir = utils.get_cachedir(config)\n    with open(os.path.join(cachedir, \'names\'), \'r\') as f:\n        names = [line.strip() for line in f]\n    width, height = np.array(utils.get_downsampling(config)) * 13\n    anchors = pd.read_csv(os.path.expanduser(os.path.expandvars(config.get(model, \'anchors\'))), sep=\'\\t\').values\n    func = getattr(inference, config.get(model, \'inference\'))\n    with tf.Session() as sess:\n        image = tf.placeholder(tf.float32, [1, height, width, 3], name=\'image\')\n        func(image, len(names), len(anchors))\n        tf.contrib.framework.get_or_create_global_step()\n        tf.global_variables_initializer().run()\n        prog = re.compile(r\'[_\\w\\d]+\\/conv(\\d*)\\/(weights|biases|(BatchNorm\\/(gamma|beta|moving_mean|moving_variance)))$\')\n        variables = [(prog.match(v.op.name).group(1), v) for v in tf.global_variables() if prog.match(v.op.name)]\n        variables = sorted([[int(k) if k else -1, [v for _, v in g]] for k, g in itertools.groupby(variables, operator.itemgetter(0))], key=operator.itemgetter(0))\n        assert variables[0][0] == -1\n        variables[0][0] = len(variables) - 1\n        variables.insert(len(variables), variables.pop(0))\n        with tf.name_scope(\'assign\'):\n            with open(os.path.expanduser(os.path.expandvars(args.file)), \'rb\') as f:\n                major, minor, revision, seen = struct.unpack(\'4i\', f.read(16))\n                tf.logging.info(\'major=%d, minor=%d, revision=%d, seen=%d\' % (major, minor, revision, seen))\n                for i, layer in variables:\n                    tf.logging.info(\'processing layer %d\' % i)\n                    total = 0\n                    for suffix in [\'biases\', \'beta\', \'gamma\', \'moving_mean\', \'moving_variance\', \'weights\']:\n                        try:\n                            v = next(filter(lambda v: v.op.name.endswith(suffix), layer))\n                        except StopIteration:\n                            continue\n                        shape = v.get_shape().as_list()\n                        cnt = np.multiply.reduce(shape)\n                        total += cnt\n                        tf.logging.info(\'%s: %s=%d\' % (v.op.name, str(shape), cnt))\n                        p = struct.unpack(\'%df\' % cnt, f.read(4 * cnt))\n                        if suffix == \'weights\':\n                            ksize1, ksize2, channels_in, channels_out = shape\n                            p = np.reshape(p, [channels_out, channels_in, ksize1, ksize2]) # Darknet format\n                            p = np.transpose(p, [2, 3, 1, 0]) # TensorFlow format (ksize1, ksize2, channels_in, channels_out)\n                        sess.run(v.assign(p))\n                    tf.logging.info(\'%d parameters assigned\' % total)\n                remaining = os.fstat(f.fileno()).st_size - f.tell()\n            transpose(sess, layer, len(anchors))\n        saver = tf.train.Saver()\n        logdir = utils.get_logdir(config)\n        if args.delete:\n            tf.logging.warn(\'delete logging directory: \' + logdir)\n            shutil.rmtree(logdir, ignore_errors=True)\n        os.makedirs(logdir, exist_ok=True)\n        model_path = os.path.join(logdir, \'model.ckpt\')\n        tf.logging.info(\'save model into \' + model_path)\n        saver.save(sess, model_path)\n        if args.summary:\n            path = os.path.join(logdir, args.logname)\n            summary_writer = tf.summary.FileWriter(path)\n            summary_writer.add_graph(sess.graph)\n            tf.logging.info(\'tensorboard --logdir \' + logdir)\n    if remaining > 0:\n        tf.logging.warn(\'%d bytes remaining\' % remaining)\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'file\', help=\'Darknet .weights file\')\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-d\', \'--delete\', action=\'store_true\', help=\'delete logdir\')\n    parser.add_argument(\'-s\', \'--summary\', action=\'store_true\')\n    parser.add_argument(\'--logname\', default=time.strftime(\'%Y-%m-%d_%H-%M-%S\'), help=\'the name of TensorBoard log\')\n    parser.add_argument(\'--level\', default=\'info\', help=\'logging level\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    main()\n'"
train.py,37,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport argparse\nimport configparser\nimport importlib\nimport shutil\nimport time\nimport inspect\nimport multiprocessing\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport utils.data\n\n\ndef summary_scalar(config):\n    try:\n        reduce = eval(config.get(\'summary\', \'scalar_reduce\'))\n        for t in utils.match_tensor(config.get(\'summary\', \'scalar\')):\n            name = t.op.name\n            if len(t.get_shape()) > 0:\n                t = reduce(t)\n                tf.logging.warn(name + \' is not a scalar tensor, reducing by \' + reduce.__name__)\n            tf.summary.scalar(name, t)\n    except (configparser.NoSectionError, configparser.NoOptionError):\n        tf.logging.warn(inspect.stack()[0][3] + \' disabled\')\n\n\ndef summary_image(config):\n    try:\n        for t in utils.match_tensor(config.get(\'summary\', \'image\')):\n            name = t.op.name\n            channels = t.get_shape()[-1].value\n            if channels not in (1, 3, 4):\n                t = tf.expand_dims(tf.reduce_sum(t, -1), -1)\n            tf.summary.image(name, t, config.getint(\'summary\', \'image_max\'))\n    except (configparser.NoSectionError, configparser.NoOptionError):\n        tf.logging.warn(inspect.stack()[0][3] + \' disabled\')\n\n\ndef summary_histogram(config):\n    try:\n        for t in utils.match_tensor(config.get(\'summary\', \'histogram\')):\n            tf.summary.histogram(t.op.name, t)\n    except (configparser.NoSectionError, configparser.NoOptionError):\n        tf.logging.warn(inspect.stack()[0][3] + \' disabled\')\n\n\ndef summary(config):\n    summary_scalar(config)\n    summary_image(config)\n    summary_histogram(config)\n\n\ndef get_optimizer(config, name):\n    section = \'optimizer_\' + name\n    return {\n        \'adam\': lambda learning_rate: tf.train.AdamOptimizer(learning_rate, config.getfloat(section, \'beta1\'), config.getfloat(section, \'beta2\'), config.getfloat(section, \'epsilon\')),\n        \'adadelta\': lambda learning_rate: tf.train.AdadeltaOptimizer(learning_rate, config.getfloat(section, \'rho\'), config.getfloat(section, \'epsilon\')),\n        \'adagrad\': lambda learning_rate: tf.train.AdagradOptimizer(learning_rate, config.getfloat(section, \'initial_accumulator_value\')),\n        \'momentum\': lambda learning_rate: tf.train.MomentumOptimizer(learning_rate, config.getfloat(section, \'momentum\')),\n        \'rmsprop\': lambda learning_rate: tf.train.RMSPropOptimizer(learning_rate, config.getfloat(section, \'decay\'), config.getfloat(section, \'momentum\'), config.getfloat(section, \'epsilon\')),\n        \'ftrl\': lambda learning_rate: tf.train.FtrlOptimizer(learning_rate, config.getfloat(section, \'learning_rate_power\'), config.getfloat(section, \'initial_accumulator_value\'), config.getfloat(section, \'l1_regularization_strength\'), config.getfloat(section, \'l2_regularization_strength\')),\n        \'gd\': lambda learning_rate: tf.train.GradientDescentOptimizer(learning_rate),\n    }[name]\n\n\ndef main():\n    model = config.get(\'config\', \'model\')\n    logdir = utils.get_logdir(config)\n    if args.delete:\n        tf.logging.warn(\'delete logging directory: \' + logdir)\n        shutil.rmtree(logdir, ignore_errors=True)\n    cachedir = utils.get_cachedir(config)\n    with open(os.path.join(cachedir, \'names\'), \'r\') as f:\n        names = [line.strip() for line in f]\n    width = config.getint(model, \'width\')\n    height = config.getint(model, \'height\')\n    cell_width, cell_height = utils.calc_cell_width_height(config, width, height)\n    tf.logging.warn(\'(width, height)=(%d, %d), (cell_width, cell_height)=(%d, %d)\' % (width, height, cell_width, cell_height))\n    yolo = importlib.import_module(\'model.\' + model)\n    paths = [os.path.join(cachedir, profile + \'.tfrecord\') for profile in args.profile]\n    num_examples = sum(sum(1 for _ in tf.python_io.tf_record_iterator(path)) for path in paths)\n    tf.logging.warn(\'num_examples=%d\' % num_examples)\n    with tf.name_scope(\'batch\'):\n        image_rgb, labels = utils.data.load_image_labels(paths, len(names), width, height, cell_width, cell_height, config)\n        with tf.name_scope(\'per_image_standardization\'):\n            image_std = tf.image.per_image_standardization(image_rgb)\n        batch = tf.train.shuffle_batch((image_std,) + labels, batch_size=args.batch_size,\n            capacity=config.getint(\'queue\', \'capacity\'), min_after_dequeue=config.getint(\'queue\', \'min_after_dequeue\'),\n            num_threads=multiprocessing.cpu_count()\n        )\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    builder = yolo.Builder(args, config)\n    builder(batch[0], training=True)\n    with tf.name_scope(\'total_loss\') as name:\n        builder.create_objectives(batch[1:])\n        total_loss = tf.losses.get_total_loss(name=name)\n    variables_to_restore = slim.get_variables_to_restore(exclude=args.exclude)\n    with tf.name_scope(\'optimizer\'):\n        try:\n            decay_steps = config.getint(\'exponential_decay\', \'decay_steps\')\n            decay_rate = config.getfloat(\'exponential_decay\', \'decay_rate\')\n            staircase = config.getboolean(\'exponential_decay\', \'staircase\')\n            learning_rate = tf.train.exponential_decay(args.learning_rate, global_step, decay_steps, decay_rate, staircase=staircase)\n            tf.logging.warn(\'using a learning rate start from %f with exponential decay (decay_steps=%d, decay_rate=%f, staircase=%d)\' % (args.learning_rate, decay_steps, decay_rate, staircase))\n        except (configparser.NoSectionError, configparser.NoOptionError):\n            learning_rate = args.learning_rate\n            tf.logging.warn(\'using a staionary learning rate %f\' % args.learning_rate)\n        optimizer = get_optimizer(config, args.optimizer)(learning_rate)\n        tf.logging.warn(\'optimizer=\' + args.optimizer)\n        train_op = slim.learning.create_train_op(total_loss, optimizer, global_step,\n            clip_gradient_norm=args.gradient_clip, summarize_gradients=config.getboolean(\'summary\', \'gradients\'),\n        )\n    if args.transfer:\n        path = os.path.expanduser(os.path.expandvars(args.transfer))\n        tf.logging.warn(\'transferring from \' + path)\n        init_assign_op, init_feed_dict = slim.assign_from_checkpoint(path, variables_to_restore)\n        def init_fn(sess):\n            sess.run(init_assign_op, init_feed_dict)\n            tf.logging.warn(\'transferring from global_step=%d, learning_rate=%f\' % sess.run((global_step, learning_rate)))\n    else:\n        init_fn = lambda sess: tf.logging.warn(\'global_step=%d, learning_rate=%f\' % sess.run((global_step, learning_rate)))\n    summary(config)\n    tf.logging.warn(\'tensorboard --logdir \' + logdir)\n    slim.learning.train(train_op, logdir, master=args.master, is_chief=(args.task == 0),\n        global_step=global_step, number_of_steps=args.steps, init_fn=init_fn,\n        summary_writer=tf.summary.FileWriter(os.path.join(logdir, args.logname)),\n        save_summaries_secs=args.summary_secs, save_interval_secs=args.save_secs\n    )\n\n\ndef make_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-c\', \'--config\', nargs=\'+\', default=[\'config.ini\'], help=\'config file\')\n    parser.add_argument(\'-t\', \'--transfer\', help=\'transferring model from a .ckpt file\')\n    parser.add_argument(\'-e\', \'--exclude\', nargs=\'+\', help=\'exclude variables while transferring\')\n    parser.add_argument(\'-p\', \'--profile\', nargs=\'+\', default=[\'train\', \'val\'])\n    parser.add_argument(\'-s\', \'--steps\', type=int, default=None, help=\'max number of steps\')\n    parser.add_argument(\'-d\', \'--delete\', action=\'store_true\', help=\'delete logdir\')\n    parser.add_argument(\'-b\', \'--batch_size\', default=8, type=int, help=\'batch size\')\n    parser.add_argument(\'-o\', \'--optimizer\', default=\'adam\')\n    parser.add_argument(\'-n\', \'--logname\', default=time.strftime(\'%Y-%m-%d_%H-%M-%S\'), help=\'the name for TensorBoard\')\n    parser.add_argument(\'-g\', \'--gradient_clip\', default=0, type=float, help=\'gradient clip\')\n    parser.add_argument(\'-lr\', \'--learning_rate\', default=1e-6, type=float, help=\'learning rate\')\n    parser.add_argument(\'--seed\', type=int, default=None)\n    parser.add_argument(\'--summary_secs\', default=30, type=int, help=\'seconds to save summaries\')\n    parser.add_argument(\'--save_secs\', default=600, type=int, help=\'seconds to save model\')\n    parser.add_argument(\'--level\', help=\'logging level\')\n    parser.add_argument(\'--master\', default=\'\', help=\'master address\')\n    parser.add_argument(\'--task\', type=int, default=0, help=\'task ID\')\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = make_args()\n    config = configparser.ConfigParser()\n    utils.load_config(config, args.config)\n    if args.level:\n        tf.logging.set_verbosity(args.level.upper())\n    main()\n'"
model/__init__.py,0,b''
utils/__init__.py,2,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport re\nimport importlib\nimport inspect\nimport numpy as np\nimport matplotlib.patches as patches\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\n\ndef get_cachedir(config):\n    basedir = os.path.expanduser(os.path.expandvars(config.get(\'config\', \'basedir\')))\n    name = os.path.basename(config.get(\'cache\', \'names\'))\n    return os.path.join(basedir, \'cache\', name)\n\n\ndef get_logdir(config):\n    basedir = os.path.expanduser(os.path.expandvars(config.get(\'config\', \'basedir\')))\n    model = config.get(\'config\', \'model\')\n    inference = config.get(model, \'inference\')\n    name = os.path.basename(config.get(\'cache\', \'names\'))\n    return os.path.join(basedir, model, inference, name)\n\n\ndef get_inference(config):\n    model = config.get(\'config\', \'model\')\n    return getattr(importlib.import_module(\'.\'.join([\'model\', model, \'inference\'])), config.get(model, \'inference\'))\n\n\ndef get_downsampling(config):\n    model = config.get(\'config\', \'model\')\n    return getattr(importlib.import_module(\'.\'.join([\'model\', model, \'inference\'])), config.get(model, \'inference\').upper() + \'_DOWNSAMPLING\')\n\n\ndef calc_cell_width_height(config, width, height):\n    downsampling_width, downsampling_height = get_downsampling(config)\n    assert width % downsampling_width == 0\n    assert height % downsampling_height == 0\n    return width // downsampling_width, height // downsampling_height\n\n\ndef match_trainable_variables(pattern):\n    prog = re.compile(pattern)\n    return [v for v in tf.trainable_variables() if prog.match(v.op.name)]\n\n\ndef match_tensor(pattern):\n    prog = re.compile(pattern)\n    return [op.values()[0] for op in tf.get_default_graph().get_operations() if op.values() and prog.match(op.name)]\n\n\ndef load_config(config, paths):\n    for path in paths:\n        path = os.path.expanduser(os.path.expandvars(path))\n        assert os.path.exists(path)\n        config.read(path)\n\ndef get_available_gpus():\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos if x.device_type == \'GPU\']\n'"
utils/postprocess.py,0,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport numpy as np\n\n\ndef iou(xy_min1, xy_max1, xy_min2, xy_max2):\n    assert(not np.isnan(xy_min1).any())\n    assert(not np.isnan(xy_max1).any())\n    assert(not np.isnan(xy_min2).any())\n    assert(not np.isnan(xy_max2).any())\n    assert np.all(xy_min1 <= xy_max1)\n    assert np.all(xy_min2 <= xy_max2)\n    areas1 = np.multiply.reduce(xy_max1 - xy_min1)\n    areas2 = np.multiply.reduce(xy_max2 - xy_min2)\n    _xy_min = np.maximum(xy_min1, xy_min2) \n    _xy_max = np.minimum(xy_max1, xy_max2)\n    _wh = np.maximum(_xy_max - _xy_min, 0)\n    _areas = np.multiply.reduce(_wh)\n    assert _areas <= areas1\n    assert _areas <= areas2\n    return _areas / np.maximum(areas1 + areas2 - _areas, 1e-10)\n\n\ndef non_max_suppress(conf, xy_min, xy_max, threshold, threshold_iou):\n    _, _, classes = conf.shape\n    boxes = [(_conf, _xy_min, _xy_max) for _conf, _xy_min, _xy_max in zip(conf.reshape(-1, classes), xy_min.reshape(-1, 2), xy_max.reshape(-1, 2))]\n    for c in range(classes):\n        boxes.sort(key=lambda box: box[0][c], reverse=True)\n        for i in range(len(boxes) - 1):\n            box = boxes[i]\n            if box[0][c] <= threshold:\n                continue\n            for _box in boxes[i + 1:]:\n                if iou(box[1], box[2], _box[1], _box[2]) >= threshold_iou:\n                    _box[0][c] = 0\n    return boxes\n'"
utils/preprocess.py,18,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport inspect\nimport numpy as np\nimport tensorflow as tf\n\n\ndef per_image_standardization(image):\n    stddev = np.std(image)\n    return (image - np.mean(image)) / max(stddev, 1.0 / np.sqrt(np.multiply.reduce(image.shape)))\n\n\ndef random_crop(image, objects_coord, width_height, scale=1):\n    assert 0 < scale <= 1\n    section = inspect.stack()[0][3]\n    with tf.name_scope(section):\n        xy_min = tf.reduce_min(objects_coord[:, :2], 0)\n        xy_max = tf.reduce_max(objects_coord[:, 2:], 0)\n        margin = width_height - xy_max\n        shrink = tf.random_uniform([4], maxval=scale) * tf.concat([xy_min, margin], 0)\n        _xy_min = shrink[:2]\n        _wh = width_height - shrink[2:] - _xy_min\n        objects_coord = objects_coord - tf.tile(_xy_min, [2])\n        _xy_min_ = tf.cast(_xy_min, tf.int32)\n        _wh_ = tf.cast(_wh, tf.int32)\n        image = tf.image.crop_to_bounding_box(image, _xy_min_[1], _xy_min_[0], _wh_[1], _wh_[0])\n    return image, objects_coord, _wh\n\n\ndef flip_horizontally(image, objects_coord, width):\n    section = inspect.stack()[0][3]\n    with tf.name_scope(section):\n        image = tf.image.flip_left_right(image)\n        xmin, ymin, xmax, ymax = objects_coord[:, 0:1], objects_coord[:, 1:2], objects_coord[:, 2:3], objects_coord[:, 3:4]\n        objects_coord = tf.concat([width - xmax, ymin, width - xmin, ymax], 1)\n    return image, objects_coord\n\n\ndef random_flip_horizontally(image, objects_coord, width, probability=0.5):\n    section = inspect.stack()[0][3]\n    with tf.name_scope(section):\n        pred = tf.random_uniform([]) < probability\n        fn1 = lambda: flip_horizontally(image, objects_coord, width)\n        fn2 = lambda: (image, objects_coord)\n        return tf.cond(pred, fn1, fn2)\n\n\ndef random_grayscale(image, probability=0.5):\n    if probability <= 0:\n        return image\n    section = inspect.stack()[0][3]\n    with tf.name_scope(section):\n        pred = tf.random_uniform([]) < probability\n        fn1 = lambda: tf.tile(tf.image.rgb_to_grayscale(image), [1] * (len(image.get_shape()) - 1) + [3])\n        fn2 = lambda: image\n        return tf.cond(pred, fn1, fn2)\n'"
utils/verify.py,0,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport numpy as np\n\n\ndef abs_mean(data):\n    return np.sum(np.abs(data)) / np.float32(data.size)\n'"
utils/visualize.py,0,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\ndef draw_labels(ax, names, width, height, cell_width, cell_height, mask, prob, coords, xy_min, xy_max, areas, rtol=1e-3):\n    colors = [prop[\'color\'] for _, prop in zip(names, itertools.cycle(plt.rcParams[\'axes.prop_cycle\']))]\n    plots = []\n    for i, (_mask, _prob, _coords, _xy_min, _xy_max, _areas) in enumerate(zip(mask, prob, coords, xy_min, xy_max, areas)):\n        _mask = _mask.reshape([])\n        _coords = _coords.reshape([-1])\n        if np.any(_mask) > 0:\n            index = np.argmax(_prob)\n            iy = i // cell_width\n            ix = i % cell_width\n            plots.append(ax.add_patch(patches.Rectangle((ix * width / cell_width, iy * height / cell_height), width / cell_width, height / cell_height, linewidth=0, facecolor=colors[index], alpha=.2)))\n            #check coords\n            offset_x, offset_y, _w_sqrt, _h_sqrt = _coords\n            cell_x, cell_y = ix + offset_x, iy + offset_y\n            x, y = cell_x * width / cell_width, cell_y * height / cell_height\n            _w, _h = _w_sqrt * _w_sqrt, _h_sqrt * _h_sqrt\n            w, h = _w * width, _h * height\n            x_min, y_min = x - w / 2, y - h / 2\n            plots.append(ax.add_patch(patches.Rectangle((x_min, y_min), w, h, linewidth=1, edgecolor=colors[index], facecolor=\'none\')))\n            plots.append(ax.annotate(names[index], (x_min, y_min), color=colors[index]))\n            #check offset_xy_min and xy_max\n            wh = _xy_max - _xy_min\n            assert np.all(wh >= 0)\n            np.testing.assert_allclose(wh / [cell_width, cell_height], [[_w, _h]], rtol=rtol)\n            np.testing.assert_allclose(_xy_min + wh / 2, [[offset_x, offset_y]], rtol=rtol)\n    return plots\n'"
model/yolo/__init__.py,51,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport configparser\nimport os\nimport re\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport utils\nfrom . import inference\n\n\ndef calc_cell_xy(cell_height, cell_width, dtype=np.float32):\n    cell_base = np.zeros([cell_height, cell_width, 2], dtype=dtype)\n    for y in range(cell_height):\n        for x in range(cell_width):\n            cell_base[y, x, :] = [x, y]\n    return cell_base\n\n\nclass Model(object):\n    def __init__(self, net, scope, classes, boxes_per_cell, training=False):\n        _, self.cell_height, self.cell_width, _ = tf.get_default_graph().get_tensor_by_name(scope + \'/conv:0\').get_shape().as_list()\n        cells = self.cell_height * self.cell_width\n        with tf.name_scope(\'regress\'):\n            with tf.name_scope(\'inputs\'):\n                end = cells * classes\n                self.prob = tf.reshape(net[:, :end], [-1, cells, 1, classes], name=\'prob\')\n                inputs_remaining = tf.reshape(net[:, end:], [-1, cells, boxes_per_cell, 5], name=\'inputs_remaining\')\n                self.iou = tf.identity(inputs_remaining[:, :, :, 0], name=\'iou\')\n                self.offset_xy = tf.identity(inputs_remaining[:, :, :, 1:3], name=\'offset_xy\')\n                wh01_sqrt_base = tf.identity(inputs_remaining[:, :, :, 3:], name=\'wh01_sqrt_base\')\n            wh01 = tf.square(wh01_sqrt_base, name=\'wh01\')\n            wh01_sqrt = tf.abs(wh01_sqrt_base, name=\'wh01_sqrt\')\n            self.coords = tf.concat([self.offset_xy, wh01_sqrt], -1, name=\'coords\')\n            self.wh = tf.identity(wh01 * [self.cell_width, self.cell_height], name=\'wh\')\n            _wh = self.wh / 2\n            self.offset_xy_min = tf.identity(self.offset_xy - _wh, name=\'offset_xy_min\')\n            self.offset_xy_max = tf.identity(self.offset_xy + _wh, name=\'offset_xy_max\')\n            self.areas = tf.reduce_prod(self.wh, -1, name=\'areas\')\n        if not training:\n            with tf.name_scope(\'detection\'):\n                cell_xy = calc_cell_xy(self.cell_height, self.cell_width).reshape([1, cells, 1, 2])\n                self.xy = tf.identity(cell_xy + self.offset_xy, name=\'xy\')\n                self.xy_min = tf.identity(cell_xy + self.offset_xy_min, name=\'xy_min\')\n                self.xy_max = tf.identity(cell_xy + self.offset_xy_max, name=\'xy_max\')\n                self.conf = tf.identity(tf.expand_dims(self.iou, -1) * self.prob, name=\'conf\')\n        self.inputs = net\n        self.classes = classes\n        self.boxes_per_cell = boxes_per_cell\n\n\nclass Objectives(dict):\n    def __init__(self, model, mask, prob, coords, offset_xy_min, offset_xy_max, areas):\n        self.model = model\n        with tf.name_scope(\'true\'):\n            self.mask = tf.identity(mask, name=\'mask\')\n            self.prob = tf.identity(prob, name=\'prob\')\n            self.coords = tf.identity(coords, name=\'coords\')\n            self.offset_xy_min = tf.identity(offset_xy_min, name=\'offset_xy_min\')\n            self.offset_xy_max = tf.identity(offset_xy_max, name=\'offset_xy_max\')\n            self.areas = tf.identity(areas, name=\'areas\')\n        with tf.name_scope(\'iou\') as name:\n            _offset_xy_min = tf.maximum(model.offset_xy_min, self.offset_xy_min, name=\'_offset_xy_min\') \n            _offset_xy_max = tf.minimum(model.offset_xy_max, self.offset_xy_max, name=\'_offset_xy_max\')\n            _wh = tf.maximum(_offset_xy_max - _offset_xy_min, 0.0, name=\'_wh\')\n            _areas = tf.reduce_prod(_wh, -1, name=\'_areas\')\n            areas = tf.maximum(self.areas + model.areas - _areas, 1e-10, name=\'areas\')\n            iou = tf.truediv(_areas, areas, name=name)\n        with tf.name_scope(\'mask\'):\n            best_box_iou = tf.reduce_max(iou, 2, True, name=\'best_box_iou\')\n            best_box = tf.to_float(tf.equal(iou, best_box_iou), name=\'best_box\')\n            mask_best = tf.identity(self.mask * best_box, name=\'mask_best\')\n            mask_normal = tf.identity(1 - mask_best, name=\'mask_normal\')\n        with tf.name_scope(\'dist\'):\n            iou_dist = tf.square(model.iou - mask_best, name=\'iou_dist\')\n            coords_dist = tf.square(model.coords - self.coords, name=\'coords_dist\')\n            prob_dist = tf.square(model.prob - self.prob, name=\'prob_dist\')\n        with tf.name_scope(\'objectives\'):\n            cnt = np.multiply.reduce(iou_dist.get_shape().as_list())\n            self[\'iou_best\'] = tf.identity(tf.reduce_sum(mask_best * iou_dist) / cnt, name=\'iou_best\')\n            self[\'iou_normal\'] = tf.identity(tf.reduce_sum(mask_normal * iou_dist) / cnt, name=\'iou_normal\')\n            self[\'coords\'] = tf.identity(tf.reduce_sum(tf.expand_dims(mask_best, -1) * coords_dist) / cnt, name=\'coords\')\n            self[\'prob\'] = tf.identity(tf.reduce_sum(tf.expand_dims(self.mask, -1) * prob_dist) / cnt, name=\'prob\')\n\n\nclass Builder(object):\n    def __init__(self, args, config):\n        section = __name__.split(\'.\')[-1]\n        self.args = args\n        self.config = config\n        with open(os.path.join(utils.get_cachedir(config), \'names\'), \'r\') as f:\n            self.names = [line.strip() for line in f]\n        self.boxes_per_cell = config.getint(section, \'boxes_per_cell\')\n        self.func = getattr(inference, config.get(section, \'inference\'))\n    \n    def __call__(self, data, training=False):\n        _scope, self.output = self.func(data, len(self.names), self.boxes_per_cell, training=training)\n        with tf.name_scope(__name__.split(\'.\')[-1]):\n            self.model = Model(self.output, _scope, len(self.names), self.boxes_per_cell)\n    \n    def create_objectives(self, labels):\n        section = __name__.split(\'.\')[-1]\n        self.objectives = Objectives(self.model, *labels)\n        with tf.name_scope(\'weighted_objectives\'):\n            for key in self.objectives:\n                tf.add_to_collection(tf.GraphKeys.LOSSES, tf.multiply(self.objectives[key], self.config.getfloat(section + \'_hparam\', key), name=\'weighted_\' + key))\n'"
model/yolo/function.py,3,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport tensorflow as tf\n\n\ndef leaky_relu(inputs, alpha=.1):\n    with tf.name_scope(\'leaky_relu\') as name:\n        data = tf.identity(inputs, name=\'data\')\n        return tf.maximum(data, alpha * data, name=name)\n'"
model/yolo/inference.py,3,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport inspect\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nfrom .function import leaky_relu\n\n\ndef tiny(net, classes, boxes_per_cell, training=False):\n    scope = __name__.split(\'.\')[-2] + \'_\' + inspect.stack()[0][3]\n    net = tf.identity(net, name=\'%s/input\' % scope)\n    with slim.arg_scope([slim.layers.conv2d], kernel_size=[3, 3], activation_fn=leaky_relu), slim.arg_scope([slim.layers.max_pool2d], kernel_size=[2, 2], padding=\'SAME\'):\n        index = 0\n        net = slim.layers.conv2d(net, 16, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 32, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 64, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 128, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 256, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 512, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 512, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 1024, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, 256, scope=\'%s/conv%d\' % (scope, index))\n    net = tf.identity(net, name=\'%s/conv\' % scope)\n    _, cell_height, cell_width, _ = net.get_shape().as_list()\n    net = slim.layers.flatten(net, scope=\'%s/flatten\' % scope)\n    with slim.arg_scope([slim.layers.fully_connected], activation_fn=leaky_relu, weights_regularizer=slim.l2_regularizer(0.001)), slim.arg_scope([slim.layers.dropout], keep_prob=.5, is_training=training):\n        index = 0\n        net = slim.layers.fully_connected(net, 256, scope=\'%s/fc%d\' % (scope, index))\n        net = slim.layers.dropout(net, scope=\'%s/dropout%d\' % (scope, index))\n        index += 1\n        net = slim.layers.fully_connected(net, 4096, scope=\'%s/fc%d\' % (scope, index))\n        net = slim.layers.dropout(net, scope=\'%s/dropout%d\' % (scope, index))\n    net = slim.layers.fully_connected(net, cell_width * cell_height * (classes + boxes_per_cell * 5), activation_fn=None, scope=\'%s/fc\' % scope)\n    net = tf.identity(net, name=\'%s/output\' % scope)\n    return scope, net\n\nTINY_DOWNSAMPLING = (2 ** 6, 2 ** 6)\n'"
model/yolo2/__init__.py,54,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport configparser\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport utils\nfrom . import inference\nfrom .. import yolo\n\n\nclass Model(object):\n    def __init__(self, net, classes, anchors, training=False):\n        _, self.cell_height, self.cell_width, _ = net.get_shape().as_list()\n        cells = self.cell_height * self.cell_width\n        inputs = tf.reshape(net, [-1, cells, len(anchors), 5 + classes], name=\'inputs\')\n        with tf.name_scope(\'regress\'):\n            with tf.name_scope(\'inputs\'):\n                with tf.name_scope(\'inputs_sigmoid\') as name:\n                    inputs_sigmoid = tf.nn.sigmoid(inputs[:, :, :, :3], name=name)\n                self.iou = tf.identity(inputs_sigmoid[:, :, :, 0], name=\'iou\')\n                self.offset_xy = tf.identity(inputs_sigmoid[:, :, :, 1:3], name=\'offset_xy\')\n                with tf.name_scope(\'wh\') as name:\n                    self.wh = tf.identity(tf.exp(inputs[:, :, :, 3:5]) * np.reshape(anchors, [1, 1, len(anchors), -1]), name=name)\n                with tf.name_scope(\'prob\') as name:\n                    self.prob = tf.identity(tf.nn.softmax(inputs[:, :, :, 5:]), name=name)\n            self.areas = tf.reduce_prod(self.wh, -1, name=\'areas\')\n            _wh = self.wh / 2\n            self.offset_xy_min = tf.identity(self.offset_xy - _wh, name=\'offset_xy_min\')\n            self.offset_xy_max = tf.identity(self.offset_xy + _wh, name=\'offset_xy_max\')\n            self.wh01 = tf.identity(self.wh / np.reshape([self.cell_width, self.cell_height], [1, 1, 1, 2]), name=\'wh01\')\n            self.wh01_sqrt = tf.sqrt(self.wh01, name=\'wh01_sqrt\')\n            self.coords = tf.concat([self.offset_xy, self.wh01_sqrt], -1, name=\'coords\')\n        if not training:\n            with tf.name_scope(\'detection\'):\n                cell_xy = yolo.calc_cell_xy(self.cell_height, self.cell_width).reshape([1, cells, 1, 2])\n                self.xy = tf.identity(cell_xy + self.offset_xy, name=\'xy\')\n                self.xy_min = tf.identity(cell_xy + self.offset_xy_min, name=\'xy_min\')\n                self.xy_max = tf.identity(cell_xy + self.offset_xy_max, name=\'xy_max\')\n                self.conf = tf.identity(tf.expand_dims(self.iou, -1) * self.prob, name=\'conf\')\n        self.inputs = net\n        self.classes = classes\n        self.anchors = anchors\n\n\nclass Objectives(dict):\n    def __init__(self, model, mask, prob, coords, offset_xy_min, offset_xy_max, areas):\n        self.model = model\n        with tf.name_scope(\'true\'):\n            self.mask = tf.identity(mask, name=\'mask\')\n            self.prob = tf.identity(prob, name=\'prob\')\n            self.coords = tf.identity(coords, name=\'coords\')\n            self.offset_xy_min = tf.identity(offset_xy_min, name=\'offset_xy_min\')\n            self.offset_xy_max = tf.identity(offset_xy_max, name=\'offset_xy_max\')\n            self.areas = tf.identity(areas, name=\'areas\')\n        with tf.name_scope(\'iou\') as name:\n            _offset_xy_min = tf.maximum(model.offset_xy_min, self.offset_xy_min, name=\'_offset_xy_min\') \n            _offset_xy_max = tf.minimum(model.offset_xy_max, self.offset_xy_max, name=\'_offset_xy_max\')\n            _wh = tf.maximum(_offset_xy_max - _offset_xy_min, 0.0, name=\'_wh\')\n            _areas = tf.reduce_prod(_wh, -1, name=\'_areas\')\n            areas = tf.maximum(self.areas + model.areas - _areas, 1e-10, name=\'areas\')\n            iou = tf.truediv(_areas, areas, name=name)\n        with tf.name_scope(\'mask\'):\n            best_box_iou = tf.reduce_max(iou, 2, True, name=\'best_box_iou\')\n            best_box = tf.to_float(tf.equal(iou, best_box_iou), name=\'best_box\')\n            mask_best = tf.identity(self.mask * best_box, name=\'mask_best\')\n            mask_normal = tf.identity(1 - mask_best, name=\'mask_normal\')\n        with tf.name_scope(\'dist\'):\n            iou_dist = tf.square(model.iou - mask_best, name=\'iou_dist\')\n            coords_dist = tf.square(model.coords - self.coords, name=\'coords_dist\')\n            prob_dist = tf.square(model.prob - self.prob, name=\'prob_dist\')\n        with tf.name_scope(\'objectives\'):\n            cnt = np.multiply.reduce(iou_dist.get_shape().as_list())\n            self[\'iou_best\'] = tf.identity(tf.reduce_sum(mask_best * iou_dist) / cnt, name=\'iou_best\')\n            self[\'iou_normal\'] = tf.identity(tf.reduce_sum(mask_normal * iou_dist) / cnt, name=\'iou_normal\')\n            _mask_best = tf.expand_dims(mask_best, -1)\n            self[\'coords\'] = tf.identity(tf.reduce_sum(_mask_best * coords_dist) / cnt, name=\'coords\')\n            self[\'prob\'] = tf.identity(tf.reduce_sum(_mask_best * prob_dist) / cnt, name=\'prob\')\n\n\nclass Builder(yolo.Builder):\n    def __init__(self, args, config):\n        section = __name__.split(\'.\')[-1]\n        self.args = args\n        self.config = config\n        with open(os.path.join(utils.get_cachedir(config), \'names\'), \'r\') as f:\n            self.names = [line.strip() for line in f]\n        self.width = config.getint(section, \'width\')\n        self.height = config.getint(section, \'height\')\n        self.anchors = pd.read_csv(os.path.expanduser(os.path.expandvars(config.get(section, \'anchors\'))), sep=\'\\t\').values\n        self.func = getattr(inference, config.get(section, \'inference\'))\n    \n    def __call__(self, data, training=False):\n        _, self.output = self.func(data, len(self.names), len(self.anchors), training=training)\n        with tf.name_scope(__name__.split(\'.\')[-1]):\n            self.model = Model(self.output, len(self.names), self.anchors, training=training)\n    \n    def create_objectives(self, labels):\n        section = __name__.split(\'.\')[-1]\n        self.objectives = Objectives(self.model, *labels)\n        with tf.name_scope(\'weighted_objectives\'):\n            for key in self.objectives:\n                tf.add_to_collection(tf.GraphKeys.LOSSES, tf.multiply(self.objectives[key], self.config.getfloat(section + \'_hparam\', key), name=\'weighted_\' + key))\n'"
model/yolo2/function.py,6,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef reorg(net, stride=2, name=\'reorg\'):\n    batch_size, height, width, channels = net.get_shape().as_list()\n    _height, _width, _channel = height // stride, width // stride, channels * stride * stride\n    with tf.name_scope(name) as name:\n        net = tf.reshape(net, [batch_size, _height, stride, _width, stride, channels])\n        net = tf.transpose(net, [0, 1, 3, 2, 4, 5]) # batch_size, _height, _width, stride, stride, channels\n        net = tf.reshape(net, [batch_size, _height, _width, -1], name=name)\n    return net\n\n\ndef main():\n    image = [\n        (0, 1, 0, 1),\n        (2, 3, 2, 3),\n        (0, 1, 0, 1),\n        (2, 3, 2, 3),\n    ]\n    image = np.expand_dims(image, 0)\n    image = np.expand_dims(image, -1)\n    with tf.Session() as sess:\n        ph_image = tf.placeholder(tf.uint8, image.shape)\n        images = sess.run(reorg(ph_image), feed_dict={ph_image: image})\n    for i, image in enumerate(np.transpose(images[0], [2, 0, 1])):\n        data = np.unique(image)\n        assert len(data) == 1\n        assert data[0] == i\n\nif __name__ == \'__main__\':\n    main()\n'"
model/yolo2/inference.py,10,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport inspect\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nfrom ..yolo.function import leaky_relu\nfrom .function import reorg\n\n\ndef tiny(net, classes, num_anchors, training=False, center=True):\n    def batch_norm(net):\n        net = slim.batch_norm(net, center=center, scale=True, epsilon=1e-5, is_training=training)\n        if not center:\n            net = tf.nn.bias_add(net, slim.variable(\'biases\', shape=[tf.shape(net)[-1]], initializer=tf.zeros_initializer()))\n        return net\n    scope = __name__.split(\'.\')[-2] + \'_\' + inspect.stack()[0][3]\n    net = tf.identity(net, name=\'%s/input\' % scope)\n    with slim.arg_scope([slim.layers.conv2d], kernel_size=[3, 3], weights_initializer=tf.truncated_normal_initializer(stddev=0.1), normalizer_fn=batch_norm, activation_fn=leaky_relu), slim.arg_scope([slim.layers.max_pool2d], kernel_size=[2, 2], padding=\'SAME\'):\n        index = 0\n        channels = 16\n        for _ in range(5):\n            net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n            net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n            index += 1\n            channels *= 2\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        net = slim.layers.max_pool2d(net, stride=1, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        channels *= 2\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n    net = slim.layers.conv2d(net, num_anchors * (5 + classes), kernel_size=[1, 1], activation_fn=None, scope=\'%s/conv\' % scope)\n    net = tf.identity(net, name=\'%s/output\' % scope)\n    return scope, net\n\nTINY_DOWNSAMPLING = (2 ** 5, 2 ** 5)\n\n\ndef _tiny(net, classes, num_anchors, training=False):\n    return tiny(net, classes, num_anchors, training, False)\n\n_TINY_DOWNSAMPLING = (2 ** 5, 2 ** 5)\n\n\ndef darknet(net, classes, num_anchors, training=False, center=True):\n    def batch_norm(net):\n        net = slim.batch_norm(net, center=center, scale=True, epsilon=1e-5, is_training=training)\n        if not center:\n            net = tf.nn.bias_add(net, slim.variable(\'biases\', shape=[tf.shape(net)[-1]], initializer=tf.zeros_initializer()))\n        return net\n    scope = __name__.split(\'.\')[-2] + \'_\' + inspect.stack()[0][3]\n    net = tf.identity(net, name=\'%s/input\' % scope)\n    with slim.arg_scope([slim.layers.conv2d], kernel_size=[3, 3], normalizer_fn=batch_norm, activation_fn=leaky_relu), slim.arg_scope([slim.layers.max_pool2d], kernel_size=[2, 2], padding=\'SAME\'):\n        index = 0\n        channels = 32\n        for _ in range(2):\n            net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n            net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n            index += 1\n            channels *= 2\n        for _ in range(2):\n            net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n            index += 1\n            net = slim.layers.conv2d(net, channels / 2, kernel_size=[1, 1], scope=\'%s/conv%d\' % (scope, index))\n            index += 1\n            net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n            net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n            index += 1\n            channels *= 2\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels / 2, kernel_size=[1, 1], scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels / 2, kernel_size=[1, 1], scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        passthrough = tf.identity(net, name=scope + \'/passthrough\')\n        net = slim.layers.max_pool2d(net, scope=\'%s/max_pool%d\' % (scope, index))\n        index += 1\n        channels *= 2\n        # downsampling finished\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels / 2, kernel_size=[1, 1], scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels / 2, kernel_size=[1, 1], scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n        index += 1\n        with tf.name_scope(scope):\n            _net = reorg(passthrough)\n        net = tf.concat([_net, net], 3, name=\'%s/concat%d\' % (scope, index))\n        net = slim.layers.conv2d(net, channels, scope=\'%s/conv%d\' % (scope, index))\n    net = slim.layers.conv2d(net, num_anchors * (5 + classes), kernel_size=[1, 1], activation_fn=None, scope=\'%s/conv\' % scope)\n    net = tf.identity(net, name=\'%s/output\' % scope)\n    return scope, net\n\nDARKNET_DOWNSAMPLING = (2 ** 5, 2 ** 5)\n\n\ndef _darknet(net, classes, num_anchors, training=False):\n    return darknet(net, classes, num_anchors, training, False)\n\n_DARKNET_DOWNSAMPLING = (2 ** 5, 2 ** 5)\n'"
utils/data/__init__.py,50,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport re\nimport importlib\nimport inspect\nimport numpy as np\nimport matplotlib.patches as patches\nimport tensorflow as tf\nfrom .. import preprocess\n\n\ndef decode_image_objects(paths):\n    with tf.name_scope(inspect.stack()[0][3]):\n        with tf.name_scope(\'parse_example\'):\n            reader = tf.TFRecordReader()\n            _, serialized = reader.read(tf.train.string_input_producer(paths))\n            example = tf.parse_single_example(serialized, features={\n                \'imagepath\': tf.FixedLenFeature([], tf.string),\n                \'imageshape\': tf.FixedLenFeature([3], tf.int64),\n                \'objects\': tf.FixedLenFeature([2], tf.string),\n            })\n        imagepath = example[\'imagepath\']\n        objects = example[\'objects\']\n        with tf.name_scope(\'decode_objects\'):\n            objects_class = tf.decode_raw(objects[0], tf.int64, name=\'objects_class\')\n            objects_coord = tf.decode_raw(objects[1], tf.float32)\n            objects_coord = tf.reshape(objects_coord, [-1, 4], name=\'objects_coord\')\n        with tf.name_scope(\'load_image\'):\n            imagefile = tf.read_file(imagepath)\n            image = tf.image.decode_jpeg(imagefile, channels=3)\n    return image, example[\'imageshape\'], objects_class, objects_coord\n\n\ndef data_augmentation_full(image, objects_coord, width_height, config):\n    section = inspect.stack()[0][3]\n    with tf.name_scope(section):\n        random_crop = config.getfloat(section, \'random_crop\')\n        if random_crop > 0:\n            image, objects_coord, width_height = tf.cond(\n                tf.random_uniform([]) < config.getfloat(section, \'enable_probability\'),\n                lambda: preprocess.random_crop(image, objects_coord, width_height, random_crop),\n                lambda: (image, objects_coord, width_height)\n            )\n    return image, objects_coord, width_height\n\n\ndef resize_image_objects(image, objects_coord, width_height, width, height):\n    with tf.name_scope(inspect.stack()[0][3]):\n        image = tf.image.resize_images(image, [height, width])\n        factor = [width, height] / width_height\n        objects_coord = objects_coord * tf.tile(factor, [2])\n    return image, objects_coord\n\n\ndef data_augmentation_resized(image, objects_coord, width, height, config):\n    section = inspect.stack()[0][3]\n    with tf.name_scope(section):\n        if config.getboolean(section, \'random_flip_horizontally\'):\n            image, objects_coord = preprocess.random_flip_horizontally(image, objects_coord, width)\n        if config.getboolean(section, \'random_brightness\'):\n            image = tf.cond(\n                tf.random_uniform([]) < config.getfloat(section, \'enable_probability\'),\n                lambda: tf.image.random_brightness(image, max_delta=63),\n                lambda: image\n            )\n        if config.getboolean(section, \'random_saturation\'):\n            image = tf.cond(\n                tf.random_uniform([]) < config.getfloat(section, \'enable_probability\'),\n                lambda: tf.image.random_saturation(image, lower=0.5, upper=1.5),\n                lambda: image\n            )\n        if config.getboolean(section, \'random_hue\'):\n            image = tf.cond(\n                tf.random_uniform([]) < config.getfloat(section, \'enable_probability\'),\n                lambda: tf.image.random_hue(image, max_delta=0.032),\n                lambda: image\n            )\n        if config.getboolean(section, \'random_contrast\'):\n            image = tf.cond(\n                tf.random_uniform([]) < config.getfloat(section, \'enable_probability\'),\n                lambda: tf.image.random_contrast(image, lower=0.5, upper=1.5),\n                lambda: image\n            )\n        if config.getboolean(section, \'noise\'):\n            image = tf.cond(\n                tf.random_uniform([]) < config.getfloat(section, \'enable_probability\'),\n                lambda: image + tf.truncated_normal(tf.shape(image)) * tf.random_uniform([], 5, 15),\n                lambda: image\n            )\n        grayscale_probability = config.getfloat(section, \'grayscale_probability\')\n        if grayscale_probability > 0:\n            image = preprocess.random_grayscale(image, grayscale_probability)\n    return image, objects_coord\n\n\ndef transform_labels(objects_class, objects_coord, classes, cell_width, cell_height, dtype=np.float32):\n    cells = cell_height * cell_width\n    mask = np.zeros([cells, 1], dtype=dtype)\n    prob = np.zeros([cells, 1, classes], dtype=dtype)\n    coords = np.zeros([cells, 1, 4], dtype=dtype)\n    offset_xy_min = np.zeros([cells, 1, 2], dtype=dtype)\n    offset_xy_max = np.zeros([cells, 1, 2], dtype=dtype)\n    assert len(objects_class) == len(objects_coord)\n    xmin, ymin, xmax, ymax = objects_coord.T\n    x = cell_width * (xmin + xmax) / 2\n    y = cell_height * (ymin + ymax) / 2\n    ix = np.floor(x)\n    iy = np.floor(y)\n    offset_x = x - ix\n    offset_y = y - iy\n    w = xmax - xmin\n    h = ymax - ymin\n    index = (iy * cell_width + ix).astype(np.int)\n    mask[index, :] = 1\n    prob[index, :, objects_class] = 1\n    coords[index, 0, 0] = offset_x\n    coords[index, 0, 1] = offset_y\n    coords[index, 0, 2] = np.sqrt(w)\n    coords[index, 0, 3] = np.sqrt(h)\n    _w = w / 2 * cell_width\n    _h = h / 2 * cell_height\n    offset_xy_min[index, 0, 0] = offset_x - _w\n    offset_xy_min[index, 0, 1] = offset_y - _h\n    offset_xy_max[index, 0, 0] = offset_x + _w\n    offset_xy_max[index, 0, 1] = offset_y + _h\n    wh = offset_xy_max - offset_xy_min\n    assert np.all(wh >= 0)\n    areas = np.multiply.reduce(wh, -1)\n    return mask, prob, coords, offset_xy_min, offset_xy_max, areas\n\n\ndef decode_labels(objects_class, objects_coord, classes, cell_width, cell_height):\n    with tf.name_scope(inspect.stack()[0][3]):\n        mask, prob, coords, offset_xy_min, offset_xy_max, areas = tf.py_func(transform_labels, [objects_class, objects_coord, classes, cell_width, cell_height], [tf.float32] * 6)\n        cells = cell_height * cell_width\n        with tf.name_scope(\'reshape_labels\'):\n            mask = tf.reshape(mask, [cells, 1], name=\'mask\')\n            prob = tf.reshape(prob, [cells, 1, classes], name=\'prob\')\n            coords = tf.reshape(coords, [cells, 1, 4], name=\'coords\')\n            offset_xy_min = tf.reshape(offset_xy_min, [cells, 1, 2], name=\'offset_xy_min\')\n            offset_xy_max = tf.reshape(offset_xy_max, [cells, 1, 2], name=\'offset_xy_max\')\n            areas = tf.reshape(areas, [cells, 1], name=\'areas\')\n    return mask, prob, coords, offset_xy_min, offset_xy_max, areas\n\n\ndef load_image_labels(paths, classes, width, height, cell_width, cell_height, config):\n    with tf.name_scope(\'batch\'):\n        image, imageshape, objects_class, objects_coord = decode_image_objects(paths)\n        image = tf.cast(image, tf.float32)\n        width_height = tf.cast(imageshape[1::-1], tf.float32)\n        if config.getboolean(\'data_augmentation_full\', \'enable\'):\n            image, objects_coord, width_height = data_augmentation_full(image, objects_coord, width_height, config)\n        image, objects_coord = resize_image_objects(image, objects_coord, width_height, width, height)\n        if config.getboolean(\'data_augmentation_resized\', \'enable\'):\n            image, objects_coord = data_augmentation_resized(image, objects_coord, width, height, config)\n        image = tf.clip_by_value(image, 0, 255)\n        objects_coord = objects_coord / [width, height, width, height]\n        labels = decode_labels(objects_class, objects_coord, classes, cell_width, cell_height)\n    return image, labels\n'"
utils/data/cache.py,24,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport os\nimport inspect\nfrom PIL import Image\nimport tqdm\nimport numpy as np\nimport tensorflow as tf\nimport utils.data.voc\n\n\ndef verify_imageshape(imagepath, imageshape):\n    with Image.open(imagepath) as image:\n        return np.all(np.equal(image.size, imageshape[1::-1]))\n\n\ndef verify_image_jpeg(imagepath, imageshape):\n    scope = inspect.stack()[0][3]\n    try:\n        graph = tf.get_default_graph()\n        path = graph.get_tensor_by_name(scope + \'/path:0\')\n        decode = graph.get_tensor_by_name(scope + \'/decode_jpeg:0\')\n    except KeyError:\n        tf.logging.debug(\'creating decode_jpeg tensor\')\n        path = tf.placeholder(tf.string, name=scope + \'/path\')\n        imagefile = tf.read_file(path, name=scope + \'/read_file\')\n        decode = tf.image.decode_jpeg(imagefile, channels=3, name=scope + \'/decode_jpeg\')\n    try:\n        image = tf.get_default_session().run(decode, {path: imagepath})\n    except:\n        return False\n    return np.all(np.equal(image.shape[:2], imageshape[:2]))\n\n\ndef check_coords(objects_coord):\n    return np.all(objects_coord[:, 0] <= objects_coord[:, 2]) and np.all(objects_coord[:, 1] <= objects_coord[:, 3])\n\n\ndef verify_coords(objects_coord, imageshape):\n    assert check_coords(objects_coord)\n    return np.all(objects_coord >= 0) and np.all(objects_coord <= np.tile(imageshape[1::-1], [2]))\n\n\ndef fix_coords(objects_coord, imageshape):\n    assert check_coords(objects_coord)\n    objects_coord = np.maximum(objects_coord, np.zeros([4], dtype=objects_coord.dtype))\n    objects_coord = np.minimum(objects_coord, np.tile(np.asanyarray(imageshape[1::-1], objects_coord.dtype), [2]))\n    return objects_coord\n\n\ndef voc(writer, name_index, profile, row, verify=False):\n    root = os.path.expanduser(os.path.expandvars(row[\'root\']))\n    path = os.path.join(root, \'ImageSets\', \'Main\', profile) + \'.txt\'\n    if not os.path.exists(path):\n        tf.logging.warn(path + \' not exists\')\n        return False\n    with open(path, \'r\') as f:\n        filenames = [line.strip() for line in f]\n    annotations = [os.path.join(root, \'Annotations\', filename + \'.xml\') for filename in filenames]\n    _annotations = list(filter(os.path.exists, annotations))\n    if len(annotations) > len(_annotations):\n        tf.logging.warn(\'%d of %d images not exists\' % (len(annotations) - len(_annotations), len(annotations)))\n    cnt_noobj = 0\n    for path in tqdm.tqdm(_annotations):\n        imagename, imageshape, objects_class, objects_coord = utils.data.voc.load_dataset(path, name_index)\n        if len(objects_class) <= 0:\n            cnt_noobj += 1\n            continue\n        objects_class = np.array(objects_class, dtype=np.int64)\n        objects_coord = np.array(objects_coord, dtype=np.float32)\n        imagepath = os.path.join(root, \'JPEGImages\', imagename)\n        if verify:\n            if not verify_coords(objects_coord, imageshape):\n                tf.logging.error(\'failed to verify coordinates of \' + imagepath)\n                continue\n            if not verify_image_jpeg(imagepath, imageshape):\n                tf.logging.error(\'failed to decode \' + imagepath)\n                continue\n        assert len(objects_class) == len(objects_coord)\n        example = tf.train.Example(features=tf.train.Features(feature={\n            \'imagepath\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(imagepath)])),\n            \'imageshape\': tf.train.Feature(int64_list=tf.train.Int64List(value=imageshape)),\n            \'objects\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[objects_class.tostring(), objects_coord.tostring()])),\n        }))\n        writer.write(example.SerializeToString())\n    if cnt_noobj > 0:\n        tf.logging.warn(\'%d of %d images have no object\' % (cnt_noobj, len(filenames)))\n    return True\n\n\ndef coco(writer, name_index, profile, row, verify=False):\n    root = os.path.expanduser(os.path.expandvars(row[\'root\']))\n    year = str(row[\'year\'])\n    name = profile + year\n    path = os.path.join(root, \'annotations\', \'instances_%s.json\' % name)\n    if not os.path.exists(path):\n        tf.logging.warn(path + \' not exists\')\n        return False\n    import pycocotools.coco\n    coco = pycocotools.coco.COCO(path)\n    catIds = coco.getCatIds(catNms=list(name_index.keys()))\n    cats = coco.loadCats(catIds)\n    id_index = dict((cat[\'id\'], name_index[cat[\'name\']]) for cat in cats)\n    imgIds = coco.getImgIds()\n    path = os.path.join(root, name)\n    imgs = coco.loadImgs(imgIds)\n    _imgs = list(filter(lambda img: os.path.exists(os.path.join(path, img[\'file_name\'])), imgs))\n    if len(imgs) > len(_imgs):\n        tf.logging.warn(\'%d of %d images not exists\' % (len(imgs) - len(_imgs), len(imgs)))\n    cnt_noobj = 0\n    for img in tqdm.tqdm(_imgs):\n        annIds = coco.getAnnIds(imgIds=img[\'id\'], catIds=catIds, iscrowd=None)\n        anns = coco.loadAnns(annIds)\n        if len(anns) <= 0:\n            cnt_noobj += 1\n            continue\n        imagepath = os.path.join(path, img[\'file_name\'])\n        width, height = img[\'width\'], img[\'height\']\n        imageshape = [height, width, 3]\n        objects_class = np.array([id_index[ann[\'category_id\']] for ann in anns], dtype=np.int64)\n        objects_coord = [ann[\'bbox\'] for ann in anns]\n        objects_coord = [(x, y, x + w, y + h) for x, y, w, h in objects_coord]\n        objects_coord = np.array(objects_coord, dtype=np.float32)\n        if verify:\n            if not verify_coords(objects_coord, imageshape):\n                tf.logging.error(\'failed to verify coordinates of \' + imagepath)\n                continue\n            if not verify_image_jpeg(imagepath, imageshape):\n                tf.logging.error(\'failed to decode \' + imagepath)\n                continue\n        assert len(objects_class) == len(objects_coord)\n        example = tf.train.Example(features=tf.train.Features(feature={\n            \'imagepath\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(imagepath)])),\n            \'imageshape\': tf.train.Feature(int64_list=tf.train.Int64List(value=imageshape)),\n            \'objects\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[objects_class.tostring(), objects_coord.tostring()])),\n        }))\n        writer.write(example.SerializeToString())\n    if cnt_noobj > 0:\n        tf.logging.warn(\'%d of %d images have no object\' % (cnt_noobj, len(_imgs)))\n    return True\n'"
utils/data/voc.py,0,"b'""""""\nCopyright (C) 2017, \xe7\x94\xb3\xe7\x91\x9e\xe7\x8f\x89 (Ruimin Shen)\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n""""""\n\nimport sys\nimport bs4\n\n\ndef load_dataset(path, name_index):\n    with open(path, \'r\') as f:\n        anno = bs4.BeautifulSoup(f.read(), \'xml\').find(\'annotation\')\n    objects_class = []\n    objects_coord = []\n    for obj in anno.find_all(\'object\', recursive=False):\n        for bndbox, name in zip(obj.find_all(\'bndbox\', recursive=False), obj.find_all(\'name\', recursive=False)):\n            if name.text in name_index:\n                objects_class.append(name_index[name.text])\n                xmin = float(bndbox.find(\'xmin\').text) - 1\n                ymin = float(bndbox.find(\'ymin\').text) - 1\n                xmax = float(bndbox.find(\'xmax\').text) - 1\n                ymax = float(bndbox.find(\'ymax\').text) - 1\n                objects_coord.append((xmin, ymin, xmax, ymax))\n            else:\n                sys.stderr.write(name.text + \' not in names\\n\')\n    size = anno.find(\'size\')\n    return anno.find(\'filename\').text, (int(size.find(\'height\').text), int(size.find(\'width\').text), int(size.find(\'depth\').text)), objects_class, objects_coord\n'"
