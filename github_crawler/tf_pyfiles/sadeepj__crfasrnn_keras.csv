file_path,api_count,code
quick_run.py,0,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nfrom crfrnn_model import get_crfrnn_model_def\nimport util\nimport argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'--model\', help=\'full path to the .h5 model (download from https://goo.gl/ciEYZi)\',\n                        required=True)\n    parser.add_argument(\'--image\', help=\'full path to the image\', required=True)\n    parser.add_argument(\'--output\', help=\'full path to the output label image\', default=None)\n    args = parser.parse_args()\n\n    saved_model_path = args.model\n    input_file = args.image\n    output_file = args.output or input_file + \'_labels.png\'\n\n    model = get_crfrnn_model_def()\n    model.load_weights(saved_model_path)\n\n    img_data, img_h, img_w, original_size = util.get_preprocessed_image(input_file)\n    probs = model.predict(img_data, verbose=False)[0]\n    segmentation = util.get_label_image(probs, img_h, img_w, original_size)\n    segmentation.save(output_file)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
run_demo.py,0,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport sys\nsys.path.insert(1, \'./src\')\nfrom crfrnn_model import get_crfrnn_model_def\nimport util\n\n\ndef main():\n    input_file = \'image.jpg\'\n    output_file = \'labels.png\'\n\n    # Download the model from https://goo.gl/ciEYZi\n    saved_model_path = \'crfrnn_keras_model.h5\'\n\n    model = get_crfrnn_model_def()\n    model.load_weights(saved_model_path)\n\n    img_data, img_h, img_w, size = util.get_preprocessed_image(input_file)\n    probs = model.predict(img_data, verbose=False)[0]\n    segmentation = util.get_label_image(probs, img_h, img_w, size)\n    segmentation.save(output_file)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
src/crfrnn_layer.py,10,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nfrom keras.engine.topology import Layer\n\nimport high_dim_filter_loader\n\ncustom_module = high_dim_filter_loader.custom_module\n\n\ndef _diagonal_initializer(shape, *ignored, **ignored_too):\n    return np.eye(shape[0], shape[1], dtype=np.float32)\n\n\ndef _potts_model_initializer(shape, *ignored, **ignored_too):\n    return -1 * _diagonal_initializer(shape)\n\n\nclass CrfRnnLayer(Layer):\n    """""" Implements the CRF-RNN layer described in:\n\n    Conditional Random Fields as Recurrent Neural Networks,\n    S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang and P. Torr,\n    ICCV 2015\n    """"""\n\n    def __init__(self, image_dims, num_classes,\n                 theta_alpha, theta_beta, theta_gamma,\n                 num_iterations, **kwargs):\n        self.image_dims = image_dims\n        self.num_classes = num_classes\n        self.theta_alpha = theta_alpha\n        self.theta_beta = theta_beta\n        self.theta_gamma = theta_gamma\n        self.num_iterations = num_iterations\n        self.spatial_ker_weights = None\n        self.bilateral_ker_weights = None\n        self.compatibility_matrix = None\n        super(CrfRnnLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        # Weights of the spatial kernel\n        self.spatial_ker_weights = self.add_weight(name=\'spatial_ker_weights\',\n                                                   shape=(self.num_classes, self.num_classes),\n                                                   initializer=_diagonal_initializer,\n                                                   trainable=True)\n\n        # Weights of the bilateral kernel\n        self.bilateral_ker_weights = self.add_weight(name=\'bilateral_ker_weights\',\n                                                     shape=(self.num_classes, self.num_classes),\n                                                     initializer=_diagonal_initializer,\n                                                     trainable=True)\n\n        # Compatibility matrix\n        self.compatibility_matrix = self.add_weight(name=\'compatibility_matrix\',\n                                                    shape=(self.num_classes, self.num_classes),\n                                                    initializer=_potts_model_initializer,\n                                                    trainable=True)\n\n        super(CrfRnnLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        unaries = tf.transpose(inputs[0][0, :, :, :], perm=(2, 0, 1))\n        rgb = tf.transpose(inputs[1][0, :, :, :], perm=(2, 0, 1))\n\n        c, h, w = self.num_classes, self.image_dims[0], self.image_dims[1]\n        all_ones = np.ones((c, h, w), dtype=np.float32)\n\n        # Prepare filter normalization coefficients\n        spatial_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=False,\n                                                          theta_gamma=self.theta_gamma)\n        bilateral_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=True,\n                                                            theta_alpha=self.theta_alpha,\n                                                            theta_beta=self.theta_beta)\n        q_values = unaries\n\n        for i in range(self.num_iterations):\n            softmax_out = tf.nn.softmax(q_values, 0)\n\n            # Spatial filtering\n            spatial_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=False,\n                                                        theta_gamma=self.theta_gamma)\n            spatial_out = spatial_out / spatial_norm_vals\n\n            # Bilateral filtering\n            bilateral_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=True,\n                                                          theta_alpha=self.theta_alpha,\n                                                          theta_beta=self.theta_beta)\n            bilateral_out = bilateral_out / bilateral_norm_vals\n\n            # Weighting filter outputs\n            message_passing = (tf.matmul(self.spatial_ker_weights,\n                                         tf.reshape(spatial_out, (c, -1))) +\n                               tf.matmul(self.bilateral_ker_weights,\n                                         tf.reshape(bilateral_out, (c, -1))))\n\n            # Compatibility transform\n            pairwise = tf.matmul(self.compatibility_matrix, message_passing)\n\n            # Adding unary potentials\n            pairwise = tf.reshape(pairwise, (c, h, w))\n            q_values = unaries - pairwise\n\n        return tf.transpose(tf.reshape(q_values, (1, c, h, w)), perm=(0, 2, 3, 1))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
src/crfrnn_model.py,0,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, \\\n    Dropout, Conv2DTranspose, Cropping2D, Add\nfrom crfrnn_layer import CrfRnnLayer\n\n\ndef get_crfrnn_model_def():\n    """""" Returns Keras CRN-RNN model definition.\n\n    Currently, only 500 x 500 images are supported. However, one can get this to\n    work with different image sizes by adjusting the parameters of the Cropping2D layers\n    below.\n    """"""\n\n    channels, height, width = 3, 500, 500\n\n    # Input\n    input_shape = (height, width, 3)\n    img_input = Input(shape=input_shape)\n\n    # Add plenty of zero padding\n    x = ZeroPadding2D(padding=(100, 100))(img_input)\n\n    # VGG-16 convolution block 1\n    x = Conv2D(64, (3, 3), activation=\'relu\', padding=\'valid\', name=\'conv1_1\')(x)\n    x = Conv2D(64, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv1_2\')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool1\')(x)\n\n    # VGG-16 convolution block 2\n    x = Conv2D(128, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv2_1\')(x)\n    x = Conv2D(128, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv2_2\')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool2\', padding=\'same\')(x)\n\n    # VGG-16 convolution block 3\n    x = Conv2D(256, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv3_1\')(x)\n    x = Conv2D(256, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv3_2\')(x)\n    x = Conv2D(256, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv3_3\')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool3\', padding=\'same\')(x)\n    pool3 = x\n\n    # VGG-16 convolution block 4\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv4_1\')(x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv4_2\')(x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv4_3\')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool4\', padding=\'same\')(x)\n    pool4 = x\n\n    # VGG-16 convolution block 5\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv5_1\')(x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv5_2\')(x)\n    x = Conv2D(512, (3, 3), activation=\'relu\', padding=\'same\', name=\'conv5_3\')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\'pool5\', padding=\'same\')(x)\n\n    # Fully-connected layers converted to convolution layers\n    x = Conv2D(4096, (7, 7), activation=\'relu\', padding=\'valid\', name=\'fc6\')(x)\n    x = Dropout(0.5)(x)\n    x = Conv2D(4096, (1, 1), activation=\'relu\', padding=\'valid\', name=\'fc7\')(x)\n    x = Dropout(0.5)(x)\n    x = Conv2D(21, (1, 1), padding=\'valid\', name=\'score-fr\')(x)\n\n    # Deconvolution\n    score2 = Conv2DTranspose(21, (4, 4), strides=2, name=\'score2\')(x)\n\n    # Skip connections from pool4\n    score_pool4 = Conv2D(21, (1, 1), name=\'score-pool4\')(pool4)\n    score_pool4c = Cropping2D((5, 5))(score_pool4)\n    score_fused = Add()([score2, score_pool4c])\n    score4 = Conv2DTranspose(21, (4, 4), strides=2, name=\'score4\', use_bias=False)(score_fused)\n\n    # Skip connections from pool3\n    score_pool3 = Conv2D(21, (1, 1), name=\'score-pool3\')(pool3)\n    score_pool3c = Cropping2D((9, 9))(score_pool3)\n\n    # Fuse things together\n    score_final = Add()([score4, score_pool3c])\n\n    # Final up-sampling and cropping\n    upsample = Conv2DTranspose(21, (16, 16), strides=8, name=\'upsample\', use_bias=False)(score_final)\n    upscore = Cropping2D(((31, 37), (31, 37)))(upsample)\n\n    output = CrfRnnLayer(image_dims=(height, width),\n                         num_classes=21,\n                         theta_alpha=160.,\n                         theta_beta=3.,\n                         theta_gamma=3.,\n                         num_iterations=10,\n                         name=\'crfrnn\')([upscore, img_input])\n\n    # Build the model\n    model = Model(img_input, output, name=\'crfrnn_net\')\n\n    return model\n'"
src/high_dim_filter_loader.py,2,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport os\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\ncustom_module = tf.load_op_library(os.path.join(os.path.dirname(__file__), \'cpp\', \'high_dim_filter.so\'))\n\n\n@ops.RegisterGradient(\'HighDimFilter\')\ndef _high_dim_filter_grad(op, grad):\n    """""" Gradients for the HighDimFilter op. We only need to calculate the gradients\n    w.r.t. the first input (unaries) as we never need to backprop errors to the\n    second input (RGB values of the image).\n\n    Args:\n    op: The `high_dim_filter` operation that we are differentiating.\n    grad: Gradients with respect to the output of the `high_dim_filter` op.\n\n    Returns:\n    Gradients with respect to the input of `high_dim_filter`.\n    """"""\n\n    rgb = op.inputs[1]\n    grad_vals = custom_module.high_dim_filter(grad, rgb,\n                                              bilateral=op.get_attr(\'bilateral\'),\n                                              theta_alpha=op.get_attr(\'theta_alpha\'),\n                                              theta_beta=op.get_attr(\'theta_beta\'),\n                                              theta_gamma=op.get_attr(\'theta_gamma\'),\n                                              backwards=True)\n\n    return [grad_vals, tf.zeros_like(rgb)]\n'"
src/test_gradients.py,2,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.framework import constant_op\nimport high_dim_filter_loader\ncustom_module = high_dim_filter_loader.custom_module\n\n\nclass HighDimGradTest(tf.test.TestCase):\n\n    def test_high_dim_filter_grad(self):\n        x_shape = [5, 10, 10]\n\n        # Test inputs: unaries and RGB values\n        unary_np = np.random.randn(*x_shape).astype(np.float32)\n        rgb_np = np.random.randint(low=0, high=256, size=x_shape).astype(np.float32)\n\n        with self.test_session():\n            unary_tf = constant_op.constant(unary_np)\n            rgb_tf = constant_op.constant(rgb_np)\n            y_tf = custom_module.high_dim_filter(unary_tf, rgb_tf,\n                                                 bilateral=True,\n                                                 theta_alpha=1000.,\n                                                 theta_beta=1000.,\n                                                 theta_gamma=1000.)\n\n            out = gradient_checker.compute_gradient([unary_tf, rgb_tf], [x_shape, x_shape],\n                                                    y_tf, x_shape)\n\n            # We only need to compare gradients w.r.t. unaries\n            computed = out[0][0].flatten()\n            estimated = out[0][1].flatten()\n\n            mask = (computed != 0)\n            computed = computed[mask]\n            estimated = estimated[mask]\n            difference = computed - estimated\n\n            measure1 = np.mean(difference) / np.mean(computed)\n            measure2 = np.max(difference) / np.max(computed)\n\n            print(\'Gradient check: measure1 = {:.6f}, measure2 = {:.6f}\'.format(measure1, measure2))\n            self.assertLess(measure1, 1e-3, \'Errors found in the gradient computation.\')\n            self.assertLess(measure2, 2e-2, \'Errors found in the gradient computation.\')\n            print(\'Gradient check: success!\')\n\n\nif __name__ == \'__main__\':\n    tf.test.main()\n'"
src/util.py,0,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nfrom PIL import Image\n\n# Pascal VOC color palette for labels\n_PALETTE = [0, 0, 0,\n            128, 0, 0,\n            0, 128, 0,\n            128, 128, 0,\n            0, 0, 128,\n            128, 0, 128,\n            0, 128, 128,\n            128, 128, 128,\n            64, 0, 0,\n            192, 0, 0,\n            64, 128, 0,\n            192, 128, 0,\n            64, 0, 128,\n            192, 0, 128,\n            64, 128, 128,\n            192, 128, 128,\n            0, 64, 0,\n            128, 64, 0,\n            0, 192, 0,\n            128, 192, 0,\n            0, 64, 128,\n            128, 64, 128,\n            0, 192, 128,\n            128, 192, 128,\n            64, 64, 0,\n            192, 64, 0,\n            64, 192, 0,\n            192, 192, 0]\n\n_IMAGENET_MEANS = np.array([123.68, 116.779, 103.939], dtype=np.float32)  # RGB mean values\n\n\ndef get_preprocessed_image(file_name):\n    """""" Reads an image from the disk, pre-processes it by subtracting mean etc. and\n    returns a numpy array that\'s ready to be fed into a Keras model.\n\n    Note: This method assumes \'channels_last\' data format in Keras.\n    """"""\n\n    image = Image.open(file_name)\n    original_size = image.size\n    w, h = original_size\n    ratio = min(500.0 / w, 500.0 / h)\n    image = image.resize((int(w * ratio), int(h * ratio)), resample=Image.BILINEAR)\n    im = np.array(image).astype(np.float32)\n    assert im.ndim == 3, \'Only RGB images are supported.\'\n    im = im[:, :, :3]\n    im = im - _IMAGENET_MEANS\n    im = im[:, :, ::-1]  # Convert to BGR\n    img_h, img_w, _ = im.shape\n\n    pad_h = 500 - img_h\n    pad_w = 500 - img_w\n    im = np.pad(im, pad_width=((0, pad_h), (0, pad_w), (0, 0)), mode=\'constant\', constant_values=0)\n    return np.expand_dims(im.astype(np.float32), 0), img_h, img_w, original_size\n\n\ndef get_label_image(probs, img_h, img_w, original_size):\n    """""" Returns the label image (PNG with Pascal VOC colormap) given the probabilities.\n\n    Note: This method assumes \'channels_last\' data format.\n    """"""\n\n    labels = probs.argmax(axis=2).astype(\'uint8\')[:img_h, :img_w]\n    label_im = Image.fromarray(labels, \'P\')\n    label_im.putpalette(_PALETTE)\n    label_im = label_im.resize(original_size)\n    return label_im\n'"
