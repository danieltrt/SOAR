file_path,api_count,code
benchmarks/inceptionv3/classify_image_timed.py,21,"b'# Copyright 2015 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Simple image classification with Inception.\n\nRun image classification with Inception trained on ImageNet 2012 Challenge data\nset.\n\nThis program creates a graph from a saved GraphDef protocol buffer,\nand runs inference on an input JPEG image. It outputs human readable\nstrings of the top 5 predictions along with their probabilities.\n\nChange the --image_file argument to any jpg image to compute a\nclassification of that image.\n\nPlease see the tutorial and website for a detailed description of how\nto use this script to perform image recognition.\n\nhttps://tensorflow.org/tutorials/image_recognition/\n\nThis file has been modified by Sam Abrahams to print out basic run-time\ninformation. These modifications have been surrounded with the comments:\n""MODIFICATION BY SAM ABRAHAMS"" and ""END OF MODIFICATION""\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os.path\nimport re\nimport sys\nimport tarfile\n\n# MODIFICATION BY SAM ABRAHAMS\nimport time\n# END OF MODIFICATION\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\n# classify_image_graph_def.pb:\n#   Binary representation of the GraphDef protocol buffer.\n# imagenet_synset_to_human_label_map.txt:\n#   Map from synset ID to a human readable string.\n# imagenet_2012_challenge_label_map_proto.pbtxt:\n#   Text representation of a protocol buffer mapping a label to synset ID.\ntf.app.flags.DEFINE_string(\n    \'model_dir\', \'/tmp/imagenet\',\n    """"""Path to classify_image_graph_def.pb, """"""\n    """"""imagenet_synset_to_human_label_map.txt, and """"""\n    """"""imagenet_2012_challenge_label_map_proto.pbtxt."""""")\ntf.app.flags.DEFINE_string(\'image_file\', \'\',\n                           """"""Absolute path to image file."""""")\ntf.app.flags.DEFINE_integer(\'num_top_predictions\', 5,\n                            """"""Display this many predictions."""""")\n# MODIFICATION BY SAM ABRAHAMS\ntf.app.flags.DEFINE_integer(\'warmup_runs\', 10,\n                            ""Number of times to run Session before starting test"")\ntf.app.flags.DEFINE_integer(\'num_runs\', 25,\n                            ""Number of sample runs to collect benchmark statistics"")\n# END OF MODIFICATION\n\n# pylint: disable=line-too-long\nDATA_URL = \'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\'\n# pylint: enable=line-too-long\n\n\nclass NodeLookup(object):\n  """"""Converts integer node ID\'s to human readable labels.""""""\n\n  def __init__(self,\n               label_lookup_path=None,\n               uid_lookup_path=None):\n    if not label_lookup_path:\n      label_lookup_path = os.path.join(\n          FLAGS.model_dir, \'imagenet_2012_challenge_label_map_proto.pbtxt\')\n    if not uid_lookup_path:\n      uid_lookup_path = os.path.join(\n          FLAGS.model_dir, \'imagenet_synset_to_human_label_map.txt\')\n    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n\n  def load(self, label_lookup_path, uid_lookup_path):\n    """"""Loads a human readable English name for each softmax node.\n\n    Args:\n      label_lookup_path: string UID to integer node ID.\n      uid_lookup_path: string UID to human-readable string.\n\n    Returns:\n      dict from integer node ID to human-readable string.\n    """"""\n    if not tf.gfile.Exists(uid_lookup_path):\n      tf.logging.fatal(\'File does not exist %s\', uid_lookup_path)\n    if not tf.gfile.Exists(label_lookup_path):\n      tf.logging.fatal(\'File does not exist %s\', label_lookup_path)\n\n    # Loads mapping from string UID to human-readable string\n    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n    uid_to_human = {}\n    p = re.compile(r\'[n\\d]*[ \\S,]*\')\n    for line in proto_as_ascii_lines:\n      parsed_items = p.findall(line)\n      uid = parsed_items[0]\n      human_string = parsed_items[2]\n      uid_to_human[uid] = human_string\n\n    # Loads mapping from string UID to integer node ID.\n    node_id_to_uid = {}\n    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n    for line in proto_as_ascii:\n      if line.startswith(\'  target_class:\'):\n        target_class = int(line.split(\': \')[1])\n      if line.startswith(\'  target_class_string:\'):\n        target_class_string = line.split(\': \')[1]\n        node_id_to_uid[target_class] = target_class_string[1:-2]\n\n    # Loads the final mapping of integer node ID to human-readable string\n    node_id_to_name = {}\n    for key, val in node_id_to_uid.items():\n      if val not in uid_to_human:\n        tf.logging.fatal(\'Failed to locate: %s\', val)\n      name = uid_to_human[val]\n      node_id_to_name[key] = name\n\n    return node_id_to_name\n\n  def id_to_string(self, node_id):\n    if node_id not in self.node_lookup:\n      return \'\'\n    return self.node_lookup[node_id]\n\n\ndef create_graph():\n  """"""Creates a graph from saved GraphDef file and returns a saver.""""""\n  # Creates graph from saved graph_def.pb.\n  with tf.gfile.FastGFile(os.path.join(\n      FLAGS.model_dir, \'classify_image_graph_def.pb\'), \'rb\') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    _ = tf.import_graph_def(graph_def, name=\'\')\n\n\ndef run_inference_on_image(image):\n  """"""Runs inference on an image.\n\n  Args:\n    image: Image file name.\n\n  Returns:\n    Nothing\n  """"""\n  if not tf.gfile.Exists(image):\n    tf.logging.fatal(\'File does not exist %s\', image)\n  image_data = tf.gfile.FastGFile(image, \'rb\').read()\n\n  # Creates graph from saved GraphDef.\n  start_time = time.time()\n  create_graph()\n  graph_time = time.time() - start_time\n\n  with tf.Session() as sess:\n    # Some useful tensors:\n    # \'softmax:0\': A tensor containing the normalized prediction across\n    #   1000 labels.\n    # \'pool_3:0\': A tensor containing the next-to-last layer containing 2048\n    #   float description of the image.\n    # \'DecodeJpeg/contents:0\': A tensor containing a string providing JPEG\n    #   encoding of the image.\n    # Runs the softmax tensor by feeding the image_data as input to the graph.\n    softmax_tensor = sess.graph.get_tensor_by_name(\'softmax:0\')\n    # MODIFICATION BY SAM ABRAHAMS\n    for i in range(FLAGS.warmup_runs):\n      predictions = sess.run(softmax_tensor,\n                             {\'DecodeJpeg/contents:0\': image_data})\n    runs = []\n    for i in range(FLAGS.num_runs):\n      start_time = time.time()\n      predictions = sess.run(softmax_tensor,\n                             {\'DecodeJpeg/contents:0\': image_data})\n      runs.append(time.time() - start_time)\n    for i, run in enumerate(runs):\n      print(\'Run %03d:\\t%0.4f seconds\' % (i, run))\n    print(\'---\')\n    print(\'Best run: %0.4f\' % min(runs))\n    print(\'Worst run: %0.4f\' % max(runs))\n    print(\'Average run: %0.4f\' % float(sum(runs) / len(runs)))\n    print(\'Build graph time: %0.4f\' % graph_time)\n    print(\'Number of warmup runs: %d\' % FLAGS.warmup_runs)\n    print(\'Number of test runs: %d\' % FLAGS.num_runs)\n    # END OF MODIFICATION\n\ndef maybe_download_and_extract():\n  """"""Download and extract model tar file.""""""\n  dest_directory = FLAGS.model_dir\n  if not os.path.exists(dest_directory):\n    os.makedirs(dest_directory)\n  filename = DATA_URL.split(\'/\')[-1]\n  filepath = os.path.join(dest_directory, filename)\n  if not os.path.exists(filepath):\n    def _progress(count, block_size, total_size):\n      sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' % (\n          filename, float(count * block_size) / float(total_size) * 100.0))\n      sys.stdout.flush()\n    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath,\n                                             reporthook=_progress)\n    print()\n    statinfo = os.stat(filepath)\n    print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n  tarfile.open(filepath, \'r:gz\').extractall(dest_directory)\n\n\ndef main(_):\n  maybe_download_and_extract()\n  image = (FLAGS.image_file if FLAGS.image_file else\n           os.path.join(FLAGS.model_dir, \'cropped_panda.jpg\'))\n  run_inference_on_image(image)\n\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
