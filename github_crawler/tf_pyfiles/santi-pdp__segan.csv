file_path,api_count,code
bnorm.py,13,"b'import tensorflow as tf\n\n\nclass VBN(object):\n    """"""\n    Virtual Batch Normalization\n    (modified from https://github.com/openai/improved-gan/ definition)\n    """"""\n\n    def __init__(self, x, name, epsilon=1e-5):\n        """"""\n        x is the reference batch\n        """"""\n        assert isinstance(epsilon, float)\n\n        shape = x.get_shape().as_list()\n        assert len(shape) == 3, shape\n        with tf.variable_scope(name) as scope:\n            assert name.startswith(""d_"") or name.startswith(""g_"")\n            self.epsilon = epsilon\n            self.name = name\n            self.mean = tf.reduce_mean(x, [0, 1], keep_dims=True)\n            self.mean_sq = tf.reduce_mean(tf.square(x), [0, 1], keep_dims=True)\n            self.batch_size = int(x.get_shape()[0])\n            assert x is not None\n            assert self.mean is not None\n            assert self.mean_sq is not None\n            out = self._normalize(x, self.mean, self.mean_sq, ""reference"")\n            self.reference_output = out\n\n    def __call__(self, x):\n\n        shape = x.get_shape().as_list()\n        with tf.variable_scope(self.name) as scope:\n            new_coeff = 1. / (self.batch_size + 1.)\n            old_coeff = 1. - new_coeff\n            new_mean = tf.reduce_mean(x, [0, 1], keep_dims=True)\n            new_mean_sq = tf.reduce_mean(tf.square(x), [0, 1], keep_dims=True)\n            mean = new_coeff * new_mean + old_coeff * self.mean\n            mean_sq = new_coeff * new_mean_sq + old_coeff * self.mean_sq\n            out = self._normalize(x, mean, mean_sq, ""live"")\n            return out\n\n    def _normalize(self, x, mean, mean_sq, message):\n        # make sure this is called with a variable scope\n        shape = x.get_shape().as_list()\n        assert len(shape) == 3\n        self.gamma = tf.get_variable(""gamma"", [shape[-1]],\n                                initializer=tf.random_normal_initializer(1., 0.02))\n        gamma = tf.reshape(self.gamma, [1, 1, -1])\n        self.beta = tf.get_variable(""beta"", [shape[-1]],\n                                initializer=tf.constant_initializer(0.))\n        beta = tf.reshape(self.beta, [1, 1, -1])\n        assert self.epsilon is not None\n        assert mean_sq is not None\n        assert mean is not None\n        std = tf.sqrt(self.epsilon + mean_sq - tf.square(mean))\n        out = x - mean\n        out = out / std\n        out = out * gamma\n        out = out + beta\n        return out\n'"
data_loader.py,12,"b""from __future__ import print_function\nimport tensorflow as tf\nfrom ops import *\nimport numpy as np\n\n\ndef pre_emph(x, coeff=0.95):\n    x0 = tf.reshape(x[0], [1,])\n    diff = x[1:] - coeff * x[:-1]\n    concat = tf.concat(0, [x0, diff])\n    return concat\n\ndef de_emph(y, coeff=0.95):\n    if coeff <= 0:\n        return y\n    x = np.zeros(y.shape[0], dtype=np.float32)\n    x[0] = y[0]\n    for n in range(1, y.shape[0], 1):\n        x[n] = coeff * x[n - 1] + y[n]\n    return x\n\ndef read_and_decode(filename_queue, canvas_size, preemph=0.):\n    reader = tf.TFRecordReader()\n    _, serialized_example = reader.read(filename_queue)\n    features = tf.parse_single_example(\n            serialized_example,\n            features={\n                'wav_raw': tf.FixedLenFeature([], tf.string),\n                'noisy_raw': tf.FixedLenFeature([], tf.string),\n            })\n    wave = tf.decode_raw(features['wav_raw'], tf.int32)\n    wave.set_shape(canvas_size)\n    wave = (2./65535.) * tf.cast((wave - 32767), tf.float32) + 1.\n    noisy = tf.decode_raw(features['noisy_raw'], tf.int32)\n    noisy.set_shape(canvas_size)\n    noisy = (2./65535.) * tf.cast((noisy - 32767), tf.float32) + 1.\n\n    if preemph > 0:\n        wave = tf.cast(pre_emph(wave, preemph), tf.float32)\n        noisy = tf.cast(pre_emph(noisy, preemph), tf.float32)\n\n    return wave, noisy\n"""
discriminator.py,9,"b'from __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import batch_norm, fully_connected, flatten\nfrom tensorflow.contrib.layers import xavier_initializer\nfrom ops import *\nimport numpy as np\n\n\ndef discriminator(self, wave_in, reuse=False):\n        """"""\n        wave_in: waveform input\n        """"""\n        # take the waveform as input ""activation""\n        in_dims = wave_in.get_shape().as_list()\n        hi = wave_in\n        if len(in_dims) == 2:\n            hi = tf.expand_dims(wave_in, -1)\n        elif len(in_dims) < 2 or len(in_dims) > 3:\n            raise ValueError(\'Discriminator input must be 2-D or 3-D\')\n\n        batch_size = int(wave_in.get_shape()[0])\n\n        # set up the disc_block function\n        with tf.variable_scope(\'d_model\') as scope:\n            if reuse:\n                scope.reuse_variables()\n            def disc_block(block_idx, input_, kwidth, nfmaps, bnorm, activation,\n                           pooling=2):\n                with tf.variable_scope(\'d_block_{}\'.format(block_idx)):\n                    if not reuse:\n                        print(\'D block {} input shape: {}\'\n                              \'\'.format(block_idx, input_.get_shape()),\n                              end=\' *** \')\n                    bias_init = None\n                    if self.bias_D_conv:\n                        if not reuse:\n                            print(\'biasing D conv\', end=\' *** \')\n                        bias_init = tf.constant_initializer(0.)\n                    downconv_init = tf.truncated_normal_initializer(stddev=0.02)\n                    hi_a = downconv(input_, nfmaps, kwidth=kwidth, pool=pooling,\n                                    init=downconv_init, bias_init=bias_init)\n                    if not reuse:\n                        print(\'downconved shape: {} \'\n                              \'\'.format(hi_a.get_shape()), end=\' *** \')\n                    if bnorm:\n                        if not reuse:\n                            print(\'Applying VBN\', end=\' *** \')\n                        hi_a = self.vbn(hi_a, \'d_vbn_{}\'.format(block_idx))\n                    if activation == \'leakyrelu\':\n                        if not reuse:\n                            print(\'Applying Lrelu\', end=\' *** \')\n                        hi = leakyrelu(hi_a)\n                    elif activation == \'relu\':\n                        if not reuse:\n                            print(\'Applying Relu\', end=\' *** \')\n                        hi = tf.nn.relu(hi_a)\n                    else:\n                        raise ValueError(\'Unrecognized activation {} \'\n                                         \'in D\'.format(activation))\n                    return hi\n            beg_size = self.canvas_size\n            # apply input noisy layer to real and fake samples\n            hi = gaussian_noise_layer(hi, self.disc_noise_std)\n            if not reuse:\n                print(\'*** Discriminator summary ***\')\n            for block_idx, fmaps in enumerate(self.d_num_fmaps):\n                hi = disc_block(block_idx, hi, 31,\n                                self.d_num_fmaps[block_idx],\n                                True, \'leakyrelu\')\n                if not reuse:\n                    print()\n            if not reuse:\n                print(\'discriminator deconved shape: \', hi.get_shape())\n            hi_f = flatten(hi)\n            #hi_f = tf.nn.dropout(hi_f, self.keep_prob_var)\n            d_logit_out = conv1d(hi, kwidth=1, num_kernels=1,\n                                 init=tf.truncated_normal_initializer(stddev=0.02),\n                                 name=\'logits_conv\')\n            d_logit_out = tf.squeeze(d_logit_out)\n            d_logit_out = fully_connected(d_logit_out, 1, activation_fn=None)\n            if not reuse:\n                print(\'discriminator output shape: \', d_logit_out.get_shape())\n                print(\'*****************************\')\n            return d_logit_out\n'"
generator.py,30,"b'from __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import batch_norm, fully_connected, flatten\nfrom tensorflow.contrib.layers import xavier_initializer\nfrom ops import *\nimport numpy as np\n\n\nclass Generator(object):\n\n    def __init__(self, segan):\n        self.segan = segan\n\n    def __call__(self, noisy_w, is_ref, spk=None):\n        """""" Build the graph propagating (noisy_w) --> x\n        On first pass will make variables.\n        """"""\n        segan = self.segan\n\n        def make_z(shape, mean=0., std=1., name=\'z\'):\n            if is_ref:\n                with tf.variable_scope(name) as scope:\n                    z_init = tf.random_normal_initializer(mean=mean, stddev=std)\n                    z = tf.get_variable(""z"", shape,\n                                        initializer=z_init,\n                                        trainable=False\n                                        )\n                    if z.device != ""/device:GPU:0"":\n                        # this has to be created into gpu0\n                        print(\'z.device is {}\'.format(z.device))\n                        assert False\n            else:\n                z = tf.random_normal(shape, mean=mean, stddev=std,\n                                     name=name, dtype=tf.float32)\n            return z\n\n        if hasattr(segan, \'generator_built\'):\n            tf.get_variable_scope().reuse_variables()\n            make_vars = False\n        else:\n            make_vars = True\n\n        print(\'*** Building Generator ***\')\n        in_dims = noisy_w.get_shape().as_list()\n        h_i = noisy_w\n        if len(in_dims) == 2:\n            h_i = tf.expand_dims(noisy_w, -1)\n        elif len(in_dims) < 2 or len(in_dims) > 3:\n            raise ValueError(\'Generator input must be 2-D or 3-D\')\n        kwidth = 3\n        z = make_z([segan.batch_size, h_i.get_shape().as_list()[1],\n                    segan.g_enc_depths[-1]])\n        h_i = tf.concat(2, [h_i, z])\n        skip_out = True\n        skips = []\n        for block_idx, dilation in enumerate(segan.g_dilated_blocks):\n                name = \'g_residual_block_{}\'.format(block_idx)\n                if block_idx >= len(segan.g_dilated_blocks) - 1:\n                    skip_out = False\n                if skip_out:\n                    res_i, skip_i = residual_block(h_i,\n                                                   dilation, kwidth, num_kernels=32,\n                                                   bias_init=None, stddev=0.02,\n                                                   do_skip = True,\n                                                   name=name)\n                else:\n                    res_i = residual_block(h_i,\n                                           dilation, kwidth, num_kernels=32,\n                                           bias_init=None, stddev=0.02,\n                                           do_skip = False,\n                                           name=name)\n                # feed the residual output to the next block\n                h_i = res_i\n                if segan.keep_prob < 1:\n                    print(\'Adding dropout w/ keep prob {} \'\n                          \'to G\'.format(segan.keep_prob))\n                    h_i = tf.nn.dropout(h_i, segan.keep_prob_var)\n                if skip_out:\n                    # accumulate the skip connections\n                    skips.append(skip_i)\n                else:\n                    # for last block, the residual output is appended\n                    skips.append(res_i)\n        print(\'Amount of skip connections: \', len(skips))\n        # TODO: last pooling for actual wave\n        with tf.variable_scope(\'g_wave_pooling\'):\n            skip_T = tf.stack(skips, axis=0)\n            skips_sum = tf.reduce_sum(skip_T, axis=0)\n            skips_sum = leakyrelu(skips_sum)\n            wave_a = conv1d(skips_sum, kwidth=1, num_kernels=1,\n                            init=tf.truncated_normal_initializer(stddev=0.02))\n            wave = tf.tanh(wave_a)\n            segan.gen_wave_summ = histogram_summary(\'gen_wave\', wave)\n        print(\'Last residual wave shape: \', res_i.get_shape())\n        print(\'*************************\')\n        segan.generator_built = True\n        return wave, z\n\nclass AEGenerator(object):\n\n    def __init__(self, segan):\n        self.segan = segan\n\n    def __call__(self, noisy_w, is_ref, spk=None, z_on=True, do_prelu=False):\n        # TODO: remove c_vec\n        """""" Build the graph propagating (noisy_w) --> x\n        On first pass will make variables.\n        """"""\n        segan = self.segan\n\n        def make_z(shape, mean=0., std=1., name=\'z\'):\n            if is_ref:\n                with tf.variable_scope(name) as scope:\n                    z_init = tf.random_normal_initializer(mean=mean, stddev=std)\n                    z = tf.get_variable(""z"", shape,\n                                        initializer=z_init,\n                                        trainable=False\n                                        )\n                    if z.device != ""/device:GPU:0"":\n                        # this has to be created into gpu0\n                        print(\'z.device is {}\'.format(z.device))\n                        assert False\n            else:\n                z = tf.random_normal(shape, mean=mean, stddev=std,\n                                     name=name, dtype=tf.float32)\n            return z\n\n        if hasattr(segan, \'generator_built\'):\n            tf.get_variable_scope().reuse_variables()\n            make_vars = False\n        else:\n            make_vars = True\n        if is_ref:\n            print(\'*** Building Generator ***\')\n        in_dims = noisy_w.get_shape().as_list()\n        h_i = noisy_w\n        if len(in_dims) == 2:\n            h_i = tf.expand_dims(noisy_w, -1)\n        elif len(in_dims) < 2 or len(in_dims) > 3:\n            raise ValueError(\'Generator input must be 2-D or 3-D\')\n        kwidth = 31\n        enc_layers = 7\n        skips = []\n        if is_ref and do_prelu:\n            #keep track of prelu activations\n            alphas = []\n        with tf.variable_scope(\'g_ae\'):\n            #AE to be built is shaped:\n            # enc ~ [16384x1, 8192x16, 4096x32, 2048x32, 1024x64, 512x64, 256x128, 128x128, 64x256, 32x256, 16x512, 8x1024]\n            # dec ~ [8x2048, 16x1024, 32x512, 64x512, 8x256, 256x256, 512x128, 1024x128, 2048x64, 4096x64, 8192x32, 16384x1]\n            #FIRST ENCODER\n            for layer_idx, layer_depth in enumerate(segan.g_enc_depths):\n                bias_init = None\n                if segan.bias_downconv:\n                    if is_ref:\n                        print(\'Biasing downconv in G\')\n                    bias_init = tf.constant_initializer(0.)\n                h_i_dwn = downconv(h_i, layer_depth, kwidth=kwidth,\n                                   init=tf.truncated_normal_initializer(stddev=0.02),\n                                   bias_init=bias_init,\n                                   name=\'enc_{}\'.format(layer_idx))\n                if is_ref:\n                    print(\'Downconv {} -> {}\'.format(h_i.get_shape(),\n                                                     h_i_dwn.get_shape()))\n                h_i = h_i_dwn\n                if layer_idx < len(segan.g_enc_depths) - 1:\n                    if is_ref:\n                        print(\'Adding skip connection downconv \'\n                              \'{}\'.format(layer_idx))\n                    # store skip connection\n                    # last one is not stored cause it\'s the code\n                    skips.append(h_i)\n                if do_prelu:\n                    if is_ref:\n                        print(\'-- Enc: prelu activation --\')\n                    h_i = prelu(h_i, ref=is_ref, name=\'enc_prelu_{}\'.format(layer_idx))\n                    if is_ref:\n                        # split h_i into its components\n                        alpha_i = h_i[1]\n                        h_i = h_i[0]\n                        alphas.append(alpha_i)\n                else:\n                    if is_ref:\n                        print(\'-- Enc: leakyrelu activation --\')\n                    h_i = leakyrelu(h_i)\n\n            if z_on:\n                # random code is fused with intermediate representation\n                z = make_z([segan.batch_size, h_i.get_shape().as_list()[1],\n                            segan.g_enc_depths[-1]])\n                h_i = tf.concat(2, [z, h_i])\n\n            #SECOND DECODER (reverse order)\n            g_dec_depths = segan.g_enc_depths[:-1][::-1] + [1]\n            if is_ref:\n                print(\'g_dec_depths: \', g_dec_depths)\n            for layer_idx, layer_depth in enumerate(g_dec_depths):\n                h_i_dim = h_i.get_shape().as_list()\n                out_shape = [h_i_dim[0], h_i_dim[1] * 2, layer_depth]\n                bias_init = None\n                # deconv\n                if segan.deconv_type == \'deconv\':\n                    if is_ref:\n                        print(\'-- Transposed deconvolution type --\')\n                        if segan.bias_deconv:\n                            print(\'Biasing deconv in G\')\n                    if segan.bias_deconv:\n                        bias_init = tf.constant_initializer(0.)\n                    h_i_dcv = deconv(h_i, out_shape, kwidth=kwidth, dilation=2,\n                                     init=tf.truncated_normal_initializer(stddev=0.02),\n                                     bias_init=bias_init,\n                                     name=\'dec_{}\'.format(layer_idx))\n                elif segan.deconv_type == \'nn_deconv\':\n                    if is_ref:\n                        print(\'-- NN interpolated deconvolution type --\')\n                        if segan.bias_deconv:\n                            print(\'Biasing deconv in G\')\n                    if segan.bias_deconv:\n                        bias_init = 0.\n                    h_i_dcv = nn_deconv(h_i, kwidth=kwidth, dilation=2,\n                                        init=tf.truncated_normal_initializer(stddev=0.02),\n                                        bias_init=bias_init,\n                                        name=\'dec_{}\'.format(layer_idx))\n                else:\n                    raise ValueError(\'Unknown deconv type {}\'.format(segan.deconv_type))\n                if is_ref:\n                    print(\'Deconv {} -> {}\'.format(h_i.get_shape(),\n                                                   h_i_dcv.get_shape()))\n                h_i = h_i_dcv\n                if layer_idx < len(g_dec_depths) - 1:\n                    if do_prelu:\n                        if is_ref:\n                            print(\'-- Dec: prelu activation --\')\n                        h_i = prelu(h_i, ref=is_ref,\n                                    name=\'dec_prelu_{}\'.format(layer_idx))\n                        if is_ref:\n                            # split h_i into its components\n                            alpha_i = h_i[1]\n                            h_i = h_i[0]\n                            alphas.append(alpha_i)\n                    else:\n                        if is_ref:\n                            print(\'-- Dec: leakyrelu activation --\')\n                        h_i = leakyrelu(h_i)\n                    # fuse skip connection\n                    skip_ = skips[-(layer_idx + 1)]\n                    if is_ref:\n                        print(\'Fusing skip connection of \'\n                              \'shape {}\'.format(skip_.get_shape()))\n                    h_i = tf.concat(2, [h_i, skip_])\n\n                else:\n                    if is_ref:\n                        print(\'-- Dec: tanh activation --\')\n                    h_i = tf.tanh(h_i)\n\n            wave = h_i\n            if is_ref and do_prelu:\n                print(\'Amount of alpha vectors: \', len(alphas))\n            segan.gen_wave_summ = histogram_summary(\'gen_wave\', wave)\n            if is_ref:\n                print(\'Amount of skip connections: \', len(skips))\n                print(\'Last wave shape: \', wave.get_shape())\n                print(\'*************************\')\n            segan.generator_built = True\n            # ret feats contains the features refs to be returned\n            ret_feats = [wave]\n            if z_on:\n                ret_feats.append(z)\n            if is_ref and do_prelu:\n                ret_feats += alphas\n            return ret_feats\n'"
main.py,5,"b'from __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nfrom model import SEGAN, SEAE\nimport os\nfrom tensorflow.python.client import device_lib\nfrom scipy.io import wavfile\nfrom data_loader import pre_emph\n\n\ndevices = device_lib.list_local_devices()\n\nflags = tf.app.flags\nflags.DEFINE_integer(""seed"",111, ""Random seed (Def: 111)."")\nflags.DEFINE_integer(""epoch"", 150, ""Epochs to train (Def: 150)."")\nflags.DEFINE_integer(""batch_size"", 150, ""Batch size (Def: 150)."")\nflags.DEFINE_integer(""save_freq"", 50, ""Batch save freq (Def: 50)."")\nflags.DEFINE_integer(""canvas_size"", 2**14, ""Canvas size (Def: 2^14)."")\nflags.DEFINE_integer(""denoise_epoch"", 5, ""Epoch where noise in disc is ""\n                                          ""removed (Def: 5)."")\nflags.DEFINE_integer(""l1_remove_epoch"", 150, ""Epoch where L1 in G is ""\n                                           ""removed (Def: 150)."")\nflags.DEFINE_boolean(""bias_deconv"", False,\n                     ""Flag to specify if we bias deconvs (Def: False)"")\nflags.DEFINE_boolean(""bias_downconv"", False,\n                     ""flag to specify if we bias downconvs (def: false)"")\nflags.DEFINE_boolean(""bias_D_conv"", False,\n                     ""flag to specify if we bias D_convs (def: false)"")\n# TODO: noise decay is under check\nflags.DEFINE_float(""denoise_lbound"", 0.01, ""Min noise std to be still alive (Def: 0.001)"")\nflags.DEFINE_float(""noise_decay"", 0.7, ""Decay rate of noise std (Def: 0.7)"")\nflags.DEFINE_float(""d_label_smooth"", 0.25, ""Smooth factor in D (Def: 0.25)"")\nflags.DEFINE_float(""init_noise_std"", 0.5, ""Init noise std (Def: 0.5)"")\nflags.DEFINE_float(""init_l1_weight"", 100., ""Init L1 lambda (Def: 100)"")\nflags.DEFINE_integer(""z_dim"", 256, ""Dimension of input noise to G (Def: 256)."")\nflags.DEFINE_integer(""z_depth"", 256, ""Depth of input noise to G (Def: 256)."")\nflags.DEFINE_string(""save_path"", ""segan_results"", ""Path to save out model ""\n                                                   ""files. (Def: dwavegan_model""\n                                                   "")."")\nflags.DEFINE_string(""g_nl"", ""leaky"", ""Type of nonlinearity in G: leaky or prelu. (Def: leaky)."")\nflags.DEFINE_string(""model"", ""gan"", ""Type of model to train: gan or ae. (Def: gan)."")\nflags.DEFINE_string(""deconv_type"", ""deconv"", ""Type of deconv method: deconv or ""\n                                             ""nn_deconv (Def: deconv)."")\nflags.DEFINE_string(""g_type"", ""ae"", ""Type of G to use: ae or dwave. (Def: ae)."")\nflags.DEFINE_float(""g_learning_rate"", 0.0002, ""G learning_rate (Def: 0.0002)"")\nflags.DEFINE_float(""d_learning_rate"", 0.0002, ""D learning_rate (Def: 0.0002)"")\nflags.DEFINE_float(""beta_1"", 0.5, ""Adam beta 1 (Def: 0.5)"")\nflags.DEFINE_float(""preemph"", 0.95, ""Pre-emph factor (Def: 0.95)"")\nflags.DEFINE_string(""synthesis_path"", ""dwavegan_samples"", ""Path to save output""\n                                                          "" generated samples.""\n                                                          "" (Def: dwavegan_sam""\n                                                          ""ples)."")\nflags.DEFINE_string(""e2e_dataset"", ""data/segan.tfrecords"", ""TFRecords""\n                                                          "" (Def: data/""\n                                                          ""segan.tfrecords."")\nflags.DEFINE_string(""save_clean_path"", ""test_clean_results"", ""Path to save clean utts"")\nflags.DEFINE_string(""test_wav"", None, ""name of test wav (it won\'t train)"")\nflags.DEFINE_string(""weights"", None, ""Weights file"")\nFLAGS = flags.FLAGS\n\ndef pre_emph_test(coeff, canvas_size):\n    x_ = tf.placeholder(tf.float32, shape=[canvas_size,])\n    x_preemph = pre_emph(x_, coeff)\n    return x_, x_preemph\n\ndef main(_):\n    print(\'Parsed arguments: \', FLAGS.__flags)\n\n    # make save path if it is required\n    if not os.path.exists(FLAGS.save_path):\n        os.makedirs(FLAGS.save_path)\n    if not os.path.exists(FLAGS.synthesis_path):\n        os.makedirs(FLAGS.synthesis_path)\n    np.random.seed(FLAGS.seed)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement=True\n    udevices = []\n    for device in devices:\n        if len(devices) > 1 and \'cpu\' in device.name:\n            # Use cpu only when we dont have gpus\n            continue\n        print(\'Using device: \', device.name)\n        udevices.append(device.name)\n    # execute the session\n    with tf.Session(config=config) as sess:\n        if FLAGS.model == \'gan\':\n            print(\'Creating GAN model\')\n            se_model = SEGAN(sess, FLAGS, udevices)\n        elif FLAGS.model == \'ae\':\n            print(\'Creating AE model\')\n            se_model = SEAE(sess, FLAGS, udevices)\n        else:\n            raise ValueError(\'{} model type not understood!\'.format(FLAGS.model))\n        if FLAGS.test_wav is None:\n            se_model.train(FLAGS, udevices)\n        else:\n            if FLAGS.weights is None:\n                raise ValueError(\'weights must be specified!\')\n            print(\'Loading model weights...\')\n            se_model.load(FLAGS.save_path, FLAGS.weights)\n            fm, wav_data = wavfile.read(FLAGS.test_wav)\n            wavname = FLAGS.test_wav.split(\'/\')[-1]\n            if fm != 16000:\n                raise ValueError(\'16kHz required! Test file is different\')\n            wave = (2./65535.) * (wav_data.astype(np.float32) - 32767) + 1.\n            if FLAGS.preemph  > 0:\n                print(\'preemph test wave with {}\'.format(FLAGS.preemph))\n                x_pholder, preemph_op = pre_emph_test(FLAGS.preemph, wave.shape[0])\n                wave = sess.run(preemph_op, feed_dict={x_pholder:wave})\n            print(\'test wave shape: \', wave.shape)\n            print(\'test wave min:{}  max:{}\'.format(np.min(wave), np.max(wave)))\n            c_wave = se_model.clean(wave)\n            print(\'c wave min:{}  max:{}\'.format(np.min(c_wave), np.max(c_wave)))\n            wavfile.write(os.path.join(FLAGS.save_clean_path, wavname), 16e3, c_wave)\n            print(\'Done cleaning {} and saved \'\n                  \'to {}\'.format(FLAGS.test_wav,\n                                 os.path.join(FLAGS.save_clean_path, wavname)))\n\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
make_tfrecords.py,4,"b'from __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nfrom collections import namedtuple, OrderedDict\nfrom subprocess import call\nimport scipy.io.wavfile as wavfile\nimport argparse\nimport codecs\nimport timeit\nimport struct\nimport toml\nimport re\nimport sys\nimport os\n\n\ndef _int64_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef slice_signal(signal, window_size, stride=0.5):\n    """""" Return windows of the given signal by sweeping in stride fractions\n        of window\n    """"""\n    assert signal.ndim == 1, signal.ndim\n    n_samples = signal.shape[0]\n    offset = int(window_size * stride)\n    slices = []\n    for beg_i, end_i in zip(range(0, n_samples, offset),\n                            range(window_size, n_samples + offset,\n                                  offset)):\n        if end_i - beg_i < window_size:\n            break\n        slice_ = signal[beg_i:end_i]\n        if slice_.shape[0] == window_size:\n            slices.append(slice_)\n    return np.array(slices, dtype=np.int32)\n\ndef read_and_slice(filename, wav_canvas_size, stride=0.5):\n    fm, wav_data = wavfile.read(filename)\n    if fm != 16000:\n        raise ValueError(\'Sampling rate is expected to be 16kHz!\')\n    signals = slice_signal(wav_data, wav_canvas_size, stride)\n    return signals\n\n\ndef encoder_proc(wav_filename, noisy_path, out_file, wav_canvas_size):\n    """""" Read and slice the wav and noisy files and write to TFRecords.\n        out_file: TFRecordWriter.\n    """"""\n    ppath, wav_fullname = os.path.split(wav_filename)\n    noisy_filename = os.path.join(noisy_path, wav_fullname)\n    wav_signals = read_and_slice(wav_filename, wav_canvas_size)\n    noisy_signals = read_and_slice(noisy_filename, wav_canvas_size)\n    assert wav_signals.shape == noisy_signals.shape, noisy_signals.shape\n\n    for (wav, noisy) in zip(wav_signals, noisy_signals):\n        wav_raw = wav.tostring()\n        noisy_raw = noisy.tostring()\n        example = tf.train.Example(features=tf.train.Features(feature={\n            \'wav_raw\': _bytes_feature(wav_raw),\n            \'noisy_raw\': _bytes_feature(noisy_raw)}))\n        out_file.write(example.SerializeToString())\n\ndef main(opts):\n    if not os.path.exists(opts.save_path):\n        # make save path if it does not exist\n        os.makedirs(opts.save_path)\n    # set up the output filepath\n    out_filepath = os.path.join(opts.save_path, opts.out_file)\n    if os.path.splitext(out_filepath)[1] != \'.tfrecords\':\n        # if wrong extension or no extension appended, put .tfrecords\n        out_filepath += \'.tfrecords\'\n    else:\n        out_filename, ext = os.path.splitext(out_filepath)\n        out_filepath = out_filename + ext\n    # check if out_file exists and if force flag is set\n    if os.path.exists(out_filepath) and not opts.force_gen:\n        raise ValueError(\'ERROR: {} already exists. Set force flag (--force-gen) to \'\n                         \'overwrite. Skipping this speaker.\'.format(out_filepath))\n    elif os.path.exists(out_filepath) and opts.force_gen:\n        print(\'Will overwrite previously existing tfrecords\')\n        os.unlink(out_filepath)\n    with open(opts.cfg) as cfh:\n        # read the configuration description\n        cfg_desc = toml.loads(cfh.read())\n        beg_enc_t = timeit.default_timer()\n        out_file = tf.python_io.TFRecordWriter(out_filepath)\n        # process the acoustic and textual data now\n        for dset_i, (dset, dset_desc) in enumerate(cfg_desc.iteritems()):\n            print(\'-\' * 50)\n            wav_dir = dset_desc[\'clean\']\n            wav_files = [os.path.join(wav_dir, wav) for wav in\n                           os.listdir(wav_dir) if wav.endswith(\'.wav\')]\n            noisy_dir = dset_desc[\'noisy\']\n            nfiles = len(wav_files)\n            for m, wav_file in enumerate(wav_files):\n                print(\'Processing wav file {}/{} {}{}\'.format(m + 1,\n                                                              nfiles,\n                                                              wav_file,\n                                                              \' \' * 10),\n                      end=\'\\r\')\n                sys.stdout.flush()\n                encoder_proc(wav_file, noisy_dir, out_file, 2 ** 14)\n        out_file.close()\n        end_enc_t = timeit.default_timer() - beg_enc_t\n        print(\'\')\n        print(\'*\' * 50)\n        print(\'Total processing and writing time: {} s\'.format(end_enc_t))\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(description=\'Convert the set of txt and \'\n                                                 \'wavs to TFRecords\')\n    parser.add_argument(\'--cfg\', type=str, default=\'cfg/e2e_maker.cfg\',\n                        help=\'File containing the description of datasets \'\n                             \'to extract the info to make the TFRecords.\')\n    parser.add_argument(\'--save_path\', type=str, default=\'data/\',\n                        help=\'Path to save the dataset\')\n    parser.add_argument(\'--out_file\', type=str, default=\'segan.tfrecords\',\n                        help=\'Output filename\')\n    parser.add_argument(\'--force-gen\', dest=\'force_gen\', action=\'store_true\',\n                        help=\'Flag to force overwriting existing dataset.\')\n    parser.set_defaults(force_gen=False)\n    opts = parser.parse_args()\n    main(opts)\n'"
model.py,62,"b'from __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import batch_norm, fully_connected, flatten\nfrom tensorflow.contrib.layers import xavier_initializer\nfrom scipy.io import wavfile\nfrom generator import *\nfrom discriminator import *\nimport numpy as np\nfrom data_loader import read_and_decode, de_emph\nfrom bnorm import VBN\nfrom ops import *\nimport timeit\nimport os\n\n\nclass Model(object):\n\n    def __init__(self, name=\'BaseModel\'):\n        self.name = name\n\n    def save(self, save_path, step):\n        model_name = self.name\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n        if not hasattr(self, \'saver\'):\n            self.saver = tf.train.Saver()\n        self.saver.save(self.sess,\n                        os.path.join(save_path, model_name),\n                        global_step=step)\n\n    def load(self, save_path, model_file=None):\n        if not os.path.exists(save_path):\n            print(\'[!] Checkpoints path does not exist...\')\n            return False\n        print(\'[*] Reading checkpoints...\')\n        if model_file is None:\n            ckpt = tf.train.get_checkpoint_state(save_path)\n            if ckpt and ckpt.model_checkpoint_path:\n                ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            else:\n                return False\n        else:\n            ckpt_name = model_file\n        if not hasattr(self, \'saver\'):\n            self.saver = tf.train.Saver()\n        self.saver.restore(self.sess, os.path.join(save_path, ckpt_name))\n        print(\'[*] Read {}\'.format(ckpt_name))\n        return True\n\n\n\nclass SEGAN(Model):\n    """""" Speech Enhancement Generative Adversarial Network """"""\n    def __init__(self, sess, args, devices, infer=False, name=\'SEGAN\'):\n        super(SEGAN, self).__init__(name)\n        self.args = args\n        self.sess = sess\n        self.keep_prob = 1.\n        if infer:\n            self.keep_prob_var = tf.Variable(self.keep_prob, trainable=False)\n        else:\n            self.keep_prob = 0.5\n            self.keep_prob_var = tf.Variable(self.keep_prob, trainable=False)\n        self.batch_size = args.batch_size\n        self.epoch = args.epoch\n        self.d_label_smooth = args.d_label_smooth\n        self.devices = devices\n        self.z_dim = args.z_dim\n        self.z_depth = args.z_depth\n        # type of deconv\n        self.deconv_type = args.deconv_type\n        # specify if use biases or not\n        self.bias_downconv = args.bias_downconv\n        self.bias_deconv = args.bias_deconv\n        self.bias_D_conv = args.bias_D_conv\n        # clip D values\n        self.d_clip_weights = False\n        # apply VBN or regular BN?\n        self.disable_vbn = False\n        self.save_path = args.save_path\n        # num of updates to be applied to D before G\n        # this is k in original GAN paper (https://arxiv.org/abs/1406.2661)\n        self.disc_updates = 1\n        # set preemph factor\n        self.preemph = args.preemph\n        if self.preemph > 0:\n            print(\'*** Applying pre-emphasis of {} ***\'.format(self.preemph))\n        else:\n            print(\'--- No pre-emphasis applied ---\')\n        # canvas size\n        self.canvas_size = args.canvas_size\n        self.deactivated_noise = False\n        # dilation factors per layer (only in atrous conv G config)\n        self.g_dilated_blocks = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n        # num fmaps for AutoEncoder SEGAN (v1)\n        self.g_enc_depths = [16, 32, 32, 64, 64, 128, 128, 256, 256, 512, 1024]\n        # Define D fmaps\n        self.d_num_fmaps = [16, 32, 32, 64, 64, 128, 128, 256, 256, 512, 1024]\n        self.init_noise_std = args.init_noise_std\n        self.disc_noise_std = tf.Variable(self.init_noise_std, trainable=False)\n        self.disc_noise_std_summ = scalar_summary(\'disc_noise_std\',\n                                                  self.disc_noise_std)\n        self.e2e_dataset = args.e2e_dataset\n        # G\'s supervised loss weight\n        self.l1_weight = args.init_l1_weight\n        self.l1_lambda = tf.Variable(self.l1_weight, trainable=False)\n        self.deactivated_l1 = False\n        # define the functions\n        self.discriminator = discriminator\n        # register G non linearity\n        self.g_nl = args.g_nl\n        if args.g_type == \'ae\':\n            self.generator = AEGenerator(self)\n        elif args.g_type == \'dwave\':\n            self.generator = Generator(self)\n        else:\n            raise ValueError(\'Unrecognized G type {}\'.format(args.g_type))\n        self.build_model(args)\n\n    def build_model(self, config):\n        all_d_grads = []\n        all_g_grads = []\n        d_opt = tf.train.RMSPropOptimizer(config.d_learning_rate)\n        g_opt = tf.train.RMSPropOptimizer(config.g_learning_rate)\n        #d_opt = tf.train.AdamOptimizer(config.d_learning_rate,\n        #                               beta1=config.beta_1)\n        #g_opt = tf.train.AdamOptimizer(config.g_learning_rate,\n        #                               beta1=config.beta_1)\n\n        for idx, device in enumerate(self.devices):\n            with tf.device(""/%s"" % device):\n                with tf.name_scope(""device_%s"" % idx):\n                    with variables_on_gpu0():\n                        self.build_model_single_gpu(idx)\n                        d_grads = d_opt.compute_gradients(self.d_losses[-1],\n                                                          var_list=self.d_vars)\n                        g_grads = g_opt.compute_gradients(self.g_losses[-1],\n                                                          var_list=self.g_vars)\n                        all_d_grads.append(d_grads)\n                        all_g_grads.append(g_grads)\n                        tf.get_variable_scope().reuse_variables()\n        avg_d_grads = average_gradients(all_d_grads)\n        avg_g_grads = average_gradients(all_g_grads)\n        self.d_opt = d_opt.apply_gradients(avg_d_grads)\n        self.g_opt = g_opt.apply_gradients(avg_g_grads)\n\n\n    def build_model_single_gpu(self, gpu_idx):\n        if gpu_idx == 0:\n            # create the nodes to load for input pipeline\n            filename_queue = tf.train.string_input_producer([self.e2e_dataset])\n            self.get_wav, self.get_noisy = read_and_decode(filename_queue,\n                                                           self.canvas_size,\n                                                           self.preemph)\n        # load the data to input pipeline\n        wavbatch, \\\n        noisybatch = tf.train.shuffle_batch([self.get_wav,\n                                             self.get_noisy],\n                                             batch_size=self.batch_size,\n                                             num_threads=2,\n                                             capacity=1000 + 3 * self.batch_size,\n                                             min_after_dequeue=1000,\n                                             name=\'wav_and_noisy\')\n        if gpu_idx == 0:\n            self.Gs = []\n            self.zs = []\n            self.gtruth_wavs = []\n            self.gtruth_noisy = []\n\n        self.gtruth_wavs.append(wavbatch)\n        self.gtruth_noisy.append(noisybatch)\n\n        # add channels dimension to manipulate in D and G\n        wavbatch = tf.expand_dims(wavbatch, -1)\n        noisybatch = tf.expand_dims(noisybatch, -1)\n        # by default leaky relu is used\n        do_prelu = False\n        if self.g_nl == \'prelu\':\n            do_prelu = True\n        if gpu_idx == 0:\n            #self.sample_wavs = tf.placeholder(tf.float32, [self.batch_size,\n            #                                               self.canvas_size],\n            #                                  name=\'sample_wavs\')\n            ref_Gs = self.generator(noisybatch, is_ref=True,\n                                    spk=None,\n                                    do_prelu=do_prelu)\n            print(\'num of G returned: \', len(ref_Gs))\n            self.reference_G = ref_Gs[0]\n            self.ref_z = ref_Gs[1]\n            if do_prelu:\n                self.ref_alpha = ref_Gs[2:]\n                self.alpha_summ = []\n                for m, ref_alpha in enumerate(self.ref_alpha):\n                    # add a summary per alpha\n                    self.alpha_summ.append(histogram_summary(\'alpha_{}\'.format(m),\n                                                             ref_alpha))\n            # make a dummy copy of discriminator to have variables and then\n            # be able to set up the variable reuse for all other devices\n            # merge along channels and this would be a real batch\n            dummy_joint = tf.concat(2, [wavbatch, noisybatch])\n            dummy = discriminator(self, dummy_joint,\n                                  reuse=False)\n\n        G, z  = self.generator(noisybatch, is_ref=False, spk=None,\n                               do_prelu=do_prelu)\n        self.Gs.append(G)\n        self.zs.append(z)\n\n        # add new dimension to merge with other pairs\n        D_rl_joint = tf.concat(2, [wavbatch, noisybatch])\n        D_fk_joint = tf.concat(2, [G, noisybatch])\n        # build rl discriminator\n        d_rl_logits = discriminator(self, D_rl_joint, reuse=True)\n        # build fk G discriminator\n        d_fk_logits = discriminator(self, D_fk_joint, reuse=True)\n\n        # make disc variables summaries\n        self.d_rl_sum = histogram_summary(""d_real"", d_rl_logits)\n        self.d_fk_sum = histogram_summary(""d_fake"", d_fk_logits)\n        #self.d_nfk_sum = histogram_summary(""d_noisyfake"", d_nfk_logits)\n\n        self.rl_audio_summ = audio_summary(\'real_audio\', wavbatch)\n        self.real_w_summ = histogram_summary(\'real_wav\', wavbatch)\n        self.noisy_audio_summ = audio_summary(\'noisy_audio\', noisybatch)\n        self.noisy_w_summ = histogram_summary(\'noisy_wav\', noisybatch)\n        self.gen_audio_summ = audio_summary(\'G_audio\', G)\n        self.gen_summ = histogram_summary(\'G_wav\', G)\n\n        if gpu_idx == 0:\n            self.g_losses = []\n            self.g_l1_losses = []\n            self.g_adv_losses = []\n            self.d_rl_losses = []\n            self.d_fk_losses = []\n            #self.d_nfk_losses = []\n            self.d_losses = []\n\n        d_rl_loss = tf.reduce_mean(tf.squared_difference(d_rl_logits, 1.))\n        d_fk_loss = tf.reduce_mean(tf.squared_difference(d_fk_logits, 0.))\n        #d_nfk_loss = tf.reduce_mean(tf.squared_difference(d_nfk_logits, 0.))\n        g_adv_loss = tf.reduce_mean(tf.squared_difference(d_fk_logits, 1.))\n\n        d_loss = d_rl_loss + d_fk_loss\n\n        # Add the L1 loss to G\n        g_l1_loss = self.l1_lambda * tf.reduce_mean(tf.abs(tf.sub(G,\n                                                                  wavbatch)))\n\n        g_loss = g_adv_loss + g_l1_loss\n\n        self.g_l1_losses.append(g_l1_loss)\n        self.g_adv_losses.append(g_adv_loss)\n        self.g_losses.append(g_loss)\n        self.d_rl_losses.append(d_rl_loss)\n        self.d_fk_losses.append(d_fk_loss)\n        #self.d_nfk_losses.append(d_nfk_loss)\n        self.d_losses.append(d_loss)\n\n        self.d_rl_loss_sum = scalar_summary(""d_rl_loss"", d_rl_loss)\n        self.d_fk_loss_sum = scalar_summary(""d_fk_loss"",\n                                            d_fk_loss)\n        #self.d_nfk_loss_sum = scalar_summary(""d_nfk_loss"",\n        #                                     d_nfk_loss)\n        self.g_loss_sum = scalar_summary(""g_loss"", g_loss)\n        self.g_loss_l1_sum = scalar_summary(""g_l1_loss"", g_l1_loss)\n        self.g_loss_adv_sum = scalar_summary(""g_adv_loss"", g_adv_loss)\n        self.d_loss_sum = scalar_summary(""d_loss"", d_loss)\n\n        if gpu_idx == 0:\n            self.get_vars()\n\n\n    def get_vars(self):\n        t_vars = tf.trainable_variables()\n        self.d_vars_dict = {}\n        self.g_vars_dict = {}\n        for var in t_vars:\n            if var.name.startswith(\'d_\'):\n                self.d_vars_dict[var.name] = var\n            if var.name.startswith(\'g_\'):\n                self.g_vars_dict[var.name] = var\n        self.d_vars = self.d_vars_dict.values()\n        self.g_vars = self.g_vars_dict.values()\n        for x in self.d_vars:\n            assert x not in self.g_vars\n        for x in self.g_vars:\n            assert x not in self.d_vars\n        for x in t_vars:\n            assert x in self.g_vars or x in self.d_vars, x.name\n        self.all_vars = t_vars\n        if self.d_clip_weights:\n            print(\'Clipping D weights\')\n            self.d_clip = [v.assign(tf.clip_by_value(v, -0.05, 0.05)) for v in self.d_vars]\n        else:\n            print(\'Not clipping D weights\')\n\n    def vbn(self, tensor, name):\n        if self.disable_vbn:\n            class Dummy(object):\n                # Do nothing here, no bnorm\n                def __init__(self, tensor, ignored):\n                    self.reference_output=tensor\n                def __call__(self, x):\n                    return x\n            VBN_cls = Dummy\n        else:\n            VBN_cls = VBN\n        if not hasattr(self, name):\n            vbn = VBN_cls(tensor, name)\n            setattr(self, name, vbn)\n            return vbn.reference_output\n        vbn = getattr(self, name)\n        return vbn(tensor)\n\n    def train(self, config, devices):\n        """""" Train the SEGAN """"""\n\n        print(\'Initializing optimizers...\')\n        # init optimizers\n        d_opt = self.d_opt\n        g_opt = self.g_opt\n        num_devices = len(devices)\n\n        try:\n            init = tf.global_variables_initializer()\n        except AttributeError:\n            # fall back to old implementation\n            init = tf.initialize_all_variables()\n\n        print(\'Initializing variables...\')\n        self.sess.run(init)\n        g_summs = [self.d_fk_sum,\n                   #self.d_nfk_sum,\n                   self.d_fk_loss_sum,\n                   #self.d_nfk_loss_sum,\n                   self.g_loss_sum,\n                   self.g_loss_l1_sum,\n                   self.g_loss_adv_sum,\n                   self.gen_summ,\n                   self.gen_audio_summ]\n        # if we have prelus, add them to summary\n        if hasattr(self, \'alpha_summ\'):\n            g_summs += self.alpha_summ\n        self.g_sum = tf.summary.merge(g_summs)\n        self.d_sum = tf.summary.merge([self.d_loss_sum,\n                                       self.d_rl_sum,\n                                       self.d_rl_loss_sum,\n                                       self.rl_audio_summ,\n                                       self.real_w_summ,\n                                       self.disc_noise_std_summ])\n\n        if not os.path.exists(os.path.join(config.save_path, \'train\')):\n            os.makedirs(os.path.join(config.save_path, \'train\'))\n\n        self.writer = tf.summary.FileWriter(os.path.join(config.save_path,\n                                                         \'train\'),\n                                            self.sess.graph)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n\n        print(\'Sampling some wavs to store sample references...\')\n        # Hang onto a copy of wavs so we can feed the same one every time\n        # we store samples to disk for hearing\n        # pick a single batch\n        sample_noisy, sample_wav, \\\n        sample_z = self.sess.run([self.gtruth_noisy[0],\n                                  self.gtruth_wavs[0],\n                                  self.zs[0]])\n        print(\'sample noisy shape: \', sample_noisy.shape)\n        print(\'sample wav shape: \', sample_wav.shape)\n        print(\'sample z shape: \', sample_z.shape)\n\n        save_path = config.save_path\n        counter = 0\n        # count number of samples\n        num_examples = 0\n        for record in tf.python_io.tf_record_iterator(self.e2e_dataset):\n            num_examples += 1\n        print(\'total examples in TFRecords {}: {}\'.format(self.e2e_dataset,\n                                                          num_examples))\n        # last samples (those not filling a complete batch) are discarded\n        num_batches = num_examples / self.batch_size\n\n        print(\'Batches per epoch: \', num_batches)\n\n        if self.load(self.save_path):\n            print(\'[*] Load SUCCESS\')\n        else:\n            print(\'[!] Load failed\')\n        batch_idx = 0\n        curr_epoch = 0\n        batch_timings = []\n        d_fk_losses = []\n        #d_nfk_losses = []\n        d_rl_losses = []\n        g_adv_losses = []\n        g_l1_losses = []\n        try:\n            while not coord.should_stop():\n                start = timeit.default_timer()\n                if counter % config.save_freq == 0:\n                    for d_iter in range(self.disc_updates):\n                        _d_opt, _d_sum, \\\n                        d_fk_loss, \\\n                        d_rl_loss = self.sess.run([d_opt, self.d_sum,\n                                                   self.d_fk_losses[0],\n                                                   #self.d_nfk_losses[0],\n                                                   self.d_rl_losses[0]])\n                        if self.d_clip_weights:\n                            self.sess.run(self.d_clip)\n                        #d_nfk_loss, \\\n\n                    # now G iterations\n                    _g_opt, _g_sum, \\\n                    g_adv_loss, \\\n                    g_l1_loss = self.sess.run([g_opt, self.g_sum,\n                                               self.g_adv_losses[0],\n                                               self.g_l1_losses[0]])\n                else:\n                    for d_iter in range(self.disc_updates):\n                        _d_opt, \\\n                        d_fk_loss, \\\n                        d_rl_loss = self.sess.run([d_opt,\n                                                   self.d_fk_losses[0],\n                                                   #self.d_nfk_losses[0],\n                                                   self.d_rl_losses[0]])\n                        #d_nfk_loss, \\\n                        if self.d_clip_weights:\n                            self.sess.run(self.d_clip)\n\n                    _g_opt, \\\n                    g_adv_loss, \\\n                    g_l1_loss = self.sess.run([g_opt, self.g_adv_losses[0],\n                                               self.g_l1_losses[0]])\n                end = timeit.default_timer()\n                batch_timings.append(end - start)\n                d_fk_losses.append(d_fk_loss)\n                #d_nfk_losses.append(d_nfk_loss)\n                d_rl_losses.append(d_rl_loss)\n                g_adv_losses.append(g_adv_loss)\n                g_l1_losses.append(g_l1_loss)\n                print(\'{}/{} (epoch {}), d_rl_loss = {:.5f}, \'\n                      \'d_fk_loss = {:.5f}, \'#d_nfk_loss = {:.5f}, \'\n                      \'g_adv_loss = {:.5f}, g_l1_loss = {:.5f},\'\n                      \' time/batch = {:.5f}, \'\n                      \'mtime/batch = {:.5f}\'.format(counter,\n                                                    config.epoch * num_batches,\n                                                    curr_epoch,\n                                                    d_rl_loss,\n                                                    d_fk_loss,\n                                                    #d_nfk_loss,\n                                                    g_adv_loss,\n                                                    g_l1_loss,\n                                                    end - start,\n                                                    np.mean(batch_timings)))\n                batch_idx += num_devices\n                counter += num_devices\n                if (counter / num_devices) % config.save_freq == 0:\n                    self.save(config.save_path, counter)\n                    self.writer.add_summary(_g_sum, counter)\n                    self.writer.add_summary(_d_sum, counter)\n                    fdict = {self.gtruth_noisy[0]:sample_noisy,\n                             self.zs[0]:sample_z}\n                    canvas_w = self.sess.run(self.Gs[0],\n                                             feed_dict=fdict)\n                    swaves = sample_wav\n                    sample_dif = sample_wav - sample_noisy\n                    for m in range(min(20, canvas_w.shape[0])):\n                        print(\'w{} max: {} min: {}\'.format(m,\n                                                           np.max(canvas_w[m]),\n                                                           np.min(canvas_w[m])))\n                        wavfile.write(os.path.join(save_path,\n                                                   \'sample_{}-\'\n                                                   \'{}.wav\'.format(counter, m)),\n                                      16e3,\n                                      de_emph(canvas_w[m],\n                                              self.preemph))\n                        m_gtruth_path = os.path.join(save_path, \'gtruth_{}.\'\n                                                                \'wav\'.format(m))\n                        if not os.path.exists(m_gtruth_path):\n                            wavfile.write(os.path.join(save_path,\n                                                       \'gtruth_{}.\'\n                                                       \'wav\'.format(m)),\n                                          16e3,\n                                          de_emph(swaves[m],\n                                                  self.preemph))\n                            wavfile.write(os.path.join(save_path,\n                                                       \'noisy_{}.\'\n                                                       \'wav\'.format(m)),\n                                          16e3,\n                                          de_emph(sample_noisy[m],\n                                                  self.preemph))\n                            wavfile.write(os.path.join(save_path,\n                                                       \'dif_{}.wav\'.format(m)),\n                                          16e3,\n                                          de_emph(sample_dif[m],\n                                                  self.preemph))\n                        np.savetxt(os.path.join(save_path, \'d_rl_losses.txt\'),\n                                   d_rl_losses)\n                        np.savetxt(os.path.join(save_path, \'d_fk_losses.txt\'),\n                                   d_fk_losses)\n                        np.savetxt(os.path.join(save_path, \'g_adv_losses.txt\'),\n                                   g_adv_losses)\n                        np.savetxt(os.path.join(save_path, \'g_l1_losses.txt\'),\n                                   g_l1_losses)\n\n                if batch_idx >= num_batches:\n                    curr_epoch += 1\n                    # re-set batch idx\n                    batch_idx = 0\n                    # check if we have to deactivate L1\n                    if curr_epoch >= config.l1_remove_epoch and self.deactivated_l1 == False:\n                        print(\'** Deactivating L1 factor! **\')\n                        self.sess.run(tf.assign(self.l1_lambda, 0.))\n                        self.deactivated_l1 = True\n                    # check if we have to start decaying noise (if any)\n                    if curr_epoch >= config.denoise_epoch and self.deactivated_noise == False:\n                        # apply noise std decay rate\n                        decay = config.noise_decay\n                        if not hasattr(self, \'curr_noise_std\'):\n                            self.curr_noise_std = self.init_noise_std\n                        new_noise_std = decay * self.curr_noise_std\n                        if new_noise_std < config.denoise_lbound:\n                            print(\'New noise std {} < lbound {}, setting 0.\'.format(new_noise_std, config.denoise_lbound))\n                            print(\'** De-activating noise layer **\')\n                            # it it\'s lower than a lower bound, cancel out completely\n                            new_noise_std = 0.\n                            self.deactivated_noise = True\n                        else:\n                            print(\'Applying decay {} to noise std {}: {}\'.format(decay, self.curr_noise_std, new_noise_std))\n                        self.sess.run(tf.assign(self.disc_noise_std, new_noise_std))\n                        self.curr_noise_std = new_noise_std\n                if curr_epoch >= config.epoch:\n                    # done training\n                    print(\'Done training; epoch limit {} \'\n                          \'reached.\'.format(self.epoch))\n                    print(\'Saving last model at iteration {}\'.format(counter))\n                    self.save(config.save_path, counter)\n                    self.writer.add_summary(_g_sum, counter)\n                    self.writer.add_summary(_d_sum, counter)\n                    break\n        except tf.errors.OutOfRangeError:\n            print(\'Done training; epoch limit {} reached.\'.format(self.epoch))\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n\n    def clean(self, x):\n        """""" clean a utterance x\n            x: numpy array containing the normalized noisy waveform\n        """"""\n        c_res = None\n        for beg_i in range(0, x.shape[0], self.canvas_size):\n            if x.shape[0] - beg_i  < self.canvas_size:\n                length = x.shape[0] - beg_i\n                pad = (self.canvas_size) - length\n            else:\n                length = self.canvas_size\n                pad = 0\n            x_ = np.zeros((self.batch_size, self.canvas_size))\n            if pad > 0:\n                x_[0] = np.concatenate((x[beg_i:beg_i + length], np.zeros(pad)))\n            else:\n                x_[0] = x[beg_i:beg_i + length]\n            print(\'Cleaning chunk {} -> {}\'.format(beg_i, beg_i + length))\n            fdict = {self.gtruth_noisy[0]:x_}\n            canvas_w = self.sess.run(self.Gs[0],\n                                     feed_dict=fdict)[0]\n            canvas_w = canvas_w.reshape((self.canvas_size))\n            print(\'canvas w shape: \', canvas_w.shape)\n            if pad > 0:\n                print(\'Removing padding of {} samples\'.format(pad))\n                # get rid of last padded samples\n                canvas_w = canvas_w[:-pad]\n            if c_res is None:\n                c_res = canvas_w\n            else:\n                c_res = np.concatenate((c_res, canvas_w))\n        # deemphasize\n        c_res = de_emph(c_res, self.preemph)\n        return c_res\n\n\nclass SEAE(Model):\n    """""" Speech Enhancement Auto Encoder """"""\n    def __init__(self, sess, args, devices, infer=False):\n        self.args = args\n        self.sess = sess\n        self.keep_prob = 1.\n        if infer:\n            self.keep_prob_var = tf.Variable(self.keep_prob, trainable=False)\n        else:\n            self.keep_prob = 0.5\n            self.keep_prob_var = tf.Variable(self.keep_prob, trainable=False)\n        self.batch_size = args.batch_size\n        self.epoch = args.epoch\n        self.devices = devices\n        self.save_path = args.save_path\n        # canvas size\n        self.canvas_size = args.canvas_size\n        self.g_enc_depths = [16, 32, 32, 64, 64, 128, 128, 256, 256, 512, 1024]\n        self.e2e_dataset = args.e2e_dataset\n        # define the Generator\n        self.generator = AEGenerator(self)\n        self.build_model(args)\n\n    def build_model(self, config):\n        all_g_grads = []\n        g_opt = tf.train.AdamOptimizer(config.g_learning_rate, config.beta_1)\n\n        for idx, device in enumerate(self.devices):\n            with tf.device(""/%s"" % device):\n                with tf.name_scope(""device_%s"" % idx):\n                    with variables_on_gpu0():\n                        self.build_model_single_gpu(idx)\n                        g_grads = g_opt.compute_gradients(self.g_losses[-1],\n                                                          var_list=self.g_vars)\n                        all_g_grads.append(g_grads)\n                        tf.get_variable_scope().reuse_variables()\n        avg_g_grads = average_gradients(all_g_grads)\n        self.g_opt = g_opt.apply_gradients(avg_g_grads)\n\n\n    def build_model_single_gpu(self, gpu_idx):\n        if gpu_idx == 0:\n            # create the nodes to load for input pipeline\n            filename_queue = tf.train.string_input_producer([self.e2e_dataset])\n            self.get_wav, self.get_noisy = read_and_decode(filename_queue,\n                                                           2 ** 14)\n        # load the data to input pipeline\n        wavbatch, \\\n        noisybatch = tf.train.shuffle_batch([self.get_wav,\n                                             self.get_noisy],\n                                             batch_size=self.batch_size,\n                                             num_threads=2,\n                                             capacity=1000 + 3 * self.batch_size,\n                                             min_after_dequeue=1000,\n                                             name=\'wav_and_noisy\')\n        if gpu_idx == 0:\n            self.Gs = []\n            self.zs = []\n            self.gtruth_wavs = []\n            self.gtruth_noisy = []\n\n        self.gtruth_wavs.append(wavbatch)\n        self.gtruth_noisy.append(noisybatch)\n\n        # add channels dimension to manipulate in D and G\n        wavbatch = tf.expand_dims(wavbatch, -1)\n        noisybatch = tf.expand_dims(noisybatch, -1)\n        if gpu_idx == 0:\n            #self.sample_wavs = tf.placeholder(tf.float32, [self.batch_size,\n            #                                               self.canvas_size],\n            #                                  name=\'sample_wavs\')\n            self.reference_G = self.generator(noisybatch, is_ref=True,\n                                              spk=None, z_on=False)\n\n        G = self.generator(noisybatch, is_ref=False, spk=None, z_on=False)\n        print(\'GAE shape: \', G.get_shape())\n        self.Gs.append(G)\n\n        self.rl_audio_summ = audio_summary(\'real_audio\', wavbatch)\n        self.real_w_summ = histogram_summary(\'real_wav\', wavbatch)\n        self.noisy_audio_summ = audio_summary(\'noisy_audio\', noisybatch)\n        self.noisy_w_summ = histogram_summary(\'noisy_wav\', noisybatch)\n        self.gen_audio_summ = audio_summary(\'G_audio\', G)\n        self.gen_summ = histogram_summary(\'G_wav\', G)\n\n        if gpu_idx == 0:\n            self.g_losses = []\n\n        # Add the L1 loss to G\n        g_loss = tf.reduce_mean(tf.abs(tf.sub(G, wavbatch)))\n\n        self.g_losses.append(g_loss)\n\n        self.g_loss_sum = scalar_summary(""g_loss"", g_loss)\n\n        if gpu_idx == 0:\n            self.get_vars()\n\n    def get_vars(self):\n        t_vars = tf.trainable_variables()\n        self.g_vars = [var for var in t_vars if var.name.startswith(\'g_\')]\n        for x in t_vars:\n            assert x in self.g_vars, x.name\n        self.all_vars = t_vars\n\n    def train(self, config, devices):\n        """""" Train the SEAE """"""\n\n        print(\'Initializing optimizer...\')\n        # init optimizer\n        g_opt = self.g_opt\n        num_devices = len(devices)\n\n        try:\n            init = tf.global_variables_initializer()\n        except AttributeError:\n            # fall back to old implementation\n            init = tf.initialize_all_variables()\n\n        print(\'Initializing variables...\')\n        self.sess.run(init)\n        self.saver = tf.train.Saver()\n        self.g_sum = tf.summary.merge([self.g_loss_sum,\n                                       self.gen_summ,\n                                       self.rl_audio_summ,\n                                       self.real_w_summ,\n                                       self.gen_audio_summ])\n\n        if not os.path.exists(os.path.join(config.save_path, \'train\')):\n            os.makedirs(os.path.join(config.save_path, \'train\'))\n\n        self.writer = tf.summary.FileWriter(os.path.join(config.save_path,\n                                                         \'train\'),\n                                            self.sess.graph)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n\n        print(\'Sampling some wavs to store sample references...\')\n        # Hang onto a copy of wavs so we can feed the same one every time\n        # we store samples to disk for hearing\n        # pick a single batch\n        sample_noisy, \\\n        sample_wav = self.sess.run([self.gtruth_noisy[0],\n                                    self.gtruth_wavs[0]])\n        print(\'sample noisy shape: \', sample_noisy.shape)\n        print(\'sample wav shape: \', sample_wav.shape)\n        save_path = config.save_path\n        counter = 0\n        # count number of samples\n        num_examples = 0\n        for record in tf.python_io.tf_record_iterator(self.e2e_dataset):\n            num_examples += 1\n        print(\'total examples in TFRecords {}: {}\'.format(self.e2e_dataset,\n                                                          num_examples))\n        # last samples (those not filling a complete batch) are discarded\n        num_batches = num_examples / self.batch_size\n\n        print(\'Batches per epoch: \', num_batches)\n\n        if self.load(self.save_path):\n            print(\'[*] Load SUCCESS\')\n        else:\n            print(\'[!] Load failed\')\n        batch_idx = 0\n        curr_epoch = 0\n        batch_timings = []\n        g_losses = []\n        try:\n            while not coord.should_stop():\n                start = timeit.default_timer()\n                if counter % config.save_freq == 0:\n                    # now G iterations\n                    _g_opt, _g_sum, \\\n                    g_loss = self.sess.run([g_opt, self.g_sum,\n                                            self.g_losses[0]])\n                else:\n                    _g_opt, \\\n                    g_loss = self.sess.run([g_opt, self.g_losses[0]])\n\n                end = timeit.default_timer()\n                batch_timings.append(end - start)\n                g_losses.append(g_loss)\n                print(\'{}/{} (epoch {}), g_loss = {:.5f},\'\n                      \' time/batch = {:.5f}, \'\n                      \'mtime/batch = {:.5f}\'.format(counter,\n                                                    config.epoch * num_batches,\n                                                    curr_epoch,\n                                                    g_loss,\n                                                    end - start,\n                                                    np.mean(batch_timings)))\n                batch_idx += num_devices\n                counter += num_devices\n                if (counter / num_devices) % config.save_freq == 0:\n                    self.save(config.save_path, counter)\n                    self.writer.add_summary(_g_sum, counter)\n                    fdict = {self.gtruth_noisy[0]:sample_noisy}\n                    canvas_w = self.sess.run(self.Gs[0],\n                                             feed_dict=fdict)\n                    swaves = sample_wav\n                    sample_dif = sample_wav - sample_noisy\n                    for m in range(min(20, canvas_w.shape[0])):\n                        print(\'w{} max: {} min: {}\'.format(m, np.max(canvas_w[m]), np.min(canvas_w[m])))\n                        wavfile.write(os.path.join(save_path, \'sample_{}-{}.wav\'.format(counter, m)), 16e3, canvas_w[m])\n                        if not os.path.exists(os.path.join(save_path, \'gtruth_{}.wav\'.format(m))):\n                            wavfile.write(os.path.join(save_path, \'gtruth_{}.wav\'.format(m)), 16e3, swaves[m])\n                            wavfile.write(os.path.join(save_path, \'noisy_{}.wav\'.format(m)), 16e3, sample_noisy[m])\n                            wavfile.write(os.path.join(save_path, \'dif_{}.wav\'.format(m)), 16e3, sample_dif[m])\n                        np.savetxt(os.path.join(save_path, \'g_losses.txt\'), g_losses)\n\n                if batch_idx >= num_batches:\n                    curr_epoch += 1\n                    # re-set batch idx\n                    batch_idx = 0\n                if curr_epoch >= config.epoch:\n                    # done training\n                    print(\'Done training; epoch limit {} \'\n                          \'reached.\'.format(self.epoch))\n                    print(\'Saving last model at iteration {}\'.format(counter))\n                    self.save(config.save_path, counter)\n                    self.writer.add_summary(_g_sum, counter)\n                    break\n        except tf.errors.OutOfRangeError:\n            print(\'[!] Reached queues limits in training loop\')\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n'"
ops.py,85,"b'from __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import batch_norm, fully_connected, flatten\nfrom tensorflow.contrib.layers import xavier_initializer\nfrom contextlib import contextmanager\nimport numpy as np\n\n\ndef gaussian_noise_layer(input_layer, std):\n    noise = tf.random_normal(shape=input_layer.get_shape().as_list(),\n                             mean=0.0,\n                             stddev=std,\n                             dtype=tf.float32)\n    return input_layer + noise\n\ndef sample_random_walk(batch_size, dim):\n    rw = np.zeros((batch_size, dim))\n    rw[:, 0] = np.random.randn(batch_size)\n    for b in range(batch_size):\n        for di in range(1, dim):\n            rw[b, di] = rw[b, di - 1] + np.random.randn(1)\n    # normalize to m=0 std=1\n    mean = np.mean(rw, axis=1).reshape((-1, 1))\n    std = np.std(rw, axis=1).reshape((-1, 1))\n    rw = (rw - mean) / std\n    return rw\n\ndef scalar_summary(name, x):\n    try:\n        summ = tf.summary.scalar(name, x)\n    except AttributeError:\n        summ = tf.scalar_summary(name, x)\n    return summ\n\ndef histogram_summary(name, x):\n    try:\n        summ = tf.summary.histogram(name, x)\n    except AttributeError:\n        summ = tf.histogram_summary(name, x)\n    return summ\n\ndef tensor_summary(name, x):\n    try:\n        summ = tf.summary.tensor_summary(name, x)\n    except AttributeError:\n        summ = tf.tensor_summary(name, x)\n    return summ\n\ndef audio_summary(name, x, sampling_rate=16e3):\n    try:\n        summ = tf.summary.audio(name, x, sampling_rate)\n    except AttributeError:\n        summ = tf.audio_summary(name, x, sampling_rate)\n    return summ\n\ndef minmax_normalize(x, x_min, x_max, o_min=-1., o_max=1.):\n    return (o_max - o_min)/(x_max - x_min) * (x - x_max) + o_max\n\ndef minmax_denormalize(x, x_min, x_max, o_min=-1., o_max=1.):\n    return minmax_normalize(x, o_min, o_max, x_min, x_max)\n\ndef downconv(x, output_dim, kwidth=5, pool=2, init=None, uniform=False,\n             bias_init=None, name=\'downconv\'):\n    """""" Downsampled convolution 1d """"""\n    x2d = tf.expand_dims(x, 2)\n    w_init = init\n    if w_init is None:\n        w_init = xavier_initializer(uniform=uniform)\n    with tf.variable_scope(name):\n        W = tf.get_variable(\'W\', [kwidth, 1, x.get_shape()[-1], output_dim],\n                            initializer=w_init)\n        conv = tf.nn.conv2d(x2d, W, strides=[1, pool, 1, 1], padding=\'SAME\')\n        if bias_init is not None:\n            b = tf.get_variable(\'b\', [output_dim],\n                                initializer=bias_init)\n            conv = tf.reshape(tf.nn.bias_add(conv, b), conv.get_shape())\n        else:\n            conv = tf.reshape(conv, conv.get_shape())\n        # reshape back to 1d\n        conv = tf.reshape(conv, conv.get_shape().as_list()[:2] +\n                          [conv.get_shape().as_list()[-1]])\n        return conv\n\n# https://github.com/carpedm20/lstm-char-cnn-tensorflow/blob/master/models/ops.py\ndef highway(input_, size, layer_size=1, bias=-2, f=tf.nn.relu, name=\'hw\'):\n    """"""Highway Network (cf. http://arxiv.org/abs/1505.00387).\n    t = sigmoid(Wy + b)\n    z = t * g(Wy + b) + (1 - t) * y\n    where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.\n    """"""\n    output = input_\n    for idx in xrange(layer_size):\n        lin_scope = \'{}_output_lin_{}\'.format(name, idx)\n        output = f(tf.nn.rnn_cell._linear(output, size, 0, scope=lin_scope))\n        transform_scope = \'{}_transform_lin_{}\'.format(name, idx)\n        transform_gate = tf.sigmoid(\n            tf.nn.rnn_cell._linear(input_, size, 0, scope=transform_scope) + bias)\n        carry_gate = 1. - transform_gate\n\n        output = transform_gate * output + carry_gate * input_\n\n    return output\n\ndef leakyrelu(x, alpha=0.3, name=\'lrelu\'):\n    return tf.maximum(x, alpha * x, name=name)\n\ndef prelu(x, name=\'prelu\', ref=False):\n    in_shape = x.get_shape().as_list()\n    with tf.variable_scope(name):\n        # make one alpha per feature\n        alpha = tf.get_variable(\'alpha\', in_shape[-1],\n                                initializer=tf.constant_initializer(0.),\n                                dtype=tf.float32)\n        pos = tf.nn.relu(x)\n        neg = alpha * (x - tf.abs(x)) * .5\n        if ref:\n            # return ref to alpha vector\n            return pos + neg, alpha\n        else:\n            return pos + neg\n\ndef conv1d(x, kwidth=5, num_kernels=1, init=None, uniform=False, bias_init=None,\n           name=\'conv1d\', padding=\'SAME\'):\n    input_shape = x.get_shape()\n    in_channels = input_shape[-1]\n    assert len(input_shape) >= 3\n    w_init = init\n    if w_init is None:\n        w_init = xavier_initializer(uniform=uniform)\n    with tf.variable_scope(name):\n        # filter shape: [kwidth, in_channels, num_kernels]\n        W = tf.get_variable(\'W\', [kwidth, in_channels, num_kernels],\n                            initializer=w_init\n                            )\n        conv = tf.nn.conv1d(x, W, stride=1, padding=padding)\n        if bias_init is not None:\n            b = tf.get_variable(\'b\', [num_kernels],\n                                initializer=tf.constant_initializer(bias_init))\n            conv = conv + b\n        return conv\n\ndef time_to_batch(value, dilation, name=None):\n    with tf.name_scope(\'time_to_batch\'):\n        shape = tf.shape(value)\n        pad_elements = dilation - 1 - (shape[1] + dilation - 1) % dilation\n        padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]])\n        reshaped = tf.reshape(padded, [-1, dilation, shape[2]])\n        transposed = tf.transpose(reshaped, perm=[1, 0, 2])\n        return tf.reshape(transposed, [shape[0] * dilation, -1, shape[2]])\n\n# https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/ops.py\ndef batch_to_time(value, dilation, name=None):\n    with tf.name_scope(\'batch_to_time\'):\n        shape = tf.shape(value)\n        prepared = tf.reshape(value, [dilation, -1, shape[2]])\n        transposed = tf.transpose(prepared, perm=[1, 0, 2])\n        return tf.reshape(transposed,\n                          [tf.div(shape[0], dilation), -1, shape[2]])\n\ndef atrous_conv1d(value, dilation, kwidth=3, num_kernels=1,\n                  name=\'atrous_conv1d\', bias_init=None, stddev=0.02):\n    input_shape = value.get_shape().as_list()\n    in_channels = input_shape[-1]\n    assert len(input_shape) >= 3\n    with tf.variable_scope(name):\n        weights_init = tf.truncated_normal_initializer(stddev=0.02)\n        # filter shape: [kwidth, in_channels, output_channels]\n        filter_ = tf.get_variable(\'w\', [kwidth, in_channels, num_kernels],\n                                  initializer=weights_init,\n                                  )\n        padding = [[0, 0], [(kwidth/2) * dilation, (kwidth/2) * dilation],\n                  [0, 0]]\n        padded = tf.pad(value, padding, mode=\'SYMMETRIC\')\n        if dilation > 1:\n            transformed = time_to_batch(padded, dilation)\n            conv = tf.nn.conv1d(transformed, filter_, stride=1, padding=\'SAME\')\n            restored = batch_to_time(conv, dilation)\n        else:\n            restored = tf.nn.conv1d(padded, filter_, stride=1, padding=\'SAME\')\n        # Remove excess elements at the end.\n        result = tf.slice(restored,\n                          [0, 0, 0],\n                          [-1, input_shape[1], num_kernels])\n        if bias_init is not None:\n            b = tf.get_variable(\'b\', [num_kernels],\n                                initializer=tf.constant_initializer(bias_init))\n            result = tf.add(result, b)\n        return result\n\ndef residual_block(input_, dilation, kwidth, num_kernels=1,\n                   bias_init=None, stddev=0.02, do_skip=True,\n                   name=\'residual_block\'):\n    print(\'input shape to residual block: \', input_.get_shape())\n    with tf.variable_scope(name):\n        h_a = atrous_conv1d(input_, dilation, kwidth, num_kernels,\n                            bias_init=bias_init, stddev=stddev)\n        h = tf.tanh(h_a)\n        # apply gated activation\n        z_a = atrous_conv1d(input_, dilation, kwidth, num_kernels,\n                            name=\'conv_gate\', bias_init=bias_init,\n                            stddev=stddev)\n        z = tf.nn.sigmoid(z_a)\n        print(\'gate shape: \', z.get_shape())\n        # element-wise apply the gate\n        gated_h = tf.mul(z, h)\n        print(\'gated h shape: \', gated_h.get_shape())\n        #make res connection\n        h_ = conv1d(gated_h, kwidth=1, num_kernels=1,\n                    init=tf.truncated_normal_initializer(stddev=stddev),\n                    name=\'residual_conv1\')\n        res = h_ + input_\n        print(\'residual result: \', res.get_shape())\n        if do_skip:\n            #make skip connection\n            skip = conv1d(gated_h, kwidth=1, num_kernels=1,\n                          init=tf.truncated_normal_initializer(stddev=stddev),\n                          name=\'skip_conv1\')\n            return res, skip\n        else:\n            return res\n\n\n# Code from keras backend \n# https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py\ndef repeat_elements(x, rep, axis):\n    """"""Repeats the elements of a tensor along an axis, like `np.repeat`.\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n    # Raises\n        ValueError: In case `x.shape[axis]` is undefined.\n    # Returns\n        A tensor.\n    """"""\n    x_shape = x.get_shape().as_list()\n    if x_shape[axis] is None:\n        raise ValueError(\'Axis \' + str(axis) + \' of input tensor \'\n                         \'should have a defined dimension, but is None. \'\n                         \'Full tensor shape: \' + str(tuple(x_shape)) + \'. \'\n                         \'Typically you need to pass a fully-defined \'\n                         \'`input_shape` argument to your first layer.\')\n    # slices along the repeat axis\n    splits = tf.split(split_dim=axis, num_split=x_shape[axis], value=x)\n    # repeat each slice the given number of reps\n    x_rep = [s for s in splits for _ in range(rep)]\n    return tf.concat(axis, x_rep)\n\ndef nn_deconv(x, kwidth=5, dilation=2, init=None, uniform=False,\n              bias_init=None, name=\'nn_deconv1d\'):\n    # first compute nearest neighbour interpolated x\n    interp_x = repeat_elements(x, dilation, 1)\n    # run a convolution over the interpolated fmap\n    dec = conv1d(interp_x, kwidth=5, num_kernels=1, init=init, uniform=uniform, \n                 bias_init=bias_init, name=name, padding=\'SAME\')\n    return dec\n\n\ndef deconv(x, output_shape, kwidth=5, dilation=2, init=None, uniform=False,\n           bias_init=None, name=\'deconv1d\'):\n    input_shape = x.get_shape()\n    in_channels = input_shape[-1]\n    out_channels = output_shape[-1]\n    assert len(input_shape) >= 3\n    # reshape the tensor to use 2d operators\n    x2d = tf.expand_dims(x, 2)\n    o2d = output_shape[:2] + [1] + [output_shape[-1]]\n    w_init = init\n    if w_init is None:\n        w_init = xavier_initializer(uniform=uniform)\n    with tf.variable_scope(name):\n        # filter shape: [kwidth, output_channels, in_channels]\n        W = tf.get_variable(\'W\', [kwidth, 1, out_channels, in_channels],\n                            initializer=w_init\n                            )\n        try:\n            deconv = tf.nn.conv2d_transpose(x2d, W, output_shape=o2d,\n                                            strides=[1, dilation, 1, 1])\n        except AttributeError:\n            # support for versions of TF before 0.7.0\n            # based on https://github.com/carpedm20/DCGAN-tensorflow\n            deconv = tf.nn.deconv2d(x2d, W, output_shape=o2d,\n                                    strides=[1, dilation, 1, 1])\n        if bias_init is not None:\n            b = tf.get_variable(\'b\', [out_channels],\n                                initializer=tf.constant_initializer(0.))\n            deconv = tf.reshape(tf.nn.bias_add(deconv, b), deconv.get_shape())\n        else:\n            deconv = tf.reshape(deconv, deconv.get_shape())\n        # reshape back to 1d\n        deconv = tf.reshape(deconv, output_shape)\n        return deconv\n\ndef conv2d(input_, output_dim, k_h, k_w, stddev=0.05, name=""conv2d"", with_w=False):\n    with tf.variable_scope(name):\n        w = tf.get_variable(\'w\', [k_h, k_w, input_.get_shape()[-1], output_dim],\n                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n        conv = tf.nn.conv2d(input_, w, strides=[1, 1, 1, 1], padding=\'VALID\')\n        if with_w:\n            return conv, w\n        else:\n            return conv\n\n# https://github.com/openai/improved-gan/blob/master/imagenet/ops.py\n@contextmanager\ndef variables_on_gpu0():\n    old_fn = tf.get_variable\n    def new_fn(*args, **kwargs):\n        with tf.device(""/gpu:0""):\n            return old_fn(*args, **kwargs)\n    tf.get_variable = new_fn\n    yield\n    tf.get_variable = old_fn\n\ndef average_gradients(tower_grads):\n    """""" Calculate the average gradient for each shared variable across towers.\n\n    Note that this function provides a sync point across al towers.\n    Args:\n        tower_grads: List of lists of (gradient, variable) tuples. The outer\n        list is over individual gradients. The inner list is over the gradient\n        calculation for each tower.\n    Returns:\n        List of pairs of (gradient, variable) where the gradient has been\n        averaged across all towers.\n    """"""\n\n    average_grads = []\n    for grad_and_vars in zip(*tower_grads):\n        # each grad is ((grad0_gpu0, var0_gpu0), ..., (grad0_gpuN, var0_gpuN))\n        grads = []\n        for g, _ in grad_and_vars:\n            # Add 0 dim to gradients to represent tower\n            expanded_g = tf.expand_dims(g, 0)\n\n            # Append on a \'tower\' dimension that we will average over below\n            grads.append(expanded_g)\n\n        # Build the tensor and average along tower dimension\n        grad = tf.concat(0, grads)\n        grad = tf.reduce_mean(grad, 0)\n\n        # The Variables are redundant because they are shared across towers\n        # just return first tower\'s pointer to the Variable\n        v = grad_and_vars[0][1]\n        grad_and_var = (grad, v)\n        average_grads.append(grad_and_var)\n    return average_grads\n'"
