file_path,api_count,code
data/TYY_create_db_biwi.py,0,"b'import scipy.io as sio\nimport pandas as pd\nfrom os import listdir\nfrom os.path import isfile, join\nfrom tqdm import tqdm\nimport sys\nimport cv2\nfrom moviepy.editor import *\nimport numpy as np\nimport argparse\nfrom mtcnn.mtcnn import MTCNN\n\n\ndef get_args():\n\tparser = argparse.ArgumentParser(description=""This script cleans-up noisy labels ""\n\t                                             ""and creates database for training."",\n\t                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\tparser.add_argument(""--db"", type=str, default=\'./BIWI\',\n\t                    help=""path to database"")\n\tparser.add_argument(""--output"", type=str, default=\'./BIWI_noTrack.npz\',\n\t                    help=""path to output database mat file"")\n\tparser.add_argument(""--img_size"", type=int, default=64,\n\t                    help=""output image size"")\n\tparser.add_argument(""--ad"", type=float, default=0.4,\n\t                    help=""enlarge margin"")\n\t\n\n\targs = parser.parse_args()\n\treturn args\n\n\ndef main():\n\targs = get_args()\n\tmypath = args.db\n\toutput_path = args.output\n\timg_size = args.img_size\n\tad = args.ad\n\n\tisPlot = True\n\tdetector = MTCNN()\n\n\tonlyfiles_png = []\n\tonlyfiles_txt = []\n\tfor num in range(0,24):\n\t\tif num<9:\n\t\t\tmypath_obj = mypath+\'/0\'+str(num+1)\n\t\telse:\n\t\t\tmypath_obj = mypath+\'/\'+str(num+1)\n\t\tprint(mypath_obj)\n\t\tonlyfiles_txt_temp = [f for f in listdir(mypath_obj) if isfile(join(mypath_obj, f)) and join(mypath_obj, f).endswith(\'.txt\')]\n\t\tonlyfiles_png_temp = [f for f in listdir(mypath_obj) if isfile(join(mypath_obj, f)) and join(mypath_obj, f).endswith(\'.png\')]\n\t\n\t\tonlyfiles_txt_temp.sort()\n\t\tonlyfiles_png_temp.sort()\n\n\t\tonlyfiles_txt.append(onlyfiles_txt_temp)\n\t\tonlyfiles_png.append(onlyfiles_png_temp)\n\tprint(len(onlyfiles_txt))\n\tprint(len(onlyfiles_png))\n\t\n\tout_imgs = []\n\tout_poses = []\n\t\n\tfor i in range(len(onlyfiles_png)):\n\t\tprint(\'object %d\' %i)\n\t\t\n\t\tmypath_obj = \'\'\n\t\tif i<9:\n\t\t\tmypath_obj = mypath+\'/0\'+str(i+1)\n\t\telse:\n\t\t\tmypath_obj = mypath+\'/\'+str(i+1)\n\n\t\tfor j in tqdm(range(len(onlyfiles_png[i]))):\n\t\t\t\n\t\t\timg_name = onlyfiles_png[i][j]\n\t\t\ttxt_name = onlyfiles_txt[i][j]\n\t\t\t\n\t\t\timg_name_split = img_name.split(\'_\')\n\t\t\ttxt_name_split = txt_name.split(\'_\')\n\n\t\t\tif img_name_split[1] != txt_name_split[1]:\n\t\t\t\tprint(\'Mismatched!\')\n\t\t\t\tsys.exit()\n\n\n\t\t\tpose_path = mypath_obj+\'/\'+txt_name\n\t\t\t# Load pose in degrees\n\t\t\tpose_annot = open(pose_path, \'r\')\n\t\t\tR = []\n\t\t\tfor line in pose_annot:\n\t\t\t\tline = line.strip(\'\\n\').split(\' \')\n\t\t\t\tL = []\n\t\t\t\tif line[0] != \'\':\n\t\t\t\t\tfor nb in line:\n\t\t\t\t\t\tif nb == \'\':\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\tL.append(float(nb))\n\t\t\t\t\tR.append(L)\n\n\t\t\tR = np.array(R)\n\t\t\tT = R[3,:]\n\t\t\tR = R[:3,:]\n\t\t\tpose_annot.close()\n\n\t\t\tR = np.transpose(R)\n\n\t\t\troll = -np.arctan2(R[1][0], R[0][0]) * 180 / np.pi\n\t\t\tyaw = -np.arctan2(-R[2][0], np.sqrt(R[2][1] ** 2 + R[2][2] ** 2)) * 180 / np.pi\n\t\t\tpitch = np.arctan2(R[2][1], R[2][2]) * 180 / np.pi\n\n\n\n\t\t\timg = cv2.imread(mypath_obj+\'/\'+img_name)\n\t\t\timg_h = img.shape[0]\n\t\t\timg_w = img.shape[1]\n\t\t\tif j==0:\n\t\t\t\t[xw1_pre,xw2_pre,yw1_pre,yw2_pre] = [0,0,0,0]\n\t\t\tdetected = detector.detect_faces(img)\n\n\t\t\tif len(detected) > 0:\n\t\t\t\tdis_list = []\n\t\t\t\tXY = []\n\t\t\t\tfor i_d, d in enumerate(detected):\n\t\t\t\t\t\n\t\t\t\t\txv = []\n\t\t\t\t\tyv = []\n\t\t\t\t\tfor key, value in d[\'keypoints\'].items():\n\t\t\t\t\t\txv.append(value[0]) \n\t\t\t\t\t\tyv.append(value[1])\n\t\t\t\t\t\n\t\t\t\t\tif d[\'confidence\'] > 0.90:\n\t\t\t\t\t\tx1,y1,w,h = d[\'box\']\n\t\t\t\t\t\tx2 = x1 + w\n\t\t\t\t\t\ty2 = y1 + h\n\t\t\t\t\t\txw1 = max(int(x1 - ad * w), 0)\n\t\t\t\t\t\tyw1 = max(int(y1 - ad * h), 0)\n\t\t\t\t\t\txw2 = min(int(x2 + ad * w), img_w - 1)\n\t\t\t\t\t\tyw2 = min(int(y2 + ad * h), img_h - 1)\n\t\t\t\t\t\t\n\t\t\t\t\t\t# Crop the face loosely\n\t\t\t\t\t\t# x_min = int(min(xv))\n\t\t\t\t\t\t# x_max = int(max(xv))\n\t\t\t\t\t\t# y_min = int(min(yv))\n\t\t\t\t\t\t# y_max = int(max(yv))\n\t\t\t\t\t\t\n\t\t\t\t\t\t# h = y_max-y_min\n\t\t\t\t\t\t# w = x_max-x_min\n\n\t\t\t\t\t\t# xw1 = max(int(x_min - ad * w), 0)\n\t\t\t\t\t\t# xw2 = min(int(x_max + ad * w), img_w - 1)\n\t\t\t\t\t\t# yw1 = max(int(y_min - ad * h), 0)\n\t\t\t\t\t\t# yw2 = min(int(y_max + ad * h), img_h - 1)\n\n\t\t\t\t\t\tXY.append([xw1,xw2,yw1,yw2])\n\t\t\t\t\t\tdis_betw_cen = np.abs(xw1-img_w*2/3)+np.abs(yw1-img_h*2/3)\n\t\t\t\t\t\tdis_list.append(dis_betw_cen)\n\t\t\t\t\n\t\t\t\tif len(dis_list)>0:\n\t\t\t\t\tmin_id = np.argmin(dis_list)\n\t\t\t\t\t[xw1,xw2,yw1,yw2] = XY[min_id]\n\n\n\t\t\t\tdis_betw_frames = np.abs(xw1-xw1_pre)\n\t\t\t\tif dis_betw_frames < 80 or j==0:\n\t\t\t\t\timg = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n\t\t\t\t\t[xw1_pre,xw2_pre,yw1_pre,yw2_pre] = [xw1,xw2,yw1,yw2]\n\t\t\t\t\tif isPlot:\n\t\t\t\t\t\tprint([xw1_pre,xw2_pre,yw1_pre,yw2_pre])\n\t\t\t\t\t\tcv2.imshow(\'check\',img)\n\t\t\t\t\t\tk=cv2.waitKey(10)\n\t\t\t\t\timg = cv2.resize(img, (img_size, img_size))\n\t\t\t\t\tcont_labels = np.array([yaw, pitch, roll])\n\t\t\t\t\tout_imgs.append(img)\n\t\t\t\t\tout_poses.append(cont_labels)\n\t\t\t# \telse:\n\t\t\t# \t\timg = cv2.resize(img[yw1_pre:yw2_pre + 1, xw1_pre:xw2_pre + 1, :], (img_size, img_size))\n\t\t\t# \t\t# Checking the cropped image\n\t\t\t# \t\tif isPlot:\n\t\t\t# \t\t\tprint([xw1_pre,xw2_pre,yw1_pre,yw2_pre])\n\t\t\t# \t\t\tprint(\'Distance between two frames too large! Use previous frame detected location.\')\n\t\t\t\t\t\n\t\t\t# \t\t\tcv2.imshow(\'check\',img)\n\t\t\t# \t\t\tk=cv2.waitKey(10)\n\t\t\t# \t\timg = cv2.resize(img, (img_size, img_size))\n\t\t\t# \t\tcont_labels = np.array([yaw, pitch, roll])\n\t\t\t# \t\tout_imgs.append(img)\n\t\t\t# \t\tout_poses.append(cont_labels)\n\t\t\t# else:\n\t\t\t# \timg = cv2.resize(img[yw1_pre:yw2_pre + 1, xw1_pre:xw2_pre + 1, :], (img_size, img_size))\n\t\t\t# \tif isPlot:\n\t\t\t# \t\tprint(\'No face detected! Use previous frame detected location.\')\n\t\t\t\t\n\t\t\t# \t# Checking the cropped image\n\t\t\t# \tif isPlot:\n\t\t\t# \t\tcv2.imshow(\'check\',img)\n\t\t\t# \t\tk=cv2.waitKey(10)\n\t\t\t# \timg = cv2.resize(img, (img_size, img_size))\n\t\t\t# \tcont_labels = np.array([yaw, pitch, roll])\n\t\t\t# \tout_imgs.append(img)\n\t\t\t# \tout_poses.append(cont_labels)\n\tnp.savez(output_path,image=np.array(out_imgs), pose=np.array(out_poses), img_size=img_size)\n\n\nif __name__ == \'__main__\':\n\tmain()\n'"
data/TYY_create_db_biwi_70_30.py,0,"b'import scipy.io as sio\nimport pandas as pd\nfrom os import listdir\nfrom os.path import isfile, join\nfrom tqdm import tqdm\nimport sys\nimport cv2\nfrom moviepy.editor import *\nimport numpy as np\nimport argparse\nfrom mtcnn.mtcnn import MTCNN\n\n\ndef get_args():\n\tparser = argparse.ArgumentParser(description=""This script cleans-up noisy labels ""\n\t                                             ""and creates database for training."",\n\t                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\tparser.add_argument(""--db"", type=str, default=\'./BIWI\',\n\t                    help=""path to database"")\n\tparser.add_argument(""--output"", type=str, default=\'./BIWI\',\n\t                    help=""path to output database mat file"")\n\tparser.add_argument(""--img_size"", type=int, default=64,\n\t                    help=""output image size"")\n\tparser.add_argument(""--ad"", type=float, default=0.4,\n\t                    help=""enlarge margin"")\n\t\n\n\targs = parser.parse_args()\n\treturn args\n\n\ndef main():\n\targs = get_args()\n\tmypath = args.db\n\toutput_path = args.output\n\timg_size = args.img_size\n\tad = args.ad\n\n\tisPlot = True\n\tdetector = MTCNN()\n\n\trandFlag = np.zeros(24)\n\trandFlag[0:16] = 1\n\trandFlag = np.random.permutation(randFlag)\n\n\tprint(randFlag)\n\toutput_train_path = output_path+\'_train.npz\'\n\toutput_test_path = output_path+\'_test.npz\'\n\n\tonlyfiles_png = []\n\tonlyfiles_txt = []\n\tfor num in range(0,24):\n\t\tif num<9:\n\t\t\tmypath_obj = mypath+\'/0\'+str(num+1)\n\t\telse:\n\t\t\tmypath_obj = mypath+\'/\'+str(num+1)\n\t\tprint(mypath_obj)\n\t\tonlyfiles_txt_temp = [f for f in listdir(mypath_obj) if isfile(join(mypath_obj, f)) and join(mypath_obj, f).endswith(\'.txt\')]\n\t\tonlyfiles_png_temp = [f for f in listdir(mypath_obj) if isfile(join(mypath_obj, f)) and join(mypath_obj, f).endswith(\'.png\')]\n\t\n\t\tonlyfiles_txt_temp.sort()\n\t\tonlyfiles_png_temp.sort()\n\n\t\tonlyfiles_txt.append(onlyfiles_txt_temp)\n\t\tonlyfiles_png.append(onlyfiles_png_temp)\n\tprint(len(onlyfiles_txt))\n\tprint(len(onlyfiles_png))\n\t\n\tout_imgs_train = []\n\tout_poses_train = []\n\n\tout_imgs_test = []\n\tout_poses_test = []\n\t\n\tfor i in range(len(onlyfiles_png)):\n\t\tprint(\'object %d\' %i)\n\t\t\n\t\tmypath_obj = \'\'\n\t\tif i<9:\n\t\t\tmypath_obj = mypath+\'/0\'+str(i+1)\n\t\telse:\n\t\t\tmypath_obj = mypath+\'/\'+str(i+1)\n\n\t\tfor j in tqdm(range(len(onlyfiles_png[i]))):\n\t\t\t\n\t\t\timg_name = onlyfiles_png[i][j]\n\t\t\ttxt_name = onlyfiles_txt[i][j]\n\t\t\t\n\t\t\timg_name_split = img_name.split(\'_\')\n\t\t\ttxt_name_split = txt_name.split(\'_\')\n\n\t\t\tif img_name_split[1] != txt_name_split[1]:\n\t\t\t\tprint(\'Mismatched!\')\n\t\t\t\tsys.exit()\n\n\n\t\t\tpose_path = mypath_obj+\'/\'+txt_name\n\t\t\t# Load pose in degrees\n\t\t\tpose_annot = open(pose_path, \'r\')\n\t\t\tR = []\n\t\t\tfor line in pose_annot:\n\t\t\t\tline = line.strip(\'\\n\').split(\' \')\n\t\t\t\tL = []\n\t\t\t\tif line[0] != \'\':\n\t\t\t\t\tfor nb in line:\n\t\t\t\t\t\tif nb == \'\':\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\tL.append(float(nb))\n\t\t\t\t\tR.append(L)\n\n\t\t\tR = np.array(R)\n\t\t\tT = R[3,:]\n\t\t\tR = R[:3,:]\n\t\t\tpose_annot.close()\n\n\t\t\tR = np.transpose(R)\n\n\t\t\troll = -np.arctan2(R[1][0], R[0][0]) * 180 / np.pi\n\t\t\tyaw = -np.arctan2(-R[2][0], np.sqrt(R[2][1] ** 2 + R[2][2] ** 2)) * 180 / np.pi\n\t\t\tpitch = np.arctan2(R[2][1], R[2][2]) * 180 / np.pi\n\n\n\n\t\t\timg = cv2.imread(mypath_obj+\'/\'+img_name)\n\t\t\timg_h = img.shape[0]\n\t\t\timg_w = img.shape[1]\n\t\t\tif j==0:\n\t\t\t\t[xw1_pre,xw2_pre,yw1_pre,yw2_pre] = [0,0,0,0]\n\t\t\tdetected = detector.detect_faces(img)\n\n\t\t\tif len(detected) > 0:\n\t\t\t\tdis_list = []\n\t\t\t\tXY = []\n\t\t\t\tfor i_d, d in enumerate(detected):\n\t\t\t\t\t\n\t\t\t\t\txv = []\n\t\t\t\t\tyv = []\n\t\t\t\t\tfor key, value in d[\'keypoints\'].items():\n\t\t\t\t\t\txv.append(value[0]) \n\t\t\t\t\t\tyv.append(value[1])\n\t\t\t\t\t\n\t\t\t\t\tif d[\'confidence\'] > 0.95:\n\t\t\t\t\t\tx1,y1,w,h = d[\'box\']\n\t\t\t\t\t\tx2 = x1 + w\n\t\t\t\t\t\ty2 = y1 + h\n\t\t\t\t\t\txw1 = max(int(x1 - ad * w), 0)\n\t\t\t\t\t\tyw1 = max(int(y1 - ad * h), 0)\n\t\t\t\t\t\txw2 = min(int(x2 + ad * w), img_w - 1)\n\t\t\t\t\t\tyw2 = min(int(y2 + ad * h), img_h - 1)\n\t\t\t\t\t\t\n\t\t\t\t\t\t# Crop the face loosely\n\t\t\t\t\t\t# x_min = int(min(xv))\n\t\t\t\t\t\t# x_max = int(max(xv))\n\t\t\t\t\t\t# y_min = int(min(yv))\n\t\t\t\t\t\t# y_max = int(max(yv))\n\t\t\t\t\t\t\n\t\t\t\t\t\t# h = y_max-y_min\n\t\t\t\t\t\t# w = x_max-x_min\n\n\t\t\t\t\t\t# xw1 = max(int(x_min - ad * w), 0)\n\t\t\t\t\t\t# xw2 = min(int(x_max + ad * w), img_w - 1)\n\t\t\t\t\t\t# yw1 = max(int(y_min - ad * h), 0)\n\t\t\t\t\t\t# yw2 = min(int(y_max + ad * h), img_h - 1)\n\n\t\t\t\t\t\tXY.append([xw1,xw2,yw1,yw2])\n\t\t\t\t\t\tdis_betw_cen = np.abs(xw1-img_w*2/3)+np.abs(yw1-img_h*2/3)\n\t\t\t\t\t\tdis_list.append(dis_betw_cen)\n\t\t\t\t\n\t\t\t\tif len(dis_list)>0:\n\t\t\t\t\tmin_id = np.argmin(dis_list)\n\t\t\t\t\t[xw1,xw2,yw1,yw2] = XY[min_id]\n\n\n\t\t\t\tdis_betw_frames = np.abs(xw1-xw1_pre)\n\t\t\t\tif dis_betw_frames < 80 or j==0:\n\t\t\t\t\timg = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n\t\t\t\t\t[xw1_pre,xw2_pre,yw1_pre,yw2_pre] = [xw1,xw2,yw1,yw2]\n\t\t\t\t\tif isPlot:\n\t\t\t\t\t\tprint([xw1_pre,xw2_pre,yw1_pre,yw2_pre])\n\t\t\t\t\t\tcv2.imshow(\'check\',img)\n\t\t\t\t\t\tk=cv2.waitKey(10)\n\t\t\t\t\timg = cv2.resize(img, (img_size, img_size))\n\t\t\t\t\tcont_labels = np.array([yaw, pitch, roll])\n\t\t\t\t\t\n\t\t\t\t\tif randFlag[i] == 1:\n\t\t\t\t\t\tout_imgs_train.append(img)\n\t\t\t\t\t\tout_poses_train.append(cont_labels)\n\t\t\t\t\telif randFlag[i] == 0:\n\t\t\t\t\t\tout_imgs_test.append(img)\n\t\t\t\t\t\tout_poses_test.append(cont_labels)\n\t\t\t\telse:\n\t\t\t\t\timg = cv2.resize(img[yw1_pre:yw2_pre + 1, xw1_pre:xw2_pre + 1, :], (img_size, img_size))\n\t\t\t\t\t# Checking the cropped image\n\t\t\t\t\tif isPlot:\n\t\t\t\t\t\tprint([xw1_pre,xw2_pre,yw1_pre,yw2_pre])\n\t\t\t\t\t\tprint(\'Distance between two frames too large! Use previous frame detected location.\')\n\t\t\t\t\t\n\t\t\t\t\t\tcv2.imshow(\'check\',img)\n\t\t\t\t\t\tk=cv2.waitKey(10)\n\t\t\t\t\timg = cv2.resize(img, (img_size, img_size))\n\t\t\t\t\tcont_labels = np.array([yaw, pitch, roll])\n\t\t\t\t\tif randFlag[i] == 1:\n\t\t\t\t\t\tout_imgs_train.append(img)\n\t\t\t\t\t\tout_poses_train.append(cont_labels)\n\t\t\t\t\telif randFlag[i] == 0:\n\t\t\t\t\t\tout_imgs_test.append(img)\n\t\t\t\t\t\tout_poses_test.append(cont_labels)\n\t\t\telse:\n\t\t\t\timg = cv2.resize(img[yw1_pre:yw2_pre + 1, xw1_pre:xw2_pre + 1, :], (img_size, img_size))\n\t\t\t\tif isPlot:\n\t\t\t\t\tprint(\'No face detected! Use previous frame detected location.\')\n\t\t\t\t\n\t\t\t\t# Checking the cropped image\n\t\t\t\tif isPlot:\n\t\t\t\t\tcv2.imshow(\'check\',img)\n\t\t\t\t\tk=cv2.waitKey(10)\n\t\t\t\timg = cv2.resize(img, (img_size, img_size))\n\t\t\t\tcont_labels = np.array([yaw, pitch, roll])\n\t\t\t\tif randFlag[i] == 1:\n\t\t\t\t\tout_imgs_train.append(img)\n\t\t\t\t\tout_poses_train.append(cont_labels)\n\t\t\t\telif randFlag[i] == 0:\n\t\t\t\t\tout_imgs_test.append(img)\n\t\t\t\t\tout_poses_test.append(cont_labels)\n\tnp.savez(output_train_path,image=np.array(out_imgs_train), pose=np.array(out_poses_train), img_size=img_size)\n\tnp.savez(output_test_path,image=np.array(out_imgs_test), pose=np.array(out_poses_test), img_size=img_size)\n\n\nif __name__ == \'__main__\':\n\tmain()'"
demo/demo_FSANET.py,0,"b'# The demo credit belongs to Yi-Ting Chen\n\nimport os\nimport cv2\nimport sys\nsys.path.append(\'..\')\nimport numpy as np\nfrom math import cos, sin\n# from moviepy.editor import *\nfrom lib.FSANET_model import *\n# from moviepy.editor import *\nfrom keras import backend as K\nfrom keras.layers import Average\n\ndef draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size = 80):\n\n    pitch = pitch * np.pi / 180\n    yaw = -(yaw * np.pi / 180)\n    roll = roll * np.pi / 180\n\n    if tdx != None and tdy != None:\n        tdx = tdx\n        tdy = tdy\n    else:\n        height, width = img.shape[:2]\n        tdx = width / 2\n        tdy = height / 2\n\n    # X-Axis pointing to right. drawn in red\n    x1 = size * (cos(yaw) * cos(roll)) + tdx\n    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n\n    # Y-Axis | drawn in green\n    #        v\n    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n\n    # Z-Axis (out of the screen) drawn in blue\n    x3 = size * (sin(yaw)) + tdx\n    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n\n    cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n    cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n    cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n\n    return img\n    \ndef draw_results(detected,input_img,faces,ad,img_size,img_w,img_h,model,time_detection,time_network,time_plot):\n    \n    if len(detected) > 0:\n        for i, (x,y,w,h) in enumerate(detected):\n            #x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n            \n            x1 = x\n            y1 = y\n            x2 = x+w\n            y2 = y+h\n\n            xw1 = max(int(x1 - ad * w), 0)\n            yw1 = max(int(y1 - ad * h), 0)\n            xw2 = min(int(x2 + ad * w), img_w - 1)\n            yw2 = min(int(y2 + ad * h), img_h - 1)\n            \n            faces[i,:,:,:] = cv2.resize(input_img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n            faces[i,:,:,:] = cv2.normalize(faces[i,:,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)        \n            \n            face = np.expand_dims(faces[i,:,:,:], axis=0)\n            p_result = model.predict(face)\n            \n            face = face.squeeze()\n            img = draw_axis(input_img[yw1:yw2 + 1, xw1:xw2 + 1, :], p_result[0][0], p_result[0][1], p_result[0][2])\n            \n            input_img[yw1:yw2 + 1, xw1:xw2 + 1, :] = img\n            \n    cv2.imshow(""result"", input_img)\n    \n    return input_img #,time_network,time_plot\n\ndef main():\n    try:\n        os.mkdir(\'./img\')\n    except OSError:\n        pass\n    \n    K.set_learning_phase(0) # make sure its testing mode\n    face_cascade = cv2.CascadeClassifier(\'lbpcascade_frontalface_improved.xml\')\n    \n    # load model and weights\n    img_size = 64\n    stage_num = [3,3,3]\n    lambda_local = 1\n    lambda_d = 1\n    img_idx = 0\n    detected = \'\' #make this not local variable\n    time_detection = 0\n    time_network = 0\n    time_plot = 0\n    skip_frame = 5 # every 5 frame do 1 detection and network forward propagation\n    ad = 0.6\n\n    #Parameters\n    num_capsule = 3\n    dim_capsule = 16\n    routings = 2\n    stage_num = [3,3,3]\n    lambda_d = 1\n    num_classes = 3\n    image_size = 64\n    num_primcaps = 7*3\n    m_dim = 5\n    S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n\n    model1 = FSA_net_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n    model2 = FSA_net_Var_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n    \n    num_primcaps = 8*8*3\n    S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n\n    model3 = FSA_net_noS_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n    \n    print(\'Loading models ...\')\n\n    weight_file1 = \'../pre-trained/300W_LP_models/fsanet_capsule_3_16_2_21_5/fsanet_capsule_3_16_2_21_5.h5\'\n    model1.load_weights(weight_file1)\n    print(\'Finished loading model 1.\')\n    \n    weight_file2 = \'../pre-trained/300W_LP_models/fsanet_var_capsule_3_16_2_21_5/fsanet_var_capsule_3_16_2_21_5.h5\'\n    model2.load_weights(weight_file2)\n    print(\'Finished loading model 2.\')\n\n    weight_file3 = \'../pre-trained/300W_LP_models/fsanet_noS_capsule_3_16_2_192_5/fsanet_noS_capsule_3_16_2_192_5.h5\'\n    model3.load_weights(weight_file3)\n    print(\'Finished loading model 3.\')\n\n    inputs = Input(shape=(64,64,3))\n    x1 = model1(inputs) #1x1\n    x2 = model2(inputs) #var\n    x3 = model3(inputs) #w/o\n    avg_model = Average()([x1,x2,x3])\n    model = Model(inputs=inputs, outputs=avg_model)\n    \n    # capture video\n    cap = cv2.VideoCapture(0)\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1024*1)\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 768*1)\n    \n    print(\'Start detecting pose ...\')\n    detected_pre = []\n\n    while True:\n        # get video frame\n        ret, input_img = cap.read()\n\n        img_idx = img_idx + 1\n        img_h, img_w, _ = np.shape(input_img)\n        \n        if img_idx==1 or img_idx%skip_frame == 0:\n            time_detection = 0\n            time_network = 0\n            time_plot = 0\n            \n            # detect faces using LBP detector\n            gray_img = cv2.cvtColor(input_img,cv2.COLOR_BGR2GRAY)\n            detected = face_cascade.detectMultiScale(gray_img, 1.1)\n            \n            if len(detected_pre) > 0 and len(detected) == 0:\n                detected = detected_pre\n\n            faces = np.empty((len(detected), img_size, img_size, 3))\n\n            input_img = draw_results(detected,input_img,faces,ad,img_size,img_w,img_h,model,time_detection,time_network,time_plot)\n            cv2.imwrite(\'img/\'+str(img_idx)+\'.png\',input_img)\n            \n        else:\n            input_img = draw_results(detected,input_img,faces,ad,img_size,img_w,img_h,model,time_detection,time_network,time_plot)\n\n\n        if len(detected) > len(detected_pre) or img_idx%(skip_frame*3) == 0:\n            detected_pre = detected\n\n        key = cv2.waitKey(1)\n        \nif __name__ == \'__main__\':\n    main()\n'"
demo/demo_FSANET_mtcnn.py,0,"b'import os\nimport cv2\nimport sys\nsys.path.append(\'..\')\n\n\nimport numpy as np\nfrom math import cos, sin\n# from moviepy.editor import *\nfrom lib.FSANET_model import *\nfrom mtcnn.mtcnn import MTCNN\n\nfrom keras import backend as K\nfrom keras.layers import Average\nfrom keras.models import Model\n\n\ndef draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size=80):\n\n    pitch = pitch * np.pi / 180\n    yaw = -(yaw * np.pi / 180)\n    roll = roll * np.pi / 180\n\n    if tdx != None and tdy != None:\n        tdx = tdx\n        tdy = tdy\n    else:\n        height, width = img.shape[:2]\n        tdx = width / 2\n        tdy = height / 2\n\n    # X-Axis pointing to right. drawn in red\n    x1 = size * (cos(yaw) * cos(roll)) + tdx\n    y1 = size * (cos(pitch) * sin(roll) + cos(roll)\n                 * sin(pitch) * sin(yaw)) + tdy\n\n    # Y-Axis | drawn in green\n    #        v\n    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n    y2 = size * (cos(pitch) * cos(roll) - sin(pitch)\n                 * sin(yaw) * sin(roll)) + tdy\n\n    # Z-Axis (out of the screen) drawn in blue\n    x3 = size * (sin(yaw)) + tdx\n    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n\n    cv2.line(img, (int(tdx), int(tdy)), (int(x1), int(y1)), (0, 0, 255), 3)\n    cv2.line(img, (int(tdx), int(tdy)), (int(x2), int(y2)), (0, 255, 0), 3)\n    cv2.line(img, (int(tdx), int(tdy)), (int(x3), int(y3)), (255, 0, 0), 2)\n\n    return img\n\n\ndef draw_results_mtcnn(detected, input_img, faces, ad, img_size, img_w, img_h, model, time_detection, time_network, time_plot):\n\n    if len(detected) > 0:\n        for i, d in enumerate(detected):\n            #x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n            if d[\'confidence\'] > 0.95:\n                x1, y1, w, h = d[\'box\']\n\n                x2 = x1+w\n                y2 = y1+h\n\n                xw1 = max(int(x1 - ad * w), 0)\n                yw1 = max(int(y1 - ad * h), 0)\n                xw2 = min(int(x2 + ad * w), img_w - 1)\n                yw2 = min(int(y2 + ad * h), img_h - 1)\n\n                faces[i, :, :, :] = cv2.resize(\n                    input_img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n                faces[i, :, :, :] = cv2.normalize(\n                    faces[i, :, :, :], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n\n                face = np.expand_dims(faces[i, :, :, :], axis=0)\n                p_result = model.predict(face)\n\n                face = face.squeeze()\n                img = draw_axis(input_img[yw1:yw2 + 1, xw1:xw2 + 1, :],\n                                p_result[0][0], p_result[0][1], p_result[0][2])\n\n                input_img[yw1:yw2 + 1, xw1:xw2 + 1, :] = img\n\n    cv2.imshow(""result"", input_img)\n    \n    return input_img  # ,time_network,time_plot\n\n\ndef main():\n    try:\n        os.mkdir(\'./img\')\n    except OSError:\n        pass\n\n    K.set_learning_phase(0)  # make sure its testing mode\n    # face_cascade = cv2.CascadeClassifier(\'lbpcascade_frontalface_improved.xml\')\n    detector = MTCNN()\n\n    # load model and weights\n    img_size = 64\n    stage_num = [3, 3, 3]\n    lambda_local = 1\n    lambda_d = 1\n    img_idx = 0\n    detected = \'\'  # make this not local variable\n    time_detection = 0\n    time_network = 0\n    time_plot = 0\n    skip_frame = 5  # every 5 frame do 1 detection and network forward propagation\n    ad = 0.6\n\n    # Parameters\n    num_capsule = 3\n    dim_capsule = 16\n    routings = 2\n    stage_num = [3, 3, 3]\n    lambda_d = 1\n    num_classes = 3\n    image_size = 64\n    num_primcaps = 7*3\n    m_dim = 5\n    S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n\n    model1 = FSA_net_Capsule(image_size, num_classes,\n                             stage_num, lambda_d, S_set)()\n    model2 = FSA_net_Var_Capsule(\n        image_size, num_classes, stage_num, lambda_d, S_set)()\n\n    num_primcaps = 8*8*3\n    S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n\n    model3 = FSA_net_noS_Capsule(\n        image_size, num_classes, stage_num, lambda_d, S_set)()\n\n    print(\'Loading models ...\')\n\n    weight_file1 = \'../pre-trained/300W_LP_models/fsanet_capsule_3_16_2_21_5/fsanet_capsule_3_16_2_21_5.h5\'\n    model1.load_weights(weight_file1)\n    print(\'Finished loading model 1.\')\n\n    weight_file2 = \'../pre-trained/300W_LP_models/fsanet_var_capsule_3_16_2_21_5/fsanet_var_capsule_3_16_2_21_5.h5\'\n    model2.load_weights(weight_file2)\n    print(\'Finished loading model 2.\')\n\n    weight_file3 = \'../pre-trained/300W_LP_models/fsanet_noS_capsule_3_16_2_192_5/fsanet_noS_capsule_3_16_2_192_5.h5\'\n    model3.load_weights(weight_file3)\n    print(\'Finished loading model 3.\')\n\n    inputs = Input(shape=(64, 64, 3))\n    x1 = model1(inputs)  # 1x1\n    x2 = model2(inputs)  # var\n    x3 = model3(inputs)  # w/o\n    avg_model = Average()([x1, x2, x3])\n    model = Model(inputs=inputs, outputs=avg_model)\n\n    # capture video\n    cap = cv2.VideoCapture(0)\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1024*1)\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 768*1)\n\n    print(\'Start detecting pose ...\')\n    detected_pre = []\n\n    while True:\n        # get video frame\n        ret, input_img = cap.read()\n\n        img_idx = img_idx + 1\n        img_h, img_w, _ = np.shape(input_img)\n\n        if img_idx == 1 or img_idx % skip_frame == 0:\n            time_detection = 0\n            time_network = 0\n            time_plot = 0\n\n            # detect faces using LBP detector\n            gray_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n            # detected = face_cascade.detectMultiScale(gray_img, 1.1)\n            detected = detector.detect_faces(input_img)\n\n            if len(detected_pre) > 0 and len(detected) == 0:\n                detected = detected_pre\n\n            faces = np.empty((len(detected), img_size, img_size, 3))\n\n            input_img = draw_results_mtcnn(\n                detected, input_img, faces, ad, img_size, img_w, img_h, model, time_detection, time_network, time_plot)\n            cv2.imwrite(\'img/\'+str(img_idx)+\'.png\', input_img)\n\n        else:\n            input_img = draw_results_mtcnn(\n                detected, input_img, faces, ad, img_size, img_w, img_h, model, time_detection, time_network, time_plot)\n\n        if len(detected) > len(detected_pre) or img_idx % (skip_frame*3) == 0:\n            detected_pre = detected\n\n        key = cv2.waitKey(1)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
demo/demo_FSANET_ssd.py,0,"b'import os\nimport cv2\nimport sys\nsys.path.append(\'..\')\nimport numpy as np\nfrom math import cos, sin\n# from moviepy.editor import *\nfrom lib.FSANET_model import *\nimport numpy as np\nfrom keras.layers import Average\n# from moviepy.editor import *\n# from mtcnn.mtcnn import MTCNN\n\ndef draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size = 50):\n    print(yaw,roll,pitch)\n    pitch = pitch * np.pi / 180\n    yaw = -(yaw * np.pi / 180)\n    roll = roll * np.pi / 180\n\n    if tdx != None and tdy != None:\n        tdx = tdx\n        tdy = tdy\n    else:\n        height, width = img.shape[:2]\n        tdx = width / 2\n        tdy = height / 2\n\n    # X-Axis pointing to right. drawn in red\n    x1 = size * (cos(yaw) * cos(roll)) + tdx\n    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n\n    # Y-Axis | drawn in green\n    #        v\n    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n\n    # Z-Axis (out of the screen) drawn in blue\n    x3 = size * (sin(yaw)) + tdx\n    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n\n    cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n    cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n    cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n\n    return img\n    \ndef draw_results_ssd(detected,input_img,faces,ad,img_size,img_w,img_h,model,time_detection,time_network,time_plot):\n    \n    # loop over the detections\n    if detected.shape[2]>0:\n        for i in range(0, detected.shape[2]):\n            # extract the confidence (i.e., probability) associated with the\n            # prediction\n            confidence = detected[0, 0, i, 2]\n\n            # filter out weak detections\n            if confidence > 0.5:\n                # compute the (x, y)-coordinates of the bounding box for\n                # the face and extract the face ROI\n                (h0, w0) = input_img.shape[:2]\n                box = detected[0, 0, i, 3:7] * np.array([w0, h0, w0, h0])\n                (startX, startY, endX, endY) = box.astype(""int"")\n                # print((startX, startY, endX, endY))\n                x1 = startX\n                y1 = startY\n                w = endX - startX\n                h = endY - startY\n                \n                x2 = x1+w\n                y2 = y1+h\n\n                xw1 = max(int(x1 - ad * w), 0)\n                yw1 = max(int(y1 - ad * h), 0)\n                xw2 = min(int(x2 + ad * w), img_w - 1)\n                yw2 = min(int(y2 + ad * h), img_h - 1)\n                \n                faces[i,:,:,:] = cv2.resize(input_img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n                faces[i,:,:,:] = cv2.normalize(faces[i,:,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)        \n                \n                face = np.expand_dims(faces[i,:,:,:], axis=0)\n                p_result = model.predict(face)\n                \n                face = face.squeeze()\n                img = draw_axis(input_img[yw1:yw2 + 1, xw1:xw2 + 1, :], p_result[0][0], p_result[0][1], p_result[0][2])\n                \n                input_img[yw1:yw2 + 1, xw1:xw2 + 1, :] = img\n                \n    cv2.imshow(""result"", input_img)\n    \n    return input_img #,time_network,time_plot\n\ndef main():\n    try:\n        os.mkdir(\'./img\')\n    except OSError:\n        pass\n\n    # face_cascade = cv2.CascadeClassifier(\'lbpcascade_frontalface_improved.xml\')\n    # detector = MTCNN()\n\n    # load model and weights\n    img_size = 64\n    stage_num = [3,3,3]\n    lambda_local = 1\n    lambda_d = 1\n    img_idx = 0\n    detected = \'\' #make this not local variable\n    time_detection = 0\n    time_network = 0\n    time_plot = 0\n    skip_frame = 1 # every 5 frame do 1 detection and network forward propagation\n    ad = 0.6\n\n    #Parameters\n    num_capsule = 3\n    dim_capsule = 16\n    routings = 2\n    stage_num = [3,3,3]\n    lambda_d = 1\n    num_classes = 3\n    image_size = 64\n    num_primcaps = 7*3\n    m_dim = 5\n    S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n\n    model1 = FSA_net_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n    model2 = FSA_net_Var_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n    \n    num_primcaps = 8*8*3\n    S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n\n    model3 = FSA_net_noS_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n    \n    print(\'Loading models ...\')\n\n    weight_file1 = \'../pre-trained/300W_LP_models/fsanet_capsule_3_16_2_21_5/fsanet_capsule_3_16_2_21_5.h5\'\n    model1.load_weights(weight_file1)\n    print(\'Finished loading model 1.\')\n    \n    weight_file2 = \'../pre-trained/300W_LP_models/fsanet_var_capsule_3_16_2_21_5/fsanet_var_capsule_3_16_2_21_5.h5\'\n    model2.load_weights(weight_file2)\n    print(\'Finished loading model 2.\')\n\n    weight_file3 = \'../pre-trained/300W_LP_models/fsanet_noS_capsule_3_16_2_192_5/fsanet_noS_capsule_3_16_2_192_5.h5\'\n    model3.load_weights(weight_file3)\n    print(\'Finished loading model 3.\')\n\n    inputs = Input(shape=(64,64,3))\n    x1 = model1(inputs) #1x1\n    x2 = model2(inputs) #var\n    x3 = model3(inputs) #w/o\n    avg_model = Average()([x1,x2,x3])\n    model = Model(inputs=inputs, outputs=avg_model)\n    \n\n\n    # load our serialized face detector from disk\n    print(""[INFO] loading face detector..."")\n    protoPath = os.path.sep.join([""face_detector"", ""deploy.prototxt""])\n    modelPath = os.path.sep.join([""face_detector"",\n        ""res10_300x300_ssd_iter_140000.caffemodel""])\n    net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n\n    # capture video\n    cap = cv2.VideoCapture(0)\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1024*1)\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 768*1)\n    \n\n\n    print(\'Start detecting pose ...\')\n    detected_pre = np.empty((1,1,1))\n\n    while True:\n        # get video frame\n        ret, input_img = cap.read()\n\n        img_idx = img_idx + 1\n        img_h, img_w, _ = np.shape(input_img)\n\n        \n        if img_idx==1 or img_idx%skip_frame == 0:\n            time_detection = 0\n            time_network = 0\n            time_plot = 0\n            \n            # detect faces using LBP detector\n            gray_img = cv2.cvtColor(input_img,cv2.COLOR_BGR2GRAY)\n            # detected = face_cascade.detectMultiScale(gray_img, 1.1)\n            # detected = detector.detect_faces(input_img)\n            # pass the blob through the network and obtain the detections and\n            # predictions\n            blob = cv2.dnn.blobFromImage(cv2.resize(input_img, (300, 300)), 1.0,\n                (300, 300), (104.0, 177.0, 123.0))\n            net.setInput(blob)\n            detected = net.forward()\n\n            if detected_pre.shape[2] > 0 and detected.shape[2] == 0:\n                detected = detected_pre\n\n            faces = np.empty((detected.shape[2], img_size, img_size, 3))\n\n            input_img = draw_results_ssd(detected,input_img,faces,ad,img_size,img_w,img_h,model,time_detection,time_network,time_plot)\n            cv2.imwrite(\'img/\'+str(img_idx)+\'.png\',input_img)\n            \n        else:\n            input_img = draw_results_ssd(detected,input_img,faces,ad,img_size,img_w,img_h,model,time_detection,time_network,time_plot)\n\n\n        if detected.shape[2] > detected_pre.shape[2] or img_idx%(skip_frame*3) == 0:\n            detected_pre = detected\n\n        key = cv2.waitKey(1)\n        \nif __name__ == \'__main__\':\n    main()\n'"
lib/FSANET_model.py,5,"b'import sys\nimport logging\nimport numpy as np\n\nimport tensorflow as tf\n\nfrom keras.models import Model\n\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import Layer\nfrom keras.layers import Reshape\nfrom keras.layers import Multiply\nfrom keras.layers import Flatten\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import SeparableConv2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import BatchNormalization\n\nfrom keras import backend as K\n\nfrom .capsulelayers import CapsuleLayer\nfrom .capsulelayers import MatMulLayer\n\nfrom .loupe_keras import NetVLAD\n\nfrom .utils import register_keras_custom_object\n\nsys.setrecursionlimit(2 ** 20)\nnp.random.seed(2 ** 10)\n\n# Custom layers\n# Note - Usage of Lambda layers prevent the convertion\n# and the optimizations by the underlying math engine (tensorflow in this case)\n\n@register_keras_custom_object\nclass SSRLayer(Layer):\n    def __init__(self, s1, s2, s3, lambda_d, **kwargs):\n        super(SSRLayer, self).__init__(**kwargs)\n        self.s1 = s1\n        self.s2 = s2\n        self.s3 = s3\n        self.lambda_d = lambda_d\n        self.trainable = False\n\n    def call(self, inputs):\n        x = inputs\n\n        a = x[0][:, :, 0] * 0\n        b = x[0][:, :, 0] * 0\n        c = x[0][:, :, 0] * 0\n\n        s1 = self.s1\n        s2 = self.s2\n        s3 = self.s3\n        lambda_d = self.lambda_d\n\n        di = s1 // 2\n        dj = s2 // 2\n        dk = s3 // 2\n\n        V = 99\n\n        for i in range(0, s1):\n            a = a + (i - di + x[6]) * x[0][:, :, i]\n        a = a / (s1 * (1 + lambda_d * x[3]))\n\n        for j in range(0, s2):\n            b = b + (j - dj + x[7]) * x[1][:, :, j]\n        b = b / (s1 * (1 + lambda_d * x[3])) / (s2 * (1 + lambda_d * x[4]))\n\n        for k in range(0, s3):\n            c = c + (k - dk + x[8]) * x[2][:, :, k]\n        c = c / (s1 * (1 + lambda_d * x[3])) / (s2 * (1 + lambda_d * x[4])) / (\n            s3 * (1 + lambda_d * x[5]))\n\n        pred = (a + b + c) * V\n\n        return pred\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], 3)\n\n    def get_config(self):\n        config = {\n            \'s1\': self.s1,\n            \'s2\': self.s2,\n            \'s3\': self.s3,\n            \'lambda_d\': self.lambda_d\n        }\n        base_config = super(SSRLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n@register_keras_custom_object\nclass FeatSliceLayer(Layer):\n    def __init__(self, start_index, end_index,  **kwargs):\n        super(FeatSliceLayer, self).__init__(**kwargs)\n        self.start_index = start_index\n        self.end_index = end_index\n        self.trainable = False\n\n    def call(self, inputs):    \n        return inputs[:,self.start_index:self.end_index]\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.end_index - self.start_index)\n\n    def get_config(self):\n        config = {\n            \'start_index\': self.start_index,\n            \'end_index\': self.end_index\n        }\n        base_config = super(FeatSliceLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n@register_keras_custom_object\nclass MomentsLayer(Layer):\n    def __init__(self, **kwargs):\n        super(MomentsLayer,self).__init__(**kwargs)\n        self.trainable = False\n\n    def call(self, inputs):        \n        _, var = tf.nn.moments(inputs,axes=-1)\n        return var\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])\n\n@register_keras_custom_object\nclass MatrixMultiplyLayer(Layer):\n    def __init__(self, **kwargs):\n        super(MatrixMultiplyLayer,self).__init__(**kwargs)\n        self.trainable = False\n\n    def call(self, inputs):                \n        x1, x2 = inputs\n        # TODO: add some asserts on the inputs\n        # it is expected the shape of inputs are \n        # arranged to be able to perform the matrix multiplication\n        return tf.matmul(x1,x2)\n\n    def compute_output_shape(self, input_shapes):        \n        return (input_shapes[0][0],input_shapes[0][1], input_shapes[1][-1])\n\n@register_keras_custom_object\nclass MatrixNormLayer(Layer):\n    def __init__(self, tile_count,  **kwargs):\n        super(MatrixNormLayer,self).__init__(**kwargs)\n        self.trainable = False\n        self.tile_count = tile_count\n\n    def call(self, input):                \n        sum = K.sum(input,axis=-1,keepdims=True)        \n        tiled = K.tile(sum,(1,1,self.tile_count))        \n        return tiled\n\n    def compute_output_shape(self, input_shape):        \n        return (input_shape[0], input_shape[1], self.tile_count)\n\n    def get_config(self):\n        config = {\n            \'tile_count\': self.tile_count\n        }\n        base_config = super(MatrixNormLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n@register_keras_custom_object\nclass PrimCapsLayer(Layer):\n    def __init__(self, **kwargs):\n        super(PrimCapsLayer,self).__init__(**kwargs)\n        self.trainable = False        \n\n    def call(self, inputs):                \n        x1, x2, norm = inputs\n        return tf.matmul(x1,x2) / norm\n\n    def compute_output_shape(self, input_shapes):                \n        return input_shapes[-1]\n\n@register_keras_custom_object\nclass AggregatedFeatureExtractionLayer(Layer):\n    def __init__(self, num_capsule,  **kwargs):\n        super(AggregatedFeatureExtractionLayer,self).__init__(**kwargs)\n        self.trainable = False\n        self.num_capsule = num_capsule\n\n    def call(self, input):                \n        s1_a = 0\n        s1_b = self.num_capsule//3\n        feat_s1_div = input[:,s1_a:s1_b,:]\n        s2_a = self.num_capsule//3\n        s2_b = 2*self.num_capsule//3\n        feat_s2_div = input[:,s2_a:s2_b,:]\n        s3_a = 2*self.num_capsule//3\n        s3_b = self.num_capsule\n        feat_s3_div = input[:,s3_a:s3_b,:]\n\n        return [feat_s1_div, feat_s2_div, feat_s3_div]\n\n    def compute_output_shape(self, input_shape):        \n        last_dim = input_shape[-1]\n        partition = self.num_capsule//3\n        return [(input_shape[0], partition, last_dim), (input_shape[0], partition, last_dim), (input_shape[0], partition, last_dim)]\n\n    def get_config(self):\n        config = {\n            \'num_capsule\': self.num_capsule\n        }\n        base_config = super(AggregatedFeatureExtractionLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass BaseFSANet(object):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        self._channel_axis = 3 if K.image_data_format() == \'channels_last\' else 1\n\n        if self._channel_axis == 1:\n            logging.debug(""image_dim_ordering = \'th\'"")            \n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._input_shape = (image_size, image_size, 3)           \n\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n        self.map_xy_size = int(8*image_size/64)\n\n        self.is_fc_model = False\n        self.is_noS_model = False\n        self.is_varS_model = False\n\n    def _convBlock(self, x, num_filters, activation, kernel_size=(3,3)):\n        x = SeparableConv2D(num_filters,kernel_size,padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(activation)(x)\n        return x\n\n    def ssr_G_model_build(self, img_inputs):\n        #-------------------------------------------------------------------------------------------------------------------------        \n        x = self._convBlock(img_inputs, num_filters=16, activation=\'relu\')\n        x_layer1 = AveragePooling2D((2,2))(x)\n        x = self._convBlock(x_layer1, num_filters=32, activation=\'relu\')\n        x = self._convBlock(x, num_filters=32, activation=\'relu\')        \n        x_layer2 = AveragePooling2D((2,2))(x)\n        x = self._convBlock(x_layer2, num_filters=64, activation=\'relu\')\n        x = self._convBlock(x, num_filters=64, activation=\'relu\')        \n        x_layer3 = AveragePooling2D((2,2))(x)\n        x = self._convBlock(x_layer3, num_filters=128, activation=\'relu\')\n        x_layer4 = self._convBlock(x, num_filters=128, activation=\'relu\')                        \n        #-------------------------------------------------------------------------------------------------------------------------\n        s = self._convBlock(img_inputs, num_filters=16, activation=\'tanh\')\n        s_layer1 = MaxPooling2D((2,2))(s)\n        s = self._convBlock(s_layer1, num_filters=32, activation=\'tanh\')\n        s = self._convBlock(s, num_filters=32, activation=\'tanh\')        \n        s_layer2 = MaxPooling2D((2,2))(s)\n        s = self._convBlock(s_layer2, num_filters=64, activation=\'tanh\')\n        s = self._convBlock(s, num_filters=64, activation=\'tanh\')        \n        s_layer3 = MaxPooling2D((2,2))(s)\n        s = self._convBlock(s_layer3, num_filters=128, activation=\'tanh\')\n        s_layer4 = self._convBlock(s, num_filters=128, activation=\'tanh\')                                \n        #-------------------------------------------------------------------------------------------------------------------------        \n        s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n        x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n\n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n        x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n\n        feat_s2_pre = Multiply()([s_layer3,x_layer3])\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n        x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n\n        feat_s3_pre = Multiply()([s_layer2,x_layer2])\n        #-------------------------------------------------------------------------------------------------------------------------\n        \n        # Spatial Pyramid Pooling\n        #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n        #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n        #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n        # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n        # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n        feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n    \n        return Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n\n    def ssr_F_model_build(self, feat_dim, name_F):\n        input_s1_pre = Input((feat_dim,))\n        input_s2_pre = Input((feat_dim,))\n        input_s3_pre = Input((feat_dim,))\n\n        def _process_input(stage_index, stage_num, num_classes, input_s_pre):            \n            feat_delta_s = FeatSliceLayer(0,4)(input_s_pre)            \n            delta_s = Dense(num_classes,activation=\'tanh\',name=f\'delta_s{stage_index}\')(feat_delta_s)            \n            \n            feat_local_s = FeatSliceLayer(4,8)(input_s_pre)            \n            local_s = Dense(units=num_classes, activation=\'tanh\', name=f\'local_delta_stage{stage_index}\')(feat_local_s)\n            \n            feat_pred_s = FeatSliceLayer(8,16)(input_s_pre)            \n            feat_pred_s = Dense(stage_num*num_classes,activation=\'relu\')(feat_pred_s) \n            pred_s = Reshape((num_classes,stage_num))(feat_pred_s)\n\n            return delta_s, local_s, pred_s\n\n        delta_s1, local_s1, pred_s1 = _process_input(1, self.stage_num[0], self.num_classes, input_s1_pre)\n        delta_s2, local_s2, pred_s2 = _process_input(2, self.stage_num[1], self.num_classes, input_s2_pre)\n        delta_s3, local_s3, pred_s3 = _process_input(3, self.stage_num[2], self.num_classes, input_s3_pre)        \n    \n        return Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n\n    def ssr_FC_model_build(self, feat_dim, name_F):\n        input_s1_pre = Input((feat_dim,))\n        input_s2_pre = Input((feat_dim,))\n        input_s3_pre = Input((feat_dim,))\n\n        def _process_input(stage_index, stage_num, num_classes, input_s_pre):\n            feat_delta_s = Dense(2*num_classes,activation=\'tanh\')(input_s_pre)\n            delta_s = Dense(num_classes,activation=\'tanh\',name=f\'delta_s{stage_index}\')(feat_delta_s)\n\n            feat_local_s = Dense(2*num_classes,activation=\'tanh\')(input_s_pre)\n            local_s = Dense(units=num_classes, activation=\'tanh\', name=f\'local_delta_stage{stage_index}\')(feat_local_s)\n\n            feat_pred_s = Dense(stage_num*num_classes,activation=\'relu\')(input_s_pre) \n            pred_s = Reshape((num_classes,stage_num))(feat_pred_s)     \n\n            return delta_s, local_s, pred_s   \n\n        delta_s1, local_s1, pred_s1 = _process_input(1, self.stage_num[0], self.num_classes, input_s1_pre)\n        delta_s2, local_s2, pred_s2 = _process_input(2, self.stage_num[1], self.num_classes, input_s2_pre)\n        delta_s3, local_s3, pred_s3 = _process_input(3, self.stage_num[2], self.num_classes, input_s3_pre)        \n           \n        return Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n\n    def ssr_feat_S_model_build(self, m_dim):\n        input_preS = Input((self.map_xy_size,self.map_xy_size,64))        \n\n\n        if self.is_varS_model:\n            feat_preS = MomentsLayer()(input_preS)\n        else:\n            feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)        \n\n        feat_preS = Reshape((-1,))(feat_preS)        \n\n        SR_matrix = Dense(m_dim*(self.map_xy_size*self.map_xy_size*3),activation=\'sigmoid\')(feat_preS)\n        SR_matrix = Reshape((m_dim,(self.map_xy_size*self.map_xy_size*3)))(SR_matrix)\n        \n        return Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n\n    def ssr_S_model_build(self, num_primcaps, m_dim):\n        input_s1_preS = Input((self.map_xy_size,self.map_xy_size,64))\n        input_s2_preS = Input((self.map_xy_size,self.map_xy_size,64))\n        input_s3_preS = Input((self.map_xy_size,self.map_xy_size,64))\n\n        feat_S_model = self.ssr_feat_S_model_build(m_dim)\n\n        SR_matrix_s1,feat_s1_preS = feat_S_model(input_s1_preS)\n        SR_matrix_s2,feat_s2_preS = feat_S_model(input_s2_preS)\n        SR_matrix_s3,feat_s3_preS = feat_S_model(input_s3_preS)\n        \n        feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n        SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n        SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)       \n\n        S_matrix_s1 = MatrixMultiplyLayer(name=""S_matrix_s1"")([SL_matrix,SR_matrix_s1])\n        S_matrix_s2 = MatrixMultiplyLayer(name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n        S_matrix_s3 = MatrixMultiplyLayer(name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])        \n\n        # Very important!!! Without this training won\'t converge.        \n        # norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n        norm_S_s1 = MatrixNormLayer(tile_count=64)(S_matrix_s1)\n        norm_S_s2 = MatrixNormLayer(tile_count=64)(S_matrix_s2)\n        norm_S_s3 = MatrixNormLayer(tile_count=64)(S_matrix_s3)        \n\n        feat_s1_pre = Reshape((self.map_xy_size*self.map_xy_size,64))(input_s1_preS)\n        feat_s2_pre = Reshape((self.map_xy_size*self.map_xy_size,64))(input_s2_preS)\n        feat_s3_pre = Reshape((self.map_xy_size*self.map_xy_size,64))(input_s3_preS)\n\n        feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n        \n        # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n        # https://github.com/keras-team/keras/issues/9779\n        # Make sure \'tf.matmul\' is used\n        # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])        \n        primcaps_s1 = PrimCapsLayer()([S_matrix_s1,feat_pre_concat, norm_S_s1])\n        primcaps_s2 = PrimCapsLayer()([S_matrix_s2,feat_pre_concat, norm_S_s2])\n        primcaps_s3 = PrimCapsLayer()([S_matrix_s3,feat_pre_concat, norm_S_s3])        \n        \n        primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n        return Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n\n    def ssr_noS_model_build(self, **kwargs):        \n\n        input_s1_preS = Input((self.map_xy_size,self.map_xy_size,64))\n        input_s2_preS = Input((self.map_xy_size,self.map_xy_size,64))\n        input_s3_preS = Input((self.map_xy_size,self.map_xy_size,64))\n\n        primcaps_s1 = Reshape((self.map_xy_size*self.map_xy_size,64))(input_s1_preS)\n        primcaps_s2 = Reshape((self.map_xy_size*self.map_xy_size,64))(input_s2_preS)\n        primcaps_s3 = Reshape((self.map_xy_size*self.map_xy_size,64))(input_s3_preS)\n\n        primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n        return Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n        img_inputs = Input(self._input_shape)        \n\n        # Build various models\n        ssr_G_model = self.ssr_G_model_build(img_inputs)        \n        \n        if self.is_noS_model:\n            ssr_S_model = self.ssr_noS_model_build()           \n        else:\n            ssr_S_model = self.ssr_S_model_build(num_primcaps=self.num_primcaps,m_dim=self.m_dim)           \n\n        ssr_aggregation_model = self.ssr_aggregation_model_build((self.num_primcaps,64))\n\n        if self.is_fc_model:\n            ssr_F_Cap_model = self.ssr_FC_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        else:    \n            ssr_F_Cap_model = self.ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')        \n\n        # Wire them up\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_aggregation_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n\n        pred_pose = SSRLayer(s1=self.stage_num[0], s2=self.stage_num[1], s3=self.stage_num[2], lambda_d=self.lambda_d, name=""pred_pose"")(ssr_F_Cap_list)        \n        \n        return Model(inputs=img_inputs, outputs=pred_pose)\n\n# Capsule FSANetworks\n\nclass BaseCapsuleFSANet(BaseFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(BaseCapsuleFSANet, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)         \n\n    def ssr_aggregation_model_build(self, shape_primcaps):\n        input_primcaps = Input(shape_primcaps)        \n        capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, routings=self.routings, name=\'caps\')(input_primcaps)        \n\n        feat_s1_div, feat_s2_div, feat_s3_div = AggregatedFeatureExtractionLayer(num_capsule=self.num_capsule)(capsule)\n\n        feat_s1_div = Reshape((-1,))(feat_s1_div)\n        feat_s2_div = Reshape((-1,))(feat_s2_div)\n        feat_s3_div = Reshape((-1,))(feat_s3_div)        \n        \n        return Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')     \n    \n\nclass FSA_net_Capsule(BaseCapsuleFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Capsule, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)       \n        self.is_varS_model = False    \n \nclass FSA_net_Var_Capsule(BaseCapsuleFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Var_Capsule, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)   \n        self.is_varS_model = True    \n        \nclass FSA_net_noS_Capsule(BaseCapsuleFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_noS_Capsule, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)   \n        self.is_noS_model = True    \n    \nclass FSA_net_Capsule_FC(FSA_net_Capsule):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Capsule_FC, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)  \n        self.is_fc_model = True\n\nclass FSA_net_Var_Capsule_FC(FSA_net_Var_Capsule):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Var_Capsule_FC, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_fc_model = True\n        \nclass FSA_net_noS_Capsule_FC(FSA_net_noS_Capsule):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_noS_Capsule_FC, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_fc_model = True\n   \n# NetVLAD models\n\nclass BaseNetVLADFSANet(BaseFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(BaseNetVLADFSANet, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)         \n\n    def ssr_aggregation_model_build(self, shape_primcaps):\n        input_primcaps = Input(shape_primcaps)\n        \n        agg_feat = NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n        agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n        feat_s1_div, feat_s2_div, feat_s3_div = AggregatedFeatureExtractionLayer(num_capsule=self.num_capsule)(agg_feat)        \n\n        feat_s1_div = Reshape((-1,))(feat_s1_div)\n        feat_s2_div = Reshape((-1,))(feat_s2_div)\n        feat_s3_div = Reshape((-1,))(feat_s3_div)\n        \n        return Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')                \n\nclass FSA_net_NetVLAD(BaseNetVLADFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_NetVLAD, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_varS_model = False    \n    \nclass FSA_net_Var_NetVLAD(BaseNetVLADFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Var_NetVLAD, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_varS_model = True    \n\nclass FSA_net_noS_NetVLAD(BaseNetVLADFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_noS_NetVLAD, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_noS_model = True\n\nclass FSA_net_NetVLAD_FC(FSA_net_NetVLAD):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_NetVLAD_FC, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_fc_model = True\n\nclass FSA_net_Var_NetVLAD_FC(FSA_net_Var_NetVLAD):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Var_NetVLAD_FC, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_fc_model = True\n\nclass FSA_net_noS_NetVLAD_FC(FSA_net_noS_NetVLAD):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_noS_NetVLAD_FC, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_fc_model = True\n\n# // Metric models\n\nclass BaseMetricFSANet(BaseFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(BaseMetricFSANet, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set) \n        \n    def ssr_aggregation_model_build(self, shape_primcaps):\n        input_primcaps = Input(shape_primcaps)\n\n        metric_feat = MatMulLayer(16,type=1)(input_primcaps)\n        metric_feat = MatMulLayer(3,type=2)(metric_feat)\n\n        feat_s1_div, feat_s2_div, feat_s3_div = AggregatedFeatureExtractionLayer(num_capsule=self.num_capsule)(metric_feat)        \n\n        feat_s1_div = Reshape((-1,))(feat_s1_div)\n        feat_s2_div = Reshape((-1,))(feat_s2_div)\n        feat_s3_div = Reshape((-1,))(feat_s3_div)\n        \n        return Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Metric_model\')     \n    \nclass FSA_net_Metric(BaseMetricFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Metric, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_varS_model = False    \n\nclass FSA_net_Var_Metric(BaseMetricFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_Var_Metric, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_varS_model = True\n        \nclass FSA_net_noS_Metric(BaseMetricFSANet):\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        super(FSA_net_noS_Metric, self).__init__(image_size,num_classes,stage_num,lambda_d, S_set)\n        self.is_noS_model = True\n   \n'"
lib/SSRNET_model.py,0,"b'import logging\nimport sys\nimport numpy as np\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.layers.convolutional import Conv2D, AveragePooling2D, MaxPooling2D, SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.optimizers import SGD,Adam\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.utils import plot_model\nfrom keras.engine.topology import Layer\nfrom keras import activations, initializers, regularizers, constraints\nimport tensorflow as tf\n\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.layers.recurrent import *\nfrom keras.layers.wrappers import *\n\nsys.setrecursionlimit(2 ** 20)\nnp.random.seed(2 ** 10)\n\nclass SSR_net:\n    def __init__(self, image_size,stage_num,lambda_local,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n\n        self.stage_num = stage_num\n        self.lambda_local = lambda_local\n        self.lambda_d = lambda_d\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n\n        inputs = Input(shape=self._input_shape)\n\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = Conv2D(32,(3,3))(inputs)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer1)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer2)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer3)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = Conv2D(16,(3,3))(inputs)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer1)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer2)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer3)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        \n\n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(10,(1,1),activation=\'relu\')(s)\n        s_layer4 = Flatten()(s_layer4)\n        s_layer4_mix = Dropout(0.2)(s_layer4)\n        s_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(s_layer4_mix)\n        \n        x_layer4 = Conv2D(10,(1,1),activation=\'relu\')(x)\n        x_layer4 = Flatten()(x_layer4)\n        x_layer4_mix = Dropout(0.2)(x_layer4)\n        x_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(x_layer4_mix)\n        \n        feat_a_s1_pre = Multiply()([s_layer4,x_layer4])\n        delta_s1 = Dense(1,activation=\'tanh\',name=\'delta_s1\')(feat_a_s1_pre)\n        \n        feat_a_s1 = Multiply()([s_layer4_mix,x_layer4_mix])\n        feat_a_s1 = Dense(2*self.stage_num[0],activation=\'relu\')(feat_a_s1)\n        pred_a_s1 = Dense(units=self.stage_num[0], activation=""relu"",name=\'pred_age_stage1\')(feat_a_s1)\n        #feat_local_s1 = Lambda(lambda x: x/10)(feat_a_s1)\n        #feat_a_s1_local = Dropout(0.2)(pred_a_s1)\n        local_s1 = Dense(units=self.stage_num[0], activation=\'tanh\', name=\'local_delta_stage1\')(feat_a_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(10,(1,1),activation=\'relu\')(s_layer2)\n        s_layer2 = MaxPooling2D(4,4)(s_layer2)\n        s_layer2 = Flatten()(s_layer2)\n        s_layer2_mix = Dropout(0.2)(s_layer2)\n        s_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(s_layer2_mix)\n        \n        x_layer2 = Conv2D(10,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D(4,4)(x_layer2)\n        x_layer2 = Flatten()(x_layer2)\n        x_layer2_mix = Dropout(0.2)(x_layer2)\n        x_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(x_layer2_mix)\n        \n        feat_a_s2_pre = Multiply()([s_layer2,x_layer2])\n        delta_s2 = Dense(1,activation=\'tanh\',name=\'delta_s2\')(feat_a_s2_pre)\n        \n        feat_a_s2 = Multiply()([s_layer2_mix,x_layer2_mix])\n        feat_a_s2 = Dense(2*self.stage_num[1],activation=\'relu\')(feat_a_s2)\n        pred_a_s2 = Dense(units=self.stage_num[1], activation=""relu"",name=\'pred_age_stage2\')(feat_a_s2)\n        #feat_local_s2 = Lambda(lambda x: x/10)(feat_a_s2)\n        #feat_a_s2_local = Dropout(0.2)(pred_a_s2)\n        local_s2 = Dense(units=self.stage_num[1], activation=\'tanh\', name=\'local_delta_stage2\')(feat_a_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer1 = Conv2D(10,(1,1),activation=\'relu\')(s_layer1)\n        s_layer1 = MaxPooling2D(8,8)(s_layer1)\n        s_layer1 = Flatten()(s_layer1)\n        s_layer1_mix = Dropout(0.2)(s_layer1)\n        s_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(s_layer1_mix)\n        \n        x_layer1 = Conv2D(10,(1,1),activation=\'relu\')(x_layer1)\n        x_layer1 = AveragePooling2D(8,8)(x_layer1)\n        x_layer1 = Flatten()(x_layer1)\n        x_layer1_mix = Dropout(0.2)(x_layer1)\n        x_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(x_layer1_mix)\n\n        feat_a_s3_pre = Multiply()([s_layer1,x_layer1])\n        delta_s3 = Dense(1,activation=\'tanh\',name=\'delta_s3\')(feat_a_s3_pre)\n        \n        feat_a_s3 = Multiply()([s_layer1_mix,x_layer1_mix])\n        feat_a_s3 = Dense(2*self.stage_num[2],activation=\'relu\')(feat_a_s3)\n        pred_a_s3 = Dense(units=self.stage_num[2], activation=""relu"",name=\'pred_age_stage3\')(feat_a_s3)\n        #feat_local_s3 = Lambda(lambda x: x/10)(feat_a_s3)\n        #feat_a_s3_local = Dropout(0.2)(pred_a_s3)\n        local_s3 = Dense(units=self.stage_num[2], activation=\'tanh\', name=\'local_delta_stage3\')(feat_a_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n        \n        def merge_age(x,s1,s2,s3,lambda_local,lambda_d):\n            a = x[0][:,0]*0\n            b = x[0][:,0]*0\n            c = x[0][:,0]*0\n            A = s1*s2*s3\n            V = 101\n\n            for i in range(0,s1):\n                a = a+(i+lambda_local*x[6][:,i])*x[0][:,i]\n            a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j+lambda_local*x[7][:,j])*x[1][:,j]\n            b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k+lambda_local*x[8][:,k])*x[2][:,k]\n            c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n\n            age = (a+b+c)*V\n            return age\n        \n        pred_a = Lambda(merge_age,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_local\':self.lambda_local,\'lambda_d\':self.lambda_d},name=\'pred_a\')([pred_a_s1,pred_a_s2,pred_a_s3,delta_s1,delta_s2,delta_s3, local_s1, local_s2, local_s3])\n\n        model = Model(inputs=inputs, outputs=pred_a)\n\n        return model\nclass SSR_net_general:\n    def __init__(self, image_size,stage_num,lambda_local,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n\n        self.stage_num = stage_num\n        self.lambda_local = lambda_local\n        self.lambda_d = lambda_d\n\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n\n        inputs = Input(shape=self._input_shape)\n\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = Conv2D(32,(3,3))(inputs)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer1)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer2)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer3)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = Conv2D(16,(3,3))(inputs)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer1)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer2)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer3)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        \n\n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(10,(1,1),activation=\'relu\')(s)\n        s_layer4 = Flatten()(s_layer4)\n        s_layer4_mix = Dropout(0.2)(s_layer4)\n        s_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(s_layer4_mix)\n        \n        x_layer4 = Conv2D(10,(1,1),activation=\'relu\')(x)\n        x_layer4 = Flatten()(x_layer4)\n        x_layer4_mix = Dropout(0.2)(x_layer4)\n        x_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(x_layer4_mix)\n        \n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        delta_s1 = Dense(1,activation=\'tanh\',name=\'delta_s1\')(feat_s1_pre)\n        \n        feat_s1 = Multiply()([s_layer4_mix,x_layer4_mix])\n        feat_s1 = Dense(2*self.stage_num[0],activation=\'relu\')(feat_s1)\n        pred_s1 = Dense(units=self.stage_num[0], activation=""relu"",name=\'pred_stage1\')(feat_s1)\n        local_s1 = Dense(units=self.stage_num[0], activation=\'tanh\', name=\'local_delta_stage1\')(feat_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(10,(1,1),activation=\'relu\')(s_layer2)\n        s_layer2 = MaxPooling2D(4,4)(s_layer2)\n        s_layer2 = Flatten()(s_layer2)\n        s_layer2_mix = Dropout(0.2)(s_layer2)\n        s_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(s_layer2_mix)\n        \n        x_layer2 = Conv2D(10,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D(4,4)(x_layer2)\n        x_layer2 = Flatten()(x_layer2)\n        x_layer2_mix = Dropout(0.2)(x_layer2)\n        x_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(x_layer2_mix)\n        \n        feat_s2_pre = Multiply()([s_layer2,x_layer2])\n        delta_s2 = Dense(1,activation=\'tanh\',name=\'delta_s2\')(feat_s2_pre)\n        \n        feat_s2 = Multiply()([s_layer2_mix,x_layer2_mix])\n        feat_s2 = Dense(2*self.stage_num[1],activation=\'relu\')(feat_s2)\n        pred_s2 = Dense(units=self.stage_num[1], activation=""relu"",name=\'pred_stage2\')(feat_s2)\n        local_s2 = Dense(units=self.stage_num[1], activation=\'tanh\', name=\'local_delta_stage2\')(feat_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer1 = Conv2D(10,(1,1),activation=\'relu\')(s_layer1)\n        s_layer1 = MaxPooling2D(8,8)(s_layer1)\n        s_layer1 = Flatten()(s_layer1)\n        s_layer1_mix = Dropout(0.2)(s_layer1)\n        s_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(s_layer1_mix)\n        \n        x_layer1 = Conv2D(10,(1,1),activation=\'relu\')(x_layer1)\n        x_layer1 = AveragePooling2D(8,8)(x_layer1)\n        x_layer1 = Flatten()(x_layer1)\n        x_layer1_mix = Dropout(0.2)(x_layer1)\n        x_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(x_layer1_mix)\n\n        feat_s3_pre = Multiply()([s_layer1,x_layer1])\n        delta_s3 = Dense(1,activation=\'tanh\',name=\'delta_s3\')(feat_s3_pre)\n        \n        feat_s3 = Multiply()([s_layer1_mix,x_layer1_mix])\n        feat_s3 = Dense(2*self.stage_num[2],activation=\'relu\')(feat_s3)\n        pred_s3 = Dense(units=self.stage_num[2], activation=""relu"",name=\'pred_stage3\')(feat_s3)\n        local_s3 = Dense(units=self.stage_num[2], activation=\'tanh\', name=\'local_delta_stage3\')(feat_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n        \n        def SSR_module(x,s1,s2,s3,lambda_local,lambda_d):\n            a = x[0][:,0]*0\n            b = x[0][:,0]*0\n            c = x[0][:,0]*0\n            V = 1\n\n            for i in range(0,s1):\n                a = a+(i+lambda_local*x[6][:,i])*x[0][:,i]\n            a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j+lambda_local*x[7][:,j])*x[1][:,j]\n            b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k+lambda_local*x[8][:,k])*x[2][:,k]\n            c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n\n            out = (a+b+c)*V\n            return out\n        \n        pred = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_local\':self.lambda_local,\'lambda_d\':self.lambda_d},name=\'pred\')([pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3, local_s1, local_s2, local_s3])\n\n        model = Model(inputs=inputs, outputs=pred)\n\n        return model\nclass SSR_net_MT:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D((2,2))(x)\n        x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D((2,2))(x)\n        x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D((2,2))(x)\n        x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x_layer4 = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D((2,2))(s)\n        s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D((2,2))(s)\n        s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D((2,2))(s)\n        s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n        s = BatchNormalization(axis=-1)(s)\n        s_layer4 = Activation(\'tanh\')(s)\n\n\n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n        s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n        x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n        x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        feat_s1_pre = Flatten()(feat_s1_pre)\n        feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n        feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n        feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_s1_pre) \n        pred_a_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n        s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n        x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n        x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n        feat_s2_pre = Multiply()([s_layer3,x_layer3])\n        feat_s2_pre  = Flatten()(feat_s2_pre)\n        feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n        feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n        feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_s2_pre) \n        pred_a_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n        s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n        x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n        feat_s3_pre = Multiply()([s_layer2,x_layer2])\n        feat_s3_pre  = Flatten()(feat_s3_pre)\n        feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n        feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n        feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_s3_pre) \n        pred_a_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            # a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            # b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            # c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')([pred_a_s1,pred_a_s2,pred_a_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3])\n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n        return model\nclass SSR_net_ori_MT:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = Conv2D(32,(3,3),padding=\'same\')(img_inputs)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3),padding=\'same\')(x_layer1)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3),padding=\'same\')(x_layer2)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3),padding=\'same\')(x_layer3)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x_layer4 = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = Conv2D(16,(3,3),padding=\'same\')(img_inputs)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3),padding=\'same\')(s_layer1)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3),padding=\'same\')(s_layer2)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3),padding=\'same\')(s_layer3)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s_layer4 = Activation(\'tanh\')(s)\n        \n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n        s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n        x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n        x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        feat_s1_pre = Flatten()(feat_s1_pre)\n        feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n        feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n        feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_s1_pre) \n        pred_a_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n        s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n        x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n        x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n        feat_s2_pre = Multiply()([s_layer3,x_layer3])\n        feat_s2_pre  = Flatten()(feat_s2_pre)\n        feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n        feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n        feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_s2_pre) \n        pred_a_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n        s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n        x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n        feat_s3_pre = Multiply()([s_layer2,x_layer2])\n        feat_s3_pre  = Flatten()(feat_s3_pre)\n        feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n        feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n        feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_s3_pre) \n        pred_a_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            # a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            # b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            # c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')([pred_a_s1,pred_a_s2,pred_a_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3])\n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n        return model'"
lib/SpatialPyramidPooling.py,0,"b'from keras.engine.topology import Layer\nimport keras.backend as K\n\n\nclass SpatialPyramidPooling(Layer):\n    """"""Spatial pyramid pooling layer for 2D inputs.\n    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n    K. He, X. Zhang, S. Ren, J. Sun\n    # Arguments\n        pool_list: list of int\n            List of pooling regions to use. The length of the list is the number of pooling regions,\n            each int in the list is the number of regions in that pool. For example [1,2,4] would be 3\n            regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map\n    # Input shape\n        4D tensor with shape:\n        `(samples, channels, rows, cols)` if dim_ordering=\'th\'\n        or 4D tensor with shape:\n        `(samples, rows, cols, channels)` if dim_ordering=\'tf\'.\n    # Output shape\n        2D tensor with shape:\n        `(samples, channels * sum([i * i for i in pool_list])`\n    """"""\n\n    def __init__(self, pool_list, pool_type, **kwargs):\n\n        self.dim_ordering = K.image_dim_ordering()\n        assert self.dim_ordering in {\'tf\', \'th\'}, \'dim_ordering must be in {tf, th}\'\n\n        self.pool_list = pool_list\n        self.pool_type = pool_type\n        self.num_outputs_per_channel = sum([i * i for i in pool_list])\n\n        super(SpatialPyramidPooling, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        if self.dim_ordering == \'th\':\n            self.nb_channels = input_shape[1]\n        elif self.dim_ordering == \'tf\':\n            self.nb_channels = input_shape[3]\n\n    def get_config(self):\n        config = {\'pool_list\': self.pool_list}\n        base_config = super(SpatialPyramidPooling, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def call(self, x, mask=None):\n\n        input_shape = K.shape(x)\n\n        if self.dim_ordering == \'th\':\n            num_rows = input_shape[2]\n            num_cols = input_shape[3]\n        elif self.dim_ordering == \'tf\':\n            num_rows = input_shape[1]\n            num_cols = input_shape[2]\n\n        row_length = [K.cast(num_rows, \'float32\') / i for i in self.pool_list]\n        col_length = [K.cast(num_cols, \'float32\') / i for i in self.pool_list]\n\n        outputs = []\n\n        if self.dim_ordering == \'th\':\n            for pool_num, num_pool_regions in enumerate(self.pool_list):\n                for jy in range(num_pool_regions):\n                    for ix in range(num_pool_regions):\n                        x1 = ix * col_length[pool_num]\n                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n                        y1 = jy * row_length[pool_num]\n                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n\n                        x1 = K.cast(K.round(x1), \'int32\')\n                        x2 = K.cast(K.round(x2), \'int32\')\n                        y1 = K.cast(K.round(y1), \'int32\')\n                        y2 = K.cast(K.round(y2), \'int32\')\n                        new_shape = [input_shape[0], input_shape[1],\n                                     y2 - y1, x2 - x1]\n                        x_crop = x[:, :, y1:y2, x1:x2]\n                        xm = K.reshape(x_crop, new_shape)\n                        pooled_val = K.max(xm, axis=(2, 3))\n                        outputs.append(pooled_val)\n\n        elif self.dim_ordering == \'tf\':\n            for pool_num, num_pool_regions in enumerate(self.pool_list):\n                for jy in range(num_pool_regions):\n                    for ix in range(num_pool_regions):\n                        x1 = ix * col_length[pool_num]\n                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n                        y1 = jy * row_length[pool_num]\n                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n\n                        x1 = K.cast(K.round(x1), \'int32\')\n                        x2 = K.cast(K.round(x2), \'int32\')\n                        y1 = K.cast(K.round(y1), \'int32\')\n                        y2 = K.cast(K.round(y2), \'int32\')\n\n                        new_shape = [input_shape[0], y2 - y1,\n                                     x2 - x1, input_shape[3]]\n\n                        x_crop = x[:, y1:y2, x1:x2, :]\n                        xm = K.reshape(x_crop, new_shape)\n                        if self.pool_type == \'max\':\n                            pooled_val = K.max(xm, axis=(1, 2))\n                        elif self.pool_type == \'average\':\n                            pooled_val = K.mean(xm, axis=(1, 2))\n                        \n                        pooled_val = K.expand_dims(pooled_val,axis=-1)\n                        \n                        outputs.append(pooled_val)\n        \n        if self.dim_ordering == \'th\':\n            outputs = K.concatenate(outputs)\n        elif self.dim_ordering == \'tf\':\n            #outputs = K.concatenate(outputs,axis = 1)\n            outputs = K.concatenate(outputs,-1)\n            \n            #outputs = K.reshape(outputs,(len(self.pool_list),self.num_outputs_per_channel,input_shape[0],input_shape[1]))\n            #outputs = K.permute_dimensions(outputs,(3,1,0,2))\n            #outputs = K.reshape(outputs,(input_shape[0], self.num_outputs_per_channel * self.nb_channels))\n        \n        return outputs\n\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.nb_channels, self.num_outputs_per_channel)\n'"
lib/__init__.py,0,b'from .FSANET_model import *\n'
lib/capsulelayers.py,10,"b'""""""\nOriginal code taken from Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\nand adjusted for the needs of this project.\n\nSome key layers used for constructing a Capsule Network. These layers can used to construct CapsNet on other dataset, \nnot just on MNIST.\n\n*NOTE*: some functions can be implemented in multiple ways, I keep all of them. You can try them for yourself just by\nuncommenting them and commenting their counterparts.\n\nAuthor: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n""""""\n\nimport sys\nimport tensorflow as tf\n\nimport keras.backend as K\nfrom keras import initializers\nfrom keras.layers import Layer\n\nfrom .utils import register_keras_custom_object\n\n\ndef batch_dot(x, y, axes=None):\n    """"""Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`\'s shape\n        (less the dimension that was summed over) and `y`\'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let `x`\'s shape be `(100, 20)` and `y`\'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`\'s shape and `y`\'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n    """"""\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = K.ndim(x)\n    y_ndim = K.ndim(y)\n    if axes is None:\n        # behaves like tf.batch_matmul as default\n        axes = [x_ndim - 1, y_ndim - 2]\n    # if K.any([isinstance(a, (list, tuple)) for a in axes]):\n    #     raise ValueError(\'Multiple target dimensions are not supported. \' +\n    #                      \'Expected: None, int, (int, int), \' +\n    #                      \'Provided: \' + str(axes))\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if K.ndim(x) == 2 and K.ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(\n                tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == K.ndim(x) - 1 else True\n            adj_y = True if axes[1] == K.ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if K.ndim(out) == 1:\n        out = K.expand_dims(out, 1)\n    return out\n\n\ndef squash(vectors, axis=-1):\n    """"""\n    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n    :param vectors: some vectors to be squashed, N-dim tensor\n    :param axis: the axis to squash\n    :return: a Tensor with same shape as input vectors\n    """"""\n    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n    scale = s_squared_norm / (1 + s_squared_norm) / \\\n        K.sqrt(s_squared_norm + K.epsilon())\n    return scale * vectors\n\n\n@register_keras_custom_object\nclass CapsuleLayer(Layer):\n    """"""\n    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n\n    :param num_capsule: number of capsules in this layer\n    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n    :param routings: number of iterations for the routing algorithm\n    """"""\n\n    def __init__(self, num_capsule, dim_capsule, routings=3,\n                 kernel_initializer=\'glorot_uniform\',\n                 **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\n    def build(self, input_shape):\n        assert len(\n            input_shape) >= 3, ""The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]""\n        self.input_num_capsule = input_shape[1]\n        self.input_dim_capsule = input_shape[2]\n\n        # Transform matrix\n        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n                                        self.dim_capsule, self.input_dim_capsule],\n                                 initializer=self.kernel_initializer,\n                                 name=\'W\')\n\n        self.built = True\n\n    def call(self, inputs, training=None):\n        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n        inputs_expand = K.expand_dims(inputs, 1)\n\n        # Replicate num_capsule dimension to prepare being multiplied by W\n        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n\n        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n        # Regard the first two dimensions as `batch` dimension,\n        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n        inputs_hat = K.map_fn(lambda x: batch_dot(\n            x, self.W, [2, 3]), elems=inputs_tiled)\n\n        # Begin: Routing algorithm ---------------------------------------------------------------------#\n        # The prior for coupling coefficient, initialized as zeros.\n        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n        b = tf.zeros(shape=[K.shape(inputs_hat)[0],\n                            self.num_capsule, self.input_num_capsule])\n        output_list = []\n        assert self.routings > 0, \'The routings should be > 0.\'\n        for i in range(self.routings):\n            # c.shape=[batch_size, num_capsule, input_num_capsule]\n            c = tf.nn.softmax(b, dim=1)\n\n            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n            # The first two dimensions as `batch` dimension,\n            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n            # outputs.shape=[None, num_capsule, dim_capsule]\n            # [None, 10, 16]\n            outputs = squash(batch_dot(c, inputs_hat, [2, 2]))\n            # output_list.append(K.expand_dims(outputs,axis=-1))\n            if i < self.routings - 1:\n                # outputs.shape =  [None, num_capsule, dim_capsule]\n                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n                # The first two dimensions as `batch` dimension,\n                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n                # b.shape=[batch_size, num_capsule, input_num_capsule]\n                b += batch_dot(outputs, inputs_hat, [2, 3])\n        # End: Routing algorithm -----------------------------------------------------------------------#\n        # return K.concatenate(output_list,-1)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.num_capsule, self.dim_capsule])\n        # return tuple([None, self.num_capsule, self.dim_capsule, self.routings])\n\n    def get_config(self):\n        config = {\n            \'num_capsule\': self.num_capsule,\n            \'dim_capsule\': self.dim_capsule,\n            \'routings\': self.routings\n        }\n        base_config = super(CapsuleLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\n@register_keras_custom_object\nclass MatMulLayer(Layer):\n\n    def __init__(self, output_dim, type, **kwargs):\n        self.output_dim = output_dim\n        self.type = type\n        super(MatMulLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n\n        # Create a trainable weight variable for this layer.\n        if self.type == 1:\n            self.kernel = self.add_weight(name=\'kernel_type1\',\n                                          shape=(\n                                              input_shape[-1], self.output_dim),\n                                          initializer=\'glorot_uniform\',\n                                          trainable=True)\n        elif self.type == 2:\n            self.kernel = self.add_weight(name=\'kernel_type2\',\n                                          shape=(\n                                              input_shape[1], self.output_dim),\n                                          initializer=\'glorot_uniform\',\n                                          trainable=True)\n\n        # Be sure to call this at the end\n        super(MatMulLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        if self.type == 1:\n            return K.dot(inputs, self.kernel)\n        elif self.type == 2:\n            new_inputs = K.permute_dimensions(inputs, (0, 2, 1))\n            outputs = K.dot(new_inputs, self.kernel)\n            return K.permute_dimensions(outputs, (0, 2, 1))\n\n    def compute_output_shape(self, input_shape):\n        if self.type == 1:\n            return tuple([None, input_shape[1], self.output_dim])\n        elif self.type == 2:\n            return tuple([None, self.output_dim, input_shape[2]])\n'"
lib/layers.py,2,"b'from keras import backend as K\nfrom keras.engine.topology import Layer\n\nif K.backend() == \'tensorflow\':\n    import tensorflow as tf\n\n    def K_meshgrid(x, y):\n        return tf.meshgrid(x, y)\n\n    def K_linspace(start, stop, num):\n        return tf.linspace(start, stop, num)\n\nelse:\n    raise Exception(""Only \'tensorflow\' is supported as backend"")\n\n\nclass BilinearInterpolation(Layer):\n    """"""Performs bilinear interpolation as a keras layer\n    References\n    ----------\n    [1]  Spatial Transformer Networks, Max Jaderberg, et al.\n    [2]  https://github.com/skaae/transformer_network\n    [3]  https://github.com/EderSantana/seya\n    """"""\n\n    def __init__(self, output_size, **kwargs):\n        self.output_size = output_size\n        super(BilinearInterpolation, self).__init__(**kwargs)\n\n    def compute_output_shape(self, input_shapes):\n        height, width = self.output_size\n        num_channels = input_shapes[0][-1]\n        return (None, height, width, num_channels)\n\n    def call(self, tensors, mask=None):\n        X, transformation = tensors\n        output = self._transform(X, transformation, self.output_size)\n        return output\n\n    def _interpolate(self, image, sampled_grids, output_size):\n\n        batch_size = K.shape(image)[0]\n        height = K.shape(image)[1]\n        width = K.shape(image)[2]\n        num_channels = K.shape(image)[3]\n\n        x = K.cast(K.flatten(sampled_grids[:, 0:1, :]), dtype=\'float32\')\n        y = K.cast(K.flatten(sampled_grids[:, 1:2, :]), dtype=\'float32\')\n\n        x = .5 * (x + 1.0) * K.cast(height, dtype=\'float32\')\n        y = .5 * (y + 1.0) * K.cast(width, dtype=\'float32\')\n\n        x0 = K.cast(x, \'int32\')\n        x1 = x0 + 1\n        y0 = K.cast(y, \'int32\')\n        y1 = y0 + 1\n\n        max_x = int(K.int_shape(image)[1] - 1)\n        max_y = int(K.int_shape(image)[2] - 1)\n\n        x0 = K.clip(x0, 0, max_x)\n        x1 = K.clip(x1, 0, max_x)\n        y0 = K.clip(y0, 0, max_y)\n        y1 = K.clip(y1, 0, max_y)\n\n        pixels_batch = K.arange(0, batch_size) * (height * width)\n        pixels_batch = K.expand_dims(pixels_batch, axis=-1)\n        flat_output_size = output_size[0] * output_size[1]\n        base = K.repeat_elements(pixels_batch, flat_output_size, axis=1)\n        base = K.flatten(base)\n\n        # base_y0 = base + (y0 * width)\n        base_y0 = y0 * width\n        base_y0 = base + base_y0\n        # base_y1 = base + (y1 * width)\n        base_y1 = y1 * width\n        base_y1 = base_y1 + base\n\n        indices_a = base_y0 + x0\n        indices_b = base_y1 + x0\n        indices_c = base_y0 + x1\n        indices_d = base_y1 + x1\n\n        flat_image = K.reshape(image, shape=(-1, num_channels))\n        flat_image = K.cast(flat_image, dtype=\'float32\')\n        pixel_values_a = K.gather(flat_image, indices_a)\n        pixel_values_b = K.gather(flat_image, indices_b)\n        pixel_values_c = K.gather(flat_image, indices_c)\n        pixel_values_d = K.gather(flat_image, indices_d)\n\n        x0 = K.cast(x0, \'float32\')\n        x1 = K.cast(x1, \'float32\')\n        y0 = K.cast(y0, \'float32\')\n        y1 = K.cast(y1, \'float32\')\n\n        area_a = K.expand_dims(((x1 - x) * (y1 - y)), 1)\n        area_b = K.expand_dims(((x1 - x) * (y - y0)), 1)\n        area_c = K.expand_dims(((x - x0) * (y1 - y)), 1)\n        area_d = K.expand_dims(((x - x0) * (y - y0)), 1)\n\n        values_a = area_a * pixel_values_a\n        values_b = area_b * pixel_values_b\n        values_c = area_c * pixel_values_c\n        values_d = area_d * pixel_values_d\n        return values_a + values_b + values_c + values_d\n\n    def _make_regular_grids(self, batch_size, height, width):\n        # making a single regular grid\n        x_linspace = K_linspace(-1., 1., width)\n        y_linspace = K_linspace(-1., 1., height)\n        x_coordinates, y_coordinates = K_meshgrid(x_linspace, y_linspace)\n        x_coordinates = K.flatten(x_coordinates)\n        y_coordinates = K.flatten(y_coordinates)\n        ones = K.ones_like(x_coordinates)\n        grid = K.concatenate([x_coordinates, y_coordinates, ones], 0)\n\n        # repeating grids for each batch\n        grid = K.flatten(grid)\n        grids = K.tile(grid, K.stack([batch_size]))\n        return K.reshape(grids, (batch_size, 3, height * width))\n\n    def _transform(self, X, affine_transformation, output_size):\n        batch_size, num_channels = K.shape(X)[0], K.shape(X)[3]\n        transformations = K.reshape(affine_transformation,\n                                    shape=(batch_size, 2, 3))\n        # transformations = K.cast(affine_transformation[:, 0:2, :], \'float32\')\n        regular_grids = self._make_regular_grids(batch_size, *output_size)\n        sampled_grids = K.batch_dot(transformations, regular_grids)\n        interpolated_image = self._interpolate(X, sampled_grids, output_size)\n        new_shape = (batch_size, output_size[0], output_size[1], num_channels)\n        interpolated_image = K.reshape(interpolated_image, new_shape)\n        return interpolated_image\n'"
lib/loupe_keras.py,91,"b'"""""" This code is modified from the following paper.\nLearnable mOdUle for Pooling fEatures (LOUPE)\nContains a collection of models (NetVLAD, NetRVLAD, NetFV and Soft-DBoW)\nwhich enables pooling of a list of features into a single compact \nrepresentation.\n\nReference:\n\nLearnable pooling method with Context Gating for video classification\nAntoine Miech, Ivan Laptev, Josef Sivic\n\n""""""\nimport math\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\nfrom keras import initializers, layers\nimport keras.backend as K\nimport sys\n\n\n# Keras version\n\nclass ContextGating(layers.Layer):\n    """"""Creates a NetVLAD class.\n    """"""\n    def __init__(self, **kwargs):\n        \n        super(ContextGating, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n    # Create a trainable weight variable for this layer.\n        self.gating_weights = self.add_weight(name=\'kernel_W1\',\n                                      shape=(input_shape[-1], input_shape[-1]),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(input_shape[-1])),\n                                      trainable=True)\n        self.gating_biases = self.add_weight(name=\'kernel_B1\',\n                                      shape=(input_shape[-1],),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(input_shape[-1])),\n                                      trainable=True)\n        \n        super(ContextGating, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, inputs):\n        """"""\n        In Keras, there are two way to do matrix multiplication (dot product)\n        1) K.dot : AxB -> when A has batchsize and B doesn\'t, use K.dot\n        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n        \n        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn\'t (2 dim)\n        ValueError: Shape must be rank 2 but is rank 3 for \'net_vlad_1/MatMul\' (op: \'MatMul\') with input shapes: [?,21,64], [64,3]\n        \n        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n        Just follow the above rules.\n        """"""\n        gates = K.dot(inputs, self.gating_weights)\n        gates += self.gating_biases\n        gates = tf.sigmoid(gates)\n\n        activation = tf.multiply(inputs,gates)\n        return activation\n\n    def compute_output_shape(self, input_shape):\n        return tuple(input_shape)\n\n\n\nclass NetVLAD(layers.Layer):\n    """"""Creates a NetVLAD class.\n    """"""\n    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n        \n        self.feature_size = feature_size\n        self.max_samples = max_samples\n        self.output_dim = output_dim\n        self.cluster_size = cluster_size\n        super(NetVLAD, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n    # Create a trainable weight variable for this layer.\n        self.cluster_weights = self.add_weight(name=\'kernel_W1\',\n                                      shape=(self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.cluster_biases = self.add_weight(name=\'kernel_B1\',\n                                      shape=(self.cluster_size,),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.cluster_weights2 = self.add_weight(name=\'kernel_W2\',\n                                      shape=(1,self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.hidden1_weights = self.add_weight(name=\'kernel_H1\',\n                                      shape=(self.cluster_size*self.feature_size, self.output_dim),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.cluster_size)),\n                                      trainable=True)\n        \n        super(NetVLAD, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, reshaped_input):\n        """"""Forward pass of a NetVLAD block.\n\n        Args:\n        reshaped_input: If your input is in that form:\n        \'batch_size\' x \'max_samples\' x \'feature_size\'\n        It should be reshaped in the following form:\n        \'batch_size*max_samples\' x \'feature_size\'\n        by performing:\n        reshaped_input = tf.reshape(input, [-1, features_size])\n\n        Returns:\n        vlad: the pooled vector of size: \'batch_size\' x \'output_dim\'\n        """"""\n        """"""\n        In Keras, there are two way to do matrix multiplication (dot product)\n        1) K.dot : AxB -> when A has batchsize and B doesn\'t, use K.dot\n        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n        \n        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn\'t (2 dim)\n        ValueError: Shape must be rank 2 but is rank 3 for \'net_vlad_1/MatMul\' (op: \'MatMul\') with input shapes: [?,21,64], [64,3]\n        \n        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n        Just follow the above rules.\n        """"""\n        activation = K.dot(reshaped_input, self.cluster_weights)\n        \n        activation += self.cluster_biases\n        \n        activation = tf.nn.softmax(activation)\n\n        activation = tf.reshape(activation,\n                [-1, self.max_samples, self.cluster_size])\n\n        a_sum = tf.reduce_sum(activation,-2,keep_dims=True)\n        \n        a = tf.multiply(a_sum,self.cluster_weights2)\n        \n        activation = tf.transpose(activation,perm=[0,2,1])\n        \n        reshaped_input = tf.reshape(reshaped_input,[-1,\n            self.max_samples, self.feature_size])\n\n        vlad = tf.matmul(activation,reshaped_input)\n        vlad = tf.transpose(vlad,perm=[0,2,1])\n        vlad = tf.subtract(vlad,a)\n        vlad = tf.nn.l2_normalize(vlad,1)\n        vlad = tf.reshape(vlad,[-1, self.cluster_size*self.feature_size])\n        vlad = tf.nn.l2_normalize(vlad,1)\n        vlad = K.dot(vlad, self.hidden1_weights)\n\n        return vlad\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.output_dim])\n\n\n\n\nclass NetRVLAD(layers.Layer):\n    """"""Creates a NetRVLAD class (Residual-less NetVLAD).\n    """"""\n    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n        \n        self.feature_size = feature_size\n        self.max_samples = max_samples\n        self.output_dim = output_dim\n        self.cluster_size = cluster_size\n        super(NetRVLAD, self).__init__(**kwargs)\n    \n    def build(self, input_shape):\n    # Create a trainable weight variable for this layer.\n        self.cluster_weights = self.add_weight(name=\'kernel_W1\',\n                                      shape=(self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.cluster_biases = self.add_weight(name=\'kernel_B1\',\n                                      shape=(self.cluster_size,),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.hidden1_weights = self.add_weight(name=\'kernel_H1\',\n                                      shape=(self.cluster_size*self.feature_size, self.output_dim),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.cluster_size)),\n                                      trainable=True)\n        \n        super(NetRVLAD, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, reshaped_input):\n        """"""Forward pass of a NetRVLAD block.\n\n        Args:\n        reshaped_input: If your input is in that form:\n        \'batch_size\' x \'max_samples\' x \'feature_size\'\n        It should be reshaped in the following form:\n        \'batch_size*max_samples\' x \'feature_size\'\n        by performing:\n        reshaped_input = tf.reshape(input, [-1, features_size])\n\n        Returns:\n        vlad: the pooled vector of size: \'batch_size\' x \'output_dim\'\n        """"""\n        """"""\n        In Keras, there are two way to do matrix multiplication (dot product)\n        1) K.dot : AxB -> when A has batchsize and B doesn\'t, use K.dot\n        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n        \n        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn\'t (2 dim)\n        ValueError: Shape must be rank 2 but is rank 3 for \'net_vlad_1/MatMul\' (op: \'MatMul\') with input shapes: [?,21,64], [64,3]\n        \n        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n        Just follow the above rules.\n        """"""\n        activation = K.dot(reshaped_input, self.cluster_weights)\n        \n        activation += self.cluster_biases\n        \n        activation = tf.nn.softmax(activation)\n\n        activation = tf.reshape(activation,\n                [-1, self.max_samples, self.cluster_size])\n\n        activation = tf.transpose(activation,perm=[0,2,1])\n        \n        reshaped_input = tf.reshape(reshaped_input,[-1,\n            self.max_samples, self.feature_size])\n\n        vlad = tf.matmul(activation,reshaped_input)\n        vlad = tf.transpose(vlad,perm=[0,2,1])\n        vlad = tf.nn.l2_normalize(vlad,1)\n        vlad = tf.reshape(vlad,[-1, self.cluster_size*self.feature_size])\n        vlad = tf.nn.l2_normalize(vlad,1)\n        vlad = K.dot(vlad, self.hidden1_weights)\n\n        return vlad\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.output_dim])\n\n\nclass SoftDBoW(layers.Layer):\n    """"""Creates a Soft Deep Bag-of-Features class.\n    """"""\n    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n        \n        self.feature_size = feature_size\n        self.max_samples = max_samples\n        self.output_dim = output_dim\n        self.cluster_size = cluster_size\n        super(SoftDBoW, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n    # Create a trainable weight variable for this layer.\n        self.cluster_weights = self.add_weight(name=\'kernel_W1\',\n                                      shape=(self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.cluster_biases = self.add_weight(name=\'kernel_B1\',\n                                      shape=(self.cluster_size,),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.hidden1_weights = self.add_weight(name=\'kernel_H1\',\n                                      shape=(self.cluster_size, self.output_dim),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.cluster_size)),\n                                      trainable=True)\n        super(SoftDBoW, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, reshaped_input):\n        """"""Forward pass of a Soft-DBoW block.\n\n        Args:\n        reshaped_input: If your input is in that form:\n        \'batch_size\' x \'max_samples\' x \'feature_size\'\n        It should be reshaped in the following form:\n        \'batch_size*max_samples\' x \'feature_size\'\n        by performing:\n        reshaped_input = tf.reshape(input, [-1, features_size])\n\n        Returns:\n        vlad: the pooled vector of size: \'batch_size\' x \'output_dim\'\n        """"""\n        """"""\n        In Keras, there are two way to do matrix multiplication (dot product)\n        1) K.dot : AxB -> when A has batchsize and B doesn\'t, use K.dot\n        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n        \n        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn\'t (2 dim)\n        ValueError: Shape must be rank 2 but is rank 3 for \'net_vlad_1/MatMul\' (op: \'MatMul\') with input shapes: [?,21,64], [64,3]\n        \n        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n        Just follow the above rules.\n        """"""\n        activation = K.dot(reshaped_input, self.cluster_weights)\n        \n        activation += self.cluster_biases\n        \n        activation = tf.nn.softmax(activation)\n\n        activation = tf.reshape(activation,\n                [-1, self.max_samples, self.cluster_size])\n\n        bow = tf.reduce_sum(activation,1)\n        bow = tf.nn.l2_normalize(bow,1)\n        bow = K.dot(bow, self.hidden1_weights)\n        return bow\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.output_dim])\n\n\n\nclass NetFV(layers.Layer):\n    """"""Creates a NetVLAD class.\n    """"""\n    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n        \n        self.feature_size = feature_size\n        self.max_samples = max_samples\n        self.output_dim = output_dim\n        self.cluster_size = cluster_size\n        super(NetFV, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n    # Create a trainable weight variable for this layer.\n        self.cluster_weights = self.add_weight(name=\'kernel_W1\',\n                                      shape=(self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.covar_weights = self.add_weight(name=\'kernel_C1\',\n                                      shape=(self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.cluster_biases = self.add_weight(name=\'kernel_B1\',\n                                      shape=(self.cluster_size,),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.cluster_weights2 = self.add_weight(name=\'kernel_W2\',\n                                      shape=(1,self.feature_size, self.cluster_size),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n                                      trainable=True)\n        self.hidden1_weights = self.add_weight(name=\'kernel_H1\',\n                                      shape=(2*self.cluster_size*self.feature_size, self.output_dim),\n                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.cluster_size)),\n                                      trainable=True)\n        super(NetFV, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, reshaped_input):\n        """"""Forward pass of a NetFV block.\n\n        Args:\n        reshaped_input: If your input is in that form:\n        \'batch_size\' x \'max_samples\' x \'feature_size\'\n        It should be reshaped in the following form:\n        \'batch_size*max_samples\' x \'feature_size\'\n        by performing:\n        reshaped_input = tf.reshape(input, [-1, features_size])\n\n        Returns:\n        vlad: the pooled vector of size: \'batch_size\' x \'output_dim\'\n        """"""\n        """"""\n        In Keras, there are two way to do matrix multiplication (dot product)\n        1) K.dot : AxB -> when A has batchsize and B doesn\'t, use K.dot\n        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n        \n        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn\'t (2 dim)\n        ValueError: Shape must be rank 2 but is rank 3 for \'net_vlad_1/MatMul\' (op: \'MatMul\') with input shapes: [?,21,64], [64,3]\n        \n        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n        Just follow the above rules.\n        """"""\n\n        covar_weights = tf.square(self.covar_weights)\n        eps = tf.constant([1e-6])\n        covar_weights = tf.add(covar_weights,eps)\n\n        activation = K.dot(reshaped_input, self.cluster_weights)\n        \n        activation += self.cluster_biases\n        \n        activation = tf.nn.softmax(activation)\n\n        activation = tf.reshape(activation,\n                [-1, self.max_samples, self.cluster_size])\n\n        a_sum = tf.reduce_sum(activation,-2,keep_dims=True)\n        \n        a = tf.multiply(a_sum,self.cluster_weights2)\n        \n        activation = tf.transpose(activation,perm=[0,2,1])\n        \n        reshaped_input = tf.reshape(reshaped_input,[-1,\n            self.max_samples, self.feature_size])\n\n        fv1 = tf.matmul(activation,reshaped_input)\n        fv1 = tf.transpose(fv1,perm=[0,2,1])\n\n        # computing second order FV\n        a2 = tf.multiply(a_sum,tf.square(self.cluster_weights2)) \n\n        b2 = tf.multiply(fv1,self.cluster_weights2) \n        fv2 = tf.matmul(activation,tf.square(reshaped_input)) \n     \n        fv2 = tf.transpose(fv2,perm=[0,2,1])\n        fv2 = tf.add_n([a2,fv2,tf.scalar_mul(-2,b2)])\n\n        fv2 = tf.divide(fv2,tf.square(covar_weights))\n        fv2 = tf.subtract(fv2,a_sum)\n\n        fv2 = tf.reshape(fv2,[-1,self.cluster_size*self.feature_size])\n      \n        fv2 = tf.nn.l2_normalize(fv2,1)\n        fv2 = tf.reshape(fv2,[-1,self.cluster_size*self.feature_size])\n        fv2 = tf.nn.l2_normalize(fv2,1)\n\n        fv1 = tf.subtract(fv1,a)\n        fv1 = tf.divide(fv1,covar_weights) \n\n        fv1 = tf.nn.l2_normalize(fv1,1)\n        fv1 = tf.reshape(fv1,[-1,self.cluster_size*self.feature_size])\n        fv1 = tf.nn.l2_normalize(fv1,1)\n\n        fv = tf.concat([fv1,fv2],1)\n\n        fv = K.dot(fv, self.hidden1_weights)\n        return fv\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.output_dim])\n\n'"
lib/utils.py,0,"b'import numpy as np\n\nfrom keras.utils import get_custom_objects\n\n\ndef get_initial_weights(output_size):\n    b = np.zeros((2, 3), dtype=\'float32\')\n    b[0, 0] = 1\n    b[1, 1] = 1\n    W = np.zeros((output_size, 6), dtype=\'float32\')\n    weights = [W, b.flatten()]\n    return weights\n\n\ndef register_keras_custom_object(cls):\n    """""" A decorator to register custom layers, loss functions etc in global scope """"""\n    get_custom_objects()[cls.__name__] = cls\n    return cls\n'"
training_and_testing/FSANET_fine_train.py,0,"b'import os\nimport sys\nsys.path.append(\'..\')\nimport logging\nimport argparse\nimport pandas as pd\n\nimport numpy as np\n\nfrom keras.utils import np_utils\nfrom keras.utils import plot_model\nfrom keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom lib.FSANET_model import *\n\nimport TYY_callbacks\nfrom TYY_generators import *\n\nimport cv2\nlogging.basicConfig(level=logging.DEBUG)\n\n\ndef load_data_npz(npz_path):\n    d = np.load(npz_path)\n    return d[""image""], d[""pose""]\n\n\ndef mk_dir(dir):\n    try:\n        os.mkdir(dir)\n    except OSError:\n        pass\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=""This script trains the CNN model for head pose estimation."",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(""--batch_size"", type=int, default=16,\n                        help=""batch size"")\n    parser.add_argument(""--nb_epochs"", type=int, default=90,\n                        help=""number of epochs"")\n    parser.add_argument(""--validation_split"", type=float, default=0.2,\n                        help=""validation split ratio"")\n    parser.add_argument(""--model_type"", type=int, default=3,\n                        help=""type of model"")\n    parser.add_argument(""--db_name"", type=str, default=\'300W_LP\',\n                        help=""type of model"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef main():\n    args = get_args()\n    db_name = args.db_name\n    batch_size = args.batch_size\n    nb_epochs = args.nb_epochs\n    validation_split = args.validation_split\n    model_type = args.model_type\n    image_size = 64\n\n    logging.debug(""Loading data..."")\n\n    if db_name == \'300W_LP\':\n        db_list = [\'AFW.npz\', \'AFW_Flip.npz\', \'HELEN.npz\', \'HELEN_Flip.npz\',\n                   \'IBUG.npz\', \'IBUG_Flip.npz\', \'LFPW.npz\', \'LFPW_Flip.npz\']\n        image = []\n        pose = []\n        for i in range(0, len(db_list)):\n            image_temp, pose_temp = load_data_npz(\'../data/type1/\'+db_list[i])\n            image.append(image_temp)\n            pose.append(pose_temp)\n        image = np.concatenate(image, 0)\n        pose = np.concatenate(pose, 0)\n\n        # we only care the angle between [-99,99] and filter other angles\n        x_data = []\n        y_data = []\n        print(image.shape)\n        print(pose.shape)\n        for i in range(0, pose.shape[0]):\n            temp_pose = pose[i, :]\n            if np.max(temp_pose) <= 99.0 and np.min(temp_pose) >= -99.0:\n                x_data.append(image[i, :, :, :])\n                y_data.append(pose[i, :])\n        x_data = np.array(x_data)\n        y_data = np.array(y_data)\n        print(x_data.shape)\n        print(y_data.shape)\n    elif db_name == \'synhead_noBIWI\':\n        image, pose = load_data_npz(\n            \'../data/synhead/media/jinweig/Data2/synhead2_release/synhead_noBIWI.npz\')\n        x_data = image\n        y_data = pose\n    elif db_name == \'BIWI\':\n        image, pose = load_data_npz(\'../data/BIWI_train.npz\')\n        x_train = image\n        y_train = pose\n        image_test, pose_test = load_data_npz(\'../data/BIWI_test.npz\')\n        x_test = image_test\n        y_test = pose_test\n    else:\n        print(\'db_name is wrong!!!\')\n        return\n\n    start_decay_epoch = [30, 60]\n\n    optMethod = Adam()\n\n    stage_num = [3, 3, 3]\n    lambda_d = 1\n    num_classes = 3\n    isFine = False\n\n    if model_type == 1:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Capsule(image_size, num_classes,\n                                stage_num, lambda_d, S_set)()\n        load_name = \'fsanet_capsule\'+str_S_set\n        save_name = \'fsanet_capsule_fine\'+str_S_set\n        weight_file = ""synhead_noBIWI""+""_models/""+load_name+""/""+load_name+"".h5""\n        model.load_weights(weight_file)\n    elif model_type == 2:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Var_Capsule(\n            image_size, num_classes, stage_num, lambda_d, S_set)()\n        load_name = \'fsanet_var_capsule\'+str_S_set\n        save_name = \'fsanet_var_capsule_fine\'+str_S_set\n        weight_file = ""synhead_noBIWI""+""_models/""+load_name+""/""+load_name+"".h5""\n        model.load_weights(weight_file)\n    elif model_type == 3:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 8*8*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_noS_Capsule(\n            image_size, num_classes, stage_num, lambda_d, S_set)()\n        load_name = \'fsanet_noS_capsule\'+str_S_set\n        save_name = \'fsanet_noS_capsule_fine\'+str_S_set\n        weight_file = ""synhead_noBIWI""+""_models/""+load_name+""/""+load_name+"".h5""\n        model.load_weights(weight_file)\n\n    model.compile(optimizer=optMethod, loss=[""mae""], loss_weights=[1])\n\n    logging.debug(""Model summary..."")\n    model.count_params()\n    model.summary()\n\n    logging.debug(""Saving model..."")\n    mk_dir(db_name+""_models"")\n    mk_dir(db_name+""_models/""+save_name)\n    mk_dir(db_name+""_checkpoints"")\n    plot_model(model, to_file=db_name+""_models/"" +\n               save_name+""/""+save_name+"".png"")\n    for i_L, layer in enumerate(model.layers):\n        if i_L > 0 and i_L < len(model.layers)-1:\n            if \'pred\' not in layer.name and \'caps\' != layer.name and \'merge\' not in layer.name and \'model\' in layer.name:\n                plot_model(layer, to_file=db_name+""_models/"" +\n                           save_name+""/""+layer.name+"".png"")\n\n    decaylearningrate = TYY_callbacks.DecayLearningRate(start_decay_epoch)\n\n    callbacks = [ModelCheckpoint(db_name+""_checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5"",\n                                 monitor=""val_loss"",\n                                 verbose=1,\n                                 save_best_only=True,\n                                 mode=""auto""), decaylearningrate\n                 ]\n\n    logging.debug(""Running training..."")\n\n    if db_name != \'BIWI\':\n        data_num = len(x_data)\n        indexes = np.arange(data_num)\n        np.random.shuffle(indexes)\n        x_data = x_data[indexes]\n        y_data = y_data[indexes]\n        train_num = int(data_num * (1 - validation_split))\n\n        x_train = x_data[:train_num]\n        x_test = x_data[train_num:]\n        y_train = y_data[:train_num]\n        y_test = y_data[train_num:]\n    elif db_name == \'BIWI\':\n        train_num = np.shape(x_train)[0]\n\n    hist = model.fit_generator(generator=data_generator_pose(X=x_train, Y=y_train, batch_size=batch_size),\n                               steps_per_epoch=train_num // batch_size,\n                               validation_data=(x_test, y_test),\n                               epochs=nb_epochs, verbose=1,\n                               callbacks=callbacks)\n\n    logging.debug(""Saving weights..."")\n    model.save_weights(os.path.join(db_name+""_models/"" +\n                                    save_name, save_name+\'.h5\'), overwrite=True)\n    pd.DataFrame(hist.history).to_hdf(os.path.join(\n        db_name+""_models/""+save_name, \'history_\'+save_name+\'.h5\'), ""history"")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
training_and_testing/FSANET_mix_test.py,0,"b'import os\nimport sys\nsys.path.append(\'..\')\nimport logging\nimport argparse\nimport pandas as pd\nimport numpy as np\n\nfrom keras import backend as K\nfrom keras.layers import *\nfrom keras.utils import np_utils\nfrom keras.utils import plot_model\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom lib.FSANET_model import *\n\nimport TYY_callbacks\nfrom TYY_generators import *\n\nimport cv2\n\n\ndef load_data_npz(npz_path):\n    d = np.load(npz_path)\n\n    return d[""image""], d[""pose""]\n\n\ndef mk_dir(dir):\n    try:\n        os.mkdir(dir)\n    except OSError:\n        pass\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=""This script tests the CNN model for head pose estimation."",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(""--model_type"", type=int, default=3,\n                        help=""type of model"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef main():\n    K.clear_session()\n    K.set_learning_phase(0)  # make sure its testing mode\n\n    args = get_args()\n    # train_db_name = \'300W_LP\'\n    train_db_name = \'BIWI\'\n    # train_db_name = \'synhead_noBIWI\'\n    model_type = args.model_type\n\n    image_size = 64\n\n    if train_db_name == \'300W_LP\':\n        test_db_list = [1, 2]\n    elif train_db_name == \'BIWI\':\n        test_db_list = [2]\n\n    for test_db_type in test_db_list:\n\n        if test_db_type == 1:\n            test_db_name = \'AFLW2000\'\n            image, pose = load_data_npz(\'../data/type1/AFLW2000.npz\')\n        elif test_db_type == 2:\n            test_db_name = \'BIWI\'\n            if train_db_name == \'300W_LP\':\n                image, pose = load_data_npz(\'../data/BIWI_noTrack.npz\')\n            elif train_db_name == \'BIWI\':\n                image, pose = load_data_npz(\'../data/BIWI_test.npz\')\n\n        if train_db_name == \'300W_LP\':\n            # we only care the angle between [-99,99] and filter other angles\n            x_data = []\n            y_data = []\n\n            for i in range(0, pose.shape[0]):\n                temp_pose = pose[i, :]\n                if np.max(temp_pose) <= 99.0 and np.min(temp_pose) >= -99.0:\n                    x_data.append(image[i, :, :, :])\n                    y_data.append(pose[i, :])\n            x_data = np.array(x_data)\n            y_data = np.array(y_data)\n        else:\n            x_data = image\n            y_data = pose\n\n        stage_num = [3, 3, 3]\n        lambda_d = 1\n        num_classes = 3\n\n        if model_type == 1:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_Capsule(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_capsule\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_Capsule(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_capsule\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_Capsule(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_capsule\'+str_S_set\n            save_name = \'fusion_dim_split_capsule\'\n        elif model_type == 2:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_Capsule_FC(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_capsule_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_Capsule_FC(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_capsule_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_Capsule_FC(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_capsule_fc\'+str_S_set\n\n            save_name = \'fusion_fc_capsule\'\n        elif model_type == 3:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_NetVLAD(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_netvlad\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_NetVLAD(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_netvlad\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_NetVLAD(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_netvlad\'+str_S_set\n\n            save_name = \'fusion_dim_split_netvlad\'\n        elif model_type == 4:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_NetVLAD_FC(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_netvlad_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_NetVLAD_FC(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_netvlad_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_NetVLAD_FC(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_netvlad_fc\'+str_S_set\n            save_name = \'fusion_fc_netvlad\'\n        elif model_type == 5:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_Capsule(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_capsule_fine\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_Capsule(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_capsule_fine\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_Capsule(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_capsule_fine\'+str_S_set\n            save_name = \'fusion_dim_split_capsule_fine\'\n        elif model_type == 6:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_Metric(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_metric\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_Metric(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_metric\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_Metric(\n                image_size, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_metric\'+str_S_set\n            save_name = \'fusion_dim_split_metric\'\n\n        weight_file1 = train_db_name+""_models/""+save_name1+""/""+save_name1+"".h5""\n        model1.load_weights(weight_file1)\n        weight_file2 = train_db_name+""_models/""+save_name2+""/""+save_name2+"".h5""\n        model2.load_weights(weight_file2)\n        weight_file3 = train_db_name+""_models/""+save_name3+""/""+save_name3+"".h5""\n        model3.load_weights(weight_file3)\n        inputs = Input(shape=(64, 64, 3))\n        x1 = model1(inputs)\n        x2 = model2(inputs)\n        x3 = model3(inputs)\n        outputs = Average()([x1, x2, x3])\n        model = Model(inputs=inputs, outputs=outputs)\n\n        p_data = model.predict(x_data)\n        pose_matrix = np.mean(np.abs(p_data-y_data), axis=0)\n        MAE = np.mean(pose_matrix)\n        yaw = pose_matrix[0]\n        pitch = pose_matrix[1]\n        roll = pose_matrix[2]\n        print(\'\\n--------------------------------------------------------------------------------\')\n        print(save_name+\', \'+test_db_name+\'(\'+train_db_name+\')\' +\n              \', MAE = %3.3f, [yaw,pitch,roll] = [%3.3f, %3.3f, %3.3f]\' % (MAE, yaw, pitch, roll))\n        print(\'--------------------------------------------------------------------------------\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
training_and_testing/FSANET_test.py,0,"b'import os\nimport sys\nsys.path.append(\'..\')\nimport logging\nimport argparse\n\nimport numpy as np\nimport pandas as pd\n\nfrom keras import backend as K\nfrom keras.layers import *\nfrom keras.utils import plot_model\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom lib.FSANET_model import *\nfrom lib.SSRNET_model import *\n\nimport TYY_callbacks\nfrom TYY_generators import *\n\n_TRAIN_DB_300W_LP = ""300W_LP""\n_TRAIN_DB_BIWI = ""BIWI""\n\n_TEST_DB_AFLW = ""AFLW2000""\n_TEST_DB_BIWI = ""BIWI""\n\n_IMAGE_SIZE = 64\n\ndef load_data_npz(npz_path):\n    d = np.load(npz_path)\n    return d[""image""], d[""pose""]\n\ndef mk_dir(dir):\n    try:\n        os.mkdir( dir )\n    except OSError:\n        pass\n\ndef get_weights_file_path(use_pretrained, train_db_name, save_name):\n    prefix = ""../pre-trained/"" if use_pretrained else """"\n    return prefix + train_db_name+""_models/""+save_name+""/""+save_name+"".h5""    \n\ndef get_args():\n    parser = argparse.ArgumentParser(description=""This script tests the CNN model for head pose estimation."",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(""--model_type"", type=int, default=3, \n                        help=""type of model"")\n    parser.add_argument(\'--use_pretrained\', required=False,\n                        dest=\'use_pretrained\',\n                        action=\'store_true\')\n    parser.add_argument(""--train_db"", choices=[_TRAIN_DB_300W_LP, _TRAIN_DB_BIWI], required=False, default=_TRAIN_DB_300W_LP)\n\n    parser.set_defaults(use_pretrained=False)\n\n    args = parser.parse_args()\n    return args\n\ndef main():\n    K.clear_session()\n    K.set_learning_phase(0) # make sure its testing mode\n    \n    args = get_args()\n    \n    model_type = args.model_type\n    train_db_name = args.train_db\n    use_pretrained = args.use_pretrained   \n    \n\n    if train_db_name == _TRAIN_DB_300W_LP:\n        test_db_list = [_TEST_DB_AFLW, _TEST_DB_BIWI]\n    elif train_db_name == _TRAIN_DB_BIWI:\n        test_db_list = [_TEST_DB_BIWI]\n\n    for test_db_name in test_db_list:\n\n        if test_db_name == _TEST_DB_AFLW:            \n            image, pose = load_data_npz(\'../data/type1/AFLW2000.npz\')\n        elif test_db_name == _TEST_DB_BIWI:            \n            if train_db_name == _TRAIN_DB_300W_LP:\n                image, pose = load_data_npz(\'../data/BIWI_noTrack.npz\')\n            elif train_db_name == _TRAIN_DB_BIWI:\n                image, pose = load_data_npz(\'../data/BIWI_test.npz\')\n        \n        if train_db_name == _TRAIN_DB_300W_LP:\n            # we only care the angle between [-99,99] and filter other angles\n            x_data = []\n            y_data = []\n\n            for i in range(0,pose.shape[0]):\n                temp_pose = pose[i,:]\n                if np.max(temp_pose)<=99.0 and np.min(temp_pose)>=-99.0:\n                    x_data.append(image[i,:,:,:])\n                    y_data.append(pose[i,:])\n            x_data = np.array(x_data)\n            y_data = np.array(y_data)\n        else:\n            x_data = image\n            y_data = pose\n        \n        stage_num = [3,3,3]\n        lambda_d = 1\n        num_classes = 3\n\n        if model_type == 0:\n            model = SSR_net_ori_MT(_IMAGE_SIZE, num_classes, stage_num, lambda_d)()\n            save_name = \'ssrnet_ori_mt\'\n\n        elif model_type == 1:\n            model = SSR_net_MT(_IMAGE_SIZE, num_classes, stage_num, lambda_d)()\n            save_name = \'ssrnet_mt\'\n\n        elif model_type == 2:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_capsule\'+str_S_set\n        \n        elif model_type == 3:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Var_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_var_capsule\'+str_S_set\n        elif model_type == 4:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_NetVLAD(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_netvlad\'+str_S_set\n        elif model_type == 5:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Var_NetVLAD(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_var_netvlad\'+str_S_set\n        elif model_type == 6:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_noS_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_noS_capsule\'+str_S_set\n        elif model_type == 7:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_noS_NetVLAD(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_noS_netvlad\'+str_S_set\n        \n        elif model_type == 8:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_capsule_fine\'+str_S_set\n            \n        elif model_type == 9:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Capsule_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_capsule_fc\'+str_S_set\n        elif model_type == 10:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Var_Capsule_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_var_capsule_fc\'+str_S_set\n        elif model_type == 11:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_noS_Capsule_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_noS_capsule_fc\'+str_S_set\n        elif model_type == 12:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_NetVLAD_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_netvlad_fc\'+str_S_set\n        elif model_type == 13:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_Var_NetVLAD_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_var_netvlad_fc\'+str_S_set\n        elif model_type == 14:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model = FSA_net_noS_NetVLAD_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name = \'fsanet_noS_netvlad_fc\'+str_S_set\n\n        elif model_type == 15:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_capsule\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_capsule\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_Capsule(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_capsule\'+str_S_set\n            save_name = \'fusion_dim_split_capsule\'\n        elif model_type == 16:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_Capsule_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_capsule_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_Capsule_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_capsule_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_Capsule_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_capsule_fc\'+str_S_set\n\n            save_name = \'fusion_fc_capsule\'\n        elif model_type == 17:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_NetVLAD(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_netvlad\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_NetVLAD(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_netvlad\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_NetVLAD(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_netvlad\'+str_S_set\n\n            save_name = \'fusion_dim_split_netvlad\'\n        elif model_type == 18:\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model1 = FSA_net_NetVLAD_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name1 = \'fsanet_netvlad_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 7*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model2 = FSA_net_Var_NetVLAD_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name2 = \'fsanet_var_netvlad_fc\'+str_S_set\n\n            num_capsule = 3\n            dim_capsule = 16\n            routings = 2\n\n            num_primcaps = 8*8*3\n            m_dim = 5\n            S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n            str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n            model3 = FSA_net_noS_NetVLAD_FC(_IMAGE_SIZE, num_classes, stage_num, lambda_d, S_set)()\n            save_name3 = \'fsanet_noS_netvlad_fc\'+str_S_set\n            save_name = \'fusion_fc_netvlad\'\n\n        if model_type <15:            \n            weight_file = get_weights_file_path(use_pretrained, train_db_name, save_name)\n            model.load_weights(weight_file)\n        else:            \n            weight_file1 = get_weights_file_path(use_pretrained, train_db_name, save_name1)\n            model1.load_weights(weight_file1)            \n            weight_file2 = get_weights_file_path(use_pretrained, train_db_name, save_name2)\n            model2.load_weights(weight_file2)            \n            weight_file3 = get_weights_file_path(use_pretrained, train_db_name, save_name3)\n            model3.load_weights(weight_file3)\n            inputs = Input(shape=(64,64,3))\n            x1 = model1(inputs)\n            x2 = model2(inputs)\n            x3 = model3(inputs)\n            outputs = Average()([x1,x2,x3])\n            model = Model(inputs=inputs,outputs=outputs)\n\n        p_data = model.predict(x_data)\n        pose_matrix = np.mean(np.abs(p_data-y_data),axis=0)\n        MAE = np.mean(pose_matrix)\n        yaw = pose_matrix[0]\n        pitch = pose_matrix[1]\n        roll = pose_matrix[2]\n        print(\'\\n--------------------------------------------------------------------------------\')\n        print(save_name+\', \'+test_db_name+\'(\'+train_db_name+\')\'+\', MAE = %3.3f, [yaw,pitch,roll] = [%3.3f, %3.3f, %3.3f]\'%(MAE, yaw, pitch, roll))\n        print(\'--------------------------------------------------------------------------------\')\n\nif __name__ == \'__main__\':    \n    main()\n'"
training_and_testing/FSANET_train.py,0,"b'import os\nimport sys\nsys.path.append(\'..\')\nimport logging\nimport argparse\nimport pandas as pd\nimport numpy as np\n\nfrom lib.FSANET_model import *\nfrom lib.SSRNET_model import *\n\nimport TYY_callbacks\nfrom TYY_generators import *\n\nfrom keras.utils import np_utils\nfrom keras.utils import plot_model\nfrom keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nlogging.basicConfig(level=logging.DEBUG)\n\ndef load_data_npz(npz_path):\n    d = np.load(npz_path)\n    return d[""image""], d[""pose""]\n\ndef mk_dir(dir):\n    try:\n        os.mkdir( dir )\n    except OSError:\n        pass\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=""This script trains the CNN model for head pose estimation."",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(""--batch_size"", type=int, default=16,\n                        help=""batch size"")\n    parser.add_argument(""--nb_epochs"", type=int, default=90,\n                        help=""number of epochs"")\n    parser.add_argument(""--validation_split"", type=float, default=0.2,\n                        help=""validation split ratio"")\n    parser.add_argument(""--model_type"", type=int, default=3,\n                        help=""type of model"")\n    parser.add_argument(""--db_name"", type=str, default=\'300W_LP\',\n                        help=""type of model"")\n\n    args = parser.parse_args()\n    return args\n\n\n\ndef main():\n    args = get_args()\n    db_name = args.db_name\n    batch_size = args.batch_size\n    nb_epochs = args.nb_epochs\n    validation_split = args.validation_split\n    model_type = args.model_type\n    image_size = 64\n\n    logging.debug(""Loading data..."")\n\n    if db_name == \'300W_LP\':\n        db_list = [\'AFW.npz\',\'AFW_Flip.npz\',\'HELEN.npz\',\'HELEN_Flip.npz\',\'IBUG.npz\',\'IBUG_Flip.npz\',\'LFPW.npz\',\'LFPW_Flip.npz\']\n        image = []\n        pose = []\n        for i in range(0,len(db_list)):\n            image_temp, pose_temp = load_data_npz(\'../data/type1/\'+db_list[i])\n            image.append(image_temp)\n            pose.append(pose_temp)\n        image = np.concatenate(image,0)\n        pose = np.concatenate(pose,0)\n        \n        # we only care the angle between [-99,99] and filter other angles\n        x_data = []\n        y_data = []\n        print(image.shape)\n        print(pose.shape)\n        for i in range(0,pose.shape[0]):\n            temp_pose = pose[i,:]\n            if np.max(temp_pose)<=99.0 and np.min(temp_pose)>=-99.0:\n                x_data.append(image[i,:,:,:])\n                y_data.append(pose[i,:])\n        x_data = np.array(x_data)\n        y_data = np.array(y_data)\n        print(x_data.shape)\n        print(y_data.shape)\n    elif db_name == \'synhead_noBIWI\':\n        image, pose = load_data_npz(\'../data/synhead/media/jinweig/Data2/synhead2_release/synhead_noBIWI.npz\')\n        x_data = image\n        y_data = pose\n    elif db_name == \'BIWI\':\n        image, pose = load_data_npz(\'../data/BIWI_train.npz\')\n        x_train = image\n        y_train = pose\n        image_test, pose_test = load_data_npz(\'../data/BIWI_test.npz\')\n        x_test = image_test\n        y_test = pose_test\n    else:\n        print(\'db_name is wrong!!!\')\n        return\n\n    start_decay_epoch = [30,60]\n\n    optMethod = Adam()\n\n    stage_num = [3,3,3]\n    lambda_d = 1\n    num_classes = 3\n    isFine = False\n\n    if model_type == 0:\n        model = SSR_net_ori_MT(image_size, num_classes, stage_num, lambda_d)()\n        save_name = \'ssrnet_ori_mt\'\n\n    elif model_type == 1:\n        model = SSR_net_MT(image_size, num_classes, stage_num, lambda_d)()\n        save_name = \'ssrnet_mt\'\n\n    elif model_type == 2:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_capsule\'+str_S_set\n    \n    elif model_type == 3:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Var_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_var_capsule\'+str_S_set\n\n    elif model_type == 4:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 8*8*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_noS_Capsule(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_noS_capsule\'+str_S_set\n\n    elif model_type == 5:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_NetVLAD(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_netvlad\'+str_S_set\n\n    elif model_type == 6:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Var_NetVLAD(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_var_netvlad\'+str_S_set\n    \n    elif model_type == 7:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 8*8*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_noS_NetVLAD(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_noS_netvlad\'+str_S_set\n\n    elif model_type == 8:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Metric(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_metric\'+str_S_set\n\n    elif model_type == 9:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 7*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_Var_Metric(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_var_metric\'+str_S_set\n    elif model_type == 10:\n        num_capsule = 3\n        dim_capsule = 16\n        routings = 2\n\n        num_primcaps = 8*8*3\n        m_dim = 5\n        S_set = [num_capsule, dim_capsule, routings, num_primcaps, m_dim]\n        str_S_set = \'\'.join(\'_\'+str(x) for x in S_set)\n\n        model = FSA_net_noS_Metric(image_size, num_classes, stage_num, lambda_d, S_set)()\n        save_name = \'fsanet_noS_metric\'+str_S_set\n\n\n\n\n    model.compile(optimizer=optMethod, loss=[""mae""],loss_weights=[1])\n\n    logging.debug(""Model summary..."")\n    model.count_params()\n    model.summary()\n\n    logging.debug(""Saving model..."")\n    mk_dir(db_name+""_models"")\n    mk_dir(db_name+""_models/""+save_name)\n    mk_dir(db_name+""_checkpoints"")\n    plot_model(model, to_file=db_name+""_models/""+save_name+""/""+save_name+"".png"")\n    for i_L,layer in enumerate(model.layers):\n        if i_L >0 and i_L< len(model.layers)-1:\n            if \'pred\' not in layer.name and \'caps\' != layer.name and \'merge\' not in layer.name and \'model\' in layer.name:\n                plot_model(layer, to_file=db_name+""_models/""+save_name+""/""+layer.name+"".png"")\n    \n\n    decaylearningrate = TYY_callbacks.DecayLearningRate(start_decay_epoch)\n\n    callbacks = [ModelCheckpoint(db_name+""_checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5"",\n                                 monitor=""val_loss"",\n                                 verbose=1,\n                                 save_best_only=True,\n                                 mode=""auto""), decaylearningrate\n                        ]\n\n    logging.debug(""Running training..."")\n    \n\n\n    if db_name != \'BIWI\':\n        data_num = len(x_data)\n        indexes = np.arange(data_num)\n        np.random.shuffle(indexes)\n        x_data = x_data[indexes]\n        y_data = y_data[indexes]\n        train_num = int(data_num * (1 - validation_split))\n        \n        x_train = x_data[:train_num]\n        x_test = x_data[train_num:]\n        y_train = y_data[:train_num]\n        y_test = y_data[train_num:]\n    elif db_name == \'BIWI\':\n        train_num = np.shape(x_train)[0]\n\n\n    hist = model.fit_generator(generator=data_generator_pose(X=x_train, Y=y_train, batch_size=batch_size),\n                                       steps_per_epoch=train_num // batch_size,\n                                       validation_data=(x_test, y_test),\n                                       epochs=nb_epochs, verbose=1,\n                                       callbacks=callbacks)\n    \n    logging.debug(""Saving weights..."")\n    model.save_weights(os.path.join(db_name+""_models/""+save_name, save_name+\'.h5\'), overwrite=True)\n    pd.DataFrame(hist.history).to_hdf(os.path.join(db_name+""_models/""+save_name, \'history_\'+save_name+\'.h5\'), ""history"")\n\n\nif __name__ == \'__main__\':\n    main()'"
training_and_testing/TYY_callbacks.py,0,"b""import keras\nfrom sklearn.metrics import roc_auc_score\nimport sys\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nimport numpy as np\nfrom keras import backend as K\nimport tensorflow as tf\n\n\nclass DecayLearningRate(keras.callbacks.Callback):\n\tdef __init__(self, startEpoch):\n\t\tself.startEpoch = startEpoch\n\t\t# self.isFine = isFine\n\t\n\t# def build_ht_copy_W(self):\n\t# \tself.ht = {}\n\t# \tfor i_m, sub_model in enumerate(self.model.layers):\n\t# \t\tif i_m>0:\n\t# \t\t\tW = sub_model.get_weights() # weight is list\n\t# \t\t\tif type(W) == list:\n\t# \t\t\t\tself.ht[i_m] = list(W) # copying a list in python\n\t# \t\t\telse:\n\t# \t\t\t\tsys.exit()\n\n\t# \t\t\t# If trying to copy a tensor\n\t# \t\t\t# make sure the saved tensor is a copy one\n\t# \t\t\t# (tensor + 0) is necessary\n\n\t# \treturn\n\t# def list_operation(self,A_list,B_list,alpha):\n\t# \ttemp = []\n\t# \tfor i_A in range(len(A_list)):\n\t# \t\ttemp.append(A_list[i_A]+alpha*B_list[i_A])\n\t# \treturn temp\n\n\tdef on_train_begin(self, logs={}):\n\t\t# if self.isFine:\n\t\t# \tself.build_ht_copy_W()\n\t\treturn\n\n\tdef on_train_end(self, logs={}):\n\t\treturn\n\n\tdef on_epoch_begin(self, epoch, logs={}):\n\t\t\n\t\tif epoch in self.startEpoch:\n\t\t\tif epoch == 0:\n\t\t\t\tratio = 1\n\t\t\telse:\n\t\t\t\tratio = 0.1\n\t\t\tLR = K.get_value(self.model.optimizer.lr)\n\t\t\tK.set_value(self.model.optimizer.lr,LR*ratio)\n\t\t\n\t\treturn\n\n\tdef on_epoch_end(self, epoch, logs={}):\t\n\t\treturn\n\n\tdef on_batch_begin(self, batch, logs={}):\n\t\treturn\n\n\tdef on_batch_end(self, batch, logs={}):\n\t\t# if self.isFine:\n\t\t# \tfor i_m, sub_model in enumerate(self.model.layers):\n\t\t# \t\tif i_m>1:\n\t\t# \t\t\tif sub_model.name != 'ssr_Cap_model' and sub_model.name != 'ssr_F_Cap_model':\n\t\t# \t\t\t\told_W = self.ht[i_m]\n\t\t# \t\t\t\tnew_W = sub_model.get_weights()\n\t\t# \t\t\t\tdelta_W = self.list_operation(new_W,old_W,-1)\n\n\t\t# \t\t\t\tsub_W = self.list_operation(old_W,delta_W,0.1)\n\t\t# \t\t\t\tsub_model.set_weights(sub_W)\n\n\t\t# \tself.build_ht_copy_W()\n\t\treturn\n"""
training_and_testing/TYY_generators.py,1,"b'import keras\nimport numpy as np\nimport sys\nimport tensorflow as tf\nimport cv2\n\n\ndef random_crop(x,dn):\n    dx = np.random.randint(dn,size=1)[0]\n    dy = np.random.randint(dn,size=1)[0]\n    h = x.shape[0]\n    w = x.shape[1]\n    out = x[0+dy:h-(dn-dy),0+dx:w-(dn-dx),:]\n    out = cv2.resize(out, (h,w), interpolation=cv2.INTER_CUBIC)\n    return out\n\ndef random_crop_black(x,dn):\n    dx = np.random.randint(dn,size=1)[0]\n    dy = np.random.randint(dn,size=1)[0]\n    \n    h = x.shape[0]\n    w = x.shape[1]\n\n    dx_shift = np.random.randint(dn,size=1)[0]\n    dy_shift = np.random.randint(dn,size=1)[0]\n    out = x*0\n    out[0+dy_shift:h-(dn-dy_shift),0+dx_shift:w-(dn-dx_shift),:] = x[0+dy:h-(dn-dy),0+dx:w-(dn-dx),:]\n    \n    return out\n\ndef random_crop_white(x,dn):\n    dx = np.random.randint(dn,size=1)[0]\n    dy = np.random.randint(dn,size=1)[0]\n    h = x.shape[0]\n    w = x.shape[1]\n\n    dx_shift = np.random.randint(dn,size=1)[0]\n    dy_shift = np.random.randint(dn,size=1)[0]\n    out = x*0+255\n    out[0+dy_shift:h-(dn-dy_shift),0+dx_shift:w-(dn-dx_shift),:] = x[0+dy:h-(dn-dy),0+dx:w-(dn-dx),:]\n    \n    return out\n\ndef augment_data(images):\n    for i in range(0,images.shape[0]):\n        \n        rand_r = np.random.random()\n        if  rand_r < 0.25:\n            dn = np.random.randint(15,size=1)[0]+1\n            images[i] = random_crop(images[i],dn)\n\n        elif rand_r >= 0.25 and rand_r < 0.5:\n            dn = np.random.randint(15,size=1)[0]+1\n            images[i] = random_crop_black(images[i],dn)\n\n        elif rand_r >= 0.5 and rand_r < 0.75:\n            dn = np.random.randint(15,size=1)[0]+1\n            images[i] = random_crop_white(images[i],dn)\n\n        \n        if np.random.random() > 0.3:\n            images[i] = tf.contrib.keras.preprocessing.image.random_zoom(images[i], [0.8,1.2], row_axis=0, col_axis=1, channel_axis=2)\n        \n    return images\n\n\ndef data_generator_reg(X,Y,batch_size):\n\n    while True:\n        idxs = np.random.permutation(len(X))\n        X = X[idxs]\n        Y = Y[idxs]\n        p,q = [],[]\n        for i in range(len(X)):\n            p.append(X[i])\n            q.append(Y[i])\n            if len(p) == batch_size:\n                yield augment_data(np.array(p)),np.array(q)\n                p,q = [],[]\n        if p:\n            yield augment_data(np.array(p)),np.array(q)\n            p,q = [],[]\n\ndef data_generator_pose(X,Y,batch_size):\n\n    while True:\n        idxs = np.random.permutation(len(X))\n        X = X[idxs]\n        Y = Y[idxs]\n        p,q = [],[]\n        for i in range(len(X)):\n            p.append(X[i])\n            q.append(Y[i])\n            if len(p) == batch_size:\n                yield augment_data(np.array(p)),np.array(q)\n                p,q = [],[]\n        if p:\n            yield augment_data(np.array(p)),np.array(q)\n            p,q = [],[]\n\n\ndef data_generator_pose_pure(X,Y,batch_size):\n\n    while True:\n        idxs = np.random.permutation(len(X))\n        X = X[idxs]\n        Y = Y[idxs]\n        p,q = [],[]\n        for i in range(len(X)):\n            p.append(X[i])\n            q.append(Y[i])\n            if len(p) == batch_size:\n                yield (np.array(p)),np.array(q)\n                p,q = [],[]\n        if p:\n            yield (np.array(p)),np.array(q)\n            p,q = [],[]\n\n\ndef data_generator_pose_ms2(X,Y,batch_size):\n\n    Y1 = Y[0]\n    Y2 = Y[1]\n    while True:\n        idxs = np.random.permutation(len(X))\n        X = X[idxs]\n        Y1 = Y1[idxs]\n        Y2 = Y2[idxs]\n        p,q1,q2 = [],[],[]\n        for i in range(len(X)):\n            p.append(X[i])\n            q1.append(Y1[i])\n            q2.append(Y2[i])\n            if len(p) == batch_size:\n                yield augment_data(np.array(p)),[np.array(q1),np.array(q2)]\n                p,q1,q2 = [],[],[]\n        if p:\n            yield augment_data(np.array(p)),[np.array(q1),np.array(q2)]\n            p,q1,q2 = [],[],[]\n\n\ndef data_generator_pose_ms3(X,Y,batch_size):\n\n    Y1 = Y[0]\n    Y2 = Y[1]\n    Y3 = Y[2]\n    while True:\n        idxs = np.random.permutation(len(X))\n        X = X[idxs]\n        Y1 = Y1[idxs]\n        Y2 = Y2[idxs]\n        Y3 = Y3[idxs]\n        p,q1,q2,q3 = [],[],[],[]\n        for i in range(len(X)):\n            p.append(X[i])\n            q1.append(Y1[i])\n            q2.append(Y2[i])\n            q3.append(Y3[i])\n            if len(p) == batch_size:\n                yield augment_data(np.array(p)),[np.array(q1),np.array(q2),np.array(q3)]\n                p,q1,q2,q3 = [],[],[],[]\n        if p:\n            yield augment_data(np.array(p)),[np.array(q1),np.array(q2),np.array(q3)]\n            p,q1,q2,q3 = [],[],[],[]\n\ndef data_generator_reg_fft_hr(X,Y,batch_size):\n\n    X1 = X[0]\n    X2 = X[1]\n    Y1 = Y[0]\n    Y2 = Y[1]\n    Y3 = Y[2]\n    while True:\n        idxs = np.random.permutation(len(X1))\n        X1 = X1[idxs]\n        X2 = X2[idxs]\n        Y1 = Y1[idxs]\n        Y2 = Y2[idxs]\n        Y3 = Y3[idxs]\n        p1,p2,q1,q2, q3 = [],[],[],[],[]\n        for i in range(len(X1)):\n            p1.append(X1[i])\n            p2.append(X2[i])\n            q1.append(Y1[i])\n            q2.append(Y2[i])\n            q3.append(Y3[i])\n            if len(p1) == batch_size:\n                yield [augment_data(np.array(p1)),augment_data(np.array(p2))],[np.array(q1),np.array(q2),np.array(q3)]\n                p1,p2,q1,q2, q3 = [],[],[],[],[]\n        if p1:\n            yield [augment_data(np.array(p1)),augment_data(np.array(p2))],[np.array(q1),np.array(q2),np.array(q3)]\n            p1,p2,q1,q2, q3 = [],[],[],[],[]\n\n\n\ndef data_generator_reg_pair(X,Y,batch_size):\n\n    X1 = X[0]\n    X2 = X[1]\n    Y1 = Y[0]\n    Y2 = Y[1]\n    Y3 = Y[2]\n    while True:\n        idxs = np.random.permutation(len(X1))\n        X1 = X1[idxs]\n        X2 = X2[idxs]\n        Y1 = Y1[idxs]\n        Y2 = Y2[idxs]\n        Y3 = Y3[idxs]\n        \n        p1,p2,q1,q2, q3 = [],[],[],[],[]\n        for i in range(len(X1)):\n            p1.append(X1[i])\n            p2.append(X2[i])\n            q1.append(Y1[i])\n            q2.append(Y2[i])\n            q3.append(Y3[i])\n            \n            if len(p1) == batch_size:\n                yield [augment_data(np.array(p1)),np.array(p2)],[np.array(q1),np.array(q2),np.array(q3)]\n                p1,p2,q1,q2,q3 = [],[],[],[],[]\n        if p1:\n            yield [augment_data(np.array(p1)),np.array(p2)],[np.array(q1),np.array(q2),np.array(q3)]\n            p1,p2,q1,q2,q3 = [],[],[],[],[]\n\n\n\ndef data_generator_dex(X,Y,batch_size):\n\n    Y1 = Y[0]\n    Y2 = Y[1]\n\n    while True:\n        idxs = np.random.permutation(len(X))\n        X = X[idxs]\n        Y1 = Y1[idxs]\n        Y2 = Y2[idxs]\n        p,q1,q2 = [],[],[]\n        for i in range(len(X)):\n            p.append(X[i])\n            q1.append(Y1[i])\n            q2.append(Y2[i])\n            if len(p) == batch_size:\n                yield augment_data(np.array(p)),[np.array(q1),np.array(q2)]\n                p,q1,q2 = [],[],[]\n        if p:\n            yield augment_data(np.array(p)),[np.array(q1),np.array(q2)]\n            p,q1,q2 = [],[],[]\n\ndef data_generator_dex_centerloss(X,Y,batch_size):\n    X1 = X[0]\n    X2 = X[1]\n    Y1 = Y[0]\n    Y2 = Y[1]\n    Y3 = Y[2]\n    while True:\n        idxs = np.random.permutation(len(X1))\n        X1 = X1[idxs] #images\n        X2 = X2[idxs] #labels for center loss\n        Y1 = Y1[idxs]\n        Y2 = Y2[idxs]\n        Y3 = Y3[idxs]\n        p1,p2,q1,q2,q3 = [],[],[],[],[]\n        for i in range(len(X1)):\n            p1.append(X1[i])\n            p2.append(X2[i])\n            q1.append(Y1[i])\n            q2.append(Y2[i])\n            q3.append(Y3[i])\n            if len(p1) == batch_size:\n                yield [augment_data(np.array(p1)),np.array(p2)],[np.array(q1),np.array(q2),np.array(q3)]\n                p1,p2,q1,q2,q3 = [],[],[],[],[]\n        if p1:\n            yield [augment_data(np.array(p1)),np.array(p2)],[np.array(q1),np.array(q2),np.array(q3)]\n            p1,p2,q1,q2,q3 = [],[],[],[],[]\n'"
training_and_testing/keras_to_tf.py,3,"b'import re\nimport os\nimport sys\nimport importlib\nimport argparse\nsys.path.append(\'..\')\n\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom tensorflow.python.framework.graph_util import convert_variables_to_constants\nfrom lib.FSANET_model import *\n\ndef freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n\n    graph = session.graph\n    with graph.as_default():\n        freeze_var_names = list(\n            set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n        output_names = output_names or []\n        output_names += [v.op.name for v in tf.global_variables()]\n        # Graph -> GraphDef ProtoBuf\n        input_graph_def = graph.as_graph_def()\n        if clear_devices:\n            for node in input_graph_def.node:\n                node.device = """"\n        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n                                                      output_names, freeze_var_names)\n        return frozen_graph\n\n\ndef class_for_name(module_name, class_name):\n    # load the module, will raise ImportError if module cannot be loaded\n    m = importlib.import_module(module_name)\n    # get the class, will raise AttributeError if class cannot be found\n    c = getattr(m, class_name)\n    return c\n\n\ndef build_model_class_from_name(model_name):\n\n    is_var_model = ""var"" in model_name\n    is_noS_model = ""noS"" in model_name\n    is_capsule_model = ""capsule"" in model_name\n    is_netvlad_model = ""netvlad"" in model_name\n    is_metric_model = ""metric"" in model_name\n\n    model_class_name = f""FSA_net_""\n    if is_capsule_model:\n        if is_var_model:\n            model_class_name = model_class_name + ""Var_Capsule""\n        elif is_noS_model:\n            model_class_name = model_class_name + ""noS_Capsule""\n        else:\n            model_class_name = model_class_name + ""Capsule""\n\n    if is_netvlad_model:\n        if is_var_model:\n            model_class_name = model_class_name + ""Var_NetVLAD""\n        elif is_noS_model:\n            model_class_name = model_class_name + ""noS_NetVLAD""\n        else:\n            model_class_name = model_class_name + ""NetVLAD""\n\n    if is_metric_model:\n        if is_var_model:\n            model_class_name = model_class_name + ""Var_Metric""\n        elif is_noS_model:\n            model_class_name = model_class_name + ""noS_Metric""\n        else:\n            model_class_name = model_class_name + ""Metric""\n\n    return model_class_name\n\n\ndef create_model(model_name, model_class_name):\n    """""" Since the archived models have lambda layers in them\n    we need to first load them using the new model definitions.\n    The load will be successful as I have preserved the names of the trainable layers.\n    After that we do need to save it so that it has custom layers and then we load it back again """"""\n\n    # we will use the name of the directory to dynamically create the corresponding\n    # class and the hyper-parameters (which thankfully are encoded in the name of the directory)\n\n    model_cls = class_for_name(""lib"", model_class_name)\n\n    hparams_start_loc = re.search(""\\d"", model_name).start()\n    hprams_str = model_name[hparams_start_loc:]\n\n    # now split it by \'_\' and cast it as int\n    hparams = [int(d) for d in hprams_str.split(\'_\')]\n\n    # static params\n    stage_num = [3, 3, 3]\n    lambda_d = 1\n    num_classes = 3\n    image_size = 64\n\n    # now create the model object\n    model_obj = model_cls(image_size, num_classes,\n                          stage_num, lambda_d, hparams)()\n\n    model_obj.count_params()\n    model_obj.summary()\n\n    return model_obj\n\n\ndef parse_arguments(argv):\n    """""" Parse the arguments """"""\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \'--trained-model-dir-path\',\n        required=True,\n        type=str,\n        help=\'The directory that contains the pre-trained model\')\n\n    parser.add_argument(\n        \'--output-dir-path\',\n        required=True,\n        type=str,\n        help=\'The directory that would contain the converted models\')\n\n    return parser.parse_args(argv)\n\n\ndef main(args):\n\n    model_name = os.path.basename(args.trained_model_dir_path)\n\n    # convert existing model with lambda layers to\n    # new model with custom layers\n    model_cls_name = build_model_class_from_name(model_name)\n\n    model_obj = create_model(model_name, model_cls_name)\n    # need to load the weights first\n    model_obj.load_weights(os.path.join(\n        args.trained_model_dir_path, model_name + "".h5""))\n\n    # we now save it in the temp folder\n    # this version will now be saved with the custom layer information\n    # serialized\n    converted_keras_model_dir = os.path.join(args.output_dir_path,\n                                             ""converted-models"", ""keras"")\n\n    os.makedirs(converted_keras_model_dir, exist_ok=True)\n\n    keras_model_path = os.path.join(\n        converted_keras_model_dir, model_name) + "".hd5""\n\n    model_obj.save(keras_model_path)\n\n    # Do the session clearing and creation first\n    K.clear_session()\n    sess = K.get_session()\n    K.set_learning_phase(0)\n\n    # Load it back\n    model = load_model(keras_model_path)\n\n    print(f""Model inputs information - {model.inputs}"")\n    print(f""Model outputs information - {model.outputs}"")\n\n    # freez the graph\n    frozen_graph = freeze_session(sess,\n                                  output_names=[out.op.name for out in model.outputs])\n\n    tf_dir_path = os.path.join(args.output_dir_path, ""converted-models"", ""tf"")\n    os.makedirs(tf_dir_path, exist_ok=True)\n\n    # write the graph\n    tf.io.write_graph(frozen_graph, tf_dir_path,\n                      f""{model_name}.pb"", as_text=False)\n\n\nif __name__ == \'__main__\':\n    main(parse_arguments(sys.argv[1:]))'"
data/type1/TYY_create_db_type1.py,0,"b'import scipy.io as sio\nimport pandas as pd\nfrom os import listdir\nfrom os.path import isfile, join\nfrom tqdm import tqdm\nimport sys\nimport cv2\nfrom moviepy.editor import *\nimport numpy as np\nimport argparse\n\n\ndef get_args():\n\tparser = argparse.ArgumentParser(description=""This script cleans-up noisy labels ""\n\t                                             ""and creates database for training."",\n\t                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\tparser.add_argument(""--db"", type=str, default=\'./AFW\',\n\t                    help=""path to database"")\n\tparser.add_argument(""--output"", type=str, default=\'./AFW.npz\',\n\t                    help=""path to output database mat file"")\n\tparser.add_argument(""--img_size"", type=int, default=64,\n\t                    help=""output image size"")\n\tparser.add_argument(""--ad"", type=float, default=0.6,\n\t                    help=""enlarge margin"")\n\n\n\targs = parser.parse_args()\n\treturn args\n\n\ndef main():\n\targs = get_args()\n\tmypath = args.db\n\toutput_path = args.output\n\timg_size = args.img_size\n\tad = args.ad\n\n\tisPlot = False\n\n\tonlyfiles_mat = [f for f in listdir(mypath) if isfile(join(mypath, f)) and join(mypath, f).endswith(\'.mat\')]\n\tonlyfiles_jpg = [f for f in listdir(mypath) if isfile(join(mypath, f)) and join(mypath, f).endswith(\'.jpg\')]\n\t\n\tonlyfiles_mat.sort()\n\tonlyfiles_jpg.sort()\n\tprint(len(onlyfiles_jpg))\n\tprint(len(onlyfiles_mat))\n\tout_imgs = []\n\tout_poses = []\n\n\tfor i in tqdm(range(len(onlyfiles_jpg))):\n\t\timg_name = onlyfiles_jpg[i]\n\t\tmat_name = onlyfiles_mat[i]\n\n\t\timg_name_split = img_name.split(\'.\')\n\t\tmat_name_split = mat_name.split(\'.\')\n\n\t\tif img_name_split[0] != mat_name_split[0]:\n\t\t\tprint(\'Mismatched!\')\n\t\t\tsys.exit()\n\n\t\tmat_contents = sio.loadmat(mypath + \'/\' + mat_name)\n\t\tpose_para = mat_contents[\'Pose_Para\'][0]\n\t\tpt2d = mat_contents[\'pt2d\']\n\t\t\n\t\tpt2d_x = pt2d[0,:]\n\t\tpt2d_y = pt2d[1,:]\n\n\t\t# I found negative value in AFLW2000. It need to be removed.\n\t\tpt2d_idx = pt2d_x>0.0\n\t\tpt2d_idy= pt2d_y>0.0\n\n\t\tpt2d_id = pt2d_idx\n\t\tif sum(pt2d_idx) > sum(pt2d_idy):\n\t\t\tpt2d_id = pt2d_idy\n\t\t\n\t\tpt2d_x = pt2d_x[pt2d_id]\n\t\tpt2d_y = pt2d_y[pt2d_id]\n\t\t\n\t\timg = cv2.imread(mypath+\'/\'+img_name)\n\t\timg_h = img.shape[0]\n\t\timg_w = img.shape[1]\n\n\t\t# Crop the face loosely\n\t\tx_min = int(min(pt2d_x))\n\t\tx_max = int(max(pt2d_x))\n\t\ty_min = int(min(pt2d_y))\n\t\ty_max = int(max(pt2d_y))\n\t\t\n\t\th = y_max-y_min\n\t\tw = x_max-x_min\n\n\t\t# ad = 0.4\n\t\tx_min = max(int(x_min - ad * w), 0)\n\t\tx_max = min(int(x_max + ad * w), img_w - 1)\n\t\ty_min = max(int(y_min - ad * h), 0)\n\t\ty_max = min(int(y_max + ad * h), img_h - 1)\n\t\t\n\t\timg = img[y_min:y_max,x_min:x_max]\n\t\t# Checking the cropped image\n\t\tif isPlot:\n\t\t\tcv2.imshow(\'check\',img)\n\t\t\tk=cv2.waitKey(500)\n\n\t\timg = cv2.resize(img, (img_size, img_size))\n\t\t\n\t\t\n\n\t\tpitch = pose_para[0] * 180 / np.pi\n\t\tyaw = pose_para[1] * 180 / np.pi\n\t\troll = pose_para[2] * 180 / np.pi\n\n\t\tcont_labels = np.array([yaw, pitch, roll])\n\n\t\tout_imgs.append(img)\n\t\tout_poses.append(cont_labels)\n\n\tnp.savez(output_path,image=np.array(out_imgs), pose=np.array(out_poses), img_size=img_size)\n\n\nif __name__ == \'__main__\':\n\tmain()'"
lib/old_version/FSANET_model.py,85,"b'import logging\nimport sys\nimport numpy as np\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.layers.convolutional import Conv2D, AveragePooling2D, MaxPooling2D, SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.optimizers import SGD,Adam\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.utils import plot_model\nfrom keras.engine.topology import Layer\nfrom keras import activations, initializers, regularizers, constraints\nimport tensorflow as tf\nfrom capsulelayers import *\n\nfrom keras.layers.advanced_activations import PReLU\nfrom utils import get_initial_weights\nfrom keras.layers.recurrent import *\nfrom keras.layers.wrappers import *\nimport loupe_keras as lpk\n\n\nsys.setrecursionlimit(2 ** 20)\nnp.random.seed(2 ** 10)\n\n\nclass SSR_net:\n    def __init__(self, image_size,stage_num,lambda_local,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n\n        self.stage_num = stage_num\n        self.lambda_local = lambda_local\n        self.lambda_d = lambda_d\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n\n        inputs = Input(shape=self._input_shape)\n\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = Conv2D(32,(3,3))(inputs)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer1)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer2)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer3)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = Conv2D(16,(3,3))(inputs)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer1)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer2)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer3)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        \n\n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(10,(1,1),activation=\'relu\')(s)\n        s_layer4 = Flatten()(s_layer4)\n        s_layer4_mix = Dropout(0.2)(s_layer4)\n        s_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(s_layer4_mix)\n        \n        x_layer4 = Conv2D(10,(1,1),activation=\'relu\')(x)\n        x_layer4 = Flatten()(x_layer4)\n        x_layer4_mix = Dropout(0.2)(x_layer4)\n        x_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(x_layer4_mix)\n        \n        feat_a_s1_pre = Multiply()([s_layer4,x_layer4])\n        delta_s1 = Dense(1,activation=\'tanh\',name=\'delta_s1\')(feat_a_s1_pre)\n        \n        feat_a_s1 = Multiply()([s_layer4_mix,x_layer4_mix])\n        feat_a_s1 = Dense(2*self.stage_num[0],activation=\'relu\')(feat_a_s1)\n        pred_a_s1 = Dense(units=self.stage_num[0], activation=""relu"",name=\'pred_age_stage1\')(feat_a_s1)\n        #feat_local_s1 = Lambda(lambda x: x/10)(feat_a_s1)\n        #feat_a_s1_local = Dropout(0.2)(pred_a_s1)\n        local_s1 = Dense(units=self.stage_num[0], activation=\'tanh\', name=\'local_delta_stage1\')(feat_a_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(10,(1,1),activation=\'relu\')(s_layer2)\n        s_layer2 = MaxPooling2D(4,4)(s_layer2)\n        s_layer2 = Flatten()(s_layer2)\n        s_layer2_mix = Dropout(0.2)(s_layer2)\n        s_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(s_layer2_mix)\n        \n        x_layer2 = Conv2D(10,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D(4,4)(x_layer2)\n        x_layer2 = Flatten()(x_layer2)\n        x_layer2_mix = Dropout(0.2)(x_layer2)\n        x_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(x_layer2_mix)\n        \n        feat_a_s2_pre = Multiply()([s_layer2,x_layer2])\n        delta_s2 = Dense(1,activation=\'tanh\',name=\'delta_s2\')(feat_a_s2_pre)\n        \n        feat_a_s2 = Multiply()([s_layer2_mix,x_layer2_mix])\n        feat_a_s2 = Dense(2*self.stage_num[1],activation=\'relu\')(feat_a_s2)\n        pred_a_s2 = Dense(units=self.stage_num[1], activation=""relu"",name=\'pred_age_stage2\')(feat_a_s2)\n        #feat_local_s2 = Lambda(lambda x: x/10)(feat_a_s2)\n        #feat_a_s2_local = Dropout(0.2)(pred_a_s2)\n        local_s2 = Dense(units=self.stage_num[1], activation=\'tanh\', name=\'local_delta_stage2\')(feat_a_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer1 = Conv2D(10,(1,1),activation=\'relu\')(s_layer1)\n        s_layer1 = MaxPooling2D(8,8)(s_layer1)\n        s_layer1 = Flatten()(s_layer1)\n        s_layer1_mix = Dropout(0.2)(s_layer1)\n        s_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(s_layer1_mix)\n        \n        x_layer1 = Conv2D(10,(1,1),activation=\'relu\')(x_layer1)\n        x_layer1 = AveragePooling2D(8,8)(x_layer1)\n        x_layer1 = Flatten()(x_layer1)\n        x_layer1_mix = Dropout(0.2)(x_layer1)\n        x_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(x_layer1_mix)\n\n        feat_a_s3_pre = Multiply()([s_layer1,x_layer1])\n        delta_s3 = Dense(1,activation=\'tanh\',name=\'delta_s3\')(feat_a_s3_pre)\n        \n        feat_a_s3 = Multiply()([s_layer1_mix,x_layer1_mix])\n        feat_a_s3 = Dense(2*self.stage_num[2],activation=\'relu\')(feat_a_s3)\n        pred_a_s3 = Dense(units=self.stage_num[2], activation=""relu"",name=\'pred_age_stage3\')(feat_a_s3)\n        #feat_local_s3 = Lambda(lambda x: x/10)(feat_a_s3)\n        #feat_a_s3_local = Dropout(0.2)(pred_a_s3)\n        local_s3 = Dense(units=self.stage_num[2], activation=\'tanh\', name=\'local_delta_stage3\')(feat_a_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n        \n        def merge_age(x,s1,s2,s3,lambda_local,lambda_d):\n            a = x[0][:,0]*0\n            b = x[0][:,0]*0\n            c = x[0][:,0]*0\n            A = s1*s2*s3\n            V = 101\n\n            for i in range(0,s1):\n                a = a+(i+lambda_local*x[6][:,i])*x[0][:,i]\n            a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j+lambda_local*x[7][:,j])*x[1][:,j]\n            b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k+lambda_local*x[8][:,k])*x[2][:,k]\n            c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n\n            age = (a+b+c)*V\n            return age\n        \n        pred_a = Lambda(merge_age,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_local\':self.lambda_local,\'lambda_d\':self.lambda_d},name=\'pred_a\')([pred_a_s1,pred_a_s2,pred_a_s3,delta_s1,delta_s2,delta_s3, local_s1, local_s2, local_s3])\n\n        model = Model(inputs=inputs, outputs=pred_a)\n\n        return model\nclass SSR_net_general:\n    def __init__(self, image_size,stage_num,lambda_local,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n\n        self.stage_num = stage_num\n        self.lambda_local = lambda_local\n        self.lambda_d = lambda_d\n\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n\n        inputs = Input(shape=self._input_shape)\n\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = Conv2D(32,(3,3))(inputs)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer1)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer2)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3))(x_layer3)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = Conv2D(16,(3,3))(inputs)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer1)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer2)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3))(s_layer3)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        \n\n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(10,(1,1),activation=\'relu\')(s)\n        s_layer4 = Flatten()(s_layer4)\n        s_layer4_mix = Dropout(0.2)(s_layer4)\n        s_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(s_layer4_mix)\n        \n        x_layer4 = Conv2D(10,(1,1),activation=\'relu\')(x)\n        x_layer4 = Flatten()(x_layer4)\n        x_layer4_mix = Dropout(0.2)(x_layer4)\n        x_layer4_mix = Dense(units=self.stage_num[0], activation=""relu"")(x_layer4_mix)\n        \n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        delta_s1 = Dense(1,activation=\'tanh\',name=\'delta_s1\')(feat_s1_pre)\n        \n        feat_s1 = Multiply()([s_layer4_mix,x_layer4_mix])\n        feat_s1 = Dense(2*self.stage_num[0],activation=\'relu\')(feat_s1)\n        pred_s1 = Dense(units=self.stage_num[0], activation=""relu"",name=\'pred_stage1\')(feat_s1)\n        local_s1 = Dense(units=self.stage_num[0], activation=\'tanh\', name=\'local_delta_stage1\')(feat_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(10,(1,1),activation=\'relu\')(s_layer2)\n        s_layer2 = MaxPooling2D(4,4)(s_layer2)\n        s_layer2 = Flatten()(s_layer2)\n        s_layer2_mix = Dropout(0.2)(s_layer2)\n        s_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(s_layer2_mix)\n        \n        x_layer2 = Conv2D(10,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D(4,4)(x_layer2)\n        x_layer2 = Flatten()(x_layer2)\n        x_layer2_mix = Dropout(0.2)(x_layer2)\n        x_layer2_mix = Dense(self.stage_num[1],activation=\'relu\')(x_layer2_mix)\n        \n        feat_s2_pre = Multiply()([s_layer2,x_layer2])\n        delta_s2 = Dense(1,activation=\'tanh\',name=\'delta_s2\')(feat_s2_pre)\n        \n        feat_s2 = Multiply()([s_layer2_mix,x_layer2_mix])\n        feat_s2 = Dense(2*self.stage_num[1],activation=\'relu\')(feat_s2)\n        pred_s2 = Dense(units=self.stage_num[1], activation=""relu"",name=\'pred_stage2\')(feat_s2)\n        local_s2 = Dense(units=self.stage_num[1], activation=\'tanh\', name=\'local_delta_stage2\')(feat_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer1 = Conv2D(10,(1,1),activation=\'relu\')(s_layer1)\n        s_layer1 = MaxPooling2D(8,8)(s_layer1)\n        s_layer1 = Flatten()(s_layer1)\n        s_layer1_mix = Dropout(0.2)(s_layer1)\n        s_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(s_layer1_mix)\n        \n        x_layer1 = Conv2D(10,(1,1),activation=\'relu\')(x_layer1)\n        x_layer1 = AveragePooling2D(8,8)(x_layer1)\n        x_layer1 = Flatten()(x_layer1)\n        x_layer1_mix = Dropout(0.2)(x_layer1)\n        x_layer1_mix = Dense(self.stage_num[2],activation=\'relu\')(x_layer1_mix)\n\n        feat_s3_pre = Multiply()([s_layer1,x_layer1])\n        delta_s3 = Dense(1,activation=\'tanh\',name=\'delta_s3\')(feat_s3_pre)\n        \n        feat_s3 = Multiply()([s_layer1_mix,x_layer1_mix])\n        feat_s3 = Dense(2*self.stage_num[2],activation=\'relu\')(feat_s3)\n        pred_s3 = Dense(units=self.stage_num[2], activation=""relu"",name=\'pred_stage3\')(feat_s3)\n        local_s3 = Dense(units=self.stage_num[2], activation=\'tanh\', name=\'local_delta_stage3\')(feat_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n        \n        def SSR_module(x,s1,s2,s3,lambda_local,lambda_d):\n            a = x[0][:,0]*0\n            b = x[0][:,0]*0\n            c = x[0][:,0]*0\n            V = 1\n\n            for i in range(0,s1):\n                a = a+(i+lambda_local*x[6][:,i])*x[0][:,i]\n            a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j+lambda_local*x[7][:,j])*x[1][:,j]\n            b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k+lambda_local*x[8][:,k])*x[2][:,k]\n            c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n\n            out = (a+b+c)*V\n            return out\n        \n        pred = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_local\':self.lambda_local,\'lambda_d\':self.lambda_d},name=\'pred\')([pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3, local_s1, local_s2, local_s3])\n\n        model = Model(inputs=inputs, outputs=pred)\n\n        return model\nclass SSR_net_MT:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D((2,2))(x)\n        x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D((2,2))(x)\n        x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D((2,2))(x)\n        x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n        x = BatchNormalization(axis=-1)(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n        x = BatchNormalization(axis=-1)(x)\n        x_layer4 = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D((2,2))(s)\n        s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D((2,2))(s)\n        s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D((2,2))(s)\n        s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n        s = BatchNormalization(axis=-1)(s)\n        s = Activation(\'tanh\')(s)\n        s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n        s = BatchNormalization(axis=-1)(s)\n        s_layer4 = Activation(\'tanh\')(s)\n\n\n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n        s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n        x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n        x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        feat_s1_pre = Flatten()(feat_s1_pre)\n        feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n        feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n        feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_s1_pre) \n        pred_a_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n        s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n        x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n        x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n        feat_s2_pre = Multiply()([s_layer3,x_layer3])\n        feat_s2_pre  = Flatten()(feat_s2_pre)\n        feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n        feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n        feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_s2_pre) \n        pred_a_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n        s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n        x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n        feat_s3_pre = Multiply()([s_layer2,x_layer2])\n        feat_s3_pre  = Flatten()(feat_s3_pre)\n        feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n        feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n        feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_s3_pre) \n        pred_a_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            # a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            # b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            # c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')([pred_a_s1,pred_a_s2,pred_a_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3])\n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n        return model\nclass SSR_net_ori_MT:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        #-------------------------------------------------------------------------------------------------------------------------\n        x = Conv2D(32,(3,3),padding=\'same\')(img_inputs)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer1 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3),padding=\'same\')(x_layer1)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer2 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3),padding=\'same\')(x_layer2)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x = Activation(\'relu\')(x)\n        x_layer3 = AveragePooling2D(2,2)(x)\n        x = Conv2D(32,(3,3),padding=\'same\')(x_layer3)\n        x = BatchNormalization(axis=self._channel_axis)(x)\n        x_layer4 = Activation(\'relu\')(x)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s = Conv2D(16,(3,3),padding=\'same\')(img_inputs)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer1 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3),padding=\'same\')(s_layer1)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer2 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3),padding=\'same\')(s_layer2)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s = Activation(\'tanh\')(s)\n        s_layer3 = MaxPooling2D(2,2)(s)\n        s = Conv2D(16,(3,3),padding=\'same\')(s_layer3)\n        s = BatchNormalization(axis=self._channel_axis)(s)\n        s_layer4 = Activation(\'tanh\')(s)\n        \n        #-------------------------------------------------------------------------------------------------------------------------\n        # Classifier block\n        s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n        s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n        x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n        x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n        feat_s1_pre = Multiply()([s_layer4,x_layer4])\n        feat_s1_pre = Flatten()(feat_s1_pre)\n        feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n        feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s1_pre)\n        local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n        feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_s1_pre) \n        pred_a_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n        s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n        x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n        x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n        feat_s2_pre = Multiply()([s_layer3,x_layer3])\n        feat_s2_pre  = Flatten()(feat_s2_pre)\n        feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n        feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s2_pre)\n        local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n        feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_s2_pre) \n        pred_a_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n        #-------------------------------------------------------------------------------------------------------------------------\n        s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n        s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n        x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n        x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n        feat_s3_pre = Multiply()([s_layer2,x_layer2])\n        feat_s3_pre  = Flatten()(feat_s3_pre)\n        feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n        feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(feat_s3_pre)\n        local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n        feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_s3_pre) \n        pred_a_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            # a = K.expand_dims(a,-1)\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            # b = K.expand_dims(b,-1)\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            # c = K.expand_dims(c,-1)\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')([pred_a_s1,pred_a_s2,pred_a_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3])\n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n        return model\n\n\n\nclass FSA_net_Capsule:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Cap_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(capsule)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(capsule)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(capsule)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Cap_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')            \n            return ssr_Cap_model\n\n        ssr_Cap_model = ssr_Cap_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        #ssr_F_model = ssr_F_model_build(21*64,\'ssr_F_model\')\n        # ssr_F_Cap_model = ssr_F_model_build(int(self.dim_capsule/3)*self.num_capsule,\'ssr_F_model_Cap\')\n        ssr_F_Cap_model = ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_Cap_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_Cap_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_Var_Capsule:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            #feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            def var(x):\n                mean, var = tf.nn.moments(x,axes=-1)\n                return var\n            feat_preS = Lambda(var)(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Cap_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(capsule)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(capsule)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(capsule)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Cap_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')            \n            return ssr_Cap_model\n\n        ssr_Cap_model = ssr_Cap_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        #ssr_F_model = ssr_F_model_build(21*64,\'ssr_F_model\')\n        # ssr_F_Cap_model = ssr_F_model_build(int(self.dim_capsule/3)*self.num_capsule,\'ssr_F_model_Cap\')\n        ssr_F_Cap_model = ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_Cap_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_Cap_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_noS_Capsule:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build():\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            primcaps_s1 = Reshape((8*8,64))(input_s1_preS)\n            primcaps_s2 = Reshape((8*8,64))(input_s2_preS)\n            primcaps_s3 = Reshape((8*8,64))(input_s3_preS)\n\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build()        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Cap_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(capsule)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(capsule)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(capsule)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Cap_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')            \n            return ssr_Cap_model\n\n        ssr_Cap_model = ssr_Cap_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_Cap_model = ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_Cap_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_Cap_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\n\n\n\nclass FSA_net_Capsule_FC:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Cap_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(capsule)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(capsule)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(capsule)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Cap_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')            \n            return ssr_Cap_model\n\n        ssr_Cap_model = ssr_Cap_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(input_s1_pre) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(input_s2_pre) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(input_s3_pre) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        #ssr_F_model = ssr_F_model_build(21*64,\'ssr_F_model\')\n        # ssr_F_Cap_model = ssr_F_model_build(int(self.dim_capsule/3)*self.num_capsule,\'ssr_F_model_Cap\')\n        ssr_F_Cap_model = ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_Cap_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_Cap_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_Var_Capsule_FC:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            #feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            def var(x):\n                mean, var = tf.nn.moments(x,axes=-1)\n                return var\n            feat_preS = Lambda(var)(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Cap_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(capsule)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(capsule)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(capsule)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Cap_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')            \n            return ssr_Cap_model\n\n        ssr_Cap_model = ssr_Cap_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(input_s1_pre) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(input_s2_pre) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(input_s3_pre) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n       \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        #ssr_F_model = ssr_F_model_build(21*64,\'ssr_F_model\')\n        # ssr_F_Cap_model = ssr_F_model_build(int(self.dim_capsule/3)*self.num_capsule,\'ssr_F_model_Cap\')\n        ssr_F_Cap_model = ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_Cap_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_Cap_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_noS_Capsule_FC:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build():\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            primcaps_s1 = Reshape((8*8,64))(input_s1_preS)\n            primcaps_s2 = Reshape((8*8,64))(input_s2_preS)\n            primcaps_s3 = Reshape((8*8,64))(input_s3_preS)\n\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build()        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Cap_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(capsule)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(capsule)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(capsule)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Cap_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Cap_model\')            \n            return ssr_Cap_model\n\n        ssr_Cap_model = ssr_Cap_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(input_s1_pre) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(input_s2_pre) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(input_s3_pre) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n       \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_Cap_model = ssr_F_model_build(self.F_shape,\'ssr_F_Cap_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Cap_list = ssr_Cap_model(ssr_primcaps)\n        ssr_F_Cap_list = ssr_F_Cap_model(ssr_Cap_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_Cap_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\n\n\nclass FSA_net_NetVLAD:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Agg_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            agg_feat = lpk.NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n            agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(agg_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(agg_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(agg_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Agg_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')            \n            return ssr_Agg_model\n\n        ssr_Agg_model = ssr_Agg_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Agg_list = ssr_Agg_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Agg_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_Var_NetVLAD:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n            \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            #feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            def var(x):\n                mean, var = tf.nn.moments(x,axes=-1)\n                return var\n            feat_preS = Lambda(var)(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Agg_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            agg_feat = lpk.NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n            agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(agg_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(agg_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(agg_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Agg_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')            \n            return ssr_Agg_model\n\n        ssr_Agg_model = ssr_Agg_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Agg_list = ssr_Agg_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Agg_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_noS_NetVLAD:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n            \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build():\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            primcaps_s1 = Reshape((8*8,64))(input_s1_preS)\n            primcaps_s2 = Reshape((8*8,64))(input_s2_preS)\n            primcaps_s3 = Reshape((8*8,64))(input_s3_preS)\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build()        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Agg_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            agg_feat = lpk.NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n            agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(agg_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(agg_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(agg_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Agg_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')            \n            return ssr_Agg_model\n\n        ssr_Agg_model = ssr_Agg_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Agg_list = ssr_Agg_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Agg_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\n\n\nclass FSA_net_NetVLAD_FC:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Agg_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            agg_feat = lpk.NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n            agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(agg_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(agg_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(agg_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Agg_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')            \n            return ssr_Agg_model\n\n        ssr_Agg_model = ssr_Agg_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(input_s1_pre) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(input_s2_pre) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(input_s3_pre) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n       \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Agg_list = ssr_Agg_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Agg_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_Var_NetVLAD_FC:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n            \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            #feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            def var(x):\n                mean, var = tf.nn.moments(x,axes=-1)\n                return var\n            feat_preS = Lambda(var)(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Agg_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            agg_feat = lpk.NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n            agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(agg_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(agg_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(agg_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Agg_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')            \n            return ssr_Agg_model\n\n        ssr_Agg_model = ssr_Agg_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(input_s1_pre) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(input_s2_pre) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(input_s3_pre) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n       \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Agg_list = ssr_Agg_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Agg_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_noS_NetVLAD_FC:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n            \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build():\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            primcaps_s1 = Reshape((8*8,64))(input_s1_preS)\n            primcaps_s2 = Reshape((8*8,64))(input_s2_preS)\n            primcaps_s3 = Reshape((8*8,64))(input_s3_preS)\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build()        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Agg_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            agg_feat = lpk.NetVLAD(feature_size=64, max_samples=self.num_primcaps, cluster_size=self.num_capsule, output_dim=self.num_capsule*self.dim_capsule)(input_primcaps)\n            agg_feat = Reshape((self.num_capsule,self.dim_capsule))(agg_feat)\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(agg_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(agg_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(agg_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Agg_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Agg_model\')            \n            return ssr_Agg_model\n\n        ssr_Agg_model = ssr_Agg_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Dense(2*self.num_classes,activation=\'tanh\')(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(input_s1_pre) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Dense(2*self.num_classes,activation=\'tanh\')(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(input_s2_pre) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Dense(2*self.num_classes,activation=\'tanh\')(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(input_s3_pre) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n       \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Agg_list = ssr_Agg_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Agg_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\n\n\nclass FSA_net_Metric:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Metric_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            metric_feat = MatMulLayer(16,type=1)(input_primcaps)\n            metric_feat = MatMulLayer(3,type=2)(metric_feat)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(metric_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(metric_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(metric_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Metric_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Metric_model\')            \n            return ssr_Metric_model\n\n        ssr_Metric_model = ssr_Metric_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Metric_list = ssr_Metric_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Metric_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_Var_Metric:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        def ssr_feat_S_model_build(num_primcaps, m_dim):\n            input_preS = Input((8,8,64))\n\n            #feat_preS = Conv2D(1,(1,1),padding=\'same\',activation=\'sigmoid\')(input_preS)\n            def var(x):\n                mean, var = tf.nn.moments(x,axes=-1)\n                return var\n            feat_preS = Lambda(var)(input_preS)\n            feat_preS = Reshape((-1,))(feat_preS)\n            SR_matrix = Dense(m_dim*(8*8+8*8+8*8),activation=\'sigmoid\')(feat_preS)\n            SR_matrix = Reshape((m_dim,(8*8+8*8+8*8)))(SR_matrix)\n            \n            ssr_feat_S_model = Model(inputs=input_preS,outputs=[SR_matrix,feat_preS],name=\'feat_S_model\')\n            return ssr_feat_S_model\n\n        ssr_feat_S_model = ssr_feat_S_model_build(self.num_primcaps,self.m_dim)  \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build(num_primcaps, m_dim):\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            SR_matrix_s1,feat_s1_preS = ssr_feat_S_model(input_s1_preS)\n            SR_matrix_s2,feat_s2_preS = ssr_feat_S_model(input_s2_preS)\n            SR_matrix_s3,feat_s3_preS = ssr_feat_S_model(input_s3_preS)\n            \n            feat_pre_concat = Concatenate()([feat_s1_preS,feat_s2_preS,feat_s3_preS])\n            SL_matrix = Dense(int(num_primcaps/3)*m_dim,activation=\'sigmoid\')(feat_pre_concat)\n            SL_matrix = Reshape((int(num_primcaps/3),m_dim))(SL_matrix)\n            \n            S_matrix_s1 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s1\')([SL_matrix,SR_matrix_s1])\n            S_matrix_s2 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s2\')([SL_matrix,SR_matrix_s2])\n            S_matrix_s3 = Lambda(lambda x: tf.matmul(x[0],x[1]),name=\'S_matrix_s3\')([SL_matrix,SR_matrix_s3])\n\n            # Very important!!! Without this training won\'t converge.\n            # norm_S = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix)\n            norm_S_s1 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s1)\n            norm_S_s2 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s2)\n            norm_S_s3 = Lambda(lambda x: K.tile(K.sum(x,axis=-1,keepdims=True),(1,1,64)))(S_matrix_s3)\n\n            feat_s1_pre = Reshape((-1,64))(input_s1_preS)\n            feat_s2_pre = Reshape((-1,64))(input_s2_preS)\n            feat_s3_pre = Reshape((-1,64))(input_s3_preS)\n            feat_pre_concat = Concatenate(axis=1)([feat_s1_pre, feat_s2_pre, feat_s3_pre])\n            \n            # Warining: don\'t use keras\'s \'K.dot\'. It is very weird when high dimension is used.\n            # https://github.com/keras-team/keras/issues/9779\n            # Make sure \'tf.matmul\' is used\n            # primcaps = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix,feat_pre_concat, norm_S])\n            primcaps_s1 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s1,feat_pre_concat, norm_S_s1])\n            primcaps_s2 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s2,feat_pre_concat, norm_S_s2])\n            primcaps_s3 = Lambda(lambda x: tf.matmul(x[0],x[1])/x[2])([S_matrix_s3,feat_pre_concat, norm_S_s3])\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build(self.num_primcaps,self.m_dim)        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Metric_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            metric_feat = MatMulLayer(16,type=1)(input_primcaps)\n            metric_feat = MatMulLayer(3,type=2)(metric_feat)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(metric_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(metric_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(metric_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Metric_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Metric_model\')            \n            return ssr_Metric_model\n\n        ssr_Metric_model = ssr_Metric_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Metric_list = ssr_Metric_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Metric_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\nclass FSA_net_noS_Metric:\n    def __init__(self, image_size,num_classes,stage_num,lambda_d, S_set):\n        \n        if K.image_dim_ordering() == ""th"":\n            logging.debug(""image_dim_ordering = \'th\'"")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(""image_dim_ordering = \'tf\'"")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n        self.num_classes = num_classes\n        self.stage_num = stage_num\n        self.lambda_d = lambda_d\n\n        self.num_capsule = S_set[0]\n        self.dim_capsule = S_set[1]\n        self.routings = S_set[2]\n\n        self.num_primcaps = S_set[3]\n        self.m_dim = S_set[4]\n\n        self.F_shape = int(self.num_capsule/3)*self.dim_capsule\n\n        \n    def __call__(self):\n        logging.debug(""Creating model..."")\n\n        img_inputs = Input(self._input_shape)\n        def ssr_G_model_build(img_inputs):\n            #-------------------------------------------------------------------------------------------------------------------------\n            x = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer1 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x_layer1)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(32,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer2 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x_layer2)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(64,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x_layer3 = AveragePooling2D((2,2))(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x_layer3)\n            x = BatchNormalization(axis=-1)(x)\n            x = Activation(\'relu\')(x)\n            x = SeparableConv2D(128,(3,3),padding=\'same\')(x)\n            x = BatchNormalization(axis=-1)(x)\n            x_layer4 = Activation(\'relu\')(x)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s = SeparableConv2D(16,(3,3),padding=\'same\')(img_inputs)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer1 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s_layer1)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(32,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer2 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s_layer2)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(64,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s_layer3 = MaxPooling2D((2,2))(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s_layer3)\n            s = BatchNormalization(axis=-1)(s)\n            s = Activation(\'tanh\')(s)\n            s = SeparableConv2D(128,(3,3),padding=\'same\')(s)\n            s = BatchNormalization(axis=-1)(s)\n            s_layer4 = Activation(\'tanh\')(s)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            s_layer4 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer4)\n            # s_layer4 = MaxPooling2D((2,2))(s_layer4)\n\n            x_layer4 = Conv2D(64,(1,1),activation=\'relu\')(x_layer4)\n            # x_layer4 = AveragePooling2D((2,2))(x_layer4)\n\n            feat_s1_pre = Multiply()([s_layer4,x_layer4])\n            # feat_s1_pre = Flatten()(feat_s1_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer3 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer3)\n            # s_layer3 = MaxPooling2D((2,2))(s_layer3)\n\n            x_layer3 = Conv2D(64,(1,1),activation=\'relu\')(x_layer3)\n            # x_layer3 = AveragePooling2D((2,2))(x_layer3)\n\n            feat_s2_pre = Multiply()([s_layer3,x_layer3])\n            # feat_s2_pre  = Flatten()(feat_s2_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            s_layer2 = Conv2D(64,(1,1),activation=\'tanh\')(s_layer2)\n            # s_layer2 = MaxPooling2D((2,2))(s_layer2)\n\n            x_layer2 = Conv2D(64,(1,1),activation=\'relu\')(x_layer2)\n            # x_layer2 = AveragePooling2D((2,2))(x_layer2)\n\n            feat_s3_pre = Multiply()([s_layer2,x_layer2])\n            # feat_s3_pre  = Flatten()(feat_s3_pre)\n            #-------------------------------------------------------------------------------------------------------------------------\n            \n            # Spatial Pyramid Pooling\n            #feat_s1_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s1_pre)        \n            #feat_s2_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s2_pre)\n            #feat_s3_pre = SpatialPyramidPooling([1, 2, 4],\'average\')(feat_s3_pre)\n            # feat_s1_pre = GlobalAveragePooling2D()(feat_s1_pre)\n            # feat_s2_pre = GlobalAveragePooling2D()(feat_s2_pre)\n            feat_s3_pre = AveragePooling2D((2,2))(feat_s3_pre) # make sure (8x8x64) feature maps \n        \n            ssr_G_model = Model(inputs=img_inputs,outputs=[feat_s1_pre,feat_s2_pre,feat_s3_pre], name=\'ssr_G_model\')\n            return ssr_G_model\n\n        ssr_G_model = ssr_G_model_build(img_inputs)\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_S_model_build():\n            input_s1_preS = Input((8,8,64))\n            input_s2_preS = Input((8,8,64))\n            input_s3_preS = Input((8,8,64))\n\n            primcaps_s1 = Reshape((8*8,64))(input_s1_preS)\n            primcaps_s2 = Reshape((8*8,64))(input_s2_preS)\n            primcaps_s3 = Reshape((8*8,64))(input_s3_preS)\n\n            primcaps = Concatenate(axis=1)([primcaps_s1,primcaps_s2,primcaps_s3])\n\n            ssr_S_model = Model(inputs=[input_s1_preS, input_s2_preS, input_s3_preS],outputs=primcaps, name=\'ssr_S_model\')\n            return ssr_S_model\n        \n        ssr_S_model = ssr_S_model_build()        \n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_Metric_model_build(shape_primcaps):\n            input_primcaps = Input(shape_primcaps)\n\n            #capsule = CapsuleLayer(self.num_capsule, self.dim_capsule, self.routings, name=\'caps\')(input_primcaps)\n            metric_feat = MatMulLayer(16,type=1)(input_primcaps)\n            metric_feat = MatMulLayer(3,type=2)(metric_feat)\n\n\n            s1_a = 0\n            s1_b = self.num_capsule//3\n            feat_s1_div = Lambda(lambda x: x[:,s1_a:s1_b,:])(metric_feat)\n            s2_a = self.num_capsule//3\n            s2_b = 2*self.num_capsule//3\n            feat_s2_div = Lambda(lambda x: x[:,s2_a:s2_b,:])(metric_feat)\n            s3_a = 2*self.num_capsule//3\n            s3_b = self.num_capsule\n            feat_s3_div = Lambda(lambda x: x[:,s3_a:s3_b,:])(metric_feat)\n\n\n            feat_s1_div = Reshape((-1,))(feat_s1_div)\n            feat_s2_div = Reshape((-1,))(feat_s2_div)\n            feat_s3_div = Reshape((-1,))(feat_s3_div)\n            \n            ssr_Metric_model = Model(inputs=input_primcaps,outputs=[feat_s1_div,feat_s2_div,feat_s3_div], name=\'ssr_Metric_model\')            \n            return ssr_Metric_model\n\n        ssr_Metric_model = ssr_Metric_model_build((self.num_primcaps,64))\n        #-------------------------------------------------------------------------------------------------------------------------\n        def ssr_F_model_build(feat_dim, name_F):\n            input_s1_pre = Input((feat_dim,))\n            input_s2_pre = Input((feat_dim,))\n            input_s3_pre = Input((feat_dim,))\n\n            feat_delta_s1 = Lambda(lambda x: x[:,0:4])(input_s1_pre)\n            delta_s1 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s1\')(feat_delta_s1)\n\n            feat_local_s1 = Lambda(lambda x: x[:,4:8])(input_s1_pre)\n            local_s1 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage1\')(feat_local_s1)\n\n            feat_pred_s1 = Lambda(lambda x: x[:,8:16])(input_s1_pre)\n            feat_pred_s1 = Dense(self.stage_num[0]*self.num_classes,activation=\'relu\')(feat_pred_s1) \n            pred_s1 = Reshape((self.num_classes,self.stage_num[0]))(feat_pred_s1)\n            \n\n            feat_delta_s2 = Lambda(lambda x: x[:,0:4])(input_s2_pre)\n            delta_s2 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s2\')(feat_delta_s2)\n\n            feat_local_s2 = Lambda(lambda x: x[:,4:8])(input_s2_pre)\n            local_s2 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage2\')(feat_local_s2)\n\n            feat_pred_s2 = Lambda(lambda x: x[:,8:16])(input_s2_pre)\n            feat_pred_s2 = Dense(self.stage_num[1]*self.num_classes,activation=\'relu\')(feat_pred_s2) \n            pred_s2 = Reshape((self.num_classes,self.stage_num[1]))(feat_pred_s2)\n            \n\n            feat_delta_s3 = Lambda(lambda x: x[:,0:4])(input_s3_pre)\n            delta_s3 = Dense(self.num_classes,activation=\'tanh\',name=\'delta_s3\')(feat_delta_s3)\n\n            feat_local_s3 = Lambda(lambda x: x[:,4:8])(input_s3_pre)\n            local_s3 = Dense(units=self.num_classes, activation=\'tanh\', name=\'local_delta_stage3\')(feat_local_s3)\n\n            feat_pred_s3 = Lambda(lambda x: x[:,8:16])(input_s3_pre)\n            feat_pred_s3 = Dense(self.stage_num[2]*self.num_classes,activation=\'relu\')(feat_pred_s3) \n            pred_s3 = Reshape((self.num_classes,self.stage_num[2]))(feat_pred_s3)\n        \n            ssr_F_model = Model(inputs=[input_s1_pre,input_s2_pre,input_s3_pre],outputs=[pred_s1,pred_s2,pred_s3,delta_s1,delta_s2,delta_s3,local_s1,local_s2,local_s3], name=name_F)\n            return ssr_F_model\n        \n        ssr_F_model = ssr_F_model_build(self.F_shape,\'ssr_F_model\')\n        #-------------------------------------------------------------------------------------------------------------------------\n\n        def SSR_module(x,s1,s2,s3,lambda_d):\n            a = x[0][:,:,0]*0\n            b = x[0][:,:,0]*0\n            c = x[0][:,:,0]*0\n\n            di = s1//2\n            dj = s2//2\n            dk = s3//2\n\n            V = 99\n            #lambda_d = 0.9\n\n            for i in range(0,s1):\n                a = a+(i-di+x[6])*x[0][:,:,i]\n            a = a/(s1*(1+lambda_d*x[3]))\n\n            for j in range(0,s2):\n                b = b+(j-dj+x[7])*x[1][:,:,j]\n            b = b/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))\n\n            for k in range(0,s3):\n                c = c+(k-dk+x[8])*x[2][:,:,k]\n            c = c/(s1*(1+lambda_d*x[3]))/(s2*(1+lambda_d*x[4]))/(s3*(1+lambda_d*x[5]))\n\n            pred = (a+b+c)*V\n            \n            return pred\n\n        ssr_G_list = ssr_G_model(img_inputs)\n        ssr_primcaps = ssr_S_model(ssr_G_list)\n        ssr_Metric_list = ssr_Metric_model(ssr_primcaps)\n        ssr_F_list = ssr_F_model(ssr_Metric_list)\n        pred_pose = Lambda(SSR_module,arguments={\'s1\':self.stage_num[0],\'s2\':self.stage_num[1],\'s3\':self.stage_num[2],\'lambda_d\':self.lambda_d},name=\'pred_pose\')(ssr_F_list)\n        \n\n\n        model = Model(inputs=img_inputs, outputs=pred_pose)\n\n\n        return model\n\n\n\n'"
pre-trained/BIWI_models/plot.py,0,"b'import pandas as pd\nimport matplotlib.pyplot as plt\nimport argparse\nimport os\nimport numpy as np\n\n\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=""This script shows training graph from history file."")\n    parser.add_argument(""--input"", ""-i"", type=str, required=True,\n                        help=""path to input history h5 file"")\n    args = parser.parse_args()\n    return args\n\n\ndef main():\n    args = get_args()\n    input_path = args.input\n\n    df = pd.read_hdf(input_path, ""history"")\n    print(df[30:60])\n\n    print(np.min(df[\'val_loss\']))\n    # input_dir = os.path.dirname(input_path)\n    # plt.plot(df[""loss""], \'-o\', label=""loss (age)"", linewidth=2.0)\n    # plt.plot(df[""val_loss""], \'-o\', label=""val_loss (age)"", linewidth=2.0)\n    # plt.xlabel(""Number of epochs"", fontsize=20)\n    # plt.ylabel(""Loss"", fontsize=20)\n    # plt.legend()\n    # plt.grid()\n    # plt.savefig(os.path.join(input_dir, ""loss.pdf""), bbox_inches=\'tight\', pad_inches=0)\n    # plt.cla()\n\n    # plt.plot(df[""mean_absolute_error""], \'-o\', label=""training"", linewidth=2.0)\n    # plt.plot(df[""val_mean_absolute_error""], \'-o\', label=""validation"", linewidth=2.0)\n    # ax = plt.gca()\n    # ax.set_ylim([2,13])\n    # ax.set_aspect(0.6/ax.get_data_ratio())\n    # plt.xticks(fontsize=20)\n    # plt.yticks(fontsize=20)\n    # plt.xlabel(""Number of epochs"", fontsize=20)\n    # plt.ylabel(""Mean absolute error"", fontsize=20)\n    # plt.legend(fontsize=20)\n    # plt.grid()\n    # plt.savefig(os.path.join(input_dir, ""performance.pdf""), bbox_inches=\'tight\', pad_inches=0)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n\n\n\n\n\n\n\n\n'"
