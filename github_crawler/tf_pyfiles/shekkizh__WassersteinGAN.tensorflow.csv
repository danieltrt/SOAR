file_path,api_count,code
__init__.py,0,"b""__author__ = 'Charlie'\n"""
main.py,14,"b'from __future__ import print_function\n\n__author__ = ""shekkizh""\n""""""\nTensorflow implementation of Wasserstein GAN\n""""""\nimport numpy as np\nimport tensorflow as tf\nfrom models.GAN_models import *\n\nFLAGS = tf.flags.FLAGS\ntf.flags.DEFINE_integer(""batch_size"", ""64"", ""batch size for training"")\ntf.flags.DEFINE_string(""logs_dir"", ""logs/CelebA_GAN_logs/"", ""path to logs directory"")\ntf.flags.DEFINE_string(""data_dir"", ""Data_zoo/CelebA_faces/"", ""path to dataset"")\ntf.flags.DEFINE_integer(""z_dim"", ""100"", ""size of input vector to generator"")\ntf.flags.DEFINE_float(""learning_rate"", ""2e-4"", ""Learning rate for Adam Optimizer"")\ntf.flags.DEFINE_float(""optimizer_param"", ""0.5"", ""beta1 for Adam optimizer / decay for RMSProp"")\ntf.flags.DEFINE_float(""iterations"", ""1e5"", ""No. of iterations to train model"")\ntf.flags.DEFINE_string(""image_size"", ""108,64"", ""Size of actual images, Size of images to be generated at."")\ntf.flags.DEFINE_integer(""model"", ""0"", ""Model to train. 0 - GAN, 1 - WassersteinGAN"")\ntf.flags.DEFINE_string(""optimizer"", ""Adam"", ""Optimizer to use for training"")\ntf.flags.DEFINE_integer(""gen_dimension"", ""16"", ""dimension of first layer in generator"")\ntf.flags.DEFINE_string(""mode"", ""train"", ""train / visualize model"")\n\n\ndef main(argv=None):\n    gen_dim = FLAGS.gen_dimension\n    generator_dims = [64 * gen_dim, 64 * gen_dim // 2, 64 * gen_dim // 4, 64 * gen_dim // 8, 3]\n    discriminator_dims = [3, 64, 64 * 2, 64 * 4, 64 * 8, 1]\n\n    crop_image_size, resized_image_size = map(int, FLAGS.image_size.split(\',\'))\n    if FLAGS.model == 0:\n        model = GAN(FLAGS.z_dim, crop_image_size, resized_image_size, FLAGS.batch_size, FLAGS.data_dir)\n    elif FLAGS.model == 1:\n        model = WasserstienGAN(FLAGS.z_dim, crop_image_size, resized_image_size, FLAGS.batch_size, FLAGS.data_dir,\n                               clip_values=(-0.01, 0.01), critic_iterations=5)\n    else:\n        raise ValueError(""Unknown model identifier - FLAGS.model=%d"" % FLAGS.model)\n\n    model.create_network(generator_dims, discriminator_dims, FLAGS.optimizer, FLAGS.learning_rate,\n                         FLAGS.optimizer_param)\n\n    model.initialize_network(FLAGS.logs_dir)\n\n    if FLAGS.mode == ""train"":\n        model.train_model(int(1 + FLAGS.iterations))\n    elif FLAGS.mode == ""visualize"":\n        model.visualize_model()\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
utils.py,31,"b'__author__ = \'shekkizh\'\n# Utils used with tensorflow implemetation\nimport tensorflow as tf\nimport numpy as np\nimport scipy.misc as misc\nimport os, sys\nfrom six.moves import urllib\nimport tarfile\nimport zipfile\nfrom tqdm import trange\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\ndef maybe_download_and_extract(dir_path, url_name, is_tarfile=False, is_zipfile=False):\n    if not os.path.exists(dir_path):\n        os.makedirs(dir_path)\n    filename = url_name.split(\'/\')[-1]\n    filepath = os.path.join(dir_path, filename)\n    if not os.path.exists(filepath):\n        def _progress(count, block_size, total_size):\n            sys.stdout.write(\n                \'\\r>> Downloading %s %.1f%%\' % (filename, float(count * block_size) / float(total_size) * 100.0))\n            sys.stdout.flush()\n\n        filepath, _ = urllib.request.urlretrieve(url_name, filepath, reporthook=_progress)\n        print()\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n        if is_tarfile:\n            tarfile.open(filepath, \'r:gz\').extractall(dir_path)\n        elif is_zipfile:\n            with zipfile.ZipFile(filepath) as zf:\n                zip_dir = zf.namelist()[0]\n                zf.extractall(dir_path)\n\n\ndef save_image(image, image_size, save_dir, name=""""):\n    """"""\n    Save image by unprocessing assuming mean 127.5\n    :param image:\n    :param save_dir:\n    :param name:\n    :return:\n    """"""\n    image += 1\n    image *= 127.5\n    image = np.clip(image, 0, 255).astype(np.uint8)\n    image = np.reshape(image, (image_size, image_size, -1))\n    misc.imsave(os.path.join(save_dir, name + ""pred_image.png""), image)\n\n\ndef xavier_init(fan_in, fan_out, constant=1):\n    """""" Xavier initialization of network weights""""""\n    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n    return tf.random_uniform((fan_in, fan_out), minval=low, maxval=high, dtype=tf.float32)\n\n\ndef weight_variable_xavier_initialized(shape, constant=1, name=None):\n    stddev = constant * np.sqrt(2.0 / (shape[2] + shape[3]))\n    return weight_variable(shape, stddev=stddev, name=name)\n\n\ndef weight_variable(shape, stddev=0.02, name=None):\n    initial = tf.truncated_normal(shape, stddev=stddev)\n    if name is None:\n        return tf.Variable(initial)\n    else:\n        return tf.get_variable(name, initializer=initial)\n\n\ndef bias_variable(shape, name=None):\n    initial = tf.constant(0.0, shape=shape)\n    if name is None:\n        return tf.Variable(initial)\n    else:\n        return tf.get_variable(name, initializer=initial)\n\n\ndef get_tensor_size(tensor):\n    from operator import mul\n    return reduce(mul, (d.value for d in tensor.get_shape()), 1)\n\n\ndef conv2d_basic(x, W, bias):\n    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=""SAME"")\n    return tf.nn.bias_add(conv, bias)\n\n\ndef conv2d_strided(x, W, b):\n    conv = tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding=""SAME"")\n    return tf.nn.bias_add(conv, b)\n\n\ndef conv2d_transpose_strided(x, W, b, output_shape=None):\n    # print x.get_shape()\n    # print W.get_shape()\n    if output_shape is None:\n        output_shape = x.get_shape().as_list()\n        output_shape[1] *= 2\n        output_shape[2] *= 2\n        output_shape[3] = W.get_shape().as_list()[2]\n    # print output_shape\n    conv = tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, 2, 2, 1], padding=""SAME"")\n    return tf.nn.bias_add(conv, b)\n\n\ndef leaky_relu(x, alpha=0.2, name=""""):\n    return tf.maximum(alpha * x, x, name)\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"")\n\n\ndef avg_pool_2x2(x):\n    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"")\n\n\ndef local_response_norm(x):\n    return tf.nn.lrn(x, depth_radius=5, bias=2, alpha=1e-4, beta=0.75)\n\n\ndef batch_norm(x, n_out, phase_train, scope=\'bn\', decay=0.9, eps=1e-5, stddev=0.02):\n    """"""\n    Code taken from http://stackoverflow.com/a/34634291/2267819\n    """"""\n    with tf.variable_scope(scope):\n        beta = tf.get_variable(name=\'beta\', shape=[n_out], initializer=tf.constant_initializer(0.0)\n                               , trainable=True)\n        gamma = tf.get_variable(name=\'gamma\', shape=[n_out], initializer=tf.random_normal_initializer(1.0, stddev),\n                                trainable=True)\n        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name=\'moments\')\n        ema = tf.train.ExponentialMovingAverage(decay=decay)\n\n        def mean_var_with_update():\n            ema_apply_op = ema.apply([batch_mean, batch_var])\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n\n        mean, var = tf.cond(phase_train,\n                            mean_var_with_update,\n                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\n    return normed\n\n\ndef process_image(image, mean_pixel, norm):\n    return (image - mean_pixel) / norm\n\n\ndef unprocess_image(image, mean_pixel, norm):\n    return image * norm + mean_pixel\n\n\ndef add_to_regularization_and_summary(var):\n    if var is not None:\n        tf.histogram_summary(var.op.name, var)\n        tf.add_to_collection(""reg_loss"", tf.nn.l2_loss(var))\n\n\ndef add_activation_summary(var):\n    tf.histogram_summary(var.op.name + ""/activation"", var)\n    tf.scalar_summary(var.op.name + ""/sparsity"", tf.nn.zero_fraction(var))\n\n\ndef add_gradient_summary(grad, var):\n    if grad is not None:\n        tf.histogram_summary(var.op.name + ""/gradient"", grad)\n\ndef save_imshow_grid(images, logs_dir, filename, shape):\n    """"""\n    Plot images in a grid of a given shape.\n    """"""\n    fig = plt.figure(1)\n    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n\n    size = shape[0] * shape[1]\n    for i in trange(size, desc=""Saving images""):\n        grid[i].axis(\'off\')\n        grid[i].imshow(images[i])\n\n    plt.savefig(os.path.join(logs_dir, filename))\n'"
Dataset_Reader/__init__.py,0,b''
Dataset_Reader/read_celebADataset.py,0,"b'__author__ = \'charlie\'\nimport numpy as np\nimport os, sys, inspect\nimport random\nfrom six.moves import cPickle as pickle\nfrom tensorflow.python.platform import gfile\nimport glob\n\nutils_path = os.path.abspath(\n    os.path.realpath(os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], "".."")))\nif utils_path not in sys.path:\n    sys.path.insert(0, utils_path)\nimport utils as utils\n\nDATA_URL = \'https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADIKlz8PR9zr6Y20qbkunrba/Img/img_align_celeba.zip\'\nrandom.seed(5)\n\n\nclass CelebA_Dataset():\n    def __init__(self, dict):\n        self.train_images = dict[\'train\']\n        self.test_images = dict[\'test\']\n        self.validation_images = dict[\'validation\']\n\n\ndef read_dataset(data_dir):\n    pickle_filename = ""celebA.pickle""\n    pickle_filepath = os.path.join(data_dir, pickle_filename)\n    if not os.path.exists(pickle_filepath):\n        # utils.maybe_download_and_extract(data_dir, DATA_URL, is_zipfile=True)\n        celebA_folder = os.path.splitext(DATA_URL.split(""/"")[-1])[0]\n        dir_path = os.path.join(data_dir, celebA_folder)\n        if not os.path.exists(dir_path):\n            print (""CelebA dataset needs to be downloaded and unzipped manually"")\n            print (""Download from: %s"" % DATA_URL)\n            raise ValueError(""Dataset not found"")\n\n        result = create_image_lists(dir_path)\n        print (""Training set: %d"" % len(result[\'train\']))\n        print (""Test set: %d"" % len(result[\'test\']))\n        print (""Validation set: %d"" % len(result[\'validation\']))\n        print (""Pickling ..."")\n        with open(pickle_filepath, \'wb\') as f:\n            pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n    else:\n        print (""Found pickle file!"")\n\n    with open(pickle_filepath, \'rb\') as f:\n        result = pickle.load(f)\n        celebA = CelebA_Dataset(result)\n        del result\n    return celebA\n\n\ndef create_image_lists(image_dir, testing_percentage=0.0, validation_percentage=0.0):\n    """"""\n    Code modified from tensorflow/tensorflow/examples/image_retraining\n    """"""\n    if not gfile.Exists(image_dir):\n        print(""Image directory \'"" + image_dir + ""\' not found."")\n        return None\n    training_images = []\n    extensions = [\'jpg\', \'jpeg\', \'JPG\', \'JPEG\']\n    sub_dirs = [x[0] for x in os.walk(image_dir)]\n    file_list = []\n\n    for extension in extensions:\n        file_glob = os.path.join(image_dir, \'*.\' + extension)\n        file_list.extend(glob.glob(file_glob))\n\n    if not file_list:\n        print(\'No files found\')\n    else:\n        # print ""No. of files found: %d"" % len(file_list)\n        training_images.extend([f for f in file_list])\n\n    random.shuffle(training_images)\n    no_of_images = len(training_images)\n    validation_offset = int(validation_percentage * no_of_images)\n    validation_images = training_images[:validation_offset]\n    test_offset = int(testing_percentage * no_of_images)\n    testing_images = training_images[validation_offset:validation_offset + test_offset]\n    training_images = training_images[validation_offset + test_offset:]\n\n    result = {\n        \'train\': training_images,\n        \'test\': testing_images,\n        \'validation\': validation_images,\n    }\n    return result\n'"
models/GAN_models.py,71,"b'from __future__ import print_function\n\n__author__ = ""shekkizh""\n\nimport tensorflow as tf\nimport numpy as np\nimport os, sys, inspect\nimport time\n\nutils_folder = os.path.realpath(\n    os.path.abspath(os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], "".."")))\nif utils_folder not in sys.path:\n    sys.path.insert(0, utils_folder)\n\nimport utils as utils\nimport Dataset_Reader.read_celebADataset as celebA\nfrom six.moves import xrange\n\n\nclass GAN(object):\n    def __init__(self, z_dim, crop_image_size, resized_image_size, batch_size, data_dir):\n        celebA_dataset = celebA.read_dataset(data_dir)\n        self.z_dim = z_dim\n        self.crop_image_size = crop_image_size\n        self.resized_image_size = resized_image_size\n        self.batch_size = batch_size\n        filename_queue = tf.train.string_input_producer(celebA_dataset.train_images)\n        self.images = self._read_input_queue(filename_queue)\n\n    def _read_input(self, filename_queue):\n        class DataRecord(object):\n            pass\n\n        reader = tf.WholeFileReader()\n        key, value = reader.read(filename_queue)\n        record = DataRecord()\n        decoded_image = tf.image.decode_jpeg(value,\n                                             channels=3)  # Assumption:Color images are read and are to be generated\n\n        # decoded_image_4d = tf.expand_dims(decoded_image, 0)\n        # resized_image = tf.image.resize_bilinear(decoded_image_4d, [self.target_image_size, self.target_image_size])\n        # record.input_image = tf.squeeze(resized_image, squeeze_dims=[0])\n\n        cropped_image = tf.cast(\n            tf.image.crop_to_bounding_box(decoded_image, 55, 35, self.crop_image_size, self.crop_image_size),\n            tf.float32)\n        decoded_image_4d = tf.expand_dims(cropped_image, 0)\n        resized_image = tf.image.resize_bilinear(decoded_image_4d, [self.resized_image_size, self.resized_image_size])\n        record.input_image = tf.squeeze(resized_image, squeeze_dims=[0])\n        return record\n\n    def _read_input_queue(self, filename_queue):\n        print(""Setting up image reader..."")\n        read_input = self._read_input(filename_queue)\n        num_preprocess_threads = 4\n        num_examples_per_epoch = 800\n        min_queue_examples = int(0.1 * num_examples_per_epoch)\n        print(""Shuffling"")\n        input_image = tf.train.batch([read_input.input_image],\n                                     batch_size=self.batch_size,\n                                     num_threads=num_preprocess_threads,\n                                     capacity=min_queue_examples + 2 * self.batch_size\n                                     )\n        input_image = utils.process_image(input_image, 127.5, 127.5)\n        return input_image\n\n    def _generator(self, z, dims, train_phase, activation=tf.nn.relu, scope_name=""generator""):\n        N = len(dims)\n        image_size = self.resized_image_size // (2 ** (N - 1))\n        with tf.variable_scope(scope_name) as scope:\n            W_z = utils.weight_variable([self.z_dim, dims[0] * image_size * image_size], name=""W_z"")\n            b_z = utils.bias_variable([dims[0] * image_size * image_size], name=""b_z"")\n            h_z = tf.matmul(z, W_z) + b_z\n            h_z = tf.reshape(h_z, [-1, image_size, image_size, dims[0]])\n            h_bnz = utils.batch_norm(h_z, dims[0], train_phase, scope=""gen_bnz"")\n            h = activation(h_bnz, name=\'h_z\')\n            utils.add_activation_summary(h)\n\n            for index in range(N - 2):\n                image_size *= 2\n                W = utils.weight_variable([5, 5, dims[index + 1], dims[index]], name=""W_%d"" % index)\n                b = utils.bias_variable([dims[index + 1]], name=""b_%d"" % index)\n                deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[index + 1]])\n                h_conv_t = utils.conv2d_transpose_strided(h, W, b, output_shape=deconv_shape)\n                h_bn = utils.batch_norm(h_conv_t, dims[index + 1], train_phase, scope=""gen_bn%d"" % index)\n                h = activation(h_bn, name=\'h_%d\' % index)\n                utils.add_activation_summary(h)\n\n            image_size *= 2\n            W_pred = utils.weight_variable([5, 5, dims[-1], dims[-2]], name=""W_pred"")\n            b_pred = utils.bias_variable([dims[-1]], name=""b_pred"")\n            deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[-1]])\n            h_conv_t = utils.conv2d_transpose_strided(h, W_pred, b_pred, output_shape=deconv_shape)\n            pred_image = tf.nn.tanh(h_conv_t, name=\'pred_image\')\n            utils.add_activation_summary(pred_image)\n\n        return pred_image\n\n    def _discriminator(self, input_images, dims, train_phase, activation=tf.nn.relu, scope_name=""discriminator"",\n                       scope_reuse=False):\n        N = len(dims)\n        with tf.variable_scope(scope_name) as scope:\n            if scope_reuse:\n                scope.reuse_variables()\n            h = input_images\n            skip_bn = True  # First layer of discriminator skips batch norm\n            for index in range(N - 2):\n                W = utils.weight_variable([5, 5, dims[index], dims[index + 1]], name=""W_%d"" % index)\n                b = utils.bias_variable([dims[index + 1]], name=""b_%d"" % index)\n                h_conv = utils.conv2d_strided(h, W, b)\n                if skip_bn:\n                    h_bn = h_conv\n                    skip_bn = False\n                else:\n                    h_bn = utils.batch_norm(h_conv, dims[index + 1], train_phase, scope=""disc_bn%d"" % index)\n                h = activation(h_bn, name=""h_%d"" % index)\n                utils.add_activation_summary(h)\n\n            shape = h.get_shape().as_list()\n            image_size = self.resized_image_size // (2 ** (N - 2))  # dims has input dim and output dim\n            h_reshaped = tf.reshape(h, [self.batch_size, image_size * image_size * shape[3]])\n            W_pred = utils.weight_variable([image_size * image_size * shape[3], dims[-1]], name=""W_pred"")\n            b_pred = utils.bias_variable([dims[-1]], name=""b_pred"")\n            h_pred = tf.matmul(h_reshaped, W_pred) + b_pred\n\n        return tf.nn.sigmoid(h_pred), h_pred, h\n\n    def _cross_entropy_loss(self, logits, labels, name=""x_entropy""):\n        xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits, labels))\n        tf.scalar_summary(name, xentropy)\n        return xentropy\n\n    def _get_optimizer(self, optimizer_name, learning_rate, optimizer_param):\n        self.learning_rate = learning_rate\n        if optimizer_name == ""Adam"":\n            return tf.train.AdamOptimizer(learning_rate, beta1=optimizer_param)\n        elif optimizer_name == ""RMSProp"":\n            return tf.train.RMSPropOptimizer(learning_rate, decay=optimizer_param)\n        else:\n            raise ValueError(""Unknown optimizer %s"" % optimizer_name)\n\n    def _train(self, loss_val, var_list, optimizer):\n        grads = optimizer.compute_gradients(loss_val, var_list=var_list)\n        for grad, var in grads:\n            utils.add_gradient_summary(grad, var)\n        return optimizer.apply_gradients(grads)\n\n    def _setup_placeholder(self):\n        self.train_phase = tf.placeholder(tf.bool)\n        self.z_vec = tf.placeholder(tf.float32, [self.batch_size, self.z_dim], name=""z"")\n\n    def _gan_loss(self, logits_real, logits_fake, feature_real, feature_fake, use_features=False):\n        discriminator_loss_real = self._cross_entropy_loss(logits_real, tf.ones_like(logits_real),\n                                                           name=""disc_real_loss"")\n\n        discriminator_loss_fake = self._cross_entropy_loss(logits_fake, tf.zeros_like(logits_fake),\n                                                           name=""disc_fake_loss"")\n        self.discriminator_loss = discriminator_loss_fake + discriminator_loss_real\n\n        gen_loss_disc = self._cross_entropy_loss(logits_fake, tf.ones_like(logits_fake), name=""gen_disc_loss"")\n        if use_features:\n            gen_loss_features = tf.reduce_mean(tf.nn.l2_loss(feature_real - feature_fake)) / (self.crop_image_size ** 2)\n        else:\n            gen_loss_features = 0\n        self.gen_loss = gen_loss_disc + 0.1 * gen_loss_features\n\n        tf.scalar_summary(""Discriminator_loss"", self.discriminator_loss)\n        tf.scalar_summary(""Generator_loss"", self.gen_loss)\n\n    def create_network(self, generator_dims, discriminator_dims, optimizer=""Adam"", learning_rate=2e-4,\n                       optimizer_param=0.9, improved_gan_loss=True):\n        print(""Setting up model..."")\n        self._setup_placeholder()\n        tf.histogram_summary(""z"", self.z_vec)\n        self.gen_images = self._generator(self.z_vec, generator_dims, self.train_phase, scope_name=""generator"")\n\n        tf.image_summary(""image_real"", self.images, max_images=2)\n        tf.image_summary(""image_generated"", self.gen_images, max_images=2)\n\n        def leaky_relu(x, name=""leaky_relu""):\n            return utils.leaky_relu(x, alpha=0.2, name=name)\n\n        discriminator_real_prob, logits_real, feature_real = self._discriminator(self.images, discriminator_dims,\n                                                                                 self.train_phase,\n                                                                                 activation=leaky_relu,\n                                                                                 scope_name=""discriminator"",\n                                                                                 scope_reuse=False)\n\n        discriminator_fake_prob, logits_fake, feature_fake = self._discriminator(self.gen_images, discriminator_dims,\n                                                                                 self.train_phase,\n                                                                                 activation=leaky_relu,\n                                                                                 scope_name=""discriminator"",\n                                                                                 scope_reuse=True)\n\n        # utils.add_activation_summary(tf.identity(discriminator_real_prob, name=\'disc_real_prob\'))\n        # utils.add_activation_summary(tf.identity(discriminator_fake_prob, name=\'disc_fake_prob\'))\n\n        # Loss calculation\n        self._gan_loss(logits_real, logits_fake, feature_real, feature_fake, use_features=improved_gan_loss)\n\n        train_variables = tf.trainable_variables()\n\n        for v in train_variables:\n            # print (v.op.name)\n            utils.add_to_regularization_and_summary(var=v)\n\n        self.generator_variables = [v for v in train_variables if v.name.startswith(""generator"")]\n        # print(map(lambda x: x.op.name, generator_variables))\n        self.discriminator_variables = [v for v in train_variables if v.name.startswith(""discriminator"")]\n        # print(map(lambda x: x.op.name, discriminator_variables))\n\n        optim = self._get_optimizer(optimizer, learning_rate, optimizer_param)\n\n        self.generator_train_op = self._train(self.gen_loss, self.generator_variables, optim)\n        self.discriminator_train_op = self._train(self.discriminator_loss, self.discriminator_variables, optim)\n\n    def initialize_network(self, logs_dir):\n        print(""Initializing network..."")\n        self.logs_dir = logs_dir\n        self.sess = tf.Session()\n        self.summary_op = tf.merge_all_summaries()\n        self.saver = tf.train.Saver()\n        self.summary_writer = tf.train.SummaryWriter(self.logs_dir, self.sess.graph)\n\n        self.sess.run(tf.initialize_all_variables())\n        ckpt = tf.train.get_checkpoint_state(self.logs_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            self.saver.restore(self.sess, ckpt.model_checkpoint_path)\n            print(""Model restored..."")\n        self.coord = tf.train.Coordinator()\n        self.threads = tf.train.start_queue_runners(self.sess, self.coord)\n\n    def train_model(self, max_iterations):\n        try:\n            print(""Training model..."")\n            for itr in xrange(1, max_iterations):\n                batch_z = np.random.uniform(-1.0, 1.0, size=[self.batch_size, self.z_dim]).astype(np.float32)\n                feed_dict = {self.z_vec: batch_z, self.train_phase: True}\n\n                self.sess.run(self.discriminator_train_op, feed_dict=feed_dict)\n                self.sess.run(self.generator_train_op, feed_dict=feed_dict)\n\n                if itr % 10 == 0:\n                    g_loss_val, d_loss_val, summary_str = self.sess.run(\n                        [self.gen_loss, self.discriminator_loss, self.summary_op], feed_dict=feed_dict)\n                    print(""Step: %d, generator loss: %g, discriminator_loss: %g"" % (itr, g_loss_val, d_loss_val))\n                    self.summary_writer.add_summary(summary_str, itr)\n\n                if itr % 2000 == 0:\n                    self.saver.save(self.sess, self.logs_dir + ""model.ckpt"", global_step=itr)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        except KeyboardInterrupt:\n            print(""Ending Training..."")\n        finally:\n            self.coord.request_stop()\n            self.coord.join(self.threads)  # Wait for threads to finish.\n\n    def visualize_model(self):\n        print(""Sampling images from model..."")\n        batch_z = np.random.uniform(-1.0, 1.0, size=[self.batch_size, self.z_dim]).astype(np.float32)\n        feed_dict = {self.z_vec: batch_z, self.train_phase: False}\n\n        images = self.sess.run(self.gen_images, feed_dict=feed_dict)\n        images = utils.unprocess_image(images, 127.5, 127.5).astype(np.uint8)\n        shape = [4, self.batch_size // 4]\n        utils.save_imshow_grid(images, self.logs_dir, ""generated.png"", shape=shape)\n\n\nclass WasserstienGAN(GAN):\n    def __init__(self, z_dim, crop_image_size, resized_image_size, batch_size, data_dir, clip_values=(-0.01, 0.01),\n                 critic_iterations=5):\n        self.critic_iterations = critic_iterations\n        self.clip_values = clip_values\n        GAN.__init__(self, z_dim, crop_image_size, resized_image_size, batch_size, data_dir)\n\n    def _generator(self, z, dims, train_phase, activation=tf.nn.relu, scope_name=""generator""):\n        N = len(dims)\n        image_size = self.resized_image_size // (2 ** (N - 1))\n        with tf.variable_scope(scope_name) as scope:\n            W_z = utils.weight_variable([self.z_dim, dims[0] * image_size * image_size], name=""W_z"")\n            h_z = tf.matmul(z, W_z)\n            h_z = tf.reshape(h_z, [-1, image_size, image_size, dims[0]])\n            h_bnz = utils.batch_norm(h_z, dims[0], train_phase, scope=""gen_bnz"")\n            h = activation(h_bnz, name=\'h_z\')\n            utils.add_activation_summary(h)\n\n            for index in range(N - 2):\n                image_size *= 2\n                W = utils.weight_variable([4, 4, dims[index + 1], dims[index]], name=""W_%d"" % index)\n                b = tf.zeros([dims[index + 1]])\n                deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[index + 1]])\n                h_conv_t = utils.conv2d_transpose_strided(h, W, b, output_shape=deconv_shape)\n                h_bn = utils.batch_norm(h_conv_t, dims[index + 1], train_phase, scope=""gen_bn%d"" % index)\n                h = activation(h_bn, name=\'h_%d\' % index)\n                utils.add_activation_summary(h)\n\n            image_size *= 2\n            W_pred = utils.weight_variable([4, 4, dims[-1], dims[-2]], name=""W_pred"")\n            b = tf.zeros([dims[-1]])\n            deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[-1]])\n            h_conv_t = utils.conv2d_transpose_strided(h, W_pred, b, output_shape=deconv_shape)\n            pred_image = tf.nn.tanh(h_conv_t, name=\'pred_image\')\n            utils.add_activation_summary(pred_image)\n\n        return pred_image\n\n    def _discriminator(self, input_images, dims, train_phase, activation=tf.nn.relu, scope_name=""discriminator"",\n                       scope_reuse=False):\n        N = len(dims)\n        with tf.variable_scope(scope_name) as scope:\n            if scope_reuse:\n                scope.reuse_variables()\n            h = input_images\n            skip_bn = True  # First layer of discriminator skips batch norm\n            for index in range(N - 2):\n                W = utils.weight_variable([4, 4, dims[index], dims[index + 1]], name=""W_%d"" % index)\n                b = tf.zeros([dims[index+1]])\n                h_conv = utils.conv2d_strided(h, W, b)\n                if skip_bn:\n                    h_bn = h_conv\n                    skip_bn = False\n                else:\n                    h_bn = utils.batch_norm(h_conv, dims[index + 1], train_phase, scope=""disc_bn%d"" % index)\n                h = activation(h_bn, name=""h_%d"" % index)\n                utils.add_activation_summary(h)\n\n            W_pred = utils.weight_variable([4, 4, dims[-2], dims[-1]], name=""W_pred"")\n            b = tf.zeros([dims[-1]])\n            h_pred = utils.conv2d_strided(h, W_pred, b)\n        return None, h_pred, None  # Return the last convolution output. None values are returned to maintatin disc from other GAN\n\n    def _gan_loss(self, logits_real, logits_fake, feature_real, feature_fake, use_features=False):\n        self.discriminator_loss = tf.reduce_mean(logits_real - logits_fake)\n        self.gen_loss = tf.reduce_mean(logits_fake)\n\n        tf.scalar_summary(""Discriminator_loss"", self.discriminator_loss)\n        tf.scalar_summary(""Generator_loss"", self.gen_loss)\n\n    def train_model(self, max_iterations):\n        try:\n            print(""Training Wasserstein GAN model..."")\n            clip_discriminator_var_op = [var.assign(tf.clip_by_value(var, self.clip_values[0], self.clip_values[1])) for\n                                         var in self.discriminator_variables]\n\n            start_time = time.time()\n\n            def get_feed_dict(train_phase=True):\n                batch_z = np.random.uniform(-1.0, 1.0, size=[self.batch_size, self.z_dim]).astype(np.float32)\n                feed_dict = {self.z_vec: batch_z, self.train_phase: train_phase}\n                return feed_dict\n\n            for itr in xrange(1, max_iterations):\n                if itr < 25 or itr % 500 == 0:\n                    critic_itrs = 25\n                else:\n                    critic_itrs = self.critic_iterations\n\n                for critic_itr in range(critic_itrs):\n                    self.sess.run(self.discriminator_train_op, feed_dict=get_feed_dict(True))\n                    self.sess.run(clip_discriminator_var_op)\n\n                feed_dict = get_feed_dict(True)\n                self.sess.run(self.generator_train_op, feed_dict=feed_dict)\n\n                if itr % 100 == 0:\n                    summary_str = self.sess.run(self.summary_op, feed_dict=feed_dict)\n                    self.summary_writer.add_summary(summary_str, itr)\n\n                if itr % 200 == 0:\n                    stop_time = time.time()\n                    duration = (stop_time - start_time) / 200.0\n                    start_time = stop_time\n                    g_loss_val, d_loss_val = self.sess.run([self.gen_loss, self.discriminator_loss],\n                                                           feed_dict=feed_dict)\n                    print(""Time: %g/itr, Step: %d, generator loss: %g, discriminator_loss: %g"" % (\n                        duration, itr, g_loss_val, d_loss_val))\n\n                if itr % 5000 == 0:\n                    self.saver.save(self.sess, self.logs_dir + ""model.ckpt"", global_step=itr)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        except KeyboardInterrupt:\n            print(""Ending Training..."")\n        finally:\n            self.coord.request_stop()\n            self.coord.join(self.threads)  # Wait for threads to finish.\n'"
models/__init__.py,0,b''
