file_path,api_count,code
cifar10/cifar10.py,0,"b'import numpy\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Activation\nfrom keras.layers import Dropout\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\n\n# \xd0\x97\xd0\xb0\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc seed \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbf\xd0\xbe\xd0\xb2\xd1\x82\xd0\xbe\xd1\x80\xd1\x8f\xd0\xb5\xd0\xbc\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd1\x80\xd0\xb5\xd0\xb7\xd1\x83\xd0\xbb\xd1\x8c\xd1\x82\xd0\xb0\xd1\x82\xd0\xbe\xd0\xb2\nnumpy.random.seed(42)\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n# \xd0\xa0\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80 \xd0\xbc\xd0\xb8\xd0\xbd\xd0\xb8-\xd0\xb2\xd1\x8b\xd0\xb1\xd0\xbe\xd1\x80\xd0\xba\xd0\xb8\nbatch_size = 32\n# \xd0\x9a\xd0\xbe\xd0\xbb\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x81\xd0\xbe\xd0\xb2 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb9\nnb_classes = 10\n# \xd0\x9a\xd0\xbe\xd0\xbb\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd1\x8d\xd0\xbf\xd0\xbe\xd1\x85 \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f\nnb_epoch = 25\n# \xd0\xa0\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb9\nimg_rows, img_cols = 32, 32\n# \xd0\x9a\xd0\xbe\xd0\xbb\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xba\xd0\xb0\xd0\xbd\xd0\xb0\xd0\xbb\xd0\xbe\xd0\xb2 \xd0\xb2 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb8: RGB\nimg_channels = 3\n\n# \xd0\x9d\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd0\xbb\xd0\xb8\xd0\xb7\xd1\x83\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\nX_train = X_train.astype(\'float32\')\nX_test = X_test.astype(\'float32\')\nX_train /= 255\nX_test /= 255\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xb5\xd1\x82\xd0\xba\xd0\xb8 \xd0\xb2 \xd0\xba\xd0\xb0\xd1\x82\xd0\xb5\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd0\xb8\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbf\xd0\xbe\xd1\x81\xd0\xbb\xd0\xb5\xd0\xb4\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8c\xd0\xbd\xd1\x83\xd1\x8e \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel = Sequential()\n# \xd0\x9f\xd0\xb5\xd1\x80\xd0\xb2\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xb2\xd0\xb5\xd1\x80\xd1\x82\xd0\xbe\xd1\x87\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9\nmodel.add(Conv2D(32, (3, 3), padding=\'same\',\n                        input_shape=(32, 32, 3), activation=\'relu\'))\n# \xd0\x92\xd1\x82\xd0\xbe\xd1\x80\xd0\xbe\xd0\xb9 \xd1\x81\xd0\xb2\xd0\xb5\xd1\x80\xd1\x82\xd0\xbe\xd1\x87\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9\nmodel.add(Conv2D(32, (3, 3), activation=\'relu\', padding=\'same\'))\n# \xd0\x9f\xd0\xb5\xd1\x80\xd0\xb2\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9 \xd0\xbf\xd0\xbe\xd0\xb4\xd0\xb2\xd1\x8b\xd0\xb1\xd0\xbe\xd1\x80\xd0\xba\xd0\xb8\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# \xd0\xa1\xd0\xbb\xd0\xbe\xd0\xb9 \xd1\x80\xd0\xb5\xd0\xb3\xd1\x83\xd0\xbb\xd1\x8f\xd1\x80\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd0\xb8 Dropout\nmodel.add(Dropout(0.25))\n\n# \xd0\xa2\xd1\x80\xd0\xb5\xd1\x82\xd0\xb8\xd0\xb9 \xd1\x81\xd0\xb2\xd0\xb5\xd1\x80\xd1\x82\xd0\xbe\xd1\x87\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9\nmodel.add(Conv2D(64, (3, 3), padding=\'same\', activation=\'relu\'))\n# \xd0\xa7\xd0\xb5\xd1\x82\xd0\xb2\xd0\xb5\xd1\x80\xd1\x82\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xb2\xd0\xb5\xd1\x80\xd1\x82\xd0\xbe\xd1\x87\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9\nmodel.add(Conv2D(64, (3, 3), activation=\'relu\'))\n# \xd0\x92\xd1\x82\xd0\xbe\xd1\x80\xd0\xbe\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9 \xd0\xbf\xd0\xbe\xd0\xb4\xd0\xb2\xd1\x8b\xd0\xb1\xd0\xbe\xd1\x80\xd0\xba\xd0\xb8\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# \xd0\xa1\xd0\xbb\xd0\xbe\xd0\xb9 \xd1\x80\xd0\xb5\xd0\xb3\xd1\x83\xd0\xbb\xd1\x8f\xd1\x80\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd0\xb8 Dropout\nmodel.add(Dropout(0.25))\n# \xd0\xa1\xd0\xbb\xd0\xbe\xd0\xb9 \xd0\xbf\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x8f \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85 \xd0\xb8\xd0\xb7 2D \xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd1\x81\xd1\x82\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd0\xb2 \xd0\xbf\xd0\xbb\xd0\xbe\xd1\x81\xd0\xba\xd0\xbe\xd0\xb5\nmodel.add(Flatten())\n# \xd0\x9f\xd0\xbe\xd0\xbb\xd0\xbd\xd0\xbe\xd1\x81\xd0\xb2\xd1\x8f\xd0\xb7\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9 \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x81\xd0\xb8\xd1\x84\xd0\xb8\xd0\xba\xd0\xb0\xd1\x86\xd0\xb8\xd0\xb8\nmodel.add(Dense(512, activation=\'relu\'))\n# \xd0\xa1\xd0\xbb\xd0\xbe\xd0\xb9 \xd1\x80\xd0\xb5\xd0\xb3\xd1\x83\xd0\xbb\xd1\x8f\xd1\x80\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd0\xb8 Dropout\nmodel.add(Dropout(0.5))\n# \xd0\x92\xd1\x8b\xd1\x85\xd0\xbe\xd0\xb4\xd0\xbd\xd0\xbe\xd0\xb9 \xd0\xbf\xd0\xbe\xd0\xbb\xd0\xbd\xd0\xbe\xd1\x81\xd0\xb2\xd1\x8f\xd0\xb7\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9\nmodel.add(Dense(nb_classes, activation=\'softmax\'))\n\n# \xd0\x97\xd0\xb0\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbf\xd0\xb0\xd1\x80\xd0\xb0\xd0\xbc\xd0\xb5\xd1\x82\xd1\x80\xd1\x8b \xd0\xbe\xd0\xbf\xd1\x82\xd0\xb8\xd0\xbc\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd0\xb8\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=sgd,\n              metrics=[\'accuracy\'])\n# \xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=nb_epoch,\n              validation_split=0.1,\n              shuffle=True,\n              verbose=2)\n\n# \xd0\x9e\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd0\xb8 \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nscores = model.evaluate(X_test, Y_test, verbose=0)\nprint(""\xd0\xa2\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c \xd1\x80\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x82\xd1\x8b \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85: %.2f%%"" % (scores[1]*100))\n'"
imdb/imdb_lstm.py,0,"b'import numpy as np\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding\nfrom keras.layers import LSTM, SpatialDropout1D\nfrom keras.datasets import imdb\n\n# \xd0\xa3\xd1\x81\xd1\x82\xd0\xb0\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc seed \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbf\xd0\xbe\xd0\xb2\xd1\x82\xd0\xbe\xd1\x80\xd1\x8f\xd0\xb5\xd0\xbc\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd1\x80\xd0\xb5\xd0\xb7\xd1\x83\xd0\xbb\xd1\x8c\xd1\x82\xd0\xb0\xd1\x82\xd0\xbe\xd0\xb2\nnp.random.seed(42)\n# \xd0\x9c\xd0\xb0\xd0\xba\xd1\x81\xd0\xb8\xd0\xbc\xd0\xb0\xd0\xbb\xd1\x8c\xd0\xbd\xd0\xbe\xd0\xb5 \xd0\xba\xd0\xbe\xd0\xbb\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb2 (\xd0\xbf\xd0\xbe \xd1\x87\xd0\xb0\xd1\x81\xd1\x82\xd0\xbe\xd1\x82\xd0\xb5 \xd0\xb8\xd1\x81\xd0\xbf\xd0\xbe\xd0\xbb\xd1\x8c\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x8f)\nmax_features = 5000\n# \xd0\x9c\xd0\xb0\xd0\xba\xd1\x81\xd0\xb8\xd0\xbc\xd0\xb0\xd0\xbb\xd1\x8c\xd0\xbd\xd0\xb0\xd1\x8f \xd0\xb4\xd0\xbb\xd0\xb8\xd0\xbd\xd0\xb0 \xd1\x80\xd0\xb5\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb7\xd0\xb8\xd0\xb8 \xd0\xb2 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x85\nmaxlen = 80\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n\n# \xd0\x97\xd0\xb0\xd0\xbf\xd0\xbe\xd0\xbb\xd0\xbd\xd1\x8f\xd0\xb5\xd0\xbc \xd0\xb8\xd0\xbb\xd0\xb8 \xd0\xbe\xd0\xb1\xd1\x80\xd0\xb5\xd0\xb7\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x80\xd0\xb5\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb7\xd0\xb8\xd0\xb8\nX_train = sequence.pad_sequences(X_train, maxlen=maxlen)\nX_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c\nmodel = Sequential()\n# \xd0\xa1\xd0\xbb\xd0\xbe\xd0\xb9 \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xb2\xd0\xb5\xd0\xba\xd1\x82\xd0\xbe\xd1\x80\xd0\xbd\xd0\xbe\xd0\xb3\xd0\xbe \xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd1\x81\xd1\x82\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb2\nmodel.add(Embedding(max_features, 32))\nmodel.add(SpatialDropout1D(0.2))\n# \xd0\xa1\xd0\xbb\xd0\xbe\xd0\xb9 \xd0\xb4\xd0\xbe\xd0\xbb\xd0\xb3\xd0\xbe-\xd0\xba\xd1\x80\xd0\xb0\xd1\x82\xd0\xba\xd0\xbe\xd1\x81\xd1\x80\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd0\xb9 \xd0\xbf\xd0\xb0\xd0\xbc\xd1\x8f\xd1\x82\xd0\xb8\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2)) \n# \xd0\x9f\xd0\xbe\xd0\xbb\xd0\xbd\xd0\xbe\xd1\x81\xd0\xb2\xd1\x8f\xd0\xb7\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb9\nmodel.add(Dense(1, activation=""sigmoid""))\n\n# \xd0\x9a\xd0\xbe\xd0\xbf\xd0\xbc\xd0\xb8\xd0\xbb\xd0\xb8\xd1\x80\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel.compile(loss=\'binary_crossentropy\',\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n\n# \xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel.fit(X_train, y_train, batch_size=64, epochs=7,\n          validation_data=(X_test, y_test), verbose=2)\n# \xd0\x9f\xd1\x80\xd0\xbe\xd0\xb2\xd0\xb5\xd1\x80\xd1\x8f\xd0\xb5\xd0\xbc \xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nscores = model.evaluate(X_test, y_test,\n                        batch_size=64)\nprint(""\xd0\xa2\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85: %.2f%%"" % (scores[1] * 100))\n'"
mnist/mnist.py,0,"b'import numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\n\n# \xd0\xa3\xd1\x81\xd1\x82\xd0\xb0\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc seed \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbf\xd0\xbe\xd0\xb2\xd1\x82\xd0\xbe\xd1\x80\xd1\x8f\xd0\xb5\xd0\xbc\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd1\x80\xd0\xb5\xd0\xb7\xd1\x83\xd0\xbb\xd1\x8c\xd1\x82\xd0\xb0\xd1\x82\xd0\xbe\xd0\xb2\nnumpy.random.seed(42)\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x80\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb9\nX_train = X_train.reshape(60000, 784)\nX_test = X_test.reshape(10000, 784)\n# \xd0\x9d\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd0\xbb\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8f \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nX_train = X_train.astype(\'float32\')\nX_test = X_test.astype(\'float32\')\nX_train /= 255\nX_test /= 255\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xb5\xd1\x82\xd0\xba\xd0\xb8 \xd0\xb2 \xd0\xba\xd0\xb0\xd1\x82\xd0\xb5\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd0\xb8\nY_train = np_utils.to_categorical(y_train, 10)\nY_test = np_utils.to_categorical(y_test, 10)\n\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbf\xd0\xbe\xd1\x81\xd0\xbb\xd0\xb5\xd0\xb4\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8c\xd0\xbd\xd1\x83\xd1\x8e \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel = Sequential()\n\n# \xd0\x94\xd0\xbe\xd0\xb1\xd0\xb0\xd0\xb2\xd0\xbb\xd1\x8f\xd0\xb5\xd0\xbc \xd1\x83\xd1\x80\xd0\xbe\xd0\xb2\xd0\xbd\xd0\xb8 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8\nmodel.add(Dense(800, input_dim=784, activation=""relu"", kernel_initializer=""normal""))\nmodel.add(Dense(10, activation=""softmax"", kernel_initializer=""normal""))\n\n# \xd0\x9a\xd0\xbe\xd0\xbc\xd0\xbf\xd0\xb8\xd0\xbb\xd0\xb8\xd1\x80\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel.compile(loss=""categorical_crossentropy"", optimizer=""SGD"", metrics=[""accuracy""])\n\nprint(model.summary())\n\n# \xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c\nmodel.fit(X_train, Y_train, batch_size=200, epochs=25, validation_split=0.2, verbose=2)\n\n# \xd0\x9e\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nscores = model.evaluate(X_test, Y_test, verbose=0)\nprint(""\xd0\xa2\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c \xd1\x80\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x82\xd1\x8b \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85: %.2f%%"" % (scores[1]*100))\n'"
mnist/mnist_cnn.py,0,"b'import numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\n\n# \xd0\xa3\xd1\x81\xd1\x82\xd0\xb0\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc seed \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbf\xd0\xbe\xd0\xb2\xd1\x82\xd0\xbe\xd1\x80\xd1\x8f\xd0\xb5\xd0\xbc\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd1\x80\xd0\xb5\xd0\xb7\xd1\x83\xd0\xbb\xd1\x8c\xd1\x82\xd0\xb0\xd1\x82\xd0\xbe\xd0\xb2\nnumpy.random.seed(42)\n\n# \xd0\xa0\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f\nimg_rows, img_cols = 28, 28\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x80\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb9\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n\n# \xd0\x9d\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd0\xbb\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8f \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nX_train = X_train.astype(\'float32\')\nX_test = X_test.astype(\'float32\')\nX_train /= 255\nX_test /= 255\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xb5\xd1\x82\xd0\xba\xd0\xb8 \xd0\xb2 \xd0\xba\xd0\xb0\xd1\x82\xd0\xb5\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd0\xb8\nY_train = np_utils.to_categorical(y_train, 10)\nY_test = np_utils.to_categorical(y_test, 10)\n\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbf\xd0\xbe\xd1\x81\xd0\xbb\xd0\xb5\xd0\xb4\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8c\xd0\xbd\xd1\x83\xd1\x8e \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel = Sequential()\n\nmodel.add(Conv2D(75, kernel_size=(5, 5),\n                 activation=\'relu\',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(100, (5, 5), activation=\'relu\'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation=\'relu\'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation=\'softmax\'))\n\n\n# \xd0\x9a\xd0\xbe\xd0\xbc\xd0\xbf\xd0\xb8\xd0\xbb\xd0\xb8\xd1\x80\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""])\n\nprint(model.summary())\n\n# \xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c\nmodel.fit(X_train, Y_train, batch_size=200, epochs=10, validation_split=0.2, verbose=2)\n\n# \xd0\x9e\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nscores = model.evaluate(X_test, Y_test, verbose=0)\nprint(""\xd0\xa2\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c \xd1\x80\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x82\xd1\x8b \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85: %.2f%%"" % (scores[1]*100))\n'"
pretrained_networks/vgg16_object_classification.py,0,"b""from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport numpy as np\n\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c \xd1\x81 \xd0\xb0\xd1\x80\xd1\x85\xd0\xb8\xd1\x82\xd0\xb5\xd0\xba\xd1\x82\xd1\x83\xd1\x80\xd0\xbe\xd0\xb9 VGG16 \xd0\xb8 \xd0\xb7\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb2\xd0\xb5\xd1\x81\xd0\xb0, \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n# \xd0\xbd\xd0\xb0 \xd0\xbd\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x80\xd0\xb5 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85 ImageNet\nmodel = VGG16(weights='imagenet')\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 \xd0\xb4\xd0\xbb\xd1\x8f \xd1\x80\xd0\xb0\xd1\x81\xd0\xbf\xd0\xbe\xd0\xb7\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x8f, \xd0\xbf\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd0\xbe\xd0\xb2\xd1\x8b\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb5\xd0\xb3\xd0\xbe \xd0\xb2 \xd0\xbc\xd0\xb0\xd1\x81\xd1\x81\xd0\xb8\xd0\xb2\n# numpy \xd0\xb8 \xd0\xb2\xd1\x8b\xd0\xbf\xd0\xbe\xd0\xbb\xd0\xbd\xd1\x8f\xd0\xb5\xd0\xbc \xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd0\xb2\xd0\xb0\xd1\x80\xd0\xb8\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8c\xd0\xbd\xd1\x83\xd1\x8e \xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x82\xd0\xba\xd1\x83\nimg_path = 'ship.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# \xd0\x97\xd0\xb0\xd0\xbf\xd1\x83\xd1\x81\xd0\xba\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x80\xd0\xb0\xd1\x81\xd0\xbf\xd0\xbe\xd0\xb7\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd0\xbe\xd0\xb1\xd1\x8a\xd0\xb5\xd0\xba\xd1\x82\xd0\xb0 \xd0\xbd\xd0\xb0 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb8\npreds = model.predict(x)\n\n# \xd0\x9f\xd0\xb5\xd1\x87\xd0\xb0\xd1\x82\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x82\xd1\x80\xd0\xb8 \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x81\xd0\xb0 \xd0\xbe\xd0\xb1\xd1\x8a\xd0\xb5\xd0\xba\xd1\x82\xd0\xb0 \xd1\x81 \xd1\x81\xd0\xb0\xd0\xbc\xd0\xbe\xd0\xb9 \xd0\xb2\xd1\x8b\xd1\x81\xd0\xbe\xd0\xba\xd0\xbe\xd0\xb9 \xd0\xb2\xd0\xb5\xd1\x80\xd0\xbe\xd1\x8f\xd1\x82\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c\xd1\x8e\nprint('\xd0\xa0\xd0\xb5\xd0\xb7\xd1\x83\xd0\xbb\xd1\x8c\xd1\x82\xd0\xb0\xd1\x82\xd1\x8b \xd1\x80\xd0\xb0\xd1\x81\xd0\xbf\xd0\xbe\xd0\xb7\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x8f:', decode_predictions(preds, top=3)[0])\n"""
saving_models/loading_net_mnist.py,0,"b'from keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import model_from_json\n\nprint(""\xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd1\x8e \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c \xd0\xb8\xd0\xb7 \xd1\x84\xd0\xb0\xd0\xb9\xd0\xbb\xd0\xbe\xd0\xb2"")\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5 \xd0\xbe\xd0\xb1 \xd0\xb0\xd1\x80\xd1\x85\xd0\xb8\xd1\x82\xd0\xb5\xd0\xba\xd1\x82\xd1\x83\xd1\x80\xd0\xb5 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8\njson_file = open(""mnist_model.json"", ""r"")\nloaded_model_json = json_file.read()\njson_file.close()\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nloaded_model = model_from_json(loaded_model_json)\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x81\xd0\xbe\xd1\x85\xd1\x80\xd0\xb0\xd0\xbd\xd0\xb5\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5 \xd0\xb2\xd0\xb5\xd1\x81\xd0\xb0 \xd0\xb2 \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nloaded_model.load_weights(""mnist_model.h5"")\nprint(""\xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb7\xd0\xba\xd0\xb0 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xb7\xd0\xb0\xd0\xb2\xd0\xb5\xd1\x80\xd1\x88\xd0\xb5\xd0\xbd\xd0\xb0"")\n\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x80\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb9\nX_train = X_train.reshape(60000, 784)\nX_test = X_test.reshape(10000, 784)\n# \xd0\x9d\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd0\xbb\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8f \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nX_train = X_train.astype(\'float32\')\nX_test = X_test.astype(\'float32\')\nX_train /= 255\nX_test /= 255\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xb5\xd1\x82\xd0\xba\xd0\xb8 \xd0\xb2 \xd0\xba\xd0\xb0\xd1\x82\xd0\xb5\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd0\xb8\nY_train = np_utils.to_categorical(y_train, 10)\nY_test = np_utils.to_categorical(y_test, 10)\n\n# \xd0\x9a\xd0\xbe\xd0\xbc\xd0\xbf\xd0\xb8\xd0\xbb\xd0\xb8\xd1\x80\xd1\x83\xd0\xb5\xd0\xbc \xd0\xb7\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xbd\xd1\x83\xd1\x8e \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nloaded_model.compile(loss=""categorical_crossentropy"", optimizer=""SGD"", metrics=[""accuracy""])\n\n# \xd0\x9e\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xb7\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb9 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nscores = loaded_model.evaluate(X_test, Y_test, verbose=0)\nprint(""\xd0\xa2\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c \xd1\x80\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x82\xd1\x8b \xd0\xb7\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb9 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85: %.2f%%"" % (scores[1]*100))\n\n\n'"
saving_models/saving_net_mnist.py,0,"b'import numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\n\n# \xd0\xa3\xd1\x81\xd1\x82\xd0\xb0\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc seed \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbf\xd0\xbe\xd0\xb2\xd1\x82\xd0\xbe\xd1\x80\xd1\x8f\xd0\xb5\xd0\xbc\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd1\x80\xd0\xb5\xd0\xb7\xd1\x83\xd0\xbb\xd1\x8c\xd1\x82\xd0\xb0\xd1\x82\xd0\xbe\xd0\xb2\nnumpy.random.seed(42)\n\n# \xd0\x97\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x80\xd0\xb0\xd0\xb7\xd0\xbc\xd0\xb5\xd1\x80\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8 \xd0\xb8\xd0\xb7\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb9\nX_train = X_train.reshape(60000, 784)\nX_test = X_test.reshape(10000, 784)\n# \xd0\x9d\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd0\xbb\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8f \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nX_train = X_train.astype(\'float32\')\nX_test = X_test.astype(\'float32\')\nX_train /= 255\nX_test /= 255\n\n# \xd0\x9f\xd1\x80\xd0\xb5\xd0\xbe\xd0\xb1\xd1\x80\xd0\xb0\xd0\xb7\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xb5\xd1\x82\xd0\xba\xd0\xb8 \xd0\xb2 \xd0\xba\xd0\xb0\xd1\x82\xd0\xb5\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd0\xb8\nY_train = np_utils.to_categorical(y_train, 10)\nY_test = np_utils.to_categorical(y_test, 10)\n\n# \xd0\xa1\xd0\xbe\xd0\xb7\xd0\xb4\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xbf\xd0\xbe\xd1\x81\xd0\xbb\xd0\xb5\xd0\xb4\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8c\xd0\xbd\xd1\x83\xd1\x8e \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel = Sequential()\n\n# \xd0\x94\xd0\xbe\xd0\xb1\xd0\xb0\xd0\xb2\xd0\xbb\xd1\x8f\xd0\xb5\xd0\xbc \xd1\x83\xd1\x80\xd0\xbe\xd0\xb2\xd0\xbd\xd0\xb8 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8\nmodel.add(Dense(800, input_dim=784, init=""normal"", activation=""relu""))\nmodel.add(Dense(10, init=""normal"", activation=""softmax""))\n\n# \xd0\x9a\xd0\xbe\xd0\xbc\xd0\xbf\xd0\xb8\xd0\xbb\xd0\xb8\xd1\x80\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c\nmodel.compile(loss=""categorical_crossentropy"", optimizer=""SGD"", metrics=[""accuracy""])\n\nprint(model.summary())\n\n# \xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb0\xd0\xb5\xd0\xbc \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c\nmodel.fit(X_train, Y_train, batch_size=200, nb_epoch=25, validation_split=0.2, verbose=1)\n\n# \xd0\x9e\xd1\x86\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd1\x81\xd1\x82\xd0\xb2\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\nscores = model.evaluate(X_test, Y_test, verbose=0)\nprint(""\xd0\xa2\xd0\xbe\xd1\x87\xd0\xbd\xd0\xbe\xd1\x81\xd1\x82\xd1\x8c \xd1\x80\xd0\xb0\xd0\xb1\xd0\xbe\xd1\x82\xd1\x8b \xd0\xbd\xd0\xb0 \xd1\x82\xd0\xb5\xd1\x81\xd1\x82\xd0\xbe\xd0\xb2\xd1\x8b\xd1\x85 \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85: %.2f%%"" % (scores[1]*100))\n\nprint(""\xd0\xa1\xd0\xbe\xd1\x85\xd1\x80\xd0\xb0\xd0\xbd\xd1\x8f\xd0\xb5\xd0\xbc \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c"")\n# \xd0\xa1\xd0\xbe\xd1\x85\xd1\x80\xd0\xb0\xd0\xbd\xd1\x8f\xd0\xb5\xd0\xbc \xd1\x81\xd0\xb5\xd1\x82\xd1\x8c \xd0\xb4\xd0\xbb\xd1\x8f \xd0\xbf\xd0\xbe\xd1\x81\xd0\xbb\xd0\xb5\xd0\xb4\xd1\x83\xd1\x8e\xd1\x89\xd0\xb5\xd0\xb3\xd0\xbe \xd0\xb8\xd1\x81\xd0\xbf\xd0\xbe\xd0\xbb\xd1\x8c\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x8f\n# \xd0\x93\xd0\xb5\xd0\xbd\xd0\xb5\xd1\x80\xd0\xb8\xd1\x80\xd1\x83\xd0\xb5\xd0\xbc \xd0\xbe\xd0\xbf\xd0\xb8\xd1\x81\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd0\xb8 \xd0\xb2 \xd1\x84\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd1\x82\xd0\xb5 json\nmodel_json = model.to_json()\njson_file = open(""mnist_model.json"", ""w"")\n# \xd0\x97\xd0\xb0\xd0\xbf\xd0\xb8\xd1\x81\xd1\x8b\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb0\xd1\x80\xd1\x85\xd0\xb8\xd1\x82\xd0\xb5\xd0\xba\xd1\x82\xd1\x83\xd1\x80\xd1\x83 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xb2 \xd1\x84\xd0\xb0\xd0\xb9\xd0\xbb\njson_file.write(model_json)\njson_file.close()\n# \xd0\x97\xd0\xb0\xd0\xbf\xd0\xb8\xd1\x81\xd1\x8b\xd0\xb2\xd0\xb0\xd0\xb5\xd0\xbc \xd0\xb4\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb5 \xd0\xbe \xd0\xb2\xd0\xb5\xd1\x81\xd0\xb0\xd1\x85 \xd0\xb2 \xd1\x84\xd0\xb0\xd0\xb9\xd0\xbb\nmodel.save_weights(""mnist_model.h5"")\nprint(""\xd0\xa1\xd0\xbe\xd1\x85\xd1\x80\xd0\xb0\xd0\xbd\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x81\xd0\xb5\xd1\x82\xd0\xb8 \xd0\xb7\xd0\xb0\xd0\xb2\xd0\xb5\xd1\x80\xd1\x88\xd0\xb5\xd0\xbd\xd0\xbe"")\n\n'"
