file_path,api_count,code
autotrain.py,9,"b""import subprocess\nimport tensorflow as tf\nimport glob\nimport scipy.io as sio\nimport numpy as np\n\nbase_path = 'Test/mhgd'\nfor i in range(5):\n    subprocess.call('python KD_methods_with_TF/train_w_distill.py '\n                   +'--train_dir=%s%d '%(base_path,i)\n                   +'--model_name=ResNet '\n                   +'--Distillation=MHGD',\n                    shell=True)\n    print ('Training Done')\n\npathes = glob.glob(base_path[:-len(base_path.split('/')[-1])] + '*')\ntraining_acc   = []\nvalidation_acc = []\nfor path in pathes:\n    logs = sio.loadmat(path + '/log.mat')\n    training_acc.append(logs['training_acc'])\n    validation_acc.append(logs['validation_acc'])\ntraining_acc   = np.mean(np.vstack(training_acc),0)\nvalidation_acc = np.mean(np.vstack(validation_acc),0)\n\ntrain_acc_place = tf.placeholder(dtype=tf.float32)\nval_acc_place   = tf.placeholder(dtype=tf.float32)\nval_summary = [tf.summary.scalar('accuracy/training_accuracy',   train_acc_place),\n               tf.summary.scalar('accuracy/validation_accuracy', val_acc_place)]\nval_summary_op = tf.summary.merge(list(val_summary), name='val_summary_op')\n    \ntrain_writer = tf.summary.FileWriter(base_path[:-len(base_path.split('/')[-1])] + 'average',flush_secs=1)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth=True\n\nwith tf.Session(config=config) as sess:\n    for i, (train_acc, val_acc) in enumerate(zip(training_acc,validation_acc)):\n        result_log = sess.run(val_summary_op, feed_dict={train_acc_place : train_acc,\n                                                         val_acc_place   : val_acc   })\n        train_writer.add_summary(result_log, i)\n    train_writer.add_session_log(tf.SessionLog(status=tf.SessionLog.STOP))\n    train_writer.close()\n"""
dataloader.py,7,"b""import tensorflow as tf\nimport scipy.io as sio    \nimport numpy as np\n\ndef Dataloader(name, home_path, model_name):\n    if name == 'cifar100':\n        return Cifar100(home_path, model_name)\n\ndef Cifar100(home_path, model_name):\n    from tensorflow.keras.datasets.cifar100 import load_data\n    (train_images, train_labels), (val_images, val_labels) = load_data()\n    teacher = sio.loadmat(home_path + '/pre_trained/%s.mat'%model_name)\n    def pre_processing(image, is_training):\n        with tf.variable_scope('preprocessing'):\n            image = tf.cast(image, tf.float32)\n            image = (image-np.array([112.4776,124.1058,129.3773]))/np.array([70.4587,65.4312,68.2094])\n            def augmentation(image):\n                image = tf.image.random_flip_left_right(image) # tf.__version__ > 1.10\n                sz = tf.shape(image)\n                image = tf.pad(image, [[0,0],[4,4],[4,4],[0,0]], 'REFLECT')\n                image = tf.random_crop(image,sz)\n                return image\n            image = tf.cond(is_training, lambda : augmentation(image), lambda : image)\n        return image\n    \n    return train_images, train_labels, val_images, val_labels, pre_processing, teacher\n"""
op_util.py,79,"b""import tensorflow as tf\nfrom tensorflow.python.ops import control_flow_ops\nfrom re import split\n\ndef Optimizer_w_Distillation(class_loss, LR, epoch, init_epoch, global_step, Distillation):\n    with tf.variable_scope('Optimizer_w_Distillation'):\n        # get variables and update operations\n        variables  = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        teacher_variables = tf.get_collection('Teacher')\n        variables = list(set(variables)-set(teacher_variables))\n        \n        # make optimizer w/ learning rate scheduler\n        optimize = tf.train.MomentumOptimizer(LR, 0.9, use_nesterov=True)\n        if Distillation is None:\n            # training main-task\n            total_loss = class_loss + tf.add_n(tf.losses.get_regularization_losses())\n            tf.summary.scalar('loss/total_loss', total_loss)\n            gradients  = optimize.compute_gradients(total_loss, var_list = variables)\n            \n        elif Distillation == 'Soft_logits':\n            # multi-task learning with alpha\n            total_loss = tf.add_n(tf.losses.get_regularization_losses()) + class_loss*0.7 + tf.get_collection('dist')[0]*0.3\n            tf.summary.scalar('loss/total_loss', total_loss)\n            gradients  = optimize.compute_gradients(total_loss, var_list = variables)\n            \n        elif Distillation in {'AT', 'RKD', 'VID'}:\n            # simple multi-task learning\n            total_loss = class_loss + tf.add_n(tf.losses.get_regularization_losses()) + tf.get_collection('dist')[0]\n            tf.summary.scalar('loss/total_loss', total_loss)\n            gradients  = optimize.compute_gradients(total_loss, var_list = variables)\n            \n        elif Distillation[:3] == 'KD-':\n            # multi-task learning w/ distillation gradients clipping\n            # distillation gradients are clipped by norm of main-task gradients\n            reg_loss = tf.add_n(tf.losses.get_regularization_losses())\n            distillation_loss = tf.get_collection('dist')[0]\n\n            total_loss = class_loss + reg_loss + distillation_loss\n            tf.summary.scalar('loss/total_loss', total_loss)\n            tf.summary.scalar('loss/distillation_loss', distillation_loss)\n            gradients  = optimize.compute_gradients(class_loss,             var_list = variables)\n            gradient_wdecay = optimize.compute_gradients(reg_loss,          var_list = variables)\n            gradient_dist   = optimize.compute_gradients(distillation_loss, var_list = variables)\n            \n            with tf.variable_scope('clip_grad'):\n                for i, (gc, gw, gd) in enumerate(zip(gradients,gradient_wdecay,gradient_dist)):\n                    gw = 0. if gw[0] is None else gw[0]\n                    if gd[0] != None:\n                        norm = tf.sqrt(tf.reduce_sum(tf.square(gc[0])))*sigmoid(epoch, 0)\n                        gradients[i] = (gc[0] + gw + tf.clip_by_norm(gd[0], norm), gc[1])\n                    elif gc[0] != None:\n                        gradients[i] = (gc[0] + gw, gc[1])\n                        \n            if Distillation[-3:] == 'SVP':\n                gradient_dist += optimize.compute_gradients(tf.add_n(tf.get_collection('basis_loss')),\n                                                            var_list = tf.get_collection('basises'))\n                \n        # merge update operators and make train operator\n        update_ops.append(optimize.apply_gradients(gradients, global_step=global_step))\n        update_op = tf.group(*update_ops)\n        train_op = control_flow_ops.with_dependencies([update_op], total_loss, name='train_op')\n        return train_op\n\ndef Optimizer_w_Initializer(class_loss, LR, epoch, init_epoch, global_step):\n    with tf.variable_scope('Optimizer_w_Distillation'):\n        # get variables and update operations\n        variables  = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        teacher_variables = tf.get_collection('Teacher')\n        variables = list(set(variables)-set(teacher_variables))\n        \n        # make optimizer w/ learning rate scheduler\n        optimize = tf.train.MomentumOptimizer(LR, 0.9, use_nesterov=True)\n        # initialization and fine-tuning\n        # in initialization phase, weight decay have to be turn-off which is not trained by distillation\n        reg_loss = tf.add_n(tf.losses.get_regularization_losses())\n        distillation_loss = tf.get_collection('dist')[0]\n\n        total_loss = class_loss + reg_loss\n        tf.summary.scalar('loss/total_loss', total_loss)\n        gradients  = optimize.compute_gradients(total_loss, var_list = variables)\n        \n        gradient_dist   = optimize.compute_gradients(distillation_loss, var_list = variables)\n        gradient_wdecay = optimize.compute_gradients(reg_loss,          var_list = variables)\n        with tf.variable_scope('clip_grad'):\n            for i, (gw, gd) in enumerate(zip(gradient_wdecay, gradient_dist)):\n                if gd[0] is not None:\n                    gradient_dist[i] = (gw[0] + gd[0], gd[1])\n\n        # merge update operators and make train operator\n        update_ops.append(optimize.apply_gradients(gradients, global_step=global_step))\n        update_op = tf.group(*update_ops)\n        train_op = control_flow_ops.with_dependencies([update_op], total_loss, name='train_op')\n        \n        update_ops_dist = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        update_ops_dist.append(optimize.apply_gradients(gradient_dist, global_step=global_step))\n        update_op_dist = tf.group(*update_ops_dist)\n        train_op_dist = control_flow_ops.with_dependencies([update_op_dist], distillation_loss, name='train_op_dist')\n        return train_op, train_op_dist\n\ndef Optimizer_w_DML(class_loss, LR, epoch, init_epoch, global_step):\n    with tf.variable_scope('Optimizer_w_Distillation'):\n        # get variables and update operations\n        teacher_variables  = [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) if split('/',v.name)[0] == 'Teacher']\n        teacher_update_ops = [u for u in tf.get_collection(tf.GraphKeys.UPDATE_OPS)          if split('/',u.name)[0] == 'Teacher']\n        teacher_reg_loss   = tf.add_n([l for l in tf.losses.get_regularization_losses()      if split('/',l.name)[0] == 'Teacher'])\n        \n        student_variables  = [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) if split('/',v.name)[0] == 'Student']\n        student_update_ops = [u for u in tf.get_collection(tf.GraphKeys.UPDATE_OPS)          if split('/',u.name)[0] == 'Student']\n        student_reg_loss   = tf.add_n([l for l in tf.losses.get_regularization_losses()      if split('/',l.name)[0] == 'Student'])\n        \n        optimize = tf.train.MomentumOptimizer(LR, 0.9, use_nesterov=True)\n        teacher_loss = tf.get_collection('teacher_class_loss')[0] + teacher_reg_loss + tf.get_collection('dist')[0]\n        student_loss = class_loss + student_reg_loss + tf.get_collection('dist')[0]\n        \n        tf.summary.scalar('loss/total_loss', student_loss)\n        gradients_teacher = optimize.compute_gradients(teacher_loss, var_list = teacher_variables)\n        gradients_student = optimize.compute_gradients(student_loss, var_list = student_variables)\n        \n        # merge update operators and make train operator\n        teacher_update_ops.append(optimize.apply_gradients(gradients_teacher))\n        teacher_update_op = tf.group(*teacher_update_ops)\n        teacher_train_op = control_flow_ops.with_dependencies([teacher_update_op], teacher_loss, name='teacher_train_op')\n        \n        student_update_ops.append(optimize.apply_gradients(gradients_student, global_step=global_step))\n        student_update_op = tf.group(*student_update_ops)\n        student_train_op = control_flow_ops.with_dependencies([student_update_op], student_loss, name='student_train_op')\n        \n        return teacher_train_op, student_train_op\n\ndef Optimizer_w_FT(class_loss, LR, epoch, init_epoch, global_step):\n    with tf.variable_scope('Optimizer_w_Distillation'):\n        # get variables and update operations\n        variables_teacher = tf.get_collection('Teacher')\n        variables_para    = tf.get_collection('Para')\n        variables         = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))-set(variables_teacher)-set(variables_para))\n        \n        reg_loss  = tf.add_n(tf.losses.get_regularization_losses())\n               \n        distillation_loss = tf.add_n(tf.get_collection('dist'))*5e2\n        \n        total_loss = distillation_loss + reg_loss + class_loss\n        tf.summary.scalar('loss/total_loss', total_loss)\n        tf.summary.scalar('loss/distillation_loss', distillation_loss)\n        \n        optimize  = tf.train.MomentumOptimizer(LR, 0.9, use_nesterov=True)\n        gradients      = optimize.compute_gradients(total_loss, var_list = variables)\n\n           \n        # merge update operators and make train operator\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        update_ops.append(optimize.apply_gradients(gradients, global_step=global_step))\n        update_op = tf.group(*update_ops)\n        train_op = control_flow_ops.with_dependencies([update_op], total_loss, name='train_op')\n\n        para_loss = tf.add_n(tf.get_collection('Para_loss'))\n        for v in variables_para:\n            if split('/',v.name)[-1][0] == 'w':\n                para_loss += tf.reduce_sum(tf.square(v))*5e-4\n\n        gradients_para = optimize.compute_gradients(para_loss, var_list = variables_para)\n        update_ops_para = [optimize.apply_gradients(gradients_para, global_step=global_step)]\n        update_ops_para = tf.group(*update_ops_para)\n        train_op_para = control_flow_ops.with_dependencies([update_ops_para], para_loss, name='train_op_para')\n        return train_op, train_op_para\n        \ndef Optimizer_w_MHGD(class_loss, LR, epoch, init_epoch, global_step):\n    with tf.variable_scope('Optimizer_w_Distillation'):\n        # get variables and update operations\n        variables_mha     = tf.get_collection('MHA')\n        variables         = [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) if split('/',v.name)[0] == 'Student']\n        reg_loss          = tf.add_n(tf.losses.get_regularization_losses())\n        distillation_loss = tf.get_collection('dist')[0]\n        \n        total_loss = distillation_loss + reg_loss + class_loss\n        tf.summary.scalar('loss/total_loss', total_loss)\n        tf.summary.scalar('loss/distillation_loss', distillation_loss)\n        \n        optimize = tf.train.MomentumOptimizer(LR, 0.9, use_nesterov=True)\n        \n        gradients        = optimize.compute_gradients(class_loss,        var_list = variables)\n        gradients_wdecay = optimize.compute_gradients(reg_loss,          var_list = variables)\n        gradients_dist   = optimize.compute_gradients(distillation_loss, var_list = variables)\n\n        with tf.variable_scope('clip_grad'):\n            for i, (gc, gw, gd) in enumerate(zip(gradients,gradients_wdecay,gradients_dist)):\n                gw = 0. if gw[0] is None else gw[0]\n                if gd[0] != None:\n                    norm = tf.sqrt(tf.reduce_sum(tf.square(gc[0])))*sigmoid(epoch-init_epoch, 0)\n                    gd = tf.clip_by_norm(gd[0], norm)\n                    gradients[i] = (gw + gc[0] + gd, gc[1])\n                elif gc[0] != None:\n                    gradients[i] = (gw + gc[0]     , gc[1])\n\n        # merge update operators and make train operator\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        update_ops_mha = [u for u in update_ops if split('/',u.name)[0] == 'Distillation']\n        update_ops     = [u for u in update_ops if split('/',u.name)[0] == 'Student']\n        update_ops.append(optimize.apply_gradients(gradients, global_step=global_step))\n        update_op = tf.group(*update_ops)\n        train_op = control_flow_ops.with_dependencies([update_op], total_loss, name='train_op')\n\n        mha_loss          = tf.add_n(tf.get_collection('MHA_loss'))\n        tf.summary.scalar('loss/mha_loss', mha_loss)\n        for v in variables_mha:\n            if v.name.split('/')[-1][0] in {'g','w','b'}:\n                mha_loss += tf.reduce_sum(tf.square(v))*5e-4\n        gradients_mha    = optimize.compute_gradients(mha_loss, var_list = variables_mha)\n        update_ops_mha.append(optimize.apply_gradients(gradients_mha, global_step=global_step))\n        update_op_mha = tf.group(*update_ops_mha)\n        train_op_mha = control_flow_ops.with_dependencies([update_op_mha], mha_loss, name='train_op_mha')\n\n        return train_op, train_op_mha\n    \ndef sigmoid(x, k, d = 1):\n    s = 1/(1+tf.exp(-(x-k)/d))\n    s = tf.cond(tf.greater(s,1-1e-8),\n                lambda : 1.0, lambda : s)\n    return s\n    \n\n"""
train_w_distill.py,39,"b""import tensorflow as tf\n\nfrom tensorflow import ConfigProto\n\nimport time, os\nimport scipy.io as sio\nimport numpy as np\nfrom random import shuffle\n\nfrom nets import nets_factory\nfrom dataloader import Dataloader\nimport op_util\n\nhome_path = os.path.dirname(os.path.abspath(__file__))\n\ntf.app.flags.DEFINE_string('train_dir', 'test',\n                           'Directory where checkpoints and event logs are written to.')\ntf.app.flags.DEFINE_string('Distillation', 'MHGD',\n                           'Distillation method : Soft_logits, FitNet, AT, FSP, DML, KD-SVD, FT, AB, RKD, MHGD')\ntf.app.flags.DEFINE_string('dataset', 'cifar100',\n                           'Distillation method : cifar100, TinyImageNet, CUB200')\ntf.app.flags.DEFINE_string('model_name', 'ResNet',\n                           'Distillation method : ResNet, WResNet')\ntf.app.flags.DEFINE_string('main_scope', 'Student',\n                           'networ`s scope')\nFLAGS = tf.app.flags.FLAGS\ndef main(_):\n    ### define path and hyper-parameter\n    Learning_rate =1e-1\n\n    batch_size = 128\n    val_batch_size = 200\n    train_epoch = 100\n    init_epoch = 40 if FLAGS.Distillation in {'FitNet', 'FSP', 'FT', 'AB', 'MHGD'} else 0\n    total_epoch = init_epoch + train_epoch\n    weight_decay = 5e-4\n\n    should_log          = 100\n    save_summaries_secs = 20\n    tf.logging.set_verbosity(tf.logging.INFO)\n    gpu_num = '0'\n\n    if FLAGS.Distillation == 'None':\n        FLAGS.Distillation = None\n        \n    train_images, train_labels, val_images, val_labels, pre_processing, teacher = Dataloader(FLAGS.dataset, home_path, FLAGS.model_name)\n    num_label = int(np.max(train_labels)+1)\n\n    dataset_len, *image_size = train_images.shape\n\n    with tf.Graph().as_default() as graph:\n        # make placeholder for inputs\n        image_ph = tf.placeholder(tf.uint8, [None]+image_size)\n        label_ph = tf.placeholder(tf.int32, [None])\n        \n        is_training_ph = tf.placeholder(tf.bool,[])\n        \n        # pre-processing\n        image = pre_processing(image_ph, is_training_ph)\n        label = tf.contrib.layers.one_hot_encoding(label_ph, num_label, on_value=1.0)\n     \n        # make global step\n        global_step = tf.train.create_global_step()\n        epoch = tf.floor_div(tf.cast(global_step, tf.float32)*batch_size, dataset_len)\n        max_number_of_steps = int(dataset_len*total_epoch)//batch_size+1\n\n        # make learning rate scheduler\n        LR = learning_rate_scheduler(Learning_rate, [epoch, init_epoch, train_epoch], [0.3, 0.6, 0.8], 0.1)\n        \n        ## load Net\n        class_loss, accuracy = MODEL(FLAGS.model_name, FLAGS.main_scope, weight_decay, image, label, [is_training_ph, epoch < init_epoch], Distillation = FLAGS.Distillation)\n        \n        #make training operator\n                #make training operator\n        if FLAGS.Distillation == 'DML':\n            train_op, teacher_train_op = op_util.Optimizer_w_DML( class_loss, LR, epoch, init_epoch, global_step)\n        elif FLAGS.Distillation in {'FitNet', 'FSP', 'AB'}:\n            train_op, train_op2 = op_util.Optimizer_w_Initializer(class_loss, LR, epoch, init_epoch, global_step)\n        elif FLAGS.Distillation == 'MHGD':\n            train_op, train_op2 = op_util.Optimizer_w_MHGD(class_loss, LR, epoch, init_epoch, global_step)\n        elif FLAGS.Distillation == 'FT':\n            train_op, train_op2 = op_util.Optimizer_w_FT(class_loss, LR, epoch, init_epoch, global_step)\n        else:\n            train_op = op_util.Optimizer_w_Distillation(class_loss, LR, epoch, init_epoch, global_step, FLAGS.Distillation)\n        \n        ## collect summary ops for plotting in tensorboard\n        summary_op = tf.summary.merge(tf.get_collection(tf.GraphKeys.SUMMARIES), name='summary_op')\n        \n        ## make placeholder and summary op for training and validation results\n        train_acc_place = tf.placeholder(dtype=tf.float32)\n        val_acc_place   = tf.placeholder(dtype=tf.float32)\n        val_summary = [tf.summary.scalar('accuracy/training_accuracy',   train_acc_place),\n                       tf.summary.scalar('accuracy/validation_accuracy', val_acc_place)]\n        val_summary_op = tf.summary.merge(list(val_summary), name='val_summary_op')\n        \n        ## start training\n        train_writer = tf.summary.FileWriter('%s'%FLAGS.train_dir,graph,flush_secs=save_summaries_secs)\n        config = ConfigProto()\n        config.gpu_options.visible_device_list = gpu_num\n        config.gpu_options.allow_growth=True\n        \n        val_itr = len(val_labels)//val_batch_size\n        logs = {'training_acc' : [], 'validation_acc' : []}\n        with tf.Session(config=config) as sess:\n            if FLAGS.Distillation is not None and FLAGS.Distillation != 'DML':\n                global_variables  = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n                n = 0\n                for v in global_variables:\n                    if teacher.get(v.name[:-2]) is not None:\n                        v._initial_value = tf.constant(teacher[v.name[:-2]].reshape(*v.get_shape().as_list()))\n                        v._initializer_op = tf.assign(v._variable,v._initial_value,name= v.name[:-2]+'/Assign').op\n                        n += 1\n                print ('%d Teacher params assigned'%n)\n            sess.run(tf.global_variables_initializer())\n                \n            sum_train_accuracy = []; time_elapsed = []; total_loss = []\n            idx = list(range(train_labels.shape[0]))\n            shuffle(idx)\n            epoch_ = 0\n            \n            for step in range(max_number_of_steps):\n                start_time = time.time()\n                \n                ## feed data\n                if FLAGS.Distillation == 'DML':\n                    sess.run([teacher_train_op],\n                             feed_dict = {image_ph : train_images[idx[:batch_size]],\n                                          label_ph : np.squeeze(train_labels[idx[:batch_size]]),\n                                          is_training_ph : True})\n                                          \n                if FLAGS.Distillation in {'FitNet', 'FSP', 'FT', 'AB', 'MHGD', 'PCA_KD'} and (step*batch_size)//dataset_len < init_epoch:\n                    tl, log, train_acc = sess.run([train_op2, summary_op, accuracy],\n                                                  feed_dict = {image_ph : train_images[idx[:batch_size]],\n                                                               label_ph : np.squeeze(train_labels[idx[:batch_size]]),\n                                                               is_training_ph : True})\n                else:\n                    tl, log, train_acc = sess.run([train_op, summary_op, accuracy],\n                                                  feed_dict = {image_ph : train_images[idx[:batch_size]],\n                                                               label_ph : np.squeeze(train_labels[idx[:batch_size]]),\n                                                               is_training_ph : True})\n    \n                time_elapsed.append( time.time() - start_time )\n                total_loss.append(tl)\n                sum_train_accuracy.append(train_acc)\n                idx[:batch_size] = []\n                if len(idx) < batch_size:\n                    idx_ = list(range(train_labels.shape[0]))\n                    shuffle(idx_)\n                    idx += idx_\n                \n                step += 1\n                if (step*batch_size)//dataset_len>=init_epoch+epoch_:\n                    ## do validation\n                    sum_val_accuracy = []\n                    for i in range(val_itr):\n                        acc = sess.run(accuracy, feed_dict = {image_ph : val_images[i*val_batch_size:(i+1)*val_batch_size],\n                                                              label_ph : np.squeeze(val_labels[i*val_batch_size:(i+1)*val_batch_size]),\n                                                              is_training_ph : False})\n                        sum_val_accuracy.append(acc)\n                        \n                    sum_train_accuracy = np.mean(sum_train_accuracy)*100 if (step*batch_size)//dataset_len>init_epoch else 1.\n                    sum_val_accuracy= np.mean(sum_val_accuracy)*100\n                    tf.logging.info('Epoch %s Step %s - train_Accuracy : %.2f%%  val_Accuracy : %.2f%%'\n                                    %(str(epoch_).rjust(3, '0'), str(step).rjust(6, '0'), \n                                    sum_train_accuracy, sum_val_accuracy))\n\n                    result_log = sess.run(val_summary_op, feed_dict={train_acc_place : sum_train_accuracy,\n                                                                     val_acc_place   : sum_val_accuracy   })\n                    logs['training_acc'].append(sum_train_accuracy)\n                    logs['validation_acc'].append(sum_val_accuracy)\n    \n                    if (step*batch_size)//dataset_len == init_epoch and FLAGS.Distillation in {'FitNet', 'FSP', 'AB'}:\n                        #re-initialize Momentum for fair comparison w/ initialization and multi-task learning methods\n                        for v in global_variables:\n                            if v.name[:-len('Momentum:0')]=='Momentum:0':\n                                sess.run(v.assign(np.zeros(*v.get_shape().as_list()) ))\n                                \n                    if step == max_number_of_steps:\n                        train_writer.add_summary(result_log, train_epoch)\n                    else:\n                        train_writer.add_summary(result_log, epoch_)\n                    sum_train_accuracy = []\n\n                    epoch_ += 1\n                    \n                    variables  = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)+tf.get_collection('BN_collection')\n                    \n                if step % should_log == 0:\n                    tf.logging.info('global step %s: loss = %.4f (%.3f sec/step)',str(step).rjust(6, '0'), np.mean(total_loss), np.mean(time_elapsed))\n                    train_writer.add_summary(log, step)\n                    time_elapsed = []\n                    total_loss = []\n                \n                \n                elif (step*batch_size) % dataset_len == 0:\n                    train_writer.add_summary(log, step)\n\n            ## save variables to use for something\n            var = {}\n            variables  = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)+tf.get_collection('BN_collection')\n            for v in variables:\n                if v.name.split('/')[0] == FLAGS.main_scope:\n                    var[v.name[:-2]] = sess.run(v)\n            \n            sio.savemat(FLAGS.train_dir + '/train_params.mat',var)\n            sio.savemat(FLAGS.train_dir + '/log.mat',logs)\n            \n            ## close all\n            tf.logging.info('Finished training! Saving model to disk.')\n            train_writer.add_session_log(tf.SessionLog(status=tf.SessionLog.STOP))\n            train_writer.close()\n\ndef MODEL(model_name, scope, weight_decay, image, label, is_training, Distillation):\n    network_fn = nets_factory.get_network_fn(model_name, weight_decay = weight_decay)\n    end_points = network_fn(image, label, scope, is_training=is_training, Distill=Distillation)\n\n    loss = tf.losses.softmax_cross_entropy(label,end_points['Logits'])\n    if Distillation == 'DML':\n        tf.add_to_collection('teacher_class_loss',tf.losses.softmax_cross_entropy(label,end_points['Logits_tch']))\n    accuracy = tf.contrib.metrics.accuracy(tf.cast(tf.argmax(end_points['Logits'], 1), tf.int32), tf.cast(tf.argmax(label, 1),tf.int32))\n    return loss, accuracy\n    \ndef learning_rate_scheduler(Learning_rate, epochs, decay_point, decay_rate):\n    with tf.variable_scope('learning_rate_scheduler'):\n        e, ie, te = epochs\n        for i, dp in enumerate(decay_point):\n            Learning_rate = tf.cond(tf.greater_equal(e, ie + int(te*dp)), lambda : Learning_rate*decay_rate, \n                                                                          lambda : Learning_rate)\n        tf.summary.scalar('learning_rate', Learning_rate)\n        return Learning_rate\n\nif __name__ == '__main__':\n    tf.app.run()\n\n\n"""
nets/Multiple.py,30,"b""import tensorflow as tf\n\ndef FitNet(student, teacher):\n    '''\n     Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta,  and  Yoshua  Bengio.\n     Fitnets:   Hints  for  thin  deep  nets.\n     arXiv preprint arXiv:1412.6550, 2014.\n    '''\n    def Guided(source, target):\n        with tf.variable_scope('Guided'):\n            Ds = source.get_shape().as_list()[-1]\n            Dt = target.get_shape().as_list()[-1]\n            if Ds != Dt:\n                with tf.variable_scope('Map'):\n                    target = tf.contrib.layers.fully_connected(target, Ds, biases_initializer = None, trainable=True, scope = 'fc')\n            \n            return tf.reduce_mean(tf.square(source-target))\n    return tf.add_n([Guided(std, tch) for i, std, tch in zip(range(len(student)), student, teacher)])\n\ndef Attention_transfer(student, teacher, beta = 1e3):\n    '''\n     Zagoruyko, Sergey and Komodakis, Nikos.\n     Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer.\n     arXiv preprint arXiv:1612.03928, 2016.\n    '''\n    def Attention(source, target):\n        with tf.variable_scope('Attention'):\n            B,_,_,Ds = source.get_shape().as_list()\n            Dt = target.get_shape().as_list()[-1]\n            if Ds != Dt:\n                with tf.variable_scope('Map'):\n                    source = tf.contrib.layers.fully_connected(source, Ds, biases_initializer = None, trainable=True, scope = 'fc')\n            \n            Qt = tf.reduce_mean(tf.square(source),-1)\n            Qt = tf.nn.l2_normalize(Qt, [1,2])\n            \n            Qs = tf.reduce_mean(tf.square(target),-1)\n            Qs = tf.nn.l2_normalize(Qs, [1,2])\n            \n            return tf.reduce_mean(tf.square(Qt-Qs))*beta/2\n    return tf.add_n([Attention(std, tch) for i, std, tch in zip(range(len(student)), student, teacher)])\n    \ndef AB_distillation(student, teacher, margin=1., weight = 3e-3):\n    '''\n    Byeongho Heo,  Minsik Lee,  Sangdoo Yun,  and Jin Young Choi.   \n    Knowledge transfer via distillation of activation boundaries formed by hidden neurons.\n    AAAI Conference on Artificial Intelligence (AAAI), 2019.\n    '''\n    def criterion_alternative_L2(source, target, margin, num):\n        with tf.variable_scope('criterion_alternative_L2'):\n            Dt = target.get_shape().as_list()[-1]\n            with tf.variable_scope('Map'):\n                source = tf.contrib.layers.conv2d(source, Dt, [1, 1], biases_initializer = None, trainable=True, scope = 'connector%d' % (num))\n                source = tf.contrib.layers.batch_norm(source, scope='connector_bn%d' %num, is_training=True, trainable = True, activation_fn = None)\n            \n            loss = tf.square(source + margin) * tf.cast(tf.logical_and(source > -margin, target <= 0.), tf.float32)\\\n                  +tf.square(source - margin) * tf.cast(tf.logical_and(source <= margin, target > 0.), tf.float32)\n            return tf.reduce_mean(tf.reduce_sum(tf.abs(loss),[1,2,3]))\n    return tf.add_n([criterion_alternative_L2(std, tch, margin, i)/2**(-i)\n                    for i, std, tch in zip(range(len(student)), student, teacher)])*weight\n    \ndef VID(student_feature_maps, teacher_feature_maps, l = 1e-1):\n    '''\n    Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D. Lawrence, Zhenwen Dai.\n    Variational Information Distillation for Knowledge Transfer.\n    In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n    '''\n    with tf.variable_scope('VID'):\n        Distillation_loss = []\n        for i, (sfm, tfm) in enumerate(zip(student_feature_maps, teacher_feature_maps)):\n            with tf.variable_scope('vid%d'%i):\n                C = tfm.get_shape().as_list()[-1]\n                if len(tfm.get_shape().as_list()) > 2:\n                    for i in range(3):\n                        sfm = tf.contrib.layers.batch_norm(tf.contrib.layers.fully_connected(sfm, C*2 if i != 2 else C, scope = 'fc%d'%i),\n                                                           activation_fn = tf.nn.relu if i != 2 else None, scope = 'bn%d'%i)\n                \n                alpha = tf.get_variable('alpha', [1,1,1,C], tf.float32, trainable = True, initializer = tf.constant_initializer(5.))\n                var   = tf.math.softplus(alpha)+1\n                vid_loss = tf.reduce_mean(tf.log(var) + tf.square(tfm - sfm)/var)/2\n                \n                Distillation_loss.append(vid_loss)\n            \n        Distillation_loss =  tf.add_n(Distillation_loss)\n        return Distillation_loss\n"""
nets/Relation.py,59,"b""import tensorflow as tf\nfrom nets import SVP\n\ntcl = tf.contrib.layers\n\ndef RKD(source, target, l = [1e2,2e2]):\n    '''\n    Wonpyo Park, Dongju Kim, Yan Lu, Minsu Cho.  \n    relational knowledge distillation.\n    arXiv preprint arXiv:1904.05068, 2019.\n    '''\n    with tf.variable_scope('Relational_Knowledge_distillation'):\n        def Huber_loss(x,y):\n            with tf.variable_scope('Huber_loss'):\n                return tf.reduce_mean(tf.where(tf.less_equal(tf.abs(x-y), 1.), \n                                               tf.square(x-y)/2, tf.abs(x-y)-1/2))\n            \n        def Distance_wise_potential(x):\n            with tf.variable_scope('DwP'):\n                x_square = tf.reduce_sum(tf.square(x),-1)\n                prod = tf.matmul(x,x,transpose_b=True)\n                distance = tf.sqrt(tf.maximum(tf.expand_dims(x_square,1)+tf.expand_dims(x_square,0) -2*prod, 1e-12))\n                mu = tf.reduce_sum(distance)/tf.reduce_sum(tf.where(distance > 0., tf.ones_like(distance), tf.zeros_like(distance)))\n                return distance/(mu+1e-8)\n            \n        def Angle_wise_potential(x):\n            with tf.variable_scope('AwP'):\n                e = tf.expand_dims(x,0)-tf.expand_dims(x,1)\n                e_norm = tf.nn.l2_normalize(e,2)\n            return tf.matmul(e_norm, e_norm,transpose_b=True)\n\n        source = tf.nn.l2_normalize(source,1)\n        target = tf.nn.l2_normalize(target,1)\n        distance_loss = Huber_loss(Distance_wise_potential(source),Distance_wise_potential(target))\n        angle_loss    = Huber_loss(   Angle_wise_potential(source),   Angle_wise_potential(target))\n        \n        return distance_loss*l[0]+angle_loss*l[1]    \n    \ndef MHGD(student_feature_maps, teacher_feature_maps):\n    '''\n    Seunghyun Lee, Byung Cheol Song.\n    Graph-based Knowledge Distillation by Multi-head Attention Network.\n    British Machine Vision Conference (BMVC) 2019\n    '''\n    with tf.variable_scope('MHGD'):\n        GNN_losses = []\n        num_head = 8\n        V_Tb = V_Sb = None\n        num_feat = len(student_feature_maps)\n        for i, sfm, tfm in zip(range(num_feat), student_feature_maps, teacher_feature_maps):\n            with tf.variable_scope('Compress_feature_map%d'%i):\n                Sigma_T, U_T, V_T = SVP.SVD_eid(tfm, 1, name = 'TSVD%d'%i)\n                _,       U_S, V_S = SVP.SVD_eid(sfm, 4, name = 'SSVD%d'%i)\n                V_S, V_T = SVP.Align_rsv(V_S, V_T)\n                D = V_T.get_shape().as_list()[1]\n            \n                V_T = tf.reshape(V_T,[-1,D])\n                V_S = tf.reshape(V_S,[-1,D])\n\n            with tf.variable_scope('MHA%d'%i):\n                if i > 0:\n                    _,D_, = V_Sb.get_shape().as_list()\n                    D2 = (D+D_)//2\n                    G_T = Attention_head(V_T, V_Tb, D2, num_head, 'Attention', is_training = True)\n                    V_T_ = Estimator(V_Tb, G_T, D, num_head, 'Estimator', is_training = True)\n                    tf.add_to_collection('MHA_loss', tf.reduce_mean(1-tf.reduce_sum(V_T_*V_T, -1)) )\n                    \n                    G_T = Attention_head(V_T, V_Tb, D2, num_head, 'Attention', reuse = True)\n                    G_S = Attention_head(V_S, V_Sb, D2, num_head, 'Attention', reuse = True)\n                    G_T = tf.tanh(G_T)\n                    G_S = tf.tanh(G_S)\n               \n                    GNN_losses.append(kld_loss(G_S, G_T))\n                    \n            V_Tb, V_Sb = V_T, V_S\n\n        transfer_loss =  tf.add_n(GNN_losses)\n\n        return transfer_loss\n    \ndef Attention_head(K, Q, D, num_head, name, is_training = False, reuse = False):\n    with tf.variable_scope(name):\n        with tf.contrib.framework.arg_scope([tf.contrib.layers.fully_connected], trainable = not(reuse), reuse = reuse,\n                                            weights_regularizer=None, variables_collections = [tf.GraphKeys.GLOBAL_VARIABLES,'MHA']):\n            with tf.contrib.framework.arg_scope([tf.contrib.layers.batch_norm], activation_fn=None, trainable = not(reuse), is_training = is_training, reuse =  reuse,\n                                                param_regularizers = None, variables_collections=[tf.GraphKeys.GLOBAL_VARIABLES,'MHA']):\n                B = tf.squeeze(tf.slice(tf.shape(K),[0],[1]))\n                \n                X_sender   = tf.contrib.layers.fully_connected(K, D*num_head, scope = 'Sfc')\n                X_sender   = tf.contrib.layers.batch_norm(X_sender, scope = 'Sbn')\n                X_sender   = tf.reshape(X_sender,   [B, D, num_head])\n\n                X_receiver = tf.contrib.layers.fully_connected(Q, D*num_head, scope = 'Rfc', reuse = reuse)\n                X_receiver = tf.contrib.layers.batch_norm(X_receiver, scope = 'Rbn')\n                X_receiver = tf.reshape(X_receiver, [B, D, num_head])\n                \n                X_sender   = tf.transpose(X_sender,  [2,0,1])\n                X_receiver = tf.transpose(X_receiver,[2,1,0])\n                X_ah = tf.matmul(X_sender, X_receiver)\n\n    return X_ah\n\ndef Estimator(X, G, Dy, num_head, name, is_training):\n    with tf.variable_scope(name):\n        with tf.contrib.framework.arg_scope([tf.contrib.layers.fully_connected], trainable = True, \n                                            weights_regularizer=None, variables_collections = [tf.GraphKeys.GLOBAL_VARIABLES,'MHA']):\n            with tf.contrib.framework.arg_scope([tf.contrib.layers.batch_norm], activation_fn=tf.nn.relu, trainable = True,\n                                                param_regularizers = None, variables_collections=[tf.GraphKeys.GLOBAL_VARIABLES,'MHA']):\n                B = tf.squeeze(tf.slice(tf.shape(G),[1],[1]))\n                G = tf.nn.softmax(G)\n                G = drop_head(G, [num_head, B, 1])\n                G = tf.reshape(G, [num_head*B, B])\n                \n                Dx = X.get_shape().as_list()[-1]\n                D = (Dx+Dy)//2\n                \n                X = tf.contrib.layers.fully_connected(X, D, scope = 'fc0')\n                X = tf.contrib.layers.batch_norm(X, activation_fn = tf.nn.relu, scope = 'bn0', is_training = is_training)\n\n                X = tf.reshape(tf.matmul(G, X), [num_head, B, D])\n                X = tf.reshape(tf.transpose(X,[1,0,2]),[B,D*num_head])\n                \n                X = tf.contrib.layers.fully_connected(X, Dy, biases_initializer=tf.zeros_initializer(), scope = 'fc1')\n                X = tf.nn.l2_normalize(X, -1)\n    return X\n    \ndef drop_head(G, shape):\n    with tf.variable_scope('Drop'):\n        noise = tf.random.normal(shape)\n        G *= tf.where(noise - tf.reduce_mean(noise, 0, keepdims=True) > 0, tf.ones_like(noise), tf.zeros_like(noise))\n        return G\n        \ndef kld_loss(X, Y):\n    with tf.variable_scope('KLD'):\n        return tf.reduce_sum( tf.nn.softmax(X)*(tf.nn.log_softmax(X)-tf.nn.log_softmax(Y)) )\n"""
nets/ResNet.py,31,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom nets import Response, Multiple, Shared, Relation\n\ntcf = tf.contrib.framework\ntcl = tf.contrib.layers\n\ndef ResBlock(x, depth, stride, get_feat, name):\n    with tf.variable_scope(name):\n        out = tcl.batch_norm(tcl.conv2d(x,   depth, [3,3], stride, scope='conv0'), scope='bn0')\n        out = tcl.batch_norm(tcl.conv2d(out, depth, [3,3], 1,      scope='conv1'), scope='bn1',activation_fn = None)\n                \n        if stride > 1 or depth != x.get_shape().as_list()[-1]:\n            x = tcl.batch_norm(tcl.conv2d(x, depth, [1,1], stride, scope='conv2'), scope='bn2', activation_fn = None)\n            \n        out_ = x+out\n        out = tf.nn.relu(out_)\n        \n        if get_feat:\n            tf.add_to_collection('feat_noact', out_)\n            tf.add_to_collection('feat', out)\n        return out\n    \ndef NetworkBlock(x, nb_layers, depth, stride, name = ''):\n    with tf.variable_scope(name):\n        for i in range(nb_layers):           \n            x = ResBlock(x, depth, stride = stride if i == 0 else 1,\n                         get_feat = True if i == nb_layers-1 else False, name = 'BasicBlock%d'%i)\n        return x\n\ndef ResNet(image, label, scope, is_training, Distill = None):\n    end_points = {}\n    is_training, auxiliary_is_training = is_training\n\n    if image.get_shape().as_list()[1] == 32:\n        nChannels = [32, 64, 128, 256]\n        stride = [1,2,2]\n    else:\n        nChannels = [16, 32, 64, 128, 256, 512]\n        stride = [1,2,2,2,2]\n        \n    n = 1 if scope != 'Teacher' else 5\n    \n    with tf.variable_scope(scope):\n        with tcf.arg_scope([tcl.conv2d, tcl.fully_connected, tcl.batch_norm], trainable = True):\n            with tcf.arg_scope([tcl.dropout, tcl.batch_norm], is_training = is_training):\n                std = tcl.conv2d(image, nChannels[0], [3,3], 1, scope='conv0')\n                std = tcl.batch_norm(std, scope='bn0')\n                for i in range(len(stride)):            \n                    std = NetworkBlock(std, n, nChannels[1+i], stride[i], name = 'Resblock%d'%i)\n                fcs = tf.reduce_mean(std, [1,2])\n                logits = tcl.fully_connected(fcs , label.get_shape().as_list()[-1],\n                                             biases_initializer = tf.zeros_initializer(),\n                                             biases_regularizer = tcl.l2_regularizer(5e-4),\n                                             scope = 'full')\n                end_points['Logits'] = logits\n        \n    if Distill is not None:\n        if Distill == 'DML':\n            teacher_trainable = True\n            weight_decay = 5e-4\n            teacher_is_training = tf.logical_not(is_training)\n        else:\n            teacher_trainable = False\n            weight_decay = 0.\n            teacher_is_training = False\n            \n        arg_scope = ResNet_arg_scope_teacher(weight_decay=weight_decay)\n            \n        with tf.variable_scope('Teacher'):\n            with tcf.arg_scope(arg_scope):\n                with tcf.arg_scope([tcl.conv2d, tcl.fully_connected, tcl.batch_norm], trainable = teacher_trainable):\n                    with tcf.arg_scope([tcl.batch_norm], is_training = teacher_is_training):\n                        n = 5\n                        tch = tcl.conv2d(image, nChannels[0], [3,3], 1, scope='conv0')\n                        tch = tcl.batch_norm(tch, scope='bn0')\n                        for i in range(len(stride)):            \n                            tch = NetworkBlock(tch, n, nChannels[1+i], stride[i], name = 'Resblock%d'%i)\n                        fct = tf.reduce_mean(tch, [1,2])\n                        logits_tch = tcl.fully_connected(fct , label.get_shape().as_list()[-1],\n                                                         biases_initializer = tf.zeros_initializer(),\n                                                         biases_regularizer = tcl.l2_regularizer(weight_decay) if weight_decay > 0. else None,\n                                                         scope = 'full')\n                        end_points['Logits_tch'] = logits_tch\n                    \n        with tf.variable_scope('Distillation'):\n            feats = tf.get_collection('feat')\n            student_feats = feats[:len(feats)//2]\n            teacher_feats = feats[len(feats)//2:]\n            \n            feats_noact = tf.get_collection('feat')\n            student_feats_noact = feats_noact[:len(feats)//2]\n            teacher_feats_noact = feats_noact[len(feats)//2:]\n            \n            if Distill == 'Soft_logits':\n                tf.add_to_collection('dist', Response.Soft_logits(logits, logits_tch, 4))\n            elif Distill == 'DML':\n                tf.add_to_collection('dist', Response.DML(logits, logits_tch))\n            elif Distill == 'FT':\n                tf.add_to_collection('dist', Response.Factor_Transfer(student_feats_noact[-1], teacher_feats_noact[-1]))\n                \n            elif Distill == 'FitNet':\n                tf.add_to_collection('dist', Multiple.FitNet(student_feats, teacher_feats))\n            elif Distill == 'AT':\n                tf.add_to_collection('dist', Multiple.Attention_transfer(student_feats, teacher_feats))\n            elif Distill == 'AB':\n                tf.add_to_collection('dist', Multiple.AB_distillation(student_feats, teacher_feats, 1., 3e-3))\n                \n            elif Distill == 'FSP':\n                tf.add_to_collection('dist', Shared.FSP(student_feats, teacher_feats))\n            elif Distill[:3] == 'KD-':\n                tf.add_to_collection('dist', Shared.KD_SVD(student_feats, teacher_feats, Distill[-3:]))\n\n            elif Distill == 'RKD':\n                tf.add_to_collection('dist', Relation.RKD(fcs, fct, l = [25,50]))\n            elif Distill == 'MHGD':\n                tf.add_to_collection('dist', Relation.MHGD(student_feats, teacher_feats))\n                \n    return end_points\n\ndef ResNet_arg_scope(weight_decay=0.0005):\n    with tcf.arg_scope([tcl.conv2d, tcl.fully_connected], \n                       weights_initializer=tcl.variance_scaling_initializer(mode='FAN_OUT'),\n                       weights_regularizer=tcl.l2_regularizer(weight_decay),\n                       biases_initializer=None, activation_fn = None):\n        with tcf.arg_scope([tcl.batch_norm], scale = True, center = True, activation_fn=tf.nn.relu, decay=0.9, epsilon = 1e-5,\n                           param_regularizers={'gamma': tcl.l2_regularizer(weight_decay),\n                                               'beta' : tcl.l2_regularizer(weight_decay)},\n                           variables_collections=[tf.GraphKeys.GLOBAL_VARIABLES,'BN_collection']) as arg_sc:\n            return arg_sc\ndef ResNet_arg_scope_teacher(weight_decay=0.0005):\n    with tcf.arg_scope([tcl.conv2d, tcl.fully_connected], \n                       weights_regularizer = tcl.l2_regularizer(weight_decay) if weight_decay > 0. else None,\n                       variables_collections=[tf.GraphKeys.GLOBAL_VARIABLES,'Teacher']):\n        with tcf.arg_scope([tcl.batch_norm], \n                           param_regularizers={'gamma': tcl.l2_regularizer(weight_decay),\n                                               'beta' : tcl.l2_regularizer(weight_decay)} if weight_decay > 0. else None,\n                           variables_collections=[tf.GraphKeys.GLOBAL_VARIABLES,'Teacher']) as arg_sc:\n            return arg_sc\n"""
nets/Response.py,26,"b""import tensorflow as tf\n\ndef Soft_logits(student, teacher, T = 2):\n    '''\n    Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.  \n    Distilling the knowledge in a neural network.\n    arXiv preprint arXiv:1503.02531, 2015.\n    '''\n    with tf.variable_scope('KD'):\n        return tf.reduce_mean(tf.reduce_sum( tf.nn.softmax(teacher/T)*(tf.nn.log_softmax(teacher/T)-tf.nn.log_softmax(student/T)),1 ))\n\ndef DML(student, teacher):\n    '''\n    Ying Zhang, Tao Xiang, Timothy M. Hospedales, Huchuan Lu. \n    Deep mutual learning.\n    IEEE Conference on Computer Vision and Pattern Recognition. 2018.\n    '''\n    with tf.variable_scope('KD'):\n        return (tf.reduce_mean(tf.reduce_sum(tf.nn.softmax(teacher)*(tf.nn.log_softmax(teacher)-tf.nn.log_softmax(student)),1)) +\n                tf.reduce_mean(tf.reduce_sum(tf.nn.softmax(student)*(tf.nn.log_softmax(student)-tf.nn.log_softmax(teacher)),1)))/2\n\ndef Factor_Transfer(sfm, tfm):\n    '''\n    Jangho Kim, SeoungUK Park, Nojun Kwak.\n    Paraphrasing Complex Network: Network Compression via Factor Transfer.\n    Advances in Neural Information Processing Systems (NeurIPS). 2018.\n    '''\n    def Factor_transfer(X, rate, scope, reuse = False):\n        with tf.variable_scope(scope):\n            with tf.contrib.framework.arg_scope([tf.contrib.layers.conv2d, tf.contrib.layers.conv2d_transpose], weights_regularizer=None,\n                                                variables_collections = [tf.GraphKeys.GLOBAL_VARIABLES, 'Para']):\n                D = tfm.get_shape().as_list()[-1]\n                conv = tf.contrib.layers.conv2d(X,    int(D*rate**1), [3,3], 1,          scope='conv0', reuse = reuse)\n                conv = tf.contrib.layers.conv2d(conv, int(D*rate**2), [3,3], int(1/rate),scope='conv1', reuse = reuse)\n                conv = tf.contrib.layers.conv2d(conv, int(D*rate**3), [3,3], 1, activation_fn = None, scope='conv2', reuse = reuse)\n                \n                if reuse:\n                    return tf.nn.l2_normalize(conv, -1)\n                conv = tf.nn.leaky_relu(conv)\n                deconv = tf.contrib.layers.conv2d_transpose(conv,   int(D*rate**2), [3,3], 1,          scope='convt0', reuse = reuse)\n                deconv = tf.contrib.layers.conv2d_transpose(deconv, int(D*rate**1), [3,3], int(1/rate),scope='convt1', reuse = reuse)\n                deconv = tf.contrib.layers.conv2d_transpose(deconv, D, [3,3], 1,  scope='convt2', reuse = reuse)\n                return deconv\n\n    with tf.variable_scope('Factor_Transfer'):\n        with tf.contrib.framework.arg_scope([tf.contrib.layers.conv2d, tf.contrib.layers.conv2d_transpose], trainable = True,\n                                            biases_initializer = tf.zeros_initializer(), activation_fn = tf.nn.leaky_relu):\n            rate = 0.5\n            tfm_ = Factor_transfer(tfm, rate, 'Factor_transfer')\n            tf.add_to_collection('Para_loss', tf.reduce_mean(tf.reduce_mean(tf.abs(tfm-tfm_),[1,2,3])))\n                    \n            F_T = Factor_transfer(tfm, rate, 'Factor_transfer', True)\n\n            with tf.variable_scope('Translator'):\n                D = tfm.get_shape().as_list()[-1]\n                conv = tf.contrib.layers.conv2d(sfm,  int(D*rate**1), [3,3], 1,          scope='conv0')\n                conv = tf.contrib.layers.conv2d(conv, int(D*rate**2), [3,3], int(1/rate),scope='conv1')\n                conv = tf.contrib.layers.conv2d(conv, int(D*rate**3), [3,3], 1, activation_fn = None, scope='conv2')\n                F_S = tf.nn.l2_normalize(conv, -1)\n            return tf.reduce_mean(tf.reduce_mean(tf.abs(F_T-F_S),[1,2,3]))\n"""
nets/SVP.py,58,"b'import tensorflow as tf\nfrom tensorflow.python.framework import function\n\ndef removenan(x):\n    return tf.where(tf.is_finite(x), x,tf.zeros_like(x))\n\ndef SVD(X, n, name = None):\n    with tf.variable_scope(name):\n        sz = X.get_shape().as_list()\n        if len(sz)==4:\n            x = tf.reshape(X,[-1,sz[1]*sz[2],sz[3]])\n        elif len(sz)==3:\n            x = X\n        else:\n            x = tf.expand_dims(X, 1)\n            n = 1\n        _, HW, D = x.get_shape().as_list()\n\n        with tf.device(\'CPU\'):\n            g = tf.get_default_graph()\n            with g.gradient_override_map({""Svd"": ""Svd_""}):\n                s,u,v = tf.svd(x,full_matrices=False)\n                \n        s = removenan(s)\n        v = removenan(v)\n        u = removenan(u)\n        \n        if n > 0:\n            s = tf.nn.l2_normalize(tf.slice(s,[0,0],[-1,n]),1)\n            u = tf.nn.l2_normalize(tf.slice(u,[0,0,0],[-1,-1,n]),1)\n            v = tf.nn.l2_normalize(tf.slice(v,[0,0,0],[-1,-1,n]),1)\n        \n        return s, u, v\n\ndef SVD_eid(X, n, name = None):\n    with tf.variable_scope(name):\n        sz = X.get_shape().as_list()\n        if len(sz)==4:\n            x = tf.reshape(X,[-1,sz[1]*sz[2],sz[3]])\n        elif len(sz)==3:\n            x = X\n        else:\n            x = tf.expand_dims(X, 1)\n            n = 1\n        _, HW, D = x.get_shape().as_list()\n\n        x_ = tf.stop_gradient(x)\n\n        if HW/D < 3/2  and 2/3 < HW/D:\n            with tf.device(\'CPU\'):\n                g = tf.get_default_graph()\n                with g.gradient_override_map({""Svd"": ""Svd_""}):\n                    s,u,v = tf.svd(x_,full_matrices=False)\n\n        else:\n            if HW < D:\n                xxt = tf.matmul(x_,x_,transpose_b = True)\n                with tf.device(\'CPU\'):\n                    _,u_svd,_ = tf.svd(xxt,full_matrices=False)\n                v_svd = tf.matmul(x_, u_svd, transpose_a = True)\n                s_svd = tf.linalg.norm(v_svd, axis = 1)\n                v_svd = removenan(v_svd/tf.expand_dims(s_svd,1))\n                \n            else:\n                xtx = tf.matmul(x_,x_,transpose_a = True)\n                with tf.device(\'CPU\'):\n                    _, v_svd = tf.linalg.eigh(xtx)\n                v_svd = tf.reshape(tf.image.flip_left_right(tf.reshape(v_svd,[-1,D,D,1])),[-1,D,D])\n\n                u_svd = tf.matmul(x_, v_svd)\n                s_svd = tf.linalg.norm(u_svd, axis = 1)\n                u_svd = removenan(u_svd/tf.expand_dims(s_svd,1))\n    \n            s,u,v = SVD_grad_map(x,s_svd,u_svd,v_svd)\n            s = tf.reshape(s,[-1,   min(HW,D)])\n            u = tf.reshape(u,[-1,HW,min(HW,D)])\n            v = tf.reshape(v,[-1, D,min(HW,D)])\n        s = tf.nn.l2_normalize(tf.slice(s,[0,0],[-1,n])     ,1)\n        U = tf.nn.l2_normalize(tf.slice(u,[0,0,0],[-1,-1,n]),1)\n        V = tf.nn.l2_normalize(tf.slice(v,[0,0,0],[-1,-1,n]),1)\n        \n        return s, U, V\n    \ndef Align_rsv(x, y):\n    with tf.variable_scope(\'Align\'):\n        cosine = tf.matmul(x, y, transpose_a=True)\n        mask = tf.where(tf.equal(tf.reduce_max(tf.abs(cosine), 1,keepdims=True), tf.abs(cosine)),\n                       tf.sign(cosine), tf.zeros_like(cosine))\n        x = tf.matmul(x, mask)\n        return x, y\n    \n@tf.RegisterGradient(\'Svd_\')\ndef gradient_svd(op, ds, dU, dV):\n    s, U, V = op.outputs\n\n    u_sz = tf.squeeze(tf.slice(tf.shape(dU),[1],[1]))\n    v_sz = tf.squeeze(tf.slice(tf.shape(dV),[1],[1]))\n    s_sz = tf.squeeze(tf.slice(tf.shape(ds),[1],[1]))\n\n    S = tf.matrix_diag(s)\n    s_2 = tf.square(s)\n\n    eye = tf.expand_dims(tf.eye(s_sz),0) \n    k = (1 - eye)/(tf.expand_dims(s_2,2)-tf.expand_dims(s_2,1) + eye)\n    KT = tf.matrix_transpose(k)\n    KT = removenan(KT)\n    \n    def msym(X):\n        return (X+tf.matrix_transpose(X))\n    \n    def left_grad(U,S,V,dU,dV):\n        U, V = (V, U); dU, dV = (dV, dU)\n        D = tf.matmul(dU,tf.matrix_diag(1/(s+1e-8)))\n    \n        grad = tf.matmul(D - tf.matmul(U, tf.matrix_diag(tf.matrix_diag_part(tf.matmul(U,D,transpose_a=True)))\n                           + 2*tf.matmul(S, msym(KT*(tf.matmul(D,tf.matmul(U,S),transpose_a=True))))), V,transpose_b=True)\n        \n        grad = tf.matrix_transpose(grad)\n        return grad\n\n    def right_grad(U,S,V,dU,dV):\n        grad = tf.matmul(2*tf.matmul(U, tf.matmul(S, msym(KT*(tf.matmul(V,dV,transpose_a=True)))) ),V,transpose_b=True)\n        return grad\n    \n    grad = tf.cond(tf.greater(v_sz, u_sz), lambda :  left_grad(U,S,V,dU,dV), \n                                           lambda : right_grad(U,S,V,dU,dV))\n    \n    return [grad]\n\ndef gradient_eid(op, ds, dU, dV):\n    return gradient_svd(op, ds, dU, dV) + [None]*3\n\n@function.Defun(tf.float32, tf.float32,tf.float32,tf.float32,func_name = \'EID\', python_grad_func = gradient_eid)\ndef SVD_grad_map(x, s, u, v):\n    return s,u,v \n'"
nets/Shared.py,18,"b""import tensorflow as tf\nfrom nets import SVP\n\ndef FSP(students, teachers, weight = 1e-3):\n    '''\n    Junho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim.\n    A gift from knowledge distillation: Fast optimization, network minimization and transfer learning. \n    In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4133\xe2\x80\x934141, 2017.\n    '''\n    def Grammian(top, bot):\n        with tf.variable_scope('Grammian'):\n            t_sz = top.get_shape().as_list()\n            b_sz = bot.get_shape().as_list()\n    \n            if t_sz[1] > b_sz[1]:\n                top = tf.contrib.layers.max_pool2d(top, [2, 2], 2)\n                            \n            top = tf.reshape(top,[-1, b_sz[1]*b_sz[2], t_sz[-1]])\n            bot = tf.reshape(bot,[-1, b_sz[1]*b_sz[2], b_sz[-1]])\n    \n            Gram = tf.matmul(top, bot, transpose_a = True)/(b_sz[1]*b_sz[2])\n            return Gram\n    with tf.variable_scope('FSP'):\n        Dist_loss = []\n        for i in range(len(students)-1):\n            gs0 = Grammian(students[i], students[i+1])\n            gt0 = Grammian(teachers[i], teachers[i+1])\n     \n            Dist_loss.append(tf.reduce_mean(tf.reduce_sum(tf.square(tf.stop_gradient(gt0)-gs0),[1,2])/2 ))\n\n        return tf.add_n(Dist_loss)*weight\n    \ndef KD_SVD(student_feature_maps, teacher_feature_maps, dist_type = 'SVD'):\n    '''\n    Seung Hyun Lee, Dae Ha Kim, and Byung Cheol Song.\n    Self-supervised knowledge distillation using singular value decomposition. In\n    European Conference on ComputerVision, pages 339\xe2\x80\x93354. Springer, 2018.\n    '''\n    with tf.variable_scope('Distillation'):\n        GNN_losses = []\n        K = 1\n        V_Tb = V_Sb = None\n        for i, sfm, tfm in zip(range(len(student_feature_maps)), student_feature_maps, teacher_feature_maps):\n            with tf.variable_scope('Compress_feature_map%d'%i):\n                if dist_type == 'SVD':\n                    Sigma_T, U_T, V_T = SVP.SVD(tfm, K, name = 'TSVD%d'%i)\n                    Sigma_S, U_S, V_S = SVP.SVD(sfm, K+3, name = 'SSVD%d'%i)\n                    B, D,_ = V_S.get_shape().as_list()\n                    V_S, V_T = SVP.Align_rsv(V_S, V_T)\n                    \n                elif dist_type == 'EID':\n                    Sigma_T, U_T, V_T = SVP.SVD_eid(tfm, K, name = 'TSVD%d'%i)\n                    Sigma_S, U_S, V_S = SVP.SVD_eid(sfm, K+3, name = 'SSVD%d'%i)\n                    B, D,_ = V_S.get_shape().as_list()\n                    V_S, V_T = SVP.Align_rsv(V_S, V_T)\n                \n                Sigma_T = tf.expand_dims(Sigma_T,1)\n                V_T *= Sigma_T\n                V_S *= Sigma_T\n                \n            if i > 0:\n                with tf.variable_scope('RBF%d'%i):    \n                    S_rbf = tf.exp(-tf.square(tf.expand_dims(V_S,2)-tf.expand_dims(V_Sb,1))/8)\n                    T_rbf = tf.exp(-tf.square(tf.expand_dims(V_T,2)-tf.expand_dims(V_Tb,1))/8)\n\n                    l2loss = (S_rbf-tf.stop_gradient(T_rbf))**2\n                    l2loss = tf.where(tf.is_finite(l2loss), l2loss, tf.zeros_like(l2loss))\n                    GNN_losses.append(tf.reduce_sum(l2loss))\n            V_Tb = V_T\n            V_Sb = V_S\n\n        transfer_loss =  tf.add_n(GNN_losses)\n\n        return transfer_loss\n"""
nets/__init__.py,0,b'\n'
nets/nets_factory.py,1,"b""import functools\n\nimport tensorflow as tf\n\nfrom nets import ResNet\n\nnetworks_map   = {\n                 'ResNet':ResNet.ResNet,\n                 }\n\narg_scopes_map = {\n                  'ResNet':ResNet.ResNet_arg_scope,\n                 }\n\ndef get_network_fn(name, weight_decay=5e-4):\n    if name not in networks_map:\n        raise ValueError('Name of network unknown %s' % name)\n    \n    arg_scope = arg_scopes_map[name](weight_decay=weight_decay)\n    func = networks_map[name]\n    @functools.wraps(func)\n    def network_fn(images, label, scope, is_training, Distill):\n        with tf.contrib.framework.arg_scope(arg_scope):\n            return func(images, label, scope = scope, is_training=is_training, Distill=Distill)\n    if hasattr(func, 'default_image_size'):\n        network_fn.default_image_size = func.default_image_size\n\n    return network_fn\n\n"""
