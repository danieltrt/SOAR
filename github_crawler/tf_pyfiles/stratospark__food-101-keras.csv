file_path,api_count,code
food.py,0,"b'from keras.utils.np_utils import to_categorical\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom keras.layers import Input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\nimport keras.backend as K\nfrom keras.optimizers import SGD, RMSprop, Adam\n\nimport numpy as np\nfrom os import listdir\nfrom os.path import isfile, join\nimport h5py\nfrom sklearn.model_selection import train_test_split\n\n\nprint(""Loading metadata..."")\nclass_to_ix = {}\nix_to_class = {}\nwith open(\'food-101/meta/classes.txt\', \'r\') as txt:\n    classes = [l.strip() for l in txt.readlines()]\n    class_to_ix = dict(zip(classes, range(len(classes))))\n    ix_to_class = dict(zip(range(len(classes)), classes))\n    class_to_ix = {v: k for k, v in ix_to_class.items()}\n\n####### Load concatenated data from disk\nprint(""Loading X_all.hdf5"")\nh = h5py.File(\'X_all.hdf5\', \'r\')\nX_all = np.array(h.get(\'data\'))\ny_all = np.array(h.get(\'classes\'))\nh.close()\n\n####### Create train/val/test split\nprint(""Creating train/val/test/split"")\nn_classes = len(np.unique(y_all))\n\nX_train, X_val_test, y_train, y_val_test = train_test_split(X_all, y_all, test_size=.20, stratify=y_all)\nX_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=.5, stratify=y_val_test)\n\ny_train_cat = to_categorical(y_train, nb_classes=n_classes)\ny_val_cat = to_categorical(y_val, nb_classes=n_classes)\ny_test_cat = to_categorical(y_test, nb_classes=n_classes)\n\nX_all = None\nX_val_test = None\ny_val_test = None\n\nprint(""Writing X_test.hdf5"")\nh = h5py.File(\'X_test.hdf5\', \'w\')\nh.create_dataset(\'data\', data=X_test)\nh.create_dataset(\'classes\', data=y_test_cat)\nh.close()\n\n######## Set up Image Augmentation\nprint(""Setting up ImageDataGenerator"")\ndatagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range=0.125,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.125,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=False, # randomly flip images\n    rescale=1./255,\n    fill_mode=\'nearest\')\ndatagen.fit(X_train)\ngenerator = datagen.flow(X_train, y_train_cat, batch_size=32)\nval_generator = datagen.flow(X_val, y_val_cat, batch_size=32)\n\n\n## Fine tuning. 70% with image augmentation.\n## 83% with pre processing (14 mins).\n## 84.5% with rmsprop/img.aug/dropout\n## 86.09% with batchnorm/dropout/img.aug/adam(10)/rmsprop(140)\n## InceptionV3\n\nK.clear_session()\n\nbase_model = InceptionV3(weights=\'imagenet\', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# # x = Flatten()(x)\nx = Dense(4096)(x)\nx = BatchNormalization()(x)\nx = Activation(\'relu\')(x)\nx = Dropout(.5)(x)\npredictions = Dense(n_classes, activation=\'softmax\')(x)\n\n# x = base_model.output\n# x = AveragePooling2D((8, 8), strides=(8, 8), name=\'avg_pool\')(x)\n# x = Flatten(name=\'flatten\')(x)\n# predictions = Dense(101, activation=\'softmax\', name=\'predictions\')(x)\n\nmodel = Model(input=base_model.input, output=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer=\'rmsprop\', loss=\'categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\nprint(""First pass"")\ncheckpointer = ModelCheckpoint(filepath=\'/home/stratospark/Code/AI/food101/first.3.{epoch:02d}-{val_loss:.2f}.hdf5\', verbose=1, save_best_only=True)\ncsv_logger = CSVLogger(\'first.3.log\')\nmodel.fit_generator(generator,\n                    validation_data=val_generator,\n                    nb_val_samples=10000,\n                    samples_per_epoch=X_train.shape[0],\n                    nb_epoch=10,\n                    verbose=1,\n                    callbacks=[csv_logger, checkpointer])\n\nfor layer in model.layers[:172]:\n    layer.trainable = False\nfor layer in model.layers[172:]:\n    layer.trainable = True\n\nprint(""Second pass"")\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=\'categorical_crossentropy\', metrics=[\'accuracy\'])\ncheckpointer = ModelCheckpoint(filepath=\'/home/stratospark/Code/AI/food101/second.3.{epoch:02d}-{val_loss:.2f}.hdf5\', verbose=1, save_best_only=True)\ncsv_logger = CSVLogger(\'second.3.log\')\nmodel.fit_generator(generator,\n                    validation_data=val_generator,\n                    nb_val_samples=10000,\n                    samples_per_epoch=X_train.shape[0],\n                    nb_epoch=100,\n                    verbose=1,\n                    callbacks=[csv_logger, checkpointer])\n'"
tools/__init__.py,0,b''
tools/image_gen_extended.py,0,"b'\'\'\'Fairly basic set of tools for real-time data augmentation on image data.\nCan easily be extended to include new transformations,\nnew process methods, etc...\n\'\'\'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport numpy as np\nimport re\nfrom scipy import linalg\nimport scipy.ndimage as ndi\nfrom six.moves import range\nimport os\nimport sys\nimport threading\nimport copy\nimport inspect\nimport types\nimport multiprocessing as mp\n\nimport keras.backend as K\n\ndef random_rotation(x, rg, row_index=1, col_index=2, channel_index=0,\n                    fill_mode=\'nearest\', cval=0., rng=None):\n    theta = np.pi / 180 * rng.uniform(-rg, rg)\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n\n    h, w = x.shape[row_index], x.shape[col_index]\n    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_shift(x, wrg, hrg, row_index=1, col_index=2, channel_index=0,\n                 fill_mode=\'nearest\', cval=0., rng=None):\n    h, w = x.shape[row_index], x.shape[col_index]\n    tx = rng.uniform(-hrg, hrg) * h\n    ty = rng.uniform(-wrg, wrg) * w\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n\n    transform_matrix = translation_matrix  # no need to do offset\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_shear(x, intensity, row_index=1, col_index=2, channel_index=0,\n                 fill_mode=\'nearest\', cval=0., rng=None):\n    shear = rng.uniform(-intensity, intensity)\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    h, w = x.shape[row_index], x.shape[col_index]\n    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_zoom(x, zoom_range, row_index=1, col_index=2, channel_index=0,\n                fill_mode=\'nearest\', cval=0., rng=None):\n    if len(zoom_range) != 2:\n        raise Exception(\'zoom_range should be a tuple or list of two floats. \'\n                        \'Received arg: \', zoom_range)\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = rng.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    h, w = x.shape[row_index], x.shape[col_index]\n    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_barrel_transform(x, intensity):\n    # TODO\n    pass\n\n\ndef random_channel_shift(x, intensity, channel_index=0, rng=None):\n    x = np.rollaxis(x, channel_index, 0)\n    min_x, max_x = np.min(x), np.max(x)\n    channel_images = [np.clip(x_channel + rng.uniform(-intensity, intensity), min_x, max_x)\n                      for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_index+1)\n    return x\n\n\ndef transform_matrix_offset_center(matrix, x, y):\n    o_x = float(x) / 2 + 0.5\n    o_y = float(y) / 2 + 0.5\n    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n    return transform_matrix\n\n\ndef apply_transform(x, transform_matrix, channel_index=0, fill_mode=\'nearest\', cval=0.):\n    x = np.rollaxis(x, channel_index, 0)\n    final_affine_matrix = transform_matrix[:2, :2]\n    final_offset = transform_matrix[:2, 2]\n    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n                      final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_index+1)\n    return x\n\n\ndef flip_axis(x, axis):\n    x = np.asarray(x).swapaxes(axis, 0)\n    x = x[::-1, ...]\n    x = x.swapaxes(0, axis)\n    return x\n\n\ndef array_to_img(x, dim_ordering=K.image_dim_ordering(), mode=None, scale=True):\n    from PIL import Image\n    x = x.copy()\n    if dim_ordering == \'th\':\n        x = x.transpose(1, 2, 0)\n    if scale:\n        x += max(-np.min(x), 0)\n        x /= np.max(x)\n        x *= 255\n    if x.shape[2] == 3 and mode == \'RGB\':\n        return Image.fromarray(x.astype(\'uint8\'), mode)\n    elif x.shape[2] == 1 and mode == \'L\':\n        return Image.fromarray(x[:, :, 0].astype(\'uint8\'), mode)\n    elif mode:\n        return Image.fromarray(x, mode)\n    else:\n        raise Exception(\'Unsupported array shape: \', x.shape)\n\n\ndef img_to_array(img, dim_ordering=K.image_dim_ordering()):\n    if dim_ordering not in [\'th\', \'tf\']:\n        raise Exception(\'Unknown dim_ordering: \', dim_ordering)\n    # image has dim_ordering (height, width, channel)\n    x = np.asarray(img, dtype=\'float32\')\n    if len(x.shape) == 3:\n        if dim_ordering == \'th\':\n            x = x.transpose(2, 0, 1)\n    elif len(x.shape) == 2:\n        if dim_ordering == \'th\':\n            x = x.reshape((1, x.shape[0], x.shape[1]))\n        else:\n            x = x.reshape((x.shape[0], x.shape[1], 1))\n    else:\n        raise Exception(\'Unsupported image shape: \', x.shape)\n    return x\n\n\ndef load_img(path, target_mode=None, target_size=None):\n    from PIL import Image\n    img = Image.open(path)\n    if target_mode:\n        img = img.convert(target_mode)\n    if target_size:\n        img = img.resize((target_size[1], target_size[0]))\n    return img\n\ndef list_pictures(directory, ext=\'jpg|jpeg|bmp|png\'):\n    return [os.path.join(directory, f) for f in os.listdir(directory)\n            if os.path.isfile(os.path.join(directory, f)) and re.match(\'([\\w]+\\.(?:\' + ext + \'))\', f)]\n\ndef pil_image_reader(filepath, target_mode=None, target_size=None, dim_ordering=K.image_dim_ordering(), **kwargs):\n    img = load_img(filepath, target_mode=target_mode, target_size=target_size)\n    return img_to_array(img, dim_ordering=dim_ordering)\n\ndef standardize(x,\n                dim_ordering=\'th\',\n                rescale=False,\n                featurewise_center=False,\n                samplewise_center=False,\n                featurewise_std_normalization=False,\n                mean=None, std=None,\n                samplewise_std_normalization=False,\n                zca_whitening=False, principal_components=None,\n                featurewise_standardize_axis=None,\n                samplewise_standardize_axis=None,\n                fitting=False,\n                verbose=0,\n                config={},\n                **kwargs):\n    \'\'\'\n\n    # Arguments\n        featurewise_center: set input mean to 0 over the dataset.\n        samplewise_center: set each sample mean to 0.\n        featurewise_std_normalization: divide inputs by std of the dataset.\n        samplewise_std_normalization: divide each input by its std.\n        featurewise_standardize_axis: axis along which to perform feature-wise center and std normalization.\n        samplewise_standardize_axis: axis along which to to perform sample-wise center and std normalization.\n        zca_whitening: apply ZCA whitening.\n\n    \'\'\'\n    if fitting:\n        if \'_X\' in config:\n            # add data to _X array\n            config[\'_X\'][config[\'_iX\']] = x\n            config[\'_iX\'] +=1\n            # if verbose and config.has_key(\'_fit_progressbar\'):\n                # config[\'_fit_progressbar\'].update(config[\'_iX\'], force=(config[\'_iX\']==fitting))\n\n            # the array (_X) is ready to fit\n            if config[\'_iX\'] >= fitting:\n                X = config[\'_X\'].astype(\'float32\')\n                del config[\'_X\']\n                del config[\'_iX\']\n                if featurewise_center or featurewise_std_normalization:\n                    featurewise_standardize_axis = featurewise_standardize_axis or 0\n                    if type(featurewise_standardize_axis) is int:\n                        featurewise_standardize_axis = (featurewise_standardize_axis, )\n                    assert 0 in featurewise_standardize_axis, \'feature-wise standardize axis should include 0\'\n\n                if featurewise_center:\n                    mean = np.mean(X, axis=featurewise_standardize_axis, keepdims=True)\n                    config[\'mean\'] = np.squeeze(mean, axis=0)\n                    X -= mean\n\n                if featurewise_std_normalization:\n                    std = np.std(X, axis=featurewise_standardize_axis, keepdims=True)\n                    config[\'std\'] = np.squeeze(std, axis=0)\n                    X /= (std + 1e-7)\n\n                if zca_whitening:\n                    flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\n                    sigma = np.dot(flatX.T, flatX) / flatX.shape[1]\n                    U, S, V = linalg.svd(sigma)\n                    config[\'principal_components\'] = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)\n                if verbose:\n                    del config[\'_fit_progressbar\']\n        else:\n            # start a new fitting, fitting = total sample number\n            config[\'_X\'] = np.zeros((fitting,)+x.shape)\n            config[\'_iX\'] = 0\n            config[\'_X\'][config[\'_iX\']] = x\n            config[\'_iX\'] +=1\n            # if verbose:\n                # config[\'_fit_progressbar\'] = Progbar(target=fitting, verbose=verbose)\n        return x\n\n    if rescale:\n        x *= rescale\n\n    # x is a single image, so it doesn\'t have image number at index 0\n    if dim_ordering == \'th\':\n        channel_index = 0\n    if dim_ordering == \'tf\':\n        channel_index = 2\n\n    samplewise_standardize_axis = samplewise_standardize_axis or channel_index\n    if type(samplewise_standardize_axis) is int:\n        samplewise_standardize_axis = (samplewise_standardize_axis, )\n\n    if samplewise_center:\n        x -= np.mean(x, axis=samplewise_standardize_axis, keepdims=True)\n    if samplewise_std_normalization:\n        x /= (np.std(x, axis=samplewise_standardize_axis, keepdims=True) + 1e-7)\n\n    if verbose:\n        if (featurewise_center and mean is None) or (featurewise_std_normalization and std is None) or (zca_whitening and principal_components is None):\n            print(\'WARNING: feature-wise standardization and zca whitening will be disabled, please run ""fit"" first.\')\n\n    if featurewise_center:\n        if mean is not None:\n            x -= mean\n    if featurewise_std_normalization:\n        if std is not None:\n            x /= (std + 1e-7)\n\n    if zca_whitening:\n        if principal_components is not None:\n            flatx = np.reshape(x, (x.size))\n            whitex = np.dot(flatx, principal_components)\n            x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n    return x\n\ndef center_crop(x, center_crop_size, **kwargs):\n    centerw, centerh = x.shape[0]//2, x.shape[1]//2\n    halfw, halfh = center_crop_size[0]//2, center_crop_size[1]//2\n    return x[centerw-halfw:centerw+halfw,centerh-halfh:centerh+halfh, :]\n\ndef random_crop(x, random_crop_size, sync_seed=None, rng=None, **kwargs):\n    # np.random.seed(sync_seed)\n    w, h = x.shape[0], x.shape[1]\n    rangew = (w - random_crop_size[0]) // 2\n    rangeh = (h - random_crop_size[1]) // 2\n    #print(\'w: {}, h: {}, rangew: {}, rangeh: {}\'.format(w, h, rangew, rangeh))\n    offsetw = 0 if rangew == 0 else rng.randint(rangew)\n    offseth = 0 if rangeh == 0 else rng.randint(rangeh)\n    return x[offsetw:offsetw+random_crop_size[0], offseth:offseth+random_crop_size[1], :]\n\nfrom keras.applications.inception_v3 import preprocess_input as pp\n\ndef preprocess_input(x, rng=None, **kwargs):\n    return pp(x)\n\ndef random_transform(x,\n                     dim_ordering=\'tf\',\n                     rotation_range=0.,\n                     width_shift_range=0.,\n                     height_shift_range=0.,\n                     shear_range=0.,\n                     zoom_range=0.,\n                     channel_shift_range=0.,\n                     fill_mode=\'nearest\',\n                     cval=0.,\n                     horizontal_flip=False,\n                     vertical_flip=False,\n                     rescale=None,\n                     sync_seed=None,\n                     rng=None,\n                     **kwargs):\n    \'\'\'\n\n    # Arguments\n        rotation_range: degrees (0 to 180).\n        width_shift_range: fraction of total width.\n        height_shift_range: fraction of total height.\n        shear_range: shear intensity (shear angle in radians).\n        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n            in the range [1-z, 1+z]. A sequence of two can be passed instead\n            to select this range.\n        channel_shift_range: shift range for each channels.\n        fill_mode: points outside the boundaries are filled according to the\n            given mode (\'constant\', \'nearest\', \'reflect\' or \'wrap\'). Default\n            is \'nearest\'.\n        cval: value used for points outside the boundaries when fill_mode is\n            \'constant\'. Default is 0.\n        horizontal_flip: whether to randomly flip images horizontally.\n        vertical_flip: whether to randomly flip images vertically.\n        rescale: rescaling factor. If None or 0, no rescaling is applied,\n            otherwise we multiply the data by the value provided (before applying\n            any other transformation).\n    \'\'\'\n    # rng.seed(sync_seed)\n\n    x = x.astype(\'float32\')\n    # x is a single image, so it doesn\'t have image number at index 0\n    if dim_ordering == \'th\':\n        img_channel_index = 0\n        img_row_index = 1\n        img_col_index = 2\n    if dim_ordering == \'tf\':\n        img_channel_index = 2\n        img_row_index = 0\n        img_col_index = 1\n    # use composition of homographies to generate final transform that needs to be applied\n    if rotation_range:\n        theta = np.pi / 180 * rng.uniform(-rotation_range, rotation_range)\n    else:\n        theta = 0\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n    if height_shift_range:\n        tx = rng.uniform(-height_shift_range, height_shift_range) * x.shape[img_row_index]\n    else:\n        tx = 0\n\n    if width_shift_range:\n        ty = rng.uniform(-width_shift_range, width_shift_range) * x.shape[img_col_index]\n    else:\n        ty = 0\n\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n    if shear_range:\n        shear = rng.uniform(-shear_range, shear_range)\n    else:\n        shear = 0\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    if np.isscalar(zoom_range):\n        zoom_range = [1 - zoom_range, 1 + zoom_range]\n    elif len(zoom_range) == 2:\n        zoom_range = [zoom_range[0], zoom_range[1]]\n    else:\n        raise Exception(\'zoom_range should be a float or \'\n                        \'a tuple or list of two floats. \'\n                        \'Received arg: \', zoom_range)\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = rng.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    transform_matrix = np.dot(np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)\n\n    h, w = x.shape[img_row_index], x.shape[img_col_index]\n    transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n    x = apply_transform(x, transform_matrix, img_channel_index,\n                        fill_mode=fill_mode, cval=cval)\n    if channel_shift_range != 0:\n        x = random_channel_shift(x, channel_shift_range, img_channel_index, rng=rng)\n\n    if horizontal_flip:\n        if rng.rand() < 0.5:\n            x = flip_axis(x, img_col_index)\n\n    if vertical_flip:\n        if rng.rand() < 0.5:\n            x = flip_axis(x, img_row_index)\n\n    # TODO:\n    # barrel/fisheye\n\n    #rng.seed()\n    return x\n\nclass ImageDataGenerator(object):\n    \'\'\'Generate minibatches with\n    real-time data augmentation.\n\n    # Arguments\n        featurewise_center: set input mean to 0 over the dataset.\n        samplewise_center: set each sample mean to 0.\n        featurewise_std_normalization: divide inputs by std of the dataset.\n        samplewise_std_normalization: divide each input by its std.\n        featurewise_standardize_axis: axis along which to perform feature-wise center and std normalization.\n        samplewise_standardize_axis: axis along which to to perform sample-wise center and std normalization.\n        zca_whitening: apply ZCA whitening.\n        rotation_range: degrees (0 to 180).\n        width_shift_range: fraction of total width.\n        height_shift_range: fraction of total height.\n        shear_range: shear intensity (shear angle in radians).\n        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n            in the range [1-z, 1+z]. A sequence of two can be passed instead\n            to select this range.\n        channel_shift_range: shift range for each channels.\n        fill_mode: points outside the boundaries are filled according to the\n            given mode (\'constant\', \'nearest\', \'reflect\' or \'wrap\'). Default\n            is \'nearest\'.\n        cval: value used for points outside the boundaries when fill_mode is\n            \'constant\'. Default is 0.\n        horizontal_flip: whether to randomly flip images horizontally.\n        vertical_flip: whether to randomly flip images vertically.\n        rescale: rescaling factor. If None or 0, no rescaling is applied,\n            otherwise we multiply the data by the value provided (before applying\n            any other transformation).\n        dim_ordering: \'th\' or \'tf\'. In \'th\' mode, the channels dimension\n            (the depth) is at index 1, in \'tf\' mode it is at index 3.\n            It defaults to the `image_dim_ordering` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""th"".\n        seed: random seed for reproducible pipeline processing. If not None, it will also be used by `flow` or\n            `flow_from_directory` to generate the shuffle index in case of no seed is set.\n    \'\'\'\n    def __init__(self,\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 featurewise_standardize_axis=None,\n                 samplewise_standardize_axis=None,\n                 zca_whitening=False,\n                 rotation_range=0.,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode=\'nearest\',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 dim_ordering=K.image_dim_ordering(),\n                 seed=None,\n                 verbose=1):\n        self.config = copy.deepcopy(locals())\n        self.config[\'config\'] = self.config\n        self.config[\'mean\'] = None\n        self.config[\'std\'] = None\n        self.config[\'principal_components\'] = None\n        self.config[\'rescale\'] = rescale\n\n        if dim_ordering not in {\'tf\', \'th\'}:\n            raise Exception(\'dim_ordering should be ""tf"" (channel after row and \'\n                            \'column) or ""th"" (channel before row and column). \'\n                            \'Received arg: \', dim_ordering)\n\n        self.__sync_seed = self.config[\'seed\'] or np.random.randint(0, 4294967295)\n\n        self.default_pipeline = []\n        self.default_pipeline.append(random_transform)\n        self.default_pipeline.append(standardize)\n        self.set_pipeline(self.default_pipeline)\n\n        self.__fitting = False\n        # self.fit_lock = threading.Lock()\n\n    @property\n    def sync_seed(self):\n        return self.__sync_seed\n\n    @property\n    def fitting(self):\n        return self.__fitting\n\n    @property\n    def pipeline(self):\n        return self.__pipeline\n\n    def sync(self, image_data_generator):\n        self.__sync_seed = image_data_generator.sync_seed\n        return (self, image_data_generator)\n\n    def set_pipeline(self, p):\n        if p is None:\n            self.__pipeline = self.default_pipeline\n        elif type(p) is list:\n            self.__pipeline = p\n        else:\n            raise Exception(\'invalid pipeline.\')\n\n    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n             save_to_dir=None, save_prefix=\'\', save_mode=None, save_format=\'jpeg\',\n             pool=None):\n        return NumpyArrayIterator(\n            X, y, self,\n            batch_size=batch_size, shuffle=shuffle, seed=seed,\n            dim_ordering=self.config[\'dim_ordering\'],\n            save_to_dir=save_to_dir, save_prefix=save_prefix,\n            save_mode=save_mode, save_format=save_format,\n            pool=pool)\n\n    def flow_from_directory(self, directory,\n                            color_mode=None, target_size=None,\n                            image_reader=\'pil\', reader_config={\'target_mode\':\'RGB\', \'target_size\':(256,256)},\n                            read_formats={\'png\',\'jpg\',\'jpeg\',\'bmp\'},\n                            classes=None, class_mode=\'categorical\',\n                            batch_size=32, shuffle=True, seed=None,\n                            save_to_dir=None, save_prefix=\'\',\n                            save_mode=None, save_format=\'jpeg\'):\n        return DirectoryIterator(\n            directory, self,\n            color_mode=color_mode, target_size=target_size,\n            image_reader=image_reader, reader_config=reader_config,\n            read_formats=read_formats,\n            classes=classes, class_mode=class_mode,\n            dim_ordering=self.config[\'dim_ordering\'],\n            batch_size=batch_size, shuffle=shuffle, seed=seed,\n            save_to_dir=save_to_dir, save_prefix=save_prefix,\n            save_mode=save_mode, save_format=save_format)\n\n    def process(self, x, rng):\n        # get next sync_seed\n        # np.random.seed(self.__sync_seed)\n        #np.random.seed(int.from_bytes(os.urandom(4), byteorder=\'little\'))\n        #self.__sync_seed = np.random.randint(0, 4294967295)\n        # __sync_seed = rng.randint(0, 4294967295)\n        # # print(self.__sync_seed)\n        # self.config[\'fitting\'] = self.__fitting\n        # try:\n        #     del self.config[\'sync_seed\']\n        # except:\n        #     pass\n        #self.config[\'sync_seed\'] = self.__sync_seed\n        for p in self.__pipeline:\n            x = p(x, rng=rng, **self.config)\n        return x\n\n    def fit_generator(self, generator, nb_iter):\n        \'\'\'Fit a generator\n\n        # Arguments\n            generator: Iterator, generate data for fitting.\n            nb_iter: Int, number of iteration to fit.\n        \'\'\'\n        # with self.fit_lock:\n        #     try:\n        #         self.__fitting = nb_iter*generator.batch_size\n        #         for i in range(nb_iter):\n        #             next(generator)\n        #     finally:\n        #         self.__fitting = False\n\n    def fit(self, X, rounds=1):\n        \'\'\'Fit the pipeline on a numpy array\n\n        # Arguments\n            X: Numpy array, the data to fit on.\n            rounds: how many rounds of fit to do over the data\n        \'\'\'\n        X = np.copy(X)\n        # with self.fit_lock:\n        #     try:\n        #         self.__fitting = rounds*X.shape[0]\n        #         for r in range(rounds):\n        #             for i in range(X.shape[0]):\n        #                 self.process(X[i])\n        #     finally:\n        #         self.__fitting = False\n\nclass Iterator(object):\n\n    def __init__(self, N, batch_size, shuffle, seed):\n        self.N = N\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.seed = seed\n        self.batch_index = 0\n        self.total_batches_seen = 0\n        self.lock = threading.Lock()\n        self.index_generator = self._flow_index(N, batch_size, shuffle, seed)\n\n    def reset(self):\n        self.batch_index = 0\n\n    def _flow_index(self, N, batch_size=32, shuffle=False, seed=None):\n        # ensure self.batch_index is 0\n        self.reset()\n        while 1:\n            if self.batch_index == 0:\n                self.index_array = np.arange(N)\n                if shuffle:\n                    if seed is not None:\n                        np.random.seed(seed + self.total_batches_seen)\n                    self.index_array = np.random.permutation(N)\n                    if seed is not None:\n                        np.random.seed()\n\n            current_index = (self.batch_index * batch_size) % N\n            if N >= current_index + batch_size:\n                current_batch_size = batch_size\n                self.batch_index += 1\n            else:\n                current_batch_size = N - current_index\n                self.batch_index = 0\n            self.total_batches_seen += 1\n            yield (self.index_array[current_index: current_index + current_batch_size],\n                   current_index, current_batch_size)\n\n    def __add__(self, it):\n        assert self.N == it.N\n        assert self.batch_size == it.batch_size\n        assert self.shuffle == it.shuffle\n        seed = self.seed or np.random.randint(0, 4294967295)\n        it.total_batches_seen = self.total_batches_seen\n        self.index_generator = self._flow_index(self.N, self.batch_size, self.shuffle, seed)\n        it.index_generator = it._flow_index(it.N, it.batch_size, it.shuffle, seed)\n        if (sys.version_info > (3, 0)):\n            iter_zip = zip\n        else:\n            from itertools import izip\n            iter_zip = izip\n        return iter_zip(self, it)\n\n    def __iter__(self):\n        # needed if we want to do something like:\n        # for x, y in data_gen.flow(...):\n        return self\n\n    def __next__(self, *args, **kwargs):\n        return self.next(*args, **kwargs)\n\ndef process_image_worker(tup):\n    process, img, rng = tup\n    ret = process(img, rng)\n    return ret\n\nclass NumpyArrayIterator(Iterator):\n\n    def __init__(self, X, y, image_data_generator,\n                 batch_size=32, shuffle=False, seed=None,\n                 dim_ordering=K.image_dim_ordering(),\n                 save_to_dir=None, save_prefix=\'\',\n                 save_mode=None, save_format=\'jpeg\',\n                 pool=None):\n        if y is not None and len(X) != len(y):\n            raise Exception(\'X (images tensor) and y (labels) \'\n                            \'should have the same length. \'\n                            \'Found: X.shape = %s, y.shape = %s\' % (np.asarray(X).shape, np.asarray(y).shape))\n        self.X = X\n        self.y = y\n        self.image_data_generator = image_data_generator\n        self.dim_ordering = dim_ordering\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_mode = save_mode\n        self.save_format = save_format\n        seed = seed or image_data_generator.config[\'seed\']\n        self.pool = pool\n        self.rngs = [np.random.RandomState(seed + i) for i in range(batch_size)]\n        super(NumpyArrayIterator, self).__init__(X.shape[0], batch_size, shuffle, seed)\n\n    def close(self):\n        pass\n        # print(\'closing pool!\')\n        # self.pool.close()\n        # self.pool.join()\n        # self.pool.terminate()\n        # self.pool = None\n        # print(\'closed pool!\')\n\n    def __add__(self, it):\n        if isinstance(it, NumpyArrayIterator):\n            assert self.X.shape[0] == it.X.shape[0]\n        if isinstance(it, DirectoryIterator):\n            assert self.X.shape[0] == it.nb_sample\n        it.image_data_generator.sync(self.image_data_generator)\n        return super(NumpyArrayIterator, self).__add__(it)\n\n    def next(self):\n        # for python 2.x.\n        # Keeps under lock only the mechanism which advances\n        # the indexing of each batch\n        # see http://anandology.com/blog/using-iterators-and-generators/\n        with self.lock:\n            index_array, current_index, current_batch_size = next(self.index_generator)\n        # The transformation of images is not under thread lock so it can be done in parallel\n        result = self.pool.map(process_image_worker, ((self.image_data_generator.process, self.X[j], self.rngs[i%self.batch_size]) for i, j in enumerate(index_array)))\n        batch_x = np.array(result)\n\n        for i, rng in enumerate(self.rngs):\n            new_seed = rng.randint(0, 4294967295)\n            self.rngs[i] = np.random.RandomState(new_seed)\n\n        # for i, j in enumerate(index_array):\n        #     # print(i, j)\n        #     x = self.X[j]\n        #     x = self.image_data_generator.process(x)\n        #     if i == 0:\n        #         batch_x = np.zeros((current_batch_size,) + x.shape)\n        #         # print(batch_x.shape)\n        #     batch_x[i] = x\n\n        if self.save_to_dir:\n            for i in range(current_batch_size):\n                img = array_to_img(batch_x[i], self.dim_ordering, mode=self.save_mode, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                  index=current_index + i,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        if self.y is None:\n            return batch_x\n        batch_y = self.y[index_array]\n        return batch_x, batch_y\n\n\nclass DirectoryIterator(Iterator):\n\n    def __init__(self, directory, image_data_generator,\n                 color_mode=None, target_size=None,\n                 image_reader=""pil"", read_formats={\'png\',\'jpg\',\'jpeg\',\'bmp\'},\n                 reader_config={\'target_mode\': \'RGB\', \'target_size\':None},\n                 dim_ordering=K.image_dim_ordering,\n                 classes=None, class_mode=\'categorical\',\n                 batch_size=32, shuffle=True, seed=None,\n                 save_to_dir=None, save_prefix=\'\',\n                 save_mode=None, save_format=\'jpeg\'):\n        self.directory = directory\n        self.image_data_generator = image_data_generator\n        self.image_reader = image_reader\n        if self.image_reader == \'pil\':\n            self.image_reader = pil_image_reader\n        self.reader_config = reader_config\n        # TODO: move color_mode and target_size to reader_config\n        if color_mode == \'rgb\':\n            self.reader_config[\'target_mode\'] = \'RGB\'\n        elif color_mode == \'grayscale\':\n            self.reader_config[\'target_mode\'] = \'L\'\n\n        if target_size:\n            self.reader_config[\'target_size\'] = target_size\n\n        self.dim_ordering = dim_ordering\n        self.reader_config[\'dim_ordering\'] = dim_ordering\n        if class_mode not in {\'categorical\', \'binary\', \'sparse\', None}:\n            raise ValueError(\'Invalid class_mode:\', class_mode,\n                             \'; expected one of ""categorical"", \'\n                             \'""binary"", ""sparse"", or None.\')\n        self.class_mode = class_mode\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_mode = save_mode\n        self.save_format = save_format\n\n        seed = seed or image_data_generator.config[\'seed\']\n\n        # first, count the number of samples and classes\n        self.nb_sample = 0\n\n        if not classes:\n            classes = []\n            for subdir in sorted(os.listdir(directory)):\n                if os.path.isdir(os.path.join(directory, subdir)):\n                    classes.append(subdir)\n        # if no class is found, add \'\' for scanning the root folder\n        if class_mode is None and len(classes) == 0:\n            classes.append(\'\')\n        self.nb_class = len(classes)\n        self.class_indices = dict(zip(classes, range(len(classes))))\n\n        for subdir in classes:\n            subpath = os.path.join(directory, subdir)\n            for fname in os.listdir(subpath):\n                is_valid = False\n                for extension in read_formats:\n                    if fname.lower().endswith(\'.\' + extension):\n                        is_valid = True\n                        break\n                if is_valid:\n                    self.nb_sample += 1\n        print(\'Found %d images belonging to %d classes.\' % (self.nb_sample, self.nb_class))\n\n        # second, build an index of the images in the different class subfolders\n        self.filenames = []\n        self.classes = np.zeros((self.nb_sample,), dtype=\'int32\')\n        i = 0\n        for subdir in classes:\n            subpath = os.path.join(directory, subdir)\n            for fname in os.listdir(subpath):\n                is_valid = False\n                for extension in read_formats:\n                    if fname.lower().endswith(\'.\' + extension):\n                        is_valid = True\n                        break\n                if is_valid:\n                    self.classes[i] = self.class_indices[subdir]\n                    self.filenames.append(os.path.join(subdir, fname))\n                    i += 1\n\n        assert len(self.filenames)>0, \'No valid file is found in the target directory.\'\n        self.reader_config[\'class_mode\'] = self.class_mode\n        self.reader_config[\'classes\'] = self.classes\n        self.reader_config[\'filenames\'] = self.filenames\n        self.reader_config[\'directory\'] = self.directory\n        self.reader_config[\'nb_sample\'] = self.nb_sample\n        self.reader_config[\'seed\'] = seed\n        self.reader_config[\'sync_seed\'] = self.image_data_generator.sync_seed\n        super(DirectoryIterator, self).__init__(self.nb_sample, batch_size, shuffle, seed)\n        if inspect.isgeneratorfunction(self.image_reader):\n            self._reader_generator_mode = True\n            self._reader_generator = []\n            # set index batch_size to 1\n            self.index_generator = self._flow_index(self.N, 1 , self.shuffle, seed)\n        else:\n            self._reader_generator_mode = False\n\n    def __add__(self, it):\n        if isinstance(it, DirectoryIterator):\n            assert self.nb_sample == it.nb_sample\n            assert len(self.filenames) == len(it.filenames)\n            assert np.alltrue(self.classes == it.classes)\n            assert self.image_reader == it.image_reader\n            if inspect.isgeneratorfunction(self.image_reader):\n                self._reader_generator = []\n                it._reader_generator = []\n        if isinstance(it, NumpyArrayIterator):\n            assert self.nb_sample == self.X.shape[0]\n        it.image_data_generator.sync(self.image_data_generator)\n        return super(DirectoryIterator, self).__add__(it)\n\n    def next(self):\n        self.reader_config[\'sync_seed\'] = self.image_data_generator.sync_seed\n        if self._reader_generator_mode:\n            sampleCount = 0\n            batch_x = None\n            _new_generator_flag = False\n            while sampleCount<self.batch_size:\n                for x in self._reader_generator:\n                    _new_generator_flag = False\n                    if x.ndim == 2:\n                        x = np.expand_dims(x, axis=0)\n                    x = self.image_data_generator.process(x)\n                    self.reader_config[\'sync_seed\'] = self.image_data_generator.sync_seed\n                    if sampleCount == 0:\n                        batch_x = np.zeros((self.batch_size,) + x.shape)\n                    batch_x[sampleCount] = x\n                    sampleCount +=1\n                    if sampleCount >= self.batch_size:\n                        break\n                if sampleCount >= self.batch_size or _new_generator_flag:\n                    break\n                with self.lock:\n                    index_array, _, _ = next(self.index_generator)\n                fname = self.filenames[index_array[0]]\n                self._reader_generator = self.image_reader(os.path.join(self.directory, fname), **self.reader_config)\n                assert isinstance(self._reader_generator, types.GeneratorType)\n                _new_generator_flag = True\n        else:\n            with self.lock:\n                index_array, current_index, current_batch_size = next(self.index_generator)\n            # The transformation of images is not under thread lock so it can be done in parallel\n            batch_x = None\n            # build batch of image data\n            for i, j in enumerate(index_array):\n                fname = self.filenames[j]\n                x = self.image_reader(os.path.join(self.directory, fname), **self.reader_config)\n                if x.ndim == 2:\n                    x = np.expand_dims(x, axis=0)\n                x = self.image_data_generator.process(x)\n                if i == 0:\n                    batch_x = np.zeros((current_batch_size,) + x.shape)\n                batch_x[i] = x\n        # optionally save augmented images to disk for debugging purposes\n        if self.save_to_dir:\n            for i in range(current_batch_size):\n                img = array_to_img(batch_x[i], self.dim_ordering, mode=self.save_mode, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                  index=current_index + i,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        # build batch of labels\n        if self.class_mode == \'sparse\':\n            batch_y = self.classes[index_array]\n        elif self.class_mode == \'binary\':\n            batch_y = self.classes[index_array].astype(\'float32\')\n        elif self.class_mode == \'categorical\':\n            batch_y = np.zeros((len(batch_x), self.nb_class), dtype=\'float32\')\n            for i, label in enumerate(self.classes[index_array]):\n                batch_y[i, label] = 1.\n        else:\n            return batch_x\n        return batch_x, batch_y\n'"
