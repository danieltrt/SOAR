file_path,api_count,code
tools/__init__.py,0,b''
tools/image.py,0,"b'""""""Fairly basic set of tools for real-time data augmentation on image data.\nCan easily be extended to include new transformations,\nnew preprocessing methods, etc...\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport numpy as np\nimport re\nfrom scipy import linalg\nimport scipy.ndimage as ndi\nfrom six.moves import range\nimport os\nimport threading\nimport warnings\n\n# from .. import backend as K\nimport keras.backend as K\n\ntry:\n    from PIL import Image as pil_image\nexcept ImportError:\n    pil_image = None\n\n\ndef random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n                    fill_mode=\'nearest\', cval=0.):\n    """"""Performs a random rotation of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        rg: Rotation range, in degrees.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{\'constant\', \'nearest\', \'reflect\', \'wrap\'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode=\'constant\'`.\n\n    # Returns\n        Rotated Numpy image tensor.\n    """"""\n    theta = np.pi / 180 * np.random.uniform(-rg, rg)\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\n\ndef random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n                 fill_mode=\'nearest\', cval=0.):\n    """"""Performs a random spatial shift of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        wrg: Width shift range, as a float fraction of the width.\n        hrg: Height shift range, as a float fraction of the height.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{\'constant\', \'nearest\', \'reflect\', \'wrap\'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode=\'constant\'`.\n\n    # Returns\n        Shifted Numpy image tensor.\n    """"""\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    tx = np.random.uniform(-hrg, hrg) * h\n    ty = np.random.uniform(-wrg, wrg) * w\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n\n    transform_matrix = translation_matrix  # no need to do offset\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\n\ndef random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n                 fill_mode=\'nearest\', cval=0.):\n    """"""Performs a random spatial shear of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        intensity: Transformation intensity.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{\'constant\', \'nearest\', \'reflect\', \'wrap\'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode=\'constant\'`.\n\n    # Returns\n        Sheared Numpy image tensor.\n    """"""\n    shear = np.random.uniform(-intensity, intensity)\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\n\ndef random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n                fill_mode=\'nearest\', cval=0.):\n    """"""Performs a random spatial zoom of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        zoom_range: Tuple of floats; zoom range for width and height.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{\'constant\', \'nearest\', \'reflect\', \'wrap\'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode=\'constant\'`.\n\n    # Returns\n        Zoomed Numpy image tensor.\n\n    # Raises\n        ValueError: if `zoom_range` isn\'t a tuple.\n    """"""\n    if len(zoom_range) != 2:\n        raise ValueError(\'zoom_range should be a tuple or list of two floats. \'\n                         \'Received arg: \', zoom_range)\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\n\ndef random_channel_shift(x, intensity, channel_axis=0):\n    x = np.rollaxis(x, channel_axis, 0)\n    min_x, max_x = np.min(x), np.max(x)\n    channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n                      for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_axis + 1)\n    return x\n\n\ndef transform_matrix_offset_center(matrix, x, y):\n    o_x = float(x) / 2 + 0.5\n    o_y = float(y) / 2 + 0.5\n    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n    return transform_matrix\n\n\ndef apply_transform(x, transform_matrix, channel_axis=0, fill_mode=\'nearest\', cval=0.):\n    x = np.rollaxis(x, channel_axis, 0)\n    final_affine_matrix = transform_matrix[:2, :2]\n    final_offset = transform_matrix[:2, 2]\n    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n                                                         final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_axis + 1)\n    return x\n\n\ndef flip_axis(x, axis):\n    x = np.asarray(x).swapaxes(axis, 0)\n    x = x[::-1, ...]\n    x = x.swapaxes(0, axis)\n    return x\n\ndef standardize(x,\n                preprocessing_function=None,\n                rescale=None,\n                channel_axis=None,\n                samplewise_center=False,\n                featurewise_center=False,\n                samplewise_std_normalization=False,\n                featurewise_std_normalization=False,\n                mean=None,\n                std=None,\n                zca_whitening=False,\n                principal_components=None,\n                rng=None):\n    if preprocessing_function:\n        x = preprocessing_function(x)\n    if rescale:\n        x *= rescale\n    # x is a single image, so it doesn\'t have image number at index 0\n    img_channel_axis = channel_axis - 1\n    if samplewise_center:\n        x -= np.mean(x, axis=img_channel_axis, keepdims=True)\n    if samplewise_std_normalization:\n        x /= (np.std(x, axis=img_channel_axis, keepdims=True) + 1e-7)\n\n    if featurewise_center:\n        if mean is not None:\n            x -= mean\n        else:\n            warnings.warn(\'This ImageDataGenerator specifies \'\n                          \'`featurewise_center`, but it hasn\\\'t\'\n                          \'been fit on any training data. Fit it \'\n                          \'first by calling `.fit(numpy_data)`.\')\n    if featurewise_std_normalization:\n        if std is not None:\n            x /= (std + 1e-7)\n        else:\n            warnings.warn(\'This ImageDataGenerator specifies \'\n                          \'`featurewise_std_normalization`, but it hasn\\\'t\'\n                          \'been fit on any training data. Fit it \'\n                          \'first by calling `.fit(numpy_data)`.\')\n    if zca_whitening:\n        if principal_components is not None:\n            flatx = np.reshape(x, (x.size))\n            whitex = np.dot(flatx, principal_components)\n            x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n        else:\n            warnings.warn(\'This ImageDataGenerator specifies \'\n                          \'`zca_whitening`, but it hasn\\\'t\'\n                          \'been fit on any training data. Fit it \'\n                          \'first by calling `.fit(numpy_data)`.\')\n    return x\n\ndef random_transform(x,\n                     row_axis=None,\n                     col_axis=None,\n                     channel_axis=None,\n                     rotation_range=0.,\n                     height_shift_range=0.,\n                     width_shift_range=0.,\n                     shear_range=0.,\n                     zoom_range=0.,\n                     fill_mode=\'nearest\',\n                     cval=0.,\n                     channel_shift_range=0.,\n                     horizontal_flip=False,\n                     vertical_flip=False,\n                     rng=None):\n\n    supplied_rngs = True\n    if rng is None:\n        supplied_rngs = False\n        rng = np.random\n\n    # x is a single image, so it doesn\'t have image number at index 0\n    img_row_axis = row_axis - 1\n    img_col_axis = col_axis - 1\n    img_channel_axis = channel_axis - 1\n\n    # use composition of homographies\n    # to generate final transform that needs to be applied\n    if rotation_range:\n        theta = np.pi / 180 * rng.uniform(-rotation_range, rotation_range)\n    else:\n        theta = 0\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n    if height_shift_range:\n        tx = rng.uniform(-height_shift_range, height_shift_range) * x.shape[img_row_axis]\n    else:\n        tx = 0\n\n    if width_shift_range:\n        ty = rng.uniform(-width_shift_range, width_shift_range) * x.shape[img_col_axis]\n    else:\n        ty = 0\n\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n    if shear_range:\n        shear = rng.uniform(-shear_range, shear_range)\n    else:\n        shear = 0\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = rng.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    transform_matrix = np.dot(np.dot(np.dot(rotation_matrix,\n                                            translation_matrix),\n                                     shear_matrix),\n                              zoom_matrix)\n\n    h, w = x.shape[img_row_axis], x.shape[img_col_axis]\n    transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n    x = apply_transform(x, transform_matrix, img_channel_axis,\n                        fill_mode=fill_mode, cval=cval)\n    if channel_shift_range != 0:\n        x = random_channel_shift(x,\n                                 channel_shift_range,\n                                 img_channel_axis)\n\n    get_random = None\n    if supplied_rngs:\n        get_random = rng.rand\n    else:\n        get_random = np.random.random\n\n    if horizontal_flip:\n        if get_random() < 0.5:\n            x = flip_axis(x, img_col_axis)\n\n    if vertical_flip:\n        if get_random() < 0.5:\n            x = flip_axis(x, img_row_axis)\n\n    return x\n\ndef array_to_img(x, dim_ordering=\'default\', scale=True):\n    """"""Converts a 3D Numpy array to a PIL Image instance.\n\n    # Arguments\n        x: Input Numpy array.\n        dim_ordering: Image data format.\n        scale: Whether to rescale image values\n            to be within [0, 255].\n\n    # Returns\n        A PIL Image instance.\n\n    # Raises\n        ImportError: if PIL is not available.\n        ValueError: if invalid `x` or `dim_ordering` is passed.\n    """"""\n    if pil_image is None:\n        raise ImportError(\'Could not import PIL.Image. \'\n                          \'The use of `array_to_img` requires PIL.\')\n    x = np.asarray(x)\n    if x.ndim != 3:\n        raise ValueError(\'Expected image array to have rank 3 (single image). \'\n                         \'Got array with shape:\', x.shape)\n\n    if dim_ordering == \'default\':\n        dim_ordering = K.image_dim_ordering()\n    if dim_ordering not in {\'th\', \'tf\'}:\n        raise ValueError(\'Invalid dim_ordering:\', dim_ordering)\n\n    # Original Numpy array x has format (height, width, channel)\n    # or (channel, height, width)\n    # but target PIL image has format (width, height, channel)\n    if dim_ordering == \'th\':\n        x = x.transpose(1, 2, 0)\n    if scale:\n        x = x + max(-np.min(x), 0)\n        x_max = np.max(x)\n        if x_max != 0:\n            x /= x_max\n        x *= 255\n    if x.shape[2] == 3:\n        # RGB\n        return pil_image.fromarray(x.astype(\'uint8\'), \'RGB\')\n    elif x.shape[2] == 1:\n        # grayscale\n        return pil_image.fromarray(x[:, :, 0].astype(\'uint8\'), \'L\')\n    else:\n        raise ValueError(\'Unsupported channel number: \', x.shape[2])\n\n\ndef img_to_array(img, dim_ordering=\'default\'):\n    """"""Converts a PIL Image instance to a Numpy array.\n\n    # Arguments\n        img: PIL Image instance.\n        dim_ordering: Image data format.\n\n    # Returns\n        A 3D Numpy array (float32).\n\n    # Raises\n        ValueError: if invalid `img` or `dim_ordering` is passed.\n    """"""\n    if dim_ordering == \'default\':\n        dim_ordering = K.image_dim_ordering()\n    if dim_ordering not in {\'th\', \'tf\'}:\n        raise ValueError(\'Unknown dim_ordering: \', dim_ordering)\n    # Numpy array x has format (height, width, channel)\n    # or (channel, height, width)\n    # but original PIL image has format (width, height, channel)\n    x = np.asarray(img, dtype=\'float32\')\n    if len(x.shape) == 3:\n        if dim_ordering == \'th\':\n            x = x.transpose(2, 0, 1)\n    elif len(x.shape) == 2:\n        if dim_ordering == \'th\':\n            x = x.reshape((1, x.shape[0], x.shape[1]))\n        else:\n            x = x.reshape((x.shape[0], x.shape[1], 1))\n    else:\n        raise ValueError(\'Unsupported image shape: \', x.shape)\n    return x\n\n\ndef load_img(path, grayscale=False, target_size=None):\n    """"""Loads an image into PIL format.\n\n    # Arguments\n        path: Path to image file\n        grayscale: Boolean, whether to load the image as grayscale.\n        target_size: Either `None` (default to original size)\n            or tuple of ints `(img_height, img_width)`.\n\n    # Returns\n        A PIL Image instance.\n\n    # Raises\n        ImportError: if PIL is not available.\n    """"""\n    if pil_image is None:\n        raise ImportError(\'Could not import PIL.Image. \'\n                          \'The use of `array_to_img` requires PIL.\')\n    img = pil_image.open(path)\n    if grayscale:\n        img = img.convert(\'L\')\n    else:  # Ensure 3 channel even when loaded image is grayscale\n        img = img.convert(\'RGB\')\n    if target_size:\n        img = img.resize((target_size[1], target_size[0]))\n    return img\n\n\ndef list_pictures(directory, ext=\'jpg|jpeg|bmp|png\'):\n    return [os.path.join(root, f)\n            for root, _, files in os.walk(directory) for f in files\n            if re.match(\'([\\w]+\\.(?:\' + ext + \'))\', f)]\n\n\nclass ImageDataGenerator(object):\n    """"""Generate minibatches of image data with real-time data augmentation.\n\n    # Arguments\n        featurewise_center: set input mean to 0 over the dataset.\n        samplewise_center: set each sample mean to 0.\n        featurewise_std_normalization: divide inputs by std of the dataset.\n        samplewise_std_normalization: divide each input by its std.\n        zca_whitening: apply ZCA whitening.\n        rotation_range: degrees (0 to 180).\n        width_shift_range: fraction of total width.\n        height_shift_range: fraction of total height.\n        shear_range: shear intensity (shear angle in radians).\n        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n            in the range [1-z, 1+z]. A sequence of two can be passed instead\n            to select this range.\n        channel_shift_range: shift range for each channels.\n        fill_mode: points outside the boundaries are filled according to the\n            given mode (\'constant\', \'nearest\', \'reflect\' or \'wrap\'). Default\n            is \'nearest\'.\n        cval: value used for points outside the boundaries when fill_mode is\n            \'constant\'. Default is 0.\n        horizontal_flip: whether to randomly flip images horizontally.\n        vertical_flip: whether to randomly flip images vertically.\n        rescale: rescaling factor. If None or 0, no rescaling is applied,\n            otherwise we multiply the data by the value provided\n            (before applying any other transformation).\n        preprocessing_function: function that will be implied on each input.\n            The function will run before any other modification on it.\n            The function should take one argument:\n            one image (Numpy tensor with rank 3),\n            and should output a Numpy tensor with the same shape.\n        dim_ordering: \'th\' or \'tf\'. In \'th\' mode, the channels dimension\n            (the depth) is at index 1, in \'tf\' mode it is at index 3.\n            It defaults to the `image_dim_ordering` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""tf"".\n        pool: an open multiprocessing.Pool that will be used to\n            process multiple images in parallel. If left off or set to\n            None, then the default serial processing with a single\n            process will be used.\n    """"""\n\n    def __init__(self,\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 zca_whitening=False,\n                 rotation_range=0.,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode=\'nearest\',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 preprocessing_function=None,\n                 dim_ordering=\'default\',\n                 pool=None):\n        if dim_ordering == \'default\':\n            dim_ordering = K.image_dim_ordering()\n        self.featurewise_center = featurewise_center\n        self.samplewise_center = samplewise_center\n        self.featurewise_std_normalization = featurewise_std_normalization\n        self.samplewise_std_normalization = samplewise_std_normalization\n        self.zca_whitening = zca_whitening\n        self.rotation_range = rotation_range\n        self.width_shift_range = width_shift_range\n        self.height_shift_range = height_shift_range\n        self.shear_range = shear_range\n        self.zoom_range = zoom_range\n        self.channel_shift_range = channel_shift_range\n        self.fill_mode = fill_mode\n        self.cval = cval\n        self.horizontal_flip = horizontal_flip\n        self.vertical_flip = vertical_flip\n        self.rescale = rescale\n        self.preprocessing_function = preprocessing_function\n        self.pool = pool\n\n        if dim_ordering not in {\'tf\', \'th\'}:\n            raise ValueError(\'dim_ordering should be ""tf"" (channel after row and \'\n                             \'column) or ""th"" (channel before row and column). \'\n                             \'Received arg: \', dim_ordering)\n        self.dim_ordering = dim_ordering\n        if dim_ordering == \'th\':\n            self.channel_axis = 1\n            self.row_axis = 2\n            self.col_axis = 3\n        if dim_ordering == \'tf\':\n            self.channel_axis = 3\n            self.row_axis = 1\n            self.col_axis = 2\n\n        self.mean = None\n        self.std = None\n        self.principal_components = None\n\n        if np.isscalar(zoom_range):\n            self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n        elif len(zoom_range) == 2:\n            self.zoom_range = [zoom_range[0], zoom_range[1]]\n        else:\n            raise ValueError(\'zoom_range should be a float or \'\n                             \'a tuple or list of two floats. \'\n                             \'Received arg: \', zoom_range)\n\n    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n             save_to_dir=None, save_prefix=\'\', save_format=\'jpeg\'):\n        return NumpyArrayIterator(\n            X, y, self,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            dim_ordering=self.dim_ordering,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            pool=self.pool)\n\n    def flow_from_directory(self, directory,\n                            target_size=(256, 256), color_mode=\'rgb\',\n                            classes=None, class_mode=\'categorical\',\n                            batch_size=32, shuffle=True, seed=None,\n                            save_to_dir=None,\n                            save_prefix=\'\',\n                            save_format=\'jpeg\',\n                            follow_links=False):\n        return DirectoryIterator(\n            directory, self,\n            target_size=target_size, color_mode=color_mode,\n            classes=classes, class_mode=class_mode,\n            dim_ordering=self.dim_ordering,\n            batch_size=batch_size, shuffle=shuffle, seed=seed,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            follow_links=follow_links,\n            pool=self.pool)\n\n\n    def pipeline(self):\n        """"""A pipeline of functions to apply in order to an image.\n        """"""\n        return [\n            (random_transform, dict(\n                row_axis=self.row_axis,\n                col_axis=self.col_axis,\n                channel_axis=self.channel_axis,\n                rotation_range=self.rotation_range,\n                height_shift_range=self.height_shift_range,\n                width_shift_range=self.width_shift_range,\n                shear_range=self.shear_range,\n                zoom_range=self.zoom_range,\n                fill_mode=self.fill_mode,\n                cval=self.cval,\n                channel_shift_range=self.channel_shift_range,\n                horizontal_flip=self.horizontal_flip,\n                vertical_flip=self.vertical_flip)\n            ),\n\n            (standardize, dict(\n                preprocessing_function=self.preprocessing_function,\n                rescale=self.rescale,\n                channel_axis=self.channel_axis,\n                samplewise_center=self.samplewise_center,\n                samplewise_std_normalization=self.samplewise_std_normalization,\n                featurewise_center=self.featurewise_center,\n                mean=self.mean,\n                featurewise_std_normalization=self.featurewise_std_normalization,\n                std=self.std,\n                zca_whitening=self.zca_whitening,\n                principal_components=self.principal_components)\n            )\n        ]\n\n    def standardize(self, x):\n        return standardize(x,\n            preprocessing_function=self.preprocessing_function,\n            rescale=self.rescale,\n            channel_axis=self.channel_axis,\n            samplewise_center=self.samplewise_center,\n            samplewise_std_normalization=self.samplewise_std_normalization,\n            featurewise_center=self.featurewise_center,\n            mean=self.mean,\n            featurewise_std_normalization=self.featurewise_std_normalization,\n            std=self.std,\n            zca_whitening=self.zca_whitening,\n            principal_components=self.principal_components)\n\n    def random_transform(self, x):\n        return random_transform(x,\n            row_axis=self.row_axis,\n            col_axis=self.col_axis,\n            channel_axis=self.channel_axis,\n            rotation_range=self.rotation_range,\n            height_shift_range=self.height_shift_range,\n            width_shift_range=self.width_shift_range,\n            shear_range=self.shear_range,\n            zoom_range=self.zoom_range,\n            fill_mode=self.fill_mode,\n            cval=self.cval,\n            channel_shift_range=self.channel_shift_range,\n            horizontal_flip=self.horizontal_flip,\n            vertical_flip=self.vertical_flip)\n\n    def fit(self, x,\n            augment=False,\n            rounds=1,\n            seed=None):\n        """"""Required for featurewise_center, featurewise_std_normalization\n        and zca_whitening.\n\n        # Arguments\n            x: Numpy array, the data to fit on. Should have rank 4.\n                In case of grayscale data,\n                the channels axis should have value 1, and in case\n                of RGB data, it should have value 3.\n            augment: Whether to fit on randomly augmented samples\n            rounds: If `augment`,\n                how many augmentation passes to do over the data\n            seed: random seed.\n\n        # Raises\n            ValueError: in case of invalid input `x`.\n        """"""\n        x = np.asarray(x)\n        if x.ndim != 4:\n            raise ValueError(\'Input to `.fit()` should have rank 4. \'\n                             \'Got array with shape: \' + str(x.shape))\n        if x.shape[self.channel_axis] not in {1, 3, 4}:\n            raise ValueError(\n                \'Expected input to be images (as Numpy array) \'\n                \'following the dimension ordering convention ""\' + self.dim_ordering + \'"" \'\n                \'(channels on axis \' + str(self.channel_axis) + \'), i.e. expected \'\n                \'either 1, 3 or 4 channels on axis \' + str(self.channel_axis) + \'. \'\n                \'However, it was passed an array with shape \' + str(x.shape) +\n                \' (\' + str(x.shape[self.channel_axis]) + \' channels).\')\n\n        if seed is not None:\n            np.random.seed(seed)\n\n        x = np.copy(x)\n        if augment:\n            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]))\n            for r in range(rounds):\n                for i in range(x.shape[0]):\n                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n            x = ax\n\n        if self.featurewise_center:\n            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n            broadcast_shape = [1, 1, 1]\n            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n            self.mean = np.reshape(self.mean, broadcast_shape)\n            x -= self.mean\n\n        if self.featurewise_std_normalization:\n            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n            broadcast_shape = [1, 1, 1]\n            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n            self.std = np.reshape(self.std, broadcast_shape)\n            x /= (self.std + K.epsilon())\n\n        if self.zca_whitening:\n            flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n            u, s, _ = linalg.svd(sigma)\n            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 10e-7))), u.T)\n\n\nclass Iterator(object):\n\n    def __init__(self, n, batch_size, shuffle, seed):\n        self.n = n\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.batch_index = 0\n        self.total_batches_seen = 0\n        self.lock = threading.Lock()\n        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n\n        # create multiple random number generators to be used separately in\n        # each process when using a multiprocessing.Pool\n        if seed:\n            self.rngs = [np.random.RandomState(seed + i) for i in range(batch_size)]\n        else:\n            self.rngs = [np.random.RandomState(i) for i in range(batch_size)]\n\n    def reset(self):\n        self.batch_index = 0\n\n    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n        # ensure self.batch_index is 0\n        self.reset()\n        while 1:\n            if seed is not None:\n                np.random.seed(seed + self.total_batches_seen)\n            if self.batch_index == 0:\n                index_array = np.arange(n)\n                if shuffle:\n                    index_array = np.random.permutation(n)\n\n            current_index = (self.batch_index * batch_size) % n\n            if n >= current_index + batch_size:\n                current_batch_size = batch_size\n                self.batch_index += 1\n            else:\n                current_batch_size = n - current_index\n                self.batch_index = 0\n            self.total_batches_seen += 1\n            yield (index_array[current_index: current_index + current_batch_size],\n                   current_index, current_batch_size)\n\n    def __iter__(self):\n        # needed if we want to do something like:\n        # for x, y in data_gen.flow(...):\n        return self\n\n    def __next__(self, *args, **kwargs):\n        return self.next(*args, **kwargs)\n\n\ndef process_image_pipeline(tup):\n    """""" Worker function for NumpyArrayIterator multiprocessing.Pool\n    """"""\n    (pipeline, x, rng) = tup\n    x = x.astype(\'float32\')\n    for (func, kwargs) in pipeline:\n        x = func(x, rng=rng, **kwargs)\n    return x\n\ndef process_image_pipeline_dir(tup):\n    """""" Worker function for DirectoryIterator multiprocessing.Pool\n    """"""\n    (pipeline, fname, directory, grayscale,\n    target_size, dim_ordering, rng) = tup\n    img = load_img(os.path.join(directory, fname),\n                   grayscale=grayscale,\n                   target_size=target_size)\n    x = img_to_array(img, dim_ordering=dim_ordering)\n    for (func, kwargs) in pipeline:\n        x = func(x, rng=rng, **kwargs)\n    return x\n\nclass NumpyArrayIterator(Iterator):\n\n    def __init__(self, x, y, image_data_generator,\n                 batch_size=32, shuffle=False, seed=None,\n                 dim_ordering=\'default\',\n                 save_to_dir=None, save_prefix=\'\', save_format=\'jpeg\',\n                 pool=None):\n        if y is not None and len(x) != len(y):\n            raise ValueError(\'X (images tensor) and y (labels) \'\n                             \'should have the same length. \'\n                             \'Found: X.shape = %s, y.shape = %s\' %\n                             (np.asarray(x).shape, np.asarray(y).shape))\n        if dim_ordering == \'default\':\n            dim_ordering = K.image_dim_ordering()\n        self.x = np.asarray(x)\n        if self.x.ndim != 4:\n            raise ValueError(\'Input data in `NumpyArrayIterator` \'\n                             \'should have rank 4. You passed an array \'\n                             \'with shape\', self.x.shape)\n        channels_axis = 3 if dim_ordering == \'tf\' else 1\n        if self.x.shape[channels_axis] not in {1, 3, 4}:\n            raise ValueError(\'NumpyArrayIterator is set to use the \'\n                             \'dimension ordering convention ""\' + dim_ordering + \'"" \'\n                             \'(channels on axis \' + str(channels_axis) + \'), i.e. expected \'\n                             \'either 1, 3 or 4 channels on axis \' + str(channels_axis) + \'. \'\n                             \'However, it was passed an array with shape \' + str(self.x.shape) +\n                             \' (\' + str(self.x.shape[channels_axis]) + \' channels).\')\n        if y is not None:\n            self.y = np.asarray(y)\n        else:\n            self.y = None\n        self.image_data_generator = image_data_generator\n        self.dim_ordering = dim_ordering\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_format = save_format\n        self.pool = pool\n\n        super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n\n    def next(self):\n        # for python 2.x.\n        # Keeps under lock only the mechanism which advances\n        # the indexing of each batch\n        # see http://anandology.com/blog/using-iterators-and-generators/\n        with self.lock:\n            index_array, current_index, current_batch_size = next(self.index_generator)\n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n\n        batch_x = None\n\n        if self.pool:\n            pipeline = self.image_data_generator.pipeline()\n            result = self.pool.map(process_image_pipeline, (\n                (pipeline, self.x[j], self.rngs[i%self.batch_size])\n                for i, j in enumerate(index_array)))\n            batch_x = np.array(result)\n        else:\n            # TODO: also utilize image_data_generator.pipeline()?\n            batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]))\n            for i, j in enumerate(index_array):\n                x = self.x[j]\n                x = self.image_data_generator.random_transform(x.astype(\'float32\'))\n                x = self.image_data_generator.standardize(x)\n                batch_x[i] = x\n\n        if self.save_to_dir:\n            for i in range(current_batch_size):\n                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                  index=current_index + i,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        if self.y is None:\n            return batch_x\n        batch_y = self.y[index_array]\n        return batch_x, batch_y\n\n\nclass DirectoryIterator(Iterator):\n\n    def __init__(self, directory, image_data_generator,\n                 target_size=(256, 256), color_mode=\'rgb\',\n                 dim_ordering=\'default\',\n                 classes=None, class_mode=\'categorical\',\n                 batch_size=32, shuffle=True, seed=None,\n                 save_to_dir=None, save_prefix=\'\', save_format=\'jpeg\',\n                 follow_links=False, pool=None):\n        if dim_ordering == \'default\':\n            dim_ordering = K.image_dim_ordering()\n        self.directory = directory\n        self.image_data_generator = image_data_generator\n        self.target_size = tuple(target_size)\n        if color_mode not in {\'rgb\', \'grayscale\'}:\n            raise ValueError(\'Invalid color mode:\', color_mode,\n                             \'; expected ""rgb"" or ""grayscale"".\')\n        self.color_mode = color_mode\n        self.dim_ordering = dim_ordering\n        if self.color_mode == \'rgb\':\n            if self.dim_ordering == \'tf\':\n                self.image_shape = self.target_size + (3,)\n            else:\n                self.image_shape = (3,) + self.target_size\n        else:\n            if self.dim_ordering == \'tf\':\n                self.image_shape = self.target_size + (1,)\n            else:\n                self.image_shape = (1,) + self.target_size\n        self.classes = classes\n        if class_mode not in {\'categorical\', \'binary\', \'sparse\', None}:\n            raise ValueError(\'Invalid class_mode:\', class_mode,\n                             \'; expected one of ""categorical"", \'\n                             \'""binary"", ""sparse"", or None.\')\n        self.class_mode = class_mode\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_format = save_format\n        self.pool = pool\n\n        white_list_formats = {\'png\', \'jpg\', \'jpeg\', \'bmp\'}\n\n        # first, count the number of samples and classes\n        self.nb_sample = 0\n\n        if not classes:\n            classes = []\n            for subdir in sorted(os.listdir(directory)):\n                if os.path.isdir(os.path.join(directory, subdir)):\n                    classes.append(subdir)\n        self.nb_class = len(classes)\n        self.class_indices = dict(zip(classes, range(len(classes))))\n\n        def _recursive_list(subpath):\n            return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n\n        for subdir in classes:\n            subpath = os.path.join(directory, subdir)\n            for root, _, files in _recursive_list(subpath):\n                for fname in files:\n                    is_valid = False\n                    for extension in white_list_formats:\n                        if fname.lower().endswith(\'.\' + extension):\n                            is_valid = True\n                            break\n                    if is_valid:\n                        self.nb_sample += 1\n        print(\'Found %d images belonging to %d classes.\' % (self.nb_sample, self.nb_class))\n\n        # second, build an index of the images in the different class subfolders\n        self.filenames = []\n        self.classes = np.zeros((self.nb_sample,), dtype=\'int32\')\n        i = 0\n        for subdir in classes:\n            subpath = os.path.join(directory, subdir)\n            for root, _, files in _recursive_list(subpath):\n                for fname in files:\n                    is_valid = False\n                    for extension in white_list_formats:\n                        if fname.lower().endswith(\'.\' + extension):\n                            is_valid = True\n                            break\n                    if is_valid:\n                        self.classes[i] = self.class_indices[subdir]\n                        i += 1\n                        # add filename relative to directory\n                        absolute_path = os.path.join(root, fname)\n                        self.filenames.append(os.path.relpath(absolute_path, directory))\n        super(DirectoryIterator, self).__init__(self.nb_sample, batch_size, shuffle, seed)\n\n    def next(self):\n        with self.lock:\n            index_array, current_index, current_batch_size = next(self.index_generator)\n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n\n        batch_x = None\n        grayscale = self.color_mode == \'grayscale\'\n\n        if self.pool:\n            pipeline = self.image_data_generator.pipeline()\n            result = self.pool.map(process_image_pipeline_dir, ((pipeline,\n                self.filenames[j],\n                self.directory,\n                grayscale,\n                self.target_size,\n                self.dim_ordering,\n                self.rngs[i%self.batch_size]) for i, j in enumerate(index_array)))\n            batch_x = np.array(result)\n        else:\n            # TODO: also utilize image_data_generator.pipeline()?\n            batch_x = np.zeros((current_batch_size,) + self.image_shape)\n            # build batch of image data\n            for i, j in enumerate(index_array):\n                fname = self.filenames[j]\n                img = load_img(os.path.join(self.directory, fname),\n                               grayscale=grayscale,\n                               target_size=self.target_size)\n                x = img_to_array(img, dim_ordering=self.dim_ordering)\n                x = self.image_data_generator.random_transform(x)\n                x = self.image_data_generator.standardize(x)\n                batch_x[i] = x\n        # optionally save augmented images to disk for debugging purposes\n        if self.save_to_dir:\n            for i in range(current_batch_size):\n                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                  index=current_index + i,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        # build batch of labels\n        if self.class_mode == \'sparse\':\n            batch_y = self.classes[index_array]\n        elif self.class_mode == \'binary\':\n            batch_y = self.classes[index_array].astype(\'float32\')\n        elif self.class_mode == \'categorical\':\n            batch_y = np.zeros((len(batch_x), self.nb_class), dtype=\'float32\')\n            for i, label in enumerate(self.classes[index_array]):\n                batch_y[i, label] = 1.\n        else:\n            return batch_x\n        return batch_x, batch_y\n'"
tools/image_gen_extended.py,0,"b'\'\'\'Fairly basic set of tools for real-time data augmentation on image data.\nCan easily be extended to include new transformations,\nnew process methods, etc...\n\'\'\'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport numpy as np\nimport re\nfrom scipy import linalg\nimport scipy.ndimage as ndi\nfrom six.moves import range\nimport os\nimport sys\nimport threading\nimport copy\nimport inspect\nimport types\nimport multiprocessing as mp\n\nimport keras.backend as K\n\ndef random_rotation(x, rg, row_index=1, col_index=2, channel_index=0,\n                    fill_mode=\'nearest\', cval=0., rng=None):\n    theta = np.pi / 180 * rng.uniform(-rg, rg)\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n\n    h, w = x.shape[row_index], x.shape[col_index]\n    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_shift(x, wrg, hrg, row_index=1, col_index=2, channel_index=0,\n                 fill_mode=\'nearest\', cval=0., rng=None):\n    h, w = x.shape[row_index], x.shape[col_index]\n    tx = rng.uniform(-hrg, hrg) * h\n    ty = rng.uniform(-wrg, wrg) * w\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n\n    transform_matrix = translation_matrix  # no need to do offset\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_shear(x, intensity, row_index=1, col_index=2, channel_index=0,\n                 fill_mode=\'nearest\', cval=0., rng=None):\n    shear = rng.uniform(-intensity, intensity)\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    h, w = x.shape[row_index], x.shape[col_index]\n    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_zoom(x, zoom_range, row_index=1, col_index=2, channel_index=0,\n                fill_mode=\'nearest\', cval=0., rng=None):\n    if len(zoom_range) != 2:\n        raise Exception(\'zoom_range should be a tuple or list of two floats. \'\n                        \'Received arg: \', zoom_range)\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = rng.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    h, w = x.shape[row_index], x.shape[col_index]\n    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n    return x\n\n\ndef random_barrel_transform(x, intensity):\n    # TODO\n    pass\n\n\ndef random_channel_shift(x, intensity, channel_index=0, rng=None):\n    x = np.rollaxis(x, channel_index, 0)\n    min_x, max_x = np.min(x), np.max(x)\n    channel_images = [np.clip(x_channel + rng.uniform(-intensity, intensity), min_x, max_x)\n                      for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_index+1)\n    return x\n\n\ndef transform_matrix_offset_center(matrix, x, y):\n    o_x = float(x) / 2 + 0.5\n    o_y = float(y) / 2 + 0.5\n    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n    return transform_matrix\n\n\ndef apply_transform(x, transform_matrix, channel_index=0, fill_mode=\'nearest\', cval=0.):\n    x = np.rollaxis(x, channel_index, 0)\n    final_affine_matrix = transform_matrix[:2, :2]\n    final_offset = transform_matrix[:2, 2]\n    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n                      final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_index+1)\n    return x\n\n\ndef flip_axis(x, axis):\n    x = np.asarray(x).swapaxes(axis, 0)\n    x = x[::-1, ...]\n    x = x.swapaxes(0, axis)\n    return x\n\n\ndef array_to_img(x, dim_ordering=K.image_dim_ordering(), mode=None, scale=True):\n    from PIL import Image\n    x = x.copy()\n    if dim_ordering == \'th\':\n        x = x.transpose(1, 2, 0)\n    if scale:\n        x += max(-np.min(x), 0)\n        x /= np.max(x)\n        x *= 255\n    if x.shape[2] == 3 and mode == \'RGB\':\n        return Image.fromarray(x.astype(\'uint8\'), mode)\n    elif x.shape[2] == 1 and mode == \'L\':\n        return Image.fromarray(x[:, :, 0].astype(\'uint8\'), mode)\n    elif mode:\n        return Image.fromarray(x, mode)\n    else:\n        raise Exception(\'Unsupported array shape: \', x.shape)\n\n\ndef img_to_array(img, dim_ordering=K.image_dim_ordering()):\n    if dim_ordering not in [\'th\', \'tf\']:\n        raise Exception(\'Unknown dim_ordering: \', dim_ordering)\n    # image has dim_ordering (height, width, channel)\n    x = np.asarray(img, dtype=\'float32\')\n    if len(x.shape) == 3:\n        if dim_ordering == \'th\':\n            x = x.transpose(2, 0, 1)\n    elif len(x.shape) == 2:\n        if dim_ordering == \'th\':\n            x = x.reshape((1, x.shape[0], x.shape[1]))\n        else:\n            x = x.reshape((x.shape[0], x.shape[1], 1))\n    else:\n        raise Exception(\'Unsupported image shape: \', x.shape)\n    return x\n\n\ndef load_img(path, target_mode=None, target_size=None):\n    from PIL import Image\n    img = Image.open(path)\n    if target_mode:\n        img = img.convert(target_mode)\n    if target_size:\n        img = img.resize((target_size[1], target_size[0]))\n    return img\n\ndef list_pictures(directory, ext=\'jpg|jpeg|bmp|png\'):\n    return [os.path.join(directory, f) for f in os.listdir(directory)\n            if os.path.isfile(os.path.join(directory, f)) and re.match(\'([\\w]+\\.(?:\' + ext + \'))\', f)]\n\ndef pil_image_reader(filepath, target_mode=None, target_size=None, dim_ordering=K.image_dim_ordering(), **kwargs):\n    img = load_img(filepath, target_mode=target_mode, target_size=target_size)\n    return img_to_array(img, dim_ordering=dim_ordering)\n\ndef standardize(x,\n                dim_ordering=\'th\',\n                rescale=False,\n                featurewise_center=False,\n                samplewise_center=False,\n                featurewise_std_normalization=False,\n                mean=None, std=None,\n                samplewise_std_normalization=False,\n                zca_whitening=False, principal_components=None,\n                featurewise_standardize_axis=None,\n                samplewise_standardize_axis=None,\n                fitting=False,\n                verbose=0,\n                config={},\n                **kwargs):\n    \'\'\'\n\n    # Arguments\n        featurewise_center: set input mean to 0 over the dataset.\n        samplewise_center: set each sample mean to 0.\n        featurewise_std_normalization: divide inputs by std of the dataset.\n        samplewise_std_normalization: divide each input by its std.\n        featurewise_standardize_axis: axis along which to perform feature-wise center and std normalization.\n        samplewise_standardize_axis: axis along which to to perform sample-wise center and std normalization.\n        zca_whitening: apply ZCA whitening.\n\n    \'\'\'\n    if fitting:\n        if \'_X\' in config:\n            # add data to _X array\n            config[\'_X\'][config[\'_iX\']] = x\n            config[\'_iX\'] +=1\n            # if verbose and config.has_key(\'_fit_progressbar\'):\n                # config[\'_fit_progressbar\'].update(config[\'_iX\'], force=(config[\'_iX\']==fitting))\n\n            # the array (_X) is ready to fit\n            if config[\'_iX\'] >= fitting:\n                X = config[\'_X\'].astype(\'float32\')\n                del config[\'_X\']\n                del config[\'_iX\']\n                if featurewise_center or featurewise_std_normalization:\n                    featurewise_standardize_axis = featurewise_standardize_axis or 0\n                    if type(featurewise_standardize_axis) is int:\n                        featurewise_standardize_axis = (featurewise_standardize_axis, )\n                    assert 0 in featurewise_standardize_axis, \'feature-wise standardize axis should include 0\'\n\n                if featurewise_center:\n                    mean = np.mean(X, axis=featurewise_standardize_axis, keepdims=True)\n                    config[\'mean\'] = np.squeeze(mean, axis=0)\n                    X -= mean\n\n                if featurewise_std_normalization:\n                    std = np.std(X, axis=featurewise_standardize_axis, keepdims=True)\n                    config[\'std\'] = np.squeeze(std, axis=0)\n                    X /= (std + 1e-7)\n\n                if zca_whitening:\n                    flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\n                    sigma = np.dot(flatX.T, flatX) / flatX.shape[1]\n                    U, S, V = linalg.svd(sigma)\n                    config[\'principal_components\'] = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)\n                if verbose:\n                    del config[\'_fit_progressbar\']\n        else:\n            # start a new fitting, fitting = total sample number\n            config[\'_X\'] = np.zeros((fitting,)+x.shape)\n            config[\'_iX\'] = 0\n            config[\'_X\'][config[\'_iX\']] = x\n            config[\'_iX\'] +=1\n            # if verbose:\n                # config[\'_fit_progressbar\'] = Progbar(target=fitting, verbose=verbose)\n        return x\n\n    if rescale:\n        x *= rescale\n\n    # x is a single image, so it doesn\'t have image number at index 0\n    if dim_ordering == \'th\':\n        channel_index = 0\n    if dim_ordering == \'tf\':\n        channel_index = 2\n\n    samplewise_standardize_axis = samplewise_standardize_axis or channel_index\n    if type(samplewise_standardize_axis) is int:\n        samplewise_standardize_axis = (samplewise_standardize_axis, )\n\n    if samplewise_center:\n        x -= np.mean(x, axis=samplewise_standardize_axis, keepdims=True)\n    if samplewise_std_normalization:\n        x /= (np.std(x, axis=samplewise_standardize_axis, keepdims=True) + 1e-7)\n\n    if verbose:\n        if (featurewise_center and mean is None) or (featurewise_std_normalization and std is None) or (zca_whitening and principal_components is None):\n            print(\'WARNING: feature-wise standardization and zca whitening will be disabled, please run ""fit"" first.\')\n\n    if featurewise_center:\n        if mean is not None:\n            x -= mean\n    if featurewise_std_normalization:\n        if std is not None:\n            x /= (std + 1e-7)\n\n    if zca_whitening:\n        if principal_components is not None:\n            flatx = np.reshape(x, (x.size))\n            whitex = np.dot(flatx, principal_components)\n            x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n    return x\n\ndef center_crop(x, center_crop_size, **kwargs):\n    centerw, centerh = x.shape[0]//2, x.shape[1]//2\n    halfw, halfh = center_crop_size[0]//2, center_crop_size[1]//2\n    return x[centerw-halfw:centerw+halfw,centerh-halfh:centerh+halfh, :]\n\ndef random_crop(x, random_crop_size, sync_seed=None, rng=None, **kwargs):\n    # np.random.seed(sync_seed)\n    w, h = x.shape[0], x.shape[1]\n    rangew = (w - random_crop_size[0]) // 2\n    rangeh = (h - random_crop_size[1]) // 2\n    #print(\'w: {}, h: {}, rangew: {}, rangeh: {}\'.format(w, h, rangew, rangeh))\n    offsetw = 0 if rangew == 0 else rng.randint(rangew)\n    offseth = 0 if rangeh == 0 else rng.randint(rangeh)\n    return x[offsetw:offsetw+random_crop_size[0], offseth:offseth+random_crop_size[1], :]\n\nfrom keras.applications.inception_v3 import preprocess_input as pp\n\ndef preprocess_input(x, rng=None, **kwargs):\n    return pp(x)\n\ndef random_transform(x,\n                     dim_ordering=\'tf\',\n                     rotation_range=0.,\n                     width_shift_range=0.,\n                     height_shift_range=0.,\n                     shear_range=0.,\n                     zoom_range=0.,\n                     channel_shift_range=0.,\n                     fill_mode=\'nearest\',\n                     cval=0.,\n                     horizontal_flip=False,\n                     vertical_flip=False,\n                     rescale=None,\n                     sync_seed=None,\n                     rng=None,\n                     **kwargs):\n    \'\'\'\n\n    # Arguments\n        rotation_range: degrees (0 to 180).\n        width_shift_range: fraction of total width.\n        height_shift_range: fraction of total height.\n        shear_range: shear intensity (shear angle in radians).\n        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n            in the range [1-z, 1+z]. A sequence of two can be passed instead\n            to select this range.\n        channel_shift_range: shift range for each channels.\n        fill_mode: points outside the boundaries are filled according to the\n            given mode (\'constant\', \'nearest\', \'reflect\' or \'wrap\'). Default\n            is \'nearest\'.\n        cval: value used for points outside the boundaries when fill_mode is\n            \'constant\'. Default is 0.\n        horizontal_flip: whether to randomly flip images horizontally.\n        vertical_flip: whether to randomly flip images vertically.\n        rescale: rescaling factor. If None or 0, no rescaling is applied,\n            otherwise we multiply the data by the value provided (before applying\n            any other transformation).\n    \'\'\'\n    # rng.seed(sync_seed)\n\n    x = x.astype(\'float32\')\n    # x is a single image, so it doesn\'t have image number at index 0\n    if dim_ordering == \'th\':\n        img_channel_index = 0\n        img_row_index = 1\n        img_col_index = 2\n    if dim_ordering == \'tf\':\n        img_channel_index = 2\n        img_row_index = 0\n        img_col_index = 1\n    # use composition of homographies to generate final transform that needs to be applied\n    if rotation_range:\n        theta = np.pi / 180 * rng.uniform(-rotation_range, rotation_range)\n    else:\n        theta = 0\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n    if height_shift_range:\n        tx = rng.uniform(-height_shift_range, height_shift_range) * x.shape[img_row_index]\n    else:\n        tx = 0\n\n    if width_shift_range:\n        ty = rng.uniform(-width_shift_range, width_shift_range) * x.shape[img_col_index]\n    else:\n        ty = 0\n\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n    if shear_range:\n        shear = rng.uniform(-shear_range, shear_range)\n    else:\n        shear = 0\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    if np.isscalar(zoom_range):\n        zoom_range = [1 - zoom_range, 1 + zoom_range]\n    elif len(zoom_range) == 2:\n        zoom_range = [zoom_range[0], zoom_range[1]]\n    else:\n        raise Exception(\'zoom_range should be a float or \'\n                        \'a tuple or list of two floats. \'\n                        \'Received arg: \', zoom_range)\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = rng.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    transform_matrix = np.dot(np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)\n\n    h, w = x.shape[img_row_index], x.shape[img_col_index]\n    transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n    x = apply_transform(x, transform_matrix, img_channel_index,\n                        fill_mode=fill_mode, cval=cval)\n    if channel_shift_range != 0:\n        x = random_channel_shift(x, channel_shift_range, img_channel_index, rng=rng)\n\n    if horizontal_flip:\n        if rng.rand() < 0.5:\n            x = flip_axis(x, img_col_index)\n\n    if vertical_flip:\n        if rng.rand() < 0.5:\n            x = flip_axis(x, img_row_index)\n\n    # TODO:\n    # barrel/fisheye\n\n    #rng.seed()\n    return x\n\nclass ImageDataGenerator(object):\n    \'\'\'Generate minibatches with\n    real-time data augmentation.\n\n    # Arguments\n        featurewise_center: set input mean to 0 over the dataset.\n        samplewise_center: set each sample mean to 0.\n        featurewise_std_normalization: divide inputs by std of the dataset.\n        samplewise_std_normalization: divide each input by its std.\n        featurewise_standardize_axis: axis along which to perform feature-wise center and std normalization.\n        samplewise_standardize_axis: axis along which to to perform sample-wise center and std normalization.\n        zca_whitening: apply ZCA whitening.\n        rotation_range: degrees (0 to 180).\n        width_shift_range: fraction of total width.\n        height_shift_range: fraction of total height.\n        shear_range: shear intensity (shear angle in radians).\n        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n            in the range [1-z, 1+z]. A sequence of two can be passed instead\n            to select this range.\n        channel_shift_range: shift range for each channels.\n        fill_mode: points outside the boundaries are filled according to the\n            given mode (\'constant\', \'nearest\', \'reflect\' or \'wrap\'). Default\n            is \'nearest\'.\n        cval: value used for points outside the boundaries when fill_mode is\n            \'constant\'. Default is 0.\n        horizontal_flip: whether to randomly flip images horizontally.\n        vertical_flip: whether to randomly flip images vertically.\n        rescale: rescaling factor. If None or 0, no rescaling is applied,\n            otherwise we multiply the data by the value provided (before applying\n            any other transformation).\n        dim_ordering: \'th\' or \'tf\'. In \'th\' mode, the channels dimension\n            (the depth) is at index 1, in \'tf\' mode it is at index 3.\n            It defaults to the `image_dim_ordering` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""th"".\n        seed: random seed for reproducible pipeline processing. If not None, it will also be used by `flow` or\n            `flow_from_directory` to generate the shuffle index in case of no seed is set.\n    \'\'\'\n    def __init__(self,\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 featurewise_standardize_axis=None,\n                 samplewise_standardize_axis=None,\n                 zca_whitening=False,\n                 rotation_range=0.,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode=\'nearest\',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 dim_ordering=K.image_dim_ordering(),\n                 seed=None,\n                 verbose=1):\n        self.config = copy.deepcopy(locals())\n        self.config[\'config\'] = self.config\n        self.config[\'mean\'] = None\n        self.config[\'std\'] = None\n        self.config[\'principal_components\'] = None\n        self.config[\'rescale\'] = rescale\n\n        if dim_ordering not in {\'tf\', \'th\'}:\n            raise Exception(\'dim_ordering should be ""tf"" (channel after row and \'\n                            \'column) or ""th"" (channel before row and column). \'\n                            \'Received arg: \', dim_ordering)\n\n        self.__sync_seed = self.config[\'seed\'] or np.random.randint(0, 4294967295)\n\n        self.default_pipeline = []\n        self.default_pipeline.append(random_transform)\n        self.default_pipeline.append(standardize)\n        self.set_pipeline(self.default_pipeline)\n\n        self.__fitting = False\n        # self.fit_lock = threading.Lock()\n\n    @property\n    def sync_seed(self):\n        return self.__sync_seed\n\n    @property\n    def fitting(self):\n        return self.__fitting\n\n    @property\n    def pipeline(self):\n        return self.__pipeline\n\n    def sync(self, image_data_generator):\n        self.__sync_seed = image_data_generator.sync_seed\n        return (self, image_data_generator)\n\n    def set_pipeline(self, p):\n        if p is None:\n            self.__pipeline = self.default_pipeline\n        elif type(p) is list:\n            self.__pipeline = p\n        else:\n            raise Exception(\'invalid pipeline.\')\n\n    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n             save_to_dir=None, save_prefix=\'\', save_mode=None, save_format=\'jpeg\',\n             pool=None):\n        return NumpyArrayIterator(\n            X, y, self,\n            batch_size=batch_size, shuffle=shuffle, seed=seed,\n            dim_ordering=self.config[\'dim_ordering\'],\n            save_to_dir=save_to_dir, save_prefix=save_prefix,\n            save_mode=save_mode, save_format=save_format,\n            pool=pool)\n\n    def flow_from_directory(self, directory,\n                            color_mode=None, target_size=None,\n                            image_reader=\'pil\', reader_config={\'target_mode\':\'RGB\', \'target_size\':(256,256)},\n                            read_formats={\'png\',\'jpg\',\'jpeg\',\'bmp\'},\n                            classes=None, class_mode=\'categorical\',\n                            batch_size=32, shuffle=True, seed=None,\n                            save_to_dir=None, save_prefix=\'\',\n                            save_mode=None, save_format=\'jpeg\'):\n        return DirectoryIterator(\n            directory, self,\n            color_mode=color_mode, target_size=target_size,\n            image_reader=image_reader, reader_config=reader_config,\n            read_formats=read_formats,\n            classes=classes, class_mode=class_mode,\n            dim_ordering=self.config[\'dim_ordering\'],\n            batch_size=batch_size, shuffle=shuffle, seed=seed,\n            save_to_dir=save_to_dir, save_prefix=save_prefix,\n            save_mode=save_mode, save_format=save_format)\n\n    def process(self, x, rng):\n        # get next sync_seed\n        # np.random.seed(self.__sync_seed)\n        #np.random.seed(int.from_bytes(os.urandom(4), byteorder=\'little\'))\n        #self.__sync_seed = np.random.randint(0, 4294967295)\n        # __sync_seed = rng.randint(0, 4294967295)\n        # # print(self.__sync_seed)\n        # self.config[\'fitting\'] = self.__fitting\n        # try:\n        #     del self.config[\'sync_seed\']\n        # except:\n        #     pass\n        #self.config[\'sync_seed\'] = self.__sync_seed\n        for p in self.__pipeline:\n            x = p(x, rng=rng, **self.config)\n        return x\n\n    def fit_generator(self, generator, nb_iter):\n        \'\'\'Fit a generator\n\n        # Arguments\n            generator: Iterator, generate data for fitting.\n            nb_iter: Int, number of iteration to fit.\n        \'\'\'\n        # with self.fit_lock:\n        #     try:\n        #         self.__fitting = nb_iter*generator.batch_size\n        #         for i in range(nb_iter):\n        #             next(generator)\n        #     finally:\n        #         self.__fitting = False\n\n    def fit(self, X, rounds=1):\n        \'\'\'Fit the pipeline on a numpy array\n\n        # Arguments\n            X: Numpy array, the data to fit on.\n            rounds: how many rounds of fit to do over the data\n        \'\'\'\n        X = np.copy(X)\n        # with self.fit_lock:\n        #     try:\n        #         self.__fitting = rounds*X.shape[0]\n        #         for r in range(rounds):\n        #             for i in range(X.shape[0]):\n        #                 self.process(X[i])\n        #     finally:\n        #         self.__fitting = False\n\nclass Iterator(object):\n\n    def __init__(self, N, batch_size, shuffle, seed):\n        self.N = N\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.seed = seed\n        self.batch_index = 0\n        self.total_batches_seen = 0\n        self.lock = threading.Lock()\n        self.index_generator = self._flow_index(N, batch_size, shuffle, seed)\n\n    def reset(self):\n        self.batch_index = 0\n\n    def _flow_index(self, N, batch_size=32, shuffle=False, seed=None):\n        # ensure self.batch_index is 0\n        self.reset()\n        while 1:\n            if self.batch_index == 0:\n                self.index_array = np.arange(N)\n                if shuffle:\n                    if seed is not None:\n                        np.random.seed(seed + self.total_batches_seen)\n                    self.index_array = np.random.permutation(N)\n                    if seed is not None:\n                        np.random.seed()\n\n            current_index = (self.batch_index * batch_size) % N\n            if N >= current_index + batch_size:\n                current_batch_size = batch_size\n                self.batch_index += 1\n            else:\n                current_batch_size = N - current_index\n                self.batch_index = 0\n            self.total_batches_seen += 1\n            yield (self.index_array[current_index: current_index + current_batch_size],\n                   current_index, current_batch_size)\n\n    def __add__(self, it):\n        assert self.N == it.N\n        assert self.batch_size == it.batch_size\n        assert self.shuffle == it.shuffle\n        seed = self.seed or np.random.randint(0, 4294967295)\n        it.total_batches_seen = self.total_batches_seen\n        self.index_generator = self._flow_index(self.N, self.batch_size, self.shuffle, seed)\n        it.index_generator = it._flow_index(it.N, it.batch_size, it.shuffle, seed)\n        if (sys.version_info > (3, 0)):\n            iter_zip = zip\n        else:\n            from itertools import izip\n            iter_zip = izip\n        return iter_zip(self, it)\n\n    def __iter__(self):\n        # needed if we want to do something like:\n        # for x, y in data_gen.flow(...):\n        return self\n\n    def __next__(self, *args, **kwargs):\n        return self.next(*args, **kwargs)\n\ndef process_image_worker(tup):\n    process, img, rng = tup\n    ret = process(img, rng)\n    return ret\n\nclass NumpyArrayIterator(Iterator):\n\n    def __init__(self, X, y, image_data_generator,\n                 batch_size=32, shuffle=False, seed=None,\n                 dim_ordering=K.image_dim_ordering(),\n                 save_to_dir=None, save_prefix=\'\',\n                 save_mode=None, save_format=\'jpeg\',\n                 pool=None):\n        if y is not None and len(X) != len(y):\n            raise Exception(\'X (images tensor) and y (labels) \'\n                            \'should have the same length. \'\n                            \'Found: X.shape = %s, y.shape = %s\' % (np.asarray(X).shape, np.asarray(y).shape))\n        self.X = X\n        self.y = y\n        self.image_data_generator = image_data_generator\n        self.dim_ordering = dim_ordering\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_mode = save_mode\n        self.save_format = save_format\n        seed = seed or image_data_generator.config[\'seed\']\n        self.pool = pool\n        self.rngs = [np.random.RandomState(seed + i) for i in range(batch_size)]\n        super(NumpyArrayIterator, self).__init__(X.shape[0], batch_size, shuffle, seed)\n\n    def close(self):\n        pass\n        # print(\'closing pool!\')\n        # self.pool.close()\n        # self.pool.join()\n        # self.pool.terminate()\n        # self.pool = None\n        # print(\'closed pool!\')\n\n    def __add__(self, it):\n        if isinstance(it, NumpyArrayIterator):\n            assert self.X.shape[0] == it.X.shape[0]\n        if isinstance(it, DirectoryIterator):\n            assert self.X.shape[0] == it.nb_sample\n        it.image_data_generator.sync(self.image_data_generator)\n        return super(NumpyArrayIterator, self).__add__(it)\n\n    def next(self):\n        # for python 2.x.\n        # Keeps under lock only the mechanism which advances\n        # the indexing of each batch\n        # see http://anandology.com/blog/using-iterators-and-generators/\n        with self.lock:\n            index_array, current_index, current_batch_size = next(self.index_generator)\n        # The transformation of images is not under thread lock so it can be done in parallel\n        result = self.pool.map(process_image_worker, ((self.image_data_generator.process, self.X[j], self.rngs[i%self.batch_size]) for i, j in enumerate(index_array)))\n        batch_x = np.array(result)\n\n        for i, rng in enumerate(self.rngs):\n            new_seed = rng.randint(0, 4294967295)\n            self.rngs[i] = np.random.RandomState(new_seed)\n\n        # for i, j in enumerate(index_array):\n        #     # print(i, j)\n        #     x = self.X[j]\n        #     x = self.image_data_generator.process(x)\n        #     if i == 0:\n        #         batch_x = np.zeros((current_batch_size,) + x.shape)\n        #         # print(batch_x.shape)\n        #     batch_x[i] = x\n\n        if self.save_to_dir:\n            for i in range(current_batch_size):\n                img = array_to_img(batch_x[i], self.dim_ordering, mode=self.save_mode, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                  index=current_index + i,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        if self.y is None:\n            return batch_x\n        batch_y = self.y[index_array]\n        return batch_x, batch_y\n\n\nclass DirectoryIterator(Iterator):\n\n    def __init__(self, directory, image_data_generator,\n                 color_mode=None, target_size=None,\n                 image_reader=""pil"", read_formats={\'png\',\'jpg\',\'jpeg\',\'bmp\'},\n                 reader_config={\'target_mode\': \'RGB\', \'target_size\':None},\n                 dim_ordering=K.image_dim_ordering,\n                 classes=None, class_mode=\'categorical\',\n                 batch_size=32, shuffle=True, seed=None,\n                 save_to_dir=None, save_prefix=\'\',\n                 save_mode=None, save_format=\'jpeg\'):\n        self.directory = directory\n        self.image_data_generator = image_data_generator\n        self.image_reader = image_reader\n        if self.image_reader == \'pil\':\n            self.image_reader = pil_image_reader\n        self.reader_config = reader_config\n        # TODO: move color_mode and target_size to reader_config\n        if color_mode == \'rgb\':\n            self.reader_config[\'target_mode\'] = \'RGB\'\n        elif color_mode == \'grayscale\':\n            self.reader_config[\'target_mode\'] = \'L\'\n\n        if target_size:\n            self.reader_config[\'target_size\'] = target_size\n\n        self.dim_ordering = dim_ordering\n        self.reader_config[\'dim_ordering\'] = dim_ordering\n        if class_mode not in {\'categorical\', \'binary\', \'sparse\', None}:\n            raise ValueError(\'Invalid class_mode:\', class_mode,\n                             \'; expected one of ""categorical"", \'\n                             \'""binary"", ""sparse"", or None.\')\n        self.class_mode = class_mode\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_mode = save_mode\n        self.save_format = save_format\n\n        seed = seed or image_data_generator.config[\'seed\']\n\n        # first, count the number of samples and classes\n        self.nb_sample = 0\n\n        if not classes:\n            classes = []\n            for subdir in sorted(os.listdir(directory)):\n                if os.path.isdir(os.path.join(directory, subdir)):\n                    classes.append(subdir)\n        # if no class is found, add \'\' for scanning the root folder\n        if class_mode is None and len(classes) == 0:\n            classes.append(\'\')\n        self.nb_class = len(classes)\n        self.class_indices = dict(zip(classes, range(len(classes))))\n\n        for subdir in classes:\n            subpath = os.path.join(directory, subdir)\n            for fname in os.listdir(subpath):\n                is_valid = False\n                for extension in read_formats:\n                    if fname.lower().endswith(\'.\' + extension):\n                        is_valid = True\n                        break\n                if is_valid:\n                    self.nb_sample += 1\n        print(\'Found %d images belonging to %d classes.\' % (self.nb_sample, self.nb_class))\n\n        # second, build an index of the images in the different class subfolders\n        self.filenames = []\n        self.classes = np.zeros((self.nb_sample,), dtype=\'int32\')\n        i = 0\n        for subdir in classes:\n            subpath = os.path.join(directory, subdir)\n            for fname in os.listdir(subpath):\n                is_valid = False\n                for extension in read_formats:\n                    if fname.lower().endswith(\'.\' + extension):\n                        is_valid = True\n                        break\n                if is_valid:\n                    self.classes[i] = self.class_indices[subdir]\n                    self.filenames.append(os.path.join(subdir, fname))\n                    i += 1\n\n        assert len(self.filenames)>0, \'No valid file is found in the target directory.\'\n        self.reader_config[\'class_mode\'] = self.class_mode\n        self.reader_config[\'classes\'] = self.classes\n        self.reader_config[\'filenames\'] = self.filenames\n        self.reader_config[\'directory\'] = self.directory\n        self.reader_config[\'nb_sample\'] = self.nb_sample\n        self.reader_config[\'seed\'] = seed\n        self.reader_config[\'sync_seed\'] = self.image_data_generator.sync_seed\n        super(DirectoryIterator, self).__init__(self.nb_sample, batch_size, shuffle, seed)\n        if inspect.isgeneratorfunction(self.image_reader):\n            self._reader_generator_mode = True\n            self._reader_generator = []\n            # set index batch_size to 1\n            self.index_generator = self._flow_index(self.N, 1 , self.shuffle, seed)\n        else:\n            self._reader_generator_mode = False\n\n    def __add__(self, it):\n        if isinstance(it, DirectoryIterator):\n            assert self.nb_sample == it.nb_sample\n            assert len(self.filenames) == len(it.filenames)\n            assert np.alltrue(self.classes == it.classes)\n            assert self.image_reader == it.image_reader\n            if inspect.isgeneratorfunction(self.image_reader):\n                self._reader_generator = []\n                it._reader_generator = []\n        if isinstance(it, NumpyArrayIterator):\n            assert self.nb_sample == self.X.shape[0]\n        it.image_data_generator.sync(self.image_data_generator)\n        return super(DirectoryIterator, self).__add__(it)\n\n    def next(self):\n        self.reader_config[\'sync_seed\'] = self.image_data_generator.sync_seed\n        if self._reader_generator_mode:\n            sampleCount = 0\n            batch_x = None\n            _new_generator_flag = False\n            while sampleCount<self.batch_size:\n                for x in self._reader_generator:\n                    _new_generator_flag = False\n                    if x.ndim == 2:\n                        x = np.expand_dims(x, axis=0)\n                    x = self.image_data_generator.process(x)\n                    self.reader_config[\'sync_seed\'] = self.image_data_generator.sync_seed\n                    if sampleCount == 0:\n                        batch_x = np.zeros((self.batch_size,) + x.shape)\n                    batch_x[sampleCount] = x\n                    sampleCount +=1\n                    if sampleCount >= self.batch_size:\n                        break\n                if sampleCount >= self.batch_size or _new_generator_flag:\n                    break\n                with self.lock:\n                    index_array, _, _ = next(self.index_generator)\n                fname = self.filenames[index_array[0]]\n                self._reader_generator = self.image_reader(os.path.join(self.directory, fname), **self.reader_config)\n                assert isinstance(self._reader_generator, types.GeneratorType)\n                _new_generator_flag = True\n        else:\n            with self.lock:\n                index_array, current_index, current_batch_size = next(self.index_generator)\n            # The transformation of images is not under thread lock so it can be done in parallel\n            batch_x = None\n            # build batch of image data\n            for i, j in enumerate(index_array):\n                fname = self.filenames[j]\n                x = self.image_reader(os.path.join(self.directory, fname), **self.reader_config)\n                if x.ndim == 2:\n                    x = np.expand_dims(x, axis=0)\n                x = self.image_data_generator.process(x)\n                if i == 0:\n                    batch_x = np.zeros((current_batch_size,) + x.shape)\n                batch_x[i] = x\n        # optionally save augmented images to disk for debugging purposes\n        if self.save_to_dir:\n            for i in range(current_batch_size):\n                img = array_to_img(batch_x[i], self.dim_ordering, mode=self.save_mode, scale=True)\n                fname = \'{prefix}_{index}_{hash}.{format}\'.format(prefix=self.save_prefix,\n                                                                  index=current_index + i,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        # build batch of labels\n        if self.class_mode == \'sparse\':\n            batch_y = self.classes[index_array]\n        elif self.class_mode == \'binary\':\n            batch_y = self.classes[index_array].astype(\'float32\')\n        elif self.class_mode == \'categorical\':\n            batch_y = np.zeros((len(batch_x), self.nb_class), dtype=\'float32\')\n            for i, label in enumerate(self.classes[index_array]):\n                batch_y[i, label] = 1.\n        else:\n            return batch_x\n        return batch_x, batch_y\n'"
tools/sysmonitor.py,0,"b'import time\nimport datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import OrderedDict\nimport psutil\nimport threading\n\nfrom pynvml import (nvmlInit,\n                     nvmlDeviceGetCount,\n                     nvmlDeviceGetHandleByIndex,\n                     nvmlDeviceGetUtilizationRates,\n                     nvmlDeviceGetName)\n\ndef gpu_info():\n    ""Returns a tuple of (GPU ID, GPU Description, GPU % Utilization)""\n    nvmlInit()\n    deviceCount = nvmlDeviceGetCount()\n    info = []\n    for i in range(0, deviceCount):\n        handle = nvmlDeviceGetHandleByIndex(i)\n        util = nvmlDeviceGetUtilizationRates(handle)\n        desc = nvmlDeviceGetName(handle)\n        info.append((i, desc, util.gpu)) #[\'GPU %i - %s\' % (i, desc)] = util.gpu\n    return info\n\nutils = []\n\nclass SysMonitor(threading.Thread):\n    shutdown = False\n\n    def __init__(self):\n        self.utils = []\n        self.start_time = time.time()\n        self.duration = 0\n        threading.Thread.__init__(self)\n\n    def run(self):\n        utils = []\n        while not self.shutdown:\n            dt = datetime.datetime.now()\n            util = gpu_info()\n            cpu_percent = psutil.cpu_percent()\n            self.utils.append([dt] + [x[2] for x in util] + [cpu_percent])\n            time.sleep(.1)\n\n    def stop(self):\n        self.shutdown = True\n        self.duration = time.time() - self.start_time\n\n    def plot(self, title, vert=False):\n        if vert:\n            fig, ax = plt.subplots(2, 1, figsize=(15, 6))\n        else:\n            fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n        fig.suptitle(title, size=24)\n        ax[0].title.set_text(\'GPU Utilization\')\n        ax[0].plot([u[1] for u in self.utils])\n        ax[0].set_ylim([0, 100])\n        ax[1].title.set_text(\'CPU Utilization\')\n        ax[1].plot([u[2] for u in self.utils])\n        ax[1].set_ylim([0, 100])\n        plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n'"
