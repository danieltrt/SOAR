file_path,api_count,code
ops.py,289,"b'import tensorflow as tf\nimport numpy as np\nfrom utils import pytorch_xavier_weight_factor, pytorch_kaiming_weight_factor\n\n##################################################################################\n# Initialization\n##################################################################################\n\n""""""\n\npytorch xavier (gain)\nhttps://pytorch.org/docs/stable/_modules/torch/nn/init.html\n\nUSE < tf.contrib.layers.variance_scaling_initializer() >\nif uniform :\n    factor = gain * gain\n    mode = \'FAN_AVG\'\nelse :\n    factor = (gain * gain) / 1.3\n    mode = \'FAN_AVG\'\n\npytorch : trunc_stddev = gain * sqrt(2 / (fan_in + fan_out))\ntensorflow  : trunc_stddev = sqrt(1.3 * factor * 2 / (fan_in + fan_out))\n\n""""""\n\n""""""\npytorch kaiming (a=0)\nhttps://pytorch.org/docs/stable/_modules/torch/nn/init.html\n\nif uniform :\n    a = 0 -> gain = sqrt(2)\n    factor = gain * gain\n    mode=\'FAN_IN\'\nelse :\n    a = 0 -> gain = sqrt(2)\n    factor = (gain * gain) / 1.3\n    mode = \'FAN_OUT\', # FAN_OUT is correct, but more use \'FAN_IN\n\npytorch : trunc_stddev = gain * sqrt(2 / fan_in)\ntensorflow  : trunc_stddev = sqrt(1.3 * factor * 2 / fan_in)\n\n""""""\n\n# Xavier : tf.contrib.layers.xavier_initializer()\n# He : tf.contrib.layers.variance_scaling_initializer()\n# Normal : tf.random_normal_initializer(mean=0.0, stddev=0.02)\n# Truncated_normal : tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n# Orthogonal : tf.orthogonal_initializer(0.02)\n\n##################################################################################\n# Regularization\n##################################################################################\n\n# l2_decay : tf.contrib.layers.l2_regularizer(0.0001)\n# orthogonal_regularizer : orthogonal_regularizer(0.0001) # orthogonal_regularizer_fully(0.0001)\n\n# factor, mode, uniform = pytorch_xavier_weight_factor(gain=0.02, uniform=False)\n# weight_init = tf_contrib.layers.variance_scaling_initializer(factor=factor, mode=mode, uniform=uniform)\n\nweight_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\nweight_regularizer = tf.contrib.layers.l2_regularizer(0.0001)\nweight_regularizer_fully = tf.contrib.layers.l2_regularizer(0.0001)\n\n\n##################################################################################\n# Layers\n##################################################################################\n\n# padding=\'SAME\' ======> pad = floor[ (kernel - stride) / 2 ]\ndef conv(x, channels, kernel=4, stride=2, pad=0, pad_type=\'zero\', use_bias=True, sn=False, scope=\'conv_0\'):\n    with tf.variable_scope(scope):\n        if pad > 0:\n            h = x.get_shape().as_list()[1]\n            if h % stride == 0:\n                pad = pad * 2\n            else:\n                pad = max(kernel - (h % stride), 0)\n\n            pad_top = pad // 2\n            pad_bottom = pad - pad_top\n            pad_left = pad // 2\n            pad_right = pad - pad_left\n\n            if pad_type == \'zero\':\n                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]])\n            if pad_type == \'reflect\':\n                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], mode=\'REFLECT\')\n\n        if sn:\n            w = tf.get_variable(""kernel"", shape=[kernel, kernel, x.get_shape()[-1], channels], initializer=weight_init,\n                                regularizer=weight_regularizer)\n            x = tf.nn.conv2d(input=x, filter=spectral_norm(w),\n                             strides=[1, stride, stride, 1], padding=\'VALID\')\n            if use_bias:\n                bias = tf.get_variable(""bias"", [channels], initializer=tf.constant_initializer(0.0))\n                x = tf.nn.bias_add(x, bias)\n\n        else:\n            x = tf.layers.conv2d(inputs=x, filters=channels,\n                                 kernel_size=kernel, kernel_initializer=weight_init,\n                                 kernel_regularizer=weight_regularizer,\n                                 strides=stride, use_bias=use_bias)\n\n        return x\n\n\ndef partial_conv(x, channels, kernel=3, stride=2, use_bias=True, padding=\'SAME\', sn=False, scope=\'conv_0\'):\n    with tf.variable_scope(scope):\n        if padding.lower() == \'SAME\'.lower():\n            with tf.variable_scope(\'mask\'):\n                _, h, w, _ = x.get_shape().as_list()\n\n                slide_window = kernel * kernel\n                mask = tf.ones(shape=[1, h, w, 1])\n\n                update_mask = tf.layers.conv2d(mask, filters=1,\n                                               kernel_size=kernel, kernel_initializer=tf.constant_initializer(1.0),\n                                               strides=stride, padding=padding, use_bias=False, trainable=False)\n\n                mask_ratio = slide_window / (update_mask + 1e-8)\n                update_mask = tf.clip_by_value(update_mask, 0.0, 1.0)\n                mask_ratio = mask_ratio * update_mask\n\n            with tf.variable_scope(\'x\'):\n                if sn:\n                    w = tf.get_variable(""kernel"", shape=[kernel, kernel, x.get_shape()[-1], channels],\n                                        initializer=weight_init, regularizer=weight_regularizer)\n                    x = tf.nn.conv2d(input=x, filter=spectral_norm(w), strides=[1, stride, stride, 1], padding=padding)\n                else:\n                    x = tf.layers.conv2d(x, filters=channels,\n                                         kernel_size=kernel, kernel_initializer=weight_init,\n                                         kernel_regularizer=weight_regularizer,\n                                         strides=stride, padding=padding, use_bias=False)\n                x = x * mask_ratio\n\n                if use_bias:\n                    bias = tf.get_variable(""bias"", [channels], initializer=tf.constant_initializer(0.0))\n\n                    x = tf.nn.bias_add(x, bias)\n                    x = x * update_mask\n        else:\n            if sn:\n                w = tf.get_variable(""kernel"", shape=[kernel, kernel, x.get_shape()[-1], channels],\n                                    initializer=weight_init, regularizer=weight_regularizer)\n                x = tf.nn.conv2d(input=x, filter=spectral_norm(w), strides=[1, stride, stride, 1], padding=padding)\n                if use_bias:\n                    bias = tf.get_variable(""bias"", [channels], initializer=tf.constant_initializer(0.0))\n\n                    x = tf.nn.bias_add(x, bias)\n            else:\n                x = tf.layers.conv2d(x, filters=channels,\n                                     kernel_size=kernel, kernel_initializer=weight_init,\n                                     kernel_regularizer=weight_regularizer,\n                                     strides=stride, padding=padding, use_bias=use_bias)\n\n        return x\n\n\ndef dilate_conv(x, channels, kernel=3, rate=2, use_bias=True, padding=\'SAME\', sn=False, scope=\'conv_0\'):\n    with tf.variable_scope(scope):\n        w = tf.get_variable(""kernel"", shape=[kernel, kernel, x.get_shape()[-1], channels], initializer=weight_init,\n                            regularizer=weight_regularizer)\n        if sn:\n            x = tf.nn.atrous_conv2d(x, spectral_norm(w), rate=rate, padding=padding)\n        else:\n            x = tf.nn.atrous_conv2d(x, w, rate=rate, padding=padding)\n\n        if use_bias:\n            bias = tf.get_variable(""bias"", [channels], initializer=tf.constant_initializer(0.0))\n            x = tf.nn.bias_add(x, bias)\n\n        return x\n\n\ndef deconv(x, channels, kernel=4, stride=2, padding=\'SAME\', use_bias=True, sn=False, scope=\'deconv_0\'):\n    with tf.variable_scope(scope):\n        x_shape = x.get_shape().as_list()\n\n        if padding == \'SAME\':\n            output_shape = [x_shape[0], x_shape[1] * stride, x_shape[2] * stride, channels]\n\n        else:\n            output_shape = [x_shape[0], x_shape[1] * stride + max(kernel - stride, 0),\n                            x_shape[2] * stride + max(kernel - stride, 0), channels]\n\n        if sn:\n            w = tf.get_variable(""kernel"", shape=[kernel, kernel, channels, x.get_shape()[-1]], initializer=weight_init,\n                                regularizer=weight_regularizer)\n            x = tf.nn.conv2d_transpose(x, filter=spectral_norm(w), output_shape=output_shape,\n                                       strides=[1, stride, stride, 1], padding=padding)\n\n            if use_bias:\n                bias = tf.get_variable(""bias"", [channels], initializer=tf.constant_initializer(0.0))\n                x = tf.nn.bias_add(x, bias)\n\n        else:\n            x = tf.layers.conv2d_transpose(inputs=x, filters=channels,\n                                           kernel_size=kernel, kernel_initializer=weight_init,\n                                           kernel_regularizer=weight_regularizer,\n                                           strides=stride, padding=padding, use_bias=use_bias)\n\n        return x\n\n\ndef conv_pixel_shuffle_up(x, scale_factor=2, use_bias=True, sn=False, scope=\'pixel_shuffle\'):\n    channel = x.get_shape()[-1] * (scale_factor ** 2)\n    x = conv(x, channel, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=scope)\n    x = tf.depth_to_space(x, block_size=scale_factor)\n\n    return x\n\n\ndef conv_pixel_shuffle_down(x, scale_factor=2, use_bias=True, sn=False, scope=\'pixel_shuffle\'):\n    channel = x.get_shape()[-1] // (scale_factor ** 2)\n    x = conv(x, channel, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=scope)\n    x = tf.space_to_depth(x, block_size=scale_factor)\n\n    return x\n\n\ndef fully_connected(x, units, use_bias=True, sn=False, scope=\'linear\'):\n    with tf.variable_scope(scope):\n        x = flatten(x)\n        shape = x.get_shape().as_list()\n        channels = shape[-1]\n\n        if sn:\n            w = tf.get_variable(""kernel"", [channels, units], tf.float32,\n                                initializer=weight_init, regularizer=weight_regularizer_fully)\n            if use_bias:\n                bias = tf.get_variable(""bias"", [units],\n                                       initializer=tf.constant_initializer(0.0))\n\n                x = tf.matmul(x, spectral_norm(w)) + bias\n            else:\n                x = tf.matmul(x, spectral_norm(w))\n\n        else:\n            x = tf.layers.dense(x, units=units, kernel_initializer=weight_init,\n                                kernel_regularizer=weight_regularizer_fully,\n                                use_bias=use_bias)\n\n        return x\n\n\n##################################################################################\n# Blocks\n##################################################################################\n\ndef resblock(x_init, channels, use_bias=True, is_training=True, sn=False, scope=\'resblock\'):\n    with tf.variable_scope(scope):\n        with tf.variable_scope(\'res1\'):\n            x = conv(x_init, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn)\n            x = batch_norm(x, is_training)\n            x = relu(x)\n\n        with tf.variable_scope(\'res2\'):\n            x = conv(x, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn)\n            x = batch_norm(x, is_training)\n\n        if channels != x_init.shape[-1]:\n            with tf.variable_scope(\'skip\'):\n                x_init = conv(x_init, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn)\n                return relu(x + x_init)\n\n        return x + x_init\n\n\ndef resblock_up(x_init, channels, use_bias=True, is_training=True, sn=False, scope=\'resblock_up\'):\n    with tf.variable_scope(scope):\n        with tf.variable_scope(\'res1\'):\n            x = deconv(x_init, channels, kernel=3, stride=2, use_bias=use_bias, sn=sn)\n            x = batch_norm(x, is_training)\n            x = relu(x)\n\n        with tf.variable_scope(\'res2\'):\n            x = deconv(x, channels, kernel=3, stride=1, use_bias=use_bias, sn=sn)\n            x = batch_norm(x, is_training)\n\n        with tf.variable_scope(\'skip\'):\n            x_init = deconv(x_init, channels, kernel=3, stride=2, use_bias=use_bias, sn=sn)\n\n    return relu(x + x_init)\n\n\ndef resblock_up_condition(x_init, z, channels, use_bias=True, is_training=True, sn=False, scope=\'resblock_up\'):\n    # See https://github.com/taki0112/BigGAN-Tensorflow\n    with tf.variable_scope(scope):\n        with tf.variable_scope(\'res1\'):\n            x = deconv(x_init, channels, kernel=3, stride=2, use_bias=use_bias, sn=sn)\n            x = condition_batch_norm(x, z, is_training)\n            x = relu(x)\n\n        with tf.variable_scope(\'res2\'):\n            x = deconv(x, channels, kernel=3, stride=1, use_bias=use_bias, sn=sn)\n            x = condition_batch_norm(x, z, is_training)\n\n        with tf.variable_scope(\'skip\'):\n            x_init = deconv(x_init, channels, kernel=3, stride=2, use_bias=use_bias, sn=sn)\n\n    return relu(x + x_init)\n\n\ndef resblock_down(x_init, channels, use_bias=True, is_training=True, sn=False, scope=\'resblock_down\'):\n    with tf.variable_scope(scope):\n        with tf.variable_scope(\'res1\'):\n            x = conv(x_init, channels, kernel=3, stride=2, pad=1, use_bias=use_bias, sn=sn)\n            x = batch_norm(x, is_training)\n            x = relu(x)\n\n        with tf.variable_scope(\'res2\'):\n            x = conv(x, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn)\n            x = batch_norm(x, is_training)\n\n        with tf.variable_scope(\'skip\'):\n            x_init = conv(x_init, channels, kernel=3, stride=2, pad=1, use_bias=use_bias, sn=sn)\n\n    return relu(x + x_init)\n\n\ndef denseblock(x_init, channels, n_db=6, use_bias=True, is_training=True, sn=False, scope=\'denseblock\'):\n    with tf.variable_scope(scope):\n        layers = []\n        layers.append(x_init)\n\n        with tf.variable_scope(\'bottle_neck_0\'):\n            x = conv(x_init, 4 * channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv_0\')\n            x = batch_norm(x, is_training, scope=\'batch_norm_0\')\n            x = relu(x)\n\n            x = conv(x, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn, scope=\'conv_1\')\n            x = batch_norm(x, is_training, scope=\'batch_norm_1\')\n            x = relu(x)\n\n            layers.append(x)\n\n        for i in range(1, n_db):\n            with tf.variable_scope(\'bottle_neck_\' + str(i)):\n                x = tf.concat(layers, axis=-1)\n\n                x = conv(x, 4 * channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv_0\')\n                x = batch_norm(x, is_training, scope=\'batch_norm_0\')\n                x = relu(x)\n\n                x = conv(x, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn, scope=\'conv_1\')\n                x = batch_norm(x, is_training, scope=\'batch_norm_1\')\n                x = relu(x)\n\n                layers.append(x)\n\n        x = tf.concat(layers, axis=-1)\n\n        return x\n\n\ndef res_denseblock(x_init, channels, n_rdb=20, n_rdb_conv=6, use_bias=True, is_training=True, sn=False,\n                   scope=\'res_denseblock\'):\n    with tf.variable_scope(scope):\n        RDBs = []\n        x_input = x_init\n\n        """"""\n        n_rdb = 20 ( RDB number )\n        n_rdb_conv = 6 ( per RDB conv layer )\n        """"""\n\n        for k in range(n_rdb):\n            with tf.variable_scope(\'RDB_\' + str(k)):\n                layers = []\n                layers.append(x_init)\n\n                x = conv(x_init, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn, scope=\'conv_0\')\n                x = batch_norm(x, is_training, scope=\'batch_norm_0\')\n                x = relu(x)\n\n                layers.append(x)\n\n                for i in range(1, n_rdb_conv):\n                    x = tf.concat(layers, axis=-1)\n\n                    x = conv(x, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn, scope=\'conv_\' + str(i))\n                    x = batch_norm(x, is_training, scope=\'batch_norm_\' + str(i))\n                    x = relu(x)\n\n                    layers.append(x)\n\n                # Local feature fusion\n                x = tf.concat(layers, axis=-1)\n                x = conv(x, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv_last\')\n\n                # Local residual learning\n                if channels != x_init.shape[-1] :\n                    x_init = conv(x_init, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'local_skip_conv\')\n                    x = relu(x + x_init)\n                else :\n                    x = x_init + x\n\n                RDBs.append(x)\n                x_init = x\n\n        with tf.variable_scope(\'GFF_1x1\'):\n            x = tf.concat(RDBs, axis=-1)\n            x = conv(x, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv\')\n\n        with tf.variable_scope(\'GFF_3x3\'):\n            x = conv(x, channels, kernel=3, stride=1, pad=1, use_bias=use_bias, sn=sn, scope=\'conv\')\n\n        # Global residual learning\n        if channels != x_input.shape[-1]:\n            x_input = conv(x_input, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'global_skip_conv\')\n            x = relu(x + x_input)\n        else :\n            x = x_input + x\n\n        return x\n\n\ndef self_attention(x, use_bias=True, sn=False, scope=\'self_attention\'):\n    with tf.variable_scope(scope):\n        channels = x.shape[-1]\n        f = conv(x, channels // 8, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'f_conv\')  # [bs, h, w, c\']\n        g = conv(x, channels // 8, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'g_conv\')  # [bs, h, w, c\']\n        h = conv(x, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'h_conv\')  # [bs, h, w, c]\n\n        # N = h * w\n        s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True)  # # [bs, N, N]\n\n        beta = tf.nn.softmax(s)  # attention map\n\n        o = tf.matmul(beta, hw_flatten(h))  # [bs, N, C]\n        gamma = tf.get_variable(""gamma"", [1], initializer=tf.constant_initializer(0.0))\n\n        o = tf.reshape(o, shape=x.shape)  # [bs, h, w, C]\n        x = gamma * o + x\n\n    return x\n\n\ndef self_attention_with_pooling(x, use_bias=True, sn=False, scope=\'self_attention\'):\n    with tf.variable_scope(scope):\n        channels = x.shape[-1]\n        f = conv(x, channels // 8, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'f_conv\')  # [bs, h, w, c\']\n        f = max_pooling(f)\n\n        g = conv(x, channels // 8, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'g_conv\')  # [bs, h, w, c\']\n\n        h = conv(x, channels // 2, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'h_conv\')  # [bs, h, w, c]\n        h = max_pooling(h)\n\n        # N = h * w\n        s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True)  # # [bs, N, N]\n\n        beta = tf.nn.softmax(s)  # attention map\n\n        o = tf.matmul(beta, hw_flatten(h))  # [bs, N, C]\n        gamma = tf.get_variable(""gamma"", [1], initializer=tf.constant_initializer(0.0))\n\n        o = tf.reshape(o, shape=[x.shape[0], x.shape[1], x.shape[2], channels // 2])  # [bs, h, w, C]\n        o = conv(o, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'attn_conv\')\n        x = gamma * o + x\n\n    return x\n\n\ndef squeeze_excitation(x, ratio=16, use_bias=True, sn=False, scope=\'senet\'):\n    with tf.variable_scope(scope):\n        channels = x.shape[-1]\n        squeeze = global_avg_pooling(x)\n\n        excitation = fully_connected(squeeze, units=channels // ratio, use_bias=use_bias, sn=sn, scope=\'fc1\')\n        excitation = relu(excitation)\n        excitation = fully_connected(excitation, units=channels, use_bias=use_bias, sn=sn, scope=\'fc2\')\n        excitation = sigmoid(excitation)\n\n        excitation = tf.reshape(excitation, [-1, 1, 1, channels])\n\n        scale = x * excitation\n\n        return scale\n\n\ndef convolution_block_attention(x, ratio=16, use_bias=True, sn=False, scope=\'cbam\'):\n    with tf.variable_scope(scope):\n        channels = x.shape[-1]\n        with tf.variable_scope(\'channel_attention\'):\n            x_gap = global_avg_pooling(x)\n            x_gap = fully_connected(x_gap, units=channels // ratio, use_bias=use_bias, sn=sn, scope=\'fc1\')\n            x_gap = relu(x_gap)\n            x_gap = fully_connected(x_gap, units=channels, use_bias=use_bias, sn=sn, scope=\'fc2\')\n\n        with tf.variable_scope(\'channel_attention\', reuse=True):\n            x_gmp = global_max_pooling(x)\n            x_gmp = fully_connected(x_gmp, units=channels // ratio, use_bias=use_bias, sn=sn, scope=\'fc1\')\n            x_gmp = relu(x_gmp)\n            x_gmp = fully_connected(x_gmp, units=channels, use_bias=use_bias, sn=sn, scope=\'fc2\')\n\n            scale = tf.reshape(x_gap + x_gmp, [-1, 1, 1, channels])\n            scale = sigmoid(scale)\n\n            x = x * scale\n\n        with tf.variable_scope(\'spatial_attention\'):\n            x_channel_avg_pooling = tf.reduce_mean(x, axis=-1, keepdims=True)\n            x_channel_max_pooling = tf.reduce_max(x, axis=-1, keepdims=True)\n            scale = tf.concat([x_channel_avg_pooling, x_channel_max_pooling], axis=-1)\n\n            scale = conv(scale, channels=1, kernel=7, stride=1, pad=3, pad_type=\'reflect\', use_bias=False, sn=sn, scope=\'conv\')\n            scale = sigmoid(scale)\n\n            x = x * scale\n\n            return x\n\n\ndef global_context_block(x, use_bias=True, sn=False, scope=\'gc_block\'):\n    with tf.variable_scope(scope):\n        channels = x.shape[-1]\n        with tf.variable_scope(\'context_modeling\'):\n            bs, h, w, c = x.get_shape().as_list()\n            input_x = x\n            input_x = hw_flatten(input_x)  # [N, H*W, C]\n            input_x = tf.transpose(input_x, perm=[0, 2, 1])\n            input_x = tf.expand_dims(input_x, axis=1)\n\n            context_mask = conv(x, channels=1, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv\')\n            context_mask = hw_flatten(context_mask)\n            context_mask = tf.nn.softmax(context_mask, axis=1)  # [N, H*W, 1]\n            context_mask = tf.transpose(context_mask, perm=[0, 2, 1])\n            context_mask = tf.expand_dims(context_mask, axis=-1)\n\n            context = tf.matmul(input_x, context_mask)\n            context = tf.reshape(context, shape=[bs, 1, 1, c])\n\n        with tf.variable_scope(\'transform_0\'):\n            context_transform = conv(context, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv_0\')\n            context_transform = layer_norm(context_transform)\n            context_transform = relu(context_transform)\n            context_transform = conv(context_transform, channels=c, kernel=1, stride=1, use_bias=use_bias, sn=sn,\n                                     scope=\'conv_1\')\n            context_transform = sigmoid(context_transform)\n\n            x = x * context_transform\n\n        with tf.variable_scope(\'transform_1\'):\n            context_transform = conv(context, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\'conv_0\')\n            context_transform = layer_norm(context_transform)\n            context_transform = relu(context_transform)\n            context_transform = conv(context_transform, channels=c, kernel=1, stride=1, use_bias=use_bias, sn=sn,\n                                     scope=\'conv_1\')\n\n            x = x + context_transform\n\n        return x\n\n\ndef srm_block(x, use_bias=False, is_training=True, scope=\'srm_block\'):\n    with tf.variable_scope(scope):\n        bs, h, w, channels = x.get_shape().as_list()  # c = channels\n\n        x = tf.reshape(x, shape=[bs, -1, channels])  # [bs, h*w, c]\n\n        x_mean, x_var = tf.nn.moments(x, axes=1, keep_dims=True)  # [bs, 1, c]\n        x_std = tf.sqrt(x_var + 1e-5)\n\n        t = tf.concat([x_mean, x_std], axis=1)  # [bs, 2, c]\n\n        z = tf.layers.conv1d(t, channels, kernel_size=2, strides=1, use_bias=use_bias)\n        z = batch_norm(z, is_training=is_training)\n\n        g = tf.sigmoid(z)\n\n        x = tf.reshape(x * g, shape=[bs, h, w, channels])\n\n        return x\n\n\n##################################################################################\n# Normalization\n##################################################################################\n\ndef batch_norm(x, is_training=False, scope=\'batch_norm\'):\n    """"""\n    if x_norm = tf.layers.batch_normalization\n\n    # ...\n\n    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n        train_op = optimizer.minimize(loss)\n    """"""\n\n    return tf.contrib.layers.batch_norm(x,\n                                        decay=0.9, epsilon=1e-05,\n                                        center=True, scale=True, updates_collections=None,\n                                        is_training=is_training, scope=scope)\n\n    # return tf.layers.batch_normalization(x, momentum=0.9, epsilon=1e-05, center=True, scale=True, training=is_training, name=scope)\n\n\ndef instance_norm(x, scope=\'instance_norm\'):\n    return tf.contrib.layers.instance_norm(x,\n                                           epsilon=1e-05,\n                                           center=True, scale=True,\n                                           scope=scope)\n\n\ndef layer_norm(x, scope=\'layer_norm\'):\n    return tf.contrib.layers.layer_norm(x,\n                                        center=True, scale=True,\n                                        scope=scope)\n\n\ndef group_norm(x, groups=32, scope=\'group_norm\'):\n    return tf.contrib.layers.group_norm(x, groups=groups, epsilon=1e-05,\n                                        center=True, scale=True,\n                                        scope=scope)\n\n\ndef adaptive_instance_norm(content, gamma, beta, epsilon=1e-5):\n    # gamma, beta = style_mean, style_std from MLP\n    # See https://github.com/taki0112/MUNIT-Tensorflow\n\n    c_mean, c_var = tf.nn.moments(content, axes=[1, 2], keep_dims=True)\n    c_std = tf.sqrt(c_var + epsilon)\n\n    return gamma * ((content - c_mean) / c_std) + beta\n\ndef adaptive_layer_instance_norm(x, gamma, beta, smoothing=True, scope=\'ada_layer_instance_norm\') :\n    # proposed by UGATIT\n    # https://github.com/taki0112/UGATIT\n    with tf.variable_scope(scope):\n        ch = x.shape[-1]\n        eps = 1e-5\n\n        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keep_dims=True)\n        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + eps))\n\n        ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3], keep_dims=True)\n        x_ln = (x - ln_mean) / (tf.sqrt(ln_sigma + eps))\n\n        rho = tf.get_variable(""rho"", [ch], initializer=tf.constant_initializer(1.0), constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n\n        if smoothing :\n            rho = tf.clip_by_value(rho - tf.constant(0.1), 0.0, 1.0)\n\n        x_hat = rho * x_ins + (1 - rho) * x_ln\n\n\n        x_hat = x_hat * gamma + beta\n\n        return x_hat\n\n\ndef condition_batch_norm(x, z, is_training=True, scope=\'batch_norm\'):\n    # See https://github.com/taki0112/BigGAN-Tensorflow\n    with tf.variable_scope(scope):\n        _, _, _, c = x.get_shape().as_list()\n        decay = 0.9\n        epsilon = 1e-05\n\n        test_mean = tf.get_variable(""pop_mean"", shape=[c], dtype=tf.float32,\n                                    initializer=tf.constant_initializer(0.0), trainable=False)\n        test_var = tf.get_variable(""pop_var"", shape=[c], dtype=tf.float32, initializer=tf.constant_initializer(1.0),\n                                   trainable=False)\n\n        beta = fully_connected(z, units=c, scope=\'beta\')\n        gamma = fully_connected(z, units=c, scope=\'gamma\')\n\n        beta = tf.reshape(beta, shape=[-1, 1, 1, c])\n        gamma = tf.reshape(gamma, shape=[-1, 1, 1, c])\n\n        if is_training:\n            batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2])\n            ema_mean = tf.assign(test_mean, test_mean * decay + batch_mean * (1 - decay))\n            ema_var = tf.assign(test_var, test_var * decay + batch_var * (1 - decay))\n\n            with tf.control_dependencies([ema_mean, ema_var]):\n                return tf.nn.batch_normalization(x, batch_mean, batch_var, beta, gamma, epsilon)\n        else:\n            return tf.nn.batch_normalization(x, test_mean, test_var, beta, gamma, epsilon)\n\n\ndef batch_instance_norm(x, scope=\'batch_instance_norm\'):\n    with tf.variable_scope(scope):\n        ch = x.shape[-1]\n        eps = 1e-5\n\n        batch_mean, batch_sigma = tf.nn.moments(x, axes=[0, 1, 2], keep_dims=True)\n        x_batch = (x - batch_mean) / (tf.sqrt(batch_sigma + eps))\n\n        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keep_dims=True)\n        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + eps))\n\n        rho = tf.get_variable(""rho"", [ch], initializer=tf.constant_initializer(1.0), constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n        gamma = tf.get_variable(""gamma"", [ch], initializer=tf.constant_initializer(1.0))\n        beta = tf.get_variable(""beta"", [ch], initializer=tf.constant_initializer(0.0))\n\n        x_hat = rho * x_batch + (1 - rho) * x_ins\n        x_hat = x_hat * gamma + beta\n\n        return x_hat\n\ndef layer_instance_norm(x, scope=\'layer_instance_norm\') :\n    # proposed by UGATIT\n    # https://github.com/taki0112/UGATIT\n    with tf.variable_scope(scope):\n        ch = x.shape[-1]\n        eps = 1e-5\n\n        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keep_dims=True)\n        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + eps))\n\n        ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3], keep_dims=True)\n        x_ln = (x - ln_mean) / (tf.sqrt(ln_sigma + eps))\n\n        rho = tf.get_variable(""rho"", [ch], initializer=tf.constant_initializer(0.0), constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n\n        gamma = tf.get_variable(""gamma"", [ch], initializer=tf.constant_initializer(1.0))\n        beta = tf.get_variable(""beta"", [ch], initializer=tf.constant_initializer(0.0))\n\n        x_hat = rho * x_ins + (1 - rho) * x_ln\n\n        x_hat = x_hat * gamma + beta\n\n        return x_hat\n\ndef pixel_norm(x, epsilon=1e-8):\n    return x * tf.rsqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + epsilon)\n\ndef switch_norm(x, scope=\'switch_norm\'):\n    with tf.variable_scope(scope):\n        ch = x.shape[-1]\n        eps = 1e-5\n\n        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], keep_dims=True)\n        ins_mean, ins_var = tf.nn.moments(x, [1, 2], keep_dims=True)\n        layer_mean, layer_var = tf.nn.moments(x, [1, 2, 3], keep_dims=True)\n\n        gamma = tf.get_variable(""gamma"", [ch], initializer=tf.constant_initializer(1.0))\n        beta = tf.get_variable(""beta"", [ch], initializer=tf.constant_initializer(0.0))\n\n        mean_weight = tf.nn.softmax(tf.get_variable(""mean_weight"", [3], initializer=tf.constant_initializer(1.0)))\n        var_wegiht = tf.nn.softmax(tf.get_variable(""var_weight"", [3], initializer=tf.constant_initializer(1.0)))\n\n        mean = mean_weight[0] * batch_mean + mean_weight[1] * ins_mean + mean_weight[2] * layer_mean\n        var = var_wegiht[0] * batch_var + var_wegiht[1] * ins_var + var_wegiht[2] * layer_var\n\n        x = (x - mean) / (tf.sqrt(var + eps))\n        x = x * gamma + beta\n\n        return x\n\ndef spectral_norm(w, iteration=1):\n    w_shape = w.shape.as_list()\n    w = tf.reshape(w, [-1, w_shape[-1]])\n\n    u = tf.get_variable(""u"", [1, w_shape[-1]], initializer=tf.random_normal_initializer(), trainable=False)\n\n    u_hat = u\n    v_hat = None\n    for i in range(iteration):\n        """"""\n        power iteration\n        Usually iteration = 1 will be enough\n        """"""\n        v_ = tf.matmul(u_hat, tf.transpose(w))\n        v_hat = tf.nn.l2_normalize(v_)\n\n        u_ = tf.matmul(v_hat, w)\n        u_hat = tf.nn.l2_normalize(u_)\n\n    u_hat = tf.stop_gradient(u_hat)\n    v_hat = tf.stop_gradient(v_hat)\n\n    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n\n    with tf.control_dependencies([u.assign(u_hat)]):\n        w_norm = w / sigma\n        w_norm = tf.reshape(w_norm, w_shape)\n\n    return w_norm\n\n##################################################################################\n# Activation Function\n##################################################################################\n\ndef lrelu(x, alpha=0.01):\n    # pytorch alpha is 0.01\n    return tf.nn.leaky_relu(x, alpha)\n\n\ndef relu(x):\n    return tf.nn.relu(x)\n\n\ndef tanh(x):\n    return tf.tanh(x)\n\n\ndef sigmoid(x):\n    return tf.sigmoid(x)\n\n\ndef swish(x):\n    return x * tf.sigmoid(x)\n\n\ndef elu(x):\n    return tf.nn.elu(x)\n\n\n##################################################################################\n# Pooling & Resize\n##################################################################################\n\ndef nearest_up_sample(x, scale_factor=2):\n    _, h, w, _ = x.get_shape().as_list()\n    new_size = [h * scale_factor, w * scale_factor]\n    return tf.image.resize_nearest_neighbor(x, size=new_size)\n\ndef bilinear_up_sample(x, scale_factor=2):\n    _, h, w, _ = x.get_shape().as_list()\n    new_size = [h * scale_factor, w * scale_factor]\n    return tf.image.resize_bilinear(x, size=new_size)\n\ndef nearest_down_sample(x, scale_factor=2):\n    _, h, w, _ = x.get_shape().as_list()\n    new_size = [h // scale_factor, w // scale_factor]\n    return tf.image.resize_nearest_neighbor(x, size=new_size)\n\ndef bilinear_down_sample(x, scale_factor=2):\n    _, h, w, _ = x.get_shape().as_list()\n    new_size = [h // scale_factor, w // scale_factor]\n    return tf.image.resize_bilinear(x, size=new_size)\n\ndef global_avg_pooling(x):\n    gap = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n    return gap\n\n\ndef global_max_pooling(x):\n    gmp = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n    return gmp\n\n\ndef max_pooling(x, pool_size=2):\n    x = tf.layers.max_pooling2d(x, pool_size=pool_size, strides=pool_size, padding=\'SAME\')\n    return x\n\n\ndef avg_pooling(x, pool_size=2):\n    x = tf.layers.average_pooling2d(x, pool_size=pool_size, strides=pool_size, padding=\'SAME\')\n    return x\n\n\ndef flatten(x):\n    return tf.layers.flatten(x)\n\n\ndef hw_flatten(x):\n    return tf.reshape(x, shape=[x.shape[0], -1, x.shape[-1]])\n\n\n##################################################################################\n# Loss Function\n##################################################################################\n\ndef classification_loss(logit, label):\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logit))\n    prediction = tf.equal(tf.argmax(logit, -1), tf.argmax(label, -1))\n    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n\n    return loss, accuracy\n\n\ndef L1_loss(x, y):\n    loss = tf.reduce_mean(tf.abs(x - y))\n\n    return loss\n\n\ndef L2_loss(x, y):\n    loss = tf.reduce_mean(tf.square(x - y))\n\n    return loss\n\n\ndef huber_loss(x, y):\n    return tf.losses.huber_loss(x, y)\n\n\ndef regularization_loss(scope_name):\n    """"""\n    If you want to use ""Regularization""\n    g_loss += regularization_loss(\'generator\')\n    d_loss += regularization_loss(\'discriminator\')\n    """"""\n    collection_regularization = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n\n    loss = []\n    for item in collection_regularization:\n        if scope_name in item.name:\n            loss.append(item)\n\n    return tf.reduce_sum(loss)\n\n\ndef histogram_loss(x, y):\n    histogram_x = get_histogram(x)\n    histogram_y = get_histogram(y)\n\n    hist_loss = L1_loss(histogram_x, histogram_y)\n\n    return hist_loss\n\n\ndef get_histogram(img, bin_size=0.2):\n    hist_entries = []\n\n    img_r, img_g, img_b = tf.split(img, num_or_size_splits=3, axis=-1)\n\n    for img_chan in [img_r, img_g, img_b]:\n        for i in np.arange(-1, 1, bin_size):\n            gt = tf.greater(img_chan, i)\n            leq = tf.less_equal(img_chan, i + bin_size)\n\n            condition = tf.cast(tf.logical_and(gt, leq), tf.float32)\n            hist_entries.append(tf.reduce_sum(condition))\n\n    hist = normalization(hist_entries)\n\n    return hist\n\n\ndef normalization(x):\n    x = (x - tf.reduce_min(x)) / (tf.reduce_max(x) - tf.reduce_min(x))\n    return x\n\n\ndef gram_matrix(x):\n    b, h, w, c = x.get_shape().as_list()\n\n    x = tf.reshape(x, shape=[b, -1, c])\n\n    x = tf.matmul(tf.transpose(x, perm=[0, 2, 1]), x)\n    x = x / (h * w * c)\n\n    return x\n\n\ndef gram_style_loss(x, y):\n    _, height, width, channels = x.get_shape().as_list()\n\n    x = gram_matrix(x)\n    y = gram_matrix(y)\n\n    loss = L2_loss(x, y)  # simple version\n\n    # Original eqn as a constant to divide i.e 1/(4. * (channels ** 2) * (width * height) ** 2)\n    # loss = tf.reduce_mean(tf.square(x - y)) / (channels ** 2 * width * height)  # (4.0 * (channels ** 2) * (width * height) ** 2)\n\n    return loss\n\n\ndef color_consistency_loss(x, y):\n    x_mu, x_var = tf.nn.moments(x, axes=[1, 2], keep_dims=True)\n    y_mu, y_var = tf.nn.moments(y, axes=[1, 2], keep_dims=True)\n\n    loss = L2_loss(x_mu, y_mu) + 5.0 * L2_loss(x_var, y_var)\n\n    return loss\n\n\ndef dice_loss(n_classes, logits, labels):\n    """"""\n    :param n_classes: number of classes\n    :param logits: [batch_size, m, n, n_classes] float32, output logits\n    :param labels: [batch_size, m, n, 1] int32, class label\n    :return:\n    """"""\n\n    # https://github.com/keras-team/keras/issues/9395\n\n    smooth = 1e-7\n    dtype = tf.float32\n\n    # alpha=beta=0.5 : dice coefficient\n    # alpha=beta=1   : tanimoto coefficient (also known as jaccard)\n    # alpha+beta=1   : produces set of F*-scores\n    alpha, beta = 0.5, 0.5\n\n    # make onehot label [batch_size, m, n, n_classes]\n    # tf.one_hot() will ignore (creates zero vector) labels larger than n_class and less then 0\n    onehot_labels = tf.one_hot(tf.squeeze(labels, axis=-1), depth=n_classes, dtype=dtype)\n\n    ones = tf.ones_like(onehot_labels, dtype=dtype)\n    predicted = tf.nn.softmax(logits)\n    p0 = predicted\n    p1 = ones - predicted\n    g0 = onehot_labels\n    g1 = ones - onehot_labels\n\n    num = tf.reduce_sum(p0 * g0, axis=[0, 1, 2])\n    den = num + alpha * tf.reduce_sum(p0 * g1, axis=[0, 1, 2]) + beta * tf.reduce_sum(p1 * g0, axis=[0, 1, 2])\n\n    loss = tf.cast(n_classes, dtype=dtype) - tf.reduce_sum((num + smooth) / (den + smooth))\n    return loss\n\n\n##################################################################################\n# GAN Loss Function\n##################################################################################\n\ndef discriminator_loss(Ra, gan_type, real, fake):\n    # Ra = Relativistic\n    real_loss = 0\n    fake_loss = 0\n\n    if Ra and (gan_type.__contains__(\'wgan\') or gan_type == \'sphere\'):\n        print(""No exist [Ra + WGAN or Ra + Sphere], so use the {} loss function"".format(gan_type))\n        Ra = False\n\n    if Ra:\n        real_logit = (real - tf.reduce_mean(fake))\n        fake_logit = (fake - tf.reduce_mean(real))\n\n        if gan_type == \'lsgan\':\n            real_loss = tf.reduce_mean(tf.square(real_logit - 1.0))\n            fake_loss = tf.reduce_mean(tf.square(fake_logit + 1.0))\n\n        if gan_type == \'gan\' or gan_type == \'gan-gp\' or gan_type == \'dragan\':\n            real_loss = tf.reduce_mean(\n                tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(real), logits=real_logit))\n            fake_loss = tf.reduce_mean(\n                tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(fake), logits=fake_logit))\n\n        if gan_type == \'hinge\':\n            real_loss = tf.reduce_mean(relu(1.0 - real_logit))\n            fake_loss = tf.reduce_mean(relu(1.0 + fake_logit))\n\n    else:\n        if gan_type.__contains__(\'wgan\'):\n            real_loss = -tf.reduce_mean(real)\n            fake_loss = tf.reduce_mean(fake)\n\n        if gan_type == \'lsgan\':\n            real_loss = tf.reduce_mean(tf.square(real - 1.0))\n            fake_loss = tf.reduce_mean(tf.square(fake))\n\n        if gan_type == \'gan\' or gan_type == \'gan-gp\' or gan_type == \'dragan\':\n            real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(real), logits=real))\n            fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(fake), logits=fake))\n\n        if gan_type == \'hinge\':\n            real_loss = tf.reduce_mean(relu(1.0 - real))\n            fake_loss = tf.reduce_mean(relu(1.0 + fake))\n\n        if gan_type == \'sphere\':\n            bs, c = real.get_shape().as_list()\n            moment = 3\n            north_pole = tf.one_hot(tf.tile([c], multiples=[bs]), depth=c + 1)  # [bs, c+1] -> [0, 0, 0, ... , 1]\n\n            real_projection = inverse_stereographic_projection(real)\n            fake_projection = inverse_stereographic_projection(fake)\n\n            for i in range(1, moment + 1):\n                real_loss += -tf.reduce_mean(tf.pow(sphere_loss(real_projection, north_pole), i))\n                fake_loss += tf.reduce_mean(tf.pow(sphere_loss(fake_projection, north_pole), i))\n\n\n    loss = real_loss + fake_loss\n\n    return loss\n\n\ndef generator_loss(Ra, gan_type, real, fake):\n    # Ra = Relativistic\n    fake_loss = 0\n    real_loss = 0\n\n    if Ra and (gan_type.__contains__(\'wgan\') or gan_type == \'sphere\'):\n        print(""No exist [Ra + WGAN or Ra + Sphere], so use the {} loss function"".format(gan_type))\n        Ra = False\n\n    if Ra:\n        fake_logit = (fake - tf.reduce_mean(real))\n        real_logit = (real - tf.reduce_mean(fake))\n\n        if gan_type == \'lsgan\':\n            fake_loss = tf.reduce_mean(tf.square(fake_logit - 1.0))\n            real_loss = tf.reduce_mean(tf.square(real_logit + 1.0))\n\n        if gan_type == \'gan\' or gan_type == \'gan-gp\' or gan_type == \'dragan\':\n            fake_loss = tf.reduce_mean(\n                tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(fake), logits=fake_logit))\n            real_loss = tf.reduce_mean(\n                tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(real), logits=real_logit))\n\n        if gan_type == \'hinge\':\n            fake_loss = tf.reduce_mean(relu(1.0 - fake_logit))\n            real_loss = tf.reduce_mean(relu(1.0 + real_logit))\n\n    else:\n        if gan_type.__contains__(\'wgan\'):\n            fake_loss = -tf.reduce_mean(fake)\n\n        if gan_type == \'lsgan\':\n            fake_loss = tf.reduce_mean(tf.square(fake - 1.0))\n\n        if gan_type == \'gan\' or gan_type == \'gan-gp\' or gan_type == \'dragan\':\n            fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(fake), logits=fake))\n\n        if gan_type == \'hinge\':\n            fake_loss = -tf.reduce_mean(fake)\n\n        if gan_type == \'sphere\':\n            bs, c = real.get_shape().as_list()\n            moment = 3\n            north_pole = tf.one_hot(tf.tile([c], multiples=[bs]), depth=c + 1)  # [bs, c+1] -> [0, 0, 0, ... , 1]\n\n            fake_projection = inverse_stereographic_projection(fake)\n\n            for i in range(1, moment + 1):\n                fake_loss += -tf.reduce_mean(tf.pow(sphere_loss(fake_projection, north_pole), i))\n\n    loss = fake_loss + real_loss\n\n    return loss\n\n\ndef vdb_loss(mu, logvar, i_c=0.1):\n    # variational discriminator bottleneck loss\n    kl_divergence = 0.5 * tf.reduce_sum(tf.square(mu) + tf.exp(logvar) - 1 - logvar, axis=-1)\n\n    loss = tf.reduce_mean(kl_divergence - i_c)\n\n    return loss\n\n\ndef simple_gp(real_logit, fake_logit, real_images, fake_images, r1_gamma=10, r2_gamma=0):\n    # Used in StyleGAN\n\n    r1_penalty = 0\n    r2_penalty = 0\n\n    if r1_gamma != 0:\n        real_loss = tf.reduce_sum(real_logit)  # In some cases, you may use reduce_mean\n        real_grads = tf.gradients(real_loss, real_images)[0]\n\n        r1_penalty = 0.5 * r1_gamma * tf.reduce_mean(tf.reduce_sum(tf.square(real_grads), axis=[1, 2, 3]))\n\n    if r2_gamma != 0:\n        fake_loss = tf.reduce_sum(fake_logit)  # In some cases, you may use reduce_mean\n        fake_grads = tf.gradients(fake_loss, fake_images)[0]\n\n        r2_penalty = 0.5 * r2_gamma * tf.reduce_mean(tf.reduce_sum(tf.square(fake_grads), axis=[1, 2, 3]))\n\n    return r1_penalty + r2_penalty\n\ndef inverse_stereographic_projection(x) :\n\n    x_u = tf.transpose(2 * x) / (tf.pow(tf.norm(x, axis=-1), 2) + 1.0)\n    x_v = (tf.pow(tf.norm(x, axis=-1), 2) - 1.0) / (tf.pow(tf.norm(x, axis=-1), 2) + 1.0)\n\n    x_projection = tf.transpose(tf.concat([x_u, [x_v]], axis=0))\n\n    return x_projection\n\ndef sphere_loss(x, y) :\n\n    loss = tf.math.acos(tf.matmul(x, tf.transpose(y)))\n\n    return loss\n\n##################################################################################\n# KL-Divergence Loss Function\n##################################################################################\n\n# typical version\ndef z_sample(mean, logvar):\n    eps = tf.random_normal(tf.shape(mean), mean=0.0, stddev=1.0, dtype=tf.float32)\n\n    return mean + tf.exp(logvar * 0.5) * eps\n\n\ndef kl_loss(mean, logvar):\n    # shape : [batch_size, channel]\n    loss = 0.5 * tf.reduce_sum(tf.square(mean) + tf.exp(logvar) - 1 - logvar, axis=-1)\n    loss = tf.reduce_mean(loss)\n\n    return loss\n\n\n# version 2\ndef z_sample_2(mean, sigma):\n    eps = tf.random_normal(tf.shape(mean), mean=0.0, stddev=1.0, dtype=tf.float32)\n\n    return mean + sigma * eps\n\n\ndef kl_loss_2(mean, sigma):\n    # shape : [batch_size, channel]\n    loss = 0.5 * tf.reduce_sum(tf.square(mean) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1, axis=-1)\n    loss = tf.reduce_mean(loss)\n\n    return loss\n'"
utils.py,60,"b'import tensorflow as tf\nimport numpy as np\nimport random, os\nfrom tensorflow.contrib import slim\nimport cv2\n\nclass ImageData:\n\n    def __init__(self, img_height, img_width, channels, augment_flag):\n        self.img_height = img_height\n        self.img_width = img_width\n        self.channels = channels\n        self.augment_flag = augment_flag\n\n    def image_processing(self, filename):\n        x = tf.read_file(filename)\n        x_decode = tf.image.decode_jpeg(x, channels=self.channels, dct_method=\'INTEGER_ACCURATE\')\n        img = tf.image.resize_images(x_decode, [self.img_height, self.img_width])\n        img = tf.cast(img, tf.float32) / 127.5 - 1\n\n        if self.augment_flag :\n            augment_height = self.img_height + (30 if self.img_height == 256 else int(self.img_height * 0.1))\n            augment_width = self.img_width + (30 if self.img_width == 256 else int(self.img_width * 0.1))\n\n            img = tf.cond(pred=tf.greater_equal(tf.random_uniform(shape=[], minval=0.0, maxval=1.0), 0.5),\n                          true_fn=lambda: augmentation(img, augment_height, augment_width),\n                          false_fn=lambda: img)\n\n        return img\n\ndef load_test_image(image_path, img_width, img_height, img_channel):\n\n    if img_channel == 1 :\n        img = cv2.imread(image_path, flags=cv2.IMREAD_GRAYSCALE)\n    else :\n        img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    img = cv2.resize(img, dsize=(img_width, img_height))\n\n    if img_channel == 1 :\n        img = np.expand_dims(img, axis=0)\n        img = np.expand_dims(img, axis=-1)\n    else :\n        img = np.expand_dims(img, axis=0)\n\n    img = img/127.5 - 1\n\n    return img\n\ndef augmentation(image, augment_height, augment_width):\n    seed = random.randint(0, 2 ** 31 - 1)\n    ori_image_shape = tf.shape(image)\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.resize_images(image, [augment_height, augment_width])\n    image = tf.random_crop(image, ori_image_shape, seed=seed)\n    return image\n\ndef save_images(images, size, image_path):\n    return imsave(inverse_transform(images), size, image_path)\n\ndef inverse_transform(images):\n    return ((images+1.) / 2) * 255.0\n\n\ndef imsave(images, size, path):\n    images = merge(images, size)\n    images = cv2.cvtColor(images.astype(\'uint8\'), cv2.COLOR_RGB2BGR)\n\n    return cv2.imwrite(path, images)\n\ndef merge(images, size):\n    h, w = images.shape[1], images.shape[2]\n    img = np.zeros((h * size[0], w * size[1], 3))\n    for idx, image in enumerate(images):\n        i = idx % size[1]\n        j = idx // size[1]\n        img[h*j:h*(j+1), w*i:w*(i+1), :] = image\n\n    return img\n\ndef orthogonal_regularizer(scale) :\n    """""" Defining the Orthogonal regularizer and return the function at last to be used in Conv layer as kernel regularizer""""""\n\n    def ortho_reg(w) :\n        """""" Reshaping the matrxi in to 2D tensor for enforcing orthogonality""""""\n        _, _, _, c = w.get_shape().as_list()\n\n        w = tf.reshape(w, [-1, c])\n\n        """""" Declaring a Identity Tensor of appropriate size""""""\n        identity = tf.eye(c)\n\n        """""" Regularizer Wt*W - I """"""\n        w_transpose = tf.transpose(w)\n        w_mul = tf.matmul(w_transpose, w)\n        reg = tf.subtract(w_mul, identity)\n\n        """"""Calculating the Loss Obtained""""""\n        ortho_loss = tf.nn.l2_loss(reg)\n\n        return scale * ortho_loss\n\n    return ortho_reg\n\ndef orthogonal_regularizer_fully(scale) :\n    """""" Defining the Orthogonal regularizer and return the function at last to be used in Fully Connected Layer """"""\n\n    def ortho_reg_fully(w) :\n        """""" Reshaping the matrix in to 2D tensor for enforcing orthogonality""""""\n        _, c = w.get_shape().as_list()\n\n        """"""Declaring a Identity Tensor of appropriate size""""""\n        identity = tf.eye(c)\n        w_transpose = tf.transpose(w)\n        w_mul = tf.matmul(w_transpose, w)\n        reg = tf.subtract(w_mul, identity)\n\n        """""" Calculating the Loss """"""\n        ortho_loss = tf.nn.l2_loss(reg)\n\n        return scale * ortho_loss\n\n    return ortho_reg_fully\n\ndef tf_rgb_to_gray(x) :\n    x = (x + 1.0) * 0.5\n    x = tf.image.rgb_to_grayscale(x)\n\n    x = (x * 2) - 1.0\n\n    return x\n\ndef RGB2LAB(srgb):\n    srgb = inverse_transform(srgb)\n\n    lab = rgb_to_lab(srgb)\n    l, a, b = preprocess_lab(lab)\n\n    l = tf.expand_dims(l, axis=-1)\n    a = tf.expand_dims(a, axis=-1)\n    b = tf.expand_dims(b, axis=-1)\n\n    x = tf.concat([l, a, b], axis=-1)\n\n    return x\n\ndef LAB2RGB(lab) :\n    lab = inverse_transform(lab)\n\n    rgb = lab_to_rgb(lab)\n    rgb = tf.clip_by_value(rgb, 0, 1)\n\n    # r, g, b = tf.unstack(rgb, axis=-1)\n    # rgb = tf.concat([r,g,b], axis=-1)\n\n    x = (rgb * 2) - 1.0\n\n    return x\n\ndef rgb_to_lab(srgb):\n    with tf.name_scope(\'rgb_to_lab\'):\n        srgb_pixels = tf.reshape(srgb, [-1, 3])\n        with tf.name_scope(\'srgb_to_xyz\'):\n            linear_mask = tf.cast(srgb_pixels <= 0.04045, dtype=tf.float32)\n            exponential_mask = tf.cast(srgb_pixels > 0.04045, dtype=tf.float32)\n            rgb_pixels = (srgb_pixels / 12.92 * linear_mask) + (((srgb_pixels + 0.055) / 1.055) ** 2.4) * exponential_mask\n            rgb_to_xyz = tf.constant([\n                #    X        Y          Z\n                [0.412453, 0.212671, 0.019334], # R\n                [0.357580, 0.715160, 0.119193], # G\n                [0.180423, 0.072169, 0.950227], # B\n            ])\n            xyz_pixels = tf.matmul(rgb_pixels, rgb_to_xyz)\n\n        with tf.name_scope(\'xyz_to_cielab\'):\n            # convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)\n\n            # normalize for D65 white point\n            xyz_normalized_pixels = tf.multiply(xyz_pixels, [1/0.950456, 1.0, 1/1.088754])\n\n            epsilon = 6/29\n            linear_mask = tf.cast(xyz_normalized_pixels <= (epsilon**3), dtype=tf.float32)\n            exponential_mask = tf.cast(xyz_normalized_pixels > (epsilon**3), dtype=tf.float32)\n            fxfyfz_pixels = (xyz_normalized_pixels / (3 * epsilon**2) + 4/29) * linear_mask + (xyz_normalized_pixels ** (1/3)) * exponential_mask\n\n            # convert to lab\n            fxfyfz_to_lab = tf.constant([\n                #  l       a       b\n                [  0.0,  500.0,    0.0], # fx\n                [116.0, -500.0,  200.0], # fy\n                [  0.0,    0.0, -200.0], # fz\n            ])\n            lab_pixels = tf.matmul(fxfyfz_pixels, fxfyfz_to_lab) + tf.constant([-16.0, 0.0, 0.0])\n\n        return tf.reshape(lab_pixels, tf.shape(srgb))\n\n\ndef lab_to_rgb(lab):\n    with tf.name_scope(\'lab_to_rgb\'):\n        lab_pixels = tf.reshape(lab, [-1, 3])\n        with tf.name_scope(\'cielab_to_xyz\'):\n            # convert to fxfyfz\n            lab_to_fxfyfz = tf.constant([\n                #   fx      fy        fz\n                [1/116.0, 1/116.0,  1/116.0], # l\n                [1/500.0,     0.0,      0.0], # a\n                [    0.0,     0.0, -1/200.0], # b\n            ])\n            fxfyfz_pixels = tf.matmul(lab_pixels + tf.constant([16.0, 0.0, 0.0]), lab_to_fxfyfz)\n\n            # convert to xyz\n            epsilon = 6/29\n            linear_mask = tf.cast(fxfyfz_pixels <= epsilon, dtype=tf.float32)\n            exponential_mask = tf.cast(fxfyfz_pixels > epsilon, dtype=tf.float32)\n            xyz_pixels = (3 * epsilon**2 * (fxfyfz_pixels - 4/29)) * linear_mask + (fxfyfz_pixels ** 3) * exponential_mask\n\n            # denormalize for D65 white point\n            xyz_pixels = tf.multiply(xyz_pixels, [0.950456, 1.0, 1.088754])\n\n        with tf.name_scope(\'xyz_to_srgb\'):\n            xyz_to_rgb = tf.constant([\n                #     r           g          b\n                [ 3.2404542, -0.9692660,  0.0556434], # x\n                [-1.5371385,  1.8760108, -0.2040259], # y\n                [-0.4985314,  0.0415560,  1.0572252], # z\n            ])\n            rgb_pixels = tf.matmul(xyz_pixels, xyz_to_rgb)\n            # avoid a slightly negative number messing up the conversion\n            rgb_pixels = tf.clip_by_value(rgb_pixels, 0.0, 1.0)\n            linear_mask = tf.cast(rgb_pixels <= 0.0031308, dtype=tf.float32)\n            exponential_mask = tf.cast(rgb_pixels > 0.0031308, dtype=tf.float32)\n            srgb_pixels = (rgb_pixels * 12.92 * linear_mask) + ((rgb_pixels ** (1/2.4) * 1.055) - 0.055) * exponential_mask\n\n        return tf.reshape(srgb_pixels, tf.shape(lab))\n\ndef preprocess_lab(lab):\n    with tf.name_scope(\'preprocess_lab\'):\n        L_chan, a_chan, b_chan = tf.unstack(lab, axis=-1)\n        # L_chan: black and white with input range [0, 100]\n        # a_chan/b_chan: color channels with input range [-128, 127]\n        # [0, 100] => [-1, 1],  ~[-128, 127] => [-1, 1]\n\n        L_chan = L_chan * 255.0 / 100.0\n        a_chan = a_chan + 128\n        b_chan = b_chan + 128\n\n        L_chan /= 255.0\n        a_chan /= 255.0\n        b_chan /= 255.0\n\n        L_chan = (L_chan - 0.5) / 0.5\n        a_chan = (a_chan - 0.5) / 0.5\n        b_chan = (b_chan - 0.5) / 0.5\n\n        return [L_chan, a_chan, b_chan]\n\ndef show_all_variables():\n    model_vars = tf.trainable_variables()\n    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n\ndef check_folder(log_dir):\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    return log_dir\n\ndef str2bool(x):\n    return x.lower() in (\'true\')\n\ndef pytorch_xavier_weight_factor(gain=0.02, uniform=False) :\n\n    if uniform :\n        factor = gain * gain\n        mode = \'FAN_AVG\'\n    else :\n        factor = (gain * gain) / 1.3\n        mode = \'FAN_AVG\'\n\n    return factor, mode, uniform\n\ndef pytorch_kaiming_weight_factor(a=0.0, activation_function=\'relu\', uniform=False) :\n\n    if activation_function == \'relu\' :\n        gain = np.sqrt(2.0)\n    elif activation_function == \'leaky_relu\' :\n        gain = np.sqrt(2.0 / (1 + a ** 2))\n    elif activation_function ==\'tanh\' :\n        gain = 5.0 / 3\n    else :\n        gain = 1.0\n\n    if uniform :\n        factor = gain * gain\n        mode = \'FAN_IN\'\n    else :\n        factor = (gain * gain) / 1.3\n        mode = \'FAN_IN\'\n\n    return factor, mode, uniform'"
