file_path,api_count,code
src/conf.py,0,b'import math\n\ntraining_patience = 6\n\ntraining_batch_size = 128\n\ntraining_default_epochs = 100\n\ntraining_default_aug_mult = 1\n\ntraining_default_aug_percent = 0.0\n\nimage_width = 160\nimage_height = 120\nimage_depth = 3\n\nrow = image_height\ncol = image_width\nch = image_depth\n\n#when we wish to try training for steering and throttle:\nnum_outputs = 2\n\n#when steering alone:\n#num_outputs = 1\n\nthrottle_out_scale = 1.0\n\n'
src/models.py,0,"b'\'\'\'\nModels\nDefine the different NN models we will use\nAuthor: Tawn Kramer\n\'\'\'\nfrom __future__ import print_function\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\nfrom tensorflow.keras.layers import Dense, Lambda, ELU\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.layers import Cropping2D\nfrom tensorflow.keras.optimizers import Adadelta, Adam\n\nimport conf\n\ndef show_model_summary(model):\n    model.summary()\n    for layer in model.layers:\n        print(layer.output_shape)\n\ndef get_nvidia_model(num_outputs):\n    \'\'\'\n    this model is inspired by the NVIDIA paper\n    https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n    Activation is RELU\n    \'\'\'\n    row, col, ch = conf.row, conf.col, conf.ch\n    \n    drop = 0.1\n    \n    img_in = Input(shape=(row, col, ch), name=\'img_in\')\n    x = img_in\n    #x = Cropping2D(cropping=((10,0), (0,0)))(x) #trim 10 pixels off top\n    #x = Lambda(lambda x: x/127.5 - 1.)(x) # normalize and re-center\n    x = Lambda(lambda x: x/255.0)(x)\n    x = Conv2D(24, (5,5), strides=(2,2), activation=\'relu\', name=""conv2d_1"")(x)\n    x = Dropout(drop)(x)\n    x = Conv2D(32, (5,5), strides=(2,2), activation=\'relu\', name=""conv2d_2"")(x)\n    x = Dropout(drop)(x)\n    x = Conv2D(64, (5,5), strides=(2,2), activation=\'relu\', name=""conv2d_3"")(x)\n    x = Dropout(drop)(x)\n    x = Conv2D(64, (3,3), strides=(1,1), activation=\'relu\', name=""conv2d_4"")(x)\n    x = Dropout(drop)(x)\n    x = Conv2D(64, (3,3), strides=(1,1), activation=\'relu\', name=""conv2d_5"")(x)\n    x = Dropout(drop)(x)\n    \n    x = Flatten(name=\'flattened\')(x)\n    x = Dense(100, activation=\'relu\')(x)\n    #x = Dropout(drop)(x)\n    x = Dense(50, activation=\'relu\')(x)\n    #x = Dropout(drop)(x)\n\n    outputs = []\n    outputs.append(Dense(num_outputs, activation=\'linear\', name=\'steering_throttle\')(x))\n    \n        \n    model = Model(inputs=[img_in], outputs=outputs)\n    opt = Adam(lr=0.0001)\n    model.compile(optimizer=opt, loss=""mse"", metrics=[\'acc\'])\n    return model\n'"
src/monitor_client.py,0,"b'#!/usr/bin/env python\n\'\'\'\nPredict Client\nCreate a client to accept image inputs and run them against a trained neural network.\nThis then sends the steering output back to the server.\nAuthor: Tawn Kramer\n\'\'\'\nfrom __future__ import print_function\nimport os\nimport argparse\nimport sys\nimport time\nimport pygame\nimport conf\nimport predict_client\n\npygame.init()\nch, row, col = conf.ch, conf.row, conf.col\n\nsize = (col*2, row*2)\npygame.display.set_caption(""sdsandbox data monitor"")\nscreen = pygame.display.set_mode(size, pygame.DOUBLEBUF)\ncamera_surface = pygame.surface.Surface((col,row),0,24).convert()\nmyfont = pygame.font.SysFont(""monospace"", 15)\n\ndef screen_print(x, y, msg, screen):\n    label = myfont.render(msg, 1, (255,255,0))\n    screen.blit(label, (x, y))\n\ndef display_img(img, steering):\n    img = img.swapaxes(0, 1)\n    # draw frame\n    pygame.surfarray.blit_array(camera_surface, img)\n    camera_surface_2x = pygame.transform.scale2x(camera_surface)\n    screen.blit(camera_surface_2x, (0,0))\n    # steering value\n    screen_print(10, 10, \'NN    :\' + str(steering), screen)\n    pygame.display.flip()\n\n\nif __name__ == ""__main__"":\n  parser = argparse.ArgumentParser(description=\'prediction server with monitor\')\n  parser.add_argument(\'--model\', type=str, help=\'model name. no json or keras.\')\n  args = parser.parse_args()\n \n  address = (\'127.0.0.1\', 9091)\n  \n  try:\n    predict_client.go(args.model, address, constant_throttle=0.3, image_cb=display_img)   \n  except KeyboardInterrupt:\n    print(\'got ctrl+c break\')\n\n  \n\n'"
src/predict_client.py,1,"b'\'\'\'\nPredict Server\nCreate a server to accept image inputs and run them against a trained neural network.\nThis then sends the steering output back to the client.\nAuthor: Tawn Kramer\n\'\'\'\nfrom __future__ import print_function\nimport os\nimport sys\nimport argparse\nimport time\nimport json\nimport base64\nimport datetime\nfrom io import BytesIO\n\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import load_model\nfrom PIL import Image\nimport numpy as np\nfrom gym_donkeycar.core.fps import FPSTimer\nfrom gym_donkeycar.core.message import IMesgHandler\nfrom gym_donkeycar.core.sim_client import SimClient\n\nimport conf\nimport models\n\n\n\nif tf.__version__ == \'1.13.1\':\n    from tensorflow import ConfigProto, Session\n\n    # Override keras session to work around a bug in TF 1.13.1\n    # Remove after we upgrade to TF 1.14 / TF 2.x.\n    config = ConfigProto()\n    config.gpu_options.allow_growth = True\n    session = Session(config=config)\n    keras.backend.set_session(session)\n\n\n\nclass DonkeySimMsgHandler(IMesgHandler):\n\n    STEERING = 0\n    THROTTLE = 1\n\n    def __init__(self, model, constant_throttle, image_cb=None, rand_seed=0):\n        self.model = model\n        self.constant_throttle = constant_throttle\n        self.client = None\n        self.timer = FPSTimer()\n        self.img_arr = None\n        self.image_cb = image_cb\n        self.steering_angle = 0.\n        self.throttle = 0.\n        self.rand_seed = rand_seed\n        self.fns = {\'telemetry\' : self.on_telemetry,\\\n                    \'car_loaded\' : self.on_car_created,\\\n                    \'on_disconnect\' : self.on_disconnect,\n                    \'aborted\' : self.on_aborted}\n\n    def on_connect(self, client):\n        self.client = client\n        self.timer.reset()\n\n    def on_aborted(self, msg):\n        self.stop()\n\n    def on_disconnect(self):\n        pass\n\n    def on_recv_message(self, message):\n        self.timer.on_frame()\n        if not \'msg_type\' in message:\n            print(\'expected msg_type field\')\n            print(""message:"", message)\n            return\n\n        msg_type = message[\'msg_type\']\n        if msg_type in self.fns:\n            self.fns[msg_type](message)\n        else:\n            print(\'unknown message type\', msg_type)\n\n    def on_car_created(self, data):\n        if self.rand_seed != 0:\n            self.send_regen_road(0, self.rand_seed, 1.0)\n\n    def on_telemetry(self, data):\n        imgString = data[""image""]\n        image = Image.open(BytesIO(base64.b64decode(imgString)))\n        img_arr = np.asarray(image, dtype=np.float32)\n        self.img_arr = img_arr.reshape((1,) + img_arr.shape)\n\n        if self.image_cb is not None:\n            self.image_cb(img_arr, self.steering_angle )\n\n    def update(self):\n        if self.img_arr is not None:\n            self.predict(self.img_arr)\n            self.img_arr = None\n\n    def predict(self, image_array):\n        outputs = self.model.predict(image_array)\n        self.parse_outputs(outputs)\n\n\n    def parse_outputs(self, outputs):\n        res = []\n\n        # Expects the model with final Dense(2) with steering and throttle\n        for i in range(outputs.shape[1]):\n            res.append(outputs[0][i])\n\n        self.on_parsed_outputs(res)\n        \n    def on_parsed_outputs(self, outputs):\n        self.outputs = outputs\n        self.steering_angle = 0.0\n        self.throttle = 0.2\n\n        if len(outputs) > 0:        \n            self.steering_angle = outputs[self.STEERING]\n\n        if self.constant_throttle != 0.0:\n            self.throttle = self.constant_throttle\n        elif len(outputs) > 1:\n            self.throttle = outputs[self.THROTTLE] * conf.throttle_out_scale\n\n        self.send_control(self.steering_angle, self.throttle)\n\n    def send_control(self, steer, throttle):\n        # print(""send st:"", steer, ""th:"", throttle)\n        msg = { \'msg_type\' : \'control\', \'steering\': steer.__str__(), \'throttle\':throttle.__str__(), \'brake\': \'0.0\' }\n        self.client.queue_message(msg)\n\n    def send_regen_road(self, road_style=0, rand_seed=0, turn_increment=0.0):\n        \'\'\'\n        Regenerate the road, where available. For now only in level 0.\n        In level 0 there are currently 5 road styles. This changes the texture on the road\n        and also the road width.\n        The rand_seed can be used to get some determinism in road generation.\n        The turn_increment defaults to 1.0 internally. Provide a non zero positive float\n        to affect the curviness of the road. Smaller numbers will provide more shallow curves.\n        \'\'\'\n        msg = { \'msg_type\' : \'regen_road\',\n            \'road_style\': road_style.__str__(),\n            \'rand_seed\': rand_seed.__str__(),\n            \'turn_increment\': turn_increment.__str__() }\n        \n        self.client.queue_message(msg)\n\n    def stop(self):\n        self.client.stop()\n\n    def __del__(self):\n        self.stop()\n\n\n\ndef clients_connected(arr):\n    for client in arr:\n        if not client.is_connected():\n            return False\n    return True\n\n\ndef go(filename, address, constant_throttle=0, num_cars=1, image_cb=None, rand_seed=None):\n\n    print(""loading model"", filename)\n    model = load_model(filename)\n\n    # In this mode, looks like we have to compile it\n    model.compile(""sgd"", ""mse"")\n\n    clients = []\n\n    for _ in range(0, num_cars):\n        # setup the clients\n        handler = DonkeySimMsgHandler(model, constant_throttle, image_cb=image_cb, rand_seed=rand_seed)\n        client = SimClient(address, handler)\n        clients.append(client)\n\n    while clients_connected(clients):\n        try:\n            time.sleep(0.02)\n            for client in clients:\n                client.msg_handler.update()\n        except KeyboardInterrupt:\n            # unless some hits Ctrl+C and then we get this interrupt\n            print(\'stopping\')\n            break\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'prediction server\')\n    parser.add_argument(\'--model\', type=str, help=\'model filename\')\n    parser.add_argument(\'--host\', type=str, default=\'127.0.0.1\', help=\'server sim host\')\n    parser.add_argument(\'--port\', type=int, default=9091, help=\'bind to port\')\n    parser.add_argument(\'--num_cars\', type=int, default=1, help=\'how many cars to spawn\')\n    parser.add_argument(\'--constant_throttle\', type=float, default=0.0, help=\'apply constant throttle\')\n    parser.add_argument(\'--rand_seed\', type=int, default=0, help=\'set road generation random seed\')\n    args = parser.parse_args()\n\n    address = (args.host, args.port)\n    go(args.model, address, args.constant_throttle, num_cars=args.num_cars, rand_seed=args.rand_seed)\n'"
src/prepare_data.py,0,"b'#!/usr/bin/env python\n\'\'\'\nPrepare Data\nMove log data into place for training\nAuthor: Tawn Kramer\n\'\'\'\nfrom __future__ import print_function\nimport os\nimport time\nimport glob\nimport shutil\n\n\ndef prepare(src_path, dest_path):\n\n    #make a new filename that uses the last modified time stamp\n    #on the dir with the driving log. replace illegal filename characers.\n    src_basename, filemask = os.path.split(src_path)\n    t = time.ctime(os.path.getmtime(src_basename))\n    t = t.replace(\' \', \'_\')\n    t = t.replace(\':\', \'_\')\n\n\n    #we save the steering, and other single channel data to log, images to camera\n    basepath_log = os.path.join(dest_path, ""log"")\n\n    #make sure these paths exist so the file open will succeed\n    if not os.path.exists(basepath_log):\n        os.makedirs(basepath_log)\n\n    log_path = os.path.join(basepath_log, ""logs_"" + t)\n    os.makedirs(log_path)\n    \n    #do a directery listing of all images\n    print(\'gathering images\', src_path)\n    images = glob.glob(src_path)\n    \n    for img_filename in images:\n        path, name = os.path.split(img_filename)\n        dest_fnm = os.path.join(log_path, name)\n        shutil.move(img_filename, dest_fnm)\n\nif __name__ == ""__main__"":\n    import argparse\n\n    # Parameters\n    parser = argparse.ArgumentParser(description=\'Prepare training data from logs and images\')\n    parser.add_argument(\'--log-src\', dest=\'log_src\', default=\'../sdsim/log/*.*\', help=\'path to log data\')\n    parser.add_argument(\'--out-path\', dest=\'out_path\', default=\'../dataset/\', help=\'path for output.\')\n    \n    args, more = parser.parse_known_args()\n\n    prepare(args.log_src, args.out_path)\n'"
src/test_client.py,0,"b'import os\nimport random\nimport json\nimport time\nfrom io import BytesIO\nimport base64\n\nfrom PIL import Image\nimport numpy as np\nfrom gym_donkeycar.core.sim_client import SDClient\n\n\n###########################################\n\nclass SimpleClient(SDClient):\n\n    def __init__(self, address, poll_socket_sleep_time=0.01):\n        super().__init__(*address, poll_socket_sleep_time=poll_socket_sleep_time)\n        self.last_image = None\n        self.car_loaded = False\n\n    def on_msg_recv(self, json_packet):\n\n        if json_packet[\'msg_type\'] == ""car_loaded"":\n            self.car_loaded = True\n        \n        if json_packet[\'msg_type\'] == ""telemetry"":\n            imgString = json_packet[""image""]\n            image = Image.open(BytesIO(base64.b64decode(imgString)))\n            image.save(""test.png"")\n            self.last_image = np.asarray(image)\n            print(""img:"", self.last_image.shape)\n\n            #don\'t have to, but to clean up the print, delete the image string.\n            del json_packet[""image""]\n\n        print(""got:"", json_packet)\n\n\n    def send_controls(self, steering, throttle):\n        p = { ""msg_type"" : ""control"",\n                ""steering"" : steering.__str__(),\n                ""throttle"" : throttle.__str__(),\n                ""brake"" : ""0.0"" }\n        msg = json.dumps(p)\n        self.send(msg)\n\n        #this sleep lets the SDClient thread poll our message and send it out.\n        time.sleep(self.poll_socket_sleep_sec)\n\n    def update(self):\n        # just random steering now\n        st = random.random() * 2.0 - 1.0\n        th = 0.3\n        self.send_controls(st, th)\n\n\n\n###########################################\n## Make some clients and have them connect with the simulator\n\ndef test_clients():\n    # test params\n    host = ""127.0.0.1"" # ""trainmydonkey.com"" for virtual racing server\n    port = 9091\n    num_clients = 1\n    clients = []\n    time_to_drive = 1.0\n\n\n    # Start Clients\n    for _ in range(0, num_clients):\n        c = SimpleClient(address=(host, port))\n        clients.append(c)\n\n    time.sleep(1)\n\n    # Load Scene message. Only one client needs to send the load scene.\n    msg = \'{ ""msg_type"" : ""load_scene"", ""scene_name"" : ""generated_track"" }\'\n    clients[0].send(msg)\n\n    # Wait briefly for the scene to load.\n    loaded = False\n    while(not loaded):\n        time.sleep(1.0)\n        for c in clients:\n            loaded = c.car_loaded           \n        \n\n    # Car config\n    msg = \'{ ""msg_type"" : ""car_config"", ""body_style"" : ""car01"", ""body_r"" : ""255"", ""body_g"" : ""0"", ""body_b"" : ""255"", ""car_name"" : ""Tawn"", ""font_size"" : ""100"" }\'\n    clients[0].send(msg)\n    time.sleep(1)\n\n    # Camera config\n    # set any field to Zero to get the default camera setting.\n    # this will position the camera right above the car, with max fisheye and wide fov\n    # this also changes the img output to 255x255x1 ( actually 255x255x3 just all three channels have same value)\n    # the offset_x moves camera left/right\n    # the offset_y moves camera up/down\n    # the offset_z moves camera forward/back\n    # with fish_eye_x/y == 0.0 then you get no distortion\n    # img_enc can be one of JPG|PNG|TGA\n    msg = \'{ ""msg_type"" : ""cam_config"", ""fov"" : ""150"", ""fish_eye_x"" : ""1.0"", ""fish_eye_y"" : ""1.0"", ""img_w"" : ""255"", ""img_h"" : ""255"", ""img_d"" : ""1"", ""img_enc"" : ""PNG"", ""offset_x"" : ""0.0"", ""offset_y"" : ""3.0"", ""offset_z"" : ""0.0"", ""rot_x"" : ""90.0"" }\'\n    clients[0].send(msg)\n    time.sleep(1)\n\n\n    # Send random driving controls\n    start = time.time()\n    do_drive = True\n    while time.time() - start < time_to_drive and do_drive:\n        for c in clients:\n            c.update()\n            if c.aborted:\n                print(""Client socket problem, stopping driving."")\n                do_drive = False\n\n    time.sleep(1.0)\n\n    # Exist Scene\n    msg = \'{ ""msg_type"" : ""exit_scene"" }\'\n    clients[0].send(msg)\n\n    time.sleep(1.0)\n\n    # Close down clients\n    print(""waiting for msg loop to stop"")\n    for c in clients:\n        c.stop()\n\n    print(""clients to stopped"")\n\n\n\nif __name__ == ""__main__"":\n    test_clients()\n\n'"
src/train.py,0,"b'\'\'\'\nTrain\nTrain your nerual network\nAuthor: Tawn Kramer\n\'\'\'\nfrom __future__ import print_function\nimport os\nimport sys\nimport glob\nimport time\nimport fnmatch\nimport argparse\nimport random\nimport json\n\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow import keras\n\nimport conf\nimport models\n\n\'\'\'\nmatplotlib can be a pain to setup. So handle the case where it is absent. When present,\nuse it to generate a plot of training results.\n\'\'\'\ntry:\n    import matplotlib\n    # Force matplotlib to not use any Xwindows backend.\n    matplotlib.use(\'Agg\')\n\n    import matplotlib.pyplot as plt\n    do_plot = True\nexcept:\n    do_plot = False\n\n\ndef shuffle(samples):\n    \'\'\'\n    randomly mix a list and return a new list\n    \'\'\'\n    ret_arr = []\n    len_samples = len(samples)\n    while len_samples > 0:\n        iSample = random.randrange(0, len_samples)\n        ret_arr.append(samples[iSample])\n        del samples[iSample]\n        len_samples -= 1\n    return ret_arr\n\ndef load_json(filename):\n    with open(filename, ""rt"") as fp:\n        data = json.load(fp)\n    return data\n\ndef generator(samples, batch_size=64,):\n    \'\'\'\n    Rather than keep all data in memory, we will make a function that keeps\n    it\'s state and returns just the latest batch required via the yield command.\n    \n    As we load images, we can optionally augment them in some manner that doesn\'t\n    change their underlying meaning or features. This is a combination of\n    brightness, contrast, sharpness, and color PIL image filters applied with random\n    settings. Optionally a shadow image may be overlayed with some random rotation and\n    opacity.\n    We flip each image horizontally and supply it as a another sample with the steering\n    negated.\n    \'\'\'\n    num_samples = len(samples)\n    \n    while 1: # Loop forever so the generator never terminates\n        samples = shuffle(samples)\n        #divide batch_size in half, because we double each output by flipping image.\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = samples[offset:offset+batch_size]\n            \n            images = []\n            controls = []\n            for fullpath in batch_samples:\n                try:\n                \n                    frame_number = os.path.basename(fullpath).split(""_"")[0]\n                    json_filename = os.path.join(os.path.dirname(fullpath), ""record_"" + frame_number + "".json"")\n                    data = load_json(json_filename)\n                    steering = float(data[""user/angle""])\n                    throttle = float(data[""user/throttle""])\n                \n                    try:\n                        image = Image.open(fullpath)\n                    except:\n                        print(\'failed to open\', fullpath)\n                        continue\n\n                    #PIL Image as a numpy array\n                    image = np.array(image, dtype=np.float32)\n\n                    images.append(image)\n                    \n                    if conf.num_outputs == 2:\n                        controls.append([steering, throttle])\n                    elif conf.num_outputs == 1:\n                        controls.append([steering])\n                    else:\n                        print(""expected 1 or 2 outputs"")\n\n                except Exception as e:\n                    print(e)\n                    print(""we threw an exception on:"", fullpath)\n                    yield [], []\n\n\n            # final np array to submit to training\n            X_train = np.array(images)\n            y_train = np.array(controls)\n            yield X_train, y_train\n\n\ndef get_files(filemask):\n    \'\'\'\n    use a filemask and search a path recursively for matches\n    \'\'\'\n    #matches = glob.glob(os.path.expanduser(filemask))\n    #return matches\n    filemask = os.path.expanduser(filemask)\n    path, mask = os.path.split(filemask)\n    \n    matches = []\n    for root, dirnames, filenames in os.walk(path):\n        for filename in fnmatch.filter(filenames, mask):\n            matches.append(os.path.join(root, filename))\n    return matches\n\n\ndef train_test_split(lines, test_perc):\n    \'\'\'\n    split a list into two parts, percentage of test used to seperate\n    \'\'\'\n    train = []\n    test = []\n\n    for line in lines:\n        if random.uniform(0.0, 1.0) < test_perc:\n            test.append(line)\n        else:\n            train.append(line)\n\n    return train, test\n\ndef make_generators(inputs, limit=None, batch_size=64):\n    \'\'\'\n    load the job spec from the csv and create some generator for training\n    \'\'\'\n    \n    #get the image/steering pairs from the csv files\n    lines = get_files(inputs)\n    print(""found %d files"" % len(lines))\n\n    if limit is not None:\n        lines = lines[:limit]\n        print(""limiting to %d files"" % len(lines))\n    \n    train_samples, validation_samples = train_test_split(lines, test_perc=0.2)\n\n    print(""num train/val"", len(train_samples), len(validation_samples))\n    \n    # compile and train the model using the generator function\n    train_generator = generator(train_samples, batch_size=batch_size)\n    validation_generator = generator(validation_samples, batch_size=batch_size)\n    \n    n_train = len(train_samples)\n    n_val = len(validation_samples)\n    \n    return train_generator, validation_generator, n_train, n_val\n\n\ndef go(model_name, epochs=50, inputs=\'./log/*.jpg\', limit=None):\n\n    print(\'working on model\', model_name)\n\n    \'\'\'\n    modify config.json to select the model to train.\n    \'\'\'\n    model = models.get_nvidia_model(conf.num_outputs)\n\n    \'\'\'\n    display layer summary and weights info\n    \'\'\'\n    #models.show_model_summary(model)\n\n    callbacks = [\n        keras.callbacks.EarlyStopping(monitor=\'val_loss\', patience=conf.training_patience, verbose=0),\n        keras.callbacks.ModelCheckpoint(model_name, monitor=\'val_loss\', save_best_only=True, verbose=0),\n    ]\n    \n    batch_size = conf.training_batch_size\n\n\n    #Train on session images\n    train_generator, validation_generator, n_train, n_val = make_generators(inputs, limit=limit, batch_size=batch_size)\n\n    if n_train == 0:\n        print(\'no training data found\')\n        return\n\n    steps_per_epoch = n_train // batch_size\n    validation_steps = n_val // batch_size\n\n    print(""steps_per_epoch"", steps_per_epoch, ""validation_steps"", validation_steps)\n\n    history = model.fit_generator(train_generator, \n        steps_per_epoch = steps_per_epoch,\n        validation_data = validation_generator,\n        validation_steps = validation_steps,\n        epochs=epochs,\n        verbose=1,\n        callbacks=callbacks)\n    \n    try:\n        if do_plot:\n            # summarize history for loss\n            plt.plot(history.history[\'loss\'])\n            plt.plot(history.history[\'val_loss\'])\n            plt.title(\'model loss\')\n            plt.ylabel(\'loss\')\n            plt.xlabel(\'epoch\')\n            plt.legend([\'train\', \'test\'], loc=\'upper left\')\n            plt.savefig(\'loss.png\')\n    except:\n        print(""problems with loss graph"")\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'train script\')\n    parser.add_argument(\'--model\', type=str, help=\'model name\')\n    parser.add_argument(\'--epochs\', type=int, default=conf.training_default_epochs, help=\'number of epochs\')\n    parser.add_argument(\'--inputs\', default=\'../dataset/log/*.jpg\', help=\'input mask to gather images\')\n    parser.add_argument(\'--limit\', type=int, default=None, help=\'max number of images to train with\')\n    args = parser.parse_args()\n    \n    go(args.model, epochs=args.epochs, limit=args.limit, inputs=args.inputs)\n\n#python train.py ..\\outputs\\mymodel_aug_90_x4_e200 --epochs=200\n'"
