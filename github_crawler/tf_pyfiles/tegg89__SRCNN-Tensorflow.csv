file_path,api_count,code
main.py,3,"b'from model import SRCNN\nfrom utils import input_setup\n\nimport numpy as np\nimport tensorflow as tf\n\nimport pprint\nimport os\n\nflags = tf.app.flags\nflags.DEFINE_integer(""epoch"", 15000, ""Number of epoch [15000]"")\nflags.DEFINE_integer(""batch_size"", 128, ""The size of batch images [128]"")\nflags.DEFINE_integer(""image_size"", 33, ""The size of image to use [33]"")\nflags.DEFINE_integer(""label_size"", 21, ""The size of label to produce [21]"")\nflags.DEFINE_float(""learning_rate"", 1e-4, ""The learning rate of gradient descent algorithm [1e-4]"")\nflags.DEFINE_integer(""c_dim"", 1, ""Dimension of image color. [1]"")\nflags.DEFINE_integer(""scale"", 3, ""The size of scale factor for preprocessing input image [3]"")\nflags.DEFINE_integer(""stride"", 14, ""The size of stride to apply input image [14]"")\nflags.DEFINE_string(""checkpoint_dir"", ""checkpoint"", ""Name of checkpoint directory [checkpoint]"")\nflags.DEFINE_string(""sample_dir"", ""sample"", ""Name of sample directory [sample]"")\nflags.DEFINE_boolean(""is_train"", True, ""True for training, False for testing [True]"")\nFLAGS = flags.FLAGS\n\npp = pprint.PrettyPrinter()\n\ndef main(_):\n  pp.pprint(flags.FLAGS.__flags)\n\n  if not os.path.exists(FLAGS.checkpoint_dir):\n    os.makedirs(FLAGS.checkpoint_dir)\n  if not os.path.exists(FLAGS.sample_dir):\n    os.makedirs(FLAGS.sample_dir)\n\n  with tf.Session() as sess:\n    srcnn = SRCNN(sess, \n                  image_size=FLAGS.image_size, \n                  label_size=FLAGS.label_size, \n                  batch_size=FLAGS.batch_size,\n                  c_dim=FLAGS.c_dim, \n                  checkpoint_dir=FLAGS.checkpoint_dir,\n                  sample_dir=FLAGS.sample_dir)\n\n    srcnn.train(FLAGS)\n    \nif __name__ == \'__main__\':\n  tf.app.run()\n'"
model.py,16,"b'from utils import (\n  read_data, \n  input_setup, \n  imsave,\n  merge\n)\n\nimport time\nimport os\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\n\ntry:\n  xrange\nexcept:\n  xrange = range\n\nclass SRCNN(object):\n\n  def __init__(self, \n               sess, \n               image_size=33,\n               label_size=21, \n               batch_size=128,\n               c_dim=1, \n               checkpoint_dir=None, \n               sample_dir=None):\n\n    self.sess = sess\n    self.is_grayscale = (c_dim == 1)\n    self.image_size = image_size\n    self.label_size = label_size\n    self.batch_size = batch_size\n\n    self.c_dim = c_dim\n\n    self.checkpoint_dir = checkpoint_dir\n    self.sample_dir = sample_dir\n    self.build_model()\n\n  def build_model(self):\n    self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, self.c_dim], name=\'images\')\n    self.labels = tf.placeholder(tf.float32, [None, self.label_size, self.label_size, self.c_dim], name=\'labels\')\n    \n    self.weights = {\n      \'w1\': tf.Variable(tf.random_normal([9, 9, 1, 64], stddev=1e-3), name=\'w1\'),\n      \'w2\': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name=\'w2\'),\n      \'w3\': tf.Variable(tf.random_normal([5, 5, 32, 1], stddev=1e-3), name=\'w3\')\n    }\n    self.biases = {\n      \'b1\': tf.Variable(tf.zeros([64]), name=\'b1\'),\n      \'b2\': tf.Variable(tf.zeros([32]), name=\'b2\'),\n      \'b3\': tf.Variable(tf.zeros([1]), name=\'b3\')\n    }\n\n    self.pred = self.model()\n\n    # Loss function (MSE)\n    self.loss = tf.reduce_mean(tf.square(self.labels - self.pred))\n\n    self.saver = tf.train.Saver()\n\n  def train(self, config):\n    if config.is_train:\n      input_setup(self.sess, config)\n    else:\n      nx, ny = input_setup(self.sess, config)\n\n    if config.is_train:     \n      data_dir = os.path.join(\'./{}\'.format(config.checkpoint_dir), ""train.h5"")\n    else:\n      data_dir = os.path.join(\'./{}\'.format(config.checkpoint_dir), ""test.h5"")\n\n    train_data, train_label = read_data(data_dir)\n\n    # Stochastic gradient descent with the standard backpropagation\n    self.train_op = tf.train.GradientDescentOptimizer(config.learning_rate).minimize(self.loss)\n\n    tf.initialize_all_variables().run()\n    \n    counter = 0\n    start_time = time.time()\n\n    if self.load(self.checkpoint_dir):\n      print("" [*] Load SUCCESS"")\n    else:\n      print("" [!] Load failed..."")\n\n    if config.is_train:\n      print(""Training..."")\n\n      for ep in xrange(config.epoch):\n        # Run by batch images\n        batch_idxs = len(train_data) // config.batch_size\n        for idx in xrange(0, batch_idxs):\n          batch_images = train_data[idx*config.batch_size : (idx+1)*config.batch_size]\n          batch_labels = train_label[idx*config.batch_size : (idx+1)*config.batch_size]\n\n          counter += 1\n          _, err = self.sess.run([self.train_op, self.loss], feed_dict={self.images: batch_images, self.labels: batch_labels})\n\n          if counter % 10 == 0:\n            print(""Epoch: [%2d], step: [%2d], time: [%4.4f], loss: [%.8f]"" \\\n              % ((ep+1), counter, time.time()-start_time, err))\n\n          if counter % 500 == 0:\n            self.save(config.checkpoint_dir, counter)\n\n    else:\n      print(""Testing..."")\n\n      result = self.pred.eval({self.images: train_data, self.labels: train_label})\n\n      result = merge(result, [nx, ny])\n      result = result.squeeze()\n      image_path = os.path.join(os.getcwd(), config.sample_dir)\n      image_path = os.path.join(image_path, ""test_image.png"")\n      imsave(result, image_path)\n\n  def model(self):\n    conv1 = tf.nn.relu(tf.nn.conv2d(self.images, self.weights[\'w1\'], strides=[1,1,1,1], padding=\'VALID\') + self.biases[\'b1\'])\n    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, self.weights[\'w2\'], strides=[1,1,1,1], padding=\'VALID\') + self.biases[\'b2\'])\n    conv3 = tf.nn.conv2d(conv2, self.weights[\'w3\'], strides=[1,1,1,1], padding=\'VALID\') + self.biases[\'b3\']\n    return conv3\n\n  def save(self, checkpoint_dir, step):\n    model_name = ""SRCNN.model""\n    model_dir = ""%s_%s"" % (""srcnn"", self.label_size)\n    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n\n    self.saver.save(self.sess,\n                    os.path.join(checkpoint_dir, model_name),\n                    global_step=step)\n\n  def load(self, checkpoint_dir):\n    print("" [*] Reading checkpoints..."")\n    model_dir = ""%s_%s"" % (""srcnn"", self.label_size)\n    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n\n    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n    if ckpt and ckpt.model_checkpoint_path:\n        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n        self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n        return True\n    else:\n        return False\n'"
utils.py,1,"b'""""""\nScipy version > 0.18 is needed, due to \'mode\' option from scipy.misc.imread function\n""""""\n\nimport os\nimport glob\nimport h5py\nimport random\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image  # for loading images as YCbCr format\nimport scipy.misc\nimport scipy.ndimage\nimport numpy as np\n\nimport tensorflow as tf\n\ntry:\n  xrange\nexcept:\n  xrange = range\n  \nFLAGS = tf.app.flags.FLAGS\n\ndef read_data(path):\n  """"""\n  Read h5 format data file\n  \n  Args:\n    path: file path of desired file\n    data: \'.h5\' file format that contains train data values\n    label: \'.h5\' file format that contains train label values\n  """"""\n  with h5py.File(path, \'r\') as hf:\n    data = np.array(hf.get(\'data\'))\n    label = np.array(hf.get(\'label\'))\n    return data, label\n\ndef preprocess(path, scale=3):\n  """"""\n  Preprocess single image file \n    (1) Read original image as YCbCr format (and grayscale as default)\n    (2) Normalize\n    (3) Apply image file with bicubic interpolation\n\n  Args:\n    path: file path of desired file\n    input_: image applied bicubic interpolation (low-resolution)\n    label_: image with original resolution (high-resolution)\n  """"""\n  image = imread(path, is_grayscale=True)\n  label_ = modcrop(image, scale)\n\n  # Must be normalized\n  image = image / 255.\n  label_ = label_ / 255.\n\n  input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n  input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n\n  return input_, label_\n\ndef prepare_data(sess, dataset):\n  """"""\n  Args:\n    dataset: choose train dataset or test dataset\n    \n    For train dataset, output data would be [\'.../t1.bmp\', \'.../t2.bmp\', ..., \'.../t99.bmp\']\n  """"""\n  if FLAGS.is_train:\n    filenames = os.listdir(dataset)\n    data_dir = os.path.join(os.getcwd(), dataset)\n    data = glob.glob(os.path.join(data_dir, ""*.bmp""))\n  else:\n    data_dir = os.path.join(os.sep, (os.path.join(os.getcwd(), dataset)), ""Set5"")\n    data = glob.glob(os.path.join(data_dir, ""*.bmp""))\n\n  return data\n\ndef make_data(sess, data, label):\n  """"""\n  Make input data as h5 file format\n  Depending on \'is_train\' (flag value), savepath would be changed.\n  """"""\n  if FLAGS.is_train:\n    savepath = os.path.join(os.getcwd(), \'checkpoint/train.h5\')\n  else:\n    savepath = os.path.join(os.getcwd(), \'checkpoint/test.h5\')\n\n  with h5py.File(savepath, \'w\') as hf:\n    hf.create_dataset(\'data\', data=data)\n    hf.create_dataset(\'label\', data=label)\n\ndef imread(path, is_grayscale=True):\n  """"""\n  Read image using its path.\n  Default value is gray-scale, and image is read by YCbCr format as the paper said.\n  """"""\n  if is_grayscale:\n    return scipy.misc.imread(path, flatten=True, mode=\'YCbCr\').astype(np.float)\n  else:\n    return scipy.misc.imread(path, mode=\'YCbCr\').astype(np.float)\n\ndef modcrop(image, scale=3):\n  """"""\n  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n  \n  We need to find modulo of height (and width) and scale factor.\n  Then, subtract the modulo from height (and width) of original image size.\n  There would be no remainder even after scaling operation.\n  """"""\n  if len(image.shape) == 3:\n    h, w, _ = image.shape\n    h = h - np.mod(h, scale)\n    w = w - np.mod(w, scale)\n    image = image[0:h, 0:w, :]\n  else:\n    h, w = image.shape\n    h = h - np.mod(h, scale)\n    w = w - np.mod(w, scale)\n    image = image[0:h, 0:w]\n  return image\n\ndef input_setup(sess, config):\n  """"""\n  Read image files and make their sub-images and saved them as a h5 file format.\n  """"""\n  # Load data path\n  if config.is_train:\n    data = prepare_data(sess, dataset=""Train"")\n  else:\n    data = prepare_data(sess, dataset=""Test"")\n\n  sub_input_sequence = []\n  sub_label_sequence = []\n  padding = abs(config.image_size - config.label_size) / 2 # 6\n\n  if config.is_train:\n    for i in xrange(len(data)):\n      input_, label_ = preprocess(data[i], config.scale)\n\n      if len(input_.shape) == 3:\n        h, w, _ = input_.shape\n      else:\n        h, w = input_.shape\n\n      for x in range(0, h-config.image_size+1, config.stride):\n        for y in range(0, w-config.image_size+1, config.stride):\n          sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n          sub_label = label_[x+int(padding):x+int(padding)+config.label_size, y+int(padding):y+int(padding)+config.label_size] # [21 x 21]\n\n          # Make channel value\n          sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n          sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n\n          sub_input_sequence.append(sub_input)\n          sub_label_sequence.append(sub_label)\n\n  else:\n    input_, label_ = preprocess(data[2], config.scale)\n\n    if len(input_.shape) == 3:\n      h, w, _ = input_.shape\n    else:\n      h, w = input_.shape\n\n    # Numbers of sub-images in height and width of image are needed to compute merge operation.\n    nx = ny = 0 \n    for x in range(0, h-config.image_size+1, config.stride):\n      nx += 1; ny = 0\n      for y in range(0, w-config.image_size+1, config.stride):\n        ny += 1\n        sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n        sub_label = label_[x+int(padding):x+int(padding)+config.label_size, y+int(padding):y+int(padding)+config.label_size] # [21 x 21]\n        \n        sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n        sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n\n        sub_input_sequence.append(sub_input)\n        sub_label_sequence.append(sub_label)\n\n  """"""\n  len(sub_input_sequence) : the number of sub_input (33 x 33 x ch) in one image\n  (sub_input_sequence[0]).shape : (33, 33, 1)\n  """"""\n  # Make list to numpy array. With this transform\n  arrdata = np.asarray(sub_input_sequence) # [?, 33, 33, 1]\n  arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 1]\n\n  make_data(sess, arrdata, arrlabel)\n\n  if not config.is_train:\n    return nx, ny\n    \ndef imsave(image, path):\n  return scipy.misc.imsave(path, image)\n\ndef merge(images, size):\n  h, w = images.shape[1], images.shape[2]\n  img = np.zeros((h*size[0], w*size[1], 1))\n  for idx, image in enumerate(images):\n    i = idx % size[1]\n    j = idx // size[1]\n    img[j*h:j*h+h, i*w:i*w+w, :] = image\n\n  return img\n'"
